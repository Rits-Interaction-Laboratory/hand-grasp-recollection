{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.5.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from PIL import ImageStat\n",
    "from pathlib import Path\n",
    "import urllib.request\n",
    "import zipfile\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.utils.data as data\n",
    "from torchvision import transforms\n",
    "import csv\n",
    "import pprint\n",
    "import math\n",
    "\n",
    "print(torch.__version__)  # 1.3.1\n",
    "\n",
    "#urllib.request.urlretrieve(\n",
    "#    \"https://download.pytorch.org/tutorial/hymenoptera_data.zip\", \n",
    "#    \"hymenoptera_data.zip\"\n",
    "#)\n",
    "\n",
    "#with zipfile.ZipFile(\"./hymenoptera_data.zip\") as zip:\n",
    "#    zip.extractall(\".\")\n",
    "    \n",
    "#print(list(Path(\"hymenoptera_data/val\").glob(\"**/*.jpg\"))[:4])\n",
    "# [PosixPath('hymenoptera_data/val/bees/2478216347_535c8fe6d7.jpg'),\n",
    "#  PosixPath('hymenoptera_data/val/bees/1486120850_490388f84b.jpg'),\n",
    "#  PosixPath('hymenoptera_data/val/bees/2060668999_e11edb10d0.jpg'),\n",
    "#  PosixPath('hymenoptera_data/val/bees/2104135106_a65eede1de.jpg')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Resize(size=(224, 224), interpolation=PIL.Image.BILINEAR), ToTensor()]\n",
      "[Resize(size=(224, 224), interpolation=PIL.Image.BILINEAR), ToTensor()]\n",
      "3868.0\n",
      "2918.0\n",
      "torch.Size([1, 224, 224]) [-585, -25, 211, -566, -22, 218, -553, 4, 258, -551, 28, 276, -572, 40, 376, -570, 43, 241, -10000, -10000, -10000, -10000, -10000, -10000, -10000, -10000, -10000, -593, 41, 280, -665, 33, 614, -10000, -10000, -10000, -577, 58, 335, -605, 37, 285, -678, 26, 608, -592, 53, 320, -581, 49, 302, -10000, -10000, -10000, -10000, -10000, -10000, -587, 50, 266, -579, 44, 259]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[0.9116, 0.9146, 0.9236,  ..., 0.5379, 0.5379, 0.5379],\n",
       "         [0.9116, 0.9146, 0.9236,  ..., 0.5379, 0.5379, 0.5379],\n",
       "         [0.9116, 0.9146, 0.9236,  ..., 0.5379, 0.5379, 0.5379],\n",
       "         ...,\n",
       "         [0.3077, 0.3076, 0.3074,  ..., 0.0648, 0.0648, 0.0648],\n",
       "         [0.3063, 0.3063, 0.3063,  ..., 0.0653, 0.0653, 0.0653],\n",
       "         [0.3063, 0.3063, 0.3063,  ..., 0.0653, 0.0653, 0.0653]]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyDataset(data.Dataset):\n",
    "    def __init__(self, dir_path, input_size, phase):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.dir_path = dir_path\n",
    "        self.input_size = input_size\n",
    "        \n",
    "        # hymenoptera_data/{train or val}/{ants or bees}/ファイル名.jpg\n",
    "        # ex. hymenoptera_data/val/bees/2478216347_535c8fe6d7.jpg\n",
    "        self.image_paths = [str(p) for p in Path(self.dir_path).glob(\"image/*.png\")]\n",
    "        self.label_paths = [str(q) for q in Path(self.dir_path).glob(\"label/*.csv\")]\n",
    "        self.len = len(self.image_paths)\n",
    "        \n",
    "        transform_ops = []\n",
    "        if phase == \"train\":\n",
    "            transform_ops.append(\n",
    "                transforms.Resize(input_size)# リサイズ\n",
    "            )\n",
    "            #transform_ops.extend([\n",
    "                #transforms.RandomVerticalFlip(),  # ランダムに左右反転\n",
    "                #transforms.RandomRotation(20),  # ±20度でランダムに回転\n",
    "                #transforms.RandomResizedCrop(input_size, scale=(0.8, 1.0))  # ランダムにクロップしてリサイズ\n",
    "            #])\n",
    "        elif phase == \"val\":\n",
    "            transform_ops.append(\n",
    "                transforms.Resize(input_size)  # リサイズ\n",
    "            )\n",
    "            \n",
    "        transform_ops.extend([\n",
    "            transforms.ToTensor(),  # Tensor化\n",
    "            #transforms.Normalize([0.5], [1.0])  # 標準化\n",
    "        ])\n",
    "        \n",
    "        print(transform_ops)\n",
    "        \n",
    "        # 1つの変換処理に集約\n",
    "        self.transformer = transforms.Compose(transform_ops)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        p = self.image_paths[index]\n",
    "        q = self.label_paths[index]\n",
    "        \n",
    "        # 入力\n",
    "        #print(p)\n",
    "        image = Image.open(p)\n",
    "        image = image.convert('F')\n",
    "        #image.show()\n",
    "        \n",
    "        #max-min標準化\n",
    "        image_min = -1\n",
    "        for y in range(image.size[1]):\n",
    "            for x in range(image.size[0]):\n",
    "                if image_min == -1:\n",
    "                    image_min = image.getpixel((x, y))\n",
    "                elif image.getpixel((x, y)) != 0 and image.getpixel((x, y)) < image_min:\n",
    "                    image_min = image.getpixel((x, y))\n",
    "        image_max = image.getextrema()[1]\n",
    "        print(image_max)\n",
    "        print(image_min)\n",
    "        #標準化\n",
    "        for y in range(image.size[1]):\n",
    "            for x in range(image.size[0]):\n",
    "                image.putpixel((x, y), (image.getpixel((x, y)) - image_min) / (image_max - image_min))\n",
    "        \n",
    "        \n",
    "#        #標準化のための平均と標準偏差計算\n",
    "#        image_sum = 0.\n",
    "#        image_sqsum = 0.\n",
    "#        image_num = image.size[0] * image.size[1]\n",
    "#        for y in range(image.size[1]):\n",
    "#            for x in range(image.size[0]):\n",
    "#                image_sum += image.getpixel((x, y))\n",
    "#                image_sqsum += image.getpixel((x, y)) ** 2\n",
    "#        image_mean = image_sum / image_num\n",
    "#        image_sqmean = image_sqsum / image_num\n",
    "#        image_std = math.sqrt(image_sqmean - (image_mean ** 2))\n",
    "#        #print(image_mean)\n",
    "#        #print(image_sqmean)\n",
    "#        #print(image_std)\n",
    "#        #標準化\n",
    "#        for y in range(image.size[1]):\n",
    "#            for x in range(image.size[0]):\n",
    "#                image.putpixel((x, y), (image.getpixel((x, y)) - image_mean) / image_std)\n",
    "       \n",
    "        #print(image)\n",
    "        image = self.transformer(image)  # __init__で定義した関数に置き換え\n",
    "        \n",
    "        # ラベル (0: ants, 1: bees)\n",
    "        with open(q) as f:\n",
    "            reader = csv.reader(f)\n",
    "            #label = p.split(\"/\")[2]\n",
    "            label = []\n",
    "            for row in reader:\n",
    "                for point in row:\n",
    "                    label.append(int(point))\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "train_dataset = MyDataset(\"./monitoring_data/train/\", (96, 96), \"train\")\n",
    "test_dataset = MyDataset(\"./monitoring_data/val/\", (96, 96), \"val\")\n",
    "\n",
    "image, label = train_dataset[0]\n",
    "print(image.size(), label)  # torch.Size([3, 224, 224]) 1\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = data.DataLoader(\n",
    "    train_dataset, batch_size=16, shuffle=True,\n",
    "    num_workers=2, drop_last=True\n",
    ")\n",
    "\n",
    "test_dataloader = data.DataLoader(\n",
    "    test_dataset, batch_size=16, shuffle=False,\n",
    "    num_workers=2, drop_last=True\n",
    ")\n",
    "\n",
    "train_images, train_labels = next(iter(train_dataloader))\n",
    "test_images, test_labels = next(iter(test_dataloader))\n",
    "print(train_images.size())  # torch.Size([16, 3, 224, 224])\n",
    "print(train_labels.size())  # torch.Size([16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.pool = nn.MaxPool2d(2, stride = 2)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(1,16,3)\n",
    "        self.conv2 = nn.Conv2d(16,32,3)\n",
    "        \n",
    "        self.fc1 = nn.Linear(32 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 60)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x) #94×94 16chunnel\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  #47×47 16chunnel\n",
    "        x = self.conv2(x) #45×45 32chunnel\n",
    "        x = self.relu(x)\n",
    "        x = self.pool(x)  #\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "net = Net()\n",
    "net = net.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr = 0.0001, momentum = 0.9, weight_decay = 0.005)\n",
    "\n",
    "for epoch in range(100):\n",
    "    for(inputs, labels) in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    for (inputs, labels) in testloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

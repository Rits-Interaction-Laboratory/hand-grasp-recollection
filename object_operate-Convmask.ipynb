{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fin loading\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt    #グラフ出力用module\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "import os\n",
    "import csv\n",
    "\n",
    "PATH = os.getcwd()\n",
    "image_size=36\n",
    "\n",
    "#seanセットフォルダ一覧取得\n",
    "datadir = PATH + \"\\\\dataset_h\"\n",
    "traindir = datadir + \"\\\\train\"\n",
    "testdir = datadir + \"\\\\test\"\n",
    "train_seanset = glob.glob(traindir + \"\\\\*\")\n",
    "test_seanset = glob.glob(testdir + \"\\\\*\")\n",
    "\n",
    "train_sean_seqs = []\n",
    "test_sean_seqs = []\n",
    "for sean in train_seanset:\n",
    "    #sean_imgcfile = glob.glob(sean + \"\\\\object*.png\")[0]\n",
    "    sean_imgdfile = glob.glob(sean + \"\\\\objectd*.png\")[0]\n",
    "    s_datafiles = glob.glob(sean + \"\\\\data\\\\*.csv\")\n",
    "    s_labelfiles = glob.glob(sean + \"\\\\label\\\\*.csv\")\n",
    "    for t in range(len(s_datafiles)):\n",
    "        pair = []\n",
    "        pair.append(s_datafiles[t])\n",
    "        pair.append(s_labelfiles[t])\n",
    "        pair.append(sean_imgdfile)\n",
    "        train_sean_seqs.append(pair) #dataとlabelと画像名をセットで登録\n",
    "for sean in test_seanset:\n",
    "    #sean_imgcfile = glob.glob(sean + \"\\\\object*.png\")[0]\n",
    "    sean_imgdfile = glob.glob(sean + \"\\\\objectd*.png\")[0]\n",
    "    s_datafiles = glob.glob(sean + \"\\\\data\\\\*.csv\")\n",
    "    s_labelfiles = glob.glob(sean + \"\\\\label\\\\*.csv\")\n",
    "    for t in range(len(s_datafiles)):\n",
    "        pair = []\n",
    "        pair.append(s_datafiles[t])\n",
    "        pair.append(s_labelfiles[t])\n",
    "        pair.append(sean_imgdfile)\n",
    "        test_sean_seqs.append(pair) #dataとlabelと画像名をセットで登録\n",
    "\n",
    "img_skeleton_sets_train = []\n",
    "img_skeleton_sets_test = []\n",
    "\n",
    "def make_datasets(sean_seqs):\n",
    "    img_skeleton_sets = []\n",
    "    for i in range(len(sean_seqs)):\n",
    "        #画像読み込み・リサイズ・配列に変換\n",
    "        image = Image.open(sean_seqs[i][2])\n",
    "        image = image.resize((image_size, image_size))\n",
    "        img_array = np.asarray(image)\n",
    "        #画像マスク作成(元画像の画素値が外れ値(0～500)の部分を1にする、他は0)\n",
    "        img_mask_array = np.zeros((image_size, image_size), np.uint8)\n",
    "        for h in range(img_array.shape[0]):\n",
    "            for w in range(img_array.shape[1]):\n",
    "                if 0 <= img_array[h,w] < 500:\n",
    "                    img_mask_array[h,w] = 1\n",
    "        data_points = []\n",
    "        data_masks = []\n",
    "        label_points = []\n",
    "        label_masks = []\n",
    "        #学習用骨格データ読み込み\n",
    "        with open(sean_seqs[i][0]) as f:\n",
    "            reader = csv.reader(f)\n",
    "            num = 0\n",
    "            for row in reader:\n",
    "                if num == 0:\n",
    "                    for point in row:\n",
    "                        if int(point) == -10000:\n",
    "                            data_points.append(float(0))\n",
    "                            data_masks.append(0)\n",
    "                        else:\n",
    "                            data_points.append(float(point))\n",
    "                            data_masks.append(1)\n",
    "                    data_points = np.asarray(data_points)\n",
    "                    data_masks = np.asarray(data_masks)\n",
    "                    num += 1\n",
    "        #ラベル用骨格データ読み込み\n",
    "        with open(sean_seqs[i][1]) as f:\n",
    "            reader = csv.reader(f)\n",
    "            num = 0\n",
    "            for row in reader:\n",
    "                if num == 0:\n",
    "                    for point in row:\n",
    "                        if int(point) == -10000:\n",
    "                            label_points.append(float(0))\n",
    "                            label_masks.append(0)\n",
    "                        else:\n",
    "                            label_points.append(float(point))\n",
    "                            label_masks.append(1)\n",
    "                    label_points = np.asarray(label_points)\n",
    "                    label_masks = np.asarray(label_masks)\n",
    "                    num += 1\n",
    "        #画像・学習用・ラベル用スケルトンデータをパッケージング\n",
    "        img_skeleton_pack = []\n",
    "        img_skeleton_pack.append(img_array)\n",
    "        img_skeleton_pack.append(img_mask_array)\n",
    "        img_skeleton_pack.append(data_points)\n",
    "        img_skeleton_pack.append(data_masks)\n",
    "        img_skeleton_pack.append(label_points)\n",
    "        img_skeleton_pack.append(label_masks)\n",
    "        #パッケージをデータセットに登録\n",
    "        img_skeleton_sets.append(img_skeleton_pack)\n",
    "    return img_skeleton_sets\n",
    "\n",
    "img_skeleton_sets_train = np.array(make_datasets(train_sean_seqs))\n",
    "img_skeleton_sets_test = np.array(make_datasets(test_sean_seqs))\n",
    "print(\"fin loading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# 数合わせ用\n",
    "img_skeleton_sets_train, govage = train_test_split(\n",
    "    img_skeleton_sets_train,\n",
    "    shuffle = False,\n",
    "    train_size = 495\n",
    ")\n",
    "img_skeleton_sets_test, govage = train_test_split(\n",
    "    img_skeleton_sets_test,\n",
    "    shuffle = False,\n",
    "    train_size = 120\n",
    ")\n",
    "#print(img_skeleton_sets_train.shape, img_skeleton_sets_test.shape, govage.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(495, 6) img_skeleton_sets_train shape\n",
      "(120, 6) img_skeleton_sets_test  shape\n"
     ]
    }
   ],
   "source": [
    "#print(\"[0]image     \", img_skeleton_sets_train[0][0].shape, \"\\n\", img_skeleton_sets_train[0][0]) #画像\n",
    "#print(\"[1]image-mask\", img_skeleton_sets_train[0][1].shape, \"\\n\", img_skeleton_sets_train[0][1]) #画像マスク\n",
    "#print(\"[2]input     \", img_skeleton_sets_train[0][2].shape, \"\\n\", img_skeleton_sets_train[0][2]) #骨格(入力)\n",
    "#print(\"[3]input-mask\", img_skeleton_sets_train[0][3].shape, \"\\n\", img_skeleton_sets_train[0][3]) #骨格マスク(入力)\n",
    "#print(\"[4]label     \", img_skeleton_sets_train[0][4].shape, \"\\n\", img_skeleton_sets_train[0][4]) #骨格(ラベル)\n",
    "#print(\"[5]label-mask\", img_skeleton_sets_train[0][5].shape, \"\\n\", img_skeleton_sets_train[0][5]) #骨格マスク(ラベル)\n",
    "\n",
    "print(type(img_skeleton_sets_train))\n",
    "#print(img_skeleton_sets_train[0].shape)\n",
    "print(img_skeleton_sets_train.shape, \"img_skeleton_sets_train shape\")\n",
    "print(img_skeleton_sets_test.shape, \"img_skeleton_sets_test  shape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-267. -214.  151.    0.    0.    0. -229. -102.  -87. -228.  -74.  -66.\n",
      "    0.    0.    0. -247. -151.  192. -249. -108.  208. -224.  -48.   -8.\n",
      " -225.  -33.  -62. -247. -145.  180.    0.    0.    0. -225.  -42.  -62.\n",
      " -234.  -34.  -73. -250. -145.  180. -224.  -73.  -36. -231.  -49.  -79.\n",
      " -239.  -40.  -96. -225.  -97.  -60. -228.  -74.  -66. -235.  -56.  -96.\n",
      " -238.  -51. -105.    0.]\n",
      "[[3425 3425 3429 ... 3441 3441 3441]\n",
      " [3416 3416 3416 ... 3418 3418 3419]\n",
      " [3415 3415 3412 ... 3399 3399 3396]\n",
      " ...\n",
      " [3028 3028 3024 ... 2922 2922 2954]\n",
      " [3015 3015 3014 ... 2927 2927 2945]\n",
      " [3015 3015 3014 ... 2927 2927 2945]]\n",
      "[1 1 1 0 0 0 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[-140.  -46. -418. -113.  -59. -423.    0.    0.    0.    0.    0.    0.\n",
      "    0.    0.    0.  -84.  -39. -437.  -58.  -28. -435.  -43.  -21. -429.\n",
      "    0.    0.    0.  -93.  -13. -428.  -63.   -1. -429.  -49.    6. -411.\n",
      "  -39.    9. -376.  -97.    4. -431.  -74.   19. -417.  -59.   24. -411.\n",
      "  -51.   29. -374.    0.    0.    0.  -86.   28. -400.    0.    0.    0.\n",
      "  -67.   36. -378.]\n",
      "[1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 1 1 1 0 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "data_train = []\n",
    "img_train = []\n",
    "mask_train = []\n",
    "imask_train = []\n",
    "data_test = []\n",
    "img_test = []\n",
    "mask_test = []\n",
    "imask_test = []\n",
    "label_train = []\n",
    "lmask_train = []\n",
    "label_test = []\n",
    "lmask_test = []\n",
    "for i in range(len(img_skeleton_sets_train)):\n",
    "    data_train.append(img_skeleton_sets_train[i][2])\n",
    "    img_train.append(img_skeleton_sets_train[i][0])\n",
    "    mask_train.append(img_skeleton_sets_train[i][3])\n",
    "    imask_train.append(img_skeleton_sets_train[i][1])\n",
    "    label_train.append(img_skeleton_sets_train[i][4])\n",
    "    lmask_train.append(img_skeleton_sets_train[i][5])\n",
    "for i in range(len(img_skeleton_sets_test)):\n",
    "    data_test.append(img_skeleton_sets_test[i][2])\n",
    "    img_test.append(img_skeleton_sets_test[i][0])\n",
    "    mask_test.append(img_skeleton_sets_test[i][3])\n",
    "    imask_test.append(img_skeleton_sets_test[i][1])\n",
    "    label_test.append(img_skeleton_sets_test[i][4])\n",
    "    lmask_test.append(img_skeleton_sets_test[i][5])\n",
    "    \n",
    "print(data_train[0])\n",
    "print(img_train[0])\n",
    "print(mask_train[0])\n",
    "print(imask_train[0])\n",
    "print(label_train[0])\n",
    "print(lmask_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trainF = np.array(data_train).astype('float32')/100\n",
    "data_testF = np.array(data_test).astype('float32')/100\n",
    "img_trainF = np.array(img_train).astype('float32')/10000\n",
    "img_testF = np.array(img_test).astype('float32')/10000\n",
    "mask_trainF = np.array(mask_train).astype('float32')\n",
    "mask_testF = np.array(mask_test).astype('float32')\n",
    "imask_trainF = np.array(imask_train).astype('float32')\n",
    "imask_testF = np.array(imask_test).astype('float32')\n",
    "label_trainF = np.array(label_train).astype('float32')/100\n",
    "label_testF = np.array(label_test).astype('float32')/100\n",
    "lmask_trainF = np.array(lmask_train).astype('float32')\n",
    "lmask_testF = np.array(lmask_test).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data        train  (495, 64)\n",
      "data        test   (120, 64)\n",
      "image       train  (495, 36, 36)\n",
      "image       test   (120, 36, 36)\n",
      "data-mask   train  (495, 64)\n",
      "data-mask   test   (120, 64)\n",
      "image-mask  train  (495, 36, 36)\n",
      "image-mask  test   (120, 36, 36)\n",
      "label       train  (495, 63)\n",
      "label       test   (120, 63)\n",
      "label-mask  train  (495, 63)\n",
      "label-mask  test   (120, 63)\n"
     ]
    }
   ],
   "source": [
    "print(\"data        train \",data_trainF.shape)\n",
    "print(\"data        test  \",data_testF.shape)\n",
    "print(\"image       train \",img_trainF.shape)\n",
    "print(\"image       test  \",img_testF.shape)\n",
    "print(\"data-mask   train \",mask_trainF.shape)\n",
    "print(\"data-mask   test  \",mask_testF.shape)\n",
    "print(\"image-mask  train \",imask_trainF.shape)\n",
    "print(\"image-mask  test  \",imask_testF.shape)\n",
    "print(\"label       train \",label_trainF.shape)\n",
    "print(\"label       test  \",label_testF.shape)\n",
    "print(\"label-mask  train \",lmask_trainF.shape)\n",
    "print(\"label-mask  test  \",lmask_testF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor()]#,torchvision.transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydatasets(torch.utils.data.Dataset):\n",
    "    def __init__(self, datas, labels, img_array, data_masks, label_masks, img_masks, transform = None):\n",
    "        self.transform = transform\n",
    "        #self.transform2 = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "        self.data = datas\n",
    "        self.label = labels\n",
    "        self.img_array = img_array\n",
    "        self.masks = data_masks\n",
    "        self.lmasks = label_masks\n",
    "        self.imasks = img_masks\n",
    "\n",
    "        self.datanum = datas.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.datanum\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #batch_set = []\n",
    "        \n",
    "        i_data = self.data[idx]\n",
    "        i_label = self.label[idx]\n",
    "        i_img = self.img_array[idx]\n",
    "        i_mask = self.masks[idx]\n",
    "        i_lmask = self.lmasks[idx]\n",
    "        i_imask = self.imasks[idx]\n",
    "        \n",
    "        #print(out_label)\n",
    "        #print(type(i_label))\n",
    "        out_label = np.array(i_label.astype(np.float32))\n",
    "        out_data = np.array(i_data.astype(np.float32))\n",
    "        out_img = np.array(i_img.astype(np.float32))\n",
    "        out_mask = np.array(i_mask.astype(np.float32))\n",
    "        out_lmask = np.array(i_lmask.astype(np.float32))\n",
    "        out_imask = np.array(i_imask.astype(np.float32))\n",
    "        #out_label.append(i_label.astype(np.float32))\n",
    "        #print(type(out_label))\n",
    "\n",
    "        if self.transform:\n",
    "            #out_data = self.transform(i_data)\n",
    "            out_img = self.transform(out_img)\n",
    "            out_imask = self.transform(out_imask)\n",
    "            #out_label = self.transform2(out_label)\n",
    "        \n",
    "        #batch_set.append(out_data)\n",
    "        #batch_set.append(out_label)\n",
    "        #batch_set.append(out_img)\n",
    "        #batch_set.append(out_mask)\n",
    "        #batch_set.append(out_lmask)\n",
    "\n",
    "        return out_data, out_label, out_img, out_mask, out_lmask, out_imask\n",
    "        #return batch_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = Mydatasets(datas = data_trainF, labels = label_trainF, img_array = img_trainF, data_masks = mask_trainF, label_masks = lmask_trainF, img_masks = imask_trainF, transform = trans)\n",
    "testset = Mydatasets(datas = data_testF, labels = label_testF, img_array = img_testF, data_masks = mask_testF, label_masks = lmask_testF, img_masks = imask_testF, transform = trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 15\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = BATCH_SIZE,\n",
    "                        shuffle = True, num_workers = 0)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = BATCH_SIZE,\n",
    "                        shuffle = False, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ignore(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, activation = lambda x: x):\n",
    "        '''\n",
    "        引数:\n",
    "            input_dim: 入力次元\n",
    "            output_dim: 出力次元\n",
    "            activation: 活性化関数\n",
    "        パラメータ:\n",
    "            W: 重み\n",
    "            b: バイアス\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.W = nn.Parameter(torch.Tensor(np.random.normal(size = (output_dim, input_dim))))\n",
    "        self.b = nn.Parameter(torch.Tensor(np.zeros(output_dim)))\n",
    "        self.activation = activation\n",
    "    def forward(self, x, mask):\n",
    "        \n",
    "        out = torch.empty_like(x).to(torch.device(\"cuda:0\"))\n",
    "        masked_x = torch.mul(x, mask)\n",
    "        \n",
    "        try:\n",
    "            m_size = torch.Tensor(mask.size()[1]).to(torch.device(\"cuda:0\"))\n",
    "            m_sum = torch.sum(mask, 1).to(torch.device(\"cuda:0\"))\n",
    "            rate = (m_size.size()[0] / m_sum).to(torch.device(\"cuda:0\"))\n",
    "            for b in range(out.size()[0]):\n",
    "                out[b] = torch.add(torch.mul(rate[b], torch.sum(torch.mul(masked_x[b], self.W), 1)), self.b)\n",
    "        except IndexError:\n",
    "            m_size = torch.Tensor(mask.size()).to(torch.device(\"cuda:0\"))\n",
    "            m_sum = torch.sum(mask).to(torch.device(\"cuda:0\"))\n",
    "            rate = (m_size.size()[0] / m_sum).to(torch.device(\"cuda:0\"))\n",
    "            out = torch.add(torch.mul(rate, torch.sum(torch.mul(masked_x, self.W))), self.b)\n",
    "        \n",
    "        return self.activation(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandGraspRecolletion(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HandGraspRecolletion, self).__init__()\n",
    "        #CNN\n",
    "        self.pool = nn.AvgPool2d(2, stride=2)\n",
    "        self.conv1 = nn.Conv2d(1,16,3)\n",
    "        self.conv2 = nn.Conv2d(16,32,3)\n",
    "        self.bn2d1 = nn.BatchNorm2d(16)\n",
    "        self.bn2d2 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.fcm = Ignore(32 * 7 * 7 + 64, 32 * 7 * 7 + 64)\n",
    "        self.bnm = nn.BatchNorm1d(32 * 7 * 7 + 64)\n",
    "        #fully connect for hand Location(x,y,z)\n",
    "        self.fcL1 = nn.Linear(32 * 7 * 7 + 64, 300)\n",
    "        self.fcL2 = nn.Linear(300, 30)\n",
    "        self.fcL3 = nn.Linear(30, 3)        \n",
    "        self.bnL1 = nn.BatchNorm1d(300)\n",
    "        self.bnL2 = nn.BatchNorm1d(30)\n",
    "        #fully connect for hand Pose Descriptor(8 properties)\n",
    "        self.fcPD1 = nn.Linear(32 * 7 * 7 + 64, 300)\n",
    "        self.fcPD2 = nn.Linear(300, 60)\n",
    "        self.fcPD3 = nn.Linear(60, 8)\n",
    "        self.bnPD1 = nn.BatchNorm1d(300)\n",
    "        self.bnPD2 = nn.BatchNorm1d(60)\n",
    "        \n",
    "        #Autoencoder\n",
    "        self.mask = Ignore(84, 84)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense_enc1 = nn.Linear(84, 40)\n",
    "        self.bn1 = nn.BatchNorm1d(40)\n",
    "        self.dense_enc2 = nn.Linear(40, 18)\n",
    "        self.bn2 = nn.BatchNorm1d(18)\n",
    "        self.dense_enc3 = nn.Linear(18,8)\n",
    "    \n",
    "        self.dense_dec1 = nn.Linear(8,16)\n",
    "        self.bn4 = nn.BatchNorm1d(16)\n",
    "        self.dense_dec2 = nn.Linear(16, 32)\n",
    "        self.bn5 = nn.BatchNorm1d(32)\n",
    "        self.drop1 = nn.Dropout(p=0.2)\n",
    "        self.dense_dec3 = nn.Linear(32, 63)\n",
    "\n",
    "    def cnn_part(self, x, y, m, im):\n",
    "        #Conv2d 1\n",
    "        x = self.conv1(x)\n",
    "        im = self.conv1(im)\n",
    "        im_conv1 = im.clone().detach().to(torch.device(\"cuda:0\"))\n",
    "        for c in range(im.size()[1]):\n",
    "            mode, ind = torch.mode(torch.reshape(im[0][c].clone().detach(), (-1, im.size()[2] * im.size()[3])))\n",
    "            im_conv1[:,c] = torch.sub(im_conv1[:,c], mode.item())\n",
    "        #ReLU→BatchNorm2d 1\n",
    "        x = self.bn2d1(self.relu(x))\n",
    "        #AvgPool2d\n",
    "        x = self.pool(x)\n",
    "        im = self.pool(im_conv1)\n",
    "        #Conv2d 2\n",
    "        x = self.conv2(x)\n",
    "        im = self.conv2(im)\n",
    "        im_conv2 = im.clone().detach().to(torch.device(\"cuda:0\"))\n",
    "        for c in range(im.size()[1]):\n",
    "            mode, ind = torch.mode(torch.reshape(im[0][c].clone().detach(), (-1, im.size()[2] * im.size()[3])))\n",
    "            im_conv2[:,c] = torch.sub(im_conv2[:,c], mode.item())\n",
    "        #ReLU→BatchNorm2d 2\n",
    "        x = self.bn2d2(self.relu(x))\n",
    "        #AvgPool2d\n",
    "        x = self.pool(x)\n",
    "        im = self.pool(im_conv2)\n",
    "        #1次元ベクトル化\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        im = im.view(im.size()[0], -1)\n",
    "        #マスク再構築(0→1, 0以外→0)\n",
    "        im = torch.logical_not(torch.logical_and(im, torch.tensor([True]).to(torch.device(\"cuda:0\")))).float()\n",
    "        #骨格データと結合\n",
    "        x = torch.cat([x, y], axis = -1)\n",
    "        m = torch.cat([im, m], axis = -1)\n",
    "        #MaskedLinear\n",
    "        x = self.fcm(x, m)\n",
    "        x = self.bnm(self.relu(x))\n",
    "        xL = self.fcL1(x)\n",
    "        xPD = self.fcPD1(x)\n",
    "        xL = self.bnL1(self.relu(xL))\n",
    "        xPD = self.bnPD1(self.relu(xPD))\n",
    "        xL = self.fcL2(xL)\n",
    "        xPD = self.fcPD2(xPD)\n",
    "        xL = self.bnL2(self.relu(xL))\n",
    "        xPD = self.bnPD2(self.relu(xPD))\n",
    "        xL = self.fcL3(xL)\n",
    "        xPD = self.fcPD3(xPD)\n",
    "        return xL, xPD\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        #x = torch.div(x, 100.)\n",
    "        #x = self.mask(x, m)\n",
    "        x = self.dense_enc1(x)\n",
    "        x = self.bn1(self.relu(x))\n",
    "        x = self.dense_enc2(x)\n",
    "        x = self.bn2(self.relu(x))\n",
    "        x = self.dense_enc3(x)\n",
    "        return x\n",
    "\n",
    "    def decoder(self, x):\n",
    "        x = self.dense_dec1(x)\n",
    "        x = self.bn4(self.relu(x))\n",
    "        x = self.dense_dec2(x)\n",
    "        x = self.bn5(self.relu(x))\n",
    "        #x = self.drop1(x)\n",
    "        x = self.dense_dec3(x)\n",
    "        #x = self.mask(x, m)\n",
    "        #x = torch.mul(x, 100.)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x, y, m, im):\n",
    "        xLoc, xPD = self.cnn_part(x, y, m, im)\n",
    "        xPose = self.decoder(xPD)\n",
    "        return xLoc, xPose, xPD\n",
    "    #    if x != None and z == None:\n",
    "    #        z = self.encoder(x)\n",
    "    #        x = self.decoder(z)\n",
    "    #    elif x == None and z != None:\n",
    "    #        print(\"decoder only\")\n",
    "    #        x = self.decoder(z)\n",
    "    #    return x, z\n",
    "\n",
    "    #def forward(self, x=None, z=None):\n",
    "    #    if x != None and z == None:\n",
    "    #        z = self.encoder(x)\n",
    "    #        x = self.decoder(z)\n",
    "    #    elif x == None and z != None:\n",
    "    #        print(\"decoder only\")\n",
    "    #        x = self.decoder(z)\n",
    "    #    return x, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskMSELoss(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MaskMSELoss, self).__init__()\n",
    "        #self.margin = margin\n",
    "\n",
    "    def forward(self, inputs, labels, lmasks):\n",
    "        m_size = lmasks.size()[1]\n",
    "        m_sum = torch.sum(lmasks, 1)\n",
    "        #print(\"m_size:\",m_size)\n",
    "        #print(\"m_sum:\",m_sum)\n",
    "        rate = (m_size / m_sum).reshape(BATCH_SIZE,-1)\n",
    "        #print(\"rate:\",rate)\n",
    "        for i in range(rate.size()[0]):\n",
    "            #print(rate[i].item())\n",
    "            if np.isinf(rate[i].item()):\n",
    "                #print(\"inf!\")\n",
    "                rate[i] = 0.\n",
    "        #print(\"rate+:\", rate)\n",
    "        masked_in = torch.mul(inputs, lmasks)\n",
    "        masked_lb = torch.mul(labels, lmasks)\n",
    "        \n",
    "        #loss = torch.sub(masked_in, masked_lb)\n",
    "        #print(\"sub:\",loss)\n",
    "        #loss = torch.pow(loss, 2)\n",
    "        #print(\"pow:\",loss)\n",
    "        #loss = torch.sum(loss, 1)\n",
    "        #print(\"sum:\",loss)\n",
    "        #loss = torch.div(loss, m_sum)\n",
    "        #print(\"div:\",loss)\n",
    "        #loss = torch.mul(rate, loss)\n",
    "        #print(\"gain2:\",loss)\n",
    "        #loss = torch.mean(loss)\n",
    "        #print(\"mean:\",loss)\n",
    "        \n",
    "        loss = torch.sub(masked_in, masked_lb)\n",
    "        loss = torch.pow(loss, 2)\n",
    "        loss = torch.mul(loss, rate)\n",
    "        loss = torch.mean(loss, 1)\n",
    "        loss = torch.mean(loss)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.01\n",
    "WEIGHT_DECAY = 0.0001\n",
    "MOMENTUM = 0.9\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "#net = Net().to(device)\n",
    "#ae = Autoencoder()\n",
    "net = HandGraspRecolletion().to(device)\n",
    "net.load_state_dict(torch.load(PATH + \"\\\\hand_AE_model\"))\n",
    "for p in net.parameters(): # freeze all model parameters\n",
    "    p.requires_grad = False\n",
    "for p in net.conv1.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.conv2.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.bn2d1.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.bn2d2.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.fcm.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.bnm.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.fcL1.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.fcL2.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.fcL3.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.bnL1.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.bnL2.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.fcPD1.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.fcPD2.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.fcPD3.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.bnPD1.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.bnPD2.parameters():\n",
    "    p.requires_grad = True    \n",
    "criterion = MaskMSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "train_loss_value=[]      #trainingのlossを保持するlist\n",
    "test_loss_value=[]       #testのlossを保持するlist\n",
    "\n",
    "train_input_value = []\n",
    "train_output_value = []\n",
    "train_desc_value = []\n",
    "train_handloc_value = []\n",
    "test_input_value = []\n",
    "test_output_value = []\n",
    "test_desc_value = []\n",
    "test_handloc_value = []\n",
    "\n",
    "train_size = data_trainF.shape[0]\n",
    "test_size = data_testF.shape[0]\n",
    "\n",
    "max_train_loss_value = 0.\n",
    "max_test_loss_value = 0.\n",
    "min_test_loss_value = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\"conv1.weight\",\"conv1.bias\",\"conv2.weight\",\"conv2.bias\",\"bn2d1.weight\",\"bn2d1.bias\",\"bn2d2.weight\",\\\n",
    "        \"bn2d2.bias\",\"fcm.W\",\"fcm.b\",\"bnm.weight\",\"bnm.bias\",\"fcL1.weight\",\"fcL1.bias\",\"fcL2.weight\",\\\n",
    "        \"fcL2.bias\",\"fcL3.weight\",\"fcL3.bias\",\"bnL1.weight\",\"bnL1.bias\",\"bnL2.weight\",\"bnL2.bias\",\\\n",
    "        \"fcPD1.weight\",\"fcPD1.bias\",\"fcPD2.weight\",\"fcPD2.bias\",\"fcPD3.weight\",\"fcPD3.bias\",\"bnPD1.weight\",\\\n",
    "        \"bnPD1.bias\",\"bnPD2.weight\",\"bnPD2.bias\",\"mask.W\",\"mask.b\",\"dense_enc1.weight\",\"dense_enc1.bias\",\\\n",
    "        \"bn1.weight\",\"bn1.bias\",\"dense_enc2.weight\",\"dense_enc2.bias\",\"bn2.weight\",\"bn2.bias\",\\\n",
    "        \"dense_enc3.weight\",\"dense_enc3.bias\",\"dense_dec1.weight\",\"dense_dec1.bias\",\"bn4.weight\",\"bn4.bias\",\\\n",
    "        \"dense_dec2.weight\",\"dense_dec2.bias\",\"bn5.weight\",\"bn5.bias\",\"dense_dec3.weight\",\"dense_dec3.bias\"]\n",
    "#for k, p in zip(keys, net.parameters()):\n",
    "#    print(k, \"\\n\", p, \"\\n\")\n",
    "#for k, p in zip(keys, net.parameters()):\n",
    "#    print(k, \"requires_grad = \", p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "test_train\n",
      "train mean loss=80739.86979166667\n",
      "test_test\n",
      "test mean loss=119943.32470703125\n",
      "epoch 2\n",
      "test_train\n",
      "train mean loss=79322.71152935606\n",
      "test_test\n",
      "test mean loss=119811.22119140625\n",
      "epoch 3\n",
      "test_train\n",
      "train mean loss=78631.42589962122\n",
      "test_test\n",
      "test mean loss=120389.73095703125\n",
      "epoch 4\n",
      "test_train\n",
      "train mean loss=78732.2431344697\n",
      "test_test\n",
      "test mean loss=119425.86572265625\n",
      "epoch 5\n",
      "test_train\n",
      "train mean loss=78754.20857007576\n",
      "test_test\n",
      "test mean loss=119631.576171875\n",
      "epoch 6\n",
      "test_train\n",
      "train mean loss=77259.17684659091\n",
      "test_test\n",
      "test mean loss=119103.9970703125\n",
      "epoch 7\n",
      "test_train\n",
      "train mean loss=78214.64464962122\n",
      "test_test\n",
      "test mean loss=120405.630859375\n",
      "epoch 8\n",
      "test_train\n",
      "train mean loss=77408.33901515152\n",
      "test_test\n",
      "test mean loss=119585.95361328125\n",
      "epoch 9\n",
      "test_train\n",
      "train mean loss=77756.81403882576\n",
      "test_test\n",
      "test mean loss=120628.86181640625\n",
      "epoch 10\n",
      "test_train\n",
      "train mean loss=78636.31273674243\n",
      "test_test\n",
      "test mean loss=120042.0146484375\n",
      "epoch 11\n",
      "test_train\n",
      "train mean loss=76952.68821022728\n",
      "test_test\n",
      "test mean loss=120074.43994140625\n",
      "epoch 12\n",
      "test_train\n",
      "train mean loss=77808.72786458333\n",
      "test_test\n",
      "test mean loss=120809.333984375\n",
      "epoch 13\n",
      "test_train\n",
      "train mean loss=78888.80456912878\n",
      "test_test\n",
      "test mean loss=122243.9560546875\n",
      "epoch 14\n",
      "test_train\n",
      "train mean loss=78550.97052556818\n",
      "test_test\n",
      "test mean loss=122839.8642578125\n",
      "epoch 15\n",
      "test_train\n",
      "train mean loss=77342.4013967803\n",
      "test_test\n",
      "test mean loss=122336.2451171875\n",
      "epoch 16\n",
      "test_train\n",
      "train mean loss=77726.52284564394\n",
      "test_test\n",
      "test mean loss=121555.630859375\n",
      "epoch 17\n",
      "test_train\n",
      "train mean loss=78021.70561079546\n",
      "test_test\n",
      "test mean loss=122854.62451171875\n",
      "epoch 18\n",
      "test_train\n",
      "train mean loss=77712.86209753787\n",
      "test_test\n",
      "test mean loss=125325.734375\n",
      "epoch 19\n",
      "test_train\n",
      "train mean loss=77589.21614583333\n",
      "test_test\n",
      "test mean loss=122532.7958984375\n",
      "epoch 20\n",
      "test_train\n",
      "train mean loss=77684.19992897728\n",
      "test_test\n",
      "test mean loss=122392.134765625\n",
      "epoch 21\n",
      "test_train\n",
      "train mean loss=77729.7743844697\n",
      "test_test\n",
      "test mean loss=121563.17236328125\n",
      "epoch 22\n",
      "test_train\n",
      "train mean loss=76680.65240293561\n",
      "test_test\n",
      "test mean loss=122963.98583984375\n",
      "epoch 23\n",
      "test_train\n",
      "train mean loss=77081.22786458333\n",
      "test_test\n",
      "test mean loss=124103.60009765625\n",
      "epoch 24\n",
      "test_train\n",
      "train mean loss=77491.57966382576\n",
      "test_test\n",
      "test mean loss=122541.24951171875\n",
      "epoch 25\n",
      "test_train\n",
      "train mean loss=77373.78480113637\n",
      "test_test\n",
      "test mean loss=122976.5576171875\n",
      "epoch 26\n",
      "test_train\n",
      "train mean loss=76704.47348484848\n",
      "test_test\n",
      "test mean loss=123495.93896484375\n",
      "epoch 27\n",
      "test_train\n",
      "train mean loss=77604.62156723485\n",
      "test_test\n",
      "test mean loss=122762.158203125\n",
      "epoch 28\n",
      "test_train\n",
      "train mean loss=76743.00189393939\n",
      "test_test\n",
      "test mean loss=122392.3271484375\n",
      "epoch 29\n",
      "test_train\n",
      "train mean loss=76127.72064393939\n",
      "test_test\n",
      "test mean loss=122946.9892578125\n",
      "epoch 30\n",
      "test_train\n",
      "train mean loss=76359.62251420454\n",
      "test_test\n",
      "test mean loss=122318.2919921875\n",
      "epoch 31\n",
      "test_train\n",
      "train mean loss=76499.94779829546\n",
      "test_test\n",
      "test mean loss=122752.88134765625\n",
      "epoch 32\n",
      "test_train\n",
      "train mean loss=75532.60819128787\n",
      "test_test\n",
      "test mean loss=122265.96630859375\n",
      "epoch 33\n",
      "test_train\n",
      "train mean loss=74767.20833333333\n",
      "test_test\n",
      "test mean loss=122812.17578125\n",
      "epoch 34\n",
      "test_train\n",
      "train mean loss=75268.38340435606\n",
      "test_test\n",
      "test mean loss=123103.73583984375\n",
      "epoch 35\n",
      "test_train\n",
      "train mean loss=76432.62890625\n",
      "test_test\n",
      "test mean loss=122835.69873046875\n",
      "epoch 36\n",
      "test_train\n",
      "train mean loss=74644.24064867424\n",
      "test_test\n",
      "test mean loss=123325.89990234375\n",
      "epoch 37\n",
      "test_train\n",
      "train mean loss=75502.58570075757\n",
      "test_test\n",
      "test mean loss=123146.15771484375\n",
      "epoch 38\n",
      "test_train\n",
      "train mean loss=75007.44140625\n",
      "test_test\n",
      "test mean loss=122575.47265625\n",
      "epoch 39\n",
      "test_train\n",
      "train mean loss=75360.52817234848\n",
      "test_test\n",
      "test mean loss=123407.16748046875\n",
      "epoch 40\n",
      "test_train\n",
      "train mean loss=74905.93051609848\n",
      "test_test\n",
      "test mean loss=121773.3701171875\n",
      "epoch 41\n",
      "test_train\n",
      "train mean loss=74931.1884469697\n",
      "test_test\n",
      "test mean loss=123348.6767578125\n",
      "epoch 42\n",
      "test_train\n",
      "train mean loss=74412.34434185606\n",
      "test_test\n",
      "test mean loss=124446.1123046875\n",
      "epoch 43\n",
      "test_train\n",
      "train mean loss=75879.74940814394\n",
      "test_test\n",
      "test mean loss=122881.302734375\n",
      "epoch 44\n",
      "test_train\n",
      "train mean loss=75766.72064393939\n",
      "test_test\n",
      "test mean loss=123196.29150390625\n",
      "epoch 45\n",
      "test_train\n",
      "train mean loss=75843.91157670454\n",
      "test_test\n",
      "test mean loss=123507.17578125\n",
      "epoch 46\n",
      "test_train\n",
      "train mean loss=75455.48745265152\n",
      "test_test\n",
      "test mean loss=123183.63818359375\n",
      "epoch 47\n",
      "test_train\n",
      "train mean loss=75463.04154829546\n",
      "test_test\n",
      "test mean loss=123254.85693359375\n",
      "epoch 48\n",
      "test_train\n",
      "train mean loss=75098.53935842802\n",
      "test_test\n",
      "test mean loss=123346.14013671875\n",
      "epoch 49\n",
      "test_train\n",
      "train mean loss=75470.54900568182\n",
      "test_test\n",
      "test mean loss=123308.72314453125\n",
      "epoch 50\n",
      "test_train\n",
      "train mean loss=75251.83540482954\n",
      "test_test\n",
      "test mean loss=122512.2978515625\n",
      "epoch 51\n",
      "test_train\n",
      "train mean loss=75071.49183238637\n",
      "test_test\n",
      "test mean loss=123468.41943359375\n",
      "epoch 52\n",
      "test_train\n",
      "train mean loss=76336.55788352272\n",
      "test_test\n",
      "test mean loss=126091.8447265625\n",
      "epoch 53\n",
      "test_train\n",
      "train mean loss=76863.11647727272\n",
      "test_test\n",
      "test mean loss=124714.57763671875\n",
      "epoch 54\n",
      "test_train\n",
      "train mean loss=76587.66382575757\n",
      "test_test\n",
      "test mean loss=126059.5322265625\n",
      "epoch 55\n",
      "test_train\n",
      "train mean loss=75745.89015151515\n",
      "test_test\n",
      "test mean loss=124639.875\n",
      "epoch 56\n",
      "test_train\n",
      "train mean loss=76057.63245738637\n",
      "test_test\n",
      "test mean loss=122606.99560546875\n",
      "epoch 57\n",
      "test_train\n",
      "train mean loss=75535.91347064394\n",
      "test_test\n",
      "test mean loss=121729.24951171875\n",
      "epoch 58\n",
      "test_train\n",
      "train mean loss=75311.97975852272\n",
      "test_test\n",
      "test mean loss=122948.62255859375\n",
      "epoch 59\n",
      "test_train\n",
      "train mean loss=75421.85866477272\n",
      "test_test\n",
      "test mean loss=120981.0634765625\n",
      "epoch 60\n",
      "test_train\n",
      "train mean loss=75899.2998342803\n",
      "test_test\n",
      "test mean loss=120650.02685546875\n",
      "epoch 61\n",
      "test_train\n",
      "train mean loss=75656.75710227272\n",
      "test_test\n",
      "test mean loss=122574.6826171875\n",
      "epoch 62\n",
      "test_train\n",
      "train mean loss=76966.38352272728\n",
      "test_test\n",
      "test mean loss=121671.8173828125\n",
      "epoch 63\n",
      "test_train\n",
      "train mean loss=76724.13162878787\n",
      "test_test\n",
      "test mean loss=122744.33154296875\n",
      "epoch 64\n",
      "test_train\n",
      "train mean loss=75629.18501420454\n",
      "test_test\n",
      "test mean loss=122919.76123046875\n",
      "epoch 65\n",
      "test_train\n",
      "train mean loss=75633.59647253787\n",
      "test_test\n",
      "test mean loss=124903.04248046875\n",
      "epoch 66\n",
      "test_train\n",
      "train mean loss=75670.78740530302\n",
      "test_test\n",
      "test mean loss=123206.3642578125\n",
      "epoch 67\n",
      "test_train\n",
      "train mean loss=75622.71537642046\n",
      "test_test\n",
      "test mean loss=122320.53271484375\n",
      "epoch 68\n",
      "test_train\n",
      "train mean loss=75522.88955965909\n",
      "test_test\n",
      "test mean loss=123251.53271484375\n",
      "epoch 69\n",
      "test_train\n",
      "train mean loss=75325.66347064394\n",
      "test_test\n",
      "test mean loss=123669.41552734375\n",
      "epoch 70\n",
      "test_train\n",
      "train mean loss=75725.42075047348\n",
      "test_test\n",
      "test mean loss=122111.00439453125\n",
      "epoch 71\n",
      "test_train\n",
      "train mean loss=75381.65731534091\n",
      "test_test\n",
      "test mean loss=124038.99365234375\n",
      "epoch 72\n",
      "test_train\n",
      "train mean loss=75398.98757102272\n",
      "test_test\n",
      "test mean loss=124597.9248046875\n",
      "epoch 73\n",
      "test_train\n",
      "train mean loss=76248.35771780302\n",
      "test_test\n",
      "test mean loss=124419.53173828125\n",
      "epoch 74\n",
      "test_train\n",
      "train mean loss=76082.87653882576\n",
      "test_test\n",
      "test mean loss=124619.61767578125\n",
      "epoch 75\n",
      "test_train\n",
      "train mean loss=74889.93323863637\n",
      "test_test\n",
      "test mean loss=123982.5341796875\n",
      "epoch 76\n",
      "test_train\n",
      "train mean loss=75281.54356060606\n",
      "test_test\n",
      "test mean loss=124612.458984375\n",
      "epoch 77\n",
      "test_train\n",
      "train mean loss=75737.36766098485\n",
      "test_test\n",
      "test mean loss=124175.43798828125\n",
      "epoch 78\n",
      "test_train\n",
      "train mean loss=74264.29995265152\n",
      "test_test\n",
      "test mean loss=125547.88037109375\n",
      "epoch 79\n",
      "test_train\n",
      "train mean loss=75259.22857481061\n",
      "test_test\n",
      "test mean loss=126106.61474609375\n",
      "epoch 80\n",
      "test_train\n",
      "train mean loss=75109.55255681818\n",
      "test_test\n",
      "test mean loss=124248.3046875\n",
      "epoch 81\n",
      "test_train\n",
      "train mean loss=76012.56711647728\n",
      "test_test\n",
      "test mean loss=124963.4052734375\n",
      "epoch 82\n",
      "test_train\n",
      "train mean loss=75499.95774147728\n",
      "test_test\n",
      "test mean loss=124197.162109375\n",
      "epoch 83\n",
      "test_train\n",
      "train mean loss=76361.03184185606\n",
      "test_test\n",
      "test mean loss=125029.8095703125\n",
      "epoch 84\n",
      "test_train\n",
      "train mean loss=76475.51491477272\n",
      "test_test\n",
      "test mean loss=125991.9541015625\n",
      "epoch 85\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=75864.1239938447\n",
      "test_test\n",
      "test mean loss=125235.3408203125\n",
      "epoch 86\n",
      "test_train\n",
      "train mean loss=76076.69081439394\n",
      "test_test\n",
      "test mean loss=125458.56494140625\n",
      "epoch 87\n",
      "test_train\n",
      "train mean loss=75602.91092566287\n",
      "test_test\n",
      "test mean loss=125769.748046875\n",
      "epoch 88\n",
      "test_train\n",
      "train mean loss=76780.55835700757\n",
      "test_test\n",
      "test mean loss=126498.0556640625\n",
      "epoch 89\n",
      "test_train\n",
      "train mean loss=76182.25609611743\n",
      "test_test\n",
      "test mean loss=126667.94775390625\n",
      "epoch 90\n",
      "test_train\n",
      "train mean loss=75756.42223011363\n",
      "test_test\n",
      "test mean loss=126853.00146484375\n",
      "epoch 91\n",
      "test_train\n",
      "train mean loss=74092.68110795454\n",
      "test_test\n",
      "test mean loss=126684.31591796875\n",
      "epoch 92\n",
      "test_train\n",
      "train mean loss=74866.36103219698\n",
      "test_test\n",
      "test mean loss=125509.287109375\n",
      "epoch 93\n",
      "test_train\n",
      "train mean loss=75569.82776988637\n",
      "test_test\n",
      "test mean loss=127050.970703125\n",
      "epoch 94\n",
      "test_train\n",
      "train mean loss=74884.37819602272\n",
      "test_test\n",
      "test mean loss=126631.2080078125\n",
      "epoch 95\n",
      "test_train\n",
      "train mean loss=75897.01236979167\n",
      "test_test\n",
      "test mean loss=127501.158203125\n",
      "epoch 96\n",
      "test_train\n",
      "train mean loss=75802.74230587122\n",
      "test_test\n",
      "test mean loss=127165.85498046875\n",
      "epoch 97\n",
      "test_train\n",
      "train mean loss=74734.44010416667\n",
      "test_test\n",
      "test mean loss=125329.10791015625\n",
      "epoch 98\n",
      "test_train\n",
      "train mean loss=74792.97028882576\n",
      "test_test\n",
      "test mean loss=125809.70458984375\n",
      "epoch 99\n",
      "test_train\n",
      "train mean loss=75110.52823153409\n",
      "test_test\n",
      "test mean loss=125344.5654296875\n",
      "epoch 100\n",
      "test_train\n",
      "train mean loss=75527.89778645833\n",
      "test_test\n",
      "test mean loss=126101.22265625\n",
      "epoch 101\n",
      "test_train\n",
      "train mean loss=75167.09848484848\n",
      "test_test\n",
      "test mean loss=125701.66796875\n",
      "epoch 102\n",
      "test_train\n",
      "train mean loss=74039.25698390152\n",
      "test_test\n",
      "test mean loss=125841.92724609375\n",
      "epoch 103\n",
      "test_train\n",
      "train mean loss=74424.99354876894\n",
      "test_test\n",
      "test mean loss=125069.94140625\n",
      "epoch 104\n",
      "test_train\n",
      "train mean loss=73731.81048768939\n",
      "test_test\n",
      "test mean loss=125225.0107421875\n",
      "epoch 105\n",
      "test_train\n",
      "train mean loss=73624.65447443182\n",
      "test_test\n",
      "test mean loss=124822.4736328125\n",
      "epoch 106\n",
      "test_train\n",
      "train mean loss=74053.67080965909\n",
      "test_test\n",
      "test mean loss=123759.87158203125\n",
      "epoch 107\n",
      "test_train\n",
      "train mean loss=74662.82244318182\n",
      "test_test\n",
      "test mean loss=124397.193359375\n",
      "epoch 108\n",
      "test_train\n",
      "train mean loss=74562.91015625\n",
      "test_test\n",
      "test mean loss=121591.3203125\n",
      "epoch 109\n",
      "test_train\n",
      "train mean loss=74458.9951467803\n",
      "test_test\n",
      "test mean loss=120638.00048828125\n",
      "epoch 110\n",
      "test_train\n",
      "train mean loss=73761.30681818182\n",
      "test_test\n",
      "test mean loss=120961.60205078125\n",
      "epoch 111\n",
      "test_train\n",
      "train mean loss=74219.67329545454\n",
      "test_test\n",
      "test mean loss=121192.333984375\n",
      "epoch 112\n",
      "test_train\n",
      "train mean loss=73101.65352746213\n",
      "test_test\n",
      "test mean loss=119684.927734375\n",
      "epoch 113\n",
      "test_train\n",
      "train mean loss=73476.32848011363\n",
      "test_test\n",
      "test mean loss=119495.990234375\n",
      "epoch 114\n",
      "test_train\n",
      "train mean loss=72628.00520833333\n",
      "test_test\n",
      "test mean loss=119171.6162109375\n",
      "epoch 115\n",
      "test_train\n",
      "train mean loss=73186.17945075757\n",
      "test_test\n",
      "test mean loss=119531.0712890625\n",
      "epoch 116\n",
      "test_train\n",
      "train mean loss=74329.79610558713\n",
      "test_test\n",
      "test mean loss=119284.814453125\n",
      "epoch 117\n",
      "test_train\n",
      "train mean loss=73607.27580492424\n",
      "test_test\n",
      "test mean loss=120846.44970703125\n",
      "epoch 118\n",
      "test_train\n",
      "train mean loss=74519.12606534091\n",
      "test_test\n",
      "test mean loss=119597.5712890625\n",
      "epoch 119\n",
      "test_train\n",
      "train mean loss=73297.15808475378\n",
      "test_test\n",
      "test mean loss=122031.46630859375\n",
      "epoch 120\n",
      "test_train\n",
      "train mean loss=73708.32883522728\n",
      "test_test\n",
      "test mean loss=121917.3740234375\n",
      "epoch 121\n",
      "test_train\n",
      "train mean loss=74180.21815814394\n",
      "test_test\n",
      "test mean loss=122566.50927734375\n",
      "epoch 122\n",
      "test_train\n",
      "train mean loss=73445.46158854167\n",
      "test_test\n",
      "test mean loss=121546.6298828125\n",
      "epoch 123\n",
      "test_train\n",
      "train mean loss=73886.47833806818\n",
      "test_test\n",
      "test mean loss=122482.83154296875\n",
      "epoch 124\n",
      "test_train\n",
      "train mean loss=72971.05184659091\n",
      "test_test\n",
      "test mean loss=122095.80322265625\n",
      "epoch 125\n",
      "test_train\n",
      "train mean loss=72851.70300662878\n",
      "test_test\n",
      "test mean loss=121749.35693359375\n",
      "epoch 126\n",
      "test_train\n",
      "train mean loss=72983.66045217802\n",
      "test_test\n",
      "test mean loss=123614.0966796875\n",
      "epoch 127\n",
      "test_train\n",
      "train mean loss=72744.48804450757\n",
      "test_test\n",
      "test mean loss=122111.3037109375\n",
      "epoch 128\n",
      "test_train\n",
      "train mean loss=72971.21638257576\n",
      "test_test\n",
      "test mean loss=123063.509765625\n",
      "epoch 129\n",
      "test_train\n",
      "train mean loss=72121.36168323863\n",
      "test_test\n",
      "test mean loss=121915.16064453125\n",
      "epoch 130\n",
      "test_train\n",
      "train mean loss=73628.25177556818\n",
      "test_test\n",
      "test mean loss=122089.8251953125\n",
      "epoch 131\n",
      "test_train\n",
      "train mean loss=71870.50473484848\n",
      "test_test\n",
      "test mean loss=122247.41162109375\n",
      "epoch 132\n",
      "test_train\n",
      "train mean loss=73541.78823390152\n",
      "test_test\n",
      "test mean loss=123383.94384765625\n",
      "epoch 133\n",
      "test_train\n",
      "train mean loss=71675.20501893939\n",
      "test_test\n",
      "test mean loss=123172.7216796875\n",
      "epoch 134\n",
      "test_train\n",
      "train mean loss=73007.96377840909\n",
      "test_test\n",
      "test mean loss=123792.38330078125\n",
      "epoch 135\n",
      "test_train\n",
      "train mean loss=71915.37162642046\n",
      "test_test\n",
      "test mean loss=123405.861328125\n",
      "epoch 136\n",
      "test_train\n",
      "train mean loss=73604.8760061553\n",
      "test_test\n",
      "test mean loss=123617.8115234375\n",
      "epoch 137\n",
      "test_train\n",
      "train mean loss=74359.45549242424\n",
      "test_test\n",
      "test mean loss=122281.09130859375\n",
      "epoch 138\n",
      "test_train\n",
      "train mean loss=73956.43288352272\n",
      "test_test\n",
      "test mean loss=121342.83740234375\n",
      "epoch 139\n",
      "test_train\n",
      "train mean loss=73919.18738162878\n",
      "test_test\n",
      "test mean loss=119951.314453125\n",
      "epoch 140\n",
      "test_train\n",
      "train mean loss=74131.53267045454\n",
      "test_test\n",
      "test mean loss=120110.04248046875\n",
      "epoch 141\n",
      "test_train\n",
      "train mean loss=74362.88121448863\n",
      "test_test\n",
      "test mean loss=119754.94873046875\n",
      "epoch 142\n",
      "test_train\n",
      "train mean loss=74347.30066287878\n",
      "test_test\n",
      "test mean loss=119128.92529296875\n",
      "epoch 143\n",
      "test_train\n",
      "train mean loss=74058.60298295454\n",
      "test_test\n",
      "test mean loss=120049.61083984375\n",
      "epoch 144\n",
      "test_train\n",
      "train mean loss=74212.77722537878\n",
      "test_test\n",
      "test mean loss=119390.103515625\n",
      "epoch 145\n",
      "test_train\n",
      "train mean loss=74687.35227272728\n",
      "test_test\n",
      "test mean loss=119383.0302734375\n",
      "epoch 146\n",
      "test_train\n",
      "train mean loss=74025.87760416667\n",
      "test_test\n",
      "test mean loss=119996.701171875\n",
      "epoch 147\n",
      "test_train\n",
      "train mean loss=73798.45040246213\n",
      "test_test\n",
      "test mean loss=119419.39013671875\n",
      "epoch 148\n",
      "test_train\n",
      "train mean loss=74748.72082149622\n",
      "test_test\n",
      "test mean loss=119740.62841796875\n",
      "epoch 149\n",
      "test_train\n",
      "train mean loss=74217.72739109848\n",
      "test_test\n",
      "test mean loss=118998.3056640625\n",
      "epoch 150\n",
      "test_train\n",
      "train mean loss=74141.33617424243\n",
      "test_test\n",
      "test mean loss=119575.92822265625\n",
      "epoch 151\n",
      "test_train\n",
      "train mean loss=74223.80610795454\n",
      "test_test\n",
      "test mean loss=119149.53369140625\n",
      "epoch 152\n",
      "test_train\n",
      "train mean loss=73483.97283380682\n",
      "test_test\n",
      "test mean loss=119293.3154296875\n",
      "epoch 153\n",
      "test_train\n",
      "train mean loss=74028.0673532197\n",
      "test_test\n",
      "test mean loss=120341.63720703125\n",
      "epoch 154\n",
      "test_train\n",
      "train mean loss=73366.78551136363\n",
      "test_test\n",
      "test mean loss=120721.97509765625\n",
      "epoch 155\n",
      "test_train\n",
      "train mean loss=73848.21176609848\n",
      "test_test\n",
      "test mean loss=119028.19482421875\n",
      "epoch 156\n",
      "test_train\n",
      "train mean loss=74323.61553030302\n",
      "test_test\n",
      "test mean loss=118469.11865234375\n",
      "epoch 157\n",
      "test_train\n",
      "train mean loss=73334.95129024622\n",
      "test_test\n",
      "test mean loss=120165.68603515625\n",
      "epoch 158\n",
      "test_train\n",
      "train mean loss=73901.11026278409\n",
      "test_test\n",
      "test mean loss=119912.482421875\n",
      "epoch 159\n",
      "test_train\n",
      "train mean loss=72985.67755681818\n",
      "test_test\n",
      "test mean loss=120041.97607421875\n",
      "epoch 160\n",
      "test_train\n",
      "train mean loss=73401.05871212122\n",
      "test_test\n",
      "test mean loss=121123.2099609375\n",
      "epoch 161\n",
      "test_train\n",
      "train mean loss=72691.36931818182\n",
      "test_test\n",
      "test mean loss=120428.533203125\n",
      "epoch 162\n",
      "test_train\n",
      "train mean loss=72680.86896306818\n",
      "test_test\n",
      "test mean loss=119926.75537109375\n",
      "epoch 163\n",
      "test_train\n",
      "train mean loss=73818.14086174243\n",
      "test_test\n",
      "test mean loss=119109.8994140625\n",
      "epoch 164\n",
      "test_train\n",
      "train mean loss=73980.87050189394\n",
      "test_test\n",
      "test mean loss=119280.0771484375\n",
      "epoch 165\n",
      "test_train\n",
      "train mean loss=73555.46661931818\n",
      "test_test\n",
      "test mean loss=118852.841796875\n",
      "epoch 166\n",
      "test_train\n",
      "train mean loss=72795.95596590909\n",
      "test_test\n",
      "test mean loss=119337.47509765625\n",
      "epoch 167\n",
      "test_train\n",
      "train mean loss=73656.22987689394\n",
      "test_test\n",
      "test mean loss=119494.8115234375\n",
      "epoch 168\n",
      "test_train\n",
      "train mean loss=73544.01225142046\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=119832.5234375\n",
      "epoch 169\n",
      "test_train\n",
      "train mean loss=72882.29060132576\n",
      "test_test\n",
      "test mean loss=119788.9873046875\n",
      "epoch 170\n",
      "test_train\n",
      "train mean loss=72841.7138967803\n",
      "test_test\n",
      "test mean loss=120236.4794921875\n",
      "epoch 171\n",
      "test_train\n",
      "train mean loss=73278.69673295454\n",
      "test_test\n",
      "test mean loss=120209.341796875\n",
      "epoch 172\n",
      "test_train\n",
      "train mean loss=73610.25136126894\n",
      "test_test\n",
      "test mean loss=120173.55712890625\n",
      "epoch 173\n",
      "test_train\n",
      "train mean loss=73142.83345170454\n",
      "test_test\n",
      "test mean loss=119950.36865234375\n",
      "epoch 174\n",
      "test_train\n",
      "train mean loss=73284.81770833333\n",
      "test_test\n",
      "test mean loss=120471.3701171875\n",
      "epoch 175\n",
      "test_train\n",
      "train mean loss=73315.89382102272\n",
      "test_test\n",
      "test mean loss=119446.2021484375\n",
      "epoch 176\n",
      "test_train\n",
      "train mean loss=72939.82658617424\n",
      "test_test\n",
      "test mean loss=120284.88916015625\n",
      "epoch 177\n",
      "test_train\n",
      "train mean loss=73220.11044034091\n",
      "test_test\n",
      "test mean loss=119651.57861328125\n",
      "epoch 178\n",
      "test_train\n",
      "train mean loss=73672.88861268939\n",
      "test_test\n",
      "test mean loss=120252.66015625\n",
      "epoch 179\n",
      "test_train\n",
      "train mean loss=72496.32688210228\n",
      "test_test\n",
      "test mean loss=119933.7353515625\n",
      "epoch 180\n",
      "test_train\n",
      "train mean loss=73262.978515625\n",
      "test_test\n",
      "test mean loss=120048.52392578125\n",
      "epoch 181\n",
      "test_train\n",
      "train mean loss=72344.09256628787\n",
      "test_test\n",
      "test mean loss=119970.5810546875\n",
      "epoch 182\n",
      "test_train\n",
      "train mean loss=73007.5849905303\n",
      "test_test\n",
      "test mean loss=121395.43310546875\n",
      "epoch 183\n",
      "test_train\n",
      "train mean loss=73138.91098484848\n",
      "test_test\n",
      "test mean loss=121660.2060546875\n",
      "epoch 184\n",
      "test_train\n",
      "train mean loss=72861.34327651515\n",
      "test_test\n",
      "test mean loss=121214.775390625\n",
      "epoch 185\n",
      "test_train\n",
      "train mean loss=73089.81036931818\n",
      "test_test\n",
      "test mean loss=121187.63427734375\n",
      "epoch 186\n",
      "test_train\n",
      "train mean loss=73562.81321022728\n",
      "test_test\n",
      "test mean loss=121960.3310546875\n",
      "epoch 187\n",
      "test_train\n",
      "train mean loss=72893.95649857954\n",
      "test_test\n",
      "test mean loss=121198.70751953125\n",
      "epoch 188\n",
      "test_train\n",
      "train mean loss=73925.53207859848\n",
      "test_test\n",
      "test mean loss=121001.439453125\n",
      "epoch 189\n",
      "test_train\n",
      "train mean loss=73205.93051609848\n",
      "test_test\n",
      "test mean loss=121591.63330078125\n",
      "epoch 190\n",
      "test_train\n",
      "train mean loss=75588.12334280302\n",
      "test_test\n",
      "test mean loss=117299.12890625\n",
      "epoch 191\n",
      "test_train\n",
      "train mean loss=74935.25603693182\n",
      "test_test\n",
      "test mean loss=117933.21728515625\n",
      "epoch 192\n",
      "test_train\n",
      "train mean loss=75674.45040246213\n",
      "test_test\n",
      "test mean loss=120831.19775390625\n",
      "epoch 193\n",
      "test_train\n",
      "train mean loss=75214.28468276515\n",
      "test_test\n",
      "test mean loss=121554.30224609375\n",
      "epoch 194\n",
      "test_train\n",
      "train mean loss=74651.47916666667\n",
      "test_test\n",
      "test mean loss=120661.42626953125\n",
      "epoch 195\n",
      "test_train\n",
      "train mean loss=74826.15370501894\n",
      "test_test\n",
      "test mean loss=121075.82373046875\n",
      "epoch 196\n",
      "test_train\n",
      "train mean loss=74944.18093039772\n",
      "test_test\n",
      "test mean loss=117830.68896484375\n",
      "epoch 197\n",
      "test_train\n",
      "train mean loss=73757.20744554924\n",
      "test_test\n",
      "test mean loss=117948.48193359375\n",
      "epoch 198\n",
      "test_train\n",
      "train mean loss=73526.40246212122\n",
      "test_test\n",
      "test mean loss=118909.57568359375\n",
      "epoch 199\n",
      "test_train\n",
      "train mean loss=74532.59576231061\n",
      "test_test\n",
      "test mean loss=119560.34521484375\n",
      "epoch 200\n",
      "test_train\n",
      "train mean loss=73013.79024621213\n",
      "test_test\n",
      "test mean loss=118761.74462890625\n",
      "epoch 201\n",
      "test_train\n",
      "train mean loss=74572.15885416667\n",
      "test_test\n",
      "test mean loss=119160.92529296875\n",
      "epoch 202\n",
      "test_train\n",
      "train mean loss=73246.63068181818\n",
      "test_test\n",
      "test mean loss=119789.2216796875\n",
      "epoch 203\n",
      "test_train\n",
      "train mean loss=73719.35866477272\n",
      "test_test\n",
      "test mean loss=119979.91650390625\n",
      "epoch 204\n",
      "test_train\n",
      "train mean loss=74365.26207386363\n",
      "test_test\n",
      "test mean loss=120425.52734375\n",
      "epoch 205\n",
      "test_train\n",
      "train mean loss=74159.31646543561\n",
      "test_test\n",
      "test mean loss=119824.4228515625\n",
      "epoch 206\n",
      "test_train\n",
      "train mean loss=74260.82504734848\n",
      "test_test\n",
      "test mean loss=119381.24072265625\n",
      "epoch 207\n",
      "test_train\n",
      "train mean loss=74001.71081912878\n",
      "test_test\n",
      "test mean loss=119827.5791015625\n",
      "epoch 208\n",
      "test_train\n",
      "train mean loss=73623.61706912878\n",
      "test_test\n",
      "test mean loss=119000.8662109375\n",
      "epoch 209\n",
      "test_train\n",
      "train mean loss=73994.68939393939\n",
      "test_test\n",
      "test mean loss=118783.2412109375\n",
      "epoch 210\n",
      "test_train\n",
      "train mean loss=73492.75639204546\n",
      "test_test\n",
      "test mean loss=118687.71630859375\n",
      "epoch 211\n",
      "test_train\n",
      "train mean loss=73124.15707859848\n",
      "test_test\n",
      "test mean loss=119235.404296875\n",
      "epoch 212\n",
      "test_train\n",
      "train mean loss=73963.43963068182\n",
      "test_test\n",
      "test mean loss=119419.197265625\n",
      "epoch 213\n",
      "test_train\n",
      "train mean loss=73737.51716382576\n",
      "test_test\n",
      "test mean loss=118398.23681640625\n",
      "epoch 214\n",
      "test_train\n",
      "train mean loss=73058.65500710228\n",
      "test_test\n",
      "test mean loss=119584.7783203125\n",
      "epoch 215\n",
      "test_train\n",
      "train mean loss=73444.9345407197\n",
      "test_test\n",
      "test mean loss=119553.5498046875\n",
      "epoch 216\n",
      "test_train\n",
      "train mean loss=72824.78077651515\n",
      "test_test\n",
      "test mean loss=119435.65380859375\n",
      "epoch 217\n",
      "test_train\n",
      "train mean loss=74332.52024147728\n",
      "test_test\n",
      "test mean loss=119995.427734375\n",
      "epoch 218\n",
      "test_train\n",
      "train mean loss=73436.60830965909\n",
      "test_test\n",
      "test mean loss=121130.00634765625\n",
      "epoch 219\n",
      "test_train\n",
      "train mean loss=73770.54403409091\n",
      "test_test\n",
      "test mean loss=120232.6220703125\n",
      "epoch 220\n",
      "test_train\n",
      "train mean loss=72883.57848011363\n",
      "test_test\n",
      "test mean loss=120843.38232421875\n",
      "epoch 221\n",
      "test_train\n",
      "train mean loss=73481.40707859848\n",
      "test_test\n",
      "test mean loss=121197.71923828125\n",
      "epoch 222\n",
      "test_train\n",
      "train mean loss=72811.71141098485\n",
      "test_test\n",
      "test mean loss=120950.83984375\n",
      "epoch 223\n",
      "test_train\n",
      "train mean loss=72789.76763731061\n",
      "test_test\n",
      "test mean loss=121504.1318359375\n",
      "epoch 224\n",
      "test_train\n",
      "train mean loss=71981.70892518939\n",
      "test_test\n",
      "test mean loss=121433.6005859375\n",
      "epoch 225\n",
      "test_train\n",
      "train mean loss=72406.42388731061\n",
      "test_test\n",
      "test mean loss=121165.78564453125\n",
      "epoch 226\n",
      "test_train\n",
      "train mean loss=72922.15056818182\n",
      "test_test\n",
      "test mean loss=120506.75927734375\n",
      "epoch 227\n",
      "test_train\n",
      "train mean loss=73184.31368371213\n",
      "test_test\n",
      "test mean loss=120207.00634765625\n",
      "epoch 228\n",
      "test_train\n",
      "train mean loss=72795.19294507576\n",
      "test_test\n",
      "test mean loss=120537.84814453125\n",
      "epoch 229\n",
      "test_train\n",
      "train mean loss=73081.19904119318\n",
      "test_test\n",
      "test mean loss=120204.482421875\n",
      "epoch 230\n",
      "test_train\n",
      "train mean loss=72552.07599431818\n",
      "test_test\n",
      "test mean loss=119656.00732421875\n",
      "epoch 231\n",
      "test_train\n",
      "train mean loss=72763.96768465909\n",
      "test_test\n",
      "test mean loss=120957.81982421875\n",
      "epoch 232\n",
      "test_train\n",
      "train mean loss=72096.74135890152\n",
      "test_test\n",
      "test mean loss=120878.0556640625\n",
      "epoch 233\n",
      "test_train\n",
      "train mean loss=73332.08084753787\n",
      "test_test\n",
      "test mean loss=120691.93603515625\n",
      "epoch 234\n",
      "test_train\n",
      "train mean loss=72125.74106297348\n",
      "test_test\n",
      "test mean loss=121055.98095703125\n",
      "epoch 235\n",
      "test_train\n",
      "train mean loss=73968.34090909091\n",
      "test_test\n",
      "test mean loss=120532.7490234375\n",
      "epoch 236\n",
      "test_train\n",
      "train mean loss=72438.77479876894\n",
      "test_test\n",
      "test mean loss=120625.90869140625\n",
      "epoch 237\n",
      "test_train\n",
      "train mean loss=73244.38973721591\n",
      "test_test\n",
      "test mean loss=121311.83056640625\n",
      "epoch 238\n",
      "test_train\n",
      "train mean loss=74042.98828125\n",
      "test_test\n",
      "test mean loss=121001.34423828125\n",
      "epoch 239\n",
      "test_train\n",
      "train mean loss=73939.48070549243\n",
      "test_test\n",
      "test mean loss=121455.56640625\n",
      "epoch 240\n",
      "test_train\n",
      "train mean loss=72966.02337831439\n",
      "test_test\n",
      "test mean loss=120477.3935546875\n",
      "epoch 241\n",
      "test_train\n",
      "train mean loss=73665.23200757576\n",
      "test_test\n",
      "test mean loss=120593.83984375\n",
      "epoch 242\n",
      "test_train\n",
      "train mean loss=73559.40376420454\n",
      "test_test\n",
      "test mean loss=121576.7783203125\n",
      "epoch 243\n",
      "test_train\n",
      "train mean loss=73166.26444128787\n",
      "test_test\n",
      "test mean loss=121110.408203125\n",
      "epoch 244\n",
      "test_train\n",
      "train mean loss=73165.32362689394\n",
      "test_test\n",
      "test mean loss=121035.23583984375\n",
      "epoch 245\n",
      "test_train\n",
      "train mean loss=74151.23757102272\n",
      "test_test\n",
      "test mean loss=120753.56591796875\n",
      "epoch 246\n",
      "test_train\n",
      "train mean loss=74018.52852746213\n",
      "test_test\n",
      "test mean loss=120940.91552734375\n",
      "epoch 247\n",
      "test_train\n",
      "train mean loss=73369.5282907197\n",
      "test_test\n",
      "test mean loss=121201.193359375\n",
      "epoch 248\n",
      "test_train\n",
      "train mean loss=73207.34599905302\n",
      "test_test\n",
      "test mean loss=121635.5986328125\n",
      "epoch 249\n",
      "test_train\n",
      "train mean loss=73679.55930397728\n",
      "test_test\n",
      "test mean loss=121371.19873046875\n",
      "epoch 250\n",
      "test_train\n",
      "train mean loss=73925.00651041667\n",
      "test_test\n",
      "test mean loss=121427.0615234375\n",
      "epoch 251\n",
      "test_train\n",
      "train mean loss=73560.90275804924\n",
      "test_test\n",
      "test mean loss=120522.416015625\n",
      "epoch 252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_train\n",
      "train mean loss=73616.50124289772\n",
      "test_test\n",
      "test mean loss=120229.86181640625\n",
      "epoch 253\n",
      "test_train\n",
      "train mean loss=73121.11393229167\n",
      "test_test\n",
      "test mean loss=120186.701171875\n",
      "epoch 254\n",
      "test_train\n",
      "train mean loss=72676.4599905303\n",
      "test_test\n",
      "test mean loss=120878.095703125\n",
      "epoch 255\n",
      "test_train\n",
      "train mean loss=73386.46839488637\n",
      "test_test\n",
      "test mean loss=121563.5712890625\n",
      "epoch 256\n",
      "test_train\n",
      "train mean loss=73872.4179391572\n",
      "test_test\n",
      "test mean loss=120838.62451171875\n",
      "epoch 257\n",
      "test_train\n",
      "train mean loss=73730.33528645833\n",
      "test_test\n",
      "test mean loss=121080.66552734375\n",
      "epoch 258\n",
      "test_train\n",
      "train mean loss=73649.548828125\n",
      "test_test\n",
      "test mean loss=120798.13623046875\n",
      "epoch 259\n",
      "test_train\n",
      "train mean loss=73636.68158143939\n",
      "test_test\n",
      "test mean loss=119376.73828125\n",
      "epoch 260\n",
      "test_train\n",
      "train mean loss=73837.04746685606\n",
      "test_test\n",
      "test mean loss=120203.91650390625\n",
      "epoch 261\n",
      "test_train\n",
      "train mean loss=73914.67424242424\n",
      "test_test\n",
      "test mean loss=120458.873046875\n",
      "epoch 262\n",
      "test_train\n",
      "train mean loss=73828.56338778409\n",
      "test_test\n",
      "test mean loss=121043.587890625\n",
      "epoch 263\n",
      "test_train\n",
      "train mean loss=74197.23910984848\n",
      "test_test\n",
      "test mean loss=121397.0615234375\n",
      "epoch 264\n",
      "test_train\n",
      "train mean loss=73689.62227746213\n",
      "test_test\n",
      "test mean loss=120548.6201171875\n",
      "epoch 265\n",
      "test_train\n",
      "train mean loss=73334.23419744318\n",
      "test_test\n",
      "test mean loss=120772.76025390625\n",
      "epoch 266\n",
      "test_train\n",
      "train mean loss=72937.12582859848\n",
      "test_test\n",
      "test mean loss=120781.55322265625\n",
      "epoch 267\n",
      "test_train\n",
      "train mean loss=73264.9814157197\n",
      "test_test\n",
      "test mean loss=122204.79638671875\n",
      "epoch 268\n",
      "test_train\n",
      "train mean loss=73155.68915719698\n",
      "test_test\n",
      "test mean loss=121289.62841796875\n",
      "epoch 269\n",
      "test_train\n",
      "train mean loss=73656.41027462122\n",
      "test_test\n",
      "test mean loss=121488.99853515625\n",
      "epoch 270\n",
      "test_train\n",
      "train mean loss=72920.60020123106\n",
      "test_test\n",
      "test mean loss=120654.84716796875\n",
      "epoch 271\n",
      "test_train\n",
      "train mean loss=73794.41666666667\n",
      "test_test\n",
      "test mean loss=120768.56396484375\n",
      "epoch 272\n",
      "test_train\n",
      "train mean loss=72413.3310842803\n",
      "test_test\n",
      "test mean loss=120679.79150390625\n",
      "epoch 273\n",
      "test_train\n",
      "train mean loss=73435.49479166667\n",
      "test_test\n",
      "test mean loss=120620.02392578125\n",
      "epoch 274\n",
      "test_train\n",
      "train mean loss=73882.95052083333\n",
      "test_test\n",
      "test mean loss=121376.6416015625\n",
      "epoch 275\n",
      "test_train\n",
      "train mean loss=74040.94513494318\n",
      "test_test\n",
      "test mean loss=121709.46728515625\n",
      "epoch 276\n",
      "test_train\n",
      "train mean loss=73067.38648200757\n",
      "test_test\n",
      "test mean loss=121878.18603515625\n",
      "epoch 277\n",
      "test_train\n",
      "train mean loss=73625.5478219697\n",
      "test_test\n",
      "test mean loss=122750.12255859375\n",
      "epoch 278\n",
      "test_train\n",
      "train mean loss=74331.0869436553\n",
      "test_test\n",
      "test mean loss=121819.8466796875\n",
      "epoch 279\n",
      "test_train\n",
      "train mean loss=72907.82634943182\n",
      "test_test\n",
      "test mean loss=122666.9814453125\n",
      "epoch 280\n",
      "test_train\n",
      "train mean loss=73826.765625\n",
      "test_test\n",
      "test mean loss=122191.11572265625\n",
      "epoch 281\n",
      "test_train\n",
      "train mean loss=72785.40305397728\n",
      "test_test\n",
      "test mean loss=122627.1064453125\n",
      "epoch 282\n",
      "test_train\n",
      "train mean loss=74352.42412405302\n",
      "test_test\n",
      "test mean loss=122729.64501953125\n",
      "epoch 283\n",
      "test_train\n",
      "train mean loss=73424.42702414772\n",
      "test_test\n",
      "test mean loss=121922.78515625\n",
      "epoch 284\n",
      "test_train\n",
      "train mean loss=74234.34895833333\n",
      "test_test\n",
      "test mean loss=121187.90673828125\n",
      "epoch 285\n",
      "test_train\n",
      "train mean loss=73418.42045454546\n",
      "test_test\n",
      "test mean loss=121002.6005859375\n",
      "epoch 286\n",
      "test_train\n",
      "train mean loss=72847.80729166667\n",
      "test_test\n",
      "test mean loss=120337.990234375\n",
      "epoch 287\n",
      "test_train\n",
      "train mean loss=73563.88156960228\n",
      "test_test\n",
      "test mean loss=120848.34765625\n",
      "epoch 288\n",
      "test_train\n",
      "train mean loss=73103.68974905302\n",
      "test_test\n",
      "test mean loss=121219.923828125\n",
      "epoch 289\n",
      "test_train\n",
      "train mean loss=73402.88529829546\n",
      "test_test\n",
      "test mean loss=120665.15771484375\n",
      "epoch 290\n",
      "test_train\n",
      "train mean loss=73847.94921875\n",
      "test_test\n",
      "test mean loss=121165.546875\n",
      "epoch 291\n",
      "test_train\n",
      "train mean loss=74391.46508049243\n",
      "test_test\n",
      "test mean loss=120933.99560546875\n",
      "epoch 292\n",
      "test_train\n",
      "train mean loss=73837.75580018939\n",
      "test_test\n",
      "test mean loss=121293.22119140625\n",
      "epoch 293\n",
      "test_train\n",
      "train mean loss=73692.11766098485\n",
      "test_test\n",
      "test mean loss=121169.5322265625\n",
      "epoch 294\n",
      "test_train\n",
      "train mean loss=73137.84043560606\n",
      "test_test\n",
      "test mean loss=121151.451171875\n",
      "epoch 295\n",
      "test_train\n",
      "train mean loss=73193.35558712122\n",
      "test_test\n",
      "test mean loss=120601.4599609375\n",
      "epoch 296\n",
      "test_train\n",
      "train mean loss=73582.89322916667\n",
      "test_test\n",
      "test mean loss=120390.42138671875\n",
      "epoch 297\n",
      "test_train\n",
      "train mean loss=74116.00538589015\n",
      "test_test\n",
      "test mean loss=120178.89599609375\n",
      "epoch 298\n",
      "test_train\n",
      "train mean loss=73697.30634469698\n",
      "test_test\n",
      "test mean loss=120715.4443359375\n",
      "epoch 299\n",
      "test_train\n",
      "train mean loss=73323.80622632576\n",
      "test_test\n",
      "test mean loss=120728.06494140625\n",
      "epoch 300\n",
      "test_train\n",
      "train mean loss=73422.17045454546\n",
      "test_test\n",
      "test mean loss=121216.4853515625\n",
      "epoch 301\n",
      "test_train\n",
      "train mean loss=73649.86564867424\n",
      "test_test\n",
      "test mean loss=120833.99755859375\n",
      "epoch 302\n",
      "test_train\n",
      "train mean loss=73680.77627840909\n",
      "test_test\n",
      "test mean loss=120573.4931640625\n",
      "epoch 303\n",
      "test_train\n",
      "train mean loss=73675.97969933713\n",
      "test_test\n",
      "test mean loss=121317.91015625\n",
      "epoch 304\n",
      "test_train\n",
      "train mean loss=73936.56096117424\n",
      "test_test\n",
      "test mean loss=121237.072265625\n",
      "epoch 305\n",
      "test_train\n",
      "train mean loss=74335.28705018939\n",
      "test_test\n",
      "test mean loss=120847.59521484375\n",
      "epoch 306\n",
      "test_train\n",
      "train mean loss=74095.91583806818\n",
      "test_test\n",
      "test mean loss=120415.0419921875\n",
      "epoch 307\n",
      "test_train\n",
      "train mean loss=73180.85629734848\n",
      "test_test\n",
      "test mean loss=120402.958984375\n",
      "epoch 308\n",
      "test_train\n",
      "train mean loss=74140.44756155302\n",
      "test_test\n",
      "test mean loss=120501.5146484375\n",
      "epoch 309\n",
      "test_train\n",
      "train mean loss=73649.17353219698\n",
      "test_test\n",
      "test mean loss=120617.4306640625\n",
      "epoch 310\n",
      "test_train\n",
      "train mean loss=73329.12582859848\n",
      "test_test\n",
      "test mean loss=120801.47607421875\n",
      "epoch 311\n",
      "test_train\n",
      "train mean loss=73572.55865293561\n",
      "test_test\n",
      "test mean loss=121270.70703125\n",
      "epoch 312\n",
      "test_train\n",
      "train mean loss=74085.28983191287\n",
      "test_test\n",
      "test mean loss=121049.775390625\n",
      "epoch 313\n",
      "test_train\n",
      "train mean loss=73796.88198390152\n",
      "test_test\n",
      "test mean loss=120044.46875\n",
      "epoch 314\n",
      "test_train\n",
      "train mean loss=73835.22076231061\n",
      "test_test\n",
      "test mean loss=120279.81396484375\n",
      "epoch 315\n",
      "test_train\n",
      "train mean loss=73760.64683948863\n",
      "test_test\n",
      "test mean loss=120091.11962890625\n",
      "epoch 316\n",
      "test_train\n",
      "train mean loss=73236.57504734848\n",
      "test_test\n",
      "test mean loss=120436.91845703125\n",
      "epoch 317\n",
      "test_train\n",
      "train mean loss=74426.61215672348\n",
      "test_test\n",
      "test mean loss=120714.19482421875\n",
      "epoch 318\n",
      "test_train\n",
      "train mean loss=73011.40068655302\n",
      "test_test\n",
      "test mean loss=120122.50341796875\n",
      "epoch 319\n",
      "test_train\n",
      "train mean loss=73387.49727746213\n",
      "test_test\n",
      "test mean loss=122223.9716796875\n",
      "epoch 320\n",
      "test_train\n",
      "train mean loss=73404.35984848485\n",
      "test_test\n",
      "test mean loss=122642.412109375\n",
      "epoch 321\n",
      "test_train\n",
      "train mean loss=73358.49301609848\n",
      "test_test\n",
      "test mean loss=122243.83837890625\n",
      "epoch 322\n",
      "test_train\n",
      "train mean loss=74320.26302083333\n",
      "test_test\n",
      "test mean loss=122331.61376953125\n",
      "epoch 323\n",
      "test_train\n",
      "train mean loss=73914.94223484848\n",
      "test_test\n",
      "test mean loss=120836.5654296875\n",
      "epoch 324\n",
      "test_train\n",
      "train mean loss=73315.22526041667\n",
      "test_test\n",
      "test mean loss=121500.65869140625\n",
      "epoch 325\n",
      "test_train\n",
      "train mean loss=74151.93205492424\n",
      "test_test\n",
      "test mean loss=121585.75341796875\n",
      "epoch 326\n",
      "test_train\n",
      "train mean loss=73472.85913825757\n",
      "test_test\n",
      "test mean loss=121308.07568359375\n",
      "epoch 327\n",
      "test_train\n",
      "train mean loss=73858.00449810606\n",
      "test_test\n",
      "test mean loss=121751.701171875\n",
      "epoch 328\n",
      "test_train\n",
      "train mean loss=73863.75366950757\n",
      "test_test\n",
      "test mean loss=121639.36181640625\n",
      "epoch 329\n",
      "test_train\n",
      "train mean loss=73550.77965198863\n",
      "test_test\n",
      "test mean loss=121996.69384765625\n",
      "epoch 330\n",
      "test_train\n",
      "train mean loss=73862.04166666667\n",
      "test_test\n",
      "test mean loss=120332.75830078125\n",
      "epoch 331\n",
      "test_train\n",
      "train mean loss=73659.54817708333\n",
      "test_test\n",
      "test mean loss=119667.99072265625\n",
      "epoch 332\n",
      "test_train\n",
      "train mean loss=74086.94661458333\n",
      "test_test\n",
      "test mean loss=119588.15576171875\n",
      "epoch 333\n",
      "test_train\n",
      "train mean loss=74003.1083688447\n",
      "test_test\n",
      "test mean loss=119431.64404296875\n",
      "epoch 334\n",
      "test_train\n",
      "train mean loss=73429.72975852272\n",
      "test_test\n",
      "test mean loss=120682.44921875\n",
      "epoch 335\n",
      "test_train\n",
      "train mean loss=73559.08830492424\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=120523.52880859375\n",
      "epoch 336\n",
      "test_train\n",
      "train mean loss=74078.33558238637\n",
      "test_test\n",
      "test mean loss=120920.23388671875\n",
      "epoch 337\n",
      "test_train\n",
      "train mean loss=73419.45762310606\n",
      "test_test\n",
      "test mean loss=121070.2568359375\n",
      "epoch 338\n",
      "test_train\n",
      "train mean loss=73158.49070785985\n",
      "test_test\n",
      "test mean loss=121281.009765625\n",
      "epoch 339\n",
      "test_train\n",
      "train mean loss=73201.00467566287\n",
      "test_test\n",
      "test mean loss=121513.97705078125\n",
      "epoch 340\n",
      "test_train\n",
      "train mean loss=73695.74289772728\n",
      "test_test\n",
      "test mean loss=120841.9404296875\n",
      "epoch 341\n",
      "test_train\n",
      "train mean loss=73370.29509943182\n",
      "test_test\n",
      "test mean loss=120598.80810546875\n",
      "epoch 342\n",
      "test_train\n",
      "train mean loss=73357.75390625\n",
      "test_test\n",
      "test mean loss=120481.60009765625\n",
      "epoch 343\n",
      "test_train\n",
      "train mean loss=73072.79131155302\n",
      "test_test\n",
      "test mean loss=121028.77099609375\n",
      "epoch 344\n",
      "test_train\n",
      "train mean loss=73822.62038352272\n",
      "test_test\n",
      "test mean loss=120894.51025390625\n",
      "epoch 345\n",
      "test_train\n",
      "train mean loss=72675.27456202652\n",
      "test_test\n",
      "test mean loss=121436.15185546875\n",
      "epoch 346\n",
      "test_train\n",
      "train mean loss=73294.03432765152\n",
      "test_test\n",
      "test mean loss=121114.921875\n",
      "epoch 347\n",
      "test_train\n",
      "train mean loss=73236.48620975378\n",
      "test_test\n",
      "test mean loss=120720.11328125\n",
      "epoch 348\n",
      "test_train\n",
      "train mean loss=72797.77722537878\n",
      "test_test\n",
      "test mean loss=120968.99462890625\n",
      "epoch 349\n",
      "test_train\n",
      "train mean loss=73121.84138257576\n",
      "test_test\n",
      "test mean loss=121241.17626953125\n",
      "epoch 350\n",
      "test_train\n",
      "train mean loss=72405.32741477272\n",
      "test_test\n",
      "test mean loss=120775.42822265625\n",
      "epoch 351\n",
      "test_train\n",
      "train mean loss=72659.18323863637\n",
      "test_test\n",
      "test mean loss=121189.9609375\n",
      "epoch 352\n",
      "test_train\n",
      "train mean loss=72326.53468276515\n",
      "test_test\n",
      "test mean loss=120981.5234375\n",
      "epoch 353\n",
      "test_train\n",
      "train mean loss=72336.14109848485\n",
      "test_test\n",
      "test mean loss=121132.2548828125\n",
      "epoch 354\n",
      "test_train\n",
      "train mean loss=72906.51089015152\n",
      "test_test\n",
      "test mean loss=119880.10107421875\n",
      "epoch 355\n",
      "test_train\n",
      "train mean loss=72887.92459753787\n",
      "test_test\n",
      "test mean loss=120871.33935546875\n",
      "epoch 356\n",
      "test_train\n",
      "train mean loss=72716.52805397728\n",
      "test_test\n",
      "test mean loss=120563.57861328125\n",
      "epoch 357\n",
      "test_train\n",
      "train mean loss=72700.51503314394\n",
      "test_test\n",
      "test mean loss=120872.92919921875\n",
      "epoch 358\n",
      "test_train\n",
      "train mean loss=72473.16074810606\n",
      "test_test\n",
      "test mean loss=120461.30712890625\n",
      "epoch 359\n",
      "test_train\n",
      "train mean loss=73397.72159090909\n",
      "test_test\n",
      "test mean loss=120681.31787109375\n",
      "epoch 360\n",
      "test_train\n",
      "train mean loss=72624.61292613637\n",
      "test_test\n",
      "test mean loss=121310.244140625\n",
      "epoch 361\n",
      "test_train\n",
      "train mean loss=73133.62772253787\n",
      "test_test\n",
      "test mean loss=120278.3779296875\n",
      "epoch 362\n",
      "test_train\n",
      "train mean loss=72577.13979640152\n",
      "test_test\n",
      "test mean loss=120723.39990234375\n",
      "epoch 363\n",
      "test_train\n",
      "train mean loss=72291.68886126894\n",
      "test_test\n",
      "test mean loss=120699.4189453125\n",
      "epoch 364\n",
      "test_train\n",
      "train mean loss=71913.32291666667\n",
      "test_test\n",
      "test mean loss=120918.1650390625\n",
      "epoch 365\n",
      "test_train\n",
      "train mean loss=72748.43880208333\n",
      "test_test\n",
      "test mean loss=121441.552734375\n",
      "epoch 366\n",
      "test_train\n",
      "train mean loss=73292.5546875\n",
      "test_test\n",
      "test mean loss=121589.46337890625\n",
      "epoch 367\n",
      "test_train\n",
      "train mean loss=72535.87263257576\n",
      "test_test\n",
      "test mean loss=122259.58642578125\n",
      "epoch 368\n",
      "test_train\n",
      "train mean loss=72458.41690340909\n",
      "test_test\n",
      "test mean loss=122255.29638671875\n",
      "epoch 369\n",
      "test_train\n",
      "train mean loss=73351.27035984848\n",
      "test_test\n",
      "test mean loss=122919.5263671875\n",
      "epoch 370\n",
      "test_train\n",
      "train mean loss=73089.45466382576\n",
      "test_test\n",
      "test mean loss=122299.921875\n",
      "epoch 371\n",
      "test_train\n",
      "train mean loss=72834.71164772728\n",
      "test_test\n",
      "test mean loss=124017.2041015625\n",
      "epoch 372\n",
      "test_train\n",
      "train mean loss=73528.208984375\n",
      "test_test\n",
      "test mean loss=123287.0068359375\n",
      "epoch 373\n",
      "test_train\n",
      "train mean loss=72261.0634469697\n",
      "test_test\n",
      "test mean loss=123822.50048828125\n",
      "epoch 374\n",
      "test_train\n",
      "train mean loss=73476.87979403409\n",
      "test_test\n",
      "test mean loss=123559.18896484375\n",
      "epoch 375\n",
      "test_train\n",
      "train mean loss=73515.60416666667\n",
      "test_test\n",
      "test mean loss=123745.853515625\n",
      "epoch 376\n",
      "test_train\n",
      "train mean loss=72923.78385416667\n",
      "test_test\n",
      "test mean loss=123365.1220703125\n",
      "epoch 377\n",
      "test_train\n",
      "train mean loss=73284.98768939394\n",
      "test_test\n",
      "test mean loss=122333.7197265625\n",
      "epoch 378\n",
      "test_train\n",
      "train mean loss=74064.17459753787\n",
      "test_test\n",
      "test mean loss=123044.46484375\n",
      "epoch 379\n",
      "test_train\n",
      "train mean loss=72860.42465672348\n",
      "test_test\n",
      "test mean loss=121319.12158203125\n",
      "epoch 380\n",
      "test_train\n",
      "train mean loss=72970.76195549243\n",
      "test_test\n",
      "test mean loss=121723.60791015625\n",
      "epoch 381\n",
      "test_train\n",
      "train mean loss=73197.25899621213\n",
      "test_test\n",
      "test mean loss=122741.94384765625\n",
      "epoch 382\n",
      "test_train\n",
      "train mean loss=74619.33735795454\n",
      "test_test\n",
      "test mean loss=123646.53662109375\n",
      "epoch 383\n",
      "test_train\n",
      "train mean loss=72296.31723484848\n",
      "test_test\n",
      "test mean loss=122822.56640625\n",
      "epoch 384\n",
      "test_train\n",
      "train mean loss=73372.15672348485\n",
      "test_test\n",
      "test mean loss=122212.91162109375\n",
      "epoch 385\n",
      "test_train\n",
      "train mean loss=72452.36274857954\n",
      "test_test\n",
      "test mean loss=122201.35205078125\n",
      "epoch 386\n",
      "test_train\n",
      "train mean loss=72707.88884943182\n",
      "test_test\n",
      "test mean loss=123829.73779296875\n",
      "epoch 387\n",
      "test_train\n",
      "train mean loss=73205.75988399622\n",
      "test_test\n",
      "test mean loss=123749.54931640625\n",
      "epoch 388\n",
      "test_train\n",
      "train mean loss=73027.48839962122\n",
      "test_test\n",
      "test mean loss=123637.03759765625\n",
      "epoch 389\n",
      "test_train\n",
      "train mean loss=73346.49538352272\n",
      "test_test\n",
      "test mean loss=121466.96337890625\n",
      "epoch 390\n",
      "test_train\n",
      "train mean loss=72312.47455018939\n",
      "test_test\n",
      "test mean loss=120775.673828125\n",
      "epoch 391\n",
      "test_train\n",
      "train mean loss=72430.45336174243\n",
      "test_test\n",
      "test mean loss=121906.3125\n",
      "epoch 392\n",
      "test_train\n",
      "train mean loss=72879.05598958333\n",
      "test_test\n",
      "test mean loss=121838.74755859375\n",
      "epoch 393\n",
      "test_train\n",
      "train mean loss=73161.84037642046\n",
      "test_test\n",
      "test mean loss=121356.82958984375\n",
      "epoch 394\n",
      "test_train\n",
      "train mean loss=73113.64133522728\n",
      "test_test\n",
      "test mean loss=121529.5361328125\n",
      "epoch 395\n",
      "test_train\n",
      "train mean loss=72623.86712831439\n",
      "test_test\n",
      "test mean loss=121973.4638671875\n",
      "epoch 396\n",
      "test_train\n",
      "train mean loss=74354.34789299243\n",
      "test_test\n",
      "test mean loss=122292.23779296875\n",
      "epoch 397\n",
      "test_train\n",
      "train mean loss=72894.91577888257\n",
      "test_test\n",
      "test mean loss=122173.62060546875\n",
      "epoch 398\n",
      "test_train\n",
      "train mean loss=72632.23283617424\n",
      "test_test\n",
      "test mean loss=123377.80908203125\n",
      "epoch 399\n",
      "test_train\n",
      "train mean loss=73438.21875\n",
      "test_test\n",
      "test mean loss=123275.3466796875\n",
      "epoch 400\n",
      "test_train\n",
      "train mean loss=72722.25071022728\n",
      "test_test\n",
      "test mean loss=122894.53173828125\n",
      "epoch 401\n",
      "test_train\n",
      "train mean loss=73696.50455729167\n",
      "test_test\n",
      "test mean loss=122243.80419921875\n",
      "epoch 402\n",
      "test_train\n",
      "train mean loss=74076.44004498106\n",
      "test_test\n",
      "test mean loss=122708.20166015625\n",
      "epoch 403\n",
      "test_train\n",
      "train mean loss=73329.76000236743\n",
      "test_test\n",
      "test mean loss=122971.02685546875\n",
      "epoch 404\n",
      "test_train\n",
      "train mean loss=73002.75319602272\n",
      "test_test\n",
      "test mean loss=123030.546875\n",
      "epoch 405\n",
      "test_train\n",
      "train mean loss=74392.66453598485\n",
      "test_test\n",
      "test mean loss=123149.3115234375\n",
      "epoch 406\n",
      "test_train\n",
      "train mean loss=73042.38991477272\n",
      "test_test\n",
      "test mean loss=122750.48876953125\n",
      "epoch 407\n",
      "test_train\n",
      "train mean loss=73241.79225852272\n",
      "test_test\n",
      "test mean loss=122882.755859375\n",
      "epoch 408\n",
      "test_train\n",
      "train mean loss=72658.66453598485\n",
      "test_test\n",
      "test mean loss=122992.33251953125\n",
      "epoch 409\n",
      "test_train\n",
      "train mean loss=73454.90281723485\n",
      "test_test\n",
      "test mean loss=123264.806640625\n",
      "epoch 410\n",
      "test_train\n",
      "train mean loss=73048.73993844698\n",
      "test_test\n",
      "test mean loss=123129.47119140625\n",
      "epoch 411\n",
      "test_train\n",
      "train mean loss=72974.39689867424\n",
      "test_test\n",
      "test mean loss=122919.59033203125\n",
      "epoch 412\n",
      "test_train\n",
      "train mean loss=71532.00710227272\n",
      "test_test\n",
      "test mean loss=123564.97314453125\n",
      "epoch 413\n",
      "test_train\n",
      "train mean loss=72971.65187026515\n",
      "test_test\n",
      "test mean loss=123506.96044921875\n",
      "epoch 414\n",
      "test_train\n",
      "train mean loss=73330.52988873106\n",
      "test_test\n",
      "test mean loss=123839.8740234375\n",
      "epoch 415\n",
      "test_train\n",
      "train mean loss=72980.27710700757\n",
      "test_test\n",
      "test mean loss=123232.6220703125\n",
      "epoch 416\n",
      "test_train\n",
      "train mean loss=72528.05196496213\n",
      "test_test\n",
      "test mean loss=123068.99169921875\n",
      "epoch 417\n",
      "test_train\n",
      "train mean loss=72425.32587594698\n",
      "test_test\n",
      "test mean loss=123366.56884765625\n",
      "epoch 418\n",
      "test_train\n",
      "train mean loss=72865.79296875\n",
      "test_test\n",
      "test mean loss=123542.6826171875\n",
      "epoch 419\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=72174.81723484848\n",
      "test_test\n",
      "test mean loss=123652.689453125\n",
      "epoch 420\n",
      "test_train\n",
      "train mean loss=72201.49976325757\n",
      "test_test\n",
      "test mean loss=123748.13671875\n",
      "epoch 421\n",
      "test_train\n",
      "train mean loss=72703.52331912878\n",
      "test_test\n",
      "test mean loss=124344.87255859375\n",
      "epoch 422\n",
      "test_train\n",
      "train mean loss=71379.90423768939\n",
      "test_test\n",
      "test mean loss=124141.9150390625\n",
      "epoch 423\n",
      "test_train\n",
      "train mean loss=72700.21999289772\n",
      "test_test\n",
      "test mean loss=124270.8837890625\n",
      "epoch 424\n",
      "test_train\n",
      "train mean loss=72096.11049952652\n",
      "test_test\n",
      "test mean loss=124066.46630859375\n",
      "epoch 425\n",
      "test_train\n",
      "train mean loss=72254.76893939394\n",
      "test_test\n",
      "test mean loss=124291.55517578125\n",
      "epoch 426\n",
      "test_train\n",
      "train mean loss=71897.6875\n",
      "test_test\n",
      "test mean loss=124075.447265625\n",
      "epoch 427\n",
      "test_train\n",
      "train mean loss=71584.48307291667\n",
      "test_test\n",
      "test mean loss=123993.8857421875\n",
      "epoch 428\n",
      "test_train\n",
      "train mean loss=72024.83132102272\n",
      "test_test\n",
      "test mean loss=123654.79345703125\n",
      "epoch 429\n",
      "test_train\n",
      "train mean loss=72268.35996685606\n",
      "test_test\n",
      "test mean loss=123186.94384765625\n",
      "epoch 430\n",
      "test_train\n",
      "train mean loss=71813.6220407197\n",
      "test_test\n",
      "test mean loss=123238.68701171875\n",
      "epoch 431\n",
      "test_train\n",
      "train mean loss=70848.77207623106\n",
      "test_test\n",
      "test mean loss=123424.6142578125\n",
      "epoch 432\n",
      "test_train\n",
      "train mean loss=71903.33132102272\n",
      "test_test\n",
      "test mean loss=122716.8740234375\n",
      "epoch 433\n",
      "test_train\n",
      "train mean loss=71670.29237689394\n",
      "test_test\n",
      "test mean loss=123158.69775390625\n",
      "epoch 434\n",
      "test_train\n",
      "train mean loss=71969.38677793561\n",
      "test_test\n",
      "test mean loss=123380.814453125\n",
      "epoch 435\n",
      "test_train\n",
      "train mean loss=72518.00757575757\n",
      "test_test\n",
      "test mean loss=123123.62060546875\n",
      "epoch 436\n",
      "test_train\n",
      "train mean loss=71836.9453125\n",
      "test_test\n",
      "test mean loss=123511.00146484375\n",
      "epoch 437\n",
      "test_train\n",
      "train mean loss=71923.2734375\n",
      "test_test\n",
      "test mean loss=123145.96630859375\n",
      "epoch 438\n",
      "test_train\n",
      "train mean loss=71722.79717092802\n",
      "test_test\n",
      "test mean loss=123871.875\n",
      "epoch 439\n",
      "test_train\n",
      "train mean loss=71666.92140151515\n",
      "test_test\n",
      "test mean loss=123878.38134765625\n",
      "epoch 440\n",
      "test_train\n",
      "train mean loss=72203.47111742424\n",
      "test_test\n",
      "test mean loss=123350.36376953125\n",
      "epoch 441\n",
      "test_train\n",
      "train mean loss=71653.59398674243\n",
      "test_test\n",
      "test mean loss=123944.763671875\n",
      "epoch 442\n",
      "test_train\n",
      "train mean loss=71507.20324337122\n",
      "test_test\n",
      "test mean loss=123746.86865234375\n",
      "epoch 443\n",
      "test_train\n",
      "train mean loss=72170.77521306818\n",
      "test_test\n",
      "test mean loss=123729.29345703125\n",
      "epoch 444\n",
      "test_train\n",
      "train mean loss=72233.90767045454\n",
      "test_test\n",
      "test mean loss=124511.10009765625\n",
      "epoch 445\n",
      "test_train\n",
      "train mean loss=71904.90068655302\n",
      "test_test\n",
      "test mean loss=124018.818359375\n",
      "epoch 446\n",
      "test_train\n",
      "train mean loss=73168.34345407198\n",
      "test_test\n",
      "test mean loss=123908.43896484375\n",
      "epoch 447\n",
      "test_train\n",
      "train mean loss=72315.34730113637\n",
      "test_test\n",
      "test mean loss=124577.36328125\n",
      "epoch 448\n",
      "test_train\n",
      "train mean loss=71434.48851799243\n",
      "test_test\n",
      "test mean loss=124220.1884765625\n",
      "epoch 449\n",
      "test_train\n",
      "train mean loss=71730.03338068182\n",
      "test_test\n",
      "test mean loss=123623.1220703125\n",
      "epoch 450\n",
      "test_train\n",
      "train mean loss=72158.84812973485\n",
      "test_test\n",
      "test mean loss=124046.08544921875\n",
      "epoch 451\n",
      "test_train\n",
      "train mean loss=73051.96081912878\n",
      "test_test\n",
      "test mean loss=123660.5126953125\n",
      "epoch 452\n",
      "test_train\n",
      "train mean loss=71030.0537405303\n",
      "test_test\n",
      "test mean loss=122691.5615234375\n",
      "epoch 453\n",
      "test_train\n",
      "train mean loss=70955.88446969698\n",
      "test_test\n",
      "test mean loss=123221.2861328125\n",
      "epoch 454\n",
      "test_train\n",
      "train mean loss=71783.07173295454\n",
      "test_test\n",
      "test mean loss=123317.7421875\n",
      "epoch 455\n",
      "test_train\n",
      "train mean loss=71451.77651515152\n",
      "test_test\n",
      "test mean loss=123771.62158203125\n",
      "epoch 456\n",
      "test_train\n",
      "train mean loss=71965.44093276515\n",
      "test_test\n",
      "test mean loss=124168.525390625\n",
      "epoch 457\n",
      "test_train\n",
      "train mean loss=71346.18761837122\n",
      "test_test\n",
      "test mean loss=122646.11865234375\n",
      "epoch 458\n",
      "test_train\n",
      "train mean loss=71828.71573153409\n",
      "test_test\n",
      "test mean loss=124096.078125\n",
      "epoch 459\n",
      "test_train\n",
      "train mean loss=72020.43726325757\n",
      "test_test\n",
      "test mean loss=121856.6318359375\n",
      "epoch 460\n",
      "test_train\n",
      "train mean loss=71612.68347537878\n",
      "test_test\n",
      "test mean loss=121458.38330078125\n",
      "epoch 461\n",
      "test_train\n",
      "train mean loss=72313.27355587122\n",
      "test_test\n",
      "test mean loss=121160.74169921875\n",
      "epoch 462\n",
      "test_train\n",
      "train mean loss=72071.60014204546\n",
      "test_test\n",
      "test mean loss=120400.43505859375\n",
      "epoch 463\n",
      "test_train\n",
      "train mean loss=71645.26627604167\n",
      "test_test\n",
      "test mean loss=120594.57080078125\n",
      "epoch 464\n",
      "test_train\n",
      "train mean loss=71665.74786931818\n",
      "test_test\n",
      "test mean loss=120143.6337890625\n",
      "epoch 465\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 8.00 GiB total capacity; 5.03 GiB already allocated; 0 bytes free; 5.05 GiB reserved in total by PyTorch) (malloc at ..\\c10\\cuda\\CUDACachingAllocator.cpp:289)\n(no backtrace available)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-7dbf747e722a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpose_o\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;31m#crit_outputs, crit_labels)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[1;31m#print(\"loss: \", loss)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[0;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[1;33m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    197\u001b[0m         \"\"\"\n\u001b[1;32m--> 198\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[0;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 100\u001b[1;33m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[0;32m    101\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    102\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 12.00 MiB (GPU 0; 8.00 GiB total capacity; 5.03 GiB already allocated; 0 bytes free; 5.05 GiB reserved in total by PyTorch) (malloc at ..\\c10\\cuda\\CUDACachingAllocator.cpp:289)\n(no backtrace available)"
     ]
    }
   ],
   "source": [
    "EPOCH = 500\n",
    "net.train()\n",
    "for epoch in range(EPOCH):#EPOCH):\n",
    "    print('epoch', epoch+1)    #epoch数の出力\n",
    "    num = 0\n",
    "    for (inputs, labels, input_img, input_mask, label_mask, img_mask) in trainloader:\n",
    "    #for batch in trainloader:\n",
    "        #num += 1\n",
    "        #print(num)\n",
    "        inputs, labels, input_img, input_mask, label_mask, img_mask = \\\n",
    "        inputs.to(device), labels.to(device), input_img.to(device),\\\n",
    "        input_mask.to(device), label_mask.to(device), img_mask.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        handloc, pose_h, posedesc = net(input_img, inputs, input_mask, img_mask)\n",
    "        #print(\"inputs\", inputs[0])\n",
    "        #print(\"labels\", labels[0])\n",
    "        #print(\"handloc\", handloc[0])\n",
    "        #print(\"pose_h\", pose_h[0])\n",
    "        #print(\"posedesc\", posedesc[0])\n",
    "        #手首位置基準座標→物体位置基準座標\n",
    "        xd = torch.zeros_like(pose_h).to(device)\n",
    "        yd = torch.zeros_like(pose_h).to(device)\n",
    "        zd = torch.zeros_like(pose_h).to(device)\n",
    "        for bsize in range(pose_h.size()[0]):\n",
    "            xval = handloc[bsize][0].item()\n",
    "            yval = handloc[bsize][1].item()\n",
    "            zval = handloc[bsize][2].item()\n",
    "            for i in range(int(pose_h.size()[1] / 3)):\n",
    "                xd[bsize][i*3+0] = xval\n",
    "                yd[bsize][i*3+1] = yval\n",
    "                zd[bsize][i*3+2] = zval\n",
    "        pose_o = (pose_h + xd + yd + zd).to(device)\n",
    "        #print(\"pose_o\", pose_o[0])\n",
    "        loss = criterion(pose_o, labels, label_mask)#crit_outputs, crit_labels)\n",
    "        #print(\"loss: \", loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    sum_loss = 0.0          #lossの合計\n",
    "    sum_total = 0           #dataの数の合計\n",
    "\n",
    "    print(\"test_train\")\n",
    "    ttrain = 0\n",
    "    #train dataを使ってテストをする(パラメータ更新がないようになっている)\n",
    "    for (inputs, labels, input_img, input_mask, label_mask, img_mask) in trainloader:\n",
    "        ttrain += 1\n",
    "        inputs, labels, input_img, input_mask, label_mask, img_mask = \\\n",
    "        inputs.to(device), labels.to(device), input_img.to(device),\\\n",
    "        input_mask.to(device), label_mask.to(device), img_mask.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        handloc, pose_h, posedesc = net(input_img, inputs, input_mask, img_mask)\n",
    "        #手首位置基準座標→物体位置基準座標\n",
    "        xd = torch.zeros_like(pose_h).to(device)\n",
    "        yd = torch.zeros_like(pose_h).to(device)\n",
    "        zd = torch.zeros_like(pose_h).to(device)\n",
    "        for bsize in range(pose_h.size()[0]):\n",
    "            xval = handloc[bsize][0].item()\n",
    "            yval = handloc[bsize][1].item()\n",
    "            zval = handloc[bsize][2].item()\n",
    "            for i in range(int(pose_h.size()[1] / 3)):\n",
    "                xd[bsize][i*3+0] = xval\n",
    "                yd[bsize][i*3+1] = yval\n",
    "                zd[bsize][i*3+2] = zval\n",
    "        pose_o = (pose_h + xd + yd + zd).to(device)\n",
    "        if ttrain == int(train_size / BATCH_SIZE):\n",
    "            train_input_value.append(inputs)\n",
    "            train_output_value.append(pose_o)\n",
    "            train_desc_value.append(posedesc)\n",
    "            train_handloc_value.append(handloc)\n",
    "        loss = criterion(pose_o*100, labels*100, label_mask)\n",
    "        sum_loss += loss.item()                            #lossを足していく\n",
    "        sum_total += labels.size(0)                        #labelの数を足していくことでデータの総和を取る\n",
    "    #print(\"len train dataset: \", len(trainloader.dataset))\n",
    "    train_mean_loss = sum_loss*BATCH_SIZE/len(trainloader.dataset)\n",
    "    print(\"train mean loss={}\".format(train_mean_loss))  #loss出力\n",
    "    train_loss_value.append(train_mean_loss)  #traindataのlossをグラフ描画のためにlistに保持\n",
    "    if train_mean_loss > max_train_loss_value:\n",
    "        max_train_loss_value = train_mean_loss\n",
    "\n",
    "    sum_loss = 0.0\n",
    "    sum_total = 0\n",
    "\n",
    "    print(\"test_test\")\n",
    "    ttest = 0\n",
    "    #test dataを使ってテストをする\n",
    "    for (inputs, labels, input_img, input_mask, label_mask, img_mask) in testloader:\n",
    "        ttest += 1\n",
    "        inputs, labels, input_img, input_mask, label_mask, img_mask = \\\n",
    "        inputs.to(device), labels.to(device), input_img.to(device),\\\n",
    "        input_mask.to(device), label_mask.to(device), img_mask.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        handloc, pose_h, posedesc = net(input_img, inputs, input_mask, img_mask)\n",
    "        #手首位置基準座標→物体位置基準座標\n",
    "        xd = torch.zeros_like(pose_h).to(device)\n",
    "        yd = torch.zeros_like(pose_h).to(device)\n",
    "        zd = torch.zeros_like(pose_h).to(device)\n",
    "        for bsize in range(pose_h.size()[0]):\n",
    "            xval = handloc[bsize][0].item()\n",
    "            yval = handloc[bsize][1].item()\n",
    "            zval = handloc[bsize][2].item()\n",
    "            for i in range(int(pose_h.size()[1] / 3)):\n",
    "                xd[bsize][i*3+0] = xval\n",
    "                yd[bsize][i*3+1] = yval\n",
    "                zd[bsize][i*3+2] = zval\n",
    "        pose_o = (pose_h + xd + yd + zd).to(device)\n",
    "        if ttest == int(test_size / BATCH_SIZE):\n",
    "            test_input_value.append(inputs)\n",
    "            test_output_value.append(pose_o)\n",
    "            test_desc_value.append(posedesc)\n",
    "            test_handloc_value.append(handloc)\n",
    "        loss = criterion(pose_o*100, labels*100, label_mask)\n",
    "        sum_loss += loss.item()\n",
    "        sum_total += labels.size(0)\n",
    "    #print(\"len test dataset: \", len(testloader.dataset))\n",
    "    test_mean_loss = sum_loss*BATCH_SIZE/len(testloader.dataset)\n",
    "    print(\"test mean loss={}\".format(test_mean_loss))\n",
    "    test_loss_value.append(test_mean_loss)\n",
    "    if test_mean_loss > max_test_loss_value:\n",
    "        max_test_loss_value = test_mean_loss\n",
    "    if (min_test_loss_value != None and test_mean_loss < min_test_loss_value) or min_test_loss_value == None:\n",
    "          min_test_loss_value = test_mean_loss\n",
    "          torch.save(net.state_dict(), PATH + \"\\\\model_epoch\" + str(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for k, p in zip(keys, net.parameters()):\n",
    "#    print(k, \"\\n\", p, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 504x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,7))      #グラフ描画用\n",
    "ylim = max(max_train_loss_value, max_test_loss_value)\n",
    "\n",
    "baseEPOCH = 100\n",
    "num_epoch = 1\n",
    "#act_num_epoch = baseEPOCH * num_epoch\n",
    "act_num_epoch = 464\n",
    "\n",
    "#以下グラフ描画\n",
    "plt.plot(range(act_num_epoch), train_loss_value)\n",
    "plt.plot(range(act_num_epoch), test_loss_value, c='#00ff00')\n",
    "plt.xlim(0, act_num_epoch)\n",
    "plt.ylim(0, ylim)\n",
    "plt.xlabel('EPOCH')\n",
    "plt.ylabel('LOSS(mm^2)')\n",
    "plt.legend(['train loss', 'test loss'])\n",
    "plt.title('loocation and pose LOSS')\n",
    "plt.savefig(PATH + \"\\\\loss_image_\" + str(act_num_epoch) + \".png\")\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "#結果画像出力\n",
    "target_epoch = 463\n",
    "\n",
    "HAND_PNT_NUM = 21\n",
    "\n",
    "#fig = plt.figure(figsize=(6,6))\n",
    "fig = plt.figure()\n",
    "for i in range(len(train_input_value[target_epoch])):\n",
    "    input_x = []\n",
    "    input_y = []\n",
    "    input_z = []\n",
    "    mid = []\n",
    "    output_x = []\n",
    "    output_y = []\n",
    "    output_z = []\n",
    "    connect_x = []\n",
    "    connect_y = []\n",
    "    connect_z = []\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    for j in range(int(len(train_input_value[target_epoch][0])/3)):\n",
    "        input_x.append(train_input_value[target_epoch][i][j*3+0].item())\n",
    "        input_y.append(-1*train_input_value[target_epoch][i][j*3+1].item())\n",
    "        input_z.append(train_input_value[target_epoch][i][j*3+2].item())\n",
    "        output_x.append(train_output_value[target_epoch][i][j*3+0].item())\n",
    "        output_y.append(-1*train_output_value[target_epoch][i][j*3+1].item())\n",
    "        output_z.append(train_output_value[target_epoch][i][j*3+2].item())\n",
    "    x_max = max([max(input_x), max(output_x)], default = -10000)\n",
    "    x_min = min([min(input_x), min(output_x)], default = 10000)\n",
    "    y_max = max([max(input_y), max(output_y)], default = -10000)\n",
    "    y_min = min([min(input_y), min(output_y)], default = 10000)\n",
    "    z_max = max([max(input_z), max(output_z)], default = -10000)\n",
    "    z_min = min([min(input_z), min(output_z)], default = 10000)\n",
    "    \n",
    "    #print(x_min, x_max, y_min, y_max, z_min, z_max, \"(fixed: x_min, x_max, y_min, y_max, z_min, z_max)\")\n",
    "    \n",
    "    #点が描画範囲内かどうか\n",
    "    isInputPointsIn = [False] * HAND_PNT_NUM\n",
    "    isOutputPointsIn = [False] * HAND_PNT_NUM\n",
    "    #print(isPointsIn)\n",
    "    \n",
    "    for p in range(HAND_PNT_NUM):\n",
    "        if x_min <= input_x[p] <= x_max and y_min <= input_y[p] <= y_max and z_min <= input_z[p] <= z_max:\n",
    "            isInputPointsIn[p] = True\n",
    "        if x_min <= output_x[p] <= x_max and y_min <= output_y[p] <= y_max and z_min <= output_z[p] <= z_max:\n",
    "            isOutputPointsIn[p] = True\n",
    "    \n",
    "    #各点をプロット\n",
    "    ax.scatter(input_x[0], input_y[0], zs=input_z[0], zdir='y', s=10, c='#e53528', marker = \".\")\n",
    "    ax.scatter(input_x[1], input_y[1], zs=input_z[1], zdir='y', s=10, c='#e77340', marker = \".\")\n",
    "    ax.scatter(input_x[2], input_y[2], zs=input_z[2], zdir='y', s=10, c='#eb8e25', marker = \".\")\n",
    "    ax.scatter(input_x[3], input_y[3], zs=input_z[3], zdir='y', s=10, c='#d7a10e', marker = \".\")\n",
    "    ax.scatter(input_x[4], input_y[4], zs=input_z[4], zdir='y', s=10, c='#d9c812', marker = \".\")\n",
    "    ax.scatter(input_x[5], input_y[5], zs=input_z[5], zdir='y', s=10, c='#a7cf21', marker = \".\")\n",
    "    ax.scatter(input_x[6], input_y[6], zs=input_z[6], zdir='y', s=10, c='#7fe545', marker = \".\")\n",
    "    ax.scatter(input_x[7], input_y[7], zs=input_z[7], zdir='y', s=10, c='#53d62d', marker = \".\")\n",
    "    ax.scatter(input_x[8], input_y[8], zs=input_z[8], zdir='y', s=10, c='#4abc2f', marker = \".\")\n",
    "    ax.scatter(input_x[9], input_y[9], zs=input_z[9], zdir='y', s=10, c='#52d686', marker = \".\")\n",
    "    ax.scatter(input_x[10], input_y[10], zs=input_z[10], zdir='y', s=10, c='#52dfbe', marker = \".\")\n",
    "    ax.scatter(input_x[11], input_y[11], zs=input_z[11], zdir='y', s=10, c='#52b9c5', marker = \".\")\n",
    "    ax.scatter(input_x[12], input_y[12], zs=input_z[12], zdir='y', s=10, c='#508ab7', marker = \".\")\n",
    "    ax.scatter(input_x[13], input_y[13], zs=input_z[13], zdir='y', s=10, c='#556fd0', marker = \".\")\n",
    "    ax.scatter(input_x[14], input_y[14], zs=input_z[14], zdir='y', s=10, c='#5245d5', marker = \".\")\n",
    "    ax.scatter(input_x[15], input_y[15], zs=input_z[15], zdir='y', s=10, c='#7e2fba', marker = \".\")\n",
    "    ax.scatter(input_x[16], input_y[16], zs=input_z[16], zdir='y', s=10, c='#bc64fb', marker = \".\")\n",
    "    ax.scatter(input_x[17], input_y[17], zs=input_z[17], zdir='y', s=10, c='#da53e8', marker = \".\")\n",
    "    ax.scatter(input_x[18], input_y[18], zs=input_z[18], zdir='y', s=10, c='#eb45bc', marker = \".\")\n",
    "    ax.scatter(input_x[19], input_y[19], zs=input_z[19], zdir='y', s=10, c='#ec3c89', marker = \".\")\n",
    "    ax.scatter(input_x[20], input_y[20], zs=input_z[20], zdir='y', s=10, c='#ff6691', marker = \".\")\n",
    "    \n",
    "    #点同士を結ぶ\n",
    "    if isInputPointsIn[0] and isInputPointsIn[1]:\n",
    "        ax.plot([input_x[0],input_x[1]], [input_y[0],input_y[1]], [input_z[0],input_z[1]], zdir='y', c='#cc0000')\n",
    "    if isInputPointsIn[1] and isInputPointsIn[2]:\n",
    "        ax.plot([input_x[1],input_x[2]], [input_y[1],input_y[2]], [input_z[1],input_z[2]], zdir='y', c='#b30000')\n",
    "    if isInputPointsIn[2] and isInputPointsIn[3]:\n",
    "        ax.plot([input_x[2],input_x[3]], [input_y[2],input_y[3]], [input_z[2],input_z[3]], zdir='y', c='#e60000')\n",
    "    if isInputPointsIn[3] and isInputPointsIn[4]:\n",
    "        ax.plot([input_x[3],input_x[4]], [input_y[3],input_y[4]], [input_z[3],input_z[4]], zdir='y', c='#ff0000')\n",
    "    if isInputPointsIn[0] and isInputPointsIn[5]:\n",
    "        ax.plot([input_x[0],input_x[5]], [input_y[0],input_y[5]], [input_z[0],input_z[5]], zdir='y', c='#a3cc00')\n",
    "    if isInputPointsIn[5] and isInputPointsIn[6]:\n",
    "        ax.plot([input_x[5],input_x[6]], [input_y[5],input_y[6]], [input_z[5],input_z[6]], zdir='y', c='#8fb300')\n",
    "    if isInputPointsIn[6] and isInputPointsIn[7]:        \n",
    "        ax.plot([input_x[6],input_x[7]], [input_y[6],input_y[7]], [input_z[6],input_z[7]], zdir='y', c='#b8e600')\n",
    "    if isInputPointsIn[7] and isInputPointsIn[8]:\n",
    "        ax.plot([input_x[7],input_x[8]], [input_y[7],input_y[8]], [input_z[7],input_z[8]], zdir='y', c='#ccff00')\n",
    "    if isInputPointsIn[0] and isInputPointsIn[9]:\n",
    "        ax.plot([input_x[0],input_x[9]], [input_y[0],input_y[9]], [input_z[0],input_z[9]], zdir='y', c='#00cc52')\n",
    "    if isInputPointsIn[9] and isInputPointsIn[10]:\n",
    "        ax.plot([input_x[9],input_x[10]], [input_y[9],input_y[10]], [input_z[9],input_z[10]], zdir='y', c='#00b347')\n",
    "    if isInputPointsIn[10] and isInputPointsIn[11]:\n",
    "        ax.plot([input_x[10],input_x[11]], [input_y[10],input_y[11]], [input_z[10],input_z[11]], zdir='y', c='#00e65c')\n",
    "    if isInputPointsIn[11] and isInputPointsIn[12]:\n",
    "        ax.plot([input_x[11],input_x[12]], [input_y[11],input_y[12]], [input_z[11],input_z[12]], zdir='y', c='#00ff66')\n",
    "    if isInputPointsIn[0] and isInputPointsIn[13]:\n",
    "        ax.plot([input_x[0],input_x[13]], [input_y[0],input_y[13]], [input_z[0],input_z[13]], zdir='y', c='#0052cc')\n",
    "    if isInputPointsIn[13] and isInputPointsIn[14]:\n",
    "        ax.plot([input_x[13],input_x[14]], [input_y[13],input_y[14]], [input_z[13],input_z[14]], zdir='y', c='#0047b3')\n",
    "    if isInputPointsIn[14] and isInputPointsIn[15]:\n",
    "        ax.plot([input_x[14],input_x[15]], [input_y[14],input_y[15]], [input_z[14],input_z[15]], zdir='y', c='#005ce6')\n",
    "    if isInputPointsIn[15] and isInputPointsIn[16]:\n",
    "        ax.plot([input_x[15],input_x[16]], [input_y[15],input_y[16]], [input_z[15],input_z[16]], zdir='y', c='#0066ff')\n",
    "    if isInputPointsIn[0] and isInputPointsIn[17]:\n",
    "        ax.plot([input_x[0],input_x[17]], [input_y[0],input_y[17]], [input_z[0],input_z[17]], zdir='y', c='#a300cc')\n",
    "    if isInputPointsIn[17] and isInputPointsIn[18]:\n",
    "        ax.plot([input_x[17],input_x[18]], [input_y[17],input_y[18]], [input_z[17],input_z[18]], zdir='y', c='#8f00b3')\n",
    "    if isInputPointsIn[18] and isInputPointsIn[19]:\n",
    "        ax.plot([input_x[18],input_x[19]], [input_y[18],input_y[19]], [input_z[18],input_z[19]], zdir='y', c='#b800e6')\n",
    "    if isInputPointsIn[19] and isInputPointsIn[20]:\n",
    "        ax.plot([input_x[19],input_x[20]], [input_y[19],input_y[20]], [input_z[19],input_z[20]], zdir='y', c='#cc00ff')\n",
    "    \n",
    "    ##stradrs = str(train_adrs[target_epoch][i].item()) #202011221813290002\n",
    "    ##d_adrs = \"dataset_\" + stradrs[4:8] + \"_\" + stradrs[8:14] + \"_\" + stradrs[14:]\n",
    "    ##ax.set_title('input(train data, ' + str(target_epoch+1) + 'th epoch)\\n' + d_adrs)\n",
    "    ax.set_title('input(train data, ' + str(target_epoch+1) + 'th epoch)\\n' + str(i))\n",
    "    ax.set_xlim([x_min, x_max])\n",
    "    ax.set_ylim([z_min, z_max])\n",
    "    ax.set_zlim([y_min, y_max])\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('z')\n",
    "    ax.set_zlabel('y')\n",
    "    #plt.subplots_adjust(left=0.04, right=0.80, bottom=0.04, top=0.80)\n",
    "    #ax.legend(loc='upper right')\n",
    "    fig.savefig(PATH + \"\\\\outputs\\\\Input_train_\" + str(target_epoch) + \"th_epoch_\" + str(i) + \".png\", dpi = 300, transparent = False, bbox_inches = 'tight', pad_inches = 0)\n",
    "    fig.clf()\n",
    "    \n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    #各点をプロット\n",
    "    ax.scatter(output_x[0], output_y[0], zs=output_z[0], zdir='y', s=10, c='#e53528', marker = \".\")\n",
    "    ax.scatter(output_x[1], output_y[1], zs=output_z[1], zdir='y', s=10, c='#e77340', marker = \".\")\n",
    "    ax.scatter(output_x[2], output_y[2], zs=output_z[2], zdir='y', s=10, c='#eb8e25', marker = \".\")\n",
    "    ax.scatter(output_x[3], output_y[3], zs=output_z[3], zdir='y', s=10, c='#d7a10e', marker = \".\")\n",
    "    ax.scatter(output_x[4], output_y[4], zs=output_z[4], zdir='y', s=10, c='#d9c812', marker = \".\")\n",
    "    ax.scatter(output_x[5], output_y[5], zs=output_z[5], zdir='y', s=10, c='#a7cf21', marker = \".\")\n",
    "    ax.scatter(output_x[6], output_y[6], zs=output_z[6], zdir='y', s=10, c='#7fe545', marker = \".\")\n",
    "    ax.scatter(output_x[7], output_y[7], zs=output_z[7], zdir='y', s=10, c='#53d62d', marker = \".\")\n",
    "    ax.scatter(output_x[8], output_y[8], zs=output_z[8], zdir='y', s=10, c='#4abc2f', marker = \".\")\n",
    "    ax.scatter(output_x[9], output_y[9], zs=output_z[9], zdir='y', s=10, c='#52d686', marker = \".\")\n",
    "    ax.scatter(output_x[10], output_y[10], zs=output_z[10], zdir='y', s=10, c='#52dfbe', marker = \".\")\n",
    "    ax.scatter(output_x[11], output_y[11], zs=output_z[11], zdir='y', s=10, c='#52b9c5', marker = \".\")\n",
    "    ax.scatter(output_x[12], output_y[12], zs=output_z[12], zdir='y', s=10, c='#508ab7', marker = \".\")\n",
    "    ax.scatter(output_x[13], output_y[13], zs=output_z[13], zdir='y', s=10, c='#556fd0', marker = \".\")\n",
    "    ax.scatter(output_x[14], output_y[14], zs=output_z[14], zdir='y', s=10, c='#5245d5', marker = \".\")\n",
    "    ax.scatter(output_x[15], output_y[15], zs=output_z[15], zdir='y', s=10, c='#7e2fba', marker = \".\")\n",
    "    ax.scatter(output_x[16], output_y[16], zs=output_z[16], zdir='y', s=10, c='#bc64fb', marker = \".\")\n",
    "    ax.scatter(output_x[17], output_y[17], zs=output_z[17], zdir='y', s=10, c='#da53e8', marker = \".\")\n",
    "    ax.scatter(output_x[18], output_y[18], zs=output_z[18], zdir='y', s=10, c='#eb45bc', marker = \".\")\n",
    "    ax.scatter(output_x[19], output_y[19], zs=output_z[19], zdir='y', s=10, c='#ec3c89', marker = \".\")\n",
    "    ax.scatter(output_x[20], output_y[20], zs=output_z[20], zdir='y', s=10, c='#ff6691', marker = \".\")\n",
    "    \n",
    "    #点同士を結ぶ\n",
    "    if isOutputPointsIn[0] and isOutputPointsIn[1]:\n",
    "        ax.plot([output_x[0],output_x[1]], [output_y[0],output_y[1]], [output_z[0],output_z[1]], zdir='y', c='#cc0000')\n",
    "    if isOutputPointsIn[1] and isOutputPointsIn[2]:\n",
    "        ax.plot([output_x[1],output_x[2]], [output_y[1],output_y[2]], [output_z[1],output_z[2]], zdir='y', c='#b30000')\n",
    "    if isOutputPointsIn[2] and isOutputPointsIn[3]:\n",
    "        ax.plot([output_x[2],output_x[3]], [output_y[2],output_y[3]], [output_z[2],output_z[3]], zdir='y', c='#e60000')\n",
    "    if isOutputPointsIn[3] and isOutputPointsIn[4]:\n",
    "        ax.plot([output_x[3],output_x[4]], [output_y[3],output_y[4]], [output_z[3],output_z[4]], zdir='y', c='#ff0000')\n",
    "    if isOutputPointsIn[0] and isOutputPointsIn[5]:\n",
    "        ax.plot([output_x[0],output_x[5]], [output_y[0],output_y[5]], [output_z[0],output_z[5]], zdir='y', c='#a3cc00')\n",
    "    if isOutputPointsIn[5] and isOutputPointsIn[6]:\n",
    "        ax.plot([output_x[5],output_x[6]], [output_y[5],output_y[6]], [output_z[5],output_z[6]], zdir='y', c='#8fb300')\n",
    "    if isOutputPointsIn[6] and isOutputPointsIn[7]:        \n",
    "        ax.plot([output_x[6],output_x[7]], [output_y[6],output_y[7]], [output_z[6],output_z[7]], zdir='y', c='#b8e600')\n",
    "    if isOutputPointsIn[7] and isOutputPointsIn[8]:\n",
    "        ax.plot([output_x[7],output_x[8]], [output_y[7],output_y[8]], [output_z[7],output_z[8]], zdir='y', c='#ccff00')\n",
    "    if isOutputPointsIn[0] and isOutputPointsIn[9]:\n",
    "        ax.plot([output_x[0],output_x[9]], [output_y[0],output_y[9]], [output_z[0],output_z[9]], zdir='y', c='#00cc52')\n",
    "    if isOutputPointsIn[9] and isOutputPointsIn[10]:\n",
    "        ax.plot([output_x[9],output_x[10]], [output_y[9],output_y[10]], [output_z[9],output_z[10]], zdir='y', c='#00b347')\n",
    "    if isOutputPointsIn[10] and isOutputPointsIn[11]:\n",
    "        ax.plot([output_x[10],output_x[11]], [output_y[10],output_y[11]], [output_z[10],output_z[11]], zdir='y', c='#00e65c')\n",
    "    if isOutputPointsIn[11] and isOutputPointsIn[12]:\n",
    "        ax.plot([output_x[11],output_x[12]], [output_y[11],output_y[12]], [output_z[11],output_z[12]], zdir='y', c='#00ff66')\n",
    "    if isOutputPointsIn[0] and isOutputPointsIn[13]:\n",
    "        ax.plot([output_x[0],output_x[13]], [output_y[0],output_y[13]], [output_z[0],output_z[13]], zdir='y', c='#0052cc')\n",
    "    if isOutputPointsIn[13] and isOutputPointsIn[14]:\n",
    "        ax.plot([output_x[13],output_x[14]], [output_y[13],output_y[14]], [output_z[13],output_z[14]], zdir='y', c='#0047b3')\n",
    "    if isOutputPointsIn[14] and isOutputPointsIn[15]:\n",
    "        ax.plot([output_x[14],output_x[15]], [output_y[14],output_y[15]], [output_z[14],output_z[15]], zdir='y', c='#005ce6')\n",
    "    if isOutputPointsIn[15] and isOutputPointsIn[16]:\n",
    "        ax.plot([output_x[15],output_x[16]], [output_y[15],output_y[16]], [output_z[15],output_z[16]], zdir='y', c='#0066ff')\n",
    "    if isOutputPointsIn[0] and isOutputPointsIn[17]:\n",
    "        ax.plot([output_x[0],output_x[17]], [output_y[0],output_y[17]], [output_z[0],output_z[17]], zdir='y', c='#a300cc')\n",
    "    if isOutputPointsIn[17] and isOutputPointsIn[18]:\n",
    "        ax.plot([output_x[17],output_x[18]], [output_y[17],output_y[18]], [output_z[17],output_z[18]], zdir='y', c='#8f00b3')\n",
    "    if isOutputPointsIn[18] and isOutputPointsIn[19]:\n",
    "        ax.plot([output_x[18],output_x[19]], [output_y[18],output_y[19]], [output_z[18],output_z[19]], zdir='y', c='#b800e6')\n",
    "    if isOutputPointsIn[19] and isOutputPointsIn[20]:\n",
    "        ax.plot([output_x[19],output_x[20]], [output_y[19],output_y[20]], [output_z[19],output_z[20]], zdir='y', c='#cc00ff')\n",
    "    #ax.scatter(input_x, input_y, c='red', label = 'input')\n",
    "    #ax.scatter(output_x, output_y, c='blue', label = 'output')\n",
    "    \n",
    "    #3stradrs = str(train_adrs[target_epoch][i].item()) #202011221813290002\n",
    "    ##d_adrs = \"dataset_\" + stradrs[4:8] + \"_\" + stradrs[8:14] + \"_\" + stradrs[14:]\n",
    "    ##ax.set_title('output(train data, ' + str(target_epoch+1) + 'th epoch)\\n' + d_adrs)\n",
    "    ax.set_title('output(train data, ' + str(target_epoch+1) + 'th epoch)\\n' + str(i))\n",
    "    ax.set_xlim([x_min, x_max])\n",
    "    ax.set_ylim([z_min, z_max])\n",
    "    ax.set_zlim([y_min, y_max])\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('z')\n",
    "    ax.set_zlabel('y')\n",
    "    #plt.subplots_adjust(left=0.04, right=0.80, bottom=0.04, top=0.80)\n",
    "    #ax.legend(loc='upper right')\n",
    "    fig.savefig(PATH + \"\\\\outputs\\\\Output_train_\" + str(target_epoch) + \"th_epoch_\" + str(i) + \".png\", dpi = 300,transparent = False, bbox_inches = 'tight', pad_inches = 0)\n",
    "    fig.clf()\n",
    "for i in range(len(test_input_value[target_epoch])):\n",
    "    input_x = []\n",
    "    input_y = []\n",
    "    input_z = []\n",
    "    mid = []\n",
    "    output_x = []\n",
    "    output_y = []\n",
    "    output_z = []\n",
    "    connect_x = []\n",
    "    connect_y = []\n",
    "    connect_z = []\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    for j in range(int(len(test_input_value[target_epoch][0])/3)):\n",
    "        input_x.append(test_input_value[target_epoch][i][j*3+0].item())\n",
    "        input_y.append(-1*test_input_value[target_epoch][i][j*3+1].item())\n",
    "        input_z.append(test_input_value[target_epoch][i][j*3+2].item())\n",
    "        output_x.append(test_output_value[target_epoch][i][j*3+0].item())\n",
    "        output_y.append(-1*test_output_value[target_epoch][i][j*3+1].item())\n",
    "        output_z.append(test_output_value[target_epoch][i][j*3+2].item())\n",
    "    x_max = max([max(input_x), max(output_x)], default = -10000)\n",
    "    x_min = min([min(input_x), min(output_x)], default = 10000)\n",
    "    y_max = max([max(input_y), max(output_y)], default = -10000)\n",
    "    y_min = min([min(input_y), min(output_y)], default = 10000)\n",
    "    z_max = max([max(input_z), max(output_z)], default = -10000)\n",
    "    z_min = min([min(input_z), min(output_z)], default = 10000)\n",
    "    \n",
    "    #print(x_min, x_max, y_min, y_max, z_min, z_max, \"(fixed: x_min, x_max, y_min, y_max, z_min, z_max)\")\n",
    "    \n",
    "    #点が描画範囲内かどうか\n",
    "    isInputPointsIn = [False] * HAND_PNT_NUM\n",
    "    isOutputPointsIn = [False] * HAND_PNT_NUM\n",
    "    #print(isPointsIn)\n",
    "    \n",
    "    for p in range(HAND_PNT_NUM):\n",
    "        if x_min <= input_x[p] <= x_max and y_min <= input_y[p] <= y_max and z_min <= input_z[p] <= z_max:\n",
    "            isInputPointsIn[p] = True\n",
    "        if x_min <= output_x[p] <= x_max and y_min <= output_y[p] <= y_max and z_min <= output_z[p] <= z_max:\n",
    "            isOutputPointsIn[p] = True\n",
    "    \n",
    "    #各点をプロット\n",
    "    ax.scatter(input_x[0], input_y[0], zs=input_z[0], zdir='y', s=10, c='#e53528', marker = \".\")\n",
    "    ax.scatter(input_x[1], input_y[1], zs=input_z[1], zdir='y', s=10, c='#e77340', marker = \".\")\n",
    "    ax.scatter(input_x[2], input_y[2], zs=input_z[2], zdir='y', s=10, c='#eb8e25', marker = \".\")\n",
    "    ax.scatter(input_x[3], input_y[3], zs=input_z[3], zdir='y', s=10, c='#d7a10e', marker = \".\")\n",
    "    ax.scatter(input_x[4], input_y[4], zs=input_z[4], zdir='y', s=10, c='#d9c812', marker = \".\")\n",
    "    ax.scatter(input_x[5], input_y[5], zs=input_z[5], zdir='y', s=10, c='#a7cf21', marker = \".\")\n",
    "    ax.scatter(input_x[6], input_y[6], zs=input_z[6], zdir='y', s=10, c='#7fe545', marker = \".\")\n",
    "    ax.scatter(input_x[7], input_y[7], zs=input_z[7], zdir='y', s=10, c='#53d62d', marker = \".\")\n",
    "    ax.scatter(input_x[8], input_y[8], zs=input_z[8], zdir='y', s=10, c='#4abc2f', marker = \".\")\n",
    "    ax.scatter(input_x[9], input_y[9], zs=input_z[9], zdir='y', s=10, c='#52d686', marker = \".\")\n",
    "    ax.scatter(input_x[10], input_y[10], zs=input_z[10], zdir='y', s=10, c='#52dfbe', marker = \".\")\n",
    "    ax.scatter(input_x[11], input_y[11], zs=input_z[11], zdir='y', s=10, c='#52b9c5', marker = \".\")\n",
    "    ax.scatter(input_x[12], input_y[12], zs=input_z[12], zdir='y', s=10, c='#508ab7', marker = \".\")\n",
    "    ax.scatter(input_x[13], input_y[13], zs=input_z[13], zdir='y', s=10, c='#556fd0', marker = \".\")\n",
    "    ax.scatter(input_x[14], input_y[14], zs=input_z[14], zdir='y', s=10, c='#5245d5', marker = \".\")\n",
    "    ax.scatter(input_x[15], input_y[15], zs=input_z[15], zdir='y', s=10, c='#7e2fba', marker = \".\")\n",
    "    ax.scatter(input_x[16], input_y[16], zs=input_z[16], zdir='y', s=10, c='#bc64fb', marker = \".\")\n",
    "    ax.scatter(input_x[17], input_y[17], zs=input_z[17], zdir='y', s=10, c='#da53e8', marker = \".\")\n",
    "    ax.scatter(input_x[18], input_y[18], zs=input_z[18], zdir='y', s=10, c='#eb45bc', marker = \".\")\n",
    "    ax.scatter(input_x[19], input_y[19], zs=input_z[19], zdir='y', s=10, c='#ec3c89', marker = \".\")\n",
    "    ax.scatter(input_x[20], input_y[20], zs=input_z[20], zdir='y', s=10, c='#ff6691', marker = \".\")\n",
    "    \n",
    "    #点同士を結ぶ\n",
    "    if isInputPointsIn[0] and isInputPointsIn[1]:\n",
    "        ax.plot([input_x[0],input_x[1]], [input_y[0],input_y[1]], [input_z[0],input_z[1]], zdir='y', c='#cc0000')\n",
    "    if isInputPointsIn[1] and isInputPointsIn[2]:\n",
    "        ax.plot([input_x[1],input_x[2]], [input_y[1],input_y[2]], [input_z[1],input_z[2]], zdir='y', c='#b30000')\n",
    "    if isInputPointsIn[2] and isInputPointsIn[3]:\n",
    "        ax.plot([input_x[2],input_x[3]], [input_y[2],input_y[3]], [input_z[2],input_z[3]], zdir='y', c='#e60000')\n",
    "    if isInputPointsIn[3] and isInputPointsIn[4]:\n",
    "        ax.plot([input_x[3],input_x[4]], [input_y[3],input_y[4]], [input_z[3],input_z[4]], zdir='y', c='#ff0000')\n",
    "    if isInputPointsIn[0] and isInputPointsIn[5]:\n",
    "        ax.plot([input_x[0],input_x[5]], [input_y[0],input_y[5]], [input_z[0],input_z[5]], zdir='y', c='#a3cc00')\n",
    "    if isInputPointsIn[5] and isInputPointsIn[6]:\n",
    "        ax.plot([input_x[5],input_x[6]], [input_y[5],input_y[6]], [input_z[5],input_z[6]], zdir='y', c='#8fb300')\n",
    "    if isInputPointsIn[6] and isInputPointsIn[7]:        \n",
    "        ax.plot([input_x[6],input_x[7]], [input_y[6],input_y[7]], [input_z[6],input_z[7]], zdir='y', c='#b8e600')\n",
    "    if isInputPointsIn[7] and isInputPointsIn[8]:\n",
    "        ax.plot([input_x[7],input_x[8]], [input_y[7],input_y[8]], [input_z[7],input_z[8]], zdir='y', c='#ccff00')\n",
    "    if isInputPointsIn[0] and isInputPointsIn[9]:\n",
    "        ax.plot([input_x[0],input_x[9]], [input_y[0],input_y[9]], [input_z[0],input_z[9]], zdir='y', c='#00cc52')\n",
    "    if isInputPointsIn[9] and isInputPointsIn[10]:\n",
    "        ax.plot([input_x[9],input_x[10]], [input_y[9],input_y[10]], [input_z[9],input_z[10]], zdir='y', c='#00b347')\n",
    "    if isInputPointsIn[10] and isInputPointsIn[11]:\n",
    "        ax.plot([input_x[10],input_x[11]], [input_y[10],input_y[11]], [input_z[10],input_z[11]], zdir='y', c='#00e65c')\n",
    "    if isInputPointsIn[11] and isInputPointsIn[12]:\n",
    "        ax.plot([input_x[11],input_x[12]], [input_y[11],input_y[12]], [input_z[11],input_z[12]], zdir='y', c='#00ff66')\n",
    "    if isInputPointsIn[0] and isInputPointsIn[13]:\n",
    "        ax.plot([input_x[0],input_x[13]], [input_y[0],input_y[13]], [input_z[0],input_z[13]], zdir='y', c='#0052cc')\n",
    "    if isInputPointsIn[13] and isInputPointsIn[14]:\n",
    "        ax.plot([input_x[13],input_x[14]], [input_y[13],input_y[14]], [input_z[13],input_z[14]], zdir='y', c='#0047b3')\n",
    "    if isInputPointsIn[14] and isInputPointsIn[15]:\n",
    "        ax.plot([input_x[14],input_x[15]], [input_y[14],input_y[15]], [input_z[14],input_z[15]], zdir='y', c='#005ce6')\n",
    "    if isInputPointsIn[15] and isInputPointsIn[16]:\n",
    "        ax.plot([input_x[15],input_x[16]], [input_y[15],input_y[16]], [input_z[15],input_z[16]], zdir='y', c='#0066ff')\n",
    "    if isInputPointsIn[0] and isInputPointsIn[17]:\n",
    "        ax.plot([input_x[0],input_x[17]], [input_y[0],input_y[17]], [input_z[0],input_z[17]], zdir='y', c='#a300cc')\n",
    "    if isInputPointsIn[17] and isInputPointsIn[18]:\n",
    "        ax.plot([input_x[17],input_x[18]], [input_y[17],input_y[18]], [input_z[17],input_z[18]], zdir='y', c='#8f00b3')\n",
    "    if isInputPointsIn[18] and isInputPointsIn[19]:\n",
    "        ax.plot([input_x[18],input_x[19]], [input_y[18],input_y[19]], [input_z[18],input_z[19]], zdir='y', c='#b800e6')\n",
    "    if isInputPointsIn[19] and isInputPointsIn[20]:\n",
    "        ax.plot([input_x[19],input_x[20]], [input_y[19],input_y[20]], [input_z[19],input_z[20]], zdir='y', c='#cc00ff')\n",
    "    \n",
    "    ##stradrs = str(test_adrs[target_epoch][i].item()) #202011221813290002\n",
    "    ##d_adrs = \"dataset_\" + stradrs[4:8] + \"_\" + stradrs[8:14] + \"_\" + stradrs[14:]\n",
    "    ##ax.set_title('input(test data, ' + str(target_epoch+1) + 'th epoch)\\n' + d_adrs)\n",
    "    ax.set_title('input(test data, ' + str(target_epoch+1) + 'th epoch)\\n' + str(i))\n",
    "    ax.set_xlim([x_min, x_max])\n",
    "    ax.set_ylim([z_min, z_max])\n",
    "    ax.set_zlim([y_min, y_max])\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('z')\n",
    "    ax.set_zlabel('y')\n",
    "    #plt.subplots_adjust(left=0.04, right=0.80, bottom=0.04, top=0.80)\n",
    "    #ax.legend(loc='upper right')\n",
    "    fig.savefig(PATH + \"\\\\outputs\\\\Input_test_\" + str(target_epoch) + \"th_epoch_\" + str(i) + \".png\", dpi = 300, transparent = False, bbox_inches = 'tight', pad_inches = 0)\n",
    "    fig.clf()\n",
    "    \n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    #各点をプロット\n",
    "    ax.scatter(output_x[0], output_y[0], zs=output_z[0], zdir='y', s=10, c='#e53528', marker = \".\")\n",
    "    ax.scatter(output_x[1], output_y[1], zs=output_z[1], zdir='y', s=10, c='#e77340', marker = \".\")\n",
    "    ax.scatter(output_x[2], output_y[2], zs=output_z[2], zdir='y', s=10, c='#eb8e25', marker = \".\")\n",
    "    ax.scatter(output_x[3], output_y[3], zs=output_z[3], zdir='y', s=10, c='#d7a10e', marker = \".\")\n",
    "    ax.scatter(output_x[4], output_y[4], zs=output_z[4], zdir='y', s=10, c='#d9c812', marker = \".\")\n",
    "    ax.scatter(output_x[5], output_y[5], zs=output_z[5], zdir='y', s=10, c='#a7cf21', marker = \".\")\n",
    "    ax.scatter(output_x[6], output_y[6], zs=output_z[6], zdir='y', s=10, c='#7fe545', marker = \".\")\n",
    "    ax.scatter(output_x[7], output_y[7], zs=output_z[7], zdir='y', s=10, c='#53d62d', marker = \".\")\n",
    "    ax.scatter(output_x[8], output_y[8], zs=output_z[8], zdir='y', s=10, c='#4abc2f', marker = \".\")\n",
    "    ax.scatter(output_x[9], output_y[9], zs=output_z[9], zdir='y', s=10, c='#52d686', marker = \".\")\n",
    "    ax.scatter(output_x[10], output_y[10], zs=output_z[10], zdir='y', s=10, c='#52dfbe', marker = \".\")\n",
    "    ax.scatter(output_x[11], output_y[11], zs=output_z[11], zdir='y', s=10, c='#52b9c5', marker = \".\")\n",
    "    ax.scatter(output_x[12], output_y[12], zs=output_z[12], zdir='y', s=10, c='#508ab7', marker = \".\")\n",
    "    ax.scatter(output_x[13], output_y[13], zs=output_z[13], zdir='y', s=10, c='#556fd0', marker = \".\")\n",
    "    ax.scatter(output_x[14], output_y[14], zs=output_z[14], zdir='y', s=10, c='#5245d5', marker = \".\")\n",
    "    ax.scatter(output_x[15], output_y[15], zs=output_z[15], zdir='y', s=10, c='#7e2fba', marker = \".\")\n",
    "    ax.scatter(output_x[16], output_y[16], zs=output_z[16], zdir='y', s=10, c='#bc64fb', marker = \".\")\n",
    "    ax.scatter(output_x[17], output_y[17], zs=output_z[17], zdir='y', s=10, c='#da53e8', marker = \".\")\n",
    "    ax.scatter(output_x[18], output_y[18], zs=output_z[18], zdir='y', s=10, c='#eb45bc', marker = \".\")\n",
    "    ax.scatter(output_x[19], output_y[19], zs=output_z[19], zdir='y', s=10, c='#ec3c89', marker = \".\")\n",
    "    ax.scatter(output_x[20], output_y[20], zs=output_z[20], zdir='y', s=10, c='#ff6691', marker = \".\")\n",
    "    \n",
    "    #点同士を結ぶ\n",
    "    if isOutputPointsIn[0] and isOutputPointsIn[1]:\n",
    "        ax.plot([output_x[0],output_x[1]], [output_y[0],output_y[1]], [output_z[0],output_z[1]], zdir='y', c='#cc0000')\n",
    "    if isOutputPointsIn[1] and isOutputPointsIn[2]:\n",
    "        ax.plot([output_x[1],output_x[2]], [output_y[1],output_y[2]], [output_z[1],output_z[2]], zdir='y', c='#b30000')\n",
    "    if isOutputPointsIn[2] and isOutputPointsIn[3]:\n",
    "        ax.plot([output_x[2],output_x[3]], [output_y[2],output_y[3]], [output_z[2],output_z[3]], zdir='y', c='#e60000')\n",
    "    if isOutputPointsIn[3] and isOutputPointsIn[4]:\n",
    "        ax.plot([output_x[3],output_x[4]], [output_y[3],output_y[4]], [output_z[3],output_z[4]], zdir='y', c='#ff0000')\n",
    "    if isOutputPointsIn[0] and isOutputPointsIn[5]:\n",
    "        ax.plot([output_x[0],output_x[5]], [output_y[0],output_y[5]], [output_z[0],output_z[5]], zdir='y', c='#a3cc00')\n",
    "    if isOutputPointsIn[5] and isOutputPointsIn[6]:\n",
    "        ax.plot([output_x[5],output_x[6]], [output_y[5],output_y[6]], [output_z[5],output_z[6]], zdir='y', c='#8fb300')\n",
    "    if isOutputPointsIn[6] and isOutputPointsIn[7]:        \n",
    "        ax.plot([output_x[6],output_x[7]], [output_y[6],output_y[7]], [output_z[6],output_z[7]], zdir='y', c='#b8e600')\n",
    "    if isOutputPointsIn[7] and isOutputPointsIn[8]:\n",
    "        ax.plot([output_x[7],output_x[8]], [output_y[7],output_y[8]], [output_z[7],output_z[8]], zdir='y', c='#ccff00')\n",
    "    if isOutputPointsIn[0] and isOutputPointsIn[9]:\n",
    "        ax.plot([output_x[0],output_x[9]], [output_y[0],output_y[9]], [output_z[0],output_z[9]], zdir='y', c='#00cc52')\n",
    "    if isOutputPointsIn[9] and isOutputPointsIn[10]:\n",
    "        ax.plot([output_x[9],output_x[10]], [output_y[9],output_y[10]], [output_z[9],output_z[10]], zdir='y', c='#00b347')\n",
    "    if isOutputPointsIn[10] and isOutputPointsIn[11]:\n",
    "        ax.plot([output_x[10],output_x[11]], [output_y[10],output_y[11]], [output_z[10],output_z[11]], zdir='y', c='#00e65c')\n",
    "    if isOutputPointsIn[11] and isOutputPointsIn[12]:\n",
    "        ax.plot([output_x[11],output_x[12]], [output_y[11],output_y[12]], [output_z[11],output_z[12]], zdir='y', c='#00ff66')\n",
    "    if isOutputPointsIn[0] and isOutputPointsIn[13]:\n",
    "        ax.plot([output_x[0],output_x[13]], [output_y[0],output_y[13]], [output_z[0],output_z[13]], zdir='y', c='#0052cc')\n",
    "    if isOutputPointsIn[13] and isOutputPointsIn[14]:\n",
    "        ax.plot([output_x[13],output_x[14]], [output_y[13],output_y[14]], [output_z[13],output_z[14]], zdir='y', c='#0047b3')\n",
    "    if isOutputPointsIn[14] and isOutputPointsIn[15]:\n",
    "        ax.plot([output_x[14],output_x[15]], [output_y[14],output_y[15]], [output_z[14],output_z[15]], zdir='y', c='#005ce6')\n",
    "    if isOutputPointsIn[15] and isOutputPointsIn[16]:\n",
    "        ax.plot([output_x[15],output_x[16]], [output_y[15],output_y[16]], [output_z[15],output_z[16]], zdir='y', c='#0066ff')\n",
    "    if isOutputPointsIn[0] and isOutputPointsIn[17]:\n",
    "        ax.plot([output_x[0],output_x[17]], [output_y[0],output_y[17]], [output_z[0],output_z[17]], zdir='y', c='#a300cc')\n",
    "    if isOutputPointsIn[17] and isOutputPointsIn[18]:\n",
    "        ax.plot([output_x[17],output_x[18]], [output_y[17],output_y[18]], [output_z[17],output_z[18]], zdir='y', c='#8f00b3')\n",
    "    if isOutputPointsIn[18] and isOutputPointsIn[19]:\n",
    "        ax.plot([output_x[18],output_x[19]], [output_y[18],output_y[19]], [output_z[18],output_z[19]], zdir='y', c='#b800e6')\n",
    "    if isOutputPointsIn[19] and isOutputPointsIn[20]:\n",
    "        ax.plot([output_x[19],output_x[20]], [output_y[19],output_y[20]], [output_z[19],output_z[20]], zdir='y', c='#cc00ff')\n",
    "    #ax.scatter(input_x, input_y, c='red', label = 'input')\n",
    "    #ax.scatter(output_x, output_y, c='blue', label = 'output')\n",
    "    \n",
    "    ##stradrs = str(test_adrs[target_epoch][i].item()) #11221813290002\n",
    "    ##d_adrs = \"dataset_\" + stradrs[4:8] + \"_\" + stradrs[8:14] + \"_\" + stradrs[14:]\n",
    "    ##ax.set_title('output(test data, ' + str(target_epoch+1) + 'th epoch)\\n' + d_adrs)\n",
    "    ax.set_title('output(test data, ' + str(target_epoch+1) + 'th epoch)\\n' + str(i))\n",
    "    ax.set_xlim([x_min, x_max])\n",
    "    ax.set_ylim([z_min, z_max])\n",
    "    ax.set_zlim([y_min, y_max])\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('z')\n",
    "    ax.set_zlabel('y')\n",
    "    #plt.subplots_adjust(left=0.04, right=0.80, bottom=0.04, top=0.80)\n",
    "    #ax.legend(loc='upper right')\n",
    "    fig.savefig(PATH + \"\\\\outputs\\\\Output_test_\" + str(target_epoch) + \"th_epoch_\" + str(i) + \".png\", dpi = 300, transparent = False, bbox_inches = 'tight', pad_inches = 0)\n",
    "    fig.clf()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fin save.\n"
     ]
    }
   ],
   "source": [
    "#出力値保存\n",
    "\n",
    "with open(PATH + \"\\\\outputs\\\\network_outs.csv\", mode='w') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"train_test\",\" \"])\n",
    "    for i in range(len(train_input_value)):                      #epoch数 loop 1000\n",
    "        writer.writerow([\"epoch:\" + str(i+1),\" \"])\n",
    "        for j in range(len(train_input_value[i])):               #batch size数 loop 10\n",
    "            writer.writerow([\"batch:\" + str(j+1),\" \"])\n",
    "            input_x = []\n",
    "            input_y = []\n",
    "            input_z = []\n",
    "            output_x = []\n",
    "            output_y = []\n",
    "            output_z = []\n",
    "            descriptor = []\n",
    "            handlocation = []\n",
    "            for k in range(int(len(train_input_value[i][j])/4)): #data size / 2 loop (x, y分離) 21(42)\n",
    "                input_x.append(train_input_value[i][j][k*4+0].item())\n",
    "                input_y.append(train_input_value[i][j][k*4+1].item())\n",
    "                input_z.append(train_input_value[i][j][k*4+2].item())\n",
    "                output_x.append(train_output_value[i][j][k*3+0].item())\n",
    "                output_y.append(train_output_value[i][j][k*3+1].item())\n",
    "                output_z.append(train_output_value[i][j][k*3+2].item())\n",
    "            for l in range(len(train_desc_value[i][j])):\n",
    "                descriptor.append(train_desc_value[i][j][l].item())\n",
    "            for l in range(len(train_handloc_value[i][j])):\n",
    "                handlocation.append(train_handloc_value[i][j][l].item())\n",
    "            writer.writerow(input_x)\n",
    "            writer.writerow(input_y)\n",
    "            writer.writerow(output_x)\n",
    "            writer.writerow(output_y)\n",
    "            writer.writerow(descriptor)\n",
    "            writer.writerow(handlocation)\n",
    "    writer.writerow([\"test_test\",\" \"])\n",
    "    for i in range(len(test_input_value)):                      #epoch数 loop 1000\n",
    "        writer.writerow([\"epoch:\" + str(i+1),\" \"])\n",
    "        for j in range(len(test_input_value[i])):               #batch size数 loop 10\n",
    "            writer.writerow([\"batch:\" + str(j+1),\" \"])\n",
    "            input_x = []\n",
    "            input_y = []\n",
    "            input_z = []\n",
    "            output_x = []\n",
    "            output_y = []\n",
    "            output_z = []\n",
    "            descriptor = []\n",
    "            handlocation = []\n",
    "            for k in range(int(len(test_input_value[i][j])/4)): #data size / 2 loop (x, y分離) 21(42)\n",
    "                input_x.append(test_input_value[i][j][k*4+0].item())\n",
    "                input_y.append(test_input_value[i][j][k*4+1].item())\n",
    "                input_z.append(test_input_value[i][j][k*4+2].item())\n",
    "                output_x.append(test_output_value[i][j][k*3+0].item())\n",
    "                output_y.append(test_output_value[i][j][k*3+1].item())\n",
    "                output_z.append(test_output_value[i][j][k*3+2].item())\n",
    "            for l in range(len(test_desc_value[i][j])):\n",
    "                descriptor.append(test_desc_value[i][j][l].item())\n",
    "            for l in range(len(test_handloc_value[i][j])):\n",
    "                handlocation.append(test_handloc_value[i][j][l].item())\n",
    "            writer.writerow(input_x)\n",
    "            writer.writerow(input_y)\n",
    "            writer.writerow(output_x)\n",
    "            writer.writerow(output_y)\n",
    "            writer.writerow(descriptor)\n",
    "            writer.writerow(handlocation)\n",
    "    print(\"fin save.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fin loading\n",
      "data [-267. -214.  151.    0.    0.    0. -229. -102.  -87. -228.  -74.  -66.\n",
      "    0.    0.    0. -247. -151.  192. -249. -108.  208. -224.  -48.   -8.\n",
      " -225.  -33.  -62. -247. -145.  180.    0.    0.    0. -225.  -42.  -62.\n",
      " -234.  -34.  -73. -250. -145.  180. -224.  -73.  -36. -231.  -49.  -79.\n",
      " -239.  -40.  -96. -225.  -97.  -60. -228.  -74.  -66. -235.  -56.  -96.\n",
      " -238.  -51. -105.    0.]\n",
      "img [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "dmask [1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "imgmask [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "sean_firsts = []\n",
    "for sean in train_seanset:\n",
    "    #sean_imgcfile = glob.glob(sean + \"\\\\object*.png\")[0]\n",
    "    sean_imgdfile = glob.glob(sean + \"\\\\objectd*.png\")[0]\n",
    "    s_datafile = glob.glob(sean + \"\\\\data\\\\*0.csv\")[0]\n",
    "    #s_labelfile = glob.glob(sean + \"\\\\label\\\\*.csv\")[0]\n",
    "    pair = []\n",
    "    pair.append(s_datafile)\n",
    "    #pair.append(s_labelfile)\n",
    "    pair.append(sean_imgdfile)\n",
    "    sean_firsts.append(pair)\n",
    "\n",
    "data_recall = []\n",
    "img_recall = []\n",
    "mask_recall = []\n",
    "imgmask_recall = []\n",
    "for i in range(len(sean_firsts)):\n",
    "    # 画像読み込み\n",
    "    image = Image.open(sean_firsts[i][1])\n",
    "    # グレイスケール変換\n",
    "    #image = image.convert('L')\n",
    "    # リサイズ\n",
    "    image = image.resize((image_size, image_size))\n",
    "    ## 画像から配列に変換\n",
    "    #img_recall.append(np.asarray(image))\n",
    "    # 画像から配列に変換\n",
    "    img_array = np.asarray(image)\n",
    "    img_recall.append(img_array)\n",
    "    img_mask_array = np.zeros((image_size, image_size), np.uint8) #画像マスク\n",
    "    \n",
    "    #元画像の画素値が0の部分のみマスク画像の画素値を1にする\n",
    "    for h in range(img_array.shape[0]):\n",
    "        for w in range(img_array.shape[1]):\n",
    "            if 0 <= img_array[h,w] < 500:\n",
    "                img_mask_array[h,w] = 1\n",
    "    #img_names.append(os.path.basename(imgfile))\n",
    "    #file_split = [i for i in file.split('_')]\n",
    "    imgmask_recall.append(img_mask_array)\n",
    "    \n",
    "    data_points = []\n",
    "    data_masks = []\n",
    "    with open(sean_firsts[i][0]) as f:\n",
    "        reader = csv.reader(f)\n",
    "        num = 0\n",
    "        for row in reader:\n",
    "            if num == 0:\n",
    "                for point in row:\n",
    "                    if int(point) == -10000:\n",
    "                        data_points.append(float(0))\n",
    "                        data_masks.append(0)\n",
    "                    else:\n",
    "                        data_points.append(float(point))\n",
    "                        data_masks.append(1)\n",
    "                data_points = np.asarray(data_points)\n",
    "                data_masks = np.asarray(data_masks)\n",
    "                num += 1\n",
    "    data_recall.append(np.asarray(data_points))\n",
    "    mask_recall.append(np.asarray(data_masks))\n",
    "\n",
    "print(\"fin loading\")\n",
    "\n",
    "data_recall = np.array(data_recall).astype('float32')\n",
    "img_recall = np.array(img_recall).astype('float32')/1000\n",
    "mask_recall = np.array(mask_recall).astype('float32')\n",
    "imgmask_recall = np.array(imgmask_recall).astype('float32')\n",
    "\n",
    "print(\"data\",data_recall[0])\n",
    "print(\"img\",img_recall[0])\n",
    "print(\"dmask\",mask_recall[0])\n",
    "print(\"imgmask\",imgmask_recall[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trans = torchvision.transforms.Compose(\n",
    "#    [torchvision.transforms.ToTensor()]#,torchvision.transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))]\n",
    "#)\n",
    "\n",
    "class Mydatasets2(torch.utils.data.Dataset):\n",
    "    def __init__(self, datas, img_array, data_masks, img_masks, transform = None):\n",
    "        self.transform = transform\n",
    "        #self.transform2 = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "        self.data = datas\n",
    "        self.img_array = img_array\n",
    "        self.masks = data_masks\n",
    "        self.img_masks = img_masks\n",
    "\n",
    "        self.datanum = datas.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.datanum\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #batch_set = []\n",
    "        \n",
    "        i_data = self.data\n",
    "        i_img = self.img_array\n",
    "        i_mask = self.masks\n",
    "        i_imgmask = self.img_masks\n",
    "        \n",
    "        #print(out_label)\n",
    "        #print(type(i_label))\n",
    "        out_data = np.array(i_data.astype(np.float32))\n",
    "        out_img = np.array(i_img.astype(np.float32))\n",
    "        out_mask = np.array(i_mask.astype(np.float32))\n",
    "        out_imgmask = np.array(i_imgmask.astype(np.float32))\n",
    "        #out_label.append(i_label.astype(np.float32))\n",
    "        #print(type(out_label))\n",
    "\n",
    "        if self.transform:\n",
    "            #out_data = self.transform(i_data)\n",
    "            out_img = self.transform(out_img)\n",
    "            out_imgmask = self.transform(out_imgmask)\n",
    "            #out_label = self.transform2(out_label)\n",
    "        \n",
    "        #batch_set.append(out_data)\n",
    "        #batch_set.append(out_label)\n",
    "        #batch_set.append(out_img)\n",
    "        #batch_set.append(out_mask)\n",
    "        #batch_set.append(out_lmask)\n",
    "\n",
    "        return out_data, out_img, out_mask, out_imgmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: [-2.67 -2.14  1.51  0.    0.    0.   -2.29 -1.02 -0.87 -2.28 -0.74 -0.66\n",
      "  0.    0.    0.   -2.47 -1.51  1.92 -2.49 -1.08  2.08 -2.24 -0.48 -0.08\n",
      " -2.25 -0.33 -0.62 -2.47 -1.45  1.8   0.    0.    0.   -2.25 -0.42 -0.62\n",
      " -2.34 -0.34 -0.73 -2.5  -1.45  1.8  -2.24 -0.73 -0.36 -2.31 -0.49 -0.79\n",
      " -2.39 -0.4  -0.96 -2.25 -0.97 -0.6  -2.28 -0.74 -0.66 -2.35 -0.56 -0.96\n",
      " -2.38 -0.51 -1.05  0.  ]\n",
      "mask: [1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001CE404BC8D0>\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 8.00 GiB total capacity; 5.02 GiB already allocated; 0 bytes free; 5.03 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-d274663fa681>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     54\u001b[0m         \u001b[0mrecord\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_recall\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         \u001b[0mwriter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriterow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 56\u001b[1;33m     \u001b[0minitial\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrecall_sequence\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_recall\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmask_recall\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_recall\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgmask_recall\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mr\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     57\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"init:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minitial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"type:\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minitial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-23-d274663fa681>\u001b[0m in \u001b[0;36mrecall_sequence\u001b[1;34m(data, mask, img, imask)\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimasks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimgs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmasks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimasks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m         \u001b[0mhandloc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpose_h\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mposedesc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput_img\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput_mask\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mimg_mask\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m         \u001b[1;31m#手首位置基準座標→物体位置基準座標\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mxd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpose_h\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-a010983abd65>\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, y, m, im)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 113\u001b[1;33m         \u001b[0mxLoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxPD\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcnn_part\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    114\u001b[0m         \u001b[0mxPose\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxPD\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    115\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mxLoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxPose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mxPD\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-a010983abd65>\u001b[0m in \u001b[0;36mcnn_part\u001b[1;34m(self, x, y, m, im)\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[0mim_conv2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msub\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mim_conv2\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mc\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[1;31m#ReLU→BatchNorm2d 2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbn2d2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m         \u001b[1;31m#AvgPool2d\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m    548\u001b[0m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m             \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\modules\\batchnorm.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    104\u001b[0m             \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    105\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtraining\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrack_running_stats\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 106\u001b[1;33m             exponential_average_factor, self.eps)\n\u001b[0m\u001b[0;32m    107\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mbatch_norm\u001b[1;34m(input, running_mean, running_var, weight, bias, training, momentum, eps)\u001b[0m\n\u001b[0;32m   1921\u001b[0m     return torch.batch_norm(\n\u001b[0;32m   1922\u001b[0m         \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_mean\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrunning_var\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1923\u001b[1;33m         \u001b[0mtraining\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmomentum\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0meps\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcudnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0menabled\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1924\u001b[0m     )\n\u001b[0;32m   1925\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 2.00 MiB (GPU 0; 8.00 GiB total capacity; 5.02 GiB already allocated; 0 bytes free; 5.03 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "#recallset = Mydatasets2(datas = data_recall, img_array = img_recall, data_masks = mask_recall, transform = trans)\n",
    "\n",
    "def recall_sequence(data, mask, img, imask):\n",
    "    data = data.astype('float32')/100\n",
    "    mask = mask.astype('float32')\n",
    "    img = img.astype('float32')\n",
    "    imask = imask.astype('float32')\n",
    "    \n",
    "    #data = np.array(data.astype(np.float32))\n",
    "    #mask = np.array(mask.astype(np.float32))\n",
    "    #img = trans(np.array(img.astype(np.float32)))\n",
    "    \n",
    "    print(\"data:\",data)\n",
    "    print(\"mask:\",mask)\n",
    "    print(\"img:\",img)\n",
    "    print(\"imask: \",imask)\n",
    "    #init_l_points = np.array(init_l_points.astype(np.float32))\n",
    "    #print(init_l_points)\n",
    "    recallset = Mydatasets2(datas = data, img_array = img, data_masks = mask, img_masks = imask, transform = trans)\n",
    "    print(\"recall_set:\",recallset)\n",
    "    recallloader = torch.utils.data.DataLoader(recallset, batch_size = 15, shuffle = False, num_workers = 0)\n",
    "    \n",
    "    #net.eval()\n",
    "    for (inputs, imgs, masks, imasks) in recallloader:\n",
    "    #tmp = recallloader.__iter__()\n",
    "    #inputs, imgs, masks = tmp.next()\n",
    "        inputs, imgs, masks, imasks = inputs.to(device), imgs.to(device), masks.to(device), imasks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        handloc, pose_h, posedesc = net(input_img, inputs, input_mask, img_mask)\n",
    "        #手首位置基準座標→物体位置基準座標\n",
    "        xd = torch.zeros_like(pose_h).to(device)\n",
    "        yd = torch.zeros_like(pose_h).to(device)\n",
    "        zd = torch.zeros_like(pose_h).to(device)\n",
    "        for bsize in range(pose_h.size()[0]):\n",
    "            xval = handloc[bsize][0].item()\n",
    "            yval = handloc[bsize][1].item()\n",
    "            zval = handloc[bsize][2].item()\n",
    "            for i in range(int(pose_h.size()[1] / 3)):\n",
    "                xd[bsize][i*3+0] = xval\n",
    "                yd[bsize][i*3+1] = yval\n",
    "                zd[bsize][i*3+2] = zval\n",
    "        recall_out = (pose_h + xd + yd + zd).to(device)\n",
    "        print(recall_out)\n",
    "        break\n",
    "    recall_out_np = recall_out.to('cpu').detach().numpy().copy()\n",
    "    print(recall_out_np[0])\n",
    "    return recall_out_np[0]\n",
    "\n",
    "mask_static = np.ones(data_recall.shape[1])\n",
    "\n",
    "for r in range(len(data_recall)):\n",
    "    with open(PATH + \"\\\\recalls\\\\{:0=4}\".format(r) + \"\\\\recall_0.csv\" , 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        record = data_recall[r]\n",
    "        writer.writerow(record.tolist())\n",
    "    initial = recall_sequence(data_recall[r], mask_recall[r], img_recall[r], imgmask_recall[r])\n",
    "    print(\"init:\",initial)\n",
    "    print(\"type:\",type(initial))\n",
    "    \n",
    "    for t in range(20):\n",
    "        initial = (initial*100).tolist()\n",
    "        initial.append(t+1)\n",
    "        with open(PATH + \"\\\\recalls\\\\{:0=4}\".format(r) + \"\\\\recall_\" + str(t+1) + \".csv\", 'w') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(initial)\n",
    "        initial = recall_sequence( np.array(initial), mask_static, img_recall[r], imgmask_recall[r])\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydatasets3(torch.utils.data.Dataset):\n",
    "    def __init__(self, datas, img_array, data_masks, img_masks, transform = None):\n",
    "        self.transform = transform\n",
    "        #self.transform2 = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "        self.data = datas\n",
    "        self.img_array = img_array\n",
    "        self.masks = data_masks\n",
    "        self.img_masks = img_masks\n",
    "\n",
    "        self.datanum = datas.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.datanum\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #batch_set = []\n",
    "        \n",
    "        i_data = self.data[idx]\n",
    "        i_img = self.img_array[idx]\n",
    "        i_mask = self.masks[idx]\n",
    "        i_imask = self.img_masks[idx]\n",
    "        \n",
    "        #print(out_label)\n",
    "        #print(type(i_label))\n",
    "        out_data = np.array(i_data.astype(np.float32))\n",
    "        out_img = np.array(i_img.astype(np.float32))\n",
    "        out_mask = np.array(i_mask.astype(np.float32))\n",
    "        out_imask = np.array(i_imask.astype(np.float32))\n",
    "        #out_label.append(i_label.astype(np.float32))\n",
    "        #print(type(out_label))\n",
    "\n",
    "        if self.transform:\n",
    "            #out_data = self.transform(i_data)\n",
    "            out_img = self.transform(out_img)\n",
    "            out_imask = self.transform(out_imask)\n",
    "            #out_label = self.transform2(out_label)\n",
    "        \n",
    "        #batch_set.append(out_data)\n",
    "        #batch_set.append(out_label)\n",
    "        #batch_set.append(out_img)\n",
    "        #batch_set.append(out_mask)\n",
    "        #batch_set.append(out_lmask)\n",
    "\n",
    "        return out_data, out_img, out_mask, out_imask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 64)\n",
      "(600, 36, 36)\n",
      "(600, 64)\n",
      "(600, 36, 36)\n",
      "train_test\n"
     ]
    }
   ],
   "source": [
    "data_check = []\n",
    "img_check = []\n",
    "mask_check = []\n",
    "imgmask_check = []\n",
    "for i in range(len(img_skeleton_sets_train)):\n",
    "    data_check.append(img_skeleton_sets_train[i][0])\n",
    "    img_check.append(img_skeleton_sets_train[i][1])\n",
    "    mask_check.append(img_skeleton_sets_train[i][2])\n",
    "    imgmask_check.append(img_skeleton_sets_train[i][3])\n",
    "    \n",
    "data_check = np.array(data_check).astype('float32')/100\n",
    "img_check = np.array(img_check).astype('float32')/1000\n",
    "mask_check = np.array(mask_check).astype('float32')\n",
    "imgmask_check = np.array(imgmask_check).astype('float32')\n",
    "print(data_check.shape)\n",
    "print(img_check.shape)\n",
    "print(mask_check.shape)\n",
    "print(imgmask_check.shape)\n",
    "\n",
    "checkset = Mydatasets3(datas = data_check, img_array = img_check, data_masks = mask_check, img_masks = imgmask_check, transform = trans)\n",
    "\n",
    "checkloader = torch.utils.data.DataLoader(checkset, batch_size = BATCH_SIZE,\n",
    "                        shuffle = False, num_workers = 0)\n",
    "\n",
    "print(\"train_test\")\n",
    "#train dataを使ってテストをする(パラメータ更新がないようになっている)\n",
    "num = 0\n",
    "net.eval()\n",
    "for (inputs, input_img, input_mask, input_imask) in checkloader:\n",
    "    inputs, input_img, input_mask, input_imask = \\\n",
    "    inputs.to(device), input_img.to(device), input_mask.to(device), input_imask.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(input_img, inputs, input_mask, input_imask)\n",
    "    out_np = (outputs.to('cpu').detach().numpy().copy()) * 100\n",
    "    for b in range(BATCH_SIZE):\n",
    "        with open(PATH + \"\\\\checks\\\\check_\" + str((num * BATCH_SIZE) + b) + \".csv\" , 'w') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(out_np[b].tolist())\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), PATH + \"\\\\model8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.pool = nn.AvgPool2d(2, stride=2)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1,16,3)\n",
    "        self.conv2 = nn.Conv2d(16,32,3)\n",
    "        self.bn2d1 = nn.BatchNorm2d(16)\n",
    "        self.bn2d2 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.fcm = Ignore(32 * 7 * 7 + 64, 32 * 7 * 7 + 64)\n",
    "        self.bnm = nn.BatchNorm1d(32 * 7 * 7 + 64)\n",
    "        #fully connect for hand Location(x,y,z)\n",
    "        self.fcL1 = nn.Linear(32 * 7 * 7 + 64, 300)\n",
    "        self.fcL2 = nn.Linear(300, 30)\n",
    "        self.fcL3 = nn.Linear(30, 3)        \n",
    "        self.bnL1 = nn.BatchNorm1d(300)\n",
    "        self.bnL2 = nn.BatchNorm1d(30)\n",
    "        #fully connect for hand Pose Descriptor(8 properties)\n",
    "        self.fcPD1 = nn.Linear(32 * 7 * 7 + 64, 300)\n",
    "        self.fcPD2 = nn.Linear(300, 60)\n",
    "        self.fcPD3 = nn.Linear(60, 8)\n",
    "        self.bnPD1 = nn.BatchNorm1d(300)\n",
    "        self.bnPD2 = nn.BatchNorm1d(60)\n",
    "\n",
    "    def forward(self, x, y, m, im):\n",
    "        #print(\"original: \",x[0][0:2],\"\\n\",x[1][0:2], x.size())\n",
    "        #print(\"original mask: \",im[0][0:2],\"\\n\",im[1][0:2], im.size())\n",
    "        \n",
    "        #Conv2d 1\n",
    "        x = self.conv1(x)\n",
    "        im = self.conv1(im)\n",
    "        #print(\"conv1: \",x[0:2][0:2], x.size())\n",
    "        #print(\"conv1 mask: \",im[0:2][0:2], im.size())\n",
    "        im_conv1 = im.clone().detach().to(torch.device(\"cuda:0\"))\n",
    "        for c in range(im.size()[1]):\n",
    "            mode, ind = torch.mode(torch.reshape(im[0][c].clone().detach(), (-1, im.size()[2] * im.size()[3])))\n",
    "            im_conv1[:,c] = torch.sub(im_conv1[:,c], mode.item())\n",
    "        #print(\"conv1 mask fix: \",im_conv1[0:2][0:2], im_conv1.size())       \n",
    "        \n",
    "        #ReLU→BatchNorm2d 1\n",
    "        x = self.bn2d1(self.relu(x))\n",
    "        #print(\"relu1: \", x[0:2][0:2], x.size())\n",
    "        #x = self.bn2d1(self.tanh(x))\n",
    "        #print(\"tanh1: \", x[0:2][0:2], x.size())\n",
    "        \n",
    "        #AvgPool2d\n",
    "        x = self.pool(x)\n",
    "        im = self.pool(im_conv1)\n",
    "        #print(\"pool1: \", x[0:2][0:2], x.size())\n",
    "        #print(\"pool1 mask: \",im[0:2][0:2], im.size())\n",
    "        \n",
    "        #Conv2d 2\n",
    "        x = self.conv2(x)\n",
    "        im = self.conv2(im)\n",
    "        #print(\"conv2: \",x[0:2][0:2], x.size())\n",
    "        #print(\"conv2 mask: \",im[0:2][0:2], im.size())\n",
    "        im_conv2 = im.clone().detach().to(torch.device(\"cuda:0\"))\n",
    "        for c in range(im.size()[1]):\n",
    "            mode, ind = torch.mode(torch.reshape(im[0][c].clone().detach(), (-1, im.size()[2] * im.size()[3])))\n",
    "            im_conv2[:,c] = torch.sub(im_conv2[:,c], mode.item())\n",
    "        #print(\"conv2 mask fix: \",im_conv2[0:2][0:2], im_conv2.size())\n",
    "        \n",
    "        #ReLU→BatchNorm2d 2\n",
    "        x = self.bn2d2(self.relu(x))\n",
    "        #print(\"relu2: \", x[0:2][0:2], x.size())\n",
    "        #x = self.bn2d2(self.tanh(x))\n",
    "        #print(\"tanh2: \", x[0:2][0:2], x.size())\n",
    "        \n",
    "        #AvgPool2d\n",
    "        x = self.pool(x)\n",
    "        im = self.pool(im_conv2)\n",
    "        #print(\"pool2: \", x[0:2][0:2], x.size())\n",
    "        #print(\"pool2 mask: \",im[0:2][0:2], im.size())\n",
    "        \n",
    "        #1次元ベクトル化\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        im = im.view(im.size()[0], -1)\n",
    "        #print(\"view: \", x[0:2], x.size())\n",
    "        #print(\"view mask: \",im[0:2], im.size())\n",
    "        \n",
    "        #マスク再構築(0→1, 0以外→0)\n",
    "        im = torch.logical_not(torch.logical_and(im, torch.tensor([True]).to(torch.device(\"cuda:0\")))).float()\n",
    "        #print(\"mask_img: \", im[0:2], im.size())\n",
    "        \n",
    "        #骨格データと結合\n",
    "        x = torch.cat([x, y], axis = -1)\n",
    "        m = torch.cat([im, m], axis = -1)\n",
    "        #print(\"cat: \", x[0:2], x.size())\n",
    "        #print(\"cat mask: \", m[0:2], m.size())\n",
    "        \n",
    "        #MaskedLinear\n",
    "        x = self.fcm(x, m)\n",
    "        #print(\"masked: \", x[0], x.size())\n",
    "        x = self.bnm(self.relu(x))\n",
    "        #x = self.bnm(self.tanh(x))\n",
    "        xL = self.fcL1(x)\n",
    "        xPD = self.fcPD1(x)\n",
    "        #print(\"fc1: \",x[0])\n",
    "        xL = self.bnL1(self.relu(xL))\n",
    "        xPD = self.bnPD1(self.relu(xPD))\n",
    "        #x = self.bn1(self.tanh(x))\n",
    "        xL = self.fcL2(xL)\n",
    "        xPD = self.fcPD2(xPD)\n",
    "        #print(\"fc2: \",x[0])\n",
    "        xL = self.bnL2(self.relu(xL))\n",
    "        xPD = self.bnPD2(self.relu(xPD))\n",
    "        #x = self.bn2(self.tanh(x))\n",
    "        xL = self.fcL3(xL)\n",
    "        xPD = self.fcPD3(xPD)\n",
    "        return xL, xPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

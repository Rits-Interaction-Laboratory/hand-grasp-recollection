{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fin loading\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt    #グラフ出力用module\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "import os\n",
    "import csv\n",
    "\n",
    "PATH = os.getcwd()\n",
    "image_size=36\n",
    "\n",
    "#seanセットフォルダ一覧取得\n",
    "datadir = PATH + \"\\\\dataset_h\"\n",
    "traindir = datadir + \"\\\\train\"\n",
    "testdir = datadir + \"\\\\test\"\n",
    "train_seanset = glob.glob(traindir + \"\\\\*\")\n",
    "test_seanset = glob.glob(testdir + \"\\\\*\")\n",
    "\n",
    "train_sean_seqs = []\n",
    "test_sean_seqs = []\n",
    "for sean in train_seanset:\n",
    "    #sean_imgcfile = glob.glob(sean + \"\\\\object*.png\")[0]\n",
    "    sean_imgdfile = glob.glob(sean + \"\\\\objectd*.png\")[0]\n",
    "    s_datafiles = glob.glob(sean + \"\\\\data\\\\*.csv\")\n",
    "    s_labelfiles = glob.glob(sean + \"\\\\label\\\\*.csv\")\n",
    "    s_datacfiles = glob.glob(sean + \"\\\\datac\\\\*.csv\")\n",
    "    s_labelcfiles = glob.glob(sean + \"\\\\labelc\\\\*.csv\")\n",
    "    for t in range(len(s_datafiles)):\n",
    "        pair = []\n",
    "        pair.append(s_datafiles[t])\n",
    "        pair.append(s_labelfiles[t])\n",
    "        pair.append(s_datacfiles[t])\n",
    "        pair.append(s_labelcfiles[t])\n",
    "        pair.append(sean_imgdfile)\n",
    "        train_sean_seqs.append(pair) #dataとlabelと画像名をセットで登録\n",
    "\n",
    "for sean in test_seanset:\n",
    "    #sean_imgcfile = glob.glob(sean + \"\\\\object*.png\")[0]\n",
    "    sean_imgdfile = glob.glob(sean + \"\\\\objectd*.png\")[0]\n",
    "    s_datafiles = glob.glob(sean + \"\\\\data\\\\*.csv\")\n",
    "    s_labelfiles = glob.glob(sean + \"\\\\label\\\\*.csv\")\n",
    "    s_datacfiles = glob.glob(sean + \"\\\\datac\\\\*.csv\")\n",
    "    s_labelcfiles = glob.glob(sean + \"\\\\labelc\\\\*.csv\")\n",
    "    for t in range(len(s_datafiles)):\n",
    "        pair = []\n",
    "        pair.append(s_datafiles[t])\n",
    "        pair.append(s_labelfiles[t])\n",
    "        pair.append(s_datacfiles[t])\n",
    "        pair.append(s_labelcfiles[t])\n",
    "        pair.append(sean_imgdfile)\n",
    "        test_sean_seqs.append(pair) #dataとlabelと画像名をセットで登録\n",
    "\n",
    "img_skeleton_sets_train = []\n",
    "img_skeleton_sets_test = []\n",
    "def make_datasets(sean_seqs):\n",
    "    img_skeleton_sets = []\n",
    "    for i in range(len(sean_seqs)):\n",
    "        #ファイル名データ\n",
    "        input_name = sean_seqs[i][0]\n",
    "        label_name = sean_seqs[i][1]\n",
    "        input_name = input_name.split(\"dataset_hand_pxmm_\")\n",
    "        label_name = label_name.split(\"dataset_hand_pxmm_\")\n",
    "        input_name = input_name[1].rsplit(\".csv\")\n",
    "        label_name = label_name[1].rsplit(\".csv\")\n",
    "        input_name = input_name[0].split(\"_\")\n",
    "        label_name = label_name[0].split(\"_\")\n",
    "        input_num = []\n",
    "        label_num = []\n",
    "        input_num.append(int(input_name[0]))\n",
    "        input_num.append(int(input_name[1]))\n",
    "        input_num.append(int(input_name[2]))\n",
    "        input_num.append(int(input_name[4]))\n",
    "        input_num.append(int(input_name[5]))\n",
    "        label_num.append(int(label_name[0]))\n",
    "        label_num.append(int(label_name[1]))\n",
    "        label_num.append(int(label_name[2]))\n",
    "        label_num.append(int(label_name[4]))\n",
    "        label_num.append(int(label_name[5]))\n",
    "        input_num = np.asarray(input_num)\n",
    "        label_num = np.asarray(label_num)\n",
    "        #画像読み込み・リサイズ・配列に変換\n",
    "        image = Image.open(sean_seqs[i][4])\n",
    "        image = image.resize((image_size, image_size))\n",
    "        img_array = np.asarray(image)\n",
    "        #画像マスク作成(元画像の画素値が外れ値(0～500)の部分を1にする、他は0)\n",
    "        img_mask_array = np.zeros((image_size, image_size), np.uint8)\n",
    "        for h in range(img_array.shape[0]):\n",
    "            for w in range(img_array.shape[1]):\n",
    "                if 0 <= img_array[h,w] < 500:\n",
    "                    img_mask_array[h,w] = 1\n",
    "        input_points = []\n",
    "        input_masks = []\n",
    "        input_masks2 = []\n",
    "        label_points = []\n",
    "        label_masks = []\n",
    "        inputc_points = []\n",
    "        inputc_masks = []\n",
    "        inputc_masks2 = []\n",
    "        labelc_points = []\n",
    "        labelc_masks = []\n",
    "        invinput_cnt = 0\n",
    "        invlabel_cnt = 0\n",
    "        #学習用骨格データ(no conf.)読み込み\n",
    "        with open(sean_seqs[i][0]) as f:\n",
    "            reader = csv.reader(f)\n",
    "            num = 0\n",
    "            for row in reader:\n",
    "                if num == 0:\n",
    "                    elem = 1\n",
    "                    for point in row:\n",
    "                        if (float(point) == -10000 or float(point) == 0) and elem != 43:\n",
    "                            invinput_cnt += 1\n",
    "                            input_points.append(float(0))\n",
    "                            input_masks.append(0)\n",
    "                            if elem != 43:\n",
    "                                input_masks2.append(0)\n",
    "                        else:\n",
    "                            input_points.append(float(point))\n",
    "                            input_masks.append(1)\n",
    "                            if elem != 43:\n",
    "                                input_masks2.append(1)\n",
    "                        elem += 1\n",
    "                    input_points = np.asarray(input_points)\n",
    "                    input_masks = np.asarray(input_masks)\n",
    "                    input_masks2 = np.array(input_masks2)\n",
    "                    num += 1\n",
    "        #ラベル用骨格データ読み込み\n",
    "        with open(sean_seqs[i][1]) as f:\n",
    "            reader = csv.reader(f)\n",
    "            num = 0\n",
    "            for row in reader:\n",
    "                if num == 0:\n",
    "                    for point in row:\n",
    "                        if float(point) == -10000 or float(point) == 0:\n",
    "                            invlabel_cnt += 1\n",
    "                            label_points.append(float(0))\n",
    "                            label_masks.append(0)\n",
    "                        else:\n",
    "                            label_points.append(float(point))\n",
    "                            label_masks.append(1)\n",
    "                    label_points = np.asarray(label_points)\n",
    "                    label_masks = np.asarray(label_masks)\n",
    "                    num += 1\n",
    "        #学習用骨格データ(no conf.)読み込み\n",
    "        with open(sean_seqs[i][2]) as f:\n",
    "            reader = csv.reader(f)\n",
    "            num = 0\n",
    "            for row in reader:\n",
    "                if num == 0:\n",
    "                    elem = 1\n",
    "                    for point in row:\n",
    "                        if (float(point) == -10000 or float(point) == 0) and elem != 64:\n",
    "                            inputc_points.append(float(0))\n",
    "                            inputc_masks.append(0)\n",
    "                            if elem != 64:\n",
    "                                inputc_masks2.append(0)\n",
    "                        else:\n",
    "                            inputc_points.append(float(point))\n",
    "                            inputc_masks.append(1)\n",
    "                            if elem != 64:\n",
    "                                inputc_masks2.append(1)\n",
    "                        elem += 1\n",
    "                    inputc_points = np.asarray(inputc_points)\n",
    "                    inputc_masks = np.asarray(inputc_masks)\n",
    "                    inputc_masks2 = np.array(inputc_masks2)\n",
    "                    num += 1\n",
    "        #ラベル用骨格データ読み込み\n",
    "        with open(sean_seqs[i][3]) as f:\n",
    "            reader = csv.reader(f)\n",
    "            num = 0\n",
    "            for row in reader:\n",
    "                if num == 0:\n",
    "                    for point in row:\n",
    "                        if float(point) == -10000 or float(point) == 0:\n",
    "                            invlabel_cnt += 1\n",
    "                            labelc_points.append(float(0))\n",
    "                            labelc_masks.append(0)\n",
    "                        else:\n",
    "                            labelc_points.append(float(point))\n",
    "                            labelc_masks.append(1)\n",
    "                    labelc_points = np.asarray(labelc_points)\n",
    "                    labelc_masks = np.asarray(labelc_masks)\n",
    "                    num += 1\n",
    "        #画像・学習用・ラベル用スケルトンデータをパッケージング\n",
    "        if invinput_cnt >= 1 or invlabel_cnt >= 1:\n",
    "            continue\n",
    "        img_skeleton_pack = []\n",
    "        img_skeleton_pack.append(img_array)\n",
    "        img_skeleton_pack.append(img_mask_array)\n",
    "        img_skeleton_pack.append(input_points)\n",
    "        img_skeleton_pack.append(input_masks)\n",
    "        img_skeleton_pack.append(input_masks2)\n",
    "        img_skeleton_pack.append(label_points)\n",
    "        img_skeleton_pack.append(label_masks)\n",
    "        img_skeleton_pack.append(inputc_points)\n",
    "        img_skeleton_pack.append(inputc_masks)\n",
    "        img_skeleton_pack.append(inputc_masks2)\n",
    "        img_skeleton_pack.append(labelc_points)\n",
    "        img_skeleton_pack.append(labelc_masks)\n",
    "        img_skeleton_pack.append(input_num)\n",
    "        img_skeleton_pack.append(label_num)\n",
    "        #パッケージをデータセットに登録\n",
    "        img_skeleton_sets.append(img_skeleton_pack)\n",
    "    return img_skeleton_sets\n",
    "\n",
    "img_skeleton_sets_train = np.array(make_datasets(train_sean_seqs))\n",
    "img_skeleton_sets_test = np.array(make_datasets(test_sean_seqs))\n",
    "print(\"fin loading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(300, 14) img_skeleton_sets_train shape\n",
      "(50, 14) img_skeleton_sets_test  shape\n"
     ]
    }
   ],
   "source": [
    "#print(\"[0]image     \", img_skeleton_sets_train[0][0].shape, \"\\n\", img_skeleton_sets_train[0][0]) #画像\n",
    "#print(\"[1]image-mask\", img_skeleton_sets_train[0][1].shape, \"\\n\", img_skeleton_sets_train[0][1]) #画像マスク\n",
    "#print(\"[2]input     \", img_skeleton_sets_train[0][2].shape, \"\\n\", img_skeleton_sets_train[0][2]) #骨格(入力)\n",
    "#print(\"[3]input-mask\", img_skeleton_sets_train[0][3].shape, \"\\n\", img_skeleton_sets_train[0][3]) #骨格マスク(入力)\n",
    "#print(\"[4]input-mask2\", img_skeleton_sets_train[0][4].shape, \"\\n\", img_skeleton_sets_train[0][4]) #骨格マスク(入力、時刻なし)\n",
    "#print(\"[5]label     \", img_skeleton_sets_train[0][5].shape, \"\\n\", img_skeleton_sets_train[0][5]) #骨格(ラベル)\n",
    "#print(\"[6]label-mask\", img_skeleton_sets_train[0][6].shape, \"\\n\", img_skeleton_sets_train[0][6]) #骨格マスク(ラベル)\n",
    "#print(\"[7]inputc     \", img_skeleton_sets_train[0][7].shape, \"\\n\", img_skeleton_sets_train[0][7]) #骨格+conf.(入力)\n",
    "#print(\"[8]inputc-mask\", img_skeleton_sets_train[0][8].shape, \"\\n\", img_skeleton_sets_train[0][8]) #骨格+conf.マスク(入力)\n",
    "#print(\"[9]inputc-mask2\", img_skeleton_sets_train[0][9].shape, \"\\n\", img_skeleton_sets_train[0][9]) #骨格+conf.マスク(入力、時刻なし)\n",
    "#print(\"[10]labelc     \", img_skeleton_sets_train[0][10].shape, \"\\n\", img_skeleton_sets_train[0][10]) #骨格+conf.(ラベル)\n",
    "#print(\"[11]labelc-mask\", img_skeleton_sets_train[0][11].shape, \"\\n\", img_skeleton_sets_train[0][11]) #骨格+conf.マスク(ラベル)\n",
    "\n",
    "print(type(img_skeleton_sets_train))\n",
    "print(img_skeleton_sets_train.shape, \"img_skeleton_sets_train shape\")\n",
    "print(img_skeleton_sets_test.shape, \"img_skeleton_sets_test  shape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# 数合わせ用train\n",
    "img_skeleton_sets_train, govage = train_test_split(\n",
    "    img_skeleton_sets_train,\n",
    "    shuffle = False,\n",
    "    train_size = 300\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# 数合わせ用test\n",
    "img_skeleton_sets_test, govage = train_test_split(\n",
    "    img_skeleton_sets_test,\n",
    "    shuffle = False,\n",
    "    train_size = 36\n",
    ")\n",
    "#print(img_skeleton_sets_train.shape, img_skeleton_sets_test.shape, govage.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_train = []\n",
    "imask_train = []\n",
    "input_train = []\n",
    "mask_train = []\n",
    "mask2_train = []\n",
    "label_train = []\n",
    "lmask_train = []\n",
    "inputc_train = []\n",
    "maskc_train = []\n",
    "maskc2_train = []\n",
    "labelc_train = []\n",
    "lmaskc_train = []\n",
    "inum_train = []\n",
    "lnum_train = []\n",
    "\n",
    "img_test = []\n",
    "imask_test = []\n",
    "input_test = []\n",
    "mask_test = []\n",
    "mask2_test = []\n",
    "label_test = []\n",
    "lmask_test = []\n",
    "inputc_test = []\n",
    "maskc_test = []\n",
    "maskc2_test = []\n",
    "labelc_test = []\n",
    "lmaskc_test = []\n",
    "inum_test = []\n",
    "lnum_test = []\n",
    "for i in range(len(img_skeleton_sets_train)):\n",
    "    img_train.append(img_skeleton_sets_train[i][0])\n",
    "    imask_train.append(img_skeleton_sets_train[i][1])\n",
    "    input_train.append(img_skeleton_sets_train[i][2])\n",
    "    mask_train.append(img_skeleton_sets_train[i][3])\n",
    "    mask2_train.append(img_skeleton_sets_train[i][4])    \n",
    "    label_train.append(img_skeleton_sets_train[i][5])\n",
    "    lmask_train.append(img_skeleton_sets_train[i][6])\n",
    "    inputc_train.append(img_skeleton_sets_train[i][7])\n",
    "    maskc_train.append(img_skeleton_sets_train[i][8])\n",
    "    maskc2_train.append(img_skeleton_sets_train[i][9])    \n",
    "    labelc_train.append(img_skeleton_sets_train[i][10])\n",
    "    lmaskc_train.append(img_skeleton_sets_train[i][11])\n",
    "    inum_train.append(img_skeleton_sets_train[i][12])\n",
    "    lnum_train.append(img_skeleton_sets_train[i][13])\n",
    "for i in range(len(img_skeleton_sets_test)):\n",
    "    img_test.append(img_skeleton_sets_test[i][0])\n",
    "    imask_test.append(img_skeleton_sets_test[i][1])\n",
    "    input_test.append(img_skeleton_sets_test[i][2])\n",
    "    mask_test.append(img_skeleton_sets_test[i][3])\n",
    "    mask2_test.append(img_skeleton_sets_train[i][4])\n",
    "    label_test.append(img_skeleton_sets_test[i][5])\n",
    "    lmask_test.append(img_skeleton_sets_test[i][6])\n",
    "    inputc_test.append(img_skeleton_sets_test[i][7])\n",
    "    maskc_test.append(img_skeleton_sets_test[i][8])\n",
    "    maskc2_test.append(img_skeleton_sets_train[i][9])\n",
    "    labelc_test.append(img_skeleton_sets_test[i][10])\n",
    "    lmaskc_test.append(img_skeleton_sets_test[i][11])\n",
    "    inum_test.append(img_skeleton_sets_test[i][12])\n",
    "    lnum_test.append(img_skeleton_sets_test[i][13])\n",
    "    \n",
    "#print(img_train[0])#print(imask_train[0])#print(input_train[0])#print(mask_train[0])#print(mask_train2[0])\n",
    "#print(label_train[0])#print(lmask_train[0])#print(inputc_train[0])#print(maskc_train[0])#print(maskc_train2[0])\n",
    "#print(labelc_train[0])#print(lmaskc_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_trainF = np.array(img_train).astype('float32')/10000\n",
    "img_testF = np.array(img_test).astype('float32')/10000\n",
    "imask_trainF = np.array(imask_train).astype('float32')\n",
    "imask_testF = np.array(imask_test).astype('float32')\n",
    "input_trainF = np.array(input_train).astype('float32')/100\n",
    "input_testF = np.array(input_test).astype('float32')/100\n",
    "mask_trainF = np.array(mask_train).astype('float32')\n",
    "mask_testF = np.array(mask_test).astype('float32')\n",
    "mask2_trainF = np.array(mask2_train).astype('float32')\n",
    "mask2_testF = np.array(mask2_test).astype('float32')\n",
    "label_trainF = np.array(label_train).astype('float32')/100\n",
    "label_testF = np.array(label_test).astype('float32')/100\n",
    "lmask_trainF = np.array(lmask_train).astype('float32')\n",
    "lmask_testF = np.array(lmask_test).astype('float32')\n",
    "inputc_trainF = np.array(inputc_train).astype('float32')/100\n",
    "inputc_testF = np.array(inputc_test).astype('float32')/100\n",
    "maskc_trainF = np.array(maskc_train).astype('float32')\n",
    "maskc_testF = np.array(maskc_test).astype('float32')\n",
    "maskc2_trainF = np.array(maskc2_train).astype('float32')\n",
    "maskc2_testF = np.array(maskc2_test).astype('float32')\n",
    "labelc_trainF = np.array(labelc_train).astype('float32')/100\n",
    "labelc_testF = np.array(labelc_test).astype('float32')/100\n",
    "lmaskc_trainF = np.array(lmaskc_train).astype('float32')\n",
    "lmaskc_testF = np.array(lmaskc_test).astype('float32')\n",
    "inum_trainF = np.array(inum_train).astype('float32')\n",
    "inum_testF = np.array(inum_test).astype('float32')\n",
    "lnum_trainF = np.array(lnum_train).astype('float32')\n",
    "lnum_testF = np.array(lnum_test).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image        train test  (300, 36, 36) (50, 36, 36)\n",
      "image-mask   train test  (300, 36, 36) (50, 36, 36)\n",
      "input        train test  (300, 43) (50, 43)\n",
      "input-mask   train test  (300, 43) (50, 43)\n",
      "input-mask2  train test  (300, 42) (50, 42)\n",
      "label        train test  (300, 42) (50, 42)\n",
      "label-mask   train test  (300, 42) (50, 42)\n",
      "inputc       train test  (300, 64) (50, 64)\n",
      "inputc-mask  train test  (300, 64) (50, 64)\n",
      "inputc-mask2 train test  (300, 63) (50, 63)\n",
      "labelc       train test  (300, 63) (50, 63)\n",
      "labelc-mask  train test  (300, 63) (50, 63)\n",
      "inum         train test  (300, 5) (50, 5)\n",
      "lnum         train test  (300, 5) (50, 5)\n"
     ]
    }
   ],
   "source": [
    "print(\"image        train test \", img_trainF.shape, img_testF.shape)\n",
    "print(\"image-mask   train test \", imask_trainF.shape, imask_testF.shape)\n",
    "print(\"input        train test \", input_trainF.shape, input_testF.shape)\n",
    "print(\"input-mask   train test \", mask_trainF.shape, mask_testF.shape)\n",
    "print(\"input-mask2  train test \", mask2_trainF.shape, mask2_testF.shape)\n",
    "print(\"label        train test \", label_trainF.shape, label_testF.shape)\n",
    "print(\"label-mask   train test \", lmask_trainF.shape, lmask_testF.shape)\n",
    "print(\"inputc       train test \", inputc_trainF.shape, inputc_testF.shape)\n",
    "print(\"inputc-mask  train test \", maskc_trainF.shape, maskc_testF.shape)\n",
    "print(\"inputc-mask2 train test \", maskc2_trainF.shape, maskc2_testF.shape)\n",
    "print(\"labelc       train test \", labelc_trainF.shape, labelc_testF.shape)\n",
    "print(\"labelc-mask  train test \", lmaskc_trainF.shape, lmaskc_testF.shape)\n",
    "print(\"inum         train test \", inum_trainF.shape, inum_testF.shape)\n",
    "print(\"lnum         train test \", lnum_trainF.shape, lnum_testF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor()]#,torchvision.transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydatasets(torch.utils.data.Dataset):\n",
    "    def __init__(self, img, immask, input_,  mask, mask2, label, lmask, inputc,  maskc, maskc2, labelc, lmaskc, inum, lnum, transform = None):\n",
    "        self.transform = transform\n",
    "        #self.transform2 = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "        self.img = img\n",
    "        self.immask = immask\n",
    "        self.input = input_\n",
    "        self.mask = mask\n",
    "        self.mask2 = mask2\n",
    "        self.label = label\n",
    "        self.lmask = lmask\n",
    "        self.inputc = inputc\n",
    "        self.maskc = maskc\n",
    "        self.maskc2 = maskc2\n",
    "        self.labelc = labelc\n",
    "        self.lmaskc = lmaskc\n",
    "        self.inum = inum\n",
    "        self.lnum = lnum\n",
    "        \n",
    "        self.datanum = input_.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.datanum\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #batch_set = []\n",
    "        \n",
    "        i_img = self.img[idx]\n",
    "        i_immask = self.immask[idx]\n",
    "        i_input = self.input[idx]\n",
    "        i_mask = self.mask[idx]\n",
    "        i_mask2 = self.mask2[idx]\n",
    "        i_label = self.label[idx]\n",
    "        i_lmask = self.lmask[idx]\n",
    "        i_inputc = self.inputc[idx]\n",
    "        i_maskc = self.maskc[idx]\n",
    "        i_maskc2 = self.maskc2[idx]\n",
    "        i_labelc = self.labelc[idx]\n",
    "        i_lmaskc = self.lmaskc[idx]\n",
    "        i_inum = self.inum[idx]\n",
    "        i_lnum = self.lnum[idx]\n",
    "        \n",
    "        #print(out_label)\n",
    "        #print(type(i_label))\n",
    "        o_img = np.array(i_img.astype(np.float32))\n",
    "        o_immask = np.array(i_immask.astype(np.float32))\n",
    "        o_input = np.array(i_input.astype(np.float32))\n",
    "        o_mask = np.array(i_mask.astype(np.float32))\n",
    "        o_mask2 = np.array(i_mask2.astype(np.float32))\n",
    "        o_label = np.array(i_label.astype(np.float32))\n",
    "        o_lmask = np.array(i_lmask.astype(np.float32))\n",
    "        o_inputc = np.array(i_inputc.astype(np.float32))\n",
    "        o_maskc = np.array(i_maskc.astype(np.float32))\n",
    "        o_maskc2 = np.array(i_maskc2.astype(np.float32))\n",
    "        o_labelc = np.array(i_labelc.astype(np.float32))\n",
    "        o_lmaskc = np.array(i_lmaskc.astype(np.float32))\n",
    "        o_inum = np.array(i_inum.astype(np.float32))\n",
    "        o_lnum = np.array(i_lnum.astype(np.float32))\n",
    "        #out_label.append(i_label.astype(np.float32))\n",
    "        #print(type(out_label))\n",
    "\n",
    "        if self.transform:\n",
    "            #out_data = self.transform(i_data)\n",
    "            o_img = self.transform(o_img)\n",
    "            o_immask = self.transform(o_immask)\n",
    "            #out_label = self.transform2(out_label)\n",
    "        \n",
    "        #batch_set.append(out_data)\n",
    "        #batch_set.append(out_label)\n",
    "        #batch_set.append(out_img)\n",
    "        #batch_set.append(out_mask)\n",
    "        #batch_set.append(out_lmask)\n",
    "\n",
    "        return o_img, o_immask, o_input, o_mask, o_mask2, o_label, o_lmask, o_inputc, o_maskc, o_maskc2, o_labelc, o_lmaskc, o_inum, o_lnum\n",
    "        #return batch_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = Mydatasets(\n",
    "    img = img_trainF, immask = imask_trainF,\n",
    "    input_ = input_trainF, mask = mask_trainF, mask2 = mask2_trainF,\n",
    "    label = label_trainF, lmask = lmask_trainF,\n",
    "    inputc = inputc_trainF, maskc = maskc_trainF, maskc2 = maskc2_trainF,\n",
    "    labelc = labelc_trainF, lmaskc = lmaskc_trainF, inum = inum_trainF, lnum = lnum_trainF, transform = trans)\n",
    "testset = Mydatasets(\n",
    "    img = img_testF, immask = imask_testF,\n",
    "    input_ = input_testF, mask = mask_testF, mask2 = mask2_testF,\n",
    "    label = label_testF, lmask = lmask_testF,\n",
    "    inputc = inputc_testF, maskc = maskc_testF, maskc2 = maskc2_testF,\n",
    "    labelc = labelc_testF, lmaskc = lmaskc_testF, inum = inum_testF, lnum = lnum_testF, transform = trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 25\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = BATCH_SIZE,\n",
    "                        shuffle = True, num_workers = 0)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = BATCH_SIZE,\n",
    "                        shuffle = False, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ignore(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, activation = lambda x: x):\n",
    "        '''\n",
    "        引数:\n",
    "            input_dim: 入力次元\n",
    "            output_dim: 出力次元\n",
    "            activation: 活性化関数\n",
    "        パラメータ:\n",
    "            W: 重み\n",
    "            b: バイアス\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.W = nn.Parameter(torch.Tensor(np.random.normal(size = (output_dim, input_dim))))\n",
    "        self.b = nn.Parameter(torch.Tensor(np.zeros(output_dim)))\n",
    "        self.activation = activation\n",
    "    def forward(self, x, mask):\n",
    "        \n",
    "        out = torch.empty_like(x).to(torch.device(\"cuda:0\"))\n",
    "        masked_x = torch.mul(x, mask)\n",
    "        \n",
    "        try:\n",
    "            m_size = torch.Tensor(mask.size()[1]).to(torch.device(\"cuda:0\"))\n",
    "            m_sum = torch.sum(mask, 1).to(torch.device(\"cuda:0\"))\n",
    "            rate = (m_size.size()[0] / m_sum).to(torch.device(\"cuda:0\"))\n",
    "            for b in range(out.size()[0]):\n",
    "                out[b] = torch.add(torch.mul(rate[b], torch.sum(torch.mul(masked_x[b], self.W), 1)), self.b)\n",
    "        except IndexError:\n",
    "            m_size = torch.Tensor(mask.size()).to(torch.device(\"cuda:0\"))\n",
    "            m_sum = torch.sum(mask).to(torch.device(\"cuda:0\"))\n",
    "            rate = (m_size.size()[0] / m_sum).to(torch.device(\"cuda:0\"))\n",
    "            out = torch.add(torch.mul(rate, torch.sum(torch.mul(masked_x, self.W))), self.b)\n",
    "        \n",
    "        return self.activation(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandGraspRecolletion(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HandGraspRecolletion, self).__init__()\n",
    "        #CNN\n",
    "        self.pool = nn.AvgPool2d(2, stride=2)\n",
    "        self.conv1 = nn.Conv2d(1,16,3)\n",
    "        self.conv2 = nn.Conv2d(16,32,3)\n",
    "        self.bn2d1 = nn.BatchNorm2d(16)\n",
    "        self.bn2d2 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.fcm = Ignore(32 * 7 * 7 + 43, 32 * 7 * 7 + 43)\n",
    "        self.fcm_c = Ignore(32 * 7 * 7 + 64, 32 * 7 * 7 + 64)\n",
    "        self.bnm = nn.BatchNorm1d(32 * 7 * 7 + 43)\n",
    "        self.bnm_c = nn.BatchNorm1d(32 * 7 * 7 + 64)\n",
    "        #fully connect for hand Location(x,y,z)\n",
    "        self.fcL1 = nn.Linear(32 * 7 * 7 + 43, 300)\n",
    "        self.fcL1_c = nn.Linear(32 * 7 * 7 + 64, 300)\n",
    "        self.fcL2 = nn.Linear(300, 30)\n",
    "        self.fcL3 = nn.Linear(30, 3)        \n",
    "        self.bnL1 = nn.BatchNorm1d(300)\n",
    "        self.bnL2 = nn.BatchNorm1d(30)\n",
    "        #fully connect for hand Pose Descriptor(8 properties)\n",
    "        self.fcPD1 = nn.Linear(32 * 7 * 7 + 43, 300)\n",
    "        self.fcPD1_c = nn.Linear(32 * 7 * 7 + 64, 300)\n",
    "        self.fcPD2 = nn.Linear(300, 60)\n",
    "        self.fcPD3 = nn.Linear(60, 8)\n",
    "        self.bnPD1 = nn.BatchNorm1d(300)\n",
    "        self.bnPD2 = nn.BatchNorm1d(60)\n",
    "        \n",
    "        #Autoencoder\n",
    "        self.mask = Ignore(63, 63)#self.mask = Ignore(84, 84)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense_enc1 = nn.Linear(63, 32)#self.dense_enc1 = nn.Linear(84, 40)\n",
    "        self.bn1 = nn.BatchNorm1d(32)#(40)\n",
    "        self.dense_enc2 = nn.Linear(32, 16)#self.bn1 = nn.BatchNorm1d(40, 18)\n",
    "        self.bn2 = nn.BatchNorm1d(16)#self.bn2 = nn.BatchNorm1d(18)\n",
    "        self.dense_enc3 = nn.Linear(16,8)#self.dense_enc3 = nn.Linear(18, 8)\n",
    "    \n",
    "        self.dense_dec1 = nn.Linear(8,16)\n",
    "        self.bn4 = nn.BatchNorm1d(16)\n",
    "        self.dense_dec2 = nn.Linear(16, 26)#self.dense_dec2 = nn.Linear(16, 32)\n",
    "        self.bn5 = nn.BatchNorm1d(26)#self.bn5 = nn.BatchNorm1d(32)\n",
    "        self.drop1 = nn.Dropout(p=0.2)\n",
    "        self.dense_dec3 = nn.Linear(26, 42)#self.dense_dec3 = nn.Linear(32, 63)\n",
    "\n",
    "    def cnn_part(self, im, imm, pose, posem):\n",
    "        #Conv2d 1\n",
    "        im = self.conv1(im)\n",
    "        imm = self.conv1(imm)\n",
    "        imm_conv1 = imm.clone().detach().to(torch.device(\"cuda:0\"))\n",
    "        for c in range(imm.size()[1]):\n",
    "            mode, ind = torch.mode(torch.reshape(imm[0][c].clone().detach(), (-1, imm.size()[2] * imm.size()[3])))\n",
    "            imm_conv1[:,c] = torch.sub(imm_conv1[:,c], mode.item())\n",
    "        #ReLU→BatchNorm2d 1\n",
    "        im = self.bn2d1(self.relu(im))\n",
    "        #AvgPool2d\n",
    "        im = self.pool(im)\n",
    "        imm = self.pool(imm_conv1)\n",
    "        #Conv2d 2\n",
    "        im = self.conv2(im)\n",
    "        imm = self.conv2(imm)\n",
    "        imm_conv2 = imm.clone().detach().to(torch.device(\"cuda:0\"))\n",
    "        for c in range(imm.size()[1]):\n",
    "            mode, ind = torch.mode(torch.reshape(imm[0][c].clone().detach(), (-1, imm.size()[2] * imm.size()[3])))\n",
    "            imm_conv2[:,c] = torch.sub(imm_conv2[:,c], mode.item())\n",
    "        #ReLU→BatchNorm2d 2\n",
    "        im = self.bn2d2(self.relu(im))\n",
    "        #AvgPool2d\n",
    "        im = self.pool(im)\n",
    "        imm = self.pool(imm_conv2)\n",
    "        #1次元ベクトル化\n",
    "        im = im.view(im.size()[0], -1)\n",
    "        imm = imm.view(imm.size()[0], -1)\n",
    "        #マスク再構築(0→1, 0以外→0)\n",
    "        imm = torch.logical_not(torch.logical_and(imm, torch.tensor([True]).to(torch.device(\"cuda:0\")))).float()\n",
    "        #骨格データと結合\n",
    "        x = torch.cat([im, pose], axis = -1)\n",
    "        m = torch.cat([imm, posem], axis = -1)\n",
    "        #MaskedLinear\n",
    "        #print(pose[0].size()[0])\n",
    "        if pose[0].size()[0] == 64:     #case: with conf.\n",
    "            x = self.fcm_c(x, m)\n",
    "            x = self.bnm_c(self.relu(x))\n",
    "            xL = self.fcL1_c(x)\n",
    "            xPD = self.fcPD1_c(x)\n",
    "        else:                           #case: no conf.\n",
    "            x = self.fcm(x, m)\n",
    "            x = self.bnm(self.relu(x))\n",
    "            xL = self.fcL1(x)\n",
    "            xPD = self.fcPD1(x)\n",
    "        xL = self.bnL1(self.relu(xL))\n",
    "        xPD = self.bnPD1(self.relu(xPD))\n",
    "        xL = self.fcL2(xL)\n",
    "        xPD = self.fcPD2(xPD)\n",
    "        xL = self.bnL2(self.relu(xL))\n",
    "        xPD = self.bnPD2(self.relu(xPD))\n",
    "        xL = self.fcL3(xL)\n",
    "        xPD = self.fcPD3(xPD)\n",
    "        return xL, xPD\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        #x = torch.div(x, 100.)\n",
    "        #x = self.mask(x, m)\n",
    "        x = self.dense_enc1(x)\n",
    "        x = self.bn1(self.relu(x))\n",
    "        x = self.dense_enc2(x)\n",
    "        x = self.bn2(self.relu(x))\n",
    "        x = self.dense_enc3(x)\n",
    "        return x\n",
    "\n",
    "    def decoder(self, x):\n",
    "        x = self.tanh(x)\n",
    "        x = self.dense_dec1(x)\n",
    "        x = self.bn4(self.relu(x))\n",
    "        x = self.dense_dec2(x)\n",
    "        x = self.bn5(self.relu(x))\n",
    "        #x = self.drop1(x)\n",
    "        x = self.dense_dec3(x)\n",
    "        #x = self.mask(x, m)\n",
    "        #x = torch.mul(x, 100.)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, im, imm, pose, posem, lbc=None):\n",
    "        if lbc != None:\n",
    "            xLoc, xPD = self.cnn_part(im, imm, pose, posem)\n",
    "            lbcPD = self.encoder(lbc)\n",
    "            return xLoc, xPD, lbcPD\n",
    "        else:\n",
    "            xLoc, xPD = self.cnn_part(im, imm, pose, posem)\n",
    "            xPose = self.decoder(xPD)\n",
    "            return xLoc, xPose, xPD\n",
    "        \n",
    "    #    if x != None and z == None:\n",
    "    #        z = self.encoder(x)\n",
    "    #        x = self.decoder(z)\n",
    "    #    elif x == None and z != None:\n",
    "    #        print(\"decoder only\")\n",
    "    #        x = self.decoder(z)\n",
    "    #    return x, z\n",
    "\n",
    "    #def forward(self, x=None, z=None):\n",
    "    #    if x != None and z == None:\n",
    "    #        z = self.encoder(x)\n",
    "    #        x = self.decoder(z)\n",
    "    #    elif x == None and z != None:\n",
    "    #        print(\"decoder only\")\n",
    "    #        x = self.decoder(z)\n",
    "    #    return x, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskMSELoss(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MaskMSELoss, self).__init__()\n",
    "        #self.margin = margin\n",
    "\n",
    "    def forward(self, inputs, labels, imasks2, lmasks):\n",
    "        ##m_size = lmasks.size()[1]     #print(\"m_size:\",m_size)\n",
    "        #3m_sum = torch.sum(lmasks, 1)  #print(\"m_sum:\",m_sum)\n",
    "        \n",
    "        #無効値をマスクがけして減った要素分の比率をlossにかけて増幅する\n",
    "        #rate = (m_size / m_sum).reshape(BATCH_SIZE,-1) #print(\"rate:\",rate)\n",
    "        #for i in range(rate.size()[0]):\n",
    "        #    #print(rate[i].item())\n",
    "        #    if np.isinf(rate[i].item()):\n",
    "        #        rate[i] = 0. #print(\"inf!\")\n",
    "        ##print(\"rate+:\", rate)\n",
    "        \n",
    "        #imask = torch.\n",
    "        \n",
    "        masked_in = torch.mul(torch.mul(inputs, imasks2), lmasks)\n",
    "        masked_lb = torch.mul(torch.mul(labels, imasks2), lmasks)\n",
    "        \n",
    "        #loss = torch.sub(masked_in, masked_lb)\n",
    "        #print(\"sub:\",loss)\n",
    "        #loss = torch.pow(loss, 2)\n",
    "        #print(\"pow:\",loss)\n",
    "        #loss = torch.sum(loss, 1)\n",
    "        #print(\"sum:\",loss)\n",
    "        #loss = torch.div(loss, m_sum)\n",
    "        #print(\"div:\",loss)\n",
    "        #loss = torch.mul(rate, loss)\n",
    "        #print(\"gain2:\",loss)\n",
    "        #loss = torch.mean(loss)\n",
    "        #print(\"mean:\",loss)\n",
    "        \n",
    "        loss = torch.sub(masked_in, masked_lb)\n",
    "        loss = torch.pow(loss, 2)\n",
    "        #loss = torch.mul(loss, rate)\n",
    "        loss = torch.mean(loss, 1)\n",
    "        loss = torch.mean(loss)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.001\n",
    "#WEIGHT_DECAY = 0.0001\n",
    "#MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 0.\n",
    "MOMENTUM = 0.\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "device_cpu = torch.device('cpu')\n",
    "#net = Net().to(device)\n",
    "#ae = Autoencoder()\n",
    "net = HandGraspRecolletion().to(device)\n",
    "net.load_state_dict(torch.load(PATH + \"\\\\AEmodel_epoch3900_trainloss_6.893233966827393\"))\n",
    "#net.load_state_dict(torch.load(PATH + \"\\\\test11\\\\model_train\\\\model_epoch3300_trainloss_62853.38125\"))\n",
    "#net.load_state_dict(torch.load(PATH + \"\\\\hand_AE_model\"))\n",
    "if True:\n",
    "    for p in net.parameters(): # freeze all model parameters\n",
    "        p.requires_grad = False\n",
    "    for p in net.conv1.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in net.conv2.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in net.bn2d1.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in net.bn2d2.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in net.fcm.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in net.bnm.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in net.fcm_c.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in net.bnm_c.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in net.fcL1.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in net.fcL1_c.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in net.fcL2.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in net.fcL3.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in net.bnL1.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in net.bnL2.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in net.fcPD1.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in net.fcPD1_c.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in net.fcPD2.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in net.fcPD3.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in net.bnPD1.parameters():\n",
    "        p.requires_grad = True\n",
    "    for p in net.bnPD2.parameters():\n",
    "        p.requires_grad = True    \n",
    "criterionM = MaskMSELoss()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "train_loss_value=[]      #trainingのlossを保持するlist\n",
    "test_loss_value=[]       #testのlossを保持するlist\n",
    "\n",
    "train_input_value = []\n",
    "train_output_value = []\n",
    "train_desc_value = []\n",
    "train_handloc_value = []\n",
    "train_ldesc_value = []\n",
    "train_lhandloc_value = []\n",
    "train_inum = []\n",
    "test_input_value = []\n",
    "test_output_value = []\n",
    "test_desc_value = []\n",
    "test_handloc_value = []\n",
    "test_ldesc_value = []\n",
    "test_lhandloc_value = []\n",
    "test_inum = []\n",
    "\n",
    "train_size = input_trainF.shape[0]\n",
    "test_size = input_testF.shape[0]\n",
    "\n",
    "max_train_loss_value = 0.\n",
    "max_test_loss_value = 0.\n",
    "min_test_loss_value = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\"conv1.weight\",\"conv1.bias\",\"conv2.weight\",\"conv2.bias\",\"bn2d1.weight\",\"bn2d1.bias\",\"bn2d2.weight\",\\\n",
    "        \"bn2d2.bias\",\"fcm.W\",\"fcm.b\",\"bnm.weight\",\"bnm.bias\",\"fcL1.weight\",\"fcL1.bias\",\"fcL2.weight\",\\\n",
    "        \"fcL2.bias\",\"fcL3.weight\",\"fcL3.bias\",\"bnL1.weight\",\"bnL1.bias\",\"bnL2.weight\",\"bnL2.bias\",\\\n",
    "        \"fcPD1.weight\",\"fcPD1.bias\",\"fcPD2.weight\",\"fcPD2.bias\",\"fcPD3.weight\",\"fcPD3.bias\",\"bnPD1.weight\",\\\n",
    "        \"bnPD1.bias\",\"bnPD2.weight\",\"bnPD2.bias\",\"mask.W\",\"mask.b\",\"dense_enc1.weight\",\"dense_enc1.bias\",\\\n",
    "        \"bn1.weight\",\"bn1.bias\",\"dense_enc2.weight\",\"dense_enc2.bias\",\"bn2.weight\",\"bn2.bias\",\\\n",
    "        \"dense_enc3.weight\",\"dense_enc3.bias\",\"dense_dec1.weight\",\"dense_dec1.bias\",\"bn4.weight\",\"bn4.bias\",\\\n",
    "        \"dense_dec2.weight\",\"dense_dec2.bias\",\"bn5.weight\",\"bn5.bias\",\"dense_dec3.weight\",\"dense_dec3.bias\"]\n",
    "#for k, p in zip(keys, net.parameters()):\n",
    "#    print(k, \"\\n\", p, \"\\n\")\n",
    "#for k, p in zip(keys, net.parameters()):\n",
    "#    print(k, \"requires_grad = \", p.requires_grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#出力値保存\n",
    "#出力値保存\n",
    "def outcsv(n_epoch, inputs, descs, hlocs, nums, mode, outputs=None, ldescs=None, lhlocs=None):\n",
    "    for b in range(len(inputs[0])):\n",
    "        adrs0 = int(nums[0][b][0])\n",
    "        adrs1 = int(nums[0][b][1])\n",
    "        adrs2 = int(nums[0][b][2])\n",
    "        adrs3 = int(nums[0][b][3])\n",
    "        adrs4 = int(nums[0][b][4])\n",
    "        fname = f\"dataset_hand_mm_{adrs0}_{adrs1}_{adrs2:04}_{adrs3:08}_{adrs4:04}.csv\"\n",
    "        os.makedirs(PATH + f'\\\\outputs\\\\{n_epoch:05}', exist_ok=True)\n",
    "        os.makedirs(PATH + f'\\\\outputs\\\\{n_epoch:05}\\\\' + mode, exist_ok=True)\n",
    "        os.makedirs(PATH + f'\\\\outputs\\\\{n_epoch:05}\\\\' + mode + \"\\\\input\", exist_ok=True)\n",
    "        os.makedirs(PATH + f'\\\\outputs\\\\{n_epoch:05}\\\\' + mode + \"\\\\output\", exist_ok=True)\n",
    "        os.makedirs(PATH + f'\\\\outputs\\\\{n_epoch:05}\\\\' + mode + \"\\\\desc\", exist_ok=True)\n",
    "        os.makedirs(PATH + f'\\\\outputs\\\\{n_epoch:05}\\\\' + mode + \"\\\\hloc\", exist_ok=True)\n",
    "        os.makedirs(PATH + f'\\\\outputs\\\\{n_epoch:05}\\\\' + mode + \"\\\\ldesc\", exist_ok=True)\n",
    "        os.makedirs(PATH + f'\\\\outputs\\\\{n_epoch:05}\\\\' + mode + \"\\\\lhloc\", exist_ok=True)\n",
    "        os.makedirs(PATH + f'\\\\outputs\\\\{n_epoch:05}\\\\' + mode + \"\\\\img\", exist_ok = True)\n",
    "        os.makedirs(PATH + f'\\\\outputs\\\\{n_epoch:05}\\\\' + mode + \"\\\\img\\\\input\", exist_ok = True)\n",
    "        os.makedirs(PATH + f'\\\\outputs\\\\{n_epoch:05}\\\\' + mode + \"\\\\img\\\\output\", exist_ok = True)\n",
    "        #print(fname)\n",
    "        with open(PATH + f'\\\\outputs\\\\{n_epoch:05}\\\\' + mode + \"\\\\input\\\\\" + fname, mode='w') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(inputs[0][b])\n",
    "        with open(PATH + f'\\\\outputs\\\\{n_epoch:05}\\\\' + mode + \"\\\\desc\\\\\" + fname, mode='w') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(descs[0][b])\n",
    "        with open(PATH + f'\\\\outputs\\\\{n_epoch:05}\\\\' + mode + \"\\\\hloc\\\\\" + fname, mode='w') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(hlocs[0][b])\n",
    "        if ldescs != None:\n",
    "            with open(PATH + f'\\\\outputs\\\\{n_epoch:05}\\\\' + mode + \"\\\\ldesc\\\\\" + fname, mode='w') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(ldescs[0][b])\n",
    "            with open(PATH + f'\\\\outputs\\\\{n_epoch:05}\\\\' + mode + \"\\\\lhloc\\\\\" + fname, mode='w') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(lhlocs[0][b])\n",
    "        else:\n",
    "            with open(PATH + f'\\\\outputs\\\\{n_epoch:05}\\\\' + mode + \"\\\\output\\\\\" + fname, mode='w') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(outputs[0][b])\n",
    "        \n",
    "    #print(\"fin save.\")\n",
    "    return\n",
    "\n",
    "def outcsvold(n_epoch, train_input_value, train_output_value, train_desc_value, train_handloc_value,\\\n",
    "           test_input_value, test_output_value, test_desc_value, test_handloc_value):\n",
    "    with open(PATH + \"\\\\outputs\\\\network_outs_\" + str(n_epoch) + \".csv\", mode='w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"train_test\",\" \"])\n",
    "        #for i in range(len(train_input_value)):                      #epoch数 loop 1000\n",
    "        writer.writerow([\"epoch:\" + str(n_epoch),\" \"])\n",
    "        for j in range(len(train_input_value[0])):               #batch size数 loop 10\n",
    "            writer.writerow([\"batch:\" + str(j+1),\" \"])\n",
    "            input_x = []\n",
    "            input_y = []\n",
    "            input_z = []\n",
    "            output_x = []\n",
    "            output_y = []\n",
    "            output_z = []\n",
    "            descriptor = []\n",
    "            handlocation = []\n",
    "            for k in range(int(len(train_input_value[0][j])/3)): #data size / 2 loop (x, y分離) 21(42)\n",
    "                input_x.append(train_input_value[0][j][k*3+0].item())\n",
    "                input_y.append(train_input_value[0][j][k*3+1].item())\n",
    "                input_z.append(train_input_value[0][j][k*3+2].item())\n",
    "                output_x.append(train_output_value[0][j][k*3+0].item())\n",
    "                output_y.append(train_output_value[0][j][k*3+1].item())\n",
    "                output_z.append(train_output_value[0][j][k*3+2].item())\n",
    "            for l in range(len(train_desc_value[0][j])):\n",
    "                descriptor.append(train_desc_value[0][j][l].item())\n",
    "            for l in range(len(train_handloc_value[0][j])):\n",
    "                handlocation.append(train_handloc_value[0][j][l].item())\n",
    "            writer.writerow(input_x)\n",
    "            writer.writerow(input_y)\n",
    "            writer.writerow(input_z)\n",
    "            writer.writerow(output_x)\n",
    "            writer.writerow(output_y)\n",
    "            writer.writerow(output_z)\n",
    "            writer.writerow(descriptor)\n",
    "            writer.writerow(handlocation)\n",
    "        writer.writerow([\"test_test\",\" \"])\n",
    "        #for i in range(len(test_input_value)):                      #epoch数 loop 1000\n",
    "        writer.writerow([\"epoch:\" + str(n_epoch),\" \"])\n",
    "        for j in range(len(test_input_value[0])):               #batch size数 loop 10\n",
    "            writer.writerow([\"batch:\" + str(j+1),\" \"])\n",
    "            input_x = []\n",
    "            input_y = []\n",
    "            input_z = []\n",
    "            output_x = []\n",
    "            output_y = []\n",
    "            output_z = []\n",
    "            descriptor = []\n",
    "            handlocation = []\n",
    "            for k in range(int(len(test_input_value[0][j])/3)): #data size / 2 loop (x, y分離) 21(42)\n",
    "                input_x.append(test_input_value[0][j][k*3+0].item())\n",
    "                input_y.append(test_input_value[0][j][k*3+1].item())\n",
    "                input_z.append(test_input_value[0][j][k*3+2].item())\n",
    "                output_x.append(test_output_value[0][j][k*3+0].item())\n",
    "                output_y.append(test_output_value[0][j][k*3+1].item())\n",
    "                output_z.append(test_output_value[0][j][k*3+2].item())\n",
    "            for l in range(len(test_desc_value[0][j])):\n",
    "                descriptor.append(test_desc_value[0][j][l].item())\n",
    "            for l in range(len(test_handloc_value[0][j])):\n",
    "                handlocation.append(test_handloc_value[0][j][l].item())\n",
    "            writer.writerow(input_x)\n",
    "            writer.writerow(input_y)\n",
    "            writer.writerow(input_z)\n",
    "            writer.writerow(output_x)\n",
    "            writer.writerow(output_y)\n",
    "            writer.writerow(output_z)\n",
    "            writer.writerow(descriptor)\n",
    "            writer.writerow(handlocation)\n",
    "        print(\"fin save.\")\n",
    "    return\n",
    "\n",
    "def saveloss(train, test):\n",
    "    with open(PATH + \"\\\\outputs\\\\loss_values.csv\", mode='a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "test_train\n",
      "train mean loss=1.340554843346278\n",
      "test_test\n",
      "test mean loss=1171.4972839355469\n",
      "epoch 2\n",
      "test_train\n",
      "train mean loss=1.1575113733609517\n",
      "test_test\n",
      "test mean loss=1168.6031494140625\n",
      "epoch 3\n",
      "test_train\n",
      "train mean loss=1.344244549671809\n",
      "test_test\n",
      "test mean loss=1166.699462890625\n",
      "epoch 4\n",
      "test_train\n",
      "train mean loss=1.450565795103709\n",
      "test_test\n",
      "test mean loss=1167.0792236328125\n",
      "epoch 5\n",
      "test_train\n",
      "train mean loss=0.9633370389540991\n",
      "test_test\n",
      "test mean loss=1162.1897888183594\n",
      "epoch 6\n",
      "test_train\n",
      "train mean loss=0.7255329042673111\n",
      "test_test\n",
      "test mean loss=1160.7520751953125\n",
      "epoch 7\n",
      "test_train\n",
      "train mean loss=0.6276263271768888\n",
      "test_test\n",
      "test mean loss=1157.5673828125\n",
      "epoch 8\n",
      "test_train\n",
      "train mean loss=0.7027222911516825\n",
      "test_test\n",
      "test mean loss=1158.9725341796875\n",
      "epoch 9\n",
      "test_train\n",
      "train mean loss=2.8810669283072152\n",
      "test_test\n",
      "test mean loss=1162.438232421875\n",
      "epoch 10\n",
      "test_train\n",
      "train mean loss=0.4423562064766884\n",
      "test_test\n",
      "test mean loss=1156.9341125488281\n",
      "epoch 11\n",
      "test_train\n",
      "train mean loss=0.5371870348850886\n",
      "test_test\n",
      "test mean loss=1157.6077270507812\n",
      "epoch 12\n",
      "test_train\n",
      "train mean loss=6.075703740119934\n",
      "test_test\n",
      "test mean loss=1176.5227661132812\n",
      "epoch 13\n",
      "test_train\n",
      "train mean loss=2.545915683110555\n",
      "test_test\n",
      "test mean loss=1164.1288452148438\n",
      "epoch 14\n",
      "test_train\n",
      "train mean loss=1.7792099118232727\n",
      "test_test\n",
      "test mean loss=1161.5296630859375\n",
      "epoch 15\n",
      "test_train\n",
      "train mean loss=0.6716047078371048\n",
      "test_test\n",
      "test mean loss=1154.3336486816406\n",
      "epoch 16\n",
      "test_train\n",
      "train mean loss=0.4969358965754509\n",
      "test_test\n",
      "test mean loss=1152.1080932617188\n",
      "epoch 17\n",
      "test_train\n",
      "train mean loss=0.4090464537342389\n",
      "test_test\n",
      "test mean loss=1154.15087890625\n",
      "epoch 18\n",
      "test_train\n",
      "train mean loss=0.363296036918958\n",
      "test_test\n",
      "test mean loss=1154.2521362304688\n",
      "epoch 19\n",
      "test_train\n",
      "train mean loss=0.36986183126767475\n",
      "test_test\n",
      "test mean loss=1153.139404296875\n",
      "epoch 20\n",
      "test_train\n",
      "train mean loss=0.3927798569202423\n",
      "test_test\n",
      "test mean loss=1152.5591430664062\n",
      "epoch 21\n",
      "test_train\n",
      "train mean loss=0.35244788726170856\n",
      "test_test\n",
      "test mean loss=1154.7068481445312\n",
      "epoch 22\n",
      "test_train\n",
      "train mean loss=0.4144003490606944\n",
      "test_test\n",
      "test mean loss=1154.0006103515625\n",
      "epoch 23\n",
      "test_train\n",
      "train mean loss=0.6528166085481644\n",
      "test_test\n",
      "test mean loss=1159.6598205566406\n",
      "epoch 24\n",
      "test_train\n",
      "train mean loss=0.4042904203136762\n",
      "test_test\n",
      "test mean loss=1157.5399169921875\n",
      "epoch 25\n",
      "test_train\n",
      "train mean loss=0.36818359047174454\n",
      "test_test\n",
      "test mean loss=1156.056884765625\n",
      "epoch 26\n",
      "test_train\n",
      "train mean loss=0.3489532135426998\n",
      "test_test\n",
      "test mean loss=1153.6126708984375\n",
      "epoch 27\n",
      "test_train\n",
      "train mean loss=0.34136173874139786\n",
      "test_test\n",
      "test mean loss=1154.0806884765625\n",
      "epoch 28\n",
      "test_train\n",
      "train mean loss=0.3130948965748151\n",
      "test_test\n",
      "test mean loss=1153.2859191894531\n",
      "epoch 29\n",
      "test_train\n",
      "train mean loss=0.2980671289066474\n",
      "test_test\n",
      "test mean loss=1154.2831115722656\n",
      "epoch 30\n",
      "test_train\n",
      "train mean loss=0.2862667739391327\n",
      "test_test\n",
      "test mean loss=1153.5319213867188\n",
      "epoch 31\n",
      "test_train\n",
      "train mean loss=0.29218192398548126\n",
      "test_test\n",
      "test mean loss=1153.7537231445312\n",
      "epoch 32\n",
      "test_train\n",
      "train mean loss=0.29542897765835124\n",
      "test_test\n",
      "test mean loss=1152.8391723632812\n",
      "epoch 33\n",
      "test_train\n",
      "train mean loss=0.28653572127223015\n",
      "test_test\n",
      "test mean loss=1152.2525634765625\n",
      "epoch 34\n",
      "test_train\n",
      "train mean loss=0.2744119130074978\n",
      "test_test\n",
      "test mean loss=1152.4041137695312\n",
      "epoch 35\n",
      "test_train\n",
      "train mean loss=0.28306614980101585\n",
      "test_test\n",
      "test mean loss=1154.2640991210938\n",
      "epoch 36\n",
      "test_train\n",
      "train mean loss=0.28233208258946735\n",
      "test_test\n",
      "test mean loss=1153.9957275390625\n",
      "epoch 37\n",
      "test_train\n",
      "train mean loss=0.2659511851767699\n",
      "test_test\n",
      "test mean loss=1152.8542785644531\n",
      "epoch 38\n",
      "test_train\n",
      "train mean loss=0.2511591464281082\n",
      "test_test\n",
      "test mean loss=1151.8717041015625\n",
      "epoch 39\n",
      "test_train\n",
      "train mean loss=0.24508895228306452\n",
      "test_test\n",
      "test mean loss=1149.972412109375\n",
      "epoch 40\n",
      "test_train\n",
      "train mean loss=0.2773250627020995\n",
      "test_test\n",
      "test mean loss=1150.9548645019531\n",
      "epoch 41\n",
      "test_train\n",
      "train mean loss=0.24124508102734885\n",
      "test_test\n",
      "test mean loss=1151.4781188964844\n",
      "epoch 42\n",
      "test_train\n",
      "train mean loss=0.25632110486427945\n",
      "test_test\n",
      "test mean loss=1152.0838012695312\n",
      "epoch 43\n",
      "test_train\n",
      "train mean loss=0.2563409358263016\n",
      "test_test\n",
      "test mean loss=1153.8605346679688\n",
      "epoch 44\n",
      "test_train\n",
      "train mean loss=0.2301838162044684\n",
      "test_test\n",
      "test mean loss=1152.5706176757812\n",
      "epoch 45\n",
      "test_train\n",
      "train mean loss=0.2585736848413944\n",
      "test_test\n",
      "test mean loss=1152.4989929199219\n",
      "epoch 46\n",
      "test_train\n",
      "train mean loss=0.2301598054667314\n",
      "test_test\n",
      "test mean loss=1153.0702209472656\n",
      "epoch 47\n",
      "test_train\n",
      "train mean loss=0.258129811535279\n",
      "test_test\n",
      "test mean loss=1151.2896118164062\n",
      "epoch 48\n",
      "test_train\n",
      "train mean loss=0.2345117616156737\n",
      "test_test\n",
      "test mean loss=1150.8854370117188\n",
      "epoch 49\n",
      "test_train\n",
      "train mean loss=0.21432780846953392\n",
      "test_test\n",
      "test mean loss=1151.1216735839844\n",
      "epoch 50\n",
      "test_train\n",
      "train mean loss=0.2205156534910202\n",
      "test_test\n",
      "test mean loss=1151.6074829101562\n",
      "epoch 51\n",
      "test_train\n",
      "train mean loss=0.25061821316679317\n",
      "test_test\n",
      "test mean loss=1151.8904418945312\n",
      "epoch 52\n",
      "test_train\n",
      "train mean loss=0.24070080990592638\n",
      "test_test\n",
      "test mean loss=1152.8499755859375\n",
      "epoch 53\n",
      "test_train\n",
      "train mean loss=0.23505438367525736\n",
      "test_test\n",
      "test mean loss=1153.1458740234375\n",
      "epoch 54\n",
      "test_train\n",
      "train mean loss=0.2056950864692529\n",
      "test_test\n",
      "test mean loss=1151.961669921875\n",
      "epoch 55\n",
      "test_train\n",
      "train mean loss=0.2052993563314279\n",
      "test_test\n",
      "test mean loss=1151.3633422851562\n",
      "epoch 56\n",
      "test_train\n",
      "train mean loss=0.20414038126667342\n",
      "test_test\n",
      "test mean loss=1150.1407165527344\n",
      "epoch 57\n",
      "test_train\n",
      "train mean loss=0.20443671569228172\n",
      "test_test\n",
      "test mean loss=1150.2216491699219\n",
      "epoch 58\n",
      "test_train\n",
      "train mean loss=0.23977610593040785\n",
      "test_test\n",
      "test mean loss=1151.0137939453125\n",
      "epoch 59\n",
      "test_train\n",
      "train mean loss=0.22302240505814552\n",
      "test_test\n",
      "test mean loss=1150.8660888671875\n",
      "epoch 60\n",
      "test_train\n",
      "train mean loss=0.2309639391799768\n",
      "test_test\n",
      "test mean loss=1150.3889465332031\n",
      "epoch 61\n",
      "test_train\n",
      "train mean loss=0.2187287633617719\n",
      "test_test\n",
      "test mean loss=1149.4078979492188\n",
      "epoch 62\n",
      "test_train\n",
      "train mean loss=0.2028392143547535\n",
      "test_test\n",
      "test mean loss=1149.7178649902344\n",
      "epoch 63\n",
      "test_train\n",
      "train mean loss=0.20286733657121658\n",
      "test_test\n",
      "test mean loss=1148.8345642089844\n",
      "epoch 64\n",
      "test_train\n",
      "train mean loss=0.21261569609244665\n",
      "test_test\n",
      "test mean loss=1149.3054809570312\n",
      "epoch 65\n",
      "test_train\n",
      "train mean loss=0.1983823080857595\n",
      "test_test\n",
      "test mean loss=1148.59326171875\n",
      "epoch 66\n",
      "test_train\n",
      "train mean loss=0.19815948605537415\n",
      "test_test\n",
      "test mean loss=1149.2366027832031\n",
      "epoch 67\n",
      "test_train\n",
      "train mean loss=0.19643226514259973\n",
      "test_test\n",
      "test mean loss=1149.5674743652344\n",
      "epoch 68\n",
      "test_train\n",
      "train mean loss=0.1886677903433641\n",
      "test_test\n",
      "test mean loss=1149.6980590820312\n",
      "epoch 69\n",
      "test_train\n",
      "train mean loss=0.19554731994867325\n",
      "test_test\n",
      "test mean loss=1149.0511474609375\n",
      "epoch 70\n",
      "test_train\n",
      "train mean loss=0.20480296574532986\n",
      "test_test\n",
      "test mean loss=1149.7980346679688\n",
      "epoch 71\n",
      "test_train\n",
      "train mean loss=0.2539308990041415\n",
      "test_test\n",
      "test mean loss=1151.3161010742188\n",
      "epoch 72\n",
      "test_train\n",
      "train mean loss=0.20985332628091177\n",
      "test_test\n",
      "test mean loss=1149.1989135742188\n",
      "epoch 73\n",
      "test_train\n",
      "train mean loss=0.2267474023004373\n",
      "test_test\n",
      "test mean loss=1149.9856567382812\n",
      "epoch 74\n",
      "test_train\n",
      "train mean loss=0.18983608298003674\n",
      "test_test\n",
      "test mean loss=1150.780517578125\n",
      "epoch 75\n",
      "test_train\n",
      "train mean loss=0.186500808224082\n",
      "test_test\n",
      "test mean loss=1149.872802734375\n",
      "epoch 76\n",
      "test_train\n",
      "train mean loss=0.18651548648873964\n",
      "test_test\n",
      "test mean loss=1149.3643493652344\n",
      "epoch 77\n",
      "test_train\n",
      "train mean loss=0.9797579149405161\n",
      "test_test\n",
      "test mean loss=1150.7775268554688\n",
      "epoch 78\n",
      "test_train\n",
      "train mean loss=0.5398817509412766\n",
      "test_test\n",
      "test mean loss=1148.9945678710938\n",
      "epoch 79\n",
      "test_train\n",
      "train mean loss=0.25760246564944583\n",
      "test_test\n",
      "test mean loss=1147.6943359375\n",
      "epoch 80\n",
      "test_train\n",
      "train mean loss=0.21440819650888443\n",
      "test_test\n",
      "test mean loss=1148.2845764160156\n",
      "epoch 81\n",
      "test_train\n",
      "train mean loss=0.209514282643795\n",
      "test_test\n",
      "test mean loss=1147.2844848632812\n",
      "epoch 82\n",
      "test_train\n",
      "train mean loss=0.2025969016055266\n",
      "test_test\n",
      "test mean loss=1146.9086303710938\n",
      "epoch 83\n",
      "test_train\n",
      "train mean loss=0.3457910840710004\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1149.9370727539062\n",
      "epoch 84\n",
      "test_train\n",
      "train mean loss=0.21319933608174324\n",
      "test_test\n",
      "test mean loss=1149.8487854003906\n",
      "epoch 85\n",
      "test_train\n",
      "train mean loss=0.20576906576752663\n",
      "test_test\n",
      "test mean loss=1149.6208190917969\n",
      "epoch 86\n",
      "test_train\n",
      "train mean loss=0.195231635744373\n",
      "test_test\n",
      "test mean loss=1148.4356384277344\n",
      "epoch 87\n",
      "test_train\n",
      "train mean loss=0.20390348508954048\n",
      "test_test\n",
      "test mean loss=1149.5635375976562\n",
      "epoch 88\n",
      "test_train\n",
      "train mean loss=0.1943288097778956\n",
      "test_test\n",
      "test mean loss=1149.9913940429688\n",
      "epoch 89\n",
      "test_train\n",
      "train mean loss=0.18929867632687092\n",
      "test_test\n",
      "test mean loss=1149.1909484863281\n",
      "epoch 90\n",
      "test_train\n",
      "train mean loss=0.1829509095599254\n",
      "test_test\n",
      "test mean loss=1149.5199584960938\n",
      "epoch 91\n",
      "test_train\n",
      "train mean loss=0.18384365923702717\n",
      "test_test\n",
      "test mean loss=1149.9763793945312\n",
      "epoch 92\n",
      "test_train\n",
      "train mean loss=0.1881508007645607\n",
      "test_test\n",
      "test mean loss=1149.5205078125\n",
      "epoch 93\n",
      "test_train\n",
      "train mean loss=0.1858481541275978\n",
      "test_test\n",
      "test mean loss=1149.3597412109375\n",
      "epoch 94\n",
      "test_train\n",
      "train mean loss=0.20604202399651209\n",
      "test_test\n",
      "test mean loss=1148.9180908203125\n",
      "epoch 95\n",
      "test_train\n",
      "train mean loss=0.17115348701675734\n",
      "test_test\n",
      "test mean loss=1149.0833129882812\n",
      "epoch 96\n",
      "test_train\n",
      "train mean loss=0.2056826762855053\n",
      "test_test\n",
      "test mean loss=1148.6964721679688\n",
      "epoch 97\n",
      "test_train\n",
      "train mean loss=0.19394311805566153\n",
      "test_test\n",
      "test mean loss=1149.07861328125\n",
      "epoch 98\n",
      "test_train\n",
      "train mean loss=0.1776681331296762\n",
      "test_test\n",
      "test mean loss=1149.116455078125\n",
      "epoch 99\n",
      "test_train\n",
      "train mean loss=0.19023023483653864\n",
      "test_test\n",
      "test mean loss=1148.9094848632812\n",
      "epoch 100\n",
      "test_train\n",
      "train mean loss=0.17658746615052223\n",
      "test_test\n",
      "test mean loss=1149.14892578125\n",
      "epoch 101\n",
      "test_train\n",
      "train mean loss=0.173323392868042\n",
      "test_test\n",
      "test mean loss=1148.6644897460938\n",
      "epoch 102\n",
      "test_train\n",
      "train mean loss=0.17641619592905045\n",
      "test_test\n",
      "test mean loss=1149.2188110351562\n",
      "epoch 103\n",
      "test_train\n",
      "train mean loss=0.17483470340569815\n",
      "test_test\n",
      "test mean loss=1150.9334106445312\n",
      "epoch 104\n",
      "test_train\n",
      "train mean loss=0.17685766518115997\n",
      "test_test\n",
      "test mean loss=1149.9794006347656\n",
      "epoch 105\n",
      "test_train\n",
      "train mean loss=0.174478679895401\n",
      "test_test\n",
      "test mean loss=1149.6879272460938\n",
      "epoch 106\n",
      "test_train\n",
      "train mean loss=0.17375814790527025\n",
      "test_test\n",
      "test mean loss=1149.81787109375\n",
      "epoch 107\n",
      "test_train\n",
      "train mean loss=0.2151003951827685\n",
      "test_test\n",
      "test mean loss=1149.8065490722656\n",
      "epoch 108\n",
      "test_train\n",
      "train mean loss=0.1806499920785427\n",
      "test_test\n",
      "test mean loss=1149.9793090820312\n",
      "epoch 109\n",
      "test_train\n",
      "train mean loss=0.17198440742989382\n",
      "test_test\n",
      "test mean loss=1150.4434814453125\n",
      "epoch 110\n",
      "test_train\n",
      "train mean loss=0.16761316172778606\n",
      "test_test\n",
      "test mean loss=1150.4715881347656\n",
      "epoch 111\n",
      "test_train\n",
      "train mean loss=0.18025336600840092\n",
      "test_test\n",
      "test mean loss=1150.9235534667969\n",
      "epoch 112\n",
      "test_train\n",
      "train mean loss=0.3603735938668251\n",
      "test_test\n",
      "test mean loss=1150.3484497070312\n",
      "epoch 113\n",
      "test_train\n",
      "train mean loss=0.21865420788526535\n",
      "test_test\n",
      "test mean loss=1149.7490844726562\n",
      "epoch 114\n",
      "test_train\n",
      "train mean loss=0.18247465416789055\n",
      "test_test\n",
      "test mean loss=1149.25244140625\n",
      "epoch 115\n",
      "test_train\n",
      "train mean loss=0.20172686812778315\n",
      "test_test\n",
      "test mean loss=1149.562744140625\n",
      "epoch 116\n",
      "test_train\n",
      "train mean loss=0.1736652199178934\n",
      "test_test\n",
      "test mean loss=1148.8992309570312\n",
      "epoch 117\n",
      "test_train\n",
      "train mean loss=4.559312383333842\n",
      "test_test\n",
      "test mean loss=1149.2986450195312\n",
      "epoch 118\n",
      "test_train\n",
      "train mean loss=1.75498562057813\n",
      "test_test\n",
      "test mean loss=1153.7325744628906\n",
      "epoch 119\n",
      "test_train\n",
      "train mean loss=0.8123148133357366\n",
      "test_test\n",
      "test mean loss=1155.5691223144531\n",
      "epoch 120\n",
      "test_train\n",
      "train mean loss=0.3485759198665619\n",
      "test_test\n",
      "test mean loss=1156.072021484375\n",
      "epoch 121\n",
      "test_train\n",
      "train mean loss=0.2365093951423963\n",
      "test_test\n",
      "test mean loss=1153.8064270019531\n",
      "epoch 122\n",
      "test_train\n",
      "train mean loss=0.21749248231450716\n",
      "test_test\n",
      "test mean loss=1153.076171875\n",
      "epoch 123\n",
      "test_train\n",
      "train mean loss=0.19544779819746813\n",
      "test_test\n",
      "test mean loss=1154.2834777832031\n",
      "epoch 124\n",
      "test_train\n",
      "train mean loss=0.18926656556626162\n",
      "test_test\n",
      "test mean loss=1153.6629333496094\n",
      "epoch 125\n",
      "test_train\n",
      "train mean loss=0.18719276413321495\n",
      "test_test\n",
      "test mean loss=1153.8992004394531\n",
      "epoch 126\n",
      "test_train\n",
      "train mean loss=0.1868552342057228\n",
      "test_test\n",
      "test mean loss=1153.7617797851562\n",
      "epoch 127\n",
      "test_train\n",
      "train mean loss=0.18295253068208694\n",
      "test_test\n",
      "test mean loss=1153.352783203125\n",
      "epoch 128\n",
      "test_train\n",
      "train mean loss=0.19786293618381023\n",
      "test_test\n",
      "test mean loss=1153.8109130859375\n",
      "epoch 129\n",
      "test_train\n",
      "train mean loss=0.18568125615517297\n",
      "test_test\n",
      "test mean loss=1152.6497802734375\n",
      "epoch 130\n",
      "test_train\n",
      "train mean loss=0.1778253639737765\n",
      "test_test\n",
      "test mean loss=1153.3410034179688\n",
      "epoch 131\n",
      "test_train\n",
      "train mean loss=0.18412444554269314\n",
      "test_test\n",
      "test mean loss=1152.1629638671875\n",
      "epoch 132\n",
      "test_train\n",
      "train mean loss=0.1765092182904482\n",
      "test_test\n",
      "test mean loss=1153.4918823242188\n",
      "epoch 133\n",
      "test_train\n",
      "train mean loss=0.43337516859173775\n",
      "test_test\n",
      "test mean loss=1152.8055114746094\n",
      "epoch 134\n",
      "test_train\n",
      "train mean loss=0.18931126097838083\n",
      "test_test\n",
      "test mean loss=1153.138427734375\n",
      "epoch 135\n",
      "test_train\n",
      "train mean loss=0.1855673405031363\n",
      "test_test\n",
      "test mean loss=1152.620849609375\n",
      "epoch 136\n",
      "test_train\n",
      "train mean loss=0.17725229387482008\n",
      "test_test\n",
      "test mean loss=1153.1919250488281\n",
      "epoch 137\n",
      "test_train\n",
      "train mean loss=0.17448393317560354\n",
      "test_test\n",
      "test mean loss=1152.7176818847656\n",
      "epoch 138\n",
      "test_train\n",
      "train mean loss=0.18281550953785577\n",
      "test_test\n",
      "test mean loss=1152.190673828125\n",
      "epoch 139\n",
      "test_train\n",
      "train mean loss=0.17568342263499895\n",
      "test_test\n",
      "test mean loss=1152.0989990234375\n",
      "epoch 140\n",
      "test_train\n",
      "train mean loss=0.16965055838227272\n",
      "test_test\n",
      "test mean loss=1152.1293334960938\n",
      "epoch 141\n",
      "test_train\n",
      "train mean loss=0.17089608497917652\n",
      "test_test\n",
      "test mean loss=1151.8167724609375\n",
      "epoch 142\n",
      "test_train\n",
      "train mean loss=0.17191533744335175\n",
      "test_test\n",
      "test mean loss=1152.2051696777344\n",
      "epoch 143\n",
      "test_train\n",
      "train mean loss=0.17173143289983273\n",
      "test_test\n",
      "test mean loss=1150.9308166503906\n",
      "epoch 144\n",
      "test_train\n",
      "train mean loss=0.17118475337823233\n",
      "test_test\n",
      "test mean loss=1151.5375061035156\n",
      "epoch 145\n",
      "test_train\n",
      "train mean loss=0.18594924236337343\n",
      "test_test\n",
      "test mean loss=1151.1536865234375\n",
      "epoch 146\n",
      "test_train\n",
      "train mean loss=0.1670048280308644\n",
      "test_test\n",
      "test mean loss=1151.0847778320312\n",
      "epoch 147\n",
      "test_train\n",
      "train mean loss=0.1664773734907309\n",
      "test_test\n",
      "test mean loss=1151.6968383789062\n",
      "epoch 148\n",
      "test_train\n",
      "train mean loss=0.1666288742174705\n",
      "test_test\n",
      "test mean loss=1150.9100952148438\n",
      "epoch 149\n",
      "test_train\n",
      "train mean loss=0.16805101496477923\n",
      "test_test\n",
      "test mean loss=1152.21484375\n",
      "epoch 150\n",
      "test_train\n",
      "train mean loss=0.1679738579938809\n",
      "test_test\n",
      "test mean loss=1151.443115234375\n",
      "epoch 151\n",
      "test_train\n",
      "train mean loss=0.1702390511830648\n",
      "test_test\n",
      "test mean loss=1151.9172058105469\n",
      "epoch 152\n",
      "test_train\n",
      "train mean loss=0.16831003998716673\n",
      "test_test\n",
      "test mean loss=1152.7981567382812\n",
      "epoch 153\n",
      "test_train\n",
      "train mean loss=0.17299483654399714\n",
      "test_test\n",
      "test mean loss=1151.681396484375\n",
      "epoch 154\n",
      "test_train\n",
      "train mean loss=0.17381688207387924\n",
      "test_test\n",
      "test mean loss=1152.6833801269531\n",
      "epoch 155\n",
      "test_train\n",
      "train mean loss=0.16243900482853255\n",
      "test_test\n",
      "test mean loss=1152.4166259765625\n",
      "epoch 156\n",
      "test_train\n",
      "train mean loss=0.16856908053159714\n",
      "test_test\n",
      "test mean loss=1153.01806640625\n",
      "epoch 157\n",
      "test_train\n",
      "train mean loss=0.1668684979279836\n",
      "test_test\n",
      "test mean loss=1151.8932189941406\n",
      "epoch 158\n",
      "test_train\n",
      "train mean loss=0.16301362154384455\n",
      "test_test\n",
      "test mean loss=1151.2760620117188\n",
      "epoch 159\n",
      "test_train\n",
      "train mean loss=0.1910456387947003\n",
      "test_test\n",
      "test mean loss=1151.6952819824219\n",
      "epoch 160\n",
      "test_train\n",
      "train mean loss=0.1641221543153127\n",
      "test_test\n",
      "test mean loss=1152.4124755859375\n",
      "epoch 161\n",
      "test_train\n",
      "train mean loss=0.1590203382074833\n",
      "test_test\n",
      "test mean loss=1152.2732543945312\n",
      "epoch 162\n",
      "test_train\n",
      "train mean loss=0.2650551510353883\n",
      "test_test\n",
      "test mean loss=1152.1069030761719\n",
      "epoch 163\n",
      "test_train\n",
      "train mean loss=0.17733003695805868\n",
      "test_test\n",
      "test mean loss=1150.5881958007812\n",
      "epoch 164\n",
      "test_train\n",
      "train mean loss=0.16799805561701456\n",
      "test_test\n",
      "test mean loss=1151.2042846679688\n",
      "epoch 165\n",
      "test_train\n",
      "train mean loss=0.16320301964879036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_test\n",
      "test mean loss=1151.4284057617188\n",
      "epoch 166\n",
      "test_train\n",
      "train mean loss=0.1559932225694259\n",
      "test_test\n",
      "test mean loss=1151.6653747558594\n",
      "epoch 167\n",
      "test_train\n",
      "train mean loss=0.1611451624582211\n",
      "test_test\n",
      "test mean loss=1150.8073120117188\n",
      "epoch 168\n",
      "test_train\n",
      "train mean loss=0.16416125744581223\n",
      "test_test\n",
      "test mean loss=1150.5113525390625\n",
      "epoch 169\n",
      "test_train\n",
      "train mean loss=0.1618813673655192\n",
      "test_test\n",
      "test mean loss=1151.3489379882812\n",
      "epoch 170\n",
      "test_train\n",
      "train mean loss=0.15876914747059345\n",
      "test_test\n",
      "test mean loss=1150.5977783203125\n",
      "epoch 171\n",
      "test_train\n",
      "train mean loss=0.16661005839705467\n",
      "test_test\n",
      "test mean loss=1150.6303100585938\n",
      "epoch 172\n",
      "test_train\n",
      "train mean loss=0.1643243171274662\n",
      "test_test\n",
      "test mean loss=1150.4574584960938\n",
      "epoch 173\n",
      "test_train\n",
      "train mean loss=0.1560252495110035\n",
      "test_test\n",
      "test mean loss=1151.3380126953125\n",
      "epoch 174\n",
      "test_train\n",
      "train mean loss=0.15340239244202772\n",
      "test_test\n",
      "test mean loss=1150.9700622558594\n",
      "epoch 175\n",
      "test_train\n",
      "train mean loss=0.15988950617611408\n",
      "test_test\n",
      "test mean loss=1151.6647338867188\n",
      "epoch 176\n",
      "test_train\n",
      "train mean loss=0.15332464625438055\n",
      "test_test\n",
      "test mean loss=1151.6184692382812\n",
      "epoch 177\n",
      "test_train\n",
      "train mean loss=0.1537915002554655\n",
      "test_test\n",
      "test mean loss=1151.5719299316406\n",
      "epoch 178\n",
      "test_train\n",
      "train mean loss=0.1662910015632709\n",
      "test_test\n",
      "test mean loss=1152.1374816894531\n",
      "epoch 179\n",
      "test_train\n",
      "train mean loss=0.19849156898756823\n",
      "test_test\n",
      "test mean loss=1151.174560546875\n",
      "epoch 180\n",
      "test_train\n",
      "train mean loss=0.15910751869281134\n",
      "test_test\n",
      "test mean loss=1152.0109252929688\n",
      "epoch 181\n",
      "test_train\n",
      "train mean loss=0.15804305486381054\n",
      "test_test\n",
      "test mean loss=1151.6695556640625\n",
      "epoch 182\n",
      "test_train\n",
      "train mean loss=0.2357702056566874\n",
      "test_test\n",
      "test mean loss=1152.060302734375\n",
      "epoch 183\n",
      "test_train\n",
      "train mean loss=0.16061141776541868\n",
      "test_test\n",
      "test mean loss=1151.4314575195312\n",
      "epoch 184\n",
      "test_train\n",
      "train mean loss=0.1552538461983204\n",
      "test_test\n",
      "test mean loss=1151.1905517578125\n",
      "epoch 185\n",
      "test_train\n",
      "train mean loss=0.16040496962765852\n",
      "test_test\n",
      "test mean loss=1151.3707275390625\n",
      "epoch 186\n",
      "test_train\n",
      "train mean loss=0.16455274199446043\n",
      "test_test\n",
      "test mean loss=1150.71533203125\n",
      "epoch 187\n",
      "test_train\n",
      "train mean loss=0.1532170232385397\n",
      "test_test\n",
      "test mean loss=1151.9984130859375\n",
      "epoch 188\n",
      "test_train\n",
      "train mean loss=0.15417779174943766\n",
      "test_test\n",
      "test mean loss=1151.9107055664062\n",
      "epoch 189\n",
      "test_train\n",
      "train mean loss=0.1527045542995135\n",
      "test_test\n",
      "test mean loss=1151.96240234375\n",
      "epoch 190\n",
      "test_train\n",
      "train mean loss=0.15064980586369833\n",
      "test_test\n",
      "test mean loss=1151.7384643554688\n",
      "epoch 191\n",
      "test_train\n",
      "train mean loss=0.15565344194571176\n",
      "test_test\n",
      "test mean loss=1151.3597717285156\n",
      "epoch 192\n",
      "test_train\n",
      "train mean loss=0.15873483630518118\n",
      "test_test\n",
      "test mean loss=1152.0702514648438\n",
      "epoch 193\n",
      "test_train\n",
      "train mean loss=0.15503441480298838\n",
      "test_test\n",
      "test mean loss=1151.8738403320312\n",
      "epoch 194\n",
      "test_train\n",
      "train mean loss=0.1573711639891068\n",
      "test_test\n",
      "test mean loss=1151.691650390625\n",
      "epoch 195\n",
      "test_train\n",
      "train mean loss=0.1555194016546011\n",
      "test_test\n",
      "test mean loss=1151.855224609375\n",
      "epoch 196\n",
      "test_train\n",
      "train mean loss=0.15890707013507685\n",
      "test_test\n",
      "test mean loss=1152.3330993652344\n",
      "epoch 197\n",
      "test_train\n",
      "train mean loss=0.1504284298668305\n",
      "test_test\n",
      "test mean loss=1152.4017028808594\n",
      "epoch 198\n",
      "test_train\n",
      "train mean loss=0.15331749866406122\n",
      "test_test\n",
      "test mean loss=1152.0308227539062\n",
      "epoch 199\n",
      "test_train\n",
      "train mean loss=0.15260174063344797\n",
      "test_test\n",
      "test mean loss=1151.1745300292969\n",
      "epoch 200\n",
      "test_train\n",
      "train mean loss=0.17559214433034262\n",
      "test_test\n",
      "test mean loss=1150.5357666015625\n",
      "epoch 201\n",
      "test_train\n",
      "train mean loss=0.15532968627909818\n",
      "test_test\n",
      "test mean loss=1151.07421875\n",
      "epoch 202\n",
      "test_train\n",
      "train mean loss=0.16567145412166914\n",
      "test_test\n",
      "test mean loss=1150.7894592285156\n",
      "epoch 203\n",
      "test_train\n",
      "train mean loss=0.16296489536762238\n",
      "test_test\n",
      "test mean loss=1151.2275390625\n",
      "epoch 204\n",
      "test_train\n",
      "train mean loss=0.15469184579948583\n",
      "test_test\n",
      "test mean loss=1151.2810668945312\n",
      "epoch 205\n",
      "test_train\n",
      "train mean loss=0.14989254561563334\n",
      "test_test\n",
      "test mean loss=1151.1876831054688\n",
      "epoch 206\n",
      "test_train\n",
      "train mean loss=0.15177277786036333\n",
      "test_test\n",
      "test mean loss=1151.5604248046875\n",
      "epoch 207\n",
      "test_train\n",
      "train mean loss=0.16499201394617558\n",
      "test_test\n",
      "test mean loss=1151.6772766113281\n",
      "epoch 208\n",
      "test_train\n",
      "train mean loss=0.2259204958875974\n",
      "test_test\n",
      "test mean loss=1151.2100830078125\n",
      "epoch 209\n",
      "test_train\n",
      "train mean loss=0.16136164094010988\n",
      "test_test\n",
      "test mean loss=1152.2854614257812\n",
      "epoch 210\n",
      "test_train\n",
      "train mean loss=0.15865837534268698\n",
      "test_test\n",
      "test mean loss=1151.957275390625\n",
      "epoch 211\n",
      "test_train\n",
      "train mean loss=0.15513921280701956\n",
      "test_test\n",
      "test mean loss=1151.5227661132812\n",
      "epoch 212\n",
      "test_train\n",
      "train mean loss=0.17039765665928522\n",
      "test_test\n",
      "test mean loss=1151.0062255859375\n",
      "epoch 213\n",
      "test_train\n",
      "train mean loss=0.1614631644139687\n",
      "test_test\n",
      "test mean loss=1152.083740234375\n",
      "epoch 214\n",
      "test_train\n",
      "train mean loss=0.1535301748663187\n",
      "test_test\n",
      "test mean loss=1152.3976135253906\n",
      "epoch 215\n",
      "test_train\n",
      "train mean loss=0.15577387996017933\n",
      "test_test\n",
      "test mean loss=1152.0455322265625\n",
      "epoch 216\n",
      "test_train\n",
      "train mean loss=0.23664074266950288\n",
      "test_test\n",
      "test mean loss=1154.1104125976562\n",
      "epoch 217\n",
      "test_train\n",
      "train mean loss=0.16210422416528067\n",
      "test_test\n",
      "test mean loss=1151.7645874023438\n",
      "epoch 218\n",
      "test_train\n",
      "train mean loss=0.156700873747468\n",
      "test_test\n",
      "test mean loss=1150.9391479492188\n",
      "epoch 219\n",
      "test_train\n",
      "train mean loss=0.15733055646220842\n",
      "test_test\n",
      "test mean loss=1151.9959716796875\n",
      "epoch 220\n",
      "test_train\n",
      "train mean loss=0.15119445386032263\n",
      "test_test\n",
      "test mean loss=1152.450927734375\n",
      "epoch 221\n",
      "test_train\n",
      "train mean loss=0.14968867413699627\n",
      "test_test\n",
      "test mean loss=1151.31689453125\n",
      "epoch 222\n",
      "test_train\n",
      "train mean loss=0.1536264605820179\n",
      "test_test\n",
      "test mean loss=1151.3484802246094\n",
      "epoch 223\n",
      "test_train\n",
      "train mean loss=0.14871851292749247\n",
      "test_test\n",
      "test mean loss=1150.8560791015625\n",
      "epoch 224\n",
      "test_train\n",
      "train mean loss=0.15237761537233988\n",
      "test_test\n",
      "test mean loss=1151.0381469726562\n",
      "epoch 225\n",
      "test_train\n",
      "train mean loss=0.15388649267454943\n",
      "test_test\n",
      "test mean loss=1150.3348388671875\n",
      "epoch 226\n",
      "test_train\n",
      "train mean loss=0.14543701770404974\n",
      "test_test\n",
      "test mean loss=1151.4956665039062\n",
      "epoch 227\n",
      "test_train\n",
      "train mean loss=0.14643051102757454\n",
      "test_test\n",
      "test mean loss=1151.794189453125\n",
      "epoch 228\n",
      "test_train\n",
      "train mean loss=0.19468825062115988\n",
      "test_test\n",
      "test mean loss=1152.1305236816406\n",
      "epoch 229\n",
      "test_train\n",
      "train mean loss=0.1515970677137375\n",
      "test_test\n",
      "test mean loss=1152.6533813476562\n",
      "epoch 230\n",
      "test_train\n",
      "train mean loss=0.1509228559831778\n",
      "test_test\n",
      "test mean loss=1151.7060852050781\n",
      "epoch 231\n",
      "test_train\n",
      "train mean loss=0.15249327383935452\n",
      "test_test\n",
      "test mean loss=1151.8156127929688\n",
      "epoch 232\n",
      "test_train\n",
      "train mean loss=0.1570406605799993\n",
      "test_test\n",
      "test mean loss=1151.9304809570312\n",
      "epoch 233\n",
      "test_train\n",
      "train mean loss=0.1496071219444275\n",
      "test_test\n",
      "test mean loss=1151.7007751464844\n",
      "epoch 234\n",
      "test_train\n",
      "train mean loss=0.15556101749340692\n",
      "test_test\n",
      "test mean loss=1151.64208984375\n",
      "epoch 235\n",
      "test_train\n",
      "train mean loss=0.14876636179784933\n",
      "test_test\n",
      "test mean loss=1151.0278015136719\n",
      "epoch 236\n",
      "test_train\n",
      "train mean loss=0.1464067790657282\n",
      "test_test\n",
      "test mean loss=1151.0315246582031\n",
      "epoch 237\n",
      "test_train\n",
      "train mean loss=0.1471455960224072\n",
      "test_test\n",
      "test mean loss=1151.1878356933594\n",
      "epoch 238\n",
      "test_train\n",
      "train mean loss=0.14569723357756934\n",
      "test_test\n",
      "test mean loss=1151.0744018554688\n",
      "epoch 239\n",
      "test_train\n",
      "train mean loss=0.15081650267044702\n",
      "test_test\n",
      "test mean loss=1150.95556640625\n",
      "epoch 240\n",
      "test_train\n",
      "train mean loss=0.1479726086060206\n",
      "test_test\n",
      "test mean loss=1151.0694885253906\n",
      "epoch 241\n",
      "test_train\n",
      "train mean loss=0.15336240641772747\n",
      "test_test\n",
      "test mean loss=1151.2964172363281\n",
      "epoch 242\n",
      "test_train\n",
      "train mean loss=0.1487611544628938\n",
      "test_test\n",
      "test mean loss=1150.9849853515625\n",
      "epoch 243\n",
      "test_train\n",
      "train mean loss=0.1449468390395244\n",
      "test_test\n",
      "test mean loss=1151.3564453125\n",
      "epoch 244\n",
      "test_train\n",
      "train mean loss=0.14298847628136477\n",
      "test_test\n",
      "test mean loss=1151.0606689453125\n",
      "epoch 245\n",
      "test_train\n",
      "train mean loss=0.14170399059851965\n",
      "test_test\n",
      "test mean loss=1151.5491333007812\n",
      "epoch 246\n",
      "test_train\n",
      "train mean loss=0.14602428302168846\n",
      "test_test\n",
      "test mean loss=1152.3681030273438\n",
      "epoch 247\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.1695586033165455\n",
      "test_test\n",
      "test mean loss=1150.9247131347656\n",
      "epoch 248\n",
      "test_train\n",
      "train mean loss=0.17259073567887148\n",
      "test_test\n",
      "test mean loss=1151.7185668945312\n",
      "epoch 249\n",
      "test_train\n",
      "train mean loss=0.15184259538849196\n",
      "test_test\n",
      "test mean loss=1152.557861328125\n",
      "epoch 250\n",
      "test_train\n",
      "train mean loss=0.1491042710840702\n",
      "test_test\n",
      "test mean loss=1150.523681640625\n",
      "epoch 251\n",
      "test_train\n",
      "train mean loss=0.17091099979976812\n",
      "test_test\n",
      "test mean loss=1153.3701171875\n",
      "epoch 252\n",
      "test_train\n",
      "train mean loss=0.14711756010850272\n",
      "test_test\n",
      "test mean loss=1153.240966796875\n",
      "epoch 253\n",
      "test_train\n",
      "train mean loss=0.14870703468720117\n",
      "test_test\n",
      "test mean loss=1152.8377685546875\n",
      "epoch 254\n",
      "test_train\n",
      "train mean loss=0.1463502130160729\n",
      "test_test\n",
      "test mean loss=1152.5123291015625\n",
      "epoch 255\n",
      "test_train\n",
      "train mean loss=0.1485551819205284\n",
      "test_test\n",
      "test mean loss=1153.175537109375\n",
      "epoch 256\n",
      "test_train\n",
      "train mean loss=0.14735724839071432\n",
      "test_test\n",
      "test mean loss=1152.0995483398438\n",
      "epoch 257\n",
      "test_train\n",
      "train mean loss=0.14590726358195147\n",
      "test_test\n",
      "test mean loss=1152.3184814453125\n",
      "epoch 258\n",
      "test_train\n",
      "train mean loss=0.15109369903802872\n",
      "test_test\n",
      "test mean loss=1152.6388854980469\n",
      "epoch 259\n",
      "test_train\n",
      "train mean loss=0.14688881548742452\n",
      "test_test\n",
      "test mean loss=1152.4518127441406\n",
      "epoch 260\n",
      "test_train\n",
      "train mean loss=0.1463217604905367\n",
      "test_test\n",
      "test mean loss=1151.2803344726562\n",
      "epoch 261\n",
      "test_train\n",
      "train mean loss=0.1510951661815246\n",
      "test_test\n",
      "test mean loss=1152.2274780273438\n",
      "epoch 262\n",
      "test_train\n",
      "train mean loss=0.1438476691643397\n",
      "test_test\n",
      "test mean loss=1152.2906494140625\n",
      "epoch 263\n",
      "test_train\n",
      "train mean loss=0.14609187406798205\n",
      "test_test\n",
      "test mean loss=1151.7039794921875\n",
      "epoch 264\n",
      "test_train\n",
      "train mean loss=0.14320662866036096\n",
      "test_test\n",
      "test mean loss=1152.0030822753906\n",
      "epoch 265\n",
      "test_train\n",
      "train mean loss=0.14310708766182265\n",
      "test_test\n",
      "test mean loss=1151.7529907226562\n",
      "epoch 266\n",
      "test_train\n",
      "train mean loss=0.14680367584029833\n",
      "test_test\n",
      "test mean loss=1151.763671875\n",
      "epoch 267\n",
      "test_train\n",
      "train mean loss=0.14660804470380148\n",
      "test_test\n",
      "test mean loss=1152.2852783203125\n",
      "epoch 268\n",
      "test_train\n",
      "train mean loss=0.1455820519477129\n",
      "test_test\n",
      "test mean loss=1151.9322509765625\n",
      "epoch 269\n",
      "test_train\n",
      "train mean loss=0.14633416508634886\n",
      "test_test\n",
      "test mean loss=1151.533447265625\n",
      "epoch 270\n",
      "test_train\n",
      "train mean loss=0.1442688157161077\n",
      "test_test\n",
      "test mean loss=1151.6939392089844\n",
      "epoch 271\n",
      "test_train\n",
      "train mean loss=0.14467142460246882\n",
      "test_test\n",
      "test mean loss=1152.0292358398438\n",
      "epoch 272\n",
      "test_train\n",
      "train mean loss=0.14796864551802477\n",
      "test_test\n",
      "test mean loss=1151.4492797851562\n",
      "epoch 273\n",
      "test_train\n",
      "train mean loss=0.14366390742361546\n",
      "test_test\n",
      "test mean loss=1152.2585754394531\n",
      "epoch 274\n",
      "test_train\n",
      "train mean loss=0.1438849549740553\n",
      "test_test\n",
      "test mean loss=1152.3419799804688\n",
      "epoch 275\n",
      "test_train\n",
      "train mean loss=0.14772674751778445\n",
      "test_test\n",
      "test mean loss=1151.2954711914062\n",
      "epoch 276\n",
      "test_train\n",
      "train mean loss=0.13991112758715948\n",
      "test_test\n",
      "test mean loss=1151.6049499511719\n",
      "epoch 277\n",
      "test_train\n",
      "train mean loss=0.23442055781682333\n",
      "test_test\n",
      "test mean loss=1152.8218994140625\n",
      "epoch 278\n",
      "test_train\n",
      "train mean loss=0.1492005152006944\n",
      "test_test\n",
      "test mean loss=1151.2671203613281\n",
      "epoch 279\n",
      "test_train\n",
      "train mean loss=0.1480561550706625\n",
      "test_test\n",
      "test mean loss=1151.0927429199219\n",
      "epoch 280\n",
      "test_train\n",
      "train mean loss=0.14670847542583942\n",
      "test_test\n",
      "test mean loss=1151.0241088867188\n",
      "epoch 281\n",
      "test_train\n",
      "train mean loss=0.14876865223050117\n",
      "test_test\n",
      "test mean loss=1151.0480041503906\n",
      "epoch 282\n",
      "test_train\n",
      "train mean loss=0.14181211901207766\n",
      "test_test\n",
      "test mean loss=1150.9690856933594\n",
      "epoch 283\n",
      "test_train\n",
      "train mean loss=0.14195597978929678\n",
      "test_test\n",
      "test mean loss=1151.1222534179688\n",
      "epoch 284\n",
      "test_train\n",
      "train mean loss=0.14550336139897505\n",
      "test_test\n",
      "test mean loss=1151.1520080566406\n",
      "epoch 285\n",
      "test_train\n",
      "train mean loss=0.13782669976353645\n",
      "test_test\n",
      "test mean loss=1152.0447998046875\n",
      "epoch 286\n",
      "test_train\n",
      "train mean loss=0.14022645726799965\n",
      "test_test\n",
      "test mean loss=1151.634521484375\n",
      "epoch 287\n",
      "test_train\n",
      "train mean loss=0.14585107130308947\n",
      "test_test\n",
      "test mean loss=1152.8466186523438\n",
      "epoch 288\n",
      "test_train\n",
      "train mean loss=0.14446013420820236\n",
      "test_test\n",
      "test mean loss=1153.1989440917969\n",
      "epoch 289\n",
      "test_train\n",
      "train mean loss=0.13924341835081577\n",
      "test_test\n",
      "test mean loss=1152.0956115722656\n",
      "epoch 290\n",
      "test_train\n",
      "train mean loss=0.13971521767477194\n",
      "test_test\n",
      "test mean loss=1151.5186157226562\n",
      "epoch 291\n",
      "test_train\n",
      "train mean loss=0.1425593706468741\n",
      "test_test\n",
      "test mean loss=1152.3948059082031\n",
      "epoch 292\n",
      "test_train\n",
      "train mean loss=0.15352447455128035\n",
      "test_test\n",
      "test mean loss=1151.1615905761719\n",
      "epoch 293\n",
      "test_train\n",
      "train mean loss=0.14744150390227637\n",
      "test_test\n",
      "test mean loss=1151.0405883789062\n",
      "epoch 294\n",
      "test_train\n",
      "train mean loss=0.14372362941503525\n",
      "test_test\n",
      "test mean loss=1150.2431030273438\n",
      "epoch 295\n",
      "test_train\n",
      "train mean loss=0.14390584702293077\n",
      "test_test\n",
      "test mean loss=1151.2224731445312\n",
      "epoch 296\n",
      "test_train\n",
      "train mean loss=0.14970415892700353\n",
      "test_test\n",
      "test mean loss=1151.9189453125\n",
      "epoch 297\n",
      "test_train\n",
      "train mean loss=0.14564281857262054\n",
      "test_test\n",
      "test mean loss=1152.3414306640625\n",
      "epoch 298\n",
      "test_train\n",
      "train mean loss=0.13914108648896217\n",
      "test_test\n",
      "test mean loss=1152.1073608398438\n",
      "epoch 299\n",
      "test_train\n",
      "train mean loss=0.1394764749954144\n",
      "test_test\n",
      "test mean loss=1150.7885131835938\n",
      "epoch 300\n",
      "test_train\n",
      "train mean loss=0.13894447001318136\n",
      "test_test\n",
      "test mean loss=1151.6282958984375\n",
      "epoch 301\n",
      "test_train\n",
      "train mean loss=0.13936602883040905\n",
      "test_test\n",
      "test mean loss=1152.85400390625\n",
      "epoch 302\n",
      "test_train\n",
      "train mean loss=0.14129994561274847\n",
      "test_test\n",
      "test mean loss=1152.4391784667969\n",
      "epoch 303\n",
      "test_train\n",
      "train mean loss=0.14452911851306757\n",
      "test_test\n",
      "test mean loss=1153.3256225585938\n",
      "epoch 304\n",
      "test_train\n",
      "train mean loss=0.14074050821363926\n",
      "test_test\n",
      "test mean loss=1153.3290405273438\n",
      "epoch 305\n",
      "test_train\n",
      "train mean loss=0.14153049079080424\n",
      "test_test\n",
      "test mean loss=1152.258056640625\n",
      "epoch 306\n",
      "test_train\n",
      "train mean loss=0.13768161522845426\n",
      "test_test\n",
      "test mean loss=1152.7151794433594\n",
      "epoch 307\n",
      "test_train\n",
      "train mean loss=0.13767239513496557\n",
      "test_test\n",
      "test mean loss=1151.2742309570312\n",
      "epoch 308\n",
      "test_train\n",
      "train mean loss=0.13508729885021845\n",
      "test_test\n",
      "test mean loss=1151.6430969238281\n",
      "epoch 309\n",
      "test_train\n",
      "train mean loss=0.1358573796848456\n",
      "test_test\n",
      "test mean loss=1152.1898193359375\n",
      "epoch 310\n",
      "test_train\n",
      "train mean loss=0.15546091521779695\n",
      "test_test\n",
      "test mean loss=1151.2131652832031\n",
      "epoch 311\n",
      "test_train\n",
      "train mean loss=0.13521930699547133\n",
      "test_test\n",
      "test mean loss=1151.247314453125\n",
      "epoch 312\n",
      "test_train\n",
      "train mean loss=0.13979342145224413\n",
      "test_test\n",
      "test mean loss=1151.3180236816406\n",
      "epoch 313\n",
      "test_train\n",
      "train mean loss=0.13841830690701803\n",
      "test_test\n",
      "test mean loss=1151.6756591796875\n",
      "epoch 314\n",
      "test_train\n",
      "train mean loss=0.14034230696658292\n",
      "test_test\n",
      "test mean loss=1152.0601196289062\n",
      "epoch 315\n",
      "test_train\n",
      "train mean loss=0.14015371228257814\n",
      "test_test\n",
      "test mean loss=1152.3147277832031\n",
      "epoch 316\n",
      "test_train\n",
      "train mean loss=0.13779004476964474\n",
      "test_test\n",
      "test mean loss=1151.5029296875\n",
      "epoch 317\n",
      "test_train\n",
      "train mean loss=0.13717384822666645\n",
      "test_test\n",
      "test mean loss=1152.5463256835938\n",
      "epoch 318\n",
      "test_train\n",
      "train mean loss=0.185618224243323\n",
      "test_test\n",
      "test mean loss=1152.4884033203125\n",
      "epoch 319\n",
      "test_train\n",
      "train mean loss=0.14215909006694952\n",
      "test_test\n",
      "test mean loss=1152.8773803710938\n",
      "epoch 320\n",
      "test_train\n",
      "train mean loss=0.14912333525717258\n",
      "test_test\n",
      "test mean loss=1152.5478515625\n",
      "epoch 321\n",
      "test_train\n",
      "train mean loss=0.15985561348497868\n",
      "test_test\n",
      "test mean loss=1152.6907653808594\n",
      "epoch 322\n",
      "test_train\n",
      "train mean loss=0.1500332225114107\n",
      "test_test\n",
      "test mean loss=1151.6891174316406\n",
      "epoch 323\n",
      "test_train\n",
      "train mean loss=0.14393551088869572\n",
      "test_test\n",
      "test mean loss=1151.7849731445312\n",
      "epoch 324\n",
      "test_train\n",
      "train mean loss=0.14872632982830206\n",
      "test_test\n",
      "test mean loss=1152.33447265625\n",
      "epoch 325\n",
      "test_train\n",
      "train mean loss=0.2914312742650509\n",
      "test_test\n",
      "test mean loss=1150.5311889648438\n",
      "epoch 326\n",
      "test_train\n",
      "train mean loss=0.16277940074602762\n",
      "test_test\n",
      "test mean loss=1150.8671875\n",
      "epoch 327\n",
      "test_train\n",
      "train mean loss=0.14058871567249298\n",
      "test_test\n",
      "test mean loss=1151.3854064941406\n",
      "epoch 328\n",
      "test_train\n",
      "train mean loss=0.13802380549410978\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1151.6610412597656\n",
      "epoch 329\n",
      "test_train\n",
      "train mean loss=0.14865805519123873\n",
      "test_test\n",
      "test mean loss=1151.3983154296875\n",
      "epoch 330\n",
      "test_train\n",
      "train mean loss=0.1546822084734837\n",
      "test_test\n",
      "test mean loss=1151.0458984375\n",
      "epoch 331\n",
      "test_train\n",
      "train mean loss=0.14491264273722967\n",
      "test_test\n",
      "test mean loss=1151.5074157714844\n",
      "epoch 332\n",
      "test_train\n",
      "train mean loss=0.14007142558693886\n",
      "test_test\n",
      "test mean loss=1152.15234375\n",
      "epoch 333\n",
      "test_train\n",
      "train mean loss=0.15938239792982736\n",
      "test_test\n",
      "test mean loss=1151.312255859375\n",
      "epoch 334\n",
      "test_train\n",
      "train mean loss=0.1401385230322679\n",
      "test_test\n",
      "test mean loss=1153.9509887695312\n",
      "epoch 335\n",
      "test_train\n",
      "train mean loss=0.13612638848523298\n",
      "test_test\n",
      "test mean loss=1153.5050354003906\n",
      "epoch 336\n",
      "test_train\n",
      "train mean loss=0.1393112832059463\n",
      "test_test\n",
      "test mean loss=1153.0572509765625\n",
      "epoch 337\n",
      "test_train\n",
      "train mean loss=0.15473135374486446\n",
      "test_test\n",
      "test mean loss=1152.8436279296875\n",
      "epoch 338\n",
      "test_train\n",
      "train mean loss=0.14117143861949444\n",
      "test_test\n",
      "test mean loss=1152.469970703125\n",
      "epoch 339\n",
      "test_train\n",
      "train mean loss=0.13947367668151855\n",
      "test_test\n",
      "test mean loss=1151.4729614257812\n",
      "epoch 340\n",
      "test_train\n",
      "train mean loss=0.1338600634286801\n",
      "test_test\n",
      "test mean loss=1151.6612548828125\n",
      "epoch 341\n",
      "test_train\n",
      "train mean loss=0.13877162585655847\n",
      "test_test\n",
      "test mean loss=1151.8682556152344\n",
      "epoch 342\n",
      "test_train\n",
      "train mean loss=0.14021676778793335\n",
      "test_test\n",
      "test mean loss=1151.4177856445312\n",
      "epoch 343\n",
      "test_train\n",
      "train mean loss=0.17158699159820875\n",
      "test_test\n",
      "test mean loss=1152.0696716308594\n",
      "epoch 344\n",
      "test_train\n",
      "train mean loss=0.14277156566580138\n",
      "test_test\n",
      "test mean loss=1151.46044921875\n",
      "epoch 345\n",
      "test_train\n",
      "train mean loss=0.13561941248675188\n",
      "test_test\n",
      "test mean loss=1151.837646484375\n",
      "epoch 346\n",
      "test_train\n",
      "train mean loss=0.14339639991521835\n",
      "test_test\n",
      "test mean loss=1152.1262512207031\n",
      "epoch 347\n",
      "test_train\n",
      "train mean loss=0.14222521396974722\n",
      "test_test\n",
      "test mean loss=1152.6466369628906\n",
      "epoch 348\n",
      "test_train\n",
      "train mean loss=0.13844747468829155\n",
      "test_test\n",
      "test mean loss=1152.4450073242188\n",
      "epoch 349\n",
      "test_train\n",
      "train mean loss=0.1518550788362821\n",
      "test_test\n",
      "test mean loss=1154.1735229492188\n",
      "epoch 350\n",
      "test_train\n",
      "train mean loss=0.19104719907045364\n",
      "test_test\n",
      "test mean loss=1152.6088256835938\n",
      "epoch 351\n",
      "test_train\n",
      "train mean loss=0.15646765381097794\n",
      "test_test\n",
      "test mean loss=1152.5245666503906\n",
      "epoch 352\n",
      "test_train\n",
      "train mean loss=0.1394956037402153\n",
      "test_test\n",
      "test mean loss=1152.548828125\n",
      "epoch 353\n",
      "test_train\n",
      "train mean loss=0.14007222714523473\n",
      "test_test\n",
      "test mean loss=1152.4228515625\n",
      "epoch 354\n",
      "test_train\n",
      "train mean loss=0.2818387585381667\n",
      "test_test\n",
      "test mean loss=1156.1123046875\n",
      "epoch 355\n",
      "test_train\n",
      "train mean loss=0.15157578513026237\n",
      "test_test\n",
      "test mean loss=1152.7491455078125\n",
      "epoch 356\n",
      "test_train\n",
      "train mean loss=0.13805936587353548\n",
      "test_test\n",
      "test mean loss=1152.6964111328125\n",
      "epoch 357\n",
      "test_train\n",
      "train mean loss=0.1566719145824512\n",
      "test_test\n",
      "test mean loss=1152.4803161621094\n",
      "epoch 358\n",
      "test_train\n",
      "train mean loss=0.13866650530447563\n",
      "test_test\n",
      "test mean loss=1152.8184509277344\n",
      "epoch 359\n",
      "test_train\n",
      "train mean loss=0.13709327206015587\n",
      "test_test\n",
      "test mean loss=1152.8528747558594\n",
      "epoch 360\n",
      "test_train\n",
      "train mean loss=0.1422308807571729\n",
      "test_test\n",
      "test mean loss=1153.014892578125\n",
      "epoch 361\n",
      "test_train\n",
      "train mean loss=0.13927095383405685\n",
      "test_test\n",
      "test mean loss=1152.068359375\n",
      "epoch 362\n",
      "test_train\n",
      "train mean loss=0.13635288116832575\n",
      "test_test\n",
      "test mean loss=1152.5991821289062\n",
      "epoch 363\n",
      "test_train\n",
      "train mean loss=0.13964453401664892\n",
      "test_test\n",
      "test mean loss=1152.961181640625\n",
      "epoch 364\n",
      "test_train\n",
      "train mean loss=0.1337471672644218\n",
      "test_test\n",
      "test mean loss=1151.9822998046875\n",
      "epoch 365\n",
      "test_train\n",
      "train mean loss=0.13502955498794714\n",
      "test_test\n",
      "test mean loss=1152.7752075195312\n",
      "epoch 366\n",
      "test_train\n",
      "train mean loss=0.13567386319239935\n",
      "test_test\n",
      "test mean loss=1152.9025268554688\n",
      "epoch 367\n",
      "test_train\n",
      "train mean loss=0.13740150382121405\n",
      "test_test\n",
      "test mean loss=1152.5841369628906\n",
      "epoch 368\n",
      "test_train\n",
      "train mean loss=0.1393812969326973\n",
      "test_test\n",
      "test mean loss=1152.0752258300781\n",
      "epoch 369\n",
      "test_train\n",
      "train mean loss=0.14171614311635494\n",
      "test_test\n",
      "test mean loss=1151.7649536132812\n",
      "epoch 370\n",
      "test_train\n",
      "train mean loss=0.13755482683579126\n",
      "test_test\n",
      "test mean loss=1152.35595703125\n",
      "epoch 371\n",
      "test_train\n",
      "train mean loss=0.13553387547532716\n",
      "test_test\n",
      "test mean loss=1152.0360717773438\n",
      "epoch 372\n",
      "test_train\n",
      "train mean loss=0.15269592963159084\n",
      "test_test\n",
      "test mean loss=1151.8867797851562\n",
      "epoch 373\n",
      "test_train\n",
      "train mean loss=0.1391465114429593\n",
      "test_test\n",
      "test mean loss=1151.3236694335938\n",
      "epoch 374\n",
      "test_train\n",
      "train mean loss=0.1371343620121479\n",
      "test_test\n",
      "test mean loss=1151.6728515625\n",
      "epoch 375\n",
      "test_train\n",
      "train mean loss=0.13362429104745388\n",
      "test_test\n",
      "test mean loss=1152.5466918945312\n",
      "epoch 376\n",
      "test_train\n",
      "train mean loss=0.14467384976645312\n",
      "test_test\n",
      "test mean loss=1151.3638916015625\n",
      "epoch 377\n",
      "test_train\n",
      "train mean loss=0.1325263443092505\n",
      "test_test\n",
      "test mean loss=1151.8575439453125\n",
      "epoch 378\n",
      "test_train\n",
      "train mean loss=0.13667350759108862\n",
      "test_test\n",
      "test mean loss=1151.915283203125\n",
      "epoch 379\n",
      "test_train\n",
      "train mean loss=0.13497750957806906\n",
      "test_test\n",
      "test mean loss=1151.4219970703125\n",
      "epoch 380\n",
      "test_train\n",
      "train mean loss=0.13614300669481358\n",
      "test_test\n",
      "test mean loss=1151.8697509765625\n",
      "epoch 381\n",
      "test_train\n",
      "train mean loss=0.14019965442518392\n",
      "test_test\n",
      "test mean loss=1151.4500732421875\n",
      "epoch 382\n",
      "test_train\n",
      "train mean loss=0.13562285527586937\n",
      "test_test\n",
      "test mean loss=1152.4425048828125\n",
      "epoch 383\n",
      "test_train\n",
      "train mean loss=0.13628504114846388\n",
      "test_test\n",
      "test mean loss=1152.2742919921875\n",
      "epoch 384\n",
      "test_train\n",
      "train mean loss=0.13846016488969326\n",
      "test_test\n",
      "test mean loss=1151.8822021484375\n",
      "epoch 385\n",
      "test_train\n",
      "train mean loss=0.13066412260135016\n",
      "test_test\n",
      "test mean loss=1150.8919677734375\n",
      "epoch 386\n",
      "test_train\n",
      "train mean loss=0.21272872760891914\n",
      "test_test\n",
      "test mean loss=1153.6144409179688\n",
      "epoch 387\n",
      "test_train\n",
      "train mean loss=0.14473899578054747\n",
      "test_test\n",
      "test mean loss=1153.1546020507812\n",
      "epoch 388\n",
      "test_train\n",
      "train mean loss=0.13479824053744474\n",
      "test_test\n",
      "test mean loss=1152.33544921875\n",
      "epoch 389\n",
      "test_train\n",
      "train mean loss=0.12981242376069227\n",
      "test_test\n",
      "test mean loss=1152.27197265625\n",
      "epoch 390\n",
      "test_train\n",
      "train mean loss=0.13342639338225126\n",
      "test_test\n",
      "test mean loss=1151.6582641601562\n",
      "epoch 391\n",
      "test_train\n",
      "train mean loss=0.1344479856391748\n",
      "test_test\n",
      "test mean loss=1152.3679809570312\n",
      "epoch 392\n",
      "test_train\n",
      "train mean loss=0.1322191928823789\n",
      "test_test\n",
      "test mean loss=1151.6430053710938\n",
      "epoch 393\n",
      "test_train\n",
      "train mean loss=0.13040829387803873\n",
      "test_test\n",
      "test mean loss=1151.5313415527344\n",
      "epoch 394\n",
      "test_train\n",
      "train mean loss=0.13361076762278876\n",
      "test_test\n",
      "test mean loss=1152.400390625\n",
      "epoch 395\n",
      "test_train\n",
      "train mean loss=0.1291510295122862\n",
      "test_test\n",
      "test mean loss=1152.9451293945312\n",
      "epoch 396\n",
      "test_train\n",
      "train mean loss=0.18552328211565813\n",
      "test_test\n",
      "test mean loss=1154.6442260742188\n",
      "epoch 397\n",
      "test_train\n",
      "train mean loss=0.33909959097703296\n",
      "test_test\n",
      "test mean loss=1153.1937866210938\n",
      "epoch 398\n",
      "test_train\n",
      "train mean loss=0.1701955764244\n",
      "test_test\n",
      "test mean loss=1152.2619018554688\n",
      "epoch 399\n",
      "test_train\n",
      "train mean loss=0.14015516887108484\n",
      "test_test\n",
      "test mean loss=1151.4092407226562\n",
      "epoch 400\n",
      "test_train\n",
      "train mean loss=0.14424430951476097\n",
      "test_test\n",
      "test mean loss=1151.24853515625\n",
      "epoch 401\n",
      "test_train\n",
      "train mean loss=0.13834535578886667\n",
      "test_test\n",
      "test mean loss=1152.5082397460938\n",
      "epoch 402\n",
      "test_train\n",
      "train mean loss=0.1355036540577809\n",
      "test_test\n",
      "test mean loss=1152.4418334960938\n",
      "epoch 403\n",
      "test_train\n",
      "train mean loss=0.1387546689560016\n",
      "test_test\n",
      "test mean loss=1151.06201171875\n",
      "epoch 404\n",
      "test_train\n",
      "train mean loss=0.1369744852806131\n",
      "test_test\n",
      "test mean loss=1150.9978637695312\n",
      "epoch 405\n",
      "test_train\n",
      "train mean loss=0.13522878289222717\n",
      "test_test\n",
      "test mean loss=1151.1666259765625\n",
      "epoch 406\n",
      "test_train\n",
      "train mean loss=0.14216478541493416\n",
      "test_test\n",
      "test mean loss=1151.0320434570312\n",
      "epoch 407\n",
      "test_train\n",
      "train mean loss=0.14065633155405521\n",
      "test_test\n",
      "test mean loss=1151.3284912109375\n",
      "epoch 408\n",
      "test_train\n",
      "train mean loss=0.14367368258535862\n",
      "test_test\n",
      "test mean loss=1151.9777526855469\n",
      "epoch 409\n",
      "test_train\n",
      "train mean loss=0.1354196115086476\n",
      "test_test\n",
      "test mean loss=1151.6028747558594\n",
      "epoch 410\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.13356387491027513\n",
      "test_test\n",
      "test mean loss=1150.9051513671875\n",
      "epoch 411\n",
      "test_train\n",
      "train mean loss=0.14165368489921093\n",
      "test_test\n",
      "test mean loss=1150.32080078125\n",
      "epoch 412\n",
      "test_train\n",
      "train mean loss=0.137268523996075\n",
      "test_test\n",
      "test mean loss=1151.6092224121094\n",
      "epoch 413\n",
      "test_train\n",
      "train mean loss=0.12986386505266032\n",
      "test_test\n",
      "test mean loss=1150.958251953125\n",
      "epoch 414\n",
      "test_train\n",
      "train mean loss=0.1301953804989656\n",
      "test_test\n",
      "test mean loss=1151.3181457519531\n",
      "epoch 415\n",
      "test_train\n",
      "train mean loss=0.18284874161084494\n",
      "test_test\n",
      "test mean loss=1153.2171325683594\n",
      "epoch 416\n",
      "test_train\n",
      "train mean loss=0.15307043368617693\n",
      "test_test\n",
      "test mean loss=1152.5611572265625\n",
      "epoch 417\n",
      "test_train\n",
      "train mean loss=0.1408888604491949\n",
      "test_test\n",
      "test mean loss=1152.9663391113281\n",
      "epoch 418\n",
      "test_train\n",
      "train mean loss=0.13385782142480215\n",
      "test_test\n",
      "test mean loss=1152.80224609375\n",
      "epoch 419\n",
      "test_train\n",
      "train mean loss=0.1365087286879619\n",
      "test_test\n",
      "test mean loss=1151.5693359375\n",
      "epoch 420\n",
      "test_train\n",
      "train mean loss=0.135580034305652\n",
      "test_test\n",
      "test mean loss=1151.6713256835938\n",
      "epoch 421\n",
      "test_train\n",
      "train mean loss=0.14271647855639458\n",
      "test_test\n",
      "test mean loss=1150.9808959960938\n",
      "epoch 422\n",
      "test_train\n",
      "train mean loss=0.13403758903344473\n",
      "test_test\n",
      "test mean loss=1151.80078125\n",
      "epoch 423\n",
      "test_train\n",
      "train mean loss=0.13278665766119957\n",
      "test_test\n",
      "test mean loss=1151.8384399414062\n",
      "epoch 424\n",
      "test_train\n",
      "train mean loss=0.1365408282727003\n",
      "test_test\n",
      "test mean loss=1151.3619079589844\n",
      "epoch 425\n",
      "test_train\n",
      "train mean loss=0.14107669238001108\n",
      "test_test\n",
      "test mean loss=1151.759765625\n",
      "epoch 426\n",
      "test_train\n",
      "train mean loss=0.13389369224508604\n",
      "test_test\n",
      "test mean loss=1151.9281616210938\n",
      "epoch 427\n",
      "test_train\n",
      "train mean loss=0.132920037334164\n",
      "test_test\n",
      "test mean loss=1151.7749633789062\n",
      "epoch 428\n",
      "test_train\n",
      "train mean loss=0.13139131230612597\n",
      "test_test\n",
      "test mean loss=1151.9276123046875\n",
      "epoch 429\n",
      "test_train\n",
      "train mean loss=0.12783215877910456\n",
      "test_test\n",
      "test mean loss=1151.886474609375\n",
      "epoch 430\n",
      "test_train\n",
      "train mean loss=0.1270664638529221\n",
      "test_test\n",
      "test mean loss=1152.0011901855469\n",
      "epoch 431\n",
      "test_train\n",
      "train mean loss=0.13164947057763735\n",
      "test_test\n",
      "test mean loss=1151.4216918945312\n",
      "epoch 432\n",
      "test_train\n",
      "train mean loss=0.12779413225750128\n",
      "test_test\n",
      "test mean loss=1151.1261596679688\n",
      "epoch 433\n",
      "test_train\n",
      "train mean loss=0.14191031890610853\n",
      "test_test\n",
      "test mean loss=1153.1011962890625\n",
      "epoch 434\n",
      "test_train\n",
      "train mean loss=0.13133562169969082\n",
      "test_test\n",
      "test mean loss=1150.9348754882812\n",
      "epoch 435\n",
      "test_train\n",
      "train mean loss=0.13038075218598047\n",
      "test_test\n",
      "test mean loss=1151.64501953125\n",
      "epoch 436\n",
      "test_train\n",
      "train mean loss=0.1275534195204576\n",
      "test_test\n",
      "test mean loss=1151.578369140625\n",
      "epoch 437\n",
      "test_train\n",
      "train mean loss=0.1302196029573679\n",
      "test_test\n",
      "test mean loss=1152.6679077148438\n",
      "epoch 438\n",
      "test_train\n",
      "train mean loss=0.1285979232440392\n",
      "test_test\n",
      "test mean loss=1151.9027709960938\n",
      "epoch 439\n",
      "test_train\n",
      "train mean loss=0.13197239177922407\n",
      "test_test\n",
      "test mean loss=1152.2656860351562\n",
      "epoch 440\n",
      "test_train\n",
      "train mean loss=0.13493868770698705\n",
      "test_test\n",
      "test mean loss=1152.0810241699219\n",
      "epoch 441\n",
      "test_train\n",
      "train mean loss=0.1304948441684246\n",
      "test_test\n",
      "test mean loss=1152.7766723632812\n",
      "epoch 442\n",
      "test_train\n",
      "train mean loss=0.12868718492488065\n",
      "test_test\n",
      "test mean loss=1152.6912231445312\n",
      "epoch 443\n",
      "test_train\n",
      "train mean loss=0.12398650869727135\n",
      "test_test\n",
      "test mean loss=1152.6527709960938\n",
      "epoch 444\n",
      "test_train\n",
      "train mean loss=0.1333470276246468\n",
      "test_test\n",
      "test mean loss=1152.2684326171875\n",
      "epoch 445\n",
      "test_train\n",
      "train mean loss=0.13210269870857397\n",
      "test_test\n",
      "test mean loss=1151.23828125\n",
      "epoch 446\n",
      "test_train\n",
      "train mean loss=0.12376365127662818\n",
      "test_test\n",
      "test mean loss=1151.4524536132812\n",
      "epoch 447\n",
      "test_train\n",
      "train mean loss=0.12414405060311158\n",
      "test_test\n",
      "test mean loss=1152.3779602050781\n",
      "epoch 448\n",
      "test_train\n",
      "train mean loss=0.12613919749855995\n",
      "test_test\n",
      "test mean loss=1152.5224914550781\n",
      "epoch 449\n",
      "test_train\n",
      "train mean loss=0.12702462635934353\n",
      "test_test\n",
      "test mean loss=1151.4947509765625\n",
      "epoch 450\n",
      "test_train\n",
      "train mean loss=0.12871863010028997\n",
      "test_test\n",
      "test mean loss=1151.5206909179688\n",
      "epoch 451\n",
      "test_train\n",
      "train mean loss=0.13396089151501656\n",
      "test_test\n",
      "test mean loss=1152.9101257324219\n",
      "epoch 452\n",
      "test_train\n",
      "train mean loss=0.1282001230865717\n",
      "test_test\n",
      "test mean loss=1152.6651000976562\n",
      "epoch 453\n",
      "test_train\n",
      "train mean loss=0.12609160443147024\n",
      "test_test\n",
      "test mean loss=1153.0542602539062\n",
      "epoch 454\n",
      "test_train\n",
      "train mean loss=0.123671087436378\n",
      "test_test\n",
      "test mean loss=1153.1721801757812\n",
      "epoch 455\n",
      "test_train\n",
      "train mean loss=0.1264678779989481\n",
      "test_test\n",
      "test mean loss=1152.7966613769531\n",
      "epoch 456\n",
      "test_train\n",
      "train mean loss=0.1341756240775188\n",
      "test_test\n",
      "test mean loss=1152.8255920410156\n",
      "epoch 457\n",
      "test_train\n",
      "train mean loss=0.1336686766395966\n",
      "test_test\n",
      "test mean loss=1152.51220703125\n",
      "epoch 458\n",
      "test_train\n",
      "train mean loss=0.12817176462461552\n",
      "test_test\n",
      "test mean loss=1152.2689819335938\n",
      "epoch 459\n",
      "test_train\n",
      "train mean loss=0.1278670777877172\n",
      "test_test\n",
      "test mean loss=1152.7897338867188\n",
      "epoch 460\n",
      "test_train\n",
      "train mean loss=0.13337084340552488\n",
      "test_test\n",
      "test mean loss=1152.3080444335938\n",
      "epoch 461\n",
      "test_train\n",
      "train mean loss=0.1267237632224957\n",
      "test_test\n",
      "test mean loss=1151.7362670898438\n",
      "epoch 462\n",
      "test_train\n",
      "train mean loss=0.12658319001396498\n",
      "test_test\n",
      "test mean loss=1152.4561767578125\n",
      "epoch 463\n",
      "test_train\n",
      "train mean loss=0.12500283867120743\n",
      "test_test\n",
      "test mean loss=1151.4617004394531\n",
      "epoch 464\n",
      "test_train\n",
      "train mean loss=0.12597583793103695\n",
      "test_test\n",
      "test mean loss=1152.1943359375\n",
      "epoch 465\n",
      "test_train\n",
      "train mean loss=0.12311972739795844\n",
      "test_test\n",
      "test mean loss=1152.83740234375\n",
      "epoch 466\n",
      "test_train\n",
      "train mean loss=0.1437366126726071\n",
      "test_test\n",
      "test mean loss=1152.7615966796875\n",
      "epoch 467\n",
      "test_train\n",
      "train mean loss=0.12652217783033848\n",
      "test_test\n",
      "test mean loss=1153.5825805664062\n",
      "epoch 468\n",
      "test_train\n",
      "train mean loss=0.1255376481761535\n",
      "test_test\n",
      "test mean loss=1152.563720703125\n",
      "epoch 469\n",
      "test_train\n",
      "train mean loss=0.12245902605354786\n",
      "test_test\n",
      "test mean loss=1152.6106872558594\n",
      "epoch 470\n",
      "test_train\n",
      "train mean loss=0.14186182214568058\n",
      "test_test\n",
      "test mean loss=1152.4058227539062\n",
      "epoch 471\n",
      "test_train\n",
      "train mean loss=0.1307367105036974\n",
      "test_test\n",
      "test mean loss=1152.1216430664062\n",
      "epoch 472\n",
      "test_train\n",
      "train mean loss=0.13752494317789873\n",
      "test_test\n",
      "test mean loss=1152.3269653320312\n",
      "epoch 473\n",
      "test_train\n",
      "train mean loss=0.1278307599325975\n",
      "test_test\n",
      "test mean loss=1153.2755126953125\n",
      "epoch 474\n",
      "test_train\n",
      "train mean loss=0.12870610319077969\n",
      "test_test\n",
      "test mean loss=1153.507568359375\n",
      "epoch 475\n",
      "test_train\n",
      "train mean loss=0.12621755401293436\n",
      "test_test\n",
      "test mean loss=1153.7332763671875\n",
      "epoch 476\n",
      "test_train\n",
      "train mean loss=0.1329149790108204\n",
      "test_test\n",
      "test mean loss=1153.763427734375\n",
      "epoch 477\n",
      "test_train\n",
      "train mean loss=0.131592637548844\n",
      "test_test\n",
      "test mean loss=1153.2611999511719\n",
      "epoch 478\n",
      "test_train\n",
      "train mean loss=0.16242356846729913\n",
      "test_test\n",
      "test mean loss=1153.1682739257812\n",
      "epoch 479\n",
      "test_train\n",
      "train mean loss=0.1397689487785101\n",
      "test_test\n",
      "test mean loss=1153.8553771972656\n",
      "epoch 480\n",
      "test_train\n",
      "train mean loss=0.12981810234487057\n",
      "test_test\n",
      "test mean loss=1152.7060852050781\n",
      "epoch 481\n",
      "test_train\n",
      "train mean loss=0.12393782598276933\n",
      "test_test\n",
      "test mean loss=1151.9725646972656\n",
      "epoch 482\n",
      "test_train\n",
      "train mean loss=0.13397953162590662\n",
      "test_test\n",
      "test mean loss=1153.1934509277344\n",
      "epoch 483\n",
      "test_train\n",
      "train mean loss=0.1327806394547224\n",
      "test_test\n",
      "test mean loss=1152.97265625\n",
      "epoch 484\n",
      "test_train\n",
      "train mean loss=0.12575483291099468\n",
      "test_test\n",
      "test mean loss=1151.9179077148438\n",
      "epoch 485\n",
      "test_train\n",
      "train mean loss=0.1334822035084168\n",
      "test_test\n",
      "test mean loss=1151.8428955078125\n",
      "epoch 486\n",
      "test_train\n",
      "train mean loss=0.16259324923157692\n",
      "test_test\n",
      "test mean loss=1150.1271362304688\n",
      "epoch 487\n",
      "test_train\n",
      "train mean loss=0.13555882622798285\n",
      "test_test\n",
      "test mean loss=1150.4879760742188\n",
      "epoch 488\n",
      "test_train\n",
      "train mean loss=0.1295324737826983\n",
      "test_test\n",
      "test mean loss=1151.3486328125\n",
      "epoch 489\n",
      "test_train\n",
      "train mean loss=0.13223280695577463\n",
      "test_test\n",
      "test mean loss=1152.2157897949219\n",
      "epoch 490\n",
      "test_train\n",
      "train mean loss=0.12813768039147058\n",
      "test_test\n",
      "test mean loss=1152.2250366210938\n",
      "epoch 491\n",
      "test_train\n",
      "train mean loss=0.13110457391788563\n",
      "test_test\n",
      "test mean loss=1152.021484375\n",
      "epoch 492\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_train\n",
      "train mean loss=0.13042303236822286\n",
      "test_test\n",
      "test mean loss=1151.0547485351562\n",
      "epoch 493\n",
      "test_train\n",
      "train mean loss=0.13235076454778513\n",
      "test_test\n",
      "test mean loss=1152.5140075683594\n",
      "epoch 494\n",
      "test_train\n",
      "train mean loss=0.13118694350123405\n",
      "test_test\n",
      "test mean loss=1152.4044189453125\n",
      "epoch 495\n",
      "test_train\n",
      "train mean loss=0.13531942293047905\n",
      "test_test\n",
      "test mean loss=1152.7199401855469\n",
      "epoch 496\n",
      "test_train\n",
      "train mean loss=0.12808152536551157\n",
      "test_test\n",
      "test mean loss=1151.7743530273438\n",
      "epoch 497\n",
      "test_train\n",
      "train mean loss=0.12532863362381855\n",
      "test_test\n",
      "test mean loss=1152.1640014648438\n",
      "epoch 498\n",
      "test_train\n",
      "train mean loss=0.12516004343827566\n",
      "test_test\n",
      "test mean loss=1152.6243591308594\n",
      "epoch 499\n",
      "test_train\n",
      "train mean loss=0.13388725245992342\n",
      "test_test\n",
      "test mean loss=1152.6795043945312\n",
      "epoch 500\n",
      "test_train\n",
      "train mean loss=0.13173924634853998\n",
      "test_test\n",
      "test mean loss=1152.4131774902344\n",
      "epoch 501\n",
      "test_train\n",
      "train mean loss=0.13319632224738598\n",
      "test_test\n",
      "test mean loss=1152.656982421875\n",
      "epoch 502\n",
      "test_train\n",
      "train mean loss=0.1350036139289538\n",
      "test_test\n",
      "test mean loss=1152.6338500976562\n",
      "epoch 503\n",
      "test_train\n",
      "train mean loss=0.1376342655469974\n",
      "test_test\n",
      "test mean loss=1151.6233520507812\n",
      "epoch 504\n",
      "test_train\n",
      "train mean loss=0.1336204862842957\n",
      "test_test\n",
      "test mean loss=1151.4832153320312\n",
      "epoch 505\n",
      "test_train\n",
      "train mean loss=0.13329691564043364\n",
      "test_test\n",
      "test mean loss=1150.7631225585938\n",
      "epoch 506\n",
      "test_train\n",
      "train mean loss=0.12895785830914974\n",
      "test_test\n",
      "test mean loss=1151.694580078125\n",
      "epoch 507\n",
      "test_train\n",
      "train mean loss=0.13687608701487383\n",
      "test_test\n",
      "test mean loss=1152.1012268066406\n",
      "epoch 508\n",
      "test_train\n",
      "train mean loss=0.1315811239182949\n",
      "test_test\n",
      "test mean loss=1150.9989929199219\n",
      "epoch 509\n",
      "test_train\n",
      "train mean loss=0.13567213962475458\n",
      "test_test\n",
      "test mean loss=1152.11328125\n",
      "epoch 510\n",
      "test_train\n",
      "train mean loss=0.13025994412600994\n",
      "test_test\n",
      "test mean loss=1151.965576171875\n",
      "epoch 511\n",
      "test_train\n",
      "train mean loss=0.1318539883941412\n",
      "test_test\n",
      "test mean loss=1151.9976196289062\n",
      "epoch 512\n",
      "test_train\n",
      "train mean loss=0.1269853375852108\n",
      "test_test\n",
      "test mean loss=1151.6077575683594\n",
      "epoch 513\n",
      "test_train\n",
      "train mean loss=0.13128791066507497\n",
      "test_test\n",
      "test mean loss=1152.3623352050781\n",
      "epoch 514\n",
      "test_train\n",
      "train mean loss=0.13068223434189954\n",
      "test_test\n",
      "test mean loss=1151.3225402832031\n",
      "epoch 515\n",
      "test_train\n",
      "train mean loss=0.15755090365807214\n",
      "test_test\n",
      "test mean loss=1150.31591796875\n",
      "epoch 516\n",
      "test_train\n",
      "train mean loss=0.13342010229825974\n",
      "test_test\n",
      "test mean loss=1151.1394653320312\n",
      "epoch 517\n",
      "test_train\n",
      "train mean loss=0.13000697828829288\n",
      "test_test\n",
      "test mean loss=1152.3089599609375\n",
      "epoch 518\n",
      "test_train\n",
      "train mean loss=0.12876146100461483\n",
      "test_test\n",
      "test mean loss=1152.5943603515625\n",
      "epoch 519\n",
      "test_train\n",
      "train mean loss=0.13778036770721278\n",
      "test_test\n",
      "test mean loss=1152.56396484375\n",
      "epoch 520\n",
      "test_train\n",
      "train mean loss=0.13434596235553423\n",
      "test_test\n",
      "test mean loss=1152.348876953125\n",
      "epoch 521\n",
      "test_train\n",
      "train mean loss=0.12836259479324022\n",
      "test_test\n",
      "test mean loss=1152.0928649902344\n",
      "epoch 522\n",
      "test_train\n",
      "train mean loss=0.12804962880909443\n",
      "test_test\n",
      "test mean loss=1152.3423461914062\n",
      "epoch 523\n",
      "test_train\n",
      "train mean loss=0.1280683216949304\n",
      "test_test\n",
      "test mean loss=1152.6134338378906\n",
      "epoch 524\n",
      "test_train\n",
      "train mean loss=0.13419902324676514\n",
      "test_test\n",
      "test mean loss=1152.2268371582031\n",
      "epoch 525\n",
      "test_train\n",
      "train mean loss=0.12833918817341328\n",
      "test_test\n",
      "test mean loss=1152.6179809570312\n",
      "epoch 526\n",
      "test_train\n",
      "train mean loss=0.12343765733142693\n",
      "test_test\n",
      "test mean loss=1153.1693725585938\n",
      "epoch 527\n",
      "test_train\n",
      "train mean loss=0.13233589784552655\n",
      "test_test\n",
      "test mean loss=1151.6112060546875\n",
      "epoch 528\n",
      "test_train\n",
      "train mean loss=0.13030563232799372\n",
      "test_test\n",
      "test mean loss=1152.15576171875\n",
      "epoch 529\n",
      "test_train\n",
      "train mean loss=0.13448791143794855\n",
      "test_test\n",
      "test mean loss=1153.2117614746094\n",
      "epoch 530\n",
      "test_train\n",
      "train mean loss=0.12679520001014075\n",
      "test_test\n",
      "test mean loss=1152.6890869140625\n",
      "epoch 531\n",
      "test_train\n",
      "train mean loss=0.13277280082305273\n",
      "test_test\n",
      "test mean loss=1152.0657348632812\n",
      "epoch 532\n",
      "test_train\n",
      "train mean loss=0.1298887183268865\n",
      "test_test\n",
      "test mean loss=1151.9920654296875\n",
      "epoch 533\n",
      "test_train\n",
      "train mean loss=0.13374304895599684\n",
      "test_test\n",
      "test mean loss=1153.5311889648438\n",
      "epoch 534\n",
      "test_train\n",
      "train mean loss=0.13426105119287968\n",
      "test_test\n",
      "test mean loss=1153.2044982910156\n",
      "epoch 535\n",
      "test_train\n",
      "train mean loss=0.13205477595329285\n",
      "test_test\n",
      "test mean loss=1154.0830688476562\n",
      "epoch 536\n",
      "test_train\n",
      "train mean loss=0.1274879208455483\n",
      "test_test\n",
      "test mean loss=1153.36767578125\n",
      "epoch 537\n",
      "test_train\n",
      "train mean loss=0.1280882159868876\n",
      "test_test\n",
      "test mean loss=1152.9603271484375\n",
      "epoch 538\n",
      "test_train\n",
      "train mean loss=0.13946479062239328\n",
      "test_test\n",
      "test mean loss=1153.19921875\n",
      "epoch 539\n",
      "test_train\n",
      "train mean loss=0.14348642776409784\n",
      "test_test\n",
      "test mean loss=1152.2379150390625\n",
      "epoch 540\n",
      "test_train\n",
      "train mean loss=0.13298646919429302\n",
      "test_test\n",
      "test mean loss=1153.2451171875\n",
      "epoch 541\n",
      "test_train\n",
      "train mean loss=0.12344569837053616\n",
      "test_test\n",
      "test mean loss=1153.0396728515625\n",
      "epoch 542\n",
      "test_train\n",
      "train mean loss=0.11971454570690791\n",
      "test_test\n",
      "test mean loss=1152.0369873046875\n",
      "epoch 543\n",
      "test_train\n",
      "train mean loss=0.12569680623710155\n",
      "test_test\n",
      "test mean loss=1152.423095703125\n",
      "epoch 544\n",
      "test_train\n",
      "train mean loss=0.12851951830089092\n",
      "test_test\n",
      "test mean loss=1152.5386352539062\n",
      "epoch 545\n",
      "test_train\n",
      "train mean loss=0.12102396848301093\n",
      "test_test\n",
      "test mean loss=1152.263427734375\n",
      "epoch 546\n",
      "test_train\n",
      "train mean loss=0.1251373626291752\n",
      "test_test\n",
      "test mean loss=1152.5414428710938\n",
      "epoch 547\n",
      "test_train\n",
      "train mean loss=0.12284600175917149\n",
      "test_test\n",
      "test mean loss=1151.6666870117188\n",
      "epoch 548\n",
      "test_train\n",
      "train mean loss=0.1232819960763057\n",
      "test_test\n",
      "test mean loss=1151.9273681640625\n",
      "epoch 549\n",
      "test_train\n",
      "train mean loss=0.13997237694760165\n",
      "test_test\n",
      "test mean loss=1152.4380187988281\n",
      "epoch 550\n",
      "test_train\n",
      "train mean loss=0.13101097693045935\n",
      "test_test\n",
      "test mean loss=1151.6639404296875\n",
      "epoch 551\n",
      "test_train\n",
      "train mean loss=0.1272840891033411\n",
      "test_test\n",
      "test mean loss=1151.5787353515625\n",
      "epoch 552\n",
      "test_train\n",
      "train mean loss=0.1260449836651484\n",
      "test_test\n",
      "test mean loss=1151.6029663085938\n",
      "epoch 553\n",
      "test_train\n",
      "train mean loss=0.12452968147893746\n",
      "test_test\n",
      "test mean loss=1151.595703125\n",
      "epoch 554\n",
      "test_train\n",
      "train mean loss=0.12773303625484309\n",
      "test_test\n",
      "test mean loss=1151.695556640625\n",
      "epoch 555\n",
      "test_train\n",
      "train mean loss=0.1303188136468331\n",
      "test_test\n",
      "test mean loss=1152.0501403808594\n",
      "epoch 556\n",
      "test_train\n",
      "train mean loss=0.12978598413368067\n",
      "test_test\n",
      "test mean loss=1151.9420776367188\n",
      "epoch 557\n",
      "test_train\n",
      "train mean loss=0.12745585851371288\n",
      "test_test\n",
      "test mean loss=1153.2145690917969\n",
      "epoch 558\n",
      "test_train\n",
      "train mean loss=0.12608830040941635\n",
      "test_test\n",
      "test mean loss=1152.9370727539062\n",
      "epoch 559\n",
      "test_train\n",
      "train mean loss=0.1279672340800365\n",
      "test_test\n",
      "test mean loss=1152.774658203125\n",
      "epoch 560\n",
      "test_train\n",
      "train mean loss=0.12725952950616679\n",
      "test_test\n",
      "test mean loss=1152.2998657226562\n",
      "epoch 561\n",
      "test_train\n",
      "train mean loss=0.12656184627364078\n",
      "test_test\n",
      "test mean loss=1152.5952758789062\n",
      "epoch 562\n",
      "test_train\n",
      "train mean loss=0.12409243142853181\n",
      "test_test\n",
      "test mean loss=1152.50830078125\n",
      "epoch 563\n",
      "test_train\n",
      "train mean loss=0.12421704983959596\n",
      "test_test\n",
      "test mean loss=1152.36279296875\n",
      "epoch 564\n",
      "test_train\n",
      "train mean loss=0.12409080068270366\n",
      "test_test\n",
      "test mean loss=1152.3387451171875\n",
      "epoch 565\n",
      "test_train\n",
      "train mean loss=0.12388226141532262\n",
      "test_test\n",
      "test mean loss=1152.9862670898438\n",
      "epoch 566\n",
      "test_train\n",
      "train mean loss=0.12119274244954188\n",
      "test_test\n",
      "test mean loss=1152.2055969238281\n",
      "epoch 567\n",
      "test_train\n",
      "train mean loss=0.12671334203332663\n",
      "test_test\n",
      "test mean loss=1153.1545104980469\n",
      "epoch 568\n",
      "test_train\n",
      "train mean loss=0.22990161056319872\n",
      "test_test\n",
      "test mean loss=1155.1527709960938\n",
      "epoch 569\n",
      "test_train\n",
      "train mean loss=0.12893062643706799\n",
      "test_test\n",
      "test mean loss=1153.1592407226562\n",
      "epoch 570\n",
      "test_train\n",
      "train mean loss=0.12459198323388894\n",
      "test_test\n",
      "test mean loss=1152.6220092773438\n",
      "epoch 571\n",
      "test_train\n",
      "train mean loss=0.12041251361370087\n",
      "test_test\n",
      "test mean loss=1152.6339416503906\n",
      "epoch 572\n",
      "test_train\n",
      "train mean loss=0.12435976540048917\n",
      "test_test\n",
      "test mean loss=1152.6826782226562\n",
      "epoch 573\n",
      "test_train\n",
      "train mean loss=0.1263196524232626\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1153.7948608398438\n",
      "epoch 574\n",
      "test_train\n",
      "train mean loss=0.1272228149076303\n",
      "test_test\n",
      "test mean loss=1153.7078857421875\n",
      "epoch 575\n",
      "test_train\n",
      "train mean loss=0.15634288638830185\n",
      "test_test\n",
      "test mean loss=1152.4081726074219\n",
      "epoch 576\n",
      "test_train\n",
      "train mean loss=0.128829433893164\n",
      "test_test\n",
      "test mean loss=1151.5628967285156\n",
      "epoch 577\n",
      "test_train\n",
      "train mean loss=0.129479189713796\n",
      "test_test\n",
      "test mean loss=1151.9149780273438\n",
      "epoch 578\n",
      "test_train\n",
      "train mean loss=0.11970696660379569\n",
      "test_test\n",
      "test mean loss=1152.1456298828125\n",
      "epoch 579\n",
      "test_train\n",
      "train mean loss=0.1198926642537117\n",
      "test_test\n",
      "test mean loss=1151.632568359375\n",
      "epoch 580\n",
      "test_train\n",
      "train mean loss=0.12479735972980659\n",
      "test_test\n",
      "test mean loss=1151.8014526367188\n",
      "epoch 581\n",
      "test_train\n",
      "train mean loss=0.12697530165314674\n",
      "test_test\n",
      "test mean loss=1152.5363159179688\n",
      "epoch 582\n",
      "test_train\n",
      "train mean loss=0.12606965067485967\n",
      "test_test\n",
      "test mean loss=1152.9047241210938\n",
      "epoch 583\n",
      "test_train\n",
      "train mean loss=0.1271274220198393\n",
      "test_test\n",
      "test mean loss=1152.1285705566406\n",
      "epoch 584\n",
      "test_train\n",
      "train mean loss=0.12084882395962875\n",
      "test_test\n",
      "test mean loss=1151.9855651855469\n",
      "epoch 585\n",
      "test_train\n",
      "train mean loss=0.12246173433959484\n",
      "test_test\n",
      "test mean loss=1152.8047180175781\n",
      "epoch 586\n",
      "test_train\n",
      "train mean loss=0.11904683522880077\n",
      "test_test\n",
      "test mean loss=1152.4602355957031\n",
      "epoch 587\n",
      "test_train\n",
      "train mean loss=0.14244508060316244\n",
      "test_test\n",
      "test mean loss=1152.4495239257812\n",
      "epoch 588\n",
      "test_train\n",
      "train mean loss=0.12876630698641142\n",
      "test_test\n",
      "test mean loss=1152.5581665039062\n",
      "epoch 589\n",
      "test_train\n",
      "train mean loss=0.11882016249001026\n",
      "test_test\n",
      "test mean loss=1152.5685424804688\n",
      "epoch 590\n",
      "test_train\n",
      "train mean loss=0.1227470301091671\n",
      "test_test\n",
      "test mean loss=1151.7571411132812\n",
      "epoch 591\n",
      "test_train\n",
      "train mean loss=0.12367947896321614\n",
      "test_test\n",
      "test mean loss=1152.8317565917969\n",
      "epoch 592\n",
      "test_train\n",
      "train mean loss=0.11796200058112542\n",
      "test_test\n",
      "test mean loss=1152.1343078613281\n",
      "epoch 593\n",
      "test_train\n",
      "train mean loss=0.12143268312017123\n",
      "test_test\n",
      "test mean loss=1152.9276733398438\n",
      "epoch 594\n",
      "test_train\n",
      "train mean loss=0.19286459311842918\n",
      "test_test\n",
      "test mean loss=1151.1793823242188\n",
      "epoch 595\n",
      "test_train\n",
      "train mean loss=0.13254515826702118\n",
      "test_test\n",
      "test mean loss=1150.9838256835938\n",
      "epoch 596\n",
      "test_train\n",
      "train mean loss=0.12480372563004494\n",
      "test_test\n",
      "test mean loss=1152.5599975585938\n",
      "epoch 597\n",
      "test_train\n",
      "train mean loss=0.12503299986322722\n",
      "test_test\n",
      "test mean loss=1152.0662841796875\n",
      "epoch 598\n",
      "test_train\n",
      "train mean loss=0.12481898752351601\n",
      "test_test\n",
      "test mean loss=1152.1062316894531\n",
      "epoch 599\n",
      "test_train\n",
      "train mean loss=0.12580684137841067\n",
      "test_test\n",
      "test mean loss=1152.4369506835938\n",
      "epoch 600\n",
      "test_train\n",
      "train mean loss=0.1272287710259358\n",
      "test_test\n",
      "test mean loss=1153.174072265625\n",
      "epoch 601\n",
      "test_train\n",
      "train mean loss=0.12632355901102224\n",
      "test_test\n",
      "test mean loss=1153.5234985351562\n",
      "epoch 602\n",
      "test_train\n",
      "train mean loss=0.1260391753166914\n",
      "test_test\n",
      "test mean loss=1152.8092651367188\n",
      "epoch 603\n",
      "test_train\n",
      "train mean loss=0.14805774576961994\n",
      "test_test\n",
      "test mean loss=1153.065185546875\n",
      "epoch 604\n",
      "test_train\n",
      "train mean loss=0.12931464177866778\n",
      "test_test\n",
      "test mean loss=1152.377685546875\n",
      "epoch 605\n",
      "test_train\n",
      "train mean loss=0.13311482469240823\n",
      "test_test\n",
      "test mean loss=1153.4464416503906\n",
      "epoch 606\n",
      "test_train\n",
      "train mean loss=0.11908312886953354\n",
      "test_test\n",
      "test mean loss=1152.665283203125\n",
      "epoch 607\n",
      "test_train\n",
      "train mean loss=0.11888066492974758\n",
      "test_test\n",
      "test mean loss=1153.0096435546875\n",
      "epoch 608\n",
      "test_train\n",
      "train mean loss=0.12065849515299003\n",
      "test_test\n",
      "test mean loss=1152.9934692382812\n",
      "epoch 609\n",
      "test_train\n",
      "train mean loss=0.11982485031088193\n",
      "test_test\n",
      "test mean loss=1152.2956237792969\n",
      "epoch 610\n",
      "test_train\n",
      "train mean loss=0.1261715218424797\n",
      "test_test\n",
      "test mean loss=1153.1158447265625\n",
      "epoch 611\n",
      "test_train\n",
      "train mean loss=0.12059865922977527\n",
      "test_test\n",
      "test mean loss=1152.8594665527344\n",
      "epoch 612\n",
      "test_train\n",
      "train mean loss=0.12817534804344177\n",
      "test_test\n",
      "test mean loss=1152.6564331054688\n",
      "epoch 613\n",
      "test_train\n",
      "train mean loss=0.12391391148169835\n",
      "test_test\n",
      "test mean loss=1152.7990112304688\n",
      "epoch 614\n",
      "test_train\n",
      "train mean loss=0.12491300298521917\n",
      "test_test\n",
      "test mean loss=1153.0794677734375\n",
      "epoch 615\n",
      "test_train\n",
      "train mean loss=0.13224148688217005\n",
      "test_test\n",
      "test mean loss=1153.5411376953125\n",
      "epoch 616\n",
      "test_train\n",
      "train mean loss=0.12780637480318546\n",
      "test_test\n",
      "test mean loss=1152.6836242675781\n",
      "epoch 617\n",
      "test_train\n",
      "train mean loss=0.12386222183704376\n",
      "test_test\n",
      "test mean loss=1152.1858215332031\n",
      "epoch 618\n",
      "test_train\n",
      "train mean loss=0.12063178575287263\n",
      "test_test\n",
      "test mean loss=1152.9207763671875\n",
      "epoch 619\n",
      "test_train\n",
      "train mean loss=0.13101501017808914\n",
      "test_test\n",
      "test mean loss=1152.2061462402344\n",
      "epoch 620\n",
      "test_train\n",
      "train mean loss=0.12781741904715696\n",
      "test_test\n",
      "test mean loss=1151.50146484375\n",
      "epoch 621\n",
      "test_train\n",
      "train mean loss=0.12418378206590812\n",
      "test_test\n",
      "test mean loss=1152.2333679199219\n",
      "epoch 622\n",
      "test_train\n",
      "train mean loss=0.12319695514937241\n",
      "test_test\n",
      "test mean loss=1153.1241455078125\n",
      "epoch 623\n",
      "test_train\n",
      "train mean loss=0.12090361366669337\n",
      "test_test\n",
      "test mean loss=1152.2019653320312\n",
      "epoch 624\n",
      "test_train\n",
      "train mean loss=0.14627248235046864\n",
      "test_test\n",
      "test mean loss=1150.8742065429688\n",
      "epoch 625\n",
      "test_train\n",
      "train mean loss=0.12173387594521046\n",
      "test_test\n",
      "test mean loss=1151.7703247070312\n",
      "epoch 626\n",
      "test_train\n",
      "train mean loss=0.12472928501665592\n",
      "test_test\n",
      "test mean loss=1152.5921630859375\n",
      "epoch 627\n",
      "test_train\n",
      "train mean loss=0.1295530398686727\n",
      "test_test\n",
      "test mean loss=1152.5869140625\n",
      "epoch 628\n",
      "test_train\n",
      "train mean loss=0.12363154099633296\n",
      "test_test\n",
      "test mean loss=1152.5481262207031\n",
      "epoch 629\n",
      "test_train\n",
      "train mean loss=0.12362871132791042\n",
      "test_test\n",
      "test mean loss=1152.9125366210938\n",
      "epoch 630\n",
      "test_train\n",
      "train mean loss=0.12436382037897904\n",
      "test_test\n",
      "test mean loss=1152.0752868652344\n",
      "epoch 631\n",
      "test_train\n",
      "train mean loss=0.12598833379646143\n",
      "test_test\n",
      "test mean loss=1150.9828491210938\n",
      "epoch 632\n",
      "test_train\n",
      "train mean loss=0.12695198009411493\n",
      "test_test\n",
      "test mean loss=1151.5767211914062\n",
      "epoch 633\n",
      "test_train\n",
      "train mean loss=0.12043994540969531\n",
      "test_test\n",
      "test mean loss=1152.1829833984375\n",
      "epoch 634\n",
      "test_train\n",
      "train mean loss=0.11993466131389141\n",
      "test_test\n",
      "test mean loss=1152.4758911132812\n",
      "epoch 635\n",
      "test_train\n",
      "train mean loss=0.12075572026272614\n",
      "test_test\n",
      "test mean loss=1152.5103759765625\n",
      "epoch 636\n",
      "test_train\n",
      "train mean loss=0.11818371216456096\n",
      "test_test\n",
      "test mean loss=1152.1681518554688\n",
      "epoch 637\n",
      "test_train\n",
      "train mean loss=0.11860729319353898\n",
      "test_test\n",
      "test mean loss=1151.9398803710938\n",
      "epoch 638\n",
      "test_train\n",
      "train mean loss=0.11825338378548622\n",
      "test_test\n",
      "test mean loss=1153.247314453125\n",
      "epoch 639\n",
      "test_train\n",
      "train mean loss=0.11991114790240924\n",
      "test_test\n",
      "test mean loss=1153.5201110839844\n",
      "epoch 640\n",
      "test_train\n",
      "train mean loss=0.13962860219180584\n",
      "test_test\n",
      "test mean loss=1154.7391967773438\n",
      "epoch 641\n",
      "test_train\n",
      "train mean loss=0.12271965605517228\n",
      "test_test\n",
      "test mean loss=1153.4857177734375\n",
      "epoch 642\n",
      "test_train\n",
      "train mean loss=0.11889856743315856\n",
      "test_test\n",
      "test mean loss=1153.2904663085938\n",
      "epoch 643\n",
      "test_train\n",
      "train mean loss=0.12468582081298034\n",
      "test_test\n",
      "test mean loss=1153.3760986328125\n",
      "epoch 644\n",
      "test_train\n",
      "train mean loss=0.12617509439587593\n",
      "test_test\n",
      "test mean loss=1152.0681762695312\n",
      "epoch 645\n",
      "test_train\n",
      "train mean loss=0.12225616350769997\n",
      "test_test\n",
      "test mean loss=1152.8344116210938\n",
      "epoch 646\n",
      "test_train\n",
      "train mean loss=0.12513876085480055\n",
      "test_test\n",
      "test mean loss=1153.6080017089844\n",
      "epoch 647\n",
      "test_train\n",
      "train mean loss=0.11926658016939957\n",
      "test_test\n",
      "test mean loss=1153.2012939453125\n",
      "epoch 648\n",
      "test_train\n",
      "train mean loss=0.12274308564762275\n",
      "test_test\n",
      "test mean loss=1152.4027099609375\n",
      "epoch 649\n",
      "test_train\n",
      "train mean loss=0.11757393615941207\n",
      "test_test\n",
      "test mean loss=1152.4994201660156\n",
      "epoch 650\n",
      "test_train\n",
      "train mean loss=0.12084563728421926\n",
      "test_test\n",
      "test mean loss=1152.3381958007812\n",
      "epoch 651\n",
      "test_train\n",
      "train mean loss=0.23288749530911446\n",
      "test_test\n",
      "test mean loss=1155.498046875\n",
      "epoch 652\n",
      "test_train\n",
      "train mean loss=0.13441062470277151\n",
      "test_test\n",
      "test mean loss=1154.1545104980469\n",
      "epoch 653\n",
      "test_train\n",
      "train mean loss=0.12535899877548218\n",
      "test_test\n",
      "test mean loss=1153.5174560546875\n",
      "epoch 654\n",
      "test_train\n",
      "train mean loss=0.1259381640702486\n",
      "test_test\n",
      "test mean loss=1152.9590148925781\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 655\n",
      "test_train\n",
      "train mean loss=0.12074689132471879\n",
      "test_test\n",
      "test mean loss=1153.1091613769531\n",
      "epoch 656\n",
      "test_train\n",
      "train mean loss=0.12092264896879594\n",
      "test_test\n",
      "test mean loss=1152.95166015625\n",
      "epoch 657\n",
      "test_train\n",
      "train mean loss=0.12538067872325578\n",
      "test_test\n",
      "test mean loss=1152.427001953125\n",
      "epoch 658\n",
      "test_train\n",
      "train mean loss=0.12597995810210705\n",
      "test_test\n",
      "test mean loss=1151.3630981445312\n",
      "epoch 659\n",
      "test_train\n",
      "train mean loss=0.11945633093516032\n",
      "test_test\n",
      "test mean loss=1152.7157897949219\n",
      "epoch 660\n",
      "test_train\n",
      "train mean loss=0.12047660412887733\n",
      "test_test\n",
      "test mean loss=1153.550048828125\n",
      "epoch 661\n",
      "test_train\n",
      "train mean loss=0.12847631300489107\n",
      "test_test\n",
      "test mean loss=1152.535888671875\n",
      "epoch 662\n",
      "test_train\n",
      "train mean loss=0.1238894434645772\n",
      "test_test\n",
      "test mean loss=1152.0618591308594\n",
      "epoch 663\n",
      "test_train\n",
      "train mean loss=0.11932621151208878\n",
      "test_test\n",
      "test mean loss=1151.4160461425781\n",
      "epoch 664\n",
      "test_train\n",
      "train mean loss=0.12439974521597226\n",
      "test_test\n",
      "test mean loss=1153.4374694824219\n",
      "epoch 665\n",
      "test_train\n",
      "train mean loss=0.12405205704271793\n",
      "test_test\n",
      "test mean loss=1152.641845703125\n",
      "epoch 666\n",
      "test_train\n",
      "train mean loss=0.11726273037493229\n",
      "test_test\n",
      "test mean loss=1152.3582763671875\n",
      "epoch 667\n",
      "test_train\n",
      "train mean loss=0.11961276705066363\n",
      "test_test\n",
      "test mean loss=1152.5404968261719\n",
      "epoch 668\n",
      "test_train\n",
      "train mean loss=0.12963361044724783\n",
      "test_test\n",
      "test mean loss=1152.8015747070312\n",
      "epoch 669\n",
      "test_train\n",
      "train mean loss=0.11684542149305344\n",
      "test_test\n",
      "test mean loss=1152.6945190429688\n",
      "epoch 670\n",
      "test_train\n",
      "train mean loss=0.11641038705905278\n",
      "test_test\n",
      "test mean loss=1152.6383666992188\n",
      "epoch 671\n",
      "test_train\n",
      "train mean loss=0.11987988837063313\n",
      "test_test\n",
      "test mean loss=1152.8133544921875\n",
      "epoch 672\n",
      "test_train\n",
      "train mean loss=0.12343258472780387\n",
      "test_test\n",
      "test mean loss=1152.2452392578125\n",
      "epoch 673\n",
      "test_train\n",
      "train mean loss=0.11620947377135356\n",
      "test_test\n",
      "test mean loss=1152.3897094726562\n",
      "epoch 674\n",
      "test_train\n",
      "train mean loss=0.11954509528974692\n",
      "test_test\n",
      "test mean loss=1152.8427124023438\n",
      "epoch 675\n",
      "test_train\n",
      "train mean loss=0.16069208706418672\n",
      "test_test\n",
      "test mean loss=1154.0021362304688\n",
      "epoch 676\n",
      "test_train\n",
      "train mean loss=0.13717741208771864\n",
      "test_test\n",
      "test mean loss=1152.7643432617188\n",
      "epoch 677\n",
      "test_train\n",
      "train mean loss=0.12434842499593894\n",
      "test_test\n",
      "test mean loss=1151.8344116210938\n",
      "epoch 678\n",
      "test_train\n",
      "train mean loss=0.12180858912567298\n",
      "test_test\n",
      "test mean loss=1152.67919921875\n",
      "epoch 679\n",
      "test_train\n",
      "train mean loss=0.12307497796912988\n",
      "test_test\n",
      "test mean loss=1153.4275512695312\n",
      "epoch 680\n",
      "test_train\n",
      "train mean loss=0.12888220076759657\n",
      "test_test\n",
      "test mean loss=1153.5900268554688\n",
      "epoch 681\n",
      "test_train\n",
      "train mean loss=0.12541296581427255\n",
      "test_test\n",
      "test mean loss=1154.3124389648438\n",
      "epoch 682\n",
      "test_train\n",
      "train mean loss=0.1272611649086078\n",
      "test_test\n",
      "test mean loss=1153.115234375\n",
      "epoch 683\n",
      "test_train\n",
      "train mean loss=0.1255219460775455\n",
      "test_test\n",
      "test mean loss=1153.0883178710938\n",
      "epoch 684\n",
      "test_train\n",
      "train mean loss=0.13144091330468655\n",
      "test_test\n",
      "test mean loss=1153.4391479492188\n",
      "epoch 685\n",
      "test_train\n",
      "train mean loss=0.12206450228889783\n",
      "test_test\n",
      "test mean loss=1153.3619995117188\n",
      "epoch 686\n",
      "test_train\n",
      "train mean loss=0.11680102037886779\n",
      "test_test\n",
      "test mean loss=1152.7865600585938\n",
      "epoch 687\n",
      "test_train\n",
      "train mean loss=0.12187156019111474\n",
      "test_test\n",
      "test mean loss=1153.1375122070312\n",
      "epoch 688\n",
      "test_train\n",
      "train mean loss=0.13138644397258759\n",
      "test_test\n",
      "test mean loss=1153.7778930664062\n",
      "epoch 689\n",
      "test_train\n",
      "train mean loss=0.1232757642865181\n",
      "test_test\n",
      "test mean loss=1152.6809692382812\n",
      "epoch 690\n",
      "test_train\n",
      "train mean loss=0.12345865275710821\n",
      "test_test\n",
      "test mean loss=1152.5468139648438\n",
      "epoch 691\n",
      "test_train\n",
      "train mean loss=0.12206449545919895\n",
      "test_test\n",
      "test mean loss=1153.3283081054688\n",
      "epoch 692\n",
      "test_train\n",
      "train mean loss=0.1233013483385245\n",
      "test_test\n",
      "test mean loss=1153.2119140625\n",
      "epoch 693\n",
      "test_train\n",
      "train mean loss=0.12176949468751748\n",
      "test_test\n",
      "test mean loss=1153.6034240722656\n",
      "epoch 694\n",
      "test_train\n",
      "train mean loss=0.12094324268400669\n",
      "test_test\n",
      "test mean loss=1153.4183959960938\n",
      "epoch 695\n",
      "test_train\n",
      "train mean loss=0.12038082381089528\n",
      "test_test\n",
      "test mean loss=1153.5034790039062\n",
      "epoch 696\n",
      "test_train\n",
      "train mean loss=0.12152084025243919\n",
      "test_test\n",
      "test mean loss=1152.5453491210938\n",
      "epoch 697\n",
      "test_train\n",
      "train mean loss=0.125057273854812\n",
      "test_test\n",
      "test mean loss=1153.2411193847656\n",
      "epoch 698\n",
      "test_train\n",
      "train mean loss=0.12122265622019768\n",
      "test_test\n",
      "test mean loss=1153.3835144042969\n",
      "epoch 699\n",
      "test_train\n",
      "train mean loss=0.1252316286166509\n",
      "test_test\n",
      "test mean loss=1155.545166015625\n",
      "epoch 700\n",
      "test_train\n",
      "train mean loss=0.11745581030845642\n",
      "test_test\n",
      "test mean loss=1153.6784057617188\n",
      "epoch 701\n",
      "test_train\n",
      "train mean loss=0.11785074695944786\n",
      "test_test\n",
      "test mean loss=1154.5476379394531\n",
      "epoch 702\n",
      "test_train\n",
      "train mean loss=0.11797954980283976\n",
      "test_test\n",
      "test mean loss=1153.9295654296875\n",
      "epoch 703\n",
      "test_train\n",
      "train mean loss=0.12130301135281722\n",
      "test_test\n",
      "test mean loss=1154.1871032714844\n",
      "epoch 704\n",
      "test_train\n",
      "train mean loss=0.12722641664246717\n",
      "test_test\n",
      "test mean loss=1153.165771484375\n",
      "epoch 705\n",
      "test_train\n",
      "train mean loss=0.12114705704152584\n",
      "test_test\n",
      "test mean loss=1152.862060546875\n",
      "epoch 706\n",
      "test_train\n",
      "train mean loss=0.12162625541289647\n",
      "test_test\n",
      "test mean loss=1153.5426330566406\n",
      "epoch 707\n",
      "test_train\n",
      "train mean loss=0.12482285064955552\n",
      "test_test\n",
      "test mean loss=1153.0328063964844\n",
      "epoch 708\n",
      "test_train\n",
      "train mean loss=0.12597837671637535\n",
      "test_test\n",
      "test mean loss=1153.6973876953125\n",
      "epoch 709\n",
      "test_train\n",
      "train mean loss=0.11740405112504959\n",
      "test_test\n",
      "test mean loss=1153.9569702148438\n",
      "epoch 710\n",
      "test_train\n",
      "train mean loss=0.12861965969204903\n",
      "test_test\n",
      "test mean loss=1154.239990234375\n",
      "epoch 711\n",
      "test_train\n",
      "train mean loss=0.11645402448872726\n",
      "test_test\n",
      "test mean loss=1153.1355590820312\n",
      "epoch 712\n",
      "test_train\n",
      "train mean loss=0.12324602529406548\n",
      "test_test\n",
      "test mean loss=1153.6073608398438\n",
      "epoch 713\n",
      "test_train\n",
      "train mean loss=0.12446893937885761\n",
      "test_test\n",
      "test mean loss=1153.6690979003906\n",
      "epoch 714\n",
      "test_train\n",
      "train mean loss=0.12142349313944578\n",
      "test_test\n",
      "test mean loss=1154.509521484375\n",
      "epoch 715\n",
      "test_train\n",
      "train mean loss=0.11834286898374557\n",
      "test_test\n",
      "test mean loss=1154.2501831054688\n",
      "epoch 716\n",
      "test_train\n",
      "train mean loss=0.12322359904646873\n",
      "test_test\n",
      "test mean loss=1154.1946716308594\n",
      "epoch 717\n",
      "test_train\n",
      "train mean loss=0.12201358750462532\n",
      "test_test\n",
      "test mean loss=1153.9723510742188\n",
      "epoch 718\n",
      "test_train\n",
      "train mean loss=0.12062008741001289\n",
      "test_test\n",
      "test mean loss=1153.4579467773438\n",
      "epoch 719\n",
      "test_train\n",
      "train mean loss=0.11791122425347567\n",
      "test_test\n",
      "test mean loss=1153.6320190429688\n",
      "epoch 720\n",
      "test_train\n",
      "train mean loss=0.13368641771376133\n",
      "test_test\n",
      "test mean loss=1152.6053771972656\n",
      "epoch 721\n",
      "test_train\n",
      "train mean loss=0.11921242903918028\n",
      "test_test\n",
      "test mean loss=1154.4978942871094\n",
      "epoch 722\n",
      "test_train\n",
      "train mean loss=0.12115991488099098\n",
      "test_test\n",
      "test mean loss=1154.3720703125\n",
      "epoch 723\n",
      "test_train\n",
      "train mean loss=0.2457913433512052\n",
      "test_test\n",
      "test mean loss=1157.2381896972656\n",
      "epoch 724\n",
      "test_train\n",
      "train mean loss=0.15481220682462057\n",
      "test_test\n",
      "test mean loss=1156.3638916015625\n",
      "epoch 725\n",
      "test_train\n",
      "train mean loss=0.14465352209905782\n",
      "test_test\n",
      "test mean loss=1155.5166015625\n",
      "epoch 726\n",
      "test_train\n",
      "train mean loss=0.14428257445494333\n",
      "test_test\n",
      "test mean loss=1155.9859008789062\n",
      "epoch 727\n",
      "test_train\n",
      "train mean loss=0.14404835862418017\n",
      "test_test\n",
      "test mean loss=1154.9757385253906\n",
      "epoch 728\n",
      "test_train\n",
      "train mean loss=0.13587248139083385\n",
      "test_test\n",
      "test mean loss=1154.8494873046875\n",
      "epoch 729\n",
      "test_train\n",
      "train mean loss=0.13880215709408125\n",
      "test_test\n",
      "test mean loss=1155.2091979980469\n",
      "epoch 730\n",
      "test_train\n",
      "train mean loss=0.13568111384908357\n",
      "test_test\n",
      "test mean loss=1155.2860107421875\n",
      "epoch 731\n",
      "test_train\n",
      "train mean loss=0.14163835905492306\n",
      "test_test\n",
      "test mean loss=1155.0468139648438\n",
      "epoch 732\n",
      "test_train\n",
      "train mean loss=0.13496607976655164\n",
      "test_test\n",
      "test mean loss=1154.1717529296875\n",
      "epoch 733\n",
      "test_train\n",
      "train mean loss=0.13700305266926685\n",
      "test_test\n",
      "test mean loss=1153.991455078125\n",
      "epoch 734\n",
      "test_train\n",
      "train mean loss=0.12775853338340917\n",
      "test_test\n",
      "test mean loss=1154.2054748535156\n",
      "epoch 735\n",
      "test_train\n",
      "train mean loss=0.1275218619654576\n",
      "test_test\n",
      "test mean loss=1154.6662292480469\n",
      "epoch 736\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.12629422824829817\n",
      "test_test\n",
      "test mean loss=1154.8597412109375\n",
      "epoch 737\n",
      "test_train\n",
      "train mean loss=0.13012504391372204\n",
      "test_test\n",
      "test mean loss=1156.12841796875\n",
      "epoch 738\n",
      "test_train\n",
      "train mean loss=0.13137965959807238\n",
      "test_test\n",
      "test mean loss=1155.1043701171875\n",
      "epoch 739\n",
      "test_train\n",
      "train mean loss=0.13027998556693396\n",
      "test_test\n",
      "test mean loss=1155.2185668945312\n",
      "epoch 740\n",
      "test_train\n",
      "train mean loss=0.12714428082108498\n",
      "test_test\n",
      "test mean loss=1154.3269653320312\n",
      "epoch 741\n",
      "test_train\n",
      "train mean loss=0.13184542457262674\n",
      "test_test\n",
      "test mean loss=1153.5114135742188\n",
      "epoch 742\n",
      "test_train\n",
      "train mean loss=0.1331666981180509\n",
      "test_test\n",
      "test mean loss=1154.7542724609375\n",
      "epoch 743\n",
      "test_train\n",
      "train mean loss=0.12763108188907304\n",
      "test_test\n",
      "test mean loss=1154.2970581054688\n",
      "epoch 744\n",
      "test_train\n",
      "train mean loss=0.12525138693551222\n",
      "test_test\n",
      "test mean loss=1153.1995849609375\n",
      "epoch 745\n",
      "test_train\n",
      "train mean loss=0.1285448552419742\n",
      "test_test\n",
      "test mean loss=1153.5191650390625\n",
      "epoch 746\n",
      "test_train\n",
      "train mean loss=0.12485121469944715\n",
      "test_test\n",
      "test mean loss=1154.3114013671875\n",
      "epoch 747\n",
      "test_train\n",
      "train mean loss=0.1254973572989305\n",
      "test_test\n",
      "test mean loss=1154.0982360839844\n",
      "epoch 748\n",
      "test_train\n",
      "train mean loss=0.1282467395067215\n",
      "test_test\n",
      "test mean loss=1153.8233337402344\n",
      "epoch 749\n",
      "test_train\n",
      "train mean loss=0.24952845896283785\n",
      "test_test\n",
      "test mean loss=1155.9382019042969\n",
      "epoch 750\n",
      "test_train\n",
      "train mean loss=0.1353688177963098\n",
      "test_test\n",
      "test mean loss=1154.959716796875\n",
      "epoch 751\n",
      "test_train\n",
      "train mean loss=0.12556660113235316\n",
      "test_test\n",
      "test mean loss=1154.4776611328125\n",
      "epoch 752\n",
      "test_train\n",
      "train mean loss=0.12282617452243964\n",
      "test_test\n",
      "test mean loss=1153.263916015625\n",
      "epoch 753\n",
      "test_train\n",
      "train mean loss=0.12220535365243752\n",
      "test_test\n",
      "test mean loss=1154.3773498535156\n",
      "epoch 754\n",
      "test_train\n",
      "train mean loss=0.12036964079986016\n",
      "test_test\n",
      "test mean loss=1153.1208190917969\n",
      "epoch 755\n",
      "test_train\n",
      "train mean loss=0.11802511848509312\n",
      "test_test\n",
      "test mean loss=1153.2835083007812\n",
      "epoch 756\n",
      "test_train\n",
      "train mean loss=0.12279087180892627\n",
      "test_test\n",
      "test mean loss=1154.1568603515625\n",
      "epoch 757\n",
      "test_train\n",
      "train mean loss=0.12700027817239365\n",
      "test_test\n",
      "test mean loss=1153.6382141113281\n",
      "epoch 758\n",
      "test_train\n",
      "train mean loss=0.1219370849430561\n",
      "test_test\n",
      "test mean loss=1153.5673828125\n",
      "epoch 759\n",
      "test_train\n",
      "train mean loss=0.12418776998917262\n",
      "test_test\n",
      "test mean loss=1154.0526123046875\n",
      "epoch 760\n",
      "test_train\n",
      "train mean loss=0.12523505029579005\n",
      "test_test\n",
      "test mean loss=1152.6763000488281\n",
      "epoch 761\n",
      "test_train\n",
      "train mean loss=0.12571834648648897\n",
      "test_test\n",
      "test mean loss=1153.2268371582031\n",
      "epoch 762\n",
      "test_train\n",
      "train mean loss=0.12182331581910451\n",
      "test_test\n",
      "test mean loss=1152.359619140625\n",
      "epoch 763\n",
      "test_train\n",
      "train mean loss=0.11978441166381042\n",
      "test_test\n",
      "test mean loss=1154.2164611816406\n",
      "epoch 764\n",
      "test_train\n",
      "train mean loss=0.12000367324799299\n",
      "test_test\n",
      "test mean loss=1155.16064453125\n",
      "epoch 765\n",
      "test_train\n",
      "train mean loss=0.11912656823794048\n",
      "test_test\n",
      "test mean loss=1154.6278076171875\n",
      "epoch 766\n",
      "test_train\n",
      "train mean loss=0.12021052837371826\n",
      "test_test\n",
      "test mean loss=1154.155517578125\n",
      "epoch 767\n",
      "test_train\n",
      "train mean loss=0.1187570517261823\n",
      "test_test\n",
      "test mean loss=1153.7804565429688\n",
      "epoch 768\n",
      "test_train\n",
      "train mean loss=0.11855717158565919\n",
      "test_test\n",
      "test mean loss=1154.5550231933594\n",
      "epoch 769\n",
      "test_train\n",
      "train mean loss=0.11697315610945225\n",
      "test_test\n",
      "test mean loss=1154.7488708496094\n",
      "epoch 770\n",
      "test_train\n",
      "train mean loss=0.11855212102333705\n",
      "test_test\n",
      "test mean loss=1154.184326171875\n",
      "epoch 771\n",
      "test_train\n",
      "train mean loss=0.12422868733604749\n",
      "test_test\n",
      "test mean loss=1152.7507934570312\n",
      "epoch 772\n",
      "test_train\n",
      "train mean loss=0.11864826455712318\n",
      "test_test\n",
      "test mean loss=1152.7047729492188\n",
      "epoch 773\n",
      "test_train\n",
      "train mean loss=0.11661766904095809\n",
      "test_test\n",
      "test mean loss=1153.1483764648438\n",
      "epoch 774\n",
      "test_train\n",
      "train mean loss=0.12069036966810624\n",
      "test_test\n",
      "test mean loss=1153.9866943359375\n",
      "epoch 775\n",
      "test_train\n",
      "train mean loss=0.11830364726483822\n",
      "test_test\n",
      "test mean loss=1154.5565795898438\n",
      "epoch 776\n",
      "test_train\n",
      "train mean loss=0.11825894191861153\n",
      "test_test\n",
      "test mean loss=1153.1152648925781\n",
      "epoch 777\n",
      "test_train\n",
      "train mean loss=0.11781645535180967\n",
      "test_test\n",
      "test mean loss=1153.94921875\n",
      "epoch 778\n",
      "test_train\n",
      "train mean loss=0.11826077538232009\n",
      "test_test\n",
      "test mean loss=1154.3828125\n",
      "epoch 779\n",
      "test_train\n",
      "train mean loss=0.12012776918709278\n",
      "test_test\n",
      "test mean loss=1154.5310668945312\n",
      "epoch 780\n",
      "test_train\n",
      "train mean loss=0.11366757471114397\n",
      "test_test\n",
      "test mean loss=1154.6644897460938\n",
      "epoch 781\n",
      "test_train\n",
      "train mean loss=0.1174733725686868\n",
      "test_test\n",
      "test mean loss=1152.8125\n",
      "epoch 782\n",
      "test_train\n",
      "train mean loss=0.11452738319834073\n",
      "test_test\n",
      "test mean loss=1151.7510986328125\n",
      "epoch 783\n",
      "test_train\n",
      "train mean loss=0.11636447844405969\n",
      "test_test\n",
      "test mean loss=1153.3873596191406\n",
      "epoch 784\n",
      "test_train\n",
      "train mean loss=0.11984867664674918\n",
      "test_test\n",
      "test mean loss=1154.4536743164062\n",
      "epoch 785\n",
      "test_train\n",
      "train mean loss=0.12230479965607326\n",
      "test_test\n",
      "test mean loss=1153.6593322753906\n",
      "epoch 786\n",
      "test_train\n",
      "train mean loss=0.11170934575299422\n",
      "test_test\n",
      "test mean loss=1153.11181640625\n",
      "epoch 787\n",
      "test_train\n",
      "train mean loss=0.112745750695467\n",
      "test_test\n",
      "test mean loss=1152.7559509277344\n",
      "epoch 788\n",
      "test_train\n",
      "train mean loss=0.11383110160628955\n",
      "test_test\n",
      "test mean loss=1153.3632202148438\n",
      "epoch 789\n",
      "test_train\n",
      "train mean loss=0.13357571264108023\n",
      "test_test\n",
      "test mean loss=1153.1387329101562\n",
      "epoch 790\n",
      "test_train\n",
      "train mean loss=0.1168776595344146\n",
      "test_test\n",
      "test mean loss=1153.1510009765625\n",
      "epoch 791\n",
      "test_train\n",
      "train mean loss=0.11754929864158233\n",
      "test_test\n",
      "test mean loss=1153.78857421875\n",
      "epoch 792\n",
      "test_train\n",
      "train mean loss=0.11213400276998679\n",
      "test_test\n",
      "test mean loss=1153.3257751464844\n",
      "epoch 793\n",
      "test_train\n",
      "train mean loss=0.11595523667832215\n",
      "test_test\n",
      "test mean loss=1153.878662109375\n",
      "epoch 794\n",
      "test_train\n",
      "train mean loss=0.11657996413608392\n",
      "test_test\n",
      "test mean loss=1153.4789123535156\n",
      "epoch 795\n",
      "test_train\n",
      "train mean loss=0.11848420773943265\n",
      "test_test\n",
      "test mean loss=1153.6492309570312\n",
      "epoch 796\n",
      "test_train\n",
      "train mean loss=0.1160953938961029\n",
      "test_test\n",
      "test mean loss=1153.7827758789062\n",
      "epoch 797\n",
      "test_train\n",
      "train mean loss=0.11257195038100083\n",
      "test_test\n",
      "test mean loss=1153.305908203125\n",
      "epoch 798\n",
      "test_train\n",
      "train mean loss=0.1174976984038949\n",
      "test_test\n",
      "test mean loss=1154.0956726074219\n",
      "epoch 799\n",
      "test_train\n",
      "train mean loss=0.1358505313595136\n",
      "test_test\n",
      "test mean loss=1152.7053833007812\n",
      "epoch 800\n",
      "test_train\n",
      "train mean loss=0.11993286106735468\n",
      "test_test\n",
      "test mean loss=1153.636962890625\n",
      "epoch 801\n",
      "test_train\n",
      "train mean loss=0.11492678274710973\n",
      "test_test\n",
      "test mean loss=1154.475341796875\n",
      "epoch 802\n",
      "test_train\n",
      "train mean loss=0.1170635987073183\n",
      "test_test\n",
      "test mean loss=1153.795654296875\n",
      "epoch 803\n",
      "test_train\n",
      "train mean loss=0.11747652105987072\n",
      "test_test\n",
      "test mean loss=1154.6070556640625\n",
      "epoch 804\n",
      "test_train\n",
      "train mean loss=0.11914579259852569\n",
      "test_test\n",
      "test mean loss=1154.620361328125\n",
      "epoch 805\n",
      "test_train\n",
      "train mean loss=0.11606742379566033\n",
      "test_test\n",
      "test mean loss=1153.6474609375\n",
      "epoch 806\n",
      "test_train\n",
      "train mean loss=0.11882839010407527\n",
      "test_test\n",
      "test mean loss=1153.9531555175781\n",
      "epoch 807\n",
      "test_train\n",
      "train mean loss=0.11450565047562122\n",
      "test_test\n",
      "test mean loss=1153.520751953125\n",
      "epoch 808\n",
      "test_train\n",
      "train mean loss=0.11341687757521868\n",
      "test_test\n",
      "test mean loss=1153.7489624023438\n",
      "epoch 809\n",
      "test_train\n",
      "train mean loss=0.1172995970894893\n",
      "test_test\n",
      "test mean loss=1153.207763671875\n",
      "epoch 810\n",
      "test_train\n",
      "train mean loss=0.11501656534771125\n",
      "test_test\n",
      "test mean loss=1153.5686340332031\n",
      "epoch 811\n",
      "test_train\n",
      "train mean loss=0.12413373589515686\n",
      "test_test\n",
      "test mean loss=1153.7084045410156\n",
      "epoch 812\n",
      "test_train\n",
      "train mean loss=0.11719732421139877\n",
      "test_test\n",
      "test mean loss=1154.816162109375\n",
      "epoch 813\n",
      "test_train\n",
      "train mean loss=0.11769268413384755\n",
      "test_test\n",
      "test mean loss=1154.2153930664062\n",
      "epoch 814\n",
      "test_train\n",
      "train mean loss=0.1325164077182611\n",
      "test_test\n",
      "test mean loss=1153.7838134765625\n",
      "epoch 815\n",
      "test_train\n",
      "train mean loss=0.12496711562077205\n",
      "test_test\n",
      "test mean loss=1152.995849609375\n",
      "epoch 816\n",
      "test_train\n",
      "train mean loss=0.11943910643458366\n",
      "test_test\n",
      "test mean loss=1153.6305847167969\n",
      "epoch 817\n",
      "test_train\n",
      "train mean loss=0.1321240533143282\n",
      "test_test\n",
      "test mean loss=1151.865478515625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 818\n",
      "test_train\n",
      "train mean loss=0.12336394439140956\n",
      "test_test\n",
      "test mean loss=1153.3228454589844\n",
      "epoch 819\n",
      "test_train\n",
      "train mean loss=0.11543284232417743\n",
      "test_test\n",
      "test mean loss=1152.866455078125\n",
      "epoch 820\n",
      "test_train\n",
      "train mean loss=0.11842884340633948\n",
      "test_test\n",
      "test mean loss=1153.72900390625\n",
      "epoch 821\n",
      "test_train\n",
      "train mean loss=0.11901722103357315\n",
      "test_test\n",
      "test mean loss=1153.5548095703125\n",
      "epoch 822\n",
      "test_train\n",
      "train mean loss=0.1130113663772742\n",
      "test_test\n",
      "test mean loss=1154.9666442871094\n",
      "epoch 823\n",
      "test_train\n",
      "train mean loss=0.11800336775680383\n",
      "test_test\n",
      "test mean loss=1153.637451171875\n",
      "epoch 824\n",
      "test_train\n",
      "train mean loss=0.11932133014003436\n",
      "test_test\n",
      "test mean loss=1154.4156494140625\n",
      "epoch 825\n",
      "test_train\n",
      "train mean loss=0.12074969274302323\n",
      "test_test\n",
      "test mean loss=1154.2133178710938\n",
      "epoch 826\n",
      "test_train\n",
      "train mean loss=0.11918118502944708\n",
      "test_test\n",
      "test mean loss=1153.351806640625\n",
      "epoch 827\n",
      "test_train\n",
      "train mean loss=0.1142417173832655\n",
      "test_test\n",
      "test mean loss=1153.4072875976562\n",
      "epoch 828\n",
      "test_train\n",
      "train mean loss=0.11583690655728181\n",
      "test_test\n",
      "test mean loss=1153.2608032226562\n",
      "epoch 829\n",
      "test_train\n",
      "train mean loss=0.12340649403631687\n",
      "test_test\n",
      "test mean loss=1153.2866821289062\n",
      "epoch 830\n",
      "test_train\n",
      "train mean loss=0.11868306683997314\n",
      "test_test\n",
      "test mean loss=1153.4339599609375\n",
      "epoch 831\n",
      "test_train\n",
      "train mean loss=0.11909216238806646\n",
      "test_test\n",
      "test mean loss=1154.2724609375\n",
      "epoch 832\n",
      "test_train\n",
      "train mean loss=0.1170445221165816\n",
      "test_test\n",
      "test mean loss=1153.62646484375\n",
      "epoch 833\n",
      "test_train\n",
      "train mean loss=0.11673729307949543\n",
      "test_test\n",
      "test mean loss=1154.3836669921875\n",
      "epoch 834\n",
      "test_train\n",
      "train mean loss=0.11561738202969234\n",
      "test_test\n",
      "test mean loss=1153.6024780273438\n",
      "epoch 835\n",
      "test_train\n",
      "train mean loss=0.11832614926000436\n",
      "test_test\n",
      "test mean loss=1153.8327026367188\n",
      "epoch 836\n",
      "test_train\n",
      "train mean loss=0.11444076430052519\n",
      "test_test\n",
      "test mean loss=1154.0049438476562\n",
      "epoch 837\n",
      "test_train\n",
      "train mean loss=0.11677731449405353\n",
      "test_test\n",
      "test mean loss=1153.9216918945312\n",
      "epoch 838\n",
      "test_train\n",
      "train mean loss=0.11552610682944457\n",
      "test_test\n",
      "test mean loss=1154.1343078613281\n",
      "epoch 839\n",
      "test_train\n",
      "train mean loss=0.19021450852354368\n",
      "test_test\n",
      "test mean loss=1154.1921081542969\n",
      "epoch 840\n",
      "test_train\n",
      "train mean loss=0.1431183908134699\n",
      "test_test\n",
      "test mean loss=1153.9035034179688\n",
      "epoch 841\n",
      "test_train\n",
      "train mean loss=0.11946251212308805\n",
      "test_test\n",
      "test mean loss=1153.1242065429688\n",
      "epoch 842\n",
      "test_train\n",
      "train mean loss=0.12571699544787407\n",
      "test_test\n",
      "test mean loss=1153.0581970214844\n",
      "epoch 843\n",
      "test_train\n",
      "train mean loss=0.11492184642702341\n",
      "test_test\n",
      "test mean loss=1153.9332885742188\n",
      "epoch 844\n",
      "test_train\n",
      "train mean loss=0.11606860533356667\n",
      "test_test\n",
      "test mean loss=1152.5347290039062\n",
      "epoch 845\n",
      "test_train\n",
      "train mean loss=0.11966951129337151\n",
      "test_test\n",
      "test mean loss=1153.9532470703125\n",
      "epoch 846\n",
      "test_train\n",
      "train mean loss=0.11999307262400787\n",
      "test_test\n",
      "test mean loss=1152.8987426757812\n",
      "epoch 847\n",
      "test_train\n",
      "train mean loss=0.11541615736981232\n",
      "test_test\n",
      "test mean loss=1152.91259765625\n",
      "epoch 848\n",
      "test_train\n",
      "train mean loss=0.11288618699957927\n",
      "test_test\n",
      "test mean loss=1153.3413391113281\n",
      "epoch 849\n",
      "test_train\n",
      "train mean loss=0.11602025696386893\n",
      "test_test\n",
      "test mean loss=1153.3779907226562\n",
      "epoch 850\n",
      "test_train\n",
      "train mean loss=0.11003812899192174\n",
      "test_test\n",
      "test mean loss=1153.0106811523438\n",
      "epoch 851\n",
      "test_train\n",
      "train mean loss=0.1173159433528781\n",
      "test_test\n",
      "test mean loss=1153.6825561523438\n",
      "epoch 852\n",
      "test_train\n",
      "train mean loss=0.11436128119627635\n",
      "test_test\n",
      "test mean loss=1152.9888916015625\n",
      "epoch 853\n",
      "test_train\n",
      "train mean loss=0.11455608097215493\n",
      "test_test\n",
      "test mean loss=1152.6573181152344\n",
      "epoch 854\n",
      "test_train\n",
      "train mean loss=0.11218107957392931\n",
      "test_test\n",
      "test mean loss=1152.8302001953125\n",
      "epoch 855\n",
      "test_train\n",
      "train mean loss=0.10928190158059199\n",
      "test_test\n",
      "test mean loss=1152.857177734375\n",
      "epoch 856\n",
      "test_train\n",
      "train mean loss=0.11076465559502442\n",
      "test_test\n",
      "test mean loss=1153.4622802734375\n",
      "epoch 857\n",
      "test_train\n",
      "train mean loss=0.213022011021773\n",
      "test_test\n",
      "test mean loss=1155.2724609375\n",
      "epoch 858\n",
      "test_train\n",
      "train mean loss=0.12795674769828716\n",
      "test_test\n",
      "test mean loss=1153.73095703125\n",
      "epoch 859\n",
      "test_train\n",
      "train mean loss=0.11876438961674769\n",
      "test_test\n",
      "test mean loss=1153.6135864257812\n",
      "epoch 860\n",
      "test_train\n",
      "train mean loss=0.11744527611881495\n",
      "test_test\n",
      "test mean loss=1153.4873046875\n",
      "epoch 861\n",
      "test_train\n",
      "train mean loss=0.10864677280187607\n",
      "test_test\n",
      "test mean loss=1154.2711791992188\n",
      "epoch 862\n",
      "test_train\n",
      "train mean loss=0.11090227495878935\n",
      "test_test\n",
      "test mean loss=1153.67529296875\n",
      "epoch 863\n",
      "test_train\n",
      "train mean loss=0.11935807950794697\n",
      "test_test\n",
      "test mean loss=1153.2470092773438\n",
      "epoch 864\n",
      "test_train\n",
      "train mean loss=0.1201368011534214\n",
      "test_test\n",
      "test mean loss=1153.2801208496094\n",
      "epoch 865\n",
      "test_train\n",
      "train mean loss=0.11504422686994076\n",
      "test_test\n",
      "test mean loss=1153.2859191894531\n",
      "epoch 866\n",
      "test_train\n",
      "train mean loss=0.12268220633268356\n",
      "test_test\n",
      "test mean loss=1153.1362915039062\n",
      "epoch 867\n",
      "test_train\n",
      "train mean loss=0.11199635329345863\n",
      "test_test\n",
      "test mean loss=1153.483642578125\n",
      "epoch 868\n",
      "test_train\n",
      "train mean loss=0.11318257575233777\n",
      "test_test\n",
      "test mean loss=1153.972900390625\n",
      "epoch 869\n",
      "test_train\n",
      "train mean loss=0.11644832976162434\n",
      "test_test\n",
      "test mean loss=1154.0994262695312\n",
      "epoch 870\n",
      "test_train\n",
      "train mean loss=0.11093140890200932\n",
      "test_test\n",
      "test mean loss=1153.842041015625\n",
      "epoch 871\n",
      "test_train\n",
      "train mean loss=0.11638538787762324\n",
      "test_test\n",
      "test mean loss=1154.5218505859375\n",
      "epoch 872\n",
      "test_train\n",
      "train mean loss=0.1165204606950283\n",
      "test_test\n",
      "test mean loss=1153.7872924804688\n",
      "epoch 873\n",
      "test_train\n",
      "train mean loss=0.1176562753195564\n",
      "test_test\n",
      "test mean loss=1152.3909912109375\n",
      "epoch 874\n",
      "test_train\n",
      "train mean loss=0.11349843628704548\n",
      "test_test\n",
      "test mean loss=1153.1803588867188\n",
      "epoch 875\n",
      "test_train\n",
      "train mean loss=0.11265721606711547\n",
      "test_test\n",
      "test mean loss=1154.277099609375\n",
      "epoch 876\n",
      "test_train\n",
      "train mean loss=0.11334992044915755\n",
      "test_test\n",
      "test mean loss=1154.5581359863281\n",
      "epoch 877\n",
      "test_train\n",
      "train mean loss=0.11641547766824563\n",
      "test_test\n",
      "test mean loss=1153.6310119628906\n",
      "epoch 878\n",
      "test_train\n",
      "train mean loss=0.11237353396912415\n",
      "test_test\n",
      "test mean loss=1154.1762084960938\n",
      "epoch 879\n",
      "test_train\n",
      "train mean loss=0.11081205091128747\n",
      "test_test\n",
      "test mean loss=1153.23193359375\n",
      "epoch 880\n",
      "test_train\n",
      "train mean loss=0.11808031362791856\n",
      "test_test\n",
      "test mean loss=1153.8929443359375\n",
      "epoch 881\n",
      "test_train\n",
      "train mean loss=0.1288663779074947\n",
      "test_test\n",
      "test mean loss=1155.3458251953125\n",
      "epoch 882\n",
      "test_train\n",
      "train mean loss=0.12087220139801502\n",
      "test_test\n",
      "test mean loss=1152.6746215820312\n",
      "epoch 883\n",
      "test_train\n",
      "train mean loss=0.11040726800759633\n",
      "test_test\n",
      "test mean loss=1153.61376953125\n",
      "epoch 884\n",
      "test_train\n",
      "train mean loss=0.11241374754657348\n",
      "test_test\n",
      "test mean loss=1154.5021362304688\n",
      "epoch 885\n",
      "test_train\n",
      "train mean loss=0.10890014283359051\n",
      "test_test\n",
      "test mean loss=1154.8734130859375\n",
      "epoch 886\n",
      "test_train\n",
      "train mean loss=0.11049763423701127\n",
      "test_test\n",
      "test mean loss=1153.5562133789062\n",
      "epoch 887\n",
      "test_train\n",
      "train mean loss=0.11425277901192506\n",
      "test_test\n",
      "test mean loss=1154.255859375\n",
      "epoch 888\n",
      "test_train\n",
      "train mean loss=0.11283762815097968\n",
      "test_test\n",
      "test mean loss=1154.3590087890625\n",
      "epoch 889\n",
      "test_train\n",
      "train mean loss=0.35442714517315227\n",
      "test_test\n",
      "test mean loss=1155.933349609375\n",
      "epoch 890\n",
      "test_train\n",
      "train mean loss=0.13311481786270937\n",
      "test_test\n",
      "test mean loss=1152.2793884277344\n",
      "epoch 891\n",
      "test_train\n",
      "train mean loss=0.12126617816587289\n",
      "test_test\n",
      "test mean loss=1152.9806518554688\n",
      "epoch 892\n",
      "test_train\n",
      "train mean loss=0.12135598560174306\n",
      "test_test\n",
      "test mean loss=1152.9935302734375\n",
      "epoch 893\n",
      "test_train\n",
      "train mean loss=0.12410470905403297\n",
      "test_test\n",
      "test mean loss=1152.4325866699219\n",
      "epoch 894\n",
      "test_train\n",
      "train mean loss=0.12554747611284256\n",
      "test_test\n",
      "test mean loss=1152.4754638671875\n",
      "epoch 895\n",
      "test_train\n",
      "train mean loss=0.12191638040045898\n",
      "test_test\n",
      "test mean loss=1151.930908203125\n",
      "epoch 896\n",
      "test_train\n",
      "train mean loss=0.11958919030924638\n",
      "test_test\n",
      "test mean loss=1151.5564880371094\n",
      "epoch 897\n",
      "test_train\n",
      "train mean loss=0.11928568718334039\n",
      "test_test\n",
      "test mean loss=1151.4967651367188\n",
      "epoch 898\n",
      "test_train\n",
      "train mean loss=0.15777852572500706\n",
      "test_test\n",
      "test mean loss=1152.822265625\n",
      "epoch 899\n",
      "test_train\n",
      "train mean loss=0.11434073063234489\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_test\n",
      "test mean loss=1153.5578918457031\n",
      "epoch 900\n",
      "test_train\n",
      "train mean loss=0.12897714941451946\n",
      "test_test\n",
      "test mean loss=1152.3818969726562\n",
      "epoch 901\n",
      "test_train\n",
      "train mean loss=0.11270727620770533\n",
      "test_test\n",
      "test mean loss=1153.1795654296875\n",
      "epoch 902\n",
      "test_train\n",
      "train mean loss=0.11107991511623065\n",
      "test_test\n",
      "test mean loss=1152.776123046875\n",
      "epoch 903\n",
      "test_train\n",
      "train mean loss=0.11875926703214645\n",
      "test_test\n",
      "test mean loss=1152.7100830078125\n",
      "epoch 904\n",
      "test_train\n",
      "train mean loss=0.11503514399131139\n",
      "test_test\n",
      "test mean loss=1152.6712951660156\n",
      "epoch 905\n",
      "test_train\n",
      "train mean loss=0.1113923682520787\n",
      "test_test\n",
      "test mean loss=1152.90966796875\n",
      "epoch 906\n",
      "test_train\n",
      "train mean loss=0.11593191636105378\n",
      "test_test\n",
      "test mean loss=1152.5947265625\n",
      "epoch 907\n",
      "test_train\n",
      "train mean loss=0.11773974138001601\n",
      "test_test\n",
      "test mean loss=1153.24462890625\n",
      "epoch 908\n",
      "test_train\n",
      "train mean loss=0.12490908180673917\n",
      "test_test\n",
      "test mean loss=1152.15478515625\n",
      "epoch 909\n",
      "test_train\n",
      "train mean loss=0.11900096728156011\n",
      "test_test\n",
      "test mean loss=1153.8824462890625\n",
      "epoch 910\n",
      "test_train\n",
      "train mean loss=0.11274759471416473\n",
      "test_test\n",
      "test mean loss=1153.0692138671875\n",
      "epoch 911\n",
      "test_train\n",
      "train mean loss=0.20377262743810812\n",
      "test_test\n",
      "test mean loss=1154.05224609375\n",
      "epoch 912\n",
      "test_train\n",
      "train mean loss=0.12742861236135164\n",
      "test_test\n",
      "test mean loss=1153.6410522460938\n",
      "epoch 913\n",
      "test_train\n",
      "train mean loss=0.11691409628838301\n",
      "test_test\n",
      "test mean loss=1153.8563537597656\n",
      "epoch 914\n",
      "test_train\n",
      "train mean loss=0.14363155762354532\n",
      "test_test\n",
      "test mean loss=1152.6820678710938\n",
      "epoch 915\n",
      "test_train\n",
      "train mean loss=0.13659285567700863\n",
      "test_test\n",
      "test mean loss=1153.2745361328125\n",
      "epoch 916\n",
      "test_train\n",
      "train mean loss=0.12007285840809345\n",
      "test_test\n",
      "test mean loss=1152.8928833007812\n",
      "epoch 917\n",
      "test_train\n",
      "train mean loss=0.11638662094871204\n",
      "test_test\n",
      "test mean loss=1152.9745483398438\n",
      "epoch 918\n",
      "test_train\n",
      "train mean loss=0.1147786056001981\n",
      "test_test\n",
      "test mean loss=1153.6399536132812\n",
      "epoch 919\n",
      "test_train\n",
      "train mean loss=0.16775923098127046\n",
      "test_test\n",
      "test mean loss=1152.2620849609375\n",
      "epoch 920\n",
      "test_train\n",
      "train mean loss=0.1218149724105994\n",
      "test_test\n",
      "test mean loss=1152.998291015625\n",
      "epoch 921\n",
      "test_train\n",
      "train mean loss=0.1106400266289711\n",
      "test_test\n",
      "test mean loss=1153.7279663085938\n",
      "epoch 922\n",
      "test_train\n",
      "train mean loss=0.11741809484859307\n",
      "test_test\n",
      "test mean loss=1153.4347534179688\n",
      "epoch 923\n",
      "test_train\n",
      "train mean loss=0.11223414447158575\n",
      "test_test\n",
      "test mean loss=1153.5353698730469\n",
      "epoch 924\n",
      "test_train\n",
      "train mean loss=0.4799693127473195\n",
      "test_test\n",
      "test mean loss=1159.1521606445312\n",
      "epoch 925\n",
      "test_train\n",
      "train mean loss=0.14227989874780178\n",
      "test_test\n",
      "test mean loss=1154.68994140625\n",
      "epoch 926\n",
      "test_train\n",
      "train mean loss=0.1257275134945909\n",
      "test_test\n",
      "test mean loss=1154.2715759277344\n",
      "epoch 927\n",
      "test_train\n",
      "train mean loss=0.126104474067688\n",
      "test_test\n",
      "test mean loss=1153.6290893554688\n",
      "epoch 928\n",
      "test_train\n",
      "train mean loss=0.12391542767484982\n",
      "test_test\n",
      "test mean loss=1154.4523315429688\n",
      "epoch 929\n",
      "test_train\n",
      "train mean loss=0.12476142992575963\n",
      "test_test\n",
      "test mean loss=1153.5810546875\n",
      "epoch 930\n",
      "test_train\n",
      "train mean loss=0.13136932657410702\n",
      "test_test\n",
      "test mean loss=1153.9779663085938\n",
      "epoch 931\n",
      "test_train\n",
      "train mean loss=0.13179472212990126\n",
      "test_test\n",
      "test mean loss=1154.1152648925781\n",
      "epoch 932\n",
      "test_train\n",
      "train mean loss=0.12452533344427745\n",
      "test_test\n",
      "test mean loss=1152.8860473632812\n",
      "epoch 933\n",
      "test_train\n",
      "train mean loss=0.11768295057117939\n",
      "test_test\n",
      "test mean loss=1153.7808227539062\n",
      "epoch 934\n",
      "test_train\n",
      "train mean loss=0.12030284789701302\n",
      "test_test\n",
      "test mean loss=1153.4886474609375\n",
      "epoch 935\n",
      "test_train\n",
      "train mean loss=0.12409634826083978\n",
      "test_test\n",
      "test mean loss=1152.6044311523438\n",
      "epoch 936\n",
      "test_train\n",
      "train mean loss=0.1198363620787859\n",
      "test_test\n",
      "test mean loss=1153.0755615234375\n",
      "epoch 937\n",
      "test_train\n",
      "train mean loss=0.115297371832033\n",
      "test_test\n",
      "test mean loss=1153.9559326171875\n",
      "epoch 938\n",
      "test_train\n",
      "train mean loss=0.11672741795579593\n",
      "test_test\n",
      "test mean loss=1154.5637817382812\n",
      "epoch 939\n",
      "test_train\n",
      "train mean loss=0.1211713207885623\n",
      "test_test\n",
      "test mean loss=1154.6373291015625\n",
      "epoch 940\n",
      "test_train\n",
      "train mean loss=0.11441265357037385\n",
      "test_test\n",
      "test mean loss=1154.5708618164062\n",
      "epoch 941\n",
      "test_train\n",
      "train mean loss=0.11456054262816906\n",
      "test_test\n",
      "test mean loss=1154.9300537109375\n",
      "epoch 942\n",
      "test_train\n",
      "train mean loss=0.11501216484854619\n",
      "test_test\n",
      "test mean loss=1154.1387939453125\n",
      "epoch 943\n",
      "test_train\n",
      "train mean loss=0.11973939649760723\n",
      "test_test\n",
      "test mean loss=1153.489501953125\n",
      "epoch 944\n",
      "test_train\n",
      "train mean loss=0.11406171446045239\n",
      "test_test\n",
      "test mean loss=1153.7587280273438\n",
      "epoch 945\n",
      "test_train\n",
      "train mean loss=0.11759205721318722\n",
      "test_test\n",
      "test mean loss=1153.8871459960938\n",
      "epoch 946\n",
      "test_train\n",
      "train mean loss=0.12007116588453452\n",
      "test_test\n",
      "test mean loss=1154.3333740234375\n",
      "epoch 947\n",
      "test_train\n",
      "train mean loss=0.11320006490374605\n",
      "test_test\n",
      "test mean loss=1154.4267883300781\n",
      "epoch 948\n",
      "test_train\n",
      "train mean loss=0.1251314456264178\n",
      "test_test\n",
      "test mean loss=1152.9351806640625\n",
      "epoch 949\n",
      "test_train\n",
      "train mean loss=0.11986374296247959\n",
      "test_test\n",
      "test mean loss=1153.758056640625\n",
      "epoch 950\n",
      "test_train\n",
      "train mean loss=0.1134667918086052\n",
      "test_test\n",
      "test mean loss=1153.4174194335938\n",
      "epoch 951\n",
      "test_train\n",
      "train mean loss=0.1169399106875062\n",
      "test_test\n",
      "test mean loss=1153.9515686035156\n",
      "epoch 952\n",
      "test_train\n",
      "train mean loss=0.11665404960513115\n",
      "test_test\n",
      "test mean loss=1153.41552734375\n",
      "epoch 953\n",
      "test_train\n",
      "train mean loss=0.11636469947795074\n",
      "test_test\n",
      "test mean loss=1153.928955078125\n",
      "epoch 954\n",
      "test_train\n",
      "train mean loss=0.11284012906253338\n",
      "test_test\n",
      "test mean loss=1153.4185180664062\n",
      "epoch 955\n",
      "test_train\n",
      "train mean loss=0.11468673807879289\n",
      "test_test\n",
      "test mean loss=1153.7145385742188\n",
      "epoch 956\n",
      "test_train\n",
      "train mean loss=0.11467288558681805\n",
      "test_test\n",
      "test mean loss=1153.7085876464844\n",
      "epoch 957\n",
      "test_train\n",
      "train mean loss=0.12216252212723096\n",
      "test_test\n",
      "test mean loss=1152.5093383789062\n",
      "epoch 958\n",
      "test_train\n",
      "train mean loss=0.11783770844340324\n",
      "test_test\n",
      "test mean loss=1153.2041625976562\n",
      "epoch 959\n",
      "test_train\n",
      "train mean loss=0.1117232342561086\n",
      "test_test\n",
      "test mean loss=1152.5881958007812\n",
      "epoch 960\n",
      "test_train\n",
      "train mean loss=0.11350933151940505\n",
      "test_test\n",
      "test mean loss=1153.3582458496094\n",
      "epoch 961\n",
      "test_train\n",
      "train mean loss=0.11516019484649102\n",
      "test_test\n",
      "test mean loss=1153.789306640625\n",
      "epoch 962\n",
      "test_train\n",
      "train mean loss=0.11747713014483452\n",
      "test_test\n",
      "test mean loss=1152.9863891601562\n",
      "epoch 963\n",
      "test_train\n",
      "train mean loss=0.11969555107255776\n",
      "test_test\n",
      "test mean loss=1154.9356689453125\n",
      "epoch 964\n",
      "test_train\n",
      "train mean loss=0.11617076459030311\n",
      "test_test\n",
      "test mean loss=1153.4545593261719\n",
      "epoch 965\n",
      "test_train\n",
      "train mean loss=0.11023647772769134\n",
      "test_test\n",
      "test mean loss=1154.625244140625\n",
      "epoch 966\n",
      "test_train\n",
      "train mean loss=0.1156588535134991\n",
      "test_test\n",
      "test mean loss=1154.4739990234375\n",
      "epoch 967\n",
      "test_train\n",
      "train mean loss=0.12373384336630504\n",
      "test_test\n",
      "test mean loss=1154.657470703125\n",
      "epoch 968\n",
      "test_train\n",
      "train mean loss=0.11919183532396953\n",
      "test_test\n",
      "test mean loss=1154.2697143554688\n",
      "epoch 969\n",
      "test_train\n",
      "train mean loss=0.11771678552031517\n",
      "test_test\n",
      "test mean loss=1154.0124206542969\n",
      "epoch 970\n",
      "test_train\n",
      "train mean loss=0.11526292376220226\n",
      "test_test\n",
      "test mean loss=1154.1026611328125\n",
      "epoch 971\n",
      "test_train\n",
      "train mean loss=0.11495926789939404\n",
      "test_test\n",
      "test mean loss=1154.0178527832031\n",
      "epoch 972\n",
      "test_train\n",
      "train mean loss=0.11981668633719285\n",
      "test_test\n",
      "test mean loss=1154.5062866210938\n",
      "epoch 973\n",
      "test_train\n",
      "train mean loss=0.11713789900143941\n",
      "test_test\n",
      "test mean loss=1153.181884765625\n",
      "epoch 974\n",
      "test_train\n",
      "train mean loss=0.11518954796095689\n",
      "test_test\n",
      "test mean loss=1153.0830993652344\n",
      "epoch 975\n",
      "test_train\n",
      "train mean loss=0.1241861389329036\n",
      "test_test\n",
      "test mean loss=1153.77587890625\n",
      "epoch 976\n",
      "test_train\n",
      "train mean loss=0.1190882616986831\n",
      "test_test\n",
      "test mean loss=1154.1741333007812\n",
      "epoch 977\n",
      "test_train\n",
      "train mean loss=0.11251539985338847\n",
      "test_test\n",
      "test mean loss=1154.2403259277344\n",
      "epoch 978\n",
      "test_train\n",
      "train mean loss=0.11189813384165366\n",
      "test_test\n",
      "test mean loss=1153.2569580078125\n",
      "epoch 979\n",
      "test_train\n",
      "train mean loss=0.11663370703657468\n",
      "test_test\n",
      "test mean loss=1153.8968811035156\n",
      "epoch 980\n",
      "test_train\n",
      "train mean loss=0.11238876916468143\n",
      "test_test\n",
      "test mean loss=1153.5970764160156\n",
      "epoch 981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_train\n",
      "train mean loss=0.11651631630957127\n",
      "test_test\n",
      "test mean loss=1154.9942626953125\n",
      "epoch 982\n",
      "test_train\n",
      "train mean loss=0.11796381200353305\n",
      "test_test\n",
      "test mean loss=1154.2449340820312\n",
      "epoch 983\n",
      "test_train\n",
      "train mean loss=0.11729500318566959\n",
      "test_test\n",
      "test mean loss=1153.229248046875\n",
      "epoch 984\n",
      "test_train\n",
      "train mean loss=0.1208859399581949\n",
      "test_test\n",
      "test mean loss=1153.1976318359375\n",
      "epoch 985\n",
      "test_train\n",
      "train mean loss=0.11934233891467254\n",
      "test_test\n",
      "test mean loss=1153.820068359375\n",
      "epoch 986\n",
      "test_train\n",
      "train mean loss=0.11199994447330634\n",
      "test_test\n",
      "test mean loss=1154.0855102539062\n",
      "epoch 987\n",
      "test_train\n",
      "train mean loss=0.11453560615579288\n",
      "test_test\n",
      "test mean loss=1154.5208129882812\n",
      "epoch 988\n",
      "test_train\n",
      "train mean loss=0.1175481950243314\n",
      "test_test\n",
      "test mean loss=1153.7181701660156\n",
      "epoch 989\n",
      "test_train\n",
      "train mean loss=0.1104829665273428\n",
      "test_test\n",
      "test mean loss=1153.7374267578125\n",
      "epoch 990\n",
      "test_train\n",
      "train mean loss=0.15341325725118318\n",
      "test_test\n",
      "test mean loss=1156.2508544921875\n",
      "epoch 991\n",
      "test_train\n",
      "train mean loss=0.11588397001226743\n",
      "test_test\n",
      "test mean loss=1154.1068725585938\n",
      "epoch 992\n",
      "test_train\n",
      "train mean loss=0.11599408028026421\n",
      "test_test\n",
      "test mean loss=1154.44384765625\n",
      "epoch 993\n",
      "test_train\n",
      "train mean loss=0.11546824624141057\n",
      "test_test\n",
      "test mean loss=1154.1939697265625\n",
      "epoch 994\n",
      "test_train\n",
      "train mean loss=0.1134088064233462\n",
      "test_test\n",
      "test mean loss=1153.249755859375\n",
      "epoch 995\n",
      "test_train\n",
      "train mean loss=0.117015124609073\n",
      "test_test\n",
      "test mean loss=1154.2295227050781\n",
      "epoch 996\n",
      "test_train\n",
      "train mean loss=0.13077183160930872\n",
      "test_test\n",
      "test mean loss=1152.2808837890625\n",
      "epoch 997\n",
      "test_train\n",
      "train mean loss=0.11657217455406983\n",
      "test_test\n",
      "test mean loss=1153.2966918945312\n",
      "epoch 998\n",
      "test_train\n",
      "train mean loss=0.11420756268004577\n",
      "test_test\n",
      "test mean loss=1154.1089477539062\n",
      "epoch 999\n",
      "test_train\n",
      "train mean loss=0.11607490914563338\n",
      "test_test\n",
      "test mean loss=1153.2256164550781\n",
      "epoch 1000\n",
      "test_train\n",
      "train mean loss=0.11397075622032087\n",
      "test_test\n",
      "test mean loss=1154.3719177246094\n",
      "epoch 1001\n",
      "test_train\n",
      "train mean loss=0.11649041747053464\n",
      "test_test\n",
      "test mean loss=1155.1834716796875\n",
      "epoch 1002\n",
      "test_train\n",
      "train mean loss=0.11498585777978103\n",
      "test_test\n",
      "test mean loss=1155.0292053222656\n",
      "epoch 1003\n",
      "test_train\n",
      "train mean loss=0.11700895987451077\n",
      "test_test\n",
      "test mean loss=1154.320068359375\n",
      "epoch 1004\n",
      "test_train\n",
      "train mean loss=0.1126862820237875\n",
      "test_test\n",
      "test mean loss=1154.6651611328125\n",
      "epoch 1005\n",
      "test_train\n",
      "train mean loss=0.11472961927453677\n",
      "test_test\n",
      "test mean loss=1155.0648193359375\n",
      "epoch 1006\n",
      "test_train\n",
      "train mean loss=0.11459897023936112\n",
      "test_test\n",
      "test mean loss=1154.4215087890625\n",
      "epoch 1007\n",
      "test_train\n",
      "train mean loss=0.11481253709644079\n",
      "test_test\n",
      "test mean loss=1154.6558837890625\n",
      "epoch 1008\n",
      "test_train\n",
      "train mean loss=0.11380903547008832\n",
      "test_test\n",
      "test mean loss=1153.905517578125\n",
      "epoch 1009\n",
      "test_train\n",
      "train mean loss=0.11636317893862724\n",
      "test_test\n",
      "test mean loss=1153.84765625\n",
      "epoch 1010\n",
      "test_train\n",
      "train mean loss=0.1152729590733846\n",
      "test_test\n",
      "test mean loss=1154.6076049804688\n",
      "epoch 1011\n",
      "test_train\n",
      "train mean loss=0.11281194413701694\n",
      "test_test\n",
      "test mean loss=1154.082275390625\n",
      "epoch 1012\n",
      "test_train\n",
      "train mean loss=0.11532964712629716\n",
      "test_test\n",
      "test mean loss=1153.9434204101562\n",
      "epoch 1013\n",
      "test_train\n",
      "train mean loss=0.11073270378013451\n",
      "test_test\n",
      "test mean loss=1154.8831176757812\n",
      "epoch 1014\n",
      "test_train\n",
      "train mean loss=0.12202676385641098\n",
      "test_test\n",
      "test mean loss=1154.1935424804688\n",
      "epoch 1015\n",
      "test_train\n",
      "train mean loss=0.1960673996557792\n",
      "test_test\n",
      "test mean loss=1157.1527709960938\n",
      "epoch 1016\n",
      "test_train\n",
      "train mean loss=0.12238203454762697\n",
      "test_test\n",
      "test mean loss=1154.5535583496094\n",
      "epoch 1017\n",
      "test_train\n",
      "train mean loss=0.11908037029206753\n",
      "test_test\n",
      "test mean loss=1154.6731567382812\n",
      "epoch 1018\n",
      "test_train\n",
      "train mean loss=0.11213633045554161\n",
      "test_test\n",
      "test mean loss=1154.0643920898438\n",
      "epoch 1019\n",
      "test_train\n",
      "train mean loss=0.10920223655800025\n",
      "test_test\n",
      "test mean loss=1154.5431518554688\n",
      "epoch 1020\n",
      "test_train\n",
      "train mean loss=0.11024797925104697\n",
      "test_test\n",
      "test mean loss=1154.1520690917969\n",
      "epoch 1021\n",
      "test_train\n",
      "train mean loss=0.11535526998341084\n",
      "test_test\n",
      "test mean loss=1154.7621459960938\n",
      "epoch 1022\n",
      "test_train\n",
      "train mean loss=0.10809163687129815\n",
      "test_test\n",
      "test mean loss=1154.05859375\n",
      "epoch 1023\n",
      "test_train\n",
      "train mean loss=0.12131763404856126\n",
      "test_test\n",
      "test mean loss=1154.4951171875\n",
      "epoch 1024\n",
      "test_train\n",
      "train mean loss=0.11323357311387856\n",
      "test_test\n",
      "test mean loss=1153.9827880859375\n",
      "epoch 1025\n",
      "test_train\n",
      "train mean loss=0.11271615885198116\n",
      "test_test\n",
      "test mean loss=1154.1651000976562\n",
      "epoch 1026\n",
      "test_train\n",
      "train mean loss=0.11111639688412349\n",
      "test_test\n",
      "test mean loss=1153.0888061523438\n",
      "epoch 1027\n",
      "test_train\n",
      "train mean loss=0.1367689867814382\n",
      "test_test\n",
      "test mean loss=1153.9712524414062\n",
      "epoch 1028\n",
      "test_train\n",
      "train mean loss=0.113418391905725\n",
      "test_test\n",
      "test mean loss=1155.0565795898438\n",
      "epoch 1029\n",
      "test_train\n",
      "train mean loss=0.11380833201110363\n",
      "test_test\n",
      "test mean loss=1155.229736328125\n",
      "epoch 1030\n",
      "test_train\n",
      "train mean loss=0.12733737317224345\n",
      "test_test\n",
      "test mean loss=1154.9513549804688\n",
      "epoch 1031\n",
      "test_train\n",
      "train mean loss=0.1226991352935632\n",
      "test_test\n",
      "test mean loss=1155.0546264648438\n",
      "epoch 1032\n",
      "test_train\n",
      "train mean loss=0.10891895058254401\n",
      "test_test\n",
      "test mean loss=1154.2680053710938\n",
      "epoch 1033\n",
      "test_train\n",
      "train mean loss=0.10778517462313175\n",
      "test_test\n",
      "test mean loss=1153.9176635742188\n",
      "epoch 1034\n",
      "test_train\n",
      "train mean loss=0.16644871545334658\n",
      "test_test\n",
      "test mean loss=1153.6510620117188\n",
      "epoch 1035\n",
      "test_train\n",
      "train mean loss=0.11684917379170656\n",
      "test_test\n",
      "test mean loss=1154.0223083496094\n",
      "epoch 1036\n",
      "test_train\n",
      "train mean loss=0.11783208511769772\n",
      "test_test\n",
      "test mean loss=1153.5059509277344\n",
      "epoch 1037\n",
      "test_train\n",
      "train mean loss=0.11246795672923326\n",
      "test_test\n",
      "test mean loss=1155.2157897949219\n",
      "epoch 1038\n",
      "test_train\n",
      "train mean loss=0.11615506404389937\n",
      "test_test\n",
      "test mean loss=1154.3856811523438\n",
      "epoch 1039\n",
      "test_train\n",
      "train mean loss=0.10972141474485397\n",
      "test_test\n",
      "test mean loss=1153.8623352050781\n",
      "epoch 1040\n",
      "test_train\n",
      "train mean loss=0.11468409250179927\n",
      "test_test\n",
      "test mean loss=1153.2421569824219\n",
      "epoch 1041\n",
      "test_train\n",
      "train mean loss=0.11382196905712287\n",
      "test_test\n",
      "test mean loss=1152.8532104492188\n",
      "epoch 1042\n",
      "test_train\n",
      "train mean loss=0.11020921884725492\n",
      "test_test\n",
      "test mean loss=1152.770263671875\n",
      "epoch 1043\n",
      "test_train\n",
      "train mean loss=0.24905095746119818\n",
      "test_test\n",
      "test mean loss=1154.7989501953125\n",
      "epoch 1044\n",
      "test_train\n",
      "train mean loss=0.13151052221655846\n",
      "test_test\n",
      "test mean loss=1153.4373168945312\n",
      "epoch 1045\n",
      "test_train\n",
      "train mean loss=0.11850890703499317\n",
      "test_test\n",
      "test mean loss=1152.6882934570312\n",
      "epoch 1046\n",
      "test_train\n",
      "train mean loss=0.11052306989828746\n",
      "test_test\n",
      "test mean loss=1153.3546142578125\n",
      "epoch 1047\n",
      "test_train\n",
      "train mean loss=0.11152618533621232\n",
      "test_test\n",
      "test mean loss=1153.9814453125\n",
      "epoch 1048\n",
      "test_train\n",
      "train mean loss=0.11114463334282239\n",
      "test_test\n",
      "test mean loss=1153.2657470703125\n",
      "epoch 1049\n",
      "test_train\n",
      "train mean loss=0.10941445920616388\n",
      "test_test\n",
      "test mean loss=1152.9485168457031\n",
      "epoch 1050\n",
      "test_train\n",
      "train mean loss=0.11308925040066242\n",
      "test_test\n",
      "test mean loss=1153.0390625\n",
      "epoch 1051\n",
      "test_train\n",
      "train mean loss=0.10957564817120631\n",
      "test_test\n",
      "test mean loss=1154.1612548828125\n",
      "epoch 1052\n",
      "test_train\n",
      "train mean loss=0.1061778577665488\n",
      "test_test\n",
      "test mean loss=1153.2434692382812\n",
      "epoch 1053\n",
      "test_train\n",
      "train mean loss=0.10986143940438826\n",
      "test_test\n",
      "test mean loss=1154.4378662109375\n",
      "epoch 1054\n",
      "test_train\n",
      "train mean loss=0.11044407698015372\n",
      "test_test\n",
      "test mean loss=1154.636474609375\n",
      "epoch 1055\n",
      "test_train\n",
      "train mean loss=0.11214546983440717\n",
      "test_test\n",
      "test mean loss=1154.6504211425781\n",
      "epoch 1056\n",
      "test_train\n",
      "train mean loss=0.11111903097480536\n",
      "test_test\n",
      "test mean loss=1154.2040710449219\n",
      "epoch 1057\n",
      "test_train\n",
      "train mean loss=0.11098883176843326\n",
      "test_test\n",
      "test mean loss=1154.8098754882812\n",
      "epoch 1058\n",
      "test_train\n",
      "train mean loss=0.11161893264700969\n",
      "test_test\n",
      "test mean loss=1154.6853637695312\n",
      "epoch 1059\n",
      "test_train\n",
      "train mean loss=0.1109522848079602\n",
      "test_test\n",
      "test mean loss=1153.862548828125\n",
      "epoch 1060\n",
      "test_train\n",
      "train mean loss=0.10551806042591731\n",
      "test_test\n",
      "test mean loss=1153.5582275390625\n",
      "epoch 1061\n",
      "test_train\n",
      "train mean loss=0.10573470344146092\n",
      "test_test\n",
      "test mean loss=1153.8859252929688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1062\n",
      "test_train\n",
      "train mean loss=0.11107718634108703\n",
      "test_test\n",
      "test mean loss=1154.1646728515625\n",
      "epoch 1063\n",
      "test_train\n",
      "train mean loss=0.10729280114173889\n",
      "test_test\n",
      "test mean loss=1154.9786071777344\n",
      "epoch 1064\n",
      "test_train\n",
      "train mean loss=0.11610477107266585\n",
      "test_test\n",
      "test mean loss=1155.6187744140625\n",
      "epoch 1065\n",
      "test_train\n",
      "train mean loss=0.10982640304913123\n",
      "test_test\n",
      "test mean loss=1155.0326538085938\n",
      "epoch 1066\n",
      "test_train\n",
      "train mean loss=0.10629669390618801\n",
      "test_test\n",
      "test mean loss=1154.498291015625\n",
      "epoch 1067\n",
      "test_train\n",
      "train mean loss=0.10787815880030394\n",
      "test_test\n",
      "test mean loss=1153.9885864257812\n",
      "epoch 1068\n",
      "test_train\n",
      "train mean loss=0.1110002522667249\n",
      "test_test\n",
      "test mean loss=1154.3843994140625\n",
      "epoch 1069\n",
      "test_train\n",
      "train mean loss=0.11408108038206895\n",
      "test_test\n",
      "test mean loss=1154.2005004882812\n",
      "epoch 1070\n",
      "test_train\n",
      "train mean loss=0.13731511744360128\n",
      "test_test\n",
      "test mean loss=1155.8243103027344\n",
      "epoch 1071\n",
      "test_train\n",
      "train mean loss=0.11440274864435196\n",
      "test_test\n",
      "test mean loss=1153.6560668945312\n",
      "epoch 1072\n",
      "test_train\n",
      "train mean loss=0.11071599026521046\n",
      "test_test\n",
      "test mean loss=1154.4634704589844\n",
      "epoch 1073\n",
      "test_train\n",
      "train mean loss=0.11011565600832303\n",
      "test_test\n",
      "test mean loss=1154.5366821289062\n",
      "epoch 1074\n",
      "test_train\n",
      "train mean loss=0.11237047985196114\n",
      "test_test\n",
      "test mean loss=1153.8721313476562\n",
      "epoch 1075\n",
      "test_train\n",
      "train mean loss=0.11055922011534373\n",
      "test_test\n",
      "test mean loss=1154.1324768066406\n",
      "epoch 1076\n",
      "test_train\n",
      "train mean loss=0.11433882328371207\n",
      "test_test\n",
      "test mean loss=1153.28173828125\n",
      "epoch 1077\n",
      "test_train\n",
      "train mean loss=0.11210693543155988\n",
      "test_test\n",
      "test mean loss=1154.5059204101562\n",
      "epoch 1078\n",
      "test_train\n",
      "train mean loss=0.11110226996243\n",
      "test_test\n",
      "test mean loss=1154.9330139160156\n",
      "epoch 1079\n",
      "test_train\n",
      "train mean loss=0.1104144776860873\n",
      "test_test\n",
      "test mean loss=1155.03271484375\n",
      "epoch 1080\n",
      "test_train\n",
      "train mean loss=0.11800789460539818\n",
      "test_test\n",
      "test mean loss=1155.7098388671875\n",
      "epoch 1081\n",
      "test_train\n",
      "train mean loss=0.11132591466108958\n",
      "test_test\n",
      "test mean loss=1155.1182861328125\n",
      "epoch 1082\n",
      "test_train\n",
      "train mean loss=0.11393988939623038\n",
      "test_test\n",
      "test mean loss=1155.2059020996094\n",
      "epoch 1083\n",
      "test_train\n",
      "train mean loss=0.11079747291902702\n",
      "test_test\n",
      "test mean loss=1155.2202758789062\n",
      "epoch 1084\n",
      "test_train\n",
      "train mean loss=0.1145267424484094\n",
      "test_test\n",
      "test mean loss=1155.3241271972656\n",
      "epoch 1085\n",
      "test_train\n",
      "train mean loss=0.11564722843468189\n",
      "test_test\n",
      "test mean loss=1155.5721435546875\n",
      "epoch 1086\n",
      "test_train\n",
      "train mean loss=0.11412329661349456\n",
      "test_test\n",
      "test mean loss=1154.9833374023438\n",
      "epoch 1087\n",
      "test_train\n",
      "train mean loss=0.11614469190438588\n",
      "test_test\n",
      "test mean loss=1154.6039733886719\n",
      "epoch 1088\n",
      "test_train\n",
      "train mean loss=0.11140021681785583\n",
      "test_test\n",
      "test mean loss=1154.9114379882812\n",
      "epoch 1089\n",
      "test_train\n",
      "train mean loss=0.1083280062302947\n",
      "test_test\n",
      "test mean loss=1155.820556640625\n",
      "epoch 1090\n",
      "test_train\n",
      "train mean loss=0.111042025188605\n",
      "test_test\n",
      "test mean loss=1155.0892944335938\n",
      "epoch 1091\n",
      "test_train\n",
      "train mean loss=0.11099233602484067\n",
      "test_test\n",
      "test mean loss=1154.1719360351562\n",
      "epoch 1092\n",
      "test_train\n",
      "train mean loss=0.10767362577219804\n",
      "test_test\n",
      "test mean loss=1154.4916687011719\n",
      "epoch 1093\n",
      "test_train\n",
      "train mean loss=0.11550524085760117\n",
      "test_test\n",
      "test mean loss=1154.1641845703125\n",
      "epoch 1094\n",
      "test_train\n",
      "train mean loss=0.10773303670187791\n",
      "test_test\n",
      "test mean loss=1153.63623046875\n",
      "epoch 1095\n",
      "test_train\n",
      "train mean loss=0.11195209063589573\n",
      "test_test\n",
      "test mean loss=1153.8192749023438\n",
      "epoch 1096\n",
      "test_train\n",
      "train mean loss=0.127051068469882\n",
      "test_test\n",
      "test mean loss=1153.2497863769531\n",
      "epoch 1097\n",
      "test_train\n",
      "train mean loss=0.11750298428038757\n",
      "test_test\n",
      "test mean loss=1152.7586669921875\n",
      "epoch 1098\n",
      "test_train\n",
      "train mean loss=0.1653762316952149\n",
      "test_test\n",
      "test mean loss=1151.5138549804688\n",
      "epoch 1099\n",
      "test_train\n",
      "train mean loss=0.11862475021431844\n",
      "test_test\n",
      "test mean loss=1152.405517578125\n",
      "epoch 1100\n",
      "test_train\n",
      "train mean loss=0.1144213667139411\n",
      "test_test\n",
      "test mean loss=1152.6897583007812\n",
      "epoch 1101\n",
      "test_train\n",
      "train mean loss=0.1188509048273166\n",
      "test_test\n",
      "test mean loss=1153.2470092773438\n",
      "epoch 1102\n",
      "test_train\n",
      "train mean loss=0.11291068668166797\n",
      "test_test\n",
      "test mean loss=1152.6141967773438\n",
      "epoch 1103\n",
      "test_train\n",
      "train mean loss=0.11173807705442111\n",
      "test_test\n",
      "test mean loss=1152.535888671875\n",
      "epoch 1104\n",
      "test_train\n",
      "train mean loss=0.1127320434898138\n",
      "test_test\n",
      "test mean loss=1153.5467529296875\n",
      "epoch 1105\n",
      "test_train\n",
      "train mean loss=0.11005759487549464\n",
      "test_test\n",
      "test mean loss=1152.9173583984375\n",
      "epoch 1106\n",
      "test_train\n",
      "train mean loss=0.114120337801675\n",
      "test_test\n",
      "test mean loss=1153.3441772460938\n",
      "epoch 1107\n",
      "test_train\n",
      "train mean loss=0.10896407564481099\n",
      "test_test\n",
      "test mean loss=1152.9815368652344\n",
      "epoch 1108\n",
      "test_train\n",
      "train mean loss=0.11288363362352054\n",
      "test_test\n",
      "test mean loss=1153.3037719726562\n",
      "epoch 1109\n",
      "test_train\n",
      "train mean loss=0.11221326484034459\n",
      "test_test\n",
      "test mean loss=1152.6986083984375\n",
      "epoch 1110\n",
      "test_train\n",
      "train mean loss=0.11546217898527782\n",
      "test_test\n",
      "test mean loss=1152.4439697265625\n",
      "epoch 1111\n",
      "test_train\n",
      "train mean loss=0.11116282517711322\n",
      "test_test\n",
      "test mean loss=1151.63525390625\n",
      "epoch 1112\n",
      "test_train\n",
      "train mean loss=0.12200194876641035\n",
      "test_test\n",
      "test mean loss=1153.0803527832031\n",
      "epoch 1113\n",
      "test_train\n",
      "train mean loss=0.1089794288078944\n",
      "test_test\n",
      "test mean loss=1152.6879577636719\n",
      "epoch 1114\n",
      "test_train\n",
      "train mean loss=0.11260501357416312\n",
      "test_test\n",
      "test mean loss=1152.9833374023438\n",
      "epoch 1115\n",
      "test_train\n",
      "train mean loss=0.11122582852840424\n",
      "test_test\n",
      "test mean loss=1152.5162353515625\n",
      "epoch 1116\n",
      "test_train\n",
      "train mean loss=0.11399754509329796\n",
      "test_test\n",
      "test mean loss=1152.0111389160156\n",
      "epoch 1117\n",
      "test_train\n",
      "train mean loss=0.1106524554391702\n",
      "test_test\n",
      "test mean loss=1151.9634704589844\n",
      "epoch 1118\n",
      "test_train\n",
      "train mean loss=0.12272081431001425\n",
      "test_test\n",
      "test mean loss=1151.9541625976562\n",
      "epoch 1119\n",
      "test_train\n",
      "train mean loss=0.1176352786521117\n",
      "test_test\n",
      "test mean loss=1152.5274047851562\n",
      "epoch 1120\n",
      "test_train\n",
      "train mean loss=0.12188630737364292\n",
      "test_test\n",
      "test mean loss=1152.498046875\n",
      "epoch 1121\n",
      "test_train\n",
      "train mean loss=0.11047449832161267\n",
      "test_test\n",
      "test mean loss=1153.1950073242188\n",
      "epoch 1122\n",
      "test_train\n",
      "train mean loss=0.1375225738932689\n",
      "test_test\n",
      "test mean loss=1153.6525268554688\n",
      "epoch 1123\n",
      "test_train\n",
      "train mean loss=0.1151952687650919\n",
      "test_test\n",
      "test mean loss=1153.3242797851562\n",
      "epoch 1124\n",
      "test_train\n",
      "train mean loss=0.11849159374833107\n",
      "test_test\n",
      "test mean loss=1152.6051025390625\n",
      "epoch 1125\n",
      "test_train\n",
      "train mean loss=0.1167081914221247\n",
      "test_test\n",
      "test mean loss=1153.155517578125\n",
      "epoch 1126\n",
      "test_train\n",
      "train mean loss=0.12533959622184435\n",
      "test_test\n",
      "test mean loss=1154.1884460449219\n",
      "epoch 1127\n",
      "test_train\n",
      "train mean loss=0.11494278131673734\n",
      "test_test\n",
      "test mean loss=1152.6528930664062\n",
      "epoch 1128\n",
      "test_train\n",
      "train mean loss=0.11538154756029446\n",
      "test_test\n",
      "test mean loss=1153.2349853515625\n",
      "epoch 1129\n",
      "test_train\n",
      "train mean loss=0.11330615977446239\n",
      "test_test\n",
      "test mean loss=1152.9520263671875\n",
      "epoch 1130\n",
      "test_train\n",
      "train mean loss=0.11215398150185744\n",
      "test_test\n",
      "test mean loss=1153.207763671875\n",
      "epoch 1131\n",
      "test_train\n",
      "train mean loss=0.11515908067425092\n",
      "test_test\n",
      "test mean loss=1152.9822998046875\n",
      "epoch 1132\n",
      "test_train\n",
      "train mean loss=0.11191543036450942\n",
      "test_test\n",
      "test mean loss=1153.2444458007812\n",
      "epoch 1133\n",
      "test_train\n",
      "train mean loss=0.10756198689341545\n",
      "test_test\n",
      "test mean loss=1153.2306823730469\n",
      "epoch 1134\n",
      "test_train\n",
      "train mean loss=0.11395627291252215\n",
      "test_test\n",
      "test mean loss=1153.6782836914062\n",
      "epoch 1135\n",
      "test_train\n",
      "train mean loss=0.11146491890152295\n",
      "test_test\n",
      "test mean loss=1153.17333984375\n",
      "epoch 1136\n",
      "test_train\n",
      "train mean loss=0.11772618815302849\n",
      "test_test\n",
      "test mean loss=1153.9241333007812\n",
      "epoch 1137\n",
      "test_train\n",
      "train mean loss=0.11191922053694725\n",
      "test_test\n",
      "test mean loss=1153.8066711425781\n",
      "epoch 1138\n",
      "test_train\n",
      "train mean loss=0.11401623239119847\n",
      "test_test\n",
      "test mean loss=1154.0436096191406\n",
      "epoch 1139\n",
      "test_train\n",
      "train mean loss=0.11003732153524955\n",
      "test_test\n",
      "test mean loss=1153.5776672363281\n",
      "epoch 1140\n",
      "test_train\n",
      "train mean loss=0.10718125725785892\n",
      "test_test\n",
      "test mean loss=1153.1040344238281\n",
      "epoch 1141\n",
      "test_train\n",
      "train mean loss=0.11599849723279476\n",
      "test_test\n",
      "test mean loss=1153.150146484375\n",
      "epoch 1142\n",
      "test_train\n",
      "train mean loss=0.11260228604078293\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1152.8199462890625\n",
      "epoch 1143\n",
      "test_train\n",
      "train mean loss=0.10757132371266682\n",
      "test_test\n",
      "test mean loss=1152.3756103515625\n",
      "epoch 1144\n",
      "test_train\n",
      "train mean loss=0.10945744005342324\n",
      "test_test\n",
      "test mean loss=1153.7379760742188\n",
      "epoch 1145\n",
      "test_train\n",
      "train mean loss=0.10989197716116905\n",
      "test_test\n",
      "test mean loss=1152.9658813476562\n",
      "epoch 1146\n",
      "test_train\n",
      "train mean loss=0.1075746634354194\n",
      "test_test\n",
      "test mean loss=1153.8450622558594\n",
      "epoch 1147\n",
      "test_train\n",
      "train mean loss=0.12202638201415539\n",
      "test_test\n",
      "test mean loss=1153.3289794921875\n",
      "epoch 1148\n",
      "test_train\n",
      "train mean loss=0.11027770924071471\n",
      "test_test\n",
      "test mean loss=1152.6336059570312\n",
      "epoch 1149\n",
      "test_train\n",
      "train mean loss=0.11207502149045467\n",
      "test_test\n",
      "test mean loss=1152.5927124023438\n",
      "epoch 1150\n",
      "test_train\n",
      "train mean loss=0.1135507629563411\n",
      "test_test\n",
      "test mean loss=1153.1708374023438\n",
      "epoch 1151\n",
      "test_train\n",
      "train mean loss=0.11431288036207359\n",
      "test_test\n",
      "test mean loss=1152.8062133789062\n",
      "epoch 1152\n",
      "test_train\n",
      "train mean loss=0.1144213347385327\n",
      "test_test\n",
      "test mean loss=1152.4513549804688\n",
      "epoch 1153\n",
      "test_train\n",
      "train mean loss=0.11612868867814541\n",
      "test_test\n",
      "test mean loss=1152.750244140625\n",
      "epoch 1154\n",
      "test_train\n",
      "train mean loss=0.10983218532055616\n",
      "test_test\n",
      "test mean loss=1153.4658813476562\n",
      "epoch 1155\n",
      "test_train\n",
      "train mean loss=0.10967146853605907\n",
      "test_test\n",
      "test mean loss=1153.2262268066406\n",
      "epoch 1156\n",
      "test_train\n",
      "train mean loss=0.11352644922832648\n",
      "test_test\n",
      "test mean loss=1153.2977905273438\n",
      "epoch 1157\n",
      "test_train\n",
      "train mean loss=0.11021576387186845\n",
      "test_test\n",
      "test mean loss=1153.8446655273438\n",
      "epoch 1158\n",
      "test_train\n",
      "train mean loss=0.10832666512578726\n",
      "test_test\n",
      "test mean loss=1153.0174560546875\n",
      "epoch 1159\n",
      "test_train\n",
      "train mean loss=0.11266336031258106\n",
      "test_test\n",
      "test mean loss=1153.1620178222656\n",
      "epoch 1160\n",
      "test_train\n",
      "train mean loss=0.11013485460231702\n",
      "test_test\n",
      "test mean loss=1152.6365051269531\n",
      "epoch 1161\n",
      "test_train\n",
      "train mean loss=0.10802162066102028\n",
      "test_test\n",
      "test mean loss=1153.2023315429688\n",
      "epoch 1162\n",
      "test_train\n",
      "train mean loss=0.11005408099542062\n",
      "test_test\n",
      "test mean loss=1153.2470703125\n",
      "epoch 1163\n",
      "test_train\n",
      "train mean loss=0.11100125126540661\n",
      "test_test\n",
      "test mean loss=1154.1936950683594\n",
      "epoch 1164\n",
      "test_train\n",
      "train mean loss=0.10806868970394135\n",
      "test_test\n",
      "test mean loss=1153.4212036132812\n",
      "epoch 1165\n",
      "test_train\n",
      "train mean loss=0.1129643376916647\n",
      "test_test\n",
      "test mean loss=1153.589111328125\n",
      "epoch 1166\n",
      "test_train\n",
      "train mean loss=0.11552565824240446\n",
      "test_test\n",
      "test mean loss=1153.7830505371094\n",
      "epoch 1167\n",
      "test_train\n",
      "train mean loss=0.11606911445657413\n",
      "test_test\n",
      "test mean loss=1152.8031311035156\n",
      "epoch 1168\n",
      "test_train\n",
      "train mean loss=0.10802778135985136\n",
      "test_test\n",
      "test mean loss=1154.3281555175781\n",
      "epoch 1169\n",
      "test_train\n",
      "train mean loss=0.10794370373090108\n",
      "test_test\n",
      "test mean loss=1154.2437133789062\n",
      "epoch 1170\n",
      "test_train\n",
      "train mean loss=0.11370214261114597\n",
      "test_test\n",
      "test mean loss=1154.3891296386719\n",
      "epoch 1171\n",
      "test_train\n",
      "train mean loss=0.11117647370944421\n",
      "test_test\n",
      "test mean loss=1153.9917602539062\n",
      "epoch 1172\n",
      "test_train\n",
      "train mean loss=0.10859747603535652\n",
      "test_test\n",
      "test mean loss=1153.7891235351562\n",
      "epoch 1173\n",
      "test_train\n",
      "train mean loss=0.10551591776311398\n",
      "test_test\n",
      "test mean loss=1153.4334106445312\n",
      "epoch 1174\n",
      "test_train\n",
      "train mean loss=0.11584371700882912\n",
      "test_test\n",
      "test mean loss=1154.04931640625\n",
      "epoch 1175\n",
      "test_train\n",
      "train mean loss=0.11107723135501146\n",
      "test_test\n",
      "test mean loss=1153.3875427246094\n",
      "epoch 1176\n",
      "test_train\n",
      "train mean loss=0.11099718200663726\n",
      "test_test\n",
      "test mean loss=1153.440673828125\n",
      "epoch 1177\n",
      "test_train\n",
      "train mean loss=0.11175493833919366\n",
      "test_test\n",
      "test mean loss=1154.1343383789062\n",
      "epoch 1178\n",
      "test_train\n",
      "train mean loss=0.1101827680443724\n",
      "test_test\n",
      "test mean loss=1154.8906860351562\n",
      "epoch 1179\n",
      "test_train\n",
      "train mean loss=0.112122418358922\n",
      "test_test\n",
      "test mean loss=1153.1835327148438\n",
      "epoch 1180\n",
      "test_train\n",
      "train mean loss=0.11300471983850002\n",
      "test_test\n",
      "test mean loss=1153.7068481445312\n",
      "epoch 1181\n",
      "test_train\n",
      "train mean loss=0.11345526451865832\n",
      "test_test\n",
      "test mean loss=1153.2427978515625\n",
      "epoch 1182\n",
      "test_train\n",
      "train mean loss=0.11277758640547593\n",
      "test_test\n",
      "test mean loss=1153.6775817871094\n",
      "epoch 1183\n",
      "test_train\n",
      "train mean loss=0.10793216619640589\n",
      "test_test\n",
      "test mean loss=1153.48388671875\n",
      "epoch 1184\n",
      "test_train\n",
      "train mean loss=0.10579523133734862\n",
      "test_test\n",
      "test mean loss=1153.250732421875\n",
      "epoch 1185\n",
      "test_train\n",
      "train mean loss=0.10589972666154306\n",
      "test_test\n",
      "test mean loss=1153.7063598632812\n",
      "epoch 1186\n",
      "test_train\n",
      "train mean loss=0.10789620255430539\n",
      "test_test\n",
      "test mean loss=1152.8727111816406\n",
      "epoch 1187\n",
      "test_train\n",
      "train mean loss=0.10974990141888459\n",
      "test_test\n",
      "test mean loss=1153.2689819335938\n",
      "epoch 1188\n",
      "test_train\n",
      "train mean loss=0.10839135323961575\n",
      "test_test\n",
      "test mean loss=1152.8785705566406\n",
      "epoch 1189\n",
      "test_train\n",
      "train mean loss=0.10607056847463052\n",
      "test_test\n",
      "test mean loss=1153.5147094726562\n",
      "epoch 1190\n",
      "test_train\n",
      "train mean loss=0.11327538546174765\n",
      "test_test\n",
      "test mean loss=1153.5788879394531\n",
      "epoch 1191\n",
      "test_train\n",
      "train mean loss=0.10461082495748997\n",
      "test_test\n",
      "test mean loss=1153.0791015625\n",
      "epoch 1192\n",
      "test_train\n",
      "train mean loss=0.10551816721757253\n",
      "test_test\n",
      "test mean loss=1153.50439453125\n",
      "epoch 1193\n",
      "test_train\n",
      "train mean loss=0.10774850472807884\n",
      "test_test\n",
      "test mean loss=1154.7130737304688\n",
      "epoch 1194\n",
      "test_train\n",
      "train mean loss=0.10669739699612062\n",
      "test_test\n",
      "test mean loss=1153.7764282226562\n",
      "epoch 1195\n",
      "test_train\n",
      "train mean loss=0.10961966371784608\n",
      "test_test\n",
      "test mean loss=1154.2815856933594\n",
      "epoch 1196\n",
      "test_train\n",
      "train mean loss=0.1159491961201032\n",
      "test_test\n",
      "test mean loss=1154.1609191894531\n",
      "epoch 1197\n",
      "test_train\n",
      "train mean loss=0.12396855279803276\n",
      "test_test\n",
      "test mean loss=1153.8197021484375\n",
      "epoch 1198\n",
      "test_train\n",
      "train mean loss=0.10620480496436357\n",
      "test_test\n",
      "test mean loss=1152.8027954101562\n",
      "epoch 1199\n",
      "test_train\n",
      "train mean loss=0.1044937027618289\n",
      "test_test\n",
      "test mean loss=1152.7342224121094\n",
      "epoch 1200\n",
      "test_train\n",
      "train mean loss=0.10858028878768285\n",
      "test_test\n",
      "test mean loss=1153.3539733886719\n",
      "epoch 1201\n",
      "test_train\n",
      "train mean loss=0.1144690706084172\n",
      "test_test\n",
      "test mean loss=1152.7028198242188\n",
      "epoch 1202\n",
      "test_train\n",
      "train mean loss=0.1099355419476827\n",
      "test_test\n",
      "test mean loss=1153.8569946289062\n",
      "epoch 1203\n",
      "test_train\n",
      "train mean loss=0.10616730308781068\n",
      "test_test\n",
      "test mean loss=1153.15478515625\n",
      "epoch 1204\n",
      "test_train\n",
      "train mean loss=0.10881857139368852\n",
      "test_test\n",
      "test mean loss=1153.5907592773438\n",
      "epoch 1205\n",
      "test_train\n",
      "train mean loss=0.11876608865956466\n",
      "test_test\n",
      "test mean loss=1153.3421630859375\n",
      "epoch 1206\n",
      "test_train\n",
      "train mean loss=0.11194395211835702\n",
      "test_test\n",
      "test mean loss=1153.3993225097656\n",
      "epoch 1207\n",
      "test_train\n",
      "train mean loss=0.10742750577628613\n",
      "test_test\n",
      "test mean loss=1153.3677673339844\n",
      "epoch 1208\n",
      "test_train\n",
      "train mean loss=0.10648774324605863\n",
      "test_test\n",
      "test mean loss=1153.086669921875\n",
      "epoch 1209\n",
      "test_train\n",
      "train mean loss=0.10775984885791938\n",
      "test_test\n",
      "test mean loss=1152.8184204101562\n",
      "epoch 1210\n",
      "test_train\n",
      "train mean loss=0.10650798150648673\n",
      "test_test\n",
      "test mean loss=1153.6880187988281\n",
      "epoch 1211\n",
      "test_train\n",
      "train mean loss=0.10781981082012256\n",
      "test_test\n",
      "test mean loss=1152.5973510742188\n",
      "epoch 1212\n",
      "test_train\n",
      "train mean loss=0.10677018575370312\n",
      "test_test\n",
      "test mean loss=1153.3023681640625\n",
      "epoch 1213\n",
      "test_train\n",
      "train mean loss=0.10730739589780569\n",
      "test_test\n",
      "test mean loss=1153.6650695800781\n",
      "epoch 1214\n",
      "test_train\n",
      "train mean loss=0.11828020835916202\n",
      "test_test\n",
      "test mean loss=1153.0712890625\n",
      "epoch 1215\n",
      "test_train\n",
      "train mean loss=0.10905007955928643\n",
      "test_test\n",
      "test mean loss=1153.4712524414062\n",
      "epoch 1216\n",
      "test_train\n",
      "train mean loss=0.10340339193741481\n",
      "test_test\n",
      "test mean loss=1153.1697387695312\n",
      "epoch 1217\n",
      "test_train\n",
      "train mean loss=0.10166726261377335\n",
      "test_test\n",
      "test mean loss=1153.3870849609375\n",
      "epoch 1218\n",
      "test_train\n",
      "train mean loss=0.10825629035631816\n",
      "test_test\n",
      "test mean loss=1154.2501220703125\n",
      "epoch 1219\n",
      "test_train\n",
      "train mean loss=0.11073717412849267\n",
      "test_test\n",
      "test mean loss=1154.2855834960938\n",
      "epoch 1220\n",
      "test_train\n",
      "train mean loss=0.11537095221380393\n",
      "test_test\n",
      "test mean loss=1153.9053649902344\n",
      "epoch 1221\n",
      "test_train\n",
      "train mean loss=0.10367818394054969\n",
      "test_test\n",
      "test mean loss=1153.9362182617188\n",
      "epoch 1222\n",
      "test_train\n",
      "train mean loss=0.1038786390175422\n",
      "test_test\n",
      "test mean loss=1154.4933776855469\n",
      "epoch 1223\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.1044921176508069\n",
      "test_test\n",
      "test mean loss=1154.267333984375\n",
      "epoch 1224\n",
      "test_train\n",
      "train mean loss=0.1058628677080075\n",
      "test_test\n",
      "test mean loss=1154.3590698242188\n",
      "epoch 1225\n",
      "test_train\n",
      "train mean loss=0.10517900343984365\n",
      "test_test\n",
      "test mean loss=1154.2459716796875\n",
      "epoch 1226\n",
      "test_train\n",
      "train mean loss=0.111594848955671\n",
      "test_test\n",
      "test mean loss=1155.3943481445312\n",
      "epoch 1227\n",
      "test_train\n",
      "train mean loss=0.10340292068819205\n",
      "test_test\n",
      "test mean loss=1154.7469177246094\n",
      "epoch 1228\n",
      "test_train\n",
      "train mean loss=0.10422540518144767\n",
      "test_test\n",
      "test mean loss=1154.0261840820312\n",
      "epoch 1229\n",
      "test_train\n",
      "train mean loss=0.1114795661220948\n",
      "test_test\n",
      "test mean loss=1153.8871459960938\n",
      "epoch 1230\n",
      "test_train\n",
      "train mean loss=0.11198244523257017\n",
      "test_test\n",
      "test mean loss=1153.8595886230469\n",
      "epoch 1231\n",
      "test_train\n",
      "train mean loss=0.11016125542422135\n",
      "test_test\n",
      "test mean loss=1153.0263671875\n",
      "epoch 1232\n",
      "test_train\n",
      "train mean loss=0.10579611485203107\n",
      "test_test\n",
      "test mean loss=1153.93603515625\n",
      "epoch 1233\n",
      "test_train\n",
      "train mean loss=0.09918972260008256\n",
      "test_test\n",
      "test mean loss=1154.2538452148438\n",
      "epoch 1234\n",
      "test_train\n",
      "train mean loss=0.09889899690945943\n",
      "test_test\n",
      "test mean loss=1154.343994140625\n",
      "epoch 1235\n",
      "test_train\n",
      "train mean loss=0.10555570510526498\n",
      "test_test\n",
      "test mean loss=1154.0986633300781\n",
      "epoch 1236\n",
      "test_train\n",
      "train mean loss=0.10384717304259539\n",
      "test_test\n",
      "test mean loss=1153.59814453125\n",
      "epoch 1237\n",
      "test_train\n",
      "train mean loss=0.10243890869120757\n",
      "test_test\n",
      "test mean loss=1153.5025024414062\n",
      "epoch 1238\n",
      "test_train\n",
      "train mean loss=0.1061058547347784\n",
      "test_test\n",
      "test mean loss=1154.4565124511719\n",
      "epoch 1239\n",
      "test_train\n",
      "train mean loss=0.10432205287118752\n",
      "test_test\n",
      "test mean loss=1152.7743835449219\n",
      "epoch 1240\n",
      "test_train\n",
      "train mean loss=0.10841075579325359\n",
      "test_test\n",
      "test mean loss=1152.961181640625\n",
      "epoch 1241\n",
      "test_train\n",
      "train mean loss=0.11411361054827769\n",
      "test_test\n",
      "test mean loss=1154.3062744140625\n",
      "epoch 1242\n",
      "test_train\n",
      "train mean loss=0.10614141076803207\n",
      "test_test\n",
      "test mean loss=1154.0640258789062\n",
      "epoch 1243\n",
      "test_train\n",
      "train mean loss=0.10645627820243438\n",
      "test_test\n",
      "test mean loss=1153.2384033203125\n",
      "epoch 1244\n",
      "test_train\n",
      "train mean loss=0.10253419571866591\n",
      "test_test\n",
      "test mean loss=1153.8108520507812\n",
      "epoch 1245\n",
      "test_train\n",
      "train mean loss=0.10969010057548682\n",
      "test_test\n",
      "test mean loss=1153.9401245117188\n",
      "epoch 1246\n",
      "test_train\n",
      "train mean loss=0.105510665414234\n",
      "test_test\n",
      "test mean loss=1153.722412109375\n",
      "epoch 1247\n",
      "test_train\n",
      "train mean loss=0.12416025685767333\n",
      "test_test\n",
      "test mean loss=1154.5544738769531\n",
      "epoch 1248\n",
      "test_train\n",
      "train mean loss=0.11029469221830368\n",
      "test_test\n",
      "test mean loss=1153.5126342773438\n",
      "epoch 1249\n",
      "test_train\n",
      "train mean loss=0.10757142243285973\n",
      "test_test\n",
      "test mean loss=1153.5037841796875\n",
      "epoch 1250\n",
      "test_train\n",
      "train mean loss=0.10440076825519402\n",
      "test_test\n",
      "test mean loss=1153.7281494140625\n",
      "epoch 1251\n",
      "test_train\n",
      "train mean loss=0.11308687335501115\n",
      "test_test\n",
      "test mean loss=1153.0487670898438\n",
      "epoch 1252\n",
      "test_train\n",
      "train mean loss=0.10800838780899842\n",
      "test_test\n",
      "test mean loss=1153.6575317382812\n",
      "epoch 1253\n",
      "test_train\n",
      "train mean loss=0.1081720544025302\n",
      "test_test\n",
      "test mean loss=1153.59716796875\n",
      "epoch 1254\n",
      "test_train\n",
      "train mean loss=0.10486899533619483\n",
      "test_test\n",
      "test mean loss=1154.0071411132812\n",
      "epoch 1255\n",
      "test_train\n",
      "train mean loss=0.10909676117201646\n",
      "test_test\n",
      "test mean loss=1153.4546203613281\n",
      "epoch 1256\n",
      "test_train\n",
      "train mean loss=0.11304653404901426\n",
      "test_test\n",
      "test mean loss=1154.6312561035156\n",
      "epoch 1257\n",
      "test_train\n",
      "train mean loss=0.1095104884977142\n",
      "test_test\n",
      "test mean loss=1154.8129272460938\n",
      "epoch 1258\n",
      "test_train\n",
      "train mean loss=0.10663337384661038\n",
      "test_test\n",
      "test mean loss=1154.4905090332031\n",
      "epoch 1259\n",
      "test_train\n",
      "train mean loss=0.10633663025995095\n",
      "test_test\n",
      "test mean loss=1154.8008422851562\n",
      "epoch 1260\n",
      "test_train\n",
      "train mean loss=0.10242219145099322\n",
      "test_test\n",
      "test mean loss=1154.1657104492188\n",
      "epoch 1261\n",
      "test_train\n",
      "train mean loss=0.10426819355537494\n",
      "test_test\n",
      "test mean loss=1154.6093139648438\n",
      "epoch 1262\n",
      "test_train\n",
      "train mean loss=0.10082319316764672\n",
      "test_test\n",
      "test mean loss=1152.906005859375\n",
      "epoch 1263\n",
      "test_train\n",
      "train mean loss=0.10278535479058822\n",
      "test_test\n",
      "test mean loss=1153.0125732421875\n",
      "epoch 1264\n",
      "test_train\n",
      "train mean loss=0.1051127826794982\n",
      "test_test\n",
      "test mean loss=1153.5716552734375\n",
      "epoch 1265\n",
      "test_train\n",
      "train mean loss=0.10027762254079182\n",
      "test_test\n",
      "test mean loss=1153.1592407226562\n",
      "epoch 1266\n",
      "test_train\n",
      "train mean loss=0.09981765846411388\n",
      "test_test\n",
      "test mean loss=1153.1560668945312\n",
      "epoch 1267\n",
      "test_train\n",
      "train mean loss=0.10440810117870569\n",
      "test_test\n",
      "test mean loss=1153.6291198730469\n",
      "epoch 1268\n",
      "test_train\n",
      "train mean loss=0.10202818146596353\n",
      "test_test\n",
      "test mean loss=1152.6598815917969\n",
      "epoch 1269\n",
      "test_train\n",
      "train mean loss=0.10522452369332314\n",
      "test_test\n",
      "test mean loss=1152.3204956054688\n",
      "epoch 1270\n",
      "test_train\n",
      "train mean loss=0.12266375310719013\n",
      "test_test\n",
      "test mean loss=1154.9204711914062\n",
      "epoch 1271\n",
      "test_train\n",
      "train mean loss=0.10131177864968777\n",
      "test_test\n",
      "test mean loss=1153.1752624511719\n",
      "epoch 1272\n",
      "test_train\n",
      "train mean loss=0.11159150799115498\n",
      "test_test\n",
      "test mean loss=1154.7665710449219\n",
      "epoch 1273\n",
      "test_train\n",
      "train mean loss=0.10818222599724929\n",
      "test_test\n",
      "test mean loss=1154.42138671875\n",
      "epoch 1274\n",
      "test_train\n",
      "train mean loss=0.14724909514188766\n",
      "test_test\n",
      "test mean loss=1153.3108520507812\n",
      "epoch 1275\n",
      "test_train\n",
      "train mean loss=0.10912153931955497\n",
      "test_test\n",
      "test mean loss=1153.7106018066406\n",
      "epoch 1276\n",
      "test_train\n",
      "train mean loss=0.10468897751222055\n",
      "test_test\n",
      "test mean loss=1153.70556640625\n",
      "epoch 1277\n",
      "test_train\n",
      "train mean loss=0.11062312684953213\n",
      "test_test\n",
      "test mean loss=1153.1927795410156\n",
      "epoch 1278\n",
      "test_train\n",
      "train mean loss=0.10686963920791943\n",
      "test_test\n",
      "test mean loss=1154.0225219726562\n",
      "epoch 1279\n",
      "test_train\n",
      "train mean loss=0.10168894628683726\n",
      "test_test\n",
      "test mean loss=1153.8958129882812\n",
      "epoch 1280\n",
      "test_train\n",
      "train mean loss=0.10623121509949367\n",
      "test_test\n",
      "test mean loss=1154.2008361816406\n",
      "epoch 1281\n",
      "test_train\n",
      "train mean loss=0.10638044277826945\n",
      "test_test\n",
      "test mean loss=1153.6768798828125\n",
      "epoch 1282\n",
      "test_train\n",
      "train mean loss=0.102336959913373\n",
      "test_test\n",
      "test mean loss=1154.6014709472656\n",
      "epoch 1283\n",
      "test_train\n",
      "train mean loss=0.1015080704043309\n",
      "test_test\n",
      "test mean loss=1154.5701904296875\n",
      "epoch 1284\n",
      "test_train\n",
      "train mean loss=0.10078713794549306\n",
      "test_test\n",
      "test mean loss=1153.9993286132812\n",
      "epoch 1285\n",
      "test_train\n",
      "train mean loss=0.39008455475171405\n",
      "test_test\n",
      "test mean loss=1156.3142700195312\n",
      "epoch 1286\n",
      "test_train\n",
      "train mean loss=0.11705757739643256\n",
      "test_test\n",
      "test mean loss=1155.2373962402344\n",
      "epoch 1287\n",
      "test_train\n",
      "train mean loss=0.10660949784020583\n",
      "test_test\n",
      "test mean loss=1154.1763000488281\n",
      "epoch 1288\n",
      "test_train\n",
      "train mean loss=0.10602756341298421\n",
      "test_test\n",
      "test mean loss=1153.9232788085938\n",
      "epoch 1289\n",
      "test_train\n",
      "train mean loss=0.10945760210355122\n",
      "test_test\n",
      "test mean loss=1154.4420166015625\n",
      "epoch 1290\n",
      "test_train\n",
      "train mean loss=0.1070106861491998\n",
      "test_test\n",
      "test mean loss=1153.3060302734375\n",
      "epoch 1291\n",
      "test_train\n",
      "train mean loss=0.11349790915846825\n",
      "test_test\n",
      "test mean loss=1153.5234985351562\n",
      "epoch 1292\n",
      "test_train\n",
      "train mean loss=0.11802863950530688\n",
      "test_test\n",
      "test mean loss=1155.7327880859375\n",
      "epoch 1293\n",
      "test_train\n",
      "train mean loss=0.10558971296995878\n",
      "test_test\n",
      "test mean loss=1154.6661987304688\n",
      "epoch 1294\n",
      "test_train\n",
      "train mean loss=0.104525792102019\n",
      "test_test\n",
      "test mean loss=1153.670654296875\n",
      "epoch 1295\n",
      "test_train\n",
      "train mean loss=0.10969571769237518\n",
      "test_test\n",
      "test mean loss=1154.1683044433594\n",
      "epoch 1296\n",
      "test_train\n",
      "train mean loss=0.10456698760390282\n",
      "test_test\n",
      "test mean loss=1154.8183288574219\n",
      "epoch 1297\n",
      "test_train\n",
      "train mean loss=0.10859131471564372\n",
      "test_test\n",
      "test mean loss=1154.6285400390625\n",
      "epoch 1298\n",
      "test_train\n",
      "train mean loss=0.1082102907821536\n",
      "test_test\n",
      "test mean loss=1154.8704528808594\n",
      "epoch 1299\n",
      "test_train\n",
      "train mean loss=0.10955938510596752\n",
      "test_test\n",
      "test mean loss=1154.5612182617188\n",
      "epoch 1300\n",
      "test_train\n",
      "train mean loss=0.10844875127077103\n",
      "test_test\n",
      "test mean loss=1154.5658569335938\n",
      "epoch 1301\n",
      "test_train\n",
      "train mean loss=0.1046160003170371\n",
      "test_test\n",
      "test mean loss=1154.0591125488281\n",
      "epoch 1302\n",
      "test_train\n",
      "train mean loss=0.1062506375213464\n",
      "test_test\n",
      "test mean loss=1154.4371643066406\n",
      "epoch 1303\n",
      "test_train\n",
      "train mean loss=0.1103594470769167\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1154.1708679199219\n",
      "epoch 1304\n",
      "test_train\n",
      "train mean loss=0.10400485744078954\n",
      "test_test\n",
      "test mean loss=1154.5020141601562\n",
      "epoch 1305\n",
      "test_train\n",
      "train mean loss=0.10779959211746852\n",
      "test_test\n",
      "test mean loss=1155.2662963867188\n",
      "epoch 1306\n",
      "test_train\n",
      "train mean loss=0.09829221510638793\n",
      "test_test\n",
      "test mean loss=1154.0139465332031\n",
      "epoch 1307\n",
      "test_train\n",
      "train mean loss=0.09840791517247756\n",
      "test_test\n",
      "test mean loss=1155.5081176757812\n",
      "epoch 1308\n",
      "test_train\n",
      "train mean loss=0.10519327285389106\n",
      "test_test\n",
      "test mean loss=1155.56005859375\n",
      "epoch 1309\n",
      "test_train\n",
      "train mean loss=0.1033145912612478\n",
      "test_test\n",
      "test mean loss=1153.9843139648438\n",
      "epoch 1310\n",
      "test_train\n",
      "train mean loss=0.10850373283028603\n",
      "test_test\n",
      "test mean loss=1154.533935546875\n",
      "epoch 1311\n",
      "test_train\n",
      "train mean loss=0.10505052438626687\n",
      "test_test\n",
      "test mean loss=1153.8012084960938\n",
      "epoch 1312\n",
      "test_train\n",
      "train mean loss=0.09958609441916148\n",
      "test_test\n",
      "test mean loss=1154.3580932617188\n",
      "epoch 1313\n",
      "test_train\n",
      "train mean loss=0.1025457934786876\n",
      "test_test\n",
      "test mean loss=1154.5913696289062\n",
      "epoch 1314\n",
      "test_train\n",
      "train mean loss=0.1076437917848428\n",
      "test_test\n",
      "test mean loss=1154.1796264648438\n",
      "epoch 1315\n",
      "test_train\n",
      "train mean loss=0.1065058574701349\n",
      "test_test\n",
      "test mean loss=1154.8272705078125\n",
      "epoch 1316\n",
      "test_train\n",
      "train mean loss=0.11559877296288808\n",
      "test_test\n",
      "test mean loss=1155.1234741210938\n",
      "epoch 1317\n",
      "test_train\n",
      "train mean loss=0.10077186052997907\n",
      "test_test\n",
      "test mean loss=1153.8671264648438\n",
      "epoch 1318\n",
      "test_train\n",
      "train mean loss=0.10149815957993269\n",
      "test_test\n",
      "test mean loss=1155.0328369140625\n",
      "epoch 1319\n",
      "test_train\n",
      "train mean loss=0.10108423201988141\n",
      "test_test\n",
      "test mean loss=1154.0155944824219\n",
      "epoch 1320\n",
      "test_train\n",
      "train mean loss=0.10421430505812168\n",
      "test_test\n",
      "test mean loss=1154.2627563476562\n",
      "epoch 1321\n",
      "test_train\n",
      "train mean loss=0.1009044914195935\n",
      "test_test\n",
      "test mean loss=1154.6640319824219\n",
      "epoch 1322\n",
      "test_train\n",
      "train mean loss=0.10422729390362899\n",
      "test_test\n",
      "test mean loss=1154.3746948242188\n",
      "epoch 1323\n",
      "test_train\n",
      "train mean loss=0.09892427921295166\n",
      "test_test\n",
      "test mean loss=1154.0\n",
      "epoch 1324\n",
      "test_train\n",
      "train mean loss=0.10678544888893764\n",
      "test_test\n",
      "test mean loss=1154.2252502441406\n",
      "epoch 1325\n",
      "test_train\n",
      "train mean loss=0.10475285941114028\n",
      "test_test\n",
      "test mean loss=1154.6348876953125\n",
      "epoch 1326\n",
      "test_train\n",
      "train mean loss=0.10846260531495015\n",
      "test_test\n",
      "test mean loss=1153.8892822265625\n",
      "epoch 1327\n",
      "test_train\n",
      "train mean loss=0.10789501667022705\n",
      "test_test\n",
      "test mean loss=1154.2940673828125\n",
      "epoch 1328\n",
      "test_train\n",
      "train mean loss=0.10213931743055582\n",
      "test_test\n",
      "test mean loss=1154.51025390625\n",
      "epoch 1329\n",
      "test_train\n",
      "train mean loss=0.10416620193670194\n",
      "test_test\n",
      "test mean loss=1154.1112060546875\n",
      "epoch 1330\n",
      "test_train\n",
      "train mean loss=0.10913444931308429\n",
      "test_test\n",
      "test mean loss=1154.5353393554688\n",
      "epoch 1331\n",
      "test_train\n",
      "train mean loss=0.10677322683235009\n",
      "test_test\n",
      "test mean loss=1154.9540405273438\n",
      "epoch 1332\n",
      "test_train\n",
      "train mean loss=0.1067558831224839\n",
      "test_test\n",
      "test mean loss=1155.8651428222656\n",
      "epoch 1333\n",
      "test_train\n",
      "train mean loss=0.10222771546492974\n",
      "test_test\n",
      "test mean loss=1154.7729187011719\n",
      "epoch 1334\n",
      "test_train\n",
      "train mean loss=0.09681678966929515\n",
      "test_test\n",
      "test mean loss=1154.2548828125\n",
      "epoch 1335\n",
      "test_train\n",
      "train mean loss=0.09990150853991508\n",
      "test_test\n",
      "test mean loss=1153.8610229492188\n",
      "epoch 1336\n",
      "test_train\n",
      "train mean loss=0.09816138415286939\n",
      "test_test\n",
      "test mean loss=1154.272705078125\n",
      "epoch 1337\n",
      "test_train\n",
      "train mean loss=0.11778533086180687\n",
      "test_test\n",
      "test mean loss=1152.8451538085938\n",
      "epoch 1338\n",
      "test_train\n",
      "train mean loss=0.10817265696823597\n",
      "test_test\n",
      "test mean loss=1154.6960144042969\n",
      "epoch 1339\n",
      "test_train\n",
      "train mean loss=0.10771811815599601\n",
      "test_test\n",
      "test mean loss=1155.0951232910156\n",
      "epoch 1340\n",
      "test_train\n",
      "train mean loss=0.10484632880737384\n",
      "test_test\n",
      "test mean loss=1154.0379028320312\n",
      "epoch 1341\n",
      "test_train\n",
      "train mean loss=0.1007371839756767\n",
      "test_test\n",
      "test mean loss=1154.6614990234375\n",
      "epoch 1342\n",
      "test_train\n",
      "train mean loss=0.11718612940361102\n",
      "test_test\n",
      "test mean loss=1156.1074523925781\n",
      "epoch 1343\n",
      "test_train\n",
      "train mean loss=0.11099733940015237\n",
      "test_test\n",
      "test mean loss=1154.87451171875\n",
      "epoch 1344\n",
      "test_train\n",
      "train mean loss=0.10410271398723125\n",
      "test_test\n",
      "test mean loss=1154.9576416015625\n",
      "epoch 1345\n",
      "test_train\n",
      "train mean loss=0.10530235525220633\n",
      "test_test\n",
      "test mean loss=1154.08935546875\n",
      "epoch 1346\n",
      "test_train\n",
      "train mean loss=0.10279451714207728\n",
      "test_test\n",
      "test mean loss=1154.3568115234375\n",
      "epoch 1347\n",
      "test_train\n",
      "train mean loss=0.09957544598728418\n",
      "test_test\n",
      "test mean loss=1154.764892578125\n",
      "epoch 1348\n",
      "test_train\n",
      "train mean loss=0.09892463497817516\n",
      "test_test\n",
      "test mean loss=1154.6860656738281\n",
      "epoch 1349\n",
      "test_train\n",
      "train mean loss=0.11224816429118316\n",
      "test_test\n",
      "test mean loss=1156.3991088867188\n",
      "epoch 1350\n",
      "test_train\n",
      "train mean loss=0.10165557420502107\n",
      "test_test\n",
      "test mean loss=1155.7691955566406\n",
      "epoch 1351\n",
      "test_train\n",
      "train mean loss=0.10019641121228536\n",
      "test_test\n",
      "test mean loss=1155.2833862304688\n",
      "epoch 1352\n",
      "test_train\n",
      "train mean loss=0.10057099877546231\n",
      "test_test\n",
      "test mean loss=1155.1076965332031\n",
      "epoch 1353\n",
      "test_train\n",
      "train mean loss=0.11519980244338512\n",
      "test_test\n",
      "test mean loss=1154.5353088378906\n",
      "epoch 1354\n",
      "test_train\n",
      "train mean loss=0.10697304612646501\n",
      "test_test\n",
      "test mean loss=1154.2748413085938\n",
      "epoch 1355\n",
      "test_train\n",
      "train mean loss=0.22853159656127295\n",
      "test_test\n",
      "test mean loss=1159.2935180664062\n",
      "epoch 1356\n",
      "test_train\n",
      "train mean loss=0.11459142714738846\n",
      "test_test\n",
      "test mean loss=1154.8565063476562\n",
      "epoch 1357\n",
      "test_train\n",
      "train mean loss=0.1280890696992477\n",
      "test_test\n",
      "test mean loss=1155.8222045898438\n",
      "epoch 1358\n",
      "test_train\n",
      "train mean loss=0.11360700304309528\n",
      "test_test\n",
      "test mean loss=1155.4873352050781\n",
      "epoch 1359\n",
      "test_train\n",
      "train mean loss=0.10849133382240932\n",
      "test_test\n",
      "test mean loss=1155.1836242675781\n",
      "epoch 1360\n",
      "test_train\n",
      "train mean loss=0.10508105220894019\n",
      "test_test\n",
      "test mean loss=1155.5465393066406\n",
      "epoch 1361\n",
      "test_train\n",
      "train mean loss=0.10173458916445573\n",
      "test_test\n",
      "test mean loss=1155.5554809570312\n",
      "epoch 1362\n",
      "test_train\n",
      "train mean loss=0.11343053728342056\n",
      "test_test\n",
      "test mean loss=1156.8221435546875\n",
      "epoch 1363\n",
      "test_train\n",
      "train mean loss=0.10457116365432739\n",
      "test_test\n",
      "test mean loss=1155.6991882324219\n",
      "epoch 1364\n",
      "test_train\n",
      "train mean loss=0.12157872940103213\n",
      "test_test\n",
      "test mean loss=1157.4326171875\n",
      "epoch 1365\n",
      "test_train\n",
      "train mean loss=0.10389924608170986\n",
      "test_test\n",
      "test mean loss=1155.1435546875\n",
      "epoch 1366\n",
      "test_train\n",
      "train mean loss=1.3047386705875397\n",
      "test_test\n",
      "test mean loss=1159.7185668945312\n",
      "epoch 1367\n",
      "test_train\n",
      "train mean loss=0.15644878956178823\n",
      "test_test\n",
      "test mean loss=1158.4232482910156\n",
      "epoch 1368\n",
      "test_train\n",
      "train mean loss=0.1242090320835511\n",
      "test_test\n",
      "test mean loss=1156.1471557617188\n",
      "epoch 1369\n",
      "test_train\n",
      "train mean loss=0.14727652010818323\n",
      "test_test\n",
      "test mean loss=1156.0484619140625\n",
      "epoch 1370\n",
      "test_train\n",
      "train mean loss=0.1234994667271773\n",
      "test_test\n",
      "test mean loss=1157.2318115234375\n",
      "epoch 1371\n",
      "test_train\n",
      "train mean loss=0.12008614217241605\n",
      "test_test\n",
      "test mean loss=1157.1385498046875\n",
      "epoch 1372\n",
      "test_train\n",
      "train mean loss=0.12469598713020484\n",
      "test_test\n",
      "test mean loss=1155.4651794433594\n",
      "epoch 1373\n",
      "test_train\n",
      "train mean loss=0.11606408034761746\n",
      "test_test\n",
      "test mean loss=1156.6871337890625\n",
      "epoch 1374\n",
      "test_train\n",
      "train mean loss=0.10443735339989264\n",
      "test_test\n",
      "test mean loss=1156.3842163085938\n",
      "epoch 1375\n",
      "test_train\n",
      "train mean loss=0.10863200202584267\n",
      "test_test\n",
      "test mean loss=1156.504638671875\n",
      "epoch 1376\n",
      "test_train\n",
      "train mean loss=0.1063529048115015\n",
      "test_test\n",
      "test mean loss=1156.7913818359375\n",
      "epoch 1377\n",
      "test_train\n",
      "train mean loss=0.10917668168743451\n",
      "test_test\n",
      "test mean loss=1156.6168823242188\n",
      "epoch 1378\n",
      "test_train\n",
      "train mean loss=0.1016734301423033\n",
      "test_test\n",
      "test mean loss=1157.0663452148438\n",
      "epoch 1379\n",
      "test_train\n",
      "train mean loss=0.17149283612767854\n",
      "test_test\n",
      "test mean loss=1155.6900024414062\n",
      "epoch 1380\n",
      "test_train\n",
      "train mean loss=0.19735562925537428\n",
      "test_test\n",
      "test mean loss=1158.9515380859375\n",
      "epoch 1381\n",
      "test_train\n",
      "train mean loss=0.11552106775343418\n",
      "test_test\n",
      "test mean loss=1155.8399047851562\n",
      "epoch 1382\n",
      "test_train\n",
      "train mean loss=0.11253397011508544\n",
      "test_test\n",
      "test mean loss=1155.2874145507812\n",
      "epoch 1383\n",
      "test_train\n",
      "train mean loss=0.1340564644585053\n",
      "test_test\n",
      "test mean loss=1154.8839721679688\n",
      "epoch 1384\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.11038402219613393\n",
      "test_test\n",
      "test mean loss=1155.6644287109375\n",
      "epoch 1385\n",
      "test_train\n",
      "train mean loss=0.11893871861199538\n",
      "test_test\n",
      "test mean loss=1156.2951049804688\n",
      "epoch 1386\n",
      "test_train\n",
      "train mean loss=0.10699364263564348\n",
      "test_test\n",
      "test mean loss=1156.2951354980469\n",
      "epoch 1387\n",
      "test_train\n",
      "train mean loss=0.14358081482350826\n",
      "test_test\n",
      "test mean loss=1156.1469116210938\n",
      "epoch 1388\n",
      "test_train\n",
      "train mean loss=0.11148230886707704\n",
      "test_test\n",
      "test mean loss=1156.0033264160156\n",
      "epoch 1389\n",
      "test_train\n",
      "train mean loss=0.1065346139172713\n",
      "test_test\n",
      "test mean loss=1155.8424682617188\n",
      "epoch 1390\n",
      "test_train\n",
      "train mean loss=0.10210711353768905\n",
      "test_test\n",
      "test mean loss=1155.5918273925781\n",
      "epoch 1391\n",
      "test_train\n",
      "train mean loss=0.10277514376988013\n",
      "test_test\n",
      "test mean loss=1155.6003112792969\n",
      "epoch 1392\n",
      "test_train\n",
      "train mean loss=0.10492958966642618\n",
      "test_test\n",
      "test mean loss=1155.6997680664062\n",
      "epoch 1393\n",
      "test_train\n",
      "train mean loss=0.10100583359599113\n",
      "test_test\n",
      "test mean loss=1154.2527160644531\n",
      "epoch 1394\n",
      "test_train\n",
      "train mean loss=0.0996951578805844\n",
      "test_test\n",
      "test mean loss=1155.9508666992188\n",
      "epoch 1395\n",
      "test_train\n",
      "train mean loss=0.10528530273586512\n",
      "test_test\n",
      "test mean loss=1156.5819702148438\n",
      "epoch 1396\n",
      "test_train\n",
      "train mean loss=0.10626361705362797\n",
      "test_test\n",
      "test mean loss=1156.4757690429688\n",
      "epoch 1397\n",
      "test_train\n",
      "train mean loss=0.10443856784452994\n",
      "test_test\n",
      "test mean loss=1156.3937072753906\n",
      "epoch 1398\n",
      "test_train\n",
      "train mean loss=0.10319218225777149\n",
      "test_test\n",
      "test mean loss=1155.100830078125\n",
      "epoch 1399\n",
      "test_train\n",
      "train mean loss=0.1042841390396158\n",
      "test_test\n",
      "test mean loss=1155.7682495117188\n",
      "epoch 1400\n",
      "test_train\n",
      "train mean loss=0.105354734386007\n",
      "test_test\n",
      "test mean loss=1156.076416015625\n",
      "epoch 1401\n",
      "test_train\n",
      "train mean loss=0.11535395961254835\n",
      "test_test\n",
      "test mean loss=1157.3287353515625\n",
      "epoch 1402\n",
      "test_train\n",
      "train mean loss=0.10311883284399907\n",
      "test_test\n",
      "test mean loss=1155.7314147949219\n",
      "epoch 1403\n",
      "test_train\n",
      "train mean loss=0.10548061598092318\n",
      "test_test\n",
      "test mean loss=1155.607666015625\n",
      "epoch 1404\n",
      "test_train\n",
      "train mean loss=0.10900448107471068\n",
      "test_test\n",
      "test mean loss=1156.3776550292969\n",
      "epoch 1405\n",
      "test_train\n",
      "train mean loss=0.10421921188632648\n",
      "test_test\n",
      "test mean loss=1154.4649047851562\n",
      "epoch 1406\n",
      "test_train\n",
      "train mean loss=0.11072491854429245\n",
      "test_test\n",
      "test mean loss=1155.8247680664062\n",
      "epoch 1407\n",
      "test_train\n",
      "train mean loss=0.2886267068485419\n",
      "test_test\n",
      "test mean loss=1157.9368896484375\n",
      "epoch 1408\n",
      "test_train\n",
      "train mean loss=0.1231136005371809\n",
      "test_test\n",
      "test mean loss=1157.7248229980469\n",
      "epoch 1409\n",
      "test_train\n",
      "train mean loss=0.106255358705918\n",
      "test_test\n",
      "test mean loss=1156.5762634277344\n",
      "epoch 1410\n",
      "test_train\n",
      "train mean loss=0.09693988505750895\n",
      "test_test\n",
      "test mean loss=1155.6846313476562\n",
      "epoch 1411\n",
      "test_train\n",
      "train mean loss=0.11789506549636523\n",
      "test_test\n",
      "test mean loss=1155.5548095703125\n",
      "epoch 1412\n",
      "test_train\n",
      "train mean loss=0.10352664565046628\n",
      "test_test\n",
      "test mean loss=1156.0615539550781\n",
      "epoch 1413\n",
      "test_train\n",
      "train mean loss=0.10775868842999141\n",
      "test_test\n",
      "test mean loss=1156.0332641601562\n",
      "epoch 1414\n",
      "test_train\n",
      "train mean loss=0.1097476997723182\n",
      "test_test\n",
      "test mean loss=1155.9486694335938\n",
      "epoch 1415\n",
      "test_train\n",
      "train mean loss=0.11114593936751287\n",
      "test_test\n",
      "test mean loss=1155.478271484375\n",
      "epoch 1416\n",
      "test_train\n",
      "train mean loss=0.1088700219988823\n",
      "test_test\n",
      "test mean loss=1156.9100952148438\n",
      "epoch 1417\n",
      "test_train\n",
      "train mean loss=0.10494786687195301\n",
      "test_test\n",
      "test mean loss=1157.01513671875\n",
      "epoch 1418\n",
      "test_train\n",
      "train mean loss=0.14339349108437696\n",
      "test_test\n",
      "test mean loss=1155.9922485351562\n",
      "epoch 1419\n",
      "test_train\n",
      "train mean loss=0.20514536773165068\n",
      "test_test\n",
      "test mean loss=1155.1942749023438\n",
      "epoch 1420\n",
      "test_train\n",
      "train mean loss=0.11500244587659836\n",
      "test_test\n",
      "test mean loss=1154.7573852539062\n",
      "epoch 1421\n",
      "test_train\n",
      "train mean loss=0.10482139171411593\n",
      "test_test\n",
      "test mean loss=1154.2710571289062\n",
      "epoch 1422\n",
      "test_train\n",
      "train mean loss=0.13557167910039425\n",
      "test_test\n",
      "test mean loss=1154.0235900878906\n",
      "epoch 1423\n",
      "test_train\n",
      "train mean loss=0.09935216388354699\n",
      "test_test\n",
      "test mean loss=1154.3847045898438\n",
      "epoch 1424\n",
      "test_train\n",
      "train mean loss=0.10229421127587557\n",
      "test_test\n",
      "test mean loss=1155.3825378417969\n",
      "epoch 1425\n",
      "test_train\n",
      "train mean loss=0.10410506588717301\n",
      "test_test\n",
      "test mean loss=1155.4086303710938\n",
      "epoch 1426\n",
      "test_train\n",
      "train mean loss=0.1067025177180767\n",
      "test_test\n",
      "test mean loss=1155.091796875\n",
      "epoch 1427\n",
      "test_train\n",
      "train mean loss=0.10252177529036999\n",
      "test_test\n",
      "test mean loss=1155.93115234375\n",
      "epoch 1428\n",
      "test_train\n",
      "train mean loss=0.09982428885996342\n",
      "test_test\n",
      "test mean loss=1155.1751708984375\n",
      "epoch 1429\n",
      "test_train\n",
      "train mean loss=0.17375166652103266\n",
      "test_test\n",
      "test mean loss=1158.2250061035156\n",
      "epoch 1430\n",
      "test_train\n",
      "train mean loss=0.11141724077363808\n",
      "test_test\n",
      "test mean loss=1156.9261474609375\n",
      "epoch 1431\n",
      "test_train\n",
      "train mean loss=0.10691581883778174\n",
      "test_test\n",
      "test mean loss=1156.4768981933594\n",
      "epoch 1432\n",
      "test_train\n",
      "train mean loss=0.107413691158096\n",
      "test_test\n",
      "test mean loss=1155.8102416992188\n",
      "epoch 1433\n",
      "test_train\n",
      "train mean loss=0.11666431340078513\n",
      "test_test\n",
      "test mean loss=1156.9784545898438\n",
      "epoch 1434\n",
      "test_train\n",
      "train mean loss=0.10250518719355266\n",
      "test_test\n",
      "test mean loss=1155.5091552734375\n",
      "epoch 1435\n",
      "test_train\n",
      "train mean loss=0.10503443237394094\n",
      "test_test\n",
      "test mean loss=1155.9353637695312\n",
      "epoch 1436\n",
      "test_train\n",
      "train mean loss=0.09824663121253252\n",
      "test_test\n",
      "test mean loss=1155.5357666015625\n",
      "epoch 1437\n",
      "test_train\n",
      "train mean loss=0.10135999818642934\n",
      "test_test\n",
      "test mean loss=1155.0471801757812\n",
      "epoch 1438\n",
      "test_train\n",
      "train mean loss=0.10610117887457211\n",
      "test_test\n",
      "test mean loss=1155.0787963867188\n",
      "epoch 1439\n",
      "test_train\n",
      "train mean loss=0.10114221119632323\n",
      "test_test\n",
      "test mean loss=1155.1475219726562\n",
      "epoch 1440\n",
      "test_train\n",
      "train mean loss=0.10118562169373035\n",
      "test_test\n",
      "test mean loss=1155.1413879394531\n",
      "epoch 1441\n",
      "test_train\n",
      "train mean loss=0.10339663239816825\n",
      "test_test\n",
      "test mean loss=1155.6695556640625\n",
      "epoch 1442\n",
      "test_train\n",
      "train mean loss=0.10395786538720131\n",
      "test_test\n",
      "test mean loss=1156.1610107421875\n",
      "epoch 1443\n",
      "test_train\n",
      "train mean loss=0.10609057918190956\n",
      "test_test\n",
      "test mean loss=1155.02099609375\n",
      "epoch 1444\n",
      "test_train\n",
      "train mean loss=0.10459172477324803\n",
      "test_test\n",
      "test mean loss=1155.82373046875\n",
      "epoch 1445\n",
      "test_train\n",
      "train mean loss=0.10115194444855054\n",
      "test_test\n",
      "test mean loss=1154.6103515625\n",
      "epoch 1446\n",
      "test_train\n",
      "train mean loss=0.1111541607727607\n",
      "test_test\n",
      "test mean loss=1155.1765747070312\n",
      "epoch 1447\n",
      "test_train\n",
      "train mean loss=0.10006212008496125\n",
      "test_test\n",
      "test mean loss=1155.40234375\n",
      "epoch 1448\n",
      "test_train\n",
      "train mean loss=0.10202000973125298\n",
      "test_test\n",
      "test mean loss=1154.6422119140625\n",
      "epoch 1449\n",
      "test_train\n",
      "train mean loss=0.10207980902244647\n",
      "test_test\n",
      "test mean loss=1155.0769653320312\n",
      "epoch 1450\n",
      "test_train\n",
      "train mean loss=0.1078759003430605\n",
      "test_test\n",
      "test mean loss=1154.2461547851562\n",
      "epoch 1451\n",
      "test_train\n",
      "train mean loss=0.1069206316024065\n",
      "test_test\n",
      "test mean loss=1154.3941040039062\n",
      "epoch 1452\n",
      "test_train\n",
      "train mean loss=0.13637475545207658\n",
      "test_test\n",
      "test mean loss=1155.7211303710938\n",
      "epoch 1453\n",
      "test_train\n",
      "train mean loss=0.10419344902038574\n",
      "test_test\n",
      "test mean loss=1156.0384216308594\n",
      "epoch 1454\n",
      "test_train\n",
      "train mean loss=0.09968444549789031\n",
      "test_test\n",
      "test mean loss=1155.4325561523438\n",
      "epoch 1455\n",
      "test_train\n",
      "train mean loss=0.10121169686317444\n",
      "test_test\n",
      "test mean loss=1155.0189819335938\n",
      "epoch 1456\n",
      "test_train\n",
      "train mean loss=0.09650331549346447\n",
      "test_test\n",
      "test mean loss=1155.6065673828125\n",
      "epoch 1457\n",
      "test_train\n",
      "train mean loss=0.09672315542896588\n",
      "test_test\n",
      "test mean loss=1154.9005737304688\n",
      "epoch 1458\n",
      "test_train\n",
      "train mean loss=0.10207534115761518\n",
      "test_test\n",
      "test mean loss=1154.9653015136719\n",
      "epoch 1459\n",
      "test_train\n",
      "train mean loss=0.1056411424651742\n",
      "test_test\n",
      "test mean loss=1155.281982421875\n",
      "epoch 1460\n",
      "test_train\n",
      "train mean loss=0.13526780158281326\n",
      "test_test\n",
      "test mean loss=1155.8984375\n",
      "epoch 1461\n",
      "test_train\n",
      "train mean loss=0.11141266021877527\n",
      "test_test\n",
      "test mean loss=1155.9447021484375\n",
      "epoch 1462\n",
      "test_train\n",
      "train mean loss=0.10703750451405843\n",
      "test_test\n",
      "test mean loss=1155.496337890625\n",
      "epoch 1463\n",
      "test_train\n",
      "train mean loss=0.10279603737095992\n",
      "test_test\n",
      "test mean loss=1155.9990844726562\n",
      "epoch 1464\n",
      "test_train\n",
      "train mean loss=0.10987407403687637\n",
      "test_test\n",
      "test mean loss=1155.0757446289062\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1465\n",
      "test_train\n",
      "train mean loss=0.10984657953182857\n",
      "test_test\n",
      "test mean loss=1154.8372192382812\n",
      "epoch 1466\n",
      "test_train\n",
      "train mean loss=0.10168269524971645\n",
      "test_test\n",
      "test mean loss=1155.1568603515625\n",
      "epoch 1467\n",
      "test_train\n",
      "train mean loss=0.10168718236188094\n",
      "test_test\n",
      "test mean loss=1154.7836608886719\n",
      "epoch 1468\n",
      "test_train\n",
      "train mean loss=0.10183300140003364\n",
      "test_test\n",
      "test mean loss=1156.1890869140625\n",
      "epoch 1469\n",
      "test_train\n",
      "train mean loss=0.10554480428496997\n",
      "test_test\n",
      "test mean loss=1156.1776123046875\n",
      "epoch 1470\n",
      "test_train\n",
      "train mean loss=0.09868248645216227\n",
      "test_test\n",
      "test mean loss=1154.8606872558594\n",
      "epoch 1471\n",
      "test_train\n",
      "train mean loss=0.09958205496271451\n",
      "test_test\n",
      "test mean loss=1155.5339660644531\n",
      "epoch 1472\n",
      "test_train\n",
      "train mean loss=0.10232809310158093\n",
      "test_test\n",
      "test mean loss=1155.5042724609375\n",
      "epoch 1473\n",
      "test_train\n",
      "train mean loss=0.09902190168698628\n",
      "test_test\n",
      "test mean loss=1154.9949340820312\n",
      "epoch 1474\n",
      "test_train\n",
      "train mean loss=0.10007576923817396\n",
      "test_test\n",
      "test mean loss=1155.69580078125\n",
      "epoch 1475\n",
      "test_train\n",
      "train mean loss=0.10495635246237119\n",
      "test_test\n",
      "test mean loss=1155.5753173828125\n",
      "epoch 1476\n",
      "test_train\n",
      "train mean loss=0.10201362085839112\n",
      "test_test\n",
      "test mean loss=1155.5600891113281\n",
      "epoch 1477\n",
      "test_train\n",
      "train mean loss=0.10462766513228416\n",
      "test_test\n",
      "test mean loss=1155.9425048828125\n",
      "epoch 1478\n",
      "test_train\n",
      "train mean loss=0.10030185865859191\n",
      "test_test\n",
      "test mean loss=1155.1345825195312\n",
      "epoch 1479\n",
      "test_train\n",
      "train mean loss=0.10455680079758167\n",
      "test_test\n",
      "test mean loss=1155.2279052734375\n",
      "epoch 1480\n",
      "test_train\n",
      "train mean loss=0.09898751539488633\n",
      "test_test\n",
      "test mean loss=1155.1689453125\n",
      "epoch 1481\n",
      "test_train\n",
      "train mean loss=0.10805624381949504\n",
      "test_test\n",
      "test mean loss=1155.3906860351562\n",
      "epoch 1482\n",
      "test_train\n",
      "train mean loss=0.10654063026110332\n",
      "test_test\n",
      "test mean loss=1154.8318176269531\n",
      "epoch 1483\n",
      "test_train\n",
      "train mean loss=0.10010743575791518\n",
      "test_test\n",
      "test mean loss=1155.955078125\n",
      "epoch 1484\n",
      "test_train\n",
      "train mean loss=0.1015744103739659\n",
      "test_test\n",
      "test mean loss=1154.6033935546875\n",
      "epoch 1485\n",
      "test_train\n",
      "train mean loss=0.10297359898686409\n",
      "test_test\n",
      "test mean loss=1155.2852783203125\n",
      "epoch 1486\n",
      "test_train\n",
      "train mean loss=0.10685204745580752\n",
      "test_test\n",
      "test mean loss=1154.8661804199219\n",
      "epoch 1487\n",
      "test_train\n",
      "train mean loss=0.10574363637715578\n",
      "test_test\n",
      "test mean loss=1156.2394104003906\n",
      "epoch 1488\n",
      "test_train\n",
      "train mean loss=0.10092034904907148\n",
      "test_test\n",
      "test mean loss=1156.1050415039062\n",
      "epoch 1489\n",
      "test_train\n",
      "train mean loss=0.21021599819262823\n",
      "test_test\n",
      "test mean loss=1157.9482727050781\n",
      "epoch 1490\n",
      "test_train\n",
      "train mean loss=0.09683375743528207\n",
      "test_test\n",
      "test mean loss=1157.1366577148438\n",
      "epoch 1491\n",
      "test_train\n",
      "train mean loss=0.0949985155214866\n",
      "test_test\n",
      "test mean loss=1155.6957397460938\n",
      "epoch 1492\n",
      "test_train\n",
      "train mean loss=0.10254431484887998\n",
      "test_test\n",
      "test mean loss=1155.7137451171875\n",
      "epoch 1493\n",
      "test_train\n",
      "train mean loss=0.09666583500802517\n",
      "test_test\n",
      "test mean loss=1155.2329406738281\n",
      "epoch 1494\n",
      "test_train\n",
      "train mean loss=0.10128389267871778\n",
      "test_test\n",
      "test mean loss=1154.6289672851562\n",
      "epoch 1495\n",
      "test_train\n",
      "train mean loss=0.1393062143276135\n",
      "test_test\n",
      "test mean loss=1153.8781127929688\n",
      "epoch 1496\n",
      "test_train\n",
      "train mean loss=0.09902398536602657\n",
      "test_test\n",
      "test mean loss=1155.0659790039062\n",
      "epoch 1497\n",
      "test_train\n",
      "train mean loss=0.10002042197932799\n",
      "test_test\n",
      "test mean loss=1154.739990234375\n",
      "epoch 1498\n",
      "test_train\n",
      "train mean loss=0.10205969369659822\n",
      "test_test\n",
      "test mean loss=1156.5237426757812\n",
      "epoch 1499\n",
      "test_train\n",
      "train mean loss=0.10662225540727377\n",
      "test_test\n",
      "test mean loss=1154.8915710449219\n",
      "epoch 1500\n",
      "test_train\n",
      "train mean loss=0.10175706321994464\n",
      "test_test\n",
      "test mean loss=1155.2950439453125\n",
      "epoch 1501\n",
      "test_train\n",
      "train mean loss=0.10125933090845744\n",
      "test_test\n",
      "test mean loss=1155.5439453125\n",
      "epoch 1502\n",
      "test_train\n",
      "train mean loss=0.10352045577019453\n",
      "test_test\n",
      "test mean loss=1155.5824584960938\n",
      "epoch 1503\n",
      "test_train\n",
      "train mean loss=0.10926212215175231\n",
      "test_test\n",
      "test mean loss=1154.9112854003906\n",
      "epoch 1504\n",
      "test_train\n",
      "train mean loss=0.1710478514432907\n",
      "test_test\n",
      "test mean loss=1158.2638549804688\n",
      "epoch 1505\n",
      "test_train\n",
      "train mean loss=0.11236672196537256\n",
      "test_test\n",
      "test mean loss=1156.5307922363281\n",
      "epoch 1506\n",
      "test_train\n",
      "train mean loss=0.10547442268580198\n",
      "test_test\n",
      "test mean loss=1155.4012451171875\n",
      "epoch 1507\n",
      "test_train\n",
      "train mean loss=0.10446260434885819\n",
      "test_test\n",
      "test mean loss=1155.9711303710938\n",
      "epoch 1508\n",
      "test_train\n",
      "train mean loss=0.10236427343140046\n",
      "test_test\n",
      "test mean loss=1155.2369995117188\n",
      "epoch 1509\n",
      "test_train\n",
      "train mean loss=0.10071496075640123\n",
      "test_test\n",
      "test mean loss=1155.4790649414062\n",
      "epoch 1510\n",
      "test_train\n",
      "train mean loss=0.10164443651835124\n",
      "test_test\n",
      "test mean loss=1156.181640625\n",
      "epoch 1511\n",
      "test_train\n",
      "train mean loss=0.10319159055749576\n",
      "test_test\n",
      "test mean loss=1154.8665771484375\n",
      "epoch 1512\n",
      "test_train\n",
      "train mean loss=0.10715923023720582\n",
      "test_test\n",
      "test mean loss=1155.0599975585938\n",
      "epoch 1513\n",
      "test_train\n",
      "train mean loss=0.11372038815170527\n",
      "test_test\n",
      "test mean loss=1155.2936401367188\n",
      "epoch 1514\n",
      "test_train\n",
      "train mean loss=0.11498559328416984\n",
      "test_test\n",
      "test mean loss=1155.5733032226562\n",
      "epoch 1515\n",
      "test_train\n",
      "train mean loss=0.10294088845451672\n",
      "test_test\n",
      "test mean loss=1154.8707275390625\n",
      "epoch 1516\n",
      "test_train\n",
      "train mean loss=0.10325238388031721\n",
      "test_test\n",
      "test mean loss=1154.8399047851562\n",
      "epoch 1517\n",
      "test_train\n",
      "train mean loss=0.10537996515631676\n",
      "test_test\n",
      "test mean loss=1155.2342529296875\n",
      "epoch 1518\n",
      "test_train\n",
      "train mean loss=0.10541774053126574\n",
      "test_test\n",
      "test mean loss=1155.2448120117188\n",
      "epoch 1519\n",
      "test_train\n",
      "train mean loss=0.10107028981049855\n",
      "test_test\n",
      "test mean loss=1154.5335083007812\n",
      "epoch 1520\n",
      "test_train\n",
      "train mean loss=0.10379179070393245\n",
      "test_test\n",
      "test mean loss=1155.2203063964844\n",
      "epoch 1521\n",
      "test_train\n",
      "train mean loss=0.10277481625477473\n",
      "test_test\n",
      "test mean loss=1155.1517639160156\n",
      "epoch 1522\n",
      "test_train\n",
      "train mean loss=0.10198789027829964\n",
      "test_test\n",
      "test mean loss=1155.5542907714844\n",
      "epoch 1523\n",
      "test_train\n",
      "train mean loss=0.10407036201407512\n",
      "test_test\n",
      "test mean loss=1154.9474487304688\n",
      "epoch 1524\n",
      "test_train\n",
      "train mean loss=0.09697822233041127\n",
      "test_test\n",
      "test mean loss=1155.2604370117188\n",
      "epoch 1525\n",
      "test_train\n",
      "train mean loss=0.09746878563115995\n",
      "test_test\n",
      "test mean loss=1155.2690124511719\n",
      "epoch 1526\n",
      "test_train\n",
      "train mean loss=0.09937046561390162\n",
      "test_test\n",
      "test mean loss=1155.3430786132812\n",
      "epoch 1527\n",
      "test_train\n",
      "train mean loss=0.10387307995309432\n",
      "test_test\n",
      "test mean loss=1155.4426879882812\n",
      "epoch 1528\n",
      "test_train\n",
      "train mean loss=0.09784783081461985\n",
      "test_test\n",
      "test mean loss=1155.1600341796875\n",
      "epoch 1529\n",
      "test_train\n",
      "train mean loss=0.10432136493424575\n",
      "test_test\n",
      "test mean loss=1156.1324462890625\n",
      "epoch 1530\n",
      "test_train\n",
      "train mean loss=0.11165114430089791\n",
      "test_test\n",
      "test mean loss=1157.058837890625\n",
      "epoch 1531\n",
      "test_train\n",
      "train mean loss=0.11481303659578164\n",
      "test_test\n",
      "test mean loss=1157.8648681640625\n",
      "epoch 1532\n",
      "test_train\n",
      "train mean loss=0.11744452578326066\n",
      "test_test\n",
      "test mean loss=1158.6641845703125\n",
      "epoch 1533\n",
      "test_train\n",
      "train mean loss=0.10239969814817111\n",
      "test_test\n",
      "test mean loss=1156.1853637695312\n",
      "epoch 1534\n",
      "test_train\n",
      "train mean loss=0.10520001997550328\n",
      "test_test\n",
      "test mean loss=1156.2081298828125\n",
      "epoch 1535\n",
      "test_train\n",
      "train mean loss=0.10399517913659413\n",
      "test_test\n",
      "test mean loss=1155.6465454101562\n",
      "epoch 1536\n",
      "test_train\n",
      "train mean loss=0.11168310046195984\n",
      "test_test\n",
      "test mean loss=1155.8123168945312\n",
      "epoch 1537\n",
      "test_train\n",
      "train mean loss=0.10281381445626418\n",
      "test_test\n",
      "test mean loss=1155.30859375\n",
      "epoch 1538\n",
      "test_train\n",
      "train mean loss=0.10049917579938968\n",
      "test_test\n",
      "test mean loss=1155.7391967773438\n",
      "epoch 1539\n",
      "test_train\n",
      "train mean loss=0.10453767764071624\n",
      "test_test\n",
      "test mean loss=1155.4243469238281\n",
      "epoch 1540\n",
      "test_train\n",
      "train mean loss=0.10073214086393516\n",
      "test_test\n",
      "test mean loss=1155.4132080078125\n",
      "epoch 1541\n",
      "test_train\n",
      "train mean loss=0.10756555323799451\n",
      "test_test\n",
      "test mean loss=1154.5416870117188\n",
      "epoch 1542\n",
      "test_train\n",
      "train mean loss=0.1245239358395338\n",
      "test_test\n",
      "test mean loss=1154.4183349609375\n",
      "epoch 1543\n",
      "test_train\n",
      "train mean loss=0.11339159930745761\n",
      "test_test\n",
      "test mean loss=1154.3685913085938\n",
      "epoch 1544\n",
      "test_train\n",
      "train mean loss=0.10478748319049676\n",
      "test_test\n",
      "test mean loss=1153.6496276855469\n",
      "epoch 1545\n",
      "test_train\n",
      "train mean loss=0.10613616742193699\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_test\n",
      "test mean loss=1153.7446899414062\n",
      "epoch 1546\n",
      "test_train\n",
      "train mean loss=0.10709592482695977\n",
      "test_test\n",
      "test mean loss=1154.4676513671875\n",
      "epoch 1547\n",
      "test_train\n",
      "train mean loss=0.10414145452280839\n",
      "test_test\n",
      "test mean loss=1154.4746704101562\n",
      "epoch 1548\n",
      "test_train\n",
      "train mean loss=0.10480133723467588\n",
      "test_test\n",
      "test mean loss=1154.3770751953125\n",
      "epoch 1549\n",
      "test_train\n",
      "train mean loss=0.1002062043795983\n",
      "test_test\n",
      "test mean loss=1154.0534362792969\n",
      "epoch 1550\n",
      "test_train\n",
      "train mean loss=0.10338349764545758\n",
      "test_test\n",
      "test mean loss=1154.2907104492188\n",
      "epoch 1551\n",
      "test_train\n",
      "train mean loss=0.10730070061981678\n",
      "test_test\n",
      "test mean loss=1153.3534545898438\n",
      "epoch 1552\n",
      "test_train\n",
      "train mean loss=0.1334275466700395\n",
      "test_test\n",
      "test mean loss=1156.0924987792969\n",
      "epoch 1553\n",
      "test_train\n",
      "train mean loss=0.10543959711988767\n",
      "test_test\n",
      "test mean loss=1155.5521240234375\n",
      "epoch 1554\n",
      "test_train\n",
      "train mean loss=0.103757510582606\n",
      "test_test\n",
      "test mean loss=1154.9778747558594\n",
      "epoch 1555\n",
      "test_train\n",
      "train mean loss=0.10483359855910142\n",
      "test_test\n",
      "test mean loss=1155.1094970703125\n",
      "epoch 1556\n",
      "test_train\n",
      "train mean loss=0.10562730797876914\n",
      "test_test\n",
      "test mean loss=1155.6332397460938\n",
      "epoch 1557\n",
      "test_train\n",
      "train mean loss=0.10774635585645835\n",
      "test_test\n",
      "test mean loss=1154.9244079589844\n",
      "epoch 1558\n",
      "test_train\n",
      "train mean loss=0.10364962772776683\n",
      "test_test\n",
      "test mean loss=1154.7803955078125\n",
      "epoch 1559\n",
      "test_train\n",
      "train mean loss=0.1024417436371247\n",
      "test_test\n",
      "test mean loss=1154.9703369140625\n",
      "epoch 1560\n",
      "test_train\n",
      "train mean loss=0.10454891451324026\n",
      "test_test\n",
      "test mean loss=1154.5465393066406\n",
      "epoch 1561\n",
      "test_train\n",
      "train mean loss=0.10631361541648705\n",
      "test_test\n",
      "test mean loss=1155.3778076171875\n",
      "epoch 1562\n",
      "test_train\n",
      "train mean loss=0.10093983821570873\n",
      "test_test\n",
      "test mean loss=1154.8965454101562\n",
      "epoch 1563\n",
      "test_train\n",
      "train mean loss=0.11513425471882026\n",
      "test_test\n",
      "test mean loss=1154.6857299804688\n",
      "epoch 1564\n",
      "test_train\n",
      "train mean loss=0.10013412218540907\n",
      "test_test\n",
      "test mean loss=1154.4123840332031\n",
      "epoch 1565\n",
      "test_train\n",
      "train mean loss=0.1019680102666219\n",
      "test_test\n",
      "test mean loss=1154.46630859375\n",
      "epoch 1566\n",
      "test_train\n",
      "train mean loss=0.10635406772295634\n",
      "test_test\n",
      "test mean loss=1154.6734008789062\n",
      "epoch 1567\n",
      "test_train\n",
      "train mean loss=0.10443728448202212\n",
      "test_test\n",
      "test mean loss=1154.844482421875\n",
      "epoch 1568\n",
      "test_train\n",
      "train mean loss=0.1052618535856406\n",
      "test_test\n",
      "test mean loss=1155.3781433105469\n",
      "epoch 1569\n",
      "test_train\n",
      "train mean loss=0.1190560112396876\n",
      "test_test\n",
      "test mean loss=1155.873291015625\n",
      "epoch 1570\n",
      "test_train\n",
      "train mean loss=0.11509623875220616\n",
      "test_test\n",
      "test mean loss=1155.3930053710938\n",
      "epoch 1571\n",
      "test_train\n",
      "train mean loss=0.1032037145147721\n",
      "test_test\n",
      "test mean loss=1155.1966552734375\n",
      "epoch 1572\n",
      "test_train\n",
      "train mean loss=0.12679521863659224\n",
      "test_test\n",
      "test mean loss=1156.3540649414062\n",
      "epoch 1573\n",
      "test_train\n",
      "train mean loss=0.09818326774984598\n",
      "test_test\n",
      "test mean loss=1155.4886474609375\n",
      "epoch 1574\n",
      "test_train\n",
      "train mean loss=0.10514127028485139\n",
      "test_test\n",
      "test mean loss=1154.8802795410156\n",
      "epoch 1575\n",
      "test_train\n",
      "train mean loss=0.1054158927872777\n",
      "test_test\n",
      "test mean loss=1154.8189392089844\n",
      "epoch 1576\n",
      "test_train\n",
      "train mean loss=0.10924986315270264\n",
      "test_test\n",
      "test mean loss=1155.3706359863281\n",
      "epoch 1577\n",
      "test_train\n",
      "train mean loss=0.10893022641539574\n",
      "test_test\n",
      "test mean loss=1154.6178588867188\n",
      "epoch 1578\n",
      "test_train\n",
      "train mean loss=0.10638369402537744\n",
      "test_test\n",
      "test mean loss=1154.6224365234375\n",
      "epoch 1579\n",
      "test_train\n",
      "train mean loss=0.10660460342963536\n",
      "test_test\n",
      "test mean loss=1154.1807861328125\n",
      "epoch 1580\n",
      "test_train\n",
      "train mean loss=0.1016465670739611\n",
      "test_test\n",
      "test mean loss=1154.8199462890625\n",
      "epoch 1581\n",
      "test_train\n",
      "train mean loss=0.10307852365076542\n",
      "test_test\n",
      "test mean loss=1154.8346557617188\n",
      "epoch 1582\n",
      "test_train\n",
      "train mean loss=0.09806688937048118\n",
      "test_test\n",
      "test mean loss=1155.2391357421875\n",
      "epoch 1583\n",
      "test_train\n",
      "train mean loss=0.09753469688196977\n",
      "test_test\n",
      "test mean loss=1155.2399291992188\n",
      "epoch 1584\n",
      "test_train\n",
      "train mean loss=0.1009889083604018\n",
      "test_test\n",
      "test mean loss=1155.0422668457031\n",
      "epoch 1585\n",
      "test_train\n",
      "train mean loss=0.1023576973627011\n",
      "test_test\n",
      "test mean loss=1155.0446472167969\n",
      "epoch 1586\n",
      "test_train\n",
      "train mean loss=0.12226850974063079\n",
      "test_test\n",
      "test mean loss=1154.57958984375\n",
      "epoch 1587\n",
      "test_train\n",
      "train mean loss=0.10359341371804476\n",
      "test_test\n",
      "test mean loss=1154.8983764648438\n",
      "epoch 1588\n",
      "test_train\n",
      "train mean loss=0.10270570715268452\n",
      "test_test\n",
      "test mean loss=1155.2193908691406\n",
      "epoch 1589\n",
      "test_train\n",
      "train mean loss=0.09785304653147857\n",
      "test_test\n",
      "test mean loss=1155.1065673828125\n",
      "epoch 1590\n",
      "test_train\n",
      "train mean loss=0.10331218503415585\n",
      "test_test\n",
      "test mean loss=1156.4263916015625\n",
      "epoch 1591\n",
      "test_train\n",
      "train mean loss=0.09704743294666211\n",
      "test_test\n",
      "test mean loss=1155.5928344726562\n",
      "epoch 1592\n",
      "test_train\n",
      "train mean loss=0.09632617297271888\n",
      "test_test\n",
      "test mean loss=1156.1129760742188\n",
      "epoch 1593\n",
      "test_train\n",
      "train mean loss=0.10399905685335398\n",
      "test_test\n",
      "test mean loss=1155.8863830566406\n",
      "epoch 1594\n",
      "test_train\n",
      "train mean loss=0.09660479705780745\n",
      "test_test\n",
      "test mean loss=1156.4440612792969\n",
      "epoch 1595\n",
      "test_train\n",
      "train mean loss=0.10023132991045713\n",
      "test_test\n",
      "test mean loss=1156.67041015625\n",
      "epoch 1596\n",
      "test_train\n",
      "train mean loss=0.09631290193647146\n",
      "test_test\n",
      "test mean loss=1155.9913940429688\n",
      "epoch 1597\n",
      "test_train\n",
      "train mean loss=0.10014232310156028\n",
      "test_test\n",
      "test mean loss=1156.3238525390625\n",
      "epoch 1598\n",
      "test_train\n",
      "train mean loss=0.10434901528060436\n",
      "test_test\n",
      "test mean loss=1156.72412109375\n",
      "epoch 1599\n",
      "test_train\n",
      "train mean loss=0.09834728452066581\n",
      "test_test\n",
      "test mean loss=1155.4612426757812\n",
      "epoch 1600\n",
      "test_train\n",
      "train mean loss=0.09742586842427652\n",
      "test_test\n",
      "test mean loss=1155.271240234375\n",
      "epoch 1601\n",
      "test_train\n",
      "train mean loss=0.09455627637604873\n",
      "test_test\n",
      "test mean loss=1156.0503540039062\n",
      "epoch 1602\n",
      "test_train\n",
      "train mean loss=0.09739176991085212\n",
      "test_test\n",
      "test mean loss=1156.181640625\n",
      "epoch 1603\n",
      "test_train\n",
      "train mean loss=0.09926334613313277\n",
      "test_test\n",
      "test mean loss=1156.006103515625\n",
      "epoch 1604\n",
      "test_train\n",
      "train mean loss=0.10028904924790065\n",
      "test_test\n",
      "test mean loss=1156.1142578125\n",
      "epoch 1605\n",
      "test_train\n",
      "train mean loss=0.10119427802662055\n",
      "test_test\n",
      "test mean loss=1155.3310546875\n",
      "epoch 1606\n",
      "test_train\n",
      "train mean loss=0.0978451743721962\n",
      "test_test\n",
      "test mean loss=1155.2256774902344\n",
      "epoch 1607\n",
      "test_train\n",
      "train mean loss=0.10051952302455902\n",
      "test_test\n",
      "test mean loss=1155.1920166015625\n",
      "epoch 1608\n",
      "test_train\n",
      "train mean loss=0.0986234787851572\n",
      "test_test\n",
      "test mean loss=1156.4122924804688\n",
      "epoch 1609\n",
      "test_train\n",
      "train mean loss=0.10123399396737416\n",
      "test_test\n",
      "test mean loss=1155.2744140625\n",
      "epoch 1610\n",
      "test_train\n",
      "train mean loss=0.10472366151710351\n",
      "test_test\n",
      "test mean loss=1156.5889282226562\n",
      "epoch 1611\n",
      "test_train\n",
      "train mean loss=0.10151669227828582\n",
      "test_test\n",
      "test mean loss=1154.2291870117188\n",
      "epoch 1612\n",
      "test_train\n",
      "train mean loss=0.10409979180743296\n",
      "test_test\n",
      "test mean loss=1155.479248046875\n",
      "epoch 1613\n",
      "test_train\n",
      "train mean loss=0.1021982707704107\n",
      "test_test\n",
      "test mean loss=1156.0953979492188\n",
      "epoch 1614\n",
      "test_train\n",
      "train mean loss=0.0996993367249767\n",
      "test_test\n",
      "test mean loss=1154.488037109375\n",
      "epoch 1615\n",
      "test_train\n",
      "train mean loss=0.09490372985601425\n",
      "test_test\n",
      "test mean loss=1155.3003540039062\n",
      "epoch 1616\n",
      "test_train\n",
      "train mean loss=0.09597079362720251\n",
      "test_test\n",
      "test mean loss=1155.7828979492188\n",
      "epoch 1617\n",
      "test_train\n",
      "train mean loss=0.095513046408693\n",
      "test_test\n",
      "test mean loss=1156.1141357421875\n",
      "epoch 1618\n",
      "test_train\n",
      "train mean loss=0.10534009461601575\n",
      "test_test\n",
      "test mean loss=1155.4418334960938\n",
      "epoch 1619\n",
      "test_train\n",
      "train mean loss=0.10150029013554256\n",
      "test_test\n",
      "test mean loss=1155.4826049804688\n",
      "epoch 1620\n",
      "test_train\n",
      "train mean loss=0.09780861934026082\n",
      "test_test\n",
      "test mean loss=1155.9625854492188\n",
      "epoch 1621\n",
      "test_train\n",
      "train mean loss=0.10005969802538554\n",
      "test_test\n",
      "test mean loss=1155.3433227539062\n",
      "epoch 1622\n",
      "test_train\n",
      "train mean loss=0.10201199197520812\n",
      "test_test\n",
      "test mean loss=1155.713134765625\n",
      "epoch 1623\n",
      "test_train\n",
      "train mean loss=0.09616060710201661\n",
      "test_test\n",
      "test mean loss=1155.3535766601562\n",
      "epoch 1624\n",
      "test_train\n",
      "train mean loss=0.09959064051508904\n",
      "test_test\n",
      "test mean loss=1156.2222290039062\n",
      "epoch 1625\n",
      "test_train\n",
      "train mean loss=0.09898207088311513\n",
      "test_test\n",
      "test mean loss=1154.9235534667969\n",
      "epoch 1626\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.10107929973552625\n",
      "test_test\n",
      "test mean loss=1155.2691650390625\n",
      "epoch 1627\n",
      "test_train\n",
      "train mean loss=0.09818269809087117\n",
      "test_test\n",
      "test mean loss=1155.3514709472656\n",
      "epoch 1628\n",
      "test_train\n",
      "train mean loss=0.10059794007490079\n",
      "test_test\n",
      "test mean loss=1154.1296997070312\n",
      "epoch 1629\n",
      "test_train\n",
      "train mean loss=0.0952049099529783\n",
      "test_test\n",
      "test mean loss=1154.3565063476562\n",
      "epoch 1630\n",
      "test_train\n",
      "train mean loss=0.10449024724463622\n",
      "test_test\n",
      "test mean loss=1155.5029296875\n",
      "epoch 1631\n",
      "test_train\n",
      "train mean loss=0.10205988554904859\n",
      "test_test\n",
      "test mean loss=1156.3449096679688\n",
      "epoch 1632\n",
      "test_train\n",
      "train mean loss=0.1028773585955302\n",
      "test_test\n",
      "test mean loss=1155.2972717285156\n",
      "epoch 1633\n",
      "test_train\n",
      "train mean loss=0.10408871993422508\n",
      "test_test\n",
      "test mean loss=1153.9421997070312\n",
      "epoch 1634\n",
      "test_train\n",
      "train mean loss=0.10120060543219249\n",
      "test_test\n",
      "test mean loss=1155.6337585449219\n",
      "epoch 1635\n",
      "test_train\n",
      "train mean loss=0.09837357110033433\n",
      "test_test\n",
      "test mean loss=1155.768310546875\n",
      "epoch 1636\n",
      "test_train\n",
      "train mean loss=0.10564199462532997\n",
      "test_test\n",
      "test mean loss=1155.5682983398438\n",
      "epoch 1637\n",
      "test_train\n",
      "train mean loss=0.1007842505350709\n",
      "test_test\n",
      "test mean loss=1154.8638916015625\n",
      "epoch 1638\n",
      "test_train\n",
      "train mean loss=0.0952534768730402\n",
      "test_test\n",
      "test mean loss=1155.732421875\n",
      "epoch 1639\n",
      "test_train\n",
      "train mean loss=0.16600492286185423\n",
      "test_test\n",
      "test mean loss=1154.7496337890625\n",
      "epoch 1640\n",
      "test_train\n",
      "train mean loss=0.10384124827881654\n",
      "test_test\n",
      "test mean loss=1155.2416076660156\n",
      "epoch 1641\n",
      "test_train\n",
      "train mean loss=0.10078718326985836\n",
      "test_test\n",
      "test mean loss=1155.02587890625\n",
      "epoch 1642\n",
      "test_train\n",
      "train mean loss=0.10100389799724023\n",
      "test_test\n",
      "test mean loss=1155.0784606933594\n",
      "epoch 1643\n",
      "test_train\n",
      "train mean loss=0.10014349098006885\n",
      "test_test\n",
      "test mean loss=1155.5011596679688\n",
      "epoch 1644\n",
      "test_train\n",
      "train mean loss=0.09633911028504372\n",
      "test_test\n",
      "test mean loss=1155.9556274414062\n",
      "epoch 1645\n",
      "test_train\n",
      "train mean loss=0.09482111595571041\n",
      "test_test\n",
      "test mean loss=1155.6810302734375\n",
      "epoch 1646\n",
      "test_train\n",
      "train mean loss=0.10134448887159427\n",
      "test_test\n",
      "test mean loss=1155.3646240234375\n",
      "epoch 1647\n",
      "test_train\n",
      "train mean loss=0.1352067676683267\n",
      "test_test\n",
      "test mean loss=1156.8929443359375\n",
      "epoch 1648\n",
      "test_train\n",
      "train mean loss=0.10176265394936006\n",
      "test_test\n",
      "test mean loss=1155.9451904296875\n",
      "epoch 1649\n",
      "test_train\n",
      "train mean loss=0.10332222189754248\n",
      "test_test\n",
      "test mean loss=1155.4658813476562\n",
      "epoch 1650\n",
      "test_train\n",
      "train mean loss=0.10223725438117981\n",
      "test_test\n",
      "test mean loss=1156.4970092773438\n",
      "epoch 1651\n",
      "test_train\n",
      "train mean loss=0.10091750199596088\n",
      "test_test\n",
      "test mean loss=1155.9345397949219\n",
      "epoch 1652\n",
      "test_train\n",
      "train mean loss=0.09870229847729206\n",
      "test_test\n",
      "test mean loss=1155.6993408203125\n",
      "epoch 1653\n",
      "test_train\n",
      "train mean loss=0.09761199386169513\n",
      "test_test\n",
      "test mean loss=1156.4241333007812\n",
      "epoch 1654\n",
      "test_train\n",
      "train mean loss=0.09550663953026135\n",
      "test_test\n",
      "test mean loss=1155.322265625\n",
      "epoch 1655\n",
      "test_train\n",
      "train mean loss=0.09822783060371876\n",
      "test_test\n",
      "test mean loss=1155.3736267089844\n",
      "epoch 1656\n",
      "test_train\n",
      "train mean loss=0.09715975107004245\n",
      "test_test\n",
      "test mean loss=1155.704345703125\n",
      "epoch 1657\n",
      "test_train\n",
      "train mean loss=0.09293715159098308\n",
      "test_test\n",
      "test mean loss=1155.3734130859375\n",
      "epoch 1658\n",
      "test_train\n",
      "train mean loss=0.10569427286585172\n",
      "test_test\n",
      "test mean loss=1155.2571716308594\n",
      "epoch 1659\n",
      "test_train\n",
      "train mean loss=0.1014348551010092\n",
      "test_test\n",
      "test mean loss=1155.4189453125\n",
      "epoch 1660\n",
      "test_train\n",
      "train mean loss=0.09926659210274617\n",
      "test_test\n",
      "test mean loss=1154.6311645507812\n",
      "epoch 1661\n",
      "test_train\n",
      "train mean loss=0.09371512662619352\n",
      "test_test\n",
      "test mean loss=1155.7300720214844\n",
      "epoch 1662\n",
      "test_train\n",
      "train mean loss=0.0959155336022377\n",
      "test_test\n",
      "test mean loss=1155.8059692382812\n",
      "epoch 1663\n",
      "test_train\n",
      "train mean loss=0.09557629935443401\n",
      "test_test\n",
      "test mean loss=1155.7458801269531\n",
      "epoch 1664\n",
      "test_train\n",
      "train mean loss=0.09306059374163549\n",
      "test_test\n",
      "test mean loss=1155.3313293457031\n",
      "epoch 1665\n",
      "test_train\n",
      "train mean loss=0.09288840709875028\n",
      "test_test\n",
      "test mean loss=1155.9689636230469\n",
      "epoch 1666\n",
      "test_train\n",
      "train mean loss=0.0987550113350153\n",
      "test_test\n",
      "test mean loss=1156.1834716796875\n",
      "epoch 1667\n",
      "test_train\n",
      "train mean loss=0.12524825210372606\n",
      "test_test\n",
      "test mean loss=1152.6659240722656\n",
      "epoch 1668\n",
      "test_train\n",
      "train mean loss=0.09337379535039265\n",
      "test_test\n",
      "test mean loss=1154.7332153320312\n",
      "epoch 1669\n",
      "test_train\n",
      "train mean loss=0.09314459469169378\n",
      "test_test\n",
      "test mean loss=1156.1480712890625\n",
      "epoch 1670\n",
      "test_train\n",
      "train mean loss=0.09093093716849883\n",
      "test_test\n",
      "test mean loss=1155.8687438964844\n",
      "epoch 1671\n",
      "test_train\n",
      "train mean loss=0.09870939453442891\n",
      "test_test\n",
      "test mean loss=1156.9542236328125\n",
      "epoch 1672\n",
      "test_train\n",
      "train mean loss=0.09526974024871986\n",
      "test_test\n",
      "test mean loss=1155.810546875\n",
      "epoch 1673\n",
      "test_train\n",
      "train mean loss=0.09738000513364871\n",
      "test_test\n",
      "test mean loss=1157.0118408203125\n",
      "epoch 1674\n",
      "test_train\n",
      "train mean loss=0.09909466467797756\n",
      "test_test\n",
      "test mean loss=1156.103515625\n",
      "epoch 1675\n",
      "test_train\n",
      "train mean loss=0.0980523256585002\n",
      "test_test\n",
      "test mean loss=1156.2540283203125\n",
      "epoch 1676\n",
      "test_train\n",
      "train mean loss=0.2325455037256082\n",
      "test_test\n",
      "test mean loss=1158.9918823242188\n",
      "epoch 1677\n",
      "test_train\n",
      "train mean loss=0.1122418741385142\n",
      "test_test\n",
      "test mean loss=1157.9977722167969\n",
      "epoch 1678\n",
      "test_train\n",
      "train mean loss=0.09581797073284785\n",
      "test_test\n",
      "test mean loss=1156.4531860351562\n",
      "epoch 1679\n",
      "test_train\n",
      "train mean loss=0.09650122343252103\n",
      "test_test\n",
      "test mean loss=1156.0105590820312\n",
      "epoch 1680\n",
      "test_train\n",
      "train mean loss=0.09924935021748145\n",
      "test_test\n",
      "test mean loss=1156.6466064453125\n",
      "epoch 1681\n",
      "test_train\n",
      "train mean loss=0.10294264492889245\n",
      "test_test\n",
      "test mean loss=1156.1334533691406\n",
      "epoch 1682\n",
      "test_train\n",
      "train mean loss=0.10090990116198857\n",
      "test_test\n",
      "test mean loss=1156.532958984375\n",
      "epoch 1683\n",
      "test_train\n",
      "train mean loss=0.10133777217318614\n",
      "test_test\n",
      "test mean loss=1155.9191284179688\n",
      "epoch 1684\n",
      "test_train\n",
      "train mean loss=0.10857005634655555\n",
      "test_test\n",
      "test mean loss=1156.385986328125\n",
      "epoch 1685\n",
      "test_train\n",
      "train mean loss=0.09780344398071368\n",
      "test_test\n",
      "test mean loss=1155.8373718261719\n",
      "epoch 1686\n",
      "test_train\n",
      "train mean loss=0.10071158471206824\n",
      "test_test\n",
      "test mean loss=1155.2815856933594\n",
      "epoch 1687\n",
      "test_train\n",
      "train mean loss=0.1050775491942962\n",
      "test_test\n",
      "test mean loss=1155.0956115722656\n",
      "epoch 1688\n",
      "test_train\n",
      "train mean loss=0.10433671188851197\n",
      "test_test\n",
      "test mean loss=1156.06494140625\n",
      "epoch 1689\n",
      "test_train\n",
      "train mean loss=0.10437258705496788\n",
      "test_test\n",
      "test mean loss=1154.8915405273438\n",
      "epoch 1690\n",
      "test_train\n",
      "train mean loss=0.10713744504998128\n",
      "test_test\n",
      "test mean loss=1157.205322265625\n",
      "epoch 1691\n",
      "test_train\n",
      "train mean loss=0.10227830087145169\n",
      "test_test\n",
      "test mean loss=1157.0021362304688\n",
      "epoch 1692\n",
      "test_train\n",
      "train mean loss=0.097789341583848\n",
      "test_test\n",
      "test mean loss=1155.8327026367188\n",
      "epoch 1693\n",
      "test_train\n",
      "train mean loss=0.09971739475925763\n",
      "test_test\n",
      "test mean loss=1156.2127380371094\n",
      "epoch 1694\n",
      "test_train\n",
      "train mean loss=0.14994015730917454\n",
      "test_test\n",
      "test mean loss=1154.1006774902344\n",
      "epoch 1695\n",
      "test_train\n",
      "train mean loss=0.11300712575515111\n",
      "test_test\n",
      "test mean loss=1155.0476379394531\n",
      "epoch 1696\n",
      "test_train\n",
      "train mean loss=0.09952904998014371\n",
      "test_test\n",
      "test mean loss=1155.3598937988281\n",
      "epoch 1697\n",
      "test_train\n",
      "train mean loss=0.09927451610565186\n",
      "test_test\n",
      "test mean loss=1155.3426818847656\n",
      "epoch 1698\n",
      "test_train\n",
      "train mean loss=0.09901542806377013\n",
      "test_test\n",
      "test mean loss=1155.1818237304688\n",
      "epoch 1699\n",
      "test_train\n",
      "train mean loss=0.10422053343305986\n",
      "test_test\n",
      "test mean loss=1155.01806640625\n",
      "epoch 1700\n",
      "test_train\n",
      "train mean loss=0.09864574329306681\n",
      "test_test\n",
      "test mean loss=1155.8247680664062\n",
      "epoch 1701\n",
      "test_train\n",
      "train mean loss=0.10319611305991809\n",
      "test_test\n",
      "test mean loss=1156.7159423828125\n",
      "epoch 1702\n",
      "test_train\n",
      "train mean loss=0.0995113958294193\n",
      "test_test\n",
      "test mean loss=1155.971435546875\n",
      "epoch 1703\n",
      "test_train\n",
      "train mean loss=0.10014697195341189\n",
      "test_test\n",
      "test mean loss=1156.1101684570312\n",
      "epoch 1704\n",
      "test_train\n",
      "train mean loss=0.10007239412516356\n",
      "test_test\n",
      "test mean loss=1155.4688110351562\n",
      "epoch 1705\n",
      "test_train\n",
      "train mean loss=0.10786595133443673\n",
      "test_test\n",
      "test mean loss=1155.3042602539062\n",
      "epoch 1706\n",
      "test_train\n",
      "train mean loss=0.10351898676405351\n",
      "test_test\n",
      "test mean loss=1155.2267456054688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1707\n",
      "test_train\n",
      "train mean loss=0.09727872504542272\n",
      "test_test\n",
      "test mean loss=1155.1167602539062\n",
      "epoch 1708\n",
      "test_train\n",
      "train mean loss=0.10213870213677485\n",
      "test_test\n",
      "test mean loss=1155.219482421875\n",
      "epoch 1709\n",
      "test_train\n",
      "train mean loss=0.09759701415896416\n",
      "test_test\n",
      "test mean loss=1154.4803466796875\n",
      "epoch 1710\n",
      "test_train\n",
      "train mean loss=0.10658007053037484\n",
      "test_test\n",
      "test mean loss=1154.70703125\n",
      "epoch 1711\n",
      "test_train\n",
      "train mean loss=0.09527588014801343\n",
      "test_test\n",
      "test mean loss=1154.4678344726562\n",
      "epoch 1712\n",
      "test_train\n",
      "train mean loss=0.10023705288767815\n",
      "test_test\n",
      "test mean loss=1155.6914672851562\n",
      "epoch 1713\n",
      "test_train\n",
      "train mean loss=0.09693900154282649\n",
      "test_test\n",
      "test mean loss=1155.7965087890625\n",
      "epoch 1714\n",
      "test_train\n",
      "train mean loss=0.09396916131178538\n",
      "test_test\n",
      "test mean loss=1155.0701293945312\n",
      "epoch 1715\n",
      "test_train\n",
      "train mean loss=0.09535329633702834\n",
      "test_test\n",
      "test mean loss=1156.6464538574219\n",
      "epoch 1716\n",
      "test_train\n",
      "train mean loss=0.09661901245514552\n",
      "test_test\n",
      "test mean loss=1156.7639465332031\n",
      "epoch 1717\n",
      "test_train\n",
      "train mean loss=0.09399224693576495\n",
      "test_test\n",
      "test mean loss=1156.962646484375\n",
      "epoch 1718\n",
      "test_train\n",
      "train mean loss=0.095979162491858\n",
      "test_test\n",
      "test mean loss=1156.3351440429688\n",
      "epoch 1719\n",
      "test_train\n",
      "train mean loss=0.09624287951737642\n",
      "test_test\n",
      "test mean loss=1155.7630615234375\n",
      "epoch 1720\n",
      "test_train\n",
      "train mean loss=0.10020604822784662\n",
      "test_test\n",
      "test mean loss=1154.9077758789062\n",
      "epoch 1721\n",
      "test_train\n",
      "train mean loss=0.11732834205031395\n",
      "test_test\n",
      "test mean loss=1155.645751953125\n",
      "epoch 1722\n",
      "test_train\n",
      "train mean loss=0.10095176597436269\n",
      "test_test\n",
      "test mean loss=1155.7355041503906\n",
      "epoch 1723\n",
      "test_train\n",
      "train mean loss=0.14207377098500729\n",
      "test_test\n",
      "test mean loss=1155.8789672851562\n",
      "epoch 1724\n",
      "test_train\n",
      "train mean loss=0.1054393785695235\n",
      "test_test\n",
      "test mean loss=1155.9503173828125\n",
      "epoch 1725\n",
      "test_train\n",
      "train mean loss=0.1065419443572561\n",
      "test_test\n",
      "test mean loss=1155.3988647460938\n",
      "epoch 1726\n",
      "test_train\n",
      "train mean loss=0.10946537492175896\n",
      "test_test\n",
      "test mean loss=1154.26416015625\n",
      "epoch 1727\n",
      "test_train\n",
      "train mean loss=0.10971229709684849\n",
      "test_test\n",
      "test mean loss=1155.4624633789062\n",
      "epoch 1728\n",
      "test_train\n",
      "train mean loss=0.11633339275916417\n",
      "test_test\n",
      "test mean loss=1154.7373352050781\n",
      "epoch 1729\n",
      "test_train\n",
      "train mean loss=0.10166671313345432\n",
      "test_test\n",
      "test mean loss=1154.485107421875\n",
      "epoch 1730\n",
      "test_train\n",
      "train mean loss=0.10073877312242985\n",
      "test_test\n",
      "test mean loss=1155.6781616210938\n",
      "epoch 1731\n",
      "test_train\n",
      "train mean loss=0.10276676093538602\n",
      "test_test\n",
      "test mean loss=1155.563720703125\n",
      "epoch 1732\n",
      "test_train\n",
      "train mean loss=0.10873038756350677\n",
      "test_test\n",
      "test mean loss=1154.9627685546875\n",
      "epoch 1733\n",
      "test_train\n",
      "train mean loss=0.09938404119263093\n",
      "test_test\n",
      "test mean loss=1154.71875\n",
      "epoch 1734\n",
      "test_train\n",
      "train mean loss=0.10241285711526871\n",
      "test_test\n",
      "test mean loss=1154.412353515625\n",
      "epoch 1735\n",
      "test_train\n",
      "train mean loss=0.27918411667148274\n",
      "test_test\n",
      "test mean loss=1157.3861694335938\n",
      "epoch 1736\n",
      "test_train\n",
      "train mean loss=0.10328421213974555\n",
      "test_test\n",
      "test mean loss=1154.4491577148438\n",
      "epoch 1737\n",
      "test_train\n",
      "train mean loss=0.10480847395956516\n",
      "test_test\n",
      "test mean loss=1154.8845520019531\n",
      "epoch 1738\n",
      "test_train\n",
      "train mean loss=0.10230410502602656\n",
      "test_test\n",
      "test mean loss=1154.8565368652344\n",
      "epoch 1739\n",
      "test_train\n",
      "train mean loss=0.10475355759263039\n",
      "test_test\n",
      "test mean loss=1155.2539672851562\n",
      "epoch 1740\n",
      "test_train\n",
      "train mean loss=0.11373301533361276\n",
      "test_test\n",
      "test mean loss=1155.4219055175781\n",
      "epoch 1741\n",
      "test_train\n",
      "train mean loss=0.10332692849139373\n",
      "test_test\n",
      "test mean loss=1155.2696533203125\n",
      "epoch 1742\n",
      "test_train\n",
      "train mean loss=0.10058523093660672\n",
      "test_test\n",
      "test mean loss=1155.1836547851562\n",
      "epoch 1743\n",
      "test_train\n",
      "train mean loss=0.10110970338185628\n",
      "test_test\n",
      "test mean loss=1155.0516967773438\n",
      "epoch 1744\n",
      "test_train\n",
      "train mean loss=0.10833224592109521\n",
      "test_test\n",
      "test mean loss=1155.7483520507812\n",
      "epoch 1745\n",
      "test_train\n",
      "train mean loss=0.1070031529913346\n",
      "test_test\n",
      "test mean loss=1156.0451049804688\n",
      "epoch 1746\n",
      "test_train\n",
      "train mean loss=0.09525348680714767\n",
      "test_test\n",
      "test mean loss=1155.4388427734375\n",
      "epoch 1747\n",
      "test_train\n",
      "train mean loss=0.10395872748146455\n",
      "test_test\n",
      "test mean loss=1155.156005859375\n",
      "epoch 1748\n",
      "test_train\n",
      "train mean loss=0.09318551234900951\n",
      "test_test\n",
      "test mean loss=1155.2538757324219\n",
      "epoch 1749\n",
      "test_train\n",
      "train mean loss=0.09884756772468488\n",
      "test_test\n",
      "test mean loss=1155.7239074707031\n",
      "epoch 1750\n",
      "test_train\n",
      "train mean loss=0.09993163961917162\n",
      "test_test\n",
      "test mean loss=1156.1658630371094\n",
      "epoch 1751\n",
      "test_train\n",
      "train mean loss=0.10209427991261084\n",
      "test_test\n",
      "test mean loss=1155.3933715820312\n",
      "epoch 1752\n",
      "test_train\n",
      "train mean loss=0.10604467553397019\n",
      "test_test\n",
      "test mean loss=1155.106689453125\n",
      "epoch 1753\n",
      "test_train\n",
      "train mean loss=0.09824364290883143\n",
      "test_test\n",
      "test mean loss=1155.072021484375\n",
      "epoch 1754\n",
      "test_train\n",
      "train mean loss=0.12239841744303703\n",
      "test_test\n",
      "test mean loss=1156.4458618164062\n",
      "epoch 1755\n",
      "test_train\n",
      "train mean loss=0.10225705647220214\n",
      "test_test\n",
      "test mean loss=1156.18212890625\n",
      "epoch 1756\n",
      "test_train\n",
      "train mean loss=0.10762988496571779\n",
      "test_test\n",
      "test mean loss=1155.7839965820312\n",
      "epoch 1757\n",
      "test_train\n",
      "train mean loss=0.09826779862244923\n",
      "test_test\n",
      "test mean loss=1155.8712158203125\n",
      "epoch 1758\n",
      "test_train\n",
      "train mean loss=0.11346307458976905\n",
      "test_test\n",
      "test mean loss=1155.995361328125\n",
      "epoch 1759\n",
      "test_train\n",
      "train mean loss=0.10405554622411728\n",
      "test_test\n",
      "test mean loss=1156.4184265136719\n",
      "epoch 1760\n",
      "test_train\n",
      "train mean loss=0.09855618079503377\n",
      "test_test\n",
      "test mean loss=1154.193603515625\n",
      "epoch 1761\n",
      "test_train\n",
      "train mean loss=0.09454056589553754\n",
      "test_test\n",
      "test mean loss=1155.1370849609375\n",
      "epoch 1762\n",
      "test_train\n",
      "train mean loss=0.09920617565512657\n",
      "test_test\n",
      "test mean loss=1155.6209106445312\n",
      "epoch 1763\n",
      "test_train\n",
      "train mean loss=0.10938907538851102\n",
      "test_test\n",
      "test mean loss=1156.3000183105469\n",
      "epoch 1764\n",
      "test_train\n",
      "train mean loss=0.10180824684600036\n",
      "test_test\n",
      "test mean loss=1154.9621276855469\n",
      "epoch 1765\n",
      "test_train\n",
      "train mean loss=0.10030182140568893\n",
      "test_test\n",
      "test mean loss=1156.1705627441406\n",
      "epoch 1766\n",
      "test_train\n",
      "train mean loss=0.09895001444965601\n",
      "test_test\n",
      "test mean loss=1155.7639770507812\n",
      "epoch 1767\n",
      "test_train\n",
      "train mean loss=0.10891434798638026\n",
      "test_test\n",
      "test mean loss=1155.5802612304688\n",
      "epoch 1768\n",
      "test_train\n",
      "train mean loss=0.10060485048840444\n",
      "test_test\n",
      "test mean loss=1155.0321350097656\n",
      "epoch 1769\n",
      "test_train\n",
      "train mean loss=0.106720890228947\n",
      "test_test\n",
      "test mean loss=1156.2085266113281\n",
      "epoch 1770\n",
      "test_train\n",
      "train mean loss=0.09739833821853001\n",
      "test_test\n",
      "test mean loss=1154.7002868652344\n",
      "epoch 1771\n",
      "test_train\n",
      "train mean loss=0.11832532286643982\n",
      "test_test\n",
      "test mean loss=1156.6629028320312\n",
      "epoch 1772\n",
      "test_train\n",
      "train mean loss=0.09654949357112248\n",
      "test_test\n",
      "test mean loss=1155.4937744140625\n",
      "epoch 1773\n",
      "test_train\n",
      "train mean loss=0.09881604152421157\n",
      "test_test\n",
      "test mean loss=1156.0753479003906\n",
      "epoch 1774\n",
      "test_train\n",
      "train mean loss=0.1006908609221379\n",
      "test_test\n",
      "test mean loss=1155.6206665039062\n",
      "epoch 1775\n",
      "test_train\n",
      "train mean loss=0.10801995173096657\n",
      "test_test\n",
      "test mean loss=1155.8689575195312\n",
      "epoch 1776\n",
      "test_train\n",
      "train mean loss=0.10456089458117883\n",
      "test_test\n",
      "test mean loss=1156.2239379882812\n",
      "epoch 1777\n",
      "test_train\n",
      "train mean loss=0.10978770069777966\n",
      "test_test\n",
      "test mean loss=1156.23291015625\n",
      "epoch 1778\n",
      "test_train\n",
      "train mean loss=0.5965932359298071\n",
      "test_test\n",
      "test mean loss=1150.7570495605469\n",
      "epoch 1779\n",
      "test_train\n",
      "train mean loss=0.1264648133267959\n",
      "test_test\n",
      "test mean loss=1154.4452514648438\n",
      "epoch 1780\n",
      "test_train\n",
      "train mean loss=0.11307806676874559\n",
      "test_test\n",
      "test mean loss=1158.026123046875\n",
      "epoch 1781\n",
      "test_train\n",
      "train mean loss=0.11390674021095037\n",
      "test_test\n",
      "test mean loss=1157.7161560058594\n",
      "epoch 1782\n",
      "test_train\n",
      "train mean loss=0.12071926115701596\n",
      "test_test\n",
      "test mean loss=1157.4811706542969\n",
      "epoch 1783\n",
      "test_train\n",
      "train mean loss=0.11646307011445363\n",
      "test_test\n",
      "test mean loss=1156.5432434082031\n",
      "epoch 1784\n",
      "test_train\n",
      "train mean loss=0.10078220752378304\n",
      "test_test\n",
      "test mean loss=1156.8513793945312\n",
      "epoch 1785\n",
      "test_train\n",
      "train mean loss=0.10158701365192731\n",
      "test_test\n",
      "test mean loss=1156.9261474609375\n",
      "epoch 1786\n",
      "test_train\n",
      "train mean loss=0.11723955006649096\n",
      "test_test\n",
      "test mean loss=1156.82861328125\n",
      "epoch 1787\n",
      "test_train\n",
      "train mean loss=0.1046316431214412\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1156.0172729492188\n",
      "epoch 1788\n",
      "test_train\n",
      "train mean loss=0.10583550110459328\n",
      "test_test\n",
      "test mean loss=1155.4763488769531\n",
      "epoch 1789\n",
      "test_train\n",
      "train mean loss=0.12050429669519265\n",
      "test_test\n",
      "test mean loss=1155.85791015625\n",
      "epoch 1790\n",
      "test_train\n",
      "train mean loss=0.10333388081441323\n",
      "test_test\n",
      "test mean loss=1155.5726928710938\n",
      "epoch 1791\n",
      "test_train\n",
      "train mean loss=0.10350016473482053\n",
      "test_test\n",
      "test mean loss=1156.3087768554688\n",
      "epoch 1792\n",
      "test_train\n",
      "train mean loss=0.10031549353152514\n",
      "test_test\n",
      "test mean loss=1156.3660278320312\n",
      "epoch 1793\n",
      "test_train\n",
      "train mean loss=0.116863747437795\n",
      "test_test\n",
      "test mean loss=1156.7955932617188\n",
      "epoch 1794\n",
      "test_train\n",
      "train mean loss=0.10320109936098258\n",
      "test_test\n",
      "test mean loss=1155.8843994140625\n",
      "epoch 1795\n",
      "test_train\n",
      "train mean loss=0.10698870103806257\n",
      "test_test\n",
      "test mean loss=1155.931640625\n",
      "epoch 1796\n",
      "test_train\n",
      "train mean loss=0.10131354816257954\n",
      "test_test\n",
      "test mean loss=1156.184326171875\n",
      "epoch 1797\n",
      "test_train\n",
      "train mean loss=0.09055515037228663\n",
      "test_test\n",
      "test mean loss=1155.5114135742188\n",
      "epoch 1798\n",
      "test_train\n",
      "train mean loss=0.09215371528019507\n",
      "test_test\n",
      "test mean loss=1155.8155517578125\n",
      "epoch 1799\n",
      "test_train\n",
      "train mean loss=0.09417230822145939\n",
      "test_test\n",
      "test mean loss=1155.9222412109375\n",
      "epoch 1800\n",
      "test_train\n",
      "train mean loss=0.09585015599926312\n",
      "test_test\n",
      "test mean loss=1155.449951171875\n",
      "epoch 1801\n",
      "test_train\n",
      "train mean loss=0.09375969755152862\n",
      "test_test\n",
      "test mean loss=1157.3450317382812\n",
      "epoch 1802\n",
      "test_train\n",
      "train mean loss=0.09895465274651845\n",
      "test_test\n",
      "test mean loss=1156.70849609375\n",
      "epoch 1803\n",
      "test_train\n",
      "train mean loss=0.10062429308891296\n",
      "test_test\n",
      "test mean loss=1156.070068359375\n",
      "epoch 1804\n",
      "test_train\n",
      "train mean loss=0.09756287932395935\n",
      "test_test\n",
      "test mean loss=1155.2005004882812\n",
      "epoch 1805\n",
      "test_train\n",
      "train mean loss=0.1352284320940574\n",
      "test_test\n",
      "test mean loss=1155.9675903320312\n",
      "epoch 1806\n",
      "test_train\n",
      "train mean loss=0.1022516901915272\n",
      "test_test\n",
      "test mean loss=1155.876708984375\n",
      "epoch 1807\n",
      "test_train\n",
      "train mean loss=0.10002811656643947\n",
      "test_test\n",
      "test mean loss=1155.7802124023438\n",
      "epoch 1808\n",
      "test_train\n",
      "train mean loss=0.11209664804240067\n",
      "test_test\n",
      "test mean loss=1157.4168395996094\n",
      "epoch 1809\n",
      "test_train\n",
      "train mean loss=0.12703192792832851\n",
      "test_test\n",
      "test mean loss=1155.7845764160156\n",
      "epoch 1810\n",
      "test_train\n",
      "train mean loss=0.18092290312051773\n",
      "test_test\n",
      "test mean loss=1156.8297729492188\n",
      "epoch 1811\n",
      "test_train\n",
      "train mean loss=0.11520473907391231\n",
      "test_test\n",
      "test mean loss=1158.0750427246094\n",
      "epoch 1812\n",
      "test_train\n",
      "train mean loss=0.10191707033663988\n",
      "test_test\n",
      "test mean loss=1157.0025024414062\n",
      "epoch 1813\n",
      "test_train\n",
      "train mean loss=0.1055920897051692\n",
      "test_test\n",
      "test mean loss=1155.534423828125\n",
      "epoch 1814\n",
      "test_train\n",
      "train mean loss=0.08992994887133439\n",
      "test_test\n",
      "test mean loss=1155.77880859375\n",
      "epoch 1815\n",
      "test_train\n",
      "train mean loss=0.14674243765572706\n",
      "test_test\n",
      "test mean loss=1154.4107055664062\n",
      "epoch 1816\n",
      "test_train\n",
      "train mean loss=0.09923163149505854\n",
      "test_test\n",
      "test mean loss=1155.3150634765625\n",
      "epoch 1817\n",
      "test_train\n",
      "train mean loss=0.11444517287115256\n",
      "test_test\n",
      "test mean loss=1155.7984924316406\n",
      "epoch 1818\n",
      "test_train\n",
      "train mean loss=0.10361102316528559\n",
      "test_test\n",
      "test mean loss=1156.6990966796875\n",
      "epoch 1819\n",
      "test_train\n",
      "train mean loss=0.10369459539651871\n",
      "test_test\n",
      "test mean loss=1155.8792419433594\n",
      "epoch 1820\n",
      "test_train\n",
      "train mean loss=0.09916198688248794\n",
      "test_test\n",
      "test mean loss=1156.4703979492188\n",
      "epoch 1821\n",
      "test_train\n",
      "train mean loss=0.09696903638541698\n",
      "test_test\n",
      "test mean loss=1155.4756469726562\n",
      "epoch 1822\n",
      "test_train\n",
      "train mean loss=0.09923232005288203\n",
      "test_test\n",
      "test mean loss=1155.7070007324219\n",
      "epoch 1823\n",
      "test_train\n",
      "train mean loss=0.10636440229912598\n",
      "test_test\n",
      "test mean loss=1155.8629760742188\n",
      "epoch 1824\n",
      "test_train\n",
      "train mean loss=0.09832635490844648\n",
      "test_test\n",
      "test mean loss=1155.8675231933594\n",
      "epoch 1825\n",
      "test_train\n",
      "train mean loss=0.10439461407562096\n",
      "test_test\n",
      "test mean loss=1155.4993286132812\n",
      "epoch 1826\n",
      "test_train\n",
      "train mean loss=0.09864611054460208\n",
      "test_test\n",
      "test mean loss=1155.32470703125\n",
      "epoch 1827\n",
      "test_train\n",
      "train mean loss=0.09703025035560131\n",
      "test_test\n",
      "test mean loss=1156.2369689941406\n",
      "epoch 1828\n",
      "test_train\n",
      "train mean loss=0.09785067196935415\n",
      "test_test\n",
      "test mean loss=1155.6903076171875\n",
      "epoch 1829\n",
      "test_train\n",
      "train mean loss=0.10563008269915979\n",
      "test_test\n",
      "test mean loss=1155.6257934570312\n",
      "epoch 1830\n",
      "test_train\n",
      "train mean loss=0.11114483326673508\n",
      "test_test\n",
      "test mean loss=1154.8795166015625\n",
      "epoch 1831\n",
      "test_train\n",
      "train mean loss=0.0957653122022748\n",
      "test_test\n",
      "test mean loss=1156.0350341796875\n",
      "epoch 1832\n",
      "test_train\n",
      "train mean loss=0.0899908480544885\n",
      "test_test\n",
      "test mean loss=1155.852294921875\n",
      "epoch 1833\n",
      "test_train\n",
      "train mean loss=0.09843756475796302\n",
      "test_test\n",
      "test mean loss=1156.2568969726562\n",
      "epoch 1834\n",
      "test_train\n",
      "train mean loss=0.1020227096353968\n",
      "test_test\n",
      "test mean loss=1156.3710327148438\n",
      "epoch 1835\n",
      "test_train\n",
      "train mean loss=0.09797780526181062\n",
      "test_test\n",
      "test mean loss=1156.5257568359375\n",
      "epoch 1836\n",
      "test_train\n",
      "train mean loss=0.10415889540066321\n",
      "test_test\n",
      "test mean loss=1157.6717529296875\n",
      "epoch 1837\n",
      "test_train\n",
      "train mean loss=0.09374625018487374\n",
      "test_test\n",
      "test mean loss=1156.0814208984375\n",
      "epoch 1838\n",
      "test_train\n",
      "train mean loss=0.20202006585896015\n",
      "test_test\n",
      "test mean loss=1156.5096435546875\n",
      "epoch 1839\n",
      "test_train\n",
      "train mean loss=0.09808921006818612\n",
      "test_test\n",
      "test mean loss=1154.7389221191406\n",
      "epoch 1840\n",
      "test_train\n",
      "train mean loss=0.09381638560444117\n",
      "test_test\n",
      "test mean loss=1155.1862487792969\n",
      "epoch 1841\n",
      "test_train\n",
      "train mean loss=0.10029488739868005\n",
      "test_test\n",
      "test mean loss=1155.6768188476562\n",
      "epoch 1842\n",
      "test_train\n",
      "train mean loss=0.1107244212180376\n",
      "test_test\n",
      "test mean loss=1156.2772827148438\n",
      "epoch 1843\n",
      "test_train\n",
      "train mean loss=0.09823435731232166\n",
      "test_test\n",
      "test mean loss=1156.0023803710938\n",
      "epoch 1844\n",
      "test_train\n",
      "train mean loss=0.09881991893053055\n",
      "test_test\n",
      "test mean loss=1155.9091186523438\n",
      "epoch 1845\n",
      "test_train\n",
      "train mean loss=0.09658267845710118\n",
      "test_test\n",
      "test mean loss=1155.6749877929688\n",
      "epoch 1846\n",
      "test_train\n",
      "train mean loss=0.09551469143480062\n",
      "test_test\n",
      "test mean loss=1156.6243896484375\n",
      "epoch 1847\n",
      "test_train\n",
      "train mean loss=0.09925797954201698\n",
      "test_test\n",
      "test mean loss=1157.4417724609375\n",
      "epoch 1848\n",
      "test_train\n",
      "train mean loss=0.10861635114997625\n",
      "test_test\n",
      "test mean loss=1156.8670959472656\n",
      "epoch 1849\n",
      "test_train\n",
      "train mean loss=0.09062430759270985\n",
      "test_test\n",
      "test mean loss=1155.5283508300781\n",
      "epoch 1850\n",
      "test_train\n",
      "train mean loss=0.0977368972574671\n",
      "test_test\n",
      "test mean loss=1155.7673950195312\n",
      "epoch 1851\n",
      "test_train\n",
      "train mean loss=0.09553650952875614\n",
      "test_test\n",
      "test mean loss=1156.2469482421875\n",
      "epoch 1852\n",
      "test_train\n",
      "train mean loss=0.0982318806151549\n",
      "test_test\n",
      "test mean loss=1156.2361145019531\n",
      "epoch 1853\n",
      "test_train\n",
      "train mean loss=0.0938943534468611\n",
      "test_test\n",
      "test mean loss=1154.96240234375\n",
      "epoch 1854\n",
      "test_train\n",
      "train mean loss=0.1345235196252664\n",
      "test_test\n",
      "test mean loss=1158.1849365234375\n",
      "epoch 1855\n",
      "test_train\n",
      "train mean loss=0.1039767802382509\n",
      "test_test\n",
      "test mean loss=1156.1092834472656\n",
      "epoch 1856\n",
      "test_train\n",
      "train mean loss=0.09897953737527132\n",
      "test_test\n",
      "test mean loss=1155.7607421875\n",
      "epoch 1857\n",
      "test_train\n",
      "train mean loss=0.10263661357263724\n",
      "test_test\n",
      "test mean loss=1155.3911437988281\n",
      "epoch 1858\n",
      "test_train\n",
      "train mean loss=0.3362675520280997\n",
      "test_test\n",
      "test mean loss=1154.718994140625\n",
      "epoch 1859\n",
      "test_train\n",
      "train mean loss=0.12360484215120475\n",
      "test_test\n",
      "test mean loss=1153.08447265625\n",
      "epoch 1860\n",
      "test_train\n",
      "train mean loss=0.09926729773481686\n",
      "test_test\n",
      "test mean loss=1154.0567932128906\n",
      "epoch 1861\n",
      "test_train\n",
      "train mean loss=0.09567861134807269\n",
      "test_test\n",
      "test mean loss=1154.9042358398438\n",
      "epoch 1862\n",
      "test_train\n",
      "train mean loss=0.09596737784643967\n",
      "test_test\n",
      "test mean loss=1154.740478515625\n",
      "epoch 1863\n",
      "test_train\n",
      "train mean loss=0.09697975963354111\n",
      "test_test\n",
      "test mean loss=1155.4452209472656\n",
      "epoch 1864\n",
      "test_train\n",
      "train mean loss=0.09604787516097228\n",
      "test_test\n",
      "test mean loss=1155.372802734375\n",
      "epoch 1865\n",
      "test_train\n",
      "train mean loss=0.09619188743333022\n",
      "test_test\n",
      "test mean loss=1155.135986328125\n",
      "epoch 1866\n",
      "test_train\n",
      "train mean loss=0.1921101218710343\n",
      "test_test\n",
      "test mean loss=1156.2169799804688\n",
      "epoch 1867\n",
      "test_train\n",
      "train mean loss=0.09946300399800141\n",
      "test_test\n",
      "test mean loss=1156.2848205566406\n",
      "epoch 1868\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.10067122181256612\n",
      "test_test\n",
      "test mean loss=1155.8623657226562\n",
      "epoch 1869\n",
      "test_train\n",
      "train mean loss=0.10282896645367146\n",
      "test_test\n",
      "test mean loss=1156.6232299804688\n",
      "epoch 1870\n",
      "test_train\n",
      "train mean loss=0.1024505253881216\n",
      "test_test\n",
      "test mean loss=1156.8277587890625\n",
      "epoch 1871\n",
      "test_train\n",
      "train mean loss=0.09941218110422294\n",
      "test_test\n",
      "test mean loss=1157.6118469238281\n",
      "epoch 1872\n",
      "test_train\n",
      "train mean loss=0.09769013493011396\n",
      "test_test\n",
      "test mean loss=1155.5436401367188\n",
      "epoch 1873\n",
      "test_train\n",
      "train mean loss=0.10486494439343612\n",
      "test_test\n",
      "test mean loss=1156.071044921875\n",
      "epoch 1874\n",
      "test_train\n",
      "train mean loss=0.09792573191225529\n",
      "test_test\n",
      "test mean loss=1156.7009887695312\n",
      "epoch 1875\n",
      "test_train\n",
      "train mean loss=0.09717662756641705\n",
      "test_test\n",
      "test mean loss=1156.8678588867188\n",
      "epoch 1876\n",
      "test_train\n",
      "train mean loss=0.09701024120052655\n",
      "test_test\n",
      "test mean loss=1156.0374755859375\n",
      "epoch 1877\n",
      "test_train\n",
      "train mean loss=0.10583714364717405\n",
      "test_test\n",
      "test mean loss=1156.3840942382812\n",
      "epoch 1878\n",
      "test_train\n",
      "train mean loss=0.10654016242672999\n",
      "test_test\n",
      "test mean loss=1156.2879638671875\n",
      "epoch 1879\n",
      "test_train\n",
      "train mean loss=0.09976478759199381\n",
      "test_test\n",
      "test mean loss=1155.9357299804688\n",
      "epoch 1880\n",
      "test_train\n",
      "train mean loss=0.09967480879276991\n",
      "test_test\n",
      "test mean loss=1156.2476196289062\n",
      "epoch 1881\n",
      "test_train\n",
      "train mean loss=0.09842951223254204\n",
      "test_test\n",
      "test mean loss=1156.1173095703125\n",
      "epoch 1882\n",
      "test_train\n",
      "train mean loss=0.10054244380444288\n",
      "test_test\n",
      "test mean loss=1156.1861877441406\n",
      "epoch 1883\n",
      "test_train\n",
      "train mean loss=0.09965179146577914\n",
      "test_test\n",
      "test mean loss=1156.2557373046875\n",
      "epoch 1884\n",
      "test_train\n",
      "train mean loss=0.09977760910987854\n",
      "test_test\n",
      "test mean loss=1156.77294921875\n",
      "epoch 1885\n",
      "test_train\n",
      "train mean loss=0.09568711742758751\n",
      "test_test\n",
      "test mean loss=1156.2880249023438\n",
      "epoch 1886\n",
      "test_train\n",
      "train mean loss=0.0969522235294183\n",
      "test_test\n",
      "test mean loss=1155.7896728515625\n",
      "epoch 1887\n",
      "test_train\n",
      "train mean loss=0.0996279859294494\n",
      "test_test\n",
      "test mean loss=1156.1741943359375\n",
      "epoch 1888\n",
      "test_train\n",
      "train mean loss=0.09490047519405682\n",
      "test_test\n",
      "test mean loss=1155.4503784179688\n",
      "epoch 1889\n",
      "test_train\n",
      "train mean loss=0.09556482018282016\n",
      "test_test\n",
      "test mean loss=1155.8052673339844\n",
      "epoch 1890\n",
      "test_train\n",
      "train mean loss=0.09796553788085778\n",
      "test_test\n",
      "test mean loss=1156.0697021484375\n",
      "epoch 1891\n",
      "test_train\n",
      "train mean loss=0.10069326031953096\n",
      "test_test\n",
      "test mean loss=1155.7413940429688\n",
      "epoch 1892\n",
      "test_train\n",
      "train mean loss=0.09848006907850504\n",
      "test_test\n",
      "test mean loss=1156.0515747070312\n",
      "epoch 1893\n",
      "test_train\n",
      "train mean loss=0.09603809285908937\n",
      "test_test\n",
      "test mean loss=1156.6005249023438\n",
      "epoch 1894\n",
      "test_train\n",
      "train mean loss=0.0977344320466121\n",
      "test_test\n",
      "test mean loss=1155.7354736328125\n",
      "epoch 1895\n",
      "test_train\n",
      "train mean loss=0.09712747453401487\n",
      "test_test\n",
      "test mean loss=1155.3120422363281\n",
      "epoch 1896\n",
      "test_train\n",
      "train mean loss=0.09998949617147446\n",
      "test_test\n",
      "test mean loss=1155.3544921875\n",
      "epoch 1897\n",
      "test_train\n",
      "train mean loss=0.09506722850104173\n",
      "test_test\n",
      "test mean loss=1156.4901123046875\n",
      "epoch 1898\n",
      "test_train\n",
      "train mean loss=0.09540444643547137\n",
      "test_test\n",
      "test mean loss=1156.107177734375\n",
      "epoch 1899\n",
      "test_train\n",
      "train mean loss=0.096050380418698\n",
      "test_test\n",
      "test mean loss=1155.5545043945312\n",
      "epoch 1900\n",
      "test_train\n",
      "train mean loss=0.09281996637582779\n",
      "test_test\n",
      "test mean loss=1156.3406677246094\n",
      "epoch 1901\n",
      "test_train\n",
      "train mean loss=0.08942688504854839\n",
      "test_test\n",
      "test mean loss=1156.3489990234375\n",
      "epoch 1902\n",
      "test_train\n",
      "train mean loss=0.09967926951746146\n",
      "test_test\n",
      "test mean loss=1157.2980041503906\n",
      "epoch 1903\n",
      "test_train\n",
      "train mean loss=0.09280848658333223\n",
      "test_test\n",
      "test mean loss=1157.1807556152344\n",
      "epoch 1904\n",
      "test_train\n",
      "train mean loss=0.09498679668953021\n",
      "test_test\n",
      "test mean loss=1156.8045043945312\n",
      "epoch 1905\n",
      "test_train\n",
      "train mean loss=0.0922473135093848\n",
      "test_test\n",
      "test mean loss=1156.4942626953125\n",
      "epoch 1906\n",
      "test_train\n",
      "train mean loss=0.1206052800019582\n",
      "test_test\n",
      "test mean loss=1158.4481811523438\n",
      "epoch 1907\n",
      "test_train\n",
      "train mean loss=0.10398607763151328\n",
      "test_test\n",
      "test mean loss=1156.3676147460938\n",
      "epoch 1908\n",
      "test_train\n",
      "train mean loss=0.11889563376704852\n",
      "test_test\n",
      "test mean loss=1158.7994995117188\n",
      "epoch 1909\n",
      "test_train\n",
      "train mean loss=0.0964219681918621\n",
      "test_test\n",
      "test mean loss=1156.5943298339844\n",
      "epoch 1910\n",
      "test_train\n",
      "train mean loss=0.10039279547830422\n",
      "test_test\n",
      "test mean loss=1156.3218994140625\n",
      "epoch 1911\n",
      "test_train\n",
      "train mean loss=0.09752975994100173\n",
      "test_test\n",
      "test mean loss=1155.9017944335938\n",
      "epoch 1912\n",
      "test_train\n",
      "train mean loss=0.09887943789362907\n",
      "test_test\n",
      "test mean loss=1156.8435363769531\n",
      "epoch 1913\n",
      "test_train\n",
      "train mean loss=0.09747791414459546\n",
      "test_test\n",
      "test mean loss=1155.8157958984375\n",
      "epoch 1914\n",
      "test_train\n",
      "train mean loss=0.1081300809358557\n",
      "test_test\n",
      "test mean loss=1155.8296203613281\n",
      "epoch 1915\n",
      "test_train\n",
      "train mean loss=0.10397631426652272\n",
      "test_test\n",
      "test mean loss=1155.4951477050781\n",
      "epoch 1916\n",
      "test_train\n",
      "train mean loss=0.10009157191962004\n",
      "test_test\n",
      "test mean loss=1156.4135437011719\n",
      "epoch 1917\n",
      "test_train\n",
      "train mean loss=0.11014576690892379\n",
      "test_test\n",
      "test mean loss=1157.5442810058594\n",
      "epoch 1918\n",
      "test_train\n",
      "train mean loss=0.10113884260257085\n",
      "test_test\n",
      "test mean loss=1155.700439453125\n",
      "epoch 1919\n",
      "test_train\n",
      "train mean loss=0.10125361600269873\n",
      "test_test\n",
      "test mean loss=1155.7644653320312\n",
      "epoch 1920\n",
      "test_train\n",
      "train mean loss=0.0946906078606844\n",
      "test_test\n",
      "test mean loss=1155.2093505859375\n",
      "epoch 1921\n",
      "test_train\n",
      "train mean loss=0.09605078243960936\n",
      "test_test\n",
      "test mean loss=1156.081298828125\n",
      "epoch 1922\n",
      "test_train\n",
      "train mean loss=0.09910000177721183\n",
      "test_test\n",
      "test mean loss=1156.1068115234375\n",
      "epoch 1923\n",
      "test_train\n",
      "train mean loss=0.09707389461497466\n",
      "test_test\n",
      "test mean loss=1154.6410522460938\n",
      "epoch 1924\n",
      "test_train\n",
      "train mean loss=0.0930526830876867\n",
      "test_test\n",
      "test mean loss=1154.3965759277344\n",
      "epoch 1925\n",
      "test_train\n",
      "train mean loss=0.39284978558619815\n",
      "test_test\n",
      "test mean loss=1154.5084228515625\n",
      "epoch 1926\n",
      "test_train\n",
      "train mean loss=0.11623932141810656\n",
      "test_test\n",
      "test mean loss=1153.80908203125\n",
      "epoch 1927\n",
      "test_train\n",
      "train mean loss=0.10496778972446918\n",
      "test_test\n",
      "test mean loss=1155.5530090332031\n",
      "epoch 1928\n",
      "test_train\n",
      "train mean loss=0.10629720830669005\n",
      "test_test\n",
      "test mean loss=1155.1649780273438\n",
      "epoch 1929\n",
      "test_train\n",
      "train mean loss=0.1042329662789901\n",
      "test_test\n",
      "test mean loss=1156.0958862304688\n",
      "epoch 1930\n",
      "test_train\n",
      "train mean loss=0.11370633107920487\n",
      "test_test\n",
      "test mean loss=1154.7162475585938\n",
      "epoch 1931\n",
      "test_train\n",
      "train mean loss=0.10138877760618925\n",
      "test_test\n",
      "test mean loss=1156.0336303710938\n",
      "epoch 1932\n",
      "test_train\n",
      "train mean loss=0.10058039488891761\n",
      "test_test\n",
      "test mean loss=1155.87109375\n",
      "epoch 1933\n",
      "test_train\n",
      "train mean loss=0.09810880571603775\n",
      "test_test\n",
      "test mean loss=1154.8295288085938\n",
      "epoch 1934\n",
      "test_train\n",
      "train mean loss=0.10008631274104118\n",
      "test_test\n",
      "test mean loss=1156.0794067382812\n",
      "epoch 1935\n",
      "test_train\n",
      "train mean loss=0.09503654514749844\n",
      "test_test\n",
      "test mean loss=1155.2317504882812\n",
      "epoch 1936\n",
      "test_train\n",
      "train mean loss=0.09786505779872338\n",
      "test_test\n",
      "test mean loss=1155.4102783203125\n",
      "epoch 1937\n",
      "test_train\n",
      "train mean loss=0.09551480847100417\n",
      "test_test\n",
      "test mean loss=1155.2911682128906\n",
      "epoch 1938\n",
      "test_train\n",
      "train mean loss=0.1381157711148262\n",
      "test_test\n",
      "test mean loss=1156.6117858886719\n",
      "epoch 1939\n",
      "test_train\n",
      "train mean loss=0.09915702231228352\n",
      "test_test\n",
      "test mean loss=1154.6466064453125\n",
      "epoch 1940\n",
      "test_train\n",
      "train mean loss=0.09498284105211496\n",
      "test_test\n",
      "test mean loss=1155.5983581542969\n",
      "epoch 1941\n",
      "test_train\n",
      "train mean loss=0.09354250567654769\n",
      "test_test\n",
      "test mean loss=1154.737060546875\n",
      "epoch 1942\n",
      "test_train\n",
      "train mean loss=0.0942041960855325\n",
      "test_test\n",
      "test mean loss=1154.6907348632812\n",
      "epoch 1943\n",
      "test_train\n",
      "train mean loss=0.09569161323209603\n",
      "test_test\n",
      "test mean loss=1155.560302734375\n",
      "epoch 1944\n",
      "test_train\n",
      "train mean loss=0.11534551779429118\n",
      "test_test\n",
      "test mean loss=1154.9032287597656\n",
      "epoch 1945\n",
      "test_train\n",
      "train mean loss=0.1769589732090632\n",
      "test_test\n",
      "test mean loss=1157.5762329101562\n",
      "epoch 1946\n",
      "test_train\n",
      "train mean loss=0.09824112989008427\n",
      "test_test\n",
      "test mean loss=1155.44482421875\n",
      "epoch 1947\n",
      "test_train\n",
      "train mean loss=0.10035201472540696\n",
      "test_test\n",
      "test mean loss=1156.8016967773438\n",
      "epoch 1948\n",
      "test_train\n",
      "train mean loss=0.09443819336593151\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1155.7261962890625\n",
      "epoch 1949\n",
      "test_train\n",
      "train mean loss=0.10049217039098342\n",
      "test_test\n",
      "test mean loss=1154.7113342285156\n",
      "epoch 1950\n",
      "test_train\n",
      "train mean loss=0.104680008875827\n",
      "test_test\n",
      "test mean loss=1154.8561401367188\n",
      "epoch 1951\n",
      "test_train\n",
      "train mean loss=0.10332869210590918\n",
      "test_test\n",
      "test mean loss=1154.6531982421875\n",
      "epoch 1952\n",
      "test_train\n",
      "train mean loss=0.10265629924833775\n",
      "test_test\n",
      "test mean loss=1154.3966064453125\n",
      "epoch 1953\n",
      "test_train\n",
      "train mean loss=0.25191063930590946\n",
      "test_test\n",
      "test mean loss=1158.2882080078125\n",
      "epoch 1954\n",
      "test_train\n",
      "train mean loss=0.35421616087357205\n",
      "test_test\n",
      "test mean loss=1156.4368896484375\n",
      "epoch 1955\n",
      "test_train\n",
      "train mean loss=0.10873153153806925\n",
      "test_test\n",
      "test mean loss=1155.716552734375\n",
      "epoch 1956\n",
      "test_train\n",
      "train mean loss=0.09988893537471692\n",
      "test_test\n",
      "test mean loss=1156.6466674804688\n",
      "epoch 1957\n",
      "test_train\n",
      "train mean loss=0.11586036781469981\n",
      "test_test\n",
      "test mean loss=1156.676513671875\n",
      "epoch 1958\n",
      "test_train\n",
      "train mean loss=0.10176603061457475\n",
      "test_test\n",
      "test mean loss=1155.4620361328125\n",
      "epoch 1959\n",
      "test_train\n",
      "train mean loss=0.11543060187250376\n",
      "test_test\n",
      "test mean loss=1156.5382080078125\n",
      "epoch 1960\n",
      "test_train\n",
      "train mean loss=0.11065035499632359\n",
      "test_test\n",
      "test mean loss=1156.275146484375\n",
      "epoch 1961\n",
      "test_train\n",
      "train mean loss=0.10480868847419818\n",
      "test_test\n",
      "test mean loss=1156.56787109375\n",
      "epoch 1962\n",
      "test_train\n",
      "train mean loss=0.10640350915491581\n",
      "test_test\n",
      "test mean loss=1155.855712890625\n",
      "epoch 1963\n",
      "test_train\n",
      "train mean loss=0.10926659343143304\n",
      "test_test\n",
      "test mean loss=1156.1836547851562\n",
      "epoch 1964\n",
      "test_train\n",
      "train mean loss=0.11928262126942475\n",
      "test_test\n",
      "test mean loss=1158.4161071777344\n",
      "epoch 1965\n",
      "test_train\n",
      "train mean loss=0.09663294907659292\n",
      "test_test\n",
      "test mean loss=1156.4567565917969\n",
      "epoch 1966\n",
      "test_train\n",
      "train mean loss=0.6573439488808314\n",
      "test_test\n",
      "test mean loss=1154.5910339355469\n",
      "epoch 1967\n",
      "test_train\n",
      "train mean loss=0.1396088358014822\n",
      "test_test\n",
      "test mean loss=1155.6123046875\n",
      "epoch 1968\n",
      "test_train\n",
      "train mean loss=0.1001872072617213\n",
      "test_test\n",
      "test mean loss=1156.119384765625\n",
      "epoch 1969\n",
      "test_train\n",
      "train mean loss=0.0983255539710323\n",
      "test_test\n",
      "test mean loss=1156.5816040039062\n",
      "epoch 1970\n",
      "test_train\n",
      "train mean loss=0.09714688329646985\n",
      "test_test\n",
      "test mean loss=1156.6878051757812\n",
      "epoch 1971\n",
      "test_train\n",
      "train mean loss=0.0970646624142925\n",
      "test_test\n",
      "test mean loss=1156.8168334960938\n",
      "epoch 1972\n",
      "test_train\n",
      "train mean loss=0.10335541081925233\n",
      "test_test\n",
      "test mean loss=1156.9716186523438\n",
      "epoch 1973\n",
      "test_train\n",
      "train mean loss=0.09820714717109998\n",
      "test_test\n",
      "test mean loss=1156.9631958007812\n",
      "epoch 1974\n",
      "test_train\n",
      "train mean loss=0.09313549753278494\n",
      "test_test\n",
      "test mean loss=1156.1127319335938\n",
      "epoch 1975\n",
      "test_train\n",
      "train mean loss=0.736562599738439\n",
      "test_test\n",
      "test mean loss=1160.3865356445312\n",
      "epoch 1976\n",
      "test_train\n",
      "train mean loss=0.1382502509901921\n",
      "test_test\n",
      "test mean loss=1161.4091796875\n",
      "epoch 1977\n",
      "test_train\n",
      "train mean loss=0.10623725814123948\n",
      "test_test\n",
      "test mean loss=1158.577392578125\n",
      "epoch 1978\n",
      "test_train\n",
      "train mean loss=0.16762431090076765\n",
      "test_test\n",
      "test mean loss=1157.0993041992188\n",
      "epoch 1979\n",
      "test_train\n",
      "train mean loss=0.11857734993100166\n",
      "test_test\n",
      "test mean loss=1157.691162109375\n",
      "epoch 1980\n",
      "test_train\n",
      "train mean loss=0.10995355962465207\n",
      "test_test\n",
      "test mean loss=1158.4020385742188\n",
      "epoch 1981\n",
      "test_train\n",
      "train mean loss=0.09969264858712752\n",
      "test_test\n",
      "test mean loss=1158.685791015625\n",
      "epoch 1982\n",
      "test_train\n",
      "train mean loss=0.09795861473927896\n",
      "test_test\n",
      "test mean loss=1159.056884765625\n",
      "epoch 1983\n",
      "test_train\n",
      "train mean loss=0.10121517442166805\n",
      "test_test\n",
      "test mean loss=1158.79833984375\n",
      "epoch 1984\n",
      "test_train\n",
      "train mean loss=0.10058350798984368\n",
      "test_test\n",
      "test mean loss=1158.103271484375\n",
      "epoch 1985\n",
      "test_train\n",
      "train mean loss=0.10126631582776706\n",
      "test_test\n",
      "test mean loss=1157.7493591308594\n",
      "epoch 1986\n",
      "test_train\n",
      "train mean loss=0.09983262326568365\n",
      "test_test\n",
      "test mean loss=1158.8385009765625\n",
      "epoch 1987\n",
      "test_train\n",
      "train mean loss=0.1024510891487201\n",
      "test_test\n",
      "test mean loss=1157.406494140625\n",
      "epoch 1988\n",
      "test_train\n",
      "train mean loss=0.09906328842043877\n",
      "test_test\n",
      "test mean loss=1157.854248046875\n",
      "epoch 1989\n",
      "test_train\n",
      "train mean loss=0.09847830422222614\n",
      "test_test\n",
      "test mean loss=1157.22607421875\n",
      "epoch 1990\n",
      "test_train\n",
      "train mean loss=0.09710397043575843\n",
      "test_test\n",
      "test mean loss=1158.5022277832031\n",
      "epoch 1991\n",
      "test_train\n",
      "train mean loss=0.09643485428144534\n",
      "test_test\n",
      "test mean loss=1158.5324096679688\n",
      "epoch 1992\n",
      "test_train\n",
      "train mean loss=0.13900300239523253\n",
      "test_test\n",
      "test mean loss=1160.4808959960938\n",
      "epoch 1993\n",
      "test_train\n",
      "train mean loss=0.09705132835855086\n",
      "test_test\n",
      "test mean loss=1157.8558349609375\n",
      "epoch 1994\n",
      "test_train\n",
      "train mean loss=0.09289145314445098\n",
      "test_test\n",
      "test mean loss=1157.7689514160156\n",
      "epoch 1995\n",
      "test_train\n",
      "train mean loss=0.09228561197717984\n",
      "test_test\n",
      "test mean loss=1158.1849975585938\n",
      "epoch 1996\n",
      "test_train\n",
      "train mean loss=0.09786537506928046\n",
      "test_test\n",
      "test mean loss=1158.1631469726562\n",
      "epoch 1997\n",
      "test_train\n",
      "train mean loss=0.12167660954097907\n",
      "test_test\n",
      "test mean loss=1155.2110595703125\n",
      "epoch 1998\n",
      "test_train\n",
      "train mean loss=0.09782143123447895\n",
      "test_test\n",
      "test mean loss=1156.4942626953125\n",
      "epoch 1999\n",
      "test_train\n",
      "train mean loss=0.09632448386400938\n",
      "test_test\n",
      "test mean loss=1157.7528686523438\n",
      "epoch 2000\n",
      "test_train\n",
      "train mean loss=0.10536959643165271\n",
      "test_test\n",
      "test mean loss=1158.064208984375\n",
      "epoch 2001\n",
      "test_train\n",
      "train mean loss=0.09701740834861994\n",
      "test_test\n",
      "test mean loss=1157.4119567871094\n",
      "epoch 2002\n",
      "test_train\n",
      "train mean loss=0.09674553293734789\n",
      "test_test\n",
      "test mean loss=1157.9457397460938\n",
      "epoch 2003\n",
      "test_train\n",
      "train mean loss=0.10241765218476455\n",
      "test_test\n",
      "test mean loss=1157.3986206054688\n",
      "epoch 2004\n",
      "test_train\n",
      "train mean loss=0.09663728376229604\n",
      "test_test\n",
      "test mean loss=1157.6574096679688\n",
      "epoch 2005\n",
      "test_train\n",
      "train mean loss=0.0988391259064277\n",
      "test_test\n",
      "test mean loss=1157.4058227539062\n",
      "epoch 2006\n",
      "test_train\n",
      "train mean loss=0.0944993185500304\n",
      "test_test\n",
      "test mean loss=1156.6285400390625\n",
      "epoch 2007\n",
      "test_train\n",
      "train mean loss=0.09526594635099173\n",
      "test_test\n",
      "test mean loss=1157.1566162109375\n",
      "epoch 2008\n",
      "test_train\n",
      "train mean loss=0.09478972665965557\n",
      "test_test\n",
      "test mean loss=1157.5732116699219\n",
      "epoch 2009\n",
      "test_train\n",
      "train mean loss=0.09312890438983838\n",
      "test_test\n",
      "test mean loss=1158.2900390625\n",
      "epoch 2010\n",
      "test_train\n",
      "train mean loss=0.09747884112099807\n",
      "test_test\n",
      "test mean loss=1156.4578247070312\n",
      "epoch 2011\n",
      "test_train\n",
      "train mean loss=0.09064342391987641\n",
      "test_test\n",
      "test mean loss=1158.0349731445312\n",
      "epoch 2012\n",
      "test_train\n",
      "train mean loss=0.09507109286884467\n",
      "test_test\n",
      "test mean loss=1157.1924438476562\n",
      "epoch 2013\n",
      "test_train\n",
      "train mean loss=0.08946114654342334\n",
      "test_test\n",
      "test mean loss=1157.36962890625\n",
      "epoch 2014\n",
      "test_train\n",
      "train mean loss=0.08887107701351245\n",
      "test_test\n",
      "test mean loss=1157.621826171875\n",
      "epoch 2015\n",
      "test_train\n",
      "train mean loss=0.09334209064642589\n",
      "test_test\n",
      "test mean loss=1157.4780578613281\n",
      "epoch 2016\n",
      "test_train\n",
      "train mean loss=0.09458165181179841\n",
      "test_test\n",
      "test mean loss=1157.1888427734375\n",
      "epoch 2017\n",
      "test_train\n",
      "train mean loss=0.09816823713481426\n",
      "test_test\n",
      "test mean loss=1157.62841796875\n",
      "epoch 2018\n",
      "test_train\n",
      "train mean loss=0.10088041890412569\n",
      "test_test\n",
      "test mean loss=1158.4788818359375\n",
      "epoch 2019\n",
      "test_train\n",
      "train mean loss=0.10360983572900295\n",
      "test_test\n",
      "test mean loss=1157.5709228515625\n",
      "epoch 2020\n",
      "test_train\n",
      "train mean loss=0.09759512543678284\n",
      "test_test\n",
      "test mean loss=1157.0521850585938\n",
      "epoch 2021\n",
      "test_train\n",
      "train mean loss=0.0900684514393409\n",
      "test_test\n",
      "test mean loss=1156.0192260742188\n",
      "epoch 2022\n",
      "test_train\n",
      "train mean loss=0.09683590816954772\n",
      "test_test\n",
      "test mean loss=1157.0709838867188\n",
      "epoch 2023\n",
      "test_train\n",
      "train mean loss=0.09069567546248436\n",
      "test_test\n",
      "test mean loss=1157.0360107421875\n",
      "epoch 2024\n",
      "test_train\n",
      "train mean loss=0.09147112568219502\n",
      "test_test\n",
      "test mean loss=1157.2862243652344\n",
      "epoch 2025\n",
      "test_train\n",
      "train mean loss=0.0931792122622331\n",
      "test_test\n",
      "test mean loss=1158.0745849609375\n",
      "epoch 2026\n",
      "test_train\n",
      "train mean loss=0.09606375265866518\n",
      "test_test\n",
      "test mean loss=1156.6123046875\n",
      "epoch 2027\n",
      "test_train\n",
      "train mean loss=0.09611653753866752\n",
      "test_test\n",
      "test mean loss=1156.8731994628906\n",
      "epoch 2028\n",
      "test_train\n",
      "train mean loss=0.08933717509110768\n",
      "test_test\n",
      "test mean loss=1156.3144836425781\n",
      "epoch 2029\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.09106246381998062\n",
      "test_test\n",
      "test mean loss=1157.125\n",
      "epoch 2030\n",
      "test_train\n",
      "train mean loss=0.15370875100294748\n",
      "test_test\n",
      "test mean loss=1155.5149536132812\n",
      "epoch 2031\n",
      "test_train\n",
      "train mean loss=0.09494469873607159\n",
      "test_test\n",
      "test mean loss=1154.7865600585938\n",
      "epoch 2032\n",
      "test_train\n",
      "train mean loss=0.09411155711859465\n",
      "test_test\n",
      "test mean loss=1155.899658203125\n",
      "epoch 2033\n",
      "test_train\n",
      "train mean loss=0.10888437554240227\n",
      "test_test\n",
      "test mean loss=1159.0731506347656\n",
      "epoch 2034\n",
      "test_train\n",
      "train mean loss=0.09884342178702354\n",
      "test_test\n",
      "test mean loss=1158.6235961914062\n",
      "epoch 2035\n",
      "test_train\n",
      "train mean loss=0.09598204245169957\n",
      "test_test\n",
      "test mean loss=1158.873779296875\n",
      "epoch 2036\n",
      "test_train\n",
      "train mean loss=0.0924715722600619\n",
      "test_test\n",
      "test mean loss=1158.9130554199219\n",
      "epoch 2037\n",
      "test_train\n",
      "train mean loss=0.093416811277469\n",
      "test_test\n",
      "test mean loss=1157.17431640625\n",
      "epoch 2038\n",
      "test_train\n",
      "train mean loss=0.09626722739388545\n",
      "test_test\n",
      "test mean loss=1157.7633361816406\n",
      "epoch 2039\n",
      "test_train\n",
      "train mean loss=0.09824372610698144\n",
      "test_test\n",
      "test mean loss=1157.5775756835938\n",
      "epoch 2040\n",
      "test_train\n",
      "train mean loss=0.11021086263159911\n",
      "test_test\n",
      "test mean loss=1158.8995971679688\n",
      "epoch 2041\n",
      "test_train\n",
      "train mean loss=0.09089752100408077\n",
      "test_test\n",
      "test mean loss=1157.3259887695312\n",
      "epoch 2042\n",
      "test_train\n",
      "train mean loss=0.09508967772126198\n",
      "test_test\n",
      "test mean loss=1158.7932739257812\n",
      "epoch 2043\n",
      "test_train\n",
      "train mean loss=0.09844928327947855\n",
      "test_test\n",
      "test mean loss=1158.8798217773438\n",
      "epoch 2044\n",
      "test_train\n",
      "train mean loss=0.09176446218043566\n",
      "test_test\n",
      "test mean loss=1157.6220703125\n",
      "epoch 2045\n",
      "test_train\n",
      "train mean loss=0.09925888168315093\n",
      "test_test\n",
      "test mean loss=1157.8861389160156\n",
      "epoch 2046\n",
      "test_train\n",
      "train mean loss=0.09237019034723441\n",
      "test_test\n",
      "test mean loss=1158.1448364257812\n",
      "epoch 2047\n",
      "test_train\n",
      "train mean loss=0.09615664184093475\n",
      "test_test\n",
      "test mean loss=1158.4230346679688\n",
      "epoch 2048\n",
      "test_train\n",
      "train mean loss=0.09701951034367085\n",
      "test_test\n",
      "test mean loss=1157.2650146484375\n",
      "epoch 2049\n",
      "test_train\n",
      "train mean loss=0.09906922498097022\n",
      "test_test\n",
      "test mean loss=1157.6239624023438\n",
      "epoch 2050\n",
      "test_train\n",
      "train mean loss=0.09627390808115403\n",
      "test_test\n",
      "test mean loss=1156.9395141601562\n",
      "epoch 2051\n",
      "test_train\n",
      "train mean loss=0.09774187703927358\n",
      "test_test\n",
      "test mean loss=1157.3827819824219\n",
      "epoch 2052\n",
      "test_train\n",
      "train mean loss=0.10134501351664464\n",
      "test_test\n",
      "test mean loss=1156.9009399414062\n",
      "epoch 2053\n",
      "test_train\n",
      "train mean loss=0.09759808176507552\n",
      "test_test\n",
      "test mean loss=1156.9666748046875\n",
      "epoch 2054\n",
      "test_train\n",
      "train mean loss=0.09679646665851276\n",
      "test_test\n",
      "test mean loss=1157.4456176757812\n",
      "epoch 2055\n",
      "test_train\n",
      "train mean loss=0.09671915074189504\n",
      "test_test\n",
      "test mean loss=1157.1938171386719\n",
      "epoch 2056\n",
      "test_train\n",
      "train mean loss=0.09663417376577854\n",
      "test_test\n",
      "test mean loss=1158.8456115722656\n",
      "epoch 2057\n",
      "test_train\n",
      "train mean loss=0.08992033669104178\n",
      "test_test\n",
      "test mean loss=1157.3223876953125\n",
      "epoch 2058\n",
      "test_train\n",
      "train mean loss=0.09566974795113008\n",
      "test_test\n",
      "test mean loss=1156.4918823242188\n",
      "epoch 2059\n",
      "test_train\n",
      "train mean loss=0.08987805588791768\n",
      "test_test\n",
      "test mean loss=1156.5194702148438\n",
      "epoch 2060\n",
      "test_train\n",
      "train mean loss=0.09558626015981038\n",
      "test_test\n",
      "test mean loss=1156.5098876953125\n",
      "epoch 2061\n",
      "test_train\n",
      "train mean loss=0.08958038873970509\n",
      "test_test\n",
      "test mean loss=1156.1956176757812\n",
      "epoch 2062\n",
      "test_train\n",
      "train mean loss=0.09233910124748945\n",
      "test_test\n",
      "test mean loss=1157.244140625\n",
      "epoch 2063\n",
      "test_train\n",
      "train mean loss=0.09591778988639514\n",
      "test_test\n",
      "test mean loss=1156.4602355957031\n",
      "epoch 2064\n",
      "test_train\n",
      "train mean loss=0.0926510722686847\n",
      "test_test\n",
      "test mean loss=1156.765869140625\n",
      "epoch 2065\n",
      "test_train\n",
      "train mean loss=0.09860602517922719\n",
      "test_test\n",
      "test mean loss=1156.8415832519531\n",
      "epoch 2066\n",
      "test_train\n",
      "train mean loss=0.10064863724013169\n",
      "test_test\n",
      "test mean loss=1156.3869018554688\n",
      "epoch 2067\n",
      "test_train\n",
      "train mean loss=0.09926637882987659\n",
      "test_test\n",
      "test mean loss=1156.52197265625\n",
      "epoch 2068\n",
      "test_train\n",
      "train mean loss=0.09644175631304581\n",
      "test_test\n",
      "test mean loss=1157.0092468261719\n",
      "epoch 2069\n",
      "test_train\n",
      "train mean loss=0.09141831782956918\n",
      "test_test\n",
      "test mean loss=1156.009521484375\n",
      "epoch 2070\n",
      "test_train\n",
      "train mean loss=0.09251705619196098\n",
      "test_test\n",
      "test mean loss=1156.8799438476562\n",
      "epoch 2071\n",
      "test_train\n",
      "train mean loss=0.09446513839066029\n",
      "test_test\n",
      "test mean loss=1157.0882568359375\n",
      "epoch 2072\n",
      "test_train\n",
      "train mean loss=0.09040953622510035\n",
      "test_test\n",
      "test mean loss=1156.34423828125\n",
      "epoch 2073\n",
      "test_train\n",
      "train mean loss=0.09421001002192497\n",
      "test_test\n",
      "test mean loss=1156.5780029296875\n",
      "epoch 2074\n",
      "test_train\n",
      "train mean loss=0.09892366857578357\n",
      "test_test\n",
      "test mean loss=1156.5625610351562\n",
      "epoch 2075\n",
      "test_train\n",
      "train mean loss=0.0956902951002121\n",
      "test_test\n",
      "test mean loss=1156.7664794921875\n",
      "epoch 2076\n",
      "test_train\n",
      "train mean loss=0.10609161015599966\n",
      "test_test\n",
      "test mean loss=1156.7976379394531\n",
      "epoch 2077\n",
      "test_train\n",
      "train mean loss=0.0971163660287857\n",
      "test_test\n",
      "test mean loss=1155.7147827148438\n",
      "epoch 2078\n",
      "test_train\n",
      "train mean loss=0.09603146618853013\n",
      "test_test\n",
      "test mean loss=1156.7324829101562\n",
      "epoch 2079\n",
      "test_train\n",
      "train mean loss=0.09946397102127473\n",
      "test_test\n",
      "test mean loss=1156.9646301269531\n",
      "epoch 2080\n",
      "test_train\n",
      "train mean loss=0.09305947367101908\n",
      "test_test\n",
      "test mean loss=1155.5957946777344\n",
      "epoch 2081\n",
      "test_train\n",
      "train mean loss=0.09350235698123772\n",
      "test_test\n",
      "test mean loss=1157.0287170410156\n",
      "epoch 2082\n",
      "test_train\n",
      "train mean loss=0.09613724425435066\n",
      "test_test\n",
      "test mean loss=1155.7007446289062\n",
      "epoch 2083\n",
      "test_train\n",
      "train mean loss=0.10032521684964497\n",
      "test_test\n",
      "test mean loss=1157.0604858398438\n",
      "epoch 2084\n",
      "test_train\n",
      "train mean loss=0.10621449227134387\n",
      "test_test\n",
      "test mean loss=1156.9712219238281\n",
      "epoch 2085\n",
      "test_train\n",
      "train mean loss=0.1023799879476428\n",
      "test_test\n",
      "test mean loss=1157.0995178222656\n",
      "epoch 2086\n",
      "test_train\n",
      "train mean loss=0.09304130884508292\n",
      "test_test\n",
      "test mean loss=1158.299560546875\n",
      "epoch 2087\n",
      "test_train\n",
      "train mean loss=0.0919065394749244\n",
      "test_test\n",
      "test mean loss=1157.5403747558594\n",
      "epoch 2088\n",
      "test_train\n",
      "train mean loss=0.10060229897499084\n",
      "test_test\n",
      "test mean loss=1158.2778930664062\n",
      "epoch 2089\n",
      "test_train\n",
      "train mean loss=0.09322351217269897\n",
      "test_test\n",
      "test mean loss=1157.5748291015625\n",
      "epoch 2090\n",
      "test_train\n",
      "train mean loss=0.09389654484887917\n",
      "test_test\n",
      "test mean loss=1156.24462890625\n",
      "epoch 2091\n",
      "test_train\n",
      "train mean loss=0.09444935464610656\n",
      "test_test\n",
      "test mean loss=1156.9938354492188\n",
      "epoch 2092\n",
      "test_train\n",
      "train mean loss=0.09615464477489392\n",
      "test_test\n",
      "test mean loss=1156.2633666992188\n",
      "epoch 2093\n",
      "test_train\n",
      "train mean loss=0.09870193277796109\n",
      "test_test\n",
      "test mean loss=1155.9514770507812\n",
      "epoch 2094\n",
      "test_train\n",
      "train mean loss=0.0914821932092309\n",
      "test_test\n",
      "test mean loss=1155.4597473144531\n",
      "epoch 2095\n",
      "test_train\n",
      "train mean loss=0.09761172719299793\n",
      "test_test\n",
      "test mean loss=1155.573486328125\n",
      "epoch 2096\n",
      "test_train\n",
      "train mean loss=0.10414337770392497\n",
      "test_test\n",
      "test mean loss=1155.6179504394531\n",
      "epoch 2097\n",
      "test_train\n",
      "train mean loss=0.08982531322787206\n",
      "test_test\n",
      "test mean loss=1156.464599609375\n",
      "epoch 2098\n",
      "test_train\n",
      "train mean loss=0.09644476355363925\n",
      "test_test\n",
      "test mean loss=1156.2001342773438\n",
      "epoch 2099\n",
      "test_train\n",
      "train mean loss=0.09203803197791179\n",
      "test_test\n",
      "test mean loss=1155.921875\n",
      "epoch 2100\n",
      "test_train\n",
      "train mean loss=0.09397181682288647\n",
      "test_test\n",
      "test mean loss=1156.6930541992188\n",
      "epoch 2101\n",
      "test_train\n",
      "train mean loss=0.0903443976615866\n",
      "test_test\n",
      "test mean loss=1157.6806640625\n",
      "epoch 2102\n",
      "test_train\n",
      "train mean loss=0.10118208732455969\n",
      "test_test\n",
      "test mean loss=1156.5762939453125\n",
      "epoch 2103\n",
      "test_train\n",
      "train mean loss=0.09673512602845828\n",
      "test_test\n",
      "test mean loss=1156.9163513183594\n",
      "epoch 2104\n",
      "test_train\n",
      "train mean loss=0.3773819257815679\n",
      "test_test\n",
      "test mean loss=1157.9508056640625\n",
      "epoch 2105\n",
      "test_train\n",
      "train mean loss=0.14950301684439182\n",
      "test_test\n",
      "test mean loss=1154.5397338867188\n",
      "epoch 2106\n",
      "test_train\n",
      "train mean loss=0.0906001425658663\n",
      "test_test\n",
      "test mean loss=1157.1757202148438\n",
      "epoch 2107\n",
      "test_train\n",
      "train mean loss=0.09276312434424956\n",
      "test_test\n",
      "test mean loss=1156.5357971191406\n",
      "epoch 2108\n",
      "test_train\n",
      "train mean loss=0.08892543024073045\n",
      "test_test\n",
      "test mean loss=1157.5746459960938\n",
      "epoch 2109\n",
      "test_train\n",
      "train mean loss=0.08985127477596204\n",
      "test_test\n",
      "test mean loss=1157.35107421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2110\n",
      "test_train\n",
      "train mean loss=0.08587057143449783\n",
      "test_test\n",
      "test mean loss=1156.7655944824219\n",
      "epoch 2111\n",
      "test_train\n",
      "train mean loss=0.1396597201625506\n",
      "test_test\n",
      "test mean loss=1161.0904846191406\n",
      "epoch 2112\n",
      "test_train\n",
      "train mean loss=0.10380928497761488\n",
      "test_test\n",
      "test mean loss=1158.9974975585938\n",
      "epoch 2113\n",
      "test_train\n",
      "train mean loss=0.09742897904167573\n",
      "test_test\n",
      "test mean loss=1157.9743041992188\n",
      "epoch 2114\n",
      "test_train\n",
      "train mean loss=0.09024800763775905\n",
      "test_test\n",
      "test mean loss=1157.214111328125\n",
      "epoch 2115\n",
      "test_train\n",
      "train mean loss=0.08763828625281651\n",
      "test_test\n",
      "test mean loss=1156.7017822265625\n",
      "epoch 2116\n",
      "test_train\n",
      "train mean loss=0.10401666661103566\n",
      "test_test\n",
      "test mean loss=1157.8970947265625\n",
      "epoch 2117\n",
      "test_train\n",
      "train mean loss=0.09199189891417821\n",
      "test_test\n",
      "test mean loss=1157.9141845703125\n",
      "epoch 2118\n",
      "test_train\n",
      "train mean loss=0.0884455842897296\n",
      "test_test\n",
      "test mean loss=1156.9385070800781\n",
      "epoch 2119\n",
      "test_train\n",
      "train mean loss=0.09368838121493657\n",
      "test_test\n",
      "test mean loss=1157.4976196289062\n",
      "epoch 2120\n",
      "test_train\n",
      "train mean loss=0.092453067501386\n",
      "test_test\n",
      "test mean loss=1157.8036804199219\n",
      "epoch 2121\n",
      "test_train\n",
      "train mean loss=0.09169355904062589\n",
      "test_test\n",
      "test mean loss=1157.9722290039062\n",
      "epoch 2122\n",
      "test_train\n",
      "train mean loss=0.09871384873986244\n",
      "test_test\n",
      "test mean loss=1157.30810546875\n",
      "epoch 2123\n",
      "test_train\n",
      "train mean loss=0.09138058684766293\n",
      "test_test\n",
      "test mean loss=1158.5539855957031\n",
      "epoch 2124\n",
      "test_train\n",
      "train mean loss=0.0910760909318924\n",
      "test_test\n",
      "test mean loss=1157.7492065429688\n",
      "epoch 2125\n",
      "test_train\n",
      "train mean loss=0.09526903927326202\n",
      "test_test\n",
      "test mean loss=1158.4856872558594\n",
      "epoch 2126\n",
      "test_train\n",
      "train mean loss=0.09271849505603313\n",
      "test_test\n",
      "test mean loss=1158.3104248046875\n",
      "epoch 2127\n",
      "test_train\n",
      "train mean loss=0.09733129913608234\n",
      "test_test\n",
      "test mean loss=1158.4437255859375\n",
      "epoch 2128\n",
      "test_train\n",
      "train mean loss=0.16843527555465698\n",
      "test_test\n",
      "test mean loss=1154.3437194824219\n",
      "epoch 2129\n",
      "test_train\n",
      "train mean loss=0.09278599979976813\n",
      "test_test\n",
      "test mean loss=1156.3286743164062\n",
      "epoch 2130\n",
      "test_train\n",
      "train mean loss=0.08741245418787003\n",
      "test_test\n",
      "test mean loss=1156.753662109375\n",
      "epoch 2131\n",
      "test_train\n",
      "train mean loss=0.09032097551971674\n",
      "test_test\n",
      "test mean loss=1158.0221557617188\n",
      "epoch 2132\n",
      "test_train\n",
      "train mean loss=0.09423872207601865\n",
      "test_test\n",
      "test mean loss=1157.7758178710938\n",
      "epoch 2133\n",
      "test_train\n",
      "train mean loss=0.8330087959766388\n",
      "test_test\n",
      "test mean loss=1154.4239501953125\n",
      "epoch 2134\n",
      "test_train\n",
      "train mean loss=0.1121681984513998\n",
      "test_test\n",
      "test mean loss=1159.4459228515625\n",
      "epoch 2135\n",
      "test_train\n",
      "train mean loss=0.10306824184954166\n",
      "test_test\n",
      "test mean loss=1159.0716552734375\n",
      "epoch 2136\n",
      "test_train\n",
      "train mean loss=0.10553362717231114\n",
      "test_test\n",
      "test mean loss=1159.2808837890625\n",
      "epoch 2137\n",
      "test_train\n",
      "train mean loss=0.10087073439111312\n",
      "test_test\n",
      "test mean loss=1159.258056640625\n",
      "epoch 2138\n",
      "test_train\n",
      "train mean loss=0.22675964112083116\n",
      "test_test\n",
      "test mean loss=1159.4862060546875\n",
      "epoch 2139\n",
      "test_train\n",
      "train mean loss=0.10330402106046677\n",
      "test_test\n",
      "test mean loss=1159.4513549804688\n",
      "epoch 2140\n",
      "test_train\n",
      "train mean loss=0.10566529755791028\n",
      "test_test\n",
      "test mean loss=1159.9979858398438\n",
      "epoch 2141\n",
      "test_train\n",
      "train mean loss=0.0982644467925032\n",
      "test_test\n",
      "test mean loss=1157.517333984375\n",
      "epoch 2142\n",
      "test_train\n",
      "train mean loss=0.32150723909338313\n",
      "test_test\n",
      "test mean loss=1156.1936645507812\n",
      "epoch 2143\n",
      "test_train\n",
      "train mean loss=0.11011880760391553\n",
      "test_test\n",
      "test mean loss=1156.71240234375\n",
      "epoch 2144\n",
      "test_train\n",
      "train mean loss=0.09860352426767349\n",
      "test_test\n",
      "test mean loss=1157.0989990234375\n",
      "epoch 2145\n",
      "test_train\n",
      "train mean loss=0.11036707057307164\n",
      "test_test\n",
      "test mean loss=1157.4304809570312\n",
      "epoch 2146\n",
      "test_train\n",
      "train mean loss=0.09380106379588445\n",
      "test_test\n",
      "test mean loss=1157.2657470703125\n",
      "epoch 2147\n",
      "test_train\n",
      "train mean loss=0.09323048094908397\n",
      "test_test\n",
      "test mean loss=1156.969970703125\n",
      "epoch 2148\n",
      "test_train\n",
      "train mean loss=0.10302656795829535\n",
      "test_test\n",
      "test mean loss=1157.3719482421875\n",
      "epoch 2149\n",
      "test_train\n",
      "train mean loss=0.09697122313082218\n",
      "test_test\n",
      "test mean loss=1156.8434448242188\n",
      "epoch 2150\n",
      "test_train\n",
      "train mean loss=0.14380699147780737\n",
      "test_test\n",
      "test mean loss=1157.4536743164062\n",
      "epoch 2151\n",
      "test_train\n",
      "train mean loss=0.10180875721077125\n",
      "test_test\n",
      "test mean loss=1157.0769653320312\n",
      "epoch 2152\n",
      "test_train\n",
      "train mean loss=0.09846191635976236\n",
      "test_test\n",
      "test mean loss=1157.9541625976562\n",
      "epoch 2153\n",
      "test_train\n",
      "train mean loss=0.10087597680588563\n",
      "test_test\n",
      "test mean loss=1157.9984130859375\n",
      "epoch 2154\n",
      "test_train\n",
      "train mean loss=0.100063922504584\n",
      "test_test\n",
      "test mean loss=1158.175048828125\n",
      "epoch 2155\n",
      "test_train\n",
      "train mean loss=0.10556685489912827\n",
      "test_test\n",
      "test mean loss=1157.6961975097656\n",
      "epoch 2156\n",
      "test_train\n",
      "train mean loss=0.09696241902808349\n",
      "test_test\n",
      "test mean loss=1156.9315185546875\n",
      "epoch 2157\n",
      "test_train\n",
      "train mean loss=0.09473368401328723\n",
      "test_test\n",
      "test mean loss=1157.6541442871094\n",
      "epoch 2158\n",
      "test_train\n",
      "train mean loss=0.0902769739429156\n",
      "test_test\n",
      "test mean loss=1157.25146484375\n",
      "epoch 2159\n",
      "test_train\n",
      "train mean loss=0.08904710039496422\n",
      "test_test\n",
      "test mean loss=1155.8988037109375\n",
      "epoch 2160\n",
      "test_train\n",
      "train mean loss=0.09361428488045931\n",
      "test_test\n",
      "test mean loss=1158.0750122070312\n",
      "epoch 2161\n",
      "test_train\n",
      "train mean loss=0.09129665760944287\n",
      "test_test\n",
      "test mean loss=1157.1024780273438\n",
      "epoch 2162\n",
      "test_train\n",
      "train mean loss=0.09282943078627189\n",
      "test_test\n",
      "test mean loss=1156.9441223144531\n",
      "epoch 2163\n",
      "test_train\n",
      "train mean loss=0.10678549855947495\n",
      "test_test\n",
      "test mean loss=1157.3961486816406\n",
      "epoch 2164\n",
      "test_train\n",
      "train mean loss=0.0976305017247796\n",
      "test_test\n",
      "test mean loss=1156.8588256835938\n",
      "epoch 2165\n",
      "test_train\n",
      "train mean loss=0.09803020395338535\n",
      "test_test\n",
      "test mean loss=1158.4621276855469\n",
      "epoch 2166\n",
      "test_train\n",
      "train mean loss=0.09091242278615634\n",
      "test_test\n",
      "test mean loss=1157.3108825683594\n",
      "epoch 2167\n",
      "test_train\n",
      "train mean loss=0.0955946600685517\n",
      "test_test\n",
      "test mean loss=1156.9501953125\n",
      "epoch 2168\n",
      "test_train\n",
      "train mean loss=0.09598363315065701\n",
      "test_test\n",
      "test mean loss=1157.9447021484375\n",
      "epoch 2169\n",
      "test_train\n",
      "train mean loss=0.09248917146275441\n",
      "test_test\n",
      "test mean loss=1157.5347290039062\n",
      "epoch 2170\n",
      "test_train\n",
      "train mean loss=0.08654726607104142\n",
      "test_test\n",
      "test mean loss=1156.8758544921875\n",
      "epoch 2171\n",
      "test_train\n",
      "train mean loss=0.09425730785975854\n",
      "test_test\n",
      "test mean loss=1158.1588745117188\n",
      "epoch 2172\n",
      "test_train\n",
      "train mean loss=0.10037874492506187\n",
      "test_test\n",
      "test mean loss=1156.7096557617188\n",
      "epoch 2173\n",
      "test_train\n",
      "train mean loss=0.10314168905218442\n",
      "test_test\n",
      "test mean loss=1155.6419982910156\n",
      "epoch 2174\n",
      "test_train\n",
      "train mean loss=0.09063396013031404\n",
      "test_test\n",
      "test mean loss=1156.1787719726562\n",
      "epoch 2175\n",
      "test_train\n",
      "train mean loss=0.09379716248561938\n",
      "test_test\n",
      "test mean loss=1155.3592529296875\n",
      "epoch 2176\n",
      "test_train\n",
      "train mean loss=0.0934565756469965\n",
      "test_test\n",
      "test mean loss=1155.6353149414062\n",
      "epoch 2177\n",
      "test_train\n",
      "train mean loss=0.09115635448445876\n",
      "test_test\n",
      "test mean loss=1156.2434692382812\n",
      "epoch 2178\n",
      "test_train\n",
      "train mean loss=0.09224955923855305\n",
      "test_test\n",
      "test mean loss=1156.845703125\n",
      "epoch 2179\n",
      "test_train\n",
      "train mean loss=0.0879932747532924\n",
      "test_test\n",
      "test mean loss=1155.521484375\n",
      "epoch 2180\n",
      "test_train\n",
      "train mean loss=0.09009825407216947\n",
      "test_test\n",
      "test mean loss=1156.1934814453125\n",
      "epoch 2181\n",
      "test_train\n",
      "train mean loss=0.09707346310218175\n",
      "test_test\n",
      "test mean loss=1156.0418090820312\n",
      "epoch 2182\n",
      "test_train\n",
      "train mean loss=0.09447103397299846\n",
      "test_test\n",
      "test mean loss=1156.8119506835938\n",
      "epoch 2183\n",
      "test_train\n",
      "train mean loss=0.0929023598631223\n",
      "test_test\n",
      "test mean loss=1157.4275512695312\n",
      "epoch 2184\n",
      "test_train\n",
      "train mean loss=0.09340106757978599\n",
      "test_test\n",
      "test mean loss=1157.0892333984375\n",
      "epoch 2185\n",
      "test_train\n",
      "train mean loss=0.1016935979326566\n",
      "test_test\n",
      "test mean loss=1157.7866821289062\n",
      "epoch 2186\n",
      "test_train\n",
      "train mean loss=0.09700863094379504\n",
      "test_test\n",
      "test mean loss=1156.7084350585938\n",
      "epoch 2187\n",
      "test_train\n",
      "train mean loss=0.09473182400688529\n",
      "test_test\n",
      "test mean loss=1157.0960083007812\n",
      "epoch 2188\n",
      "test_train\n",
      "train mean loss=0.09154420004536708\n",
      "test_test\n",
      "test mean loss=1156.3645629882812\n",
      "epoch 2189\n",
      "test_train\n",
      "train mean loss=0.08940456838657458\n",
      "test_test\n",
      "test mean loss=1156.1470947265625\n",
      "epoch 2190\n",
      "test_train\n",
      "train mean loss=0.0839519053697586\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1156.91064453125\n",
      "epoch 2191\n",
      "test_train\n",
      "train mean loss=0.10100372259815533\n",
      "test_test\n",
      "test mean loss=1158.6486206054688\n",
      "epoch 2192\n",
      "test_train\n",
      "train mean loss=0.09298429048309724\n",
      "test_test\n",
      "test mean loss=1157.4771118164062\n",
      "epoch 2193\n",
      "test_train\n",
      "train mean loss=0.10142580109337966\n",
      "test_test\n",
      "test mean loss=1157.528076171875\n",
      "epoch 2194\n",
      "test_train\n",
      "train mean loss=0.098085127150019\n",
      "test_test\n",
      "test mean loss=1157.1943969726562\n",
      "epoch 2195\n",
      "test_train\n",
      "train mean loss=0.08684201880047719\n",
      "test_test\n",
      "test mean loss=1156.5367126464844\n",
      "epoch 2196\n",
      "test_train\n",
      "train mean loss=0.09109696590652068\n",
      "test_test\n",
      "test mean loss=1156.9505615234375\n",
      "epoch 2197\n",
      "test_train\n",
      "train mean loss=0.09467092575505376\n",
      "test_test\n",
      "test mean loss=1158.0714111328125\n",
      "epoch 2198\n",
      "test_train\n",
      "train mean loss=0.0875148397559921\n",
      "test_test\n",
      "test mean loss=1157.60791015625\n",
      "epoch 2199\n",
      "test_train\n",
      "train mean loss=0.0875287748252352\n",
      "test_test\n",
      "test mean loss=1158.8125305175781\n",
      "epoch 2200\n",
      "test_train\n",
      "train mean loss=0.0922874640673399\n",
      "test_test\n",
      "test mean loss=1157.7470703125\n",
      "epoch 2201\n",
      "test_train\n",
      "train mean loss=0.0890889245395859\n",
      "test_test\n",
      "test mean loss=1158.1455993652344\n",
      "epoch 2202\n",
      "test_train\n",
      "train mean loss=0.09520238762100537\n",
      "test_test\n",
      "test mean loss=1158.43505859375\n",
      "epoch 2203\n",
      "test_train\n",
      "train mean loss=0.09552011887232463\n",
      "test_test\n",
      "test mean loss=1158.0576477050781\n",
      "epoch 2204\n",
      "test_train\n",
      "train mean loss=0.09232185874134302\n",
      "test_test\n",
      "test mean loss=1157.8837890625\n",
      "epoch 2205\n",
      "test_train\n",
      "train mean loss=0.09846599058558543\n",
      "test_test\n",
      "test mean loss=1157.9087829589844\n",
      "epoch 2206\n",
      "test_train\n",
      "train mean loss=0.0915872963766257\n",
      "test_test\n",
      "test mean loss=1158.1373901367188\n",
      "epoch 2207\n",
      "test_train\n",
      "train mean loss=0.09538275562226772\n",
      "test_test\n",
      "test mean loss=1158.3013305664062\n",
      "epoch 2208\n",
      "test_train\n",
      "train mean loss=0.08665721553067367\n",
      "test_test\n",
      "test mean loss=1158.2265014648438\n",
      "epoch 2209\n",
      "test_train\n",
      "train mean loss=0.0862778074418505\n",
      "test_test\n",
      "test mean loss=1157.1353149414062\n",
      "epoch 2210\n",
      "test_train\n",
      "train mean loss=0.18772736067573229\n",
      "test_test\n",
      "test mean loss=1154.2000732421875\n",
      "epoch 2211\n",
      "test_train\n",
      "train mean loss=0.10845521092414856\n",
      "test_test\n",
      "test mean loss=1155.95947265625\n",
      "epoch 2212\n",
      "test_train\n",
      "train mean loss=0.13473669377466044\n",
      "test_test\n",
      "test mean loss=1155.0907592773438\n",
      "epoch 2213\n",
      "test_train\n",
      "train mean loss=0.09719116892665625\n",
      "test_test\n",
      "test mean loss=1155.66455078125\n",
      "epoch 2214\n",
      "test_train\n",
      "train mean loss=0.08907742363711198\n",
      "test_test\n",
      "test mean loss=1156.4685974121094\n",
      "epoch 2215\n",
      "test_train\n",
      "train mean loss=0.09823632054030895\n",
      "test_test\n",
      "test mean loss=1157.3652038574219\n",
      "epoch 2216\n",
      "test_train\n",
      "train mean loss=0.09427984617650509\n",
      "test_test\n",
      "test mean loss=1158.0609436035156\n",
      "epoch 2217\n",
      "test_train\n",
      "train mean loss=0.0910082720220089\n",
      "test_test\n",
      "test mean loss=1157.056396484375\n",
      "epoch 2218\n",
      "test_train\n",
      "train mean loss=0.08845077144602935\n",
      "test_test\n",
      "test mean loss=1156.7741088867188\n",
      "epoch 2219\n",
      "test_train\n",
      "train mean loss=0.09058166667819023\n",
      "test_test\n",
      "test mean loss=1156.3814697265625\n",
      "epoch 2220\n",
      "test_train\n",
      "train mean loss=0.09437388802568118\n",
      "test_test\n",
      "test mean loss=1156.9573364257812\n",
      "epoch 2221\n",
      "test_train\n",
      "train mean loss=0.09793508394310872\n",
      "test_test\n",
      "test mean loss=1158.0108947753906\n",
      "epoch 2222\n",
      "test_train\n",
      "train mean loss=0.09249162984391053\n",
      "test_test\n",
      "test mean loss=1156.5176391601562\n",
      "epoch 2223\n",
      "test_train\n",
      "train mean loss=0.0872913422062993\n",
      "test_test\n",
      "test mean loss=1156.2443237304688\n",
      "epoch 2224\n",
      "test_train\n",
      "train mean loss=0.09761824738234282\n",
      "test_test\n",
      "test mean loss=1158.5888671875\n",
      "epoch 2225\n",
      "test_train\n",
      "train mean loss=0.09025356297691663\n",
      "test_test\n",
      "test mean loss=1157.6645202636719\n",
      "epoch 2226\n",
      "test_train\n",
      "train mean loss=0.08889638322095077\n",
      "test_test\n",
      "test mean loss=1156.9177856445312\n",
      "epoch 2227\n",
      "test_train\n",
      "train mean loss=0.9727679590384165\n",
      "test_test\n",
      "test mean loss=1159.8810424804688\n",
      "epoch 2228\n",
      "test_train\n",
      "train mean loss=0.11235889885574579\n",
      "test_test\n",
      "test mean loss=1156.4442443847656\n",
      "epoch 2229\n",
      "test_train\n",
      "train mean loss=0.10119186341762543\n",
      "test_test\n",
      "test mean loss=1156.7463989257812\n",
      "epoch 2230\n",
      "test_train\n",
      "train mean loss=0.09951682171473901\n",
      "test_test\n",
      "test mean loss=1156.9541015625\n",
      "epoch 2231\n",
      "test_train\n",
      "train mean loss=0.12746639860173067\n",
      "test_test\n",
      "test mean loss=1157.9959106445312\n",
      "epoch 2232\n",
      "test_train\n",
      "train mean loss=0.10177135157088439\n",
      "test_test\n",
      "test mean loss=1157.5252075195312\n",
      "epoch 2233\n",
      "test_train\n",
      "train mean loss=0.09862599211434524\n",
      "test_test\n",
      "test mean loss=1157.4804077148438\n",
      "epoch 2234\n",
      "test_train\n",
      "train mean loss=0.09655652288347483\n",
      "test_test\n",
      "test mean loss=1157.1907348632812\n",
      "epoch 2235\n",
      "test_train\n",
      "train mean loss=0.09186813576767842\n",
      "test_test\n",
      "test mean loss=1156.2792053222656\n",
      "epoch 2236\n",
      "test_train\n",
      "train mean loss=0.09227415422598521\n",
      "test_test\n",
      "test mean loss=1156.4486694335938\n",
      "epoch 2237\n",
      "test_train\n",
      "train mean loss=0.0903383099163572\n",
      "test_test\n",
      "test mean loss=1155.8956298828125\n",
      "epoch 2238\n",
      "test_train\n",
      "train mean loss=0.533488504588604\n",
      "test_test\n",
      "test mean loss=1158.529541015625\n",
      "epoch 2239\n",
      "test_train\n",
      "train mean loss=0.11427685307959716\n",
      "test_test\n",
      "test mean loss=1159.4961853027344\n",
      "epoch 2240\n",
      "test_train\n",
      "train mean loss=0.09205432484547298\n",
      "test_test\n",
      "test mean loss=1157.8462524414062\n",
      "epoch 2241\n",
      "test_train\n",
      "train mean loss=0.09846887458115816\n",
      "test_test\n",
      "test mean loss=1157.3133544921875\n",
      "epoch 2242\n",
      "test_train\n",
      "train mean loss=0.09745281127591927\n",
      "test_test\n",
      "test mean loss=1156.8881225585938\n",
      "epoch 2243\n",
      "test_train\n",
      "train mean loss=0.1395371543864409\n",
      "test_test\n",
      "test mean loss=1156.336181640625\n",
      "epoch 2244\n",
      "test_train\n",
      "train mean loss=0.10760740594317515\n",
      "test_test\n",
      "test mean loss=1158.1347045898438\n",
      "epoch 2245\n",
      "test_train\n",
      "train mean loss=0.10118051556249459\n",
      "test_test\n",
      "test mean loss=1157.4072875976562\n",
      "epoch 2246\n",
      "test_train\n",
      "train mean loss=0.10018216073513031\n",
      "test_test\n",
      "test mean loss=1156.9845275878906\n",
      "epoch 2247\n",
      "test_train\n",
      "train mean loss=0.10235748377939065\n",
      "test_test\n",
      "test mean loss=1156.6505432128906\n",
      "epoch 2248\n",
      "test_train\n",
      "train mean loss=0.09373766121764977\n",
      "test_test\n",
      "test mean loss=1156.7124633789062\n",
      "epoch 2249\n",
      "test_train\n",
      "train mean loss=0.09776322885106008\n",
      "test_test\n",
      "test mean loss=1156.5269470214844\n",
      "epoch 2250\n",
      "test_train\n",
      "train mean loss=0.17713477338353792\n",
      "test_test\n",
      "test mean loss=1157.0934448242188\n",
      "epoch 2251\n",
      "test_train\n",
      "train mean loss=0.10428486205637455\n",
      "test_test\n",
      "test mean loss=1155.8006591796875\n",
      "epoch 2252\n",
      "test_train\n",
      "train mean loss=0.10360816555718581\n",
      "test_test\n",
      "test mean loss=1156.2626953125\n",
      "epoch 2253\n",
      "test_train\n",
      "train mean loss=0.09665294953932364\n",
      "test_test\n",
      "test mean loss=1156.3974914550781\n",
      "epoch 2254\n",
      "test_train\n",
      "train mean loss=0.0986893664424618\n",
      "test_test\n",
      "test mean loss=1156.8610534667969\n",
      "epoch 2255\n",
      "test_train\n",
      "train mean loss=0.09805336284140746\n",
      "test_test\n",
      "test mean loss=1156.8861083984375\n",
      "epoch 2256\n",
      "test_train\n",
      "train mean loss=0.09796225714186828\n",
      "test_test\n",
      "test mean loss=1156.9275207519531\n",
      "epoch 2257\n",
      "test_train\n",
      "train mean loss=0.09554243336121242\n",
      "test_test\n",
      "test mean loss=1157.1512451171875\n",
      "epoch 2258\n",
      "test_train\n",
      "train mean loss=0.11168105403582256\n",
      "test_test\n",
      "test mean loss=1156.2193298339844\n",
      "epoch 2259\n",
      "test_train\n",
      "train mean loss=0.0981633539001147\n",
      "test_test\n",
      "test mean loss=1155.9014892578125\n",
      "epoch 2260\n",
      "test_train\n",
      "train mean loss=0.11197237484157085\n",
      "test_test\n",
      "test mean loss=1157.5823364257812\n",
      "epoch 2261\n",
      "test_train\n",
      "train mean loss=0.10332978454728921\n",
      "test_test\n",
      "test mean loss=1157.0805053710938\n",
      "epoch 2262\n",
      "test_train\n",
      "train mean loss=0.10050952807068825\n",
      "test_test\n",
      "test mean loss=1156.7872009277344\n",
      "epoch 2263\n",
      "test_train\n",
      "train mean loss=0.101420810756584\n",
      "test_test\n",
      "test mean loss=1157.29638671875\n",
      "epoch 2264\n",
      "test_train\n",
      "train mean loss=0.09713484502087037\n",
      "test_test\n",
      "test mean loss=1156.5691528320312\n",
      "epoch 2265\n",
      "test_train\n",
      "train mean loss=0.09264419848720233\n",
      "test_test\n",
      "test mean loss=1157.105224609375\n",
      "epoch 2266\n",
      "test_train\n",
      "train mean loss=0.09332448026786248\n",
      "test_test\n",
      "test mean loss=1157.1482238769531\n",
      "epoch 2267\n",
      "test_train\n",
      "train mean loss=0.09446588655312856\n",
      "test_test\n",
      "test mean loss=1157.4020690917969\n",
      "epoch 2268\n",
      "test_train\n",
      "train mean loss=0.09354048936317365\n",
      "test_test\n",
      "test mean loss=1156.2035522460938\n",
      "epoch 2269\n",
      "test_train\n",
      "train mean loss=0.09425660688430071\n",
      "test_test\n",
      "test mean loss=1155.5279541015625\n",
      "epoch 2270\n",
      "test_train\n",
      "train mean loss=0.09724198064456384\n",
      "test_test\n",
      "test mean loss=1156.905029296875\n",
      "epoch 2271\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.09779907204210758\n",
      "test_test\n",
      "test mean loss=1157.706787109375\n",
      "epoch 2272\n",
      "test_train\n",
      "train mean loss=0.11773573172589143\n",
      "test_test\n",
      "test mean loss=1157.1116943359375\n",
      "epoch 2273\n",
      "test_train\n",
      "train mean loss=0.10186923543612163\n",
      "test_test\n",
      "test mean loss=1157.6482543945312\n",
      "epoch 2274\n",
      "test_train\n",
      "train mean loss=0.08965037887295087\n",
      "test_test\n",
      "test mean loss=1156.6315307617188\n",
      "epoch 2275\n",
      "test_train\n",
      "train mean loss=0.09089548327028751\n",
      "test_test\n",
      "test mean loss=1156.990966796875\n",
      "epoch 2276\n",
      "test_train\n",
      "train mean loss=0.09147570965190728\n",
      "test_test\n",
      "test mean loss=1156.6295166015625\n",
      "epoch 2277\n",
      "test_train\n",
      "train mean loss=0.09856690155963103\n",
      "test_test\n",
      "test mean loss=1156.6192626953125\n",
      "epoch 2278\n",
      "test_train\n",
      "train mean loss=0.10008411947637796\n",
      "test_test\n",
      "test mean loss=1156.368896484375\n",
      "epoch 2279\n",
      "test_train\n",
      "train mean loss=0.09744591141740482\n",
      "test_test\n",
      "test mean loss=1156.625732421875\n",
      "epoch 2280\n",
      "test_train\n",
      "train mean loss=0.09710083653529485\n",
      "test_test\n",
      "test mean loss=1155.9039916992188\n",
      "epoch 2281\n",
      "test_train\n",
      "train mean loss=0.10015986083696286\n",
      "test_test\n",
      "test mean loss=1155.9841918945312\n",
      "epoch 2282\n",
      "test_train\n",
      "train mean loss=0.10017103049904108\n",
      "test_test\n",
      "test mean loss=1156.8965454101562\n",
      "epoch 2283\n",
      "test_train\n",
      "train mean loss=0.09181477533032496\n",
      "test_test\n",
      "test mean loss=1156.4718017578125\n",
      "epoch 2284\n",
      "test_train\n",
      "train mean loss=0.09851283083359401\n",
      "test_test\n",
      "test mean loss=1156.7666625976562\n",
      "epoch 2285\n",
      "test_train\n",
      "train mean loss=0.09633332056303819\n",
      "test_test\n",
      "test mean loss=1156.8565673828125\n",
      "epoch 2286\n",
      "test_train\n",
      "train mean loss=0.09002487765004237\n",
      "test_test\n",
      "test mean loss=1155.8507080078125\n",
      "epoch 2287\n",
      "test_train\n",
      "train mean loss=0.0935337683185935\n",
      "test_test\n",
      "test mean loss=1155.8379211425781\n",
      "epoch 2288\n",
      "test_train\n",
      "train mean loss=0.09598377471168835\n",
      "test_test\n",
      "test mean loss=1156.1805419921875\n",
      "epoch 2289\n",
      "test_train\n",
      "train mean loss=0.09750169826050599\n",
      "test_test\n",
      "test mean loss=1156.739501953125\n",
      "epoch 2290\n",
      "test_train\n",
      "train mean loss=0.0955004229520758\n",
      "test_test\n",
      "test mean loss=1156.6129760742188\n",
      "epoch 2291\n",
      "test_train\n",
      "train mean loss=0.09831013654669125\n",
      "test_test\n",
      "test mean loss=1156.9650573730469\n",
      "epoch 2292\n",
      "test_train\n",
      "train mean loss=0.09607914400597413\n",
      "test_test\n",
      "test mean loss=1156.3045043945312\n",
      "epoch 2293\n",
      "test_train\n",
      "train mean loss=0.08950359902034204\n",
      "test_test\n",
      "test mean loss=1156.3550415039062\n",
      "epoch 2294\n",
      "test_train\n",
      "train mean loss=0.09554697014391422\n",
      "test_test\n",
      "test mean loss=1156.1076965332031\n",
      "epoch 2295\n",
      "test_train\n",
      "train mean loss=0.09370227468510468\n",
      "test_test\n",
      "test mean loss=1155.81787109375\n",
      "epoch 2296\n",
      "test_train\n",
      "train mean loss=0.09153357769052188\n",
      "test_test\n",
      "test mean loss=1157.4682312011719\n",
      "epoch 2297\n",
      "test_train\n",
      "train mean loss=0.09505259462942679\n",
      "test_test\n",
      "test mean loss=1156.2832641601562\n",
      "epoch 2298\n",
      "test_train\n",
      "train mean loss=0.09727530150363843\n",
      "test_test\n",
      "test mean loss=1156.3911743164062\n",
      "epoch 2299\n",
      "test_train\n",
      "train mean loss=0.09056071906040113\n",
      "test_test\n",
      "test mean loss=1156.395263671875\n",
      "epoch 2300\n",
      "test_train\n",
      "train mean loss=0.0881413547322154\n",
      "test_test\n",
      "test mean loss=1155.6603088378906\n",
      "epoch 2301\n",
      "test_train\n",
      "train mean loss=0.08884669591983159\n",
      "test_test\n",
      "test mean loss=1156.1232604980469\n",
      "epoch 2302\n",
      "test_train\n",
      "train mean loss=0.0893079439798991\n",
      "test_test\n",
      "test mean loss=1156.8480834960938\n",
      "epoch 2303\n",
      "test_train\n",
      "train mean loss=0.08963427568475406\n",
      "test_test\n",
      "test mean loss=1157.0396118164062\n",
      "epoch 2304\n",
      "test_train\n",
      "train mean loss=0.0900220787152648\n",
      "test_test\n",
      "test mean loss=1156.1896362304688\n",
      "epoch 2305\n",
      "test_train\n",
      "train mean loss=0.09680349752306938\n",
      "test_test\n",
      "test mean loss=1156.7839660644531\n",
      "epoch 2306\n",
      "test_train\n",
      "train mean loss=0.09872129869957764\n",
      "test_test\n",
      "test mean loss=1156.6056518554688\n",
      "epoch 2307\n",
      "test_train\n",
      "train mean loss=0.0944935039927562\n",
      "test_test\n",
      "test mean loss=1157.407470703125\n",
      "epoch 2308\n",
      "test_train\n",
      "train mean loss=0.08988785184919834\n",
      "test_test\n",
      "test mean loss=1157.0290222167969\n",
      "epoch 2309\n",
      "test_train\n",
      "train mean loss=0.09293089931209882\n",
      "test_test\n",
      "test mean loss=1157.823974609375\n",
      "epoch 2310\n",
      "test_train\n",
      "train mean loss=0.09165563713759184\n",
      "test_test\n",
      "test mean loss=1157.3735656738281\n",
      "epoch 2311\n",
      "test_train\n",
      "train mean loss=0.09953708698352177\n",
      "test_test\n",
      "test mean loss=1157.77880859375\n",
      "epoch 2312\n",
      "test_train\n",
      "train mean loss=0.09146326159437497\n",
      "test_test\n",
      "test mean loss=1156.5431823730469\n",
      "epoch 2313\n",
      "test_train\n",
      "train mean loss=0.10045838790635268\n",
      "test_test\n",
      "test mean loss=1156.8045959472656\n",
      "epoch 2314\n",
      "test_train\n",
      "train mean loss=0.09093772247433662\n",
      "test_test\n",
      "test mean loss=1155.7974243164062\n",
      "epoch 2315\n",
      "test_train\n",
      "train mean loss=0.0996487873295943\n",
      "test_test\n",
      "test mean loss=1156.7070007324219\n",
      "epoch 2316\n",
      "test_train\n",
      "train mean loss=0.6078415960073471\n",
      "test_test\n",
      "test mean loss=1156.4293212890625\n",
      "epoch 2317\n",
      "test_train\n",
      "train mean loss=0.1419220119714737\n",
      "test_test\n",
      "test mean loss=1155.8892211914062\n",
      "epoch 2318\n",
      "test_train\n",
      "train mean loss=0.10239945879826944\n",
      "test_test\n",
      "test mean loss=1155.2258605957031\n",
      "epoch 2319\n",
      "test_train\n",
      "train mean loss=0.0940188579261303\n",
      "test_test\n",
      "test mean loss=1155.320068359375\n",
      "epoch 2320\n",
      "test_train\n",
      "train mean loss=0.10174564768870671\n",
      "test_test\n",
      "test mean loss=1156.1098327636719\n",
      "epoch 2321\n",
      "test_train\n",
      "train mean loss=0.09476935646186273\n",
      "test_test\n",
      "test mean loss=1156.1721801757812\n",
      "epoch 2322\n",
      "test_train\n",
      "train mean loss=0.09013481593380372\n",
      "test_test\n",
      "test mean loss=1155.1109619140625\n",
      "epoch 2323\n",
      "test_train\n",
      "train mean loss=0.0928131624435385\n",
      "test_test\n",
      "test mean loss=1155.5965881347656\n",
      "epoch 2324\n",
      "test_train\n",
      "train mean loss=0.09260442418356736\n",
      "test_test\n",
      "test mean loss=1155.7483215332031\n",
      "epoch 2325\n",
      "test_train\n",
      "train mean loss=0.09472623374313116\n",
      "test_test\n",
      "test mean loss=1156.7355651855469\n",
      "epoch 2326\n",
      "test_train\n",
      "train mean loss=0.09341697891553243\n",
      "test_test\n",
      "test mean loss=1155.904296875\n",
      "epoch 2327\n",
      "test_train\n",
      "train mean loss=0.09412246725211541\n",
      "test_test\n",
      "test mean loss=1156.5111694335938\n",
      "epoch 2328\n",
      "test_train\n",
      "train mean loss=0.091967078546683\n",
      "test_test\n",
      "test mean loss=1156.1417846679688\n",
      "epoch 2329\n",
      "test_train\n",
      "train mean loss=0.09580015484243631\n",
      "test_test\n",
      "test mean loss=1156.2705993652344\n",
      "epoch 2330\n",
      "test_train\n",
      "train mean loss=0.09015737442920606\n",
      "test_test\n",
      "test mean loss=1156.1794128417969\n",
      "epoch 2331\n",
      "test_train\n",
      "train mean loss=0.10361002385616302\n",
      "test_test\n",
      "test mean loss=1157.427490234375\n",
      "epoch 2332\n",
      "test_train\n",
      "train mean loss=0.09127313146988551\n",
      "test_test\n",
      "test mean loss=1156.5657348632812\n",
      "epoch 2333\n",
      "test_train\n",
      "train mean loss=0.15004292502999306\n",
      "test_test\n",
      "test mean loss=1157.5690307617188\n",
      "epoch 2334\n",
      "test_train\n",
      "train mean loss=0.10036841966211796\n",
      "test_test\n",
      "test mean loss=1156.6527709960938\n",
      "epoch 2335\n",
      "test_train\n",
      "train mean loss=0.0937588419765234\n",
      "test_test\n",
      "test mean loss=1155.7692565917969\n",
      "epoch 2336\n",
      "test_train\n",
      "train mean loss=0.09584535596271355\n",
      "test_test\n",
      "test mean loss=1155.580078125\n",
      "epoch 2337\n",
      "test_train\n",
      "train mean loss=0.08839648185918729\n",
      "test_test\n",
      "test mean loss=1154.8538818359375\n",
      "epoch 2338\n",
      "test_train\n",
      "train mean loss=0.09396626738210519\n",
      "test_test\n",
      "test mean loss=1153.7879333496094\n",
      "epoch 2339\n",
      "test_train\n",
      "train mean loss=0.09715024940669537\n",
      "test_test\n",
      "test mean loss=1154.8493957519531\n",
      "epoch 2340\n",
      "test_train\n",
      "train mean loss=0.10029382320741813\n",
      "test_test\n",
      "test mean loss=1154.3297119140625\n",
      "epoch 2341\n",
      "test_train\n",
      "train mean loss=0.0914687126254042\n",
      "test_test\n",
      "test mean loss=1155.4173889160156\n",
      "epoch 2342\n",
      "test_train\n",
      "train mean loss=0.09639900270849466\n",
      "test_test\n",
      "test mean loss=1155.2283325195312\n",
      "epoch 2343\n",
      "test_train\n",
      "train mean loss=0.09302591967085998\n",
      "test_test\n",
      "test mean loss=1154.7750244140625\n",
      "epoch 2344\n",
      "test_train\n",
      "train mean loss=0.09537690629561742\n",
      "test_test\n",
      "test mean loss=1155.2422790527344\n",
      "epoch 2345\n",
      "test_train\n",
      "train mean loss=0.0902739657709996\n",
      "test_test\n",
      "test mean loss=1155.0465087890625\n",
      "epoch 2346\n",
      "test_train\n",
      "train mean loss=0.0881574774781863\n",
      "test_test\n",
      "test mean loss=1155.9098510742188\n",
      "epoch 2347\n",
      "test_train\n",
      "train mean loss=0.08527401089668274\n",
      "test_test\n",
      "test mean loss=1155.956787109375\n",
      "epoch 2348\n",
      "test_train\n",
      "train mean loss=0.08906774005542199\n",
      "test_test\n",
      "test mean loss=1155.4428100585938\n",
      "epoch 2349\n",
      "test_train\n",
      "train mean loss=0.09410777781158686\n",
      "test_test\n",
      "test mean loss=1155.1226806640625\n",
      "epoch 2350\n",
      "test_train\n",
      "train mean loss=0.09542376703272264\n",
      "test_test\n",
      "test mean loss=1154.6798095703125\n",
      "epoch 2351\n",
      "test_train\n",
      "train mean loss=0.12703132132689157\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1152.7133483886719\n",
      "epoch 2352\n",
      "test_train\n",
      "train mean loss=0.09033612441271544\n",
      "test_test\n",
      "test mean loss=1154.7433471679688\n",
      "epoch 2353\n",
      "test_train\n",
      "train mean loss=0.10278435610234737\n",
      "test_test\n",
      "test mean loss=1154.7750854492188\n",
      "epoch 2354\n",
      "test_train\n",
      "train mean loss=0.09315672268470128\n",
      "test_test\n",
      "test mean loss=1155.4156494140625\n",
      "epoch 2355\n",
      "test_train\n",
      "train mean loss=0.09293324841807286\n",
      "test_test\n",
      "test mean loss=1155.8707275390625\n",
      "epoch 2356\n",
      "test_train\n",
      "train mean loss=0.0906483077754577\n",
      "test_test\n",
      "test mean loss=1156.2791748046875\n",
      "epoch 2357\n",
      "test_train\n",
      "train mean loss=0.08810239440451066\n",
      "test_test\n",
      "test mean loss=1155.6831665039062\n",
      "epoch 2358\n",
      "test_train\n",
      "train mean loss=0.08668004348874092\n",
      "test_test\n",
      "test mean loss=1155.6217651367188\n",
      "epoch 2359\n",
      "test_train\n",
      "train mean loss=0.08777961072822411\n",
      "test_test\n",
      "test mean loss=1156.1271667480469\n",
      "epoch 2360\n",
      "test_train\n",
      "train mean loss=0.08558566713084777\n",
      "test_test\n",
      "test mean loss=1156.2024536132812\n",
      "epoch 2361\n",
      "test_train\n",
      "train mean loss=0.11053847738852103\n",
      "test_test\n",
      "test mean loss=1155.7177734375\n",
      "epoch 2362\n",
      "test_train\n",
      "train mean loss=0.09804819493244092\n",
      "test_test\n",
      "test mean loss=1156.7621765136719\n",
      "epoch 2363\n",
      "test_train\n",
      "train mean loss=0.09570070759703715\n",
      "test_test\n",
      "test mean loss=1156.7554321289062\n",
      "epoch 2364\n",
      "test_train\n",
      "train mean loss=0.09321496232102315\n",
      "test_test\n",
      "test mean loss=1155.8852233886719\n",
      "epoch 2365\n",
      "test_train\n",
      "train mean loss=0.0960255643973748\n",
      "test_test\n",
      "test mean loss=1156.6753540039062\n",
      "epoch 2366\n",
      "test_train\n",
      "train mean loss=0.09680751680086057\n",
      "test_test\n",
      "test mean loss=1155.5702514648438\n",
      "epoch 2367\n",
      "test_train\n",
      "train mean loss=0.09273569689442714\n",
      "test_test\n",
      "test mean loss=1155.0575866699219\n",
      "epoch 2368\n",
      "test_train\n",
      "train mean loss=0.09094334859400988\n",
      "test_test\n",
      "test mean loss=1155.6829833984375\n",
      "epoch 2369\n",
      "test_train\n",
      "train mean loss=0.09635584553082784\n",
      "test_test\n",
      "test mean loss=1155.8598022460938\n",
      "epoch 2370\n",
      "test_train\n",
      "train mean loss=0.09507441458602746\n",
      "test_test\n",
      "test mean loss=1155.76220703125\n",
      "epoch 2371\n",
      "test_train\n",
      "train mean loss=0.09256723274787267\n",
      "test_test\n",
      "test mean loss=1155.9957275390625\n",
      "epoch 2372\n",
      "test_train\n",
      "train mean loss=0.09134684068461259\n",
      "test_test\n",
      "test mean loss=1156.6690063476562\n",
      "epoch 2373\n",
      "test_train\n",
      "train mean loss=0.09203999862074852\n",
      "test_test\n",
      "test mean loss=1156.5682373046875\n",
      "epoch 2374\n",
      "test_train\n",
      "train mean loss=0.08815535778800647\n",
      "test_test\n",
      "test mean loss=1155.8084106445312\n",
      "epoch 2375\n",
      "test_train\n",
      "train mean loss=0.09460731130093336\n",
      "test_test\n",
      "test mean loss=1156.1134033203125\n",
      "epoch 2376\n",
      "test_train\n",
      "train mean loss=0.09138226509094238\n",
      "test_test\n",
      "test mean loss=1156.1024780273438\n",
      "epoch 2377\n",
      "test_train\n",
      "train mean loss=0.09189884178340435\n",
      "test_test\n",
      "test mean loss=1157.9879150390625\n",
      "epoch 2378\n",
      "test_train\n",
      "train mean loss=0.09554164080570142\n",
      "test_test\n",
      "test mean loss=1156.549560546875\n",
      "epoch 2379\n",
      "test_train\n",
      "train mean loss=0.09096697407464187\n",
      "test_test\n",
      "test mean loss=1155.8798828125\n",
      "epoch 2380\n",
      "test_train\n",
      "train mean loss=0.09008254731694858\n",
      "test_test\n",
      "test mean loss=1155.932373046875\n",
      "epoch 2381\n",
      "test_train\n",
      "train mean loss=0.08934721692154805\n",
      "test_test\n",
      "test mean loss=1156.6995239257812\n",
      "epoch 2382\n",
      "test_train\n",
      "train mean loss=0.09823313727974892\n",
      "test_test\n",
      "test mean loss=1155.1353149414062\n",
      "epoch 2383\n",
      "test_train\n",
      "train mean loss=0.0918296795959274\n",
      "test_test\n",
      "test mean loss=1154.7720336914062\n",
      "epoch 2384\n",
      "test_train\n",
      "train mean loss=0.09179932779322068\n",
      "test_test\n",
      "test mean loss=1155.1575012207031\n",
      "epoch 2385\n",
      "test_train\n",
      "train mean loss=0.09525175640980403\n",
      "test_test\n",
      "test mean loss=1156.0899963378906\n",
      "epoch 2386\n",
      "test_train\n",
      "train mean loss=0.09765424113720655\n",
      "test_test\n",
      "test mean loss=1155.9493408203125\n",
      "epoch 2387\n",
      "test_train\n",
      "train mean loss=0.0918962915117542\n",
      "test_test\n",
      "test mean loss=1156.6622924804688\n",
      "epoch 2388\n",
      "test_train\n",
      "train mean loss=0.09386838072290023\n",
      "test_test\n",
      "test mean loss=1156.1449584960938\n",
      "epoch 2389\n",
      "test_train\n",
      "train mean loss=0.09261106792837381\n",
      "test_test\n",
      "test mean loss=1156.0362854003906\n",
      "epoch 2390\n",
      "test_train\n",
      "train mean loss=0.09132459728668134\n",
      "test_test\n",
      "test mean loss=1156.7288208007812\n",
      "epoch 2391\n",
      "test_train\n",
      "train mean loss=0.09203754458576441\n",
      "test_test\n",
      "test mean loss=1156.7096557617188\n",
      "epoch 2392\n",
      "test_train\n",
      "train mean loss=0.09014553452531497\n",
      "test_test\n",
      "test mean loss=1157.1629638671875\n",
      "epoch 2393\n",
      "test_train\n",
      "train mean loss=0.23879540711641312\n",
      "test_test\n",
      "test mean loss=1159.7639770507812\n",
      "epoch 2394\n",
      "test_train\n",
      "train mean loss=0.6755617260932922\n",
      "test_test\n",
      "test mean loss=1159.6043701171875\n",
      "epoch 2395\n",
      "test_train\n",
      "train mean loss=0.11379627697169781\n",
      "test_test\n",
      "test mean loss=1157.3429565429688\n",
      "epoch 2396\n",
      "test_train\n",
      "train mean loss=0.0988656918828686\n",
      "test_test\n",
      "test mean loss=1157.9521789550781\n",
      "epoch 2397\n",
      "test_train\n",
      "train mean loss=0.09714276188363631\n",
      "test_test\n",
      "test mean loss=1157.05419921875\n",
      "epoch 2398\n",
      "test_train\n",
      "train mean loss=0.10132186797757943\n",
      "test_test\n",
      "test mean loss=1156.9420471191406\n",
      "epoch 2399\n",
      "test_train\n",
      "train mean loss=0.10271722233543794\n",
      "test_test\n",
      "test mean loss=1156.49658203125\n",
      "epoch 2400\n",
      "test_train\n",
      "train mean loss=0.09124706809719403\n",
      "test_test\n",
      "test mean loss=1156.5826110839844\n",
      "epoch 2401\n",
      "test_train\n",
      "train mean loss=0.09607049853851397\n",
      "test_test\n",
      "test mean loss=1156.3982849121094\n",
      "epoch 2402\n",
      "test_train\n",
      "train mean loss=0.08959094434976578\n",
      "test_test\n",
      "test mean loss=1157.2368469238281\n",
      "epoch 2403\n",
      "test_train\n",
      "train mean loss=0.10104475046197574\n",
      "test_test\n",
      "test mean loss=1156.1364440917969\n",
      "epoch 2404\n",
      "test_train\n",
      "train mean loss=0.10103242782255013\n",
      "test_test\n",
      "test mean loss=1156.6549072265625\n",
      "epoch 2405\n",
      "test_train\n",
      "train mean loss=0.09615683928132057\n",
      "test_test\n",
      "test mean loss=1155.8277282714844\n",
      "epoch 2406\n",
      "test_train\n",
      "train mean loss=0.10050438654919465\n",
      "test_test\n",
      "test mean loss=1156.1153869628906\n",
      "epoch 2407\n",
      "test_train\n",
      "train mean loss=0.10055663188298543\n",
      "test_test\n",
      "test mean loss=1156.1759033203125\n",
      "epoch 2408\n",
      "test_train\n",
      "train mean loss=0.09748649969696999\n",
      "test_test\n",
      "test mean loss=1156.3659057617188\n",
      "epoch 2409\n",
      "test_train\n",
      "train mean loss=0.09615528956055641\n",
      "test_test\n",
      "test mean loss=1156.1268920898438\n",
      "epoch 2410\n",
      "test_train\n",
      "train mean loss=0.08852965788294871\n",
      "test_test\n",
      "test mean loss=1156.926025390625\n",
      "epoch 2411\n",
      "test_train\n",
      "train mean loss=0.09838972582171361\n",
      "test_test\n",
      "test mean loss=1157.0035705566406\n",
      "epoch 2412\n",
      "test_train\n",
      "train mean loss=0.0974038125326236\n",
      "test_test\n",
      "test mean loss=1155.4957580566406\n",
      "epoch 2413\n",
      "test_train\n",
      "train mean loss=0.09579700883477926\n",
      "test_test\n",
      "test mean loss=1155.7730407714844\n",
      "epoch 2414\n",
      "test_train\n",
      "train mean loss=0.087649199180305\n",
      "test_test\n",
      "test mean loss=1156.1296691894531\n",
      "epoch 2415\n",
      "test_train\n",
      "train mean loss=0.09381914945940177\n",
      "test_test\n",
      "test mean loss=1155.7300109863281\n",
      "epoch 2416\n",
      "test_train\n",
      "train mean loss=0.09559146718432505\n",
      "test_test\n",
      "test mean loss=1156.8782348632812\n",
      "epoch 2417\n",
      "test_train\n",
      "train mean loss=0.0904370214169224\n",
      "test_test\n",
      "test mean loss=1156.3204040527344\n",
      "epoch 2418\n",
      "test_train\n",
      "train mean loss=0.09235693886876106\n",
      "test_test\n",
      "test mean loss=1156.14306640625\n",
      "epoch 2419\n",
      "test_train\n",
      "train mean loss=0.09415046498179436\n",
      "test_test\n",
      "test mean loss=1157.012939453125\n",
      "epoch 2420\n",
      "test_train\n",
      "train mean loss=0.09789443699022134\n",
      "test_test\n",
      "test mean loss=1156.8065490722656\n",
      "epoch 2421\n",
      "test_train\n",
      "train mean loss=0.09582129679620266\n",
      "test_test\n",
      "test mean loss=1156.376953125\n",
      "epoch 2422\n",
      "test_train\n",
      "train mean loss=0.10338972012201945\n",
      "test_test\n",
      "test mean loss=1156.0075073242188\n",
      "epoch 2423\n",
      "test_train\n",
      "train mean loss=0.09813379092762868\n",
      "test_test\n",
      "test mean loss=1156.6167602539062\n",
      "epoch 2424\n",
      "test_train\n",
      "train mean loss=0.09142848135282595\n",
      "test_test\n",
      "test mean loss=1156.5634155273438\n",
      "epoch 2425\n",
      "test_train\n",
      "train mean loss=0.0892084048440059\n",
      "test_test\n",
      "test mean loss=1157.1101684570312\n",
      "epoch 2426\n",
      "test_train\n",
      "train mean loss=0.08973085011045139\n",
      "test_test\n",
      "test mean loss=1155.740966796875\n",
      "epoch 2427\n",
      "test_train\n",
      "train mean loss=0.09405589507271846\n",
      "test_test\n",
      "test mean loss=1155.8682556152344\n",
      "epoch 2428\n",
      "test_train\n",
      "train mean loss=0.09096001523236434\n",
      "test_test\n",
      "test mean loss=1156.28369140625\n",
      "epoch 2429\n",
      "test_train\n",
      "train mean loss=0.0948556646083792\n",
      "test_test\n",
      "test mean loss=1156.2656860351562\n",
      "epoch 2430\n",
      "test_train\n",
      "train mean loss=0.09295933786779642\n",
      "test_test\n",
      "test mean loss=1155.5200500488281\n",
      "epoch 2431\n",
      "test_train\n",
      "train mean loss=0.10219093939910333\n",
      "test_test\n",
      "test mean loss=1155.7713928222656\n",
      "epoch 2432\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.0902025243267417\n",
      "test_test\n",
      "test mean loss=1156.804931640625\n",
      "epoch 2433\n",
      "test_train\n",
      "train mean loss=0.09329319217552741\n",
      "test_test\n",
      "test mean loss=1155.87451171875\n",
      "epoch 2434\n",
      "test_train\n",
      "train mean loss=0.08778666177143653\n",
      "test_test\n",
      "test mean loss=1157.0477294921875\n",
      "epoch 2435\n",
      "test_train\n",
      "train mean loss=0.08983344646791618\n",
      "test_test\n",
      "test mean loss=1156.9584045410156\n",
      "epoch 2436\n",
      "test_train\n",
      "train mean loss=0.09470828498403232\n",
      "test_test\n",
      "test mean loss=1156.240478515625\n",
      "epoch 2437\n",
      "test_train\n",
      "train mean loss=0.10111842739085357\n",
      "test_test\n",
      "test mean loss=1157.391845703125\n",
      "epoch 2438\n",
      "test_train\n",
      "train mean loss=0.09036211452136438\n",
      "test_test\n",
      "test mean loss=1156.0687866210938\n",
      "epoch 2439\n",
      "test_train\n",
      "train mean loss=0.08878945931792259\n",
      "test_test\n",
      "test mean loss=1155.64697265625\n",
      "epoch 2440\n",
      "test_train\n",
      "train mean loss=0.09792020792762439\n",
      "test_test\n",
      "test mean loss=1156.3995666503906\n",
      "epoch 2441\n",
      "test_train\n",
      "train mean loss=0.11809874015549819\n",
      "test_test\n",
      "test mean loss=1158.3953857421875\n",
      "epoch 2442\n",
      "test_train\n",
      "train mean loss=0.09625994429613154\n",
      "test_test\n",
      "test mean loss=1157.7255859375\n",
      "epoch 2443\n",
      "test_train\n",
      "train mean loss=0.09080467155824105\n",
      "test_test\n",
      "test mean loss=1156.2109985351562\n",
      "epoch 2444\n",
      "test_train\n",
      "train mean loss=0.09000204255183537\n",
      "test_test\n",
      "test mean loss=1157.2644958496094\n",
      "epoch 2445\n",
      "test_train\n",
      "train mean loss=0.11425954103469849\n",
      "test_test\n",
      "test mean loss=1156.6056823730469\n",
      "epoch 2446\n",
      "test_train\n",
      "train mean loss=0.09011236702402432\n",
      "test_test\n",
      "test mean loss=1156.1106872558594\n",
      "epoch 2447\n",
      "test_train\n",
      "train mean loss=0.09194032506396373\n",
      "test_test\n",
      "test mean loss=1157.2183532714844\n",
      "epoch 2448\n",
      "test_train\n",
      "train mean loss=0.09127721842378378\n",
      "test_test\n",
      "test mean loss=1156.205322265625\n",
      "epoch 2449\n",
      "test_train\n",
      "train mean loss=0.09220817405730486\n",
      "test_test\n",
      "test mean loss=1156.6688232421875\n",
      "epoch 2450\n",
      "test_train\n",
      "train mean loss=0.09033928718417883\n",
      "test_test\n",
      "test mean loss=1157.36669921875\n",
      "epoch 2451\n",
      "test_train\n",
      "train mean loss=0.09227354638278484\n",
      "test_test\n",
      "test mean loss=1155.7828369140625\n",
      "epoch 2452\n",
      "test_train\n",
      "train mean loss=0.09435954752067725\n",
      "test_test\n",
      "test mean loss=1157.1986694335938\n",
      "epoch 2453\n",
      "test_train\n",
      "train mean loss=0.09763699118047953\n",
      "test_test\n",
      "test mean loss=1158.1180114746094\n",
      "epoch 2454\n",
      "test_train\n",
      "train mean loss=0.0922117658580343\n",
      "test_test\n",
      "test mean loss=1156.6061401367188\n",
      "epoch 2455\n",
      "test_train\n",
      "train mean loss=0.09634995398422082\n",
      "test_test\n",
      "test mean loss=1157.3360595703125\n",
      "epoch 2456\n",
      "test_train\n",
      "train mean loss=0.08683935087174177\n",
      "test_test\n",
      "test mean loss=1156.8147888183594\n",
      "epoch 2457\n",
      "test_train\n",
      "train mean loss=0.08781445274750392\n",
      "test_test\n",
      "test mean loss=1157.0050048828125\n",
      "epoch 2458\n",
      "test_train\n",
      "train mean loss=0.09050699199239413\n",
      "test_test\n",
      "test mean loss=1157.2692565917969\n",
      "epoch 2459\n",
      "test_train\n",
      "train mean loss=0.13809732596079508\n",
      "test_test\n",
      "test mean loss=1159.3320007324219\n",
      "epoch 2460\n",
      "test_train\n",
      "train mean loss=0.09163845454653104\n",
      "test_test\n",
      "test mean loss=1156.7846069335938\n",
      "epoch 2461\n",
      "test_train\n",
      "train mean loss=0.13958009084065756\n",
      "test_test\n",
      "test mean loss=1158.3394165039062\n",
      "epoch 2462\n",
      "test_train\n",
      "train mean loss=0.09224748021612565\n",
      "test_test\n",
      "test mean loss=1155.9833679199219\n",
      "epoch 2463\n",
      "test_train\n",
      "train mean loss=0.10381183462838332\n",
      "test_test\n",
      "test mean loss=1156.0130615234375\n",
      "epoch 2464\n",
      "test_train\n",
      "train mean loss=0.09697756279880802\n",
      "test_test\n",
      "test mean loss=1156.2971801757812\n",
      "epoch 2465\n",
      "test_train\n",
      "train mean loss=0.1060685624058048\n",
      "test_test\n",
      "test mean loss=1156.9878540039062\n",
      "epoch 2466\n",
      "test_train\n",
      "train mean loss=0.09944144791613023\n",
      "test_test\n",
      "test mean loss=1156.33642578125\n",
      "epoch 2467\n",
      "test_train\n",
      "train mean loss=0.10265618904183309\n",
      "test_test\n",
      "test mean loss=1156.238525390625\n",
      "epoch 2468\n",
      "test_train\n",
      "train mean loss=0.09947140018145244\n",
      "test_test\n",
      "test mean loss=1156.0155334472656\n",
      "epoch 2469\n",
      "test_train\n",
      "train mean loss=0.09724732550481956\n",
      "test_test\n",
      "test mean loss=1157.0136413574219\n",
      "epoch 2470\n",
      "test_train\n",
      "train mean loss=0.09824673117448886\n",
      "test_test\n",
      "test mean loss=1156.2333679199219\n",
      "epoch 2471\n",
      "test_train\n",
      "train mean loss=0.099205550737679\n",
      "test_test\n",
      "test mean loss=1156.7974853515625\n",
      "epoch 2472\n",
      "test_train\n",
      "train mean loss=0.09318834667404492\n",
      "test_test\n",
      "test mean loss=1156.5978393554688\n",
      "epoch 2473\n",
      "test_train\n",
      "train mean loss=0.09220796544104815\n",
      "test_test\n",
      "test mean loss=1155.9837036132812\n",
      "epoch 2474\n",
      "test_train\n",
      "train mean loss=0.08903488734116156\n",
      "test_test\n",
      "test mean loss=1156.2663269042969\n",
      "epoch 2475\n",
      "test_train\n",
      "train mean loss=0.09108054699997108\n",
      "test_test\n",
      "test mean loss=1156.7819519042969\n",
      "epoch 2476\n",
      "test_train\n",
      "train mean loss=0.10105545787761609\n",
      "test_test\n",
      "test mean loss=1156.2368469238281\n",
      "epoch 2477\n",
      "test_train\n",
      "train mean loss=0.08922056512286265\n",
      "test_test\n",
      "test mean loss=1156.6082458496094\n",
      "epoch 2478\n",
      "test_train\n",
      "train mean loss=0.09725523460656404\n",
      "test_test\n",
      "test mean loss=1156.3218994140625\n",
      "epoch 2479\n",
      "test_train\n",
      "train mean loss=0.09274120597789685\n",
      "test_test\n",
      "test mean loss=1157.0755004882812\n",
      "epoch 2480\n",
      "test_train\n",
      "train mean loss=0.08900423906743526\n",
      "test_test\n",
      "test mean loss=1157.0758056640625\n",
      "epoch 2481\n",
      "test_train\n",
      "train mean loss=0.08942133374512196\n",
      "test_test\n",
      "test mean loss=1157.163818359375\n",
      "epoch 2482\n",
      "test_train\n",
      "train mean loss=0.08981712783376376\n",
      "test_test\n",
      "test mean loss=1157.0503540039062\n",
      "epoch 2483\n",
      "test_train\n",
      "train mean loss=0.09022256887207429\n",
      "test_test\n",
      "test mean loss=1156.5819702148438\n",
      "epoch 2484\n",
      "test_train\n",
      "train mean loss=0.09509985521435738\n",
      "test_test\n",
      "test mean loss=1156.2798767089844\n",
      "epoch 2485\n",
      "test_train\n",
      "train mean loss=0.09206482209265232\n",
      "test_test\n",
      "test mean loss=1156.4358215332031\n",
      "epoch 2486\n",
      "test_train\n",
      "train mean loss=0.09279796698441108\n",
      "test_test\n",
      "test mean loss=1156.219970703125\n",
      "epoch 2487\n",
      "test_train\n",
      "train mean loss=0.09152453889449437\n",
      "test_test\n",
      "test mean loss=1157.5772094726562\n",
      "epoch 2488\n",
      "test_train\n",
      "train mean loss=0.09410756236563127\n",
      "test_test\n",
      "test mean loss=1155.6316528320312\n",
      "epoch 2489\n",
      "test_train\n",
      "train mean loss=0.09716582049926122\n",
      "test_test\n",
      "test mean loss=1156.0472412109375\n",
      "epoch 2490\n",
      "test_train\n",
      "train mean loss=0.09731280306975047\n",
      "test_test\n",
      "test mean loss=1157.1058654785156\n",
      "epoch 2491\n",
      "test_train\n",
      "train mean loss=0.09455456988265117\n",
      "test_test\n",
      "test mean loss=1157.3880920410156\n",
      "epoch 2492\n",
      "test_train\n",
      "train mean loss=0.0984926363453269\n",
      "test_test\n",
      "test mean loss=1157.713623046875\n",
      "epoch 2493\n",
      "test_train\n",
      "train mean loss=0.09596026533593734\n",
      "test_test\n",
      "test mean loss=1155.9243469238281\n",
      "epoch 2494\n",
      "test_train\n",
      "train mean loss=0.09320096423228581\n",
      "test_test\n",
      "test mean loss=1155.6585388183594\n",
      "epoch 2495\n",
      "test_train\n",
      "train mean loss=0.13688033819198608\n",
      "test_test\n",
      "test mean loss=1158.5172729492188\n",
      "epoch 2496\n",
      "test_train\n",
      "train mean loss=0.09814986276129882\n",
      "test_test\n",
      "test mean loss=1156.6066284179688\n",
      "epoch 2497\n",
      "test_train\n",
      "train mean loss=0.3439349556962649\n",
      "test_test\n",
      "test mean loss=1155.3231201171875\n",
      "epoch 2498\n",
      "test_train\n",
      "train mean loss=0.10413668863475323\n",
      "test_test\n",
      "test mean loss=1155.3564758300781\n",
      "epoch 2499\n",
      "test_train\n",
      "train mean loss=0.09674487883845966\n",
      "test_test\n",
      "test mean loss=1155.0331420898438\n",
      "epoch 2500\n",
      "test_train\n",
      "train mean loss=0.09538102646668752\n",
      "test_test\n",
      "test mean loss=1155.7706909179688\n",
      "epoch 2501\n",
      "test_train\n",
      "train mean loss=0.08856315289934476\n",
      "test_test\n",
      "test mean loss=1154.9747924804688\n",
      "epoch 2502\n",
      "test_train\n",
      "train mean loss=0.09058450690160195\n",
      "test_test\n",
      "test mean loss=1155.1961059570312\n",
      "epoch 2503\n",
      "test_train\n",
      "train mean loss=0.09688647960623105\n",
      "test_test\n",
      "test mean loss=1155.9990234375\n",
      "epoch 2504\n",
      "test_train\n",
      "train mean loss=0.09349936495224635\n",
      "test_test\n",
      "test mean loss=1156.1038208007812\n",
      "epoch 2505\n",
      "test_train\n",
      "train mean loss=0.09613620179394881\n",
      "test_test\n",
      "test mean loss=1155.8182373046875\n",
      "epoch 2506\n",
      "test_train\n",
      "train mean loss=0.0936587726076444\n",
      "test_test\n",
      "test mean loss=1155.4021606445312\n",
      "epoch 2507\n",
      "test_train\n",
      "train mean loss=0.09727874615540107\n",
      "test_test\n",
      "test mean loss=1155.9813232421875\n",
      "epoch 2508\n",
      "test_train\n",
      "train mean loss=0.09070719126611948\n",
      "test_test\n",
      "test mean loss=1155.3501586914062\n",
      "epoch 2509\n",
      "test_train\n",
      "train mean loss=0.09953094770510991\n",
      "test_test\n",
      "test mean loss=1155.1409606933594\n",
      "epoch 2510\n",
      "test_train\n",
      "train mean loss=0.09718689477692048\n",
      "test_test\n",
      "test mean loss=1155.50927734375\n",
      "epoch 2511\n",
      "test_train\n",
      "train mean loss=0.08925108301142852\n",
      "test_test\n",
      "test mean loss=1155.2195434570312\n",
      "epoch 2512\n",
      "test_train\n",
      "train mean loss=0.08588660725702842\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1154.9966430664062\n",
      "epoch 2513\n",
      "test_train\n",
      "train mean loss=0.08845757351567347\n",
      "test_test\n",
      "test mean loss=1155.311279296875\n",
      "epoch 2514\n",
      "test_train\n",
      "train mean loss=0.09080155535290639\n",
      "test_test\n",
      "test mean loss=1155.4767456054688\n",
      "epoch 2515\n",
      "test_train\n",
      "train mean loss=0.09166109065214793\n",
      "test_test\n",
      "test mean loss=1154.4401245117188\n",
      "epoch 2516\n",
      "test_train\n",
      "train mean loss=0.0890691668416063\n",
      "test_test\n",
      "test mean loss=1155.550537109375\n",
      "epoch 2517\n",
      "test_train\n",
      "train mean loss=0.09419179645677407\n",
      "test_test\n",
      "test mean loss=1155.8344116210938\n",
      "epoch 2518\n",
      "test_train\n",
      "train mean loss=0.09493201474348704\n",
      "test_test\n",
      "test mean loss=1155.4385070800781\n",
      "epoch 2519\n",
      "test_train\n",
      "train mean loss=0.09640754790355761\n",
      "test_test\n",
      "test mean loss=1156.0115051269531\n",
      "epoch 2520\n",
      "test_train\n",
      "train mean loss=0.09130304989715417\n",
      "test_test\n",
      "test mean loss=1155.1138916015625\n",
      "epoch 2521\n",
      "test_train\n",
      "train mean loss=0.08736370348682006\n",
      "test_test\n",
      "test mean loss=1155.1364135742188\n",
      "epoch 2522\n",
      "test_train\n",
      "train mean loss=0.0920435410613815\n",
      "test_test\n",
      "test mean loss=1155.1613159179688\n",
      "epoch 2523\n",
      "test_train\n",
      "train mean loss=0.09180365378657977\n",
      "test_test\n",
      "test mean loss=1155.5194396972656\n",
      "epoch 2524\n",
      "test_train\n",
      "train mean loss=0.09109843398133914\n",
      "test_test\n",
      "test mean loss=1156.0557556152344\n",
      "epoch 2525\n",
      "test_train\n",
      "train mean loss=0.08977695849413674\n",
      "test_test\n",
      "test mean loss=1156.2839050292969\n",
      "epoch 2526\n",
      "test_train\n",
      "train mean loss=0.09406736275802056\n",
      "test_test\n",
      "test mean loss=1156.72216796875\n",
      "epoch 2527\n",
      "test_train\n",
      "train mean loss=0.08705190010368824\n",
      "test_test\n",
      "test mean loss=1156.8815307617188\n",
      "epoch 2528\n",
      "test_train\n",
      "train mean loss=0.09097843399892251\n",
      "test_test\n",
      "test mean loss=1156.8609619140625\n",
      "epoch 2529\n",
      "test_train\n",
      "train mean loss=0.0889216431727012\n",
      "test_test\n",
      "test mean loss=1156.6212158203125\n",
      "epoch 2530\n",
      "test_train\n",
      "train mean loss=0.09120677287379901\n",
      "test_test\n",
      "test mean loss=1157.2803955078125\n",
      "epoch 2531\n",
      "test_train\n",
      "train mean loss=0.09119952532152335\n",
      "test_test\n",
      "test mean loss=1156.7506103515625\n",
      "epoch 2532\n",
      "test_train\n",
      "train mean loss=0.09671253307412069\n",
      "test_test\n",
      "test mean loss=1157.3003234863281\n",
      "epoch 2533\n",
      "test_train\n",
      "train mean loss=0.09561936122675736\n",
      "test_test\n",
      "test mean loss=1157.2971801757812\n",
      "epoch 2534\n",
      "test_train\n",
      "train mean loss=0.08789752796292305\n",
      "test_test\n",
      "test mean loss=1155.7991943359375\n",
      "epoch 2535\n",
      "test_train\n",
      "train mean loss=0.09300711068014304\n",
      "test_test\n",
      "test mean loss=1157.2477416992188\n",
      "epoch 2536\n",
      "test_train\n",
      "train mean loss=0.08613541194548209\n",
      "test_test\n",
      "test mean loss=1157.1389770507812\n",
      "epoch 2537\n",
      "test_train\n",
      "train mean loss=0.09248372664054234\n",
      "test_test\n",
      "test mean loss=1157.1493530273438\n",
      "epoch 2538\n",
      "test_train\n",
      "train mean loss=0.08741106558591127\n",
      "test_test\n",
      "test mean loss=1155.895751953125\n",
      "epoch 2539\n",
      "test_train\n",
      "train mean loss=0.0885723577812314\n",
      "test_test\n",
      "test mean loss=1156.3719482421875\n",
      "epoch 2540\n",
      "test_train\n",
      "train mean loss=0.09521748373905818\n",
      "test_test\n",
      "test mean loss=1157.8096313476562\n",
      "epoch 2541\n",
      "test_train\n",
      "train mean loss=0.09163670645405848\n",
      "test_test\n",
      "test mean loss=1157.2824401855469\n",
      "epoch 2542\n",
      "test_train\n",
      "train mean loss=0.09129989799112082\n",
      "test_test\n",
      "test mean loss=1158.7591552734375\n",
      "epoch 2543\n",
      "test_train\n",
      "train mean loss=0.09873109435041745\n",
      "test_test\n",
      "test mean loss=1158.8656005859375\n",
      "epoch 2544\n",
      "test_train\n",
      "train mean loss=0.08805585807810228\n",
      "test_test\n",
      "test mean loss=1157.830322265625\n",
      "epoch 2545\n",
      "test_train\n",
      "train mean loss=0.09160464225957791\n",
      "test_test\n",
      "test mean loss=1157.8235778808594\n",
      "epoch 2546\n",
      "test_train\n",
      "train mean loss=0.08795704847822587\n",
      "test_test\n",
      "test mean loss=1157.0065307617188\n",
      "epoch 2547\n",
      "test_train\n",
      "train mean loss=0.08866461211194594\n",
      "test_test\n",
      "test mean loss=1157.0928344726562\n",
      "epoch 2548\n",
      "test_train\n",
      "train mean loss=0.08694280373553435\n",
      "test_test\n",
      "test mean loss=1156.620849609375\n",
      "epoch 2549\n",
      "test_train\n",
      "train mean loss=0.09920416896541913\n",
      "test_test\n",
      "test mean loss=1158.1239013671875\n",
      "epoch 2550\n",
      "test_train\n",
      "train mean loss=0.08774745836853981\n",
      "test_test\n",
      "test mean loss=1156.400634765625\n",
      "epoch 2551\n",
      "test_train\n",
      "train mean loss=0.08877591819812854\n",
      "test_test\n",
      "test mean loss=1157.73828125\n",
      "epoch 2552\n",
      "test_train\n",
      "train mean loss=0.09395864699035883\n",
      "test_test\n",
      "test mean loss=1157.0914306640625\n",
      "epoch 2553\n",
      "test_train\n",
      "train mean loss=0.08758387435227633\n",
      "test_test\n",
      "test mean loss=1156.8690795898438\n",
      "epoch 2554\n",
      "test_train\n",
      "train mean loss=0.08914880796025197\n",
      "test_test\n",
      "test mean loss=1157.5197143554688\n",
      "epoch 2555\n",
      "test_train\n",
      "train mean loss=0.09008402625719707\n",
      "test_test\n",
      "test mean loss=1158.327880859375\n",
      "epoch 2556\n",
      "test_train\n",
      "train mean loss=0.09297472766290109\n",
      "test_test\n",
      "test mean loss=1156.2349243164062\n",
      "epoch 2557\n",
      "test_train\n",
      "train mean loss=0.087956625657777\n",
      "test_test\n",
      "test mean loss=1157.2868041992188\n",
      "epoch 2558\n",
      "test_train\n",
      "train mean loss=0.08942942228168249\n",
      "test_test\n",
      "test mean loss=1157.6228637695312\n",
      "epoch 2559\n",
      "test_train\n",
      "train mean loss=0.09668267083664735\n",
      "test_test\n",
      "test mean loss=1157.1606140136719\n",
      "epoch 2560\n",
      "test_train\n",
      "train mean loss=0.09055612764010827\n",
      "test_test\n",
      "test mean loss=1157.7363891601562\n",
      "epoch 2561\n",
      "test_train\n",
      "train mean loss=0.08558602041254441\n",
      "test_test\n",
      "test mean loss=1156.604736328125\n",
      "epoch 2562\n",
      "test_train\n",
      "train mean loss=0.08278954618920882\n",
      "test_test\n",
      "test mean loss=1157.080322265625\n",
      "epoch 2563\n",
      "test_train\n",
      "train mean loss=0.0890570127715667\n",
      "test_test\n",
      "test mean loss=1156.83154296875\n",
      "epoch 2564\n",
      "test_train\n",
      "train mean loss=0.09492403051505487\n",
      "test_test\n",
      "test mean loss=1157.0494995117188\n",
      "epoch 2565\n",
      "test_train\n",
      "train mean loss=0.08933210745453835\n",
      "test_test\n",
      "test mean loss=1157.2541809082031\n",
      "epoch 2566\n",
      "test_train\n",
      "train mean loss=0.08942922577261925\n",
      "test_test\n",
      "test mean loss=1156.8399963378906\n",
      "epoch 2567\n",
      "test_train\n",
      "train mean loss=0.08863893989473581\n",
      "test_test\n",
      "test mean loss=1156.594482421875\n",
      "epoch 2568\n",
      "test_train\n",
      "train mean loss=0.09881708212196827\n",
      "test_test\n",
      "test mean loss=1156.952880859375\n",
      "epoch 2569\n",
      "test_train\n",
      "train mean loss=0.08866002721091111\n",
      "test_test\n",
      "test mean loss=1156.7166137695312\n",
      "epoch 2570\n",
      "test_train\n",
      "train mean loss=0.0886174663901329\n",
      "test_test\n",
      "test mean loss=1157.2318725585938\n",
      "epoch 2571\n",
      "test_train\n",
      "train mean loss=0.08965825972457726\n",
      "test_test\n",
      "test mean loss=1156.3141784667969\n",
      "epoch 2572\n",
      "test_train\n",
      "train mean loss=0.09125742005805175\n",
      "test_test\n",
      "test mean loss=1155.6892700195312\n",
      "epoch 2573\n",
      "test_train\n",
      "train mean loss=0.10757580151160558\n",
      "test_test\n",
      "test mean loss=1156.6166381835938\n",
      "epoch 2574\n",
      "test_train\n",
      "train mean loss=0.09421650289247434\n",
      "test_test\n",
      "test mean loss=1156.7018432617188\n",
      "epoch 2575\n",
      "test_train\n",
      "train mean loss=0.09005236563583215\n",
      "test_test\n",
      "test mean loss=1157.0897521972656\n",
      "epoch 2576\n",
      "test_train\n",
      "train mean loss=0.08624243487914403\n",
      "test_test\n",
      "test mean loss=1157.5784301757812\n",
      "epoch 2577\n",
      "test_train\n",
      "train mean loss=0.09086830851932366\n",
      "test_test\n",
      "test mean loss=1157.3419799804688\n",
      "epoch 2578\n",
      "test_train\n",
      "train mean loss=0.09105573501437902\n",
      "test_test\n",
      "test mean loss=1155.8856201171875\n",
      "epoch 2579\n",
      "test_train\n",
      "train mean loss=0.08788720797747374\n",
      "test_test\n",
      "test mean loss=1156.8598022460938\n",
      "epoch 2580\n",
      "test_train\n",
      "train mean loss=0.094917600043118\n",
      "test_test\n",
      "test mean loss=1158.4054565429688\n",
      "epoch 2581\n",
      "test_train\n",
      "train mean loss=0.09315685338030259\n",
      "test_test\n",
      "test mean loss=1157.3997802734375\n",
      "epoch 2582\n",
      "test_train\n",
      "train mean loss=0.08364295493811369\n",
      "test_test\n",
      "test mean loss=1156.90771484375\n",
      "epoch 2583\n",
      "test_train\n",
      "train mean loss=0.08779298669348161\n",
      "test_test\n",
      "test mean loss=1157.220947265625\n",
      "epoch 2584\n",
      "test_train\n",
      "train mean loss=0.08668669840941827\n",
      "test_test\n",
      "test mean loss=1158.2393188476562\n",
      "epoch 2585\n",
      "test_train\n",
      "train mean loss=0.08594333504637082\n",
      "test_test\n",
      "test mean loss=1156.8168334960938\n",
      "epoch 2586\n",
      "test_train\n",
      "train mean loss=0.08943335649867852\n",
      "test_test\n",
      "test mean loss=1158.3048706054688\n",
      "epoch 2587\n",
      "test_train\n",
      "train mean loss=0.089974794536829\n",
      "test_test\n",
      "test mean loss=1156.809814453125\n",
      "epoch 2588\n",
      "test_train\n",
      "train mean loss=0.09466464320818584\n",
      "test_test\n",
      "test mean loss=1158.3143920898438\n",
      "epoch 2589\n",
      "test_train\n",
      "train mean loss=0.08510354223350684\n",
      "test_test\n",
      "test mean loss=1157.2622985839844\n",
      "epoch 2590\n",
      "test_train\n",
      "train mean loss=0.08981156970063846\n",
      "test_test\n",
      "test mean loss=1157.8868713378906\n",
      "epoch 2591\n",
      "test_train\n",
      "train mean loss=0.09798118254790704\n",
      "test_test\n",
      "test mean loss=1157.6558837890625\n",
      "epoch 2592\n",
      "test_train\n",
      "train mean loss=0.09338870209952195\n",
      "test_test\n",
      "test mean loss=1158.1923828125\n",
      "epoch 2593\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.08827753116687138\n",
      "test_test\n",
      "test mean loss=1157.2732543945312\n",
      "epoch 2594\n",
      "test_train\n",
      "train mean loss=0.08815765008330345\n",
      "test_test\n",
      "test mean loss=1156.4987182617188\n",
      "epoch 2595\n",
      "test_train\n",
      "train mean loss=0.09018995488683383\n",
      "test_test\n",
      "test mean loss=1156.7611083984375\n",
      "epoch 2596\n",
      "test_train\n",
      "train mean loss=0.09487731568515301\n",
      "test_test\n",
      "test mean loss=1156.7522277832031\n",
      "epoch 2597\n",
      "test_train\n",
      "train mean loss=0.08983592999478181\n",
      "test_test\n",
      "test mean loss=1156.3627319335938\n",
      "epoch 2598\n",
      "test_train\n",
      "train mean loss=0.08720643321673076\n",
      "test_test\n",
      "test mean loss=1157.2715454101562\n",
      "epoch 2599\n",
      "test_train\n",
      "train mean loss=0.09055147009591262\n",
      "test_test\n",
      "test mean loss=1157.4690856933594\n",
      "epoch 2600\n",
      "test_train\n",
      "train mean loss=0.08600059244781733\n",
      "test_test\n",
      "test mean loss=1156.9047241210938\n",
      "epoch 2601\n",
      "test_train\n",
      "train mean loss=0.09279764288415511\n",
      "test_test\n",
      "test mean loss=1158.000732421875\n",
      "epoch 2602\n",
      "test_train\n",
      "train mean loss=0.09822468397517999\n",
      "test_test\n",
      "test mean loss=1156.2693176269531\n",
      "epoch 2603\n",
      "test_train\n",
      "train mean loss=0.09302062882731359\n",
      "test_test\n",
      "test mean loss=1156.1577758789062\n",
      "epoch 2604\n",
      "test_train\n",
      "train mean loss=0.08843952665726344\n",
      "test_test\n",
      "test mean loss=1156.3977661132812\n",
      "epoch 2605\n",
      "test_train\n",
      "train mean loss=0.085417989641428\n",
      "test_test\n",
      "test mean loss=1156.1921997070312\n",
      "epoch 2606\n",
      "test_train\n",
      "train mean loss=0.10001704841852188\n",
      "test_test\n",
      "test mean loss=1156.778076171875\n",
      "epoch 2607\n",
      "test_train\n",
      "train mean loss=0.09473458491265774\n",
      "test_test\n",
      "test mean loss=1156.54150390625\n",
      "epoch 2608\n",
      "test_train\n",
      "train mean loss=0.09479854504267375\n",
      "test_test\n",
      "test mean loss=1156.2778015136719\n",
      "epoch 2609\n",
      "test_train\n",
      "train mean loss=0.095623383919398\n",
      "test_test\n",
      "test mean loss=1156.6917419433594\n",
      "epoch 2610\n",
      "test_train\n",
      "train mean loss=0.0902676194285353\n",
      "test_test\n",
      "test mean loss=1156.5410766601562\n",
      "epoch 2611\n",
      "test_train\n",
      "train mean loss=0.08644474235673745\n",
      "test_test\n",
      "test mean loss=1157.118896484375\n",
      "epoch 2612\n",
      "test_train\n",
      "train mean loss=0.09364823686579864\n",
      "test_test\n",
      "test mean loss=1157.7286376953125\n",
      "epoch 2613\n",
      "test_train\n",
      "train mean loss=0.091853483269612\n",
      "test_test\n",
      "test mean loss=1157.4216613769531\n",
      "epoch 2614\n",
      "test_train\n",
      "train mean loss=0.08696875565995772\n",
      "test_test\n",
      "test mean loss=1156.3256225585938\n",
      "epoch 2615\n",
      "test_train\n",
      "train mean loss=0.09212336068352063\n",
      "test_test\n",
      "test mean loss=1156.4825134277344\n",
      "epoch 2616\n",
      "test_train\n",
      "train mean loss=0.09379119891673326\n",
      "test_test\n",
      "test mean loss=1156.5407104492188\n",
      "epoch 2617\n",
      "test_train\n",
      "train mean loss=0.08983748468259971\n",
      "test_test\n",
      "test mean loss=1156.6762390136719\n",
      "epoch 2618\n",
      "test_train\n",
      "train mean loss=0.09245037597914536\n",
      "test_test\n",
      "test mean loss=1156.7455139160156\n",
      "epoch 2619\n",
      "test_train\n",
      "train mean loss=0.09576098496715228\n",
      "test_test\n",
      "test mean loss=1156.1338806152344\n",
      "epoch 2620\n",
      "test_train\n",
      "train mean loss=0.0860466534892718\n",
      "test_test\n",
      "test mean loss=1155.2495727539062\n",
      "epoch 2621\n",
      "test_train\n",
      "train mean loss=0.09736867186923821\n",
      "test_test\n",
      "test mean loss=1157.26708984375\n",
      "epoch 2622\n",
      "test_train\n",
      "train mean loss=0.08822920639067888\n",
      "test_test\n",
      "test mean loss=1156.932861328125\n",
      "epoch 2623\n",
      "test_train\n",
      "train mean loss=0.09131599062432845\n",
      "test_test\n",
      "test mean loss=1156.7083740234375\n",
      "epoch 2624\n",
      "test_train\n",
      "train mean loss=0.09432013798505068\n",
      "test_test\n",
      "test mean loss=1155.9608764648438\n",
      "epoch 2625\n",
      "test_train\n",
      "train mean loss=0.08556881158923109\n",
      "test_test\n",
      "test mean loss=1156.3053588867188\n",
      "epoch 2626\n",
      "test_train\n",
      "train mean loss=0.08646978003283341\n",
      "test_test\n",
      "test mean loss=1156.7259216308594\n",
      "epoch 2627\n",
      "test_train\n",
      "train mean loss=0.09385486940542857\n",
      "test_test\n",
      "test mean loss=1156.48779296875\n",
      "epoch 2628\n",
      "test_train\n",
      "train mean loss=0.09187487792223692\n",
      "test_test\n",
      "test mean loss=1156.1010131835938\n",
      "epoch 2629\n",
      "test_train\n",
      "train mean loss=0.08736449107527733\n",
      "test_test\n",
      "test mean loss=1157.5696716308594\n",
      "epoch 2630\n",
      "test_train\n",
      "train mean loss=0.09369560951987903\n",
      "test_test\n",
      "test mean loss=1157.7460632324219\n",
      "epoch 2631\n",
      "test_train\n",
      "train mean loss=0.09602116917570432\n",
      "test_test\n",
      "test mean loss=1158.0510864257812\n",
      "epoch 2632\n",
      "test_train\n",
      "train mean loss=0.08975503252198298\n",
      "test_test\n",
      "test mean loss=1157.4369812011719\n",
      "epoch 2633\n",
      "test_train\n",
      "train mean loss=0.10290985958029826\n",
      "test_test\n",
      "test mean loss=1156.6697082519531\n",
      "epoch 2634\n",
      "test_train\n",
      "train mean loss=0.08888295385986567\n",
      "test_test\n",
      "test mean loss=1156.5568237304688\n",
      "epoch 2635\n",
      "test_train\n",
      "train mean loss=0.0925480779260397\n",
      "test_test\n",
      "test mean loss=1157.2076416015625\n",
      "epoch 2636\n",
      "test_train\n",
      "train mean loss=0.09342978708446026\n",
      "test_test\n",
      "test mean loss=1157.2279357910156\n",
      "epoch 2637\n",
      "test_train\n",
      "train mean loss=0.09233988138536613\n",
      "test_test\n",
      "test mean loss=1157.0377502441406\n",
      "epoch 2638\n",
      "test_train\n",
      "train mean loss=0.08759560870627563\n",
      "test_test\n",
      "test mean loss=1157.103515625\n",
      "epoch 2639\n",
      "test_train\n",
      "train mean loss=0.09602841424445312\n",
      "test_test\n",
      "test mean loss=1158.002685546875\n",
      "epoch 2640\n",
      "test_train\n",
      "train mean loss=0.23246839394172034\n",
      "test_test\n",
      "test mean loss=1159.0547485351562\n",
      "epoch 2641\n",
      "test_train\n",
      "train mean loss=0.09941405989229679\n",
      "test_test\n",
      "test mean loss=1159.0248718261719\n",
      "epoch 2642\n",
      "test_train\n",
      "train mean loss=0.09704968674729268\n",
      "test_test\n",
      "test mean loss=1157.7527465820312\n",
      "epoch 2643\n",
      "test_train\n",
      "train mean loss=0.09818593164285024\n",
      "test_test\n",
      "test mean loss=1157.5288696289062\n",
      "epoch 2644\n",
      "test_train\n",
      "train mean loss=0.09907662744323413\n",
      "test_test\n",
      "test mean loss=1157.2054748535156\n",
      "epoch 2645\n",
      "test_train\n",
      "train mean loss=0.09556940104812384\n",
      "test_test\n",
      "test mean loss=1155.7828674316406\n",
      "epoch 2646\n",
      "test_train\n",
      "train mean loss=0.0900977614025275\n",
      "test_test\n",
      "test mean loss=1156.8204345703125\n",
      "epoch 2647\n",
      "test_train\n",
      "train mean loss=0.09725694327304761\n",
      "test_test\n",
      "test mean loss=1157.7672729492188\n",
      "epoch 2648\n",
      "test_train\n",
      "train mean loss=0.09925460629165173\n",
      "test_test\n",
      "test mean loss=1157.0742492675781\n",
      "epoch 2649\n",
      "test_train\n",
      "train mean loss=0.09716194123029709\n",
      "test_test\n",
      "test mean loss=1156.69189453125\n",
      "epoch 2650\n",
      "test_train\n",
      "train mean loss=0.08824571315199137\n",
      "test_test\n",
      "test mean loss=1156.069091796875\n",
      "epoch 2651\n",
      "test_train\n",
      "train mean loss=0.09310633813341458\n",
      "test_test\n",
      "test mean loss=1157.223876953125\n",
      "epoch 2652\n",
      "test_train\n",
      "train mean loss=0.10795771144330502\n",
      "test_test\n",
      "test mean loss=1158.0625\n",
      "epoch 2653\n",
      "test_train\n",
      "train mean loss=0.09825086841980617\n",
      "test_test\n",
      "test mean loss=1157.4226684570312\n",
      "epoch 2654\n",
      "test_train\n",
      "train mean loss=0.09458085925628741\n",
      "test_test\n",
      "test mean loss=1156.7489929199219\n",
      "epoch 2655\n",
      "test_train\n",
      "train mean loss=0.08479916925231616\n",
      "test_test\n",
      "test mean loss=1157.2630615234375\n",
      "epoch 2656\n",
      "test_train\n",
      "train mean loss=0.08974572581549485\n",
      "test_test\n",
      "test mean loss=1156.93896484375\n",
      "epoch 2657\n",
      "test_train\n",
      "train mean loss=0.1066720758875211\n",
      "test_test\n",
      "test mean loss=1156.2120056152344\n",
      "epoch 2658\n",
      "test_train\n",
      "train mean loss=0.09771778093030055\n",
      "test_test\n",
      "test mean loss=1156.767333984375\n",
      "epoch 2659\n",
      "test_train\n",
      "train mean loss=0.09092346703012784\n",
      "test_test\n",
      "test mean loss=1156.5609130859375\n",
      "epoch 2660\n",
      "test_train\n",
      "train mean loss=0.0943642994388938\n",
      "test_test\n",
      "test mean loss=1157.7146911621094\n",
      "epoch 2661\n",
      "test_train\n",
      "train mean loss=0.1012971643358469\n",
      "test_test\n",
      "test mean loss=1157.1676635742188\n",
      "epoch 2662\n",
      "test_train\n",
      "train mean loss=0.0882891807705164\n",
      "test_test\n",
      "test mean loss=1157.1570129394531\n",
      "epoch 2663\n",
      "test_train\n",
      "train mean loss=0.08892190534000595\n",
      "test_test\n",
      "test mean loss=1155.7713012695312\n",
      "epoch 2664\n",
      "test_train\n",
      "train mean loss=0.09419016353785992\n",
      "test_test\n",
      "test mean loss=1157.5122680664062\n",
      "epoch 2665\n",
      "test_train\n",
      "train mean loss=0.09348311368376017\n",
      "test_test\n",
      "test mean loss=1157.4508972167969\n",
      "epoch 2666\n",
      "test_train\n",
      "train mean loss=0.12773698257903257\n",
      "test_test\n",
      "test mean loss=1155.8781433105469\n",
      "epoch 2667\n",
      "test_train\n",
      "train mean loss=0.09234879538416862\n",
      "test_test\n",
      "test mean loss=1157.0051879882812\n",
      "epoch 2668\n",
      "test_train\n",
      "train mean loss=0.09908090066164732\n",
      "test_test\n",
      "test mean loss=1155.7824096679688\n",
      "epoch 2669\n",
      "test_train\n",
      "train mean loss=0.08997189688185851\n",
      "test_test\n",
      "test mean loss=1155.9566345214844\n",
      "epoch 2670\n",
      "test_train\n",
      "train mean loss=0.08734664879739285\n",
      "test_test\n",
      "test mean loss=1156.5673217773438\n",
      "epoch 2671\n",
      "test_train\n",
      "train mean loss=0.9782905330260595\n",
      "test_test\n",
      "test mean loss=1156.0085144042969\n",
      "epoch 2672\n",
      "test_train\n",
      "train mean loss=0.10926565621048212\n",
      "test_test\n",
      "test mean loss=1157.7642822265625\n",
      "epoch 2673\n",
      "test_train\n",
      "train mean loss=0.09453048122425874\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1156.6410522460938\n",
      "epoch 2674\n",
      "test_train\n",
      "train mean loss=0.09556981269270182\n",
      "test_test\n",
      "test mean loss=1156.5360107421875\n",
      "epoch 2675\n",
      "test_train\n",
      "train mean loss=0.0917609641328454\n",
      "test_test\n",
      "test mean loss=1156.552978515625\n",
      "epoch 2676\n",
      "test_train\n",
      "train mean loss=0.09111157339066267\n",
      "test_test\n",
      "test mean loss=1156.257568359375\n",
      "epoch 2677\n",
      "test_train\n",
      "train mean loss=0.08927794049183528\n",
      "test_test\n",
      "test mean loss=1156.4849853515625\n",
      "epoch 2678\n",
      "test_train\n",
      "train mean loss=0.085570325764517\n",
      "test_test\n",
      "test mean loss=1156.5929565429688\n",
      "epoch 2679\n",
      "test_train\n",
      "train mean loss=0.09210729598999023\n",
      "test_test\n",
      "test mean loss=1155.9586791992188\n",
      "epoch 2680\n",
      "test_train\n",
      "train mean loss=0.1453256874034802\n",
      "test_test\n",
      "test mean loss=1153.7203979492188\n",
      "epoch 2681\n",
      "test_train\n",
      "train mean loss=0.09660520032048225\n",
      "test_test\n",
      "test mean loss=1156.5406188964844\n",
      "epoch 2682\n",
      "test_train\n",
      "train mean loss=0.08603100509693225\n",
      "test_test\n",
      "test mean loss=1156.1460876464844\n",
      "epoch 2683\n",
      "test_train\n",
      "train mean loss=0.09144980072354277\n",
      "test_test\n",
      "test mean loss=1155.8438110351562\n",
      "epoch 2684\n",
      "test_train\n",
      "train mean loss=0.0933104179178675\n",
      "test_test\n",
      "test mean loss=1157.7376708984375\n",
      "epoch 2685\n",
      "test_train\n",
      "train mean loss=0.21870372568567595\n",
      "test_test\n",
      "test mean loss=1158.9595947265625\n",
      "epoch 2686\n",
      "test_train\n",
      "train mean loss=0.09761593428750832\n",
      "test_test\n",
      "test mean loss=1157.8612060546875\n",
      "epoch 2687\n",
      "test_train\n",
      "train mean loss=0.092368652112782\n",
      "test_test\n",
      "test mean loss=1156.8408813476562\n",
      "epoch 2688\n",
      "test_train\n",
      "train mean loss=0.30037152394652367\n",
      "test_test\n",
      "test mean loss=1156.8922119140625\n",
      "epoch 2689\n",
      "test_train\n",
      "train mean loss=0.1141082759325703\n",
      "test_test\n",
      "test mean loss=1156.871337890625\n",
      "epoch 2690\n",
      "test_train\n",
      "train mean loss=0.09000190999358892\n",
      "test_test\n",
      "test mean loss=1156.5741882324219\n",
      "epoch 2691\n",
      "test_train\n",
      "train mean loss=0.0886033143227299\n",
      "test_test\n",
      "test mean loss=1155.9932250976562\n",
      "epoch 2692\n",
      "test_train\n",
      "train mean loss=0.08915677666664124\n",
      "test_test\n",
      "test mean loss=1156.2474060058594\n",
      "epoch 2693\n",
      "test_train\n",
      "train mean loss=0.09149314711491267\n",
      "test_test\n",
      "test mean loss=1156.3532104492188\n",
      "epoch 2694\n",
      "test_train\n",
      "train mean loss=0.09085395808021228\n",
      "test_test\n",
      "test mean loss=1156.392578125\n",
      "epoch 2695\n",
      "test_train\n",
      "train mean loss=0.09366223712762196\n",
      "test_test\n",
      "test mean loss=1156.3007202148438\n",
      "epoch 2696\n",
      "test_train\n",
      "train mean loss=0.0853631819287936\n",
      "test_test\n",
      "test mean loss=1155.860107421875\n",
      "epoch 2697\n",
      "test_train\n",
      "train mean loss=0.10643457093586524\n",
      "test_test\n",
      "test mean loss=1157.865234375\n",
      "epoch 2698\n",
      "test_train\n",
      "train mean loss=0.09207711555063725\n",
      "test_test\n",
      "test mean loss=1156.2437744140625\n",
      "epoch 2699\n",
      "test_train\n",
      "train mean loss=0.08633230750759442\n",
      "test_test\n",
      "test mean loss=1157.0955200195312\n",
      "epoch 2700\n",
      "test_train\n",
      "train mean loss=0.0900066668788592\n",
      "test_test\n",
      "test mean loss=1157.0403442382812\n",
      "epoch 2701\n",
      "test_train\n",
      "train mean loss=0.0841049508502086\n",
      "test_test\n",
      "test mean loss=1157.4257202148438\n",
      "epoch 2702\n",
      "test_train\n",
      "train mean loss=0.0810693521052599\n",
      "test_test\n",
      "test mean loss=1156.6102294921875\n",
      "epoch 2703\n",
      "test_train\n",
      "train mean loss=0.10888288356363773\n",
      "test_test\n",
      "test mean loss=1155.5517578125\n",
      "epoch 2704\n",
      "test_train\n",
      "train mean loss=0.08892132497082154\n",
      "test_test\n",
      "test mean loss=1157.2212524414062\n",
      "epoch 2705\n",
      "test_train\n",
      "train mean loss=0.0849100702131788\n",
      "test_test\n",
      "test mean loss=1157.3492431640625\n",
      "epoch 2706\n",
      "test_train\n",
      "train mean loss=0.08598583657294512\n",
      "test_test\n",
      "test mean loss=1157.69873046875\n",
      "epoch 2707\n",
      "test_train\n",
      "train mean loss=0.09126290120184422\n",
      "test_test\n",
      "test mean loss=1157.882568359375\n",
      "epoch 2708\n",
      "test_train\n",
      "train mean loss=0.0864703319966793\n",
      "test_test\n",
      "test mean loss=1156.40966796875\n",
      "epoch 2709\n",
      "test_train\n",
      "train mean loss=0.09181468281894922\n",
      "test_test\n",
      "test mean loss=1157.1233520507812\n",
      "epoch 2710\n",
      "test_train\n",
      "train mean loss=0.1777898178746303\n",
      "test_test\n",
      "test mean loss=1156.9393310546875\n",
      "epoch 2711\n",
      "test_train\n",
      "train mean loss=0.10231471341103315\n",
      "test_test\n",
      "test mean loss=1155.7838745117188\n",
      "epoch 2712\n",
      "test_train\n",
      "train mean loss=0.09790079109370708\n",
      "test_test\n",
      "test mean loss=1157.0524597167969\n",
      "epoch 2713\n",
      "test_train\n",
      "train mean loss=0.09725176511953275\n",
      "test_test\n",
      "test mean loss=1158.5465393066406\n",
      "epoch 2714\n",
      "test_train\n",
      "train mean loss=0.08657417818903923\n",
      "test_test\n",
      "test mean loss=1157.2542419433594\n",
      "epoch 2715\n",
      "test_train\n",
      "train mean loss=0.0848841741681099\n",
      "test_test\n",
      "test mean loss=1157.3013305664062\n",
      "epoch 2716\n",
      "test_train\n",
      "train mean loss=0.08389411525179942\n",
      "test_test\n",
      "test mean loss=1157.202392578125\n",
      "epoch 2717\n",
      "test_train\n",
      "train mean loss=0.08560287207365036\n",
      "test_test\n",
      "test mean loss=1157.1907348632812\n",
      "epoch 2718\n",
      "test_train\n",
      "train mean loss=0.08980112584928672\n",
      "test_test\n",
      "test mean loss=1157.9442749023438\n",
      "epoch 2719\n",
      "test_train\n",
      "train mean loss=0.08305967847506206\n",
      "test_test\n",
      "test mean loss=1157.2828979492188\n",
      "epoch 2720\n",
      "test_train\n",
      "train mean loss=0.0968288170794646\n",
      "test_test\n",
      "test mean loss=1157.8428344726562\n",
      "epoch 2721\n",
      "test_train\n",
      "train mean loss=0.09345633909106255\n",
      "test_test\n",
      "test mean loss=1157.77587890625\n",
      "epoch 2722\n",
      "test_train\n",
      "train mean loss=0.08767359890043736\n",
      "test_test\n",
      "test mean loss=1157.3441467285156\n",
      "epoch 2723\n",
      "test_train\n",
      "train mean loss=0.09152321579555671\n",
      "test_test\n",
      "test mean loss=1157.5138549804688\n",
      "epoch 2724\n",
      "test_train\n",
      "train mean loss=0.08851995412260294\n",
      "test_test\n",
      "test mean loss=1157.2043762207031\n",
      "epoch 2725\n",
      "test_train\n",
      "train mean loss=0.09084113283703725\n",
      "test_test\n",
      "test mean loss=1157.7612915039062\n",
      "epoch 2726\n",
      "test_train\n",
      "train mean loss=0.08973962161689997\n",
      "test_test\n",
      "test mean loss=1157.2186889648438\n",
      "epoch 2727\n",
      "test_train\n",
      "train mean loss=0.0928059524546067\n",
      "test_test\n",
      "test mean loss=1156.8365478515625\n",
      "epoch 2728\n",
      "test_train\n",
      "train mean loss=0.08579047241558631\n",
      "test_test\n",
      "test mean loss=1155.9861450195312\n",
      "epoch 2729\n",
      "test_train\n",
      "train mean loss=0.08969652590652306\n",
      "test_test\n",
      "test mean loss=1155.9790649414062\n",
      "epoch 2730\n",
      "test_train\n",
      "train mean loss=0.086850106716156\n",
      "test_test\n",
      "test mean loss=1156.8206787109375\n",
      "epoch 2731\n",
      "test_train\n",
      "train mean loss=0.09073370322585106\n",
      "test_test\n",
      "test mean loss=1157.1514892578125\n",
      "epoch 2732\n",
      "test_train\n",
      "train mean loss=0.09402439743280411\n",
      "test_test\n",
      "test mean loss=1156.6854858398438\n",
      "epoch 2733\n",
      "test_train\n",
      "train mean loss=0.10171619988977909\n",
      "test_test\n",
      "test mean loss=1156.980712890625\n",
      "epoch 2734\n",
      "test_train\n",
      "train mean loss=0.09441140790780385\n",
      "test_test\n",
      "test mean loss=1155.8511962890625\n",
      "epoch 2735\n",
      "test_train\n",
      "train mean loss=0.09234394319355488\n",
      "test_test\n",
      "test mean loss=1156.4041137695312\n",
      "epoch 2736\n",
      "test_train\n",
      "train mean loss=0.08354156604036689\n",
      "test_test\n",
      "test mean loss=1156.3303833007812\n",
      "epoch 2737\n",
      "test_train\n",
      "train mean loss=0.08736460749059916\n",
      "test_test\n",
      "test mean loss=1155.9765014648438\n",
      "epoch 2738\n",
      "test_train\n",
      "train mean loss=0.0922809016580383\n",
      "test_test\n",
      "test mean loss=1156.5933227539062\n",
      "epoch 2739\n",
      "test_train\n",
      "train mean loss=0.09244000415007274\n",
      "test_test\n",
      "test mean loss=1156.9518737792969\n",
      "epoch 2740\n",
      "test_train\n",
      "train mean loss=0.09272574912756681\n",
      "test_test\n",
      "test mean loss=1156.4714660644531\n",
      "epoch 2741\n",
      "test_train\n",
      "train mean loss=0.0886168625826637\n",
      "test_test\n",
      "test mean loss=1155.1082153320312\n",
      "epoch 2742\n",
      "test_train\n",
      "train mean loss=0.08387620840221643\n",
      "test_test\n",
      "test mean loss=1154.9313354492188\n",
      "epoch 2743\n",
      "test_train\n",
      "train mean loss=0.12711825159688792\n",
      "test_test\n",
      "test mean loss=1154.560302734375\n",
      "epoch 2744\n",
      "test_train\n",
      "train mean loss=0.09555556997656822\n",
      "test_test\n",
      "test mean loss=1156.0249633789062\n",
      "epoch 2745\n",
      "test_train\n",
      "train mean loss=0.085872999082009\n",
      "test_test\n",
      "test mean loss=1155.857421875\n",
      "epoch 2746\n",
      "test_train\n",
      "train mean loss=0.08760569694762428\n",
      "test_test\n",
      "test mean loss=1155.3753051757812\n",
      "epoch 2747\n",
      "test_train\n",
      "train mean loss=0.0864513423293829\n",
      "test_test\n",
      "test mean loss=1155.4555053710938\n",
      "epoch 2748\n",
      "test_train\n",
      "train mean loss=0.08652124926447868\n",
      "test_test\n",
      "test mean loss=1156.6541748046875\n",
      "epoch 2749\n",
      "test_train\n",
      "train mean loss=0.12353426218032837\n",
      "test_test\n",
      "test mean loss=1157.4685668945312\n",
      "epoch 2750\n",
      "test_train\n",
      "train mean loss=0.09080140603085358\n",
      "test_test\n",
      "test mean loss=1157.0883483886719\n",
      "epoch 2751\n",
      "test_train\n",
      "train mean loss=0.08749924910565217\n",
      "test_test\n",
      "test mean loss=1157.144287109375\n",
      "epoch 2752\n",
      "test_train\n",
      "train mean loss=0.08172848292936881\n",
      "test_test\n",
      "test mean loss=1156.7570495605469\n",
      "epoch 2753\n",
      "test_train\n",
      "train mean loss=0.08438488002866507\n",
      "test_test\n",
      "test mean loss=1156.9046325683594\n",
      "epoch 2754\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.09494114791353543\n",
      "test_test\n",
      "test mean loss=1156.9098510742188\n",
      "epoch 2755\n",
      "test_train\n",
      "train mean loss=0.09623660426586866\n",
      "test_test\n",
      "test mean loss=1156.2789916992188\n",
      "epoch 2756\n",
      "test_train\n",
      "train mean loss=0.08702345782270034\n",
      "test_test\n",
      "test mean loss=1156.297119140625\n",
      "epoch 2757\n",
      "test_train\n",
      "train mean loss=0.09470462923248608\n",
      "test_test\n",
      "test mean loss=1156.728759765625\n",
      "epoch 2758\n",
      "test_train\n",
      "train mean loss=0.09246570182343324\n",
      "test_test\n",
      "test mean loss=1156.6689147949219\n",
      "epoch 2759\n",
      "test_train\n",
      "train mean loss=0.09697214048355818\n",
      "test_test\n",
      "test mean loss=1157.6451416015625\n",
      "epoch 2760\n",
      "test_train\n",
      "train mean loss=0.09093435574322939\n",
      "test_test\n",
      "test mean loss=1156.5761108398438\n",
      "epoch 2761\n",
      "test_train\n",
      "train mean loss=0.09355040950079758\n",
      "test_test\n",
      "test mean loss=1156.8986206054688\n",
      "epoch 2762\n",
      "test_train\n",
      "train mean loss=0.08925298290948074\n",
      "test_test\n",
      "test mean loss=1157.5818176269531\n",
      "epoch 2763\n",
      "test_train\n",
      "train mean loss=0.09040292662878831\n",
      "test_test\n",
      "test mean loss=1157.0559692382812\n",
      "epoch 2764\n",
      "test_train\n",
      "train mean loss=0.09118333862473567\n",
      "test_test\n",
      "test mean loss=1156.3970642089844\n",
      "epoch 2765\n",
      "test_train\n",
      "train mean loss=0.09275533600399892\n",
      "test_test\n",
      "test mean loss=1156.7948608398438\n",
      "epoch 2766\n",
      "test_train\n",
      "train mean loss=0.09459793195128441\n",
      "test_test\n",
      "test mean loss=1157.8836059570312\n",
      "epoch 2767\n",
      "test_train\n",
      "train mean loss=0.08515283092856407\n",
      "test_test\n",
      "test mean loss=1155.9861450195312\n",
      "epoch 2768\n",
      "test_train\n",
      "train mean loss=0.08956402912735939\n",
      "test_test\n",
      "test mean loss=1157.4541015625\n",
      "epoch 2769\n",
      "test_train\n",
      "train mean loss=0.0903557160248359\n",
      "test_test\n",
      "test mean loss=1157.8748779296875\n",
      "epoch 2770\n",
      "test_train\n",
      "train mean loss=0.08601776510477066\n",
      "test_test\n",
      "test mean loss=1156.5830383300781\n",
      "epoch 2771\n",
      "test_train\n",
      "train mean loss=0.09036845806986094\n",
      "test_test\n",
      "test mean loss=1156.4567565917969\n",
      "epoch 2772\n",
      "test_train\n",
      "train mean loss=0.09073353248337905\n",
      "test_test\n",
      "test mean loss=1157.2237243652344\n",
      "epoch 2773\n",
      "test_train\n",
      "train mean loss=0.08936289449532826\n",
      "test_test\n",
      "test mean loss=1156.2896118164062\n",
      "epoch 2774\n",
      "test_train\n",
      "train mean loss=0.08984006258348624\n",
      "test_test\n",
      "test mean loss=1156.92333984375\n",
      "epoch 2775\n",
      "test_train\n",
      "train mean loss=0.0829327143728733\n",
      "test_test\n",
      "test mean loss=1157.7363586425781\n",
      "epoch 2776\n",
      "test_train\n",
      "train mean loss=0.087197445333004\n",
      "test_test\n",
      "test mean loss=1158.0625610351562\n",
      "epoch 2777\n",
      "test_train\n",
      "train mean loss=0.0928044014920791\n",
      "test_test\n",
      "test mean loss=1156.732666015625\n",
      "epoch 2778\n",
      "test_train\n",
      "train mean loss=0.08799801766872406\n",
      "test_test\n",
      "test mean loss=1156.66455078125\n",
      "epoch 2779\n",
      "test_train\n",
      "train mean loss=0.0888108207533757\n",
      "test_test\n",
      "test mean loss=1156.3367004394531\n",
      "epoch 2780\n",
      "test_train\n",
      "train mean loss=0.09907650140424569\n",
      "test_test\n",
      "test mean loss=1157.9295654296875\n",
      "epoch 2781\n",
      "test_train\n",
      "train mean loss=0.09001787596692641\n",
      "test_test\n",
      "test mean loss=1157.3900756835938\n",
      "epoch 2782\n",
      "test_train\n",
      "train mean loss=0.08653760639329751\n",
      "test_test\n",
      "test mean loss=1157.1513671875\n",
      "epoch 2783\n",
      "test_train\n",
      "train mean loss=0.08473917034765084\n",
      "test_test\n",
      "test mean loss=1157.2192993164062\n",
      "epoch 2784\n",
      "test_train\n",
      "train mean loss=0.08785889049371083\n",
      "test_test\n",
      "test mean loss=1157.8609008789062\n",
      "epoch 2785\n",
      "test_train\n",
      "train mean loss=0.08591191625843446\n",
      "test_test\n",
      "test mean loss=1157.5391235351562\n",
      "epoch 2786\n",
      "test_train\n",
      "train mean loss=0.08884528217216332\n",
      "test_test\n",
      "test mean loss=1158.563720703125\n",
      "epoch 2787\n",
      "test_train\n",
      "train mean loss=0.08558963052928448\n",
      "test_test\n",
      "test mean loss=1157.626220703125\n",
      "epoch 2788\n",
      "test_train\n",
      "train mean loss=0.16981475303570429\n",
      "test_test\n",
      "test mean loss=1158.9119262695312\n",
      "epoch 2789\n",
      "test_train\n",
      "train mean loss=0.10929130328198274\n",
      "test_test\n",
      "test mean loss=1158.5858154296875\n",
      "epoch 2790\n",
      "test_train\n",
      "train mean loss=0.09174153798570235\n",
      "test_test\n",
      "test mean loss=1156.5863037109375\n",
      "epoch 2791\n",
      "test_train\n",
      "train mean loss=0.09811449361344178\n",
      "test_test\n",
      "test mean loss=1156.436279296875\n",
      "epoch 2792\n",
      "test_train\n",
      "train mean loss=0.08854694260905187\n",
      "test_test\n",
      "test mean loss=1157.1200561523438\n",
      "epoch 2793\n",
      "test_train\n",
      "train mean loss=0.09707140736281872\n",
      "test_test\n",
      "test mean loss=1156.7169799804688\n",
      "epoch 2794\n",
      "test_train\n",
      "train mean loss=0.09635612772156794\n",
      "test_test\n",
      "test mean loss=1156.5493774414062\n",
      "epoch 2795\n",
      "test_train\n",
      "train mean loss=0.08684951905161142\n",
      "test_test\n",
      "test mean loss=1156.4087524414062\n",
      "epoch 2796\n",
      "test_train\n",
      "train mean loss=0.0902195293456316\n",
      "test_test\n",
      "test mean loss=1157.8109741210938\n",
      "epoch 2797\n",
      "test_train\n",
      "train mean loss=0.08914054899166028\n",
      "test_test\n",
      "test mean loss=1156.9459838867188\n",
      "epoch 2798\n",
      "test_train\n",
      "train mean loss=0.08927672822028399\n",
      "test_test\n",
      "test mean loss=1156.6636047363281\n",
      "epoch 2799\n",
      "test_train\n",
      "train mean loss=0.0868714094782869\n",
      "test_test\n",
      "test mean loss=1156.6067810058594\n",
      "epoch 2800\n",
      "test_train\n",
      "train mean loss=0.08869655119876067\n",
      "test_test\n",
      "test mean loss=1156.9244995117188\n",
      "epoch 2801\n",
      "test_train\n",
      "train mean loss=0.08736340639491876\n",
      "test_test\n",
      "test mean loss=1156.5899658203125\n",
      "epoch 2802\n",
      "test_train\n",
      "train mean loss=0.08499506333221991\n",
      "test_test\n",
      "test mean loss=1156.3345336914062\n",
      "epoch 2803\n",
      "test_train\n",
      "train mean loss=0.09055131301283836\n",
      "test_test\n",
      "test mean loss=1156.567138671875\n",
      "epoch 2804\n",
      "test_train\n",
      "train mean loss=0.09176667003581922\n",
      "test_test\n",
      "test mean loss=1156.928466796875\n",
      "epoch 2805\n",
      "test_train\n",
      "train mean loss=0.09008055552840233\n",
      "test_test\n",
      "test mean loss=1156.608642578125\n",
      "epoch 2806\n",
      "test_train\n",
      "train mean loss=0.08854928892105818\n",
      "test_test\n",
      "test mean loss=1156.8672180175781\n",
      "epoch 2807\n",
      "test_train\n",
      "train mean loss=0.11523502320051193\n",
      "test_test\n",
      "test mean loss=1157.67822265625\n",
      "epoch 2808\n",
      "test_train\n",
      "train mean loss=0.09186719792584579\n",
      "test_test\n",
      "test mean loss=1156.9897155761719\n",
      "epoch 2809\n",
      "test_train\n",
      "train mean loss=0.09067670286943515\n",
      "test_test\n",
      "test mean loss=1156.61376953125\n",
      "epoch 2810\n",
      "test_train\n",
      "train mean loss=0.07904572691768408\n",
      "test_test\n",
      "test mean loss=1156.4620971679688\n",
      "epoch 2811\n",
      "test_train\n",
      "train mean loss=0.078898711130023\n",
      "test_test\n",
      "test mean loss=1155.4682006835938\n",
      "epoch 2812\n",
      "test_train\n",
      "train mean loss=0.08189913040647905\n",
      "test_test\n",
      "test mean loss=1155.6661376953125\n",
      "epoch 2813\n",
      "test_train\n",
      "train mean loss=0.08908062676588695\n",
      "test_test\n",
      "test mean loss=1156.6341857910156\n",
      "epoch 2814\n",
      "test_train\n",
      "train mean loss=0.08422089306016763\n",
      "test_test\n",
      "test mean loss=1155.776611328125\n",
      "epoch 2815\n",
      "test_train\n",
      "train mean loss=0.08247520308941603\n",
      "test_test\n",
      "test mean loss=1155.0201721191406\n",
      "epoch 2816\n",
      "test_train\n",
      "train mean loss=0.08445263716081779\n",
      "test_test\n",
      "test mean loss=1155.068359375\n",
      "epoch 2817\n",
      "test_train\n",
      "train mean loss=0.08659798419103026\n",
      "test_test\n",
      "test mean loss=1156.1967163085938\n",
      "epoch 2818\n",
      "test_train\n",
      "train mean loss=0.08556217513978481\n",
      "test_test\n",
      "test mean loss=1155.6761474609375\n",
      "epoch 2819\n",
      "test_train\n",
      "train mean loss=0.7805240899324417\n",
      "test_test\n",
      "test mean loss=1155.4491577148438\n",
      "epoch 2820\n",
      "test_train\n",
      "train mean loss=0.11755566361049812\n",
      "test_test\n",
      "test mean loss=1156.3663330078125\n",
      "epoch 2821\n",
      "test_train\n",
      "train mean loss=0.08493068379660447\n",
      "test_test\n",
      "test mean loss=1156.6755981445312\n",
      "epoch 2822\n",
      "test_train\n",
      "train mean loss=0.09344485029578209\n",
      "test_test\n",
      "test mean loss=1157.521240234375\n",
      "epoch 2823\n",
      "test_train\n",
      "train mean loss=0.09225341367224853\n",
      "test_test\n",
      "test mean loss=1157.9102478027344\n",
      "epoch 2824\n",
      "test_train\n",
      "train mean loss=0.08543685916811228\n",
      "test_test\n",
      "test mean loss=1156.7280883789062\n",
      "epoch 2825\n",
      "test_train\n",
      "train mean loss=0.08245137085517247\n",
      "test_test\n",
      "test mean loss=1156.3817749023438\n",
      "epoch 2826\n",
      "test_train\n",
      "train mean loss=0.08390785939991474\n",
      "test_test\n",
      "test mean loss=1157.1694946289062\n",
      "epoch 2827\n",
      "test_train\n",
      "train mean loss=0.08739156400163968\n",
      "test_test\n",
      "test mean loss=1156.0880126953125\n",
      "epoch 2828\n",
      "test_train\n",
      "train mean loss=0.09098036680370569\n",
      "test_test\n",
      "test mean loss=1155.858154296875\n",
      "epoch 2829\n",
      "test_train\n",
      "train mean loss=0.08341132539014022\n",
      "test_test\n",
      "test mean loss=1155.9019165039062\n",
      "epoch 2830\n",
      "test_train\n",
      "train mean loss=0.08523093070834875\n",
      "test_test\n",
      "test mean loss=1156.1127319335938\n",
      "epoch 2831\n",
      "test_train\n",
      "train mean loss=0.08335350795338552\n",
      "test_test\n",
      "test mean loss=1156.0831909179688\n",
      "epoch 2832\n",
      "test_train\n",
      "train mean loss=0.08818394613141815\n",
      "test_test\n",
      "test mean loss=1156.2311401367188\n",
      "epoch 2833\n",
      "test_train\n",
      "train mean loss=0.09834748972207308\n",
      "test_test\n",
      "test mean loss=1156.9041748046875\n",
      "epoch 2834\n",
      "test_train\n",
      "train mean loss=0.09567758006354173\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1156.3865966796875\n",
      "epoch 2835\n",
      "test_train\n",
      "train mean loss=0.09287198850264151\n",
      "test_test\n",
      "test mean loss=1156.3987121582031\n",
      "epoch 2836\n",
      "test_train\n",
      "train mean loss=0.08684832012901704\n",
      "test_test\n",
      "test mean loss=1156.7331848144531\n",
      "epoch 2837\n",
      "test_train\n",
      "train mean loss=0.08726167430480321\n",
      "test_test\n",
      "test mean loss=1156.131103515625\n",
      "epoch 2838\n",
      "test_train\n",
      "train mean loss=0.08772482071071863\n",
      "test_test\n",
      "test mean loss=1156.0972900390625\n",
      "epoch 2839\n",
      "test_train\n",
      "train mean loss=0.08594148295621078\n",
      "test_test\n",
      "test mean loss=1156.99169921875\n",
      "epoch 2840\n",
      "test_train\n",
      "train mean loss=0.09141676096866529\n",
      "test_test\n",
      "test mean loss=1158.0284423828125\n",
      "epoch 2841\n",
      "test_train\n",
      "train mean loss=0.08714866793404023\n",
      "test_test\n",
      "test mean loss=1157.3596801757812\n",
      "epoch 2842\n",
      "test_train\n",
      "train mean loss=0.08832746092230082\n",
      "test_test\n",
      "test mean loss=1157.5323486328125\n",
      "epoch 2843\n",
      "test_train\n",
      "train mean loss=0.0840523491303126\n",
      "test_test\n",
      "test mean loss=1157.905517578125\n",
      "epoch 2844\n",
      "test_train\n",
      "train mean loss=0.08384018298238516\n",
      "test_test\n",
      "test mean loss=1157.8577575683594\n",
      "epoch 2845\n",
      "test_train\n",
      "train mean loss=0.07873202829311292\n",
      "test_test\n",
      "test mean loss=1157.7926635742188\n",
      "epoch 2846\n",
      "test_train\n",
      "train mean loss=0.0893465547511975\n",
      "test_test\n",
      "test mean loss=1157.7166137695312\n",
      "epoch 2847\n",
      "test_train\n",
      "train mean loss=0.08180324143419664\n",
      "test_test\n",
      "test mean loss=1157.2531127929688\n",
      "epoch 2848\n",
      "test_train\n",
      "train mean loss=0.08579158876091242\n",
      "test_test\n",
      "test mean loss=1156.6536865234375\n",
      "epoch 2849\n",
      "test_train\n",
      "train mean loss=0.0831950328623255\n",
      "test_test\n",
      "test mean loss=1156.0670166015625\n",
      "epoch 2850\n",
      "test_train\n",
      "train mean loss=0.0929579958319664\n",
      "test_test\n",
      "test mean loss=1155.5064392089844\n",
      "epoch 2851\n",
      "test_train\n",
      "train mean loss=0.09288190988202889\n",
      "test_test\n",
      "test mean loss=1156.6397094726562\n",
      "epoch 2852\n",
      "test_train\n",
      "train mean loss=0.09243414675196011\n",
      "test_test\n",
      "test mean loss=1156.3802185058594\n",
      "epoch 2853\n",
      "test_train\n",
      "train mean loss=0.0891894434268276\n",
      "test_test\n",
      "test mean loss=1157.1228637695312\n",
      "epoch 2854\n",
      "test_train\n",
      "train mean loss=0.09010917600244284\n",
      "test_test\n",
      "test mean loss=1156.879638671875\n",
      "epoch 2855\n",
      "test_train\n",
      "train mean loss=0.08416843755791585\n",
      "test_test\n",
      "test mean loss=1156.3785400390625\n",
      "epoch 2856\n",
      "test_train\n",
      "train mean loss=0.08461778052151203\n",
      "test_test\n",
      "test mean loss=1157.1786193847656\n",
      "epoch 2857\n",
      "test_train\n",
      "train mean loss=0.08441699234147866\n",
      "test_test\n",
      "test mean loss=1155.6397705078125\n",
      "epoch 2858\n",
      "test_train\n",
      "train mean loss=0.084452741779387\n",
      "test_test\n",
      "test mean loss=1156.6976318359375\n",
      "epoch 2859\n",
      "test_train\n",
      "train mean loss=0.07851860734323661\n",
      "test_test\n",
      "test mean loss=1156.9124755859375\n",
      "epoch 2860\n",
      "test_train\n",
      "train mean loss=0.08140831037114064\n",
      "test_test\n",
      "test mean loss=1156.44091796875\n",
      "epoch 2861\n",
      "test_train\n",
      "train mean loss=0.08728849080701669\n",
      "test_test\n",
      "test mean loss=1156.5982055664062\n",
      "epoch 2862\n",
      "test_train\n",
      "train mean loss=0.08443341590464115\n",
      "test_test\n",
      "test mean loss=1155.665771484375\n",
      "epoch 2863\n",
      "test_train\n",
      "train mean loss=0.0860767054061095\n",
      "test_test\n",
      "test mean loss=1155.7313232421875\n",
      "epoch 2864\n",
      "test_train\n",
      "train mean loss=0.08418065231914322\n",
      "test_test\n",
      "test mean loss=1156.04638671875\n",
      "epoch 2865\n",
      "test_train\n",
      "train mean loss=0.08368234088023503\n",
      "test_test\n",
      "test mean loss=1156.6517333984375\n",
      "epoch 2866\n",
      "test_train\n",
      "train mean loss=0.07700443733483553\n",
      "test_test\n",
      "test mean loss=1156.1263732910156\n",
      "epoch 2867\n",
      "test_train\n",
      "train mean loss=0.08221333132435878\n",
      "test_test\n",
      "test mean loss=1157.4053344726562\n",
      "epoch 2868\n",
      "test_train\n",
      "train mean loss=0.084152827039361\n",
      "test_test\n",
      "test mean loss=1157.188232421875\n",
      "epoch 2869\n",
      "test_train\n",
      "train mean loss=0.09171668812632561\n",
      "test_test\n",
      "test mean loss=1157.0776977539062\n",
      "epoch 2870\n",
      "test_train\n",
      "train mean loss=0.27006479104359943\n",
      "test_test\n",
      "test mean loss=1158.1412048339844\n",
      "epoch 2871\n",
      "test_train\n",
      "train mean loss=0.11899290916820367\n",
      "test_test\n",
      "test mean loss=1158.194580078125\n",
      "epoch 2872\n",
      "test_train\n",
      "train mean loss=0.1006164172043403\n",
      "test_test\n",
      "test mean loss=1158.9804077148438\n",
      "epoch 2873\n",
      "test_train\n",
      "train mean loss=0.08962480972210567\n",
      "test_test\n",
      "test mean loss=1157.5316772460938\n",
      "epoch 2874\n",
      "test_train\n",
      "train mean loss=0.08602241054177284\n",
      "test_test\n",
      "test mean loss=1158.683837890625\n",
      "epoch 2875\n",
      "test_train\n",
      "train mean loss=0.08597362724443276\n",
      "test_test\n",
      "test mean loss=1159.0885620117188\n",
      "epoch 2876\n",
      "test_train\n",
      "train mean loss=0.08393816308428843\n",
      "test_test\n",
      "test mean loss=1157.4508972167969\n",
      "epoch 2877\n",
      "test_train\n",
      "train mean loss=0.0823119521761934\n",
      "test_test\n",
      "test mean loss=1157.2181396484375\n",
      "epoch 2878\n",
      "test_train\n",
      "train mean loss=0.08760007222493489\n",
      "test_test\n",
      "test mean loss=1157.1754760742188\n",
      "epoch 2879\n",
      "test_train\n",
      "train mean loss=0.09103493485599756\n",
      "test_test\n",
      "test mean loss=1155.9579467773438\n",
      "epoch 2880\n",
      "test_train\n",
      "train mean loss=0.08133562250683705\n",
      "test_test\n",
      "test mean loss=1156.9104614257812\n",
      "epoch 2881\n",
      "test_train\n",
      "train mean loss=0.08331730340917905\n",
      "test_test\n",
      "test mean loss=1157.1658630371094\n",
      "epoch 2882\n",
      "test_train\n",
      "train mean loss=0.09078719435880582\n",
      "test_test\n",
      "test mean loss=1157.1831665039062\n",
      "epoch 2883\n",
      "test_train\n",
      "train mean loss=0.08420243455717961\n",
      "test_test\n",
      "test mean loss=1156.6906127929688\n",
      "epoch 2884\n",
      "test_train\n",
      "train mean loss=0.07824504685898621\n",
      "test_test\n",
      "test mean loss=1156.6501159667969\n",
      "epoch 2885\n",
      "test_train\n",
      "train mean loss=0.0821869516124328\n",
      "test_test\n",
      "test mean loss=1157.3681640625\n",
      "epoch 2886\n",
      "test_train\n",
      "train mean loss=0.08484547523160775\n",
      "test_test\n",
      "test mean loss=1156.8749389648438\n",
      "epoch 2887\n",
      "test_train\n",
      "train mean loss=0.08842691251387198\n",
      "test_test\n",
      "test mean loss=1156.9884033203125\n",
      "epoch 2888\n",
      "test_train\n",
      "train mean loss=0.0945539316162467\n",
      "test_test\n",
      "test mean loss=1156.523193359375\n",
      "epoch 2889\n",
      "test_train\n",
      "train mean loss=0.08864005748182535\n",
      "test_test\n",
      "test mean loss=1155.45947265625\n",
      "epoch 2890\n",
      "test_train\n",
      "train mean loss=0.08470434602349997\n",
      "test_test\n",
      "test mean loss=1156.3793334960938\n",
      "epoch 2891\n",
      "test_train\n",
      "train mean loss=0.0878931600600481\n",
      "test_test\n",
      "test mean loss=1157.2728271484375\n",
      "epoch 2892\n",
      "test_train\n",
      "train mean loss=0.08354993971685569\n",
      "test_test\n",
      "test mean loss=1155.6770935058594\n",
      "epoch 2893\n",
      "test_train\n",
      "train mean loss=0.08547483570873737\n",
      "test_test\n",
      "test mean loss=1156.520751953125\n",
      "epoch 2894\n",
      "test_train\n",
      "train mean loss=0.08408552749703328\n",
      "test_test\n",
      "test mean loss=1155.7755126953125\n",
      "epoch 2895\n",
      "test_train\n",
      "train mean loss=0.08388820942491293\n",
      "test_test\n",
      "test mean loss=1156.3792114257812\n",
      "epoch 2896\n",
      "test_train\n",
      "train mean loss=0.08604296358923118\n",
      "test_test\n",
      "test mean loss=1156.1973266601562\n",
      "epoch 2897\n",
      "test_train\n",
      "train mean loss=0.08224762200067441\n",
      "test_test\n",
      "test mean loss=1156.3707885742188\n",
      "epoch 2898\n",
      "test_train\n",
      "train mean loss=0.07963880089422067\n",
      "test_test\n",
      "test mean loss=1156.1699829101562\n",
      "epoch 2899\n",
      "test_train\n",
      "train mean loss=0.08520305218795936\n",
      "test_test\n",
      "test mean loss=1156.6478271484375\n",
      "epoch 2900\n",
      "test_train\n",
      "train mean loss=0.10075247411926587\n",
      "test_test\n",
      "test mean loss=1154.9561767578125\n",
      "epoch 2901\n",
      "test_train\n",
      "train mean loss=0.08986667698870103\n",
      "test_test\n",
      "test mean loss=1155.6930541992188\n",
      "epoch 2902\n",
      "test_train\n",
      "train mean loss=0.08700212215383847\n",
      "test_test\n",
      "test mean loss=1155.8759765625\n",
      "epoch 2903\n",
      "test_train\n",
      "train mean loss=0.07951711149265368\n",
      "test_test\n",
      "test mean loss=1156.0431518554688\n",
      "epoch 2904\n",
      "test_train\n",
      "train mean loss=0.08602816580484311\n",
      "test_test\n",
      "test mean loss=1156.4280700683594\n",
      "epoch 2905\n",
      "test_train\n",
      "train mean loss=0.08438919174174468\n",
      "test_test\n",
      "test mean loss=1156.8319091796875\n",
      "epoch 2906\n",
      "test_train\n",
      "train mean loss=0.08336898715545733\n",
      "test_test\n",
      "test mean loss=1156.8914184570312\n",
      "epoch 2907\n",
      "test_train\n",
      "train mean loss=0.08578718826174736\n",
      "test_test\n",
      "test mean loss=1155.9227294921875\n",
      "epoch 2908\n",
      "test_train\n",
      "train mean loss=0.08982636158665021\n",
      "test_test\n",
      "test mean loss=1156.6718444824219\n",
      "epoch 2909\n",
      "test_train\n",
      "train mean loss=0.0851203069711725\n",
      "test_test\n",
      "test mean loss=1156.2149353027344\n",
      "epoch 2910\n",
      "test_train\n",
      "train mean loss=0.08408938876042764\n",
      "test_test\n",
      "test mean loss=1155.7977600097656\n",
      "epoch 2911\n",
      "test_train\n",
      "train mean loss=0.08348447798440854\n",
      "test_test\n",
      "test mean loss=1156.3702087402344\n",
      "epoch 2912\n",
      "test_train\n",
      "train mean loss=0.08282863317678373\n",
      "test_test\n",
      "test mean loss=1156.9622802734375\n",
      "epoch 2913\n",
      "test_train\n",
      "train mean loss=0.09233121604969104\n",
      "test_test\n",
      "test mean loss=1156.7222595214844\n",
      "epoch 2914\n",
      "test_train\n",
      "train mean loss=0.09910267343123753\n",
      "test_test\n",
      "test mean loss=1157.9843444824219\n",
      "epoch 2915\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.08842787674317758\n",
      "test_test\n",
      "test mean loss=1156.4900512695312\n",
      "epoch 2916\n",
      "test_train\n",
      "train mean loss=0.09328963421285152\n",
      "test_test\n",
      "test mean loss=1157.1619873046875\n",
      "epoch 2917\n",
      "test_train\n",
      "train mean loss=0.08328130437682073\n",
      "test_test\n",
      "test mean loss=1155.6868286132812\n",
      "epoch 2918\n",
      "test_train\n",
      "train mean loss=0.08313670381903648\n",
      "test_test\n",
      "test mean loss=1156.2517700195312\n",
      "epoch 2919\n",
      "test_train\n",
      "train mean loss=0.08335118399312098\n",
      "test_test\n",
      "test mean loss=1156.1365051269531\n",
      "epoch 2920\n",
      "test_train\n",
      "train mean loss=0.09335527196526527\n",
      "test_test\n",
      "test mean loss=1156.9415893554688\n",
      "epoch 2921\n",
      "test_train\n",
      "train mean loss=0.08328250360985597\n",
      "test_test\n",
      "test mean loss=1156.2835083007812\n",
      "epoch 2922\n",
      "test_train\n",
      "train mean loss=0.09003311426689227\n",
      "test_test\n",
      "test mean loss=1157.6759948730469\n",
      "epoch 2923\n",
      "test_train\n",
      "train mean loss=0.08386312549312909\n",
      "test_test\n",
      "test mean loss=1156.9946899414062\n",
      "epoch 2924\n",
      "test_train\n",
      "train mean loss=0.08587329648435116\n",
      "test_test\n",
      "test mean loss=1155.7208251953125\n",
      "epoch 2925\n",
      "test_train\n",
      "train mean loss=0.08267013356089592\n",
      "test_test\n",
      "test mean loss=1156.6575317382812\n",
      "epoch 2926\n",
      "test_train\n",
      "train mean loss=0.08768931000183026\n",
      "test_test\n",
      "test mean loss=1157.618896484375\n",
      "epoch 2927\n",
      "test_train\n",
      "train mean loss=0.6774867077668508\n",
      "test_test\n",
      "test mean loss=1157.2942504882812\n",
      "epoch 2928\n",
      "test_train\n",
      "train mean loss=0.13760334439575672\n",
      "test_test\n",
      "test mean loss=1155.29345703125\n",
      "epoch 2929\n",
      "test_train\n",
      "train mean loss=0.10957939146707456\n",
      "test_test\n",
      "test mean loss=1155.7607421875\n",
      "epoch 2930\n",
      "test_train\n",
      "train mean loss=0.09563202100495498\n",
      "test_test\n",
      "test mean loss=1155.8212585449219\n",
      "epoch 2931\n",
      "test_train\n",
      "train mean loss=0.0930847271035115\n",
      "test_test\n",
      "test mean loss=1156.1923828125\n",
      "epoch 2932\n",
      "test_train\n",
      "train mean loss=0.08585195429623127\n",
      "test_test\n",
      "test mean loss=1156.0663452148438\n",
      "epoch 2933\n",
      "test_train\n",
      "train mean loss=0.08147421013563871\n",
      "test_test\n",
      "test mean loss=1156.0000610351562\n",
      "epoch 2934\n",
      "test_train\n",
      "train mean loss=0.08285152384390433\n",
      "test_test\n",
      "test mean loss=1155.8009033203125\n",
      "epoch 2935\n",
      "test_train\n",
      "train mean loss=0.08936178063352902\n",
      "test_test\n",
      "test mean loss=1155.4569396972656\n",
      "epoch 2936\n",
      "test_train\n",
      "train mean loss=0.08711028937250376\n",
      "test_test\n",
      "test mean loss=1156.1178588867188\n",
      "epoch 2937\n",
      "test_train\n",
      "train mean loss=0.09529690444469452\n",
      "test_test\n",
      "test mean loss=1155.4103393554688\n",
      "epoch 2938\n",
      "test_train\n",
      "train mean loss=0.08925854538877805\n",
      "test_test\n",
      "test mean loss=1155.7010498046875\n",
      "epoch 2939\n",
      "test_train\n",
      "train mean loss=0.08103327577312787\n",
      "test_test\n",
      "test mean loss=1155.9346618652344\n",
      "epoch 2940\n",
      "test_train\n",
      "train mean loss=0.08600165632863839\n",
      "test_test\n",
      "test mean loss=1156.9729614257812\n",
      "epoch 2941\n",
      "test_train\n",
      "train mean loss=0.11500977165997028\n",
      "test_test\n",
      "test mean loss=1154.0623779296875\n",
      "epoch 2942\n",
      "test_train\n",
      "train mean loss=0.08765619217107694\n",
      "test_test\n",
      "test mean loss=1155.9768981933594\n",
      "epoch 2943\n",
      "test_train\n",
      "train mean loss=0.09051728093375762\n",
      "test_test\n",
      "test mean loss=1157.1708374023438\n",
      "epoch 2944\n",
      "test_train\n",
      "train mean loss=0.09270390123128891\n",
      "test_test\n",
      "test mean loss=1156.5123901367188\n",
      "epoch 2945\n",
      "test_train\n",
      "train mean loss=0.0855278791859746\n",
      "test_test\n",
      "test mean loss=1157.05615234375\n",
      "epoch 2946\n",
      "test_train\n",
      "train mean loss=0.08301794528961182\n",
      "test_test\n",
      "test mean loss=1157.0705871582031\n",
      "epoch 2947\n",
      "test_train\n",
      "train mean loss=0.08278502617031336\n",
      "test_test\n",
      "test mean loss=1157.5286254882812\n",
      "epoch 2948\n",
      "test_train\n",
      "train mean loss=0.08679384334633748\n",
      "test_test\n",
      "test mean loss=1157.2174682617188\n",
      "epoch 2949\n",
      "test_train\n",
      "train mean loss=0.08688951997707288\n",
      "test_test\n",
      "test mean loss=1157.3455810546875\n",
      "epoch 2950\n",
      "test_train\n",
      "train mean loss=0.09145564616968234\n",
      "test_test\n",
      "test mean loss=1157.256591796875\n",
      "epoch 2951\n",
      "test_train\n",
      "train mean loss=0.08978202907989423\n",
      "test_test\n",
      "test mean loss=1158.1296081542969\n",
      "epoch 2952\n",
      "test_train\n",
      "train mean loss=0.10611191267768542\n",
      "test_test\n",
      "test mean loss=1156.0485229492188\n",
      "epoch 2953\n",
      "test_train\n",
      "train mean loss=0.0882843742147088\n",
      "test_test\n",
      "test mean loss=1157.3114013671875\n",
      "epoch 2954\n",
      "test_train\n",
      "train mean loss=0.08199752680957317\n",
      "test_test\n",
      "test mean loss=1157.0134582519531\n",
      "epoch 2955\n",
      "test_train\n",
      "train mean loss=0.08558548800647259\n",
      "test_test\n",
      "test mean loss=1156.6817321777344\n",
      "epoch 2956\n",
      "test_train\n",
      "train mean loss=0.08628716475019853\n",
      "test_test\n",
      "test mean loss=1156.6385498046875\n",
      "epoch 2957\n",
      "test_train\n",
      "train mean loss=0.08515654349078734\n",
      "test_test\n",
      "test mean loss=1155.9581909179688\n",
      "epoch 2958\n",
      "test_train\n",
      "train mean loss=0.08806727423022191\n",
      "test_test\n",
      "test mean loss=1157.0528564453125\n",
      "epoch 2959\n",
      "test_train\n",
      "train mean loss=0.09109464225669701\n",
      "test_test\n",
      "test mean loss=1157.8143615722656\n",
      "epoch 2960\n",
      "test_train\n",
      "train mean loss=0.11985367971162002\n",
      "test_test\n",
      "test mean loss=1157.1813354492188\n",
      "epoch 2961\n",
      "test_train\n",
      "train mean loss=0.08732554378608863\n",
      "test_test\n",
      "test mean loss=1156.6182861328125\n",
      "epoch 2962\n",
      "test_train\n",
      "train mean loss=0.08731984098752339\n",
      "test_test\n",
      "test mean loss=1156.8638305664062\n",
      "epoch 2963\n",
      "test_train\n",
      "train mean loss=0.0823118615274628\n",
      "test_test\n",
      "test mean loss=1156.8284301757812\n",
      "epoch 2964\n",
      "test_train\n",
      "train mean loss=0.08489963536461194\n",
      "test_test\n",
      "test mean loss=1156.6761474609375\n",
      "epoch 2965\n",
      "test_train\n",
      "train mean loss=0.07926291817178328\n",
      "test_test\n",
      "test mean loss=1156.8262939453125\n",
      "epoch 2966\n",
      "test_train\n",
      "train mean loss=0.08775283178935449\n",
      "test_test\n",
      "test mean loss=1157.6511535644531\n",
      "epoch 2967\n",
      "test_train\n",
      "train mean loss=0.08515315223485231\n",
      "test_test\n",
      "test mean loss=1156.2893981933594\n",
      "epoch 2968\n",
      "test_train\n",
      "train mean loss=0.09122127667069435\n",
      "test_test\n",
      "test mean loss=1156.6842651367188\n",
      "epoch 2969\n",
      "test_train\n",
      "train mean loss=0.08795009925961494\n",
      "test_test\n",
      "test mean loss=1157.7285766601562\n",
      "epoch 2970\n",
      "test_train\n",
      "train mean loss=0.08775020421793063\n",
      "test_test\n",
      "test mean loss=1157.2496643066406\n",
      "epoch 2971\n",
      "test_train\n",
      "train mean loss=0.07760720886290073\n",
      "test_test\n",
      "test mean loss=1156.073974609375\n",
      "epoch 2972\n",
      "test_train\n",
      "train mean loss=0.08061198517680168\n",
      "test_test\n",
      "test mean loss=1156.0785522460938\n",
      "epoch 2973\n",
      "test_train\n",
      "train mean loss=0.08082355776180823\n",
      "test_test\n",
      "test mean loss=1156.5960083007812\n",
      "epoch 2974\n",
      "test_train\n",
      "train mean loss=0.08835896927242477\n",
      "test_test\n",
      "test mean loss=1158.36279296875\n",
      "epoch 2975\n",
      "test_train\n",
      "train mean loss=0.08323407918214798\n",
      "test_test\n",
      "test mean loss=1156.9895629882812\n",
      "epoch 2976\n",
      "test_train\n",
      "train mean loss=0.0903604831546545\n",
      "test_test\n",
      "test mean loss=1155.9224853515625\n",
      "epoch 2977\n",
      "test_train\n",
      "train mean loss=0.089388992326955\n",
      "test_test\n",
      "test mean loss=1155.894775390625\n",
      "epoch 2978\n",
      "test_train\n",
      "train mean loss=0.09680978301912546\n",
      "test_test\n",
      "test mean loss=1156.6907348632812\n",
      "epoch 2979\n",
      "test_train\n",
      "train mean loss=0.09051287019004424\n",
      "test_test\n",
      "test mean loss=1157.626220703125\n",
      "epoch 2980\n",
      "test_train\n",
      "train mean loss=0.08681423123925924\n",
      "test_test\n",
      "test mean loss=1157.7367858886719\n",
      "epoch 2981\n",
      "test_train\n",
      "train mean loss=0.10042611043900251\n",
      "test_test\n",
      "test mean loss=1155.629638671875\n",
      "epoch 2982\n",
      "test_train\n",
      "train mean loss=0.08850413902352254\n",
      "test_test\n",
      "test mean loss=1157.2464904785156\n",
      "epoch 2983\n",
      "test_train\n",
      "train mean loss=0.08396130117277305\n",
      "test_test\n",
      "test mean loss=1157.6532592773438\n",
      "epoch 2984\n",
      "test_train\n",
      "train mean loss=0.08232824814816316\n",
      "test_test\n",
      "test mean loss=1157.8624877929688\n",
      "epoch 2985\n",
      "test_train\n",
      "train mean loss=0.08674714528024197\n",
      "test_test\n",
      "test mean loss=1157.9688110351562\n",
      "epoch 2986\n",
      "test_train\n",
      "train mean loss=0.08925508909548323\n",
      "test_test\n",
      "test mean loss=1157.4881591796875\n",
      "epoch 2987\n",
      "test_train\n",
      "train mean loss=0.08651859623690446\n",
      "test_test\n",
      "test mean loss=1157.3929443359375\n",
      "epoch 2988\n",
      "test_train\n",
      "train mean loss=0.08191832558562358\n",
      "test_test\n",
      "test mean loss=1157.7498779296875\n",
      "epoch 2989\n",
      "test_train\n",
      "train mean loss=0.07951896140972774\n",
      "test_test\n",
      "test mean loss=1157.781494140625\n",
      "epoch 2990\n",
      "test_train\n",
      "train mean loss=0.08629103098064661\n",
      "test_test\n",
      "test mean loss=1157.6835021972656\n",
      "epoch 2991\n",
      "test_train\n",
      "train mean loss=0.08606988191604614\n",
      "test_test\n",
      "test mean loss=1156.9354248046875\n",
      "epoch 2992\n",
      "test_train\n",
      "train mean loss=0.08494823674360912\n",
      "test_test\n",
      "test mean loss=1156.7109985351562\n",
      "epoch 2993\n",
      "test_train\n",
      "train mean loss=0.08574399693558614\n",
      "test_test\n",
      "test mean loss=1157.0507202148438\n",
      "epoch 2994\n",
      "test_train\n",
      "train mean loss=0.08265683768937986\n",
      "test_test\n",
      "test mean loss=1157.4358215332031\n",
      "epoch 2995\n",
      "test_train\n",
      "train mean loss=0.08667199810345967\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1155.5972900390625\n",
      "epoch 2996\n",
      "test_train\n",
      "train mean loss=0.09442504029721022\n",
      "test_test\n",
      "test mean loss=1157.3096923828125\n",
      "epoch 2997\n",
      "test_train\n",
      "train mean loss=0.09087053732946515\n",
      "test_test\n",
      "test mean loss=1156.7487182617188\n",
      "epoch 2998\n",
      "test_train\n",
      "train mean loss=0.08449900212387244\n",
      "test_test\n",
      "test mean loss=1156.738037109375\n",
      "epoch 2999\n",
      "test_train\n",
      "train mean loss=0.08657926910867293\n",
      "test_test\n",
      "test mean loss=1156.8583374023438\n",
      "epoch 3000\n",
      "test_train\n",
      "train mean loss=0.08346681296825409\n",
      "test_test\n",
      "test mean loss=1157.5103454589844\n",
      "epoch 3001\n",
      "test_train\n",
      "train mean loss=0.08340675290673971\n",
      "test_test\n",
      "test mean loss=1157.2061462402344\n",
      "epoch 3002\n",
      "test_train\n",
      "train mean loss=0.08665832194189231\n",
      "test_test\n",
      "test mean loss=1158.251708984375\n",
      "epoch 3003\n",
      "test_train\n",
      "train mean loss=0.09097070309023063\n",
      "test_test\n",
      "test mean loss=1157.1502075195312\n",
      "epoch 3004\n",
      "test_train\n",
      "train mean loss=0.08361654697606961\n",
      "test_test\n",
      "test mean loss=1157.0652770996094\n",
      "epoch 3005\n",
      "test_train\n",
      "train mean loss=0.08469999457399051\n",
      "test_test\n",
      "test mean loss=1156.9959411621094\n",
      "epoch 3006\n",
      "test_train\n",
      "train mean loss=0.08320195507258177\n",
      "test_test\n",
      "test mean loss=1157.3901977539062\n",
      "epoch 3007\n",
      "test_train\n",
      "train mean loss=0.08954854185382526\n",
      "test_test\n",
      "test mean loss=1157.0545349121094\n",
      "epoch 3008\n",
      "test_train\n",
      "train mean loss=0.08090969951202472\n",
      "test_test\n",
      "test mean loss=1157.4620971679688\n",
      "epoch 3009\n",
      "test_train\n",
      "train mean loss=0.08078417399277289\n",
      "test_test\n",
      "test mean loss=1157.3580627441406\n",
      "epoch 3010\n",
      "test_train\n",
      "train mean loss=0.08100982569158077\n",
      "test_test\n",
      "test mean loss=1157.1327514648438\n",
      "epoch 3011\n",
      "test_train\n",
      "train mean loss=0.08254692237824202\n",
      "test_test\n",
      "test mean loss=1156.4519653320312\n",
      "epoch 3012\n",
      "test_train\n",
      "train mean loss=0.09879012530048688\n",
      "test_test\n",
      "test mean loss=1158.5963134765625\n",
      "epoch 3013\n",
      "test_train\n",
      "train mean loss=0.08141677392025788\n",
      "test_test\n",
      "test mean loss=1157.3853759765625\n",
      "epoch 3014\n",
      "test_train\n",
      "train mean loss=0.08058399024109046\n",
      "test_test\n",
      "test mean loss=1156.5552978515625\n",
      "epoch 3015\n",
      "test_train\n",
      "train mean loss=0.08462036990871032\n",
      "test_test\n",
      "test mean loss=1156.6135864257812\n",
      "epoch 3016\n",
      "test_train\n",
      "train mean loss=0.0996250519528985\n",
      "test_test\n",
      "test mean loss=1154.6808776855469\n",
      "epoch 3017\n",
      "test_train\n",
      "train mean loss=0.08296752814203501\n",
      "test_test\n",
      "test mean loss=1155.3087768554688\n",
      "epoch 3018\n",
      "test_train\n",
      "train mean loss=0.08129772823303938\n",
      "test_test\n",
      "test mean loss=1154.9027099609375\n",
      "epoch 3019\n",
      "test_train\n",
      "train mean loss=0.0813724681114157\n",
      "test_test\n",
      "test mean loss=1156.6935424804688\n",
      "epoch 3020\n",
      "test_train\n",
      "train mean loss=0.08598954106370608\n",
      "test_test\n",
      "test mean loss=1156.629638671875\n",
      "epoch 3021\n",
      "test_train\n",
      "train mean loss=0.08242251599828403\n",
      "test_test\n",
      "test mean loss=1155.9690246582031\n",
      "epoch 3022\n",
      "test_train\n",
      "train mean loss=0.08100614168991645\n",
      "test_test\n",
      "test mean loss=1156.4608154296875\n",
      "epoch 3023\n",
      "test_train\n",
      "train mean loss=0.07774444824705522\n",
      "test_test\n",
      "test mean loss=1156.5813903808594\n",
      "epoch 3024\n",
      "test_train\n",
      "train mean loss=0.09132651053369045\n",
      "test_test\n",
      "test mean loss=1155.842041015625\n",
      "epoch 3025\n",
      "test_train\n",
      "train mean loss=0.08909136584649484\n",
      "test_test\n",
      "test mean loss=1155.2659301757812\n",
      "epoch 3026\n",
      "test_train\n",
      "train mean loss=0.08151827426627278\n",
      "test_test\n",
      "test mean loss=1155.7227172851562\n",
      "epoch 3027\n",
      "test_train\n",
      "train mean loss=0.08873891147474448\n",
      "test_test\n",
      "test mean loss=1155.9083862304688\n",
      "epoch 3028\n",
      "test_train\n",
      "train mean loss=0.09133051553120215\n",
      "test_test\n",
      "test mean loss=1157.2109985351562\n",
      "epoch 3029\n",
      "test_train\n",
      "train mean loss=0.08408645447343588\n",
      "test_test\n",
      "test mean loss=1156.6032104492188\n",
      "epoch 3030\n",
      "test_train\n",
      "train mean loss=0.08409737547238667\n",
      "test_test\n",
      "test mean loss=1155.6478881835938\n",
      "epoch 3031\n",
      "test_train\n",
      "train mean loss=0.08102994132786989\n",
      "test_test\n",
      "test mean loss=1156.4227294921875\n",
      "epoch 3032\n",
      "test_train\n",
      "train mean loss=0.08376646228134632\n",
      "test_test\n",
      "test mean loss=1157.5409545898438\n",
      "epoch 3033\n",
      "test_train\n",
      "train mean loss=0.08502315388371547\n",
      "test_test\n",
      "test mean loss=1156.7037353515625\n",
      "epoch 3034\n",
      "test_train\n",
      "train mean loss=0.08537341405948003\n",
      "test_test\n",
      "test mean loss=1156.7742004394531\n",
      "epoch 3035\n",
      "test_train\n",
      "train mean loss=0.08742871973663568\n",
      "test_test\n",
      "test mean loss=1156.1035766601562\n",
      "epoch 3036\n",
      "test_train\n",
      "train mean loss=0.09672951853523652\n",
      "test_test\n",
      "test mean loss=1157.0237426757812\n",
      "epoch 3037\n",
      "test_train\n",
      "train mean loss=0.0911428431669871\n",
      "test_test\n",
      "test mean loss=1157.401611328125\n",
      "epoch 3038\n",
      "test_train\n",
      "train mean loss=0.11824994037548701\n",
      "test_test\n",
      "test mean loss=1158.3643798828125\n",
      "epoch 3039\n",
      "test_train\n",
      "train mean loss=0.09127445643146832\n",
      "test_test\n",
      "test mean loss=1157.435302734375\n",
      "epoch 3040\n",
      "test_train\n",
      "train mean loss=0.08557132134834926\n",
      "test_test\n",
      "test mean loss=1156.2128295898438\n",
      "epoch 3041\n",
      "test_train\n",
      "train mean loss=0.09392980237801869\n",
      "test_test\n",
      "test mean loss=1157.1669006347656\n",
      "epoch 3042\n",
      "test_train\n",
      "train mean loss=0.10194568273921807\n",
      "test_test\n",
      "test mean loss=1156.933837890625\n",
      "epoch 3043\n",
      "test_train\n",
      "train mean loss=0.098810448932151\n",
      "test_test\n",
      "test mean loss=1156.9308471679688\n",
      "epoch 3044\n",
      "test_train\n",
      "train mean loss=0.091335058833162\n",
      "test_test\n",
      "test mean loss=1157.0053100585938\n",
      "epoch 3045\n",
      "test_train\n",
      "train mean loss=0.08972973252336185\n",
      "test_test\n",
      "test mean loss=1155.5946044921875\n",
      "epoch 3046\n",
      "test_train\n",
      "train mean loss=0.09695689504345258\n",
      "test_test\n",
      "test mean loss=1155.1919555664062\n",
      "epoch 3047\n",
      "test_train\n",
      "train mean loss=0.09298773854970932\n",
      "test_test\n",
      "test mean loss=1155.837158203125\n",
      "epoch 3048\n",
      "test_train\n",
      "train mean loss=0.09399462724104524\n",
      "test_test\n",
      "test mean loss=1157.1159057617188\n",
      "epoch 3049\n",
      "test_train\n",
      "train mean loss=0.0842764638364315\n",
      "test_test\n",
      "test mean loss=1156.1441650390625\n",
      "epoch 3050\n",
      "test_train\n",
      "train mean loss=0.08207036554813385\n",
      "test_test\n",
      "test mean loss=1156.3551025390625\n",
      "epoch 3051\n",
      "test_train\n",
      "train mean loss=0.08269750823577245\n",
      "test_test\n",
      "test mean loss=1155.9480590820312\n",
      "epoch 3052\n",
      "test_train\n",
      "train mean loss=0.07910946880777676\n",
      "test_test\n",
      "test mean loss=1156.5103149414062\n",
      "epoch 3053\n",
      "test_train\n",
      "train mean loss=0.09447620343416929\n",
      "test_test\n",
      "test mean loss=1156.5465698242188\n",
      "epoch 3054\n",
      "test_train\n",
      "train mean loss=0.08946083951741457\n",
      "test_test\n",
      "test mean loss=1156.58251953125\n",
      "epoch 3055\n",
      "test_train\n",
      "train mean loss=0.09173612203449011\n",
      "test_test\n",
      "test mean loss=1156.9690551757812\n",
      "epoch 3056\n",
      "test_train\n",
      "train mean loss=0.0853575374931097\n",
      "test_test\n",
      "test mean loss=1155.9514770507812\n",
      "epoch 3057\n",
      "test_train\n",
      "train mean loss=0.08151630902041991\n",
      "test_test\n",
      "test mean loss=1154.9772033691406\n",
      "epoch 3058\n",
      "test_train\n",
      "train mean loss=0.08699396904557943\n",
      "test_test\n",
      "test mean loss=1155.7080383300781\n",
      "epoch 3059\n",
      "test_train\n",
      "train mean loss=0.08869106757144134\n",
      "test_test\n",
      "test mean loss=1155.8339233398438\n",
      "epoch 3060\n",
      "test_train\n",
      "train mean loss=0.0825330304602782\n",
      "test_test\n",
      "test mean loss=1155.241943359375\n",
      "epoch 3061\n",
      "test_train\n",
      "train mean loss=0.07832443217436473\n",
      "test_test\n",
      "test mean loss=1155.8727416992188\n",
      "epoch 3062\n",
      "test_train\n",
      "train mean loss=0.08043801101545493\n",
      "test_test\n",
      "test mean loss=1155.8572998046875\n",
      "epoch 3063\n",
      "test_train\n",
      "train mean loss=0.08183202721799414\n",
      "test_test\n",
      "test mean loss=1156.6161499023438\n",
      "epoch 3064\n",
      "test_train\n",
      "train mean loss=0.08380350315322478\n",
      "test_test\n",
      "test mean loss=1156.4157104492188\n",
      "epoch 3065\n",
      "test_train\n",
      "train mean loss=0.08542545946935813\n",
      "test_test\n",
      "test mean loss=1156.3732604980469\n",
      "epoch 3066\n",
      "test_train\n",
      "train mean loss=0.08662440689901511\n",
      "test_test\n",
      "test mean loss=1156.5449523925781\n",
      "epoch 3067\n",
      "test_train\n",
      "train mean loss=0.09840590817232926\n",
      "test_test\n",
      "test mean loss=1157.3270263671875\n",
      "epoch 3068\n",
      "test_train\n",
      "train mean loss=0.08609533620377381\n",
      "test_test\n",
      "test mean loss=1156.7125244140625\n",
      "epoch 3069\n",
      "test_train\n",
      "train mean loss=0.08794366319974263\n",
      "test_test\n",
      "test mean loss=1156.2532653808594\n",
      "epoch 3070\n",
      "test_train\n",
      "train mean loss=0.08481747688104709\n",
      "test_test\n",
      "test mean loss=1156.5592041015625\n",
      "epoch 3071\n",
      "test_train\n",
      "train mean loss=0.07880857307463884\n",
      "test_test\n",
      "test mean loss=1155.5029296875\n",
      "epoch 3072\n",
      "test_train\n",
      "train mean loss=0.08325123507529497\n",
      "test_test\n",
      "test mean loss=1156.6619873046875\n",
      "epoch 3073\n",
      "test_train\n",
      "train mean loss=0.08830087135235469\n",
      "test_test\n",
      "test mean loss=1155.6132202148438\n",
      "epoch 3074\n",
      "test_train\n",
      "train mean loss=0.08927742081383865\n",
      "test_test\n",
      "test mean loss=1156.1851196289062\n",
      "epoch 3075\n",
      "test_train\n",
      "train mean loss=0.08797846517215173\n",
      "test_test\n",
      "test mean loss=1156.9579162597656\n",
      "epoch 3076\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.08766791100303332\n",
      "test_test\n",
      "test mean loss=1157.55615234375\n",
      "epoch 3077\n",
      "test_train\n",
      "train mean loss=0.08630160397539537\n",
      "test_test\n",
      "test mean loss=1155.7251281738281\n",
      "epoch 3078\n",
      "test_train\n",
      "train mean loss=0.08266669542839129\n",
      "test_test\n",
      "test mean loss=1156.0328979492188\n",
      "epoch 3079\n",
      "test_train\n",
      "train mean loss=0.08496907508621614\n",
      "test_test\n",
      "test mean loss=1155.7304077148438\n",
      "epoch 3080\n",
      "test_train\n",
      "train mean loss=0.08347359268615644\n",
      "test_test\n",
      "test mean loss=1156.2810363769531\n",
      "epoch 3081\n",
      "test_train\n",
      "train mean loss=0.08051845710724592\n",
      "test_test\n",
      "test mean loss=1155.0517578125\n",
      "epoch 3082\n",
      "test_train\n",
      "train mean loss=0.08079782376686732\n",
      "test_test\n",
      "test mean loss=1155.4569396972656\n",
      "epoch 3083\n",
      "test_train\n",
      "train mean loss=0.07952757769574721\n",
      "test_test\n",
      "test mean loss=1156.0755310058594\n",
      "epoch 3084\n",
      "test_train\n",
      "train mean loss=0.08336236203710239\n",
      "test_test\n",
      "test mean loss=1155.9046630859375\n",
      "epoch 3085\n",
      "test_train\n",
      "train mean loss=0.07985010308523972\n",
      "test_test\n",
      "test mean loss=1156.0640258789062\n",
      "epoch 3086\n",
      "test_train\n",
      "train mean loss=0.0880949239556988\n",
      "test_test\n",
      "test mean loss=1156.5902099609375\n",
      "epoch 3087\n",
      "test_train\n",
      "train mean loss=0.08513574892034133\n",
      "test_test\n",
      "test mean loss=1156.5367431640625\n",
      "epoch 3088\n",
      "test_train\n",
      "train mean loss=0.09165959401677053\n",
      "test_test\n",
      "test mean loss=1156.5899658203125\n",
      "epoch 3089\n",
      "test_train\n",
      "train mean loss=0.08220354529718558\n",
      "test_test\n",
      "test mean loss=1155.6304931640625\n",
      "epoch 3090\n",
      "test_train\n",
      "train mean loss=0.08227225548277299\n",
      "test_test\n",
      "test mean loss=1155.9254760742188\n",
      "epoch 3091\n",
      "test_train\n",
      "train mean loss=0.08751297245423\n",
      "test_test\n",
      "test mean loss=1156.55810546875\n",
      "epoch 3092\n",
      "test_train\n",
      "train mean loss=0.08260572515428066\n",
      "test_test\n",
      "test mean loss=1156.0701904296875\n",
      "epoch 3093\n",
      "test_train\n",
      "train mean loss=0.10064752989759047\n",
      "test_test\n",
      "test mean loss=1155.783203125\n",
      "epoch 3094\n",
      "test_train\n",
      "train mean loss=0.09446689610679944\n",
      "test_test\n",
      "test mean loss=1155.386962890625\n",
      "epoch 3095\n",
      "test_train\n",
      "train mean loss=0.0860054325312376\n",
      "test_test\n",
      "test mean loss=1155.0768432617188\n",
      "epoch 3096\n",
      "test_train\n",
      "train mean loss=0.12194652048250039\n",
      "test_test\n",
      "test mean loss=1155.6838989257812\n",
      "epoch 3097\n",
      "test_train\n",
      "train mean loss=0.08830865068982045\n",
      "test_test\n",
      "test mean loss=1154.9547424316406\n",
      "epoch 3098\n",
      "test_train\n",
      "train mean loss=0.08306784338007371\n",
      "test_test\n",
      "test mean loss=1156.0015258789062\n",
      "epoch 3099\n",
      "test_train\n",
      "train mean loss=0.08346966064224641\n",
      "test_test\n",
      "test mean loss=1156.2364501953125\n",
      "epoch 3100\n",
      "test_train\n",
      "train mean loss=0.08269732383390267\n",
      "test_test\n",
      "test mean loss=1155.8795776367188\n",
      "epoch 3101\n",
      "test_train\n",
      "train mean loss=0.6194581538438797\n",
      "test_test\n",
      "test mean loss=1158.3570556640625\n",
      "epoch 3102\n",
      "test_train\n",
      "train mean loss=0.14842728028694788\n",
      "test_test\n",
      "test mean loss=1156.9014587402344\n",
      "epoch 3103\n",
      "test_train\n",
      "train mean loss=0.09758304618299007\n",
      "test_test\n",
      "test mean loss=1157.4400024414062\n",
      "epoch 3104\n",
      "test_train\n",
      "train mean loss=0.08732730460663636\n",
      "test_test\n",
      "test mean loss=1157.8666381835938\n",
      "epoch 3105\n",
      "test_train\n",
      "train mean loss=0.09760881339510281\n",
      "test_test\n",
      "test mean loss=1158.215576171875\n",
      "epoch 3106\n",
      "test_train\n",
      "train mean loss=0.10454078080753486\n",
      "test_test\n",
      "test mean loss=1156.795654296875\n",
      "epoch 3107\n",
      "test_train\n",
      "train mean loss=0.1202267234524091\n",
      "test_test\n",
      "test mean loss=1160.2517700195312\n",
      "epoch 3108\n",
      "test_train\n",
      "train mean loss=0.10681885853409767\n",
      "test_test\n",
      "test mean loss=1156.939453125\n",
      "epoch 3109\n",
      "test_train\n",
      "train mean loss=0.10655214823782444\n",
      "test_test\n",
      "test mean loss=1155.7188110351562\n",
      "epoch 3110\n",
      "test_train\n",
      "train mean loss=0.09407344770928223\n",
      "test_test\n",
      "test mean loss=1155.9579467773438\n",
      "epoch 3111\n",
      "test_train\n",
      "train mean loss=0.09255616397907336\n",
      "test_test\n",
      "test mean loss=1155.2326049804688\n",
      "epoch 3112\n",
      "test_train\n",
      "train mean loss=0.08733522302160661\n",
      "test_test\n",
      "test mean loss=1154.9027099609375\n",
      "epoch 3113\n",
      "test_train\n",
      "train mean loss=0.09067936272670825\n",
      "test_test\n",
      "test mean loss=1153.9375\n",
      "epoch 3114\n",
      "test_train\n",
      "train mean loss=0.08667145669460297\n",
      "test_test\n",
      "test mean loss=1155.9725341796875\n",
      "epoch 3115\n",
      "test_train\n",
      "train mean loss=0.10035089993228515\n",
      "test_test\n",
      "test mean loss=1155.640869140625\n",
      "epoch 3116\n",
      "test_train\n",
      "train mean loss=0.09199302581449349\n",
      "test_test\n",
      "test mean loss=1156.087158203125\n",
      "epoch 3117\n",
      "test_train\n",
      "train mean loss=0.08997717810173829\n",
      "test_test\n",
      "test mean loss=1156.0708618164062\n",
      "epoch 3118\n",
      "test_train\n",
      "train mean loss=0.08876759745180607\n",
      "test_test\n",
      "test mean loss=1155.0510864257812\n",
      "epoch 3119\n",
      "test_train\n",
      "train mean loss=0.08547608026613791\n",
      "test_test\n",
      "test mean loss=1155.330078125\n",
      "epoch 3120\n",
      "test_train\n",
      "train mean loss=0.08840800169855356\n",
      "test_test\n",
      "test mean loss=1156.0764770507812\n",
      "epoch 3121\n",
      "test_train\n",
      "train mean loss=0.08844558925678332\n",
      "test_test\n",
      "test mean loss=1155.1516723632812\n",
      "epoch 3122\n",
      "test_train\n",
      "train mean loss=0.09731628497441609\n",
      "test_test\n",
      "test mean loss=1156.1210021972656\n",
      "epoch 3123\n",
      "test_train\n",
      "train mean loss=0.08549920779963334\n",
      "test_test\n",
      "test mean loss=1155.9918823242188\n",
      "epoch 3124\n",
      "test_train\n",
      "train mean loss=0.08185018909474213\n",
      "test_test\n",
      "test mean loss=1156.5726928710938\n",
      "epoch 3125\n",
      "test_train\n",
      "train mean loss=0.07980125242223342\n",
      "test_test\n",
      "test mean loss=1156.7508544921875\n",
      "epoch 3126\n",
      "test_train\n",
      "train mean loss=0.09815457463264465\n",
      "test_test\n",
      "test mean loss=1155.7683715820312\n",
      "epoch 3127\n",
      "test_train\n",
      "train mean loss=0.08854273116836946\n",
      "test_test\n",
      "test mean loss=1156.316650390625\n",
      "epoch 3128\n",
      "test_train\n",
      "train mean loss=0.08649877458810806\n",
      "test_test\n",
      "test mean loss=1156.7176208496094\n",
      "epoch 3129\n",
      "test_train\n",
      "train mean loss=0.08754412457346916\n",
      "test_test\n",
      "test mean loss=1155.924072265625\n",
      "epoch 3130\n",
      "test_train\n",
      "train mean loss=0.12037599893907706\n",
      "test_test\n",
      "test mean loss=1157.7830810546875\n",
      "epoch 3131\n",
      "test_train\n",
      "train mean loss=0.09517497755587101\n",
      "test_test\n",
      "test mean loss=1155.6141662597656\n",
      "epoch 3132\n",
      "test_train\n",
      "train mean loss=0.09254821048428614\n",
      "test_test\n",
      "test mean loss=1157.0536499023438\n",
      "epoch 3133\n",
      "test_train\n",
      "train mean loss=0.09230139665305614\n",
      "test_test\n",
      "test mean loss=1156.057373046875\n",
      "epoch 3134\n",
      "test_train\n",
      "train mean loss=0.08931681048125029\n",
      "test_test\n",
      "test mean loss=1156.614013671875\n",
      "epoch 3135\n",
      "test_train\n",
      "train mean loss=0.0882609011605382\n",
      "test_test\n",
      "test mean loss=1157.1446838378906\n",
      "epoch 3136\n",
      "test_train\n",
      "train mean loss=0.09317354174951713\n",
      "test_test\n",
      "test mean loss=1156.5947265625\n",
      "epoch 3137\n",
      "test_train\n",
      "train mean loss=0.09499373597403367\n",
      "test_test\n",
      "test mean loss=1155.5211486816406\n",
      "epoch 3138\n",
      "test_train\n",
      "train mean loss=0.08519895126422246\n",
      "test_test\n",
      "test mean loss=1155.9570922851562\n",
      "epoch 3139\n",
      "test_train\n",
      "train mean loss=0.09035162689785163\n",
      "test_test\n",
      "test mean loss=1156.2041015625\n",
      "epoch 3140\n",
      "test_train\n",
      "train mean loss=0.10496316384524107\n",
      "test_test\n",
      "test mean loss=1157.7005920410156\n",
      "epoch 3141\n",
      "test_train\n",
      "train mean loss=0.11279531350980203\n",
      "test_test\n",
      "test mean loss=1156.5867004394531\n",
      "epoch 3142\n",
      "test_train\n",
      "train mean loss=0.09683846185604732\n",
      "test_test\n",
      "test mean loss=1156.0330505371094\n",
      "epoch 3143\n",
      "test_train\n",
      "train mean loss=0.08605109807103872\n",
      "test_test\n",
      "test mean loss=1156.8744812011719\n",
      "epoch 3144\n",
      "test_train\n",
      "train mean loss=0.0865127199018995\n",
      "test_test\n",
      "test mean loss=1157.205322265625\n",
      "epoch 3145\n",
      "test_train\n",
      "train mean loss=0.08926233773430188\n",
      "test_test\n",
      "test mean loss=1155.8963623046875\n",
      "epoch 3146\n",
      "test_train\n",
      "train mean loss=0.07935283457239468\n",
      "test_test\n",
      "test mean loss=1157.2830505371094\n",
      "epoch 3147\n",
      "test_train\n",
      "train mean loss=0.08931774956484635\n",
      "test_test\n",
      "test mean loss=1156.3782348632812\n",
      "epoch 3148\n",
      "test_train\n",
      "train mean loss=0.08519487703839938\n",
      "test_test\n",
      "test mean loss=1155.5001220703125\n",
      "epoch 3149\n",
      "test_train\n",
      "train mean loss=0.0821814111744364\n",
      "test_test\n",
      "test mean loss=1156.5196533203125\n",
      "epoch 3150\n",
      "test_train\n",
      "train mean loss=0.09492017918576796\n",
      "test_test\n",
      "test mean loss=1156.9471130371094\n",
      "epoch 3151\n",
      "test_train\n",
      "train mean loss=0.09020773290346067\n",
      "test_test\n",
      "test mean loss=1156.5625305175781\n",
      "epoch 3152\n",
      "test_train\n",
      "train mean loss=0.08301275875419378\n",
      "test_test\n",
      "test mean loss=1157.0407409667969\n",
      "epoch 3153\n",
      "test_train\n",
      "train mean loss=0.08797754968206088\n",
      "test_test\n",
      "test mean loss=1157.4144287109375\n",
      "epoch 3154\n",
      "test_train\n",
      "train mean loss=0.08705948169032733\n",
      "test_test\n",
      "test mean loss=1156.2820434570312\n",
      "epoch 3155\n",
      "test_train\n",
      "train mean loss=0.08402251824736595\n",
      "test_test\n",
      "test mean loss=1157.1367797851562\n",
      "epoch 3156\n",
      "test_train\n",
      "train mean loss=0.0850654582803448\n",
      "test_test\n",
      "test mean loss=1156.4088439941406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3157\n",
      "test_train\n",
      "train mean loss=0.08398419711738825\n",
      "test_test\n",
      "test mean loss=1157.3759155273438\n",
      "epoch 3158\n",
      "test_train\n",
      "train mean loss=0.09043142541001241\n",
      "test_test\n",
      "test mean loss=1157.3941650390625\n",
      "epoch 3159\n",
      "test_train\n",
      "train mean loss=0.08723770454525948\n",
      "test_test\n",
      "test mean loss=1156.7685546875\n",
      "epoch 3160\n",
      "test_train\n",
      "train mean loss=0.08536539288858573\n",
      "test_test\n",
      "test mean loss=1156.8480224609375\n",
      "epoch 3161\n",
      "test_train\n",
      "train mean loss=0.09285691690941651\n",
      "test_test\n",
      "test mean loss=1157.7857055664062\n",
      "epoch 3162\n",
      "test_train\n",
      "train mean loss=0.1151321716606617\n",
      "test_test\n",
      "test mean loss=1157.3814086914062\n",
      "epoch 3163\n",
      "test_train\n",
      "train mean loss=0.10723351935545604\n",
      "test_test\n",
      "test mean loss=1158.0999450683594\n",
      "epoch 3164\n",
      "test_train\n",
      "train mean loss=0.10165048018097878\n",
      "test_test\n",
      "test mean loss=1157.7205200195312\n",
      "epoch 3165\n",
      "test_train\n",
      "train mean loss=0.09166510806729396\n",
      "test_test\n",
      "test mean loss=1156.8699951171875\n",
      "epoch 3166\n",
      "test_train\n",
      "train mean loss=0.08239263575524092\n",
      "test_test\n",
      "test mean loss=1156.9860229492188\n",
      "epoch 3167\n",
      "test_train\n",
      "train mean loss=0.08361499446133773\n",
      "test_test\n",
      "test mean loss=1157.0757446289062\n",
      "epoch 3168\n",
      "test_train\n",
      "train mean loss=0.08769524407883485\n",
      "test_test\n",
      "test mean loss=1155.8465881347656\n",
      "epoch 3169\n",
      "test_train\n",
      "train mean loss=0.0824322843303283\n",
      "test_test\n",
      "test mean loss=1156.0627136230469\n",
      "epoch 3170\n",
      "test_train\n",
      "train mean loss=0.09113031315306823\n",
      "test_test\n",
      "test mean loss=1156.8443603515625\n",
      "epoch 3171\n",
      "test_train\n",
      "train mean loss=0.09994348883628845\n",
      "test_test\n",
      "test mean loss=1157.882080078125\n",
      "epoch 3172\n",
      "test_train\n",
      "train mean loss=0.09027944225817919\n",
      "test_test\n",
      "test mean loss=1156.3924560546875\n",
      "epoch 3173\n",
      "test_train\n",
      "train mean loss=0.08981102270384629\n",
      "test_test\n",
      "test mean loss=1156.7301940917969\n",
      "epoch 3174\n",
      "test_train\n",
      "train mean loss=0.10114861031373341\n",
      "test_test\n",
      "test mean loss=1157.4222412109375\n",
      "epoch 3175\n",
      "test_train\n",
      "train mean loss=0.08776528822878997\n",
      "test_test\n",
      "test mean loss=1156.256591796875\n",
      "epoch 3176\n",
      "test_train\n",
      "train mean loss=0.16815269676347575\n",
      "test_test\n",
      "test mean loss=1156.9844970703125\n",
      "epoch 3177\n",
      "test_train\n",
      "train mean loss=0.09594566468149424\n",
      "test_test\n",
      "test mean loss=1156.5795288085938\n",
      "epoch 3178\n",
      "test_train\n",
      "train mean loss=0.0826704849799474\n",
      "test_test\n",
      "test mean loss=1156.490478515625\n",
      "epoch 3179\n",
      "test_train\n",
      "train mean loss=0.08203484211117029\n",
      "test_test\n",
      "test mean loss=1155.5686645507812\n",
      "epoch 3180\n",
      "test_train\n",
      "train mean loss=0.09524584313233693\n",
      "test_test\n",
      "test mean loss=1155.7358093261719\n",
      "epoch 3181\n",
      "test_train\n",
      "train mean loss=0.08350851417829593\n",
      "test_test\n",
      "test mean loss=1155.8384399414062\n",
      "epoch 3182\n",
      "test_train\n",
      "train mean loss=0.08475499351819356\n",
      "test_test\n",
      "test mean loss=1157.0537109375\n",
      "epoch 3183\n",
      "test_train\n",
      "train mean loss=0.07868320712198813\n",
      "test_test\n",
      "test mean loss=1156.4323120117188\n",
      "epoch 3184\n",
      "test_train\n",
      "train mean loss=0.1099556057403485\n",
      "test_test\n",
      "test mean loss=1156.0950317382812\n",
      "epoch 3185\n",
      "test_train\n",
      "train mean loss=0.0884958306948344\n",
      "test_test\n",
      "test mean loss=1155.5505065917969\n",
      "epoch 3186\n",
      "test_train\n",
      "train mean loss=0.09668658518542846\n",
      "test_test\n",
      "test mean loss=1157.00732421875\n",
      "epoch 3187\n",
      "test_train\n",
      "train mean loss=0.09059665041665237\n",
      "test_test\n",
      "test mean loss=1155.697998046875\n",
      "epoch 3188\n",
      "test_train\n",
      "train mean loss=0.09080213898171981\n",
      "test_test\n",
      "test mean loss=1156.3611450195312\n",
      "epoch 3189\n",
      "test_train\n",
      "train mean loss=0.09025891994436581\n",
      "test_test\n",
      "test mean loss=1156.1946105957031\n",
      "epoch 3190\n",
      "test_train\n",
      "train mean loss=0.08283574786037207\n",
      "test_test\n",
      "test mean loss=1155.7664794921875\n",
      "epoch 3191\n",
      "test_train\n",
      "train mean loss=0.07657724680999915\n",
      "test_test\n",
      "test mean loss=1155.705322265625\n",
      "epoch 3192\n",
      "test_train\n",
      "train mean loss=0.08047728644063075\n",
      "test_test\n",
      "test mean loss=1155.642578125\n",
      "epoch 3193\n",
      "test_train\n",
      "train mean loss=0.08399879839271307\n",
      "test_test\n",
      "test mean loss=1156.4215698242188\n",
      "epoch 3194\n",
      "test_train\n",
      "train mean loss=0.10486474509040515\n",
      "test_test\n",
      "test mean loss=1156.47900390625\n",
      "epoch 3195\n",
      "test_train\n",
      "train mean loss=0.12354426210125287\n",
      "test_test\n",
      "test mean loss=1158.5006103515625\n",
      "epoch 3196\n",
      "test_train\n",
      "train mean loss=0.08433427289128304\n",
      "test_test\n",
      "test mean loss=1157.6922302246094\n",
      "epoch 3197\n",
      "test_train\n",
      "train mean loss=0.09526451614995797\n",
      "test_test\n",
      "test mean loss=1156.256591796875\n",
      "epoch 3198\n",
      "test_train\n",
      "train mean loss=0.09108444768935442\n",
      "test_test\n",
      "test mean loss=1156.3371887207031\n",
      "epoch 3199\n",
      "test_train\n",
      "train mean loss=0.08640852104872465\n",
      "test_test\n",
      "test mean loss=1157.5733032226562\n",
      "epoch 3200\n",
      "test_train\n",
      "train mean loss=0.08610659465193748\n",
      "test_test\n",
      "test mean loss=1157.0115356445312\n",
      "epoch 3201\n",
      "test_train\n",
      "train mean loss=0.0895472861205538\n",
      "test_test\n",
      "test mean loss=1156.2679443359375\n",
      "epoch 3202\n",
      "test_train\n",
      "train mean loss=0.0959239574149251\n",
      "test_test\n",
      "test mean loss=1157.3318481445312\n",
      "epoch 3203\n",
      "test_train\n",
      "train mean loss=0.09164208546280861\n",
      "test_test\n",
      "test mean loss=1157.8770751953125\n",
      "epoch 3204\n",
      "test_train\n",
      "train mean loss=0.07669511282195647\n",
      "test_test\n",
      "test mean loss=1156.2520446777344\n",
      "epoch 3205\n",
      "test_train\n",
      "train mean loss=0.0852522999048233\n",
      "test_test\n",
      "test mean loss=1156.7457275390625\n",
      "epoch 3206\n",
      "test_train\n",
      "train mean loss=0.08844983205199242\n",
      "test_test\n",
      "test mean loss=1156.7939147949219\n",
      "epoch 3207\n",
      "test_train\n",
      "train mean loss=0.08549711635957162\n",
      "test_test\n",
      "test mean loss=1157.04541015625\n",
      "epoch 3208\n",
      "test_train\n",
      "train mean loss=0.08445201193292935\n",
      "test_test\n",
      "test mean loss=1156.78662109375\n",
      "epoch 3209\n",
      "test_train\n",
      "train mean loss=0.08958758910497029\n",
      "test_test\n",
      "test mean loss=1155.984130859375\n",
      "epoch 3210\n",
      "test_train\n",
      "train mean loss=0.0841723137224714\n",
      "test_test\n",
      "test mean loss=1155.5750732421875\n",
      "epoch 3211\n",
      "test_train\n",
      "train mean loss=0.09218818694353104\n",
      "test_test\n",
      "test mean loss=1157.5054321289062\n",
      "epoch 3212\n",
      "test_train\n",
      "train mean loss=0.08861107596506675\n",
      "test_test\n",
      "test mean loss=1154.8012084960938\n",
      "epoch 3213\n",
      "test_train\n",
      "train mean loss=0.08901687463124593\n",
      "test_test\n",
      "test mean loss=1155.5696716308594\n",
      "epoch 3214\n",
      "test_train\n",
      "train mean loss=0.08504159484679501\n",
      "test_test\n",
      "test mean loss=1155.2527465820312\n",
      "epoch 3215\n",
      "test_train\n",
      "train mean loss=0.08453241145859162\n",
      "test_test\n",
      "test mean loss=1156.65673828125\n",
      "epoch 3216\n",
      "test_train\n",
      "train mean loss=0.08070726164927085\n",
      "test_test\n",
      "test mean loss=1156.2314758300781\n",
      "epoch 3217\n",
      "test_train\n",
      "train mean loss=0.07873942144215107\n",
      "test_test\n",
      "test mean loss=1156.3406372070312\n",
      "epoch 3218\n",
      "test_train\n",
      "train mean loss=0.08003486475596826\n",
      "test_test\n",
      "test mean loss=1156.2610473632812\n",
      "epoch 3219\n",
      "test_train\n",
      "train mean loss=0.09073435856650273\n",
      "test_test\n",
      "test mean loss=1156.4718017578125\n",
      "epoch 3220\n",
      "test_train\n",
      "train mean loss=0.08347875128189723\n",
      "test_test\n",
      "test mean loss=1155.6300048828125\n",
      "epoch 3221\n",
      "test_train\n",
      "train mean loss=0.08448298710087936\n",
      "test_test\n",
      "test mean loss=1155.6361694335938\n",
      "epoch 3222\n",
      "test_train\n",
      "train mean loss=0.10507065368195374\n",
      "test_test\n",
      "test mean loss=1156.1938171386719\n",
      "epoch 3223\n",
      "test_train\n",
      "train mean loss=0.08729397474477689\n",
      "test_test\n",
      "test mean loss=1155.488525390625\n",
      "epoch 3224\n",
      "test_train\n",
      "train mean loss=0.12108808321257432\n",
      "test_test\n",
      "test mean loss=1154.7667846679688\n",
      "epoch 3225\n",
      "test_train\n",
      "train mean loss=0.08903671770046155\n",
      "test_test\n",
      "test mean loss=1155.9093627929688\n",
      "epoch 3226\n",
      "test_train\n",
      "train mean loss=0.08363443923493226\n",
      "test_test\n",
      "test mean loss=1157.0246887207031\n",
      "epoch 3227\n",
      "test_train\n",
      "train mean loss=0.09117816668003798\n",
      "test_test\n",
      "test mean loss=1157.463134765625\n",
      "epoch 3228\n",
      "test_train\n",
      "train mean loss=0.08618502225726843\n",
      "test_test\n",
      "test mean loss=1156.7742309570312\n",
      "epoch 3229\n",
      "test_train\n",
      "train mean loss=0.07957058120518923\n",
      "test_test\n",
      "test mean loss=1155.8569030761719\n",
      "epoch 3230\n",
      "test_train\n",
      "train mean loss=0.07533927758534749\n",
      "test_test\n",
      "test mean loss=1154.6234130859375\n",
      "epoch 3231\n",
      "test_train\n",
      "train mean loss=0.08645708796878655\n",
      "test_test\n",
      "test mean loss=1155.688720703125\n",
      "epoch 3232\n",
      "test_train\n",
      "train mean loss=0.08887030680974324\n",
      "test_test\n",
      "test mean loss=1156.08544921875\n",
      "epoch 3233\n",
      "test_train\n",
      "train mean loss=0.08294417709112167\n",
      "test_test\n",
      "test mean loss=1154.0797119140625\n",
      "epoch 3234\n",
      "test_train\n",
      "train mean loss=0.07894213854645689\n",
      "test_test\n",
      "test mean loss=1154.298828125\n",
      "epoch 3235\n",
      "test_train\n",
      "train mean loss=0.13008076387147108\n",
      "test_test\n",
      "test mean loss=1152.5647583007812\n",
      "epoch 3236\n",
      "test_train\n",
      "train mean loss=0.09524830927451451\n",
      "test_test\n",
      "test mean loss=1154.8529663085938\n",
      "epoch 3237\n",
      "test_train\n",
      "train mean loss=0.08221974472204845\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1154.98291015625\n",
      "epoch 3238\n",
      "test_train\n",
      "train mean loss=0.08971776999533176\n",
      "test_test\n",
      "test mean loss=1155.8592834472656\n",
      "epoch 3239\n",
      "test_train\n",
      "train mean loss=0.08039905906965335\n",
      "test_test\n",
      "test mean loss=1154.8605346679688\n",
      "epoch 3240\n",
      "test_train\n",
      "train mean loss=0.08353809112062056\n",
      "test_test\n",
      "test mean loss=1154.6593017578125\n",
      "epoch 3241\n",
      "test_train\n",
      "train mean loss=0.08954293405016263\n",
      "test_test\n",
      "test mean loss=1155.69384765625\n",
      "epoch 3242\n",
      "test_train\n",
      "train mean loss=0.08871491036067407\n",
      "test_test\n",
      "test mean loss=1156.654541015625\n",
      "epoch 3243\n",
      "test_train\n",
      "train mean loss=0.08226400737961133\n",
      "test_test\n",
      "test mean loss=1155.1553344726562\n",
      "epoch 3244\n",
      "test_train\n",
      "train mean loss=0.10195446790506442\n",
      "test_test\n",
      "test mean loss=1155.3063354492188\n",
      "epoch 3245\n",
      "test_train\n",
      "train mean loss=0.0879882328833143\n",
      "test_test\n",
      "test mean loss=1156.115966796875\n",
      "epoch 3246\n",
      "test_train\n",
      "train mean loss=0.38212888812025386\n",
      "test_test\n",
      "test mean loss=1154.9642944335938\n",
      "epoch 3247\n",
      "test_train\n",
      "train mean loss=0.08991454044977824\n",
      "test_test\n",
      "test mean loss=1156.4908752441406\n",
      "epoch 3248\n",
      "test_train\n",
      "train mean loss=0.09102352894842625\n",
      "test_test\n",
      "test mean loss=1157.0830688476562\n",
      "epoch 3249\n",
      "test_train\n",
      "train mean loss=0.08773065482576688\n",
      "test_test\n",
      "test mean loss=1156.9154052734375\n",
      "epoch 3250\n",
      "test_train\n",
      "train mean loss=0.08920707398404677\n",
      "test_test\n",
      "test mean loss=1157.827880859375\n",
      "epoch 3251\n",
      "test_train\n",
      "train mean loss=0.10300078429281712\n",
      "test_test\n",
      "test mean loss=1156.4013061523438\n",
      "epoch 3252\n",
      "test_train\n",
      "train mean loss=0.08842955374469359\n",
      "test_test\n",
      "test mean loss=1156.98779296875\n",
      "epoch 3253\n",
      "test_train\n",
      "train mean loss=0.08500662663330634\n",
      "test_test\n",
      "test mean loss=1156.3407287597656\n",
      "epoch 3254\n",
      "test_train\n",
      "train mean loss=0.08235366828739643\n",
      "test_test\n",
      "test mean loss=1155.49853515625\n",
      "epoch 3255\n",
      "test_train\n",
      "train mean loss=0.08148362518598636\n",
      "test_test\n",
      "test mean loss=1156.22216796875\n",
      "epoch 3256\n",
      "test_train\n",
      "train mean loss=0.08825089534123738\n",
      "test_test\n",
      "test mean loss=1156.0068969726562\n",
      "epoch 3257\n",
      "test_train\n",
      "train mean loss=0.08197947374234597\n",
      "test_test\n",
      "test mean loss=1157.1511840820312\n",
      "epoch 3258\n",
      "test_train\n",
      "train mean loss=0.08418852277100086\n",
      "test_test\n",
      "test mean loss=1157.5272216796875\n",
      "epoch 3259\n",
      "test_train\n",
      "train mean loss=0.08053740827987592\n",
      "test_test\n",
      "test mean loss=1157.1727600097656\n",
      "epoch 3260\n",
      "test_train\n",
      "train mean loss=0.08503713303556044\n",
      "test_test\n",
      "test mean loss=1155.8318481445312\n",
      "epoch 3261\n",
      "test_train\n",
      "train mean loss=0.08315940480679274\n",
      "test_test\n",
      "test mean loss=1156.9812316894531\n",
      "epoch 3262\n",
      "test_train\n",
      "train mean loss=0.09110476883749168\n",
      "test_test\n",
      "test mean loss=1156.8650512695312\n",
      "epoch 3263\n",
      "test_train\n",
      "train mean loss=0.08150103408843279\n",
      "test_test\n",
      "test mean loss=1157.5120849609375\n",
      "epoch 3264\n",
      "test_train\n",
      "train mean loss=0.07810594172527392\n",
      "test_test\n",
      "test mean loss=1156.7525939941406\n",
      "epoch 3265\n",
      "test_train\n",
      "train mean loss=0.08251406687001388\n",
      "test_test\n",
      "test mean loss=1156.8542785644531\n",
      "epoch 3266\n",
      "test_train\n",
      "train mean loss=0.07957977584252755\n",
      "test_test\n",
      "test mean loss=1157.1785888671875\n",
      "epoch 3267\n",
      "test_train\n",
      "train mean loss=0.08393174409866333\n",
      "test_test\n",
      "test mean loss=1156.5260009765625\n",
      "epoch 3268\n",
      "test_train\n",
      "train mean loss=0.08112536650151014\n",
      "test_test\n",
      "test mean loss=1157.277587890625\n",
      "epoch 3269\n",
      "test_train\n",
      "train mean loss=0.0926582192381223\n",
      "test_test\n",
      "test mean loss=1158.3170471191406\n",
      "epoch 3270\n",
      "test_train\n",
      "train mean loss=0.0867422241717577\n",
      "test_test\n",
      "test mean loss=1158.5784301757812\n",
      "epoch 3271\n",
      "test_train\n",
      "train mean loss=0.09254523211469252\n",
      "test_test\n",
      "test mean loss=1157.0276489257812\n",
      "epoch 3272\n",
      "test_train\n",
      "train mean loss=0.08385758909086387\n",
      "test_test\n",
      "test mean loss=1157.1965942382812\n",
      "epoch 3273\n",
      "test_train\n",
      "train mean loss=0.08045806704709928\n",
      "test_test\n",
      "test mean loss=1157.5160522460938\n",
      "epoch 3274\n",
      "test_train\n",
      "train mean loss=0.08569577522575855\n",
      "test_test\n",
      "test mean loss=1158.3738403320312\n",
      "epoch 3275\n",
      "test_train\n",
      "train mean loss=0.08444287565847237\n",
      "test_test\n",
      "test mean loss=1157.456298828125\n",
      "epoch 3276\n",
      "test_train\n",
      "train mean loss=0.08354001212865114\n",
      "test_test\n",
      "test mean loss=1156.4039611816406\n",
      "epoch 3277\n",
      "test_train\n",
      "train mean loss=0.08871862106025219\n",
      "test_test\n",
      "test mean loss=1156.7022094726562\n",
      "epoch 3278\n",
      "test_train\n",
      "train mean loss=0.0877843676134944\n",
      "test_test\n",
      "test mean loss=1157.7254638671875\n",
      "epoch 3279\n",
      "test_train\n",
      "train mean loss=0.08116071081409852\n",
      "test_test\n",
      "test mean loss=1156.83544921875\n",
      "epoch 3280\n",
      "test_train\n",
      "train mean loss=0.07765073515474796\n",
      "test_test\n",
      "test mean loss=1157.6576538085938\n",
      "epoch 3281\n",
      "test_train\n",
      "train mean loss=0.08601407427340746\n",
      "test_test\n",
      "test mean loss=1158.2182006835938\n",
      "epoch 3282\n",
      "test_train\n",
      "train mean loss=0.08486192176739375\n",
      "test_test\n",
      "test mean loss=1157.59619140625\n",
      "epoch 3283\n",
      "test_train\n",
      "train mean loss=0.08102524187415838\n",
      "test_test\n",
      "test mean loss=1156.5494689941406\n",
      "epoch 3284\n",
      "test_train\n",
      "train mean loss=0.08163116841266553\n",
      "test_test\n",
      "test mean loss=1156.4744262695312\n",
      "epoch 3285\n",
      "test_train\n",
      "train mean loss=0.07931537212183078\n",
      "test_test\n",
      "test mean loss=1157.5361328125\n",
      "epoch 3286\n",
      "test_train\n",
      "train mean loss=0.08073525161792834\n",
      "test_test\n",
      "test mean loss=1156.30810546875\n",
      "epoch 3287\n",
      "test_train\n",
      "train mean loss=0.08400365865478913\n",
      "test_test\n",
      "test mean loss=1156.505126953125\n",
      "epoch 3288\n",
      "test_train\n",
      "train mean loss=0.0818889420479536\n",
      "test_test\n",
      "test mean loss=1157.537109375\n",
      "epoch 3289\n",
      "test_train\n",
      "train mean loss=0.08173727461447318\n",
      "test_test\n",
      "test mean loss=1157.356201171875\n",
      "epoch 3290\n",
      "test_train\n",
      "train mean loss=0.08240656151125829\n",
      "test_test\n",
      "test mean loss=1156.7857666015625\n",
      "epoch 3291\n",
      "test_train\n",
      "train mean loss=0.08364866953343153\n",
      "test_test\n",
      "test mean loss=1157.5973510742188\n",
      "epoch 3292\n",
      "test_train\n",
      "train mean loss=0.09582107203702132\n",
      "test_test\n",
      "test mean loss=1157.4584350585938\n",
      "epoch 3293\n",
      "test_train\n",
      "train mean loss=0.08658819397290547\n",
      "test_test\n",
      "test mean loss=1157.3101806640625\n",
      "epoch 3294\n",
      "test_train\n",
      "train mean loss=0.08203921063492696\n",
      "test_test\n",
      "test mean loss=1158.483642578125\n",
      "epoch 3295\n",
      "test_train\n",
      "train mean loss=0.07721652059505384\n",
      "test_test\n",
      "test mean loss=1158.2628479003906\n",
      "epoch 3296\n",
      "test_train\n",
      "train mean loss=0.07660978566855192\n",
      "test_test\n",
      "test mean loss=1156.8220520019531\n",
      "epoch 3297\n",
      "test_train\n",
      "train mean loss=0.0789113078887264\n",
      "test_test\n",
      "test mean loss=1157.4178771972656\n",
      "epoch 3298\n",
      "test_train\n",
      "train mean loss=0.08106342982500792\n",
      "test_test\n",
      "test mean loss=1155.8795471191406\n",
      "epoch 3299\n",
      "test_train\n",
      "train mean loss=0.07959328715999921\n",
      "test_test\n",
      "test mean loss=1156.3182373046875\n",
      "epoch 3300\n",
      "test_train\n",
      "train mean loss=0.07957303089400132\n",
      "test_test\n",
      "test mean loss=1156.7345886230469\n",
      "epoch 3301\n",
      "test_train\n",
      "train mean loss=0.08232851264377435\n",
      "test_test\n",
      "test mean loss=1156.8889770507812\n",
      "epoch 3302\n",
      "test_train\n",
      "train mean loss=0.07924710183093946\n",
      "test_test\n",
      "test mean loss=1156.7974243164062\n",
      "epoch 3303\n",
      "test_train\n",
      "train mean loss=0.08051927108317614\n",
      "test_test\n",
      "test mean loss=1158.8474426269531\n",
      "epoch 3304\n",
      "test_train\n",
      "train mean loss=0.07442661095410585\n",
      "test_test\n",
      "test mean loss=1156.9650573730469\n",
      "epoch 3305\n",
      "test_train\n",
      "train mean loss=0.08559905644506216\n",
      "test_test\n",
      "test mean loss=1157.0399780273438\n",
      "epoch 3306\n",
      "test_train\n",
      "train mean loss=0.07797527747849624\n",
      "test_test\n",
      "test mean loss=1157.7345581054688\n",
      "epoch 3307\n",
      "test_train\n",
      "train mean loss=0.08189196822543938\n",
      "test_test\n",
      "test mean loss=1157.7571411132812\n",
      "epoch 3308\n",
      "test_train\n",
      "train mean loss=0.0865503391250968\n",
      "test_test\n",
      "test mean loss=1158.6644897460938\n",
      "epoch 3309\n",
      "test_train\n",
      "train mean loss=0.08670227974653244\n",
      "test_test\n",
      "test mean loss=1157.6558227539062\n",
      "epoch 3310\n",
      "test_train\n",
      "train mean loss=0.08025259835024674\n",
      "test_test\n",
      "test mean loss=1157.5503845214844\n",
      "epoch 3311\n",
      "test_train\n",
      "train mean loss=0.08299418073147535\n",
      "test_test\n",
      "test mean loss=1158.0286254882812\n",
      "epoch 3312\n",
      "test_train\n",
      "train mean loss=1.8923316995302837\n",
      "test_test\n",
      "test mean loss=1150.9446411132812\n",
      "epoch 3313\n",
      "test_train\n",
      "train mean loss=0.16219070429603258\n",
      "test_test\n",
      "test mean loss=1159.5660705566406\n",
      "epoch 3314\n",
      "test_train\n",
      "train mean loss=0.15719251769284406\n",
      "test_test\n",
      "test mean loss=1160.0826110839844\n",
      "epoch 3315\n",
      "test_train\n",
      "train mean loss=0.09386578326423962\n",
      "test_test\n",
      "test mean loss=1159.6942138671875\n",
      "epoch 3316\n",
      "test_train\n",
      "train mean loss=0.09205451638748248\n",
      "test_test\n",
      "test mean loss=1158.8125\n",
      "epoch 3317\n",
      "test_train\n",
      "train mean loss=0.08474795209864776\n",
      "test_test\n",
      "test mean loss=1159.2904663085938\n",
      "epoch 3318\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.08366461501767238\n",
      "test_test\n",
      "test mean loss=1157.8128051757812\n",
      "epoch 3319\n",
      "test_train\n",
      "train mean loss=0.10843962679306667\n",
      "test_test\n",
      "test mean loss=1157.9932861328125\n",
      "epoch 3320\n",
      "test_train\n",
      "train mean loss=0.09080812272926171\n",
      "test_test\n",
      "test mean loss=1158.5902404785156\n",
      "epoch 3321\n",
      "test_train\n",
      "train mean loss=0.0872939129670461\n",
      "test_test\n",
      "test mean loss=1158.4779663085938\n",
      "epoch 3322\n",
      "test_train\n",
      "train mean loss=0.09505054261535406\n",
      "test_test\n",
      "test mean loss=1159.242919921875\n",
      "epoch 3323\n",
      "test_train\n",
      "train mean loss=0.08805008574078481\n",
      "test_test\n",
      "test mean loss=1159.0815124511719\n",
      "epoch 3324\n",
      "test_train\n",
      "train mean loss=0.1108545633032918\n",
      "test_test\n",
      "test mean loss=1159.072021484375\n",
      "epoch 3325\n",
      "test_train\n",
      "train mean loss=0.09281010304888089\n",
      "test_test\n",
      "test mean loss=1158.991943359375\n",
      "epoch 3326\n",
      "test_train\n",
      "train mean loss=0.09286108271529277\n",
      "test_test\n",
      "test mean loss=1159.2681884765625\n",
      "epoch 3327\n",
      "test_train\n",
      "train mean loss=0.08312557948132356\n",
      "test_test\n",
      "test mean loss=1158.6980590820312\n",
      "epoch 3328\n",
      "test_train\n",
      "train mean loss=0.0804577615732948\n",
      "test_test\n",
      "test mean loss=1157.8091430664062\n",
      "epoch 3329\n",
      "test_train\n",
      "train mean loss=0.08632905843357246\n",
      "test_test\n",
      "test mean loss=1157.7878723144531\n",
      "epoch 3330\n",
      "test_train\n",
      "train mean loss=0.0824943498397867\n",
      "test_test\n",
      "test mean loss=1157.9437866210938\n",
      "epoch 3331\n",
      "test_train\n",
      "train mean loss=0.08289151887098949\n",
      "test_test\n",
      "test mean loss=1157.762451171875\n",
      "epoch 3332\n",
      "test_train\n",
      "train mean loss=0.0816876869648695\n",
      "test_test\n",
      "test mean loss=1157.4467163085938\n",
      "epoch 3333\n",
      "test_train\n",
      "train mean loss=0.0846918464327852\n",
      "test_test\n",
      "test mean loss=1158.3652954101562\n",
      "epoch 3334\n",
      "test_train\n",
      "train mean loss=0.08905581167588632\n",
      "test_test\n",
      "test mean loss=1159.3777465820312\n",
      "epoch 3335\n",
      "test_train\n",
      "train mean loss=0.08759835952272017\n",
      "test_test\n",
      "test mean loss=1159.0286254882812\n",
      "epoch 3336\n",
      "test_train\n",
      "train mean loss=0.07825867024560769\n",
      "test_test\n",
      "test mean loss=1158.3557739257812\n",
      "epoch 3337\n",
      "test_train\n",
      "train mean loss=0.08848759594062965\n",
      "test_test\n",
      "test mean loss=1158.9903259277344\n",
      "epoch 3338\n",
      "test_train\n",
      "train mean loss=0.09034065343439579\n",
      "test_test\n",
      "test mean loss=1158.7307739257812\n",
      "epoch 3339\n",
      "test_train\n",
      "train mean loss=0.08160084703316291\n",
      "test_test\n",
      "test mean loss=1157.9662475585938\n",
      "epoch 3340\n",
      "test_train\n",
      "train mean loss=0.07561619176218908\n",
      "test_test\n",
      "test mean loss=1157.64013671875\n",
      "epoch 3341\n",
      "test_train\n",
      "train mean loss=0.08401031295458476\n",
      "test_test\n",
      "test mean loss=1157.3719482421875\n",
      "epoch 3342\n",
      "test_train\n",
      "train mean loss=0.0877606337890029\n",
      "test_test\n",
      "test mean loss=1158.7694396972656\n",
      "epoch 3343\n",
      "test_train\n",
      "train mean loss=0.08839861831317346\n",
      "test_test\n",
      "test mean loss=1157.6661987304688\n",
      "epoch 3344\n",
      "test_train\n",
      "train mean loss=0.08664343102524678\n",
      "test_test\n",
      "test mean loss=1157.5003967285156\n",
      "epoch 3345\n",
      "test_train\n",
      "train mean loss=0.08812102396041155\n",
      "test_test\n",
      "test mean loss=1156.723876953125\n",
      "epoch 3346\n",
      "test_train\n",
      "train mean loss=0.13329761661589146\n",
      "test_test\n",
      "test mean loss=1156.4298095703125\n",
      "epoch 3347\n",
      "test_train\n",
      "train mean loss=0.08245163535078366\n",
      "test_test\n",
      "test mean loss=1156.5084533691406\n",
      "epoch 3348\n",
      "test_train\n",
      "train mean loss=0.08143333997577429\n",
      "test_test\n",
      "test mean loss=1157.2347412109375\n",
      "epoch 3349\n",
      "test_train\n",
      "train mean loss=0.07807073431710403\n",
      "test_test\n",
      "test mean loss=1156.3329772949219\n",
      "epoch 3350\n",
      "test_train\n",
      "train mean loss=0.08249813256164391\n",
      "test_test\n",
      "test mean loss=1158.2967529296875\n",
      "epoch 3351\n",
      "test_train\n",
      "train mean loss=0.07963786118974288\n",
      "test_test\n",
      "test mean loss=1157.9660034179688\n",
      "epoch 3352\n",
      "test_train\n",
      "train mean loss=0.07573049142956734\n",
      "test_test\n",
      "test mean loss=1157.7352905273438\n",
      "epoch 3353\n",
      "test_train\n",
      "train mean loss=0.17293003077308336\n",
      "test_test\n",
      "test mean loss=1159.5690612792969\n",
      "epoch 3354\n",
      "test_train\n",
      "train mean loss=0.08046422308931749\n",
      "test_test\n",
      "test mean loss=1158.7701110839844\n",
      "epoch 3355\n",
      "test_train\n",
      "train mean loss=0.08098974451422691\n",
      "test_test\n",
      "test mean loss=1157.48828125\n",
      "epoch 3356\n",
      "test_train\n",
      "train mean loss=0.09216739997888605\n",
      "test_test\n",
      "test mean loss=1158.1196899414062\n",
      "epoch 3357\n",
      "test_train\n",
      "train mean loss=0.08141527852664392\n",
      "test_test\n",
      "test mean loss=1158.2998046875\n",
      "epoch 3358\n",
      "test_train\n",
      "train mean loss=0.10193512278298537\n",
      "test_test\n",
      "test mean loss=1157.238037109375\n",
      "epoch 3359\n",
      "test_train\n",
      "train mean loss=0.08198268773655097\n",
      "test_test\n",
      "test mean loss=1156.3173522949219\n",
      "epoch 3360\n",
      "test_train\n",
      "train mean loss=0.08494190623362859\n",
      "test_test\n",
      "test mean loss=1157.28369140625\n",
      "epoch 3361\n",
      "test_train\n",
      "train mean loss=0.10777274457116921\n",
      "test_test\n",
      "test mean loss=1156.699462890625\n",
      "epoch 3362\n",
      "test_train\n",
      "train mean loss=0.2749902767439683\n",
      "test_test\n",
      "test mean loss=1156.5993041992188\n",
      "epoch 3363\n",
      "test_train\n",
      "train mean loss=0.09612769198914368\n",
      "test_test\n",
      "test mean loss=1156.0001831054688\n",
      "epoch 3364\n",
      "test_train\n",
      "train mean loss=0.0862358467032512\n",
      "test_test\n",
      "test mean loss=1156.3797607421875\n",
      "epoch 3365\n",
      "test_train\n",
      "train mean loss=0.07918982021510601\n",
      "test_test\n",
      "test mean loss=1157.2249145507812\n",
      "epoch 3366\n",
      "test_train\n",
      "train mean loss=0.0863458514213562\n",
      "test_test\n",
      "test mean loss=1157.6172790527344\n",
      "epoch 3367\n",
      "test_train\n",
      "train mean loss=0.08007869434853394\n",
      "test_test\n",
      "test mean loss=1157.5994262695312\n",
      "epoch 3368\n",
      "test_train\n",
      "train mean loss=0.07790284665922324\n",
      "test_test\n",
      "test mean loss=1156.6633911132812\n",
      "epoch 3369\n",
      "test_train\n",
      "train mean loss=0.09727638494223356\n",
      "test_test\n",
      "test mean loss=1157.6112365722656\n",
      "epoch 3370\n",
      "test_train\n",
      "train mean loss=0.07818992498020332\n",
      "test_test\n",
      "test mean loss=1157.7008056640625\n",
      "epoch 3371\n",
      "test_train\n",
      "train mean loss=0.1288924776017666\n",
      "test_test\n",
      "test mean loss=1156.7450561523438\n",
      "epoch 3372\n",
      "test_train\n",
      "train mean loss=0.08946738143761952\n",
      "test_test\n",
      "test mean loss=1158.5274047851562\n",
      "epoch 3373\n",
      "test_train\n",
      "train mean loss=0.07996139706422885\n",
      "test_test\n",
      "test mean loss=1158.5440063476562\n",
      "epoch 3374\n",
      "test_train\n",
      "train mean loss=0.10653380118310452\n",
      "test_test\n",
      "test mean loss=1159.3917846679688\n",
      "epoch 3375\n",
      "test_train\n",
      "train mean loss=0.07999468687921762\n",
      "test_test\n",
      "test mean loss=1158.81982421875\n",
      "epoch 3376\n",
      "test_train\n",
      "train mean loss=0.08407262495408456\n",
      "test_test\n",
      "test mean loss=1159.4856262207031\n",
      "epoch 3377\n",
      "test_train\n",
      "train mean loss=0.08469470590353012\n",
      "test_test\n",
      "test mean loss=1158.2203369140625\n",
      "epoch 3378\n",
      "test_train\n",
      "train mean loss=0.08079894632101059\n",
      "test_test\n",
      "test mean loss=1157.4168090820312\n",
      "epoch 3379\n",
      "test_train\n",
      "train mean loss=0.1184698489184181\n",
      "test_test\n",
      "test mean loss=1156.9300537109375\n",
      "epoch 3380\n",
      "test_train\n",
      "train mean loss=0.08941471762955189\n",
      "test_test\n",
      "test mean loss=1157.9303588867188\n",
      "epoch 3381\n",
      "test_train\n",
      "train mean loss=0.08101409828911225\n",
      "test_test\n",
      "test mean loss=1156.8372497558594\n",
      "epoch 3382\n",
      "test_train\n",
      "train mean loss=0.08433393544207017\n",
      "test_test\n",
      "test mean loss=1156.61767578125\n",
      "epoch 3383\n",
      "test_train\n",
      "train mean loss=0.08235554893811543\n",
      "test_test\n",
      "test mean loss=1156.966064453125\n",
      "epoch 3384\n",
      "test_train\n",
      "train mean loss=0.08925790525972843\n",
      "test_test\n",
      "test mean loss=1159.5534057617188\n",
      "epoch 3385\n",
      "test_train\n",
      "train mean loss=0.08147493905077378\n",
      "test_test\n",
      "test mean loss=1158.4578247070312\n",
      "epoch 3386\n",
      "test_train\n",
      "train mean loss=0.07834389588485162\n",
      "test_test\n",
      "test mean loss=1158.6553649902344\n",
      "epoch 3387\n",
      "test_train\n",
      "train mean loss=0.07867584408571322\n",
      "test_test\n",
      "test mean loss=1157.4381408691406\n",
      "epoch 3388\n",
      "test_train\n",
      "train mean loss=0.07709520496428013\n",
      "test_test\n",
      "test mean loss=1158.2273559570312\n",
      "epoch 3389\n",
      "test_train\n",
      "train mean loss=0.08779090146223704\n",
      "test_test\n",
      "test mean loss=1157.7425537109375\n",
      "epoch 3390\n",
      "test_train\n",
      "train mean loss=0.07846395764499903\n",
      "test_test\n",
      "test mean loss=1158.3511352539062\n",
      "epoch 3391\n",
      "test_train\n",
      "train mean loss=0.10635512073834737\n",
      "test_test\n",
      "test mean loss=1156.6165161132812\n",
      "epoch 3392\n",
      "test_train\n",
      "train mean loss=0.08065339922904968\n",
      "test_test\n",
      "test mean loss=1158.3531494140625\n",
      "epoch 3393\n",
      "test_train\n",
      "train mean loss=0.08052489844461282\n",
      "test_test\n",
      "test mean loss=1158.1831970214844\n",
      "epoch 3394\n",
      "test_train\n",
      "train mean loss=0.08206072744602959\n",
      "test_test\n",
      "test mean loss=1158.7697448730469\n",
      "epoch 3395\n",
      "test_train\n",
      "train mean loss=0.07885085418820381\n",
      "test_test\n",
      "test mean loss=1159.0453491210938\n",
      "epoch 3396\n",
      "test_train\n",
      "train mean loss=0.07804144934440653\n",
      "test_test\n",
      "test mean loss=1158.5595397949219\n",
      "epoch 3397\n",
      "test_train\n",
      "train mean loss=0.07821858519067366\n",
      "test_test\n",
      "test mean loss=1157.7342529296875\n",
      "epoch 3398\n",
      "test_train\n",
      "train mean loss=0.08977415040135384\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1159.0206909179688\n",
      "epoch 3399\n",
      "test_train\n",
      "train mean loss=0.07563707449783881\n",
      "test_test\n",
      "test mean loss=1157.4454345703125\n",
      "epoch 3400\n",
      "test_train\n",
      "train mean loss=0.07797351200133562\n",
      "test_test\n",
      "test mean loss=1157.8645629882812\n",
      "epoch 3401\n",
      "test_train\n",
      "train mean loss=0.09721958730369806\n",
      "test_test\n",
      "test mean loss=1158.94189453125\n",
      "epoch 3402\n",
      "test_train\n",
      "train mean loss=0.22085129593809447\n",
      "test_test\n",
      "test mean loss=1158.0844116210938\n",
      "epoch 3403\n",
      "test_train\n",
      "train mean loss=0.5705671136577924\n",
      "test_test\n",
      "test mean loss=1155.6200561523438\n",
      "epoch 3404\n",
      "test_train\n",
      "train mean loss=0.29607558126250905\n",
      "test_test\n",
      "test mean loss=1155.5185546875\n",
      "epoch 3405\n",
      "test_train\n",
      "train mean loss=0.10681859403848648\n",
      "test_test\n",
      "test mean loss=1160.5771179199219\n",
      "epoch 3406\n",
      "test_train\n",
      "train mean loss=0.10362469870597124\n",
      "test_test\n",
      "test mean loss=1158.9586791992188\n",
      "epoch 3407\n",
      "test_train\n",
      "train mean loss=0.12614601540068784\n",
      "test_test\n",
      "test mean loss=1158.9400024414062\n",
      "epoch 3408\n",
      "test_train\n",
      "train mean loss=0.10668076885243256\n",
      "test_test\n",
      "test mean loss=1159.614013671875\n",
      "epoch 3409\n",
      "test_train\n",
      "train mean loss=0.10532876818130414\n",
      "test_test\n",
      "test mean loss=1161.0795593261719\n",
      "epoch 3410\n",
      "test_train\n",
      "train mean loss=0.0983518473803997\n",
      "test_test\n",
      "test mean loss=1161.6990661621094\n",
      "epoch 3411\n",
      "test_train\n",
      "train mean loss=0.10386735573410988\n",
      "test_test\n",
      "test mean loss=1160.3038330078125\n",
      "epoch 3412\n",
      "test_train\n",
      "train mean loss=0.10200887297590573\n",
      "test_test\n",
      "test mean loss=1159.351806640625\n",
      "epoch 3413\n",
      "test_train\n",
      "train mean loss=0.10302952987452348\n",
      "test_test\n",
      "test mean loss=1159.3578796386719\n",
      "epoch 3414\n",
      "test_train\n",
      "train mean loss=0.0880409957220157\n",
      "test_test\n",
      "test mean loss=1158.5700073242188\n",
      "epoch 3415\n",
      "test_train\n",
      "train mean loss=0.10583360244830449\n",
      "test_test\n",
      "test mean loss=1157.93603515625\n",
      "epoch 3416\n",
      "test_train\n",
      "train mean loss=0.08663448660324018\n",
      "test_test\n",
      "test mean loss=1158.6832885742188\n",
      "epoch 3417\n",
      "test_train\n",
      "train mean loss=0.14448431879281998\n",
      "test_test\n",
      "test mean loss=1159.846923828125\n",
      "epoch 3418\n",
      "test_train\n",
      "train mean loss=0.09217739043136437\n",
      "test_test\n",
      "test mean loss=1158.958740234375\n",
      "epoch 3419\n",
      "test_train\n",
      "train mean loss=0.08731787527600925\n",
      "test_test\n",
      "test mean loss=1157.7334289550781\n",
      "epoch 3420\n",
      "test_train\n",
      "train mean loss=0.0824670372530818\n",
      "test_test\n",
      "test mean loss=1158.473876953125\n",
      "epoch 3421\n",
      "test_train\n",
      "train mean loss=0.08500639411310355\n",
      "test_test\n",
      "test mean loss=1156.5588684082031\n",
      "epoch 3422\n",
      "test_train\n",
      "train mean loss=0.08897504831353824\n",
      "test_test\n",
      "test mean loss=1157.2511901855469\n",
      "epoch 3423\n",
      "test_train\n",
      "train mean loss=0.09386062311629455\n",
      "test_test\n",
      "test mean loss=1157.5517578125\n",
      "epoch 3424\n",
      "test_train\n",
      "train mean loss=0.08156372637798388\n",
      "test_test\n",
      "test mean loss=1156.9631958007812\n",
      "epoch 3425\n",
      "test_train\n",
      "train mean loss=0.08375020201007526\n",
      "test_test\n",
      "test mean loss=1156.99560546875\n",
      "epoch 3426\n",
      "test_train\n",
      "train mean loss=0.08977363351732492\n",
      "test_test\n",
      "test mean loss=1157.43359375\n",
      "epoch 3427\n",
      "test_train\n",
      "train mean loss=0.09250191692262888\n",
      "test_test\n",
      "test mean loss=1158.1678466796875\n",
      "epoch 3428\n",
      "test_train\n",
      "train mean loss=0.07738350083430608\n",
      "test_test\n",
      "test mean loss=1157.4538269042969\n",
      "epoch 3429\n",
      "test_train\n",
      "train mean loss=0.08150601169715326\n",
      "test_test\n",
      "test mean loss=1157.8330688476562\n",
      "epoch 3430\n",
      "test_train\n",
      "train mean loss=0.08101123974968989\n",
      "test_test\n",
      "test mean loss=1157.591064453125\n",
      "epoch 3431\n",
      "test_train\n",
      "train mean loss=0.08148831191162269\n",
      "test_test\n",
      "test mean loss=1158.0111694335938\n",
      "epoch 3432\n",
      "test_train\n",
      "train mean loss=0.08616028260439634\n",
      "test_test\n",
      "test mean loss=1158.40673828125\n",
      "epoch 3433\n",
      "test_train\n",
      "train mean loss=0.08826791417474548\n",
      "test_test\n",
      "test mean loss=1159.8303833007812\n",
      "epoch 3434\n",
      "test_train\n",
      "train mean loss=0.08419422153383493\n",
      "test_test\n",
      "test mean loss=1159.355712890625\n",
      "epoch 3435\n",
      "test_train\n",
      "train mean loss=0.12081991539647181\n",
      "test_test\n",
      "test mean loss=1158.361083984375\n",
      "epoch 3436\n",
      "test_train\n",
      "train mean loss=0.08639602052668731\n",
      "test_test\n",
      "test mean loss=1157.0516662597656\n",
      "epoch 3437\n",
      "test_train\n",
      "train mean loss=0.4112463928759098\n",
      "test_test\n",
      "test mean loss=1151.9434204101562\n",
      "epoch 3438\n",
      "test_train\n",
      "train mean loss=0.11897862950960796\n",
      "test_test\n",
      "test mean loss=1155.5390625\n",
      "epoch 3439\n",
      "test_train\n",
      "train mean loss=0.0847688748811682\n",
      "test_test\n",
      "test mean loss=1155.6061401367188\n",
      "epoch 3440\n",
      "test_train\n",
      "train mean loss=0.08537958189845085\n",
      "test_test\n",
      "test mean loss=1155.2701416015625\n",
      "epoch 3441\n",
      "test_train\n",
      "train mean loss=0.08205339840302865\n",
      "test_test\n",
      "test mean loss=1154.66455078125\n",
      "epoch 3442\n",
      "test_train\n",
      "train mean loss=0.07875734008848667\n",
      "test_test\n",
      "test mean loss=1155.0771179199219\n",
      "epoch 3443\n",
      "test_train\n",
      "train mean loss=0.1013268269598484\n",
      "test_test\n",
      "test mean loss=1157.9068908691406\n",
      "epoch 3444\n",
      "test_train\n",
      "train mean loss=0.09212292979160945\n",
      "test_test\n",
      "test mean loss=1154.9121704101562\n",
      "epoch 3445\n",
      "test_train\n",
      "train mean loss=0.08804695152988036\n",
      "test_test\n",
      "test mean loss=1156.2127685546875\n",
      "epoch 3446\n",
      "test_train\n",
      "train mean loss=0.08835680782794952\n",
      "test_test\n",
      "test mean loss=1156.14794921875\n",
      "epoch 3447\n",
      "test_train\n",
      "train mean loss=0.083327389943103\n",
      "test_test\n",
      "test mean loss=1157.1241455078125\n",
      "epoch 3448\n",
      "test_train\n",
      "train mean loss=0.08402822849651177\n",
      "test_test\n",
      "test mean loss=1156.9718933105469\n",
      "epoch 3449\n",
      "test_train\n",
      "train mean loss=0.084917102009058\n",
      "test_test\n",
      "test mean loss=1155.5840148925781\n",
      "epoch 3450\n",
      "test_train\n",
      "train mean loss=0.08365143338839214\n",
      "test_test\n",
      "test mean loss=1156.6485290527344\n",
      "epoch 3451\n",
      "test_train\n",
      "train mean loss=0.08277757062266271\n",
      "test_test\n",
      "test mean loss=1156.9622802734375\n",
      "epoch 3452\n",
      "test_train\n",
      "train mean loss=0.08702169420818488\n",
      "test_test\n",
      "test mean loss=1155.80322265625\n",
      "epoch 3453\n",
      "test_train\n",
      "train mean loss=0.08712732574592034\n",
      "test_test\n",
      "test mean loss=1156.2026672363281\n",
      "epoch 3454\n",
      "test_train\n",
      "train mean loss=0.08276043195898335\n",
      "test_test\n",
      "test mean loss=1155.6695251464844\n",
      "epoch 3455\n",
      "test_train\n",
      "train mean loss=0.10205068190892537\n",
      "test_test\n",
      "test mean loss=1157.480224609375\n",
      "epoch 3456\n",
      "test_train\n",
      "train mean loss=0.0851820157840848\n",
      "test_test\n",
      "test mean loss=1155.7933959960938\n",
      "epoch 3457\n",
      "test_train\n",
      "train mean loss=0.09061240404844284\n",
      "test_test\n",
      "test mean loss=1155.5870971679688\n",
      "epoch 3458\n",
      "test_train\n",
      "train mean loss=0.08596760127693415\n",
      "test_test\n",
      "test mean loss=1155.8475341796875\n",
      "epoch 3459\n",
      "test_train\n",
      "train mean loss=0.08316906758894523\n",
      "test_test\n",
      "test mean loss=1155.5170288085938\n",
      "epoch 3460\n",
      "test_train\n",
      "train mean loss=0.08102925059696038\n",
      "test_test\n",
      "test mean loss=1156.0521240234375\n",
      "epoch 3461\n",
      "test_train\n",
      "train mean loss=0.0874387351796031\n",
      "test_test\n",
      "test mean loss=1155.3366088867188\n",
      "epoch 3462\n",
      "test_train\n",
      "train mean loss=0.08588213101029396\n",
      "test_test\n",
      "test mean loss=1156.1395263671875\n",
      "epoch 3463\n",
      "test_train\n",
      "train mean loss=0.0897728589673837\n",
      "test_test\n",
      "test mean loss=1156.7035217285156\n",
      "epoch 3464\n",
      "test_train\n",
      "train mean loss=0.10620000306516886\n",
      "test_test\n",
      "test mean loss=1155.1744995117188\n",
      "epoch 3465\n",
      "test_train\n",
      "train mean loss=0.09041812364012003\n",
      "test_test\n",
      "test mean loss=1155.9559936523438\n",
      "epoch 3466\n",
      "test_train\n",
      "train mean loss=0.10027150437235832\n",
      "test_test\n",
      "test mean loss=1157.61376953125\n",
      "epoch 3467\n",
      "test_train\n",
      "train mean loss=0.0851924146215121\n",
      "test_test\n",
      "test mean loss=1156.9912719726562\n",
      "epoch 3468\n",
      "test_train\n",
      "train mean loss=0.08459681210418542\n",
      "test_test\n",
      "test mean loss=1157.6557922363281\n",
      "epoch 3469\n",
      "test_train\n",
      "train mean loss=0.09595818941791852\n",
      "test_test\n",
      "test mean loss=1157.8932800292969\n",
      "epoch 3470\n",
      "test_train\n",
      "train mean loss=0.08259189625581105\n",
      "test_test\n",
      "test mean loss=1157.9579772949219\n",
      "epoch 3471\n",
      "test_train\n",
      "train mean loss=0.08767949230968952\n",
      "test_test\n",
      "test mean loss=1157.5739135742188\n",
      "epoch 3472\n",
      "test_train\n",
      "train mean loss=0.0847719016795357\n",
      "test_test\n",
      "test mean loss=1156.1934814453125\n",
      "epoch 3473\n",
      "test_train\n",
      "train mean loss=0.08916700351983309\n",
      "test_test\n",
      "test mean loss=1157.2180786132812\n",
      "epoch 3474\n",
      "test_train\n",
      "train mean loss=0.08820194005966187\n",
      "test_test\n",
      "test mean loss=1158.1275634765625\n",
      "epoch 3475\n",
      "test_train\n",
      "train mean loss=0.08262815854201715\n",
      "test_test\n",
      "test mean loss=1156.5656127929688\n",
      "epoch 3476\n",
      "test_train\n",
      "train mean loss=0.08318838694443305\n",
      "test_test\n",
      "test mean loss=1155.6774291992188\n",
      "epoch 3477\n",
      "test_train\n",
      "train mean loss=0.22988830134272575\n",
      "test_test\n",
      "test mean loss=1153.8323669433594\n",
      "epoch 3478\n",
      "test_train\n",
      "train mean loss=0.08619388410200675\n",
      "test_test\n",
      "test mean loss=1157.0162658691406\n",
      "epoch 3479\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.08074861392378807\n",
      "test_test\n",
      "test mean loss=1156.9132080078125\n",
      "epoch 3480\n",
      "test_train\n",
      "train mean loss=0.08626698547353347\n",
      "test_test\n",
      "test mean loss=1155.1465454101562\n",
      "epoch 3481\n",
      "test_train\n",
      "train mean loss=0.07798485737293959\n",
      "test_test\n",
      "test mean loss=1156.5335083007812\n",
      "epoch 3482\n",
      "test_train\n",
      "train mean loss=0.07848121163745721\n",
      "test_test\n",
      "test mean loss=1157.2001953125\n",
      "epoch 3483\n",
      "test_train\n",
      "train mean loss=0.09114835131913424\n",
      "test_test\n",
      "test mean loss=1158.2564697265625\n",
      "epoch 3484\n",
      "test_train\n",
      "train mean loss=0.10627029091119766\n",
      "test_test\n",
      "test mean loss=1156.7089538574219\n",
      "epoch 3485\n",
      "test_train\n",
      "train mean loss=0.08288807111481826\n",
      "test_test\n",
      "test mean loss=1155.6196899414062\n",
      "epoch 3486\n",
      "test_train\n",
      "train mean loss=0.08939327951520681\n",
      "test_test\n",
      "test mean loss=1156.7071533203125\n",
      "epoch 3487\n",
      "test_train\n",
      "train mean loss=0.08297359943389893\n",
      "test_test\n",
      "test mean loss=1156.4918212890625\n",
      "epoch 3488\n",
      "test_train\n",
      "train mean loss=0.08317540399730206\n",
      "test_test\n",
      "test mean loss=1155.5879516601562\n",
      "epoch 3489\n",
      "test_train\n",
      "train mean loss=0.08210906262199084\n",
      "test_test\n",
      "test mean loss=1155.8573608398438\n",
      "epoch 3490\n",
      "test_train\n",
      "train mean loss=0.08263354158649842\n",
      "test_test\n",
      "test mean loss=1156.7973937988281\n",
      "epoch 3491\n",
      "test_train\n",
      "train mean loss=0.07975710493822892\n",
      "test_test\n",
      "test mean loss=1156.4630737304688\n",
      "epoch 3492\n",
      "test_train\n",
      "train mean loss=0.09370084355274837\n",
      "test_test\n",
      "test mean loss=1157.1755981445312\n",
      "epoch 3493\n",
      "test_train\n",
      "train mean loss=0.08137576747685671\n",
      "test_test\n",
      "test mean loss=1156.186279296875\n",
      "epoch 3494\n",
      "test_train\n",
      "train mean loss=0.08565238087127607\n",
      "test_test\n",
      "test mean loss=1157.3168334960938\n",
      "epoch 3495\n",
      "test_train\n",
      "train mean loss=0.08084649406373501\n",
      "test_test\n",
      "test mean loss=1156.5239562988281\n",
      "epoch 3496\n",
      "test_train\n",
      "train mean loss=0.07602652814239264\n",
      "test_test\n",
      "test mean loss=1156.6260375976562\n",
      "epoch 3497\n",
      "test_train\n",
      "train mean loss=0.08233850914984941\n",
      "test_test\n",
      "test mean loss=1156.6495971679688\n",
      "epoch 3498\n",
      "test_train\n",
      "train mean loss=0.07919411920011044\n",
      "test_test\n",
      "test mean loss=1158.2586059570312\n",
      "epoch 3499\n",
      "test_train\n",
      "train mean loss=0.08083402800063293\n",
      "test_test\n",
      "test mean loss=1158.26123046875\n",
      "epoch 3500\n",
      "test_train\n",
      "train mean loss=0.08765121673544247\n",
      "test_test\n",
      "test mean loss=1156.9171752929688\n",
      "epoch 3501\n",
      "test_train\n",
      "train mean loss=0.0851418621217211\n",
      "test_test\n",
      "test mean loss=1157.7926025390625\n",
      "epoch 3502\n",
      "test_train\n",
      "train mean loss=0.08866669610142708\n",
      "test_test\n",
      "test mean loss=1156.673828125\n",
      "epoch 3503\n",
      "test_train\n",
      "train mean loss=0.08491126478960116\n",
      "test_test\n",
      "test mean loss=1157.5707397460938\n",
      "epoch 3504\n",
      "test_train\n",
      "train mean loss=0.07914996519684792\n",
      "test_test\n",
      "test mean loss=1157.8477783203125\n",
      "epoch 3505\n",
      "test_train\n",
      "train mean loss=0.08729396605243285\n",
      "test_test\n",
      "test mean loss=1158.4442443847656\n",
      "epoch 3506\n",
      "test_train\n",
      "train mean loss=0.0862786943713824\n",
      "test_test\n",
      "test mean loss=1157.6875610351562\n",
      "epoch 3507\n",
      "test_train\n",
      "train mean loss=0.0825492621709903\n",
      "test_test\n",
      "test mean loss=1157.412109375\n",
      "epoch 3508\n",
      "test_train\n",
      "train mean loss=0.0794447169949611\n",
      "test_test\n",
      "test mean loss=1155.8724975585938\n",
      "epoch 3509\n",
      "test_train\n",
      "train mean loss=0.0876390573879083\n",
      "test_test\n",
      "test mean loss=1157.408935546875\n",
      "epoch 3510\n",
      "test_train\n",
      "train mean loss=0.08017502756168444\n",
      "test_test\n",
      "test mean loss=1157.0824584960938\n",
      "epoch 3511\n",
      "test_train\n",
      "train mean loss=0.08007423797001441\n",
      "test_test\n",
      "test mean loss=1156.447265625\n",
      "epoch 3512\n",
      "test_train\n",
      "train mean loss=0.0787375917037328\n",
      "test_test\n",
      "test mean loss=1158.0388793945312\n",
      "epoch 3513\n",
      "test_train\n",
      "train mean loss=0.08030007996906836\n",
      "test_test\n",
      "test mean loss=1158.32666015625\n",
      "epoch 3514\n",
      "test_train\n",
      "train mean loss=0.08041227329522371\n",
      "test_test\n",
      "test mean loss=1156.9556579589844\n",
      "epoch 3515\n",
      "test_train\n",
      "train mean loss=0.07712188487251599\n",
      "test_test\n",
      "test mean loss=1157.6129150390625\n",
      "epoch 3516\n",
      "test_train\n",
      "train mean loss=0.07965286603818338\n",
      "test_test\n",
      "test mean loss=1157.9935302734375\n",
      "epoch 3517\n",
      "test_train\n",
      "train mean loss=0.0864311767121156\n",
      "test_test\n",
      "test mean loss=1157.9106750488281\n",
      "epoch 3518\n",
      "test_train\n",
      "train mean loss=0.08724561737229426\n",
      "test_test\n",
      "test mean loss=1156.920654296875\n",
      "epoch 3519\n",
      "test_train\n",
      "train mean loss=0.08889192497978608\n",
      "test_test\n",
      "test mean loss=1157.4221801757812\n",
      "epoch 3520\n",
      "test_train\n",
      "train mean loss=0.07959325735767682\n",
      "test_test\n",
      "test mean loss=1157.5103149414062\n",
      "epoch 3521\n",
      "test_train\n",
      "train mean loss=0.08894011564552784\n",
      "test_test\n",
      "test mean loss=1156.6580810546875\n",
      "epoch 3522\n",
      "test_train\n",
      "train mean loss=0.08086062440027793\n",
      "test_test\n",
      "test mean loss=1155.9088134765625\n",
      "epoch 3523\n",
      "test_train\n",
      "train mean loss=0.08294361534838875\n",
      "test_test\n",
      "test mean loss=1156.7998657226562\n",
      "epoch 3524\n",
      "test_train\n",
      "train mean loss=0.0810866200675567\n",
      "test_test\n",
      "test mean loss=1156.1456909179688\n",
      "epoch 3525\n",
      "test_train\n",
      "train mean loss=0.07823751339068015\n",
      "test_test\n",
      "test mean loss=1156.0242919921875\n",
      "epoch 3526\n",
      "test_train\n",
      "train mean loss=0.09040661839147408\n",
      "test_test\n",
      "test mean loss=1157.2112426757812\n",
      "epoch 3527\n",
      "test_train\n",
      "train mean loss=0.08853666360179584\n",
      "test_test\n",
      "test mean loss=1155.9768676757812\n",
      "epoch 3528\n",
      "test_train\n",
      "train mean loss=0.08463192048172156\n",
      "test_test\n",
      "test mean loss=1156.1668395996094\n",
      "epoch 3529\n",
      "test_train\n",
      "train mean loss=0.08617910742759705\n",
      "test_test\n",
      "test mean loss=1157.1013793945312\n",
      "epoch 3530\n",
      "test_train\n",
      "train mean loss=0.08029366719226043\n",
      "test_test\n",
      "test mean loss=1156.3829345703125\n",
      "epoch 3531\n",
      "test_train\n",
      "train mean loss=0.08995803042004506\n",
      "test_test\n",
      "test mean loss=1156.5100708007812\n",
      "epoch 3532\n",
      "test_train\n",
      "train mean loss=0.0798482820391655\n",
      "test_test\n",
      "test mean loss=1156.0801086425781\n",
      "epoch 3533\n",
      "test_train\n",
      "train mean loss=0.08201924990862608\n",
      "test_test\n",
      "test mean loss=1155.6143798828125\n",
      "epoch 3534\n",
      "test_train\n",
      "train mean loss=0.08762560815860827\n",
      "test_test\n",
      "test mean loss=1155.8982543945312\n",
      "epoch 3535\n",
      "test_train\n",
      "train mean loss=0.11119772959500551\n",
      "test_test\n",
      "test mean loss=1156.6321411132812\n",
      "epoch 3536\n",
      "test_train\n",
      "train mean loss=0.08197350179155667\n",
      "test_test\n",
      "test mean loss=1156.26904296875\n",
      "epoch 3537\n",
      "test_train\n",
      "train mean loss=0.07928700714061658\n",
      "test_test\n",
      "test mean loss=1156.464599609375\n",
      "epoch 3538\n",
      "test_train\n",
      "train mean loss=0.08232072927057743\n",
      "test_test\n",
      "test mean loss=1157.7053833007812\n",
      "epoch 3539\n",
      "test_train\n",
      "train mean loss=0.0924856395771106\n",
      "test_test\n",
      "test mean loss=1157.3511962890625\n",
      "epoch 3540\n",
      "test_train\n",
      "train mean loss=0.08227438790102799\n",
      "test_test\n",
      "test mean loss=1156.5427856445312\n",
      "epoch 3541\n",
      "test_train\n",
      "train mean loss=0.08141870889812708\n",
      "test_test\n",
      "test mean loss=1155.756591796875\n",
      "epoch 3542\n",
      "test_train\n",
      "train mean loss=0.08135806769132614\n",
      "test_test\n",
      "test mean loss=1157.8748779296875\n",
      "epoch 3543\n",
      "test_train\n",
      "train mean loss=0.18342087666193643\n",
      "test_test\n",
      "test mean loss=1160.9132080078125\n",
      "epoch 3544\n",
      "test_train\n",
      "train mean loss=0.08932535133014123\n",
      "test_test\n",
      "test mean loss=1158.4956665039062\n",
      "epoch 3545\n",
      "test_train\n",
      "train mean loss=0.08530200521151225\n",
      "test_test\n",
      "test mean loss=1157.1460876464844\n",
      "epoch 3546\n",
      "test_train\n",
      "train mean loss=0.07893148250877857\n",
      "test_test\n",
      "test mean loss=1156.1429138183594\n",
      "epoch 3547\n",
      "test_train\n",
      "train mean loss=0.08303366663555305\n",
      "test_test\n",
      "test mean loss=1157.0764465332031\n",
      "epoch 3548\n",
      "test_train\n",
      "train mean loss=0.10503806080669165\n",
      "test_test\n",
      "test mean loss=1156.7411499023438\n",
      "epoch 3549\n",
      "test_train\n",
      "train mean loss=0.08783037525912125\n",
      "test_test\n",
      "test mean loss=1156.5942993164062\n",
      "epoch 3550\n",
      "test_train\n",
      "train mean loss=0.09011458791792393\n",
      "test_test\n",
      "test mean loss=1157.0271606445312\n",
      "epoch 3551\n",
      "test_train\n",
      "train mean loss=0.08978361636400223\n",
      "test_test\n",
      "test mean loss=1156.6312255859375\n",
      "epoch 3552\n",
      "test_train\n",
      "train mean loss=0.07865071979661782\n",
      "test_test\n",
      "test mean loss=1156.0406799316406\n",
      "epoch 3553\n",
      "test_train\n",
      "train mean loss=0.09119249259432156\n",
      "test_test\n",
      "test mean loss=1156.7457885742188\n",
      "epoch 3554\n",
      "test_train\n",
      "train mean loss=0.0872464133426547\n",
      "test_test\n",
      "test mean loss=1156.138427734375\n",
      "epoch 3555\n",
      "test_train\n",
      "train mean loss=0.08561867040892442\n",
      "test_test\n",
      "test mean loss=1155.7859802246094\n",
      "epoch 3556\n",
      "test_train\n",
      "train mean loss=0.08299323543906212\n",
      "test_test\n",
      "test mean loss=1156.3574829101562\n",
      "epoch 3557\n",
      "test_train\n",
      "train mean loss=0.08715984287361304\n",
      "test_test\n",
      "test mean loss=1157.2662048339844\n",
      "epoch 3558\n",
      "test_train\n",
      "train mean loss=0.08677770507832368\n",
      "test_test\n",
      "test mean loss=1157.7528381347656\n",
      "epoch 3559\n",
      "test_train\n",
      "train mean loss=0.09060320599625508\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1156.5556335449219\n",
      "epoch 3560\n",
      "test_train\n",
      "train mean loss=0.08747278247028589\n",
      "test_test\n",
      "test mean loss=1157.2185363769531\n",
      "epoch 3561\n",
      "test_train\n",
      "train mean loss=0.08701568717757861\n",
      "test_test\n",
      "test mean loss=1157.3549194335938\n",
      "epoch 3562\n",
      "test_train\n",
      "train mean loss=0.08035503638287385\n",
      "test_test\n",
      "test mean loss=1157.2923583984375\n",
      "epoch 3563\n",
      "test_train\n",
      "train mean loss=0.08481090764204662\n",
      "test_test\n",
      "test mean loss=1157.3833618164062\n",
      "epoch 3564\n",
      "test_train\n",
      "train mean loss=0.08926277856032054\n",
      "test_test\n",
      "test mean loss=1157.4987182617188\n",
      "epoch 3565\n",
      "test_train\n",
      "train mean loss=0.08017075061798096\n",
      "test_test\n",
      "test mean loss=1156.0348815917969\n",
      "epoch 3566\n",
      "test_train\n",
      "train mean loss=0.08155693175892036\n",
      "test_test\n",
      "test mean loss=1155.830322265625\n",
      "epoch 3567\n",
      "test_train\n",
      "train mean loss=0.08263682605077823\n",
      "test_test\n",
      "test mean loss=1156.8512573242188\n",
      "epoch 3568\n",
      "test_train\n",
      "train mean loss=0.08385145695259173\n",
      "test_test\n",
      "test mean loss=1157.615966796875\n",
      "epoch 3569\n",
      "test_train\n",
      "train mean loss=0.08639506219575803\n",
      "test_test\n",
      "test mean loss=1158.3270874023438\n",
      "epoch 3570\n",
      "test_train\n",
      "train mean loss=0.08202735148370266\n",
      "test_test\n",
      "test mean loss=1158.4718933105469\n",
      "epoch 3571\n",
      "test_train\n",
      "train mean loss=0.08121359348297119\n",
      "test_test\n",
      "test mean loss=1157.2209777832031\n",
      "epoch 3572\n",
      "test_train\n",
      "train mean loss=0.08297264793266852\n",
      "test_test\n",
      "test mean loss=1157.2713012695312\n",
      "epoch 3573\n",
      "test_train\n",
      "train mean loss=0.08436609338968992\n",
      "test_test\n",
      "test mean loss=1157.3618774414062\n",
      "epoch 3574\n",
      "test_train\n",
      "train mean loss=0.0804510327676932\n",
      "test_test\n",
      "test mean loss=1157.2745361328125\n",
      "epoch 3575\n",
      "test_train\n",
      "train mean loss=0.0850664380316933\n",
      "test_test\n",
      "test mean loss=1158.1305541992188\n",
      "epoch 3576\n",
      "test_train\n",
      "train mean loss=0.0818418599665165\n",
      "test_test\n",
      "test mean loss=1157.9263000488281\n",
      "epoch 3577\n",
      "test_train\n",
      "train mean loss=0.09260474455853303\n",
      "test_test\n",
      "test mean loss=1158.0926513671875\n",
      "epoch 3578\n",
      "test_train\n",
      "train mean loss=0.08110899478197098\n",
      "test_test\n",
      "test mean loss=1157.475830078125\n",
      "epoch 3579\n",
      "test_train\n",
      "train mean loss=0.0898078413059314\n",
      "test_test\n",
      "test mean loss=1156.9520874023438\n",
      "epoch 3580\n",
      "test_train\n",
      "train mean loss=0.07769755832850933\n",
      "test_test\n",
      "test mean loss=1157.6194152832031\n",
      "epoch 3581\n",
      "test_train\n",
      "train mean loss=0.08385443439086278\n",
      "test_test\n",
      "test mean loss=1157.3212280273438\n",
      "epoch 3582\n",
      "test_train\n",
      "train mean loss=0.08110004135717948\n",
      "test_test\n",
      "test mean loss=1157.24658203125\n",
      "epoch 3583\n",
      "test_train\n",
      "train mean loss=0.08403173554688692\n",
      "test_test\n",
      "test mean loss=1157.1015625\n",
      "epoch 3584\n",
      "test_train\n",
      "train mean loss=0.07790815395613511\n",
      "test_test\n",
      "test mean loss=1157.8407897949219\n",
      "epoch 3585\n",
      "test_train\n",
      "train mean loss=0.08910991748174031\n",
      "test_test\n",
      "test mean loss=1157.8494873046875\n",
      "epoch 3586\n",
      "test_train\n",
      "train mean loss=0.08074842859059572\n",
      "test_test\n",
      "test mean loss=1156.800048828125\n",
      "epoch 3587\n",
      "test_train\n",
      "train mean loss=0.08494479923198621\n",
      "test_test\n",
      "test mean loss=1155.6864624023438\n",
      "epoch 3588\n",
      "test_train\n",
      "train mean loss=0.0887340350697438\n",
      "test_test\n",
      "test mean loss=1157.2616577148438\n",
      "epoch 3589\n",
      "test_train\n",
      "train mean loss=0.09802347142249346\n",
      "test_test\n",
      "test mean loss=1157.4584655761719\n",
      "epoch 3590\n",
      "test_train\n",
      "train mean loss=0.08466525127490361\n",
      "test_test\n",
      "test mean loss=1157.1637573242188\n",
      "epoch 3591\n",
      "test_train\n",
      "train mean loss=0.0907873051861922\n",
      "test_test\n",
      "test mean loss=1157.6231689453125\n",
      "epoch 3592\n",
      "test_train\n",
      "train mean loss=0.09324915024141471\n",
      "test_test\n",
      "test mean loss=1158.4713745117188\n",
      "epoch 3593\n",
      "test_train\n",
      "train mean loss=0.08442827841887872\n",
      "test_test\n",
      "test mean loss=1157.6138305664062\n",
      "epoch 3594\n",
      "test_train\n",
      "train mean loss=0.07678206730633974\n",
      "test_test\n",
      "test mean loss=1156.43408203125\n",
      "epoch 3595\n",
      "test_train\n",
      "train mean loss=0.06932561751455069\n",
      "test_test\n",
      "test mean loss=1157.2719116210938\n",
      "epoch 3596\n",
      "test_train\n",
      "train mean loss=0.07128152685860793\n",
      "test_test\n",
      "test mean loss=1156.7312622070312\n",
      "epoch 3597\n",
      "test_train\n",
      "train mean loss=19.06858217716217\n",
      "test_test\n",
      "test mean loss=1149.5714721679688\n",
      "epoch 3598\n",
      "test_train\n",
      "train mean loss=0.626210813721021\n",
      "test_test\n",
      "test mean loss=1160.1519165039062\n",
      "epoch 3599\n",
      "test_train\n",
      "train mean loss=0.1202433208624522\n",
      "test_test\n",
      "test mean loss=1160.5289611816406\n",
      "epoch 3600\n",
      "test_train\n",
      "train mean loss=0.11417592875659466\n",
      "test_test\n",
      "test mean loss=1158.43017578125\n",
      "epoch 3601\n",
      "test_train\n",
      "train mean loss=0.1258791753401359\n",
      "test_test\n",
      "test mean loss=1158.7846069335938\n",
      "epoch 3602\n",
      "test_train\n",
      "train mean loss=0.6487045387427012\n",
      "test_test\n",
      "test mean loss=1156.7386169433594\n",
      "epoch 3603\n",
      "test_train\n",
      "train mean loss=0.14132789460321268\n",
      "test_test\n",
      "test mean loss=1158.0535888671875\n",
      "epoch 3604\n",
      "test_train\n",
      "train mean loss=0.09639540873467922\n",
      "test_test\n",
      "test mean loss=1157.6594848632812\n",
      "epoch 3605\n",
      "test_train\n",
      "train mean loss=0.09112728790690501\n",
      "test_test\n",
      "test mean loss=1157.5123291015625\n",
      "epoch 3606\n",
      "test_train\n",
      "train mean loss=0.09208642225712538\n",
      "test_test\n",
      "test mean loss=1157.3828125\n",
      "epoch 3607\n",
      "test_train\n",
      "train mean loss=0.09901749715209007\n",
      "test_test\n",
      "test mean loss=1157.179443359375\n",
      "epoch 3608\n",
      "test_train\n",
      "train mean loss=0.09364309751739104\n",
      "test_test\n",
      "test mean loss=1157.822265625\n",
      "epoch 3609\n",
      "test_train\n",
      "train mean loss=0.0898265636836489\n",
      "test_test\n",
      "test mean loss=1158.0048217773438\n",
      "epoch 3610\n",
      "test_train\n",
      "train mean loss=0.08738527695337932\n",
      "test_test\n",
      "test mean loss=1156.4062194824219\n",
      "epoch 3611\n",
      "test_train\n",
      "train mean loss=0.08902956638485193\n",
      "test_test\n",
      "test mean loss=1156.931396484375\n",
      "epoch 3612\n",
      "test_train\n",
      "train mean loss=0.09163983569790919\n",
      "test_test\n",
      "test mean loss=1157.6705627441406\n",
      "epoch 3613\n",
      "test_train\n",
      "train mean loss=0.09697033154467742\n",
      "test_test\n",
      "test mean loss=1157.6379699707031\n",
      "epoch 3614\n",
      "test_train\n",
      "train mean loss=0.10790019171933334\n",
      "test_test\n",
      "test mean loss=1157.3131103515625\n",
      "epoch 3615\n",
      "test_train\n",
      "train mean loss=0.08671026257798076\n",
      "test_test\n",
      "test mean loss=1156.47265625\n",
      "epoch 3616\n",
      "test_train\n",
      "train mean loss=0.08971579683323701\n",
      "test_test\n",
      "test mean loss=1157.5119323730469\n",
      "epoch 3617\n",
      "test_train\n",
      "train mean loss=0.09145721265425284\n",
      "test_test\n",
      "test mean loss=1156.4380493164062\n",
      "epoch 3618\n",
      "test_train\n",
      "train mean loss=0.094698674355944\n",
      "test_test\n",
      "test mean loss=1156.913330078125\n",
      "epoch 3619\n",
      "test_train\n",
      "train mean loss=0.09682538422445457\n",
      "test_test\n",
      "test mean loss=1156.8587036132812\n",
      "epoch 3620\n",
      "test_train\n",
      "train mean loss=0.09279037546366453\n",
      "test_test\n",
      "test mean loss=1156.7916259765625\n",
      "epoch 3621\n",
      "test_train\n",
      "train mean loss=0.08179496290783088\n",
      "test_test\n",
      "test mean loss=1156.40869140625\n",
      "epoch 3622\n",
      "test_train\n",
      "train mean loss=0.08872187323868275\n",
      "test_test\n",
      "test mean loss=1156.4652099609375\n",
      "epoch 3623\n",
      "test_train\n",
      "train mean loss=0.09240447512517373\n",
      "test_test\n",
      "test mean loss=1155.4252319335938\n",
      "epoch 3624\n",
      "test_train\n",
      "train mean loss=0.09097760543227196\n",
      "test_test\n",
      "test mean loss=1156.60498046875\n",
      "epoch 3625\n",
      "test_train\n",
      "train mean loss=0.08576005604118109\n",
      "test_test\n",
      "test mean loss=1156.6298217773438\n",
      "epoch 3626\n",
      "test_train\n",
      "train mean loss=0.08647194287429254\n",
      "test_test\n",
      "test mean loss=1157.6608276367188\n",
      "epoch 3627\n",
      "test_train\n",
      "train mean loss=0.11976092619200547\n",
      "test_test\n",
      "test mean loss=1156.7068786621094\n",
      "epoch 3628\n",
      "test_train\n",
      "train mean loss=0.5546617557605108\n",
      "test_test\n",
      "test mean loss=1152.9413452148438\n",
      "epoch 3629\n",
      "test_train\n",
      "train mean loss=0.12924322051306567\n",
      "test_test\n",
      "test mean loss=1156.3144836425781\n",
      "epoch 3630\n",
      "test_train\n",
      "train mean loss=0.08580270626892646\n",
      "test_test\n",
      "test mean loss=1157.4078369140625\n",
      "epoch 3631\n",
      "test_train\n",
      "train mean loss=0.09417124123622973\n",
      "test_test\n",
      "test mean loss=1157.2406005859375\n",
      "epoch 3632\n",
      "test_train\n",
      "train mean loss=0.12041684115926425\n",
      "test_test\n",
      "test mean loss=1158.217529296875\n",
      "epoch 3633\n",
      "test_train\n",
      "train mean loss=0.08835631236433983\n",
      "test_test\n",
      "test mean loss=1157.6749572753906\n",
      "epoch 3634\n",
      "test_train\n",
      "train mean loss=0.08911148272454739\n",
      "test_test\n",
      "test mean loss=1157.7794189453125\n",
      "epoch 3635\n",
      "test_train\n",
      "train mean loss=0.08536006323993206\n",
      "test_test\n",
      "test mean loss=1158.3741760253906\n",
      "epoch 3636\n",
      "test_train\n",
      "train mean loss=0.08485965648045142\n",
      "test_test\n",
      "test mean loss=1157.0167236328125\n",
      "epoch 3637\n",
      "test_train\n",
      "train mean loss=0.08329680282622576\n",
      "test_test\n",
      "test mean loss=1156.7159423828125\n",
      "epoch 3638\n",
      "test_train\n",
      "train mean loss=0.0913056352486213\n",
      "test_test\n",
      "test mean loss=1157.7080688476562\n",
      "epoch 3639\n",
      "test_train\n",
      "train mean loss=0.09745058976113796\n",
      "test_test\n",
      "test mean loss=1157.2269897460938\n",
      "epoch 3640\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.09784286251912515\n",
      "test_test\n",
      "test mean loss=1156.153076171875\n",
      "epoch 3641\n",
      "test_train\n",
      "train mean loss=0.09264890166620414\n",
      "test_test\n",
      "test mean loss=1157.1294555664062\n",
      "epoch 3642\n",
      "test_train\n",
      "train mean loss=0.08818098747481902\n",
      "test_test\n",
      "test mean loss=1157.4166259765625\n",
      "epoch 3643\n",
      "test_train\n",
      "train mean loss=0.09897673316299915\n",
      "test_test\n",
      "test mean loss=1158.0982971191406\n",
      "epoch 3644\n",
      "test_train\n",
      "train mean loss=0.08309419918805361\n",
      "test_test\n",
      "test mean loss=1157.0140380859375\n",
      "epoch 3645\n",
      "test_train\n",
      "train mean loss=0.09063713066279888\n",
      "test_test\n",
      "test mean loss=1156.9105834960938\n",
      "epoch 3646\n",
      "test_train\n",
      "train mean loss=0.09379014931619167\n",
      "test_test\n",
      "test mean loss=1156.3997192382812\n",
      "epoch 3647\n",
      "test_train\n",
      "train mean loss=0.0907919170955817\n",
      "test_test\n",
      "test mean loss=1158.1748046875\n",
      "epoch 3648\n",
      "test_train\n",
      "train mean loss=0.09646193062265714\n",
      "test_test\n",
      "test mean loss=1157.9491577148438\n",
      "epoch 3649\n",
      "test_train\n",
      "train mean loss=0.10009719617664814\n",
      "test_test\n",
      "test mean loss=1158.0505981445312\n",
      "epoch 3650\n",
      "test_train\n",
      "train mean loss=0.08914076971511047\n",
      "test_test\n",
      "test mean loss=1158.2306518554688\n",
      "epoch 3651\n",
      "test_train\n",
      "train mean loss=0.08505550461510818\n",
      "test_test\n",
      "test mean loss=1158.3204040527344\n",
      "epoch 3652\n",
      "test_train\n",
      "train mean loss=0.08431238122284412\n",
      "test_test\n",
      "test mean loss=1157.5530395507812\n",
      "epoch 3653\n",
      "test_train\n",
      "train mean loss=0.08823490887880325\n",
      "test_test\n",
      "test mean loss=1157.7556762695312\n",
      "epoch 3654\n",
      "test_train\n",
      "train mean loss=0.08765751247604688\n",
      "test_test\n",
      "test mean loss=1157.2412719726562\n",
      "epoch 3655\n",
      "test_train\n",
      "train mean loss=0.09183436321715514\n",
      "test_test\n",
      "test mean loss=1159.1527099609375\n",
      "epoch 3656\n",
      "test_train\n",
      "train mean loss=0.08459141571074724\n",
      "test_test\n",
      "test mean loss=1158.136962890625\n",
      "epoch 3657\n",
      "test_train\n",
      "train mean loss=0.08180237126847108\n",
      "test_test\n",
      "test mean loss=1157.4926147460938\n",
      "epoch 3658\n",
      "test_train\n",
      "train mean loss=0.08323613926768303\n",
      "test_test\n",
      "test mean loss=1158.4208984375\n",
      "epoch 3659\n",
      "test_train\n",
      "train mean loss=0.08835352429499228\n",
      "test_test\n",
      "test mean loss=1158.7691040039062\n",
      "epoch 3660\n",
      "test_train\n",
      "train mean loss=0.08286173269152641\n",
      "test_test\n",
      "test mean loss=1157.2205810546875\n",
      "epoch 3661\n",
      "test_train\n",
      "train mean loss=0.09013146193077166\n",
      "test_test\n",
      "test mean loss=1157.219970703125\n",
      "epoch 3662\n",
      "test_train\n",
      "train mean loss=0.08914931149532397\n",
      "test_test\n",
      "test mean loss=1157.8201904296875\n",
      "epoch 3663\n",
      "test_train\n",
      "train mean loss=0.09167898415277402\n",
      "test_test\n",
      "test mean loss=1157.4489135742188\n",
      "epoch 3664\n",
      "test_train\n",
      "train mean loss=0.08604616485536098\n",
      "test_test\n",
      "test mean loss=1158.4453735351562\n",
      "epoch 3665\n",
      "test_train\n",
      "train mean loss=0.0862671264136831\n",
      "test_test\n",
      "test mean loss=1158.3212280273438\n",
      "epoch 3666\n",
      "test_train\n",
      "train mean loss=0.12185542254398267\n",
      "test_test\n",
      "test mean loss=1157.6919555664062\n",
      "epoch 3667\n",
      "test_train\n",
      "train mean loss=0.08963367405037086\n",
      "test_test\n",
      "test mean loss=1157.4339904785156\n",
      "epoch 3668\n",
      "test_train\n",
      "train mean loss=0.10541661828756332\n",
      "test_test\n",
      "test mean loss=1157.8975219726562\n",
      "epoch 3669\n",
      "test_train\n",
      "train mean loss=0.09077855572104454\n",
      "test_test\n",
      "test mean loss=1159.0920715332031\n",
      "epoch 3670\n",
      "test_train\n",
      "train mean loss=0.0905239110191663\n",
      "test_test\n",
      "test mean loss=1158.546630859375\n",
      "epoch 3671\n",
      "test_train\n",
      "train mean loss=0.0836536834637324\n",
      "test_test\n",
      "test mean loss=1158.367919921875\n",
      "epoch 3672\n",
      "test_train\n",
      "train mean loss=0.08098989818245173\n",
      "test_test\n",
      "test mean loss=1157.8818054199219\n",
      "epoch 3673\n",
      "test_train\n",
      "train mean loss=0.08177248574793339\n",
      "test_test\n",
      "test mean loss=1157.1135864257812\n",
      "epoch 3674\n",
      "test_train\n",
      "train mean loss=0.09260159234205882\n",
      "test_test\n",
      "test mean loss=1157.7525634765625\n",
      "epoch 3675\n",
      "test_train\n",
      "train mean loss=0.09481902265300353\n",
      "test_test\n",
      "test mean loss=1158.6626586914062\n",
      "epoch 3676\n",
      "test_train\n",
      "train mean loss=0.09032794926315546\n",
      "test_test\n",
      "test mean loss=1158.3299560546875\n",
      "epoch 3677\n",
      "test_train\n",
      "train mean loss=0.10492731754978497\n",
      "test_test\n",
      "test mean loss=1159.7409057617188\n",
      "epoch 3678\n",
      "test_train\n",
      "train mean loss=0.09029003822555144\n",
      "test_test\n",
      "test mean loss=1158.0988159179688\n",
      "epoch 3679\n",
      "test_train\n",
      "train mean loss=0.08498398618151744\n",
      "test_test\n",
      "test mean loss=1157.5740661621094\n",
      "epoch 3680\n",
      "test_train\n",
      "train mean loss=0.08397332454721133\n",
      "test_test\n",
      "test mean loss=1157.8358764648438\n",
      "epoch 3681\n",
      "test_train\n",
      "train mean loss=0.089936347057422\n",
      "test_test\n",
      "test mean loss=1158.7625427246094\n",
      "epoch 3682\n",
      "test_train\n",
      "train mean loss=0.09248963557183743\n",
      "test_test\n",
      "test mean loss=1159.2528686523438\n",
      "epoch 3683\n",
      "test_train\n",
      "train mean loss=0.08100242074579\n",
      "test_test\n",
      "test mean loss=1158.0797424316406\n",
      "epoch 3684\n",
      "test_train\n",
      "train mean loss=0.08317163524528344\n",
      "test_test\n",
      "test mean loss=1158.4975280761719\n",
      "epoch 3685\n",
      "test_train\n",
      "train mean loss=0.08164797816425562\n",
      "test_test\n",
      "test mean loss=1157.9735717773438\n",
      "epoch 3686\n",
      "test_train\n",
      "train mean loss=0.08190884534269571\n",
      "test_test\n",
      "test mean loss=1157.6180419921875\n",
      "epoch 3687\n",
      "test_train\n",
      "train mean loss=0.07868038319672148\n",
      "test_test\n",
      "test mean loss=1158.1512451171875\n",
      "epoch 3688\n",
      "test_train\n",
      "train mean loss=0.08246387634426355\n",
      "test_test\n",
      "test mean loss=1156.8662719726562\n",
      "epoch 3689\n",
      "test_train\n",
      "train mean loss=0.09011658808837335\n",
      "test_test\n",
      "test mean loss=1157.27783203125\n",
      "epoch 3690\n",
      "test_train\n",
      "train mean loss=0.08590866966793935\n",
      "test_test\n",
      "test mean loss=1157.7632446289062\n",
      "epoch 3691\n",
      "test_train\n",
      "train mean loss=0.09560830766956012\n",
      "test_test\n",
      "test mean loss=1157.8919677734375\n",
      "epoch 3692\n",
      "test_train\n",
      "train mean loss=0.08534083887934685\n",
      "test_test\n",
      "test mean loss=1156.6294250488281\n",
      "epoch 3693\n",
      "test_train\n",
      "train mean loss=0.09170669876039028\n",
      "test_test\n",
      "test mean loss=1157.2736206054688\n",
      "epoch 3694\n",
      "test_train\n",
      "train mean loss=0.08447132632136345\n",
      "test_test\n",
      "test mean loss=1159.0157165527344\n",
      "epoch 3695\n",
      "test_train\n",
      "train mean loss=0.08888080157339573\n",
      "test_test\n",
      "test mean loss=1158.8728942871094\n",
      "epoch 3696\n",
      "test_train\n",
      "train mean loss=0.08573998262484868\n",
      "test_test\n",
      "test mean loss=1157.5997314453125\n",
      "epoch 3697\n",
      "test_train\n",
      "train mean loss=0.08776869376500447\n",
      "test_test\n",
      "test mean loss=1157.7192687988281\n",
      "epoch 3698\n",
      "test_train\n",
      "train mean loss=0.08705170328418414\n",
      "test_test\n",
      "test mean loss=1158.9209594726562\n",
      "epoch 3699\n",
      "test_train\n",
      "train mean loss=0.0912230300406615\n",
      "test_test\n",
      "test mean loss=1158.4682922363281\n",
      "epoch 3700\n",
      "test_train\n",
      "train mean loss=0.09535041141013305\n",
      "test_test\n",
      "test mean loss=1158.0904541015625\n",
      "epoch 3701\n",
      "test_train\n",
      "train mean loss=0.09228581779946883\n",
      "test_test\n",
      "test mean loss=1156.0800170898438\n",
      "epoch 3702\n",
      "test_train\n",
      "train mean loss=0.08187834018220504\n",
      "test_test\n",
      "test mean loss=1156.38232421875\n",
      "epoch 3703\n",
      "test_train\n",
      "train mean loss=0.08132197925200065\n",
      "test_test\n",
      "test mean loss=1157.0879516601562\n",
      "epoch 3704\n",
      "test_train\n",
      "train mean loss=0.0802055262029171\n",
      "test_test\n",
      "test mean loss=1157.3558349609375\n",
      "epoch 3705\n",
      "test_train\n",
      "train mean loss=0.08377238890777032\n",
      "test_test\n",
      "test mean loss=1157.096435546875\n",
      "epoch 3706\n",
      "test_train\n",
      "train mean loss=0.08082569700976212\n",
      "test_test\n",
      "test mean loss=1157.9779663085938\n",
      "epoch 3707\n",
      "test_train\n",
      "train mean loss=0.08276525031154354\n",
      "test_test\n",
      "test mean loss=1157.9779052734375\n",
      "epoch 3708\n",
      "test_train\n",
      "train mean loss=0.07925497026493152\n",
      "test_test\n",
      "test mean loss=1157.1752319335938\n",
      "epoch 3709\n",
      "test_train\n",
      "train mean loss=0.08113384960840146\n",
      "test_test\n",
      "test mean loss=1158.0479125976562\n",
      "epoch 3710\n",
      "test_train\n",
      "train mean loss=0.08688986704995234\n",
      "test_test\n",
      "test mean loss=1157.4486694335938\n",
      "epoch 3711\n",
      "test_train\n",
      "train mean loss=0.0836696857586503\n",
      "test_test\n",
      "test mean loss=1158.4171142578125\n",
      "epoch 3712\n",
      "test_train\n",
      "train mean loss=0.1028046462063988\n",
      "test_test\n",
      "test mean loss=1158.0618286132812\n",
      "epoch 3713\n",
      "test_train\n",
      "train mean loss=0.09748736924181382\n",
      "test_test\n",
      "test mean loss=1157.8306274414062\n",
      "epoch 3714\n",
      "test_train\n",
      "train mean loss=0.09063555548588435\n",
      "test_test\n",
      "test mean loss=1158.3165283203125\n",
      "epoch 3715\n",
      "test_train\n",
      "train mean loss=0.07781130044410627\n",
      "test_test\n",
      "test mean loss=1157.9909362792969\n",
      "epoch 3716\n",
      "test_train\n",
      "train mean loss=0.08325111276159684\n",
      "test_test\n",
      "test mean loss=1157.29833984375\n",
      "epoch 3717\n",
      "test_train\n",
      "train mean loss=0.07895417728771766\n",
      "test_test\n",
      "test mean loss=1156.767822265625\n",
      "epoch 3718\n",
      "test_train\n",
      "train mean loss=0.07834542480607827\n",
      "test_test\n",
      "test mean loss=1157.0693969726562\n",
      "epoch 3719\n",
      "test_train\n",
      "train mean loss=0.08420512856294711\n",
      "test_test\n",
      "test mean loss=1158.1017456054688\n",
      "epoch 3720\n",
      "test_train\n",
      "train mean loss=0.108243344972531\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1159.7296752929688\n",
      "epoch 3721\n",
      "test_train\n",
      "train mean loss=0.08122235350310802\n",
      "test_test\n",
      "test mean loss=1157.727783203125\n",
      "epoch 3722\n",
      "test_train\n",
      "train mean loss=0.08405450607339542\n",
      "test_test\n",
      "test mean loss=1157.903564453125\n",
      "epoch 3723\n",
      "test_train\n",
      "train mean loss=0.09111083454142015\n",
      "test_test\n",
      "test mean loss=1158.762451171875\n",
      "epoch 3724\n",
      "test_train\n",
      "train mean loss=0.09370485444863637\n",
      "test_test\n",
      "test mean loss=1158.2639770507812\n",
      "epoch 3725\n",
      "test_train\n",
      "train mean loss=0.08586814192434152\n",
      "test_test\n",
      "test mean loss=1157.5859375\n",
      "epoch 3726\n",
      "test_train\n",
      "train mean loss=0.08445572604735692\n",
      "test_test\n",
      "test mean loss=1157.3309936523438\n",
      "epoch 3727\n",
      "test_train\n",
      "train mean loss=0.08366854799290498\n",
      "test_test\n",
      "test mean loss=1157.5762023925781\n",
      "epoch 3728\n",
      "test_train\n",
      "train mean loss=0.08890151263525088\n",
      "test_test\n",
      "test mean loss=1158.0267944335938\n",
      "epoch 3729\n",
      "test_train\n",
      "train mean loss=0.11726590245962143\n",
      "test_test\n",
      "test mean loss=1158.6072082519531\n",
      "epoch 3730\n",
      "test_train\n",
      "train mean loss=0.08752920757979155\n",
      "test_test\n",
      "test mean loss=1157.1951904296875\n",
      "epoch 3731\n",
      "test_train\n",
      "train mean loss=0.08643524503956239\n",
      "test_test\n",
      "test mean loss=1158.5347900390625\n",
      "epoch 3732\n",
      "test_train\n",
      "train mean loss=0.0901005497823159\n",
      "test_test\n",
      "test mean loss=1157.9846801757812\n",
      "epoch 3733\n",
      "test_train\n",
      "train mean loss=0.08663744727770488\n",
      "test_test\n",
      "test mean loss=1158.2463989257812\n",
      "epoch 3734\n",
      "test_train\n",
      "train mean loss=0.08508639472226302\n",
      "test_test\n",
      "test mean loss=1158.0188903808594\n",
      "epoch 3735\n",
      "test_train\n",
      "train mean loss=0.08229845234503348\n",
      "test_test\n",
      "test mean loss=1157.0073547363281\n",
      "epoch 3736\n",
      "test_train\n",
      "train mean loss=0.08732938673347235\n",
      "test_test\n",
      "test mean loss=1158.0604858398438\n",
      "epoch 3737\n",
      "test_train\n",
      "train mean loss=0.08670950960367918\n",
      "test_test\n",
      "test mean loss=1157.6043701171875\n",
      "epoch 3738\n",
      "test_train\n",
      "train mean loss=0.0780027573928237\n",
      "test_test\n",
      "test mean loss=1157.9410400390625\n",
      "epoch 3739\n",
      "test_train\n",
      "train mean loss=0.08371871896088123\n",
      "test_test\n",
      "test mean loss=1157.7842407226562\n",
      "epoch 3740\n",
      "test_train\n",
      "train mean loss=0.08381285052746534\n",
      "test_test\n",
      "test mean loss=1157.4105224609375\n",
      "epoch 3741\n",
      "test_train\n",
      "train mean loss=0.08996740325043599\n",
      "test_test\n",
      "test mean loss=1158.9503173828125\n",
      "epoch 3742\n",
      "test_train\n",
      "train mean loss=0.08326907207568486\n",
      "test_test\n",
      "test mean loss=1156.8812866210938\n",
      "epoch 3743\n",
      "test_train\n",
      "train mean loss=0.08235770277678967\n",
      "test_test\n",
      "test mean loss=1158.6792907714844\n",
      "epoch 3744\n",
      "test_train\n",
      "train mean loss=0.08447451485941808\n",
      "test_test\n",
      "test mean loss=1157.1070861816406\n",
      "epoch 3745\n",
      "test_train\n",
      "train mean loss=0.09237463772296906\n",
      "test_test\n",
      "test mean loss=1157.7100219726562\n",
      "epoch 3746\n",
      "test_train\n",
      "train mean loss=0.08483511240532\n",
      "test_test\n",
      "test mean loss=1158.3584899902344\n",
      "epoch 3747\n",
      "test_train\n",
      "train mean loss=0.08811793942004442\n",
      "test_test\n",
      "test mean loss=1158.1829833984375\n",
      "epoch 3748\n",
      "test_train\n",
      "train mean loss=0.08152712695300579\n",
      "test_test\n",
      "test mean loss=1157.9414672851562\n",
      "epoch 3749\n",
      "test_train\n",
      "train mean loss=0.08119089870403211\n",
      "test_test\n",
      "test mean loss=1158.4759521484375\n",
      "epoch 3750\n",
      "test_train\n",
      "train mean loss=0.09711959244062503\n",
      "test_test\n",
      "test mean loss=1156.3527221679688\n",
      "epoch 3751\n",
      "test_train\n",
      "train mean loss=0.08863893647988637\n",
      "test_test\n",
      "test mean loss=1156.9126586914062\n",
      "epoch 3752\n",
      "test_train\n",
      "train mean loss=0.11108534286419551\n",
      "test_test\n",
      "test mean loss=1156.7686157226562\n",
      "epoch 3753\n",
      "test_train\n",
      "train mean loss=0.07980100996792316\n",
      "test_test\n",
      "test mean loss=1156.7781066894531\n",
      "epoch 3754\n",
      "test_train\n",
      "train mean loss=0.0885849070424835\n",
      "test_test\n",
      "test mean loss=1157.6237182617188\n",
      "epoch 3755\n",
      "test_train\n",
      "train mean loss=0.09113718258837859\n",
      "test_test\n",
      "test mean loss=1158.4415893554688\n",
      "epoch 3756\n",
      "test_train\n",
      "train mean loss=0.08052197378128767\n",
      "test_test\n",
      "test mean loss=1156.968017578125\n",
      "epoch 3757\n",
      "test_train\n",
      "train mean loss=0.08031298437466224\n",
      "test_test\n",
      "test mean loss=1157.7904052734375\n",
      "epoch 3758\n",
      "test_train\n",
      "train mean loss=0.08047367632389069\n",
      "test_test\n",
      "test mean loss=1157.1533813476562\n",
      "epoch 3759\n",
      "test_train\n",
      "train mean loss=0.08124512465049823\n",
      "test_test\n",
      "test mean loss=1157.5025024414062\n",
      "epoch 3760\n",
      "test_train\n",
      "train mean loss=0.08128011443962653\n",
      "test_test\n",
      "test mean loss=1157.3534545898438\n",
      "epoch 3761\n",
      "test_train\n",
      "train mean loss=0.08080116504182418\n",
      "test_test\n",
      "test mean loss=1157.6786499023438\n",
      "epoch 3762\n",
      "test_train\n",
      "train mean loss=0.07803188714509209\n",
      "test_test\n",
      "test mean loss=1157.4673461914062\n",
      "epoch 3763\n",
      "test_train\n",
      "train mean loss=0.0868513851116101\n",
      "test_test\n",
      "test mean loss=1158.3124389648438\n",
      "epoch 3764\n",
      "test_train\n",
      "train mean loss=0.08233282342553139\n",
      "test_test\n",
      "test mean loss=1158.66259765625\n",
      "epoch 3765\n",
      "test_train\n",
      "train mean loss=0.07777147243420283\n",
      "test_test\n",
      "test mean loss=1158.1661987304688\n",
      "epoch 3766\n",
      "test_train\n",
      "train mean loss=0.08416475883374612\n",
      "test_test\n",
      "test mean loss=1158.840576171875\n",
      "epoch 3767\n",
      "test_train\n",
      "train mean loss=0.08572530653327703\n",
      "test_test\n",
      "test mean loss=1159.1395568847656\n",
      "epoch 3768\n",
      "test_train\n",
      "train mean loss=0.0918439319357276\n",
      "test_test\n",
      "test mean loss=1159.06787109375\n",
      "epoch 3769\n",
      "test_train\n",
      "train mean loss=0.0936254020780325\n",
      "test_test\n",
      "test mean loss=1160.5364379882812\n",
      "epoch 3770\n",
      "test_train\n",
      "train mean loss=0.07911138981580734\n",
      "test_test\n",
      "test mean loss=1159.3212585449219\n",
      "epoch 3771\n",
      "test_train\n",
      "train mean loss=0.0765448755895098\n",
      "test_test\n",
      "test mean loss=1159.2791137695312\n",
      "epoch 3772\n",
      "test_train\n",
      "train mean loss=0.0842319621394078\n",
      "test_test\n",
      "test mean loss=1158.717529296875\n",
      "epoch 3773\n",
      "test_train\n",
      "train mean loss=0.08502544462680817\n",
      "test_test\n",
      "test mean loss=1158.3050537109375\n",
      "epoch 3774\n",
      "test_train\n",
      "train mean loss=0.08073656602452199\n",
      "test_test\n",
      "test mean loss=1158.4729309082031\n",
      "epoch 3775\n",
      "test_train\n",
      "train mean loss=0.07456813318034013\n",
      "test_test\n",
      "test mean loss=1158.2491455078125\n",
      "epoch 3776\n",
      "test_train\n",
      "train mean loss=0.08123577029133837\n",
      "test_test\n",
      "test mean loss=1159.3060302734375\n",
      "epoch 3777\n",
      "test_train\n",
      "train mean loss=0.08563921445359786\n",
      "test_test\n",
      "test mean loss=1159.3440551757812\n",
      "epoch 3778\n",
      "test_train\n",
      "train mean loss=0.08813102326045434\n",
      "test_test\n",
      "test mean loss=1158.9607543945312\n",
      "epoch 3779\n",
      "test_train\n",
      "train mean loss=0.08551537555952866\n",
      "test_test\n",
      "test mean loss=1159.190673828125\n",
      "epoch 3780\n",
      "test_train\n",
      "train mean loss=0.0827054815987746\n",
      "test_test\n",
      "test mean loss=1158.8917846679688\n",
      "epoch 3781\n",
      "test_train\n",
      "train mean loss=0.08369908078263204\n",
      "test_test\n",
      "test mean loss=1159.76953125\n",
      "epoch 3782\n",
      "test_train\n",
      "train mean loss=0.08594497696806987\n",
      "test_test\n",
      "test mean loss=1160.2955322265625\n",
      "epoch 3783\n",
      "test_train\n",
      "train mean loss=0.08370788022875786\n",
      "test_test\n",
      "test mean loss=1159.6882629394531\n",
      "epoch 3784\n",
      "test_train\n",
      "train mean loss=0.20981701463460922\n",
      "test_test\n",
      "test mean loss=1157.9955444335938\n",
      "epoch 3785\n",
      "test_train\n",
      "train mean loss=0.09939859962711732\n",
      "test_test\n",
      "test mean loss=1158.9310302734375\n",
      "epoch 3786\n",
      "test_train\n",
      "train mean loss=0.07371876606096824\n",
      "test_test\n",
      "test mean loss=1157.5950317382812\n",
      "epoch 3787\n",
      "test_train\n",
      "train mean loss=0.0778940748423338\n",
      "test_test\n",
      "test mean loss=1158.526611328125\n",
      "epoch 3788\n",
      "test_train\n",
      "train mean loss=0.08433329841742913\n",
      "test_test\n",
      "test mean loss=1160.0778198242188\n",
      "epoch 3789\n",
      "test_train\n",
      "train mean loss=0.08422757623096307\n",
      "test_test\n",
      "test mean loss=1158.0056762695312\n",
      "epoch 3790\n",
      "test_train\n",
      "train mean loss=0.07453943323343992\n",
      "test_test\n",
      "test mean loss=1158.1553344726562\n",
      "epoch 3791\n",
      "test_train\n",
      "train mean loss=0.07735602495570977\n",
      "test_test\n",
      "test mean loss=1158.251708984375\n",
      "epoch 3792\n",
      "test_train\n",
      "train mean loss=0.08227028387288253\n",
      "test_test\n",
      "test mean loss=1158.4553833007812\n",
      "epoch 3793\n",
      "test_train\n",
      "train mean loss=0.08498229427884023\n",
      "test_test\n",
      "test mean loss=1158.1825866699219\n",
      "epoch 3794\n",
      "test_train\n",
      "train mean loss=0.0846977202842633\n",
      "test_test\n",
      "test mean loss=1158.0208435058594\n",
      "epoch 3795\n",
      "test_train\n",
      "train mean loss=0.08104277557382981\n",
      "test_test\n",
      "test mean loss=1158.9900512695312\n",
      "epoch 3796\n",
      "test_train\n",
      "train mean loss=0.08625460074593623\n",
      "test_test\n",
      "test mean loss=1158.7459716796875\n",
      "epoch 3797\n",
      "test_train\n",
      "train mean loss=0.08498562748233478\n",
      "test_test\n",
      "test mean loss=1158.5785522460938\n",
      "epoch 3798\n",
      "test_train\n",
      "train mean loss=0.08200435775021712\n",
      "test_test\n",
      "test mean loss=1158.4183349609375\n",
      "epoch 3799\n",
      "test_train\n",
      "train mean loss=0.0922147814805309\n",
      "test_test\n",
      "test mean loss=1159.3038635253906\n",
      "epoch 3800\n",
      "test_train\n",
      "train mean loss=0.08352282363921404\n",
      "test_test\n",
      "test mean loss=1158.0765686035156\n",
      "epoch 3801\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.08526536667098601\n",
      "test_test\n",
      "test mean loss=1157.2694091796875\n",
      "epoch 3802\n",
      "test_train\n",
      "train mean loss=0.0845417973274986\n",
      "test_test\n",
      "test mean loss=1158.051025390625\n",
      "epoch 3803\n",
      "test_train\n",
      "train mean loss=14.366182384391626\n",
      "test_test\n",
      "test mean loss=1160.6017150878906\n",
      "epoch 3804\n",
      "test_train\n",
      "train mean loss=0.08194101881235838\n",
      "test_test\n",
      "test mean loss=1158.4451599121094\n",
      "epoch 3805\n",
      "test_train\n",
      "train mean loss=0.08526384768386681\n",
      "test_test\n",
      "test mean loss=1158.2146606445312\n",
      "epoch 3806\n",
      "test_train\n",
      "train mean loss=0.08723350210736196\n",
      "test_test\n",
      "test mean loss=1159.7166137695312\n",
      "epoch 3807\n",
      "test_train\n",
      "train mean loss=0.07811798760667443\n",
      "test_test\n",
      "test mean loss=1158.6556396484375\n",
      "epoch 3808\n",
      "test_train\n",
      "train mean loss=0.08017116350432237\n",
      "test_test\n",
      "test mean loss=1158.8365478515625\n",
      "epoch 3809\n",
      "test_train\n",
      "train mean loss=0.0773885678499937\n",
      "test_test\n",
      "test mean loss=1159.1298828125\n",
      "epoch 3810\n",
      "test_train\n",
      "train mean loss=0.08758213308950265\n",
      "test_test\n",
      "test mean loss=1159.5557861328125\n",
      "epoch 3811\n",
      "test_train\n",
      "train mean loss=0.0881561515852809\n",
      "test_test\n",
      "test mean loss=1160.2151489257812\n",
      "epoch 3812\n",
      "test_train\n",
      "train mean loss=0.09573183146615823\n",
      "test_test\n",
      "test mean loss=1158.8272399902344\n",
      "epoch 3813\n",
      "test_train\n",
      "train mean loss=0.07750230841338634\n",
      "test_test\n",
      "test mean loss=1158.5274963378906\n",
      "epoch 3814\n",
      "test_train\n",
      "train mean loss=0.0926931429033478\n",
      "test_test\n",
      "test mean loss=1158.3179931640625\n",
      "epoch 3815\n",
      "test_train\n",
      "train mean loss=0.07954055815935135\n",
      "test_test\n",
      "test mean loss=1158.9117126464844\n",
      "epoch 3816\n",
      "test_train\n",
      "train mean loss=0.07728631049394608\n",
      "test_test\n",
      "test mean loss=1158.2379455566406\n",
      "epoch 3817\n",
      "test_train\n",
      "train mean loss=0.08133144459376733\n",
      "test_test\n",
      "test mean loss=1158.4512939453125\n",
      "epoch 3818\n",
      "test_train\n",
      "train mean loss=0.0812466200441122\n",
      "test_test\n",
      "test mean loss=1158.5009460449219\n",
      "epoch 3819\n",
      "test_train\n",
      "train mean loss=0.09175812111546595\n",
      "test_test\n",
      "test mean loss=1157.0299682617188\n",
      "epoch 3820\n",
      "test_train\n",
      "train mean loss=0.09146161781003077\n",
      "test_test\n",
      "test mean loss=1158.2125549316406\n",
      "epoch 3821\n",
      "test_train\n",
      "train mean loss=0.0844041183590889\n",
      "test_test\n",
      "test mean loss=1157.6803588867188\n",
      "epoch 3822\n",
      "test_train\n",
      "train mean loss=0.09043080825358629\n",
      "test_test\n",
      "test mean loss=1157.7386474609375\n",
      "epoch 3823\n",
      "test_train\n",
      "train mean loss=0.08508394006639719\n",
      "test_test\n",
      "test mean loss=1158.4210815429688\n",
      "epoch 3824\n",
      "test_train\n",
      "train mean loss=0.08699892554432154\n",
      "test_test\n",
      "test mean loss=1159.9027099609375\n",
      "epoch 3825\n",
      "test_train\n",
      "train mean loss=0.11205976518491904\n",
      "test_test\n",
      "test mean loss=1158.4540405273438\n",
      "epoch 3826\n",
      "test_train\n",
      "train mean loss=0.09182900780191024\n",
      "test_test\n",
      "test mean loss=1159.2338256835938\n",
      "epoch 3827\n",
      "test_train\n",
      "train mean loss=0.08889485243707895\n",
      "test_test\n",
      "test mean loss=1158.6416015625\n",
      "epoch 3828\n",
      "test_train\n",
      "train mean loss=0.08109687951703866\n",
      "test_test\n",
      "test mean loss=1158.0612182617188\n",
      "epoch 3829\n",
      "test_train\n",
      "train mean loss=0.08671830625583728\n",
      "test_test\n",
      "test mean loss=1158.3764343261719\n",
      "epoch 3830\n",
      "test_train\n",
      "train mean loss=0.08828326997657616\n",
      "test_test\n",
      "test mean loss=1158.667236328125\n",
      "epoch 3831\n",
      "test_train\n",
      "train mean loss=0.08138470072299242\n",
      "test_test\n",
      "test mean loss=1158.4867858886719\n",
      "epoch 3832\n",
      "test_train\n",
      "train mean loss=0.08431791669378678\n",
      "test_test\n",
      "test mean loss=1159.7384643554688\n",
      "epoch 3833\n",
      "test_train\n",
      "train mean loss=0.08816447978218396\n",
      "test_test\n",
      "test mean loss=1159.5627136230469\n",
      "epoch 3834\n",
      "test_train\n",
      "train mean loss=0.0875114422912399\n",
      "test_test\n",
      "test mean loss=1158.5997009277344\n",
      "epoch 3835\n",
      "test_train\n",
      "train mean loss=0.11553723427156608\n",
      "test_test\n",
      "test mean loss=1158.5053100585938\n",
      "epoch 3836\n",
      "test_train\n",
      "train mean loss=0.09750547135869662\n",
      "test_test\n",
      "test mean loss=1158.9682006835938\n",
      "epoch 3837\n",
      "test_train\n",
      "train mean loss=0.08964638287822406\n",
      "test_test\n",
      "test mean loss=1157.6396789550781\n",
      "epoch 3838\n",
      "test_train\n",
      "train mean loss=0.08431768883019686\n",
      "test_test\n",
      "test mean loss=1157.9388427734375\n",
      "epoch 3839\n",
      "test_train\n",
      "train mean loss=0.07860400279362996\n",
      "test_test\n",
      "test mean loss=1157.9328002929688\n",
      "epoch 3840\n",
      "test_train\n",
      "train mean loss=0.09648049995303154\n",
      "test_test\n",
      "test mean loss=1158.8731384277344\n",
      "epoch 3841\n",
      "test_train\n",
      "train mean loss=0.0886091726521651\n",
      "test_test\n",
      "test mean loss=1158.4452514648438\n",
      "epoch 3842\n",
      "test_train\n",
      "train mean loss=0.3359871506690979\n",
      "test_test\n",
      "test mean loss=1158.9044494628906\n",
      "epoch 3843\n",
      "test_train\n",
      "train mean loss=0.09772912381837766\n",
      "test_test\n",
      "test mean loss=1157.7107543945312\n",
      "epoch 3844\n",
      "test_train\n",
      "train mean loss=0.08724491391330957\n",
      "test_test\n",
      "test mean loss=1156.8920288085938\n",
      "epoch 3845\n",
      "test_train\n",
      "train mean loss=0.08258804368476073\n",
      "test_test\n",
      "test mean loss=1155.9414672851562\n",
      "epoch 3846\n",
      "test_train\n",
      "train mean loss=0.09324708580970764\n",
      "test_test\n",
      "test mean loss=1155.2126770019531\n",
      "epoch 3847\n",
      "test_train\n",
      "train mean loss=0.08804876233140628\n",
      "test_test\n",
      "test mean loss=1156.4678344726562\n",
      "epoch 3848\n",
      "test_train\n",
      "train mean loss=0.08964080301423867\n",
      "test_test\n",
      "test mean loss=1156.6106872558594\n",
      "epoch 3849\n",
      "test_train\n",
      "train mean loss=0.0916608131180207\n",
      "test_test\n",
      "test mean loss=1157.1173400878906\n",
      "epoch 3850\n",
      "test_train\n",
      "train mean loss=0.08843573710570733\n",
      "test_test\n",
      "test mean loss=1157.7843017578125\n",
      "epoch 3851\n",
      "test_train\n",
      "train mean loss=0.08813871101786692\n",
      "test_test\n",
      "test mean loss=1156.4800415039062\n",
      "epoch 3852\n",
      "test_train\n",
      "train mean loss=0.08243975912531216\n",
      "test_test\n",
      "test mean loss=1156.0358276367188\n",
      "epoch 3853\n",
      "test_train\n",
      "train mean loss=0.08458863478153944\n",
      "test_test\n",
      "test mean loss=1156.111572265625\n",
      "epoch 3854\n",
      "test_train\n",
      "train mean loss=0.08690607516715924\n",
      "test_test\n",
      "test mean loss=1156.7225036621094\n",
      "epoch 3855\n",
      "test_train\n",
      "train mean loss=0.08486173239847024\n",
      "test_test\n",
      "test mean loss=1156.5112609863281\n",
      "epoch 3856\n",
      "test_train\n",
      "train mean loss=0.08331249623248975\n",
      "test_test\n",
      "test mean loss=1155.9342041015625\n",
      "epoch 3857\n",
      "test_train\n",
      "train mean loss=0.07810379130144914\n",
      "test_test\n",
      "test mean loss=1156.1988525390625\n",
      "epoch 3858\n",
      "test_train\n",
      "train mean loss=0.08168544247746468\n",
      "test_test\n",
      "test mean loss=1155.3314819335938\n",
      "epoch 3859\n",
      "test_train\n",
      "train mean loss=0.08048773494859536\n",
      "test_test\n",
      "test mean loss=1156.9722290039062\n",
      "epoch 3860\n",
      "test_train\n",
      "train mean loss=0.07873433238516252\n",
      "test_test\n",
      "test mean loss=1156.9776000976562\n",
      "epoch 3861\n",
      "test_train\n",
      "train mean loss=0.1093443011244138\n",
      "test_test\n",
      "test mean loss=1157.4251708984375\n",
      "epoch 3862\n",
      "test_train\n",
      "train mean loss=0.08990532159805298\n",
      "test_test\n",
      "test mean loss=1158.298828125\n",
      "epoch 3863\n",
      "test_train\n",
      "train mean loss=0.0806448378910621\n",
      "test_test\n",
      "test mean loss=1157.6784057617188\n",
      "epoch 3864\n",
      "test_train\n",
      "train mean loss=0.1156748350088795\n",
      "test_test\n",
      "test mean loss=1158.1633911132812\n",
      "epoch 3865\n",
      "test_train\n",
      "train mean loss=0.08999553757409255\n",
      "test_test\n",
      "test mean loss=1157.8833618164062\n",
      "epoch 3866\n",
      "test_train\n",
      "train mean loss=0.08642012719064951\n",
      "test_test\n",
      "test mean loss=1158.0771179199219\n",
      "epoch 3867\n",
      "test_train\n",
      "train mean loss=0.1146533874173959\n",
      "test_test\n",
      "test mean loss=1157.6597290039062\n",
      "epoch 3868\n",
      "test_train\n",
      "train mean loss=0.07792094349861145\n",
      "test_test\n",
      "test mean loss=1155.9590148925781\n",
      "epoch 3869\n",
      "test_train\n",
      "train mean loss=0.15823492407798767\n",
      "test_test\n",
      "test mean loss=1157.3229064941406\n",
      "epoch 3870\n",
      "test_train\n",
      "train mean loss=0.08868954765299956\n",
      "test_test\n",
      "test mean loss=1155.1243286132812\n",
      "epoch 3871\n",
      "test_train\n",
      "train mean loss=0.08169427141547203\n",
      "test_test\n",
      "test mean loss=1156.8006591796875\n",
      "epoch 3872\n",
      "test_train\n",
      "train mean loss=0.08000215919067462\n",
      "test_test\n",
      "test mean loss=1156.4385986328125\n",
      "epoch 3873\n",
      "test_train\n",
      "train mean loss=0.08387935534119606\n",
      "test_test\n",
      "test mean loss=1157.4818115234375\n",
      "epoch 3874\n",
      "test_train\n",
      "train mean loss=0.08291263195375602\n",
      "test_test\n",
      "test mean loss=1156.3486938476562\n",
      "epoch 3875\n",
      "test_train\n",
      "train mean loss=0.08699044088522594\n",
      "test_test\n",
      "test mean loss=1157.0906982421875\n",
      "epoch 3876\n",
      "test_train\n",
      "train mean loss=0.08672172762453556\n",
      "test_test\n",
      "test mean loss=1157.6613159179688\n",
      "epoch 3877\n",
      "test_train\n",
      "train mean loss=0.08641193186243375\n",
      "test_test\n",
      "test mean loss=1157.4230346679688\n",
      "epoch 3878\n",
      "test_train\n",
      "train mean loss=0.08517774908492963\n",
      "test_test\n",
      "test mean loss=1157.7349243164062\n",
      "epoch 3879\n",
      "test_train\n",
      "train mean loss=0.089324951171875\n",
      "test_test\n",
      "test mean loss=1157.5831909179688\n",
      "epoch 3880\n",
      "test_train\n",
      "train mean loss=0.08466333368172248\n",
      "test_test\n",
      "test mean loss=1157.5965270996094\n",
      "epoch 3881\n",
      "test_train\n",
      "train mean loss=0.0809183685729901\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1157.5587158203125\n",
      "epoch 3882\n",
      "test_train\n",
      "train mean loss=0.10872092594703038\n",
      "test_test\n",
      "test mean loss=1156.8262329101562\n",
      "epoch 3883\n",
      "test_train\n",
      "train mean loss=0.0823780307546258\n",
      "test_test\n",
      "test mean loss=1156.8986511230469\n",
      "epoch 3884\n",
      "test_train\n",
      "train mean loss=0.07735492940992117\n",
      "test_test\n",
      "test mean loss=1157.630126953125\n",
      "epoch 3885\n",
      "test_train\n",
      "train mean loss=0.08098033753534158\n",
      "test_test\n",
      "test mean loss=1158.411865234375\n",
      "epoch 3886\n",
      "test_train\n",
      "train mean loss=0.08156577590852976\n",
      "test_test\n",
      "test mean loss=1157.7510070800781\n",
      "epoch 3887\n",
      "test_train\n",
      "train mean loss=0.08805605458716552\n",
      "test_test\n",
      "test mean loss=1156.6673583984375\n",
      "epoch 3888\n",
      "test_train\n",
      "train mean loss=0.07998972913871209\n",
      "test_test\n",
      "test mean loss=1157.8953857421875\n",
      "epoch 3889\n",
      "test_train\n",
      "train mean loss=0.08685872983187437\n",
      "test_test\n",
      "test mean loss=1157.704345703125\n",
      "epoch 3890\n",
      "test_train\n",
      "train mean loss=0.07877329085022211\n",
      "test_test\n",
      "test mean loss=1156.8583068847656\n",
      "epoch 3891\n",
      "test_train\n",
      "train mean loss=0.08575688768178225\n",
      "test_test\n",
      "test mean loss=1158.094482421875\n",
      "epoch 3892\n",
      "test_train\n",
      "train mean loss=0.08495887958755095\n",
      "test_test\n",
      "test mean loss=1158.2105712890625\n",
      "epoch 3893\n",
      "test_train\n",
      "train mean loss=0.07899072145422299\n",
      "test_test\n",
      "test mean loss=1156.8077392578125\n",
      "epoch 3894\n",
      "test_train\n",
      "train mean loss=0.1447265806297461\n",
      "test_test\n",
      "test mean loss=1160.066650390625\n",
      "epoch 3895\n",
      "test_train\n",
      "train mean loss=0.086935982418557\n",
      "test_test\n",
      "test mean loss=1158.6177978515625\n",
      "epoch 3896\n",
      "test_train\n",
      "train mean loss=0.10236908619602521\n",
      "test_test\n",
      "test mean loss=1156.7708740234375\n",
      "epoch 3897\n",
      "test_train\n",
      "train mean loss=0.08133580846091111\n",
      "test_test\n",
      "test mean loss=1157.6132202148438\n",
      "epoch 3898\n",
      "test_train\n",
      "train mean loss=0.08211118852098782\n",
      "test_test\n",
      "test mean loss=1157.6521606445312\n",
      "epoch 3899\n",
      "test_train\n",
      "train mean loss=0.08411644212901592\n",
      "test_test\n",
      "test mean loss=1157.4972534179688\n",
      "epoch 3900\n",
      "test_train\n",
      "train mean loss=0.08860745901862781\n",
      "test_test\n",
      "test mean loss=1156.7783813476562\n",
      "epoch 3901\n",
      "test_train\n",
      "train mean loss=0.08577334725608428\n",
      "test_test\n",
      "test mean loss=1156.8812255859375\n",
      "epoch 3902\n",
      "test_train\n",
      "train mean loss=0.07725803926587105\n",
      "test_test\n",
      "test mean loss=1156.7777709960938\n",
      "epoch 3903\n",
      "test_train\n",
      "train mean loss=0.07459252048283815\n",
      "test_test\n",
      "test mean loss=1157.2042236328125\n",
      "epoch 3904\n",
      "test_train\n",
      "train mean loss=0.07704316296925147\n",
      "test_test\n",
      "test mean loss=1157.926025390625\n",
      "epoch 3905\n",
      "test_train\n",
      "train mean loss=0.07965857132027547\n",
      "test_test\n",
      "test mean loss=1157.8928527832031\n",
      "epoch 3906\n",
      "test_train\n",
      "train mean loss=0.08459482652445634\n",
      "test_test\n",
      "test mean loss=1156.98291015625\n",
      "epoch 3907\n",
      "test_train\n",
      "train mean loss=0.0778033606087168\n",
      "test_test\n",
      "test mean loss=1157.1004028320312\n",
      "epoch 3908\n",
      "test_train\n",
      "train mean loss=0.07944863382726908\n",
      "test_test\n",
      "test mean loss=1157.0191650390625\n",
      "epoch 3909\n",
      "test_train\n",
      "train mean loss=0.07995754977067311\n",
      "test_test\n",
      "test mean loss=1158.3245849609375\n",
      "epoch 3910\n",
      "test_train\n",
      "train mean loss=0.07897171347091596\n",
      "test_test\n",
      "test mean loss=1157.4656372070312\n",
      "epoch 3911\n",
      "test_train\n",
      "train mean loss=0.07467833595971267\n",
      "test_test\n",
      "test mean loss=1157.0276489257812\n",
      "epoch 3912\n",
      "test_train\n",
      "train mean loss=0.07530119394262631\n",
      "test_test\n",
      "test mean loss=1158.3872680664062\n",
      "epoch 3913\n",
      "test_train\n",
      "train mean loss=0.088427413875858\n",
      "test_test\n",
      "test mean loss=1157.2220458984375\n",
      "epoch 3914\n",
      "test_train\n",
      "train mean loss=0.08049982475737731\n",
      "test_test\n",
      "test mean loss=1157.3197021484375\n",
      "epoch 3915\n",
      "test_train\n",
      "train mean loss=0.0816988159591953\n",
      "test_test\n",
      "test mean loss=1157.8157043457031\n",
      "epoch 3916\n",
      "test_train\n",
      "train mean loss=0.15174360076586405\n",
      "test_test\n",
      "test mean loss=1160.0182495117188\n",
      "epoch 3917\n",
      "test_train\n",
      "train mean loss=0.09675711455444495\n",
      "test_test\n",
      "test mean loss=1158.3372192382812\n",
      "epoch 3918\n",
      "test_train\n",
      "train mean loss=0.07275793794542551\n",
      "test_test\n",
      "test mean loss=1157.54052734375\n",
      "epoch 3919\n",
      "test_train\n",
      "train mean loss=0.07486156715701024\n",
      "test_test\n",
      "test mean loss=1157.969482421875\n",
      "epoch 3920\n",
      "test_train\n",
      "train mean loss=0.0837621558457613\n",
      "test_test\n",
      "test mean loss=1158.4180297851562\n",
      "epoch 3921\n",
      "test_train\n",
      "train mean loss=0.08079056379695733\n",
      "test_test\n",
      "test mean loss=1157.164794921875\n",
      "epoch 3922\n",
      "test_train\n",
      "train mean loss=0.08234213044246037\n",
      "test_test\n",
      "test mean loss=1157.6907958984375\n",
      "epoch 3923\n",
      "test_train\n",
      "train mean loss=0.08182068231205146\n",
      "test_test\n",
      "test mean loss=1157.6672668457031\n",
      "epoch 3924\n",
      "test_train\n",
      "train mean loss=0.09768309940894444\n",
      "test_test\n",
      "test mean loss=1155.7799682617188\n",
      "epoch 3925\n",
      "test_train\n",
      "train mean loss=0.08107087792207797\n",
      "test_test\n",
      "test mean loss=1157.2152709960938\n",
      "epoch 3926\n",
      "test_train\n",
      "train mean loss=0.07850521833946307\n",
      "test_test\n",
      "test mean loss=1156.1858520507812\n",
      "epoch 3927\n",
      "test_train\n",
      "train mean loss=0.07522959914058447\n",
      "test_test\n",
      "test mean loss=1157.2589721679688\n",
      "epoch 3928\n",
      "test_train\n",
      "train mean loss=0.07822851712505023\n",
      "test_test\n",
      "test mean loss=1156.7844543457031\n",
      "epoch 3929\n",
      "test_train\n",
      "train mean loss=0.08639743365347385\n",
      "test_test\n",
      "test mean loss=1157.9539794921875\n",
      "epoch 3930\n",
      "test_train\n",
      "train mean loss=0.08513082781185706\n",
      "test_test\n",
      "test mean loss=1156.7809448242188\n",
      "epoch 3931\n",
      "test_train\n",
      "train mean loss=0.11498838228483994\n",
      "test_test\n",
      "test mean loss=1157.0117797851562\n",
      "epoch 3932\n",
      "test_train\n",
      "train mean loss=0.07437541956702869\n",
      "test_test\n",
      "test mean loss=1157.3712158203125\n",
      "epoch 3933\n",
      "test_train\n",
      "train mean loss=0.07664115075021982\n",
      "test_test\n",
      "test mean loss=1157.2596130371094\n",
      "epoch 3934\n",
      "test_train\n",
      "train mean loss=0.08357556164264679\n",
      "test_test\n",
      "test mean loss=1157.8882446289062\n",
      "epoch 3935\n",
      "test_train\n",
      "train mean loss=0.08127015735954046\n",
      "test_test\n",
      "test mean loss=1156.51708984375\n",
      "epoch 3936\n",
      "test_train\n",
      "train mean loss=0.08072665582100551\n",
      "test_test\n",
      "test mean loss=1158.1930236816406\n",
      "epoch 3937\n",
      "test_train\n",
      "train mean loss=0.08377022637675206\n",
      "test_test\n",
      "test mean loss=1157.82080078125\n",
      "epoch 3938\n",
      "test_train\n",
      "train mean loss=0.07887253320465486\n",
      "test_test\n",
      "test mean loss=1157.7274780273438\n",
      "epoch 3939\n",
      "test_train\n",
      "train mean loss=0.078104295146962\n",
      "test_test\n",
      "test mean loss=1157.2850036621094\n",
      "epoch 3940\n",
      "test_train\n",
      "train mean loss=0.07526134078701337\n",
      "test_test\n",
      "test mean loss=1156.8646240234375\n",
      "epoch 3941\n",
      "test_train\n",
      "train mean loss=0.07330370446046193\n",
      "test_test\n",
      "test mean loss=1157.585693359375\n",
      "epoch 3942\n",
      "test_train\n",
      "train mean loss=0.07802323376139005\n",
      "test_test\n",
      "test mean loss=1158.2371520996094\n",
      "epoch 3943\n",
      "test_train\n",
      "train mean loss=0.07991143688559532\n",
      "test_test\n",
      "test mean loss=1157.4267578125\n",
      "epoch 3944\n",
      "test_train\n",
      "train mean loss=0.08495808144410451\n",
      "test_test\n",
      "test mean loss=1157.6114501953125\n",
      "epoch 3945\n",
      "test_train\n",
      "train mean loss=0.07689641571293275\n",
      "test_test\n",
      "test mean loss=1157.4788818359375\n",
      "epoch 3946\n",
      "test_train\n",
      "train mean loss=0.0796784075597922\n",
      "test_test\n",
      "test mean loss=1158.2030639648438\n",
      "epoch 3947\n",
      "test_train\n",
      "train mean loss=0.09083330134550731\n",
      "test_test\n",
      "test mean loss=1156.9490966796875\n",
      "epoch 3948\n",
      "test_train\n",
      "train mean loss=12.429482777913412\n",
      "test_test\n",
      "test mean loss=1154.5050048828125\n",
      "epoch 3949\n",
      "test_train\n",
      "train mean loss=0.25234994168082875\n",
      "test_test\n",
      "test mean loss=1159.3562622070312\n",
      "epoch 3950\n",
      "test_train\n",
      "train mean loss=0.09327547810971737\n",
      "test_test\n",
      "test mean loss=1159.1649169921875\n",
      "epoch 3951\n",
      "test_train\n",
      "train mean loss=0.09216337526837985\n",
      "test_test\n",
      "test mean loss=1160.2225952148438\n",
      "epoch 3952\n",
      "test_train\n",
      "train mean loss=0.0853883782401681\n",
      "test_test\n",
      "test mean loss=1159.1283569335938\n",
      "epoch 3953\n",
      "test_train\n",
      "train mean loss=0.08575484311829011\n",
      "test_test\n",
      "test mean loss=1159.6736145019531\n",
      "epoch 3954\n",
      "test_train\n",
      "train mean loss=0.09285187566032012\n",
      "test_test\n",
      "test mean loss=1160.3182067871094\n",
      "epoch 3955\n",
      "test_train\n",
      "train mean loss=0.09351213648915291\n",
      "test_test\n",
      "test mean loss=1160.6676025390625\n",
      "epoch 3956\n",
      "test_train\n",
      "train mean loss=0.08261521967748801\n",
      "test_test\n",
      "test mean loss=1161.0641479492188\n",
      "epoch 3957\n",
      "test_train\n",
      "train mean loss=0.08072451688349247\n",
      "test_test\n",
      "test mean loss=1160.333251953125\n",
      "epoch 3958\n",
      "test_train\n",
      "train mean loss=0.09024965980400641\n",
      "test_test\n",
      "test mean loss=1159.2203979492188\n",
      "epoch 3959\n",
      "test_train\n",
      "train mean loss=0.08733772362271945\n",
      "test_test\n",
      "test mean loss=1159.8333740234375\n",
      "epoch 3960\n",
      "test_train\n",
      "train mean loss=0.08461643615737557\n",
      "test_test\n",
      "test mean loss=1158.8992614746094\n",
      "epoch 3961\n",
      "test_train\n",
      "train mean loss=0.08605020834753911\n",
      "test_test\n",
      "test mean loss=1160.0999755859375\n",
      "epoch 3962\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.0857226758574446\n",
      "test_test\n",
      "test mean loss=1161.5252685546875\n",
      "epoch 3963\n",
      "test_train\n",
      "train mean loss=0.08090802592535813\n",
      "test_test\n",
      "test mean loss=1161.2661437988281\n",
      "epoch 3964\n",
      "test_train\n",
      "train mean loss=0.08858812926337123\n",
      "test_test\n",
      "test mean loss=1161.69677734375\n",
      "epoch 3965\n",
      "test_train\n",
      "train mean loss=0.08035620053609212\n",
      "test_test\n",
      "test mean loss=1161.5835266113281\n",
      "epoch 3966\n",
      "test_train\n",
      "train mean loss=0.08880514682581027\n",
      "test_test\n",
      "test mean loss=1161.4620666503906\n",
      "epoch 3967\n",
      "test_train\n",
      "train mean loss=0.07532717287540436\n",
      "test_test\n",
      "test mean loss=1161.4306030273438\n",
      "epoch 3968\n",
      "test_train\n",
      "train mean loss=0.0766229818885525\n",
      "test_test\n",
      "test mean loss=1160.0419311523438\n",
      "epoch 3969\n",
      "test_train\n",
      "train mean loss=0.08005737420171499\n",
      "test_test\n",
      "test mean loss=1159.3537902832031\n",
      "epoch 3970\n",
      "test_train\n",
      "train mean loss=0.0779387413834532\n",
      "test_test\n",
      "test mean loss=1159.2117309570312\n",
      "epoch 3971\n",
      "test_train\n",
      "train mean loss=0.0787939705575506\n",
      "test_test\n",
      "test mean loss=1159.9803771972656\n",
      "epoch 3972\n",
      "test_train\n",
      "train mean loss=0.0888155394544204\n",
      "test_test\n",
      "test mean loss=1159.6434936523438\n",
      "epoch 3973\n",
      "test_train\n",
      "train mean loss=0.08820381046583255\n",
      "test_test\n",
      "test mean loss=1159.4015197753906\n",
      "epoch 3974\n",
      "test_train\n",
      "train mean loss=0.08134804448733728\n",
      "test_test\n",
      "test mean loss=1158.4518432617188\n",
      "epoch 3975\n",
      "test_train\n",
      "train mean loss=0.08477761006603639\n",
      "test_test\n",
      "test mean loss=1159.7697448730469\n",
      "epoch 3976\n",
      "test_train\n",
      "train mean loss=0.07985735560456912\n",
      "test_test\n",
      "test mean loss=1159.4703063964844\n",
      "epoch 3977\n",
      "test_train\n",
      "train mean loss=0.07374138416101535\n",
      "test_test\n",
      "test mean loss=1159.3738708496094\n",
      "epoch 3978\n",
      "test_train\n",
      "train mean loss=0.29571524262428284\n",
      "test_test\n",
      "test mean loss=1156.7451782226562\n",
      "epoch 3979\n",
      "test_train\n",
      "train mean loss=0.09008758266766866\n",
      "test_test\n",
      "test mean loss=1158.9864196777344\n",
      "epoch 3980\n",
      "test_train\n",
      "train mean loss=0.07825842499732971\n",
      "test_test\n",
      "test mean loss=1159.1239624023438\n",
      "epoch 3981\n",
      "test_train\n",
      "train mean loss=0.09333574461440246\n",
      "test_test\n",
      "test mean loss=1160.462158203125\n",
      "epoch 3982\n",
      "test_train\n",
      "train mean loss=0.15205154133339724\n",
      "test_test\n",
      "test mean loss=1155.0578002929688\n",
      "epoch 3983\n",
      "test_train\n",
      "train mean loss=0.12251654453575611\n",
      "test_test\n",
      "test mean loss=1157.5704345703125\n",
      "epoch 3984\n",
      "test_train\n",
      "train mean loss=0.07810421691586573\n",
      "test_test\n",
      "test mean loss=1157.7301635742188\n",
      "epoch 3985\n",
      "test_train\n",
      "train mean loss=0.08177692784617345\n",
      "test_test\n",
      "test mean loss=1159.3811645507812\n",
      "epoch 3986\n",
      "test_train\n",
      "train mean loss=0.07532545986274879\n",
      "test_test\n",
      "test mean loss=1158.2170715332031\n",
      "epoch 3987\n",
      "test_train\n",
      "train mean loss=0.07514529799421628\n",
      "test_test\n",
      "test mean loss=1158.0596313476562\n",
      "epoch 3988\n",
      "test_train\n",
      "train mean loss=0.07590226891140144\n",
      "test_test\n",
      "test mean loss=1157.5513610839844\n",
      "epoch 3989\n",
      "test_train\n",
      "train mean loss=0.07468707424898942\n",
      "test_test\n",
      "test mean loss=1159.219970703125\n",
      "epoch 3990\n",
      "test_train\n",
      "train mean loss=0.08098026271909475\n",
      "test_test\n",
      "test mean loss=1158.6970520019531\n",
      "epoch 3991\n",
      "test_train\n",
      "train mean loss=0.07970063481479883\n",
      "test_test\n",
      "test mean loss=1158.3365783691406\n",
      "epoch 3992\n",
      "test_train\n",
      "train mean loss=0.07801545287172\n",
      "test_test\n",
      "test mean loss=1160.0878295898438\n",
      "epoch 3993\n",
      "test_train\n",
      "train mean loss=0.07745976063112418\n",
      "test_test\n",
      "test mean loss=1160.2315368652344\n",
      "epoch 3994\n",
      "test_train\n",
      "train mean loss=0.07557289550701778\n",
      "test_test\n",
      "test mean loss=1160.4291381835938\n",
      "epoch 3995\n",
      "test_train\n",
      "train mean loss=0.08307161057988803\n",
      "test_test\n",
      "test mean loss=1159.3584289550781\n",
      "epoch 3996\n",
      "test_train\n",
      "train mean loss=0.08281856092313926\n",
      "test_test\n",
      "test mean loss=1159.2437744140625\n",
      "epoch 3997\n",
      "test_train\n",
      "train mean loss=0.08588078866402309\n",
      "test_test\n",
      "test mean loss=1160.2276306152344\n",
      "epoch 3998\n",
      "test_train\n",
      "train mean loss=0.08270517364144325\n",
      "test_test\n",
      "test mean loss=1159.3816223144531\n",
      "epoch 3999\n",
      "test_train\n",
      "train mean loss=0.07968361303210258\n",
      "test_test\n",
      "test mean loss=1158.3114624023438\n",
      "epoch 4000\n",
      "test_train\n",
      "train mean loss=0.07723884625981252\n",
      "test_test\n",
      "test mean loss=1158.607666015625\n",
      "epoch 4001\n",
      "test_train\n",
      "train mean loss=0.07919150218367577\n",
      "test_test\n",
      "test mean loss=1159.4902954101562\n",
      "epoch 4002\n",
      "test_train\n",
      "train mean loss=0.08396195558210214\n",
      "test_test\n",
      "test mean loss=1159.3309631347656\n",
      "epoch 4003\n",
      "test_train\n",
      "train mean loss=0.08291676609466474\n",
      "test_test\n",
      "test mean loss=1158.6812438964844\n",
      "epoch 4004\n",
      "test_train\n",
      "train mean loss=0.07692726034050186\n",
      "test_test\n",
      "test mean loss=1157.745849609375\n",
      "epoch 4005\n",
      "test_train\n",
      "train mean loss=0.07885722847034533\n",
      "test_test\n",
      "test mean loss=1158.3150024414062\n",
      "epoch 4006\n",
      "test_train\n",
      "train mean loss=0.08370717397580545\n",
      "test_test\n",
      "test mean loss=1158.83984375\n",
      "epoch 4007\n",
      "test_train\n",
      "train mean loss=0.08631156447033088\n",
      "test_test\n",
      "test mean loss=1159.232177734375\n",
      "epoch 4008\n",
      "test_train\n",
      "train mean loss=0.0824301370109121\n",
      "test_test\n",
      "test mean loss=1158.7344665527344\n",
      "epoch 4009\n",
      "test_train\n",
      "train mean loss=0.08957752740631501\n",
      "test_test\n",
      "test mean loss=1159.464599609375\n",
      "epoch 4010\n",
      "test_train\n",
      "train mean loss=0.07798138881723087\n",
      "test_test\n",
      "test mean loss=1158.5586242675781\n",
      "epoch 4011\n",
      "test_train\n",
      "train mean loss=0.07654090349872907\n",
      "test_test\n",
      "test mean loss=1159.3214416503906\n",
      "epoch 4012\n",
      "test_train\n",
      "train mean loss=0.07706598192453384\n",
      "test_test\n",
      "test mean loss=1158.5244445800781\n",
      "epoch 4013\n",
      "test_train\n",
      "train mean loss=0.08094469271600246\n",
      "test_test\n",
      "test mean loss=1158.0423583984375\n",
      "epoch 4014\n",
      "test_train\n",
      "train mean loss=0.08126296040912469\n",
      "test_test\n",
      "test mean loss=1158.5166625976562\n",
      "epoch 4015\n",
      "test_train\n",
      "train mean loss=0.08481600725402434\n",
      "test_test\n",
      "test mean loss=1158.6689758300781\n",
      "epoch 4016\n",
      "test_train\n",
      "train mean loss=0.08539978973567486\n",
      "test_test\n",
      "test mean loss=1159.2850341796875\n",
      "epoch 4017\n",
      "test_train\n",
      "train mean loss=0.08726739852378766\n",
      "test_test\n",
      "test mean loss=1158.1354675292969\n",
      "epoch 4018\n",
      "test_train\n",
      "train mean loss=0.07934036571532488\n",
      "test_test\n",
      "test mean loss=1158.5572814941406\n",
      "epoch 4019\n",
      "test_train\n",
      "train mean loss=0.09965401577452819\n",
      "test_test\n",
      "test mean loss=1158.0828247070312\n",
      "epoch 4020\n",
      "test_train\n",
      "train mean loss=0.07975234681119521\n",
      "test_test\n",
      "test mean loss=1158.869873046875\n",
      "epoch 4021\n",
      "test_train\n",
      "train mean loss=0.0804263527194659\n",
      "test_test\n",
      "test mean loss=1158.0296020507812\n",
      "epoch 4022\n",
      "test_train\n",
      "train mean loss=0.09262327011674643\n",
      "test_test\n",
      "test mean loss=1158.2124633789062\n",
      "epoch 4023\n",
      "test_train\n",
      "train mean loss=0.08678443543612957\n",
      "test_test\n",
      "test mean loss=1157.6600952148438\n",
      "epoch 4024\n",
      "test_train\n",
      "train mean loss=0.07864377927035093\n",
      "test_test\n",
      "test mean loss=1157.451904296875\n",
      "epoch 4025\n",
      "test_train\n",
      "train mean loss=0.08611171692609787\n",
      "test_test\n",
      "test mean loss=1158.7259216308594\n",
      "epoch 4026\n",
      "test_train\n",
      "train mean loss=0.0760754169896245\n",
      "test_test\n",
      "test mean loss=1158.3380737304688\n",
      "epoch 4027\n",
      "test_train\n",
      "train mean loss=0.0845016014451782\n",
      "test_test\n",
      "test mean loss=1159.8544311523438\n",
      "epoch 4028\n",
      "test_train\n",
      "train mean loss=0.0815001589556535\n",
      "test_test\n",
      "test mean loss=1158.8043823242188\n",
      "epoch 4029\n",
      "test_train\n",
      "train mean loss=0.08393376879394054\n",
      "test_test\n",
      "test mean loss=1158.7074584960938\n",
      "epoch 4030\n",
      "test_train\n",
      "train mean loss=0.08537782387187083\n",
      "test_test\n",
      "test mean loss=1158.8433837890625\n",
      "epoch 4031\n",
      "test_train\n",
      "train mean loss=0.07513835622618596\n",
      "test_test\n",
      "test mean loss=1158.5438537597656\n",
      "epoch 4032\n",
      "test_train\n",
      "train mean loss=0.0802512379984061\n",
      "test_test\n",
      "test mean loss=1158.8698425292969\n",
      "epoch 4033\n",
      "test_train\n",
      "train mean loss=0.08207705741127332\n",
      "test_test\n",
      "test mean loss=1158.1058349609375\n",
      "epoch 4034\n",
      "test_train\n",
      "train mean loss=0.08718539774417877\n",
      "test_test\n",
      "test mean loss=1158.7142333984375\n",
      "epoch 4035\n",
      "test_train\n",
      "train mean loss=0.08561996091157198\n",
      "test_test\n",
      "test mean loss=1158.809326171875\n",
      "epoch 4036\n",
      "test_train\n",
      "train mean loss=0.08525491862868269\n",
      "test_test\n",
      "test mean loss=1158.7630004882812\n",
      "epoch 4037\n",
      "test_train\n",
      "train mean loss=0.08171035038928191\n",
      "test_test\n",
      "test mean loss=1159.6540832519531\n",
      "epoch 4038\n",
      "test_train\n",
      "train mean loss=0.08668646744141977\n",
      "test_test\n",
      "test mean loss=1159.82470703125\n",
      "epoch 4039\n",
      "test_train\n",
      "train mean loss=0.07667336768160264\n",
      "test_test\n",
      "test mean loss=1158.5159912109375\n",
      "epoch 4040\n",
      "test_train\n",
      "train mean loss=0.0777156554783384\n",
      "test_test\n",
      "test mean loss=1158.5102844238281\n",
      "epoch 4041\n",
      "test_train\n",
      "train mean loss=0.0849225465208292\n",
      "test_test\n",
      "test mean loss=1157.6146240234375\n",
      "epoch 4042\n",
      "test_train\n",
      "train mean loss=0.0765111908937494\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1158.5985107421875\n",
      "epoch 4043\n",
      "test_train\n",
      "train mean loss=0.07417058882613976\n",
      "test_test\n",
      "test mean loss=1159.1383666992188\n",
      "epoch 4044\n",
      "test_train\n",
      "train mean loss=0.07623500314851601\n",
      "test_test\n",
      "test mean loss=1159.3797607421875\n",
      "epoch 4045\n",
      "test_train\n",
      "train mean loss=0.07963879810025294\n",
      "test_test\n",
      "test mean loss=1159.126708984375\n",
      "epoch 4046\n",
      "test_train\n",
      "train mean loss=0.08991040444622438\n",
      "test_test\n",
      "test mean loss=1160.034912109375\n",
      "epoch 4047\n",
      "test_train\n",
      "train mean loss=0.07549401403715213\n",
      "test_test\n",
      "test mean loss=1158.2957763671875\n",
      "epoch 4048\n",
      "test_train\n",
      "train mean loss=0.0811997214332223\n",
      "test_test\n",
      "test mean loss=1158.5316772460938\n",
      "epoch 4049\n",
      "test_train\n",
      "train mean loss=0.07585834246128798\n",
      "test_test\n",
      "test mean loss=1159.7894897460938\n",
      "epoch 4050\n",
      "test_train\n",
      "train mean loss=0.08150422604133685\n",
      "test_test\n",
      "test mean loss=1159.1549072265625\n",
      "epoch 4051\n",
      "test_train\n",
      "train mean loss=0.08088341510544221\n",
      "test_test\n",
      "test mean loss=1158.7952880859375\n",
      "epoch 4052\n",
      "test_train\n",
      "train mean loss=0.0855324004466335\n",
      "test_test\n",
      "test mean loss=1158.8260803222656\n",
      "epoch 4053\n",
      "test_train\n",
      "train mean loss=0.13206799452503523\n",
      "test_test\n",
      "test mean loss=1158.9566650390625\n",
      "epoch 4054\n",
      "test_train\n",
      "train mean loss=0.07843516891201337\n",
      "test_test\n",
      "test mean loss=1158.2577819824219\n",
      "epoch 4055\n",
      "test_train\n",
      "train mean loss=0.07736432552337646\n",
      "test_test\n",
      "test mean loss=1159.2181396484375\n",
      "epoch 4056\n",
      "test_train\n",
      "train mean loss=0.07819323396931092\n",
      "test_test\n",
      "test mean loss=1159.2624206542969\n",
      "epoch 4057\n",
      "test_train\n",
      "train mean loss=0.07555693419029315\n",
      "test_test\n",
      "test mean loss=1158.9413452148438\n",
      "epoch 4058\n",
      "test_train\n",
      "train mean loss=0.06820380501449108\n",
      "test_test\n",
      "test mean loss=1157.607177734375\n",
      "epoch 4059\n",
      "test_train\n",
      "train mean loss=0.08124102434764306\n",
      "test_test\n",
      "test mean loss=1158.3414916992188\n",
      "epoch 4060\n",
      "test_train\n",
      "train mean loss=0.07204334965596597\n",
      "test_test\n",
      "test mean loss=1158.0178833007812\n",
      "epoch 4061\n",
      "test_train\n",
      "train mean loss=0.07867664719621341\n",
      "test_test\n",
      "test mean loss=1159.0673217773438\n",
      "epoch 4062\n",
      "test_train\n",
      "train mean loss=0.0724308742210269\n",
      "test_test\n",
      "test mean loss=1157.767822265625\n",
      "epoch 4063\n",
      "test_train\n",
      "train mean loss=0.07737335376441479\n",
      "test_test\n",
      "test mean loss=1158.2864990234375\n",
      "epoch 4064\n",
      "test_train\n",
      "train mean loss=0.08862352619568507\n",
      "test_test\n",
      "test mean loss=1158.181884765625\n",
      "epoch 4065\n",
      "test_train\n",
      "train mean loss=0.07762228138744831\n",
      "test_test\n",
      "test mean loss=1157.3204345703125\n",
      "epoch 4066\n",
      "test_train\n",
      "train mean loss=0.08822644036263227\n",
      "test_test\n",
      "test mean loss=1159.1097106933594\n",
      "epoch 4067\n",
      "test_train\n",
      "train mean loss=0.08052045137931903\n",
      "test_test\n",
      "test mean loss=1158.8445434570312\n",
      "epoch 4068\n",
      "test_train\n",
      "train mean loss=0.07882858657588561\n",
      "test_test\n",
      "test mean loss=1159.28125\n",
      "epoch 4069\n",
      "test_train\n",
      "train mean loss=0.07936966419219971\n",
      "test_test\n",
      "test mean loss=1157.7467651367188\n",
      "epoch 4070\n",
      "test_train\n",
      "train mean loss=0.08497456554323435\n",
      "test_test\n",
      "test mean loss=1158.8950805664062\n",
      "epoch 4071\n",
      "test_train\n",
      "train mean loss=0.08145176681379478\n",
      "test_test\n",
      "test mean loss=1158.1519165039062\n",
      "epoch 4072\n",
      "test_train\n",
      "train mean loss=0.0808282953997453\n",
      "test_test\n",
      "test mean loss=1158.59033203125\n",
      "epoch 4073\n",
      "test_train\n",
      "train mean loss=0.07645994486908118\n",
      "test_test\n",
      "test mean loss=1158.1239624023438\n",
      "epoch 4074\n",
      "test_train\n",
      "train mean loss=0.07517634549488623\n",
      "test_test\n",
      "test mean loss=1158.4481811523438\n",
      "epoch 4075\n",
      "test_train\n",
      "train mean loss=0.08351098870237668\n",
      "test_test\n",
      "test mean loss=1158.607421875\n",
      "epoch 4076\n",
      "test_train\n",
      "train mean loss=0.09146022703498602\n",
      "test_test\n",
      "test mean loss=1159.013671875\n",
      "epoch 4077\n",
      "test_train\n",
      "train mean loss=0.0815436973546942\n",
      "test_test\n",
      "test mean loss=1158.4574890136719\n",
      "epoch 4078\n",
      "test_train\n",
      "train mean loss=0.08149046761294206\n",
      "test_test\n",
      "test mean loss=1158.3035278320312\n",
      "epoch 4079\n",
      "test_train\n",
      "train mean loss=0.08795790436367194\n",
      "test_test\n",
      "test mean loss=1159.314453125\n",
      "epoch 4080\n",
      "test_train\n",
      "train mean loss=0.11862054653465748\n",
      "test_test\n",
      "test mean loss=1157.7719116210938\n",
      "epoch 4081\n",
      "test_train\n",
      "train mean loss=0.08763197405884664\n",
      "test_test\n",
      "test mean loss=1158.9365844726562\n",
      "epoch 4082\n",
      "test_train\n",
      "train mean loss=0.10085159291823705\n",
      "test_test\n",
      "test mean loss=1159.2276000976562\n",
      "epoch 4083\n",
      "test_train\n",
      "train mean loss=0.08729963687558968\n",
      "test_test\n",
      "test mean loss=1159.4784851074219\n",
      "epoch 4084\n",
      "test_train\n",
      "train mean loss=0.07819322496652603\n",
      "test_test\n",
      "test mean loss=1157.59228515625\n",
      "epoch 4085\n",
      "test_train\n",
      "train mean loss=0.080109019142886\n",
      "test_test\n",
      "test mean loss=1158.2439575195312\n",
      "epoch 4086\n",
      "test_train\n",
      "train mean loss=0.08817465261866649\n",
      "test_test\n",
      "test mean loss=1157.5674438476562\n",
      "epoch 4087\n",
      "test_train\n",
      "train mean loss=0.07861364353448153\n",
      "test_test\n",
      "test mean loss=1158.48876953125\n",
      "epoch 4088\n",
      "test_train\n",
      "train mean loss=0.07409167196601629\n",
      "test_test\n",
      "test mean loss=1157.6271362304688\n",
      "epoch 4089\n",
      "test_train\n",
      "train mean loss=0.07976214711864789\n",
      "test_test\n",
      "test mean loss=1158.3070678710938\n",
      "epoch 4090\n",
      "test_train\n",
      "train mean loss=0.0746303607399265\n",
      "test_test\n",
      "test mean loss=1157.0855102539062\n",
      "epoch 4091\n",
      "test_train\n",
      "train mean loss=0.0769173043469588\n",
      "test_test\n",
      "test mean loss=1157.4906005859375\n",
      "epoch 4092\n",
      "test_train\n",
      "train mean loss=0.07842170043538015\n",
      "test_test\n",
      "test mean loss=1158.524169921875\n",
      "epoch 4093\n",
      "test_train\n",
      "train mean loss=0.09400216086457173\n",
      "test_test\n",
      "test mean loss=1158.0276489257812\n",
      "epoch 4094\n",
      "test_train\n",
      "train mean loss=0.07763318407038848\n",
      "test_test\n",
      "test mean loss=1157.6464538574219\n",
      "epoch 4095\n",
      "test_train\n",
      "train mean loss=0.08400271646678448\n",
      "test_test\n",
      "test mean loss=1158.270751953125\n",
      "epoch 4096\n",
      "test_train\n",
      "train mean loss=0.08083393021176259\n",
      "test_test\n",
      "test mean loss=1157.1730651855469\n",
      "epoch 4097\n",
      "test_train\n",
      "train mean loss=0.0740721778323253\n",
      "test_test\n",
      "test mean loss=1157.6467895507812\n",
      "epoch 4098\n",
      "test_train\n",
      "train mean loss=0.08036197597781818\n",
      "test_test\n",
      "test mean loss=1157.5004272460938\n",
      "epoch 4099\n",
      "test_train\n",
      "train mean loss=0.07491904838631551\n",
      "test_test\n",
      "test mean loss=1157.2426452636719\n",
      "epoch 4100\n",
      "test_train\n",
      "train mean loss=0.07470448408275843\n",
      "test_test\n",
      "test mean loss=1158.0529174804688\n",
      "epoch 4101\n",
      "test_train\n",
      "train mean loss=0.08309459903587897\n",
      "test_test\n",
      "test mean loss=1157.6706848144531\n",
      "epoch 4102\n",
      "test_train\n",
      "train mean loss=0.07502063860495885\n",
      "test_test\n",
      "test mean loss=1157.114990234375\n",
      "epoch 4103\n",
      "test_train\n",
      "train mean loss=0.07654499945541222\n",
      "test_test\n",
      "test mean loss=1157.4475708007812\n",
      "epoch 4104\n",
      "test_train\n",
      "train mean loss=0.08092787675559521\n",
      "test_test\n",
      "test mean loss=1158.2092895507812\n",
      "epoch 4105\n",
      "test_train\n",
      "train mean loss=0.07599263374383251\n",
      "test_test\n",
      "test mean loss=1156.8735656738281\n",
      "epoch 4106\n",
      "test_train\n",
      "train mean loss=0.07168316499640544\n",
      "test_test\n",
      "test mean loss=1157.3478393554688\n",
      "epoch 4107\n",
      "test_train\n",
      "train mean loss=0.0754926096027096\n",
      "test_test\n",
      "test mean loss=1158.029052734375\n",
      "epoch 4108\n",
      "test_train\n",
      "train mean loss=0.08042672959466775\n",
      "test_test\n",
      "test mean loss=1157.826171875\n",
      "epoch 4109\n",
      "test_train\n",
      "train mean loss=0.07064209661136071\n",
      "test_test\n",
      "test mean loss=1156.7554016113281\n",
      "epoch 4110\n",
      "test_train\n",
      "train mean loss=0.07418421190232038\n",
      "test_test\n",
      "test mean loss=1157.7864379882812\n",
      "epoch 4111\n",
      "test_train\n",
      "train mean loss=0.07223746366798878\n",
      "test_test\n",
      "test mean loss=1158.158203125\n",
      "epoch 4112\n",
      "test_train\n",
      "train mean loss=0.06908837209145229\n",
      "test_test\n",
      "test mean loss=1157.2883911132812\n",
      "epoch 4113\n",
      "test_train\n",
      "train mean loss=0.07377388949195544\n",
      "test_test\n",
      "test mean loss=1157.8709716796875\n",
      "epoch 4114\n",
      "test_train\n",
      "train mean loss=0.08038078496853511\n",
      "test_test\n",
      "test mean loss=1158.6937866210938\n",
      "epoch 4115\n",
      "test_train\n",
      "train mean loss=0.08013827633112669\n",
      "test_test\n",
      "test mean loss=1159.0899658203125\n",
      "epoch 4116\n",
      "test_train\n",
      "train mean loss=0.08764778356999159\n",
      "test_test\n",
      "test mean loss=1157.3142700195312\n",
      "epoch 4117\n",
      "test_train\n",
      "train mean loss=0.07343303598463535\n",
      "test_test\n",
      "test mean loss=1158.1706848144531\n",
      "epoch 4118\n",
      "test_train\n",
      "train mean loss=0.07443989564975102\n",
      "test_test\n",
      "test mean loss=1157.6178588867188\n",
      "epoch 4119\n",
      "test_train\n",
      "train mean loss=0.08291976650555928\n",
      "test_test\n",
      "test mean loss=1158.0819702148438\n",
      "epoch 4120\n",
      "test_train\n",
      "train mean loss=0.0813634783650438\n",
      "test_test\n",
      "test mean loss=1158.2556762695312\n",
      "epoch 4121\n",
      "test_train\n",
      "train mean loss=0.08776527798424165\n",
      "test_test\n",
      "test mean loss=1159.4939575195312\n",
      "epoch 4122\n",
      "test_train\n",
      "train mean loss=0.0839739590883255\n",
      "test_test\n",
      "test mean loss=1158.0706176757812\n",
      "epoch 4123\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.08644583200414975\n",
      "test_test\n",
      "test mean loss=1158.8006591796875\n",
      "epoch 4124\n",
      "test_train\n",
      "train mean loss=0.08142840955406427\n",
      "test_test\n",
      "test mean loss=1158.2594909667969\n",
      "epoch 4125\n",
      "test_train\n",
      "train mean loss=0.07693327652911346\n",
      "test_test\n",
      "test mean loss=1158.4793701171875\n",
      "epoch 4126\n",
      "test_train\n",
      "train mean loss=0.07286915710816781\n",
      "test_test\n",
      "test mean loss=1157.4913330078125\n",
      "epoch 4127\n",
      "test_train\n",
      "train mean loss=0.07648139509061973\n",
      "test_test\n",
      "test mean loss=1158.5235900878906\n",
      "epoch 4128\n",
      "test_train\n",
      "train mean loss=0.07660980398456256\n",
      "test_test\n",
      "test mean loss=1158.40234375\n",
      "epoch 4129\n",
      "test_train\n",
      "train mean loss=0.07903745087484519\n",
      "test_test\n",
      "test mean loss=1158.4634399414062\n",
      "epoch 4130\n",
      "test_train\n",
      "train mean loss=0.07938356387118499\n",
      "test_test\n",
      "test mean loss=1157.4100341796875\n",
      "epoch 4131\n",
      "test_train\n",
      "train mean loss=0.08315430581569672\n",
      "test_test\n",
      "test mean loss=1159.7221069335938\n",
      "epoch 4132\n",
      "test_train\n",
      "train mean loss=0.0765906386077404\n",
      "test_test\n",
      "test mean loss=1159.9327392578125\n",
      "epoch 4133\n",
      "test_train\n",
      "train mean loss=0.07533678722878297\n",
      "test_test\n",
      "test mean loss=1158.6319580078125\n",
      "epoch 4134\n",
      "test_train\n",
      "train mean loss=0.06946072758485873\n",
      "test_test\n",
      "test mean loss=1157.735595703125\n",
      "epoch 4135\n",
      "test_train\n",
      "train mean loss=0.0813109939917922\n",
      "test_test\n",
      "test mean loss=1158.9917602539062\n",
      "epoch 4136\n",
      "test_train\n",
      "train mean loss=0.09101416977743308\n",
      "test_test\n",
      "test mean loss=1159.01513671875\n",
      "epoch 4137\n",
      "test_train\n",
      "train mean loss=0.0790463387966156\n",
      "test_test\n",
      "test mean loss=1157.6890869140625\n",
      "epoch 4138\n",
      "test_train\n",
      "train mean loss=0.07934855949133635\n",
      "test_test\n",
      "test mean loss=1158.9795532226562\n",
      "epoch 4139\n",
      "test_train\n",
      "train mean loss=0.07152637715140979\n",
      "test_test\n",
      "test mean loss=1159.0404357910156\n",
      "epoch 4140\n",
      "test_train\n",
      "train mean loss=0.0758879582087199\n",
      "test_test\n",
      "test mean loss=1158.3548583984375\n",
      "epoch 4141\n",
      "test_train\n",
      "train mean loss=0.14121327797571817\n",
      "test_test\n",
      "test mean loss=1159.0211791992188\n",
      "epoch 4142\n",
      "test_train\n",
      "train mean loss=0.08553847298026085\n",
      "test_test\n",
      "test mean loss=1158.1644897460938\n",
      "epoch 4143\n",
      "test_train\n",
      "train mean loss=0.08564151947697003\n",
      "test_test\n",
      "test mean loss=1158.5286254882812\n",
      "epoch 4144\n",
      "test_train\n",
      "train mean loss=0.07920278081049521\n",
      "test_test\n",
      "test mean loss=1157.873779296875\n",
      "epoch 4145\n",
      "test_train\n",
      "train mean loss=0.10439445575078328\n",
      "test_test\n",
      "test mean loss=1158.235595703125\n",
      "epoch 4146\n",
      "test_train\n",
      "train mean loss=0.08131424306581418\n",
      "test_test\n",
      "test mean loss=1157.3096618652344\n",
      "epoch 4147\n",
      "test_train\n",
      "train mean loss=0.07440653691689174\n",
      "test_test\n",
      "test mean loss=1157.50537109375\n",
      "epoch 4148\n",
      "test_train\n",
      "train mean loss=0.07451697780440251\n",
      "test_test\n",
      "test mean loss=1156.7709655761719\n",
      "epoch 4149\n",
      "test_train\n",
      "train mean loss=0.07336046205212672\n",
      "test_test\n",
      "test mean loss=1157.1338500976562\n",
      "epoch 4150\n",
      "test_train\n",
      "train mean loss=0.08591305216153462\n",
      "test_test\n",
      "test mean loss=1158.2625732421875\n",
      "epoch 4151\n",
      "test_train\n",
      "train mean loss=0.07684879532704751\n",
      "test_test\n",
      "test mean loss=1157.3260498046875\n",
      "epoch 4152\n",
      "test_train\n",
      "train mean loss=0.0777396426225702\n",
      "test_test\n",
      "test mean loss=1158.0201721191406\n",
      "epoch 4153\n",
      "test_train\n",
      "train mean loss=0.08099336735904217\n",
      "test_test\n",
      "test mean loss=1158.3040466308594\n",
      "epoch 4154\n",
      "test_train\n",
      "train mean loss=0.08687937787423532\n",
      "test_test\n",
      "test mean loss=1157.89990234375\n",
      "epoch 4155\n",
      "test_train\n",
      "train mean loss=0.07556359469890594\n",
      "test_test\n",
      "test mean loss=1158.1148071289062\n",
      "epoch 4156\n",
      "test_train\n",
      "train mean loss=0.07811152189970016\n",
      "test_test\n",
      "test mean loss=1158.215576171875\n",
      "epoch 4157\n",
      "test_train\n",
      "train mean loss=0.13402271270751953\n",
      "test_test\n",
      "test mean loss=1159.5105590820312\n",
      "epoch 4158\n",
      "test_train\n",
      "train mean loss=0.0682947679112355\n",
      "test_test\n",
      "test mean loss=1158.4131469726562\n",
      "epoch 4159\n",
      "test_train\n",
      "train mean loss=0.07397018217792113\n",
      "test_test\n",
      "test mean loss=1159.0223999023438\n",
      "epoch 4160\n",
      "test_train\n",
      "train mean loss=0.13663973907629648\n",
      "test_test\n",
      "test mean loss=1161.3080444335938\n",
      "epoch 4161\n",
      "test_train\n",
      "train mean loss=0.0777685409411788\n",
      "test_test\n",
      "test mean loss=1160.23486328125\n",
      "epoch 4162\n",
      "test_train\n",
      "train mean loss=0.07688383323450883\n",
      "test_test\n",
      "test mean loss=1160.4125366210938\n",
      "epoch 4163\n",
      "test_train\n",
      "train mean loss=0.07365151370565097\n",
      "test_test\n",
      "test mean loss=1158.8418884277344\n",
      "epoch 4164\n",
      "test_train\n",
      "train mean loss=0.08021411920587222\n",
      "test_test\n",
      "test mean loss=1158.38623046875\n",
      "epoch 4165\n",
      "test_train\n",
      "train mean loss=0.0761825932810704\n",
      "test_test\n",
      "test mean loss=1158.2730712890625\n",
      "epoch 4166\n",
      "test_train\n",
      "train mean loss=0.08222175358484189\n",
      "test_test\n",
      "test mean loss=1158.30078125\n",
      "epoch 4167\n",
      "test_train\n",
      "train mean loss=0.08744205565502246\n",
      "test_test\n",
      "test mean loss=1157.7360534667969\n",
      "epoch 4168\n",
      "test_train\n",
      "train mean loss=0.0741034575427572\n",
      "test_test\n",
      "test mean loss=1159.3419799804688\n",
      "epoch 4169\n",
      "test_train\n",
      "train mean loss=0.08590373396873474\n",
      "test_test\n",
      "test mean loss=1159.0108032226562\n",
      "epoch 4170\n",
      "test_train\n",
      "train mean loss=0.07506820932030678\n",
      "test_test\n",
      "test mean loss=1157.3001403808594\n",
      "epoch 4171\n",
      "test_train\n",
      "train mean loss=0.07774032404025395\n",
      "test_test\n",
      "test mean loss=1157.2766723632812\n",
      "epoch 4172\n",
      "test_train\n",
      "train mean loss=0.07886056291560332\n",
      "test_test\n",
      "test mean loss=1158.6875610351562\n",
      "epoch 4173\n",
      "test_train\n",
      "train mean loss=0.07227813079953194\n",
      "test_test\n",
      "test mean loss=1158.0349426269531\n",
      "epoch 4174\n",
      "test_train\n",
      "train mean loss=0.06981847155839205\n",
      "test_test\n",
      "test mean loss=1156.8007202148438\n",
      "epoch 4175\n",
      "test_train\n",
      "train mean loss=0.07401635497808456\n",
      "test_test\n",
      "test mean loss=1156.4953002929688\n",
      "epoch 4176\n",
      "test_train\n",
      "train mean loss=0.0777629471073548\n",
      "test_test\n",
      "test mean loss=1158.7125244140625\n",
      "epoch 4177\n",
      "test_train\n",
      "train mean loss=0.118522593130668\n",
      "test_test\n",
      "test mean loss=1157.4174194335938\n",
      "epoch 4178\n",
      "test_train\n",
      "train mean loss=0.08254820853471756\n",
      "test_test\n",
      "test mean loss=1158.3587646484375\n",
      "epoch 4179\n",
      "test_train\n",
      "train mean loss=0.0777184758335352\n",
      "test_test\n",
      "test mean loss=1158.4185791015625\n",
      "epoch 4180\n",
      "test_train\n",
      "train mean loss=0.0788645048936208\n",
      "test_test\n",
      "test mean loss=1159.132080078125\n",
      "epoch 4181\n",
      "test_train\n",
      "train mean loss=0.0863760154073437\n",
      "test_test\n",
      "test mean loss=1159.767822265625\n",
      "epoch 4182\n",
      "test_train\n",
      "train mean loss=0.07962683619310458\n",
      "test_test\n",
      "test mean loss=1158.7782592773438\n",
      "epoch 4183\n",
      "test_train\n",
      "train mean loss=0.08830084061870973\n",
      "test_test\n",
      "test mean loss=1158.9362182617188\n",
      "epoch 4184\n",
      "test_train\n",
      "train mean loss=0.07978233105192582\n",
      "test_test\n",
      "test mean loss=1159.053955078125\n",
      "epoch 4185\n",
      "test_train\n",
      "train mean loss=0.07642325603713591\n",
      "test_test\n",
      "test mean loss=1159.2554931640625\n",
      "epoch 4186\n",
      "test_train\n",
      "train mean loss=0.07322825584560633\n",
      "test_test\n",
      "test mean loss=1159.2423095703125\n",
      "epoch 4187\n",
      "test_train\n",
      "train mean loss=0.07316737932463487\n",
      "test_test\n",
      "test mean loss=1158.9000244140625\n",
      "epoch 4188\n",
      "test_train\n",
      "train mean loss=0.07115576136857271\n",
      "test_test\n",
      "test mean loss=1157.3613891601562\n",
      "epoch 4189\n",
      "test_train\n",
      "train mean loss=0.07333181705325842\n",
      "test_test\n",
      "test mean loss=1157.6995849609375\n",
      "epoch 4190\n",
      "test_train\n",
      "train mean loss=0.07228980275491874\n",
      "test_test\n",
      "test mean loss=1158.7592163085938\n",
      "epoch 4191\n",
      "test_train\n",
      "train mean loss=0.0760129742945234\n",
      "test_test\n",
      "test mean loss=1158.7109375\n",
      "epoch 4192\n",
      "test_train\n",
      "train mean loss=0.0718327530970176\n",
      "test_test\n",
      "test mean loss=1159.2979125976562\n",
      "epoch 4193\n",
      "test_train\n",
      "train mean loss=0.0745215422163407\n",
      "test_test\n",
      "test mean loss=1159.0287170410156\n",
      "epoch 4194\n",
      "test_train\n",
      "train mean loss=0.08035505531976621\n",
      "test_test\n",
      "test mean loss=1159.0974426269531\n",
      "epoch 4195\n",
      "test_train\n",
      "train mean loss=0.07511172350496054\n",
      "test_test\n",
      "test mean loss=1158.3908081054688\n",
      "epoch 4196\n",
      "test_train\n",
      "train mean loss=0.08184191895027955\n",
      "test_test\n",
      "test mean loss=1158.8280944824219\n",
      "epoch 4197\n",
      "test_train\n",
      "train mean loss=0.09256519749760628\n",
      "test_test\n",
      "test mean loss=1159.3255920410156\n",
      "epoch 4198\n",
      "test_train\n",
      "train mean loss=0.07275441630433004\n",
      "test_test\n",
      "test mean loss=1158.3465576171875\n",
      "epoch 4199\n",
      "test_train\n",
      "train mean loss=0.07642165229966243\n",
      "test_test\n",
      "test mean loss=1159.1759033203125\n",
      "epoch 4200\n",
      "test_train\n",
      "train mean loss=0.0791291231289506\n",
      "test_test\n",
      "test mean loss=1157.9031982421875\n",
      "epoch 4201\n",
      "test_train\n",
      "train mean loss=0.08169811094800632\n",
      "test_test\n",
      "test mean loss=1157.781494140625\n",
      "epoch 4202\n",
      "test_train\n",
      "train mean loss=0.10710827137033145\n",
      "test_test\n",
      "test mean loss=1156.9658203125\n",
      "epoch 4203\n",
      "test_train\n",
      "train mean loss=0.07011289335787296\n",
      "test_test\n",
      "test mean loss=1157.0362548828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4204\n",
      "test_train\n",
      "train mean loss=0.07157129266609748\n",
      "test_test\n",
      "test mean loss=1158.1942138671875\n",
      "epoch 4205\n",
      "test_train\n",
      "train mean loss=0.18704515136778355\n",
      "test_test\n",
      "test mean loss=1161.5353393554688\n",
      "epoch 4206\n",
      "test_train\n",
      "train mean loss=0.07650194223970175\n",
      "test_test\n",
      "test mean loss=1158.7207336425781\n",
      "epoch 4207\n",
      "test_train\n",
      "train mean loss=0.07023159073044856\n",
      "test_test\n",
      "test mean loss=1157.2366638183594\n",
      "epoch 4208\n",
      "test_train\n",
      "train mean loss=0.07274330391859014\n",
      "test_test\n",
      "test mean loss=1157.680419921875\n",
      "epoch 4209\n",
      "test_train\n",
      "train mean loss=0.07666405942291021\n",
      "test_test\n",
      "test mean loss=1158.3367919921875\n",
      "epoch 4210\n",
      "test_train\n",
      "train mean loss=0.07440197685112555\n",
      "test_test\n",
      "test mean loss=1157.7829895019531\n",
      "epoch 4211\n",
      "test_train\n",
      "train mean loss=0.0688084230447809\n",
      "test_test\n",
      "test mean loss=1157.4053039550781\n",
      "epoch 4212\n",
      "test_train\n",
      "train mean loss=0.06964397088934977\n",
      "test_test\n",
      "test mean loss=1157.0690307617188\n",
      "epoch 4213\n",
      "test_train\n",
      "train mean loss=0.08627181158711512\n",
      "test_test\n",
      "test mean loss=1156.1089782714844\n",
      "epoch 4214\n",
      "test_train\n",
      "train mean loss=0.07363095258673032\n",
      "test_test\n",
      "test mean loss=1156.5906066894531\n",
      "epoch 4215\n",
      "test_train\n",
      "train mean loss=0.07203619306286176\n",
      "test_test\n",
      "test mean loss=1157.9587097167969\n",
      "epoch 4216\n",
      "test_train\n",
      "train mean loss=0.07310616038739681\n",
      "test_test\n",
      "test mean loss=1158.5331420898438\n",
      "epoch 4217\n",
      "test_train\n",
      "train mean loss=0.07814354449510574\n",
      "test_test\n",
      "test mean loss=1157.0275268554688\n",
      "epoch 4218\n",
      "test_train\n",
      "train mean loss=0.07299138481418292\n",
      "test_test\n",
      "test mean loss=1157.7288818359375\n",
      "epoch 4219\n",
      "test_train\n",
      "train mean loss=0.07981202689309914\n",
      "test_test\n",
      "test mean loss=1158.9911499023438\n",
      "epoch 4220\n",
      "test_train\n",
      "train mean loss=0.07386191468685865\n",
      "test_test\n",
      "test mean loss=1158.9749755859375\n",
      "epoch 4221\n",
      "test_train\n",
      "train mean loss=0.07948215988775094\n",
      "test_test\n",
      "test mean loss=1157.1686401367188\n",
      "epoch 4222\n",
      "test_train\n",
      "train mean loss=0.08093563498308261\n",
      "test_test\n",
      "test mean loss=1157.972900390625\n",
      "epoch 4223\n",
      "test_train\n",
      "train mean loss=0.09112780603269736\n",
      "test_test\n",
      "test mean loss=1158.0983276367188\n",
      "epoch 4224\n",
      "test_train\n",
      "train mean loss=0.08312745081881683\n",
      "test_test\n",
      "test mean loss=1158.5665283203125\n",
      "epoch 4225\n",
      "test_train\n",
      "train mean loss=0.08387636113911867\n",
      "test_test\n",
      "test mean loss=1159.0589599609375\n",
      "epoch 4226\n",
      "test_train\n",
      "train mean loss=0.07947547982136409\n",
      "test_test\n",
      "test mean loss=1159.0327758789062\n",
      "epoch 4227\n",
      "test_train\n",
      "train mean loss=0.07871061811844508\n",
      "test_test\n",
      "test mean loss=1158.1671142578125\n",
      "epoch 4228\n",
      "test_train\n",
      "train mean loss=0.09443890179196994\n",
      "test_test\n",
      "test mean loss=1159.2670288085938\n",
      "epoch 4229\n",
      "test_train\n",
      "train mean loss=0.07334965436408918\n",
      "test_test\n",
      "test mean loss=1157.9312744140625\n",
      "epoch 4230\n",
      "test_train\n",
      "train mean loss=0.07191575101266305\n",
      "test_test\n",
      "test mean loss=1157.2857971191406\n",
      "epoch 4231\n",
      "test_train\n",
      "train mean loss=0.07627836335450411\n",
      "test_test\n",
      "test mean loss=1158.5538330078125\n",
      "epoch 4232\n",
      "test_train\n",
      "train mean loss=0.07227222279955943\n",
      "test_test\n",
      "test mean loss=1158.1756286621094\n",
      "epoch 4233\n",
      "test_train\n",
      "train mean loss=0.06858769928415616\n",
      "test_test\n",
      "test mean loss=1157.7168884277344\n",
      "epoch 4234\n",
      "test_train\n",
      "train mean loss=2.8403853426376977\n",
      "test_test\n",
      "test mean loss=1181.9163818359375\n",
      "epoch 4235\n",
      "test_train\n",
      "train mean loss=0.5240975345174471\n",
      "test_test\n",
      "test mean loss=1160.9512023925781\n",
      "epoch 4236\n",
      "test_train\n",
      "train mean loss=0.14961745776236057\n",
      "test_test\n",
      "test mean loss=1162.7310180664062\n",
      "epoch 4237\n",
      "test_train\n",
      "train mean loss=0.0800242352609833\n",
      "test_test\n",
      "test mean loss=1161.5140991210938\n",
      "epoch 4238\n",
      "test_train\n",
      "train mean loss=0.2917067917684714\n",
      "test_test\n",
      "test mean loss=1161.1705017089844\n",
      "epoch 4239\n",
      "test_train\n",
      "train mean loss=0.11225462642808755\n",
      "test_test\n",
      "test mean loss=1161.7564697265625\n",
      "epoch 4240\n",
      "test_train\n",
      "train mean loss=0.10233561135828495\n",
      "test_test\n",
      "test mean loss=1159.6504516601562\n",
      "epoch 4241\n",
      "test_train\n",
      "train mean loss=0.12178350985050201\n",
      "test_test\n",
      "test mean loss=1159.2041625976562\n",
      "epoch 4242\n",
      "test_train\n",
      "train mean loss=0.08011765281359355\n",
      "test_test\n",
      "test mean loss=1160.0162048339844\n",
      "epoch 4243\n",
      "test_train\n",
      "train mean loss=0.07759197770307462\n",
      "test_test\n",
      "test mean loss=1159.7020874023438\n",
      "epoch 4244\n",
      "test_train\n",
      "train mean loss=0.08053454911957185\n",
      "test_test\n",
      "test mean loss=1160.4489135742188\n",
      "epoch 4245\n",
      "test_train\n",
      "train mean loss=0.0857083285227418\n",
      "test_test\n",
      "test mean loss=1160.6216430664062\n",
      "epoch 4246\n",
      "test_train\n",
      "train mean loss=0.07489921214679877\n",
      "test_test\n",
      "test mean loss=1159.5789184570312\n",
      "epoch 4247\n",
      "test_train\n",
      "train mean loss=0.06947952462360263\n",
      "test_test\n",
      "test mean loss=1159.951171875\n",
      "epoch 4248\n",
      "test_train\n",
      "train mean loss=0.07519750110805035\n",
      "test_test\n",
      "test mean loss=1159.7230529785156\n",
      "epoch 4249\n",
      "test_train\n",
      "train mean loss=0.07503108323241274\n",
      "test_test\n",
      "test mean loss=1160.2391357421875\n",
      "epoch 4250\n",
      "test_train\n",
      "train mean loss=0.07629437713573377\n",
      "test_test\n",
      "test mean loss=1160.2623901367188\n",
      "epoch 4251\n",
      "test_train\n",
      "train mean loss=0.07885851493726174\n",
      "test_test\n",
      "test mean loss=1160.2181091308594\n",
      "epoch 4252\n",
      "test_train\n",
      "train mean loss=0.07751013773183028\n",
      "test_test\n",
      "test mean loss=1159.4122314453125\n",
      "epoch 4253\n",
      "test_train\n",
      "train mean loss=0.07267964662363131\n",
      "test_test\n",
      "test mean loss=1160.0095520019531\n",
      "epoch 4254\n",
      "test_train\n",
      "train mean loss=0.08270499141265948\n",
      "test_test\n",
      "test mean loss=1159.3237915039062\n",
      "epoch 4255\n",
      "test_train\n",
      "train mean loss=0.07568437264611323\n",
      "test_test\n",
      "test mean loss=1159.243896484375\n",
      "epoch 4256\n",
      "test_train\n",
      "train mean loss=0.0763541255146265\n",
      "test_test\n",
      "test mean loss=1158.8887023925781\n",
      "epoch 4257\n",
      "test_train\n",
      "train mean loss=0.07436692124853532\n",
      "test_test\n",
      "test mean loss=1159.0675048828125\n",
      "epoch 4258\n",
      "test_train\n",
      "train mean loss=0.08898338954895735\n",
      "test_test\n",
      "test mean loss=1160.1864624023438\n",
      "epoch 4259\n",
      "test_train\n",
      "train mean loss=0.08186061525096495\n",
      "test_test\n",
      "test mean loss=1160.0566711425781\n",
      "epoch 4260\n",
      "test_train\n",
      "train mean loss=0.08202029298990965\n",
      "test_test\n",
      "test mean loss=1158.3341064453125\n",
      "epoch 4261\n",
      "test_train\n",
      "train mean loss=0.6383447249730428\n",
      "test_test\n",
      "test mean loss=1153.9098815917969\n",
      "epoch 4262\n",
      "test_train\n",
      "train mean loss=0.1345469088604053\n",
      "test_test\n",
      "test mean loss=1156.1270141601562\n",
      "epoch 4263\n",
      "test_train\n",
      "train mean loss=0.08142664097249508\n",
      "test_test\n",
      "test mean loss=1157.4909057617188\n",
      "epoch 4264\n",
      "test_train\n",
      "train mean loss=0.08104255857566993\n",
      "test_test\n",
      "test mean loss=1157.5670166015625\n",
      "epoch 4265\n",
      "test_train\n",
      "train mean loss=0.09250112436711788\n",
      "test_test\n",
      "test mean loss=1157.8048706054688\n",
      "epoch 4266\n",
      "test_train\n",
      "train mean loss=0.08537361118942499\n",
      "test_test\n",
      "test mean loss=1156.7492370605469\n",
      "epoch 4267\n",
      "test_train\n",
      "train mean loss=0.07917834632098675\n",
      "test_test\n",
      "test mean loss=1156.76904296875\n",
      "epoch 4268\n",
      "test_train\n",
      "train mean loss=0.07482420715192954\n",
      "test_test\n",
      "test mean loss=1155.7996826171875\n",
      "epoch 4269\n",
      "test_train\n",
      "train mean loss=0.0810696432987849\n",
      "test_test\n",
      "test mean loss=1156.26904296875\n",
      "epoch 4270\n",
      "test_train\n",
      "train mean loss=0.07665487471967936\n",
      "test_test\n",
      "test mean loss=1157.660888671875\n",
      "epoch 4271\n",
      "test_train\n",
      "train mean loss=0.07730260646591584\n",
      "test_test\n",
      "test mean loss=1157.8295593261719\n",
      "epoch 4272\n",
      "test_train\n",
      "train mean loss=0.07432096389432748\n",
      "test_test\n",
      "test mean loss=1158.1249084472656\n",
      "epoch 4273\n",
      "test_train\n",
      "train mean loss=0.07342815926919381\n",
      "test_test\n",
      "test mean loss=1156.8333740234375\n",
      "epoch 4274\n",
      "test_train\n",
      "train mean loss=0.09714612830430269\n",
      "test_test\n",
      "test mean loss=1157.7904357910156\n",
      "epoch 4275\n",
      "test_train\n",
      "train mean loss=0.07909922581166029\n",
      "test_test\n",
      "test mean loss=1158.8688049316406\n",
      "epoch 4276\n",
      "test_train\n",
      "train mean loss=0.08393547683954239\n",
      "test_test\n",
      "test mean loss=1158.5681762695312\n",
      "epoch 4277\n",
      "test_train\n",
      "train mean loss=0.08051363751292229\n",
      "test_test\n",
      "test mean loss=1157.2393188476562\n",
      "epoch 4278\n",
      "test_train\n",
      "train mean loss=0.07849997375160456\n",
      "test_test\n",
      "test mean loss=1157.7955932617188\n",
      "epoch 4279\n",
      "test_train\n",
      "train mean loss=0.08531487795213859\n",
      "test_test\n",
      "test mean loss=1157.8861694335938\n",
      "epoch 4280\n",
      "test_train\n",
      "train mean loss=0.07680001327147086\n",
      "test_test\n",
      "test mean loss=1158.6468811035156\n",
      "epoch 4281\n",
      "test_train\n",
      "train mean loss=0.07789770886301994\n",
      "test_test\n",
      "test mean loss=1158.40966796875\n",
      "epoch 4282\n",
      "test_train\n",
      "train mean loss=0.07854696828871965\n",
      "test_test\n",
      "test mean loss=1158.2094421386719\n",
      "epoch 4283\n",
      "test_train\n",
      "train mean loss=0.08347031225760777\n",
      "test_test\n",
      "test mean loss=1159.0426635742188\n",
      "epoch 4284\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.08077380464722712\n",
      "test_test\n",
      "test mean loss=1158.064208984375\n",
      "epoch 4285\n",
      "test_train\n",
      "train mean loss=0.0962127431606253\n",
      "test_test\n",
      "test mean loss=1157.3351440429688\n",
      "epoch 4286\n",
      "test_train\n",
      "train mean loss=0.08129152748733759\n",
      "test_test\n",
      "test mean loss=1158.1854248046875\n",
      "epoch 4287\n",
      "test_train\n",
      "train mean loss=0.08124373387545347\n",
      "test_test\n",
      "test mean loss=1158.2720336914062\n",
      "epoch 4288\n",
      "test_train\n",
      "train mean loss=0.07547189015895128\n",
      "test_test\n",
      "test mean loss=1158.4695434570312\n",
      "epoch 4289\n",
      "test_train\n",
      "train mean loss=0.07487580211212237\n",
      "test_test\n",
      "test mean loss=1159.1641235351562\n",
      "epoch 4290\n",
      "test_train\n",
      "train mean loss=0.08778372344871362\n",
      "test_test\n",
      "test mean loss=1158.3920593261719\n",
      "epoch 4291\n",
      "test_train\n",
      "train mean loss=0.07458891005565722\n",
      "test_test\n",
      "test mean loss=1157.0928344726562\n",
      "epoch 4292\n",
      "test_train\n",
      "train mean loss=0.08529114071279764\n",
      "test_test\n",
      "test mean loss=1159.20654296875\n",
      "epoch 4293\n",
      "test_train\n",
      "train mean loss=0.07966827228665352\n",
      "test_test\n",
      "test mean loss=1158.3978881835938\n",
      "epoch 4294\n",
      "test_train\n",
      "train mean loss=0.0775584913790226\n",
      "test_test\n",
      "test mean loss=1158.0530090332031\n",
      "epoch 4295\n",
      "test_train\n",
      "train mean loss=0.08082742181917031\n",
      "test_test\n",
      "test mean loss=1158.4107666015625\n",
      "epoch 4296\n",
      "test_train\n",
      "train mean loss=0.07843202042082946\n",
      "test_test\n",
      "test mean loss=1157.4951782226562\n",
      "epoch 4297\n",
      "test_train\n",
      "train mean loss=0.07739917933940887\n",
      "test_test\n",
      "test mean loss=1158.4131164550781\n",
      "epoch 4298\n",
      "test_train\n",
      "train mean loss=0.0756449569016695\n",
      "test_test\n",
      "test mean loss=1159.0936584472656\n",
      "epoch 4299\n",
      "test_train\n",
      "train mean loss=0.11063681604961555\n",
      "test_test\n",
      "test mean loss=1159.5708618164062\n",
      "epoch 4300\n",
      "test_train\n",
      "train mean loss=0.07879207873096068\n",
      "test_test\n",
      "test mean loss=1158.4776611328125\n",
      "epoch 4301\n",
      "test_train\n",
      "train mean loss=0.0815119007602334\n",
      "test_test\n",
      "test mean loss=1158.4148254394531\n",
      "epoch 4302\n",
      "test_train\n",
      "train mean loss=0.08324432993928592\n",
      "test_test\n",
      "test mean loss=1158.9853515625\n",
      "epoch 4303\n",
      "test_train\n",
      "train mean loss=0.07667774986475706\n",
      "test_test\n",
      "test mean loss=1159.5991821289062\n",
      "epoch 4304\n",
      "test_train\n",
      "train mean loss=0.07568116439506412\n",
      "test_test\n",
      "test mean loss=1158.8649291992188\n",
      "epoch 4305\n",
      "test_train\n",
      "train mean loss=0.07660798728466034\n",
      "test_test\n",
      "test mean loss=1159.4606323242188\n",
      "epoch 4306\n",
      "test_train\n",
      "train mean loss=0.07833340546737115\n",
      "test_test\n",
      "test mean loss=1159.5388488769531\n",
      "epoch 4307\n",
      "test_train\n",
      "train mean loss=0.07549833226948977\n",
      "test_test\n",
      "test mean loss=1158.2906494140625\n",
      "epoch 4308\n",
      "test_train\n",
      "train mean loss=0.08290531237920125\n",
      "test_test\n",
      "test mean loss=1159.546142578125\n",
      "epoch 4309\n",
      "test_train\n",
      "train mean loss=0.07387917581945658\n",
      "test_test\n",
      "test mean loss=1159.0234680175781\n",
      "epoch 4310\n",
      "test_train\n",
      "train mean loss=0.07560208532959223\n",
      "test_test\n",
      "test mean loss=1158.8343811035156\n",
      "epoch 4311\n",
      "test_train\n",
      "train mean loss=0.07929998403415084\n",
      "test_test\n",
      "test mean loss=1158.8432312011719\n",
      "epoch 4312\n",
      "test_train\n",
      "train mean loss=0.0770605265473326\n",
      "test_test\n",
      "test mean loss=1158.7315368652344\n",
      "epoch 4313\n",
      "test_train\n",
      "train mean loss=0.07618910198410352\n",
      "test_test\n",
      "test mean loss=1158.5721130371094\n",
      "epoch 4314\n",
      "test_train\n",
      "train mean loss=0.07392896804958582\n",
      "test_test\n",
      "test mean loss=1159.7640075683594\n",
      "epoch 4315\n",
      "test_train\n",
      "train mean loss=0.07319105525190632\n",
      "test_test\n",
      "test mean loss=1160.3526611328125\n",
      "epoch 4316\n",
      "test_train\n",
      "train mean loss=0.06961247480163972\n",
      "test_test\n",
      "test mean loss=1159.8391723632812\n",
      "epoch 4317\n",
      "test_train\n",
      "train mean loss=0.07735789691408475\n",
      "test_test\n",
      "test mean loss=1159.5970458984375\n",
      "epoch 4318\n",
      "test_train\n",
      "train mean loss=0.07526865229010582\n",
      "test_test\n",
      "test mean loss=1159.7546997070312\n",
      "epoch 4319\n",
      "test_train\n",
      "train mean loss=0.09971554701526959\n",
      "test_test\n",
      "test mean loss=1156.8965454101562\n",
      "epoch 4320\n",
      "test_train\n",
      "train mean loss=0.0748989274725318\n",
      "test_test\n",
      "test mean loss=1158.449951171875\n",
      "epoch 4321\n",
      "test_train\n",
      "train mean loss=0.11250136233866215\n",
      "test_test\n",
      "test mean loss=1157.5864562988281\n",
      "epoch 4322\n",
      "test_train\n",
      "train mean loss=0.07701861423750718\n",
      "test_test\n",
      "test mean loss=1159.3153076171875\n",
      "epoch 4323\n",
      "test_train\n",
      "train mean loss=0.08159615316738685\n",
      "test_test\n",
      "test mean loss=1159.6126708984375\n",
      "epoch 4324\n",
      "test_train\n",
      "train mean loss=0.07964302195856969\n",
      "test_test\n",
      "test mean loss=1158.7730712890625\n",
      "epoch 4325\n",
      "test_train\n",
      "train mean loss=0.08316681627184153\n",
      "test_test\n",
      "test mean loss=1158.7694091796875\n",
      "epoch 4326\n",
      "test_train\n",
      "train mean loss=0.07830793410539627\n",
      "test_test\n",
      "test mean loss=1159.0490112304688\n",
      "epoch 4327\n",
      "test_train\n",
      "train mean loss=0.08748073969036341\n",
      "test_test\n",
      "test mean loss=1158.4455871582031\n",
      "epoch 4328\n",
      "test_train\n",
      "train mean loss=0.0833530193194747\n",
      "test_test\n",
      "test mean loss=1158.876708984375\n",
      "epoch 4329\n",
      "test_train\n",
      "train mean loss=0.07033418212085962\n",
      "test_test\n",
      "test mean loss=1158.707275390625\n",
      "epoch 4330\n",
      "test_train\n",
      "train mean loss=0.07843828822175662\n",
      "test_test\n",
      "test mean loss=1158.9812622070312\n",
      "epoch 4331\n",
      "test_train\n",
      "train mean loss=0.07882827830811341\n",
      "test_test\n",
      "test mean loss=1157.9851684570312\n",
      "epoch 4332\n",
      "test_train\n",
      "train mean loss=0.07230072468519211\n",
      "test_test\n",
      "test mean loss=1157.9381713867188\n",
      "epoch 4333\n",
      "test_train\n",
      "train mean loss=0.07219517976045609\n",
      "test_test\n",
      "test mean loss=1158.5560302734375\n",
      "epoch 4334\n",
      "test_train\n",
      "train mean loss=0.0710886496429642\n",
      "test_test\n",
      "test mean loss=1158.2433471679688\n",
      "epoch 4335\n",
      "test_train\n",
      "train mean loss=0.07820473828663428\n",
      "test_test\n",
      "test mean loss=1159.1294250488281\n",
      "epoch 4336\n",
      "test_train\n",
      "train mean loss=0.0804485660046339\n",
      "test_test\n",
      "test mean loss=1159.5023193359375\n",
      "epoch 4337\n",
      "test_train\n",
      "train mean loss=0.07925502179811399\n",
      "test_test\n",
      "test mean loss=1158.2928466796875\n",
      "epoch 4338\n",
      "test_train\n",
      "train mean loss=0.08230484245965879\n",
      "test_test\n",
      "test mean loss=1158.7014770507812\n",
      "epoch 4339\n",
      "test_train\n",
      "train mean loss=0.0750464287896951\n",
      "test_test\n",
      "test mean loss=1158.073486328125\n",
      "epoch 4340\n",
      "test_train\n",
      "train mean loss=0.09965079215665658\n",
      "test_test\n",
      "test mean loss=1155.6097106933594\n",
      "epoch 4341\n",
      "test_train\n",
      "train mean loss=0.076018371929725\n",
      "test_test\n",
      "test mean loss=1158.500732421875\n",
      "epoch 4342\n",
      "test_train\n",
      "train mean loss=0.07781663164496422\n",
      "test_test\n",
      "test mean loss=1160.3950805664062\n",
      "epoch 4343\n",
      "test_train\n",
      "train mean loss=0.0728331155454119\n",
      "test_test\n",
      "test mean loss=1158.1951293945312\n",
      "epoch 4344\n",
      "test_train\n",
      "train mean loss=0.07576355710625648\n",
      "test_test\n",
      "test mean loss=1158.6057434082031\n",
      "epoch 4345\n",
      "test_train\n",
      "train mean loss=0.08503378741443157\n",
      "test_test\n",
      "test mean loss=1158.7727355957031\n",
      "epoch 4346\n",
      "test_train\n",
      "train mean loss=0.0822229590266943\n",
      "test_test\n",
      "test mean loss=1159.0213928222656\n",
      "epoch 4347\n",
      "test_train\n",
      "train mean loss=0.07601525541394949\n",
      "test_test\n",
      "test mean loss=1158.9470825195312\n",
      "epoch 4348\n",
      "test_train\n",
      "train mean loss=0.0711705507710576\n",
      "test_test\n",
      "test mean loss=1158.7320861816406\n",
      "epoch 4349\n",
      "test_train\n",
      "train mean loss=0.07414601867397626\n",
      "test_test\n",
      "test mean loss=1159.3936462402344\n",
      "epoch 4350\n",
      "test_train\n",
      "train mean loss=0.07058301226546367\n",
      "test_test\n",
      "test mean loss=1158.6067504882812\n",
      "epoch 4351\n",
      "test_train\n",
      "train mean loss=0.07817056092123191\n",
      "test_test\n",
      "test mean loss=1159.2783813476562\n",
      "epoch 4352\n",
      "test_train\n",
      "train mean loss=0.07079648117845257\n",
      "test_test\n",
      "test mean loss=1159.0360717773438\n",
      "epoch 4353\n",
      "test_train\n",
      "train mean loss=0.08340049317727487\n",
      "test_test\n",
      "test mean loss=1158.2744140625\n",
      "epoch 4354\n",
      "test_train\n",
      "train mean loss=0.07634049622962873\n",
      "test_test\n",
      "test mean loss=1158.6535339355469\n",
      "epoch 4355\n",
      "test_train\n",
      "train mean loss=0.07482063273588817\n",
      "test_test\n",
      "test mean loss=1158.4077758789062\n",
      "epoch 4356\n",
      "test_train\n",
      "train mean loss=0.07998450923090179\n",
      "test_test\n",
      "test mean loss=1158.112548828125\n",
      "epoch 4357\n",
      "test_train\n",
      "train mean loss=0.08333280651519696\n",
      "test_test\n",
      "test mean loss=1158.6566162109375\n",
      "epoch 4358\n",
      "test_train\n",
      "train mean loss=0.07126985459278028\n",
      "test_test\n",
      "test mean loss=1157.8526000976562\n",
      "epoch 4359\n",
      "test_train\n",
      "train mean loss=0.0802733755360047\n",
      "test_test\n",
      "test mean loss=1158.8953857421875\n",
      "epoch 4360\n",
      "test_train\n",
      "train mean loss=0.15352964277068773\n",
      "test_test\n",
      "test mean loss=1158.0578918457031\n",
      "epoch 4361\n",
      "test_train\n",
      "train mean loss=0.08223675439755122\n",
      "test_test\n",
      "test mean loss=1159.3505859375\n",
      "epoch 4362\n",
      "test_train\n",
      "train mean loss=0.07904891731838386\n",
      "test_test\n",
      "test mean loss=1158.575439453125\n",
      "epoch 4363\n",
      "test_train\n",
      "train mean loss=0.07566693269958098\n",
      "test_test\n",
      "test mean loss=1157.875244140625\n",
      "epoch 4364\n",
      "test_train\n",
      "train mean loss=0.07356853565822045\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1158.016845703125\n",
      "epoch 4365\n",
      "test_train\n",
      "train mean loss=0.07392230785141389\n",
      "test_test\n",
      "test mean loss=1158.7660827636719\n",
      "epoch 4366\n",
      "test_train\n",
      "train mean loss=0.07522336393594742\n",
      "test_test\n",
      "test mean loss=1158.6441040039062\n",
      "epoch 4367\n",
      "test_train\n",
      "train mean loss=0.07067399161557357\n",
      "test_test\n",
      "test mean loss=1158.4185791015625\n",
      "epoch 4368\n",
      "test_train\n",
      "train mean loss=0.0857030525803566\n",
      "test_test\n",
      "test mean loss=1159.1903381347656\n",
      "epoch 4369\n",
      "test_train\n",
      "train mean loss=0.07768977402398984\n",
      "test_test\n",
      "test mean loss=1159.5290832519531\n",
      "epoch 4370\n",
      "test_train\n",
      "train mean loss=0.07114044049133857\n",
      "test_test\n",
      "test mean loss=1159.3109130859375\n",
      "epoch 4371\n",
      "test_train\n",
      "train mean loss=0.07561823446303606\n",
      "test_test\n",
      "test mean loss=1159.1696166992188\n",
      "epoch 4372\n",
      "test_train\n",
      "train mean loss=0.07495424710214138\n",
      "test_test\n",
      "test mean loss=1159.3335266113281\n",
      "epoch 4373\n",
      "test_train\n",
      "train mean loss=0.07821064038823049\n",
      "test_test\n",
      "test mean loss=1159.542724609375\n",
      "epoch 4374\n",
      "test_train\n",
      "train mean loss=0.07596088604380687\n",
      "test_test\n",
      "test mean loss=1158.2986450195312\n",
      "epoch 4375\n",
      "test_train\n",
      "train mean loss=0.07808830433835585\n",
      "test_test\n",
      "test mean loss=1158.9115600585938\n",
      "epoch 4376\n",
      "test_train\n",
      "train mean loss=0.07358500454574823\n",
      "test_test\n",
      "test mean loss=1158.6835327148438\n",
      "epoch 4377\n",
      "test_train\n",
      "train mean loss=0.08391401761521895\n",
      "test_test\n",
      "test mean loss=1159.2457275390625\n",
      "epoch 4378\n",
      "test_train\n",
      "train mean loss=0.07577664622416098\n",
      "test_test\n",
      "test mean loss=1158.3756103515625\n",
      "epoch 4379\n",
      "test_train\n",
      "train mean loss=0.07775233639404178\n",
      "test_test\n",
      "test mean loss=1157.760498046875\n",
      "epoch 4380\n",
      "test_train\n",
      "train mean loss=0.07969508847842614\n",
      "test_test\n",
      "test mean loss=1158.4837646484375\n",
      "epoch 4381\n",
      "test_train\n",
      "train mean loss=0.07891666733970244\n",
      "test_test\n",
      "test mean loss=1159.393798828125\n",
      "epoch 4382\n",
      "test_train\n",
      "train mean loss=0.07806270848959684\n",
      "test_test\n",
      "test mean loss=1157.7576599121094\n",
      "epoch 4383\n",
      "test_train\n",
      "train mean loss=0.07170123575876157\n",
      "test_test\n",
      "test mean loss=1158.9742126464844\n",
      "epoch 4384\n",
      "test_train\n",
      "train mean loss=0.08467502954105537\n",
      "test_test\n",
      "test mean loss=1158.5087280273438\n",
      "epoch 4385\n",
      "test_train\n",
      "train mean loss=0.08171489275991917\n",
      "test_test\n",
      "test mean loss=1157.8634033203125\n",
      "epoch 4386\n",
      "test_train\n",
      "train mean loss=0.0762715544551611\n",
      "test_test\n",
      "test mean loss=1157.9032592773438\n",
      "epoch 4387\n",
      "test_train\n",
      "train mean loss=0.08102074855317672\n",
      "test_test\n",
      "test mean loss=1157.9306030273438\n",
      "epoch 4388\n",
      "test_train\n",
      "train mean loss=0.07347856182605028\n",
      "test_test\n",
      "test mean loss=1158.3912963867188\n",
      "epoch 4389\n",
      "test_train\n",
      "train mean loss=0.07640159378449123\n",
      "test_test\n",
      "test mean loss=1158.17578125\n",
      "epoch 4390\n",
      "test_train\n",
      "train mean loss=0.07443359152724345\n",
      "test_test\n",
      "test mean loss=1158.0144348144531\n",
      "epoch 4391\n",
      "test_train\n",
      "train mean loss=0.07642450338850419\n",
      "test_test\n",
      "test mean loss=1158.7020874023438\n",
      "epoch 4392\n",
      "test_train\n",
      "train mean loss=0.07751194946467876\n",
      "test_test\n",
      "test mean loss=1157.9275207519531\n",
      "epoch 4393\n",
      "test_train\n",
      "train mean loss=0.07643259068330129\n",
      "test_test\n",
      "test mean loss=1158.8547973632812\n",
      "epoch 4394\n",
      "test_train\n",
      "train mean loss=0.07620914125194152\n",
      "test_test\n",
      "test mean loss=1157.5999755859375\n",
      "epoch 4395\n",
      "test_train\n",
      "train mean loss=0.06951903862257798\n",
      "test_test\n",
      "test mean loss=1158.3984375\n",
      "epoch 4396\n",
      "test_train\n",
      "train mean loss=0.07543203110496204\n",
      "test_test\n",
      "test mean loss=1157.878173828125\n",
      "epoch 4397\n",
      "test_train\n",
      "train mean loss=0.07494050574799378\n",
      "test_test\n",
      "test mean loss=1158.7626953125\n",
      "epoch 4398\n",
      "test_train\n",
      "train mean loss=0.07303564809262753\n",
      "test_test\n",
      "test mean loss=1158.0660400390625\n",
      "epoch 4399\n",
      "test_train\n",
      "train mean loss=0.06793287117034197\n",
      "test_test\n",
      "test mean loss=1157.7040100097656\n",
      "epoch 4400\n",
      "test_train\n",
      "train mean loss=0.07602520380169153\n",
      "test_test\n",
      "test mean loss=1159.172607421875\n",
      "epoch 4401\n",
      "test_train\n",
      "train mean loss=0.07999658739815156\n",
      "test_test\n",
      "test mean loss=1157.4124755859375\n",
      "epoch 4402\n",
      "test_train\n",
      "train mean loss=0.06954569307466348\n",
      "test_test\n",
      "test mean loss=1158.4391479492188\n",
      "epoch 4403\n",
      "test_train\n",
      "train mean loss=0.06596636368582647\n",
      "test_test\n",
      "test mean loss=1158.529541015625\n",
      "epoch 4404\n",
      "test_train\n",
      "train mean loss=0.07094729660699765\n",
      "test_test\n",
      "test mean loss=1157.7247314453125\n",
      "epoch 4405\n",
      "test_train\n",
      "train mean loss=0.07223636377602816\n",
      "test_test\n",
      "test mean loss=1158.1580200195312\n",
      "epoch 4406\n",
      "test_train\n",
      "train mean loss=0.08484564069658518\n",
      "test_test\n",
      "test mean loss=1157.5062866210938\n",
      "epoch 4407\n",
      "test_train\n",
      "train mean loss=0.07420723388592403\n",
      "test_test\n",
      "test mean loss=1158.0993957519531\n",
      "epoch 4408\n",
      "test_train\n",
      "train mean loss=0.07221669796854258\n",
      "test_test\n",
      "test mean loss=1159.1543579101562\n",
      "epoch 4409\n",
      "test_train\n",
      "train mean loss=0.07769001772006352\n",
      "test_test\n",
      "test mean loss=1158.8645629882812\n",
      "epoch 4410\n",
      "test_train\n",
      "train mean loss=0.08164658801009257\n",
      "test_test\n",
      "test mean loss=1158.9871215820312\n",
      "epoch 4411\n",
      "test_train\n",
      "train mean loss=0.07937711601456006\n",
      "test_test\n",
      "test mean loss=1158.29443359375\n",
      "epoch 4412\n",
      "test_train\n",
      "train mean loss=0.07734685267011325\n",
      "test_test\n",
      "test mean loss=1158.9873046875\n",
      "epoch 4413\n",
      "test_train\n",
      "train mean loss=0.07621988436828057\n",
      "test_test\n",
      "test mean loss=1158.4117126464844\n",
      "epoch 4414\n",
      "test_train\n",
      "train mean loss=0.08087308891117573\n",
      "test_test\n",
      "test mean loss=1158.3067321777344\n",
      "epoch 4415\n",
      "test_train\n",
      "train mean loss=0.07508508022874594\n",
      "test_test\n",
      "test mean loss=1158.4948120117188\n",
      "epoch 4416\n",
      "test_train\n",
      "train mean loss=0.07244948546091716\n",
      "test_test\n",
      "test mean loss=1158.4476623535156\n",
      "epoch 4417\n",
      "test_train\n",
      "train mean loss=0.06736664784451325\n",
      "test_test\n",
      "test mean loss=1158.8514709472656\n",
      "epoch 4418\n",
      "test_train\n",
      "train mean loss=0.07310491210470597\n",
      "test_test\n",
      "test mean loss=1158.7763061523438\n",
      "epoch 4419\n",
      "test_train\n",
      "train mean loss=0.07243657733003299\n",
      "test_test\n",
      "test mean loss=1158.3153686523438\n",
      "epoch 4420\n",
      "test_train\n",
      "train mean loss=0.07282636128365993\n",
      "test_test\n",
      "test mean loss=1157.7947998046875\n",
      "epoch 4421\n",
      "test_train\n",
      "train mean loss=0.07772829135258992\n",
      "test_test\n",
      "test mean loss=1159.5166320800781\n",
      "epoch 4422\n",
      "test_train\n",
      "train mean loss=0.07129642646759748\n",
      "test_test\n",
      "test mean loss=1158.5067138671875\n",
      "epoch 4423\n",
      "test_train\n",
      "train mean loss=0.07253673144926627\n",
      "test_test\n",
      "test mean loss=1158.77392578125\n",
      "epoch 4424\n",
      "test_train\n",
      "train mean loss=0.1206864466269811\n",
      "test_test\n",
      "test mean loss=1159.9031982421875\n",
      "epoch 4425\n",
      "test_train\n",
      "train mean loss=0.07743969466537237\n",
      "test_test\n",
      "test mean loss=1157.7205810546875\n",
      "epoch 4426\n",
      "test_train\n",
      "train mean loss=0.07352927916993697\n",
      "test_test\n",
      "test mean loss=1157.5908508300781\n",
      "epoch 4427\n",
      "test_train\n",
      "train mean loss=0.06981949880719185\n",
      "test_test\n",
      "test mean loss=1156.1827087402344\n",
      "epoch 4428\n",
      "test_train\n",
      "train mean loss=0.07127421007802089\n",
      "test_test\n",
      "test mean loss=1157.2957763671875\n",
      "epoch 4429\n",
      "test_train\n",
      "train mean loss=0.07688415205727021\n",
      "test_test\n",
      "test mean loss=1158.3562622070312\n",
      "epoch 4430\n",
      "test_train\n",
      "train mean loss=0.08265590978165467\n",
      "test_test\n",
      "test mean loss=1157.8194580078125\n",
      "epoch 4431\n",
      "test_train\n",
      "train mean loss=0.07505528597782056\n",
      "test_test\n",
      "test mean loss=1156.7603149414062\n",
      "epoch 4432\n",
      "test_train\n",
      "train mean loss=0.08141195494681597\n",
      "test_test\n",
      "test mean loss=1158.3443603515625\n",
      "epoch 4433\n",
      "test_train\n",
      "train mean loss=0.08114149638762076\n",
      "test_test\n",
      "test mean loss=1157.8245239257812\n",
      "epoch 4434\n",
      "test_train\n",
      "train mean loss=0.07223753444850445\n",
      "test_test\n",
      "test mean loss=1157.9400939941406\n",
      "epoch 4435\n",
      "test_train\n",
      "train mean loss=0.0773211745545268\n",
      "test_test\n",
      "test mean loss=1158.247802734375\n",
      "epoch 4436\n",
      "test_train\n",
      "train mean loss=0.0789675669123729\n",
      "test_test\n",
      "test mean loss=1158.8571166992188\n",
      "epoch 4437\n",
      "test_train\n",
      "train mean loss=0.2246562708169222\n",
      "test_test\n",
      "test mean loss=1157.3555297851562\n",
      "epoch 4438\n",
      "test_train\n",
      "train mean loss=0.09820373356342316\n",
      "test_test\n",
      "test mean loss=1158.307373046875\n",
      "epoch 4439\n",
      "test_train\n",
      "train mean loss=0.16040348323682943\n",
      "test_test\n",
      "test mean loss=1160.0907287597656\n",
      "epoch 4440\n",
      "test_train\n",
      "train mean loss=0.0825489057848851\n",
      "test_test\n",
      "test mean loss=1159.7926635742188\n",
      "epoch 4441\n",
      "test_train\n",
      "train mean loss=0.07302480470389128\n",
      "test_test\n",
      "test mean loss=1159.0762329101562\n",
      "epoch 4442\n",
      "test_train\n",
      "train mean loss=0.08821534148106973\n",
      "test_test\n",
      "test mean loss=1159.2206420898438\n",
      "epoch 4443\n",
      "test_train\n",
      "train mean loss=0.07297815817097823\n",
      "test_test\n",
      "test mean loss=1158.4859313964844\n",
      "epoch 4444\n",
      "test_train\n",
      "train mean loss=0.07329504657536745\n",
      "test_test\n",
      "test mean loss=1159.3644714355469\n",
      "epoch 4445\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.07089542597532272\n",
      "test_test\n",
      "test mean loss=1158.5322265625\n",
      "epoch 4446\n",
      "test_train\n",
      "train mean loss=0.07624600827693939\n",
      "test_test\n",
      "test mean loss=1158.7627563476562\n",
      "epoch 4447\n",
      "test_train\n",
      "train mean loss=0.07292359570662181\n",
      "test_test\n",
      "test mean loss=1157.3611450195312\n",
      "epoch 4448\n",
      "test_train\n",
      "train mean loss=0.07604738728453715\n",
      "test_test\n",
      "test mean loss=1159.0892028808594\n",
      "epoch 4449\n",
      "test_train\n",
      "train mean loss=0.07652027190973361\n",
      "test_test\n",
      "test mean loss=1158.6721801757812\n",
      "epoch 4450\n",
      "test_train\n",
      "train mean loss=0.07262343727052212\n",
      "test_test\n",
      "test mean loss=1157.7940673828125\n",
      "epoch 4451\n",
      "test_train\n",
      "train mean loss=0.07561601667354505\n",
      "test_test\n",
      "test mean loss=1158.598876953125\n",
      "epoch 4452\n",
      "test_train\n",
      "train mean loss=0.07850844971835613\n",
      "test_test\n",
      "test mean loss=1158.5418701171875\n",
      "epoch 4453\n",
      "test_train\n",
      "train mean loss=0.07533019905289014\n",
      "test_test\n",
      "test mean loss=1157.7055053710938\n",
      "epoch 4454\n",
      "test_train\n",
      "train mean loss=0.07560490071773529\n",
      "test_test\n",
      "test mean loss=1157.6315307617188\n",
      "epoch 4455\n",
      "test_train\n",
      "train mean loss=0.0744257876649499\n",
      "test_test\n",
      "test mean loss=1157.7605285644531\n",
      "epoch 4456\n",
      "test_train\n",
      "train mean loss=0.06823385848353307\n",
      "test_test\n",
      "test mean loss=1157.7877807617188\n",
      "epoch 4457\n",
      "test_train\n",
      "train mean loss=0.07385752629488707\n",
      "test_test\n",
      "test mean loss=1157.8530883789062\n",
      "epoch 4458\n",
      "test_train\n",
      "train mean loss=0.08604388342549403\n",
      "test_test\n",
      "test mean loss=1158.6166687011719\n",
      "epoch 4459\n",
      "test_train\n",
      "train mean loss=0.07614352895567815\n",
      "test_test\n",
      "test mean loss=1157.5022888183594\n",
      "epoch 4460\n",
      "test_train\n",
      "train mean loss=0.07359941272685926\n",
      "test_test\n",
      "test mean loss=1157.1860961914062\n",
      "epoch 4461\n",
      "test_train\n",
      "train mean loss=0.07322376221418381\n",
      "test_test\n",
      "test mean loss=1157.9268188476562\n",
      "epoch 4462\n",
      "test_train\n",
      "train mean loss=0.08062530650446813\n",
      "test_test\n",
      "test mean loss=1159.2621459960938\n",
      "epoch 4463\n",
      "test_train\n",
      "train mean loss=0.07570778019726276\n",
      "test_test\n",
      "test mean loss=1158.5170288085938\n",
      "epoch 4464\n",
      "test_train\n",
      "train mean loss=0.09452201581249635\n",
      "test_test\n",
      "test mean loss=1159.3672485351562\n",
      "epoch 4465\n",
      "test_train\n",
      "train mean loss=0.07678015173102419\n",
      "test_test\n",
      "test mean loss=1159.0292663574219\n",
      "epoch 4466\n",
      "test_train\n",
      "train mean loss=0.07298129765937726\n",
      "test_test\n",
      "test mean loss=1157.696533203125\n",
      "epoch 4467\n",
      "test_train\n",
      "train mean loss=0.07712714280933142\n",
      "test_test\n",
      "test mean loss=1157.6076354980469\n",
      "epoch 4468\n",
      "test_train\n",
      "train mean loss=0.0778869033480684\n",
      "test_test\n",
      "test mean loss=1158.3094177246094\n",
      "epoch 4469\n",
      "test_train\n",
      "train mean loss=0.07229104917496443\n",
      "test_test\n",
      "test mean loss=1158.6214599609375\n",
      "epoch 4470\n",
      "test_train\n",
      "train mean loss=0.07523971361418565\n",
      "test_test\n",
      "test mean loss=1157.466064453125\n",
      "epoch 4471\n",
      "test_train\n",
      "train mean loss=0.07665550522506237\n",
      "test_test\n",
      "test mean loss=1157.47705078125\n",
      "epoch 4472\n",
      "test_train\n",
      "train mean loss=0.07786966984470685\n",
      "test_test\n",
      "test mean loss=1157.7376098632812\n",
      "epoch 4473\n",
      "test_train\n",
      "train mean loss=0.08268004314353068\n",
      "test_test\n",
      "test mean loss=1157.8327941894531\n",
      "epoch 4474\n",
      "test_train\n",
      "train mean loss=0.14012902230024338\n",
      "test_test\n",
      "test mean loss=1156.9359741210938\n",
      "epoch 4475\n",
      "test_train\n",
      "train mean loss=0.07661115781714518\n",
      "test_test\n",
      "test mean loss=1157.1915893554688\n",
      "epoch 4476\n",
      "test_train\n",
      "train mean loss=0.07670187981178363\n",
      "test_test\n",
      "test mean loss=1157.6884155273438\n",
      "epoch 4477\n",
      "test_train\n",
      "train mean loss=0.08353448038299878\n",
      "test_test\n",
      "test mean loss=1157.5929565429688\n",
      "epoch 4478\n",
      "test_train\n",
      "train mean loss=0.07766348496079445\n",
      "test_test\n",
      "test mean loss=1156.8972473144531\n",
      "epoch 4479\n",
      "test_train\n",
      "train mean loss=0.08015282545238733\n",
      "test_test\n",
      "test mean loss=1157.673828125\n",
      "epoch 4480\n",
      "test_train\n",
      "train mean loss=0.07117088635762532\n",
      "test_test\n",
      "test mean loss=1157.5189208984375\n",
      "epoch 4481\n",
      "test_train\n",
      "train mean loss=0.07979509234428406\n",
      "test_test\n",
      "test mean loss=1157.773681640625\n",
      "epoch 4482\n",
      "test_train\n",
      "train mean loss=0.07941421369711558\n",
      "test_test\n",
      "test mean loss=1157.9635620117188\n",
      "epoch 4483\n",
      "test_train\n",
      "train mean loss=0.0733912040789922\n",
      "test_test\n",
      "test mean loss=1158.6802978515625\n",
      "epoch 4484\n",
      "test_train\n",
      "train mean loss=0.07662016339600086\n",
      "test_test\n",
      "test mean loss=1158.5232849121094\n",
      "epoch 4485\n",
      "test_train\n",
      "train mean loss=0.0764774961086611\n",
      "test_test\n",
      "test mean loss=1158.7434387207031\n",
      "epoch 4486\n",
      "test_train\n",
      "train mean loss=0.06831859176357587\n",
      "test_test\n",
      "test mean loss=1158.1056518554688\n",
      "epoch 4487\n",
      "test_train\n",
      "train mean loss=0.07228662601361673\n",
      "test_test\n",
      "test mean loss=1157.033447265625\n",
      "epoch 4488\n",
      "test_train\n",
      "train mean loss=0.0740923232709368\n",
      "test_test\n",
      "test mean loss=1157.6464233398438\n",
      "epoch 4489\n",
      "test_train\n",
      "train mean loss=0.07860578379283349\n",
      "test_test\n",
      "test mean loss=1158.2637329101562\n",
      "epoch 4490\n",
      "test_train\n",
      "train mean loss=0.06808398695041736\n",
      "test_test\n",
      "test mean loss=1158.3045043945312\n",
      "epoch 4491\n",
      "test_train\n",
      "train mean loss=0.07431047347684701\n",
      "test_test\n",
      "test mean loss=1158.4193725585938\n",
      "epoch 4492\n",
      "test_train\n",
      "train mean loss=0.07627689434836309\n",
      "test_test\n",
      "test mean loss=1158.6642456054688\n",
      "epoch 4493\n",
      "test_train\n",
      "train mean loss=0.07450955143819253\n",
      "test_test\n",
      "test mean loss=1158.7458190917969\n",
      "epoch 4494\n",
      "test_train\n",
      "train mean loss=0.0718676382675767\n",
      "test_test\n",
      "test mean loss=1158.32958984375\n",
      "epoch 4495\n",
      "test_train\n",
      "train mean loss=0.07219336709628503\n",
      "test_test\n",
      "test mean loss=1158.9274597167969\n",
      "epoch 4496\n",
      "test_train\n",
      "train mean loss=0.07535931933671236\n",
      "test_test\n",
      "test mean loss=1158.8460083007812\n",
      "epoch 4497\n",
      "test_train\n",
      "train mean loss=0.07001495112975438\n",
      "test_test\n",
      "test mean loss=1158.6826171875\n",
      "epoch 4498\n",
      "test_train\n",
      "train mean loss=0.07337641281386216\n",
      "test_test\n",
      "test mean loss=1159.1133117675781\n",
      "epoch 4499\n",
      "test_train\n",
      "train mean loss=0.07396051101386547\n",
      "test_test\n",
      "test mean loss=1158.0426025390625\n",
      "epoch 4500\n",
      "test_train\n",
      "train mean loss=0.07318265891323487\n",
      "test_test\n",
      "test mean loss=1158.1113891601562\n",
      "epoch 4501\n",
      "test_train\n",
      "train mean loss=0.07650346650431554\n",
      "test_test\n",
      "test mean loss=1158.5502319335938\n",
      "epoch 4502\n",
      "test_train\n",
      "train mean loss=0.07404575993617375\n",
      "test_test\n",
      "test mean loss=1158.3128967285156\n",
      "epoch 4503\n",
      "test_train\n",
      "train mean loss=0.07288013150294621\n",
      "test_test\n",
      "test mean loss=1157.7949829101562\n",
      "epoch 4504\n",
      "test_train\n",
      "train mean loss=0.10369891424973805\n",
      "test_test\n",
      "test mean loss=1156.4591674804688\n",
      "epoch 4505\n",
      "test_train\n",
      "train mean loss=0.0791397796322902\n",
      "test_test\n",
      "test mean loss=1158.2165222167969\n",
      "epoch 4506\n",
      "test_train\n",
      "train mean loss=0.0750333103351295\n",
      "test_test\n",
      "test mean loss=1157.7157897949219\n",
      "epoch 4507\n",
      "test_train\n",
      "train mean loss=0.07925698005904754\n",
      "test_test\n",
      "test mean loss=1158.5563354492188\n",
      "epoch 4508\n",
      "test_train\n",
      "train mean loss=0.06706710408131282\n",
      "test_test\n",
      "test mean loss=1158.4302062988281\n",
      "epoch 4509\n",
      "test_train\n",
      "train mean loss=0.06945848402877648\n",
      "test_test\n",
      "test mean loss=1157.195556640625\n",
      "epoch 4510\n",
      "test_train\n",
      "train mean loss=0.0782355172559619\n",
      "test_test\n",
      "test mean loss=1158.40625\n",
      "epoch 4511\n",
      "test_train\n",
      "train mean loss=0.07239427355428536\n",
      "test_test\n",
      "test mean loss=1156.8414916992188\n",
      "epoch 4512\n",
      "test_train\n",
      "train mean loss=0.07255368959158659\n",
      "test_test\n",
      "test mean loss=1158.3533630371094\n",
      "epoch 4513\n",
      "test_train\n",
      "train mean loss=0.07371704497685035\n",
      "test_test\n",
      "test mean loss=1157.6896057128906\n",
      "epoch 4514\n",
      "test_train\n",
      "train mean loss=0.07956301017353933\n",
      "test_test\n",
      "test mean loss=1157.6028747558594\n",
      "epoch 4515\n",
      "test_train\n",
      "train mean loss=0.07358179924388726\n",
      "test_test\n",
      "test mean loss=1157.5458068847656\n",
      "epoch 4516\n",
      "test_train\n",
      "train mean loss=0.0695743877440691\n",
      "test_test\n",
      "test mean loss=1157.6704711914062\n",
      "epoch 4517\n",
      "test_train\n",
      "train mean loss=0.07699073292315006\n",
      "test_test\n",
      "test mean loss=1158.3316650390625\n",
      "epoch 4518\n",
      "test_train\n",
      "train mean loss=0.07646536578734715\n",
      "test_test\n",
      "test mean loss=1157.6637573242188\n",
      "epoch 4519\n",
      "test_train\n",
      "train mean loss=0.0736033096909523\n",
      "test_test\n",
      "test mean loss=1156.1348876953125\n",
      "epoch 4520\n",
      "test_train\n",
      "train mean loss=0.09463873164107402\n",
      "test_test\n",
      "test mean loss=1158.190185546875\n",
      "epoch 4521\n",
      "test_train\n",
      "train mean loss=0.0723040144269665\n",
      "test_test\n",
      "test mean loss=1157.1299133300781\n",
      "epoch 4522\n",
      "test_train\n",
      "train mean loss=0.07362390433748563\n",
      "test_test\n",
      "test mean loss=1158.0420532226562\n",
      "epoch 4523\n",
      "test_train\n",
      "train mean loss=0.07298777035127084\n",
      "test_test\n",
      "test mean loss=1158.7686157226562\n",
      "epoch 4524\n",
      "test_train\n",
      "train mean loss=0.0754145182048281\n",
      "test_test\n",
      "test mean loss=1158.200927734375\n",
      "epoch 4525\n",
      "test_train\n",
      "train mean loss=0.07657106469074886\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1158.5050964355469\n",
      "epoch 4526\n",
      "test_train\n",
      "train mean loss=0.08107544605930646\n",
      "test_test\n",
      "test mean loss=1158.8773803710938\n",
      "epoch 4527\n",
      "test_train\n",
      "train mean loss=0.07405216867725055\n",
      "test_test\n",
      "test mean loss=1158.4862060546875\n",
      "epoch 4528\n",
      "test_train\n",
      "train mean loss=0.06792862775425117\n",
      "test_test\n",
      "test mean loss=1156.961181640625\n",
      "epoch 4529\n",
      "test_train\n",
      "train mean loss=0.07636994682252407\n",
      "test_test\n",
      "test mean loss=1156.9699401855469\n",
      "epoch 4530\n",
      "test_train\n",
      "train mean loss=0.07283600543936093\n",
      "test_test\n",
      "test mean loss=1157.5635681152344\n",
      "epoch 4531\n",
      "test_train\n",
      "train mean loss=0.07390560706456502\n",
      "test_test\n",
      "test mean loss=1158.0913696289062\n",
      "epoch 4532\n",
      "test_train\n",
      "train mean loss=0.07231531757861376\n",
      "test_test\n",
      "test mean loss=1157.5418395996094\n",
      "epoch 4533\n",
      "test_train\n",
      "train mean loss=0.08861419775833686\n",
      "test_test\n",
      "test mean loss=1158.2095031738281\n",
      "epoch 4534\n",
      "test_train\n",
      "train mean loss=0.07368822007750471\n",
      "test_test\n",
      "test mean loss=1158.3028259277344\n",
      "epoch 4535\n",
      "test_train\n",
      "train mean loss=0.06564151092121999\n",
      "test_test\n",
      "test mean loss=1157.9422607421875\n",
      "epoch 4536\n",
      "test_train\n",
      "train mean loss=0.07629307359457016\n",
      "test_test\n",
      "test mean loss=1157.915283203125\n",
      "epoch 4537\n",
      "test_train\n",
      "train mean loss=0.07300556513170402\n",
      "test_test\n",
      "test mean loss=1157.5984497070312\n",
      "epoch 4538\n",
      "test_train\n",
      "train mean loss=0.08473989771058162\n",
      "test_test\n",
      "test mean loss=1158.8658447265625\n",
      "epoch 4539\n",
      "test_train\n",
      "train mean loss=0.0826329638560613\n",
      "test_test\n",
      "test mean loss=1158.0131530761719\n",
      "epoch 4540\n",
      "test_train\n",
      "train mean loss=0.08273427902410428\n",
      "test_test\n",
      "test mean loss=1158.3794555664062\n",
      "epoch 4541\n",
      "test_train\n",
      "train mean loss=0.0766212164113919\n",
      "test_test\n",
      "test mean loss=1157.6349487304688\n",
      "epoch 4542\n",
      "test_train\n",
      "train mean loss=0.07800502485285203\n",
      "test_test\n",
      "test mean loss=1158.5419006347656\n",
      "epoch 4543\n",
      "test_train\n",
      "train mean loss=0.07243754249066114\n",
      "test_test\n",
      "test mean loss=1158.1959838867188\n",
      "epoch 4544\n",
      "test_train\n",
      "train mean loss=0.07415444683283567\n",
      "test_test\n",
      "test mean loss=1157.0870361328125\n",
      "epoch 4545\n",
      "test_train\n",
      "train mean loss=0.07923975493758917\n",
      "test_test\n",
      "test mean loss=1157.9877319335938\n",
      "epoch 4546\n",
      "test_train\n",
      "train mean loss=0.07662687792132299\n",
      "test_test\n",
      "test mean loss=1157.4879760742188\n",
      "epoch 4547\n",
      "test_train\n",
      "train mean loss=0.07579114101827145\n",
      "test_test\n",
      "test mean loss=1157.8721008300781\n",
      "epoch 4548\n",
      "test_train\n",
      "train mean loss=0.0732058562959234\n",
      "test_test\n",
      "test mean loss=1157.2879028320312\n",
      "epoch 4549\n",
      "test_train\n",
      "train mean loss=0.0732051373148958\n",
      "test_test\n",
      "test mean loss=1158.0148315429688\n",
      "epoch 4550\n",
      "test_train\n",
      "train mean loss=0.07489741531511147\n",
      "test_test\n",
      "test mean loss=1158.3119506835938\n",
      "epoch 4551\n",
      "test_train\n",
      "train mean loss=0.11008274865647157\n",
      "test_test\n",
      "test mean loss=1158.2149658203125\n",
      "epoch 4552\n",
      "test_train\n",
      "train mean loss=0.0720992994805177\n",
      "test_test\n",
      "test mean loss=1155.8887939453125\n",
      "epoch 4553\n",
      "test_train\n",
      "train mean loss=0.08510207509001096\n",
      "test_test\n",
      "test mean loss=1157.1990356445312\n",
      "epoch 4554\n",
      "test_train\n",
      "train mean loss=0.07103132580717404\n",
      "test_test\n",
      "test mean loss=1156.2145690917969\n",
      "epoch 4555\n",
      "test_train\n",
      "train mean loss=0.06628343105937044\n",
      "test_test\n",
      "test mean loss=1157.1270446777344\n",
      "epoch 4556\n",
      "test_train\n",
      "train mean loss=0.07371171843260527\n",
      "test_test\n",
      "test mean loss=1157.6112060546875\n",
      "epoch 4557\n",
      "test_train\n",
      "train mean loss=0.08075404757012923\n",
      "test_test\n",
      "test mean loss=1158.2774658203125\n",
      "epoch 4558\n",
      "test_train\n",
      "train mean loss=0.07467565344025691\n",
      "test_test\n",
      "test mean loss=1157.8311767578125\n",
      "epoch 4559\n",
      "test_train\n",
      "train mean loss=0.07185054880877335\n",
      "test_test\n",
      "test mean loss=1157.9063110351562\n",
      "epoch 4560\n",
      "test_train\n",
      "train mean loss=0.07250705982247989\n",
      "test_test\n",
      "test mean loss=1157.2438049316406\n",
      "epoch 4561\n",
      "test_train\n",
      "train mean loss=0.07275776037325461\n",
      "test_test\n",
      "test mean loss=1157.9407348632812\n",
      "epoch 4562\n",
      "test_train\n",
      "train mean loss=0.07563578213254611\n",
      "test_test\n",
      "test mean loss=1158.406494140625\n",
      "epoch 4563\n",
      "test_train\n",
      "train mean loss=0.07989533183475335\n",
      "test_test\n",
      "test mean loss=1159.5610046386719\n",
      "epoch 4564\n",
      "test_train\n",
      "train mean loss=0.06983481037120025\n",
      "test_test\n",
      "test mean loss=1159.0719604492188\n",
      "epoch 4565\n",
      "test_train\n",
      "train mean loss=0.10668517804394166\n",
      "test_test\n",
      "test mean loss=1156.8958129882812\n",
      "epoch 4566\n",
      "test_train\n",
      "train mean loss=0.07368564109007518\n",
      "test_test\n",
      "test mean loss=1158.1449584960938\n",
      "epoch 4567\n",
      "test_train\n",
      "train mean loss=0.08118788587550323\n",
      "test_test\n",
      "test mean loss=1158.1711730957031\n",
      "epoch 4568\n",
      "test_train\n",
      "train mean loss=0.07382757402956486\n",
      "test_test\n",
      "test mean loss=1157.0650634765625\n",
      "epoch 4569\n",
      "test_train\n",
      "train mean loss=0.07508379748711984\n",
      "test_test\n",
      "test mean loss=1158.0589599609375\n",
      "epoch 4570\n",
      "test_train\n",
      "train mean loss=0.08297674109538396\n",
      "test_test\n",
      "test mean loss=1157.1611938476562\n",
      "epoch 4571\n",
      "test_train\n",
      "train mean loss=0.0778315681964159\n",
      "test_test\n",
      "test mean loss=1158.0123901367188\n",
      "epoch 4572\n",
      "test_train\n",
      "train mean loss=0.08129749881724517\n",
      "test_test\n",
      "test mean loss=1157.9992065429688\n",
      "epoch 4573\n",
      "test_train\n",
      "train mean loss=0.07977311561505\n",
      "test_test\n",
      "test mean loss=1158.0132446289062\n",
      "epoch 4574\n",
      "test_train\n",
      "train mean loss=0.07491443958133459\n",
      "test_test\n",
      "test mean loss=1158.3423156738281\n",
      "epoch 4575\n",
      "test_train\n",
      "train mean loss=0.0771653400734067\n",
      "test_test\n",
      "test mean loss=1158.05859375\n",
      "epoch 4576\n",
      "test_train\n",
      "train mean loss=0.0771546745672822\n",
      "test_test\n",
      "test mean loss=1157.7542724609375\n",
      "epoch 4577\n",
      "test_train\n",
      "train mean loss=0.07721794148286183\n",
      "test_test\n",
      "test mean loss=1157.5057983398438\n",
      "epoch 4578\n",
      "test_train\n",
      "train mean loss=0.08341360030074914\n",
      "test_test\n",
      "test mean loss=1157.6231689453125\n",
      "epoch 4579\n",
      "test_train\n",
      "train mean loss=0.08064375010629495\n",
      "test_test\n",
      "test mean loss=1157.2155151367188\n",
      "epoch 4580\n",
      "test_train\n",
      "train mean loss=0.08037392050027847\n",
      "test_test\n",
      "test mean loss=1157.8834228515625\n",
      "epoch 4581\n",
      "test_train\n",
      "train mean loss=0.08003101373712222\n",
      "test_test\n",
      "test mean loss=1157.7084350585938\n",
      "epoch 4582\n",
      "test_train\n",
      "train mean loss=0.07496352183322112\n",
      "test_test\n",
      "test mean loss=1158.689208984375\n",
      "epoch 4583\n",
      "test_train\n",
      "train mean loss=0.07411756242314975\n",
      "test_test\n",
      "test mean loss=1157.1142578125\n",
      "epoch 4584\n",
      "test_train\n",
      "train mean loss=0.07552658735464017\n",
      "test_test\n",
      "test mean loss=1157.8115539550781\n",
      "epoch 4585\n",
      "test_train\n",
      "train mean loss=0.07342445788284142\n",
      "test_test\n",
      "test mean loss=1156.680419921875\n",
      "epoch 4586\n",
      "test_train\n",
      "train mean loss=0.07481854346891244\n",
      "test_test\n",
      "test mean loss=1157.7332153320312\n",
      "epoch 4587\n",
      "test_train\n",
      "train mean loss=0.08709838924308617\n",
      "test_test\n",
      "test mean loss=1159.052490234375\n",
      "epoch 4588\n",
      "test_train\n",
      "train mean loss=0.07517335408677657\n",
      "test_test\n",
      "test mean loss=1157.9815673828125\n",
      "epoch 4589\n",
      "test_train\n",
      "train mean loss=0.08550957528253396\n",
      "test_test\n",
      "test mean loss=1157.2584838867188\n",
      "epoch 4590\n",
      "test_train\n",
      "train mean loss=0.07646480109542608\n",
      "test_test\n",
      "test mean loss=1158.3513793945312\n",
      "epoch 4591\n",
      "test_train\n",
      "train mean loss=0.07024403444180886\n",
      "test_test\n",
      "test mean loss=1158.524169921875\n",
      "epoch 4592\n",
      "test_train\n",
      "train mean loss=0.07414062817891438\n",
      "test_test\n",
      "test mean loss=1157.7348022460938\n",
      "epoch 4593\n",
      "test_train\n",
      "train mean loss=0.07641887199133635\n",
      "test_test\n",
      "test mean loss=1157.7219848632812\n",
      "epoch 4594\n",
      "test_train\n",
      "train mean loss=0.07100437115877867\n",
      "test_test\n",
      "test mean loss=1157.67138671875\n",
      "epoch 4595\n",
      "test_train\n",
      "train mean loss=0.07727639346073072\n",
      "test_test\n",
      "test mean loss=1158.1659545898438\n",
      "epoch 4596\n",
      "test_train\n",
      "train mean loss=0.07275501887003581\n",
      "test_test\n",
      "test mean loss=1158.0617065429688\n",
      "epoch 4597\n",
      "test_train\n",
      "train mean loss=0.08275397401303053\n",
      "test_test\n",
      "test mean loss=1157.2837524414062\n",
      "epoch 4598\n",
      "test_train\n",
      "train mean loss=0.0705636761461695\n",
      "test_test\n",
      "test mean loss=1157.2748107910156\n",
      "epoch 4599\n",
      "test_train\n",
      "train mean loss=0.07449621924509604\n",
      "test_test\n",
      "test mean loss=1158.5622253417969\n",
      "epoch 4600\n",
      "test_train\n",
      "train mean loss=0.1880211445192496\n",
      "test_test\n",
      "test mean loss=1155.1398010253906\n",
      "epoch 4601\n",
      "test_train\n",
      "train mean loss=0.07874369497100513\n",
      "test_test\n",
      "test mean loss=1157.2792358398438\n",
      "epoch 4602\n",
      "test_train\n",
      "train mean loss=0.08138274059941371\n",
      "test_test\n",
      "test mean loss=1157.4518432617188\n",
      "epoch 4603\n",
      "test_train\n",
      "train mean loss=0.07480565458536148\n",
      "test_test\n",
      "test mean loss=1156.8482971191406\n",
      "epoch 4604\n",
      "test_train\n",
      "train mean loss=0.07703808943430583\n",
      "test_test\n",
      "test mean loss=1157.1050415039062\n",
      "epoch 4605\n",
      "test_train\n",
      "train mean loss=0.07860484439879656\n",
      "test_test\n",
      "test mean loss=1157.6244506835938\n",
      "epoch 4606\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.07381206595649321\n",
      "test_test\n",
      "test mean loss=1156.8574829101562\n",
      "epoch 4607\n",
      "test_train\n",
      "train mean loss=0.07361996670564015\n",
      "test_test\n",
      "test mean loss=1157.5057983398438\n",
      "epoch 4608\n",
      "test_train\n",
      "train mean loss=0.07193080180635054\n",
      "test_test\n",
      "test mean loss=1157.0399169921875\n",
      "epoch 4609\n",
      "test_train\n",
      "train mean loss=0.0719817178323865\n",
      "test_test\n",
      "test mean loss=1156.8868713378906\n",
      "epoch 4610\n",
      "test_train\n",
      "train mean loss=0.07994331698864698\n",
      "test_test\n",
      "test mean loss=1156.888671875\n",
      "epoch 4611\n",
      "test_train\n",
      "train mean loss=0.07648095767945051\n",
      "test_test\n",
      "test mean loss=1157.301513671875\n",
      "epoch 4612\n",
      "test_train\n",
      "train mean loss=0.06636003560076158\n",
      "test_test\n",
      "test mean loss=1156.2301025390625\n",
      "epoch 4613\n",
      "test_train\n",
      "train mean loss=0.07678302299852173\n",
      "test_test\n",
      "test mean loss=1156.4013671875\n",
      "epoch 4614\n",
      "test_train\n",
      "train mean loss=0.07476470836748679\n",
      "test_test\n",
      "test mean loss=1158.1017456054688\n",
      "epoch 4615\n",
      "test_train\n",
      "train mean loss=0.07512312817076842\n",
      "test_test\n",
      "test mean loss=1157.2104187011719\n",
      "epoch 4616\n",
      "test_train\n",
      "train mean loss=0.07838551638027032\n",
      "test_test\n",
      "test mean loss=1155.68212890625\n",
      "epoch 4617\n",
      "test_train\n",
      "train mean loss=0.07584506956239541\n",
      "test_test\n",
      "test mean loss=1157.4018859863281\n",
      "epoch 4618\n",
      "test_train\n",
      "train mean loss=0.07905415538698435\n",
      "test_test\n",
      "test mean loss=1157.5773620605469\n",
      "epoch 4619\n",
      "test_train\n",
      "train mean loss=0.0818845812852184\n",
      "test_test\n",
      "test mean loss=1157.2480163574219\n",
      "epoch 4620\n",
      "test_train\n",
      "train mean loss=0.08351885930945475\n",
      "test_test\n",
      "test mean loss=1156.9688720703125\n",
      "epoch 4621\n",
      "test_train\n",
      "train mean loss=0.07973577609906594\n",
      "test_test\n",
      "test mean loss=1155.8622436523438\n",
      "epoch 4622\n",
      "test_train\n",
      "train mean loss=0.0804591824611028\n",
      "test_test\n",
      "test mean loss=1156.8502197265625\n",
      "epoch 4623\n",
      "test_train\n",
      "train mean loss=0.06551027484238148\n",
      "test_test\n",
      "test mean loss=1156.1318359375\n",
      "epoch 4624\n",
      "test_train\n",
      "train mean loss=0.0767269404605031\n",
      "test_test\n",
      "test mean loss=1157.1251220703125\n",
      "epoch 4625\n",
      "test_train\n",
      "train mean loss=0.07591692948093016\n",
      "test_test\n",
      "test mean loss=1157.0126342773438\n",
      "epoch 4626\n",
      "test_train\n",
      "train mean loss=0.07179744883129995\n",
      "test_test\n",
      "test mean loss=1156.1002807617188\n",
      "epoch 4627\n",
      "test_train\n",
      "train mean loss=0.0838325209915638\n",
      "test_test\n",
      "test mean loss=1157.3401489257812\n",
      "epoch 4628\n",
      "test_train\n",
      "train mean loss=0.07701222505420446\n",
      "test_test\n",
      "test mean loss=1156.7666320800781\n",
      "epoch 4629\n",
      "test_train\n",
      "train mean loss=0.08040527471651633\n",
      "test_test\n",
      "test mean loss=1157.231201171875\n",
      "epoch 4630\n",
      "test_train\n",
      "train mean loss=0.07466045829157035\n",
      "test_test\n",
      "test mean loss=1157.81884765625\n",
      "epoch 4631\n",
      "test_train\n",
      "train mean loss=0.07897746811310451\n",
      "test_test\n",
      "test mean loss=1157.0954284667969\n",
      "epoch 4632\n",
      "test_train\n",
      "train mean loss=0.07392272197951873\n",
      "test_test\n",
      "test mean loss=1155.9403076171875\n",
      "epoch 4633\n",
      "test_train\n",
      "train mean loss=0.0798703342055281\n",
      "test_test\n",
      "test mean loss=1156.9096374511719\n",
      "epoch 4634\n",
      "test_train\n",
      "train mean loss=0.07343062261740367\n",
      "test_test\n",
      "test mean loss=1155.1929931640625\n",
      "epoch 4635\n",
      "test_train\n",
      "train mean loss=0.0724964269126455\n",
      "test_test\n",
      "test mean loss=1156.2376098632812\n",
      "epoch 4636\n",
      "test_train\n",
      "train mean loss=0.07388454147924979\n",
      "test_test\n",
      "test mean loss=1156.7050170898438\n",
      "epoch 4637\n",
      "test_train\n",
      "train mean loss=0.07648138888180256\n",
      "test_test\n",
      "test mean loss=1157.0804443359375\n",
      "epoch 4638\n",
      "test_train\n",
      "train mean loss=0.07908299751579762\n",
      "test_test\n",
      "test mean loss=1156.9193115234375\n",
      "epoch 4639\n",
      "test_train\n",
      "train mean loss=0.0792427243043979\n",
      "test_test\n",
      "test mean loss=1156.8886108398438\n",
      "epoch 4640\n",
      "test_train\n",
      "train mean loss=0.07275688958664735\n",
      "test_test\n",
      "test mean loss=1156.637939453125\n",
      "epoch 4641\n",
      "test_train\n",
      "train mean loss=0.06870607721308868\n",
      "test_test\n",
      "test mean loss=1156.4970092773438\n",
      "epoch 4642\n",
      "test_train\n",
      "train mean loss=0.07096940620491902\n",
      "test_test\n",
      "test mean loss=1157.5370483398438\n",
      "epoch 4643\n",
      "test_train\n",
      "train mean loss=0.08227356243878603\n",
      "test_test\n",
      "test mean loss=1156.8578491210938\n",
      "epoch 4644\n",
      "test_train\n",
      "train mean loss=0.0782344580317537\n",
      "test_test\n",
      "test mean loss=1158.7316284179688\n",
      "epoch 4645\n",
      "test_train\n",
      "train mean loss=0.07071952366580565\n",
      "test_test\n",
      "test mean loss=1158.0477905273438\n",
      "epoch 4646\n",
      "test_train\n",
      "train mean loss=0.07507549536724885\n",
      "test_test\n",
      "test mean loss=1157.8057556152344\n",
      "epoch 4647\n",
      "test_train\n",
      "train mean loss=0.07247613680859406\n",
      "test_test\n",
      "test mean loss=1157.8654479980469\n",
      "epoch 4648\n",
      "test_train\n",
      "train mean loss=0.07838954652349155\n",
      "test_test\n",
      "test mean loss=1157.6228637695312\n",
      "epoch 4649\n",
      "test_train\n",
      "train mean loss=0.07548824263115723\n",
      "test_test\n",
      "test mean loss=1158.0750732421875\n",
      "epoch 4650\n",
      "test_train\n",
      "train mean loss=0.07675224697838227\n",
      "test_test\n",
      "test mean loss=1157.5619506835938\n",
      "epoch 4651\n",
      "test_train\n",
      "train mean loss=0.06677520895997684\n",
      "test_test\n",
      "test mean loss=1155.5420532226562\n",
      "epoch 4652\n",
      "test_train\n",
      "train mean loss=0.06803014532973369\n",
      "test_test\n",
      "test mean loss=1157.3030395507812\n",
      "epoch 4653\n",
      "test_train\n",
      "train mean loss=0.07407353135446708\n",
      "test_test\n",
      "test mean loss=1157.8193969726562\n",
      "epoch 4654\n",
      "test_train\n",
      "train mean loss=0.07221991599847873\n",
      "test_test\n",
      "test mean loss=1157.5161743164062\n",
      "epoch 4655\n",
      "test_train\n",
      "train mean loss=0.07259831639627616\n",
      "test_test\n",
      "test mean loss=1158.3930053710938\n",
      "epoch 4656\n",
      "test_train\n",
      "train mean loss=0.07301819697022438\n",
      "test_test\n",
      "test mean loss=1158.45751953125\n",
      "epoch 4657\n",
      "test_train\n",
      "train mean loss=0.0774087958658735\n",
      "test_test\n",
      "test mean loss=1158.5607299804688\n",
      "epoch 4658\n",
      "test_train\n",
      "train mean loss=0.08153334663559993\n",
      "test_test\n",
      "test mean loss=1157.1820678710938\n",
      "epoch 4659\n",
      "test_train\n",
      "train mean loss=0.06941160171603163\n",
      "test_test\n",
      "test mean loss=1156.2364501953125\n",
      "epoch 4660\n",
      "test_train\n",
      "train mean loss=0.07567615527659655\n",
      "test_test\n",
      "test mean loss=1157.8690185546875\n",
      "epoch 4661\n",
      "test_train\n",
      "train mean loss=0.06872830912470818\n",
      "test_test\n",
      "test mean loss=1156.2898254394531\n",
      "epoch 4662\n",
      "test_train\n",
      "train mean loss=0.07211105028788249\n",
      "test_test\n",
      "test mean loss=1156.3931274414062\n",
      "epoch 4663\n",
      "test_train\n",
      "train mean loss=0.06987400818616152\n",
      "test_test\n",
      "test mean loss=1156.906005859375\n",
      "epoch 4664\n",
      "test_train\n",
      "train mean loss=0.07082932845999797\n",
      "test_test\n",
      "test mean loss=1156.6221618652344\n",
      "epoch 4665\n",
      "test_train\n",
      "train mean loss=0.08083399912963311\n",
      "test_test\n",
      "test mean loss=1157.5275268554688\n",
      "epoch 4666\n",
      "test_train\n",
      "train mean loss=0.06966549530625343\n",
      "test_test\n",
      "test mean loss=1157.0928344726562\n",
      "epoch 4667\n",
      "test_train\n",
      "train mean loss=0.07306117750704288\n",
      "test_test\n",
      "test mean loss=1157.3933410644531\n",
      "epoch 4668\n",
      "test_train\n",
      "train mean loss=0.07886766052494447\n",
      "test_test\n",
      "test mean loss=1157.9207458496094\n",
      "epoch 4669\n",
      "test_train\n",
      "train mean loss=0.07995704840868711\n",
      "test_test\n",
      "test mean loss=1157.3595581054688\n",
      "epoch 4670\n",
      "test_train\n",
      "train mean loss=0.46875303735335666\n",
      "test_test\n",
      "test mean loss=1158.543701171875\n",
      "epoch 4671\n",
      "test_train\n",
      "train mean loss=0.11029689945280552\n",
      "test_test\n",
      "test mean loss=1155.2122192382812\n",
      "epoch 4672\n",
      "test_train\n",
      "train mean loss=0.07866451268394788\n",
      "test_test\n",
      "test mean loss=1156.146728515625\n",
      "epoch 4673\n",
      "test_train\n",
      "train mean loss=0.0756791237120827\n",
      "test_test\n",
      "test mean loss=1156.6689453125\n",
      "epoch 4674\n",
      "test_train\n",
      "train mean loss=0.07733368283758561\n",
      "test_test\n",
      "test mean loss=1157.1788940429688\n",
      "epoch 4675\n",
      "test_train\n",
      "train mean loss=0.07445327378809452\n",
      "test_test\n",
      "test mean loss=1155.5023193359375\n",
      "epoch 4676\n",
      "test_train\n",
      "train mean loss=0.08936026878654957\n",
      "test_test\n",
      "test mean loss=1157.740966796875\n",
      "epoch 4677\n",
      "test_train\n",
      "train mean loss=0.07684974434475104\n",
      "test_test\n",
      "test mean loss=1157.5667724609375\n",
      "epoch 4678\n",
      "test_train\n",
      "train mean loss=0.07098099527259667\n",
      "test_test\n",
      "test mean loss=1156.8253784179688\n",
      "epoch 4679\n",
      "test_train\n",
      "train mean loss=0.07790461524079244\n",
      "test_test\n",
      "test mean loss=1156.8419799804688\n",
      "epoch 4680\n",
      "test_train\n",
      "train mean loss=0.06703554621587197\n",
      "test_test\n",
      "test mean loss=1157.2891235351562\n",
      "epoch 4681\n",
      "test_train\n",
      "train mean loss=0.1065495926886797\n",
      "test_test\n",
      "test mean loss=1157.40185546875\n",
      "epoch 4682\n",
      "test_train\n",
      "train mean loss=0.08545561165859301\n",
      "test_test\n",
      "test mean loss=1157.4688110351562\n",
      "epoch 4683\n",
      "test_train\n",
      "train mean loss=0.0805124727388223\n",
      "test_test\n",
      "test mean loss=1158.8450317382812\n",
      "epoch 4684\n",
      "test_train\n",
      "train mean loss=0.07194286709030469\n",
      "test_test\n",
      "test mean loss=1157.1878662109375\n",
      "epoch 4685\n",
      "test_train\n",
      "train mean loss=0.06845041612784068\n",
      "test_test\n",
      "test mean loss=1157.4471435546875\n",
      "epoch 4686\n",
      "test_train\n",
      "train mean loss=0.09266674518585205\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1157.4840087890625\n",
      "epoch 4687\n",
      "test_train\n",
      "train mean loss=0.07150656916201115\n",
      "test_test\n",
      "test mean loss=1157.6056518554688\n",
      "epoch 4688\n",
      "test_train\n",
      "train mean loss=0.08233936162044604\n",
      "test_test\n",
      "test mean loss=1158.3692016601562\n",
      "epoch 4689\n",
      "test_train\n",
      "train mean loss=0.08160648960620165\n",
      "test_test\n",
      "test mean loss=1159.2597961425781\n",
      "epoch 4690\n",
      "test_train\n",
      "train mean loss=0.07346128486096859\n",
      "test_test\n",
      "test mean loss=1156.5538024902344\n",
      "epoch 4691\n",
      "test_train\n",
      "train mean loss=0.07348812030007441\n",
      "test_test\n",
      "test mean loss=1156.7579650878906\n",
      "epoch 4692\n",
      "test_train\n",
      "train mean loss=0.07627342641353607\n",
      "test_test\n",
      "test mean loss=1158.1264038085938\n",
      "epoch 4693\n",
      "test_train\n",
      "train mean loss=0.07808290918668111\n",
      "test_test\n",
      "test mean loss=1157.22119140625\n",
      "epoch 4694\n",
      "test_train\n",
      "train mean loss=0.07109879578153293\n",
      "test_test\n",
      "test mean loss=1157.2785034179688\n",
      "epoch 4695\n",
      "test_train\n",
      "train mean loss=0.06989726765702169\n",
      "test_test\n",
      "test mean loss=1156.6933288574219\n",
      "epoch 4696\n",
      "test_train\n",
      "train mean loss=0.07592871319502592\n",
      "test_test\n",
      "test mean loss=1158.2018432617188\n",
      "epoch 4697\n",
      "test_train\n",
      "train mean loss=0.06940420375516017\n",
      "test_test\n",
      "test mean loss=1158.8208618164062\n",
      "epoch 4698\n",
      "test_train\n",
      "train mean loss=0.08046522364020348\n",
      "test_test\n",
      "test mean loss=1159.335205078125\n",
      "epoch 4699\n",
      "test_train\n",
      "train mean loss=0.07557408853123586\n",
      "test_test\n",
      "test mean loss=1158.64453125\n",
      "epoch 4700\n",
      "test_train\n",
      "train mean loss=0.07063770014792681\n",
      "test_test\n",
      "test mean loss=1158.299072265625\n",
      "epoch 4701\n",
      "test_train\n",
      "train mean loss=0.07138647014896075\n",
      "test_test\n",
      "test mean loss=1157.9779052734375\n",
      "epoch 4702\n",
      "test_train\n",
      "train mean loss=0.06863609949747722\n",
      "test_test\n",
      "test mean loss=1158.7280883789062\n",
      "epoch 4703\n",
      "test_train\n",
      "train mean loss=0.07468986697494984\n",
      "test_test\n",
      "test mean loss=1158.1319885253906\n",
      "epoch 4704\n",
      "test_train\n",
      "train mean loss=0.07720845254758994\n",
      "test_test\n",
      "test mean loss=1158.2589416503906\n",
      "epoch 4705\n",
      "test_train\n",
      "train mean loss=0.0719783032933871\n",
      "test_test\n",
      "test mean loss=1157.2315673828125\n",
      "epoch 4706\n",
      "test_train\n",
      "train mean loss=0.07309920340776443\n",
      "test_test\n",
      "test mean loss=1157.9826049804688\n",
      "epoch 4707\n",
      "test_train\n",
      "train mean loss=0.07956098454693954\n",
      "test_test\n",
      "test mean loss=1157.7578125\n",
      "epoch 4708\n",
      "test_train\n",
      "train mean loss=0.08224093355238438\n",
      "test_test\n",
      "test mean loss=1158.4465942382812\n",
      "epoch 4709\n",
      "test_train\n",
      "train mean loss=0.07017367146909237\n",
      "test_test\n",
      "test mean loss=1157.4024963378906\n",
      "epoch 4710\n",
      "test_train\n",
      "train mean loss=0.07283673683802287\n",
      "test_test\n",
      "test mean loss=1157.1775817871094\n",
      "epoch 4711\n",
      "test_train\n",
      "train mean loss=0.07549658045172691\n",
      "test_test\n",
      "test mean loss=1158.2991638183594\n",
      "epoch 4712\n",
      "test_train\n",
      "train mean loss=0.07297029066830873\n",
      "test_test\n",
      "test mean loss=1159.2421264648438\n",
      "epoch 4713\n",
      "test_train\n",
      "train mean loss=0.06756609647224347\n",
      "test_test\n",
      "test mean loss=1158.8544921875\n",
      "epoch 4714\n",
      "test_train\n",
      "train mean loss=0.06959265408416589\n",
      "test_test\n",
      "test mean loss=1157.6895751953125\n",
      "epoch 4715\n",
      "test_train\n",
      "train mean loss=0.06567063337812822\n",
      "test_test\n",
      "test mean loss=1158.328369140625\n",
      "epoch 4716\n",
      "test_train\n",
      "train mean loss=0.07422057011475165\n",
      "test_test\n",
      "test mean loss=1158.1657409667969\n",
      "epoch 4717\n",
      "test_train\n",
      "train mean loss=0.08254148159176111\n",
      "test_test\n",
      "test mean loss=1159.3248596191406\n",
      "epoch 4718\n",
      "test_train\n",
      "train mean loss=0.0822145923351248\n",
      "test_test\n",
      "test mean loss=1157.5418090820312\n",
      "epoch 4719\n",
      "test_train\n",
      "train mean loss=0.0751211146513621\n",
      "test_test\n",
      "test mean loss=1159.3641662597656\n",
      "epoch 4720\n",
      "test_train\n",
      "train mean loss=0.07609367401649554\n",
      "test_test\n",
      "test mean loss=1158.8272399902344\n",
      "epoch 4721\n",
      "test_train\n",
      "train mean loss=0.08031768817454576\n",
      "test_test\n",
      "test mean loss=1157.9138793945312\n",
      "epoch 4722\n",
      "test_train\n",
      "train mean loss=0.07567274818817775\n",
      "test_test\n",
      "test mean loss=1158.0918579101562\n",
      "epoch 4723\n",
      "test_train\n",
      "train mean loss=0.06799587327986956\n",
      "test_test\n",
      "test mean loss=1158.0012817382812\n",
      "epoch 4724\n",
      "test_train\n",
      "train mean loss=0.07510011208554108\n",
      "test_test\n",
      "test mean loss=1158.4904479980469\n",
      "epoch 4725\n",
      "test_train\n",
      "train mean loss=0.0790655209372441\n",
      "test_test\n",
      "test mean loss=1158.9518432617188\n",
      "epoch 4726\n",
      "test_train\n",
      "train mean loss=0.07623747736215591\n",
      "test_test\n",
      "test mean loss=1158.781005859375\n",
      "epoch 4727\n",
      "test_train\n",
      "train mean loss=0.07941909910490115\n",
      "test_test\n",
      "test mean loss=1158.462158203125\n",
      "epoch 4728\n",
      "test_train\n",
      "train mean loss=0.08045499306172132\n",
      "test_test\n",
      "test mean loss=1158.744384765625\n",
      "epoch 4729\n",
      "test_train\n",
      "train mean loss=0.0723397151256601\n",
      "test_test\n",
      "test mean loss=1157.730712890625\n",
      "epoch 4730\n",
      "test_train\n",
      "train mean loss=0.07607874025901158\n",
      "test_test\n",
      "test mean loss=1158.04736328125\n",
      "epoch 4731\n",
      "test_train\n",
      "train mean loss=0.07080066669732332\n",
      "test_test\n",
      "test mean loss=1157.4451293945312\n",
      "epoch 4732\n",
      "test_train\n",
      "train mean loss=0.06917260897656281\n",
      "test_test\n",
      "test mean loss=1157.0803833007812\n",
      "epoch 4733\n",
      "test_train\n",
      "train mean loss=0.07176771480590105\n",
      "test_test\n",
      "test mean loss=1158.4540405273438\n",
      "epoch 4734\n",
      "test_train\n",
      "train mean loss=0.07342284995441635\n",
      "test_test\n",
      "test mean loss=1158.7939147949219\n",
      "epoch 4735\n",
      "test_train\n",
      "train mean loss=0.07334793296953042\n",
      "test_test\n",
      "test mean loss=1157.8039855957031\n",
      "epoch 4736\n",
      "test_train\n",
      "train mean loss=0.07785883980492751\n",
      "test_test\n",
      "test mean loss=1158.7350769042969\n",
      "epoch 4737\n",
      "test_train\n",
      "train mean loss=0.06987025992323954\n",
      "test_test\n",
      "test mean loss=1157.7838745117188\n",
      "epoch 4738\n",
      "test_train\n",
      "train mean loss=0.06721814100941022\n",
      "test_test\n",
      "test mean loss=1157.8175659179688\n",
      "epoch 4739\n",
      "test_train\n",
      "train mean loss=0.06734911880145471\n",
      "test_test\n",
      "test mean loss=1157.0121459960938\n",
      "epoch 4740\n",
      "test_train\n",
      "train mean loss=0.06865175440907478\n",
      "test_test\n",
      "test mean loss=1157.5585632324219\n",
      "epoch 4741\n",
      "test_train\n",
      "train mean loss=0.07678349036723375\n",
      "test_test\n",
      "test mean loss=1157.678466796875\n",
      "epoch 4742\n",
      "test_train\n",
      "train mean loss=0.07259973604232073\n",
      "test_test\n",
      "test mean loss=1158.0762634277344\n",
      "epoch 4743\n",
      "test_train\n",
      "train mean loss=0.08245895182092984\n",
      "test_test\n",
      "test mean loss=1158.7130126953125\n",
      "epoch 4744\n",
      "test_train\n",
      "train mean loss=0.07642283445845048\n",
      "test_test\n",
      "test mean loss=1157.9592895507812\n",
      "epoch 4745\n",
      "test_train\n",
      "train mean loss=0.07213129941374063\n",
      "test_test\n",
      "test mean loss=1158.2410888671875\n",
      "epoch 4746\n",
      "test_train\n",
      "train mean loss=0.07224581856280565\n",
      "test_test\n",
      "test mean loss=1157.2168579101562\n",
      "epoch 4747\n",
      "test_train\n",
      "train mean loss=0.07597678992897272\n",
      "test_test\n",
      "test mean loss=1157.6517944335938\n",
      "epoch 4748\n",
      "test_train\n",
      "train mean loss=0.07563684446116288\n",
      "test_test\n",
      "test mean loss=1158.3712463378906\n",
      "epoch 4749\n",
      "test_train\n",
      "train mean loss=0.07042472716420889\n",
      "test_test\n",
      "test mean loss=1158.0927124023438\n",
      "epoch 4750\n",
      "test_train\n",
      "train mean loss=0.07621426973491907\n",
      "test_test\n",
      "test mean loss=1158.0106201171875\n",
      "epoch 4751\n",
      "test_train\n",
      "train mean loss=0.07500942579160134\n",
      "test_test\n",
      "test mean loss=1157.5075073242188\n",
      "epoch 4752\n",
      "test_train\n",
      "train mean loss=0.08000220606724422\n",
      "test_test\n",
      "test mean loss=1157.2400817871094\n",
      "epoch 4753\n",
      "test_train\n",
      "train mean loss=0.07981883082538843\n",
      "test_test\n",
      "test mean loss=1158.1337280273438\n",
      "epoch 4754\n",
      "test_train\n",
      "train mean loss=0.08531349555899699\n",
      "test_test\n",
      "test mean loss=1158.5855712890625\n",
      "epoch 4755\n",
      "test_train\n",
      "train mean loss=0.07776294865955909\n",
      "test_test\n",
      "test mean loss=1157.0706787109375\n",
      "epoch 4756\n",
      "test_train\n",
      "train mean loss=0.06869470980018377\n",
      "test_test\n",
      "test mean loss=1156.7227172851562\n",
      "epoch 4757\n",
      "test_train\n",
      "train mean loss=0.07116879181315501\n",
      "test_test\n",
      "test mean loss=1157.2412414550781\n",
      "epoch 4758\n",
      "test_train\n",
      "train mean loss=0.07209629255036513\n",
      "test_test\n",
      "test mean loss=1157.8683776855469\n",
      "epoch 4759\n",
      "test_train\n",
      "train mean loss=0.0754121458157897\n",
      "test_test\n",
      "test mean loss=1157.1614074707031\n",
      "epoch 4760\n",
      "test_train\n",
      "train mean loss=0.07583179480085771\n",
      "test_test\n",
      "test mean loss=1157.7807006835938\n",
      "epoch 4761\n",
      "test_train\n",
      "train mean loss=0.07216809627910455\n",
      "test_test\n",
      "test mean loss=1156.626953125\n",
      "epoch 4762\n",
      "test_train\n",
      "train mean loss=0.07093215050796668\n",
      "test_test\n",
      "test mean loss=1156.1937255859375\n",
      "epoch 4763\n",
      "test_train\n",
      "train mean loss=0.07509678105513255\n",
      "test_test\n",
      "test mean loss=1157.1892700195312\n",
      "epoch 4764\n",
      "test_train\n",
      "train mean loss=0.07468615736191471\n",
      "test_test\n",
      "test mean loss=1157.4015808105469\n",
      "epoch 4765\n",
      "test_train\n",
      "train mean loss=0.07908519419531028\n",
      "test_test\n",
      "test mean loss=1157.3093566894531\n",
      "epoch 4766\n",
      "test_train\n",
      "train mean loss=0.07763054594397545\n",
      "test_test\n",
      "test mean loss=1158.0587768554688\n",
      "epoch 4767\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.07165431541701157\n",
      "test_test\n",
      "test mean loss=1155.96484375\n",
      "epoch 4768\n",
      "test_train\n",
      "train mean loss=0.07304017245769501\n",
      "test_test\n",
      "test mean loss=1157.0504455566406\n",
      "epoch 4769\n",
      "test_train\n",
      "train mean loss=0.06937999681880076\n",
      "test_test\n",
      "test mean loss=1157.1859130859375\n",
      "epoch 4770\n",
      "test_train\n",
      "train mean loss=0.07303417939692736\n",
      "test_test\n",
      "test mean loss=1156.6946105957031\n",
      "epoch 4771\n",
      "test_train\n",
      "train mean loss=0.07598304562270641\n",
      "test_test\n",
      "test mean loss=1157.3125305175781\n",
      "epoch 4772\n",
      "test_train\n",
      "train mean loss=0.07651988261689742\n",
      "test_test\n",
      "test mean loss=1157.0523681640625\n",
      "epoch 4773\n",
      "test_train\n",
      "train mean loss=0.08055727339039247\n",
      "test_test\n",
      "test mean loss=1157.4658203125\n",
      "epoch 4774\n",
      "test_train\n",
      "train mean loss=0.08047009600947301\n",
      "test_test\n",
      "test mean loss=1158.2442626953125\n",
      "epoch 4775\n",
      "test_train\n",
      "train mean loss=0.0850187096123894\n",
      "test_test\n",
      "test mean loss=1157.9119567871094\n",
      "epoch 4776\n",
      "test_train\n",
      "train mean loss=0.06954924700160821\n",
      "test_test\n",
      "test mean loss=1156.9197387695312\n",
      "epoch 4777\n",
      "test_train\n",
      "train mean loss=0.06885582270721595\n",
      "test_test\n",
      "test mean loss=1157.6710205078125\n",
      "epoch 4778\n",
      "test_train\n",
      "train mean loss=0.07813223389287789\n",
      "test_test\n",
      "test mean loss=1158.5826416015625\n",
      "epoch 4779\n",
      "test_train\n",
      "train mean loss=0.07226888152460258\n",
      "test_test\n",
      "test mean loss=1157.3812255859375\n",
      "epoch 4780\n",
      "test_train\n",
      "train mean loss=0.07133098940054576\n",
      "test_test\n",
      "test mean loss=1156.9754638671875\n",
      "epoch 4781\n",
      "test_train\n",
      "train mean loss=0.06663613921652238\n",
      "test_test\n",
      "test mean loss=1158.112060546875\n",
      "epoch 4782\n",
      "test_train\n",
      "train mean loss=0.0719757021094362\n",
      "test_test\n",
      "test mean loss=1158.1099853515625\n",
      "epoch 4783\n",
      "test_train\n",
      "train mean loss=0.08779390559842189\n",
      "test_test\n",
      "test mean loss=1159.847412109375\n",
      "epoch 4784\n",
      "test_train\n",
      "train mean loss=0.09877250095208485\n",
      "test_test\n",
      "test mean loss=1155.8695678710938\n",
      "epoch 4785\n",
      "test_train\n",
      "train mean loss=0.07916174301256736\n",
      "test_test\n",
      "test mean loss=1156.2442321777344\n",
      "epoch 4786\n",
      "test_train\n",
      "train mean loss=0.07734513003379107\n",
      "test_test\n",
      "test mean loss=1157.239990234375\n",
      "epoch 4787\n",
      "test_train\n",
      "train mean loss=0.0767107739423712\n",
      "test_test\n",
      "test mean loss=1158.3290405273438\n",
      "epoch 4788\n",
      "test_train\n",
      "train mean loss=0.06809051272769769\n",
      "test_test\n",
      "test mean loss=1157.4944458007812\n",
      "epoch 4789\n",
      "test_train\n",
      "train mean loss=0.0739186117425561\n",
      "test_test\n",
      "test mean loss=1157.6087646484375\n",
      "epoch 4790\n",
      "test_train\n",
      "train mean loss=0.06818302627652884\n",
      "test_test\n",
      "test mean loss=1156.6815795898438\n",
      "epoch 4791\n",
      "test_train\n",
      "train mean loss=0.07270299022396405\n",
      "test_test\n",
      "test mean loss=1157.3026123046875\n",
      "epoch 4792\n",
      "test_train\n",
      "train mean loss=0.07512498460710049\n",
      "test_test\n",
      "test mean loss=1157.8639526367188\n",
      "epoch 4793\n",
      "test_train\n",
      "train mean loss=0.07346120957906048\n",
      "test_test\n",
      "test mean loss=1157.9680480957031\n",
      "epoch 4794\n",
      "test_train\n",
      "train mean loss=0.07468826199571292\n",
      "test_test\n",
      "test mean loss=1157.88330078125\n",
      "epoch 4795\n",
      "test_train\n",
      "train mean loss=0.06784323199341695\n",
      "test_test\n",
      "test mean loss=1157.4620666503906\n",
      "epoch 4796\n",
      "test_train\n",
      "train mean loss=0.07040745330353577\n",
      "test_test\n",
      "test mean loss=1157.9266967773438\n",
      "epoch 4797\n",
      "test_train\n",
      "train mean loss=0.07485868874937296\n",
      "test_test\n",
      "test mean loss=1156.7846374511719\n",
      "epoch 4798\n",
      "test_train\n",
      "train mean loss=0.07428903287897508\n",
      "test_test\n",
      "test mean loss=1157.5592651367188\n",
      "epoch 4799\n",
      "test_train\n",
      "train mean loss=0.06885803878928225\n",
      "test_test\n",
      "test mean loss=1157.1197509765625\n",
      "epoch 4800\n",
      "test_train\n",
      "train mean loss=0.06762680597603321\n",
      "test_test\n",
      "test mean loss=1156.0399169921875\n",
      "epoch 4801\n",
      "test_train\n",
      "train mean loss=0.07200087420642376\n",
      "test_test\n",
      "test mean loss=1156.0450439453125\n",
      "epoch 4802\n",
      "test_train\n",
      "train mean loss=0.07232044202586015\n",
      "test_test\n",
      "test mean loss=1156.69384765625\n",
      "epoch 4803\n",
      "test_train\n",
      "train mean loss=0.07329253324617942\n",
      "test_test\n",
      "test mean loss=1156.9138793945312\n",
      "epoch 4804\n",
      "test_train\n",
      "train mean loss=0.07724041026085615\n",
      "test_test\n",
      "test mean loss=1156.9077758789062\n",
      "epoch 4805\n",
      "test_train\n",
      "train mean loss=0.07532741067310174\n",
      "test_test\n",
      "test mean loss=1155.5511474609375\n",
      "epoch 4806\n",
      "test_train\n",
      "train mean loss=0.07159709930419922\n",
      "test_test\n",
      "test mean loss=1156.8021850585938\n",
      "epoch 4807\n",
      "test_train\n",
      "train mean loss=0.07366226458301146\n",
      "test_test\n",
      "test mean loss=1157.0043334960938\n",
      "epoch 4808\n",
      "test_train\n",
      "train mean loss=0.07334029860794544\n",
      "test_test\n",
      "test mean loss=1157.5187377929688\n",
      "epoch 4809\n",
      "test_train\n",
      "train mean loss=0.0784848453477025\n",
      "test_test\n",
      "test mean loss=1156.6640625\n",
      "epoch 4810\n",
      "test_train\n",
      "train mean loss=0.07995741255581379\n",
      "test_test\n",
      "test mean loss=1156.7379760742188\n",
      "epoch 4811\n",
      "test_train\n",
      "train mean loss=0.07895282159248988\n",
      "test_test\n",
      "test mean loss=1157.1390380859375\n",
      "epoch 4812\n",
      "test_train\n",
      "train mean loss=0.07281784216562907\n",
      "test_test\n",
      "test mean loss=1156.8353271484375\n",
      "epoch 4813\n",
      "test_train\n",
      "train mean loss=0.06984463753178716\n",
      "test_test\n",
      "test mean loss=1156.5110473632812\n",
      "epoch 4814\n",
      "test_train\n",
      "train mean loss=0.06957703859855731\n",
      "test_test\n",
      "test mean loss=1156.8146362304688\n",
      "epoch 4815\n",
      "test_train\n",
      "train mean loss=0.0714618864779671\n",
      "test_test\n",
      "test mean loss=1156.3308715820312\n",
      "epoch 4816\n",
      "test_train\n",
      "train mean loss=0.07707249497373898\n",
      "test_test\n",
      "test mean loss=1157.1222534179688\n",
      "epoch 4817\n",
      "test_train\n",
      "train mean loss=0.0743767141054074\n",
      "test_test\n",
      "test mean loss=1157.146484375\n",
      "epoch 4818\n",
      "test_train\n",
      "train mean loss=0.07857250329107046\n",
      "test_test\n",
      "test mean loss=1157.2454528808594\n",
      "epoch 4819\n",
      "test_train\n",
      "train mean loss=0.07549197599291801\n",
      "test_test\n",
      "test mean loss=1156.3148803710938\n",
      "epoch 4820\n",
      "test_train\n",
      "train mean loss=0.07413103586683671\n",
      "test_test\n",
      "test mean loss=1156.9100952148438\n",
      "epoch 4821\n",
      "test_train\n",
      "train mean loss=0.08386891148984432\n",
      "test_test\n",
      "test mean loss=1158.1022338867188\n",
      "epoch 4822\n",
      "test_train\n",
      "train mean loss=0.07936475084473689\n",
      "test_test\n",
      "test mean loss=1158.819091796875\n",
      "epoch 4823\n",
      "test_train\n",
      "train mean loss=0.07178906351327896\n",
      "test_test\n",
      "test mean loss=1157.8882141113281\n",
      "epoch 4824\n",
      "test_train\n",
      "train mean loss=0.07344834847996633\n",
      "test_test\n",
      "test mean loss=1156.6846313476562\n",
      "epoch 4825\n",
      "test_train\n",
      "train mean loss=0.07135055772960186\n",
      "test_test\n",
      "test mean loss=1158.2698669433594\n",
      "epoch 4826\n",
      "test_train\n",
      "train mean loss=0.07204492079714934\n",
      "test_test\n",
      "test mean loss=1158.7283325195312\n",
      "epoch 4827\n",
      "test_train\n",
      "train mean loss=0.07403082028031349\n",
      "test_test\n",
      "test mean loss=1158.7839965820312\n",
      "epoch 4828\n",
      "test_train\n",
      "train mean loss=0.08354863276084264\n",
      "test_test\n",
      "test mean loss=1159.0555419921875\n",
      "epoch 4829\n",
      "test_train\n",
      "train mean loss=0.07582023988167445\n",
      "test_test\n",
      "test mean loss=1158.34716796875\n",
      "epoch 4830\n",
      "test_train\n",
      "train mean loss=0.07531348057091236\n",
      "test_test\n",
      "test mean loss=1157.8145141601562\n",
      "epoch 4831\n",
      "test_train\n",
      "train mean loss=0.08111081862201293\n",
      "test_test\n",
      "test mean loss=1157.5490112304688\n",
      "epoch 4832\n",
      "test_train\n",
      "train mean loss=0.07887604211767514\n",
      "test_test\n",
      "test mean loss=1158.6553039550781\n",
      "epoch 4833\n",
      "test_train\n",
      "train mean loss=0.07069032359868288\n",
      "test_test\n",
      "test mean loss=1158.62255859375\n",
      "epoch 4834\n",
      "test_train\n",
      "train mean loss=0.07533019781112671\n",
      "test_test\n",
      "test mean loss=1159.0580139160156\n",
      "epoch 4835\n",
      "test_train\n",
      "train mean loss=0.07031181392570336\n",
      "test_test\n",
      "test mean loss=1158.0937805175781\n",
      "epoch 4836\n",
      "test_train\n",
      "train mean loss=0.07241279693941276\n",
      "test_test\n",
      "test mean loss=1158.3131713867188\n",
      "epoch 4837\n",
      "test_train\n",
      "train mean loss=0.06505921203643084\n",
      "test_test\n",
      "test mean loss=1157.3484497070312\n",
      "epoch 4838\n",
      "test_train\n",
      "train mean loss=0.066780351412793\n",
      "test_test\n",
      "test mean loss=1159.0158081054688\n",
      "epoch 4839\n",
      "test_train\n",
      "train mean loss=0.07523632204780976\n",
      "test_test\n",
      "test mean loss=1159.2291564941406\n",
      "epoch 4840\n",
      "test_train\n",
      "train mean loss=0.08111098501831293\n",
      "test_test\n",
      "test mean loss=1159.251708984375\n",
      "epoch 4841\n",
      "test_train\n",
      "train mean loss=0.07340872474014759\n",
      "test_test\n",
      "test mean loss=1157.591796875\n",
      "epoch 4842\n",
      "test_train\n",
      "train mean loss=0.07593738939613104\n",
      "test_test\n",
      "test mean loss=1158.4762573242188\n",
      "epoch 4843\n",
      "test_train\n",
      "train mean loss=0.07004277501255274\n",
      "test_test\n",
      "test mean loss=1158.4446411132812\n",
      "epoch 4844\n",
      "test_train\n",
      "train mean loss=0.06932187887529533\n",
      "test_test\n",
      "test mean loss=1158.05712890625\n",
      "epoch 4845\n",
      "test_train\n",
      "train mean loss=0.06430252858748038\n",
      "test_test\n",
      "test mean loss=1158.2525024414062\n",
      "epoch 4846\n",
      "test_train\n",
      "train mean loss=0.06486686194936435\n",
      "test_test\n",
      "test mean loss=1157.9747924804688\n",
      "epoch 4847\n",
      "test_train\n",
      "train mean loss=0.07281611828754346\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1158.8185119628906\n",
      "epoch 4848\n",
      "test_train\n",
      "train mean loss=0.07120136637240648\n",
      "test_test\n",
      "test mean loss=1159.0699462890625\n",
      "epoch 4849\n",
      "test_train\n",
      "train mean loss=0.06976461472610633\n",
      "test_test\n",
      "test mean loss=1156.5587158203125\n",
      "epoch 4850\n",
      "test_train\n",
      "train mean loss=0.07469264573107164\n",
      "test_test\n",
      "test mean loss=1158.9681396484375\n",
      "epoch 4851\n",
      "test_train\n",
      "train mean loss=0.07049629775186379\n",
      "test_test\n",
      "test mean loss=1158.8040771484375\n",
      "epoch 4852\n",
      "test_train\n",
      "train mean loss=0.06852164398878813\n",
      "test_test\n",
      "test mean loss=1158.8203125\n",
      "epoch 4853\n",
      "test_train\n",
      "train mean loss=0.0637030905733506\n",
      "test_test\n",
      "test mean loss=1158.8800964355469\n",
      "epoch 4854\n",
      "test_train\n",
      "train mean loss=0.06722372770309448\n",
      "test_test\n",
      "test mean loss=1158.7470092773438\n",
      "epoch 4855\n",
      "test_train\n",
      "train mean loss=0.06976103161772092\n",
      "test_test\n",
      "test mean loss=1158.4680786132812\n",
      "epoch 4856\n",
      "test_train\n",
      "train mean loss=0.07133826085676749\n",
      "test_test\n",
      "test mean loss=1158.41357421875\n",
      "epoch 4857\n",
      "test_train\n",
      "train mean loss=0.07769375015050173\n",
      "test_test\n",
      "test mean loss=1158.8377685546875\n",
      "epoch 4858\n",
      "test_train\n",
      "train mean loss=0.08305819674084584\n",
      "test_test\n",
      "test mean loss=1156.6221008300781\n",
      "epoch 4859\n",
      "test_train\n",
      "train mean loss=0.07149932657678922\n",
      "test_test\n",
      "test mean loss=1158.297607421875\n",
      "epoch 4860\n",
      "test_train\n",
      "train mean loss=0.06938845695306857\n",
      "test_test\n",
      "test mean loss=1158.2493591308594\n",
      "epoch 4861\n",
      "test_train\n",
      "train mean loss=0.07703985956807931\n",
      "test_test\n",
      "test mean loss=1158.5858459472656\n",
      "epoch 4862\n",
      "test_train\n",
      "train mean loss=0.0665019170070688\n",
      "test_test\n",
      "test mean loss=1157.410400390625\n",
      "epoch 4863\n",
      "test_train\n",
      "train mean loss=0.07326351230343182\n",
      "test_test\n",
      "test mean loss=1158.3933410644531\n",
      "epoch 4864\n",
      "test_train\n",
      "train mean loss=0.0746675431728363\n",
      "test_test\n",
      "test mean loss=1158.1328125\n",
      "epoch 4865\n",
      "test_train\n",
      "train mean loss=0.07000662603725989\n",
      "test_test\n",
      "test mean loss=1157.5729370117188\n",
      "epoch 4866\n",
      "test_train\n",
      "train mean loss=0.08052227490892012\n",
      "test_test\n",
      "test mean loss=1158.6752624511719\n",
      "epoch 4867\n",
      "test_train\n",
      "train mean loss=0.06960417951146762\n",
      "test_test\n",
      "test mean loss=1158.4882202148438\n",
      "epoch 4868\n",
      "test_train\n",
      "train mean loss=0.07794423711796601\n",
      "test_test\n",
      "test mean loss=1158.6090087890625\n",
      "epoch 4869\n",
      "test_train\n",
      "train mean loss=0.07297352515161037\n",
      "test_test\n",
      "test mean loss=1157.6950988769531\n",
      "epoch 4870\n",
      "test_train\n",
      "train mean loss=0.07227770642687877\n",
      "test_test\n",
      "test mean loss=1156.972412109375\n",
      "epoch 4871\n",
      "test_train\n",
      "train mean loss=0.06834160257130861\n",
      "test_test\n",
      "test mean loss=1157.9688415527344\n",
      "epoch 4872\n",
      "test_train\n",
      "train mean loss=0.06239398196339607\n",
      "test_test\n",
      "test mean loss=1156.8446044921875\n",
      "epoch 4873\n",
      "test_train\n",
      "train mean loss=0.0728300716727972\n",
      "test_test\n",
      "test mean loss=1157.827392578125\n",
      "epoch 4874\n",
      "test_train\n",
      "train mean loss=0.06568554323166609\n",
      "test_test\n",
      "test mean loss=1157.6979370117188\n",
      "epoch 4875\n",
      "test_train\n",
      "train mean loss=0.06559861358255148\n",
      "test_test\n",
      "test mean loss=1157.5136413574219\n",
      "epoch 4876\n",
      "test_train\n",
      "train mean loss=0.06882404411832492\n",
      "test_test\n",
      "test mean loss=1157.2722778320312\n",
      "epoch 4877\n",
      "test_train\n",
      "train mean loss=0.06915953724334638\n",
      "test_test\n",
      "test mean loss=1157.1661376953125\n",
      "epoch 4878\n",
      "test_train\n",
      "train mean loss=0.06787215297420819\n",
      "test_test\n",
      "test mean loss=1156.7305297851562\n",
      "epoch 4879\n",
      "test_train\n",
      "train mean loss=0.06626669876277447\n",
      "test_test\n",
      "test mean loss=1157.3871459960938\n",
      "epoch 4880\n",
      "test_train\n",
      "train mean loss=0.06863842128465573\n",
      "test_test\n",
      "test mean loss=1156.6507568359375\n",
      "epoch 4881\n",
      "test_train\n",
      "train mean loss=0.07088528294116259\n",
      "test_test\n",
      "test mean loss=1156.7102661132812\n",
      "epoch 4882\n",
      "test_train\n",
      "train mean loss=0.08006877514223258\n",
      "test_test\n",
      "test mean loss=1157.6838989257812\n",
      "epoch 4883\n",
      "test_train\n",
      "train mean loss=0.07536957412958145\n",
      "test_test\n",
      "test mean loss=1157.5166625976562\n",
      "epoch 4884\n",
      "test_train\n",
      "train mean loss=0.07617433834820986\n",
      "test_test\n",
      "test mean loss=1158.1670532226562\n",
      "epoch 4885\n",
      "test_train\n",
      "train mean loss=0.0772990236679713\n",
      "test_test\n",
      "test mean loss=1156.6166381835938\n",
      "epoch 4886\n",
      "test_train\n",
      "train mean loss=0.06826007335136335\n",
      "test_test\n",
      "test mean loss=1157.082763671875\n",
      "epoch 4887\n",
      "test_train\n",
      "train mean loss=0.07289580783496301\n",
      "test_test\n",
      "test mean loss=1158.4329223632812\n",
      "epoch 4888\n",
      "test_train\n",
      "train mean loss=0.07308126334100962\n",
      "test_test\n",
      "test mean loss=1157.1419677734375\n",
      "epoch 4889\n",
      "test_train\n",
      "train mean loss=0.06224520318210125\n",
      "test_test\n",
      "test mean loss=1156.50146484375\n",
      "epoch 4890\n",
      "test_train\n",
      "train mean loss=0.0697504331668218\n",
      "test_test\n",
      "test mean loss=1157.5014953613281\n",
      "epoch 4891\n",
      "test_train\n",
      "train mean loss=0.06871746232112248\n",
      "test_test\n",
      "test mean loss=1157.3969116210938\n",
      "epoch 4892\n",
      "test_train\n",
      "train mean loss=0.06742506722609203\n",
      "test_test\n",
      "test mean loss=1157.4106140136719\n",
      "epoch 4893\n",
      "test_train\n",
      "train mean loss=0.0705467148994406\n",
      "test_test\n",
      "test mean loss=1156.4708557128906\n",
      "epoch 4894\n",
      "test_train\n",
      "train mean loss=0.06825230410322547\n",
      "test_test\n",
      "test mean loss=1157.24658203125\n",
      "epoch 4895\n",
      "test_train\n",
      "train mean loss=0.06872730624551575\n",
      "test_test\n",
      "test mean loss=1157.9647827148438\n",
      "epoch 4896\n",
      "test_train\n",
      "train mean loss=0.06977946621676286\n",
      "test_test\n",
      "test mean loss=1158.01123046875\n",
      "epoch 4897\n",
      "test_train\n",
      "train mean loss=0.06767584228267272\n",
      "test_test\n",
      "test mean loss=1158.3135681152344\n",
      "epoch 4898\n",
      "test_train\n",
      "train mean loss=0.06884800518552463\n",
      "test_test\n",
      "test mean loss=1157.794189453125\n",
      "epoch 4899\n",
      "test_train\n",
      "train mean loss=0.07486994347224633\n",
      "test_test\n",
      "test mean loss=1157.9965209960938\n",
      "epoch 4900\n",
      "test_train\n",
      "train mean loss=0.07062458743651708\n",
      "test_test\n",
      "test mean loss=1157.6414184570312\n",
      "epoch 4901\n",
      "test_train\n",
      "train mean loss=0.06503146514296532\n",
      "test_test\n",
      "test mean loss=1157.8128051757812\n",
      "epoch 4902\n",
      "test_train\n",
      "train mean loss=0.07011715633173783\n",
      "test_test\n",
      "test mean loss=1157.4857788085938\n",
      "epoch 4903\n",
      "test_train\n",
      "train mean loss=0.06965317483991385\n",
      "test_test\n",
      "test mean loss=1157.8056640625\n",
      "epoch 4904\n",
      "test_train\n",
      "train mean loss=0.07174473535269499\n",
      "test_test\n",
      "test mean loss=1157.3134765625\n",
      "epoch 4905\n",
      "test_train\n",
      "train mean loss=0.0821966774140795\n",
      "test_test\n",
      "test mean loss=1157.7945556640625\n",
      "epoch 4906\n",
      "test_train\n",
      "train mean loss=0.1715968425075213\n",
      "test_test\n",
      "test mean loss=1158.783203125\n",
      "epoch 4907\n",
      "test_train\n",
      "train mean loss=0.07164585000524919\n",
      "test_test\n",
      "test mean loss=1157.0856018066406\n",
      "epoch 4908\n",
      "test_train\n",
      "train mean loss=0.0668660057708621\n",
      "test_test\n",
      "test mean loss=1156.1025390625\n",
      "epoch 4909\n",
      "test_train\n",
      "train mean loss=0.07091136773427327\n",
      "test_test\n",
      "test mean loss=1157.1209716796875\n",
      "epoch 4910\n",
      "test_train\n",
      "train mean loss=0.07206081195424001\n",
      "test_test\n",
      "test mean loss=1158.3843994140625\n",
      "epoch 4911\n",
      "test_train\n",
      "train mean loss=0.0691473822419842\n",
      "test_test\n",
      "test mean loss=1157.2957458496094\n",
      "epoch 4912\n",
      "test_train\n",
      "train mean loss=0.07124805854012568\n",
      "test_test\n",
      "test mean loss=1157.4272155761719\n",
      "epoch 4913\n",
      "test_train\n",
      "train mean loss=0.06490643865739305\n",
      "test_test\n",
      "test mean loss=1156.8166809082031\n",
      "epoch 4914\n",
      "test_train\n",
      "train mean loss=0.07514986178527276\n",
      "test_test\n",
      "test mean loss=1157.35791015625\n",
      "epoch 4915\n",
      "test_train\n",
      "train mean loss=0.07229640117535989\n",
      "test_test\n",
      "test mean loss=1156.6387634277344\n",
      "epoch 4916\n",
      "test_train\n",
      "train mean loss=0.06908150389790535\n",
      "test_test\n",
      "test mean loss=1157.3124389648438\n",
      "epoch 4917\n",
      "test_train\n",
      "train mean loss=0.072676711405317\n",
      "test_test\n",
      "test mean loss=1157.4421081542969\n",
      "epoch 4918\n",
      "test_train\n",
      "train mean loss=0.07521417085081339\n",
      "test_test\n",
      "test mean loss=1157.8554382324219\n",
      "epoch 4919\n",
      "test_train\n",
      "train mean loss=0.07063510331014793\n",
      "test_test\n",
      "test mean loss=1157.5415649414062\n",
      "epoch 4920\n",
      "test_train\n",
      "train mean loss=0.0679151751101017\n",
      "test_test\n",
      "test mean loss=1156.4976806640625\n",
      "epoch 4921\n",
      "test_train\n",
      "train mean loss=0.07305176028360923\n",
      "test_test\n",
      "test mean loss=1156.4189453125\n",
      "epoch 4922\n",
      "test_train\n",
      "train mean loss=0.08083087671548128\n",
      "test_test\n",
      "test mean loss=1157.6723937988281\n",
      "epoch 4923\n",
      "test_train\n",
      "train mean loss=0.07527947177489598\n",
      "test_test\n",
      "test mean loss=1157.0128784179688\n",
      "epoch 4924\n",
      "test_train\n",
      "train mean loss=0.07626306576033433\n",
      "test_test\n",
      "test mean loss=1156.9650268554688\n",
      "epoch 4925\n",
      "test_train\n",
      "train mean loss=0.06884063376734655\n",
      "test_test\n",
      "test mean loss=1156.5732421875\n",
      "epoch 4926\n",
      "test_train\n",
      "train mean loss=0.07856311835348606\n",
      "test_test\n",
      "test mean loss=1157.8573913574219\n",
      "epoch 4927\n",
      "test_train\n",
      "train mean loss=0.07611744835351904\n",
      "test_test\n",
      "test mean loss=1155.8438720703125\n",
      "epoch 4928\n",
      "test_train\n",
      "train mean loss=0.0767513494938612\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_test\n",
      "test mean loss=1157.1903381347656\n",
      "epoch 4929\n",
      "test_train\n",
      "train mean loss=0.07487222986916701\n",
      "test_test\n",
      "test mean loss=1158.1419677734375\n",
      "epoch 4930\n",
      "test_train\n",
      "train mean loss=0.06854382591942947\n",
      "test_test\n",
      "test mean loss=1156.3226928710938\n",
      "epoch 4931\n",
      "test_train\n",
      "train mean loss=0.07364290890594323\n",
      "test_test\n",
      "test mean loss=1157.7197875976562\n",
      "epoch 4932\n",
      "test_train\n",
      "train mean loss=0.06673710886389017\n",
      "test_test\n",
      "test mean loss=1156.9137268066406\n",
      "epoch 4933\n",
      "test_train\n",
      "train mean loss=0.07609560526907444\n",
      "test_test\n",
      "test mean loss=1157.9895629882812\n",
      "epoch 4934\n",
      "test_train\n",
      "train mean loss=0.06906508933752775\n",
      "test_test\n",
      "test mean loss=1157.2180786132812\n",
      "epoch 4935\n",
      "test_train\n",
      "train mean loss=0.07286728483935197\n",
      "test_test\n",
      "test mean loss=1157.7847595214844\n",
      "epoch 4936\n",
      "test_train\n",
      "train mean loss=0.6470804562171301\n",
      "test_test\n",
      "test mean loss=1161.477783203125\n",
      "epoch 4937\n",
      "test_train\n",
      "train mean loss=0.11590491545697053\n",
      "test_test\n",
      "test mean loss=1160.4792175292969\n",
      "epoch 4938\n",
      "test_train\n",
      "train mean loss=0.0858919620513916\n",
      "test_test\n",
      "test mean loss=1159.6383666992188\n",
      "epoch 4939\n",
      "test_train\n",
      "train mean loss=0.16102161320547262\n",
      "test_test\n",
      "test mean loss=1159.3344116210938\n",
      "epoch 4940\n",
      "test_train\n",
      "train mean loss=0.08098699431866407\n",
      "test_test\n",
      "test mean loss=1158.8397521972656\n",
      "epoch 4941\n",
      "test_train\n",
      "train mean loss=0.07473937670389812\n",
      "test_test\n",
      "test mean loss=1159.0138854980469\n",
      "epoch 4942\n",
      "test_train\n",
      "train mean loss=0.07245697515706222\n",
      "test_test\n",
      "test mean loss=1158.7545776367188\n",
      "epoch 4943\n",
      "test_train\n",
      "train mean loss=0.07853596129765113\n",
      "test_test\n",
      "test mean loss=1158.6923828125\n",
      "epoch 4944\n",
      "test_train\n",
      "train mean loss=0.07250059364984433\n",
      "test_test\n",
      "test mean loss=1158.2732238769531\n",
      "epoch 4945\n",
      "test_train\n",
      "train mean loss=0.07396090310066938\n",
      "test_test\n",
      "test mean loss=1158.1019287109375\n",
      "epoch 4946\n",
      "test_train\n",
      "train mean loss=0.07647510493795077\n",
      "test_test\n",
      "test mean loss=1157.4478149414062\n",
      "epoch 4947\n",
      "test_train\n",
      "train mean loss=0.07749469454089801\n",
      "test_test\n",
      "test mean loss=1157.4509582519531\n",
      "epoch 4948\n",
      "test_train\n",
      "train mean loss=0.07286794887234767\n",
      "test_test\n",
      "test mean loss=1157.3349609375\n",
      "epoch 4949\n",
      "test_train\n",
      "train mean loss=0.07397556894769271\n",
      "test_test\n",
      "test mean loss=1157.5320129394531\n",
      "epoch 4950\n",
      "test_train\n",
      "train mean loss=0.0802895724773407\n",
      "test_test\n",
      "test mean loss=1156.4146728515625\n",
      "epoch 4951\n",
      "test_train\n",
      "train mean loss=0.06929351389408112\n",
      "test_test\n",
      "test mean loss=1156.2532653808594\n",
      "epoch 4952\n",
      "test_train\n",
      "train mean loss=0.07172104467948277\n",
      "test_test\n",
      "test mean loss=1155.7633056640625\n",
      "epoch 4953\n",
      "test_train\n",
      "train mean loss=0.07207549704859655\n",
      "test_test\n",
      "test mean loss=1156.4015197753906\n",
      "epoch 4954\n",
      "test_train\n",
      "train mean loss=0.07324647717177868\n",
      "test_test\n",
      "test mean loss=1157.026611328125\n",
      "epoch 4955\n",
      "test_train\n",
      "train mean loss=0.0698812020321687\n",
      "test_test\n",
      "test mean loss=1157.4976806640625\n",
      "epoch 4956\n",
      "test_train\n",
      "train mean loss=0.0733918718372782\n",
      "test_test\n",
      "test mean loss=1157.4047241210938\n",
      "epoch 4957\n",
      "test_train\n",
      "train mean loss=0.07395456576098998\n",
      "test_test\n",
      "test mean loss=1157.1834411621094\n",
      "epoch 4958\n",
      "test_train\n",
      "train mean loss=0.07567512771735589\n",
      "test_test\n",
      "test mean loss=1158.0416870117188\n",
      "epoch 4959\n",
      "test_train\n",
      "train mean loss=0.07803847299267848\n",
      "test_test\n",
      "test mean loss=1157.0059204101562\n",
      "epoch 4960\n",
      "test_train\n",
      "train mean loss=0.06643725279718637\n",
      "test_test\n",
      "test mean loss=1155.8516540527344\n",
      "epoch 4961\n",
      "test_train\n",
      "train mean loss=0.06588368583470583\n",
      "test_test\n",
      "test mean loss=1156.4928588867188\n",
      "epoch 4962\n",
      "test_train\n",
      "train mean loss=0.07215165595213573\n",
      "test_test\n",
      "test mean loss=1157.001220703125\n",
      "epoch 4963\n",
      "test_train\n",
      "train mean loss=0.06503585974375407\n",
      "test_test\n",
      "test mean loss=1156.6734008789062\n",
      "epoch 4964\n",
      "test_train\n",
      "train mean loss=0.06822183200468619\n",
      "test_test\n",
      "test mean loss=1157.2466125488281\n",
      "epoch 4965\n",
      "test_train\n",
      "train mean loss=0.07801035357018311\n",
      "test_test\n",
      "test mean loss=1156.9552612304688\n",
      "epoch 4966\n",
      "test_train\n",
      "train mean loss=0.07173032468805711\n",
      "test_test\n",
      "test mean loss=1156.353515625\n",
      "epoch 4967\n",
      "test_train\n",
      "train mean loss=0.07352662396927674\n",
      "test_test\n",
      "test mean loss=1156.6788330078125\n",
      "epoch 4968\n",
      "test_train\n",
      "train mean loss=0.06652980204671621\n",
      "test_test\n",
      "test mean loss=1157.0523681640625\n",
      "epoch 4969\n",
      "test_train\n",
      "train mean loss=0.09177615493535995\n",
      "test_test\n",
      "test mean loss=1157.5117797851562\n",
      "epoch 4970\n",
      "test_train\n",
      "train mean loss=0.0739330096791188\n",
      "test_test\n",
      "test mean loss=1156.2402038574219\n",
      "epoch 4971\n",
      "test_train\n",
      "train mean loss=0.0708615987872084\n",
      "test_test\n",
      "test mean loss=1156.8265991210938\n",
      "epoch 4972\n",
      "test_train\n",
      "train mean loss=0.07068581941227119\n",
      "test_test\n",
      "test mean loss=1156.1676635742188\n",
      "epoch 4973\n",
      "test_train\n",
      "train mean loss=0.07041019077102344\n",
      "test_test\n",
      "test mean loss=1157.3190002441406\n",
      "epoch 4974\n",
      "test_train\n",
      "train mean loss=0.07438660723467667\n",
      "test_test\n",
      "test mean loss=1157.718017578125\n",
      "epoch 4975\n",
      "test_train\n",
      "train mean loss=0.06922255580623944\n",
      "test_test\n",
      "test mean loss=1157.4342041015625\n",
      "epoch 4976\n",
      "test_train\n",
      "train mean loss=0.06851248349994421\n",
      "test_test\n",
      "test mean loss=1157.291015625\n",
      "epoch 4977\n",
      "test_train\n",
      "train mean loss=0.06307767207423846\n",
      "test_test\n",
      "test mean loss=1156.8941040039062\n",
      "epoch 4978\n",
      "test_train\n",
      "train mean loss=0.06905947346240282\n",
      "test_test\n",
      "test mean loss=1156.7507934570312\n",
      "epoch 4979\n",
      "test_train\n",
      "train mean loss=0.06790780772765477\n",
      "test_test\n",
      "test mean loss=1157.0078735351562\n",
      "epoch 4980\n",
      "test_train\n",
      "train mean loss=0.06730559468269348\n",
      "test_test\n",
      "test mean loss=1156.7374267578125\n",
      "epoch 4981\n",
      "test_train\n",
      "train mean loss=0.07336231165875991\n",
      "test_test\n",
      "test mean loss=1156.0306396484375\n",
      "epoch 4982\n",
      "test_train\n",
      "train mean loss=0.07062860702474912\n",
      "test_test\n",
      "test mean loss=1157.4614562988281\n",
      "epoch 4983\n",
      "test_train\n",
      "train mean loss=0.06730726081877947\n",
      "test_test\n",
      "test mean loss=1156.9207458496094\n",
      "epoch 4984\n",
      "test_train\n",
      "train mean loss=0.0694340355694294\n",
      "test_test\n",
      "test mean loss=1155.9226684570312\n",
      "epoch 4985\n",
      "test_train\n",
      "train mean loss=0.07043449052919944\n",
      "test_test\n",
      "test mean loss=1157.1853637695312\n",
      "epoch 4986\n",
      "test_train\n",
      "train mean loss=0.06814203721781571\n",
      "test_test\n",
      "test mean loss=1156.43701171875\n",
      "epoch 4987\n",
      "test_train\n",
      "train mean loss=0.07179863595714171\n",
      "test_test\n",
      "test mean loss=1156.9589233398438\n",
      "epoch 4988\n",
      "test_train\n",
      "train mean loss=0.07389744060734908\n",
      "test_test\n",
      "test mean loss=1157.2808227539062\n",
      "epoch 4989\n",
      "test_train\n",
      "train mean loss=0.07127768266946077\n",
      "test_test\n",
      "test mean loss=1156.45068359375\n",
      "epoch 4990\n",
      "test_train\n",
      "train mean loss=0.06721956562250853\n",
      "test_test\n",
      "test mean loss=1157.3836669921875\n",
      "epoch 4991\n",
      "test_train\n",
      "train mean loss=0.06957747228443623\n",
      "test_test\n",
      "test mean loss=1156.4955444335938\n",
      "epoch 4992\n",
      "test_train\n",
      "train mean loss=0.10006842575967312\n",
      "test_test\n",
      "test mean loss=1156.7641296386719\n",
      "epoch 4993\n",
      "test_train\n",
      "train mean loss=0.07328447140753269\n",
      "test_test\n",
      "test mean loss=1156.3515625\n",
      "epoch 4994\n",
      "test_train\n",
      "train mean loss=0.06941008226325114\n",
      "test_test\n",
      "test mean loss=1156.4754943847656\n",
      "epoch 4995\n",
      "test_train\n",
      "train mean loss=0.07264669922490914\n",
      "test_test\n",
      "test mean loss=1156.4193725585938\n",
      "epoch 4996\n",
      "test_train\n",
      "train mean loss=0.07413053140044212\n",
      "test_test\n",
      "test mean loss=1157.3551025390625\n",
      "epoch 4997\n",
      "test_train\n",
      "train mean loss=0.07540050040309627\n",
      "test_test\n",
      "test mean loss=1156.908447265625\n",
      "epoch 4998\n",
      "test_train\n",
      "train mean loss=0.07443536228189866\n",
      "test_test\n",
      "test mean loss=1156.656005859375\n",
      "epoch 4999\n",
      "test_train\n",
      "train mean loss=0.07516698477168877\n",
      "test_test\n",
      "test mean loss=1158.1623229980469\n",
      "epoch 5000\n",
      "test_train\n",
      "train mean loss=0.07028582443793614\n",
      "test_test\n",
      "test mean loss=1157.1227416992188\n",
      "epoch 5001\n",
      "test_train\n",
      "train mean loss=0.07474981620907784\n",
      "test_test\n",
      "test mean loss=1157.5862426757812\n",
      "epoch 5002\n",
      "test_train\n",
      "train mean loss=0.08700434118509293\n",
      "test_test\n",
      "test mean loss=1156.382080078125\n",
      "epoch 5003\n",
      "test_train\n",
      "train mean loss=0.06911915152644117\n",
      "test_test\n",
      "test mean loss=1157.3874816894531\n",
      "epoch 5004\n",
      "test_train\n",
      "train mean loss=0.07341802213340998\n",
      "test_test\n",
      "test mean loss=1158.527099609375\n",
      "epoch 5005\n",
      "test_train\n",
      "train mean loss=0.06698193152745564\n",
      "test_test\n",
      "test mean loss=1156.044677734375\n",
      "epoch 5006\n",
      "test_train\n",
      "train mean loss=0.07139328060050805\n",
      "test_test\n",
      "test mean loss=1157.1323547363281\n",
      "epoch 5007\n",
      "test_train\n",
      "train mean loss=0.07122772559523582\n",
      "test_test\n",
      "test mean loss=1156.2252807617188\n",
      "epoch 5008\n",
      "test_train\n",
      "train mean loss=0.06777483224868774\n",
      "test_test\n",
      "test mean loss=1155.6629028320312\n",
      "epoch 5009\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.07148769063254197\n",
      "test_test\n",
      "test mean loss=1155.8294677734375\n",
      "epoch 5010\n",
      "test_train\n",
      "train mean loss=0.06844462454319\n",
      "test_test\n",
      "test mean loss=1157.1533813476562\n",
      "epoch 5011\n",
      "test_train\n",
      "train mean loss=0.06579341491063435\n",
      "test_test\n",
      "test mean loss=1156.7590942382812\n",
      "epoch 5012\n",
      "test_train\n",
      "train mean loss=0.06766555768748124\n",
      "test_test\n",
      "test mean loss=1157.7445068359375\n",
      "epoch 5013\n",
      "test_train\n",
      "train mean loss=0.06986184262981017\n",
      "test_test\n",
      "test mean loss=1157.2306518554688\n",
      "epoch 5014\n",
      "test_train\n",
      "train mean loss=0.07200333569198847\n",
      "test_test\n",
      "test mean loss=1157.9691162109375\n",
      "epoch 5015\n",
      "test_train\n",
      "train mean loss=0.07513230821738641\n",
      "test_test\n",
      "test mean loss=1159.744140625\n",
      "epoch 5016\n",
      "test_train\n",
      "train mean loss=0.07669048570096493\n",
      "test_test\n",
      "test mean loss=1157.8785705566406\n",
      "epoch 5017\n",
      "test_train\n",
      "train mean loss=0.06931505165994167\n",
      "test_test\n",
      "test mean loss=1157.3576354980469\n",
      "epoch 5018\n",
      "test_train\n",
      "train mean loss=0.07363033946603537\n",
      "test_test\n",
      "test mean loss=1157.654296875\n",
      "epoch 5019\n",
      "test_train\n",
      "train mean loss=0.0764390416443348\n",
      "test_test\n",
      "test mean loss=1158.3046569824219\n",
      "epoch 5020\n",
      "test_train\n",
      "train mean loss=0.07234688227375348\n",
      "test_test\n",
      "test mean loss=1157.5009765625\n",
      "epoch 5021\n",
      "test_train\n",
      "train mean loss=0.07826283512016137\n",
      "test_test\n",
      "test mean loss=1157.9085693359375\n",
      "epoch 5022\n",
      "test_train\n",
      "train mean loss=0.07090367438892524\n",
      "test_test\n",
      "test mean loss=1157.7846069335938\n",
      "epoch 5023\n",
      "test_train\n",
      "train mean loss=0.07602119057749708\n",
      "test_test\n",
      "test mean loss=1156.9758911132812\n",
      "epoch 5024\n",
      "test_train\n",
      "train mean loss=0.0752160061771671\n",
      "test_test\n",
      "test mean loss=1157.612060546875\n",
      "epoch 5025\n",
      "test_train\n",
      "train mean loss=0.074092673137784\n",
      "test_test\n",
      "test mean loss=1156.940185546875\n",
      "epoch 5026\n",
      "test_train\n",
      "train mean loss=0.07101581307748954\n",
      "test_test\n",
      "test mean loss=1157.2245483398438\n",
      "epoch 5027\n",
      "test_train\n",
      "train mean loss=0.06912475948532422\n",
      "test_test\n",
      "test mean loss=1157.9195251464844\n",
      "epoch 5028\n",
      "test_train\n",
      "train mean loss=0.07325511022160451\n",
      "test_test\n",
      "test mean loss=1157.3358154296875\n",
      "epoch 5029\n",
      "test_train\n",
      "train mean loss=0.06856829797228177\n",
      "test_test\n",
      "test mean loss=1157.5494995117188\n",
      "epoch 5030\n",
      "test_train\n",
      "train mean loss=0.0651001629109184\n",
      "test_test\n",
      "test mean loss=1158.1430969238281\n",
      "epoch 5031\n",
      "test_train\n",
      "train mean loss=0.06734870312114556\n",
      "test_test\n",
      "test mean loss=1158.0721435546875\n",
      "epoch 5032\n",
      "test_train\n",
      "train mean loss=0.06942700315266848\n",
      "test_test\n",
      "test mean loss=1158.2903747558594\n",
      "epoch 5033\n",
      "test_train\n",
      "train mean loss=0.08600706917544206\n",
      "test_test\n",
      "test mean loss=1155.629638671875\n",
      "epoch 5034\n",
      "test_train\n",
      "train mean loss=0.06667056462417047\n",
      "test_test\n",
      "test mean loss=1157.5751037597656\n",
      "epoch 5035\n",
      "test_train\n",
      "train mean loss=0.0710118090113004\n",
      "test_test\n",
      "test mean loss=1157.8690795898438\n",
      "epoch 5036\n",
      "test_train\n",
      "train mean loss=0.06398372321079175\n",
      "test_test\n",
      "test mean loss=1157.4407348632812\n",
      "epoch 5037\n",
      "test_train\n",
      "train mean loss=0.07288357211897771\n",
      "test_test\n",
      "test mean loss=1158.7234497070312\n",
      "epoch 5038\n",
      "test_train\n",
      "train mean loss=0.07550035572300355\n",
      "test_test\n",
      "test mean loss=1157.5450744628906\n",
      "epoch 5039\n",
      "test_train\n",
      "train mean loss=0.07094956111783783\n",
      "test_test\n",
      "test mean loss=1158.1314697265625\n",
      "epoch 5040\n",
      "test_train\n",
      "train mean loss=0.0722375341380636\n",
      "test_test\n",
      "test mean loss=1158.4833374023438\n",
      "epoch 5041\n",
      "test_train\n",
      "train mean loss=0.06925871782004833\n",
      "test_test\n",
      "test mean loss=1157.7008666992188\n",
      "epoch 5042\n",
      "test_train\n",
      "train mean loss=0.06435884690533082\n",
      "test_test\n",
      "test mean loss=1157.5288391113281\n",
      "epoch 5043\n",
      "test_train\n",
      "train mean loss=0.06416202491770188\n",
      "test_test\n",
      "test mean loss=1157.7887573242188\n",
      "epoch 5044\n",
      "test_train\n",
      "train mean loss=0.0683178569500645\n",
      "test_test\n",
      "test mean loss=1157.9164428710938\n",
      "epoch 5045\n",
      "test_train\n",
      "train mean loss=0.08401660714298487\n",
      "test_test\n",
      "test mean loss=1157.0343627929688\n",
      "epoch 5046\n",
      "test_train\n",
      "train mean loss=0.07168016210198402\n",
      "test_test\n",
      "test mean loss=1157.7898559570312\n",
      "epoch 5047\n",
      "test_train\n",
      "train mean loss=0.08504653753091891\n",
      "test_test\n",
      "test mean loss=1159.3795166015625\n",
      "epoch 5048\n",
      "test_train\n",
      "train mean loss=0.06760227214545012\n",
      "test_test\n",
      "test mean loss=1157.936279296875\n",
      "epoch 5049\n",
      "test_train\n",
      "train mean loss=0.07044396828860044\n",
      "test_test\n",
      "test mean loss=1156.9828491210938\n",
      "epoch 5050\n",
      "test_train\n",
      "train mean loss=0.06836992936829726\n",
      "test_test\n",
      "test mean loss=1157.1871948242188\n",
      "epoch 5051\n",
      "test_train\n",
      "train mean loss=0.06928744601706664\n",
      "test_test\n",
      "test mean loss=1157.6517028808594\n",
      "epoch 5052\n",
      "test_train\n",
      "train mean loss=0.07339458943655093\n",
      "test_test\n",
      "test mean loss=1158.1419067382812\n",
      "epoch 5053\n",
      "test_train\n",
      "train mean loss=0.06907838831345241\n",
      "test_test\n",
      "test mean loss=1157.828125\n",
      "epoch 5054\n",
      "test_train\n",
      "train mean loss=0.07037419484307368\n",
      "test_test\n",
      "test mean loss=1156.5393676757812\n",
      "epoch 5055\n",
      "test_train\n",
      "train mean loss=0.06549005427708228\n",
      "test_test\n",
      "test mean loss=1157.8267211914062\n",
      "epoch 5056\n",
      "test_train\n",
      "train mean loss=0.06922332445780437\n",
      "test_test\n",
      "test mean loss=1157.4263305664062\n",
      "epoch 5057\n",
      "test_train\n",
      "train mean loss=0.06467787797252338\n",
      "test_test\n",
      "test mean loss=1157.35009765625\n",
      "epoch 5058\n",
      "test_train\n",
      "train mean loss=0.06229584229489168\n",
      "test_test\n",
      "test mean loss=1156.9604187011719\n",
      "epoch 5059\n",
      "test_train\n",
      "train mean loss=0.07239115331321955\n",
      "test_test\n",
      "test mean loss=1155.9931945800781\n",
      "epoch 5060\n",
      "test_train\n",
      "train mean loss=0.06336225382983685\n",
      "test_test\n",
      "test mean loss=1157.8017578125\n",
      "epoch 5061\n",
      "test_train\n",
      "train mean loss=0.07128740288317204\n",
      "test_test\n",
      "test mean loss=1158.4281616210938\n",
      "epoch 5062\n",
      "test_train\n",
      "train mean loss=0.06661733193323016\n",
      "test_test\n",
      "test mean loss=1158.0120544433594\n",
      "epoch 5063\n",
      "test_train\n",
      "train mean loss=0.060882062651216984\n",
      "test_test\n",
      "test mean loss=1157.5239868164062\n",
      "epoch 5064\n",
      "test_train\n",
      "train mean loss=0.06802947757144769\n",
      "test_test\n",
      "test mean loss=1157.6785278320312\n",
      "epoch 5065\n",
      "test_train\n",
      "train mean loss=0.06799528157959382\n",
      "test_test\n",
      "test mean loss=1157.9126586914062\n",
      "epoch 5066\n",
      "test_train\n",
      "train mean loss=0.06587025181700785\n",
      "test_test\n",
      "test mean loss=1157.677001953125\n",
      "epoch 5067\n",
      "test_train\n",
      "train mean loss=0.07253488929321368\n",
      "test_test\n",
      "test mean loss=1157.9179077148438\n",
      "epoch 5068\n",
      "test_train\n",
      "train mean loss=0.07084153251101573\n",
      "test_test\n",
      "test mean loss=1158.1985473632812\n",
      "epoch 5069\n",
      "test_train\n",
      "train mean loss=0.07118512441714604\n",
      "test_test\n",
      "test mean loss=1157.199951171875\n",
      "epoch 5070\n",
      "test_train\n",
      "train mean loss=0.07109335282196601\n",
      "test_test\n",
      "test mean loss=1158.0043640136719\n",
      "epoch 5071\n",
      "test_train\n",
      "train mean loss=0.06613603048026562\n",
      "test_test\n",
      "test mean loss=1157.8853149414062\n",
      "epoch 5072\n",
      "test_train\n",
      "train mean loss=0.07150688363860051\n",
      "test_test\n",
      "test mean loss=1158.4935302734375\n",
      "epoch 5073\n",
      "test_train\n",
      "train mean loss=0.07272745048006375\n",
      "test_test\n",
      "test mean loss=1157.6510009765625\n",
      "epoch 5074\n",
      "test_train\n",
      "train mean loss=0.07155206054449081\n",
      "test_test\n",
      "test mean loss=1157.7908935546875\n",
      "epoch 5075\n",
      "test_train\n",
      "train mean loss=0.07832951688518126\n",
      "test_test\n",
      "test mean loss=1158.4981689453125\n",
      "epoch 5076\n",
      "test_train\n",
      "train mean loss=0.0655742824698488\n",
      "test_test\n",
      "test mean loss=1157.3917236328125\n",
      "epoch 5077\n",
      "test_train\n",
      "train mean loss=0.0603456332658728\n",
      "test_test\n",
      "test mean loss=1157.6925964355469\n",
      "epoch 5078\n",
      "test_train\n",
      "train mean loss=0.07193843647837639\n",
      "test_test\n",
      "test mean loss=1158.7925109863281\n",
      "epoch 5079\n",
      "test_train\n",
      "train mean loss=0.06969388698538144\n",
      "test_test\n",
      "test mean loss=1157.6900024414062\n",
      "epoch 5080\n",
      "test_train\n",
      "train mean loss=0.07081493145475785\n",
      "test_test\n",
      "test mean loss=1158.3000793457031\n",
      "epoch 5081\n",
      "test_train\n",
      "train mean loss=0.07425584116329749\n",
      "test_test\n",
      "test mean loss=1156.7721557617188\n",
      "epoch 5082\n",
      "test_train\n",
      "train mean loss=0.06988493259996176\n",
      "test_test\n",
      "test mean loss=1157.9585266113281\n",
      "epoch 5083\n",
      "test_train\n",
      "train mean loss=0.07327656727284193\n",
      "test_test\n",
      "test mean loss=1158.0362548828125\n",
      "epoch 5084\n",
      "test_train\n",
      "train mean loss=0.06230968547364076\n",
      "test_test\n",
      "test mean loss=1157.3561401367188\n",
      "epoch 5085\n",
      "test_train\n",
      "train mean loss=0.06284887654085954\n",
      "test_test\n",
      "test mean loss=1158.26513671875\n",
      "epoch 5086\n",
      "test_train\n",
      "train mean loss=0.061717561756571136\n",
      "test_test\n",
      "test mean loss=1157.8793640136719\n",
      "epoch 5087\n",
      "test_train\n",
      "train mean loss=0.06579560569177072\n",
      "test_test\n",
      "test mean loss=1158.3442993164062\n",
      "epoch 5088\n",
      "test_train\n",
      "train mean loss=0.06775199187298615\n",
      "test_test\n",
      "test mean loss=1158.6377563476562\n",
      "epoch 5089\n",
      "test_train\n",
      "train mean loss=0.062098363103965916\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1158.2196350097656\n",
      "epoch 5090\n",
      "test_train\n",
      "train mean loss=0.06641309428960085\n",
      "test_test\n",
      "test mean loss=1158.0170288085938\n",
      "epoch 5091\n",
      "test_train\n",
      "train mean loss=0.06830504971245925\n",
      "test_test\n",
      "test mean loss=1157.3953857421875\n",
      "epoch 5092\n",
      "test_train\n",
      "train mean loss=0.06508742800603311\n",
      "test_test\n",
      "test mean loss=1157.9954833984375\n",
      "epoch 5093\n",
      "test_train\n",
      "train mean loss=0.07325462220857541\n",
      "test_test\n",
      "test mean loss=1158.4285888671875\n",
      "epoch 5094\n",
      "test_train\n",
      "train mean loss=0.06675963258991639\n",
      "test_test\n",
      "test mean loss=1157.6292724609375\n",
      "epoch 5095\n",
      "test_train\n",
      "train mean loss=0.06813853358229001\n",
      "test_test\n",
      "test mean loss=1158.36376953125\n",
      "epoch 5096\n",
      "test_train\n",
      "train mean loss=0.06394313865651687\n",
      "test_test\n",
      "test mean loss=1157.3511352539062\n",
      "epoch 5097\n",
      "test_train\n",
      "train mean loss=0.06832268306364615\n",
      "test_test\n",
      "test mean loss=1158.4283142089844\n",
      "epoch 5098\n",
      "test_train\n",
      "train mean loss=0.07064783945679665\n",
      "test_test\n",
      "test mean loss=1158.4451904296875\n",
      "epoch 5099\n",
      "test_train\n",
      "train mean loss=0.06837370122472446\n",
      "test_test\n",
      "test mean loss=1158.3968811035156\n",
      "epoch 5100\n",
      "test_train\n",
      "train mean loss=0.0698520749186476\n",
      "test_test\n",
      "test mean loss=1159.4466552734375\n",
      "epoch 5101\n",
      "test_train\n",
      "train mean loss=0.07104881837343176\n",
      "test_test\n",
      "test mean loss=1159.1321105957031\n",
      "epoch 5102\n",
      "test_train\n",
      "train mean loss=0.0743706754098336\n",
      "test_test\n",
      "test mean loss=1159.1366882324219\n",
      "epoch 5103\n",
      "test_train\n",
      "train mean loss=0.07415802714725335\n",
      "test_test\n",
      "test mean loss=1158.6421813964844\n",
      "epoch 5104\n",
      "test_train\n",
      "train mean loss=0.07119356530408065\n",
      "test_test\n",
      "test mean loss=1158.8400268554688\n",
      "epoch 5105\n",
      "test_train\n",
      "train mean loss=0.06634215886394183\n",
      "test_test\n",
      "test mean loss=1157.4433288574219\n",
      "epoch 5106\n",
      "test_train\n",
      "train mean loss=0.07017965832104285\n",
      "test_test\n",
      "test mean loss=1158.7054748535156\n",
      "epoch 5107\n",
      "test_train\n",
      "train mean loss=0.072327577508986\n",
      "test_test\n",
      "test mean loss=1158.5367431640625\n",
      "epoch 5108\n",
      "test_train\n",
      "train mean loss=0.07696643409629662\n",
      "test_test\n",
      "test mean loss=1159.05126953125\n",
      "epoch 5109\n",
      "test_train\n",
      "train mean loss=0.06754698480168979\n",
      "test_test\n",
      "test mean loss=1157.7867431640625\n",
      "epoch 5110\n",
      "test_train\n",
      "train mean loss=0.06246054576088985\n",
      "test_test\n",
      "test mean loss=1158.00537109375\n",
      "epoch 5111\n",
      "test_train\n",
      "train mean loss=0.08413904812186956\n",
      "test_test\n",
      "test mean loss=1157.998779296875\n",
      "epoch 5112\n",
      "test_train\n",
      "train mean loss=0.07464691748221715\n",
      "test_test\n",
      "test mean loss=1157.3537902832031\n",
      "epoch 5113\n",
      "test_train\n",
      "train mean loss=0.07106911080578963\n",
      "test_test\n",
      "test mean loss=1156.9200439453125\n",
      "epoch 5114\n",
      "test_train\n",
      "train mean loss=0.06454385444521904\n",
      "test_test\n",
      "test mean loss=1158.693115234375\n",
      "epoch 5115\n",
      "test_train\n",
      "train mean loss=0.07035775886227687\n",
      "test_test\n",
      "test mean loss=1158.826171875\n",
      "epoch 5116\n",
      "test_train\n",
      "train mean loss=0.0719526403894027\n",
      "test_test\n",
      "test mean loss=1157.8416442871094\n",
      "epoch 5117\n",
      "test_train\n",
      "train mean loss=0.07174324865142505\n",
      "test_test\n",
      "test mean loss=1157.6862182617188\n",
      "epoch 5118\n",
      "test_train\n",
      "train mean loss=0.06660548162957032\n",
      "test_test\n",
      "test mean loss=1157.53369140625\n",
      "epoch 5119\n",
      "test_train\n",
      "train mean loss=0.062486291863024235\n",
      "test_test\n",
      "test mean loss=1156.7006530761719\n",
      "epoch 5120\n",
      "test_train\n",
      "train mean loss=0.06778374407440424\n",
      "test_test\n",
      "test mean loss=1157.4647216796875\n",
      "epoch 5121\n",
      "test_train\n",
      "train mean loss=0.06906597812970479\n",
      "test_test\n",
      "test mean loss=1157.7224731445312\n",
      "epoch 5122\n",
      "test_train\n",
      "train mean loss=0.17189111871023974\n",
      "test_test\n",
      "test mean loss=1148.9888916015625\n",
      "epoch 5123\n",
      "test_train\n",
      "train mean loss=0.06406691794594128\n",
      "test_test\n",
      "test mean loss=1157.2577514648438\n",
      "epoch 5124\n",
      "test_train\n",
      "train mean loss=0.06302765881021817\n",
      "test_test\n",
      "test mean loss=1156.79833984375\n",
      "epoch 5125\n",
      "test_train\n",
      "train mean loss=0.06105457618832588\n",
      "test_test\n",
      "test mean loss=1156.8893432617188\n",
      "epoch 5126\n",
      "test_train\n",
      "train mean loss=0.05663765392576655\n",
      "test_test\n",
      "test mean loss=1157.2029418945312\n",
      "epoch 5127\n",
      "test_train\n",
      "train mean loss=0.07293819884459178\n",
      "test_test\n",
      "test mean loss=1158.5046997070312\n",
      "epoch 5128\n",
      "test_train\n",
      "train mean loss=0.0720218230659763\n",
      "test_test\n",
      "test mean loss=1157.7142333984375\n",
      "epoch 5129\n",
      "test_train\n",
      "train mean loss=0.06895817692081134\n",
      "test_test\n",
      "test mean loss=1158.6321105957031\n",
      "epoch 5130\n",
      "test_train\n",
      "train mean loss=0.06939016096293926\n",
      "test_test\n",
      "test mean loss=1158.4631958007812\n",
      "epoch 5131\n",
      "test_train\n",
      "train mean loss=0.06922096759080887\n",
      "test_test\n",
      "test mean loss=1158.2203369140625\n",
      "epoch 5132\n",
      "test_train\n",
      "train mean loss=0.06336667171368997\n",
      "test_test\n",
      "test mean loss=1158.1558837890625\n",
      "epoch 5133\n",
      "test_train\n",
      "train mean loss=0.06618959146241347\n",
      "test_test\n",
      "test mean loss=1158.8875732421875\n",
      "epoch 5134\n",
      "test_train\n",
      "train mean loss=0.05928971820200483\n",
      "test_test\n",
      "test mean loss=1158.0701904296875\n",
      "epoch 5135\n",
      "test_train\n",
      "train mean loss=0.06468066324790318\n",
      "test_test\n",
      "test mean loss=1158.6342163085938\n",
      "epoch 5136\n",
      "test_train\n",
      "train mean loss=0.06416281405836344\n",
      "test_test\n",
      "test mean loss=1159.1316833496094\n",
      "epoch 5137\n",
      "test_train\n",
      "train mean loss=0.06553550312916438\n",
      "test_test\n",
      "test mean loss=1158.5198364257812\n",
      "epoch 5138\n",
      "test_train\n",
      "train mean loss=0.0638836429764827\n",
      "test_test\n",
      "test mean loss=1158.1936340332031\n",
      "epoch 5139\n",
      "test_train\n",
      "train mean loss=0.06839046316842239\n",
      "test_test\n",
      "test mean loss=1157.4302978515625\n",
      "epoch 5140\n",
      "test_train\n",
      "train mean loss=0.07129023068894942\n",
      "test_test\n",
      "test mean loss=1158.7737426757812\n",
      "epoch 5141\n",
      "test_train\n",
      "train mean loss=0.06234433533002933\n",
      "test_test\n",
      "test mean loss=1158.0694274902344\n",
      "epoch 5142\n",
      "test_train\n",
      "train mean loss=0.07083111349493265\n",
      "test_test\n",
      "test mean loss=1158.406982421875\n",
      "epoch 5143\n",
      "test_train\n",
      "train mean loss=0.0636128019541502\n",
      "test_test\n",
      "test mean loss=1157.1752624511719\n",
      "epoch 5144\n",
      "test_train\n",
      "train mean loss=0.06483335886150599\n",
      "test_test\n",
      "test mean loss=1158.2902221679688\n",
      "epoch 5145\n",
      "test_train\n",
      "train mean loss=0.06296958215534687\n",
      "test_test\n",
      "test mean loss=1157.7431030273438\n",
      "epoch 5146\n",
      "test_train\n",
      "train mean loss=0.0695605759198467\n",
      "test_test\n",
      "test mean loss=1157.4913940429688\n",
      "epoch 5147\n",
      "test_train\n",
      "train mean loss=0.06707088587184747\n",
      "test_test\n",
      "test mean loss=1158.3245239257812\n",
      "epoch 5148\n",
      "test_train\n",
      "train mean loss=0.06459775070349376\n",
      "test_test\n",
      "test mean loss=1157.2738647460938\n",
      "epoch 5149\n",
      "test_train\n",
      "train mean loss=0.06165984862794479\n",
      "test_test\n",
      "test mean loss=1157.1797485351562\n",
      "epoch 5150\n",
      "test_train\n",
      "train mean loss=0.07711705844849348\n",
      "test_test\n",
      "test mean loss=1157.4522094726562\n",
      "epoch 5151\n",
      "test_train\n",
      "train mean loss=0.07011158112436533\n",
      "test_test\n",
      "test mean loss=1157.0260620117188\n",
      "epoch 5152\n",
      "test_train\n",
      "train mean loss=0.06591048402090867\n",
      "test_test\n",
      "test mean loss=1157.6287536621094\n",
      "epoch 5153\n",
      "test_train\n",
      "train mean loss=0.06890537465612094\n",
      "test_test\n",
      "test mean loss=1159.3945922851562\n",
      "epoch 5154\n",
      "test_train\n",
      "train mean loss=0.06481008448948462\n",
      "test_test\n",
      "test mean loss=1158.4072875976562\n",
      "epoch 5155\n",
      "test_train\n",
      "train mean loss=0.0656797398502628\n",
      "test_test\n",
      "test mean loss=1156.959228515625\n",
      "epoch 5156\n",
      "test_train\n",
      "train mean loss=0.06512826184431712\n",
      "test_test\n",
      "test mean loss=1157.9463806152344\n",
      "epoch 5157\n",
      "test_train\n",
      "train mean loss=0.06601838146646817\n",
      "test_test\n",
      "test mean loss=1158.9664306640625\n",
      "epoch 5158\n",
      "test_train\n",
      "train mean loss=0.06489157614608605\n",
      "test_test\n",
      "test mean loss=1158.0896301269531\n",
      "epoch 5159\n",
      "test_train\n",
      "train mean loss=0.08323403199513753\n",
      "test_test\n",
      "test mean loss=1156.391845703125\n",
      "epoch 5160\n",
      "test_train\n",
      "train mean loss=0.06423538209249575\n",
      "test_test\n",
      "test mean loss=1158.7461242675781\n",
      "epoch 5161\n",
      "test_train\n",
      "train mean loss=0.06847979687154293\n",
      "test_test\n",
      "test mean loss=1159.2623596191406\n",
      "epoch 5162\n",
      "test_train\n",
      "train mean loss=0.07240220531821251\n",
      "test_test\n",
      "test mean loss=1159.9629211425781\n",
      "epoch 5163\n",
      "test_train\n",
      "train mean loss=0.07821459198991458\n",
      "test_test\n",
      "test mean loss=1160.2820739746094\n",
      "epoch 5164\n",
      "test_train\n",
      "train mean loss=0.07224525945882003\n",
      "test_test\n",
      "test mean loss=1160.0339965820312\n",
      "epoch 5165\n",
      "test_train\n",
      "train mean loss=0.06378921959549189\n",
      "test_test\n",
      "test mean loss=1159.6676025390625\n",
      "epoch 5166\n",
      "test_train\n",
      "train mean loss=0.06948261583844821\n",
      "test_test\n",
      "test mean loss=1158.6838073730469\n",
      "epoch 5167\n",
      "test_train\n",
      "train mean loss=0.06853890015433232\n",
      "test_test\n",
      "test mean loss=1158.2843017578125\n",
      "epoch 5168\n",
      "test_train\n",
      "train mean loss=0.07618258303652208\n",
      "test_test\n",
      "test mean loss=1158.4812622070312\n",
      "epoch 5169\n",
      "test_train\n",
      "train mean loss=0.06556156060347955\n",
      "test_test\n",
      "test mean loss=1157.5835266113281\n",
      "epoch 5170\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.06774885642031829\n",
      "test_test\n",
      "test mean loss=1158.4102172851562\n",
      "epoch 5171\n",
      "test_train\n",
      "train mean loss=0.06310222701479991\n",
      "test_test\n",
      "test mean loss=1157.9814453125\n",
      "epoch 5172\n",
      "test_train\n",
      "train mean loss=0.07066539985438187\n",
      "test_test\n",
      "test mean loss=1159.130126953125\n",
      "epoch 5173\n",
      "test_train\n",
      "train mean loss=0.06872215960174799\n",
      "test_test\n",
      "test mean loss=1159.1361694335938\n",
      "epoch 5174\n",
      "test_train\n",
      "train mean loss=0.06801354605704546\n",
      "test_test\n",
      "test mean loss=1158.7205200195312\n",
      "epoch 5175\n",
      "test_train\n",
      "train mean loss=0.06637352115164201\n",
      "test_test\n",
      "test mean loss=1158.5859375\n",
      "epoch 5176\n",
      "test_train\n",
      "train mean loss=0.0699408824245135\n",
      "test_test\n",
      "test mean loss=1159.3238220214844\n",
      "epoch 5177\n",
      "test_train\n",
      "train mean loss=0.06631214575221141\n",
      "test_test\n",
      "test mean loss=1158.7910766601562\n",
      "epoch 5178\n",
      "test_train\n",
      "train mean loss=0.07279694452881813\n",
      "test_test\n",
      "test mean loss=1159.74072265625\n",
      "epoch 5179\n",
      "test_train\n",
      "train mean loss=0.06764947343617678\n",
      "test_test\n",
      "test mean loss=1159.4207153320312\n",
      "epoch 5180\n",
      "test_train\n",
      "train mean loss=0.07461302727460861\n",
      "test_test\n",
      "test mean loss=1159.2672424316406\n",
      "epoch 5181\n",
      "test_train\n",
      "train mean loss=0.07008656083295743\n",
      "test_test\n",
      "test mean loss=1158.7893371582031\n",
      "epoch 5182\n",
      "test_train\n",
      "train mean loss=0.07942512879769008\n",
      "test_test\n",
      "test mean loss=1158.6560668945312\n",
      "epoch 5183\n",
      "test_train\n",
      "train mean loss=0.07334280293434858\n",
      "test_test\n",
      "test mean loss=1159.8129272460938\n",
      "epoch 5184\n",
      "test_train\n",
      "train mean loss=0.06754015603413184\n",
      "test_test\n",
      "test mean loss=1159.3696594238281\n",
      "epoch 5185\n",
      "test_train\n",
      "train mean loss=0.06542848702520132\n",
      "test_test\n",
      "test mean loss=1159.3432006835938\n",
      "epoch 5186\n",
      "test_train\n",
      "train mean loss=0.06960184654841821\n",
      "test_test\n",
      "test mean loss=1158.4008178710938\n",
      "epoch 5187\n",
      "test_train\n",
      "train mean loss=0.06790897467484076\n",
      "test_test\n",
      "test mean loss=1158.6300048828125\n",
      "epoch 5188\n",
      "test_train\n",
      "train mean loss=0.0675389568010966\n",
      "test_test\n",
      "test mean loss=1158.774169921875\n",
      "epoch 5189\n",
      "test_train\n",
      "train mean loss=0.07074291631579399\n",
      "test_test\n",
      "test mean loss=1159.410888671875\n",
      "epoch 5190\n",
      "test_train\n",
      "train mean loss=0.0651990007609129\n",
      "test_test\n",
      "test mean loss=1159.8360290527344\n",
      "epoch 5191\n",
      "test_train\n",
      "train mean loss=0.07859356763462226\n",
      "test_test\n",
      "test mean loss=1158.036376953125\n",
      "epoch 5192\n",
      "test_train\n",
      "train mean loss=0.09143666177988052\n",
      "test_test\n",
      "test mean loss=1159.5126037597656\n",
      "epoch 5193\n",
      "test_train\n",
      "train mean loss=0.06553214291731517\n",
      "test_test\n",
      "test mean loss=1158.5934753417969\n",
      "epoch 5194\n",
      "test_train\n",
      "train mean loss=0.06139586089799801\n",
      "test_test\n",
      "test mean loss=1156.806884765625\n",
      "epoch 5195\n",
      "test_train\n",
      "train mean loss=0.07238774715612332\n",
      "test_test\n",
      "test mean loss=1157.9323120117188\n",
      "epoch 5196\n",
      "test_train\n",
      "train mean loss=0.06777126962939899\n",
      "test_test\n",
      "test mean loss=1158.3759155273438\n",
      "epoch 5197\n",
      "test_train\n",
      "train mean loss=0.06540416584660609\n",
      "test_test\n",
      "test mean loss=1158.0597839355469\n",
      "epoch 5198\n",
      "test_train\n",
      "train mean loss=0.06306007007757823\n",
      "test_test\n",
      "test mean loss=1157.7383117675781\n",
      "epoch 5199\n",
      "test_train\n",
      "train mean loss=0.07379952942331632\n",
      "test_test\n",
      "test mean loss=1159.4107055664062\n",
      "epoch 5200\n",
      "test_train\n",
      "train mean loss=0.0704566038524111\n",
      "test_test\n",
      "test mean loss=1159.0131530761719\n",
      "epoch 5201\n",
      "test_train\n",
      "train mean loss=0.05922709001849095\n",
      "test_test\n",
      "test mean loss=1158.7841186523438\n",
      "epoch 5202\n",
      "test_train\n",
      "train mean loss=0.07006121271600325\n",
      "test_test\n",
      "test mean loss=1158.9505615234375\n",
      "epoch 5203\n",
      "test_train\n",
      "train mean loss=0.07224214853097995\n",
      "test_test\n",
      "test mean loss=1158.5102233886719\n",
      "epoch 5204\n",
      "test_train\n",
      "train mean loss=0.06857424788177013\n",
      "test_test\n",
      "test mean loss=1158.0323486328125\n",
      "epoch 5205\n",
      "test_train\n",
      "train mean loss=0.06012959529956182\n",
      "test_test\n",
      "test mean loss=1157.9594116210938\n",
      "epoch 5206\n",
      "test_train\n",
      "train mean loss=0.06432838489611943\n",
      "test_test\n",
      "test mean loss=1158.01708984375\n",
      "epoch 5207\n",
      "test_train\n",
      "train mean loss=0.06639817636460066\n",
      "test_test\n",
      "test mean loss=1159.9924926757812\n",
      "epoch 5208\n",
      "test_train\n",
      "train mean loss=0.07836443558335304\n",
      "test_test\n",
      "test mean loss=1160.3943481445312\n",
      "epoch 5209\n",
      "test_train\n",
      "train mean loss=0.06666825494418542\n",
      "test_test\n",
      "test mean loss=1158.8900146484375\n",
      "epoch 5210\n",
      "test_train\n",
      "train mean loss=0.07296589761972427\n",
      "test_test\n",
      "test mean loss=1159.1646423339844\n",
      "epoch 5211\n",
      "test_train\n",
      "train mean loss=0.06884822963426511\n",
      "test_test\n",
      "test mean loss=1158.7806396484375\n",
      "epoch 5212\n",
      "test_train\n",
      "train mean loss=0.060492832524081074\n",
      "test_test\n",
      "test mean loss=1158.2872619628906\n",
      "epoch 5213\n",
      "test_train\n",
      "train mean loss=0.06956306441376607\n",
      "test_test\n",
      "test mean loss=1159.6320495605469\n",
      "epoch 5214\n",
      "test_train\n",
      "train mean loss=0.06335753419746955\n",
      "test_test\n",
      "test mean loss=1159.1595458984375\n",
      "epoch 5215\n",
      "test_train\n",
      "train mean loss=0.06451863873129089\n",
      "test_test\n",
      "test mean loss=1159.3417358398438\n",
      "epoch 5216\n",
      "test_train\n",
      "train mean loss=0.06023448705673218\n",
      "test_test\n",
      "test mean loss=1158.279541015625\n",
      "epoch 5217\n",
      "test_train\n",
      "train mean loss=0.062194651924073696\n",
      "test_test\n",
      "test mean loss=1158.4452514648438\n",
      "epoch 5218\n",
      "test_train\n",
      "train mean loss=0.06269944086670876\n",
      "test_test\n",
      "test mean loss=1158.0153198242188\n",
      "epoch 5219\n",
      "test_train\n",
      "train mean loss=0.06177784161021312\n",
      "test_test\n",
      "test mean loss=1158.0897827148438\n",
      "epoch 5220\n",
      "test_train\n",
      "train mean loss=0.06667732540518045\n",
      "test_test\n",
      "test mean loss=1159.843994140625\n",
      "epoch 5221\n",
      "test_train\n",
      "train mean loss=0.06580773834139109\n",
      "test_test\n",
      "test mean loss=1159.65087890625\n",
      "epoch 5222\n",
      "test_train\n",
      "train mean loss=0.0646294994900624\n",
      "test_test\n",
      "test mean loss=1159.3121032714844\n",
      "epoch 5223\n",
      "test_train\n",
      "train mean loss=0.0639702823633949\n",
      "test_test\n",
      "test mean loss=1158.9476318359375\n",
      "epoch 5224\n",
      "test_train\n",
      "train mean loss=0.06615602411329746\n",
      "test_test\n",
      "test mean loss=1157.9874877929688\n",
      "epoch 5225\n",
      "test_train\n",
      "train mean loss=0.06568783521652222\n",
      "test_test\n",
      "test mean loss=1158.303466796875\n",
      "epoch 5226\n",
      "test_train\n",
      "train mean loss=0.06455134910841782\n",
      "test_test\n",
      "test mean loss=1158.1611328125\n",
      "epoch 5227\n",
      "test_train\n",
      "train mean loss=0.06768471437195937\n",
      "test_test\n",
      "test mean loss=1158.6525268554688\n",
      "epoch 5228\n",
      "test_train\n",
      "train mean loss=0.06746398874868949\n",
      "test_test\n",
      "test mean loss=1158.4955749511719\n",
      "epoch 5229\n",
      "test_train\n",
      "train mean loss=0.06791195211311181\n",
      "test_test\n",
      "test mean loss=1157.7120971679688\n",
      "epoch 5230\n",
      "test_train\n",
      "train mean loss=0.07124386448413134\n",
      "test_test\n",
      "test mean loss=1158.550048828125\n",
      "epoch 5231\n",
      "test_train\n",
      "train mean loss=0.06540058211733897\n",
      "test_test\n",
      "test mean loss=1158.0187072753906\n",
      "epoch 5232\n",
      "test_train\n",
      "train mean loss=0.06469436703870694\n",
      "test_test\n",
      "test mean loss=1158.9545288085938\n",
      "epoch 5233\n",
      "test_train\n",
      "train mean loss=0.06767018573979537\n",
      "test_test\n",
      "test mean loss=1158.0901489257812\n",
      "epoch 5234\n",
      "test_train\n",
      "train mean loss=0.07118452774981658\n",
      "test_test\n",
      "test mean loss=1157.9868469238281\n",
      "epoch 5235\n",
      "test_train\n",
      "train mean loss=0.07626481167972088\n",
      "test_test\n",
      "test mean loss=1159.0252685546875\n",
      "epoch 5236\n",
      "test_train\n",
      "train mean loss=0.06232428581764301\n",
      "test_test\n",
      "test mean loss=1158.44677734375\n",
      "epoch 5237\n",
      "test_train\n",
      "train mean loss=0.062206536841889225\n",
      "test_test\n",
      "test mean loss=1159.0265808105469\n",
      "epoch 5238\n",
      "test_train\n",
      "train mean loss=0.06837571691721678\n",
      "test_test\n",
      "test mean loss=1158.3743286132812\n",
      "epoch 5239\n",
      "test_train\n",
      "train mean loss=0.06973040848970413\n",
      "test_test\n",
      "test mean loss=1160.2264709472656\n",
      "epoch 5240\n",
      "test_train\n",
      "train mean loss=0.07262603162477414\n",
      "test_test\n",
      "test mean loss=1159.8711547851562\n",
      "epoch 5241\n",
      "test_train\n",
      "train mean loss=0.06959686428308487\n",
      "test_test\n",
      "test mean loss=1159.0914306640625\n",
      "epoch 5242\n",
      "test_train\n",
      "train mean loss=0.1373230665922165\n",
      "test_test\n",
      "test mean loss=1161.255615234375\n",
      "epoch 5243\n",
      "test_train\n",
      "train mean loss=0.06696416654934485\n",
      "test_test\n",
      "test mean loss=1158.9359741210938\n",
      "epoch 5244\n",
      "test_train\n",
      "train mean loss=0.06987771081427734\n",
      "test_test\n",
      "test mean loss=1158.9273071289062\n",
      "epoch 5245\n",
      "test_train\n",
      "train mean loss=0.06478431494906545\n",
      "test_test\n",
      "test mean loss=1158.6649780273438\n",
      "epoch 5246\n",
      "test_train\n",
      "train mean loss=0.08006253217657407\n",
      "test_test\n",
      "test mean loss=1159.24609375\n",
      "epoch 5247\n",
      "test_train\n",
      "train mean loss=0.06748087176432212\n",
      "test_test\n",
      "test mean loss=1159.1477355957031\n",
      "epoch 5248\n",
      "test_train\n",
      "train mean loss=0.06633706390857697\n",
      "test_test\n",
      "test mean loss=1158.4412536621094\n",
      "epoch 5249\n",
      "test_train\n",
      "train mean loss=0.07124488179882367\n",
      "test_test\n",
      "test mean loss=1157.8296508789062\n",
      "epoch 5250\n",
      "test_train\n",
      "train mean loss=0.061695034305254616\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1157.527587890625\n",
      "epoch 5251\n",
      "test_train\n",
      "train mean loss=0.061615564239521824\n",
      "test_test\n",
      "test mean loss=1157.8153076171875\n",
      "epoch 5252\n",
      "test_train\n",
      "train mean loss=0.0659270581478874\n",
      "test_test\n",
      "test mean loss=1158.6201477050781\n",
      "epoch 5253\n",
      "test_train\n",
      "train mean loss=0.07248101600756247\n",
      "test_test\n",
      "test mean loss=1159.1786193847656\n",
      "epoch 5254\n",
      "test_train\n",
      "train mean loss=0.05816273018717766\n",
      "test_test\n",
      "test mean loss=1157.1016845703125\n",
      "epoch 5255\n",
      "test_train\n",
      "train mean loss=0.06851187068969011\n",
      "test_test\n",
      "test mean loss=1158.0667724609375\n",
      "epoch 5256\n",
      "test_train\n",
      "train mean loss=0.09111963057269652\n",
      "test_test\n",
      "test mean loss=1157.0557861328125\n",
      "epoch 5257\n",
      "test_train\n",
      "train mean loss=0.06996977453430493\n",
      "test_test\n",
      "test mean loss=1157.5081481933594\n",
      "epoch 5258\n",
      "test_train\n",
      "train mean loss=0.06643084871272247\n",
      "test_test\n",
      "test mean loss=1158.2818603515625\n",
      "epoch 5259\n",
      "test_train\n",
      "train mean loss=0.06991986899326245\n",
      "test_test\n",
      "test mean loss=1158.238037109375\n",
      "epoch 5260\n",
      "test_train\n",
      "train mean loss=0.07121659566958745\n",
      "test_test\n",
      "test mean loss=1158.2747802734375\n",
      "epoch 5261\n",
      "test_train\n",
      "train mean loss=0.06560047250241041\n",
      "test_test\n",
      "test mean loss=1157.5020751953125\n",
      "epoch 5262\n",
      "test_train\n",
      "train mean loss=0.06323507241904736\n",
      "test_test\n",
      "test mean loss=1157.6651000976562\n",
      "epoch 5263\n",
      "test_train\n",
      "train mean loss=0.05596629002441963\n",
      "test_test\n",
      "test mean loss=1157.8279418945312\n",
      "epoch 5264\n",
      "test_train\n",
      "train mean loss=0.06281211196134488\n",
      "test_test\n",
      "test mean loss=1158.7576904296875\n",
      "epoch 5265\n",
      "test_train\n",
      "train mean loss=0.0628872700035572\n",
      "test_test\n",
      "test mean loss=1158.4634094238281\n",
      "epoch 5266\n",
      "test_train\n",
      "train mean loss=0.0598708752853175\n",
      "test_test\n",
      "test mean loss=1158.2869262695312\n",
      "epoch 5267\n",
      "test_train\n",
      "train mean loss=0.06371349065254132\n",
      "test_test\n",
      "test mean loss=1159.1870727539062\n",
      "epoch 5268\n",
      "test_train\n",
      "train mean loss=0.061406378323833145\n",
      "test_test\n",
      "test mean loss=1159.151611328125\n",
      "epoch 5269\n",
      "test_train\n",
      "train mean loss=0.06965515731523435\n",
      "test_test\n",
      "test mean loss=1160.3842468261719\n",
      "epoch 5270\n",
      "test_train\n",
      "train mean loss=0.07675839836398761\n",
      "test_test\n",
      "test mean loss=1160.1522827148438\n",
      "epoch 5271\n",
      "test_train\n",
      "train mean loss=0.07203392963856459\n",
      "test_test\n",
      "test mean loss=1159.6091918945312\n",
      "epoch 5272\n",
      "test_train\n",
      "train mean loss=0.07050839811563492\n",
      "test_test\n",
      "test mean loss=1159.1834716796875\n",
      "epoch 5273\n",
      "test_train\n",
      "train mean loss=0.06424795805166165\n",
      "test_test\n",
      "test mean loss=1158.7803955078125\n",
      "epoch 5274\n",
      "test_train\n",
      "train mean loss=0.06366810295730829\n",
      "test_test\n",
      "test mean loss=1159.0659790039062\n",
      "epoch 5275\n",
      "test_train\n",
      "train mean loss=0.065901605412364\n",
      "test_test\n",
      "test mean loss=1158.5914916992188\n",
      "epoch 5276\n",
      "test_train\n",
      "train mean loss=0.07197444420307875\n",
      "test_test\n",
      "test mean loss=1158.5921020507812\n",
      "epoch 5277\n",
      "test_train\n",
      "train mean loss=0.0703268339857459\n",
      "test_test\n",
      "test mean loss=1158.3507080078125\n",
      "epoch 5278\n",
      "test_train\n",
      "train mean loss=0.06568543612957001\n",
      "test_test\n",
      "test mean loss=1158.9069213867188\n",
      "epoch 5279\n",
      "test_train\n",
      "train mean loss=0.06702383266141017\n",
      "test_test\n",
      "test mean loss=1158.4202270507812\n",
      "epoch 5280\n",
      "test_train\n",
      "train mean loss=0.06635024212300777\n",
      "test_test\n",
      "test mean loss=1158.0028991699219\n",
      "epoch 5281\n",
      "test_train\n",
      "train mean loss=0.06508289060244958\n",
      "test_test\n",
      "test mean loss=1157.2467651367188\n",
      "epoch 5282\n",
      "test_train\n",
      "train mean loss=0.06824829864005248\n",
      "test_test\n",
      "test mean loss=1156.9166259765625\n",
      "epoch 5283\n",
      "test_train\n",
      "train mean loss=0.06228619286169609\n",
      "test_test\n",
      "test mean loss=1157.8024291992188\n",
      "epoch 5284\n",
      "test_train\n",
      "train mean loss=0.06059737751881281\n",
      "test_test\n",
      "test mean loss=1158.2373046875\n",
      "epoch 5285\n",
      "test_train\n",
      "train mean loss=0.05807297211140394\n",
      "test_test\n",
      "test mean loss=1157.6736145019531\n",
      "epoch 5286\n",
      "test_train\n",
      "train mean loss=0.06652169690156977\n",
      "test_test\n",
      "test mean loss=1158.6346130371094\n",
      "epoch 5287\n",
      "test_train\n",
      "train mean loss=0.07492066329965989\n",
      "test_test\n",
      "test mean loss=1157.6264343261719\n",
      "epoch 5288\n",
      "test_train\n",
      "train mean loss=0.06074893878151973\n",
      "test_test\n",
      "test mean loss=1157.6757507324219\n",
      "epoch 5289\n",
      "test_train\n",
      "train mean loss=0.06821119040250778\n",
      "test_test\n",
      "test mean loss=1158.319091796875\n",
      "epoch 5290\n",
      "test_train\n",
      "train mean loss=0.08420208655297756\n",
      "test_test\n",
      "test mean loss=1158.5989685058594\n",
      "epoch 5291\n",
      "test_train\n",
      "train mean loss=0.0710853065053622\n",
      "test_test\n",
      "test mean loss=1158.6513061523438\n",
      "epoch 5292\n",
      "test_train\n",
      "train mean loss=0.07010051980614662\n",
      "test_test\n",
      "test mean loss=1158.7347412109375\n",
      "epoch 5293\n",
      "test_train\n",
      "train mean loss=0.06852024048566818\n",
      "test_test\n",
      "test mean loss=1158.5704345703125\n",
      "epoch 5294\n",
      "test_train\n",
      "train mean loss=0.06225954461842775\n",
      "test_test\n",
      "test mean loss=1157.1825866699219\n",
      "epoch 5295\n",
      "test_train\n",
      "train mean loss=0.06235348774741093\n",
      "test_test\n",
      "test mean loss=1158.0191040039062\n",
      "epoch 5296\n",
      "test_train\n",
      "train mean loss=0.06817184357593457\n",
      "test_test\n",
      "test mean loss=1158.2861328125\n",
      "epoch 5297\n",
      "test_train\n",
      "train mean loss=0.06253305822610855\n",
      "test_test\n",
      "test mean loss=1157.8454895019531\n",
      "epoch 5298\n",
      "test_train\n",
      "train mean loss=0.06410878881191213\n",
      "test_test\n",
      "test mean loss=1158.9458618164062\n",
      "epoch 5299\n",
      "test_train\n",
      "train mean loss=0.06721304884801309\n",
      "test_test\n",
      "test mean loss=1158.487060546875\n",
      "epoch 5300\n",
      "test_train\n",
      "train mean loss=0.07156998664140701\n",
      "test_test\n",
      "test mean loss=1158.4741516113281\n",
      "epoch 5301\n",
      "test_train\n",
      "train mean loss=0.07556277420371771\n",
      "test_test\n",
      "test mean loss=1158.6331481933594\n",
      "epoch 5302\n",
      "test_train\n",
      "train mean loss=0.06272042356431484\n",
      "test_test\n",
      "test mean loss=1159.2938232421875\n",
      "epoch 5303\n",
      "test_train\n",
      "train mean loss=0.06839506731679042\n",
      "test_test\n",
      "test mean loss=1159.3082885742188\n",
      "epoch 5304\n",
      "test_train\n",
      "train mean loss=0.06665135361254215\n",
      "test_test\n",
      "test mean loss=1158.7774047851562\n",
      "epoch 5305\n",
      "test_train\n",
      "train mean loss=0.07093253172934055\n",
      "test_test\n",
      "test mean loss=1159.4971923828125\n",
      "epoch 5306\n",
      "test_train\n",
      "train mean loss=0.06425334699451923\n",
      "test_test\n",
      "test mean loss=1159.6350402832031\n",
      "epoch 5307\n",
      "test_train\n",
      "train mean loss=0.06605580914765596\n",
      "test_test\n",
      "test mean loss=1158.5848388671875\n",
      "epoch 5308\n",
      "test_train\n",
      "train mean loss=0.06105675455182791\n",
      "test_test\n",
      "test mean loss=1158.7236328125\n",
      "epoch 5309\n",
      "test_train\n",
      "train mean loss=0.06399936073770125\n",
      "test_test\n",
      "test mean loss=1158.2487487792969\n",
      "epoch 5310\n",
      "test_train\n",
      "train mean loss=0.0597896600763003\n",
      "test_test\n",
      "test mean loss=1158.5420532226562\n",
      "epoch 5311\n",
      "test_train\n",
      "train mean loss=0.06859579371909301\n",
      "test_test\n",
      "test mean loss=1158.1113891601562\n",
      "epoch 5312\n",
      "test_train\n",
      "train mean loss=0.06505468456695478\n",
      "test_test\n",
      "test mean loss=1157.4974975585938\n",
      "epoch 5313\n",
      "test_train\n",
      "train mean loss=0.06900774221867323\n",
      "test_test\n",
      "test mean loss=1157.6788330078125\n",
      "epoch 5314\n",
      "test_train\n",
      "train mean loss=0.06935143905381362\n",
      "test_test\n",
      "test mean loss=1159.12255859375\n",
      "epoch 5315\n",
      "test_train\n",
      "train mean loss=0.06760416366159916\n",
      "test_test\n",
      "test mean loss=1158.0673522949219\n",
      "epoch 5316\n",
      "test_train\n",
      "train mean loss=0.06513255337874095\n",
      "test_test\n",
      "test mean loss=1158.2980346679688\n",
      "epoch 5317\n",
      "test_train\n",
      "train mean loss=0.060294020300110183\n",
      "test_test\n",
      "test mean loss=1158.2789306640625\n",
      "epoch 5318\n",
      "test_train\n",
      "train mean loss=0.0616462342441082\n",
      "test_test\n",
      "test mean loss=1158.413330078125\n",
      "epoch 5319\n",
      "test_train\n",
      "train mean loss=0.062281712579230465\n",
      "test_test\n",
      "test mean loss=1158.4086303710938\n",
      "epoch 5320\n",
      "test_train\n",
      "train mean loss=0.06475902007271846\n",
      "test_test\n",
      "test mean loss=1158.4434204101562\n",
      "epoch 5321\n",
      "test_train\n",
      "train mean loss=0.0652259277800719\n",
      "test_test\n",
      "test mean loss=1158.9677734375\n",
      "epoch 5322\n",
      "test_train\n",
      "train mean loss=0.06674040822933118\n",
      "test_test\n",
      "test mean loss=1158.9841918945312\n",
      "epoch 5323\n",
      "test_train\n",
      "train mean loss=0.07591022706280152\n",
      "test_test\n",
      "test mean loss=1159.3087768554688\n",
      "epoch 5324\n",
      "test_train\n",
      "train mean loss=0.07084311544895172\n",
      "test_test\n",
      "test mean loss=1158.133544921875\n",
      "epoch 5325\n",
      "test_train\n",
      "train mean loss=0.07201896049082279\n",
      "test_test\n",
      "test mean loss=1158.7039794921875\n",
      "epoch 5326\n",
      "test_train\n",
      "train mean loss=0.06496193849792083\n",
      "test_test\n",
      "test mean loss=1157.5893249511719\n",
      "epoch 5327\n",
      "test_train\n",
      "train mean loss=0.05659990757703781\n",
      "test_test\n",
      "test mean loss=1158.16796875\n",
      "epoch 5328\n",
      "test_train\n",
      "train mean loss=0.06759081532557805\n",
      "test_test\n",
      "test mean loss=1158.5675659179688\n",
      "epoch 5329\n",
      "test_train\n",
      "train mean loss=0.07251761698474486\n",
      "test_test\n",
      "test mean loss=1158.8460998535156\n",
      "epoch 5330\n",
      "test_train\n",
      "train mean loss=0.06381495762616396\n",
      "test_test\n",
      "test mean loss=1158.1667785644531\n",
      "epoch 5331\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.0690105448787411\n",
      "test_test\n",
      "test mean loss=1158.8262634277344\n",
      "epoch 5332\n",
      "test_train\n",
      "train mean loss=0.07044410270949204\n",
      "test_test\n",
      "test mean loss=1158.5352172851562\n",
      "epoch 5333\n",
      "test_train\n",
      "train mean loss=0.06515255725632112\n",
      "test_test\n",
      "test mean loss=1158.1593627929688\n",
      "epoch 5334\n",
      "test_train\n",
      "train mean loss=0.06385301208744447\n",
      "test_test\n",
      "test mean loss=1157.3112487792969\n",
      "epoch 5335\n",
      "test_train\n",
      "train mean loss=0.058438529881338276\n",
      "test_test\n",
      "test mean loss=1157.8255004882812\n",
      "epoch 5336\n",
      "test_train\n",
      "train mean loss=0.0634148707613349\n",
      "test_test\n",
      "test mean loss=1157.8228759765625\n",
      "epoch 5337\n",
      "test_train\n",
      "train mean loss=0.06734430106977622\n",
      "test_test\n",
      "test mean loss=1158.3101196289062\n",
      "epoch 5338\n",
      "test_train\n",
      "train mean loss=0.07313694121936958\n",
      "test_test\n",
      "test mean loss=1157.977783203125\n",
      "epoch 5339\n",
      "test_train\n",
      "train mean loss=0.07348487029472987\n",
      "test_test\n",
      "test mean loss=1158.098388671875\n",
      "epoch 5340\n",
      "test_train\n",
      "train mean loss=0.06867949571460485\n",
      "test_test\n",
      "test mean loss=1157.7070922851562\n",
      "epoch 5341\n",
      "test_train\n",
      "train mean loss=0.07026336745669444\n",
      "test_test\n",
      "test mean loss=1157.8311767578125\n",
      "epoch 5342\n",
      "test_train\n",
      "train mean loss=0.06669502798467875\n",
      "test_test\n",
      "test mean loss=1157.2960510253906\n",
      "epoch 5343\n",
      "test_train\n",
      "train mean loss=0.06518049693355958\n",
      "test_test\n",
      "test mean loss=1157.4508056640625\n",
      "epoch 5344\n",
      "test_train\n",
      "train mean loss=0.06208527460694313\n",
      "test_test\n",
      "test mean loss=1156.8579711914062\n",
      "epoch 5345\n",
      "test_train\n",
      "train mean loss=0.06773257348686457\n",
      "test_test\n",
      "test mean loss=1158.4674072265625\n",
      "epoch 5346\n",
      "test_train\n",
      "train mean loss=0.06521006270001332\n",
      "test_test\n",
      "test mean loss=1158.0403442382812\n",
      "epoch 5347\n",
      "test_train\n",
      "train mean loss=0.06099786749109626\n",
      "test_test\n",
      "test mean loss=1157.0611572265625\n",
      "epoch 5348\n",
      "test_train\n",
      "train mean loss=0.07341527969886859\n",
      "test_test\n",
      "test mean loss=1157.5474853515625\n",
      "epoch 5349\n",
      "test_train\n",
      "train mean loss=0.06763733426729839\n",
      "test_test\n",
      "test mean loss=1158.6443481445312\n",
      "epoch 5350\n",
      "test_train\n",
      "train mean loss=0.13069682382047176\n",
      "test_test\n",
      "test mean loss=1160.99365234375\n",
      "epoch 5351\n",
      "test_train\n",
      "train mean loss=0.07004591108610232\n",
      "test_test\n",
      "test mean loss=1159.907958984375\n",
      "epoch 5352\n",
      "test_train\n",
      "train mean loss=0.1195220872759819\n",
      "test_test\n",
      "test mean loss=1162.0106201171875\n",
      "epoch 5353\n",
      "test_train\n",
      "train mean loss=0.07403496497621138\n",
      "test_test\n",
      "test mean loss=1160.7504272460938\n",
      "epoch 5354\n",
      "test_train\n",
      "train mean loss=0.0723324604332447\n",
      "test_test\n",
      "test mean loss=1159.0108032226562\n",
      "epoch 5355\n",
      "test_train\n",
      "train mean loss=0.07774093560874462\n",
      "test_test\n",
      "test mean loss=1160.361083984375\n",
      "epoch 5356\n",
      "test_train\n",
      "train mean loss=0.07731943298131227\n",
      "test_test\n",
      "test mean loss=1157.9270324707031\n",
      "epoch 5357\n",
      "test_train\n",
      "train mean loss=0.07277600653469563\n",
      "test_test\n",
      "test mean loss=1158.5211791992188\n",
      "epoch 5358\n",
      "test_train\n",
      "train mean loss=0.06603177605817716\n",
      "test_test\n",
      "test mean loss=1158.4972534179688\n",
      "epoch 5359\n",
      "test_train\n",
      "train mean loss=0.07299895615627368\n",
      "test_test\n",
      "test mean loss=1158.6820373535156\n",
      "epoch 5360\n",
      "test_train\n",
      "train mean loss=0.0715863723307848\n",
      "test_test\n",
      "test mean loss=1158.3799438476562\n",
      "epoch 5361\n",
      "test_train\n",
      "train mean loss=0.07977866629759471\n",
      "test_test\n",
      "test mean loss=1159.6610717773438\n",
      "epoch 5362\n",
      "test_train\n",
      "train mean loss=0.07602023240178823\n",
      "test_test\n",
      "test mean loss=1158.8046264648438\n",
      "epoch 5363\n",
      "test_train\n",
      "train mean loss=0.07288942548135917\n",
      "test_test\n",
      "test mean loss=1160.0539245605469\n",
      "epoch 5364\n",
      "test_train\n",
      "train mean loss=0.0681955028946201\n",
      "test_test\n",
      "test mean loss=1159.5406494140625\n",
      "epoch 5365\n",
      "test_train\n",
      "train mean loss=0.06667626897493999\n",
      "test_test\n",
      "test mean loss=1157.4635009765625\n",
      "epoch 5366\n",
      "test_train\n",
      "train mean loss=0.0728730324966212\n",
      "test_test\n",
      "test mean loss=1158.8570556640625\n",
      "epoch 5367\n",
      "test_train\n",
      "train mean loss=0.0712597311163942\n",
      "test_test\n",
      "test mean loss=1158.85009765625\n",
      "epoch 5368\n",
      "test_train\n",
      "train mean loss=0.06715994949142139\n",
      "test_test\n",
      "test mean loss=1159.6099853515625\n",
      "epoch 5369\n",
      "test_train\n",
      "train mean loss=0.06719532919426759\n",
      "test_test\n",
      "test mean loss=1158.9505310058594\n",
      "epoch 5370\n",
      "test_train\n",
      "train mean loss=0.06372758590926726\n",
      "test_test\n",
      "test mean loss=1159.1942749023438\n",
      "epoch 5371\n",
      "test_train\n",
      "train mean loss=0.07220657511303823\n",
      "test_test\n",
      "test mean loss=1159.374755859375\n",
      "epoch 5372\n",
      "test_train\n",
      "train mean loss=0.07790689480801423\n",
      "test_test\n",
      "test mean loss=1159.8519897460938\n",
      "epoch 5373\n",
      "test_train\n",
      "train mean loss=0.0636484157294035\n",
      "test_test\n",
      "test mean loss=1158.8626708984375\n",
      "epoch 5374\n",
      "test_train\n",
      "train mean loss=0.06897839717566967\n",
      "test_test\n",
      "test mean loss=1159.4779052734375\n",
      "epoch 5375\n",
      "test_train\n",
      "train mean loss=0.06725250463932753\n",
      "test_test\n",
      "test mean loss=1159.8248901367188\n",
      "epoch 5376\n",
      "test_train\n",
      "train mean loss=0.06975607636074226\n",
      "test_test\n",
      "test mean loss=1159.3643188476562\n",
      "epoch 5377\n",
      "test_train\n",
      "train mean loss=0.08057107559094827\n",
      "test_test\n",
      "test mean loss=1159.9596557617188\n",
      "epoch 5378\n",
      "test_train\n",
      "train mean loss=0.06833130804200967\n",
      "test_test\n",
      "test mean loss=1158.8868408203125\n",
      "epoch 5379\n",
      "test_train\n",
      "train mean loss=0.06513460259884596\n",
      "test_test\n",
      "test mean loss=1159.4563598632812\n",
      "epoch 5380\n",
      "test_train\n",
      "train mean loss=0.06450238358229399\n",
      "test_test\n",
      "test mean loss=1159.5225524902344\n",
      "epoch 5381\n",
      "test_train\n",
      "train mean loss=0.06054844862471024\n",
      "test_test\n",
      "test mean loss=1159.106201171875\n",
      "epoch 5382\n",
      "test_train\n",
      "train mean loss=0.06162728431324164\n",
      "test_test\n",
      "test mean loss=1159.5150451660156\n",
      "epoch 5383\n",
      "test_train\n",
      "train mean loss=0.05863068299368024\n",
      "test_test\n",
      "test mean loss=1158.4899291992188\n",
      "epoch 5384\n",
      "test_train\n",
      "train mean loss=0.06368744776894648\n",
      "test_test\n",
      "test mean loss=1160.2081909179688\n",
      "epoch 5385\n",
      "test_train\n",
      "train mean loss=0.06415429462989171\n",
      "test_test\n",
      "test mean loss=1159.0496826171875\n",
      "epoch 5386\n",
      "test_train\n",
      "train mean loss=0.06346559214095275\n",
      "test_test\n",
      "test mean loss=1159.3146362304688\n",
      "epoch 5387\n",
      "test_train\n",
      "train mean loss=0.08253556117415428\n",
      "test_test\n",
      "test mean loss=1159.5037841796875\n",
      "epoch 5388\n",
      "test_train\n",
      "train mean loss=0.0667494130320847\n",
      "test_test\n",
      "test mean loss=1160.1786499023438\n",
      "epoch 5389\n",
      "test_train\n",
      "train mean loss=0.6766300275921822\n",
      "test_test\n",
      "test mean loss=1164.106201171875\n",
      "epoch 5390\n",
      "test_train\n",
      "train mean loss=0.13221989820400873\n",
      "test_test\n",
      "test mean loss=1162.170166015625\n",
      "epoch 5391\n",
      "test_train\n",
      "train mean loss=0.08020787717153628\n",
      "test_test\n",
      "test mean loss=1161.8994750976562\n",
      "epoch 5392\n",
      "test_train\n",
      "train mean loss=0.09111505933105946\n",
      "test_test\n",
      "test mean loss=1160.9223022460938\n",
      "epoch 5393\n",
      "test_train\n",
      "train mean loss=0.07885762179891269\n",
      "test_test\n",
      "test mean loss=1161.9821166992188\n",
      "epoch 5394\n",
      "test_train\n",
      "train mean loss=0.0743879429064691\n",
      "test_test\n",
      "test mean loss=1160.9015502929688\n",
      "epoch 5395\n",
      "test_train\n",
      "train mean loss=0.07824290078133345\n",
      "test_test\n",
      "test mean loss=1160.6502075195312\n",
      "epoch 5396\n",
      "test_train\n",
      "train mean loss=0.07430359007169803\n",
      "test_test\n",
      "test mean loss=1160.4507141113281\n",
      "epoch 5397\n",
      "test_train\n",
      "train mean loss=0.08090668606261413\n",
      "test_test\n",
      "test mean loss=1160.5759887695312\n",
      "epoch 5398\n",
      "test_train\n",
      "train mean loss=0.0679817780231436\n",
      "test_test\n",
      "test mean loss=1160.254150390625\n",
      "epoch 5399\n",
      "test_train\n",
      "train mean loss=0.07076434387514989\n",
      "test_test\n",
      "test mean loss=1159.9232482910156\n",
      "epoch 5400\n",
      "test_train\n",
      "train mean loss=0.07276347698643804\n",
      "test_test\n",
      "test mean loss=1158.8268127441406\n",
      "epoch 5401\n",
      "test_train\n",
      "train mean loss=0.07215669626990955\n",
      "test_test\n",
      "test mean loss=1158.6842041015625\n",
      "epoch 5402\n",
      "test_train\n",
      "train mean loss=0.07278504812469085\n",
      "test_test\n",
      "test mean loss=1158.0394897460938\n",
      "epoch 5403\n",
      "test_train\n",
      "train mean loss=0.07450184101859729\n",
      "test_test\n",
      "test mean loss=1158.8912963867188\n",
      "epoch 5404\n",
      "test_train\n",
      "train mean loss=0.06890869823594888\n",
      "test_test\n",
      "test mean loss=1157.4598388671875\n",
      "epoch 5405\n",
      "test_train\n",
      "train mean loss=0.05916524678468704\n",
      "test_test\n",
      "test mean loss=1157.284423828125\n",
      "epoch 5406\n",
      "test_train\n",
      "train mean loss=0.0674978553627928\n",
      "test_test\n",
      "test mean loss=1158.0346069335938\n",
      "epoch 5407\n",
      "test_train\n",
      "train mean loss=0.06440435474117596\n",
      "test_test\n",
      "test mean loss=1158.0559692382812\n",
      "epoch 5408\n",
      "test_train\n",
      "train mean loss=0.06807407395293315\n",
      "test_test\n",
      "test mean loss=1157.9465637207031\n",
      "epoch 5409\n",
      "test_train\n",
      "train mean loss=0.06486507629354794\n",
      "test_test\n",
      "test mean loss=1158.508056640625\n",
      "epoch 5410\n",
      "test_train\n",
      "train mean loss=0.06578891103466351\n",
      "test_test\n",
      "test mean loss=1157.8242492675781\n",
      "epoch 5411\n",
      "test_train\n",
      "train mean loss=0.06325482421865065\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1158.5890197753906\n",
      "epoch 5412\n",
      "test_train\n",
      "train mean loss=0.06048142444342375\n",
      "test_test\n",
      "test mean loss=1158.806396484375\n",
      "epoch 5413\n",
      "test_train\n",
      "train mean loss=0.06297694984823465\n",
      "test_test\n",
      "test mean loss=1159.71435546875\n",
      "epoch 5414\n",
      "test_train\n",
      "train mean loss=0.062290756652752556\n",
      "test_test\n",
      "test mean loss=1158.58056640625\n",
      "epoch 5415\n",
      "test_train\n",
      "train mean loss=0.06458935793489218\n",
      "test_test\n",
      "test mean loss=1158.0083618164062\n",
      "epoch 5416\n",
      "test_train\n",
      "train mean loss=0.06661191303282976\n",
      "test_test\n",
      "test mean loss=1159.0291137695312\n",
      "epoch 5417\n",
      "test_train\n",
      "train mean loss=0.06288275122642517\n",
      "test_test\n",
      "test mean loss=1158.8468627929688\n",
      "epoch 5418\n",
      "test_train\n",
      "train mean loss=0.06787381538500388\n",
      "test_test\n",
      "test mean loss=1157.4035949707031\n",
      "epoch 5419\n",
      "test_train\n",
      "train mean loss=0.06341927622755368\n",
      "test_test\n",
      "test mean loss=1158.618896484375\n",
      "epoch 5420\n",
      "test_train\n",
      "train mean loss=0.06047899089753628\n",
      "test_test\n",
      "test mean loss=1157.9465637207031\n",
      "epoch 5421\n",
      "test_train\n",
      "train mean loss=0.06614671492328246\n",
      "test_test\n",
      "test mean loss=1158.2550659179688\n",
      "epoch 5422\n",
      "test_train\n",
      "train mean loss=0.06318323407322168\n",
      "test_test\n",
      "test mean loss=1157.41015625\n",
      "epoch 5423\n",
      "test_train\n",
      "train mean loss=0.060700702791412674\n",
      "test_test\n",
      "test mean loss=1157.6375122070312\n",
      "epoch 5424\n",
      "test_train\n",
      "train mean loss=0.06884834977487723\n",
      "test_test\n",
      "test mean loss=1157.7429809570312\n",
      "epoch 5425\n",
      "test_train\n",
      "train mean loss=0.068016169903179\n",
      "test_test\n",
      "test mean loss=1157.1500244140625\n",
      "epoch 5426\n",
      "test_train\n",
      "train mean loss=0.06362690000484388\n",
      "test_test\n",
      "test mean loss=1157.6651611328125\n",
      "epoch 5427\n",
      "test_train\n",
      "train mean loss=0.06549306369076173\n",
      "test_test\n",
      "test mean loss=1158.8518676757812\n",
      "epoch 5428\n",
      "test_train\n",
      "train mean loss=0.06217295924822489\n",
      "test_test\n",
      "test mean loss=1157.9861145019531\n",
      "epoch 5429\n",
      "test_train\n",
      "train mean loss=0.07322998779515426\n",
      "test_test\n",
      "test mean loss=1158.7032775878906\n",
      "epoch 5430\n",
      "test_train\n",
      "train mean loss=0.06740685272961855\n",
      "test_test\n",
      "test mean loss=1158.3623962402344\n",
      "epoch 5431\n",
      "test_train\n",
      "train mean loss=0.07152278907597065\n",
      "test_test\n",
      "test mean loss=1157.4869079589844\n",
      "epoch 5432\n",
      "test_train\n",
      "train mean loss=0.07413530629128218\n",
      "test_test\n",
      "test mean loss=1159.1521301269531\n",
      "epoch 5433\n",
      "test_train\n",
      "train mean loss=0.07774752906213205\n",
      "test_test\n",
      "test mean loss=1158.3445434570312\n",
      "epoch 5434\n",
      "test_train\n",
      "train mean loss=0.06821625897039969\n",
      "test_test\n",
      "test mean loss=1158.1068725585938\n",
      "epoch 5435\n",
      "test_train\n",
      "train mean loss=0.06680485668281715\n",
      "test_test\n",
      "test mean loss=1157.3788452148438\n",
      "epoch 5436\n",
      "test_train\n",
      "train mean loss=0.06951585939774911\n",
      "test_test\n",
      "test mean loss=1157.6541748046875\n",
      "epoch 5437\n",
      "test_train\n",
      "train mean loss=0.06988354865461588\n",
      "test_test\n",
      "test mean loss=1157.6377563476562\n",
      "epoch 5438\n",
      "test_train\n",
      "train mean loss=0.06439087043205897\n",
      "test_test\n",
      "test mean loss=1158.656982421875\n",
      "epoch 5439\n",
      "test_train\n",
      "train mean loss=0.0668216235935688\n",
      "test_test\n",
      "test mean loss=1159.2278442382812\n",
      "epoch 5440\n",
      "test_train\n",
      "train mean loss=0.06319722222785155\n",
      "test_test\n",
      "test mean loss=1157.80078125\n",
      "epoch 5441\n",
      "test_train\n",
      "train mean loss=0.12240994721651077\n",
      "test_test\n",
      "test mean loss=1157.684814453125\n",
      "epoch 5442\n",
      "test_train\n",
      "train mean loss=0.08132886638243993\n",
      "test_test\n",
      "test mean loss=1158.5849914550781\n",
      "epoch 5443\n",
      "test_train\n",
      "train mean loss=0.07289064240952332\n",
      "test_test\n",
      "test mean loss=1157.7272338867188\n",
      "epoch 5444\n",
      "test_train\n",
      "train mean loss=0.06804484811921914\n",
      "test_test\n",
      "test mean loss=1159.2415161132812\n",
      "epoch 5445\n",
      "test_train\n",
      "train mean loss=0.0628608128366371\n",
      "test_test\n",
      "test mean loss=1158.7896728515625\n",
      "epoch 5446\n",
      "test_train\n",
      "train mean loss=0.06094302050769329\n",
      "test_test\n",
      "test mean loss=1158.3369445800781\n",
      "epoch 5447\n",
      "test_train\n",
      "train mean loss=0.06919041679551204\n",
      "test_test\n",
      "test mean loss=1159.2609558105469\n",
      "epoch 5448\n",
      "test_train\n",
      "train mean loss=0.067902027318875\n",
      "test_test\n",
      "test mean loss=1158.3529052734375\n",
      "epoch 5449\n",
      "test_train\n",
      "train mean loss=0.06830550978581111\n",
      "test_test\n",
      "test mean loss=1159.0676879882812\n",
      "epoch 5450\n",
      "test_train\n",
      "train mean loss=0.0694656992952029\n",
      "test_test\n",
      "test mean loss=1159.7257080078125\n",
      "epoch 5451\n",
      "test_train\n",
      "train mean loss=0.06885380453119676\n",
      "test_test\n",
      "test mean loss=1159.6563720703125\n",
      "epoch 5452\n",
      "test_train\n",
      "train mean loss=0.06746529756734769\n",
      "test_test\n",
      "test mean loss=1159.1064147949219\n",
      "epoch 5453\n",
      "test_train\n",
      "train mean loss=0.08059587360670169\n",
      "test_test\n",
      "test mean loss=1159.2651977539062\n",
      "epoch 5454\n",
      "test_train\n",
      "train mean loss=0.065057549936076\n",
      "test_test\n",
      "test mean loss=1159.2601928710938\n",
      "epoch 5455\n",
      "test_train\n",
      "train mean loss=0.06495261130233605\n",
      "test_test\n",
      "test mean loss=1158.4541015625\n",
      "epoch 5456\n",
      "test_train\n",
      "train mean loss=0.06693438130120437\n",
      "test_test\n",
      "test mean loss=1159.2128295898438\n",
      "epoch 5457\n",
      "test_train\n",
      "train mean loss=0.09617324732244015\n",
      "test_test\n",
      "test mean loss=1159.498779296875\n",
      "epoch 5458\n",
      "test_train\n",
      "train mean loss=0.06465404573827982\n",
      "test_test\n",
      "test mean loss=1158.84619140625\n",
      "epoch 5459\n",
      "test_train\n",
      "train mean loss=0.06800311865905921\n",
      "test_test\n",
      "test mean loss=1158.9578857421875\n",
      "epoch 5460\n",
      "test_train\n",
      "train mean loss=0.06612386895964543\n",
      "test_test\n",
      "test mean loss=1158.3351440429688\n",
      "epoch 5461\n",
      "test_train\n",
      "train mean loss=0.07636925453941028\n",
      "test_test\n",
      "test mean loss=1158.2533569335938\n",
      "epoch 5462\n",
      "test_train\n",
      "train mean loss=0.07202541486670573\n",
      "test_test\n",
      "test mean loss=1158.8126525878906\n",
      "epoch 5463\n",
      "test_train\n",
      "train mean loss=0.06344998441636562\n",
      "test_test\n",
      "test mean loss=1158.8682556152344\n",
      "epoch 5464\n",
      "test_train\n",
      "train mean loss=0.21314670518040657\n",
      "test_test\n",
      "test mean loss=1159.077880859375\n",
      "epoch 5465\n",
      "test_train\n",
      "train mean loss=0.07941481284797192\n",
      "test_test\n",
      "test mean loss=1160.8973388671875\n",
      "epoch 5466\n",
      "test_train\n",
      "train mean loss=0.06587256584316492\n",
      "test_test\n",
      "test mean loss=1159.6761169433594\n",
      "epoch 5467\n",
      "test_train\n",
      "train mean loss=0.06928209991504748\n",
      "test_test\n",
      "test mean loss=1160.6364135742188\n",
      "epoch 5468\n",
      "test_train\n",
      "train mean loss=0.07038629365464051\n",
      "test_test\n",
      "test mean loss=1159.6981506347656\n",
      "epoch 5469\n",
      "test_train\n",
      "train mean loss=0.07328152718643348\n",
      "test_test\n",
      "test mean loss=1160.1026000976562\n",
      "epoch 5470\n",
      "test_train\n",
      "train mean loss=0.06406705329815547\n",
      "test_test\n",
      "test mean loss=1159.947265625\n",
      "epoch 5471\n",
      "test_train\n",
      "train mean loss=0.06802807748317719\n",
      "test_test\n",
      "test mean loss=1159.0720520019531\n",
      "epoch 5472\n",
      "test_train\n",
      "train mean loss=0.07096107179919879\n",
      "test_test\n",
      "test mean loss=1159.3030700683594\n",
      "epoch 5473\n",
      "test_train\n",
      "train mean loss=0.07220679614692926\n",
      "test_test\n",
      "test mean loss=1159.482177734375\n",
      "epoch 5474\n",
      "test_train\n",
      "train mean loss=0.06680402128646772\n",
      "test_test\n",
      "test mean loss=1159.535400390625\n",
      "epoch 5475\n",
      "test_train\n",
      "train mean loss=0.06923283605525891\n",
      "test_test\n",
      "test mean loss=1159.05810546875\n",
      "epoch 5476\n",
      "test_train\n",
      "train mean loss=0.07445989549160004\n",
      "test_test\n",
      "test mean loss=1158.030029296875\n",
      "epoch 5477\n",
      "test_train\n",
      "train mean loss=0.07081762639184792\n",
      "test_test\n",
      "test mean loss=1158.6490783691406\n",
      "epoch 5478\n",
      "test_train\n",
      "train mean loss=0.08678403310477734\n",
      "test_test\n",
      "test mean loss=1158.9182739257812\n",
      "epoch 5479\n",
      "test_train\n",
      "train mean loss=0.07241280718396108\n",
      "test_test\n",
      "test mean loss=1159.5162048339844\n",
      "epoch 5480\n",
      "test_train\n",
      "train mean loss=0.07429193208614986\n",
      "test_test\n",
      "test mean loss=1159.2666015625\n",
      "epoch 5481\n",
      "test_train\n",
      "train mean loss=0.06836639313648145\n",
      "test_test\n",
      "test mean loss=1160.0491027832031\n",
      "epoch 5482\n",
      "test_train\n",
      "train mean loss=0.06464648308853309\n",
      "test_test\n",
      "test mean loss=1159.8845825195312\n",
      "epoch 5483\n",
      "test_train\n",
      "train mean loss=0.06657522761573394\n",
      "test_test\n",
      "test mean loss=1160.517578125\n",
      "epoch 5484\n",
      "test_train\n",
      "train mean loss=0.06611067491273086\n",
      "test_test\n",
      "test mean loss=1159.6785278320312\n",
      "epoch 5485\n",
      "test_train\n",
      "train mean loss=0.06186941095317403\n",
      "test_test\n",
      "test mean loss=1160.6288452148438\n",
      "epoch 5486\n",
      "test_train\n",
      "train mean loss=0.06100342112282912\n",
      "test_test\n",
      "test mean loss=1158.5953979492188\n",
      "epoch 5487\n",
      "test_train\n",
      "train mean loss=0.06339707970619202\n",
      "test_test\n",
      "test mean loss=1158.9613037109375\n",
      "epoch 5488\n",
      "test_train\n",
      "train mean loss=0.07032382612427075\n",
      "test_test\n",
      "test mean loss=1159.4337158203125\n",
      "epoch 5489\n",
      "test_train\n",
      "train mean loss=0.06982652315249045\n",
      "test_test\n",
      "test mean loss=1160.2259521484375\n",
      "epoch 5490\n",
      "test_train\n",
      "train mean loss=0.07397993529836337\n",
      "test_test\n",
      "test mean loss=1159.11767578125\n",
      "epoch 5491\n",
      "test_train\n",
      "train mean loss=0.07442842920621236\n",
      "test_test\n",
      "test mean loss=1159.1717529296875\n",
      "epoch 5492\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.06602061881373326\n",
      "test_test\n",
      "test mean loss=1159.3538513183594\n",
      "epoch 5493\n",
      "test_train\n",
      "train mean loss=0.06402110556761424\n",
      "test_test\n",
      "test mean loss=1159.4495239257812\n",
      "epoch 5494\n",
      "test_train\n",
      "train mean loss=0.06339914724230766\n",
      "test_test\n",
      "test mean loss=1158.9956665039062\n",
      "epoch 5495\n",
      "test_train\n",
      "train mean loss=0.07288727567841609\n",
      "test_test\n",
      "test mean loss=1159.18603515625\n",
      "epoch 5496\n",
      "test_train\n",
      "train mean loss=0.06952963676303625\n",
      "test_test\n",
      "test mean loss=1158.4288635253906\n",
      "epoch 5497\n",
      "test_train\n",
      "train mean loss=0.06660893435279529\n",
      "test_test\n",
      "test mean loss=1158.9007263183594\n",
      "epoch 5498\n",
      "test_train\n",
      "train mean loss=0.0693928673863411\n",
      "test_test\n",
      "test mean loss=1158.5554809570312\n",
      "epoch 5499\n",
      "test_train\n",
      "train mean loss=0.06659972139944632\n",
      "test_test\n",
      "test mean loss=1158.6739501953125\n",
      "epoch 5500\n",
      "test_train\n",
      "train mean loss=0.07063273340463638\n",
      "test_test\n",
      "test mean loss=1160.1848754882812\n",
      "epoch 5501\n",
      "test_train\n",
      "train mean loss=0.06822528224438429\n",
      "test_test\n",
      "test mean loss=1160.17578125\n",
      "epoch 5502\n",
      "test_train\n",
      "train mean loss=0.0675270442540447\n",
      "test_test\n",
      "test mean loss=1158.8687133789062\n",
      "epoch 5503\n",
      "test_train\n",
      "train mean loss=0.07681331411004066\n",
      "test_test\n",
      "test mean loss=1160.094970703125\n",
      "epoch 5504\n",
      "test_train\n",
      "train mean loss=0.0673839555432399\n",
      "test_test\n",
      "test mean loss=1158.4237976074219\n",
      "epoch 5505\n",
      "test_train\n",
      "train mean loss=0.06579065136611462\n",
      "test_test\n",
      "test mean loss=1159.0104064941406\n",
      "epoch 5506\n",
      "test_train\n",
      "train mean loss=0.06986868381500244\n",
      "test_test\n",
      "test mean loss=1161.0703125\n",
      "epoch 5507\n",
      "test_train\n",
      "train mean loss=0.0680517580670615\n",
      "test_test\n",
      "test mean loss=1158.3604431152344\n",
      "epoch 5508\n",
      "test_train\n",
      "train mean loss=0.07029243030895789\n",
      "test_test\n",
      "test mean loss=1158.537841796875\n",
      "epoch 5509\n",
      "test_train\n",
      "train mean loss=0.0745901744812727\n",
      "test_test\n",
      "test mean loss=1158.985595703125\n",
      "epoch 5510\n",
      "test_train\n",
      "train mean loss=0.0723139972736438\n",
      "test_test\n",
      "test mean loss=1159.2367553710938\n",
      "epoch 5511\n",
      "test_train\n",
      "train mean loss=0.0717157010609905\n",
      "test_test\n",
      "test mean loss=1158.4591674804688\n",
      "epoch 5512\n",
      "test_train\n",
      "train mean loss=0.06455621495842934\n",
      "test_test\n",
      "test mean loss=1159.7900390625\n",
      "epoch 5513\n",
      "test_train\n",
      "train mean loss=0.06236343877390027\n",
      "test_test\n",
      "test mean loss=1159.4970092773438\n",
      "epoch 5514\n",
      "test_train\n",
      "train mean loss=0.0622582541157802\n",
      "test_test\n",
      "test mean loss=1158.86279296875\n",
      "epoch 5515\n",
      "test_train\n",
      "train mean loss=0.10795738734304905\n",
      "test_test\n",
      "test mean loss=1158.153564453125\n",
      "epoch 5516\n",
      "test_train\n",
      "train mean loss=0.07095547765493393\n",
      "test_test\n",
      "test mean loss=1158.0307006835938\n",
      "epoch 5517\n",
      "test_train\n",
      "train mean loss=0.06559099753697713\n",
      "test_test\n",
      "test mean loss=1158.0113220214844\n",
      "epoch 5518\n",
      "test_train\n",
      "train mean loss=0.06458454734335344\n",
      "test_test\n",
      "test mean loss=1157.6771850585938\n",
      "epoch 5519\n",
      "test_train\n",
      "train mean loss=0.06729214762647946\n",
      "test_test\n",
      "test mean loss=1157.6264038085938\n",
      "epoch 5520\n",
      "test_train\n",
      "train mean loss=0.07075596724947293\n",
      "test_test\n",
      "test mean loss=1159.2088012695312\n",
      "epoch 5521\n",
      "test_train\n",
      "train mean loss=0.07930372562259436\n",
      "test_test\n",
      "test mean loss=1159.0689697265625\n",
      "epoch 5522\n",
      "test_train\n",
      "train mean loss=0.0767465140670538\n",
      "test_test\n",
      "test mean loss=1159.0031127929688\n",
      "epoch 5523\n",
      "test_train\n",
      "train mean loss=0.07816597539931536\n",
      "test_test\n",
      "test mean loss=1158.5235595703125\n",
      "epoch 5524\n",
      "test_train\n",
      "train mean loss=0.06908573023974895\n",
      "test_test\n",
      "test mean loss=1158.0385131835938\n",
      "epoch 5525\n",
      "test_train\n",
      "train mean loss=0.07424224478503068\n",
      "test_test\n",
      "test mean loss=1159.1802673339844\n",
      "epoch 5526\n",
      "test_train\n",
      "train mean loss=0.06777830111483733\n",
      "test_test\n",
      "test mean loss=1159.2178344726562\n",
      "epoch 5527\n",
      "test_train\n",
      "train mean loss=0.0671728067100048\n",
      "test_test\n",
      "test mean loss=1158.5631103515625\n",
      "epoch 5528\n",
      "test_train\n",
      "train mean loss=0.066584176539133\n",
      "test_test\n",
      "test mean loss=1158.5469360351562\n",
      "epoch 5529\n",
      "test_train\n",
      "train mean loss=0.06492991000413895\n",
      "test_test\n",
      "test mean loss=1157.5593566894531\n",
      "epoch 5530\n",
      "test_train\n",
      "train mean loss=0.06957898816714685\n",
      "test_test\n",
      "test mean loss=1158.142333984375\n",
      "epoch 5531\n",
      "test_train\n",
      "train mean loss=0.07211475539952517\n",
      "test_test\n",
      "test mean loss=1157.6823120117188\n",
      "epoch 5532\n",
      "test_train\n",
      "train mean loss=0.06855603742102782\n",
      "test_test\n",
      "test mean loss=1158.6256713867188\n",
      "epoch 5533\n",
      "test_train\n",
      "train mean loss=0.06483694383253653\n",
      "test_test\n",
      "test mean loss=1158.3256530761719\n",
      "epoch 5534\n",
      "test_train\n",
      "train mean loss=0.06755915656685829\n",
      "test_test\n",
      "test mean loss=1158.5628051757812\n",
      "epoch 5535\n",
      "test_train\n",
      "train mean loss=0.06779313708345096\n",
      "test_test\n",
      "test mean loss=1159.1709594726562\n",
      "epoch 5536\n",
      "test_train\n",
      "train mean loss=0.07021018676459789\n",
      "test_test\n",
      "test mean loss=1159.4271240234375\n",
      "epoch 5537\n",
      "test_train\n",
      "train mean loss=0.07281138996283214\n",
      "test_test\n",
      "test mean loss=1160.1944885253906\n",
      "epoch 5538\n",
      "test_train\n",
      "train mean loss=0.06763904045025508\n",
      "test_test\n",
      "test mean loss=1158.718505859375\n",
      "epoch 5539\n",
      "test_train\n",
      "train mean loss=0.07071325493355592\n",
      "test_test\n",
      "test mean loss=1159.2821044921875\n",
      "epoch 5540\n",
      "test_train\n",
      "train mean loss=0.06721854644517104\n",
      "test_test\n",
      "test mean loss=1159.0244140625\n",
      "epoch 5541\n",
      "test_train\n",
      "train mean loss=0.12342217316230138\n",
      "test_test\n",
      "test mean loss=1160.1008911132812\n",
      "epoch 5542\n",
      "test_train\n",
      "train mean loss=0.07775939690570037\n",
      "test_test\n",
      "test mean loss=1160.03564453125\n",
      "epoch 5543\n",
      "test_train\n",
      "train mean loss=0.0623096814379096\n",
      "test_test\n",
      "test mean loss=1157.9331665039062\n",
      "epoch 5544\n",
      "test_train\n",
      "train mean loss=0.06635524611920118\n",
      "test_test\n",
      "test mean loss=1158.4756469726562\n",
      "epoch 5545\n",
      "test_train\n",
      "train mean loss=0.06672912215193112\n",
      "test_test\n",
      "test mean loss=1158.9634094238281\n",
      "epoch 5546\n",
      "test_train\n",
      "train mean loss=0.061181391744563975\n",
      "test_test\n",
      "test mean loss=1158.27880859375\n",
      "epoch 5547\n",
      "test_train\n",
      "train mean loss=0.07942419219762087\n",
      "test_test\n",
      "test mean loss=1159.3699951171875\n",
      "epoch 5548\n",
      "test_train\n",
      "train mean loss=0.06286752177402377\n",
      "test_test\n",
      "test mean loss=1158.4096984863281\n",
      "epoch 5549\n",
      "test_train\n",
      "train mean loss=0.06240502869089445\n",
      "test_test\n",
      "test mean loss=1159.2432250976562\n",
      "epoch 5550\n",
      "test_train\n",
      "train mean loss=0.06836149872591098\n",
      "test_test\n",
      "test mean loss=1158.53076171875\n",
      "epoch 5551\n",
      "test_train\n",
      "train mean loss=0.06268197546402614\n",
      "test_test\n",
      "test mean loss=1157.9904174804688\n",
      "epoch 5552\n",
      "test_train\n",
      "train mean loss=0.06824502162635326\n",
      "test_test\n",
      "test mean loss=1159.3823852539062\n",
      "epoch 5553\n",
      "test_train\n",
      "train mean loss=0.06670184340327978\n",
      "test_test\n",
      "test mean loss=1159.0924072265625\n",
      "epoch 5554\n",
      "test_train\n",
      "train mean loss=0.06744898793598016\n",
      "test_test\n",
      "test mean loss=1158.79443359375\n",
      "epoch 5555\n",
      "test_train\n",
      "train mean loss=0.0680710868909955\n",
      "test_test\n",
      "test mean loss=1158.6359558105469\n",
      "epoch 5556\n",
      "test_train\n",
      "train mean loss=0.06857304585476716\n",
      "test_test\n",
      "test mean loss=1157.9691772460938\n",
      "epoch 5557\n",
      "test_train\n",
      "train mean loss=0.066320998283724\n",
      "test_test\n",
      "test mean loss=1158.176025390625\n",
      "epoch 5558\n",
      "test_train\n",
      "train mean loss=0.07283737355222304\n",
      "test_test\n",
      "test mean loss=1160.041015625\n",
      "epoch 5559\n",
      "test_train\n",
      "train mean loss=0.06555205179999272\n",
      "test_test\n",
      "test mean loss=1158.4273071289062\n",
      "epoch 5560\n",
      "test_train\n",
      "train mean loss=0.06598883680999279\n",
      "test_test\n",
      "test mean loss=1158.3953552246094\n",
      "epoch 5561\n",
      "test_train\n",
      "train mean loss=0.062458260295291744\n",
      "test_test\n",
      "test mean loss=1158.1673278808594\n",
      "epoch 5562\n",
      "test_train\n",
      "train mean loss=0.07945298807074626\n",
      "test_test\n",
      "test mean loss=1158.453125\n",
      "epoch 5563\n",
      "test_train\n",
      "train mean loss=0.07055983940760295\n",
      "test_test\n",
      "test mean loss=1159.587646484375\n",
      "epoch 5564\n",
      "test_train\n",
      "train mean loss=0.06544122938066721\n",
      "test_test\n",
      "test mean loss=1158.8988037109375\n",
      "epoch 5565\n",
      "test_train\n",
      "train mean loss=0.06740016428132851\n",
      "test_test\n",
      "test mean loss=1159.2192687988281\n",
      "epoch 5566\n",
      "test_train\n",
      "train mean loss=0.0661807411039869\n",
      "test_test\n",
      "test mean loss=1158.2041320800781\n",
      "epoch 5567\n",
      "test_train\n",
      "train mean loss=0.06648976045350234\n",
      "test_test\n",
      "test mean loss=1159.3987426757812\n",
      "epoch 5568\n",
      "test_train\n",
      "train mean loss=0.07204899316032727\n",
      "test_test\n",
      "test mean loss=1158.4064331054688\n",
      "epoch 5569\n",
      "test_train\n",
      "train mean loss=0.07032648536066215\n",
      "test_test\n",
      "test mean loss=1158.958984375\n",
      "epoch 5570\n",
      "test_train\n",
      "train mean loss=0.07315114916612704\n",
      "test_test\n",
      "test mean loss=1159.3963623046875\n",
      "epoch 5571\n",
      "test_train\n",
      "train mean loss=0.06453490971277158\n",
      "test_test\n",
      "test mean loss=1158.6033020019531\n",
      "epoch 5572\n",
      "test_train\n",
      "train mean loss=0.06834098510444164\n",
      "test_test\n",
      "test mean loss=1158.6715087890625\n",
      "epoch 5573\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_train\n",
      "train mean loss=0.07294709080209334\n",
      "test_test\n",
      "test mean loss=1158.4784545898438\n",
      "epoch 5574\n",
      "test_train\n",
      "train mean loss=0.07584679902841647\n",
      "test_test\n",
      "test mean loss=1158.9292297363281\n",
      "epoch 5575\n",
      "test_train\n",
      "train mean loss=0.07309773688515027\n",
      "test_test\n",
      "test mean loss=1158.3210754394531\n",
      "epoch 5576\n",
      "test_train\n",
      "train mean loss=0.0607290497670571\n",
      "test_test\n",
      "test mean loss=1158.816650390625\n",
      "epoch 5577\n",
      "test_train\n",
      "train mean loss=0.06658773496747017\n",
      "test_test\n",
      "test mean loss=1160.0688781738281\n",
      "epoch 5578\n",
      "test_train\n",
      "train mean loss=0.06383853405714035\n",
      "test_test\n",
      "test mean loss=1160.14697265625\n",
      "epoch 5579\n",
      "test_train\n",
      "train mean loss=0.061279756637911\n",
      "test_test\n",
      "test mean loss=1158.6585998535156\n",
      "epoch 5580\n",
      "test_train\n",
      "train mean loss=0.06519943879296382\n",
      "test_test\n",
      "test mean loss=1158.53564453125\n",
      "epoch 5581\n",
      "test_train\n",
      "train mean loss=0.0665644253604114\n",
      "test_test\n",
      "test mean loss=1159.6455993652344\n",
      "epoch 5582\n",
      "test_train\n",
      "train mean loss=0.06685558644433816\n",
      "test_test\n",
      "test mean loss=1159.1356811523438\n",
      "epoch 5583\n",
      "test_train\n",
      "train mean loss=0.06713637181868155\n",
      "test_test\n",
      "test mean loss=1160.1444091796875\n",
      "epoch 5584\n",
      "test_train\n",
      "train mean loss=0.06957244376341502\n",
      "test_test\n",
      "test mean loss=1158.0595092773438\n",
      "epoch 5585\n",
      "test_train\n",
      "train mean loss=0.06534051926185687\n",
      "test_test\n",
      "test mean loss=1158.5540161132812\n",
      "epoch 5586\n",
      "test_train\n",
      "train mean loss=0.06494860568394263\n",
      "test_test\n",
      "test mean loss=1160.411376953125\n",
      "epoch 5587\n",
      "test_train\n",
      "train mean loss=0.0638774757583936\n",
      "test_test\n",
      "test mean loss=1158.9733276367188\n",
      "epoch 5588\n",
      "test_train\n",
      "train mean loss=0.06599551749726136\n",
      "test_test\n",
      "test mean loss=1159.36474609375\n",
      "epoch 5589\n",
      "test_train\n",
      "train mean loss=0.07504145180185635\n",
      "test_test\n",
      "test mean loss=1159.8509521484375\n",
      "epoch 5590\n",
      "test_train\n",
      "train mean loss=0.07240107872833808\n",
      "test_test\n",
      "test mean loss=1159.831787109375\n",
      "epoch 5591\n",
      "test_train\n",
      "train mean loss=0.0693979033579429\n",
      "test_test\n",
      "test mean loss=1157.9420776367188\n",
      "epoch 5592\n",
      "test_train\n",
      "train mean loss=0.07032973257203896\n",
      "test_test\n",
      "test mean loss=1159.2613525390625\n",
      "epoch 5593\n",
      "test_train\n",
      "train mean loss=0.06882812424252431\n",
      "test_test\n",
      "test mean loss=1159.931396484375\n",
      "epoch 5594\n",
      "test_train\n",
      "train mean loss=0.06687232851982117\n",
      "test_test\n",
      "test mean loss=1159.8972778320312\n",
      "epoch 5595\n",
      "test_train\n",
      "train mean loss=0.061034662959476314\n",
      "test_test\n",
      "test mean loss=1159.1355590820312\n",
      "epoch 5596\n",
      "test_train\n",
      "train mean loss=0.05922923826922973\n",
      "test_test\n",
      "test mean loss=1157.843017578125\n",
      "epoch 5597\n",
      "test_train\n",
      "train mean loss=0.06574297432477276\n",
      "test_test\n",
      "test mean loss=1159.2525634765625\n",
      "epoch 5598\n",
      "test_train\n",
      "train mean loss=0.06180926505476236\n",
      "test_test\n",
      "test mean loss=1158.6702880859375\n",
      "epoch 5599\n",
      "test_train\n",
      "train mean loss=0.06300388804326455\n",
      "test_test\n",
      "test mean loss=1158.9908447265625\n",
      "epoch 5600\n",
      "test_train\n",
      "train mean loss=0.06123853521421552\n",
      "test_test\n",
      "test mean loss=1159.1619567871094\n",
      "epoch 5601\n",
      "test_train\n",
      "train mean loss=0.07222653894374768\n",
      "test_test\n",
      "test mean loss=1160.5963745117188\n",
      "epoch 5602\n",
      "test_train\n",
      "train mean loss=0.07232937092582385\n",
      "test_test\n",
      "test mean loss=1160.6456604003906\n",
      "epoch 5603\n",
      "test_train\n",
      "train mean loss=0.06293986132368445\n",
      "test_test\n",
      "test mean loss=1160.206298828125\n",
      "epoch 5604\n",
      "test_train\n",
      "train mean loss=0.06186514254659414\n",
      "test_test\n",
      "test mean loss=1159.076904296875\n",
      "epoch 5605\n",
      "test_train\n",
      "train mean loss=0.061387378411988415\n",
      "test_test\n",
      "test mean loss=1158.7247619628906\n",
      "epoch 5606\n",
      "test_train\n",
      "train mean loss=0.06306885384644072\n",
      "test_test\n",
      "test mean loss=1159.4876708984375\n",
      "epoch 5607\n",
      "test_train\n",
      "train mean loss=0.06288940832018852\n",
      "test_test\n",
      "test mean loss=1159.9194946289062\n",
      "epoch 5608\n",
      "test_train\n",
      "train mean loss=0.061532738928993545\n",
      "test_test\n",
      "test mean loss=1159.155029296875\n",
      "epoch 5609\n",
      "test_train\n",
      "train mean loss=0.0812333111340801\n",
      "test_test\n",
      "test mean loss=1159.791259765625\n",
      "epoch 5610\n",
      "test_train\n",
      "train mean loss=0.06694597285240889\n",
      "test_test\n",
      "test mean loss=1160.1246643066406\n",
      "epoch 5611\n",
      "test_train\n",
      "train mean loss=0.05943365519245466\n",
      "test_test\n",
      "test mean loss=1159.67529296875\n",
      "epoch 5612\n",
      "test_train\n",
      "train mean loss=0.06545810401439667\n",
      "test_test\n",
      "test mean loss=1159.58056640625\n",
      "epoch 5613\n",
      "test_train\n",
      "train mean loss=0.07999161289383967\n",
      "test_test\n",
      "test mean loss=1158.710205078125\n",
      "epoch 5614\n",
      "test_train\n",
      "train mean loss=0.06918787956237793\n",
      "test_test\n",
      "test mean loss=1158.3485412597656\n",
      "epoch 5615\n",
      "test_train\n",
      "train mean loss=0.06431837007403374\n",
      "test_test\n",
      "test mean loss=1158.8080444335938\n",
      "epoch 5616\n",
      "test_train\n",
      "train mean loss=0.07210236353178819\n",
      "test_test\n",
      "test mean loss=1159.504638671875\n",
      "epoch 5617\n",
      "test_train\n",
      "train mean loss=0.07041370961815119\n",
      "test_test\n",
      "test mean loss=1159.14892578125\n",
      "epoch 5618\n",
      "test_train\n",
      "train mean loss=0.07387664386381705\n",
      "test_test\n",
      "test mean loss=1159.554443359375\n",
      "epoch 5619\n",
      "test_train\n",
      "train mean loss=0.06683006913711627\n",
      "test_test\n",
      "test mean loss=1158.0206604003906\n",
      "epoch 5620\n",
      "test_train\n",
      "train mean loss=0.0694371135905385\n",
      "test_test\n",
      "test mean loss=1157.2929992675781\n",
      "epoch 5621\n",
      "test_train\n",
      "train mean loss=0.06755636353045702\n",
      "test_test\n",
      "test mean loss=1158.3050537109375\n",
      "epoch 5622\n",
      "test_train\n",
      "train mean loss=0.07367825756470363\n",
      "test_test\n",
      "test mean loss=1158.28173828125\n",
      "epoch 5623\n",
      "test_train\n",
      "train mean loss=0.06625241506844759\n",
      "test_test\n",
      "test mean loss=1157.767578125\n",
      "epoch 5624\n",
      "test_train\n",
      "train mean loss=0.06630729542424281\n",
      "test_test\n",
      "test mean loss=1158.0623168945312\n",
      "epoch 5625\n",
      "test_train\n",
      "train mean loss=0.0644892215107878\n",
      "test_test\n",
      "test mean loss=1158.5992431640625\n",
      "epoch 5626\n",
      "test_train\n",
      "train mean loss=0.06812548916786909\n",
      "test_test\n",
      "test mean loss=1157.9259033203125\n",
      "epoch 5627\n",
      "test_train\n",
      "train mean loss=0.06342343706637621\n",
      "test_test\n",
      "test mean loss=1158.5924987792969\n",
      "epoch 5628\n",
      "test_train\n",
      "train mean loss=0.07764256652444601\n",
      "test_test\n",
      "test mean loss=1158.91943359375\n",
      "epoch 5629\n",
      "test_train\n",
      "train mean loss=0.07634517177939415\n",
      "test_test\n",
      "test mean loss=1159.3163146972656\n",
      "epoch 5630\n",
      "test_train\n",
      "train mean loss=0.0671596002454559\n",
      "test_test\n",
      "test mean loss=1158.7798461914062\n",
      "epoch 5631\n",
      "test_train\n",
      "train mean loss=0.07171650355060895\n",
      "test_test\n",
      "test mean loss=1159.3402709960938\n",
      "epoch 5632\n",
      "test_train\n",
      "train mean loss=0.07011792094757159\n",
      "test_test\n",
      "test mean loss=1158.3401184082031\n",
      "epoch 5633\n",
      "test_train\n",
      "train mean loss=0.06609897098193566\n",
      "test_test\n",
      "test mean loss=1159.251953125\n",
      "epoch 5634\n",
      "test_train\n",
      "train mean loss=0.06427706234777968\n",
      "test_test\n",
      "test mean loss=1158.6671142578125\n",
      "epoch 5635\n",
      "test_train\n",
      "train mean loss=0.06257893051952124\n",
      "test_test\n",
      "test mean loss=1158.1661987304688\n",
      "epoch 5636\n",
      "test_train\n",
      "train mean loss=0.06326247161875169\n",
      "test_test\n",
      "test mean loss=1158.8885803222656\n",
      "epoch 5637\n",
      "test_train\n",
      "train mean loss=0.06516310479491949\n",
      "test_test\n",
      "test mean loss=1159.1701049804688\n",
      "epoch 5638\n",
      "test_train\n",
      "train mean loss=0.06559588418652613\n",
      "test_test\n",
      "test mean loss=1158.8657531738281\n",
      "epoch 5639\n",
      "test_train\n",
      "train mean loss=0.078193468041718\n",
      "test_test\n",
      "test mean loss=1157.3466796875\n",
      "epoch 5640\n",
      "test_train\n",
      "train mean loss=0.06461343914270401\n",
      "test_test\n",
      "test mean loss=1157.915771484375\n",
      "epoch 5641\n",
      "test_train\n",
      "train mean loss=0.0674523242438833\n",
      "test_test\n",
      "test mean loss=1158.1981201171875\n",
      "epoch 5642\n",
      "test_train\n",
      "train mean loss=0.06441723881289363\n",
      "test_test\n",
      "test mean loss=1158.5709838867188\n",
      "epoch 5643\n",
      "test_train\n",
      "train mean loss=0.06344851354757945\n",
      "test_test\n",
      "test mean loss=1158.4946594238281\n",
      "epoch 5644\n",
      "test_train\n",
      "train mean loss=0.06712289371838172\n",
      "test_test\n",
      "test mean loss=1158.5607299804688\n",
      "epoch 5645\n",
      "test_train\n",
      "train mean loss=0.07227588289727767\n",
      "test_test\n",
      "test mean loss=1159.4837036132812\n",
      "epoch 5646\n",
      "test_train\n",
      "train mean loss=0.07807637006044388\n",
      "test_test\n",
      "test mean loss=1159.59521484375\n",
      "epoch 5647\n",
      "test_train\n",
      "train mean loss=0.061088400427252054\n",
      "test_test\n",
      "test mean loss=1158.914306640625\n",
      "epoch 5648\n",
      "test_train\n",
      "train mean loss=0.06416055342803399\n",
      "test_test\n",
      "test mean loss=1159.6980590820312\n",
      "epoch 5649\n",
      "test_train\n",
      "train mean loss=0.06022136968870958\n",
      "test_test\n",
      "test mean loss=1159.4329833984375\n",
      "epoch 5650\n",
      "test_train\n",
      "train mean loss=0.06420786088953416\n",
      "test_test\n",
      "test mean loss=1159.5475158691406\n",
      "epoch 5651\n",
      "test_train\n",
      "train mean loss=0.06487199136366446\n",
      "test_test\n",
      "test mean loss=1159.7359313964844\n",
      "epoch 5652\n",
      "test_train\n",
      "train mean loss=0.06147818205257257\n",
      "test_test\n",
      "test mean loss=1159.0972900390625\n",
      "epoch 5653\n",
      "test_train\n",
      "train mean loss=0.06988518250485261\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1158.88916015625\n",
      "epoch 5654\n",
      "test_train\n",
      "train mean loss=0.07079954786847036\n",
      "test_test\n",
      "test mean loss=1157.9647827148438\n",
      "epoch 5655\n",
      "test_train\n",
      "train mean loss=0.0703208517904083\n",
      "test_test\n",
      "test mean loss=1159.3263549804688\n",
      "epoch 5656\n",
      "test_train\n",
      "train mean loss=0.05834400405486425\n",
      "test_test\n",
      "test mean loss=1157.3638305664062\n",
      "epoch 5657\n",
      "test_train\n",
      "train mean loss=0.06138769413034121\n",
      "test_test\n",
      "test mean loss=1158.6702880859375\n",
      "epoch 5658\n",
      "test_train\n",
      "train mean loss=0.07487125089392066\n",
      "test_test\n",
      "test mean loss=1158.3237915039062\n",
      "epoch 5659\n",
      "test_train\n",
      "train mean loss=0.07270854835708936\n",
      "test_test\n",
      "test mean loss=1158.6784057617188\n",
      "epoch 5660\n",
      "test_train\n",
      "train mean loss=0.06998598792900641\n",
      "test_test\n",
      "test mean loss=1159.7044067382812\n",
      "epoch 5661\n",
      "test_train\n",
      "train mean loss=0.06529274551818769\n",
      "test_test\n",
      "test mean loss=1159.733154296875\n",
      "epoch 5662\n",
      "test_train\n",
      "train mean loss=0.06739772732059161\n",
      "test_test\n",
      "test mean loss=1158.8490600585938\n",
      "epoch 5663\n",
      "test_train\n",
      "train mean loss=0.06665743328630924\n",
      "test_test\n",
      "test mean loss=1158.9377746582031\n",
      "epoch 5664\n",
      "test_train\n",
      "train mean loss=0.06683756085112691\n",
      "test_test\n",
      "test mean loss=1160.0165405273438\n",
      "epoch 5665\n",
      "test_train\n",
      "train mean loss=0.06918892171233892\n",
      "test_test\n",
      "test mean loss=1159.2739868164062\n",
      "epoch 5666\n",
      "test_train\n",
      "train mean loss=0.07062641593317191\n",
      "test_test\n",
      "test mean loss=1160.7585144042969\n",
      "epoch 5667\n",
      "test_train\n",
      "train mean loss=0.06290065683424473\n",
      "test_test\n",
      "test mean loss=1159.6302490234375\n",
      "epoch 5668\n",
      "test_train\n",
      "train mean loss=0.06003006920218468\n",
      "test_test\n",
      "test mean loss=1160.1980285644531\n",
      "epoch 5669\n",
      "test_train\n",
      "train mean loss=0.10906241585810979\n",
      "test_test\n",
      "test mean loss=1161.4075012207031\n",
      "epoch 5670\n",
      "test_train\n",
      "train mean loss=0.07089496559153001\n",
      "test_test\n",
      "test mean loss=1160.13232421875\n",
      "epoch 5671\n",
      "test_train\n",
      "train mean loss=0.06029843849440416\n",
      "test_test\n",
      "test mean loss=1158.637939453125\n",
      "epoch 5672\n",
      "test_train\n",
      "train mean loss=0.064031934676071\n",
      "test_test\n",
      "test mean loss=1157.9662475585938\n",
      "epoch 5673\n",
      "test_train\n",
      "train mean loss=0.06724411621689796\n",
      "test_test\n",
      "test mean loss=1158.3770141601562\n",
      "epoch 5674\n",
      "test_train\n",
      "train mean loss=0.07093630606929462\n",
      "test_test\n",
      "test mean loss=1159.198486328125\n",
      "epoch 5675\n",
      "test_train\n",
      "train mean loss=0.07617136090993881\n",
      "test_test\n",
      "test mean loss=1159.6145629882812\n",
      "epoch 5676\n",
      "test_train\n",
      "train mean loss=0.07525248887638251\n",
      "test_test\n",
      "test mean loss=1159.7496643066406\n",
      "epoch 5677\n",
      "test_train\n",
      "train mean loss=0.06167690362781286\n",
      "test_test\n",
      "test mean loss=1158.7773742675781\n",
      "epoch 5678\n",
      "test_train\n",
      "train mean loss=0.06816992970804374\n",
      "test_test\n",
      "test mean loss=1159.0072326660156\n",
      "epoch 5679\n",
      "test_train\n",
      "train mean loss=0.06654548210402329\n",
      "test_test\n",
      "test mean loss=1159.5119018554688\n",
      "epoch 5680\n",
      "test_train\n",
      "train mean loss=0.06721868459135294\n",
      "test_test\n",
      "test mean loss=1159.3662109375\n",
      "epoch 5681\n",
      "test_train\n",
      "train mean loss=0.0570414982115229\n",
      "test_test\n",
      "test mean loss=1158.6162414550781\n",
      "epoch 5682\n",
      "test_train\n",
      "train mean loss=0.06468374809871118\n",
      "test_test\n",
      "test mean loss=1159.691162109375\n",
      "epoch 5683\n",
      "test_train\n",
      "train mean loss=0.06399518251419067\n",
      "test_test\n",
      "test mean loss=1159.5842895507812\n",
      "epoch 5684\n",
      "test_train\n",
      "train mean loss=0.07482211912671725\n",
      "test_test\n",
      "test mean loss=1159.3741455078125\n",
      "epoch 5685\n",
      "test_train\n",
      "train mean loss=0.07281822773317496\n",
      "test_test\n",
      "test mean loss=1159.1047973632812\n",
      "epoch 5686\n",
      "test_train\n",
      "train mean loss=0.06409016251564026\n",
      "test_test\n",
      "test mean loss=1159.8653564453125\n",
      "epoch 5687\n",
      "test_train\n",
      "train mean loss=0.06372045849760373\n",
      "test_test\n",
      "test mean loss=1159.2276611328125\n",
      "epoch 5688\n",
      "test_train\n",
      "train mean loss=0.06058830457429091\n",
      "test_test\n",
      "test mean loss=1158.5724487304688\n",
      "epoch 5689\n",
      "test_train\n",
      "train mean loss=0.06238462356850505\n",
      "test_test\n",
      "test mean loss=1158.0450439453125\n",
      "epoch 5690\n",
      "test_train\n",
      "train mean loss=0.07187202014029026\n",
      "test_test\n",
      "test mean loss=1158.8244018554688\n",
      "epoch 5691\n",
      "test_train\n",
      "train mean loss=0.06293604367723067\n",
      "test_test\n",
      "test mean loss=1158.469970703125\n",
      "epoch 5692\n",
      "test_train\n",
      "train mean loss=0.060293031545976795\n",
      "test_test\n",
      "test mean loss=1158.9644165039062\n",
      "epoch 5693\n",
      "test_train\n",
      "train mean loss=0.06786652995894353\n",
      "test_test\n",
      "test mean loss=1158.9844360351562\n",
      "epoch 5694\n",
      "test_train\n",
      "train mean loss=0.06950982722143333\n",
      "test_test\n",
      "test mean loss=1159.312255859375\n",
      "epoch 5695\n",
      "test_train\n",
      "train mean loss=0.06317695199201505\n",
      "test_test\n",
      "test mean loss=1158.2953491210938\n",
      "epoch 5696\n",
      "test_train\n",
      "train mean loss=0.06209196988493204\n",
      "test_test\n",
      "test mean loss=1158.0819091796875\n",
      "epoch 5697\n",
      "test_train\n",
      "train mean loss=0.06735083709160487\n",
      "test_test\n",
      "test mean loss=1159.5286254882812\n",
      "epoch 5698\n",
      "test_train\n",
      "train mean loss=0.06197307755549749\n",
      "test_test\n",
      "test mean loss=1159.2813720703125\n",
      "epoch 5699\n",
      "test_train\n",
      "train mean loss=0.06205688354869684\n",
      "test_test\n",
      "test mean loss=1158.6131286621094\n",
      "epoch 5700\n",
      "test_train\n",
      "train mean loss=0.05959442971895138\n",
      "test_test\n",
      "test mean loss=1159.537109375\n",
      "epoch 5701\n",
      "test_train\n",
      "train mean loss=0.06569275197883447\n",
      "test_test\n",
      "test mean loss=1158.5545043945312\n",
      "epoch 5702\n",
      "test_train\n",
      "train mean loss=0.11885067137579124\n",
      "test_test\n",
      "test mean loss=1160.3519897460938\n",
      "epoch 5703\n",
      "test_train\n",
      "train mean loss=0.06907287736733754\n",
      "test_test\n",
      "test mean loss=1158.8717041015625\n",
      "epoch 5704\n",
      "test_train\n",
      "train mean loss=0.07074403731773297\n",
      "test_test\n",
      "test mean loss=1158.9315490722656\n",
      "epoch 5705\n",
      "test_train\n",
      "train mean loss=0.06304269920413692\n",
      "test_test\n",
      "test mean loss=1157.9021606445312\n",
      "epoch 5706\n",
      "test_train\n",
      "train mean loss=0.05997979547828436\n",
      "test_test\n",
      "test mean loss=1158.84765625\n",
      "epoch 5707\n",
      "test_train\n",
      "train mean loss=0.06233192918201288\n",
      "test_test\n",
      "test mean loss=1159.1098022460938\n",
      "epoch 5708\n",
      "test_train\n",
      "train mean loss=0.07114378238717715\n",
      "test_test\n",
      "test mean loss=1159.0068969726562\n",
      "epoch 5709\n",
      "test_train\n",
      "train mean loss=0.07511600200086832\n",
      "test_test\n",
      "test mean loss=1158.6170959472656\n",
      "epoch 5710\n",
      "test_train\n",
      "train mean loss=0.07056131741652887\n",
      "test_test\n",
      "test mean loss=1158.7855224609375\n",
      "epoch 5711\n",
      "test_train\n",
      "train mean loss=0.06837023297945659\n",
      "test_test\n",
      "test mean loss=1159.2008666992188\n",
      "epoch 5712\n",
      "test_train\n",
      "train mean loss=0.1913005399207274\n",
      "test_test\n",
      "test mean loss=1150.01513671875\n",
      "epoch 5713\n",
      "test_train\n",
      "train mean loss=0.07326604208598535\n",
      "test_test\n",
      "test mean loss=1158.3562622070312\n",
      "epoch 5714\n",
      "test_train\n",
      "train mean loss=0.07322048240651687\n",
      "test_test\n",
      "test mean loss=1159.6284790039062\n",
      "epoch 5715\n",
      "test_train\n",
      "train mean loss=0.06365473506351312\n",
      "test_test\n",
      "test mean loss=1159.6880493164062\n",
      "epoch 5716\n",
      "test_train\n",
      "train mean loss=0.0658881248285373\n",
      "test_test\n",
      "test mean loss=1158.5917358398438\n",
      "epoch 5717\n",
      "test_train\n",
      "train mean loss=0.0657118633389473\n",
      "test_test\n",
      "test mean loss=1157.4881286621094\n",
      "epoch 5718\n",
      "test_train\n",
      "train mean loss=0.06512618716806173\n",
      "test_test\n",
      "test mean loss=1158.87646484375\n",
      "epoch 5719\n",
      "test_train\n",
      "train mean loss=0.06388081392894189\n",
      "test_test\n",
      "test mean loss=1158.7876586914062\n",
      "epoch 5720\n",
      "test_train\n",
      "train mean loss=0.06662522380550702\n",
      "test_test\n",
      "test mean loss=1158.8573913574219\n",
      "epoch 5721\n",
      "test_train\n",
      "train mean loss=0.07323391269892454\n",
      "test_test\n",
      "test mean loss=1160.3203735351562\n",
      "epoch 5722\n",
      "test_train\n",
      "train mean loss=0.06997580981502931\n",
      "test_test\n",
      "test mean loss=1160.7491149902344\n",
      "epoch 5723\n",
      "test_train\n",
      "train mean loss=0.06947851522515218\n",
      "test_test\n",
      "test mean loss=1160.4498291015625\n",
      "epoch 5724\n",
      "test_train\n",
      "train mean loss=0.061666292448838554\n",
      "test_test\n",
      "test mean loss=1159.5777587890625\n",
      "epoch 5725\n",
      "test_train\n",
      "train mean loss=0.0706507886449496\n",
      "test_test\n",
      "test mean loss=1160.8729858398438\n",
      "epoch 5726\n",
      "test_train\n",
      "train mean loss=0.06730256291727225\n",
      "test_test\n",
      "test mean loss=1160.2366333007812\n",
      "epoch 5727\n",
      "test_train\n",
      "train mean loss=0.06508512701839209\n",
      "test_test\n",
      "test mean loss=1161.2726135253906\n",
      "epoch 5728\n",
      "test_train\n",
      "train mean loss=0.06394070976724227\n",
      "test_test\n",
      "test mean loss=1159.8517456054688\n",
      "epoch 5729\n",
      "test_train\n",
      "train mean loss=0.06487707265963157\n",
      "test_test\n",
      "test mean loss=1160.6753540039062\n",
      "epoch 5730\n",
      "test_train\n",
      "train mean loss=0.06772052372495334\n",
      "test_test\n",
      "test mean loss=1160.24169921875\n",
      "epoch 5731\n",
      "test_train\n",
      "train mean loss=0.06088049026827017\n",
      "test_test\n",
      "test mean loss=1160.381103515625\n",
      "epoch 5732\n",
      "test_train\n",
      "train mean loss=0.0655567105859518\n",
      "test_test\n",
      "test mean loss=1160.3495483398438\n",
      "epoch 5733\n",
      "test_train\n",
      "train mean loss=0.0674898773431778\n",
      "test_test\n",
      "test mean loss=1159.7764587402344\n",
      "epoch 5734\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.0623625535517931\n",
      "test_test\n",
      "test mean loss=1159.7696533203125\n",
      "epoch 5735\n",
      "test_train\n",
      "train mean loss=0.06461593136191368\n",
      "test_test\n",
      "test mean loss=1159.9586791992188\n",
      "epoch 5736\n",
      "test_train\n",
      "train mean loss=0.05657092885424694\n",
      "test_test\n",
      "test mean loss=1159.25146484375\n",
      "epoch 5737\n",
      "test_train\n",
      "train mean loss=0.06508291854212682\n",
      "test_test\n",
      "test mean loss=1159.6348266601562\n",
      "epoch 5738\n",
      "test_train\n",
      "train mean loss=0.06485928626110156\n",
      "test_test\n",
      "test mean loss=1160.1094360351562\n",
      "epoch 5739\n",
      "test_train\n",
      "train mean loss=0.06274580598498385\n",
      "test_test\n",
      "test mean loss=1161.1505737304688\n",
      "epoch 5740\n",
      "test_train\n",
      "train mean loss=0.06440147229780753\n",
      "test_test\n",
      "test mean loss=1160.693115234375\n",
      "epoch 5741\n",
      "test_train\n",
      "train mean loss=0.06153300000975529\n",
      "test_test\n",
      "test mean loss=1159.9737548828125\n",
      "epoch 5742\n",
      "test_train\n",
      "train mean loss=0.0644048402706782\n",
      "test_test\n",
      "test mean loss=1160.4906616210938\n",
      "epoch 5743\n",
      "test_train\n",
      "train mean loss=0.07924168432752292\n",
      "test_test\n",
      "test mean loss=1159.7003784179688\n",
      "epoch 5744\n",
      "test_train\n",
      "train mean loss=0.06403650746991237\n",
      "test_test\n",
      "test mean loss=1160.09716796875\n",
      "epoch 5745\n",
      "test_train\n",
      "train mean loss=0.07312520531316598\n",
      "test_test\n",
      "test mean loss=1160.1412963867188\n",
      "epoch 5746\n",
      "test_train\n",
      "train mean loss=0.07009330298751593\n",
      "test_test\n",
      "test mean loss=1160.3528442382812\n",
      "epoch 5747\n",
      "test_train\n",
      "train mean loss=0.07023334285865228\n",
      "test_test\n",
      "test mean loss=1160.5794067382812\n",
      "epoch 5748\n",
      "test_train\n",
      "train mean loss=0.07118483477582534\n",
      "test_test\n",
      "test mean loss=1160.6163635253906\n",
      "epoch 5749\n",
      "test_train\n",
      "train mean loss=0.06710016696403424\n",
      "test_test\n",
      "test mean loss=1161.9495239257812\n",
      "epoch 5750\n",
      "test_train\n",
      "train mean loss=0.06726587346444528\n",
      "test_test\n",
      "test mean loss=1160.3824462890625\n",
      "epoch 5751\n",
      "test_train\n",
      "train mean loss=0.06828318194796641\n",
      "test_test\n",
      "test mean loss=1160.75732421875\n",
      "epoch 5752\n",
      "test_train\n",
      "train mean loss=0.06310069405784209\n",
      "test_test\n",
      "test mean loss=1160.3906555175781\n",
      "epoch 5753\n",
      "test_train\n",
      "train mean loss=0.06335331406444311\n",
      "test_test\n",
      "test mean loss=1160.5129089355469\n",
      "epoch 5754\n",
      "test_train\n",
      "train mean loss=0.06367069156840444\n",
      "test_test\n",
      "test mean loss=1160.8252868652344\n",
      "epoch 5755\n",
      "test_train\n",
      "train mean loss=0.06224858481436968\n",
      "test_test\n",
      "test mean loss=1160.2255859375\n",
      "epoch 5756\n",
      "test_train\n",
      "train mean loss=0.062120819774766765\n",
      "test_test\n",
      "test mean loss=1159.8217163085938\n",
      "epoch 5757\n",
      "test_train\n",
      "train mean loss=0.06169731309637427\n",
      "test_test\n",
      "test mean loss=1159.409912109375\n",
      "epoch 5758\n",
      "test_train\n",
      "train mean loss=0.06409433421989282\n",
      "test_test\n",
      "test mean loss=1159.1209106445312\n",
      "epoch 5759\n",
      "test_train\n",
      "train mean loss=0.0628745115051667\n",
      "test_test\n",
      "test mean loss=1159.7456665039062\n",
      "epoch 5760\n",
      "test_train\n",
      "train mean loss=0.0691841912145416\n",
      "test_test\n",
      "test mean loss=1160.382568359375\n",
      "epoch 5761\n",
      "test_train\n",
      "train mean loss=0.06263475368420283\n",
      "test_test\n",
      "test mean loss=1160.4708862304688\n",
      "epoch 5762\n",
      "test_train\n",
      "train mean loss=0.06848664116114378\n",
      "test_test\n",
      "test mean loss=1159.6035461425781\n",
      "epoch 5763\n",
      "test_train\n",
      "train mean loss=0.06324286106973886\n",
      "test_test\n",
      "test mean loss=1160.1114196777344\n",
      "epoch 5764\n",
      "test_train\n",
      "train mean loss=0.0747255040332675\n",
      "test_test\n",
      "test mean loss=1160.0321655273438\n",
      "epoch 5765\n",
      "test_train\n",
      "train mean loss=0.0681168617059787\n",
      "test_test\n",
      "test mean loss=1161.8834228515625\n",
      "epoch 5766\n",
      "test_train\n",
      "train mean loss=0.06549111350129048\n",
      "test_test\n",
      "test mean loss=1160.557373046875\n",
      "epoch 5767\n",
      "test_train\n",
      "train mean loss=0.09138401597738266\n",
      "test_test\n",
      "test mean loss=1159.59765625\n",
      "epoch 5768\n",
      "test_train\n",
      "train mean loss=0.06869738828390837\n",
      "test_test\n",
      "test mean loss=1161.1966552734375\n",
      "epoch 5769\n",
      "test_train\n",
      "train mean loss=0.07330242140839498\n",
      "test_test\n",
      "test mean loss=1162.8613891601562\n",
      "epoch 5770\n",
      "test_train\n",
      "train mean loss=0.07008677410582702\n",
      "test_test\n",
      "test mean loss=1162.5879516601562\n",
      "epoch 5771\n",
      "test_train\n",
      "train mean loss=0.06890216873337825\n",
      "test_test\n",
      "test mean loss=1161.16015625\n",
      "epoch 5772\n",
      "test_train\n",
      "train mean loss=0.0635711591069897\n",
      "test_test\n",
      "test mean loss=1161.143310546875\n",
      "epoch 5773\n",
      "test_train\n",
      "train mean loss=0.06399950447181861\n",
      "test_test\n",
      "test mean loss=1161.0120239257812\n",
      "epoch 5774\n",
      "test_train\n",
      "train mean loss=0.07365444488823414\n",
      "test_test\n",
      "test mean loss=1159.2610473632812\n",
      "epoch 5775\n",
      "test_train\n",
      "train mean loss=0.0679058435683449\n",
      "test_test\n",
      "test mean loss=1160.5756225585938\n",
      "epoch 5776\n",
      "test_train\n",
      "train mean loss=0.06732862473775943\n",
      "test_test\n",
      "test mean loss=1160.5600891113281\n",
      "epoch 5777\n",
      "test_train\n",
      "train mean loss=0.0649508365119497\n",
      "test_test\n",
      "test mean loss=1160.7215270996094\n",
      "epoch 5778\n",
      "test_train\n",
      "train mean loss=0.0691772191785276\n",
      "test_test\n",
      "test mean loss=1161.4777221679688\n",
      "epoch 5779\n",
      "test_train\n",
      "train mean loss=0.0793071078757445\n",
      "test_test\n",
      "test mean loss=1160.0265502929688\n",
      "epoch 5780\n",
      "test_train\n",
      "train mean loss=0.06922853738069534\n",
      "test_test\n",
      "test mean loss=1160.0530090332031\n",
      "epoch 5781\n",
      "test_train\n",
      "train mean loss=0.07287466432899237\n",
      "test_test\n",
      "test mean loss=1160.0824279785156\n",
      "epoch 5782\n",
      "test_train\n",
      "train mean loss=0.06792372651398182\n",
      "test_test\n",
      "test mean loss=1160.328369140625\n",
      "epoch 5783\n",
      "test_train\n",
      "train mean loss=0.06431217879677813\n",
      "test_test\n",
      "test mean loss=1159.6768188476562\n",
      "epoch 5784\n",
      "test_train\n",
      "train mean loss=0.06633738521486521\n",
      "test_test\n",
      "test mean loss=1160.9763793945312\n",
      "epoch 5785\n",
      "test_train\n",
      "train mean loss=0.06972575063506763\n",
      "test_test\n",
      "test mean loss=1161.5989990234375\n",
      "epoch 5786\n",
      "test_train\n",
      "train mean loss=0.06523129343986511\n",
      "test_test\n",
      "test mean loss=1161.2631225585938\n",
      "epoch 5787\n",
      "test_train\n",
      "train mean loss=0.062372488590578236\n",
      "test_test\n",
      "test mean loss=1161.0247802734375\n",
      "epoch 5788\n",
      "test_train\n",
      "train mean loss=0.06973490522553523\n",
      "test_test\n",
      "test mean loss=1161.083251953125\n",
      "epoch 5789\n",
      "test_train\n",
      "train mean loss=0.06322651946296294\n",
      "test_test\n",
      "test mean loss=1161.1812133789062\n",
      "epoch 5790\n",
      "test_train\n",
      "train mean loss=0.0726357726380229\n",
      "test_test\n",
      "test mean loss=1158.8533325195312\n",
      "epoch 5791\n",
      "test_train\n",
      "train mean loss=0.06028795397529999\n",
      "test_test\n",
      "test mean loss=1159.9771728515625\n",
      "epoch 5792\n",
      "test_train\n",
      "train mean loss=0.5885499740640322\n",
      "test_test\n",
      "test mean loss=1155.3164367675781\n",
      "epoch 5793\n",
      "test_train\n",
      "train mean loss=0.07343310955911875\n",
      "test_test\n",
      "test mean loss=1162.6084594726562\n",
      "epoch 5794\n",
      "test_train\n",
      "train mean loss=0.06869693224628766\n",
      "test_test\n",
      "test mean loss=1160.5986633300781\n",
      "epoch 5795\n",
      "test_train\n",
      "train mean loss=0.07381588344772656\n",
      "test_test\n",
      "test mean loss=1161.0421752929688\n",
      "epoch 5796\n",
      "test_train\n",
      "train mean loss=0.165141141662995\n",
      "test_test\n",
      "test mean loss=1163.2809448242188\n",
      "epoch 5797\n",
      "test_train\n",
      "train mean loss=0.06851552116374175\n",
      "test_test\n",
      "test mean loss=1162.7533569335938\n",
      "epoch 5798\n",
      "test_train\n",
      "train mean loss=0.08185672822097938\n",
      "test_test\n",
      "test mean loss=1161.2579956054688\n",
      "epoch 5799\n",
      "test_train\n",
      "train mean loss=0.07026437390595675\n",
      "test_test\n",
      "test mean loss=1161.3019409179688\n",
      "epoch 5800\n",
      "test_train\n",
      "train mean loss=0.06257046790172656\n",
      "test_test\n",
      "test mean loss=1160.9529724121094\n",
      "epoch 5801\n",
      "test_train\n",
      "train mean loss=0.07734547927975655\n",
      "test_test\n",
      "test mean loss=1161.1622924804688\n",
      "epoch 5802\n",
      "test_train\n",
      "train mean loss=0.07229491664717595\n",
      "test_test\n",
      "test mean loss=1160.1741943359375\n",
      "epoch 5803\n",
      "test_train\n",
      "train mean loss=0.21819548215717077\n",
      "test_test\n",
      "test mean loss=1161.0018310546875\n",
      "epoch 5804\n",
      "test_train\n",
      "train mean loss=0.06850377470254898\n",
      "test_test\n",
      "test mean loss=1160.7088623046875\n",
      "epoch 5805\n",
      "test_train\n",
      "train mean loss=0.1793471264342467\n",
      "test_test\n",
      "test mean loss=1163.5612182617188\n",
      "epoch 5806\n",
      "test_train\n",
      "train mean loss=0.07265271432697773\n",
      "test_test\n",
      "test mean loss=1161.9088745117188\n",
      "epoch 5807\n",
      "test_train\n",
      "train mean loss=0.06701430367926757\n",
      "test_test\n",
      "test mean loss=1161.3440551757812\n",
      "epoch 5808\n",
      "test_train\n",
      "train mean loss=0.07272305556883414\n",
      "test_test\n",
      "test mean loss=1160.4578247070312\n",
      "epoch 5809\n",
      "test_train\n",
      "train mean loss=0.0777846962834398\n",
      "test_test\n",
      "test mean loss=1160.8341064453125\n",
      "epoch 5810\n",
      "test_train\n",
      "train mean loss=0.0779102947562933\n",
      "test_test\n",
      "test mean loss=1161.0021362304688\n",
      "epoch 5811\n",
      "test_train\n",
      "train mean loss=0.08590821580340464\n",
      "test_test\n",
      "test mean loss=1161.53662109375\n",
      "epoch 5812\n",
      "test_train\n",
      "train mean loss=0.08363172303264339\n",
      "test_test\n",
      "test mean loss=1161.48388671875\n",
      "epoch 5813\n",
      "test_train\n",
      "train mean loss=0.07329187542200089\n",
      "test_test\n",
      "test mean loss=1162.3642578125\n",
      "epoch 5814\n",
      "test_train\n",
      "train mean loss=0.08739731398721536\n",
      "test_test\n",
      "test mean loss=1160.4104614257812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5815\n",
      "test_train\n",
      "train mean loss=0.07614273329575856\n",
      "test_test\n",
      "test mean loss=1160.7156982421875\n",
      "epoch 5816\n",
      "test_train\n",
      "train mean loss=0.07447921608885129\n",
      "test_test\n",
      "test mean loss=1161.6917724609375\n",
      "epoch 5817\n",
      "test_train\n",
      "train mean loss=0.07604298957933982\n",
      "test_test\n",
      "test mean loss=1162.201416015625\n",
      "epoch 5818\n",
      "test_train\n",
      "train mean loss=0.06764617376029491\n",
      "test_test\n",
      "test mean loss=1160.9046936035156\n",
      "epoch 5819\n",
      "test_train\n",
      "train mean loss=0.06273298275967439\n",
      "test_test\n",
      "test mean loss=1160.6614990234375\n",
      "epoch 5820\n",
      "test_train\n",
      "train mean loss=0.06336499750614166\n",
      "test_test\n",
      "test mean loss=1161.0455932617188\n",
      "epoch 5821\n",
      "test_train\n",
      "train mean loss=0.07170824147760868\n",
      "test_test\n",
      "test mean loss=1161.3826293945312\n",
      "epoch 5822\n",
      "test_train\n",
      "train mean loss=0.06300461540619533\n",
      "test_test\n",
      "test mean loss=1160.7489013671875\n",
      "epoch 5823\n",
      "test_train\n",
      "train mean loss=0.06934354764719804\n",
      "test_test\n",
      "test mean loss=1160.4722290039062\n",
      "epoch 5824\n",
      "test_train\n",
      "train mean loss=0.06403598313530286\n",
      "test_test\n",
      "test mean loss=1160.642333984375\n",
      "epoch 5825\n",
      "test_train\n",
      "train mean loss=0.06578514911234379\n",
      "test_test\n",
      "test mean loss=1160.9910583496094\n",
      "epoch 5826\n",
      "test_train\n",
      "train mean loss=0.05813330846528212\n",
      "test_test\n",
      "test mean loss=1160.4905395507812\n",
      "epoch 5827\n",
      "test_train\n",
      "train mean loss=0.06800762253503005\n",
      "test_test\n",
      "test mean loss=1161.3460083007812\n",
      "epoch 5828\n",
      "test_train\n",
      "train mean loss=0.060157920233905315\n",
      "test_test\n",
      "test mean loss=1160.9345397949219\n",
      "epoch 5829\n",
      "test_train\n",
      "train mean loss=0.06467788325001796\n",
      "test_test\n",
      "test mean loss=1161.5322265625\n",
      "epoch 5830\n",
      "test_train\n",
      "train mean loss=0.0667687679330508\n",
      "test_test\n",
      "test mean loss=1160.371826171875\n",
      "epoch 5831\n",
      "test_train\n",
      "train mean loss=0.07442534963289897\n",
      "test_test\n",
      "test mean loss=1161.4091491699219\n",
      "epoch 5832\n",
      "test_train\n",
      "train mean loss=0.06942150183022022\n",
      "test_test\n",
      "test mean loss=1160.314453125\n",
      "epoch 5833\n",
      "test_train\n",
      "train mean loss=0.07029155269265175\n",
      "test_test\n",
      "test mean loss=1160.4065551757812\n",
      "epoch 5834\n",
      "test_train\n",
      "train mean loss=0.08192355216791232\n",
      "test_test\n",
      "test mean loss=1160.2039794921875\n",
      "epoch 5835\n",
      "test_train\n",
      "train mean loss=0.07823243737220764\n",
      "test_test\n",
      "test mean loss=1161.531494140625\n",
      "epoch 5836\n",
      "test_train\n",
      "train mean loss=0.0824923658122619\n",
      "test_test\n",
      "test mean loss=1161.456787109375\n",
      "epoch 5837\n",
      "test_train\n",
      "train mean loss=0.07319441841294368\n",
      "test_test\n",
      "test mean loss=1160.2224731445312\n",
      "epoch 5838\n",
      "test_train\n",
      "train mean loss=0.06541613303124905\n",
      "test_test\n",
      "test mean loss=1159.6415405273438\n",
      "epoch 5839\n",
      "test_train\n",
      "train mean loss=0.06967871946593125\n",
      "test_test\n",
      "test mean loss=1160.7217407226562\n",
      "epoch 5840\n",
      "test_train\n",
      "train mean loss=0.06211526102075974\n",
      "test_test\n",
      "test mean loss=1160.8700256347656\n",
      "epoch 5841\n",
      "test_train\n",
      "train mean loss=0.06176977635671695\n",
      "test_test\n",
      "test mean loss=1160.73291015625\n",
      "epoch 5842\n",
      "test_train\n",
      "train mean loss=0.062206314876675606\n",
      "test_test\n",
      "test mean loss=1161.6278076171875\n",
      "epoch 5843\n",
      "test_train\n",
      "train mean loss=0.0630489153166612\n",
      "test_test\n",
      "test mean loss=1161.1901245117188\n",
      "epoch 5844\n",
      "test_train\n",
      "train mean loss=0.06524159448842208\n",
      "test_test\n",
      "test mean loss=1160.5545959472656\n",
      "epoch 5845\n",
      "test_train\n",
      "train mean loss=0.06273754158367713\n",
      "test_test\n",
      "test mean loss=1161.3465576171875\n",
      "epoch 5846\n",
      "test_train\n",
      "train mean loss=0.05899972002953291\n",
      "test_test\n",
      "test mean loss=1161.7090454101562\n",
      "epoch 5847\n",
      "test_train\n",
      "train mean loss=0.24368718887368837\n",
      "test_test\n",
      "test mean loss=1158.2818908691406\n",
      "epoch 5848\n",
      "test_train\n",
      "train mean loss=0.08290482126176357\n",
      "test_test\n",
      "test mean loss=1158.656005859375\n",
      "epoch 5849\n",
      "test_train\n",
      "train mean loss=0.07236720621585846\n",
      "test_test\n",
      "test mean loss=1160.6046142578125\n",
      "epoch 5850\n",
      "test_train\n",
      "train mean loss=0.22811795150240263\n",
      "test_test\n",
      "test mean loss=1160.6025390625\n",
      "epoch 5851\n",
      "test_train\n",
      "train mean loss=0.0718587211643656\n",
      "test_test\n",
      "test mean loss=1160.3597412109375\n",
      "epoch 5852\n",
      "test_train\n",
      "train mean loss=0.06758156201491754\n",
      "test_test\n",
      "test mean loss=1159.9661254882812\n",
      "epoch 5853\n",
      "test_train\n",
      "train mean loss=0.06272162248690923\n",
      "test_test\n",
      "test mean loss=1160.0882568359375\n",
      "epoch 5854\n",
      "test_train\n",
      "train mean loss=0.06702415831387043\n",
      "test_test\n",
      "test mean loss=1161.0900573730469\n",
      "epoch 5855\n",
      "test_train\n",
      "train mean loss=0.0649029112731417\n",
      "test_test\n",
      "test mean loss=1160.9736633300781\n",
      "epoch 5856\n",
      "test_train\n",
      "train mean loss=0.06576566273967425\n",
      "test_test\n",
      "test mean loss=1161.2692260742188\n",
      "epoch 5857\n",
      "test_train\n",
      "train mean loss=0.0786268546556433\n",
      "test_test\n",
      "test mean loss=1162.05322265625\n",
      "epoch 5858\n",
      "test_train\n",
      "train mean loss=0.07248894559840362\n",
      "test_test\n",
      "test mean loss=1159.9159851074219\n",
      "epoch 5859\n",
      "test_train\n",
      "train mean loss=0.0823822496458888\n",
      "test_test\n",
      "test mean loss=1160.9743347167969\n",
      "epoch 5860\n",
      "test_train\n",
      "train mean loss=0.0660514673218131\n",
      "test_test\n",
      "test mean loss=1161.1576538085938\n",
      "epoch 5861\n",
      "test_train\n",
      "train mean loss=0.168659970164299\n",
      "test_test\n",
      "test mean loss=1161.7769470214844\n",
      "epoch 5862\n",
      "test_train\n",
      "train mean loss=0.07405378576368093\n",
      "test_test\n",
      "test mean loss=1162.5940551757812\n",
      "epoch 5863\n",
      "test_train\n",
      "train mean loss=0.06283999979496002\n",
      "test_test\n",
      "test mean loss=1161.7350769042969\n",
      "epoch 5864\n",
      "test_train\n",
      "train mean loss=0.06811950355768204\n",
      "test_test\n",
      "test mean loss=1161.5123291015625\n",
      "epoch 5865\n",
      "test_train\n",
      "train mean loss=0.06424249398211639\n",
      "test_test\n",
      "test mean loss=1161.8602905273438\n",
      "epoch 5866\n",
      "test_train\n",
      "train mean loss=0.06058938832332691\n",
      "test_test\n",
      "test mean loss=1159.902099609375\n",
      "epoch 5867\n",
      "test_train\n",
      "train mean loss=0.06264547817409039\n",
      "test_test\n",
      "test mean loss=1160.0143737792969\n",
      "epoch 5868\n",
      "test_train\n",
      "train mean loss=0.06477203716834386\n",
      "test_test\n",
      "test mean loss=1160.5531616210938\n",
      "epoch 5869\n",
      "test_train\n",
      "train mean loss=0.06264621904119849\n",
      "test_test\n",
      "test mean loss=1160.9740600585938\n",
      "epoch 5870\n",
      "test_train\n",
      "train mean loss=0.06920603010803461\n",
      "test_test\n",
      "test mean loss=1161.0745849609375\n",
      "epoch 5871\n",
      "test_train\n",
      "train mean loss=0.06891162320971489\n",
      "test_test\n",
      "test mean loss=1161.72412109375\n",
      "epoch 5872\n",
      "test_train\n",
      "train mean loss=0.06354890763759613\n",
      "test_test\n",
      "test mean loss=1161.4518737792969\n",
      "epoch 5873\n",
      "test_train\n",
      "train mean loss=0.06602704897522926\n",
      "test_test\n",
      "test mean loss=1161.1260375976562\n",
      "epoch 5874\n",
      "test_train\n",
      "train mean loss=0.06636607615898053\n",
      "test_test\n",
      "test mean loss=1161.3439331054688\n",
      "epoch 5875\n",
      "test_train\n",
      "train mean loss=0.06372787741323312\n",
      "test_test\n",
      "test mean loss=1161.1055297851562\n",
      "epoch 5876\n",
      "test_train\n",
      "train mean loss=0.06410580407828093\n",
      "test_test\n",
      "test mean loss=1160.1239318847656\n",
      "epoch 5877\n",
      "test_train\n",
      "train mean loss=0.06582825506726901\n",
      "test_test\n",
      "test mean loss=1160.8554992675781\n",
      "epoch 5878\n",
      "test_train\n",
      "train mean loss=0.06757524547477563\n",
      "test_test\n",
      "test mean loss=1161.4783630371094\n",
      "epoch 5879\n",
      "test_train\n",
      "train mean loss=0.06756745387489597\n",
      "test_test\n",
      "test mean loss=1161.1516723632812\n",
      "epoch 5880\n",
      "test_train\n",
      "train mean loss=0.062234038642297186\n",
      "test_test\n",
      "test mean loss=1160.0216674804688\n",
      "epoch 5881\n",
      "test_train\n",
      "train mean loss=0.06822228338569403\n",
      "test_test\n",
      "test mean loss=1160.357421875\n",
      "epoch 5882\n",
      "test_train\n",
      "train mean loss=0.05970074298481146\n",
      "test_test\n",
      "test mean loss=1161.2181091308594\n",
      "epoch 5883\n",
      "test_train\n",
      "train mean loss=0.06700665457174182\n",
      "test_test\n",
      "test mean loss=1160.3695068359375\n",
      "epoch 5884\n",
      "test_train\n",
      "train mean loss=0.06738858669996262\n",
      "test_test\n",
      "test mean loss=1161.269287109375\n",
      "epoch 5885\n",
      "test_train\n",
      "train mean loss=0.07345477708925803\n",
      "test_test\n",
      "test mean loss=1160.9258728027344\n",
      "epoch 5886\n",
      "test_train\n",
      "train mean loss=0.06792539979020755\n",
      "test_test\n",
      "test mean loss=1160.7345275878906\n",
      "epoch 5887\n",
      "test_train\n",
      "train mean loss=0.06031374136606852\n",
      "test_test\n",
      "test mean loss=1160.191162109375\n",
      "epoch 5888\n",
      "test_train\n",
      "train mean loss=0.061547692554692425\n",
      "test_test\n",
      "test mean loss=1160.8795166015625\n",
      "epoch 5889\n",
      "test_train\n",
      "train mean loss=0.07038982057323058\n",
      "test_test\n",
      "test mean loss=1160.47998046875\n",
      "epoch 5890\n",
      "test_train\n",
      "train mean loss=0.0714034562309583\n",
      "test_test\n",
      "test mean loss=1160.4852294921875\n",
      "epoch 5891\n",
      "test_train\n",
      "train mean loss=0.0687729228908817\n",
      "test_test\n",
      "test mean loss=1159.6792907714844\n",
      "epoch 5892\n",
      "test_train\n",
      "train mean loss=0.06383984908461571\n",
      "test_test\n",
      "test mean loss=1161.2487182617188\n",
      "epoch 5893\n",
      "test_train\n",
      "train mean loss=0.06106293108314276\n",
      "test_test\n",
      "test mean loss=1160.9511108398438\n",
      "epoch 5894\n",
      "test_train\n",
      "train mean loss=0.06454329611733556\n",
      "test_test\n",
      "test mean loss=1159.5039672851562\n",
      "epoch 5895\n",
      "test_train\n",
      "train mean loss=0.06010515242815018\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1159.8003234863281\n",
      "epoch 5896\n",
      "test_train\n",
      "train mean loss=0.057619995437562466\n",
      "test_test\n",
      "test mean loss=1159.1514892578125\n",
      "epoch 5897\n",
      "test_train\n",
      "train mean loss=0.0627267334299783\n",
      "test_test\n",
      "test mean loss=1160.0019836425781\n",
      "epoch 5898\n",
      "test_train\n",
      "train mean loss=0.0749757937155664\n",
      "test_test\n",
      "test mean loss=1160.0489501953125\n",
      "epoch 5899\n",
      "test_train\n",
      "train mean loss=0.06263757186631362\n",
      "test_test\n",
      "test mean loss=1160.1320190429688\n",
      "epoch 5900\n",
      "test_train\n",
      "train mean loss=0.06069712806493044\n",
      "test_test\n",
      "test mean loss=1160.257080078125\n",
      "epoch 5901\n",
      "test_train\n",
      "train mean loss=0.07244913807759683\n",
      "test_test\n",
      "test mean loss=1159.4799499511719\n",
      "epoch 5902\n",
      "test_train\n",
      "train mean loss=0.06254601602753003\n",
      "test_test\n",
      "test mean loss=1160.494140625\n",
      "epoch 5903\n",
      "test_train\n",
      "train mean loss=0.06320855176697175\n",
      "test_test\n",
      "test mean loss=1159.9303894042969\n",
      "epoch 5904\n",
      "test_train\n",
      "train mean loss=0.06728190711388986\n",
      "test_test\n",
      "test mean loss=1160.8192443847656\n",
      "epoch 5905\n",
      "test_train\n",
      "train mean loss=0.06464755504081647\n",
      "test_test\n",
      "test mean loss=1159.9956665039062\n",
      "epoch 5906\n",
      "test_train\n",
      "train mean loss=0.0629452212403218\n",
      "test_test\n",
      "test mean loss=1161.4794311523438\n",
      "epoch 5907\n",
      "test_train\n",
      "train mean loss=0.060550960091253124\n",
      "test_test\n",
      "test mean loss=1161.3524780273438\n",
      "epoch 5908\n",
      "test_train\n",
      "train mean loss=0.06302035987998049\n",
      "test_test\n",
      "test mean loss=1162.4054870605469\n",
      "epoch 5909\n",
      "test_train\n",
      "train mean loss=0.060429323464632034\n",
      "test_test\n",
      "test mean loss=1161.3056335449219\n",
      "epoch 5910\n",
      "test_train\n",
      "train mean loss=0.06346436900397141\n",
      "test_test\n",
      "test mean loss=1160.9975891113281\n",
      "epoch 5911\n",
      "test_train\n",
      "train mean loss=0.059299052537729345\n",
      "test_test\n",
      "test mean loss=1161.724853515625\n",
      "epoch 5912\n",
      "test_train\n",
      "train mean loss=0.061508232106765114\n",
      "test_test\n",
      "test mean loss=1162.2708129882812\n",
      "epoch 5913\n",
      "test_train\n",
      "train mean loss=0.05681173705185453\n",
      "test_test\n",
      "test mean loss=1160.7177734375\n",
      "epoch 5914\n",
      "test_train\n",
      "train mean loss=0.058961912989616394\n",
      "test_test\n",
      "test mean loss=1160.3631591796875\n",
      "epoch 5915\n",
      "test_train\n",
      "train mean loss=0.05929347065587839\n",
      "test_test\n",
      "test mean loss=1160.4658203125\n",
      "epoch 5916\n",
      "test_train\n",
      "train mean loss=0.058800192239383854\n",
      "test_test\n",
      "test mean loss=1160.3749084472656\n",
      "epoch 5917\n",
      "test_train\n",
      "train mean loss=0.06568672321736813\n",
      "test_test\n",
      "test mean loss=1161.362060546875\n",
      "epoch 5918\n",
      "test_train\n",
      "train mean loss=0.06415581951538722\n",
      "test_test\n",
      "test mean loss=1161.6941223144531\n",
      "epoch 5919\n",
      "test_train\n",
      "train mean loss=0.060157653565208115\n",
      "test_test\n",
      "test mean loss=1160.70751953125\n",
      "epoch 5920\n",
      "test_train\n",
      "train mean loss=0.06548463770498832\n",
      "test_test\n",
      "test mean loss=1162.0590209960938\n",
      "epoch 5921\n",
      "test_train\n",
      "train mean loss=0.061328351187209286\n",
      "test_test\n",
      "test mean loss=1159.9030151367188\n",
      "epoch 5922\n",
      "test_train\n",
      "train mean loss=0.06337521784007549\n",
      "test_test\n",
      "test mean loss=1161.0730590820312\n",
      "epoch 5923\n",
      "test_train\n",
      "train mean loss=0.06230164226144552\n",
      "test_test\n",
      "test mean loss=1160.7705078125\n",
      "epoch 5924\n",
      "test_train\n",
      "train mean loss=0.06179587791363398\n",
      "test_test\n",
      "test mean loss=1162.3618774414062\n",
      "epoch 5925\n",
      "test_train\n",
      "train mean loss=0.06801430725802977\n",
      "test_test\n",
      "test mean loss=1161.2291870117188\n",
      "epoch 5926\n",
      "test_train\n",
      "train mean loss=0.06039777863770723\n",
      "test_test\n",
      "test mean loss=1161.2879333496094\n",
      "epoch 5927\n",
      "test_train\n",
      "train mean loss=0.063358165944616\n",
      "test_test\n",
      "test mean loss=1161.0857238769531\n",
      "epoch 5928\n",
      "test_train\n",
      "train mean loss=0.06600858705739181\n",
      "test_test\n",
      "test mean loss=1161.1820068359375\n",
      "epoch 5929\n",
      "test_train\n",
      "train mean loss=0.06936322525143623\n",
      "test_test\n",
      "test mean loss=1161.4940185546875\n",
      "epoch 5930\n",
      "test_train\n",
      "train mean loss=0.06531320822735627\n",
      "test_test\n",
      "test mean loss=1160.9750366210938\n",
      "epoch 5931\n",
      "test_train\n",
      "train mean loss=0.08796855621039867\n",
      "test_test\n",
      "test mean loss=1161.1567687988281\n",
      "epoch 5932\n",
      "test_train\n",
      "train mean loss=0.062489524794121586\n",
      "test_test\n",
      "test mean loss=1160.6377563476562\n",
      "epoch 5933\n",
      "test_train\n",
      "train mean loss=0.06703524850308895\n",
      "test_test\n",
      "test mean loss=1161.044677734375\n",
      "epoch 5934\n",
      "test_train\n",
      "train mean loss=0.06753887080897887\n",
      "test_test\n",
      "test mean loss=1162.6066284179688\n",
      "epoch 5935\n",
      "test_train\n",
      "train mean loss=0.06412856373935938\n",
      "test_test\n",
      "test mean loss=1162.4518127441406\n",
      "epoch 5936\n",
      "test_train\n",
      "train mean loss=0.06937078603853782\n",
      "test_test\n",
      "test mean loss=1161.13134765625\n",
      "epoch 5937\n",
      "test_train\n",
      "train mean loss=0.06616097285101812\n",
      "test_test\n",
      "test mean loss=1161.6300354003906\n",
      "epoch 5938\n",
      "test_train\n",
      "train mean loss=0.06794534406314294\n",
      "test_test\n",
      "test mean loss=1161.544189453125\n",
      "epoch 5939\n",
      "test_train\n",
      "train mean loss=0.07198025907079379\n",
      "test_test\n",
      "test mean loss=1161.0411376953125\n",
      "epoch 5940\n",
      "test_train\n",
      "train mean loss=0.06370851366470258\n",
      "test_test\n",
      "test mean loss=1161.1522827148438\n",
      "epoch 5941\n",
      "test_train\n",
      "train mean loss=0.07054341491311789\n",
      "test_test\n",
      "test mean loss=1162.2824096679688\n",
      "epoch 5942\n",
      "test_train\n",
      "train mean loss=0.0706588365137577\n",
      "test_test\n",
      "test mean loss=1161.0068054199219\n",
      "epoch 5943\n",
      "test_train\n",
      "train mean loss=0.07105129833022754\n",
      "test_test\n",
      "test mean loss=1160.401611328125\n",
      "epoch 5944\n",
      "test_train\n",
      "train mean loss=0.0614566213140885\n",
      "test_test\n",
      "test mean loss=1160.1834411621094\n",
      "epoch 5945\n",
      "test_train\n",
      "train mean loss=0.06672549402962129\n",
      "test_test\n",
      "test mean loss=1161.0791625976562\n",
      "epoch 5946\n",
      "test_train\n",
      "train mean loss=0.06650851884235938\n",
      "test_test\n",
      "test mean loss=1159.5302429199219\n",
      "epoch 5947\n",
      "test_train\n",
      "train mean loss=0.05811852806558212\n",
      "test_test\n",
      "test mean loss=1160.7293701171875\n",
      "epoch 5948\n",
      "test_train\n",
      "train mean loss=0.06828778112928073\n",
      "test_test\n",
      "test mean loss=1162.044677734375\n",
      "epoch 5949\n",
      "test_train\n",
      "train mean loss=0.06266451999545097\n",
      "test_test\n",
      "test mean loss=1160.9666748046875\n",
      "epoch 5950\n",
      "test_train\n",
      "train mean loss=0.06678513127068679\n",
      "test_test\n",
      "test mean loss=1159.5905151367188\n",
      "epoch 5951\n",
      "test_train\n",
      "train mean loss=0.061663118191063404\n",
      "test_test\n",
      "test mean loss=1160.6256103515625\n",
      "epoch 5952\n",
      "test_train\n",
      "train mean loss=0.06482203770428896\n",
      "test_test\n",
      "test mean loss=1160.8673706054688\n",
      "epoch 5953\n",
      "test_train\n",
      "train mean loss=0.0588442658384641\n",
      "test_test\n",
      "test mean loss=1160.8080749511719\n",
      "epoch 5954\n",
      "test_train\n",
      "train mean loss=0.06988868645081918\n",
      "test_test\n",
      "test mean loss=1161.2272338867188\n",
      "epoch 5955\n",
      "test_train\n",
      "train mean loss=0.060529159381985664\n",
      "test_test\n",
      "test mean loss=1160.327880859375\n",
      "epoch 5956\n",
      "test_train\n",
      "train mean loss=0.06433524331077933\n",
      "test_test\n",
      "test mean loss=1160.7659301757812\n",
      "epoch 5957\n",
      "test_train\n",
      "train mean loss=0.069008427982529\n",
      "test_test\n",
      "test mean loss=1160.0940246582031\n",
      "epoch 5958\n",
      "test_train\n",
      "train mean loss=0.0686978551869591\n",
      "test_test\n",
      "test mean loss=1160.0748291015625\n",
      "epoch 5959\n",
      "test_train\n",
      "train mean loss=0.06674503007282813\n",
      "test_test\n",
      "test mean loss=1160.7926940917969\n",
      "epoch 5960\n",
      "test_train\n",
      "train mean loss=0.0760843160872658\n",
      "test_test\n",
      "test mean loss=1155.2428588867188\n",
      "epoch 5961\n",
      "test_train\n",
      "train mean loss=0.06280385609716177\n",
      "test_test\n",
      "test mean loss=1159.7479248046875\n",
      "epoch 5962\n",
      "test_train\n",
      "train mean loss=0.0626030657440424\n",
      "test_test\n",
      "test mean loss=1161.1589965820312\n",
      "epoch 5963\n",
      "test_train\n",
      "train mean loss=0.06136425149937471\n",
      "test_test\n",
      "test mean loss=1160.4711303710938\n",
      "epoch 5964\n",
      "test_train\n",
      "train mean loss=0.06221063559254011\n",
      "test_test\n",
      "test mean loss=1160.0795288085938\n",
      "epoch 5965\n",
      "test_train\n",
      "train mean loss=0.06469882108892004\n",
      "test_test\n",
      "test mean loss=1160.6532592773438\n",
      "epoch 5966\n",
      "test_train\n",
      "train mean loss=0.06035303510725498\n",
      "test_test\n",
      "test mean loss=1160.9092407226562\n",
      "epoch 5967\n",
      "test_train\n",
      "train mean loss=0.059060657396912575\n",
      "test_test\n",
      "test mean loss=1160.8206481933594\n",
      "epoch 5968\n",
      "test_train\n",
      "train mean loss=0.05879545211791992\n",
      "test_test\n",
      "test mean loss=1160.5027160644531\n",
      "epoch 5969\n",
      "test_train\n",
      "train mean loss=0.06290363582472007\n",
      "test_test\n",
      "test mean loss=1160.7451477050781\n",
      "epoch 5970\n",
      "test_train\n",
      "train mean loss=0.06167959204564492\n",
      "test_test\n",
      "test mean loss=1160.666259765625\n",
      "epoch 5971\n",
      "test_train\n",
      "train mean loss=0.06365802247698109\n",
      "test_test\n",
      "test mean loss=1159.4717712402344\n",
      "epoch 5972\n",
      "test_train\n",
      "train mean loss=0.057210018237431846\n",
      "test_test\n",
      "test mean loss=1160.8580932617188\n",
      "epoch 5973\n",
      "test_train\n",
      "train mean loss=0.06352112426732977\n",
      "test_test\n",
      "test mean loss=1159.8642883300781\n",
      "epoch 5974\n",
      "test_train\n",
      "train mean loss=0.06203754153102636\n",
      "test_test\n",
      "test mean loss=1160.854248046875\n",
      "epoch 5975\n",
      "test_train\n",
      "train mean loss=0.05964074811587731\n",
      "test_test\n",
      "test mean loss=1160.6080932617188\n",
      "epoch 5976\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.05753941601142287\n",
      "test_test\n",
      "test mean loss=1159.9931030273438\n",
      "epoch 5977\n",
      "test_train\n",
      "train mean loss=0.07099293700108926\n",
      "test_test\n",
      "test mean loss=1160.1840209960938\n",
      "epoch 5978\n",
      "test_train\n",
      "train mean loss=0.0611079316586256\n",
      "test_test\n",
      "test mean loss=1160.8573608398438\n",
      "epoch 5979\n",
      "test_train\n",
      "train mean loss=0.06718791120996077\n",
      "test_test\n",
      "test mean loss=1160.8717956542969\n",
      "epoch 5980\n",
      "test_train\n",
      "train mean loss=0.08158458427836497\n",
      "test_test\n",
      "test mean loss=1159.531494140625\n",
      "epoch 5981\n",
      "test_train\n",
      "train mean loss=0.060217542573809624\n",
      "test_test\n",
      "test mean loss=1161.0790405273438\n",
      "epoch 5982\n",
      "test_train\n",
      "train mean loss=0.061602928986152015\n",
      "test_test\n",
      "test mean loss=1159.4718627929688\n",
      "epoch 5983\n",
      "test_train\n",
      "train mean loss=0.06438755430281162\n",
      "test_test\n",
      "test mean loss=1160.9580078125\n",
      "epoch 5984\n",
      "test_train\n",
      "train mean loss=0.0649573781217138\n",
      "test_test\n",
      "test mean loss=1160.8963623046875\n",
      "epoch 5985\n",
      "test_train\n",
      "train mean loss=0.06472593608001868\n",
      "test_test\n",
      "test mean loss=1161.3529663085938\n",
      "epoch 5986\n",
      "test_train\n",
      "train mean loss=0.06294463916371267\n",
      "test_test\n",
      "test mean loss=1160.1240844726562\n",
      "epoch 5987\n",
      "test_train\n",
      "train mean loss=0.06071652192622423\n",
      "test_test\n",
      "test mean loss=1161.3789978027344\n",
      "epoch 5988\n",
      "test_train\n",
      "train mean loss=0.06657281797379255\n",
      "test_test\n",
      "test mean loss=1161.1630859375\n",
      "epoch 5989\n",
      "test_train\n",
      "train mean loss=0.06429632628957431\n",
      "test_test\n",
      "test mean loss=1160.8630981445312\n",
      "epoch 5990\n",
      "test_train\n",
      "train mean loss=0.05893608213712772\n",
      "test_test\n",
      "test mean loss=1159.9751892089844\n",
      "epoch 5991\n",
      "test_train\n",
      "train mean loss=0.060456691309809685\n",
      "test_test\n",
      "test mean loss=1159.9599609375\n",
      "epoch 5992\n",
      "test_train\n",
      "train mean loss=0.0596787774314483\n",
      "test_test\n",
      "test mean loss=1159.484375\n",
      "epoch 5993\n",
      "test_train\n",
      "train mean loss=0.06357487322141726\n",
      "test_test\n",
      "test mean loss=1160.3605041503906\n",
      "epoch 5994\n",
      "test_train\n",
      "train mean loss=0.0677126298348109\n",
      "test_test\n",
      "test mean loss=1159.2522277832031\n",
      "epoch 5995\n",
      "test_train\n",
      "train mean loss=0.06727323401719332\n",
      "test_test\n",
      "test mean loss=1160.180908203125\n",
      "epoch 5996\n",
      "test_train\n",
      "train mean loss=0.06190034716079632\n",
      "test_test\n",
      "test mean loss=1160.4911499023438\n",
      "epoch 5997\n",
      "test_train\n",
      "train mean loss=0.06737515392402808\n",
      "test_test\n",
      "test mean loss=1161.0406188964844\n",
      "epoch 5998\n",
      "test_train\n",
      "train mean loss=0.06378442390511434\n",
      "test_test\n",
      "test mean loss=1162.0075378417969\n",
      "epoch 5999\n",
      "test_train\n",
      "train mean loss=0.06758320859322946\n",
      "test_test\n",
      "test mean loss=1161.7366333007812\n",
      "epoch 6000\n",
      "test_train\n",
      "train mean loss=0.0662248944863677\n",
      "test_test\n",
      "test mean loss=1162.0928955078125\n",
      "epoch 6001\n",
      "test_train\n",
      "train mean loss=0.07479581609368324\n",
      "test_test\n",
      "test mean loss=1161.3902893066406\n",
      "epoch 6002\n",
      "test_train\n",
      "train mean loss=0.06626635293165843\n",
      "test_test\n",
      "test mean loss=1160.6196899414062\n",
      "epoch 6003\n",
      "test_train\n",
      "train mean loss=0.059899019387861095\n",
      "test_test\n",
      "test mean loss=1160.1330871582031\n",
      "epoch 6004\n",
      "test_train\n",
      "train mean loss=0.06432860934485991\n",
      "test_test\n",
      "test mean loss=1161.0529174804688\n",
      "epoch 6005\n",
      "test_train\n",
      "train mean loss=0.06639354303479195\n",
      "test_test\n",
      "test mean loss=1160.7081909179688\n",
      "epoch 6006\n",
      "test_train\n",
      "train mean loss=0.06372350935513775\n",
      "test_test\n",
      "test mean loss=1160.6585083007812\n",
      "epoch 6007\n",
      "test_train\n",
      "train mean loss=0.061709943848351635\n",
      "test_test\n",
      "test mean loss=1161.2332458496094\n",
      "epoch 6008\n",
      "test_train\n",
      "train mean loss=0.07013655547052622\n",
      "test_test\n",
      "test mean loss=1161.0440368652344\n",
      "epoch 6009\n",
      "test_train\n",
      "train mean loss=0.07288373277212183\n",
      "test_test\n",
      "test mean loss=1160.91064453125\n",
      "epoch 6010\n",
      "test_train\n",
      "train mean loss=0.06480008115371068\n",
      "test_test\n",
      "test mean loss=1161.0638122558594\n",
      "epoch 6011\n",
      "test_train\n",
      "train mean loss=0.05879319521288077\n",
      "test_test\n",
      "test mean loss=1161.411865234375\n",
      "epoch 6012\n",
      "test_train\n",
      "train mean loss=0.07376288125912349\n",
      "test_test\n",
      "test mean loss=1162.5358276367188\n",
      "epoch 6013\n",
      "test_train\n",
      "train mean loss=0.05930881388485432\n",
      "test_test\n",
      "test mean loss=1161.263671875\n",
      "epoch 6014\n",
      "test_train\n",
      "train mean loss=0.06563176525135835\n",
      "test_test\n",
      "test mean loss=1160.921875\n",
      "epoch 6015\n",
      "test_train\n",
      "train mean loss=0.06470990677674611\n",
      "test_test\n",
      "test mean loss=1159.6941223144531\n",
      "epoch 6016\n",
      "test_train\n",
      "train mean loss=0.06752008758485317\n",
      "test_test\n",
      "test mean loss=1160.2261352539062\n",
      "epoch 6017\n",
      "test_train\n",
      "train mean loss=0.0679580286766092\n",
      "test_test\n",
      "test mean loss=1160.4656066894531\n",
      "epoch 6018\n",
      "test_train\n",
      "train mean loss=0.058223210740834475\n",
      "test_test\n",
      "test mean loss=1159.5199584960938\n",
      "epoch 6019\n",
      "test_train\n",
      "train mean loss=0.06539975510289271\n",
      "test_test\n",
      "test mean loss=1161.0192260742188\n",
      "epoch 6020\n",
      "test_train\n",
      "train mean loss=0.06430946476757526\n",
      "test_test\n",
      "test mean loss=1160.3610229492188\n",
      "epoch 6021\n",
      "test_train\n",
      "train mean loss=0.058526895474642515\n",
      "test_test\n",
      "test mean loss=1160.5423583984375\n",
      "epoch 6022\n",
      "test_train\n",
      "train mean loss=0.05918095167726278\n",
      "test_test\n",
      "test mean loss=1160.2841491699219\n",
      "epoch 6023\n",
      "test_train\n",
      "train mean loss=0.06802349723875523\n",
      "test_test\n",
      "test mean loss=1161.4463500976562\n",
      "epoch 6024\n",
      "test_train\n",
      "train mean loss=0.06291341750572126\n",
      "test_test\n",
      "test mean loss=1160.2366333007812\n",
      "epoch 6025\n",
      "test_train\n",
      "train mean loss=0.06241499042759339\n",
      "test_test\n",
      "test mean loss=1159.863525390625\n",
      "epoch 6026\n",
      "test_train\n",
      "train mean loss=0.06428687088191509\n",
      "test_test\n",
      "test mean loss=1159.99853515625\n",
      "epoch 6027\n",
      "test_train\n",
      "train mean loss=0.05873144045472145\n",
      "test_test\n",
      "test mean loss=1159.8726196289062\n",
      "epoch 6028\n",
      "test_train\n",
      "train mean loss=0.08367264581223328\n",
      "test_test\n",
      "test mean loss=1160.9970703125\n",
      "epoch 6029\n",
      "test_train\n",
      "train mean loss=0.06350249486664931\n",
      "test_test\n",
      "test mean loss=1159.2209777832031\n",
      "epoch 6030\n",
      "test_train\n",
      "train mean loss=0.09602745218823354\n",
      "test_test\n",
      "test mean loss=1160.2832641601562\n",
      "epoch 6031\n",
      "test_train\n",
      "train mean loss=0.05954343732446432\n",
      "test_test\n",
      "test mean loss=1160.1669921875\n",
      "epoch 6032\n",
      "test_train\n",
      "train mean loss=0.05939354716489712\n",
      "test_test\n",
      "test mean loss=1159.6729736328125\n",
      "epoch 6033\n",
      "test_train\n",
      "train mean loss=0.06218067929148674\n",
      "test_test\n",
      "test mean loss=1160.060546875\n",
      "epoch 6034\n",
      "test_train\n",
      "train mean loss=0.06534804279605548\n",
      "test_test\n",
      "test mean loss=1158.872314453125\n",
      "epoch 6035\n",
      "test_train\n",
      "train mean loss=0.06597950744132201\n",
      "test_test\n",
      "test mean loss=1159.3081970214844\n",
      "epoch 6036\n",
      "test_train\n",
      "train mean loss=0.06670469790697098\n",
      "test_test\n",
      "test mean loss=1160.4655151367188\n",
      "epoch 6037\n",
      "test_train\n",
      "train mean loss=0.06440670105318229\n",
      "test_test\n",
      "test mean loss=1159.2338256835938\n",
      "epoch 6038\n",
      "test_train\n",
      "train mean loss=0.06304994101325671\n",
      "test_test\n",
      "test mean loss=1159.3988037109375\n",
      "epoch 6039\n",
      "test_train\n",
      "train mean loss=0.07156741510455807\n",
      "test_test\n",
      "test mean loss=1160.4963989257812\n",
      "epoch 6040\n",
      "test_train\n",
      "train mean loss=0.05872176835934321\n",
      "test_test\n",
      "test mean loss=1159.9046020507812\n",
      "epoch 6041\n",
      "test_train\n",
      "train mean loss=0.06415772438049316\n",
      "test_test\n",
      "test mean loss=1159.7159423828125\n",
      "epoch 6042\n",
      "test_train\n",
      "train mean loss=0.05844664853066206\n",
      "test_test\n",
      "test mean loss=1159.99365234375\n",
      "epoch 6043\n",
      "test_train\n",
      "train mean loss=0.061250283382833004\n",
      "test_test\n",
      "test mean loss=1159.9541625976562\n",
      "epoch 6044\n",
      "test_train\n",
      "train mean loss=0.06395944813266397\n",
      "test_test\n",
      "test mean loss=1159.7257690429688\n",
      "epoch 6045\n",
      "test_train\n",
      "train mean loss=0.06757837782303493\n",
      "test_test\n",
      "test mean loss=1160.4742431640625\n",
      "epoch 6046\n",
      "test_train\n",
      "train mean loss=0.0643672333098948\n",
      "test_test\n",
      "test mean loss=1159.7543029785156\n",
      "epoch 6047\n",
      "test_train\n",
      "train mean loss=0.060663494281470776\n",
      "test_test\n",
      "test mean loss=1159.021728515625\n",
      "epoch 6048\n",
      "test_train\n",
      "train mean loss=0.05656083238621553\n",
      "test_test\n",
      "test mean loss=1158.8779907226562\n",
      "epoch 6049\n",
      "test_train\n",
      "train mean loss=0.07672132675846417\n",
      "test_test\n",
      "test mean loss=1159.4351196289062\n",
      "epoch 6050\n",
      "test_train\n",
      "train mean loss=0.06281538167968392\n",
      "test_test\n",
      "test mean loss=1159.3101196289062\n",
      "epoch 6051\n",
      "test_train\n",
      "train mean loss=0.06481453528006871\n",
      "test_test\n",
      "test mean loss=1159.0404052734375\n",
      "epoch 6052\n",
      "test_train\n",
      "train mean loss=0.0601215964804093\n",
      "test_test\n",
      "test mean loss=1159.1416015625\n",
      "epoch 6053\n",
      "test_train\n",
      "train mean loss=0.06282431725412607\n",
      "test_test\n",
      "test mean loss=1159.7485046386719\n",
      "epoch 6054\n",
      "test_train\n",
      "train mean loss=0.06624563441922267\n",
      "test_test\n",
      "test mean loss=1159.3720397949219\n",
      "epoch 6055\n",
      "test_train\n",
      "train mean loss=0.059563329753776394\n",
      "test_test\n",
      "test mean loss=1158.5869445800781\n",
      "epoch 6056\n",
      "test_train\n",
      "train mean loss=0.055823456030339\n",
      "test_test\n",
      "test mean loss=1158.86279296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6057\n",
      "test_train\n",
      "train mean loss=0.05754072157045206\n",
      "test_test\n",
      "test mean loss=1158.93798828125\n",
      "epoch 6058\n",
      "test_train\n",
      "train mean loss=0.07510621317972739\n",
      "test_test\n",
      "test mean loss=1158.2266235351562\n",
      "epoch 6059\n",
      "test_train\n",
      "train mean loss=0.061923992820084095\n",
      "test_test\n",
      "test mean loss=1159.185546875\n",
      "epoch 6060\n",
      "test_train\n",
      "train mean loss=0.05529651107887427\n",
      "test_test\n",
      "test mean loss=1159.2706298828125\n",
      "epoch 6061\n",
      "test_train\n",
      "train mean loss=0.06059492162118355\n",
      "test_test\n",
      "test mean loss=1159.0484313964844\n",
      "epoch 6062\n",
      "test_train\n",
      "train mean loss=0.06336854305118322\n",
      "test_test\n",
      "test mean loss=1158.4484252929688\n",
      "epoch 6063\n",
      "test_train\n",
      "train mean loss=0.07276747561991215\n",
      "test_test\n",
      "test mean loss=1159.1195068359375\n",
      "epoch 6064\n",
      "test_train\n",
      "train mean loss=0.07250119404246409\n",
      "test_test\n",
      "test mean loss=1159.644287109375\n",
      "epoch 6065\n",
      "test_train\n",
      "train mean loss=0.06342719960957766\n",
      "test_test\n",
      "test mean loss=1159.3258666992188\n",
      "epoch 6066\n",
      "test_train\n",
      "train mean loss=0.06529365728298824\n",
      "test_test\n",
      "test mean loss=1159.9447021484375\n",
      "epoch 6067\n",
      "test_train\n",
      "train mean loss=0.05334655288606882\n",
      "test_test\n",
      "test mean loss=1158.4228515625\n",
      "epoch 6068\n",
      "test_train\n",
      "train mean loss=0.07036511817326148\n",
      "test_test\n",
      "test mean loss=1158.7096252441406\n",
      "epoch 6069\n",
      "test_train\n",
      "train mean loss=0.06397652657081683\n",
      "test_test\n",
      "test mean loss=1158.926513671875\n",
      "epoch 6070\n",
      "test_train\n",
      "train mean loss=0.05605218900988499\n",
      "test_test\n",
      "test mean loss=1157.2507934570312\n",
      "epoch 6071\n",
      "test_train\n",
      "train mean loss=0.06139977897206942\n",
      "test_test\n",
      "test mean loss=1159.7752685546875\n",
      "epoch 6072\n",
      "test_train\n",
      "train mean loss=0.06822722436239322\n",
      "test_test\n",
      "test mean loss=1159.5877685546875\n",
      "epoch 6073\n",
      "test_train\n",
      "train mean loss=0.05817333903784553\n",
      "test_test\n",
      "test mean loss=1158.4680786132812\n",
      "epoch 6074\n",
      "test_train\n",
      "train mean loss=0.06530707298467557\n",
      "test_test\n",
      "test mean loss=1158.4388122558594\n",
      "epoch 6075\n",
      "test_train\n",
      "train mean loss=0.07010725699365139\n",
      "test_test\n",
      "test mean loss=1158.4595336914062\n",
      "epoch 6076\n",
      "test_train\n",
      "train mean loss=0.06666555938621362\n",
      "test_test\n",
      "test mean loss=1159.2174072265625\n",
      "epoch 6077\n",
      "test_train\n",
      "train mean loss=0.06668297139306863\n",
      "test_test\n",
      "test mean loss=1160.1601257324219\n",
      "epoch 6078\n",
      "test_train\n",
      "train mean loss=0.06185620836913586\n",
      "test_test\n",
      "test mean loss=1159.2156677246094\n",
      "epoch 6079\n",
      "test_train\n",
      "train mean loss=0.06356218146781127\n",
      "test_test\n",
      "test mean loss=1160.1790161132812\n",
      "epoch 6080\n",
      "test_train\n",
      "train mean loss=0.06439594396700461\n",
      "test_test\n",
      "test mean loss=1158.8948669433594\n",
      "epoch 6081\n",
      "test_train\n",
      "train mean loss=0.06238491740077734\n",
      "test_test\n",
      "test mean loss=1159.2052001953125\n",
      "epoch 6082\n",
      "test_train\n",
      "train mean loss=0.06706390871355931\n",
      "test_test\n",
      "test mean loss=1159.8039855957031\n",
      "epoch 6083\n",
      "test_train\n",
      "train mean loss=0.06082061926523844\n",
      "test_test\n",
      "test mean loss=1159.8449401855469\n",
      "epoch 6084\n",
      "test_train\n",
      "train mean loss=0.0676443896566828\n",
      "test_test\n",
      "test mean loss=1159.3729553222656\n",
      "epoch 6085\n",
      "test_train\n",
      "train mean loss=0.06499624811112881\n",
      "test_test\n",
      "test mean loss=1158.4952697753906\n",
      "epoch 6086\n",
      "test_train\n",
      "train mean loss=0.06361597310751677\n",
      "test_test\n",
      "test mean loss=1158.1577453613281\n",
      "epoch 6087\n",
      "test_train\n",
      "train mean loss=0.05968161299824715\n",
      "test_test\n",
      "test mean loss=1159.5695190429688\n",
      "epoch 6088\n",
      "test_train\n",
      "train mean loss=0.06258034737159808\n",
      "test_test\n",
      "test mean loss=1159.5287170410156\n",
      "epoch 6089\n",
      "test_train\n",
      "train mean loss=0.068828157770137\n",
      "test_test\n",
      "test mean loss=1159.385498046875\n",
      "epoch 6090\n",
      "test_train\n",
      "train mean loss=0.07951000394920509\n",
      "test_test\n",
      "test mean loss=1156.8807067871094\n",
      "epoch 6091\n",
      "test_train\n",
      "train mean loss=0.06145339707533518\n",
      "test_test\n",
      "test mean loss=1159.9981994628906\n",
      "epoch 6092\n",
      "test_train\n",
      "train mean loss=0.06331013670812051\n",
      "test_test\n",
      "test mean loss=1160.9730224609375\n",
      "epoch 6093\n",
      "test_train\n",
      "train mean loss=0.06070330925285816\n",
      "test_test\n",
      "test mean loss=1160.1928100585938\n",
      "epoch 6094\n",
      "test_train\n",
      "train mean loss=0.06462285450349252\n",
      "test_test\n",
      "test mean loss=1158.7663879394531\n",
      "epoch 6095\n",
      "test_train\n",
      "train mean loss=0.0716509281968077\n",
      "test_test\n",
      "test mean loss=1159.2876586914062\n",
      "epoch 6096\n",
      "test_train\n",
      "train mean loss=0.07079187128692865\n",
      "test_test\n",
      "test mean loss=1159.7377014160156\n",
      "epoch 6097\n",
      "test_train\n",
      "train mean loss=0.06717742700129747\n",
      "test_test\n",
      "test mean loss=1159.427734375\n",
      "epoch 6098\n",
      "test_train\n",
      "train mean loss=0.06186898797750473\n",
      "test_test\n",
      "test mean loss=1159.6676330566406\n",
      "epoch 6099\n",
      "test_train\n",
      "train mean loss=0.07052499242126942\n",
      "test_test\n",
      "test mean loss=1159.1236877441406\n",
      "epoch 6100\n",
      "test_train\n",
      "train mean loss=0.19668713957071304\n",
      "test_test\n",
      "test mean loss=1159.3880920410156\n",
      "epoch 6101\n",
      "test_train\n",
      "train mean loss=0.08206021009633939\n",
      "test_test\n",
      "test mean loss=1159.4645690917969\n",
      "epoch 6102\n",
      "test_train\n",
      "train mean loss=0.07351493959625562\n",
      "test_test\n",
      "test mean loss=1159.5633544921875\n",
      "epoch 6103\n",
      "test_train\n",
      "train mean loss=0.07109612226486206\n",
      "test_test\n",
      "test mean loss=1159.7574462890625\n",
      "epoch 6104\n",
      "test_train\n",
      "train mean loss=0.06733092324187358\n",
      "test_test\n",
      "test mean loss=1159.5830078125\n",
      "epoch 6105\n",
      "test_train\n",
      "train mean loss=0.062186420895159245\n",
      "test_test\n",
      "test mean loss=1159.8549194335938\n",
      "epoch 6106\n",
      "test_train\n",
      "train mean loss=0.06635298331578572\n",
      "test_test\n",
      "test mean loss=1159.7664489746094\n",
      "epoch 6107\n",
      "test_train\n",
      "train mean loss=0.07827179972082376\n",
      "test_test\n",
      "test mean loss=1161.0255126953125\n",
      "epoch 6108\n",
      "test_train\n",
      "train mean loss=0.06042305938899517\n",
      "test_test\n",
      "test mean loss=1159.8313293457031\n",
      "epoch 6109\n",
      "test_train\n",
      "train mean loss=0.06827044657741983\n",
      "test_test\n",
      "test mean loss=1159.3226928710938\n",
      "epoch 6110\n",
      "test_train\n",
      "train mean loss=0.06267739149431388\n",
      "test_test\n",
      "test mean loss=1158.1537475585938\n",
      "epoch 6111\n",
      "test_train\n",
      "train mean loss=0.05915864153454701\n",
      "test_test\n",
      "test mean loss=1159.1197814941406\n",
      "epoch 6112\n",
      "test_train\n",
      "train mean loss=0.06475842061142127\n",
      "test_test\n",
      "test mean loss=1159.5757446289062\n",
      "epoch 6113\n",
      "test_train\n",
      "train mean loss=0.07355697763462861\n",
      "test_test\n",
      "test mean loss=1161.0970458984375\n",
      "epoch 6114\n",
      "test_train\n",
      "train mean loss=0.06875006761401892\n",
      "test_test\n",
      "test mean loss=1160.2927856445312\n",
      "epoch 6115\n",
      "test_train\n",
      "train mean loss=0.06577831817169984\n",
      "test_test\n",
      "test mean loss=1160.9561462402344\n",
      "epoch 6116\n",
      "test_train\n",
      "train mean loss=0.06224819831550121\n",
      "test_test\n",
      "test mean loss=1159.5806579589844\n",
      "epoch 6117\n",
      "test_train\n",
      "train mean loss=0.055618874418238796\n",
      "test_test\n",
      "test mean loss=1160.1849060058594\n",
      "epoch 6118\n",
      "test_train\n",
      "train mean loss=0.058635800145566463\n",
      "test_test\n",
      "test mean loss=1159.8263549804688\n",
      "epoch 6119\n",
      "test_train\n",
      "train mean loss=0.06760029370586078\n",
      "test_test\n",
      "test mean loss=1159.7023315429688\n",
      "epoch 6120\n",
      "test_train\n",
      "train mean loss=0.06289557041600347\n",
      "test_test\n",
      "test mean loss=1160.0357360839844\n",
      "epoch 6121\n",
      "test_train\n",
      "train mean loss=0.06661840807646513\n",
      "test_test\n",
      "test mean loss=1159.98876953125\n",
      "epoch 6122\n",
      "test_train\n",
      "train mean loss=0.05935826633746425\n",
      "test_test\n",
      "test mean loss=1159.5950622558594\n",
      "epoch 6123\n",
      "test_train\n",
      "train mean loss=0.06403378428270419\n",
      "test_test\n",
      "test mean loss=1158.9352416992188\n",
      "epoch 6124\n",
      "test_train\n",
      "train mean loss=0.062175619415938854\n",
      "test_test\n",
      "test mean loss=1159.0655212402344\n",
      "epoch 6125\n",
      "test_train\n",
      "train mean loss=0.0619874553134044\n",
      "test_test\n",
      "test mean loss=1159.1983337402344\n",
      "epoch 6126\n",
      "test_train\n",
      "train mean loss=0.0636517433449626\n",
      "test_test\n",
      "test mean loss=1159.9127502441406\n",
      "epoch 6127\n",
      "test_train\n",
      "train mean loss=0.06377625791355968\n",
      "test_test\n",
      "test mean loss=1160.175537109375\n",
      "epoch 6128\n",
      "test_train\n",
      "train mean loss=0.06939212636401255\n",
      "test_test\n",
      "test mean loss=1160.5588989257812\n",
      "epoch 6129\n",
      "test_train\n",
      "train mean loss=0.06648529507219791\n",
      "test_test\n",
      "test mean loss=1159.9608459472656\n",
      "epoch 6130\n",
      "test_train\n",
      "train mean loss=0.11700206870834033\n",
      "test_test\n",
      "test mean loss=1154.9602661132812\n",
      "epoch 6131\n",
      "test_train\n",
      "train mean loss=0.05716274259611964\n",
      "test_test\n",
      "test mean loss=1158.730224609375\n",
      "epoch 6132\n",
      "test_train\n",
      "train mean loss=0.06360331984857719\n",
      "test_test\n",
      "test mean loss=1159.6778564453125\n",
      "epoch 6133\n",
      "test_train\n",
      "train mean loss=0.06237264738107721\n",
      "test_test\n",
      "test mean loss=1159.593505859375\n",
      "epoch 6134\n",
      "test_train\n",
      "train mean loss=0.058681590016931295\n",
      "test_test\n",
      "test mean loss=1159.3380737304688\n",
      "epoch 6135\n",
      "test_train\n",
      "train mean loss=0.07006939748922984\n",
      "test_test\n",
      "test mean loss=1160.0044250488281\n",
      "epoch 6136\n",
      "test_train\n",
      "train mean loss=0.06784087667862575\n",
      "test_test\n",
      "test mean loss=1159.5428466796875\n",
      "epoch 6137\n",
      "test_train\n",
      "train mean loss=0.0626604234178861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_test\n",
      "test mean loss=1159.157470703125\n",
      "epoch 6138\n",
      "test_train\n",
      "train mean loss=0.06187393330037594\n",
      "test_test\n",
      "test mean loss=1159.3460083007812\n",
      "epoch 6139\n",
      "test_train\n",
      "train mean loss=0.06553847715258598\n",
      "test_test\n",
      "test mean loss=1159.9822998046875\n",
      "epoch 6140\n",
      "test_train\n",
      "train mean loss=0.0565106151625514\n",
      "test_test\n",
      "test mean loss=1158.7552795410156\n",
      "epoch 6141\n",
      "test_train\n",
      "train mean loss=0.06843419993917148\n",
      "test_test\n",
      "test mean loss=1160.5128173828125\n",
      "epoch 6142\n",
      "test_train\n",
      "train mean loss=0.06776890189697345\n",
      "test_test\n",
      "test mean loss=1159.0628662109375\n",
      "epoch 6143\n",
      "test_train\n",
      "train mean loss=0.06627853230262797\n",
      "test_test\n",
      "test mean loss=1158.7012023925781\n",
      "epoch 6144\n",
      "test_train\n",
      "train mean loss=0.05719319932783643\n",
      "test_test\n",
      "test mean loss=1158.0131225585938\n",
      "epoch 6145\n",
      "test_train\n",
      "train mean loss=6.464292029539744\n",
      "test_test\n",
      "test mean loss=1114.95703125\n",
      "epoch 6146\n",
      "test_train\n",
      "train mean loss=0.2207736757894357\n",
      "test_test\n",
      "test mean loss=1154.170654296875\n",
      "epoch 6147\n",
      "test_train\n",
      "train mean loss=0.0891727168733875\n",
      "test_test\n",
      "test mean loss=1158.8489990234375\n",
      "epoch 6148\n",
      "test_train\n",
      "train mean loss=0.07149391372998555\n",
      "test_test\n",
      "test mean loss=1158.9741821289062\n",
      "epoch 6149\n",
      "test_train\n",
      "train mean loss=0.0762054758767287\n",
      "test_test\n",
      "test mean loss=1158.7046813964844\n",
      "epoch 6150\n",
      "test_train\n",
      "train mean loss=0.07483220472931862\n",
      "test_test\n",
      "test mean loss=1158.870361328125\n",
      "epoch 6151\n",
      "test_train\n",
      "train mean loss=0.07361864391714334\n",
      "test_test\n",
      "test mean loss=1159.0140380859375\n",
      "epoch 6152\n",
      "test_train\n",
      "train mean loss=0.07215299954017003\n",
      "test_test\n",
      "test mean loss=1158.3014221191406\n",
      "epoch 6153\n",
      "test_train\n",
      "train mean loss=0.07089495907227199\n",
      "test_test\n",
      "test mean loss=1159.2595825195312\n",
      "epoch 6154\n",
      "test_train\n",
      "train mean loss=0.0650948475425442\n",
      "test_test\n",
      "test mean loss=1158.7195739746094\n",
      "epoch 6155\n",
      "test_train\n",
      "train mean loss=0.07135532175501187\n",
      "test_test\n",
      "test mean loss=1158.4112548828125\n",
      "epoch 6156\n",
      "test_train\n",
      "train mean loss=0.06383259190867345\n",
      "test_test\n",
      "test mean loss=1158.1243591308594\n",
      "epoch 6157\n",
      "test_train\n",
      "train mean loss=0.07232102223982413\n",
      "test_test\n",
      "test mean loss=1158.0506591796875\n",
      "epoch 6158\n",
      "test_train\n",
      "train mean loss=0.09727951884269714\n",
      "test_test\n",
      "test mean loss=1161.0831909179688\n",
      "epoch 6159\n",
      "test_train\n",
      "train mean loss=0.07847509471078713\n",
      "test_test\n",
      "test mean loss=1159.8134155273438\n",
      "epoch 6160\n",
      "test_train\n",
      "train mean loss=0.07578544194499652\n",
      "test_test\n",
      "test mean loss=1161.4097595214844\n",
      "epoch 6161\n",
      "test_train\n",
      "train mean loss=0.0709520981957515\n",
      "test_test\n",
      "test mean loss=1159.8984985351562\n",
      "epoch 6162\n",
      "test_train\n",
      "train mean loss=0.06498066646357377\n",
      "test_test\n",
      "test mean loss=1160.0528564453125\n",
      "epoch 6163\n",
      "test_train\n",
      "train mean loss=0.06700910426055391\n",
      "test_test\n",
      "test mean loss=1159.30224609375\n",
      "epoch 6164\n",
      "test_train\n",
      "train mean loss=0.07601479720324278\n",
      "test_test\n",
      "test mean loss=1159.5652465820312\n",
      "epoch 6165\n",
      "test_train\n",
      "train mean loss=0.08173399108151595\n",
      "test_test\n",
      "test mean loss=1159.8535766601562\n",
      "epoch 6166\n",
      "test_train\n",
      "train mean loss=0.07737578482677539\n",
      "test_test\n",
      "test mean loss=1159.7872009277344\n",
      "epoch 6167\n",
      "test_train\n",
      "train mean loss=0.08085282084842522\n",
      "test_test\n",
      "test mean loss=1159.4767761230469\n",
      "epoch 6168\n",
      "test_train\n",
      "train mean loss=0.07798859942704439\n",
      "test_test\n",
      "test mean loss=1160.1751708984375\n",
      "epoch 6169\n",
      "test_train\n",
      "train mean loss=0.4736442007124424\n",
      "test_test\n",
      "test mean loss=1153.3055725097656\n",
      "epoch 6170\n",
      "test_train\n",
      "train mean loss=0.08060740865767002\n",
      "test_test\n",
      "test mean loss=1158.8308715820312\n",
      "epoch 6171\n",
      "test_train\n",
      "train mean loss=0.07264867688839634\n",
      "test_test\n",
      "test mean loss=1159.59716796875\n",
      "epoch 6172\n",
      "test_train\n",
      "train mean loss=0.06653881383438905\n",
      "test_test\n",
      "test mean loss=1159.6301574707031\n",
      "epoch 6173\n",
      "test_train\n",
      "train mean loss=0.07171409049381812\n",
      "test_test\n",
      "test mean loss=1159.8408203125\n",
      "epoch 6174\n",
      "test_train\n",
      "train mean loss=0.06954831040153901\n",
      "test_test\n",
      "test mean loss=1160.1317749023438\n",
      "epoch 6175\n",
      "test_train\n",
      "train mean loss=0.12254098368187745\n",
      "test_test\n",
      "test mean loss=1161.0975036621094\n",
      "epoch 6176\n",
      "test_train\n",
      "train mean loss=0.07353650623311599\n",
      "test_test\n",
      "test mean loss=1159.7498779296875\n",
      "epoch 6177\n",
      "test_train\n",
      "train mean loss=0.08765061634282272\n",
      "test_test\n",
      "test mean loss=1160.8504638671875\n",
      "epoch 6178\n",
      "test_train\n",
      "train mean loss=0.06779593601822853\n",
      "test_test\n",
      "test mean loss=1160.4197387695312\n",
      "epoch 6179\n",
      "test_train\n",
      "train mean loss=0.19983228482306004\n",
      "test_test\n",
      "test mean loss=1153.5621643066406\n",
      "epoch 6180\n",
      "test_train\n",
      "train mean loss=0.07944655480484168\n",
      "test_test\n",
      "test mean loss=1159.9180297851562\n",
      "epoch 6181\n",
      "test_train\n",
      "train mean loss=0.06956171151250601\n",
      "test_test\n",
      "test mean loss=1160.2799072265625\n",
      "epoch 6182\n",
      "test_train\n",
      "train mean loss=0.07215371293326218\n",
      "test_test\n",
      "test mean loss=1159.8283081054688\n",
      "epoch 6183\n",
      "test_train\n",
      "train mean loss=0.07416430115699768\n",
      "test_test\n",
      "test mean loss=1161.6116943359375\n",
      "epoch 6184\n",
      "test_train\n",
      "train mean loss=0.07007662827769916\n",
      "test_test\n",
      "test mean loss=1160.7946166992188\n",
      "epoch 6185\n",
      "test_train\n",
      "train mean loss=0.06969378795474768\n",
      "test_test\n",
      "test mean loss=1160.2562866210938\n",
      "epoch 6186\n",
      "test_train\n",
      "train mean loss=0.06591092919309934\n",
      "test_test\n",
      "test mean loss=1160.345947265625\n",
      "epoch 6187\n",
      "test_train\n",
      "train mean loss=0.07008471091588338\n",
      "test_test\n",
      "test mean loss=1161.0003051757812\n",
      "epoch 6188\n",
      "test_train\n",
      "train mean loss=0.07140866946429014\n",
      "test_test\n",
      "test mean loss=1159.88671875\n",
      "epoch 6189\n",
      "test_train\n",
      "train mean loss=0.06852748182912667\n",
      "test_test\n",
      "test mean loss=1159.43994140625\n",
      "epoch 6190\n",
      "test_train\n",
      "train mean loss=0.06625773819784324\n",
      "test_test\n",
      "test mean loss=1159.5965576171875\n",
      "epoch 6191\n",
      "test_train\n",
      "train mean loss=0.06628998617331187\n",
      "test_test\n",
      "test mean loss=1159.678466796875\n",
      "epoch 6192\n",
      "test_train\n",
      "train mean loss=0.06508735443154971\n",
      "test_test\n",
      "test mean loss=1159.150390625\n",
      "epoch 6193\n",
      "test_train\n",
      "train mean loss=0.06605126538003485\n",
      "test_test\n",
      "test mean loss=1159.1485290527344\n",
      "epoch 6194\n",
      "test_train\n",
      "train mean loss=0.06715899674842755\n",
      "test_test\n",
      "test mean loss=1159.8973999023438\n",
      "epoch 6195\n",
      "test_train\n",
      "train mean loss=0.06575536293288071\n",
      "test_test\n",
      "test mean loss=1160.2337036132812\n",
      "epoch 6196\n",
      "test_train\n",
      "train mean loss=0.06322476919740438\n",
      "test_test\n",
      "test mean loss=1159.5393676757812\n",
      "epoch 6197\n",
      "test_train\n",
      "train mean loss=0.07168875293185313\n",
      "test_test\n",
      "test mean loss=1159.9754638671875\n",
      "epoch 6198\n",
      "test_train\n",
      "train mean loss=0.07227152399718761\n",
      "test_test\n",
      "test mean loss=1160.6861572265625\n",
      "epoch 6199\n",
      "test_train\n",
      "train mean loss=0.0649723111030956\n",
      "test_test\n",
      "test mean loss=1161.2857971191406\n",
      "epoch 6200\n",
      "test_train\n",
      "train mean loss=0.06651893133918445\n",
      "test_test\n",
      "test mean loss=1162.6326293945312\n",
      "epoch 6201\n",
      "test_train\n",
      "train mean loss=0.06756346641729276\n",
      "test_test\n",
      "test mean loss=1161.1575622558594\n",
      "epoch 6202\n",
      "test_train\n",
      "train mean loss=0.06965759117156267\n",
      "test_test\n",
      "test mean loss=1160.5642395019531\n",
      "epoch 6203\n",
      "test_train\n",
      "train mean loss=0.06008639776458343\n",
      "test_test\n",
      "test mean loss=1160.6375732421875\n",
      "epoch 6204\n",
      "test_train\n",
      "train mean loss=0.0671900746723016\n",
      "test_test\n",
      "test mean loss=1161.4393615722656\n",
      "epoch 6205\n",
      "test_train\n",
      "train mean loss=0.06900261125216882\n",
      "test_test\n",
      "test mean loss=1161.2608337402344\n",
      "epoch 6206\n",
      "test_train\n",
      "train mean loss=0.06831641805668671\n",
      "test_test\n",
      "test mean loss=1160.8363647460938\n",
      "epoch 6207\n",
      "test_train\n",
      "train mean loss=0.07288712387283643\n",
      "test_test\n",
      "test mean loss=1159.8608703613281\n",
      "epoch 6208\n",
      "test_train\n",
      "train mean loss=0.07516789591560762\n",
      "test_test\n",
      "test mean loss=1161.6041870117188\n",
      "epoch 6209\n",
      "test_train\n",
      "train mean loss=0.06535612046718597\n",
      "test_test\n",
      "test mean loss=1161.5523071289062\n",
      "epoch 6210\n",
      "test_train\n",
      "train mean loss=0.06660044752061367\n",
      "test_test\n",
      "test mean loss=1160.8250122070312\n",
      "epoch 6211\n",
      "test_train\n",
      "train mean loss=0.061832865389684834\n",
      "test_test\n",
      "test mean loss=1161.6054077148438\n",
      "epoch 6212\n",
      "test_train\n",
      "train mean loss=0.07312056701630354\n",
      "test_test\n",
      "test mean loss=1161.68701171875\n",
      "epoch 6213\n",
      "test_train\n",
      "train mean loss=0.07279708112279575\n",
      "test_test\n",
      "test mean loss=1161.6549072265625\n",
      "epoch 6214\n",
      "test_train\n",
      "train mean loss=0.06413350316385429\n",
      "test_test\n",
      "test mean loss=1161.11328125\n",
      "epoch 6215\n",
      "test_train\n",
      "train mean loss=0.06300165721525748\n",
      "test_test\n",
      "test mean loss=1161.5045776367188\n",
      "epoch 6216\n",
      "test_train\n",
      "train mean loss=0.06604155572131276\n",
      "test_test\n",
      "test mean loss=1161.5413818359375\n",
      "epoch 6217\n",
      "test_train\n",
      "train mean loss=0.068361045482258\n",
      "test_test\n",
      "test mean loss=1162.0963745117188\n",
      "epoch 6218\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.06559756553421418\n",
      "test_test\n",
      "test mean loss=1161.9136047363281\n",
      "epoch 6219\n",
      "test_train\n",
      "train mean loss=0.07164891654004653\n",
      "test_test\n",
      "test mean loss=1161.9953002929688\n",
      "epoch 6220\n",
      "test_train\n",
      "train mean loss=0.07132925869276126\n",
      "test_test\n",
      "test mean loss=1160.5199584960938\n",
      "epoch 6221\n",
      "test_train\n",
      "train mean loss=0.06580971647053957\n",
      "test_test\n",
      "test mean loss=1160.4058837890625\n",
      "epoch 6222\n",
      "test_train\n",
      "train mean loss=0.06811529211699963\n",
      "test_test\n",
      "test mean loss=1160.260498046875\n",
      "epoch 6223\n",
      "test_train\n",
      "train mean loss=0.06549878728886445\n",
      "test_test\n",
      "test mean loss=1161.0567932128906\n",
      "epoch 6224\n",
      "test_train\n",
      "train mean loss=0.06682361631343763\n",
      "test_test\n",
      "test mean loss=1161.5597229003906\n",
      "epoch 6225\n",
      "test_train\n",
      "train mean loss=0.07231855268279712\n",
      "test_test\n",
      "test mean loss=1160.5532836914062\n",
      "epoch 6226\n",
      "test_train\n",
      "train mean loss=0.08496695787956317\n",
      "test_test\n",
      "test mean loss=1159.2534790039062\n",
      "epoch 6227\n",
      "test_train\n",
      "train mean loss=0.07682176275799672\n",
      "test_test\n",
      "test mean loss=1161.2429809570312\n",
      "epoch 6228\n",
      "test_train\n",
      "train mean loss=0.06455379041532676\n",
      "test_test\n",
      "test mean loss=1160.3446044921875\n",
      "epoch 6229\n",
      "test_train\n",
      "train mean loss=0.062173920994003616\n",
      "test_test\n",
      "test mean loss=1160.6522521972656\n",
      "epoch 6230\n",
      "test_train\n",
      "train mean loss=0.0645430361231168\n",
      "test_test\n",
      "test mean loss=1159.4272155761719\n",
      "epoch 6231\n",
      "test_train\n",
      "train mean loss=0.06277055479586124\n",
      "test_test\n",
      "test mean loss=1160.1808471679688\n",
      "epoch 6232\n",
      "test_train\n",
      "train mean loss=0.06706169589112203\n",
      "test_test\n",
      "test mean loss=1161.6585388183594\n",
      "epoch 6233\n",
      "test_train\n",
      "train mean loss=0.06401526493330796\n",
      "test_test\n",
      "test mean loss=1160.7864990234375\n",
      "epoch 6234\n",
      "test_train\n",
      "train mean loss=0.06244977517053485\n",
      "test_test\n",
      "test mean loss=1160.07275390625\n",
      "epoch 6235\n",
      "test_train\n",
      "train mean loss=0.06651524112870295\n",
      "test_test\n",
      "test mean loss=1160.3076782226562\n",
      "epoch 6236\n",
      "test_train\n",
      "train mean loss=0.06691307450334232\n",
      "test_test\n",
      "test mean loss=1160.8190307617188\n",
      "epoch 6237\n",
      "test_train\n",
      "train mean loss=0.06461561564356089\n",
      "test_test\n",
      "test mean loss=1159.9067993164062\n",
      "epoch 6238\n",
      "test_train\n",
      "train mean loss=0.06557069874058168\n",
      "test_test\n",
      "test mean loss=1160.42431640625\n",
      "epoch 6239\n",
      "test_train\n",
      "train mean loss=0.0621134719500939\n",
      "test_test\n",
      "test mean loss=1159.3056945800781\n",
      "epoch 6240\n",
      "test_train\n",
      "train mean loss=0.05814277504881223\n",
      "test_test\n",
      "test mean loss=1160.1264038085938\n",
      "epoch 6241\n",
      "test_train\n",
      "train mean loss=0.06535920687019825\n",
      "test_test\n",
      "test mean loss=1160.4820251464844\n",
      "epoch 6242\n",
      "test_train\n",
      "train mean loss=0.060616821981966496\n",
      "test_test\n",
      "test mean loss=1160.1417846679688\n",
      "epoch 6243\n",
      "test_train\n",
      "train mean loss=0.05905654809127251\n",
      "test_test\n",
      "test mean loss=1160.3024597167969\n",
      "epoch 6244\n",
      "test_train\n",
      "train mean loss=0.060281659166018166\n",
      "test_test\n",
      "test mean loss=1160.1512451171875\n",
      "epoch 6245\n",
      "test_train\n",
      "train mean loss=0.05892443719009558\n",
      "test_test\n",
      "test mean loss=1159.240234375\n",
      "epoch 6246\n",
      "test_train\n",
      "train mean loss=0.06494213392337163\n",
      "test_test\n",
      "test mean loss=1160.2720947265625\n",
      "epoch 6247\n",
      "test_train\n",
      "train mean loss=0.0647271207223336\n",
      "test_test\n",
      "test mean loss=1159.7366027832031\n",
      "epoch 6248\n",
      "test_train\n",
      "train mean loss=0.05962583112219969\n",
      "test_test\n",
      "test mean loss=1160.0875854492188\n",
      "epoch 6249\n",
      "test_train\n",
      "train mean loss=0.061096031218767166\n",
      "test_test\n",
      "test mean loss=1159.682373046875\n",
      "epoch 6250\n",
      "test_train\n",
      "train mean loss=0.06182979544003805\n",
      "test_test\n",
      "test mean loss=1160.3424987792969\n",
      "epoch 6251\n",
      "test_train\n",
      "train mean loss=0.0648825589256982\n",
      "test_test\n",
      "test mean loss=1160.4358825683594\n",
      "epoch 6252\n",
      "test_train\n",
      "train mean loss=0.06011814375718435\n",
      "test_test\n",
      "test mean loss=1159.8310546875\n",
      "epoch 6253\n",
      "test_train\n",
      "train mean loss=0.06117557051281134\n",
      "test_test\n",
      "test mean loss=1159.8941345214844\n",
      "epoch 6254\n",
      "test_train\n",
      "train mean loss=0.0665470523138841\n",
      "test_test\n",
      "test mean loss=1160.3128662109375\n",
      "epoch 6255\n",
      "test_train\n",
      "train mean loss=0.06892127823084593\n",
      "test_test\n",
      "test mean loss=1161.0608520507812\n",
      "epoch 6256\n",
      "test_train\n",
      "train mean loss=0.06288332802553971\n",
      "test_test\n",
      "test mean loss=1160.814208984375\n",
      "epoch 6257\n",
      "test_train\n",
      "train mean loss=0.06408160862823327\n",
      "test_test\n",
      "test mean loss=1160.7697143554688\n",
      "epoch 6258\n",
      "test_train\n",
      "train mean loss=0.059571715692679085\n",
      "test_test\n",
      "test mean loss=1160.4282531738281\n",
      "epoch 6259\n",
      "test_train\n",
      "train mean loss=0.06992446507016818\n",
      "test_test\n",
      "test mean loss=1161.0437622070312\n",
      "epoch 6260\n",
      "test_train\n",
      "train mean loss=0.08133213842908542\n",
      "test_test\n",
      "test mean loss=1160.5187377929688\n",
      "epoch 6261\n",
      "test_train\n",
      "train mean loss=0.05944078663984934\n",
      "test_test\n",
      "test mean loss=1160.661865234375\n",
      "epoch 6262\n",
      "test_train\n",
      "train mean loss=0.06621839633832376\n",
      "test_test\n",
      "test mean loss=1159.8870849609375\n",
      "epoch 6263\n",
      "test_train\n",
      "train mean loss=0.07125596236437559\n",
      "test_test\n",
      "test mean loss=1161.0726928710938\n",
      "epoch 6264\n",
      "test_train\n",
      "train mean loss=0.06732857692986727\n",
      "test_test\n",
      "test mean loss=1160.7798767089844\n",
      "epoch 6265\n",
      "test_train\n",
      "train mean loss=0.06174762717758616\n",
      "test_test\n",
      "test mean loss=1161.3455200195312\n",
      "epoch 6266\n",
      "test_train\n",
      "train mean loss=0.07103667221963406\n",
      "test_test\n",
      "test mean loss=1160.447509765625\n",
      "epoch 6267\n",
      "test_train\n",
      "train mean loss=0.06743673887103796\n",
      "test_test\n",
      "test mean loss=1159.8877258300781\n",
      "epoch 6268\n",
      "test_train\n",
      "train mean loss=0.06330834872399767\n",
      "test_test\n",
      "test mean loss=1160.0406494140625\n",
      "epoch 6269\n",
      "test_train\n",
      "train mean loss=0.06253377037743728\n",
      "test_test\n",
      "test mean loss=1160.2724609375\n",
      "epoch 6270\n",
      "test_train\n",
      "train mean loss=0.06112422545750936\n",
      "test_test\n",
      "test mean loss=1159.9894104003906\n",
      "epoch 6271\n",
      "test_train\n",
      "train mean loss=0.08058204129338264\n",
      "test_test\n",
      "test mean loss=1160.2420654296875\n",
      "epoch 6272\n",
      "test_train\n",
      "train mean loss=0.06578267645090818\n",
      "test_test\n",
      "test mean loss=1159.6279602050781\n",
      "epoch 6273\n",
      "test_train\n",
      "train mean loss=0.06616499740630388\n",
      "test_test\n",
      "test mean loss=1159.3096923828125\n",
      "epoch 6274\n",
      "test_train\n",
      "train mean loss=0.07367189135402441\n",
      "test_test\n",
      "test mean loss=1159.3303833007812\n",
      "epoch 6275\n",
      "test_train\n",
      "train mean loss=0.06463858236869176\n",
      "test_test\n",
      "test mean loss=1159.189208984375\n",
      "epoch 6276\n",
      "test_train\n",
      "train mean loss=0.07373578660190105\n",
      "test_test\n",
      "test mean loss=1159.239501953125\n",
      "epoch 6277\n",
      "test_train\n",
      "train mean loss=0.10576876749595006\n",
      "test_test\n",
      "test mean loss=1163.035400390625\n",
      "epoch 6278\n",
      "test_train\n",
      "train mean loss=0.06798899173736572\n",
      "test_test\n",
      "test mean loss=1160.4090576171875\n",
      "epoch 6279\n",
      "test_train\n",
      "train mean loss=0.08554028005649646\n",
      "test_test\n",
      "test mean loss=1159.9893798828125\n",
      "epoch 6280\n",
      "test_train\n",
      "train mean loss=0.0627987648670872\n",
      "test_test\n",
      "test mean loss=1159.7958374023438\n",
      "epoch 6281\n",
      "test_train\n",
      "train mean loss=0.07292861553529899\n",
      "test_test\n",
      "test mean loss=1160.307373046875\n",
      "epoch 6282\n",
      "test_train\n",
      "train mean loss=0.0644872710108757\n",
      "test_test\n",
      "test mean loss=1159.7214965820312\n",
      "epoch 6283\n",
      "test_train\n",
      "train mean loss=0.061265286058187485\n",
      "test_test\n",
      "test mean loss=1159.6000366210938\n",
      "epoch 6284\n",
      "test_train\n",
      "train mean loss=0.06628562851498525\n",
      "test_test\n",
      "test mean loss=1160.04150390625\n",
      "epoch 6285\n",
      "test_train\n",
      "train mean loss=0.06349136276791494\n",
      "test_test\n",
      "test mean loss=1161.0250854492188\n",
      "epoch 6286\n",
      "test_train\n",
      "train mean loss=0.05900312028825283\n",
      "test_test\n",
      "test mean loss=1159.2968139648438\n",
      "epoch 6287\n",
      "test_train\n",
      "train mean loss=0.07298748816053073\n",
      "test_test\n",
      "test mean loss=1161.0402221679688\n",
      "epoch 6288\n",
      "test_train\n",
      "train mean loss=0.05901549973835548\n",
      "test_test\n",
      "test mean loss=1159.5645446777344\n",
      "epoch 6289\n",
      "test_train\n",
      "train mean loss=0.06481904443353415\n",
      "test_test\n",
      "test mean loss=1160.259033203125\n",
      "epoch 6290\n",
      "test_train\n",
      "train mean loss=0.06660150022556384\n",
      "test_test\n",
      "test mean loss=1160.2628784179688\n",
      "epoch 6291\n",
      "test_train\n",
      "train mean loss=0.060552568174898624\n",
      "test_test\n",
      "test mean loss=1159.822509765625\n",
      "epoch 6292\n",
      "test_train\n",
      "train mean loss=0.06765512221803267\n",
      "test_test\n",
      "test mean loss=1160.9033203125\n",
      "epoch 6293\n",
      "test_train\n",
      "train mean loss=0.06726020916054647\n",
      "test_test\n",
      "test mean loss=1159.8712158203125\n",
      "epoch 6294\n",
      "test_train\n",
      "train mean loss=0.08282413550963004\n",
      "test_test\n",
      "test mean loss=1159.4995727539062\n",
      "epoch 6295\n",
      "test_train\n",
      "train mean loss=0.06734508058677117\n",
      "test_test\n",
      "test mean loss=1159.5244140625\n",
      "epoch 6296\n",
      "test_train\n",
      "train mean loss=0.05900196172297001\n",
      "test_test\n",
      "test mean loss=1159.9133911132812\n",
      "epoch 6297\n",
      "test_train\n",
      "train mean loss=0.0627905613121887\n",
      "test_test\n",
      "test mean loss=1161.3033752441406\n",
      "epoch 6298\n",
      "test_train\n",
      "train mean loss=0.06143579507867495\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1160.6771545410156\n",
      "epoch 6299\n",
      "test_train\n",
      "train mean loss=0.07450941018760204\n",
      "test_test\n",
      "test mean loss=1160.0941162109375\n",
      "epoch 6300\n",
      "test_train\n",
      "train mean loss=0.0658586227024595\n",
      "test_test\n",
      "test mean loss=1160.3661193847656\n",
      "epoch 6301\n",
      "test_train\n",
      "train mean loss=0.07163087526957194\n",
      "test_test\n",
      "test mean loss=1160.2720336914062\n",
      "epoch 6302\n",
      "test_train\n",
      "train mean loss=0.0629154530664285\n",
      "test_test\n",
      "test mean loss=1160.310302734375\n",
      "epoch 6303\n",
      "test_train\n",
      "train mean loss=0.06763750873506069\n",
      "test_test\n",
      "test mean loss=1161.3506469726562\n",
      "epoch 6304\n",
      "test_train\n",
      "train mean loss=0.060948215735455356\n",
      "test_test\n",
      "test mean loss=1159.7870483398438\n",
      "epoch 6305\n",
      "test_train\n",
      "train mean loss=0.06534248931954305\n",
      "test_test\n",
      "test mean loss=1159.8397216796875\n",
      "epoch 6306\n",
      "test_train\n",
      "train mean loss=0.06850104918703437\n",
      "test_test\n",
      "test mean loss=1161.4201049804688\n",
      "epoch 6307\n",
      "test_train\n",
      "train mean loss=0.07080357366551955\n",
      "test_test\n",
      "test mean loss=1159.855224609375\n",
      "epoch 6308\n",
      "test_train\n",
      "train mean loss=0.06801273363331954\n",
      "test_test\n",
      "test mean loss=1159.8070983886719\n",
      "epoch 6309\n",
      "test_train\n",
      "train mean loss=0.06630102389802535\n",
      "test_test\n",
      "test mean loss=1160.3994140625\n",
      "epoch 6310\n",
      "test_train\n",
      "train mean loss=0.071917868219316\n",
      "test_test\n",
      "test mean loss=1159.5892639160156\n",
      "epoch 6311\n",
      "test_train\n",
      "train mean loss=0.06881731748580933\n",
      "test_test\n",
      "test mean loss=1160.1001892089844\n",
      "epoch 6312\n",
      "test_train\n",
      "train mean loss=0.06486483352879684\n",
      "test_test\n",
      "test mean loss=1159.7922973632812\n",
      "epoch 6313\n",
      "test_train\n",
      "train mean loss=0.06436043108503024\n",
      "test_test\n",
      "test mean loss=1159.6881713867188\n",
      "epoch 6314\n",
      "test_train\n",
      "train mean loss=0.0631155138835311\n",
      "test_test\n",
      "test mean loss=1158.4721069335938\n",
      "epoch 6315\n",
      "test_train\n",
      "train mean loss=0.06250534237672885\n",
      "test_test\n",
      "test mean loss=1159.66064453125\n",
      "epoch 6316\n",
      "test_train\n",
      "train mean loss=0.06498897913843393\n",
      "test_test\n",
      "test mean loss=1160.0283813476562\n",
      "epoch 6317\n",
      "test_train\n",
      "train mean loss=0.06400825673093398\n",
      "test_test\n",
      "test mean loss=1158.9292602539062\n",
      "epoch 6318\n",
      "test_train\n",
      "train mean loss=0.05868384443844358\n",
      "test_test\n",
      "test mean loss=1159.8214111328125\n",
      "epoch 6319\n",
      "test_train\n",
      "train mean loss=0.06565195477257173\n",
      "test_test\n",
      "test mean loss=1160.5301208496094\n",
      "epoch 6320\n",
      "test_train\n",
      "train mean loss=0.06743429508060217\n",
      "test_test\n",
      "test mean loss=1159.4820556640625\n",
      "epoch 6321\n",
      "test_train\n",
      "train mean loss=0.06334915633002917\n",
      "test_test\n",
      "test mean loss=1159.2875671386719\n",
      "epoch 6322\n",
      "test_train\n",
      "train mean loss=0.06975568054864804\n",
      "test_test\n",
      "test mean loss=1160.0053100585938\n",
      "epoch 6323\n",
      "test_train\n",
      "train mean loss=0.06912441489597161\n",
      "test_test\n",
      "test mean loss=1160.4329833984375\n",
      "epoch 6324\n",
      "test_train\n",
      "train mean loss=0.06649128937472899\n",
      "test_test\n",
      "test mean loss=1159.8397216796875\n",
      "epoch 6325\n",
      "test_train\n",
      "train mean loss=0.08566103130578995\n",
      "test_test\n",
      "test mean loss=1157.4700317382812\n",
      "epoch 6326\n",
      "test_train\n",
      "train mean loss=0.06549426726996899\n",
      "test_test\n",
      "test mean loss=1158.9520874023438\n",
      "epoch 6327\n",
      "test_train\n",
      "train mean loss=0.06555076315999031\n",
      "test_test\n",
      "test mean loss=1159.67529296875\n",
      "epoch 6328\n",
      "test_train\n",
      "train mean loss=0.06187168167283138\n",
      "test_test\n",
      "test mean loss=1159.3661499023438\n",
      "epoch 6329\n",
      "test_train\n",
      "train mean loss=0.07701899949461222\n",
      "test_test\n",
      "test mean loss=1159.4487915039062\n",
      "epoch 6330\n",
      "test_train\n",
      "train mean loss=0.06059626086304585\n",
      "test_test\n",
      "test mean loss=1159.5885620117188\n",
      "epoch 6331\n",
      "test_train\n",
      "train mean loss=0.0659863877420624\n",
      "test_test\n",
      "test mean loss=1159.115478515625\n",
      "epoch 6332\n",
      "test_train\n",
      "train mean loss=0.07530813664197922\n",
      "test_test\n",
      "test mean loss=1159.8358764648438\n",
      "epoch 6333\n",
      "test_train\n",
      "train mean loss=0.06932164231936137\n",
      "test_test\n",
      "test mean loss=1160.6674194335938\n",
      "epoch 6334\n",
      "test_train\n",
      "train mean loss=0.06555196487655242\n",
      "test_test\n",
      "test mean loss=1159.6507873535156\n",
      "epoch 6335\n",
      "test_train\n",
      "train mean loss=0.06032654860367378\n",
      "test_test\n",
      "test mean loss=1159.7227783203125\n",
      "epoch 6336\n",
      "test_train\n",
      "train mean loss=0.06714880559593439\n",
      "test_test\n",
      "test mean loss=1160.0987243652344\n",
      "epoch 6337\n",
      "test_train\n",
      "train mean loss=0.31472524503866833\n",
      "test_test\n",
      "test mean loss=1150.8097534179688\n",
      "epoch 6338\n",
      "test_train\n",
      "train mean loss=0.06266963978608449\n",
      "test_test\n",
      "test mean loss=1159.6943969726562\n",
      "epoch 6339\n",
      "test_train\n",
      "train mean loss=0.07029809554417928\n",
      "test_test\n",
      "test mean loss=1159.7345886230469\n",
      "epoch 6340\n",
      "test_train\n",
      "train mean loss=0.06430074339732528\n",
      "test_test\n",
      "test mean loss=1160.5465698242188\n",
      "epoch 6341\n",
      "test_train\n",
      "train mean loss=0.10485476317505042\n",
      "test_test\n",
      "test mean loss=1154.0394287109375\n",
      "epoch 6342\n",
      "test_train\n",
      "train mean loss=0.07133892675240834\n",
      "test_test\n",
      "test mean loss=1160.523193359375\n",
      "epoch 6343\n",
      "test_train\n",
      "train mean loss=0.06861952257653077\n",
      "test_test\n",
      "test mean loss=1160.715087890625\n",
      "epoch 6344\n",
      "test_train\n",
      "train mean loss=0.06836326451351245\n",
      "test_test\n",
      "test mean loss=1161.8069763183594\n",
      "epoch 6345\n",
      "test_train\n",
      "train mean loss=0.07181419835736354\n",
      "test_test\n",
      "test mean loss=1161.1885681152344\n",
      "epoch 6346\n",
      "test_train\n",
      "train mean loss=0.06504776204625766\n",
      "test_test\n",
      "test mean loss=1160.400390625\n",
      "epoch 6347\n",
      "test_train\n",
      "train mean loss=0.06378641352057457\n",
      "test_test\n",
      "test mean loss=1159.4009399414062\n",
      "epoch 6348\n",
      "test_train\n",
      "train mean loss=0.06395283155143261\n",
      "test_test\n",
      "test mean loss=1161.6183471679688\n",
      "epoch 6349\n",
      "test_train\n",
      "train mean loss=0.05647896664837996\n",
      "test_test\n",
      "test mean loss=1159.4368286132812\n",
      "epoch 6350\n",
      "test_train\n",
      "train mean loss=0.062097751535475254\n",
      "test_test\n",
      "test mean loss=1159.62890625\n",
      "epoch 6351\n",
      "test_train\n",
      "train mean loss=0.06458561541512609\n",
      "test_test\n",
      "test mean loss=1160.0397338867188\n",
      "epoch 6352\n",
      "test_train\n",
      "train mean loss=0.06771084169546764\n",
      "test_test\n",
      "test mean loss=1160.6959838867188\n",
      "epoch 6353\n",
      "test_train\n",
      "train mean loss=0.06625227443873882\n",
      "test_test\n",
      "test mean loss=1160.1902465820312\n",
      "epoch 6354\n",
      "test_train\n",
      "train mean loss=0.067435164625446\n",
      "test_test\n",
      "test mean loss=1160.47314453125\n",
      "epoch 6355\n",
      "test_train\n",
      "train mean loss=0.059957399343450866\n",
      "test_test\n",
      "test mean loss=1160.8490295410156\n",
      "epoch 6356\n",
      "test_train\n",
      "train mean loss=0.0567922565775613\n",
      "test_test\n",
      "test mean loss=1159.5260314941406\n",
      "epoch 6357\n",
      "test_train\n",
      "train mean loss=0.24184260393182436\n",
      "test_test\n",
      "test mean loss=1162.0325012207031\n",
      "epoch 6358\n",
      "test_train\n",
      "train mean loss=0.07153581377739708\n",
      "test_test\n",
      "test mean loss=1160.858642578125\n",
      "epoch 6359\n",
      "test_train\n",
      "train mean loss=0.07173311648269494\n",
      "test_test\n",
      "test mean loss=1159.2039794921875\n",
      "epoch 6360\n",
      "test_train\n",
      "train mean loss=0.07198858726769686\n",
      "test_test\n",
      "test mean loss=1160.7633666992188\n",
      "epoch 6361\n",
      "test_train\n",
      "train mean loss=0.06199252481261889\n",
      "test_test\n",
      "test mean loss=1159.3128051757812\n",
      "epoch 6362\n",
      "test_train\n",
      "train mean loss=0.058262635643283524\n",
      "test_test\n",
      "test mean loss=1159.6283569335938\n",
      "epoch 6363\n",
      "test_train\n",
      "train mean loss=0.06398065170894067\n",
      "test_test\n",
      "test mean loss=1160.6505737304688\n",
      "epoch 6364\n",
      "test_train\n",
      "train mean loss=0.0650397976860404\n",
      "test_test\n",
      "test mean loss=1161.20947265625\n",
      "epoch 6365\n",
      "test_train\n",
      "train mean loss=0.06221912397692601\n",
      "test_test\n",
      "test mean loss=1160.581298828125\n",
      "epoch 6366\n",
      "test_train\n",
      "train mean loss=0.06323836868007977\n",
      "test_test\n",
      "test mean loss=1159.5117797851562\n",
      "epoch 6367\n",
      "test_train\n",
      "train mean loss=0.05582848625878493\n",
      "test_test\n",
      "test mean loss=1159.2073974609375\n",
      "epoch 6368\n",
      "test_train\n",
      "train mean loss=0.05906197242438793\n",
      "test_test\n",
      "test mean loss=1159.9029235839844\n",
      "epoch 6369\n",
      "test_train\n",
      "train mean loss=0.06111370865255594\n",
      "test_test\n",
      "test mean loss=1159.3055725097656\n",
      "epoch 6370\n",
      "test_train\n",
      "train mean loss=0.06177679573496183\n",
      "test_test\n",
      "test mean loss=1159.4616394042969\n",
      "epoch 6371\n",
      "test_train\n",
      "train mean loss=0.0642597358673811\n",
      "test_test\n",
      "test mean loss=1160.154052734375\n",
      "epoch 6372\n",
      "test_train\n",
      "train mean loss=0.07200088196744521\n",
      "test_test\n",
      "test mean loss=1160.64501953125\n",
      "epoch 6373\n",
      "test_train\n",
      "train mean loss=0.0620775685335199\n",
      "test_test\n",
      "test mean loss=1160.0361938476562\n",
      "epoch 6374\n",
      "test_train\n",
      "train mean loss=0.06059779413044453\n",
      "test_test\n",
      "test mean loss=1158.5033264160156\n",
      "epoch 6375\n",
      "test_train\n",
      "train mean loss=0.061380017238358654\n",
      "test_test\n",
      "test mean loss=1159.5223999023438\n",
      "epoch 6376\n",
      "test_train\n",
      "train mean loss=0.06883085099980235\n",
      "test_test\n",
      "test mean loss=1160.3943481445312\n",
      "epoch 6377\n",
      "test_train\n",
      "train mean loss=0.062026153008143105\n",
      "test_test\n",
      "test mean loss=1159.9846801757812\n",
      "epoch 6378\n",
      "test_train\n",
      "train mean loss=0.06371105182915926\n",
      "test_test\n",
      "test mean loss=1158.895263671875\n",
      "epoch 6379\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.06462290075918038\n",
      "test_test\n",
      "test mean loss=1159.7525024414062\n",
      "epoch 6380\n",
      "test_train\n",
      "train mean loss=0.22577016366024813\n",
      "test_test\n",
      "test mean loss=1156.679931640625\n",
      "epoch 6381\n",
      "test_train\n",
      "train mean loss=0.07397531562795241\n",
      "test_test\n",
      "test mean loss=1158.8057861328125\n",
      "epoch 6382\n",
      "test_train\n",
      "train mean loss=0.07013786335786183\n",
      "test_test\n",
      "test mean loss=1159.6157836914062\n",
      "epoch 6383\n",
      "test_train\n",
      "train mean loss=0.06085857811073462\n",
      "test_test\n",
      "test mean loss=1160.1463317871094\n",
      "epoch 6384\n",
      "test_train\n",
      "train mean loss=0.06240667309612036\n",
      "test_test\n",
      "test mean loss=1159.8505554199219\n",
      "epoch 6385\n",
      "test_train\n",
      "train mean loss=0.05925314733758569\n",
      "test_test\n",
      "test mean loss=1159.6571655273438\n",
      "epoch 6386\n",
      "test_train\n",
      "train mean loss=0.06055617177238067\n",
      "test_test\n",
      "test mean loss=1160.4535217285156\n",
      "epoch 6387\n",
      "test_train\n",
      "train mean loss=0.0673306022460262\n",
      "test_test\n",
      "test mean loss=1159.9708862304688\n",
      "epoch 6388\n",
      "test_train\n",
      "train mean loss=0.06240071853001913\n",
      "test_test\n",
      "test mean loss=1160.8717956542969\n",
      "epoch 6389\n",
      "test_train\n",
      "train mean loss=0.06579021612803142\n",
      "test_test\n",
      "test mean loss=1160.2376098632812\n",
      "epoch 6390\n",
      "test_train\n",
      "train mean loss=0.06261651505095263\n",
      "test_test\n",
      "test mean loss=1160.0119018554688\n",
      "epoch 6391\n",
      "test_train\n",
      "train mean loss=0.06216958072036505\n",
      "test_test\n",
      "test mean loss=1160.06298828125\n",
      "epoch 6392\n",
      "test_train\n",
      "train mean loss=0.06919214595109224\n",
      "test_test\n",
      "test mean loss=1159.6626586914062\n",
      "epoch 6393\n",
      "test_train\n",
      "train mean loss=0.05940157795945803\n",
      "test_test\n",
      "test mean loss=1159.4535522460938\n",
      "epoch 6394\n",
      "test_train\n",
      "train mean loss=0.06994605933626492\n",
      "test_test\n",
      "test mean loss=1160.265380859375\n",
      "epoch 6395\n",
      "test_train\n",
      "train mean loss=0.0671365074813366\n",
      "test_test\n",
      "test mean loss=1159.8380737304688\n",
      "epoch 6396\n",
      "test_train\n",
      "train mean loss=0.07136074174195528\n",
      "test_test\n",
      "test mean loss=1158.9254150390625\n",
      "epoch 6397\n",
      "test_train\n",
      "train mean loss=0.06984020831684272\n",
      "test_test\n",
      "test mean loss=1160.1853637695312\n",
      "epoch 6398\n",
      "test_train\n",
      "train mean loss=0.07083427005757888\n",
      "test_test\n",
      "test mean loss=1160.2399291992188\n",
      "epoch 6399\n",
      "test_train\n",
      "train mean loss=0.06442619922260444\n",
      "test_test\n",
      "test mean loss=1158.7924194335938\n",
      "epoch 6400\n",
      "test_train\n",
      "train mean loss=0.06947190128266811\n",
      "test_test\n",
      "test mean loss=1159.689453125\n",
      "epoch 6401\n",
      "test_train\n",
      "train mean loss=0.06494626154502232\n",
      "test_test\n",
      "test mean loss=1159.0987548828125\n",
      "epoch 6402\n",
      "test_train\n",
      "train mean loss=0.07333304795126121\n",
      "test_test\n",
      "test mean loss=1159.01953125\n",
      "epoch 6403\n",
      "test_train\n",
      "train mean loss=0.06322308878103892\n",
      "test_test\n",
      "test mean loss=1159.5970458984375\n",
      "epoch 6404\n",
      "test_train\n",
      "train mean loss=0.06163161030660073\n",
      "test_test\n",
      "test mean loss=1159.4105529785156\n",
      "epoch 6405\n",
      "test_train\n",
      "train mean loss=0.06212796332935492\n",
      "test_test\n",
      "test mean loss=1159.0986022949219\n",
      "epoch 6406\n",
      "test_train\n",
      "train mean loss=0.06651931318144004\n",
      "test_test\n",
      "test mean loss=1160.3493041992188\n",
      "epoch 6407\n",
      "test_train\n",
      "train mean loss=0.06524719142665465\n",
      "test_test\n",
      "test mean loss=1161.1121215820312\n",
      "epoch 6408\n",
      "test_train\n",
      "train mean loss=0.06900919834151864\n",
      "test_test\n",
      "test mean loss=1161.0664672851562\n",
      "epoch 6409\n",
      "test_train\n",
      "train mean loss=0.0680205812677741\n",
      "test_test\n",
      "test mean loss=1160.1288452148438\n",
      "epoch 6410\n",
      "test_train\n",
      "train mean loss=0.06724137378235658\n",
      "test_test\n",
      "test mean loss=1160.2652587890625\n",
      "epoch 6411\n",
      "test_train\n",
      "train mean loss=0.06613625368724267\n",
      "test_test\n",
      "test mean loss=1161.57568359375\n",
      "epoch 6412\n",
      "test_train\n",
      "train mean loss=0.06874908025686939\n",
      "test_test\n",
      "test mean loss=1160.1493530273438\n",
      "epoch 6413\n",
      "test_train\n",
      "train mean loss=0.05902893282473087\n",
      "test_test\n",
      "test mean loss=1159.1235961914062\n",
      "epoch 6414\n",
      "test_train\n",
      "train mean loss=0.06623275127882759\n",
      "test_test\n",
      "test mean loss=1160.013671875\n",
      "epoch 6415\n",
      "test_train\n",
      "train mean loss=0.06577375018969178\n",
      "test_test\n",
      "test mean loss=1160.0415649414062\n",
      "epoch 6416\n",
      "test_train\n",
      "train mean loss=0.059922401482860245\n",
      "test_test\n",
      "test mean loss=1160.0880432128906\n",
      "epoch 6417\n",
      "test_train\n",
      "train mean loss=0.06216501351445913\n",
      "test_test\n",
      "test mean loss=1160.2879638671875\n",
      "epoch 6418\n",
      "test_train\n",
      "train mean loss=0.06483819739272197\n",
      "test_test\n",
      "test mean loss=1159.7691650390625\n",
      "epoch 6419\n",
      "test_train\n",
      "train mean loss=0.06647321519752343\n",
      "test_test\n",
      "test mean loss=1160.5113525390625\n",
      "epoch 6420\n",
      "test_train\n",
      "train mean loss=0.05838003568351269\n",
      "test_test\n",
      "test mean loss=1159.9629516601562\n",
      "epoch 6421\n",
      "test_train\n",
      "train mean loss=0.06096002459526062\n",
      "test_test\n",
      "test mean loss=1159.6798706054688\n",
      "epoch 6422\n",
      "test_train\n",
      "train mean loss=0.05784407304599881\n",
      "test_test\n",
      "test mean loss=1160.5805969238281\n",
      "epoch 6423\n",
      "test_train\n",
      "train mean loss=0.06103358914454778\n",
      "test_test\n",
      "test mean loss=1160.9727172851562\n",
      "epoch 6424\n",
      "test_train\n",
      "train mean loss=0.06465714207539956\n",
      "test_test\n",
      "test mean loss=1161.0296630859375\n",
      "epoch 6425\n",
      "test_train\n",
      "train mean loss=0.062485068726042904\n",
      "test_test\n",
      "test mean loss=1160.9516296386719\n",
      "epoch 6426\n",
      "test_train\n",
      "train mean loss=0.06686367560178041\n",
      "test_test\n",
      "test mean loss=1161.8957214355469\n",
      "epoch 6427\n",
      "test_train\n",
      "train mean loss=0.08391696928689878\n",
      "test_test\n",
      "test mean loss=1162.2373962402344\n",
      "epoch 6428\n",
      "test_train\n",
      "train mean loss=0.06108328700065613\n",
      "test_test\n",
      "test mean loss=1161.0550537109375\n",
      "epoch 6429\n",
      "test_train\n",
      "train mean loss=0.06770513486117125\n",
      "test_test\n",
      "test mean loss=1161.2120056152344\n",
      "epoch 6430\n",
      "test_train\n",
      "train mean loss=0.05652706200877825\n",
      "test_test\n",
      "test mean loss=1160.0270690917969\n",
      "epoch 6431\n",
      "test_train\n",
      "train mean loss=0.05829505529254675\n",
      "test_test\n",
      "test mean loss=1159.8487243652344\n",
      "epoch 6432\n",
      "test_train\n",
      "train mean loss=0.06293741489450137\n",
      "test_test\n",
      "test mean loss=1161.4772644042969\n",
      "epoch 6433\n",
      "test_train\n",
      "train mean loss=0.06736078159883618\n",
      "test_test\n",
      "test mean loss=1160.7240600585938\n",
      "epoch 6434\n",
      "test_train\n",
      "train mean loss=0.06174667769422134\n",
      "test_test\n",
      "test mean loss=1160.3771362304688\n",
      "epoch 6435\n",
      "test_train\n",
      "train mean loss=0.06051330858220657\n",
      "test_test\n",
      "test mean loss=1161.0326538085938\n",
      "epoch 6436\n",
      "test_train\n",
      "train mean loss=0.07005509175360203\n",
      "test_test\n",
      "test mean loss=1160.1758422851562\n",
      "epoch 6437\n",
      "test_train\n",
      "train mean loss=0.06267384657015403\n",
      "test_test\n",
      "test mean loss=1160.2817687988281\n",
      "epoch 6438\n",
      "test_train\n",
      "train mean loss=0.06247634906321764\n",
      "test_test\n",
      "test mean loss=1160.7356567382812\n",
      "epoch 6439\n",
      "test_train\n",
      "train mean loss=0.06261390075087547\n",
      "test_test\n",
      "test mean loss=1161.0618591308594\n",
      "epoch 6440\n",
      "test_train\n",
      "train mean loss=0.06211188404510418\n",
      "test_test\n",
      "test mean loss=1160.3551025390625\n",
      "epoch 6441\n",
      "test_train\n",
      "train mean loss=0.07493770681321621\n",
      "test_test\n",
      "test mean loss=1162.03173828125\n",
      "epoch 6442\n",
      "test_train\n",
      "train mean loss=0.06806228123605251\n",
      "test_test\n",
      "test mean loss=1161.7189331054688\n",
      "epoch 6443\n",
      "test_train\n",
      "train mean loss=0.06379621258626382\n",
      "test_test\n",
      "test mean loss=1161.7742919921875\n",
      "epoch 6444\n",
      "test_train\n",
      "train mean loss=0.05612959867964188\n",
      "test_test\n",
      "test mean loss=1160.390380859375\n",
      "epoch 6445\n",
      "test_train\n",
      "train mean loss=0.07047257572412491\n",
      "test_test\n",
      "test mean loss=1161.3568725585938\n",
      "epoch 6446\n",
      "test_train\n",
      "train mean loss=0.06323209032416344\n",
      "test_test\n",
      "test mean loss=1160.3179321289062\n",
      "epoch 6447\n",
      "test_train\n",
      "train mean loss=0.054935783768693604\n",
      "test_test\n",
      "test mean loss=1159.5737915039062\n",
      "epoch 6448\n",
      "test_train\n",
      "train mean loss=0.061928536742925644\n",
      "test_test\n",
      "test mean loss=1160.28271484375\n",
      "epoch 6449\n",
      "test_train\n",
      "train mean loss=0.0652041845023632\n",
      "test_test\n",
      "test mean loss=1158.9491577148438\n",
      "epoch 6450\n",
      "test_train\n",
      "train mean loss=0.062077944787840046\n",
      "test_test\n",
      "test mean loss=1160.2569580078125\n",
      "epoch 6451\n",
      "test_train\n",
      "train mean loss=0.07709414232522249\n",
      "test_test\n",
      "test mean loss=1160.9689331054688\n",
      "epoch 6452\n",
      "test_train\n",
      "train mean loss=0.06506639812141657\n",
      "test_test\n",
      "test mean loss=1158.9481506347656\n",
      "epoch 6453\n",
      "test_train\n",
      "train mean loss=0.06575347110629082\n",
      "test_test\n",
      "test mean loss=1160.3883666992188\n",
      "epoch 6454\n",
      "test_train\n",
      "train mean loss=0.06188401502246658\n",
      "test_test\n",
      "test mean loss=1159.4723205566406\n",
      "epoch 6455\n",
      "test_train\n",
      "train mean loss=0.11810034234076738\n",
      "test_test\n",
      "test mean loss=1159.9954223632812\n",
      "epoch 6456\n",
      "test_train\n",
      "train mean loss=0.062417351019879184\n",
      "test_test\n",
      "test mean loss=1160.3115844726562\n",
      "epoch 6457\n",
      "test_train\n",
      "train mean loss=0.07355681682626407\n",
      "test_test\n",
      "test mean loss=1162.7395629882812\n",
      "epoch 6458\n",
      "test_train\n",
      "train mean loss=0.06374014976123969\n",
      "test_test\n",
      "test mean loss=1160.704833984375\n",
      "epoch 6459\n",
      "test_train\n",
      "train mean loss=0.06767888708661\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1159.4867553710938\n",
      "epoch 6460\n",
      "test_train\n",
      "train mean loss=0.0853686820094784\n",
      "test_test\n",
      "test mean loss=1161.730224609375\n",
      "epoch 6461\n",
      "test_train\n",
      "train mean loss=0.07015849091112614\n",
      "test_test\n",
      "test mean loss=1161.4556884765625\n",
      "epoch 6462\n",
      "test_train\n",
      "train mean loss=0.06594962192078431\n",
      "test_test\n",
      "test mean loss=1161.3044128417969\n",
      "epoch 6463\n",
      "test_train\n",
      "train mean loss=0.06797865219414234\n",
      "test_test\n",
      "test mean loss=1160.1473693847656\n",
      "epoch 6464\n",
      "test_train\n",
      "train mean loss=0.06393480688954394\n",
      "test_test\n",
      "test mean loss=1160.3005065917969\n",
      "epoch 6465\n",
      "test_train\n",
      "train mean loss=0.05846860414991776\n",
      "test_test\n",
      "test mean loss=1160.4583129882812\n",
      "epoch 6466\n",
      "test_train\n",
      "train mean loss=0.06479184608906507\n",
      "test_test\n",
      "test mean loss=1160.330322265625\n",
      "epoch 6467\n",
      "test_train\n",
      "train mean loss=0.06314251758158207\n",
      "test_test\n",
      "test mean loss=1160.7803344726562\n",
      "epoch 6468\n",
      "test_train\n",
      "train mean loss=0.06286568287760019\n",
      "test_test\n",
      "test mean loss=1160.8474731445312\n",
      "epoch 6469\n",
      "test_train\n",
      "train mean loss=0.06509656148652236\n",
      "test_test\n",
      "test mean loss=1161.28759765625\n",
      "epoch 6470\n",
      "test_train\n",
      "train mean loss=0.06067981291562319\n",
      "test_test\n",
      "test mean loss=1160.4584350585938\n",
      "epoch 6471\n",
      "test_train\n",
      "train mean loss=0.06069072522222996\n",
      "test_test\n",
      "test mean loss=1159.6488952636719\n",
      "epoch 6472\n",
      "test_train\n",
      "train mean loss=0.06771369154254596\n",
      "test_test\n",
      "test mean loss=1159.8797912597656\n",
      "epoch 6473\n",
      "test_train\n",
      "train mean loss=0.07920547512670358\n",
      "test_test\n",
      "test mean loss=1158.2442626953125\n",
      "epoch 6474\n",
      "test_train\n",
      "train mean loss=0.06250780603537957\n",
      "test_test\n",
      "test mean loss=1160.1415100097656\n",
      "epoch 6475\n",
      "test_train\n",
      "train mean loss=0.06021225933606426\n",
      "test_test\n",
      "test mean loss=1160.7187805175781\n",
      "epoch 6476\n",
      "test_train\n",
      "train mean loss=0.059041776694357395\n",
      "test_test\n",
      "test mean loss=1159.7196655273438\n",
      "epoch 6477\n",
      "test_train\n",
      "train mean loss=0.06265211229523023\n",
      "test_test\n",
      "test mean loss=1160.6208801269531\n",
      "epoch 6478\n",
      "test_train\n",
      "train mean loss=0.06807724138100942\n",
      "test_test\n",
      "test mean loss=1160.9016723632812\n",
      "epoch 6479\n",
      "test_train\n",
      "train mean loss=0.07128653954714537\n",
      "test_test\n",
      "test mean loss=1160.5269165039062\n",
      "epoch 6480\n",
      "test_train\n",
      "train mean loss=0.06038458117594322\n",
      "test_test\n",
      "test mean loss=1159.4703979492188\n",
      "epoch 6481\n",
      "test_train\n",
      "train mean loss=0.06193573183069626\n",
      "test_test\n",
      "test mean loss=1160.1350708007812\n",
      "epoch 6482\n",
      "test_train\n",
      "train mean loss=0.06349968848129113\n",
      "test_test\n",
      "test mean loss=1158.7327270507812\n",
      "epoch 6483\n",
      "test_train\n",
      "train mean loss=0.06333872769027948\n",
      "test_test\n",
      "test mean loss=1160.2389831542969\n",
      "epoch 6484\n",
      "test_train\n",
      "train mean loss=0.06790899795790513\n",
      "test_test\n",
      "test mean loss=1160.1947631835938\n",
      "epoch 6485\n",
      "test_train\n",
      "train mean loss=0.07142263775070508\n",
      "test_test\n",
      "test mean loss=1160.330810546875\n",
      "epoch 6486\n",
      "test_train\n",
      "train mean loss=0.06556981646766265\n",
      "test_test\n",
      "test mean loss=1160.584716796875\n",
      "epoch 6487\n",
      "test_train\n",
      "train mean loss=0.06465574229756992\n",
      "test_test\n",
      "test mean loss=1160.1826171875\n",
      "epoch 6488\n",
      "test_train\n",
      "train mean loss=0.06287928142895301\n",
      "test_test\n",
      "test mean loss=1160.8809814453125\n",
      "epoch 6489\n",
      "test_train\n",
      "train mean loss=0.06537553202360868\n",
      "test_test\n",
      "test mean loss=1158.89453125\n",
      "epoch 6490\n",
      "test_train\n",
      "train mean loss=0.060976255064209305\n",
      "test_test\n",
      "test mean loss=1159.5543823242188\n",
      "epoch 6491\n",
      "test_train\n",
      "train mean loss=0.06192779385795196\n",
      "test_test\n",
      "test mean loss=1160.1887817382812\n",
      "epoch 6492\n",
      "test_train\n",
      "train mean loss=0.06150451395660639\n",
      "test_test\n",
      "test mean loss=1160.0396728515625\n",
      "epoch 6493\n",
      "test_train\n",
      "train mean loss=0.06295842646310727\n",
      "test_test\n",
      "test mean loss=1160.5880126953125\n",
      "epoch 6494\n",
      "test_train\n",
      "train mean loss=0.07643773499876261\n",
      "test_test\n",
      "test mean loss=1162.54345703125\n",
      "epoch 6495\n",
      "test_train\n",
      "train mean loss=0.07227341551333666\n",
      "test_test\n",
      "test mean loss=1161.2440795898438\n",
      "epoch 6496\n",
      "test_train\n",
      "train mean loss=0.056496474581460156\n",
      "test_test\n",
      "test mean loss=1160.76416015625\n",
      "epoch 6497\n",
      "test_train\n",
      "train mean loss=0.060241239455839\n",
      "test_test\n",
      "test mean loss=1159.735107421875\n",
      "epoch 6498\n",
      "test_train\n",
      "train mean loss=0.06238103347520033\n",
      "test_test\n",
      "test mean loss=1160.8481750488281\n",
      "epoch 6499\n",
      "test_train\n",
      "train mean loss=0.05826084781438112\n",
      "test_test\n",
      "test mean loss=1161.1357421875\n",
      "epoch 6500\n",
      "test_train\n",
      "train mean loss=0.05633605613062779\n",
      "test_test\n",
      "test mean loss=1160.0154724121094\n",
      "epoch 6501\n",
      "test_train\n",
      "train mean loss=0.06269709315771858\n",
      "test_test\n",
      "test mean loss=1160.8345031738281\n",
      "epoch 6502\n",
      "test_train\n",
      "train mean loss=0.6339917505780855\n",
      "test_test\n",
      "test mean loss=1156.2843017578125\n",
      "epoch 6503\n",
      "test_train\n",
      "train mean loss=0.07760407496243715\n",
      "test_test\n",
      "test mean loss=1161.35986328125\n",
      "epoch 6504\n",
      "test_train\n",
      "train mean loss=0.0547249186784029\n",
      "test_test\n",
      "test mean loss=1158.6208190917969\n",
      "epoch 6505\n",
      "test_train\n",
      "train mean loss=0.053406991685430207\n",
      "test_test\n",
      "test mean loss=1158.8392333984375\n",
      "epoch 6506\n",
      "test_train\n",
      "train mean loss=0.07316253458460172\n",
      "test_test\n",
      "test mean loss=1157.2715148925781\n",
      "epoch 6507\n",
      "test_train\n",
      "train mean loss=0.06934937927871943\n",
      "test_test\n",
      "test mean loss=1160.177490234375\n",
      "epoch 6508\n",
      "test_train\n",
      "train mean loss=0.06419010336200397\n",
      "test_test\n",
      "test mean loss=1160.3923645019531\n",
      "epoch 6509\n",
      "test_train\n",
      "train mean loss=0.05945910389224688\n",
      "test_test\n",
      "test mean loss=1159.2116394042969\n",
      "epoch 6510\n",
      "test_train\n",
      "train mean loss=0.06221608414004246\n",
      "test_test\n",
      "test mean loss=1159.961669921875\n",
      "epoch 6511\n",
      "test_train\n",
      "train mean loss=0.06012099701911211\n",
      "test_test\n",
      "test mean loss=1159.9335021972656\n",
      "epoch 6512\n",
      "test_train\n",
      "train mean loss=0.06322816542039315\n",
      "test_test\n",
      "test mean loss=1160.4773864746094\n",
      "epoch 6513\n",
      "test_train\n",
      "train mean loss=0.06855511820564668\n",
      "test_test\n",
      "test mean loss=1160.0743408203125\n",
      "epoch 6514\n",
      "test_train\n",
      "train mean loss=0.06444864425187309\n",
      "test_test\n",
      "test mean loss=1160.044189453125\n",
      "epoch 6515\n",
      "test_train\n",
      "train mean loss=0.06884557971109946\n",
      "test_test\n",
      "test mean loss=1158.7102661132812\n",
      "epoch 6516\n",
      "test_train\n",
      "train mean loss=0.06164651814227303\n",
      "test_test\n",
      "test mean loss=1160.5074462890625\n",
      "epoch 6517\n",
      "test_train\n",
      "train mean loss=0.06428208823005359\n",
      "test_test\n",
      "test mean loss=1160.534912109375\n",
      "epoch 6518\n",
      "test_train\n",
      "train mean loss=0.05796145927160978\n",
      "test_test\n",
      "test mean loss=1161.0737915039062\n",
      "epoch 6519\n",
      "test_train\n",
      "train mean loss=0.05893162668993076\n",
      "test_test\n",
      "test mean loss=1160.800537109375\n",
      "epoch 6520\n",
      "test_train\n",
      "train mean loss=0.06378158492346604\n",
      "test_test\n",
      "test mean loss=1160.5325927734375\n",
      "epoch 6521\n",
      "test_train\n",
      "train mean loss=0.06108450020352999\n",
      "test_test\n",
      "test mean loss=1159.2791748046875\n",
      "epoch 6522\n",
      "test_train\n",
      "train mean loss=0.0613171081058681\n",
      "test_test\n",
      "test mean loss=1160.744873046875\n",
      "epoch 6523\n",
      "test_train\n",
      "train mean loss=0.060768996054927506\n",
      "test_test\n",
      "test mean loss=1161.4605712890625\n",
      "epoch 6524\n",
      "test_train\n",
      "train mean loss=0.06904057785868645\n",
      "test_test\n",
      "test mean loss=1161.6381225585938\n",
      "epoch 6525\n",
      "test_train\n",
      "train mean loss=0.06347894823799531\n",
      "test_test\n",
      "test mean loss=1160.9825439453125\n",
      "epoch 6526\n",
      "test_train\n",
      "train mean loss=0.0796352153023084\n",
      "test_test\n",
      "test mean loss=1158.5890502929688\n",
      "epoch 6527\n",
      "test_train\n",
      "train mean loss=0.07035086303949356\n",
      "test_test\n",
      "test mean loss=1161.2916259765625\n",
      "epoch 6528\n",
      "test_train\n",
      "train mean loss=0.06746724589417379\n",
      "test_test\n",
      "test mean loss=1161.4624938964844\n",
      "epoch 6529\n",
      "test_train\n",
      "train mean loss=0.07212046254426241\n",
      "test_test\n",
      "test mean loss=1159.9161376953125\n",
      "epoch 6530\n",
      "test_train\n",
      "train mean loss=0.06387919591118892\n",
      "test_test\n",
      "test mean loss=1159.771240234375\n",
      "epoch 6531\n",
      "test_train\n",
      "train mean loss=0.06675562045226495\n",
      "test_test\n",
      "test mean loss=1160.3591003417969\n",
      "epoch 6532\n",
      "test_train\n",
      "train mean loss=0.062452074761192\n",
      "test_test\n",
      "test mean loss=1159.7615966796875\n",
      "epoch 6533\n",
      "test_train\n",
      "train mean loss=0.05732331549127897\n",
      "test_test\n",
      "test mean loss=1160.0918579101562\n",
      "epoch 6534\n",
      "test_train\n",
      "train mean loss=0.060820830054581165\n",
      "test_test\n",
      "test mean loss=1159.6732177734375\n",
      "epoch 6535\n",
      "test_train\n",
      "train mean loss=0.063695947950085\n",
      "test_test\n",
      "test mean loss=1159.8184814453125\n",
      "epoch 6536\n",
      "test_train\n",
      "train mean loss=0.06731207327296336\n",
      "test_test\n",
      "test mean loss=1160.1470336914062\n",
      "epoch 6537\n",
      "test_train\n",
      "train mean loss=0.06226904379824797\n",
      "test_test\n",
      "test mean loss=1159.6221923828125\n",
      "epoch 6538\n",
      "test_train\n",
      "train mean loss=0.05641724821180105\n",
      "test_test\n",
      "test mean loss=1159.014404296875\n",
      "epoch 6539\n",
      "test_train\n",
      "train mean loss=0.06651629911114772\n",
      "test_test\n",
      "test mean loss=1159.9263000488281\n",
      "epoch 6540\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.06192062857250372\n",
      "test_test\n",
      "test mean loss=1159.8787536621094\n",
      "epoch 6541\n",
      "test_train\n",
      "train mean loss=0.06362114877750476\n",
      "test_test\n",
      "test mean loss=1159.42431640625\n",
      "epoch 6542\n",
      "test_train\n",
      "train mean loss=0.06382282761236031\n",
      "test_test\n",
      "test mean loss=1159.9296875\n",
      "epoch 6543\n",
      "test_train\n",
      "train mean loss=0.06590383034199476\n",
      "test_test\n",
      "test mean loss=1160.1654968261719\n",
      "epoch 6544\n",
      "test_train\n",
      "train mean loss=0.06205348173777262\n",
      "test_test\n",
      "test mean loss=1159.0950927734375\n",
      "epoch 6545\n",
      "test_train\n",
      "train mean loss=0.07031048896412055\n",
      "test_test\n",
      "test mean loss=1160.9592590332031\n",
      "epoch 6546\n",
      "test_train\n",
      "train mean loss=0.06992785011728604\n",
      "test_test\n",
      "test mean loss=1159.6317138671875\n",
      "epoch 6547\n",
      "test_train\n",
      "train mean loss=0.06451451064397891\n",
      "test_test\n",
      "test mean loss=1160.225830078125\n",
      "epoch 6548\n",
      "test_train\n",
      "train mean loss=0.0680109141394496\n",
      "test_test\n",
      "test mean loss=1159.9072265625\n",
      "epoch 6549\n",
      "test_train\n",
      "train mean loss=0.06672923111667235\n",
      "test_test\n",
      "test mean loss=1159.5668334960938\n",
      "epoch 6550\n",
      "test_train\n",
      "train mean loss=0.06405248182515304\n",
      "test_test\n",
      "test mean loss=1160.5274047851562\n",
      "epoch 6551\n",
      "test_train\n",
      "train mean loss=0.06085670584191879\n",
      "test_test\n",
      "test mean loss=1159.8277282714844\n",
      "epoch 6552\n",
      "test_train\n",
      "train mean loss=0.06275310429433982\n",
      "test_test\n",
      "test mean loss=1159.93798828125\n",
      "epoch 6553\n",
      "test_train\n",
      "train mean loss=0.07200948055833578\n",
      "test_test\n",
      "test mean loss=1160.7599182128906\n",
      "epoch 6554\n",
      "test_train\n",
      "train mean loss=0.06352082919329405\n",
      "test_test\n",
      "test mean loss=1160.64453125\n",
      "epoch 6555\n",
      "test_train\n",
      "train mean loss=0.055500746394197144\n",
      "test_test\n",
      "test mean loss=1159.9134216308594\n",
      "epoch 6556\n",
      "test_train\n",
      "train mean loss=0.055999623301128544\n",
      "test_test\n",
      "test mean loss=1160.4522094726562\n",
      "epoch 6557\n",
      "test_train\n",
      "train mean loss=0.06282373797148466\n",
      "test_test\n",
      "test mean loss=1161.3000183105469\n",
      "epoch 6558\n",
      "test_train\n",
      "train mean loss=0.060895282154281936\n",
      "test_test\n",
      "test mean loss=1159.923583984375\n",
      "epoch 6559\n",
      "test_train\n",
      "train mean loss=0.06143614059935013\n",
      "test_test\n",
      "test mean loss=1159.1561889648438\n",
      "epoch 6560\n",
      "test_train\n",
      "train mean loss=0.059848543256521225\n",
      "test_test\n",
      "test mean loss=1159.367431640625\n",
      "epoch 6561\n",
      "test_train\n",
      "train mean loss=0.1443121638149023\n",
      "test_test\n",
      "test mean loss=1156.928955078125\n",
      "epoch 6562\n",
      "test_train\n",
      "train mean loss=0.060234224734207\n",
      "test_test\n",
      "test mean loss=1158.6860961914062\n",
      "epoch 6563\n",
      "test_train\n",
      "train mean loss=0.06338621148218711\n",
      "test_test\n",
      "test mean loss=1159.2246704101562\n",
      "epoch 6564\n",
      "test_train\n",
      "train mean loss=0.059622786939144135\n",
      "test_test\n",
      "test mean loss=1158.7532653808594\n",
      "epoch 6565\n",
      "test_train\n",
      "train mean loss=0.05258982038746277\n",
      "test_test\n",
      "test mean loss=1158.9862670898438\n",
      "epoch 6566\n",
      "test_train\n",
      "train mean loss=0.06419108373423417\n",
      "test_test\n",
      "test mean loss=1160.1414794921875\n",
      "epoch 6567\n",
      "test_train\n",
      "train mean loss=0.05868020824467143\n",
      "test_test\n",
      "test mean loss=1159.4879760742188\n",
      "epoch 6568\n",
      "test_train\n",
      "train mean loss=0.06173676811158657\n",
      "test_test\n",
      "test mean loss=1161.4530029296875\n",
      "epoch 6569\n",
      "test_train\n",
      "train mean loss=0.06334838426361482\n",
      "test_test\n",
      "test mean loss=1161.0989685058594\n",
      "epoch 6570\n",
      "test_train\n",
      "train mean loss=0.06128622218966484\n",
      "test_test\n",
      "test mean loss=1161.151123046875\n",
      "epoch 6571\n",
      "test_train\n",
      "train mean loss=0.052792183899631105\n",
      "test_test\n",
      "test mean loss=1160.5703125\n",
      "epoch 6572\n",
      "test_train\n",
      "train mean loss=0.05648238677531481\n",
      "test_test\n",
      "test mean loss=1160.1301574707031\n",
      "epoch 6573\n",
      "test_train\n",
      "train mean loss=0.13733053455750147\n",
      "test_test\n",
      "test mean loss=1161.5144653320312\n",
      "epoch 6574\n",
      "test_train\n",
      "train mean loss=0.06247887682790557\n",
      "test_test\n",
      "test mean loss=1159.4139709472656\n",
      "epoch 6575\n",
      "test_train\n",
      "train mean loss=0.06797162505487601\n",
      "test_test\n",
      "test mean loss=1159.8740234375\n",
      "epoch 6576\n",
      "test_train\n",
      "train mean loss=0.05718610994517803\n",
      "test_test\n",
      "test mean loss=1158.7351379394531\n",
      "epoch 6577\n",
      "test_train\n",
      "train mean loss=0.06280300052215655\n",
      "test_test\n",
      "test mean loss=1158.7652587890625\n",
      "epoch 6578\n",
      "test_train\n",
      "train mean loss=0.06151289617021879\n",
      "test_test\n",
      "test mean loss=1160.1047973632812\n",
      "epoch 6579\n",
      "test_train\n",
      "train mean loss=0.06507433640460174\n",
      "test_test\n",
      "test mean loss=1159.9160766601562\n",
      "epoch 6580\n",
      "test_train\n",
      "train mean loss=0.056225189939141273\n",
      "test_test\n",
      "test mean loss=1159.4102783203125\n",
      "epoch 6581\n",
      "test_train\n",
      "train mean loss=0.05376493884250522\n",
      "test_test\n",
      "test mean loss=1158.495361328125\n",
      "epoch 6582\n",
      "test_train\n",
      "train mean loss=0.06868274851391713\n",
      "test_test\n",
      "test mean loss=1159.36474609375\n",
      "epoch 6583\n",
      "test_train\n",
      "train mean loss=0.06336766295135021\n",
      "test_test\n",
      "test mean loss=1158.9463500976562\n",
      "epoch 6584\n",
      "test_train\n",
      "train mean loss=0.0669725261007746\n",
      "test_test\n",
      "test mean loss=1160.0792541503906\n",
      "epoch 6585\n",
      "test_train\n",
      "train mean loss=0.06450764586528142\n",
      "test_test\n",
      "test mean loss=1159.4869384765625\n",
      "epoch 6586\n",
      "test_train\n",
      "train mean loss=0.06847218858699004\n",
      "test_test\n",
      "test mean loss=1159.6587829589844\n",
      "epoch 6587\n",
      "test_train\n",
      "train mean loss=0.0645404780904452\n",
      "test_test\n",
      "test mean loss=1160.5761108398438\n",
      "epoch 6588\n",
      "test_train\n",
      "train mean loss=0.059087833079198994\n",
      "test_test\n",
      "test mean loss=1161.1515502929688\n",
      "epoch 6589\n",
      "test_train\n",
      "train mean loss=0.0670066565896074\n",
      "test_test\n",
      "test mean loss=1160.4237670898438\n",
      "epoch 6590\n",
      "test_train\n",
      "train mean loss=0.06479034836714466\n",
      "test_test\n",
      "test mean loss=1160.2455444335938\n",
      "epoch 6591\n",
      "test_train\n",
      "train mean loss=0.07296772456417482\n",
      "test_test\n",
      "test mean loss=1161.5790405273438\n",
      "epoch 6592\n",
      "test_train\n",
      "train mean loss=0.060663867741823196\n",
      "test_test\n",
      "test mean loss=1159.70556640625\n",
      "epoch 6593\n",
      "test_train\n",
      "train mean loss=0.06353217301269372\n",
      "test_test\n",
      "test mean loss=1160.3308715820312\n",
      "epoch 6594\n",
      "test_train\n",
      "train mean loss=0.1183135670920213\n",
      "test_test\n",
      "test mean loss=1160.6253051757812\n",
      "epoch 6595\n",
      "test_train\n",
      "train mean loss=0.07462773937731981\n",
      "test_test\n",
      "test mean loss=1159.3148193359375\n",
      "epoch 6596\n",
      "test_train\n",
      "train mean loss=0.06127894405896465\n",
      "test_test\n",
      "test mean loss=1158.2954711914062\n",
      "epoch 6597\n",
      "test_train\n",
      "train mean loss=0.060978516936302185\n",
      "test_test\n",
      "test mean loss=1159.6960754394531\n",
      "epoch 6598\n",
      "test_train\n",
      "train mean loss=0.06060243118554354\n",
      "test_test\n",
      "test mean loss=1159.6398010253906\n",
      "epoch 6599\n",
      "test_train\n",
      "train mean loss=0.06484160230805476\n",
      "test_test\n",
      "test mean loss=1160.5068969726562\n",
      "epoch 6600\n",
      "test_train\n",
      "train mean loss=0.05834018252789974\n",
      "test_test\n",
      "test mean loss=1159.7979431152344\n",
      "epoch 6601\n",
      "test_train\n",
      "train mean loss=0.06182855119307836\n",
      "test_test\n",
      "test mean loss=1159.9946594238281\n",
      "epoch 6602\n",
      "test_train\n",
      "train mean loss=0.05932100676000118\n",
      "test_test\n",
      "test mean loss=1159.5665893554688\n",
      "epoch 6603\n",
      "test_train\n",
      "train mean loss=0.05885483603924513\n",
      "test_test\n",
      "test mean loss=1159.3931274414062\n",
      "epoch 6604\n",
      "test_train\n",
      "train mean loss=0.06350334485371907\n",
      "test_test\n",
      "test mean loss=1160.292236328125\n",
      "epoch 6605\n",
      "test_train\n",
      "train mean loss=0.06924381914238135\n",
      "test_test\n",
      "test mean loss=1159.4484558105469\n",
      "epoch 6606\n",
      "test_train\n",
      "train mean loss=0.07074345679332812\n",
      "test_test\n",
      "test mean loss=1159.1124267578125\n",
      "epoch 6607\n",
      "test_train\n",
      "train mean loss=0.06072752239803473\n",
      "test_test\n",
      "test mean loss=1159.8452758789062\n",
      "epoch 6608\n",
      "test_train\n",
      "train mean loss=0.06104407645761967\n",
      "test_test\n",
      "test mean loss=1160.4361877441406\n",
      "epoch 6609\n",
      "test_train\n",
      "train mean loss=0.06190597700575987\n",
      "test_test\n",
      "test mean loss=1160.3531494140625\n",
      "epoch 6610\n",
      "test_train\n",
      "train mean loss=0.11115603893995285\n",
      "test_test\n",
      "test mean loss=1161.4620361328125\n",
      "epoch 6611\n",
      "test_train\n",
      "train mean loss=0.0569748409713308\n",
      "test_test\n",
      "test mean loss=1160.45166015625\n",
      "epoch 6612\n",
      "test_train\n",
      "train mean loss=0.06838908170660336\n",
      "test_test\n",
      "test mean loss=1160.2346801757812\n",
      "epoch 6613\n",
      "test_train\n",
      "train mean loss=0.06130335479974747\n",
      "test_test\n",
      "test mean loss=1160.71630859375\n",
      "epoch 6614\n",
      "test_train\n",
      "train mean loss=0.06726705376058817\n",
      "test_test\n",
      "test mean loss=1161.1419067382812\n",
      "epoch 6615\n",
      "test_train\n",
      "train mean loss=0.0632772867878278\n",
      "test_test\n",
      "test mean loss=1160.5609741210938\n",
      "epoch 6616\n",
      "test_train\n",
      "train mean loss=0.05860194827740391\n",
      "test_test\n",
      "test mean loss=1159.9779663085938\n",
      "epoch 6617\n",
      "test_train\n",
      "train mean loss=0.05968622614940008\n",
      "test_test\n",
      "test mean loss=1160.5115356445312\n",
      "epoch 6618\n",
      "test_train\n",
      "train mean loss=0.06305233218396704\n",
      "test_test\n",
      "test mean loss=1161.0241088867188\n",
      "epoch 6619\n",
      "test_train\n",
      "train mean loss=0.05895194582020243\n",
      "test_test\n",
      "test mean loss=1160.0675659179688\n",
      "epoch 6620\n",
      "test_train\n",
      "train mean loss=0.06417375430464745\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1160.2516479492188\n",
      "epoch 6621\n",
      "test_train\n",
      "train mean loss=0.06100423587486148\n",
      "test_test\n",
      "test mean loss=1160.5546875\n",
      "epoch 6622\n",
      "test_train\n",
      "train mean loss=0.06434900748233001\n",
      "test_test\n",
      "test mean loss=1160.4942626953125\n",
      "epoch 6623\n",
      "test_train\n",
      "train mean loss=0.06003847857937217\n",
      "test_test\n",
      "test mean loss=1160.8605651855469\n",
      "epoch 6624\n",
      "test_train\n",
      "train mean loss=0.061647938253978886\n",
      "test_test\n",
      "test mean loss=1160.5701904296875\n",
      "epoch 6625\n",
      "test_train\n",
      "train mean loss=0.057918802835047245\n",
      "test_test\n",
      "test mean loss=1160.5322265625\n",
      "epoch 6626\n",
      "test_train\n",
      "train mean loss=0.0622102323298653\n",
      "test_test\n",
      "test mean loss=1161.0589904785156\n",
      "epoch 6627\n",
      "test_train\n",
      "train mean loss=0.0614578298603495\n",
      "test_test\n",
      "test mean loss=1159.6131591796875\n",
      "epoch 6628\n",
      "test_train\n",
      "train mean loss=0.0654758356201152\n",
      "test_test\n",
      "test mean loss=1159.4794921875\n",
      "epoch 6629\n",
      "test_train\n",
      "train mean loss=0.06448079211016496\n",
      "test_test\n",
      "test mean loss=1160.1090698242188\n",
      "epoch 6630\n",
      "test_train\n",
      "train mean loss=3.1477938493092856\n",
      "test_test\n",
      "test mean loss=1164.75634765625\n",
      "epoch 6631\n",
      "test_train\n",
      "train mean loss=2.8765117128690085\n",
      "test_test\n",
      "test mean loss=1163.2337036132812\n",
      "epoch 6632\n",
      "test_train\n",
      "train mean loss=0.15724640587965646\n",
      "test_test\n",
      "test mean loss=1161.6304321289062\n",
      "epoch 6633\n",
      "test_train\n",
      "train mean loss=0.1004798449575901\n",
      "test_test\n",
      "test mean loss=1162.4754638671875\n",
      "epoch 6634\n",
      "test_train\n",
      "train mean loss=0.07139432864884536\n",
      "test_test\n",
      "test mean loss=1161.4687805175781\n",
      "epoch 6635\n",
      "test_train\n",
      "train mean loss=0.07221484463661909\n",
      "test_test\n",
      "test mean loss=1161.88525390625\n",
      "epoch 6636\n",
      "test_train\n",
      "train mean loss=0.05848356212178866\n",
      "test_test\n",
      "test mean loss=1160.0594482421875\n",
      "epoch 6637\n",
      "test_train\n",
      "train mean loss=0.06418856016049783\n",
      "test_test\n",
      "test mean loss=1160.3287963867188\n",
      "epoch 6638\n",
      "test_train\n",
      "train mean loss=0.06867152328292529\n",
      "test_test\n",
      "test mean loss=1161.1994323730469\n",
      "epoch 6639\n",
      "test_train\n",
      "train mean loss=0.07105477216343085\n",
      "test_test\n",
      "test mean loss=1161.0663452148438\n",
      "epoch 6640\n",
      "test_train\n",
      "train mean loss=0.08531900898863871\n",
      "test_test\n",
      "test mean loss=1162.2338256835938\n",
      "epoch 6641\n",
      "test_train\n",
      "train mean loss=0.06027808102468649\n",
      "test_test\n",
      "test mean loss=1159.9668273925781\n",
      "epoch 6642\n",
      "test_train\n",
      "train mean loss=0.06237807249029478\n",
      "test_test\n",
      "test mean loss=1160.1641845703125\n",
      "epoch 6643\n",
      "test_train\n",
      "train mean loss=0.06438222123930852\n",
      "test_test\n",
      "test mean loss=1159.6702270507812\n",
      "epoch 6644\n",
      "test_train\n",
      "train mean loss=0.06587170530110598\n",
      "test_test\n",
      "test mean loss=1159.7621459960938\n",
      "epoch 6645\n",
      "test_train\n",
      "train mean loss=0.06878441603233416\n",
      "test_test\n",
      "test mean loss=1159.8399353027344\n",
      "epoch 6646\n",
      "test_train\n",
      "train mean loss=0.06950296958287557\n",
      "test_test\n",
      "test mean loss=1159.6515808105469\n",
      "epoch 6647\n",
      "test_train\n",
      "train mean loss=0.06888528012981017\n",
      "test_test\n",
      "test mean loss=1160.7158813476562\n",
      "epoch 6648\n",
      "test_train\n",
      "train mean loss=0.06411822667966287\n",
      "test_test\n",
      "test mean loss=1160.9856567382812\n",
      "epoch 6649\n",
      "test_train\n",
      "train mean loss=0.06411655309299628\n",
      "test_test\n",
      "test mean loss=1160.123291015625\n",
      "epoch 6650\n",
      "test_train\n",
      "train mean loss=0.06559357233345509\n",
      "test_test\n",
      "test mean loss=1159.5020751953125\n",
      "epoch 6651\n",
      "test_train\n",
      "train mean loss=0.08148762707908948\n",
      "test_test\n",
      "test mean loss=1160.9032592773438\n",
      "epoch 6652\n",
      "test_train\n",
      "train mean loss=0.06236314649383227\n",
      "test_test\n",
      "test mean loss=1160.1063537597656\n",
      "epoch 6653\n",
      "test_train\n",
      "train mean loss=0.06951375647137563\n",
      "test_test\n",
      "test mean loss=1160.1781616210938\n",
      "epoch 6654\n",
      "test_train\n",
      "train mean loss=0.06283673830330372\n",
      "test_test\n",
      "test mean loss=1160.1799011230469\n",
      "epoch 6655\n",
      "test_train\n",
      "train mean loss=0.06563948808858792\n",
      "test_test\n",
      "test mean loss=1160.0068969726562\n",
      "epoch 6656\n",
      "test_train\n",
      "train mean loss=0.07162143010646105\n",
      "test_test\n",
      "test mean loss=1160.5957641601562\n",
      "epoch 6657\n",
      "test_train\n",
      "train mean loss=0.060378368478268385\n",
      "test_test\n",
      "test mean loss=1160.5625610351562\n",
      "epoch 6658\n",
      "test_train\n",
      "train mean loss=0.06727096904069185\n",
      "test_test\n",
      "test mean loss=1160.7969055175781\n",
      "epoch 6659\n",
      "test_train\n",
      "train mean loss=0.16206744126975536\n",
      "test_test\n",
      "test mean loss=1157.1209106445312\n",
      "epoch 6660\n",
      "test_train\n",
      "train mean loss=0.07029935127745073\n",
      "test_test\n",
      "test mean loss=1160.2911376953125\n",
      "epoch 6661\n",
      "test_train\n",
      "train mean loss=0.07456933862219255\n",
      "test_test\n",
      "test mean loss=1160.8150634765625\n",
      "epoch 6662\n",
      "test_train\n",
      "train mean loss=0.06606483086943626\n",
      "test_test\n",
      "test mean loss=1159.8273620605469\n",
      "epoch 6663\n",
      "test_train\n",
      "train mean loss=0.06741114829977353\n",
      "test_test\n",
      "test mean loss=1160.2654418945312\n",
      "epoch 6664\n",
      "test_train\n",
      "train mean loss=0.061030367854982615\n",
      "test_test\n",
      "test mean loss=1161.023681640625\n",
      "epoch 6665\n",
      "test_train\n",
      "train mean loss=0.06673397372166316\n",
      "test_test\n",
      "test mean loss=1160.7241516113281\n",
      "epoch 6666\n",
      "test_train\n",
      "train mean loss=0.07622351419801514\n",
      "test_test\n",
      "test mean loss=1161.2728271484375\n",
      "epoch 6667\n",
      "test_train\n",
      "train mean loss=0.07119281000147264\n",
      "test_test\n",
      "test mean loss=1160.4098510742188\n",
      "epoch 6668\n",
      "test_train\n",
      "train mean loss=0.06514098433156808\n",
      "test_test\n",
      "test mean loss=1159.4823608398438\n",
      "epoch 6669\n",
      "test_train\n",
      "train mean loss=1.4589353054761887\n",
      "test_test\n",
      "test mean loss=1154.9307861328125\n",
      "epoch 6670\n",
      "test_train\n",
      "train mean loss=0.24548195923368135\n",
      "test_test\n",
      "test mean loss=1152.5979614257812\n",
      "epoch 6671\n",
      "test_train\n",
      "train mean loss=0.06195789435878396\n",
      "test_test\n",
      "test mean loss=1159.3931274414062\n",
      "epoch 6672\n",
      "test_train\n",
      "train mean loss=0.0648465221747756\n",
      "test_test\n",
      "test mean loss=1158.9011535644531\n",
      "epoch 6673\n",
      "test_train\n",
      "train mean loss=0.06562188857545455\n",
      "test_test\n",
      "test mean loss=1161.4598999023438\n",
      "epoch 6674\n",
      "test_train\n",
      "train mean loss=0.08369674999266863\n",
      "test_test\n",
      "test mean loss=1161.7102966308594\n",
      "epoch 6675\n",
      "test_train\n",
      "train mean loss=0.07307349083324273\n",
      "test_test\n",
      "test mean loss=1162.0390014648438\n",
      "epoch 6676\n",
      "test_train\n",
      "train mean loss=0.0680854981765151\n",
      "test_test\n",
      "test mean loss=1159.6634216308594\n",
      "epoch 6677\n",
      "test_train\n",
      "train mean loss=0.06894614330182473\n",
      "test_test\n",
      "test mean loss=1160.9691772460938\n",
      "epoch 6678\n",
      "test_train\n",
      "train mean loss=0.06243357186516126\n",
      "test_test\n",
      "test mean loss=1160.7210998535156\n",
      "epoch 6679\n",
      "test_train\n",
      "train mean loss=0.06393730298926432\n",
      "test_test\n",
      "test mean loss=1160.1436157226562\n",
      "epoch 6680\n",
      "test_train\n",
      "train mean loss=0.06019470592339834\n",
      "test_test\n",
      "test mean loss=1161.8783569335938\n",
      "epoch 6681\n",
      "test_train\n",
      "train mean loss=0.06469362834468484\n",
      "test_test\n",
      "test mean loss=1162.593505859375\n",
      "epoch 6682\n",
      "test_train\n",
      "train mean loss=0.06714258824164669\n",
      "test_test\n",
      "test mean loss=1161.52685546875\n",
      "epoch 6683\n",
      "test_train\n",
      "train mean loss=0.06833154894411564\n",
      "test_test\n",
      "test mean loss=1162.1666564941406\n",
      "epoch 6684\n",
      "test_train\n",
      "train mean loss=0.059650762317081295\n",
      "test_test\n",
      "test mean loss=1161.1372680664062\n",
      "epoch 6685\n",
      "test_train\n",
      "train mean loss=0.05936564660320679\n",
      "test_test\n",
      "test mean loss=1160.7557983398438\n",
      "epoch 6686\n",
      "test_train\n",
      "train mean loss=0.08393575406322877\n",
      "test_test\n",
      "test mean loss=1160.1954345703125\n",
      "epoch 6687\n",
      "test_train\n",
      "train mean loss=0.0710251626248161\n",
      "test_test\n",
      "test mean loss=1161.7667846679688\n",
      "epoch 6688\n",
      "test_train\n",
      "train mean loss=0.061887450671444334\n",
      "test_test\n",
      "test mean loss=1160.6461181640625\n",
      "epoch 6689\n",
      "test_train\n",
      "train mean loss=0.061913575045764446\n",
      "test_test\n",
      "test mean loss=1161.2262573242188\n",
      "epoch 6690\n",
      "test_train\n",
      "train mean loss=0.06875858937079708\n",
      "test_test\n",
      "test mean loss=1162.3096008300781\n",
      "epoch 6691\n",
      "test_train\n",
      "train mean loss=0.06480674507717292\n",
      "test_test\n",
      "test mean loss=1161.1953430175781\n",
      "epoch 6692\n",
      "test_train\n",
      "train mean loss=0.07256346025193731\n",
      "test_test\n",
      "test mean loss=1161.7255249023438\n",
      "epoch 6693\n",
      "test_train\n",
      "train mean loss=0.0643952414393425\n",
      "test_test\n",
      "test mean loss=1161.6170959472656\n",
      "epoch 6694\n",
      "test_train\n",
      "train mean loss=0.06156331238647302\n",
      "test_test\n",
      "test mean loss=1160.6486206054688\n",
      "epoch 6695\n",
      "test_train\n",
      "train mean loss=0.06575969358285268\n",
      "test_test\n",
      "test mean loss=1160.8666687011719\n",
      "epoch 6696\n",
      "test_train\n",
      "train mean loss=32.4488480091095\n",
      "test_test\n",
      "test mean loss=1158.4285888671875\n",
      "epoch 6697\n",
      "test_train\n",
      "train mean loss=0.13204203204562268\n",
      "test_test\n",
      "test mean loss=1159.8136596679688\n",
      "epoch 6698\n",
      "test_train\n",
      "train mean loss=0.07147059310227633\n",
      "test_test\n",
      "test mean loss=1159.2386169433594\n",
      "epoch 6699\n",
      "test_train\n",
      "train mean loss=0.06981350015848875\n",
      "test_test\n",
      "test mean loss=1158.1868896484375\n",
      "epoch 6700\n",
      "test_train\n",
      "train mean loss=0.07290428100774686\n",
      "test_test\n",
      "test mean loss=1158.4366455078125\n",
      "epoch 6701\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.06394888398547967\n",
      "test_test\n",
      "test mean loss=1156.1507263183594\n",
      "epoch 6702\n",
      "test_train\n",
      "train mean loss=0.06404206420605381\n",
      "test_test\n",
      "test mean loss=1157.3553466796875\n",
      "epoch 6703\n",
      "test_train\n",
      "train mean loss=0.05892267792175213\n",
      "test_test\n",
      "test mean loss=1158.0765991210938\n",
      "epoch 6704\n",
      "test_train\n",
      "train mean loss=0.06613172823563218\n",
      "test_test\n",
      "test mean loss=1158.432373046875\n",
      "epoch 6705\n",
      "test_train\n",
      "train mean loss=0.0647314740344882\n",
      "test_test\n",
      "test mean loss=1158.7506408691406\n",
      "epoch 6706\n",
      "test_train\n",
      "train mean loss=0.06800243351608515\n",
      "test_test\n",
      "test mean loss=1158.8446044921875\n",
      "epoch 6707\n",
      "test_train\n",
      "train mean loss=0.06506721333911021\n",
      "test_test\n",
      "test mean loss=1158.1492004394531\n",
      "epoch 6708\n",
      "test_train\n",
      "train mean loss=0.06569160769383113\n",
      "test_test\n",
      "test mean loss=1158.011962890625\n",
      "epoch 6709\n",
      "test_train\n",
      "train mean loss=0.06124611416210731\n",
      "test_test\n",
      "test mean loss=1158.2466430664062\n",
      "epoch 6710\n",
      "test_train\n",
      "train mean loss=0.06523861751581232\n",
      "test_test\n",
      "test mean loss=1157.1910400390625\n",
      "epoch 6711\n",
      "test_train\n",
      "train mean loss=0.060050563886761665\n",
      "test_test\n",
      "test mean loss=1157.3523559570312\n",
      "epoch 6712\n",
      "test_train\n",
      "train mean loss=0.07071203924715519\n",
      "test_test\n",
      "test mean loss=1159.2870178222656\n",
      "epoch 6713\n",
      "test_train\n",
      "train mean loss=0.06509411955873172\n",
      "test_test\n",
      "test mean loss=1158.1746215820312\n",
      "epoch 6714\n",
      "test_train\n",
      "train mean loss=0.06740997203936179\n",
      "test_test\n",
      "test mean loss=1159.16845703125\n",
      "epoch 6715\n",
      "test_train\n",
      "train mean loss=0.07226472565283378\n",
      "test_test\n",
      "test mean loss=1159.6211547851562\n",
      "epoch 6716\n",
      "test_train\n",
      "train mean loss=0.06741936504840851\n",
      "test_test\n",
      "test mean loss=1158.9614868164062\n",
      "epoch 6717\n",
      "test_train\n",
      "train mean loss=0.06587920958797137\n",
      "test_test\n",
      "test mean loss=1159.0521240234375\n",
      "epoch 6718\n",
      "test_train\n",
      "train mean loss=0.06180076114833355\n",
      "test_test\n",
      "test mean loss=1157.1038818359375\n",
      "epoch 6719\n",
      "test_train\n",
      "train mean loss=0.06661540021498998\n",
      "test_test\n",
      "test mean loss=1159.6095581054688\n",
      "epoch 6720\n",
      "test_train\n",
      "train mean loss=0.06714578283329804\n",
      "test_test\n",
      "test mean loss=1159.1614074707031\n",
      "epoch 6721\n",
      "test_train\n",
      "train mean loss=0.06172066585471233\n",
      "test_test\n",
      "test mean loss=1158.8640747070312\n",
      "epoch 6722\n",
      "test_train\n",
      "train mean loss=0.06678448896855116\n",
      "test_test\n",
      "test mean loss=1159.616943359375\n",
      "epoch 6723\n",
      "test_train\n",
      "train mean loss=0.060151004853347935\n",
      "test_test\n",
      "test mean loss=1159.5868530273438\n",
      "epoch 6724\n",
      "test_train\n",
      "train mean loss=0.06293120762954156\n",
      "test_test\n",
      "test mean loss=1158.9928283691406\n",
      "epoch 6725\n",
      "test_train\n",
      "train mean loss=0.0697603365406394\n",
      "test_test\n",
      "test mean loss=1159.4986267089844\n",
      "epoch 6726\n",
      "test_train\n",
      "train mean loss=0.06181952139983574\n",
      "test_test\n",
      "test mean loss=1158.9033813476562\n",
      "epoch 6727\n",
      "test_train\n",
      "train mean loss=0.058398256388803325\n",
      "test_test\n",
      "test mean loss=1158.0969848632812\n",
      "epoch 6728\n",
      "test_train\n",
      "train mean loss=0.05934331441919009\n",
      "test_test\n",
      "test mean loss=1159.0091247558594\n",
      "epoch 6729\n",
      "test_train\n",
      "train mean loss=0.0655357784902056\n",
      "test_test\n",
      "test mean loss=1158.9557495117188\n",
      "epoch 6730\n",
      "test_train\n",
      "train mean loss=0.05837685770044724\n",
      "test_test\n",
      "test mean loss=1158.4836120605469\n",
      "epoch 6731\n",
      "test_train\n",
      "train mean loss=0.06422239759316047\n",
      "test_test\n",
      "test mean loss=1159.3765258789062\n",
      "epoch 6732\n",
      "test_train\n",
      "train mean loss=0.06467003499468167\n",
      "test_test\n",
      "test mean loss=1158.4053955078125\n",
      "epoch 6733\n",
      "test_train\n",
      "train mean loss=0.06402068833510081\n",
      "test_test\n",
      "test mean loss=1157.4417419433594\n",
      "epoch 6734\n",
      "test_train\n",
      "train mean loss=0.06637080231060584\n",
      "test_test\n",
      "test mean loss=1158.7874145507812\n",
      "epoch 6735\n",
      "test_train\n",
      "train mean loss=0.06378846429288387\n",
      "test_test\n",
      "test mean loss=1158.9506225585938\n",
      "epoch 6736\n",
      "test_train\n",
      "train mean loss=0.06525046657770872\n",
      "test_test\n",
      "test mean loss=1159.4484252929688\n",
      "epoch 6737\n",
      "test_train\n",
      "train mean loss=0.06699848206092913\n",
      "test_test\n",
      "test mean loss=1159.4163208007812\n",
      "epoch 6738\n",
      "test_train\n",
      "train mean loss=0.0729150352999568\n",
      "test_test\n",
      "test mean loss=1160.5705261230469\n",
      "epoch 6739\n",
      "test_train\n",
      "train mean loss=0.07071844612558682\n",
      "test_test\n",
      "test mean loss=1159.4810180664062\n",
      "epoch 6740\n",
      "test_train\n",
      "train mean loss=0.0834752107039094\n",
      "test_test\n",
      "test mean loss=1159.3212280273438\n",
      "epoch 6741\n",
      "test_train\n",
      "train mean loss=0.07271893881261349\n",
      "test_test\n",
      "test mean loss=1159.3969116210938\n",
      "epoch 6742\n",
      "test_train\n",
      "train mean loss=0.06298365164548159\n",
      "test_test\n",
      "test mean loss=1156.2617797851562\n",
      "epoch 6743\n",
      "test_train\n",
      "train mean loss=0.06151171416665117\n",
      "test_test\n",
      "test mean loss=1154.4956970214844\n",
      "epoch 6744\n",
      "test_train\n",
      "train mean loss=0.06588082325955232\n",
      "test_test\n",
      "test mean loss=1157.9022216796875\n",
      "epoch 6745\n",
      "test_train\n",
      "train mean loss=0.06053019563357035\n",
      "test_test\n",
      "test mean loss=1157.8417358398438\n",
      "epoch 6746\n",
      "test_train\n",
      "train mean loss=0.058918654918670654\n",
      "test_test\n",
      "test mean loss=1158.60693359375\n",
      "epoch 6747\n",
      "test_train\n",
      "train mean loss=0.06713251583278179\n",
      "test_test\n",
      "test mean loss=1158.9915161132812\n",
      "epoch 6748\n",
      "test_train\n",
      "train mean loss=0.06576005990306537\n",
      "test_test\n",
      "test mean loss=1157.6449584960938\n",
      "epoch 6749\n",
      "test_train\n",
      "train mean loss=0.06204235584785541\n",
      "test_test\n",
      "test mean loss=1158.8187866210938\n",
      "epoch 6750\n",
      "test_train\n",
      "train mean loss=0.0585104973676304\n",
      "test_test\n",
      "test mean loss=1156.1703491210938\n",
      "epoch 6751\n",
      "test_train\n",
      "train mean loss=0.06555626044670741\n",
      "test_test\n",
      "test mean loss=1157.498291015625\n",
      "epoch 6752\n",
      "test_train\n",
      "train mean loss=0.06028436946993073\n",
      "test_test\n",
      "test mean loss=1155.8786315917969\n",
      "epoch 6753\n",
      "test_train\n",
      "train mean loss=0.06523376827438672\n",
      "test_test\n",
      "test mean loss=1158.52587890625\n",
      "epoch 6754\n",
      "test_train\n",
      "train mean loss=0.05799456841001908\n",
      "test_test\n",
      "test mean loss=1158.1485290527344\n",
      "epoch 6755\n",
      "test_train\n",
      "train mean loss=0.06461506833632787\n",
      "test_test\n",
      "test mean loss=1158.6090698242188\n",
      "epoch 6756\n",
      "test_train\n",
      "train mean loss=0.06370227007816236\n",
      "test_test\n",
      "test mean loss=1158.9873046875\n",
      "epoch 6757\n",
      "test_train\n",
      "train mean loss=0.059103834753235183\n",
      "test_test\n",
      "test mean loss=1158.0910339355469\n",
      "epoch 6758\n",
      "test_train\n",
      "train mean loss=0.06622361112385988\n",
      "test_test\n",
      "test mean loss=1158.4146728515625\n",
      "epoch 6759\n",
      "test_train\n",
      "train mean loss=0.0638148362437884\n",
      "test_test\n",
      "test mean loss=1158.4005737304688\n",
      "epoch 6760\n",
      "test_train\n",
      "train mean loss=0.062429013662040234\n",
      "test_test\n",
      "test mean loss=1157.892822265625\n",
      "epoch 6761\n",
      "test_train\n",
      "train mean loss=0.06716475480546553\n",
      "test_test\n",
      "test mean loss=1157.8763427734375\n",
      "epoch 6762\n",
      "test_train\n",
      "train mean loss=0.06866633053869009\n",
      "test_test\n",
      "test mean loss=1159.2744750976562\n",
      "epoch 6763\n",
      "test_train\n",
      "train mean loss=0.06266910365472238\n",
      "test_test\n",
      "test mean loss=1159.9362182617188\n",
      "epoch 6764\n",
      "test_train\n",
      "train mean loss=0.05813480463499824\n",
      "test_test\n",
      "test mean loss=1159.0059814453125\n",
      "epoch 6765\n",
      "test_train\n",
      "train mean loss=0.06921014593293269\n",
      "test_test\n",
      "test mean loss=1159.1802368164062\n",
      "epoch 6766\n",
      "test_train\n",
      "train mean loss=0.06811201386153698\n",
      "test_test\n",
      "test mean loss=1158.1376953125\n",
      "epoch 6767\n",
      "test_train\n",
      "train mean loss=0.06204711149136225\n",
      "test_test\n",
      "test mean loss=1158.0615234375\n",
      "epoch 6768\n",
      "test_train\n",
      "train mean loss=0.060105063331623874\n",
      "test_test\n",
      "test mean loss=1158.3529052734375\n",
      "epoch 6769\n",
      "test_train\n",
      "train mean loss=0.06908471354593833\n",
      "test_test\n",
      "test mean loss=1159.0007934570312\n",
      "epoch 6770\n",
      "test_train\n",
      "train mean loss=0.062154756703724466\n",
      "test_test\n",
      "test mean loss=1158.1632080078125\n",
      "epoch 6771\n",
      "test_train\n",
      "train mean loss=0.05935647043709954\n",
      "test_test\n",
      "test mean loss=1158.1886901855469\n",
      "epoch 6772\n",
      "test_train\n",
      "train mean loss=0.060628519083062805\n",
      "test_test\n",
      "test mean loss=1158.3383178710938\n",
      "epoch 6773\n",
      "test_train\n",
      "train mean loss=0.06054638729741176\n",
      "test_test\n",
      "test mean loss=1159.0964965820312\n",
      "epoch 6774\n",
      "test_train\n",
      "train mean loss=0.06877496807525556\n",
      "test_test\n",
      "test mean loss=1160.7097778320312\n",
      "epoch 6775\n",
      "test_train\n",
      "train mean loss=0.061395122980078064\n",
      "test_test\n",
      "test mean loss=1159.7015991210938\n",
      "epoch 6776\n",
      "test_train\n",
      "train mean loss=0.06781574711203575\n",
      "test_test\n",
      "test mean loss=1160.2073974609375\n",
      "epoch 6777\n",
      "test_train\n",
      "train mean loss=0.06022152537479997\n",
      "test_test\n",
      "test mean loss=1159.9927978515625\n",
      "epoch 6778\n",
      "test_train\n",
      "train mean loss=0.06320235443611939\n",
      "test_test\n",
      "test mean loss=1159.9157104492188\n",
      "epoch 6779\n",
      "test_train\n",
      "train mean loss=0.06091685717304548\n",
      "test_test\n",
      "test mean loss=1160.0623779296875\n",
      "epoch 6780\n",
      "test_train\n",
      "train mean loss=0.06456389091908932\n",
      "test_test\n",
      "test mean loss=1160.0824584960938\n",
      "epoch 6781\n",
      "test_train\n",
      "train mean loss=0.07234170598288377\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1159.4407348632812\n",
      "epoch 6782\n",
      "test_train\n",
      "train mean loss=0.07212518124530713\n",
      "test_test\n",
      "test mean loss=1160.7398071289062\n",
      "epoch 6783\n",
      "test_train\n",
      "train mean loss=0.06918260439609487\n",
      "test_test\n",
      "test mean loss=1160.8017578125\n",
      "epoch 6784\n",
      "test_train\n",
      "train mean loss=0.06294810523589452\n",
      "test_test\n",
      "test mean loss=1160.3248291015625\n",
      "epoch 6785\n",
      "test_train\n",
      "train mean loss=0.06645897434403499\n",
      "test_test\n",
      "test mean loss=1160.6201477050781\n",
      "epoch 6786\n",
      "test_train\n",
      "train mean loss=0.07484761190911134\n",
      "test_test\n",
      "test mean loss=1160.1468505859375\n",
      "epoch 6787\n",
      "test_train\n",
      "train mean loss=0.06437155821671088\n",
      "test_test\n",
      "test mean loss=1159.7897644042969\n",
      "epoch 6788\n",
      "test_train\n",
      "train mean loss=0.06293180569385488\n",
      "test_test\n",
      "test mean loss=1158.2617797851562\n",
      "epoch 6789\n",
      "test_train\n",
      "train mean loss=0.06201691056291262\n",
      "test_test\n",
      "test mean loss=1159.6498413085938\n",
      "epoch 6790\n",
      "test_train\n",
      "train mean loss=0.06842625979334116\n",
      "test_test\n",
      "test mean loss=1160.4896850585938\n",
      "epoch 6791\n",
      "test_train\n",
      "train mean loss=0.05772083935638269\n",
      "test_test\n",
      "test mean loss=1159.5452270507812\n",
      "epoch 6792\n",
      "test_train\n",
      "train mean loss=0.0653195814229548\n",
      "test_test\n",
      "test mean loss=1159.74853515625\n",
      "epoch 6793\n",
      "test_train\n",
      "train mean loss=0.06238922600944837\n",
      "test_test\n",
      "test mean loss=1159.84326171875\n",
      "epoch 6794\n",
      "test_train\n",
      "train mean loss=0.06377683424701293\n",
      "test_test\n",
      "test mean loss=1158.7518310546875\n",
      "epoch 6795\n",
      "test_train\n",
      "train mean loss=0.06769251233587663\n",
      "test_test\n",
      "test mean loss=1160.8949584960938\n",
      "epoch 6796\n",
      "test_train\n",
      "train mean loss=0.06550689476231734\n",
      "test_test\n",
      "test mean loss=1160.025146484375\n",
      "epoch 6797\n",
      "test_train\n",
      "train mean loss=0.06932059396058321\n",
      "test_test\n",
      "test mean loss=1159.6546325683594\n",
      "epoch 6798\n",
      "test_train\n",
      "train mean loss=0.06870503040651481\n",
      "test_test\n",
      "test mean loss=1160.7646179199219\n",
      "epoch 6799\n",
      "test_train\n",
      "train mean loss=0.05689963698387146\n",
      "test_test\n",
      "test mean loss=1159.2806396484375\n",
      "epoch 6800\n",
      "test_train\n",
      "train mean loss=0.09236893678704898\n",
      "test_test\n",
      "test mean loss=1161.19091796875\n",
      "epoch 6801\n",
      "test_train\n",
      "train mean loss=0.06895342220862706\n",
      "test_test\n",
      "test mean loss=1160.6998901367188\n",
      "epoch 6802\n",
      "test_train\n",
      "train mean loss=0.06096230509380499\n",
      "test_test\n",
      "test mean loss=1159.01513671875\n",
      "epoch 6803\n",
      "test_train\n",
      "train mean loss=0.06433858132610719\n",
      "test_test\n",
      "test mean loss=1159.9768676757812\n",
      "epoch 6804\n",
      "test_train\n",
      "train mean loss=0.061221457862605654\n",
      "test_test\n",
      "test mean loss=1160.4671630859375\n",
      "epoch 6805\n",
      "test_train\n",
      "train mean loss=0.06536454303810994\n",
      "test_test\n",
      "test mean loss=1159.9441833496094\n",
      "epoch 6806\n",
      "test_train\n",
      "train mean loss=0.05920385103672743\n",
      "test_test\n",
      "test mean loss=1159.5144653320312\n",
      "epoch 6807\n",
      "test_train\n",
      "train mean loss=0.06325120323648055\n",
      "test_test\n",
      "test mean loss=1158.0703735351562\n",
      "epoch 6808\n",
      "test_train\n",
      "train mean loss=0.06550962384790182\n",
      "test_test\n",
      "test mean loss=1159.6007690429688\n",
      "epoch 6809\n",
      "test_train\n",
      "train mean loss=0.05913064101090034\n",
      "test_test\n",
      "test mean loss=1158.3260498046875\n",
      "epoch 6810\n",
      "test_train\n",
      "train mean loss=0.05970431367556254\n",
      "test_test\n",
      "test mean loss=1157.5186767578125\n",
      "epoch 6811\n",
      "test_train\n",
      "train mean loss=0.0601639609473447\n",
      "test_test\n",
      "test mean loss=1157.7578125\n",
      "epoch 6812\n",
      "test_train\n",
      "train mean loss=0.06209532109399637\n",
      "test_test\n",
      "test mean loss=1158.5459594726562\n",
      "epoch 6813\n",
      "test_train\n",
      "train mean loss=0.05879374531408151\n",
      "test_test\n",
      "test mean loss=1157.2068786621094\n",
      "epoch 6814\n",
      "test_train\n",
      "train mean loss=0.06056485200921694\n",
      "test_test\n",
      "test mean loss=1158.8659057617188\n",
      "epoch 6815\n",
      "test_train\n",
      "train mean loss=0.05532213890304168\n",
      "test_test\n",
      "test mean loss=1159.32861328125\n",
      "epoch 6816\n",
      "test_train\n",
      "train mean loss=0.0626562728236119\n",
      "test_test\n",
      "test mean loss=1158.7671203613281\n",
      "epoch 6817\n",
      "test_train\n",
      "train mean loss=0.0598093889032801\n",
      "test_test\n",
      "test mean loss=1157.9317626953125\n",
      "epoch 6818\n",
      "test_train\n",
      "train mean loss=0.06824750204881032\n",
      "test_test\n",
      "test mean loss=1159.2216186523438\n",
      "epoch 6819\n",
      "test_train\n",
      "train mean loss=0.06534866336733103\n",
      "test_test\n",
      "test mean loss=1157.8117065429688\n",
      "epoch 6820\n",
      "test_train\n",
      "train mean loss=0.054247182328253984\n",
      "test_test\n",
      "test mean loss=1158.1396484375\n",
      "epoch 6821\n",
      "test_train\n",
      "train mean loss=0.0643791143471996\n",
      "test_test\n",
      "test mean loss=1159.1300354003906\n",
      "epoch 6822\n",
      "test_train\n",
      "train mean loss=0.05993338053425153\n",
      "test_test\n",
      "test mean loss=1158.4858093261719\n",
      "epoch 6823\n",
      "test_train\n",
      "train mean loss=0.05951157367477814\n",
      "test_test\n",
      "test mean loss=1157.9137878417969\n",
      "epoch 6824\n",
      "test_train\n",
      "train mean loss=0.060595897026360035\n",
      "test_test\n",
      "test mean loss=1159.23046875\n",
      "epoch 6825\n",
      "test_train\n",
      "train mean loss=0.05671556325008472\n",
      "test_test\n",
      "test mean loss=1159.2587585449219\n",
      "epoch 6826\n",
      "test_train\n",
      "train mean loss=0.06494513340294361\n",
      "test_test\n",
      "test mean loss=1158.3353881835938\n",
      "epoch 6827\n",
      "test_train\n",
      "train mean loss=0.06737957832713921\n",
      "test_test\n",
      "test mean loss=1159.4148254394531\n",
      "epoch 6828\n",
      "test_train\n",
      "train mean loss=0.06774901365861297\n",
      "test_test\n",
      "test mean loss=1160.376708984375\n",
      "epoch 6829\n",
      "test_train\n",
      "train mean loss=0.08286079640189807\n",
      "test_test\n",
      "test mean loss=1159.6507568359375\n",
      "epoch 6830\n",
      "test_train\n",
      "train mean loss=0.06711102680613597\n",
      "test_test\n",
      "test mean loss=1159.5589294433594\n",
      "epoch 6831\n",
      "test_train\n",
      "train mean loss=0.06287507154047489\n",
      "test_test\n",
      "test mean loss=1159.943359375\n",
      "epoch 6832\n",
      "test_train\n",
      "train mean loss=0.06739802875866492\n",
      "test_test\n",
      "test mean loss=1159.9908447265625\n",
      "epoch 6833\n",
      "test_train\n",
      "train mean loss=0.060882206074893475\n",
      "test_test\n",
      "test mean loss=1159.441162109375\n",
      "epoch 6834\n",
      "test_train\n",
      "train mean loss=0.06067419874792298\n",
      "test_test\n",
      "test mean loss=1160.6716918945312\n",
      "epoch 6835\n",
      "test_train\n",
      "train mean loss=0.06405202361444633\n",
      "test_test\n",
      "test mean loss=1159.0211791992188\n",
      "epoch 6836\n",
      "test_train\n",
      "train mean loss=0.0595718827098608\n",
      "test_test\n",
      "test mean loss=1158.8742980957031\n",
      "epoch 6837\n",
      "test_train\n",
      "train mean loss=0.06192104114840428\n",
      "test_test\n",
      "test mean loss=1160.0914001464844\n",
      "epoch 6838\n",
      "test_train\n",
      "train mean loss=0.060131536796689034\n",
      "test_test\n",
      "test mean loss=1158.1860961914062\n",
      "epoch 6839\n",
      "test_train\n",
      "train mean loss=0.06399604926506679\n",
      "test_test\n",
      "test mean loss=1159.3049011230469\n",
      "epoch 6840\n",
      "test_train\n",
      "train mean loss=0.05586523034920295\n",
      "test_test\n",
      "test mean loss=1158.2042236328125\n",
      "epoch 6841\n",
      "test_train\n",
      "train mean loss=0.06653829974432786\n",
      "test_test\n",
      "test mean loss=1159.7434692382812\n",
      "epoch 6842\n",
      "test_train\n",
      "train mean loss=0.0590387632449468\n",
      "test_test\n",
      "test mean loss=1159.3074340820312\n",
      "epoch 6843\n",
      "test_train\n",
      "train mean loss=0.056354990073790155\n",
      "test_test\n",
      "test mean loss=1158.020751953125\n",
      "epoch 6844\n",
      "test_train\n",
      "train mean loss=0.057734684397776924\n",
      "test_test\n",
      "test mean loss=1159.7237548828125\n",
      "epoch 6845\n",
      "test_train\n",
      "train mean loss=0.060090187626580395\n",
      "test_test\n",
      "test mean loss=1159.7941284179688\n",
      "epoch 6846\n",
      "test_train\n",
      "train mean loss=0.06021915997068087\n",
      "test_test\n",
      "test mean loss=1159.4922485351562\n",
      "epoch 6847\n",
      "test_train\n",
      "train mean loss=0.06308472001304229\n",
      "test_test\n",
      "test mean loss=1159.6641845703125\n",
      "epoch 6848\n",
      "test_train\n",
      "train mean loss=0.06316686111191909\n",
      "test_test\n",
      "test mean loss=1160.7453918457031\n",
      "epoch 6849\n",
      "test_train\n",
      "train mean loss=0.06476910101870696\n",
      "test_test\n",
      "test mean loss=1160.2374267578125\n",
      "epoch 6850\n",
      "test_train\n",
      "train mean loss=0.05836281677087148\n",
      "test_test\n",
      "test mean loss=1159.2775268554688\n",
      "epoch 6851\n",
      "test_train\n",
      "train mean loss=0.059974453101555504\n",
      "test_test\n",
      "test mean loss=1158.67626953125\n",
      "epoch 6852\n",
      "test_train\n",
      "train mean loss=0.0677609044748048\n",
      "test_test\n",
      "test mean loss=1159.2911987304688\n",
      "epoch 6853\n",
      "test_train\n",
      "train mean loss=0.06265466039379437\n",
      "test_test\n",
      "test mean loss=1159.8531188964844\n",
      "epoch 6854\n",
      "test_train\n",
      "train mean loss=0.054581680024663605\n",
      "test_test\n",
      "test mean loss=1159.2245483398438\n",
      "epoch 6855\n",
      "test_train\n",
      "train mean loss=0.0644051091124614\n",
      "test_test\n",
      "test mean loss=1159.6744995117188\n",
      "epoch 6856\n",
      "test_train\n",
      "train mean loss=0.05860480231543382\n",
      "test_test\n",
      "test mean loss=1159.2562866210938\n",
      "epoch 6857\n",
      "test_train\n",
      "train mean loss=0.05737154340992371\n",
      "test_test\n",
      "test mean loss=1158.6292114257812\n",
      "epoch 6858\n",
      "test_train\n",
      "train mean loss=0.06051423167809844\n",
      "test_test\n",
      "test mean loss=1159.1809692382812\n",
      "epoch 6859\n",
      "test_train\n",
      "train mean loss=0.057472199822465576\n",
      "test_test\n",
      "test mean loss=1159.0612487792969\n",
      "epoch 6860\n",
      "test_train\n",
      "train mean loss=0.07061947602778673\n",
      "test_test\n",
      "test mean loss=1160.4046325683594\n",
      "epoch 6861\n",
      "test_train\n",
      "train mean loss=0.053187571465969086\n",
      "test_test\n",
      "test mean loss=1159.2886352539062\n",
      "epoch 6862\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.058791275757054486\n",
      "test_test\n",
      "test mean loss=1159.2919311523438\n",
      "epoch 6863\n",
      "test_train\n",
      "train mean loss=0.0577405725295345\n",
      "test_test\n",
      "test mean loss=1157.72119140625\n",
      "epoch 6864\n",
      "test_train\n",
      "train mean loss=0.06128035175303618\n",
      "test_test\n",
      "test mean loss=1159.3768920898438\n",
      "epoch 6865\n",
      "test_train\n",
      "train mean loss=0.06402238675703605\n",
      "test_test\n",
      "test mean loss=1158.5820922851562\n",
      "epoch 6866\n",
      "test_train\n",
      "train mean loss=0.05675002901504437\n",
      "test_test\n",
      "test mean loss=1158.6904907226562\n",
      "epoch 6867\n",
      "test_train\n",
      "train mean loss=0.06234313532089194\n",
      "test_test\n",
      "test mean loss=1159.1758728027344\n",
      "epoch 6868\n",
      "test_train\n",
      "train mean loss=0.05809834444274505\n",
      "test_test\n",
      "test mean loss=1158.6829833984375\n",
      "epoch 6869\n",
      "test_train\n",
      "train mean loss=0.059095211792737246\n",
      "test_test\n",
      "test mean loss=1158.3155212402344\n",
      "epoch 6870\n",
      "test_train\n",
      "train mean loss=0.05577672210832437\n",
      "test_test\n",
      "test mean loss=1159.3588256835938\n",
      "epoch 6871\n",
      "test_train\n",
      "train mean loss=0.058896792431672416\n",
      "test_test\n",
      "test mean loss=1159.0989379882812\n",
      "epoch 6872\n",
      "test_train\n",
      "train mean loss=0.061787545991440616\n",
      "test_test\n",
      "test mean loss=1159.230224609375\n",
      "epoch 6873\n",
      "test_train\n",
      "train mean loss=0.06046849271903435\n",
      "test_test\n",
      "test mean loss=1159.3915405273438\n",
      "epoch 6874\n",
      "test_train\n",
      "train mean loss=0.07390141735474269\n",
      "test_test\n",
      "test mean loss=1159.9613647460938\n",
      "epoch 6875\n",
      "test_train\n",
      "train mean loss=0.061264870377878346\n",
      "test_test\n",
      "test mean loss=1158.77978515625\n",
      "epoch 6876\n",
      "test_train\n",
      "train mean loss=0.060059406949828066\n",
      "test_test\n",
      "test mean loss=1158.7515258789062\n",
      "epoch 6877\n",
      "test_train\n",
      "train mean loss=0.06119357359906038\n",
      "test_test\n",
      "test mean loss=1159.023681640625\n",
      "epoch 6878\n",
      "test_train\n",
      "train mean loss=0.06704314891248941\n",
      "test_test\n",
      "test mean loss=1159.5770874023438\n",
      "epoch 6879\n",
      "test_train\n",
      "train mean loss=0.09838088663915794\n",
      "test_test\n",
      "test mean loss=1161.9791564941406\n",
      "epoch 6880\n",
      "test_train\n",
      "train mean loss=0.06468500165889661\n",
      "test_test\n",
      "test mean loss=1159.8123779296875\n",
      "epoch 6881\n",
      "test_train\n",
      "train mean loss=0.06133770911643902\n",
      "test_test\n",
      "test mean loss=1159.3863830566406\n",
      "epoch 6882\n",
      "test_train\n",
      "train mean loss=0.06402789459874232\n",
      "test_test\n",
      "test mean loss=1159.895263671875\n",
      "epoch 6883\n",
      "test_train\n",
      "train mean loss=0.06522698700428009\n",
      "test_test\n",
      "test mean loss=1159.585693359375\n",
      "epoch 6884\n",
      "test_train\n",
      "train mean loss=0.07044962048530579\n",
      "test_test\n",
      "test mean loss=1154.2503662109375\n",
      "epoch 6885\n",
      "test_train\n",
      "train mean loss=0.06639222335070372\n",
      "test_test\n",
      "test mean loss=1160.632568359375\n",
      "epoch 6886\n",
      "test_train\n",
      "train mean loss=0.05878776125609875\n",
      "test_test\n",
      "test mean loss=1160.2598266601562\n",
      "epoch 6887\n",
      "test_train\n",
      "train mean loss=0.06573759174595277\n",
      "test_test\n",
      "test mean loss=1160.7841186523438\n",
      "epoch 6888\n",
      "test_train\n",
      "train mean loss=0.05951611946026484\n",
      "test_test\n",
      "test mean loss=1158.964599609375\n",
      "epoch 6889\n",
      "test_train\n",
      "train mean loss=0.0636575948446989\n",
      "test_test\n",
      "test mean loss=1159.9437866210938\n",
      "epoch 6890\n",
      "test_train\n",
      "train mean loss=0.06635516043752432\n",
      "test_test\n",
      "test mean loss=1159.9915161132812\n",
      "epoch 6891\n",
      "test_train\n",
      "train mean loss=0.06468720889339845\n",
      "test_test\n",
      "test mean loss=1160.2415771484375\n",
      "epoch 6892\n",
      "test_train\n",
      "train mean loss=0.06613955336312453\n",
      "test_test\n",
      "test mean loss=1160.4459838867188\n",
      "epoch 6893\n",
      "test_train\n",
      "train mean loss=0.06019279733300209\n",
      "test_test\n",
      "test mean loss=1160.0868835449219\n",
      "epoch 6894\n",
      "test_train\n",
      "train mean loss=0.06060936053593954\n",
      "test_test\n",
      "test mean loss=1160.3479614257812\n",
      "epoch 6895\n",
      "test_train\n",
      "train mean loss=0.06313685141503811\n",
      "test_test\n",
      "test mean loss=1157.836669921875\n",
      "epoch 6896\n",
      "test_train\n",
      "train mean loss=0.06409095817555983\n",
      "test_test\n",
      "test mean loss=1159.422607421875\n",
      "epoch 6897\n",
      "test_train\n",
      "train mean loss=0.07002479940031965\n",
      "test_test\n",
      "test mean loss=1159.520263671875\n",
      "epoch 6898\n",
      "test_train\n",
      "train mean loss=0.059788369884093605\n",
      "test_test\n",
      "test mean loss=1158.8865661621094\n",
      "epoch 6899\n",
      "test_train\n",
      "train mean loss=0.06417242561777432\n",
      "test_test\n",
      "test mean loss=1160.2695922851562\n",
      "epoch 6900\n",
      "test_train\n",
      "train mean loss=0.06050748315950235\n",
      "test_test\n",
      "test mean loss=1160.2584838867188\n",
      "epoch 6901\n",
      "test_train\n",
      "train mean loss=0.06561459259440501\n",
      "test_test\n",
      "test mean loss=1159.8104248046875\n",
      "epoch 6902\n",
      "test_train\n",
      "train mean loss=0.07015366076181333\n",
      "test_test\n",
      "test mean loss=1160.2019958496094\n",
      "epoch 6903\n",
      "test_train\n",
      "train mean loss=0.06901588353017966\n",
      "test_test\n",
      "test mean loss=1159.3814392089844\n",
      "epoch 6904\n",
      "test_train\n",
      "train mean loss=0.06111427334447702\n",
      "test_test\n",
      "test mean loss=1158.8371276855469\n",
      "epoch 6905\n",
      "test_train\n",
      "train mean loss=0.06334890238940716\n",
      "test_test\n",
      "test mean loss=1159.6744384765625\n",
      "epoch 6906\n",
      "test_train\n",
      "train mean loss=0.06456987373530865\n",
      "test_test\n",
      "test mean loss=1159.3931884765625\n",
      "epoch 6907\n",
      "test_train\n",
      "train mean loss=0.0595097200324138\n",
      "test_test\n",
      "test mean loss=1159.4747314453125\n",
      "epoch 6908\n",
      "test_train\n",
      "train mean loss=0.05981386359781027\n",
      "test_test\n",
      "test mean loss=1159.9788208007812\n",
      "epoch 6909\n",
      "test_train\n",
      "train mean loss=0.05760154811044534\n",
      "test_test\n",
      "test mean loss=1159.3189697265625\n",
      "epoch 6910\n",
      "test_train\n",
      "train mean loss=0.06014243699610233\n",
      "test_test\n",
      "test mean loss=1159.6358032226562\n",
      "epoch 6911\n",
      "test_train\n",
      "train mean loss=0.05846120944867531\n",
      "test_test\n",
      "test mean loss=1160.2341918945312\n",
      "epoch 6912\n",
      "test_train\n",
      "train mean loss=0.05616648169234395\n",
      "test_test\n",
      "test mean loss=1159.7132568359375\n",
      "epoch 6913\n",
      "test_train\n",
      "train mean loss=0.062319127221902214\n",
      "test_test\n",
      "test mean loss=1160.1942749023438\n",
      "epoch 6914\n",
      "test_train\n",
      "train mean loss=0.0611005158474048\n",
      "test_test\n",
      "test mean loss=1160.7439575195312\n",
      "epoch 6915\n",
      "test_train\n",
      "train mean loss=0.05566913324097792\n",
      "test_test\n",
      "test mean loss=1160.2764892578125\n",
      "epoch 6916\n",
      "test_train\n",
      "train mean loss=0.062113394029438496\n",
      "test_test\n",
      "test mean loss=1160.3214416503906\n",
      "epoch 6917\n",
      "test_train\n",
      "train mean loss=0.06015645184864601\n",
      "test_test\n",
      "test mean loss=1158.8927001953125\n",
      "epoch 6918\n",
      "test_train\n",
      "train mean loss=0.057960398184756436\n",
      "test_test\n",
      "test mean loss=1160.4812927246094\n",
      "epoch 6919\n",
      "test_train\n",
      "train mean loss=0.05669404255847136\n",
      "test_test\n",
      "test mean loss=1160.0509643554688\n",
      "epoch 6920\n",
      "test_train\n",
      "train mean loss=0.05667923887570699\n",
      "test_test\n",
      "test mean loss=1159.7979736328125\n",
      "epoch 6921\n",
      "test_train\n",
      "train mean loss=0.05754523569097122\n",
      "test_test\n",
      "test mean loss=1158.7943115234375\n",
      "epoch 6922\n",
      "test_train\n",
      "train mean loss=0.05802372936159372\n",
      "test_test\n",
      "test mean loss=1160.1429138183594\n",
      "epoch 6923\n",
      "test_train\n",
      "train mean loss=0.06505479911963145\n",
      "test_test\n",
      "test mean loss=1159.1782836914062\n",
      "epoch 6924\n",
      "test_train\n",
      "train mean loss=0.07560463560124238\n",
      "test_test\n",
      "test mean loss=1159.9278259277344\n",
      "epoch 6925\n",
      "test_train\n",
      "train mean loss=0.06579144702603419\n",
      "test_test\n",
      "test mean loss=1161.23974609375\n",
      "epoch 6926\n",
      "test_train\n",
      "train mean loss=0.07173301341633002\n",
      "test_test\n",
      "test mean loss=1159.5018920898438\n",
      "epoch 6927\n",
      "test_train\n",
      "train mean loss=0.05821715450535218\n",
      "test_test\n",
      "test mean loss=1159.4794311523438\n",
      "epoch 6928\n",
      "test_train\n",
      "train mean loss=0.05707798432558775\n",
      "test_test\n",
      "test mean loss=1160.1006469726562\n",
      "epoch 6929\n",
      "test_train\n",
      "train mean loss=0.05372390476986766\n",
      "test_test\n",
      "test mean loss=1159.3615417480469\n",
      "epoch 6930\n",
      "test_train\n",
      "train mean loss=0.05519632436335087\n",
      "test_test\n",
      "test mean loss=1160.3306579589844\n",
      "epoch 6931\n",
      "test_train\n",
      "train mean loss=0.06292529745648305\n",
      "test_test\n",
      "test mean loss=1160.5182189941406\n",
      "epoch 6932\n",
      "test_train\n",
      "train mean loss=0.06363501927504937\n",
      "test_test\n",
      "test mean loss=1161.1095581054688\n",
      "epoch 6933\n",
      "test_train\n",
      "train mean loss=0.06114846871544918\n",
      "test_test\n",
      "test mean loss=1158.7328491210938\n",
      "epoch 6934\n",
      "test_train\n",
      "train mean loss=0.057535248498121895\n",
      "test_test\n",
      "test mean loss=1160.35693359375\n",
      "epoch 6935\n",
      "test_train\n",
      "train mean loss=0.055335097635785736\n",
      "test_test\n",
      "test mean loss=1160.05078125\n",
      "epoch 6936\n",
      "test_train\n",
      "train mean loss=0.08926266059279442\n",
      "test_test\n",
      "test mean loss=1162.0705261230469\n",
      "epoch 6937\n",
      "test_train\n",
      "train mean loss=0.08527245869239171\n",
      "test_test\n",
      "test mean loss=1160.6630859375\n",
      "epoch 6938\n",
      "test_train\n",
      "train mean loss=0.06436085856209199\n",
      "test_test\n",
      "test mean loss=1160.768310546875\n",
      "epoch 6939\n",
      "test_train\n",
      "train mean loss=0.06470873641471069\n",
      "test_test\n",
      "test mean loss=1161.001708984375\n",
      "epoch 6940\n",
      "test_train\n",
      "train mean loss=0.08281512713680665\n",
      "test_test\n",
      "test mean loss=1163.8225708007812\n",
      "epoch 6941\n",
      "test_train\n",
      "train mean loss=0.06115581685056289\n",
      "test_test\n",
      "test mean loss=1161.5466918945312\n",
      "epoch 6942\n",
      "test_train\n",
      "train mean loss=0.06258324099083741\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1161.6292419433594\n",
      "epoch 6943\n",
      "test_train\n",
      "train mean loss=0.060252838768064976\n",
      "test_test\n",
      "test mean loss=1161.3273620605469\n",
      "epoch 6944\n",
      "test_train\n",
      "train mean loss=0.06703828399380048\n",
      "test_test\n",
      "test mean loss=1159.9298400878906\n",
      "epoch 6945\n",
      "test_train\n",
      "train mean loss=0.060427444676558174\n",
      "test_test\n",
      "test mean loss=1160.3756713867188\n",
      "epoch 6946\n",
      "test_train\n",
      "train mean loss=0.06474003164718549\n",
      "test_test\n",
      "test mean loss=1160.8997802734375\n",
      "epoch 6947\n",
      "test_train\n",
      "train mean loss=0.06188814279933771\n",
      "test_test\n",
      "test mean loss=1161.8788146972656\n",
      "epoch 6948\n",
      "test_train\n",
      "train mean loss=0.06093079627801975\n",
      "test_test\n",
      "test mean loss=1161.2349853515625\n",
      "epoch 6949\n",
      "test_train\n",
      "train mean loss=0.05224607698619366\n",
      "test_test\n",
      "test mean loss=1159.4353942871094\n",
      "epoch 6950\n",
      "test_train\n",
      "train mean loss=0.05606420415764054\n",
      "test_test\n",
      "test mean loss=1160.1639099121094\n",
      "epoch 6951\n",
      "test_train\n",
      "train mean loss=0.059953981544822454\n",
      "test_test\n",
      "test mean loss=1159.736083984375\n",
      "epoch 6952\n",
      "test_train\n",
      "train mean loss=0.060645585569242634\n",
      "test_test\n",
      "test mean loss=1160.7524108886719\n",
      "epoch 6953\n",
      "test_train\n",
      "train mean loss=0.06098512870570024\n",
      "test_test\n",
      "test mean loss=1158.9384765625\n",
      "epoch 6954\n",
      "test_train\n",
      "train mean loss=0.060010155042012535\n",
      "test_test\n",
      "test mean loss=1158.7081298828125\n",
      "epoch 6955\n",
      "test_train\n",
      "train mean loss=0.05943220853805542\n",
      "test_test\n",
      "test mean loss=1160.4404602050781\n",
      "epoch 6956\n",
      "test_train\n",
      "train mean loss=0.06270382677515347\n",
      "test_test\n",
      "test mean loss=1160.959228515625\n",
      "epoch 6957\n",
      "test_train\n",
      "train mean loss=0.060677675219873585\n",
      "test_test\n",
      "test mean loss=1159.7510375976562\n",
      "epoch 6958\n",
      "test_train\n",
      "train mean loss=0.06507804555197556\n",
      "test_test\n",
      "test mean loss=1161.4120483398438\n",
      "epoch 6959\n",
      "test_train\n",
      "train mean loss=0.0636096481854717\n",
      "test_test\n",
      "test mean loss=1161.4224243164062\n",
      "epoch 6960\n",
      "test_train\n",
      "train mean loss=0.06165946274995804\n",
      "test_test\n",
      "test mean loss=1161.043701171875\n",
      "epoch 6961\n",
      "test_train\n",
      "train mean loss=0.05766790841395656\n",
      "test_test\n",
      "test mean loss=1159.9490051269531\n",
      "epoch 6962\n",
      "test_train\n",
      "train mean loss=0.06618980023389061\n",
      "test_test\n",
      "test mean loss=1160.4041748046875\n",
      "epoch 6963\n",
      "test_train\n",
      "train mean loss=0.07115911785513163\n",
      "test_test\n",
      "test mean loss=1162.0088500976562\n",
      "epoch 6964\n",
      "test_train\n",
      "train mean loss=0.05828438699245453\n",
      "test_test\n",
      "test mean loss=1159.5010375976562\n",
      "epoch 6965\n",
      "test_train\n",
      "train mean loss=0.0591401569545269\n",
      "test_test\n",
      "test mean loss=1158.946044921875\n",
      "epoch 6966\n",
      "test_train\n",
      "train mean loss=0.06257715976486604\n",
      "test_test\n",
      "test mean loss=1160.2643432617188\n",
      "epoch 6967\n",
      "test_train\n",
      "train mean loss=0.060913612600415945\n",
      "test_test\n",
      "test mean loss=1160.1121826171875\n",
      "epoch 6968\n",
      "test_train\n",
      "train mean loss=0.058455277855197586\n",
      "test_test\n",
      "test mean loss=1157.572021484375\n",
      "epoch 6969\n",
      "test_train\n",
      "train mean loss=0.056702151584128536\n",
      "test_test\n",
      "test mean loss=1159.3387451171875\n",
      "epoch 6970\n",
      "test_train\n",
      "train mean loss=0.060547212759653725\n",
      "test_test\n",
      "test mean loss=1160.7751159667969\n",
      "epoch 6971\n",
      "test_train\n",
      "train mean loss=0.058584283106029034\n",
      "test_test\n",
      "test mean loss=1160.0716552734375\n",
      "epoch 6972\n",
      "test_train\n",
      "train mean loss=0.06072651998450359\n",
      "test_test\n",
      "test mean loss=1159.6290893554688\n",
      "epoch 6973\n",
      "test_train\n",
      "train mean loss=0.06418246465424697\n",
      "test_test\n",
      "test mean loss=1159.2753295898438\n",
      "epoch 6974\n",
      "test_train\n",
      "train mean loss=0.061449164524674416\n",
      "test_test\n",
      "test mean loss=1159.0852661132812\n",
      "epoch 6975\n",
      "test_train\n",
      "train mean loss=0.07240769453346729\n",
      "test_test\n",
      "test mean loss=1159.4409790039062\n",
      "epoch 6976\n",
      "test_train\n",
      "train mean loss=0.06532453155765931\n",
      "test_test\n",
      "test mean loss=1160.3053588867188\n",
      "epoch 6977\n",
      "test_train\n",
      "train mean loss=0.06605331754932801\n",
      "test_test\n",
      "test mean loss=1158.9179077148438\n",
      "epoch 6978\n",
      "test_train\n",
      "train mean loss=0.0657991599291563\n",
      "test_test\n",
      "test mean loss=1160.3232727050781\n",
      "epoch 6979\n",
      "test_train\n",
      "train mean loss=0.0629661629597346\n",
      "test_test\n",
      "test mean loss=1159.993408203125\n",
      "epoch 6980\n",
      "test_train\n",
      "train mean loss=0.06190933659672737\n",
      "test_test\n",
      "test mean loss=1160.0549926757812\n",
      "epoch 6981\n",
      "test_train\n",
      "train mean loss=0.055533053974310555\n",
      "test_test\n",
      "test mean loss=1158.2868041992188\n",
      "epoch 6982\n",
      "test_train\n",
      "train mean loss=0.06127112591639161\n",
      "test_test\n",
      "test mean loss=1159.2589111328125\n",
      "epoch 6983\n",
      "test_train\n",
      "train mean loss=0.05869174345086018\n",
      "test_test\n",
      "test mean loss=1160.0987243652344\n",
      "epoch 6984\n",
      "test_train\n",
      "train mean loss=0.05667372358342012\n",
      "test_test\n",
      "test mean loss=1159.4464721679688\n",
      "epoch 6985\n",
      "test_train\n",
      "train mean loss=0.0593309523537755\n",
      "test_test\n",
      "test mean loss=1157.9503173828125\n",
      "epoch 6986\n",
      "test_train\n",
      "train mean loss=0.06365048171331485\n",
      "test_test\n",
      "test mean loss=1160.1483764648438\n",
      "epoch 6987\n",
      "test_train\n",
      "train mean loss=0.060139505192637444\n",
      "test_test\n",
      "test mean loss=1157.6483764648438\n",
      "epoch 6988\n",
      "test_train\n",
      "train mean loss=0.06259218044579029\n",
      "test_test\n",
      "test mean loss=1160.5752563476562\n",
      "epoch 6989\n",
      "test_train\n",
      "train mean loss=0.06100212472180525\n",
      "test_test\n",
      "test mean loss=1159.3855590820312\n",
      "epoch 6990\n",
      "test_train\n",
      "train mean loss=0.06397161725908518\n",
      "test_test\n",
      "test mean loss=1159.3506469726562\n",
      "epoch 6991\n",
      "test_train\n",
      "train mean loss=0.0623291019971172\n",
      "test_test\n",
      "test mean loss=1159.5392150878906\n",
      "epoch 6992\n",
      "test_train\n",
      "train mean loss=0.06409860526522\n",
      "test_test\n",
      "test mean loss=1160.022705078125\n",
      "epoch 6993\n",
      "test_train\n",
      "train mean loss=0.05946188357969125\n",
      "test_test\n",
      "test mean loss=1159.4687805175781\n",
      "epoch 6994\n",
      "test_train\n",
      "train mean loss=0.06092218014722069\n",
      "test_test\n",
      "test mean loss=1160.3160400390625\n",
      "epoch 6995\n",
      "test_train\n",
      "train mean loss=0.06288941328724225\n",
      "test_test\n",
      "test mean loss=1159.2171020507812\n",
      "epoch 6996\n",
      "test_train\n",
      "train mean loss=0.05876522045582533\n",
      "test_test\n",
      "test mean loss=1158.9974365234375\n",
      "epoch 6997\n",
      "test_train\n",
      "train mean loss=0.06235946109518409\n",
      "test_test\n",
      "test mean loss=1159.2607116699219\n",
      "epoch 6998\n",
      "test_train\n",
      "train mean loss=0.06289864455660184\n",
      "test_test\n",
      "test mean loss=1159.2044677734375\n",
      "epoch 6999\n",
      "test_train\n",
      "train mean loss=0.05799065716564655\n",
      "test_test\n",
      "test mean loss=1159.6433410644531\n",
      "epoch 7000\n",
      "test_train\n",
      "train mean loss=0.06109091825783253\n",
      "test_test\n",
      "test mean loss=1160.5142822265625\n",
      "epoch 7001\n",
      "test_train\n",
      "train mean loss=0.05312604115655025\n",
      "test_test\n",
      "test mean loss=1159.0430908203125\n",
      "epoch 7002\n",
      "test_train\n",
      "train mean loss=0.059501031724115215\n",
      "test_test\n",
      "test mean loss=1160.1252746582031\n",
      "epoch 7003\n",
      "test_train\n",
      "train mean loss=0.049795044430842005\n",
      "test_test\n",
      "test mean loss=1159.9136352539062\n",
      "epoch 7004\n",
      "test_train\n",
      "train mean loss=0.05987223982810974\n",
      "test_test\n",
      "test mean loss=1161.1163940429688\n",
      "epoch 7005\n",
      "test_train\n",
      "train mean loss=0.05995911592617631\n",
      "test_test\n",
      "test mean loss=1159.9017028808594\n",
      "epoch 7006\n",
      "test_train\n",
      "train mean loss=0.05574960261583328\n",
      "test_test\n",
      "test mean loss=1159.4515686035156\n",
      "epoch 7007\n",
      "test_train\n",
      "train mean loss=0.05934710645427307\n",
      "test_test\n",
      "test mean loss=1159.4451293945312\n",
      "epoch 7008\n",
      "test_train\n",
      "train mean loss=0.05726739438250661\n",
      "test_test\n",
      "test mean loss=1159.8695373535156\n",
      "epoch 7009\n",
      "test_train\n",
      "train mean loss=0.06458866937706868\n",
      "test_test\n",
      "test mean loss=1161.0168151855469\n",
      "epoch 7010\n",
      "test_train\n",
      "train mean loss=0.06222250033169985\n",
      "test_test\n",
      "test mean loss=1160.4944458007812\n",
      "epoch 7011\n",
      "test_train\n",
      "train mean loss=0.06087782885879278\n",
      "test_test\n",
      "test mean loss=1160.2496337890625\n",
      "epoch 7012\n",
      "test_train\n",
      "train mean loss=0.0607376741245389\n",
      "test_test\n",
      "test mean loss=1160.5306396484375\n",
      "epoch 7013\n",
      "test_train\n",
      "train mean loss=0.0628221503769358\n",
      "test_test\n",
      "test mean loss=1160.0976257324219\n",
      "epoch 7014\n",
      "test_train\n",
      "train mean loss=0.061970023748775326\n",
      "test_test\n",
      "test mean loss=1159.6680908203125\n",
      "epoch 7015\n",
      "test_train\n",
      "train mean loss=0.05489837207521001\n",
      "test_test\n",
      "test mean loss=1159.7040405273438\n",
      "epoch 7016\n",
      "test_train\n",
      "train mean loss=0.050934426176051296\n",
      "test_test\n",
      "test mean loss=1160.481689453125\n",
      "epoch 7017\n",
      "test_train\n",
      "train mean loss=0.05613146505008141\n",
      "test_test\n",
      "test mean loss=1159.9798278808594\n",
      "epoch 7018\n",
      "test_train\n",
      "train mean loss=0.05933442525565624\n",
      "test_test\n",
      "test mean loss=1160.8335266113281\n",
      "epoch 7019\n",
      "test_train\n",
      "train mean loss=0.05745106594016155\n",
      "test_test\n",
      "test mean loss=1160.7422485351562\n",
      "epoch 7020\n",
      "test_train\n",
      "train mean loss=0.058381035613516964\n",
      "test_test\n",
      "test mean loss=1159.5982971191406\n",
      "epoch 7021\n",
      "test_train\n",
      "train mean loss=0.05517866710821787\n",
      "test_test\n",
      "test mean loss=1160.4237365722656\n",
      "epoch 7022\n",
      "test_train\n",
      "train mean loss=0.06539004296064377\n",
      "test_test\n",
      "test mean loss=1160.8638916015625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7023\n",
      "test_train\n",
      "train mean loss=0.05731667454044024\n",
      "test_test\n",
      "test mean loss=1160.6678161621094\n",
      "epoch 7024\n",
      "test_train\n",
      "train mean loss=0.07551798907419045\n",
      "test_test\n",
      "test mean loss=1157.9373168945312\n",
      "epoch 7025\n",
      "test_train\n",
      "train mean loss=0.0630186569566528\n",
      "test_test\n",
      "test mean loss=1160.519287109375\n",
      "epoch 7026\n",
      "test_train\n",
      "train mean loss=0.06316820438951254\n",
      "test_test\n",
      "test mean loss=1160.8435668945312\n",
      "epoch 7027\n",
      "test_train\n",
      "train mean loss=0.04879200800011555\n",
      "test_test\n",
      "test mean loss=1160.5492248535156\n",
      "epoch 7028\n",
      "test_train\n",
      "train mean loss=0.05886209073166052\n",
      "test_test\n",
      "test mean loss=1161.73486328125\n",
      "epoch 7029\n",
      "test_train\n",
      "train mean loss=0.05831893300637603\n",
      "test_test\n",
      "test mean loss=1161.4320983886719\n",
      "epoch 7030\n",
      "test_train\n",
      "train mean loss=0.05517055653035641\n",
      "test_test\n",
      "test mean loss=1161.2319946289062\n",
      "epoch 7031\n",
      "test_train\n",
      "train mean loss=0.05906623384604851\n",
      "test_test\n",
      "test mean loss=1161.451904296875\n",
      "epoch 7032\n",
      "test_train\n",
      "train mean loss=0.05382723485430082\n",
      "test_test\n",
      "test mean loss=1159.3738098144531\n",
      "epoch 7033\n",
      "test_train\n",
      "train mean loss=0.05235986908276876\n",
      "test_test\n",
      "test mean loss=1161.270263671875\n",
      "epoch 7034\n",
      "test_train\n",
      "train mean loss=0.05422770045697689\n",
      "test_test\n",
      "test mean loss=1160.4074096679688\n",
      "epoch 7035\n",
      "test_train\n",
      "train mean loss=0.05272917325297991\n",
      "test_test\n",
      "test mean loss=1161.1788940429688\n",
      "epoch 7036\n",
      "test_train\n",
      "train mean loss=0.056266241086026035\n",
      "test_test\n",
      "test mean loss=1161.1072387695312\n",
      "epoch 7037\n",
      "test_train\n",
      "train mean loss=0.05604927303890387\n",
      "test_test\n",
      "test mean loss=1162.3712768554688\n",
      "epoch 7038\n",
      "test_train\n",
      "train mean loss=0.05877055320888758\n",
      "test_test\n",
      "test mean loss=1162.208740234375\n",
      "epoch 7039\n",
      "test_train\n",
      "train mean loss=0.06666940761109193\n",
      "test_test\n",
      "test mean loss=1163.0987548828125\n",
      "epoch 7040\n",
      "test_train\n",
      "train mean loss=0.06482109675804774\n",
      "test_test\n",
      "test mean loss=1161.4656982421875\n",
      "epoch 7041\n",
      "test_train\n",
      "train mean loss=0.0673513210689028\n",
      "test_test\n",
      "test mean loss=1161.6888732910156\n",
      "epoch 7042\n",
      "test_train\n",
      "train mean loss=0.06348493943611781\n",
      "test_test\n",
      "test mean loss=1161.5842895507812\n",
      "epoch 7043\n",
      "test_train\n",
      "train mean loss=0.06460729707032442\n",
      "test_test\n",
      "test mean loss=1160.586181640625\n",
      "epoch 7044\n",
      "test_train\n",
      "train mean loss=0.06495165793846051\n",
      "test_test\n",
      "test mean loss=1159.3765258789062\n",
      "epoch 7045\n",
      "test_train\n",
      "train mean loss=0.054119788110256195\n",
      "test_test\n",
      "test mean loss=1160.6910095214844\n",
      "epoch 7046\n",
      "test_train\n",
      "train mean loss=0.052810950204730034\n",
      "test_test\n",
      "test mean loss=1160.8271179199219\n",
      "epoch 7047\n",
      "test_train\n",
      "train mean loss=0.0641442562143008\n",
      "test_test\n",
      "test mean loss=1161.7418823242188\n",
      "epoch 7048\n",
      "test_train\n",
      "train mean loss=0.05579464634259542\n",
      "test_test\n",
      "test mean loss=1161.0391235351562\n",
      "epoch 7049\n",
      "test_train\n",
      "train mean loss=0.06299606865892808\n",
      "test_test\n",
      "test mean loss=1160.0984497070312\n",
      "epoch 7050\n",
      "test_train\n",
      "train mean loss=0.06604649095485608\n",
      "test_test\n",
      "test mean loss=1160.8197021484375\n",
      "epoch 7051\n",
      "test_train\n",
      "train mean loss=0.056709132467707\n",
      "test_test\n",
      "test mean loss=1160.4254455566406\n",
      "epoch 7052\n",
      "test_train\n",
      "train mean loss=0.05834228110810121\n",
      "test_test\n",
      "test mean loss=1160.6058959960938\n",
      "epoch 7053\n",
      "test_train\n",
      "train mean loss=0.05865048679212729\n",
      "test_test\n",
      "test mean loss=1160.0595092773438\n",
      "epoch 7054\n",
      "test_train\n",
      "train mean loss=0.05824465801318487\n",
      "test_test\n",
      "test mean loss=1160.35693359375\n",
      "epoch 7055\n",
      "test_train\n",
      "train mean loss=0.0570305318882068\n",
      "test_test\n",
      "test mean loss=1160.3121337890625\n",
      "epoch 7056\n",
      "test_train\n",
      "train mean loss=0.0529392808675766\n",
      "test_test\n",
      "test mean loss=1161.0817260742188\n",
      "epoch 7057\n",
      "test_train\n",
      "train mean loss=0.06195125076919794\n",
      "test_test\n",
      "test mean loss=1160.5740356445312\n",
      "epoch 7058\n",
      "test_train\n",
      "train mean loss=0.061836328667898975\n",
      "test_test\n",
      "test mean loss=1160.0880737304688\n",
      "epoch 7059\n",
      "test_train\n",
      "train mean loss=0.06096817987660567\n",
      "test_test\n",
      "test mean loss=1161.7725524902344\n",
      "epoch 7060\n",
      "test_train\n",
      "train mean loss=0.06054882984608412\n",
      "test_test\n",
      "test mean loss=1160.5388488769531\n",
      "epoch 7061\n",
      "test_train\n",
      "train mean loss=0.0543371740107735\n",
      "test_test\n",
      "test mean loss=1160.8297119140625\n",
      "epoch 7062\n",
      "test_train\n",
      "train mean loss=0.05081104300916195\n",
      "test_test\n",
      "test mean loss=1161.4451904296875\n",
      "epoch 7063\n",
      "test_train\n",
      "train mean loss=0.0601409412920475\n",
      "test_test\n",
      "test mean loss=1161.7439880371094\n",
      "epoch 7064\n",
      "test_train\n",
      "train mean loss=0.055002361536026\n",
      "test_test\n",
      "test mean loss=1160.9839172363281\n",
      "epoch 7065\n",
      "test_train\n",
      "train mean loss=0.05896546753744284\n",
      "test_test\n",
      "test mean loss=1161.991455078125\n",
      "epoch 7066\n",
      "test_train\n",
      "train mean loss=0.056542797634998955\n",
      "test_test\n",
      "test mean loss=1161.0954895019531\n",
      "epoch 7067\n",
      "test_train\n",
      "train mean loss=0.06102234683930874\n",
      "test_test\n",
      "test mean loss=1161.4578247070312\n",
      "epoch 7068\n",
      "test_train\n",
      "train mean loss=0.05732079998900493\n",
      "test_test\n",
      "test mean loss=1160.89697265625\n",
      "epoch 7069\n",
      "test_train\n",
      "train mean loss=0.05996702052652836\n",
      "test_test\n",
      "test mean loss=1160.9258728027344\n",
      "epoch 7070\n",
      "test_train\n",
      "train mean loss=0.056856391641000904\n",
      "test_test\n",
      "test mean loss=1161.702880859375\n",
      "epoch 7071\n",
      "test_train\n",
      "train mean loss=0.05610845610499382\n",
      "test_test\n",
      "test mean loss=1162.22265625\n",
      "epoch 7072\n",
      "test_train\n",
      "train mean loss=0.0573897169282039\n",
      "test_test\n",
      "test mean loss=1160.8901062011719\n",
      "epoch 7073\n",
      "test_train\n",
      "train mean loss=0.05592139810323715\n",
      "test_test\n",
      "test mean loss=1160.0428466796875\n",
      "epoch 7074\n",
      "test_train\n",
      "train mean loss=0.06834597326815128\n",
      "test_test\n",
      "test mean loss=1160.9676208496094\n",
      "epoch 7075\n",
      "test_train\n",
      "train mean loss=0.05983163043856621\n",
      "test_test\n",
      "test mean loss=1160.1063232421875\n",
      "epoch 7076\n",
      "test_train\n",
      "train mean loss=0.05791616843392452\n",
      "test_test\n",
      "test mean loss=1160.2853393554688\n",
      "epoch 7077\n",
      "test_train\n",
      "train mean loss=0.0663378940274318\n",
      "test_test\n",
      "test mean loss=1160.0282592773438\n",
      "epoch 7078\n",
      "test_train\n",
      "train mean loss=0.06255906975517671\n",
      "test_test\n",
      "test mean loss=1161.537353515625\n",
      "epoch 7079\n",
      "test_train\n",
      "train mean loss=0.054788981564342976\n",
      "test_test\n",
      "test mean loss=1160.9693298339844\n",
      "epoch 7080\n",
      "test_train\n",
      "train mean loss=0.05988190943996111\n",
      "test_test\n",
      "test mean loss=1160.9669189453125\n",
      "epoch 7081\n",
      "test_train\n",
      "train mean loss=0.05523593723773956\n",
      "test_test\n",
      "test mean loss=1159.80859375\n",
      "epoch 7082\n",
      "test_train\n",
      "train mean loss=0.06008995541681846\n",
      "test_test\n",
      "test mean loss=1160.6085205078125\n",
      "epoch 7083\n",
      "test_train\n",
      "train mean loss=0.0493580245723327\n",
      "test_test\n",
      "test mean loss=1160.0227966308594\n",
      "epoch 7084\n",
      "test_train\n",
      "train mean loss=0.058978633334239326\n",
      "test_test\n",
      "test mean loss=1160.9153442382812\n",
      "epoch 7085\n",
      "test_train\n",
      "train mean loss=0.061551876521358885\n",
      "test_test\n",
      "test mean loss=1160.5556945800781\n",
      "epoch 7086\n",
      "test_train\n",
      "train mean loss=0.0597362145781517\n",
      "test_test\n",
      "test mean loss=1161.6804809570312\n",
      "epoch 7087\n",
      "test_train\n",
      "train mean loss=0.05654949850092331\n",
      "test_test\n",
      "test mean loss=1161.5848388671875\n",
      "epoch 7088\n",
      "test_train\n",
      "train mean loss=0.07226665876805782\n",
      "test_test\n",
      "test mean loss=1161.8099365234375\n",
      "epoch 7089\n",
      "test_train\n",
      "train mean loss=0.057566790686299406\n",
      "test_test\n",
      "test mean loss=1160.8818359375\n",
      "epoch 7090\n",
      "test_train\n",
      "train mean loss=0.05356151610612869\n",
      "test_test\n",
      "test mean loss=1160.7055053710938\n",
      "epoch 7091\n",
      "test_train\n",
      "train mean loss=0.058649064352115\n",
      "test_test\n",
      "test mean loss=1160.6026916503906\n",
      "epoch 7092\n",
      "test_train\n",
      "train mean loss=0.05790545356770357\n",
      "test_test\n",
      "test mean loss=1160.7036437988281\n",
      "epoch 7093\n",
      "test_train\n",
      "train mean loss=0.06847950412581365\n",
      "test_test\n",
      "test mean loss=1160.5730590820312\n",
      "epoch 7094\n",
      "test_train\n",
      "train mean loss=0.061151610066493355\n",
      "test_test\n",
      "test mean loss=1160.27587890625\n",
      "epoch 7095\n",
      "test_train\n",
      "train mean loss=0.05749727366492152\n",
      "test_test\n",
      "test mean loss=1158.9525146484375\n",
      "epoch 7096\n",
      "test_train\n",
      "train mean loss=0.057425071795781456\n",
      "test_test\n",
      "test mean loss=1160.0152587890625\n",
      "epoch 7097\n",
      "test_train\n",
      "train mean loss=0.05930417558799187\n",
      "test_test\n",
      "test mean loss=1159.9820556640625\n",
      "epoch 7098\n",
      "test_train\n",
      "train mean loss=0.06100449586908022\n",
      "test_test\n",
      "test mean loss=1160.0576171875\n",
      "epoch 7099\n",
      "test_train\n",
      "train mean loss=0.056341107934713364\n",
      "test_test\n",
      "test mean loss=1160.46435546875\n",
      "epoch 7100\n",
      "test_train\n",
      "train mean loss=0.06445484422147274\n",
      "test_test\n",
      "test mean loss=1160.1532592773438\n",
      "epoch 7101\n",
      "test_train\n",
      "train mean loss=0.05791874478260676\n",
      "test_test\n",
      "test mean loss=1159.7048645019531\n",
      "epoch 7102\n",
      "test_train\n",
      "train mean loss=0.06080168051024278\n",
      "test_test\n",
      "test mean loss=1158.603759765625\n",
      "epoch 7103\n",
      "test_train\n",
      "train mean loss=0.05785001488402486\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1160.3378295898438\n",
      "epoch 7104\n",
      "test_train\n",
      "train mean loss=0.05348676101615032\n",
      "test_test\n",
      "test mean loss=1159.9693603515625\n",
      "epoch 7105\n",
      "test_train\n",
      "train mean loss=0.05317465029656887\n",
      "test_test\n",
      "test mean loss=1159.8834228515625\n",
      "epoch 7106\n",
      "test_train\n",
      "train mean loss=0.05976905611654123\n",
      "test_test\n",
      "test mean loss=1160.8692321777344\n",
      "epoch 7107\n",
      "test_train\n",
      "train mean loss=0.0521299314374725\n",
      "test_test\n",
      "test mean loss=1159.4700317382812\n",
      "epoch 7108\n",
      "test_train\n",
      "train mean loss=0.057798171415925026\n",
      "test_test\n",
      "test mean loss=1160.1093139648438\n",
      "epoch 7109\n",
      "test_train\n",
      "train mean loss=0.0588367140541474\n",
      "test_test\n",
      "test mean loss=1160.512939453125\n",
      "epoch 7110\n",
      "test_train\n",
      "train mean loss=0.06178890944768985\n",
      "test_test\n",
      "test mean loss=1159.8528442382812\n",
      "epoch 7111\n",
      "test_train\n",
      "train mean loss=0.056134589637319245\n",
      "test_test\n",
      "test mean loss=1159.5025634765625\n",
      "epoch 7112\n",
      "test_train\n",
      "train mean loss=0.05297020388146242\n",
      "test_test\n",
      "test mean loss=1158.8285217285156\n",
      "epoch 7113\n",
      "test_train\n",
      "train mean loss=0.05160841982190808\n",
      "test_test\n",
      "test mean loss=1159.0156860351562\n",
      "epoch 7114\n",
      "test_train\n",
      "train mean loss=0.06091825353602568\n",
      "test_test\n",
      "test mean loss=1160.3209228515625\n",
      "epoch 7115\n",
      "test_train\n",
      "train mean loss=0.06498946156352758\n",
      "test_test\n",
      "test mean loss=1161.1077575683594\n",
      "epoch 7116\n",
      "test_train\n",
      "train mean loss=0.06558249425143003\n",
      "test_test\n",
      "test mean loss=1161.043212890625\n",
      "epoch 7117\n",
      "test_train\n",
      "train mean loss=0.05570483176658551\n",
      "test_test\n",
      "test mean loss=1159.3270568847656\n",
      "epoch 7118\n",
      "test_train\n",
      "train mean loss=0.05602486447120706\n",
      "test_test\n",
      "test mean loss=1159.9300537109375\n",
      "epoch 7119\n",
      "test_train\n",
      "train mean loss=0.04773853439837694\n",
      "test_test\n",
      "test mean loss=1158.91845703125\n",
      "epoch 7120\n",
      "test_train\n",
      "train mean loss=0.055889155715703964\n",
      "test_test\n",
      "test mean loss=1160.6343383789062\n",
      "epoch 7121\n",
      "test_train\n",
      "train mean loss=0.06157391828795274\n",
      "test_test\n",
      "test mean loss=1161.01171875\n",
      "epoch 7122\n",
      "test_train\n",
      "train mean loss=0.0592105183750391\n",
      "test_test\n",
      "test mean loss=1160.8988037109375\n",
      "epoch 7123\n",
      "test_train\n",
      "train mean loss=0.05682201295470198\n",
      "test_test\n",
      "test mean loss=1159.8457946777344\n",
      "epoch 7124\n",
      "test_train\n",
      "train mean loss=0.05852098328371843\n",
      "test_test\n",
      "test mean loss=1159.8302612304688\n",
      "epoch 7125\n",
      "test_train\n",
      "train mean loss=0.049741959354529776\n",
      "test_test\n",
      "test mean loss=1159.2380065917969\n",
      "epoch 7126\n",
      "test_train\n",
      "train mean loss=0.04816072418664893\n",
      "test_test\n",
      "test mean loss=1159.7150268554688\n",
      "epoch 7127\n",
      "test_train\n",
      "train mean loss=0.060814920191963516\n",
      "test_test\n",
      "test mean loss=1161.0436401367188\n",
      "epoch 7128\n",
      "test_train\n",
      "train mean loss=0.053785257041454315\n",
      "test_test\n",
      "test mean loss=1159.8416442871094\n",
      "epoch 7129\n",
      "test_train\n",
      "train mean loss=0.06335668327907722\n",
      "test_test\n",
      "test mean loss=1160.8878173828125\n",
      "epoch 7130\n",
      "test_train\n",
      "train mean loss=0.05193493872260054\n",
      "test_test\n",
      "test mean loss=1160.614990234375\n",
      "epoch 7131\n",
      "test_train\n",
      "train mean loss=0.05284276232123375\n",
      "test_test\n",
      "test mean loss=1160.6121215820312\n",
      "epoch 7132\n",
      "test_train\n",
      "train mean loss=0.054331294571359955\n",
      "test_test\n",
      "test mean loss=1160.0988159179688\n",
      "epoch 7133\n",
      "test_train\n",
      "train mean loss=0.05382182247315844\n",
      "test_test\n",
      "test mean loss=1157.7626953125\n",
      "epoch 7134\n",
      "test_train\n",
      "train mean loss=0.055085130811979376\n",
      "test_test\n",
      "test mean loss=1160.2798461914062\n",
      "epoch 7135\n",
      "test_train\n",
      "train mean loss=0.05758657647917668\n",
      "test_test\n",
      "test mean loss=1160.2166748046875\n",
      "epoch 7136\n",
      "test_train\n",
      "train mean loss=0.05211986353000005\n",
      "test_test\n",
      "test mean loss=1159.6878662109375\n",
      "epoch 7137\n",
      "test_train\n",
      "train mean loss=0.051043412648141384\n",
      "test_test\n",
      "test mean loss=1159.9486083984375\n",
      "epoch 7138\n",
      "test_train\n",
      "train mean loss=0.05567282593498627\n",
      "test_test\n",
      "test mean loss=1160.4221496582031\n",
      "epoch 7139\n",
      "test_train\n",
      "train mean loss=0.07479832818110783\n",
      "test_test\n",
      "test mean loss=1159.7109985351562\n",
      "epoch 7140\n",
      "test_train\n",
      "train mean loss=0.0575696916008989\n",
      "test_test\n",
      "test mean loss=1160.0155334472656\n",
      "epoch 7141\n",
      "test_train\n",
      "train mean loss=0.05473843915387988\n",
      "test_test\n",
      "test mean loss=1159.8780517578125\n",
      "epoch 7142\n",
      "test_train\n",
      "train mean loss=0.060612946127851806\n",
      "test_test\n",
      "test mean loss=1160.3233947753906\n",
      "epoch 7143\n",
      "test_train\n",
      "train mean loss=0.059531835839152336\n",
      "test_test\n",
      "test mean loss=1160.3787841796875\n",
      "epoch 7144\n",
      "test_train\n",
      "train mean loss=0.05693775570640961\n",
      "test_test\n",
      "test mean loss=1159.8314514160156\n",
      "epoch 7145\n",
      "test_train\n",
      "train mean loss=0.059488452350099884\n",
      "test_test\n",
      "test mean loss=1160.4207763671875\n",
      "epoch 7146\n",
      "test_train\n",
      "train mean loss=0.057528638591368995\n",
      "test_test\n",
      "test mean loss=1159.67724609375\n",
      "epoch 7147\n",
      "test_train\n",
      "train mean loss=0.06886455416679382\n",
      "test_test\n",
      "test mean loss=1160.4624633789062\n",
      "epoch 7148\n",
      "test_train\n",
      "train mean loss=0.05823628387103478\n",
      "test_test\n",
      "test mean loss=1161.2760620117188\n",
      "epoch 7149\n",
      "test_train\n",
      "train mean loss=0.05761102059235176\n",
      "test_test\n",
      "test mean loss=1160.7506103515625\n",
      "epoch 7150\n",
      "test_train\n",
      "train mean loss=0.06361590325832367\n",
      "test_test\n",
      "test mean loss=1161.3878784179688\n",
      "epoch 7151\n",
      "test_train\n",
      "train mean loss=0.05956588375071684\n",
      "test_test\n",
      "test mean loss=1161.2299194335938\n",
      "epoch 7152\n",
      "test_train\n",
      "train mean loss=0.05353837677588066\n",
      "test_test\n",
      "test mean loss=1160.15576171875\n",
      "epoch 7153\n",
      "test_train\n",
      "train mean loss=0.06540863557408254\n",
      "test_test\n",
      "test mean loss=1160.7438354492188\n",
      "epoch 7154\n",
      "test_train\n",
      "train mean loss=0.06323468747238319\n",
      "test_test\n",
      "test mean loss=1160.319580078125\n",
      "epoch 7155\n",
      "test_train\n",
      "train mean loss=0.05819464661180973\n",
      "test_test\n",
      "test mean loss=1161.1893310546875\n",
      "epoch 7156\n",
      "test_train\n",
      "train mean loss=0.05797154363244772\n",
      "test_test\n",
      "test mean loss=1161.898193359375\n",
      "epoch 7157\n",
      "test_train\n",
      "train mean loss=0.06207647453993559\n",
      "test_test\n",
      "test mean loss=1161.0757751464844\n",
      "epoch 7158\n",
      "test_train\n",
      "train mean loss=0.05511271891494592\n",
      "test_test\n",
      "test mean loss=1160.7105407714844\n",
      "epoch 7159\n",
      "test_train\n",
      "train mean loss=0.06100687167296807\n",
      "test_test\n",
      "test mean loss=1161.4736328125\n",
      "epoch 7160\n",
      "test_train\n",
      "train mean loss=0.05465778475627303\n",
      "test_test\n",
      "test mean loss=1160.9038391113281\n",
      "epoch 7161\n",
      "test_train\n",
      "train mean loss=0.05793320558344325\n",
      "test_test\n",
      "test mean loss=1160.3762817382812\n",
      "epoch 7162\n",
      "test_train\n",
      "train mean loss=0.057827685959637165\n",
      "test_test\n",
      "test mean loss=1161.7166137695312\n",
      "epoch 7163\n",
      "test_train\n",
      "train mean loss=0.05948757380247116\n",
      "test_test\n",
      "test mean loss=1160.0209350585938\n",
      "epoch 7164\n",
      "test_train\n",
      "train mean loss=0.05525351377824942\n",
      "test_test\n",
      "test mean loss=1159.4701232910156\n",
      "epoch 7165\n",
      "test_train\n",
      "train mean loss=0.07410069337735574\n",
      "test_test\n",
      "test mean loss=1161.1947326660156\n",
      "epoch 7166\n",
      "test_train\n",
      "train mean loss=0.05704123588899771\n",
      "test_test\n",
      "test mean loss=1161.4520874023438\n",
      "epoch 7167\n",
      "test_train\n",
      "train mean loss=0.059757793322205544\n",
      "test_test\n",
      "test mean loss=1160.1873779296875\n",
      "epoch 7168\n",
      "test_train\n",
      "train mean loss=0.05497091946502527\n",
      "test_test\n",
      "test mean loss=1160.3134155273438\n",
      "epoch 7169\n",
      "test_train\n",
      "train mean loss=0.05208153044804931\n",
      "test_test\n",
      "test mean loss=1161.3720703125\n",
      "epoch 7170\n",
      "test_train\n",
      "train mean loss=0.0636855394889911\n",
      "test_test\n",
      "test mean loss=1159.8727416992188\n",
      "epoch 7171\n",
      "test_train\n",
      "train mean loss=0.054219384056826435\n",
      "test_test\n",
      "test mean loss=1159.5984802246094\n",
      "epoch 7172\n",
      "test_train\n",
      "train mean loss=0.05516234692186117\n",
      "test_test\n",
      "test mean loss=1160.6123657226562\n",
      "epoch 7173\n",
      "test_train\n",
      "train mean loss=0.05243733059614897\n",
      "test_test\n",
      "test mean loss=1160.7360229492188\n",
      "epoch 7174\n",
      "test_train\n",
      "train mean loss=0.054571169428527355\n",
      "test_test\n",
      "test mean loss=1160.8475646972656\n",
      "epoch 7175\n",
      "test_train\n",
      "train mean loss=0.05807005117336909\n",
      "test_test\n",
      "test mean loss=1161.2187194824219\n",
      "epoch 7176\n",
      "test_train\n",
      "train mean loss=0.051969658893843494\n",
      "test_test\n",
      "test mean loss=1160.3244018554688\n",
      "epoch 7177\n",
      "test_train\n",
      "train mean loss=0.054246627570440374\n",
      "test_test\n",
      "test mean loss=1159.8952026367188\n",
      "epoch 7178\n",
      "test_train\n",
      "train mean loss=0.059804108614722885\n",
      "test_test\n",
      "test mean loss=1161.0307006835938\n",
      "epoch 7179\n",
      "test_train\n",
      "train mean loss=0.060197338772316776\n",
      "test_test\n",
      "test mean loss=1160.3898315429688\n",
      "epoch 7180\n",
      "test_train\n",
      "train mean loss=0.06021902896463871\n",
      "test_test\n",
      "test mean loss=1161.5803833007812\n",
      "epoch 7181\n",
      "test_train\n",
      "train mean loss=0.06276387566079696\n",
      "test_test\n",
      "test mean loss=1160.9534912109375\n",
      "epoch 7182\n",
      "test_train\n",
      "train mean loss=0.05718385428190231\n",
      "test_test\n",
      "test mean loss=1160.7093505859375\n",
      "epoch 7183\n",
      "test_train\n",
      "train mean loss=0.0924466581394275\n",
      "test_test\n",
      "test mean loss=1162.4504699707031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7184\n",
      "test_train\n",
      "train mean loss=0.062394985308249794\n",
      "test_test\n",
      "test mean loss=1162.1825561523438\n",
      "epoch 7185\n",
      "test_train\n",
      "train mean loss=0.06270758000512917\n",
      "test_test\n",
      "test mean loss=1161.9866027832031\n",
      "epoch 7186\n",
      "test_train\n",
      "train mean loss=0.07008184399455786\n",
      "test_test\n",
      "test mean loss=1162.1096496582031\n",
      "epoch 7187\n",
      "test_train\n",
      "train mean loss=0.0574835812052091\n",
      "test_test\n",
      "test mean loss=1161.4972534179688\n",
      "epoch 7188\n",
      "test_train\n",
      "train mean loss=0.05875180537501971\n",
      "test_test\n",
      "test mean loss=1161.6175231933594\n",
      "epoch 7189\n",
      "test_train\n",
      "train mean loss=0.0605209202816089\n",
      "test_test\n",
      "test mean loss=1161.3872680664062\n",
      "epoch 7190\n",
      "test_train\n",
      "train mean loss=0.059398820313314594\n",
      "test_test\n",
      "test mean loss=1160.977783203125\n",
      "epoch 7191\n",
      "test_train\n",
      "train mean loss=0.052601110811034836\n",
      "test_test\n",
      "test mean loss=1159.8235473632812\n",
      "epoch 7192\n",
      "test_train\n",
      "train mean loss=0.06002807694797715\n",
      "test_test\n",
      "test mean loss=1161.5574340820312\n",
      "epoch 7193\n",
      "test_train\n",
      "train mean loss=0.05879943631589413\n",
      "test_test\n",
      "test mean loss=1160.8290405273438\n",
      "epoch 7194\n",
      "test_train\n",
      "train mean loss=0.0496392915956676\n",
      "test_test\n",
      "test mean loss=1159.6061096191406\n",
      "epoch 7195\n",
      "test_train\n",
      "train mean loss=0.05463309120386839\n",
      "test_test\n",
      "test mean loss=1161.47802734375\n",
      "epoch 7196\n",
      "test_train\n",
      "train mean loss=0.05880150261024634\n",
      "test_test\n",
      "test mean loss=1159.5227661132812\n",
      "epoch 7197\n",
      "test_train\n",
      "train mean loss=0.06233344661692778\n",
      "test_test\n",
      "test mean loss=1159.7740478515625\n",
      "epoch 7198\n",
      "test_train\n",
      "train mean loss=0.058261468075215816\n",
      "test_test\n",
      "test mean loss=1160.3070068359375\n",
      "epoch 7199\n",
      "test_train\n",
      "train mean loss=0.05433736524234215\n",
      "test_test\n",
      "test mean loss=1160.2791442871094\n",
      "epoch 7200\n",
      "test_train\n",
      "train mean loss=0.07693644985556602\n",
      "test_test\n",
      "test mean loss=1161.343994140625\n",
      "epoch 7201\n",
      "test_train\n",
      "train mean loss=0.05875354539602995\n",
      "test_test\n",
      "test mean loss=1161.1475830078125\n",
      "epoch 7202\n",
      "test_train\n",
      "train mean loss=0.053872956739117704\n",
      "test_test\n",
      "test mean loss=1160.6755981445312\n",
      "epoch 7203\n",
      "test_train\n",
      "train mean loss=0.06194629116604725\n",
      "test_test\n",
      "test mean loss=1160.77392578125\n",
      "epoch 7204\n",
      "test_train\n",
      "train mean loss=0.06152554384122292\n",
      "test_test\n",
      "test mean loss=1159.6108703613281\n",
      "epoch 7205\n",
      "test_train\n",
      "train mean loss=0.05686539256324371\n",
      "test_test\n",
      "test mean loss=1160.1934204101562\n",
      "epoch 7206\n",
      "test_train\n",
      "train mean loss=0.05664763071884712\n",
      "test_test\n",
      "test mean loss=1159.651611328125\n",
      "epoch 7207\n",
      "test_train\n",
      "train mean loss=0.058470904206236206\n",
      "test_test\n",
      "test mean loss=1160.5685424804688\n",
      "epoch 7208\n",
      "test_train\n",
      "train mean loss=0.05553620060284933\n",
      "test_test\n",
      "test mean loss=1160.5250854492188\n",
      "epoch 7209\n",
      "test_train\n",
      "train mean loss=0.06239830950895945\n",
      "test_test\n",
      "test mean loss=1160.962890625\n",
      "epoch 7210\n",
      "test_train\n",
      "train mean loss=0.06068827863782644\n",
      "test_test\n",
      "test mean loss=1160.340576171875\n",
      "epoch 7211\n",
      "test_train\n",
      "train mean loss=0.072075798176229\n",
      "test_test\n",
      "test mean loss=1162.0105590820312\n",
      "epoch 7212\n",
      "test_train\n",
      "train mean loss=0.06200487197687229\n",
      "test_test\n",
      "test mean loss=1160.3394775390625\n",
      "epoch 7213\n",
      "test_train\n",
      "train mean loss=0.057570814775923886\n",
      "test_test\n",
      "test mean loss=1160.0108642578125\n",
      "epoch 7214\n",
      "test_train\n",
      "train mean loss=0.05229627309987942\n",
      "test_test\n",
      "test mean loss=1159.749267578125\n",
      "epoch 7215\n",
      "test_train\n",
      "train mean loss=0.05275149084627628\n",
      "test_test\n",
      "test mean loss=1159.7332153320312\n",
      "epoch 7216\n",
      "test_train\n",
      "train mean loss=0.05553027909869949\n",
      "test_test\n",
      "test mean loss=1160.6190185546875\n",
      "epoch 7217\n",
      "test_train\n",
      "train mean loss=0.0581730209911863\n",
      "test_test\n",
      "test mean loss=1160.6082763671875\n",
      "epoch 7218\n",
      "test_train\n",
      "train mean loss=0.06196596644197901\n",
      "test_test\n",
      "test mean loss=1160.6116943359375\n",
      "epoch 7219\n",
      "test_train\n",
      "train mean loss=0.06267253650973241\n",
      "test_test\n",
      "test mean loss=1160.0505065917969\n",
      "epoch 7220\n",
      "test_train\n",
      "train mean loss=0.06032283262660106\n",
      "test_test\n",
      "test mean loss=1160.5384521484375\n",
      "epoch 7221\n",
      "test_train\n",
      "train mean loss=0.05733692071711024\n",
      "test_test\n",
      "test mean loss=1159.96923828125\n",
      "epoch 7222\n",
      "test_train\n",
      "train mean loss=0.055339140817523\n",
      "test_test\n",
      "test mean loss=1160.9916381835938\n",
      "epoch 7223\n",
      "test_train\n",
      "train mean loss=0.053113792557269335\n",
      "test_test\n",
      "test mean loss=1160.9935913085938\n",
      "epoch 7224\n",
      "test_train\n",
      "train mean loss=0.06253461726009846\n",
      "test_test\n",
      "test mean loss=1160.0205078125\n",
      "epoch 7225\n",
      "test_train\n",
      "train mean loss=0.14633228133122125\n",
      "test_test\n",
      "test mean loss=1157.9021606445312\n",
      "epoch 7226\n",
      "test_train\n",
      "train mean loss=0.05920976089934508\n",
      "test_test\n",
      "test mean loss=1160.4353942871094\n",
      "epoch 7227\n",
      "test_train\n",
      "train mean loss=0.051845728885382414\n",
      "test_test\n",
      "test mean loss=1160.3792724609375\n",
      "epoch 7228\n",
      "test_train\n",
      "train mean loss=0.05637184530496597\n",
      "test_test\n",
      "test mean loss=1159.9066772460938\n",
      "epoch 7229\n",
      "test_train\n",
      "train mean loss=0.06306329400589068\n",
      "test_test\n",
      "test mean loss=1160.8409423828125\n",
      "epoch 7230\n",
      "test_train\n",
      "train mean loss=0.14144211200376353\n",
      "test_test\n",
      "test mean loss=1161.7799682617188\n",
      "epoch 7231\n",
      "test_train\n",
      "train mean loss=0.05951817985624075\n",
      "test_test\n",
      "test mean loss=1160.7837219238281\n",
      "epoch 7232\n",
      "test_train\n",
      "train mean loss=0.05471806336815158\n",
      "test_test\n",
      "test mean loss=1160.2432556152344\n",
      "epoch 7233\n",
      "test_train\n",
      "train mean loss=0.07868506293743849\n",
      "test_test\n",
      "test mean loss=1158.72119140625\n",
      "epoch 7234\n",
      "test_train\n",
      "train mean loss=0.09060478582978249\n",
      "test_test\n",
      "test mean loss=1158.9090576171875\n",
      "epoch 7235\n",
      "test_train\n",
      "train mean loss=0.0611788984388113\n",
      "test_test\n",
      "test mean loss=1160.5635681152344\n",
      "epoch 7236\n",
      "test_train\n",
      "train mean loss=0.05858121905475855\n",
      "test_test\n",
      "test mean loss=1160.8231811523438\n",
      "epoch 7237\n",
      "test_train\n",
      "train mean loss=0.05876016182204088\n",
      "test_test\n",
      "test mean loss=1160.5284729003906\n",
      "epoch 7238\n",
      "test_train\n",
      "train mean loss=0.05706597274790207\n",
      "test_test\n",
      "test mean loss=1160.7581787109375\n",
      "epoch 7239\n",
      "test_train\n",
      "train mean loss=0.06222351392110189\n",
      "test_test\n",
      "test mean loss=1160.8760681152344\n",
      "epoch 7240\n",
      "test_train\n",
      "train mean loss=0.05480823448548714\n",
      "test_test\n",
      "test mean loss=1159.7562866210938\n",
      "epoch 7241\n",
      "test_train\n",
      "train mean loss=0.05338077247142792\n",
      "test_test\n",
      "test mean loss=1160.060791015625\n",
      "epoch 7242\n",
      "test_train\n",
      "train mean loss=0.05386719231804212\n",
      "test_test\n",
      "test mean loss=1160.5313110351562\n",
      "epoch 7243\n",
      "test_train\n",
      "train mean loss=0.06241890198240677\n",
      "test_test\n",
      "test mean loss=1160.9564819335938\n",
      "epoch 7244\n",
      "test_train\n",
      "train mean loss=0.05586598378916582\n",
      "test_test\n",
      "test mean loss=1159.7313232421875\n",
      "epoch 7245\n",
      "test_train\n",
      "train mean loss=0.05592079988370339\n",
      "test_test\n",
      "test mean loss=1159.7271118164062\n",
      "epoch 7246\n",
      "test_train\n",
      "train mean loss=0.05459607299417257\n",
      "test_test\n",
      "test mean loss=1159.6015319824219\n",
      "epoch 7247\n",
      "test_train\n",
      "train mean loss=0.05470620250950257\n",
      "test_test\n",
      "test mean loss=1158.818603515625\n",
      "epoch 7248\n",
      "test_train\n",
      "train mean loss=0.05268151111279925\n",
      "test_test\n",
      "test mean loss=1160.5872802734375\n",
      "epoch 7249\n",
      "test_train\n",
      "train mean loss=0.058495855734994016\n",
      "test_test\n",
      "test mean loss=1160.4174499511719\n",
      "epoch 7250\n",
      "test_train\n",
      "train mean loss=0.06131061166524887\n",
      "test_test\n",
      "test mean loss=1160.2083129882812\n",
      "epoch 7251\n",
      "test_train\n",
      "train mean loss=0.08122748260696729\n",
      "test_test\n",
      "test mean loss=1158.9434814453125\n",
      "epoch 7252\n",
      "test_train\n",
      "train mean loss=0.059077594274034105\n",
      "test_test\n",
      "test mean loss=1159.1107788085938\n",
      "epoch 7253\n",
      "test_train\n",
      "train mean loss=0.061214796267449856\n",
      "test_test\n",
      "test mean loss=1159.5299377441406\n",
      "epoch 7254\n",
      "test_train\n",
      "train mean loss=0.06102388553942243\n",
      "test_test\n",
      "test mean loss=1160.4559326171875\n",
      "epoch 7255\n",
      "test_train\n",
      "train mean loss=0.053524347487837076\n",
      "test_test\n",
      "test mean loss=1160.2003173828125\n",
      "epoch 7256\n",
      "test_train\n",
      "train mean loss=0.054649647790938616\n",
      "test_test\n",
      "test mean loss=1159.3272705078125\n",
      "epoch 7257\n",
      "test_train\n",
      "train mean loss=0.056071508675813675\n",
      "test_test\n",
      "test mean loss=1158.1533813476562\n",
      "epoch 7258\n",
      "test_train\n",
      "train mean loss=0.05842894408851862\n",
      "test_test\n",
      "test mean loss=1158.9679565429688\n",
      "epoch 7259\n",
      "test_train\n",
      "train mean loss=0.057245528946320214\n",
      "test_test\n",
      "test mean loss=1159.1329956054688\n",
      "epoch 7260\n",
      "test_train\n",
      "train mean loss=0.05998000347365936\n",
      "test_test\n",
      "test mean loss=1159.052001953125\n",
      "epoch 7261\n",
      "test_train\n",
      "train mean loss=0.058720579991738\n",
      "test_test\n",
      "test mean loss=1160.2516784667969\n",
      "epoch 7262\n",
      "test_train\n",
      "train mean loss=0.05871830942730109\n",
      "test_test\n",
      "test mean loss=1160.5443420410156\n",
      "epoch 7263\n",
      "test_train\n",
      "train mean loss=0.06003088317811489\n",
      "test_test\n",
      "test mean loss=1160.3716735839844\n",
      "epoch 7264\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.05718941334635019\n",
      "test_test\n",
      "test mean loss=1160.483154296875\n",
      "epoch 7265\n",
      "test_train\n",
      "train mean loss=0.05595279640207688\n",
      "test_test\n",
      "test mean loss=1160.0922546386719\n",
      "epoch 7266\n",
      "test_train\n",
      "train mean loss=0.05566986619184414\n",
      "test_test\n",
      "test mean loss=1161.281494140625\n",
      "epoch 7267\n",
      "test_train\n",
      "train mean loss=0.0594854544227322\n",
      "test_test\n",
      "test mean loss=1159.7803955078125\n",
      "epoch 7268\n",
      "test_train\n",
      "train mean loss=0.054475617284576096\n",
      "test_test\n",
      "test mean loss=1158.5484008789062\n",
      "epoch 7269\n",
      "test_train\n",
      "train mean loss=0.060608805467685066\n",
      "test_test\n",
      "test mean loss=1159.5290832519531\n",
      "epoch 7270\n",
      "test_train\n",
      "train mean loss=0.05650251669188341\n",
      "test_test\n",
      "test mean loss=1159.677001953125\n",
      "epoch 7271\n",
      "test_train\n",
      "train mean loss=0.05849758442491293\n",
      "test_test\n",
      "test mean loss=1159.1768188476562\n",
      "epoch 7272\n",
      "test_train\n",
      "train mean loss=0.056673431458572544\n",
      "test_test\n",
      "test mean loss=1158.8706359863281\n",
      "epoch 7273\n",
      "test_train\n",
      "train mean loss=0.05760394191990296\n",
      "test_test\n",
      "test mean loss=1159.6400451660156\n",
      "epoch 7274\n",
      "test_train\n",
      "train mean loss=0.059659528080374\n",
      "test_test\n",
      "test mean loss=1160.7651672363281\n",
      "epoch 7275\n",
      "test_train\n",
      "train mean loss=0.05356930599858364\n",
      "test_test\n",
      "test mean loss=1159.9412841796875\n",
      "epoch 7276\n",
      "test_train\n",
      "train mean loss=0.053291428834199905\n",
      "test_test\n",
      "test mean loss=1158.9372863769531\n",
      "epoch 7277\n",
      "test_train\n",
      "train mean loss=0.05793641166140636\n",
      "test_test\n",
      "test mean loss=1159.7686462402344\n",
      "epoch 7278\n",
      "test_train\n",
      "train mean loss=0.05585504819949468\n",
      "test_test\n",
      "test mean loss=1159.4583129882812\n",
      "epoch 7279\n",
      "test_train\n",
      "train mean loss=0.05373875175913175\n",
      "test_test\n",
      "test mean loss=1158.9696044921875\n",
      "epoch 7280\n",
      "test_train\n",
      "train mean loss=0.06413641447822253\n",
      "test_test\n",
      "test mean loss=1159.4470825195312\n",
      "epoch 7281\n",
      "test_train\n",
      "train mean loss=0.06169557090227803\n",
      "test_test\n",
      "test mean loss=1159.470703125\n",
      "epoch 7282\n",
      "test_train\n",
      "train mean loss=0.060104930152495704\n",
      "test_test\n",
      "test mean loss=1159.7229614257812\n",
      "epoch 7283\n",
      "test_train\n",
      "train mean loss=0.056193675535420574\n",
      "test_test\n",
      "test mean loss=1159.4284362792969\n",
      "epoch 7284\n",
      "test_train\n",
      "train mean loss=0.06262363695229094\n",
      "test_test\n",
      "test mean loss=1159.57861328125\n",
      "epoch 7285\n",
      "test_train\n",
      "train mean loss=0.06275673272709052\n",
      "test_test\n",
      "test mean loss=1158.98974609375\n",
      "epoch 7286\n",
      "test_train\n",
      "train mean loss=0.062726607080549\n",
      "test_test\n",
      "test mean loss=1159.770751953125\n",
      "epoch 7287\n",
      "test_train\n",
      "train mean loss=0.06566772951434056\n",
      "test_test\n",
      "test mean loss=1160.1274719238281\n",
      "epoch 7288\n",
      "test_train\n",
      "train mean loss=0.06059056939557195\n",
      "test_test\n",
      "test mean loss=1161.1278076171875\n",
      "epoch 7289\n",
      "test_train\n",
      "train mean loss=0.0625719353556633\n",
      "test_test\n",
      "test mean loss=1160.5640869140625\n",
      "epoch 7290\n",
      "test_train\n",
      "train mean loss=0.0559747414663434\n",
      "test_test\n",
      "test mean loss=1160.1361694335938\n",
      "epoch 7291\n",
      "test_train\n",
      "train mean loss=0.06359427484373252\n",
      "test_test\n",
      "test mean loss=1160.5230102539062\n",
      "epoch 7292\n",
      "test_train\n",
      "train mean loss=0.054415304524203144\n",
      "test_test\n",
      "test mean loss=1159.1058959960938\n",
      "epoch 7293\n",
      "test_train\n",
      "train mean loss=0.05631930101662874\n",
      "test_test\n",
      "test mean loss=1159.8987731933594\n",
      "epoch 7294\n",
      "test_train\n",
      "train mean loss=0.054106003449608885\n",
      "test_test\n",
      "test mean loss=1160.1805725097656\n",
      "epoch 7295\n",
      "test_train\n",
      "train mean loss=0.059829587737719216\n",
      "test_test\n",
      "test mean loss=1160.8235168457031\n",
      "epoch 7296\n",
      "test_train\n",
      "train mean loss=0.06225943720589081\n",
      "test_test\n",
      "test mean loss=1161.0734252929688\n",
      "epoch 7297\n",
      "test_train\n",
      "train mean loss=0.06321348529309034\n",
      "test_test\n",
      "test mean loss=1160.15380859375\n",
      "epoch 7298\n",
      "test_train\n",
      "train mean loss=0.05664300235609213\n",
      "test_test\n",
      "test mean loss=1160.0133666992188\n",
      "epoch 7299\n",
      "test_train\n",
      "train mean loss=0.05672222965707382\n",
      "test_test\n",
      "test mean loss=1159.581298828125\n",
      "epoch 7300\n",
      "test_train\n",
      "train mean loss=0.055418854424109064\n",
      "test_test\n",
      "test mean loss=1159.0189514160156\n",
      "epoch 7301\n",
      "test_train\n",
      "train mean loss=0.0541497147642076\n",
      "test_test\n",
      "test mean loss=1159.3341674804688\n",
      "epoch 7302\n",
      "test_train\n",
      "train mean loss=0.05768046403924624\n",
      "test_test\n",
      "test mean loss=1160.0405883789062\n",
      "epoch 7303\n",
      "test_train\n",
      "train mean loss=0.05254217439020673\n",
      "test_test\n",
      "test mean loss=1160.1546630859375\n",
      "epoch 7304\n",
      "test_train\n",
      "train mean loss=0.05736204252267877\n",
      "test_test\n",
      "test mean loss=1160.9166564941406\n",
      "epoch 7305\n",
      "test_train\n",
      "train mean loss=0.059622280610104404\n",
      "test_test\n",
      "test mean loss=1161.7629089355469\n",
      "epoch 7306\n",
      "test_train\n",
      "train mean loss=0.05143909497807423\n",
      "test_test\n",
      "test mean loss=1160.8591918945312\n",
      "epoch 7307\n",
      "test_train\n",
      "train mean loss=0.05791189211110274\n",
      "test_test\n",
      "test mean loss=1160.372314453125\n",
      "epoch 7308\n",
      "test_train\n",
      "train mean loss=0.06399613246321678\n",
      "test_test\n",
      "test mean loss=1162.0357971191406\n",
      "epoch 7309\n",
      "test_train\n",
      "train mean loss=0.11138933897018433\n",
      "test_test\n",
      "test mean loss=1162.3576049804688\n",
      "epoch 7310\n",
      "test_train\n",
      "train mean loss=0.06277507574607928\n",
      "test_test\n",
      "test mean loss=1161.0840759277344\n",
      "epoch 7311\n",
      "test_train\n",
      "train mean loss=0.06027964844057957\n",
      "test_test\n",
      "test mean loss=1159.9337768554688\n",
      "epoch 7312\n",
      "test_train\n",
      "train mean loss=0.058909518333772816\n",
      "test_test\n",
      "test mean loss=1160.0134582519531\n",
      "epoch 7313\n",
      "test_train\n",
      "train mean loss=0.05759890191257\n",
      "test_test\n",
      "test mean loss=1160.8029479980469\n",
      "epoch 7314\n",
      "test_train\n",
      "train mean loss=0.06132038217037916\n",
      "test_test\n",
      "test mean loss=1159.8766784667969\n",
      "epoch 7315\n",
      "test_train\n",
      "train mean loss=0.05452939122915268\n",
      "test_test\n",
      "test mean loss=1160.1406860351562\n",
      "epoch 7316\n",
      "test_train\n",
      "train mean loss=0.06363128498196602\n",
      "test_test\n",
      "test mean loss=1160.3774719238281\n",
      "epoch 7317\n",
      "test_train\n",
      "train mean loss=0.05773986751834551\n",
      "test_test\n",
      "test mean loss=1161.2012939453125\n",
      "epoch 7318\n",
      "test_train\n",
      "train mean loss=0.06045046867802739\n",
      "test_test\n",
      "test mean loss=1161.1541137695312\n",
      "epoch 7319\n",
      "test_train\n",
      "train mean loss=0.0537279414323469\n",
      "test_test\n",
      "test mean loss=1160.303466796875\n",
      "epoch 7320\n",
      "test_train\n",
      "train mean loss=0.05435041214028994\n",
      "test_test\n",
      "test mean loss=1159.1097106933594\n",
      "epoch 7321\n",
      "test_train\n",
      "train mean loss=0.06432088386888306\n",
      "test_test\n",
      "test mean loss=1160.5766296386719\n",
      "epoch 7322\n",
      "test_train\n",
      "train mean loss=0.055959402893980346\n",
      "test_test\n",
      "test mean loss=1159.1815795898438\n",
      "epoch 7323\n",
      "test_train\n",
      "train mean loss=0.05609704771389564\n",
      "test_test\n",
      "test mean loss=1159.5765991210938\n",
      "epoch 7324\n",
      "test_train\n",
      "train mean loss=0.05769614658008019\n",
      "test_test\n",
      "test mean loss=1159.2864074707031\n",
      "epoch 7325\n",
      "test_train\n",
      "train mean loss=0.057383657743533455\n",
      "test_test\n",
      "test mean loss=1159.0037231445312\n",
      "epoch 7326\n",
      "test_train\n",
      "train mean loss=0.05662679191057881\n",
      "test_test\n",
      "test mean loss=1159.2207946777344\n",
      "epoch 7327\n",
      "test_train\n",
      "train mean loss=0.055265093532701336\n",
      "test_test\n",
      "test mean loss=1158.7800903320312\n",
      "epoch 7328\n",
      "test_train\n",
      "train mean loss=0.05960836044202248\n",
      "test_test\n",
      "test mean loss=1159.5216064453125\n",
      "epoch 7329\n",
      "test_train\n",
      "train mean loss=0.056426988914608955\n",
      "test_test\n",
      "test mean loss=1160.6033935546875\n",
      "epoch 7330\n",
      "test_train\n",
      "train mean loss=0.05769314973925551\n",
      "test_test\n",
      "test mean loss=1160.0185241699219\n",
      "epoch 7331\n",
      "test_train\n",
      "train mean loss=0.0515445809190472\n",
      "test_test\n",
      "test mean loss=1158.935546875\n",
      "epoch 7332\n",
      "test_train\n",
      "train mean loss=0.054525064614911876\n",
      "test_test\n",
      "test mean loss=1159.6427001953125\n",
      "epoch 7333\n",
      "test_train\n",
      "train mean loss=0.05965272492418686\n",
      "test_test\n",
      "test mean loss=1160.0675048828125\n",
      "epoch 7334\n",
      "test_train\n",
      "train mean loss=0.05706467246636748\n",
      "test_test\n",
      "test mean loss=1159.8611450195312\n",
      "epoch 7335\n",
      "test_train\n",
      "train mean loss=0.05953901447355747\n",
      "test_test\n",
      "test mean loss=1159.4990844726562\n",
      "epoch 7336\n",
      "test_train\n",
      "train mean loss=0.057566073102255665\n",
      "test_test\n",
      "test mean loss=1157.9918212890625\n",
      "epoch 7337\n",
      "test_train\n",
      "train mean loss=0.05877458738783995\n",
      "test_test\n",
      "test mean loss=1158.7924194335938\n",
      "epoch 7338\n",
      "test_train\n",
      "train mean loss=0.06064270374675592\n",
      "test_test\n",
      "test mean loss=1159.8614501953125\n",
      "epoch 7339\n",
      "test_train\n",
      "train mean loss=0.0658506341278553\n",
      "test_test\n",
      "test mean loss=1160.6675415039062\n",
      "epoch 7340\n",
      "test_train\n",
      "train mean loss=0.061837207060307264\n",
      "test_test\n",
      "test mean loss=1161.2219543457031\n",
      "epoch 7341\n",
      "test_train\n",
      "train mean loss=0.055305700438718\n",
      "test_test\n",
      "test mean loss=1159.985107421875\n",
      "epoch 7342\n",
      "test_train\n",
      "train mean loss=0.059834684866170086\n",
      "test_test\n",
      "test mean loss=1159.64990234375\n",
      "epoch 7343\n",
      "test_train\n",
      "train mean loss=0.053539768482247986\n",
      "test_test\n",
      "test mean loss=1159.4314575195312\n",
      "epoch 7344\n",
      "test_train\n",
      "train mean loss=0.05420103048284849\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1160.1660766601562\n",
      "epoch 7345\n",
      "test_train\n",
      "train mean loss=0.05704349341491858\n",
      "test_test\n",
      "test mean loss=1159.1016235351562\n",
      "epoch 7346\n",
      "test_train\n",
      "train mean loss=0.05552860007931789\n",
      "test_test\n",
      "test mean loss=1159.5027770996094\n",
      "epoch 7347\n",
      "test_train\n",
      "train mean loss=0.05426587350666523\n",
      "test_test\n",
      "test mean loss=1159.5556640625\n",
      "epoch 7348\n",
      "test_train\n",
      "train mean loss=0.05321076698601246\n",
      "test_test\n",
      "test mean loss=1159.1129150390625\n",
      "epoch 7349\n",
      "test_train\n",
      "train mean loss=0.06000560102984309\n",
      "test_test\n",
      "test mean loss=1159.134521484375\n",
      "epoch 7350\n",
      "test_train\n",
      "train mean loss=0.05276110830406348\n",
      "test_test\n",
      "test mean loss=1159.637939453125\n",
      "epoch 7351\n",
      "test_train\n",
      "train mean loss=0.05670053760210673\n",
      "test_test\n",
      "test mean loss=1160.1773071289062\n",
      "epoch 7352\n",
      "test_train\n",
      "train mean loss=0.0571102819715937\n",
      "test_test\n",
      "test mean loss=1158.74853515625\n",
      "epoch 7353\n",
      "test_train\n",
      "train mean loss=0.08044963826735814\n",
      "test_test\n",
      "test mean loss=1160.1897583007812\n",
      "epoch 7354\n",
      "test_train\n",
      "train mean loss=0.06201820758481821\n",
      "test_test\n",
      "test mean loss=1159.4099731445312\n",
      "epoch 7355\n",
      "test_train\n",
      "train mean loss=0.05638654576614499\n",
      "test_test\n",
      "test mean loss=1158.6838989257812\n",
      "epoch 7356\n",
      "test_train\n",
      "train mean loss=0.05395830888301134\n",
      "test_test\n",
      "test mean loss=1158.4447326660156\n",
      "epoch 7357\n",
      "test_train\n",
      "train mean loss=0.0563987308802704\n",
      "test_test\n",
      "test mean loss=1158.4100036621094\n",
      "epoch 7358\n",
      "test_train\n",
      "train mean loss=0.06102430851509174\n",
      "test_test\n",
      "test mean loss=1159.1724853515625\n",
      "epoch 7359\n",
      "test_train\n",
      "train mean loss=0.05475196366508802\n",
      "test_test\n",
      "test mean loss=1158.8563232421875\n",
      "epoch 7360\n",
      "test_train\n",
      "train mean loss=0.05837170189867417\n",
      "test_test\n",
      "test mean loss=1159.4831237792969\n",
      "epoch 7361\n",
      "test_train\n",
      "train mean loss=0.10182839166373014\n",
      "test_test\n",
      "test mean loss=1150.3482666015625\n",
      "epoch 7362\n",
      "test_train\n",
      "train mean loss=0.05147455384333929\n",
      "test_test\n",
      "test mean loss=1158.0042114257812\n",
      "epoch 7363\n",
      "test_train\n",
      "train mean loss=0.05709836445748806\n",
      "test_test\n",
      "test mean loss=1159.6890563964844\n",
      "epoch 7364\n",
      "test_train\n",
      "train mean loss=0.05165015781919161\n",
      "test_test\n",
      "test mean loss=1160.0278930664062\n",
      "epoch 7365\n",
      "test_train\n",
      "train mean loss=0.056874405747900404\n",
      "test_test\n",
      "test mean loss=1159.8388061523438\n",
      "epoch 7366\n",
      "test_train\n",
      "train mean loss=0.057376161217689514\n",
      "test_test\n",
      "test mean loss=1160.1334838867188\n",
      "epoch 7367\n",
      "test_train\n",
      "train mean loss=0.05956571099037925\n",
      "test_test\n",
      "test mean loss=1159.1082763671875\n",
      "epoch 7368\n",
      "test_train\n",
      "train mean loss=0.06049509346485138\n",
      "test_test\n",
      "test mean loss=1159.687255859375\n",
      "epoch 7369\n",
      "test_train\n",
      "train mean loss=0.05654523863146702\n",
      "test_test\n",
      "test mean loss=1158.7840576171875\n",
      "epoch 7370\n",
      "test_train\n",
      "train mean loss=0.05559026294698318\n",
      "test_test\n",
      "test mean loss=1160.38525390625\n",
      "epoch 7371\n",
      "test_train\n",
      "train mean loss=0.05761299810061852\n",
      "test_test\n",
      "test mean loss=1159.3212280273438\n",
      "epoch 7372\n",
      "test_train\n",
      "train mean loss=0.05764881893992424\n",
      "test_test\n",
      "test mean loss=1159.6985473632812\n",
      "epoch 7373\n",
      "test_train\n",
      "train mean loss=0.06592556772132714\n",
      "test_test\n",
      "test mean loss=1160.5551147460938\n",
      "epoch 7374\n",
      "test_train\n",
      "train mean loss=0.05087294057011604\n",
      "test_test\n",
      "test mean loss=1159.7515869140625\n",
      "epoch 7375\n",
      "test_train\n",
      "train mean loss=0.05042364106824001\n",
      "test_test\n",
      "test mean loss=1158.1279296875\n",
      "epoch 7376\n",
      "test_train\n",
      "train mean loss=0.04782146603489915\n",
      "test_test\n",
      "test mean loss=1159.4640502929688\n",
      "epoch 7377\n",
      "test_train\n",
      "train mean loss=0.0590338014687101\n",
      "test_test\n",
      "test mean loss=1160.0538024902344\n",
      "epoch 7378\n",
      "test_train\n",
      "train mean loss=0.05482219718396664\n",
      "test_test\n",
      "test mean loss=1159.244873046875\n",
      "epoch 7379\n",
      "test_train\n",
      "train mean loss=0.06075211055576801\n",
      "test_test\n",
      "test mean loss=1159.6056518554688\n",
      "epoch 7380\n",
      "test_train\n",
      "train mean loss=0.05915140453726053\n",
      "test_test\n",
      "test mean loss=1159.6051635742188\n",
      "epoch 7381\n",
      "test_train\n",
      "train mean loss=0.05557800425837437\n",
      "test_test\n",
      "test mean loss=1159.4338989257812\n",
      "epoch 7382\n",
      "test_train\n",
      "train mean loss=0.059877556593467794\n",
      "test_test\n",
      "test mean loss=1158.4262084960938\n",
      "epoch 7383\n",
      "test_train\n",
      "train mean loss=0.057493627381821476\n",
      "test_test\n",
      "test mean loss=1159.4000244140625\n",
      "epoch 7384\n",
      "test_train\n",
      "train mean loss=0.06480900725970666\n",
      "test_test\n",
      "test mean loss=1159.73876953125\n",
      "epoch 7385\n",
      "test_train\n",
      "train mean loss=0.05138904027019938\n",
      "test_test\n",
      "test mean loss=1159.5361633300781\n",
      "epoch 7386\n",
      "test_train\n",
      "train mean loss=0.05789307116841277\n",
      "test_test\n",
      "test mean loss=1160.0869140625\n",
      "epoch 7387\n",
      "test_train\n",
      "train mean loss=0.05214547381425897\n",
      "test_test\n",
      "test mean loss=1160.3318176269531\n",
      "epoch 7388\n",
      "test_train\n",
      "train mean loss=0.05182090060164531\n",
      "test_test\n",
      "test mean loss=1159.9544677734375\n",
      "epoch 7389\n",
      "test_train\n",
      "train mean loss=0.05457682084913055\n",
      "test_test\n",
      "test mean loss=1158.7408447265625\n",
      "epoch 7390\n",
      "test_train\n",
      "train mean loss=0.05199326792111\n",
      "test_test\n",
      "test mean loss=1158.6259460449219\n",
      "epoch 7391\n",
      "test_train\n",
      "train mean loss=0.06123890463883678\n",
      "test_test\n",
      "test mean loss=1159.4971008300781\n",
      "epoch 7392\n",
      "test_train\n",
      "train mean loss=0.06622218775252502\n",
      "test_test\n",
      "test mean loss=1160.3977661132812\n",
      "epoch 7393\n",
      "test_train\n",
      "train mean loss=0.05919151660054922\n",
      "test_test\n",
      "test mean loss=1160.7162780761719\n",
      "epoch 7394\n",
      "test_train\n",
      "train mean loss=0.06359400724371274\n",
      "test_test\n",
      "test mean loss=1160.4121704101562\n",
      "epoch 7395\n",
      "test_train\n",
      "train mean loss=0.06020964402705431\n",
      "test_test\n",
      "test mean loss=1159.552001953125\n",
      "epoch 7396\n",
      "test_train\n",
      "train mean loss=0.06045111920684576\n",
      "test_test\n",
      "test mean loss=1159.6210327148438\n",
      "epoch 7397\n",
      "test_train\n",
      "train mean loss=0.07007188194741805\n",
      "test_test\n",
      "test mean loss=1160.6740112304688\n",
      "epoch 7398\n",
      "test_train\n",
      "train mean loss=0.06390166205043595\n",
      "test_test\n",
      "test mean loss=1160.3551330566406\n",
      "epoch 7399\n",
      "test_train\n",
      "train mean loss=0.05751814413815737\n",
      "test_test\n",
      "test mean loss=1159.3521728515625\n",
      "epoch 7400\n",
      "test_train\n",
      "train mean loss=0.061936627918233476\n",
      "test_test\n",
      "test mean loss=1159.7318115234375\n",
      "epoch 7401\n",
      "test_train\n",
      "train mean loss=0.06396889748672645\n",
      "test_test\n",
      "test mean loss=1160.9354248046875\n",
      "epoch 7402\n",
      "test_train\n",
      "train mean loss=0.05838540072242419\n",
      "test_test\n",
      "test mean loss=1160.0753173828125\n",
      "epoch 7403\n",
      "test_train\n",
      "train mean loss=0.0539266187697649\n",
      "test_test\n",
      "test mean loss=1159.2200317382812\n",
      "epoch 7404\n",
      "test_train\n",
      "train mean loss=0.06200964624683062\n",
      "test_test\n",
      "test mean loss=1159.5486755371094\n",
      "epoch 7405\n",
      "test_train\n",
      "train mean loss=0.05621379644920429\n",
      "test_test\n",
      "test mean loss=1159.9480285644531\n",
      "epoch 7406\n",
      "test_train\n",
      "train mean loss=0.05883760967602333\n",
      "test_test\n",
      "test mean loss=1159.5590515136719\n",
      "epoch 7407\n",
      "test_train\n",
      "train mean loss=0.05968101772790154\n",
      "test_test\n",
      "test mean loss=1158.8236694335938\n",
      "epoch 7408\n",
      "test_train\n",
      "train mean loss=0.05757414270192385\n",
      "test_test\n",
      "test mean loss=1159.4689331054688\n",
      "epoch 7409\n",
      "test_train\n",
      "train mean loss=0.056396132024625935\n",
      "test_test\n",
      "test mean loss=1159.1586608886719\n",
      "epoch 7410\n",
      "test_train\n",
      "train mean loss=0.057969958521425724\n",
      "test_test\n",
      "test mean loss=1160.1063537597656\n",
      "epoch 7411\n",
      "test_train\n",
      "train mean loss=0.061872600577771664\n",
      "test_test\n",
      "test mean loss=1161.7067260742188\n",
      "epoch 7412\n",
      "test_train\n",
      "train mean loss=0.1113427821546793\n",
      "test_test\n",
      "test mean loss=1156.650390625\n",
      "epoch 7413\n",
      "test_train\n",
      "train mean loss=0.06480839507033427\n",
      "test_test\n",
      "test mean loss=1157.3489074707031\n",
      "epoch 7414\n",
      "test_train\n",
      "train mean loss=0.05448665857935945\n",
      "test_test\n",
      "test mean loss=1158.8827514648438\n",
      "epoch 7415\n",
      "test_train\n",
      "train mean loss=0.05884492831925551\n",
      "test_test\n",
      "test mean loss=1158.6787719726562\n",
      "epoch 7416\n",
      "test_train\n",
      "train mean loss=0.052858163602650166\n",
      "test_test\n",
      "test mean loss=1159.623046875\n",
      "epoch 7417\n",
      "test_train\n",
      "train mean loss=0.054260193991164364\n",
      "test_test\n",
      "test mean loss=1158.8342590332031\n",
      "epoch 7418\n",
      "test_train\n",
      "train mean loss=0.05756126499424378\n",
      "test_test\n",
      "test mean loss=1159.2742919921875\n",
      "epoch 7419\n",
      "test_train\n",
      "train mean loss=0.059244800048569836\n",
      "test_test\n",
      "test mean loss=1158.8303833007812\n",
      "epoch 7420\n",
      "test_train\n",
      "train mean loss=0.05354515245805184\n",
      "test_test\n",
      "test mean loss=1158.7114868164062\n",
      "epoch 7421\n",
      "test_train\n",
      "train mean loss=0.05078651445607344\n",
      "test_test\n",
      "test mean loss=1158.1718139648438\n",
      "epoch 7422\n",
      "test_train\n",
      "train mean loss=0.057352652152379356\n",
      "test_test\n",
      "test mean loss=1159.418212890625\n",
      "epoch 7423\n",
      "test_train\n",
      "train mean loss=0.05857259780168533\n",
      "test_test\n",
      "test mean loss=1160.2456665039062\n",
      "epoch 7424\n",
      "test_train\n",
      "train mean loss=0.05633964637915293\n",
      "test_test\n",
      "test mean loss=1158.1697998046875\n",
      "epoch 7425\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.05847291306902965\n",
      "test_test\n",
      "test mean loss=1159.6708984375\n",
      "epoch 7426\n",
      "test_train\n",
      "train mean loss=0.05881234739596645\n",
      "test_test\n",
      "test mean loss=1160.2011413574219\n",
      "epoch 7427\n",
      "test_train\n",
      "train mean loss=0.057661996533473335\n",
      "test_test\n",
      "test mean loss=1159.6868896484375\n",
      "epoch 7428\n",
      "test_train\n",
      "train mean loss=0.0534635546306769\n",
      "test_test\n",
      "test mean loss=1158.8353881835938\n",
      "epoch 7429\n",
      "test_train\n",
      "train mean loss=0.0575787586470445\n",
      "test_test\n",
      "test mean loss=1160.6363830566406\n",
      "epoch 7430\n",
      "test_train\n",
      "train mean loss=0.0550950588658452\n",
      "test_test\n",
      "test mean loss=1160.3338623046875\n",
      "epoch 7431\n",
      "test_train\n",
      "train mean loss=0.058295767133434616\n",
      "test_test\n",
      "test mean loss=1160.4666442871094\n",
      "epoch 7432\n",
      "test_train\n",
      "train mean loss=0.058472190983593464\n",
      "test_test\n",
      "test mean loss=1160.449462890625\n",
      "epoch 7433\n",
      "test_train\n",
      "train mean loss=0.057672146086891495\n",
      "test_test\n",
      "test mean loss=1159.8740844726562\n",
      "epoch 7434\n",
      "test_train\n",
      "train mean loss=0.05472669377923012\n",
      "test_test\n",
      "test mean loss=1159.7743530273438\n",
      "epoch 7435\n",
      "test_train\n",
      "train mean loss=0.055758487743635975\n",
      "test_test\n",
      "test mean loss=1159.109375\n",
      "epoch 7436\n",
      "test_train\n",
      "train mean loss=0.05148600973188877\n",
      "test_test\n",
      "test mean loss=1159.0621948242188\n",
      "epoch 7437\n",
      "test_train\n",
      "train mean loss=0.05593231972306967\n",
      "test_test\n",
      "test mean loss=1159.7831726074219\n",
      "epoch 7438\n",
      "test_train\n",
      "train mean loss=0.05580151050041119\n",
      "test_test\n",
      "test mean loss=1159.646240234375\n",
      "epoch 7439\n",
      "test_train\n",
      "train mean loss=0.054123908281326294\n",
      "test_test\n",
      "test mean loss=1159.5277099609375\n",
      "epoch 7440\n",
      "test_train\n",
      "train mean loss=0.05443138939638933\n",
      "test_test\n",
      "test mean loss=1159.296875\n",
      "epoch 7441\n",
      "test_train\n",
      "train mean loss=0.04992855650683244\n",
      "test_test\n",
      "test mean loss=1158.9717712402344\n",
      "epoch 7442\n",
      "test_train\n",
      "train mean loss=0.06026845828940471\n",
      "test_test\n",
      "test mean loss=1158.3429260253906\n",
      "epoch 7443\n",
      "test_train\n",
      "train mean loss=0.05438048640886942\n",
      "test_test\n",
      "test mean loss=1159.2328796386719\n",
      "epoch 7444\n",
      "test_train\n",
      "train mean loss=0.11003620425860088\n",
      "test_test\n",
      "test mean loss=1158.3328247070312\n",
      "epoch 7445\n",
      "test_train\n",
      "train mean loss=0.06535537199427684\n",
      "test_test\n",
      "test mean loss=1158.6799926757812\n",
      "epoch 7446\n",
      "test_train\n",
      "train mean loss=0.054252661454180874\n",
      "test_test\n",
      "test mean loss=1157.8892822265625\n",
      "epoch 7447\n",
      "test_train\n",
      "train mean loss=0.054353623961408935\n",
      "test_test\n",
      "test mean loss=1158.5980224609375\n",
      "epoch 7448\n",
      "test_train\n",
      "train mean loss=0.056822268292307854\n",
      "test_test\n",
      "test mean loss=1159.1940307617188\n",
      "epoch 7449\n",
      "test_train\n",
      "train mean loss=0.05161531254028281\n",
      "test_test\n",
      "test mean loss=1157.792236328125\n",
      "epoch 7450\n",
      "test_train\n",
      "train mean loss=0.07345862748722236\n",
      "test_test\n",
      "test mean loss=1157.8883666992188\n",
      "epoch 7451\n",
      "test_train\n",
      "train mean loss=0.0632621565212806\n",
      "test_test\n",
      "test mean loss=1159.362548828125\n",
      "epoch 7452\n",
      "test_train\n",
      "train mean loss=0.05769467322776715\n",
      "test_test\n",
      "test mean loss=1158.8496398925781\n",
      "epoch 7453\n",
      "test_train\n",
      "train mean loss=0.04978298023343086\n",
      "test_test\n",
      "test mean loss=1158.2731323242188\n",
      "epoch 7454\n",
      "test_train\n",
      "train mean loss=0.05077361067136129\n",
      "test_test\n",
      "test mean loss=1158.4248046875\n",
      "epoch 7455\n",
      "test_train\n",
      "train mean loss=0.052179795068999134\n",
      "test_test\n",
      "test mean loss=1159.2545776367188\n",
      "epoch 7456\n",
      "test_train\n",
      "train mean loss=0.06300110090523958\n",
      "test_test\n",
      "test mean loss=1159.1018676757812\n",
      "epoch 7457\n",
      "test_train\n",
      "train mean loss=0.058310156998535\n",
      "test_test\n",
      "test mean loss=1159.2948608398438\n",
      "epoch 7458\n",
      "test_train\n",
      "train mean loss=0.11722859119375546\n",
      "test_test\n",
      "test mean loss=1153.9295654296875\n",
      "epoch 7459\n",
      "test_train\n",
      "train mean loss=0.055792316483954586\n",
      "test_test\n",
      "test mean loss=1158.7699584960938\n",
      "epoch 7460\n",
      "test_train\n",
      "train mean loss=0.05662335983167092\n",
      "test_test\n",
      "test mean loss=1159.3092041015625\n",
      "epoch 7461\n",
      "test_train\n",
      "train mean loss=0.06151563612123331\n",
      "test_test\n",
      "test mean loss=1158.6856994628906\n",
      "epoch 7462\n",
      "test_train\n",
      "train mean loss=0.06156751917054256\n",
      "test_test\n",
      "test mean loss=1158.9723205566406\n",
      "epoch 7463\n",
      "test_train\n",
      "train mean loss=0.058352578120927014\n",
      "test_test\n",
      "test mean loss=1159.1273498535156\n",
      "epoch 7464\n",
      "test_train\n",
      "train mean loss=0.05577628624935945\n",
      "test_test\n",
      "test mean loss=1159.377197265625\n",
      "epoch 7465\n",
      "test_train\n",
      "train mean loss=0.06107824373369416\n",
      "test_test\n",
      "test mean loss=1159.9171142578125\n",
      "epoch 7466\n",
      "test_train\n",
      "train mean loss=0.06032008957117796\n",
      "test_test\n",
      "test mean loss=1159.5593872070312\n",
      "epoch 7467\n",
      "test_train\n",
      "train mean loss=0.0587589576219519\n",
      "test_test\n",
      "test mean loss=1157.882568359375\n",
      "epoch 7468\n",
      "test_train\n",
      "train mean loss=0.0571013605222106\n",
      "test_test\n",
      "test mean loss=1157.9000854492188\n",
      "epoch 7469\n",
      "test_train\n",
      "train mean loss=0.06241429535051187\n",
      "test_test\n",
      "test mean loss=1159.8083801269531\n",
      "epoch 7470\n",
      "test_train\n",
      "train mean loss=0.05589100377013286\n",
      "test_test\n",
      "test mean loss=1159.2959899902344\n",
      "epoch 7471\n",
      "test_train\n",
      "train mean loss=0.06838981496791045\n",
      "test_test\n",
      "test mean loss=1159.5637512207031\n",
      "epoch 7472\n",
      "test_train\n",
      "train mean loss=0.0701699663574497\n",
      "test_test\n",
      "test mean loss=1157.697021484375\n",
      "epoch 7473\n",
      "test_train\n",
      "train mean loss=0.053977412171661854\n",
      "test_test\n",
      "test mean loss=1159.0433654785156\n",
      "epoch 7474\n",
      "test_train\n",
      "train mean loss=0.0525991457204024\n",
      "test_test\n",
      "test mean loss=1159.4577941894531\n",
      "epoch 7475\n",
      "test_train\n",
      "train mean loss=0.051786367315799\n",
      "test_test\n",
      "test mean loss=1160.5859375\n",
      "epoch 7476\n",
      "test_train\n",
      "train mean loss=0.1004088344052434\n",
      "test_test\n",
      "test mean loss=1160.5211791992188\n",
      "epoch 7477\n",
      "test_train\n",
      "train mean loss=0.06678616876403491\n",
      "test_test\n",
      "test mean loss=1159.8363342285156\n",
      "epoch 7478\n",
      "test_train\n",
      "train mean loss=0.05462726547072331\n",
      "test_test\n",
      "test mean loss=1159.0545654296875\n",
      "epoch 7479\n",
      "test_train\n",
      "train mean loss=0.06390353230138619\n",
      "test_test\n",
      "test mean loss=1160.666259765625\n",
      "epoch 7480\n",
      "test_train\n",
      "train mean loss=0.059985531494021416\n",
      "test_test\n",
      "test mean loss=1160.60009765625\n",
      "epoch 7481\n",
      "test_train\n",
      "train mean loss=0.056872446555644274\n",
      "test_test\n",
      "test mean loss=1159.8638305664062\n",
      "epoch 7482\n",
      "test_train\n",
      "train mean loss=0.055839300621300936\n",
      "test_test\n",
      "test mean loss=1160.1004638671875\n",
      "epoch 7483\n",
      "test_train\n",
      "train mean loss=0.057477932733794056\n",
      "test_test\n",
      "test mean loss=1160.0120849609375\n",
      "epoch 7484\n",
      "test_train\n",
      "train mean loss=0.05410443991422653\n",
      "test_test\n",
      "test mean loss=1161.3161010742188\n",
      "epoch 7485\n",
      "test_train\n",
      "train mean loss=0.06018194711456696\n",
      "test_test\n",
      "test mean loss=1160.1641845703125\n",
      "epoch 7486\n",
      "test_train\n",
      "train mean loss=0.057726433811088405\n",
      "test_test\n",
      "test mean loss=1159.4399108886719\n",
      "epoch 7487\n",
      "test_train\n",
      "train mean loss=0.05013140135755142\n",
      "test_test\n",
      "test mean loss=1159.3508911132812\n",
      "epoch 7488\n",
      "test_train\n",
      "train mean loss=0.05749391609181961\n",
      "test_test\n",
      "test mean loss=1160.5165710449219\n",
      "epoch 7489\n",
      "test_train\n",
      "train mean loss=0.05506121522436539\n",
      "test_test\n",
      "test mean loss=1159.2534790039062\n",
      "epoch 7490\n",
      "test_train\n",
      "train mean loss=0.05439272476360202\n",
      "test_test\n",
      "test mean loss=1160.0556640625\n",
      "epoch 7491\n",
      "test_train\n",
      "train mean loss=0.05653588970502218\n",
      "test_test\n",
      "test mean loss=1160.672607421875\n",
      "epoch 7492\n",
      "test_train\n",
      "train mean loss=0.05843343989302715\n",
      "test_test\n",
      "test mean loss=1159.5299072265625\n",
      "epoch 7493\n",
      "test_train\n",
      "train mean loss=0.05068072831879059\n",
      "test_test\n",
      "test mean loss=1160.0601196289062\n",
      "epoch 7494\n",
      "test_train\n",
      "train mean loss=0.05410047868887583\n",
      "test_test\n",
      "test mean loss=1160.2010192871094\n",
      "epoch 7495\n",
      "test_train\n",
      "train mean loss=0.05599985830485821\n",
      "test_test\n",
      "test mean loss=1160.4253234863281\n",
      "epoch 7496\n",
      "test_train\n",
      "train mean loss=0.059537604451179504\n",
      "test_test\n",
      "test mean loss=1161.6466979980469\n",
      "epoch 7497\n",
      "test_train\n",
      "train mean loss=0.06395920428136985\n",
      "test_test\n",
      "test mean loss=1160.6336975097656\n",
      "epoch 7498\n",
      "test_train\n",
      "train mean loss=0.061140016031761966\n",
      "test_test\n",
      "test mean loss=1161.1997680664062\n",
      "epoch 7499\n",
      "test_train\n",
      "train mean loss=0.05438634132345518\n",
      "test_test\n",
      "test mean loss=1160.3552856445312\n",
      "epoch 7500\n",
      "test_train\n",
      "train mean loss=0.054124931494394936\n",
      "test_test\n",
      "test mean loss=1160.7864074707031\n",
      "epoch 7501\n",
      "test_train\n",
      "train mean loss=0.055613781635959945\n",
      "test_test\n",
      "test mean loss=1160.1241760253906\n",
      "epoch 7502\n",
      "test_train\n",
      "train mean loss=0.06401562349249919\n",
      "test_test\n",
      "test mean loss=1160.9280395507812\n",
      "epoch 7503\n",
      "test_train\n",
      "train mean loss=0.06923071605463822\n",
      "test_test\n",
      "test mean loss=1159.8474426269531\n",
      "epoch 7504\n",
      "test_train\n",
      "train mean loss=0.059918174209694065\n",
      "test_test\n",
      "test mean loss=1161.0590209960938\n",
      "epoch 7505\n",
      "test_train\n",
      "train mean loss=0.06679925881326199\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1161.2866821289062\n",
      "epoch 7506\n",
      "test_train\n",
      "train mean loss=0.06008663090566794\n",
      "test_test\n",
      "test mean loss=1160.9276733398438\n",
      "epoch 7507\n",
      "test_train\n",
      "train mean loss=0.0524122160859406\n",
      "test_test\n",
      "test mean loss=1161.7135620117188\n",
      "epoch 7508\n",
      "test_train\n",
      "train mean loss=0.05190408912797769\n",
      "test_test\n",
      "test mean loss=1160.31787109375\n",
      "epoch 7509\n",
      "test_train\n",
      "train mean loss=0.05826452591766914\n",
      "test_test\n",
      "test mean loss=1160.3477172851562\n",
      "epoch 7510\n",
      "test_train\n",
      "train mean loss=0.05590091459453106\n",
      "test_test\n",
      "test mean loss=1160.266845703125\n",
      "epoch 7511\n",
      "test_train\n",
      "train mean loss=0.05644708592444658\n",
      "test_test\n",
      "test mean loss=1159.2200317382812\n",
      "epoch 7512\n",
      "test_train\n",
      "train mean loss=0.06417600406954686\n",
      "test_test\n",
      "test mean loss=1160.84228515625\n",
      "epoch 7513\n",
      "test_train\n",
      "train mean loss=0.053594087871412434\n",
      "test_test\n",
      "test mean loss=1159.13818359375\n",
      "epoch 7514\n",
      "test_train\n",
      "train mean loss=0.0564383544648687\n",
      "test_test\n",
      "test mean loss=1160.4952392578125\n",
      "epoch 7515\n",
      "test_train\n",
      "train mean loss=0.05971120561783513\n",
      "test_test\n",
      "test mean loss=1159.4939575195312\n",
      "epoch 7516\n",
      "test_train\n",
      "train mean loss=0.05201344688733419\n",
      "test_test\n",
      "test mean loss=1160.087646484375\n",
      "epoch 7517\n",
      "test_train\n",
      "train mean loss=0.05606346887846788\n",
      "test_test\n",
      "test mean loss=1160.3239135742188\n",
      "epoch 7518\n",
      "test_train\n",
      "train mean loss=0.057529953929285206\n",
      "test_test\n",
      "test mean loss=1159.7523498535156\n",
      "epoch 7519\n",
      "test_train\n",
      "train mean loss=0.052565629283587136\n",
      "test_test\n",
      "test mean loss=1159.6760559082031\n",
      "epoch 7520\n",
      "test_train\n",
      "train mean loss=0.056378171468774475\n",
      "test_test\n",
      "test mean loss=1160.6194458007812\n",
      "epoch 7521\n",
      "test_train\n",
      "train mean loss=0.05013776244595647\n",
      "test_test\n",
      "test mean loss=1159.7923583984375\n",
      "epoch 7522\n",
      "test_train\n",
      "train mean loss=0.051444862658778824\n",
      "test_test\n",
      "test mean loss=1159.9432067871094\n",
      "epoch 7523\n",
      "test_train\n",
      "train mean loss=0.05733069187651078\n",
      "test_test\n",
      "test mean loss=1160.1336059570312\n",
      "epoch 7524\n",
      "test_train\n",
      "train mean loss=0.05957224344213804\n",
      "test_test\n",
      "test mean loss=1160.1438598632812\n",
      "epoch 7525\n",
      "test_train\n",
      "train mean loss=0.057456490894158684\n",
      "test_test\n",
      "test mean loss=1158.8388061523438\n",
      "epoch 7526\n",
      "test_train\n",
      "train mean loss=0.05572397789607445\n",
      "test_test\n",
      "test mean loss=1159.9442138671875\n",
      "epoch 7527\n",
      "test_train\n",
      "train mean loss=0.054862311420341335\n",
      "test_test\n",
      "test mean loss=1159.6737365722656\n",
      "epoch 7528\n",
      "test_train\n",
      "train mean loss=0.0950974514707923\n",
      "test_test\n",
      "test mean loss=1154.3739929199219\n",
      "epoch 7529\n",
      "test_train\n",
      "train mean loss=0.06075611524283886\n",
      "test_test\n",
      "test mean loss=1159.0098876953125\n",
      "epoch 7530\n",
      "test_train\n",
      "train mean loss=0.054218474930773176\n",
      "test_test\n",
      "test mean loss=1159.787841796875\n",
      "epoch 7531\n",
      "test_train\n",
      "train mean loss=0.0621369918808341\n",
      "test_test\n",
      "test mean loss=1159.9959411621094\n",
      "epoch 7532\n",
      "test_train\n",
      "train mean loss=0.0548596785714229\n",
      "test_test\n",
      "test mean loss=1160.3031921386719\n",
      "epoch 7533\n",
      "test_train\n",
      "train mean loss=0.06014677323400974\n",
      "test_test\n",
      "test mean loss=1159.6612548828125\n",
      "epoch 7534\n",
      "test_train\n",
      "train mean loss=0.05711568767825762\n",
      "test_test\n",
      "test mean loss=1159.2566528320312\n",
      "epoch 7535\n",
      "test_train\n",
      "train mean loss=0.06691732723265886\n",
      "test_test\n",
      "test mean loss=1160.8970947265625\n",
      "epoch 7536\n",
      "test_train\n",
      "train mean loss=0.05773627789070209\n",
      "test_test\n",
      "test mean loss=1159.4274597167969\n",
      "epoch 7537\n",
      "test_train\n",
      "train mean loss=0.05877821845933795\n",
      "test_test\n",
      "test mean loss=1159.1136474609375\n",
      "epoch 7538\n",
      "test_train\n",
      "train mean loss=0.05568829116721948\n",
      "test_test\n",
      "test mean loss=1158.6796875\n",
      "epoch 7539\n",
      "test_train\n",
      "train mean loss=0.05245231480027238\n",
      "test_test\n",
      "test mean loss=1159.3357238769531\n",
      "epoch 7540\n",
      "test_train\n",
      "train mean loss=0.0546170457576712\n",
      "test_test\n",
      "test mean loss=1159.4355163574219\n",
      "epoch 7541\n",
      "test_train\n",
      "train mean loss=0.05449401307851076\n",
      "test_test\n",
      "test mean loss=1159.1289672851562\n",
      "epoch 7542\n",
      "test_train\n",
      "train mean loss=0.05587845823417107\n",
      "test_test\n",
      "test mean loss=1159.6047973632812\n",
      "epoch 7543\n",
      "test_train\n",
      "train mean loss=0.06064653225863973\n",
      "test_test\n",
      "test mean loss=1159.9400024414062\n",
      "epoch 7544\n",
      "test_train\n",
      "train mean loss=0.0559145330140988\n",
      "test_test\n",
      "test mean loss=1157.773193359375\n",
      "epoch 7545\n",
      "test_train\n",
      "train mean loss=0.052773892879486084\n",
      "test_test\n",
      "test mean loss=1158.84521484375\n",
      "epoch 7546\n",
      "test_train\n",
      "train mean loss=0.054965803399682045\n",
      "test_test\n",
      "test mean loss=1159.8070068359375\n",
      "epoch 7547\n",
      "test_train\n",
      "train mean loss=0.05141873378306627\n",
      "test_test\n",
      "test mean loss=1160.0466918945312\n",
      "epoch 7548\n",
      "test_train\n",
      "train mean loss=0.06122653838247061\n",
      "test_test\n",
      "test mean loss=1160.6947937011719\n",
      "epoch 7549\n",
      "test_train\n",
      "train mean loss=0.05433720598618189\n",
      "test_test\n",
      "test mean loss=1160.0526123046875\n",
      "epoch 7550\n",
      "test_train\n",
      "train mean loss=0.04868205341820916\n",
      "test_test\n",
      "test mean loss=1158.7902221679688\n",
      "epoch 7551\n",
      "test_train\n",
      "train mean loss=0.05756841010103623\n",
      "test_test\n",
      "test mean loss=1160.06640625\n",
      "epoch 7552\n",
      "test_train\n",
      "train mean loss=0.05906824457148711\n",
      "test_test\n",
      "test mean loss=1160.7398681640625\n",
      "epoch 7553\n",
      "test_train\n",
      "train mean loss=0.05456127738580108\n",
      "test_test\n",
      "test mean loss=1160.314453125\n",
      "epoch 7554\n",
      "test_train\n",
      "train mean loss=0.05207312091564139\n",
      "test_test\n",
      "test mean loss=1159.6090087890625\n",
      "epoch 7555\n",
      "test_train\n",
      "train mean loss=0.05532565247267485\n",
      "test_test\n",
      "test mean loss=1159.6537170410156\n",
      "epoch 7556\n",
      "test_train\n",
      "train mean loss=0.057615562342107296\n",
      "test_test\n",
      "test mean loss=1159.8546142578125\n",
      "epoch 7557\n",
      "test_train\n",
      "train mean loss=0.05495026179899772\n",
      "test_test\n",
      "test mean loss=1160.0389404296875\n",
      "epoch 7558\n",
      "test_train\n",
      "train mean loss=0.059720767041047416\n",
      "test_test\n",
      "test mean loss=1159.2900390625\n",
      "epoch 7559\n",
      "test_train\n",
      "train mean loss=0.06163855890432993\n",
      "test_test\n",
      "test mean loss=1158.776123046875\n",
      "epoch 7560\n",
      "test_train\n",
      "train mean loss=0.05636145360767841\n",
      "test_test\n",
      "test mean loss=1160.2877807617188\n",
      "epoch 7561\n",
      "test_train\n",
      "train mean loss=0.05960294914742311\n",
      "test_test\n",
      "test mean loss=1160.1114501953125\n",
      "epoch 7562\n",
      "test_train\n",
      "train mean loss=0.060061549146970115\n",
      "test_test\n",
      "test mean loss=1160.4349975585938\n",
      "epoch 7563\n",
      "test_train\n",
      "train mean loss=0.05613633679846922\n",
      "test_test\n",
      "test mean loss=1159.7601318359375\n",
      "epoch 7564\n",
      "test_train\n",
      "train mean loss=0.05265475995838642\n",
      "test_test\n",
      "test mean loss=1160.2496948242188\n",
      "epoch 7565\n",
      "test_train\n",
      "train mean loss=0.05448953714221716\n",
      "test_test\n",
      "test mean loss=1161.15234375\n",
      "epoch 7566\n",
      "test_train\n",
      "train mean loss=0.04600001002351443\n",
      "test_test\n",
      "test mean loss=1158.9192199707031\n",
      "epoch 7567\n",
      "test_train\n",
      "train mean loss=0.06041724265863498\n",
      "test_test\n",
      "test mean loss=1161.6430053710938\n",
      "epoch 7568\n",
      "test_train\n",
      "train mean loss=0.051737782234946884\n",
      "test_test\n",
      "test mean loss=1160.6816101074219\n",
      "epoch 7569\n",
      "test_train\n",
      "train mean loss=0.0527004882072409\n",
      "test_test\n",
      "test mean loss=1160.8839111328125\n",
      "epoch 7570\n",
      "test_train\n",
      "train mean loss=0.053734047804027796\n",
      "test_test\n",
      "test mean loss=1159.8772583007812\n",
      "epoch 7571\n",
      "test_train\n",
      "train mean loss=0.05882410332560539\n",
      "test_test\n",
      "test mean loss=1160.1699523925781\n",
      "epoch 7572\n",
      "test_train\n",
      "train mean loss=0.05796876922249794\n",
      "test_test\n",
      "test mean loss=1159.9173583984375\n",
      "epoch 7573\n",
      "test_train\n",
      "train mean loss=0.054453879594802856\n",
      "test_test\n",
      "test mean loss=1159.8462524414062\n",
      "epoch 7574\n",
      "test_train\n",
      "train mean loss=0.1684621199965477\n",
      "test_test\n",
      "test mean loss=1160.7349243164062\n",
      "epoch 7575\n",
      "test_train\n",
      "train mean loss=0.06022344964245955\n",
      "test_test\n",
      "test mean loss=1160.2637329101562\n",
      "epoch 7576\n",
      "test_train\n",
      "train mean loss=0.055324192779759564\n",
      "test_test\n",
      "test mean loss=1161.0795593261719\n",
      "epoch 7577\n",
      "test_train\n",
      "train mean loss=0.060634867288172245\n",
      "test_test\n",
      "test mean loss=1160.8017578125\n",
      "epoch 7578\n",
      "test_train\n",
      "train mean loss=0.05791453722243508\n",
      "test_test\n",
      "test mean loss=1161.4648132324219\n",
      "epoch 7579\n",
      "test_train\n",
      "train mean loss=0.05563804383079211\n",
      "test_test\n",
      "test mean loss=1160.3517456054688\n",
      "epoch 7580\n",
      "test_train\n",
      "train mean loss=0.05864419415593147\n",
      "test_test\n",
      "test mean loss=1160.4419555664062\n",
      "epoch 7581\n",
      "test_train\n",
      "train mean loss=0.06661780613164107\n",
      "test_test\n",
      "test mean loss=1161.720703125\n",
      "epoch 7582\n",
      "test_train\n",
      "train mean loss=0.06001445557922125\n",
      "test_test\n",
      "test mean loss=1161.2608642578125\n",
      "epoch 7583\n",
      "test_train\n",
      "train mean loss=0.054988518357276917\n",
      "test_test\n",
      "test mean loss=1160.6131591796875\n",
      "epoch 7584\n",
      "test_train\n",
      "train mean loss=0.050568586215376854\n",
      "test_test\n",
      "test mean loss=1159.9347534179688\n",
      "epoch 7585\n",
      "test_train\n",
      "train mean loss=0.0588832131276528\n",
      "test_test\n",
      "test mean loss=1159.7832641601562\n",
      "epoch 7586\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.06490029549847047\n",
      "test_test\n",
      "test mean loss=1159.0963745117188\n",
      "epoch 7587\n",
      "test_train\n",
      "train mean loss=0.05810619487116734\n",
      "test_test\n",
      "test mean loss=1160.1042175292969\n",
      "epoch 7588\n",
      "test_train\n",
      "train mean loss=0.059394481436659895\n",
      "test_test\n",
      "test mean loss=1160.657470703125\n",
      "epoch 7589\n",
      "test_train\n",
      "train mean loss=0.058331651302675404\n",
      "test_test\n",
      "test mean loss=1160.7630920410156\n",
      "epoch 7590\n",
      "test_train\n",
      "train mean loss=0.060288486536592245\n",
      "test_test\n",
      "test mean loss=1160.6874389648438\n",
      "epoch 7591\n",
      "test_train\n",
      "train mean loss=0.05384307820349932\n",
      "test_test\n",
      "test mean loss=1160.1344604492188\n",
      "epoch 7592\n",
      "test_train\n",
      "train mean loss=0.054904176853597164\n",
      "test_test\n",
      "test mean loss=1159.9635925292969\n",
      "epoch 7593\n",
      "test_train\n",
      "train mean loss=0.04671567523231109\n",
      "test_test\n",
      "test mean loss=1159.583984375\n",
      "epoch 7594\n",
      "test_train\n",
      "train mean loss=0.05750487341235081\n",
      "test_test\n",
      "test mean loss=1159.88134765625\n",
      "epoch 7595\n",
      "test_train\n",
      "train mean loss=0.05452513306712111\n",
      "test_test\n",
      "test mean loss=1160.2998657226562\n",
      "epoch 7596\n",
      "test_train\n",
      "train mean loss=0.04815497047578295\n",
      "test_test\n",
      "test mean loss=1159.908447265625\n",
      "epoch 7597\n",
      "test_train\n",
      "train mean loss=0.05681890621781349\n",
      "test_test\n",
      "test mean loss=1161.462646484375\n",
      "epoch 7598\n",
      "test_train\n",
      "train mean loss=0.0560319380213817\n",
      "test_test\n",
      "test mean loss=1161.0115356445312\n",
      "epoch 7599\n",
      "test_train\n",
      "train mean loss=0.06079533246035377\n",
      "test_test\n",
      "test mean loss=1160.7937622070312\n",
      "epoch 7600\n",
      "test_train\n",
      "train mean loss=0.05741408482814828\n",
      "test_test\n",
      "test mean loss=1159.6807250976562\n",
      "epoch 7601\n",
      "test_train\n",
      "train mean loss=0.05780392357458671\n",
      "test_test\n",
      "test mean loss=1159.2058715820312\n",
      "epoch 7602\n",
      "test_train\n",
      "train mean loss=0.051600737031549215\n",
      "test_test\n",
      "test mean loss=1160.2758178710938\n",
      "epoch 7603\n",
      "test_train\n",
      "train mean loss=0.129055538525184\n",
      "test_test\n",
      "test mean loss=1161.2252197265625\n",
      "epoch 7604\n",
      "test_train\n",
      "train mean loss=0.05392954653749863\n",
      "test_test\n",
      "test mean loss=1160.275390625\n",
      "epoch 7605\n",
      "test_train\n",
      "train mean loss=0.057493540458381176\n",
      "test_test\n",
      "test mean loss=1160.8959045410156\n",
      "epoch 7606\n",
      "test_train\n",
      "train mean loss=0.0595361969123284\n",
      "test_test\n",
      "test mean loss=1161.0541381835938\n",
      "epoch 7607\n",
      "test_train\n",
      "train mean loss=0.049009914665172495\n",
      "test_test\n",
      "test mean loss=1160.6392822265625\n",
      "epoch 7608\n",
      "test_train\n",
      "train mean loss=0.0633730050176382\n",
      "test_test\n",
      "test mean loss=1160.8122863769531\n",
      "epoch 7609\n",
      "test_train\n",
      "train mean loss=0.057180860079824924\n",
      "test_test\n",
      "test mean loss=1161.2765808105469\n",
      "epoch 7610\n",
      "test_train\n",
      "train mean loss=0.055278241323928036\n",
      "test_test\n",
      "test mean loss=1160.8905029296875\n",
      "epoch 7611\n",
      "test_train\n",
      "train mean loss=0.053875584776202835\n",
      "test_test\n",
      "test mean loss=1161.1378784179688\n",
      "epoch 7612\n",
      "test_train\n",
      "train mean loss=0.06022823229432106\n",
      "test_test\n",
      "test mean loss=1160.6417541503906\n",
      "epoch 7613\n",
      "test_train\n",
      "train mean loss=0.06656855810433626\n",
      "test_test\n",
      "test mean loss=1159.7661743164062\n",
      "epoch 7614\n",
      "test_train\n",
      "train mean loss=0.06069192895665765\n",
      "test_test\n",
      "test mean loss=1159.5887145996094\n",
      "epoch 7615\n",
      "test_train\n",
      "train mean loss=0.05574780826767286\n",
      "test_test\n",
      "test mean loss=1160.3954467773438\n",
      "epoch 7616\n",
      "test_train\n",
      "train mean loss=0.06381872948259115\n",
      "test_test\n",
      "test mean loss=1160.1962890625\n",
      "epoch 7617\n",
      "test_train\n",
      "train mean loss=0.05860432516783476\n",
      "test_test\n",
      "test mean loss=1160.3526611328125\n",
      "epoch 7618\n",
      "test_train\n",
      "train mean loss=0.058664070131878056\n",
      "test_test\n",
      "test mean loss=1160.3932189941406\n",
      "epoch 7619\n",
      "test_train\n",
      "train mean loss=0.05627383664250374\n",
      "test_test\n",
      "test mean loss=1159.556396484375\n",
      "epoch 7620\n",
      "test_train\n",
      "train mean loss=0.060572169721126556\n",
      "test_test\n",
      "test mean loss=1161.1650390625\n",
      "epoch 7621\n",
      "test_train\n",
      "train mean loss=0.059611902882655464\n",
      "test_test\n",
      "test mean loss=1160.8353576660156\n",
      "epoch 7622\n",
      "test_train\n",
      "train mean loss=0.06940047380824883\n",
      "test_test\n",
      "test mean loss=1163.3009643554688\n",
      "epoch 7623\n",
      "test_train\n",
      "train mean loss=0.05764208392550548\n",
      "test_test\n",
      "test mean loss=1160.7688598632812\n",
      "epoch 7624\n",
      "test_train\n",
      "train mean loss=0.05676535734285911\n",
      "test_test\n",
      "test mean loss=1160.469970703125\n",
      "epoch 7625\n",
      "test_train\n",
      "train mean loss=0.05815774636964003\n",
      "test_test\n",
      "test mean loss=1160.6385498046875\n",
      "epoch 7626\n",
      "test_train\n",
      "train mean loss=0.05678985516230265\n",
      "test_test\n",
      "test mean loss=1159.5704345703125\n",
      "epoch 7627\n",
      "test_train\n",
      "train mean loss=0.06069495559980472\n",
      "test_test\n",
      "test mean loss=1161.9248046875\n",
      "epoch 7628\n",
      "test_train\n",
      "train mean loss=0.058270796202123165\n",
      "test_test\n",
      "test mean loss=1160.4434814453125\n",
      "epoch 7629\n",
      "test_train\n",
      "train mean loss=0.05198539483050505\n",
      "test_test\n",
      "test mean loss=1159.8987731933594\n",
      "epoch 7630\n",
      "test_train\n",
      "train mean loss=0.052891060089071594\n",
      "test_test\n",
      "test mean loss=1161.4287109375\n",
      "epoch 7631\n",
      "test_train\n",
      "train mean loss=0.05379344988614321\n",
      "test_test\n",
      "test mean loss=1160.4731140136719\n",
      "epoch 7632\n",
      "test_train\n",
      "train mean loss=0.0569272938494881\n",
      "test_test\n",
      "test mean loss=1160.3058776855469\n",
      "epoch 7633\n",
      "test_train\n",
      "train mean loss=0.0599296847358346\n",
      "test_test\n",
      "test mean loss=1162.0054321289062\n",
      "epoch 7634\n",
      "test_train\n",
      "train mean loss=0.05519384207824866\n",
      "test_test\n",
      "test mean loss=1160.8785095214844\n",
      "epoch 7635\n",
      "test_train\n",
      "train mean loss=0.04994404471168915\n",
      "test_test\n",
      "test mean loss=1160.9236450195312\n",
      "epoch 7636\n",
      "test_train\n",
      "train mean loss=0.05302143904070059\n",
      "test_test\n",
      "test mean loss=1161.17431640625\n",
      "epoch 7637\n",
      "test_train\n",
      "train mean loss=0.06003565372278293\n",
      "test_test\n",
      "test mean loss=1161.3379516601562\n",
      "epoch 7638\n",
      "test_train\n",
      "train mean loss=0.05646340362727642\n",
      "test_test\n",
      "test mean loss=1160.55517578125\n",
      "epoch 7639\n",
      "test_train\n",
      "train mean loss=0.05122970106701056\n",
      "test_test\n",
      "test mean loss=1159.6661987304688\n",
      "epoch 7640\n",
      "test_train\n",
      "train mean loss=0.06481125329931577\n",
      "test_test\n",
      "test mean loss=1162.0454711914062\n",
      "epoch 7641\n",
      "test_train\n",
      "train mean loss=0.05992617178708315\n",
      "test_test\n",
      "test mean loss=1161.0712890625\n",
      "epoch 7642\n",
      "test_train\n",
      "train mean loss=0.05506737592319647\n",
      "test_test\n",
      "test mean loss=1162.086669921875\n",
      "epoch 7643\n",
      "test_train\n",
      "train mean loss=0.05583487171679735\n",
      "test_test\n",
      "test mean loss=1161.4102783203125\n",
      "epoch 7644\n",
      "test_train\n",
      "train mean loss=0.05729069281369448\n",
      "test_test\n",
      "test mean loss=1161.6535339355469\n",
      "epoch 7645\n",
      "test_train\n",
      "train mean loss=0.05581485169629256\n",
      "test_test\n",
      "test mean loss=1160.9566650390625\n",
      "epoch 7646\n",
      "test_train\n",
      "train mean loss=0.06254952835539977\n",
      "test_test\n",
      "test mean loss=1161.970703125\n",
      "epoch 7647\n",
      "test_train\n",
      "train mean loss=0.060260381549596786\n",
      "test_test\n",
      "test mean loss=1161.9365844726562\n",
      "epoch 7648\n",
      "test_train\n",
      "train mean loss=0.06438516577084859\n",
      "test_test\n",
      "test mean loss=1160.5372009277344\n",
      "epoch 7649\n",
      "test_train\n",
      "train mean loss=0.05640969860057036\n",
      "test_test\n",
      "test mean loss=1160.4642028808594\n",
      "epoch 7650\n",
      "test_train\n",
      "train mean loss=0.057105242585142456\n",
      "test_test\n",
      "test mean loss=1160.7103576660156\n",
      "epoch 7651\n",
      "test_train\n",
      "train mean loss=0.05134807309756676\n",
      "test_test\n",
      "test mean loss=1160.9288940429688\n",
      "epoch 7652\n",
      "test_train\n",
      "train mean loss=0.05677408026531339\n",
      "test_test\n",
      "test mean loss=1161.7103881835938\n",
      "epoch 7653\n",
      "test_train\n",
      "train mean loss=0.05674761440604925\n",
      "test_test\n",
      "test mean loss=1161.1656188964844\n",
      "epoch 7654\n",
      "test_train\n",
      "train mean loss=0.05674678801248471\n",
      "test_test\n",
      "test mean loss=1161.434814453125\n",
      "epoch 7655\n",
      "test_train\n",
      "train mean loss=0.06134597056855758\n",
      "test_test\n",
      "test mean loss=1161.7029418945312\n",
      "epoch 7656\n",
      "test_train\n",
      "train mean loss=0.05862968104581038\n",
      "test_test\n",
      "test mean loss=1160.4599609375\n",
      "epoch 7657\n",
      "test_train\n",
      "train mean loss=0.05477047090729078\n",
      "test_test\n",
      "test mean loss=1160.6339721679688\n",
      "epoch 7658\n",
      "test_train\n",
      "train mean loss=0.054316398998101555\n",
      "test_test\n",
      "test mean loss=1161.9527893066406\n",
      "epoch 7659\n",
      "test_train\n",
      "train mean loss=0.055933586321771145\n",
      "test_test\n",
      "test mean loss=1161.33984375\n",
      "epoch 7660\n",
      "test_train\n",
      "train mean loss=0.05656585159401099\n",
      "test_test\n",
      "test mean loss=1160.6442260742188\n",
      "epoch 7661\n",
      "test_train\n",
      "train mean loss=0.09150235665341218\n",
      "test_test\n",
      "test mean loss=1158.6729431152344\n",
      "epoch 7662\n",
      "test_train\n",
      "train mean loss=0.0655328705906868\n",
      "test_test\n",
      "test mean loss=1161.5100708007812\n",
      "epoch 7663\n",
      "test_train\n",
      "train mean loss=0.05073366593569517\n",
      "test_test\n",
      "test mean loss=1160.6437683105469\n",
      "epoch 7664\n",
      "test_train\n",
      "train mean loss=0.048494541086256504\n",
      "test_test\n",
      "test mean loss=1160.2440795898438\n",
      "epoch 7665\n",
      "test_train\n",
      "train mean loss=0.05216562561690807\n",
      "test_test\n",
      "test mean loss=1158.8539428710938\n",
      "epoch 7666\n",
      "test_train\n",
      "train mean loss=0.05253748750934998\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1160.2269287109375\n",
      "epoch 7667\n",
      "test_train\n",
      "train mean loss=0.05209867904583613\n",
      "test_test\n",
      "test mean loss=1160.4190063476562\n",
      "epoch 7668\n",
      "test_train\n",
      "train mean loss=0.07097265683114529\n",
      "test_test\n",
      "test mean loss=1160.0166931152344\n",
      "epoch 7669\n",
      "test_train\n",
      "train mean loss=0.05258716456592083\n",
      "test_test\n",
      "test mean loss=1160.9228515625\n",
      "epoch 7670\n",
      "test_train\n",
      "train mean loss=0.051202409279843174\n",
      "test_test\n",
      "test mean loss=1160.2235107421875\n",
      "epoch 7671\n",
      "test_train\n",
      "train mean loss=0.05383316272248825\n",
      "test_test\n",
      "test mean loss=1160.95068359375\n",
      "epoch 7672\n",
      "test_train\n",
      "train mean loss=0.05013929369548956\n",
      "test_test\n",
      "test mean loss=1160.4491577148438\n",
      "epoch 7673\n",
      "test_train\n",
      "train mean loss=0.05790323888262113\n",
      "test_test\n",
      "test mean loss=1161.608642578125\n",
      "epoch 7674\n",
      "test_train\n",
      "train mean loss=0.05267817620187998\n",
      "test_test\n",
      "test mean loss=1160.8451843261719\n",
      "epoch 7675\n",
      "test_train\n",
      "train mean loss=0.06132061888153354\n",
      "test_test\n",
      "test mean loss=1161.412109375\n",
      "epoch 7676\n",
      "test_train\n",
      "train mean loss=0.049758835385243096\n",
      "test_test\n",
      "test mean loss=1160.6415100097656\n",
      "epoch 7677\n",
      "test_train\n",
      "train mean loss=0.05861750803887844\n",
      "test_test\n",
      "test mean loss=1161.5043334960938\n",
      "epoch 7678\n",
      "test_train\n",
      "train mean loss=0.04949560606231292\n",
      "test_test\n",
      "test mean loss=1160.2103271484375\n",
      "epoch 7679\n",
      "test_train\n",
      "train mean loss=0.06055278331041336\n",
      "test_test\n",
      "test mean loss=1161.0711669921875\n",
      "epoch 7680\n",
      "test_train\n",
      "train mean loss=0.05628212308511138\n",
      "test_test\n",
      "test mean loss=1161.6185302734375\n",
      "epoch 7681\n",
      "test_train\n",
      "train mean loss=0.05409877281636\n",
      "test_test\n",
      "test mean loss=1160.5050354003906\n",
      "epoch 7682\n",
      "test_train\n",
      "train mean loss=0.057750508189201355\n",
      "test_test\n",
      "test mean loss=1160.2940979003906\n",
      "epoch 7683\n",
      "test_train\n",
      "train mean loss=0.05223742344727119\n",
      "test_test\n",
      "test mean loss=1158.975830078125\n",
      "epoch 7684\n",
      "test_train\n",
      "train mean loss=0.049047392482558884\n",
      "test_test\n",
      "test mean loss=1160.5708923339844\n",
      "epoch 7685\n",
      "test_train\n",
      "train mean loss=0.05401140730828047\n",
      "test_test\n",
      "test mean loss=1160.3033447265625\n",
      "epoch 7686\n",
      "test_train\n",
      "train mean loss=0.05453406429539124\n",
      "test_test\n",
      "test mean loss=1160.2876892089844\n",
      "epoch 7687\n",
      "test_train\n",
      "train mean loss=0.05010428776343664\n",
      "test_test\n",
      "test mean loss=1160.4184875488281\n",
      "epoch 7688\n",
      "test_train\n",
      "train mean loss=0.051406911884744964\n",
      "test_test\n",
      "test mean loss=1160.8931579589844\n",
      "epoch 7689\n",
      "test_train\n",
      "train mean loss=0.05044145261247953\n",
      "test_test\n",
      "test mean loss=1161.176513671875\n",
      "epoch 7690\n",
      "test_train\n",
      "train mean loss=0.05502411102255186\n",
      "test_test\n",
      "test mean loss=1161.3346862792969\n",
      "epoch 7691\n",
      "test_train\n",
      "train mean loss=0.05846255924552679\n",
      "test_test\n",
      "test mean loss=1162.5746459960938\n",
      "epoch 7692\n",
      "test_train\n",
      "train mean loss=0.055614557738105454\n",
      "test_test\n",
      "test mean loss=1161.9274291992188\n",
      "epoch 7693\n",
      "test_train\n",
      "train mean loss=0.055524717861165605\n",
      "test_test\n",
      "test mean loss=1161.6311950683594\n",
      "epoch 7694\n",
      "test_train\n",
      "train mean loss=0.06260942916075389\n",
      "test_test\n",
      "test mean loss=1160.1289672851562\n",
      "epoch 7695\n",
      "test_train\n",
      "train mean loss=0.0509867916504542\n",
      "test_test\n",
      "test mean loss=1160.00244140625\n",
      "epoch 7696\n",
      "test_train\n",
      "train mean loss=0.05420476756989956\n",
      "test_test\n",
      "test mean loss=1160.046875\n",
      "epoch 7697\n",
      "test_train\n",
      "train mean loss=0.05756558462356528\n",
      "test_test\n",
      "test mean loss=1161.649169921875\n",
      "epoch 7698\n",
      "test_train\n",
      "train mean loss=0.054204889573156834\n",
      "test_test\n",
      "test mean loss=1161.5653686523438\n",
      "epoch 7699\n",
      "test_train\n",
      "train mean loss=0.055615538731217384\n",
      "test_test\n",
      "test mean loss=1161.2462158203125\n",
      "epoch 7700\n",
      "test_train\n",
      "train mean loss=0.049690574407577515\n",
      "test_test\n",
      "test mean loss=1160.7725830078125\n",
      "epoch 7701\n",
      "test_train\n",
      "train mean loss=0.04903459859391054\n",
      "test_test\n",
      "test mean loss=1160.63916015625\n",
      "epoch 7702\n",
      "test_train\n",
      "train mean loss=0.053654932572195925\n",
      "test_test\n",
      "test mean loss=1161.4105834960938\n",
      "epoch 7703\n",
      "test_train\n",
      "train mean loss=0.0519579293516775\n",
      "test_test\n",
      "test mean loss=1161.0468139648438\n",
      "epoch 7704\n",
      "test_train\n",
      "train mean loss=0.04927588766440749\n",
      "test_test\n",
      "test mean loss=1161.0709533691406\n",
      "epoch 7705\n",
      "test_train\n",
      "train mean loss=0.05386476715405782\n",
      "test_test\n",
      "test mean loss=1161.2040405273438\n",
      "epoch 7706\n",
      "test_train\n",
      "train mean loss=0.05144210128734509\n",
      "test_test\n",
      "test mean loss=1161.0562438964844\n",
      "epoch 7707\n",
      "test_train\n",
      "train mean loss=0.05593174261351427\n",
      "test_test\n",
      "test mean loss=1161.8156127929688\n",
      "epoch 7708\n",
      "test_train\n",
      "train mean loss=0.052387261763215065\n",
      "test_test\n",
      "test mean loss=1160.8775024414062\n",
      "epoch 7709\n",
      "test_train\n",
      "train mean loss=0.05414348157743613\n",
      "test_test\n",
      "test mean loss=1161.5833129882812\n",
      "epoch 7710\n",
      "test_train\n",
      "train mean loss=0.04990032439430555\n",
      "test_test\n",
      "test mean loss=1161.64697265625\n",
      "epoch 7711\n",
      "test_train\n",
      "train mean loss=0.0503396587446332\n",
      "test_test\n",
      "test mean loss=1160.3245239257812\n",
      "epoch 7712\n",
      "test_train\n",
      "train mean loss=0.1407529835899671\n",
      "test_test\n",
      "test mean loss=1157.25634765625\n",
      "epoch 7713\n",
      "test_train\n",
      "train mean loss=0.06267468507091205\n",
      "test_test\n",
      "test mean loss=1160.19970703125\n",
      "epoch 7714\n",
      "test_train\n",
      "train mean loss=0.05250508524477482\n",
      "test_test\n",
      "test mean loss=1161.2900085449219\n",
      "epoch 7715\n",
      "test_train\n",
      "train mean loss=0.05085821899895867\n",
      "test_test\n",
      "test mean loss=1160.4178161621094\n",
      "epoch 7716\n",
      "test_train\n",
      "train mean loss=0.05157611689840754\n",
      "test_test\n",
      "test mean loss=1161.3815307617188\n",
      "epoch 7717\n",
      "test_train\n",
      "train mean loss=0.05787437999000152\n",
      "test_test\n",
      "test mean loss=1160.782958984375\n",
      "epoch 7718\n",
      "test_train\n",
      "train mean loss=0.053769884010156\n",
      "test_test\n",
      "test mean loss=1160.423583984375\n",
      "epoch 7719\n",
      "test_train\n",
      "train mean loss=0.051022857427597046\n",
      "test_test\n",
      "test mean loss=1161.5202026367188\n",
      "epoch 7720\n",
      "test_train\n",
      "train mean loss=0.06985317325840394\n",
      "test_test\n",
      "test mean loss=1162.9157104492188\n",
      "epoch 7721\n",
      "test_train\n",
      "train mean loss=0.05341755862658223\n",
      "test_test\n",
      "test mean loss=1161.6488037109375\n",
      "epoch 7722\n",
      "test_train\n",
      "train mean loss=0.055650968104600906\n",
      "test_test\n",
      "test mean loss=1160.9660949707031\n",
      "epoch 7723\n",
      "test_train\n",
      "train mean loss=0.05227546083430449\n",
      "test_test\n",
      "test mean loss=1160.509521484375\n",
      "epoch 7724\n",
      "test_train\n",
      "train mean loss=0.05862714101870855\n",
      "test_test\n",
      "test mean loss=1161.2491760253906\n",
      "epoch 7725\n",
      "test_train\n",
      "train mean loss=0.0630105696618557\n",
      "test_test\n",
      "test mean loss=1160.8048095703125\n",
      "epoch 7726\n",
      "test_train\n",
      "train mean loss=0.05479837550471226\n",
      "test_test\n",
      "test mean loss=1159.3947143554688\n",
      "epoch 7727\n",
      "test_train\n",
      "train mean loss=0.05991270858794451\n",
      "test_test\n",
      "test mean loss=1161.2318115234375\n",
      "epoch 7728\n",
      "test_train\n",
      "train mean loss=0.050096639121572174\n",
      "test_test\n",
      "test mean loss=1160.6543273925781\n",
      "epoch 7729\n",
      "test_train\n",
      "train mean loss=0.049182009883224964\n",
      "test_test\n",
      "test mean loss=1160.8114624023438\n",
      "epoch 7730\n",
      "test_train\n",
      "train mean loss=0.052704633213579655\n",
      "test_test\n",
      "test mean loss=1161.8456420898438\n",
      "epoch 7731\n",
      "test_train\n",
      "train mean loss=0.05814263535042604\n",
      "test_test\n",
      "test mean loss=1160.9974365234375\n",
      "epoch 7732\n",
      "test_train\n",
      "train mean loss=0.051173885352909565\n",
      "test_test\n",
      "test mean loss=1160.0475463867188\n",
      "epoch 7733\n",
      "test_train\n",
      "train mean loss=0.05567962924639384\n",
      "test_test\n",
      "test mean loss=1160.3873901367188\n",
      "epoch 7734\n",
      "test_train\n",
      "train mean loss=0.060930073261260986\n",
      "test_test\n",
      "test mean loss=1161.05908203125\n",
      "epoch 7735\n",
      "test_train\n",
      "train mean loss=4.235306143760681\n",
      "test_test\n",
      "test mean loss=1113.1444396972656\n",
      "epoch 7736\n",
      "test_train\n",
      "train mean loss=0.07595403989156087\n",
      "test_test\n",
      "test mean loss=1156.6231689453125\n",
      "epoch 7737\n",
      "test_train\n",
      "train mean loss=0.04744514978180329\n",
      "test_test\n",
      "test mean loss=1159.3039855957031\n",
      "epoch 7738\n",
      "test_train\n",
      "train mean loss=0.048022300781061254\n",
      "test_test\n",
      "test mean loss=1159.1964111328125\n",
      "epoch 7739\n",
      "test_train\n",
      "train mean loss=0.05589049061139425\n",
      "test_test\n",
      "test mean loss=1160.60693359375\n",
      "epoch 7740\n",
      "test_train\n",
      "train mean loss=0.055138650039831795\n",
      "test_test\n",
      "test mean loss=1160.4359741210938\n",
      "epoch 7741\n",
      "test_train\n",
      "train mean loss=0.05034968117251992\n",
      "test_test\n",
      "test mean loss=1159.57861328125\n",
      "epoch 7742\n",
      "test_train\n",
      "train mean loss=0.04871686641126871\n",
      "test_test\n",
      "test mean loss=1159.9215393066406\n",
      "epoch 7743\n",
      "test_train\n",
      "train mean loss=0.055171107252438865\n",
      "test_test\n",
      "test mean loss=1158.9747924804688\n",
      "epoch 7744\n",
      "test_train\n",
      "train mean loss=0.06754900639255841\n",
      "test_test\n",
      "test mean loss=1154.2844848632812\n",
      "epoch 7745\n",
      "test_train\n",
      "train mean loss=0.0466476307871441\n",
      "test_test\n",
      "test mean loss=1159.4140930175781\n",
      "epoch 7746\n",
      "test_train\n",
      "train mean loss=0.05728785786777735\n",
      "test_test\n",
      "test mean loss=1160.3501586914062\n",
      "epoch 7747\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.061116718066235386\n",
      "test_test\n",
      "test mean loss=1160.61376953125\n",
      "epoch 7748\n",
      "test_train\n",
      "train mean loss=0.05724358527610699\n",
      "test_test\n",
      "test mean loss=1161.2337646484375\n",
      "epoch 7749\n",
      "test_train\n",
      "train mean loss=0.05655287252739072\n",
      "test_test\n",
      "test mean loss=1161.628662109375\n",
      "epoch 7750\n",
      "test_train\n",
      "train mean loss=0.0542614315636456\n",
      "test_test\n",
      "test mean loss=1159.903564453125\n",
      "epoch 7751\n",
      "test_train\n",
      "train mean loss=0.05537994112819433\n",
      "test_test\n",
      "test mean loss=1161.4076232910156\n",
      "epoch 7752\n",
      "test_train\n",
      "train mean loss=0.053625072818249464\n",
      "test_test\n",
      "test mean loss=1160.3505859375\n",
      "epoch 7753\n",
      "test_train\n",
      "train mean loss=0.04793651960790157\n",
      "test_test\n",
      "test mean loss=1160.0829467773438\n",
      "epoch 7754\n",
      "test_train\n",
      "train mean loss=0.05313043529167771\n",
      "test_test\n",
      "test mean loss=1160.3135986328125\n",
      "epoch 7755\n",
      "test_train\n",
      "train mean loss=0.0526880018102626\n",
      "test_test\n",
      "test mean loss=1160.2443237304688\n",
      "epoch 7756\n",
      "test_train\n",
      "train mean loss=0.05489824526011944\n",
      "test_test\n",
      "test mean loss=1161.3032531738281\n",
      "epoch 7757\n",
      "test_train\n",
      "train mean loss=0.045957627395788826\n",
      "test_test\n",
      "test mean loss=1159.7405700683594\n",
      "epoch 7758\n",
      "test_train\n",
      "train mean loss=0.05217746024330457\n",
      "test_test\n",
      "test mean loss=1160.2465209960938\n",
      "epoch 7759\n",
      "test_train\n",
      "train mean loss=0.04981829598546028\n",
      "test_test\n",
      "test mean loss=1159.898193359375\n",
      "epoch 7760\n",
      "test_train\n",
      "train mean loss=0.05906517477706075\n",
      "test_test\n",
      "test mean loss=1158.888916015625\n",
      "epoch 7761\n",
      "test_train\n",
      "train mean loss=0.05155907105654478\n",
      "test_test\n",
      "test mean loss=1159.3568115234375\n",
      "epoch 7762\n",
      "test_train\n",
      "train mean loss=0.04882247420027852\n",
      "test_test\n",
      "test mean loss=1160.2190856933594\n",
      "epoch 7763\n",
      "test_train\n",
      "train mean loss=0.06673525149623553\n",
      "test_test\n",
      "test mean loss=1159.2581787109375\n",
      "epoch 7764\n",
      "test_train\n",
      "train mean loss=0.055004619993269444\n",
      "test_test\n",
      "test mean loss=1160.0891723632812\n",
      "epoch 7765\n",
      "test_train\n",
      "train mean loss=0.0482367305085063\n",
      "test_test\n",
      "test mean loss=1159.7405395507812\n",
      "epoch 7766\n",
      "test_train\n",
      "train mean loss=0.05318117359032234\n",
      "test_test\n",
      "test mean loss=1160.2786254882812\n",
      "epoch 7767\n",
      "test_train\n",
      "train mean loss=0.055112896797557674\n",
      "test_test\n",
      "test mean loss=1160.3729858398438\n",
      "epoch 7768\n",
      "test_train\n",
      "train mean loss=0.05011343924949566\n",
      "test_test\n",
      "test mean loss=1160.5204162597656\n",
      "epoch 7769\n",
      "test_train\n",
      "train mean loss=0.053004489901165165\n",
      "test_test\n",
      "test mean loss=1160.414306640625\n",
      "epoch 7770\n",
      "test_train\n",
      "train mean loss=0.0771167262767752\n",
      "test_test\n",
      "test mean loss=1160.7596130371094\n",
      "epoch 7771\n",
      "test_train\n",
      "train mean loss=0.08621013350784779\n",
      "test_test\n",
      "test mean loss=1162.00341796875\n",
      "epoch 7772\n",
      "test_train\n",
      "train mean loss=0.05511063430458307\n",
      "test_test\n",
      "test mean loss=1160.0286254882812\n",
      "epoch 7773\n",
      "test_train\n",
      "train mean loss=0.05458958695332209\n",
      "test_test\n",
      "test mean loss=1158.8704833984375\n",
      "epoch 7774\n",
      "test_train\n",
      "train mean loss=0.06970568808416526\n",
      "test_test\n",
      "test mean loss=1158.1834716796875\n",
      "epoch 7775\n",
      "test_train\n",
      "train mean loss=0.05203561205416918\n",
      "test_test\n",
      "test mean loss=1160.0807495117188\n",
      "epoch 7776\n",
      "test_train\n",
      "train mean loss=0.050041202610979475\n",
      "test_test\n",
      "test mean loss=1160.313720703125\n",
      "epoch 7777\n",
      "test_train\n",
      "train mean loss=0.052414080748955406\n",
      "test_test\n",
      "test mean loss=1160.3262329101562\n",
      "epoch 7778\n",
      "test_train\n",
      "train mean loss=0.05604202641795079\n",
      "test_test\n",
      "test mean loss=1159.8818359375\n",
      "epoch 7779\n",
      "test_train\n",
      "train mean loss=0.3408302242557208\n",
      "test_test\n",
      "test mean loss=1161.783203125\n",
      "epoch 7780\n",
      "test_train\n",
      "train mean loss=0.0800033404181401\n",
      "test_test\n",
      "test mean loss=1162.5154418945312\n",
      "epoch 7781\n",
      "test_train\n",
      "train mean loss=0.05430391523987055\n",
      "test_test\n",
      "test mean loss=1160.29833984375\n",
      "epoch 7782\n",
      "test_train\n",
      "train mean loss=0.05638344927380482\n",
      "test_test\n",
      "test mean loss=1160.2152099609375\n",
      "epoch 7783\n",
      "test_train\n",
      "train mean loss=0.06072376916805903\n",
      "test_test\n",
      "test mean loss=1160.2623596191406\n",
      "epoch 7784\n",
      "test_train\n",
      "train mean loss=0.05408706391851107\n",
      "test_test\n",
      "test mean loss=1160.8648071289062\n",
      "epoch 7785\n",
      "test_train\n",
      "train mean loss=0.12445442688961823\n",
      "test_test\n",
      "test mean loss=1151.5902709960938\n",
      "epoch 7786\n",
      "test_train\n",
      "train mean loss=0.05969595101972421\n",
      "test_test\n",
      "test mean loss=1160.6125183105469\n",
      "epoch 7787\n",
      "test_train\n",
      "train mean loss=0.05726103329410156\n",
      "test_test\n",
      "test mean loss=1162.0311889648438\n",
      "epoch 7788\n",
      "test_train\n",
      "train mean loss=0.05870061243573824\n",
      "test_test\n",
      "test mean loss=1162.456298828125\n",
      "epoch 7789\n",
      "test_train\n",
      "train mean loss=0.35037196800112724\n",
      "test_test\n",
      "test mean loss=1149.9067993164062\n",
      "epoch 7790\n",
      "test_train\n",
      "train mean loss=0.07659768685698509\n",
      "test_test\n",
      "test mean loss=1161.0459899902344\n",
      "epoch 7791\n",
      "test_train\n",
      "train mean loss=0.05747133524467548\n",
      "test_test\n",
      "test mean loss=1161.4061889648438\n",
      "epoch 7792\n",
      "test_train\n",
      "train mean loss=0.07339426099012296\n",
      "test_test\n",
      "test mean loss=1162.400390625\n",
      "epoch 7793\n",
      "test_train\n",
      "train mean loss=0.06609577188889186\n",
      "test_test\n",
      "test mean loss=1161.740966796875\n",
      "epoch 7794\n",
      "test_train\n",
      "train mean loss=0.06143628883485993\n",
      "test_test\n",
      "test mean loss=1161.2183837890625\n",
      "epoch 7795\n",
      "test_train\n",
      "train mean loss=0.06091550923883915\n",
      "test_test\n",
      "test mean loss=1162.3147583007812\n",
      "epoch 7796\n",
      "test_train\n",
      "train mean loss=0.06405664545794328\n",
      "test_test\n",
      "test mean loss=1162.9353637695312\n",
      "epoch 7797\n",
      "test_train\n",
      "train mean loss=0.055623555555939674\n",
      "test_test\n",
      "test mean loss=1161.479248046875\n",
      "epoch 7798\n",
      "test_train\n",
      "train mean loss=0.05829348197827736\n",
      "test_test\n",
      "test mean loss=1161.1319885253906\n",
      "epoch 7799\n",
      "test_train\n",
      "train mean loss=0.057663558050990105\n",
      "test_test\n",
      "test mean loss=1161.2626342773438\n",
      "epoch 7800\n",
      "test_train\n",
      "train mean loss=0.058755199114481606\n",
      "test_test\n",
      "test mean loss=1161.5533447265625\n",
      "epoch 7801\n",
      "test_train\n",
      "train mean loss=0.05420695555706819\n",
      "test_test\n",
      "test mean loss=1161.1162414550781\n",
      "epoch 7802\n",
      "test_train\n",
      "train mean loss=0.05628543005635341\n",
      "test_test\n",
      "test mean loss=1160.45263671875\n",
      "epoch 7803\n",
      "test_train\n",
      "train mean loss=0.055255427956581116\n",
      "test_test\n",
      "test mean loss=1158.9268493652344\n",
      "epoch 7804\n",
      "test_train\n",
      "train mean loss=0.059085252694785595\n",
      "test_test\n",
      "test mean loss=1159.8331604003906\n",
      "epoch 7805\n",
      "test_train\n",
      "train mean loss=0.05290686680624882\n",
      "test_test\n",
      "test mean loss=1159.697998046875\n",
      "epoch 7806\n",
      "test_train\n",
      "train mean loss=0.05599353710810343\n",
      "test_test\n",
      "test mean loss=1160.9559631347656\n",
      "epoch 7807\n",
      "test_train\n",
      "train mean loss=0.05464057748516401\n",
      "test_test\n",
      "test mean loss=1161.3847045898438\n",
      "epoch 7808\n",
      "test_train\n",
      "train mean loss=0.05958907213062048\n",
      "test_test\n",
      "test mean loss=1161.7007751464844\n",
      "epoch 7809\n",
      "test_train\n",
      "train mean loss=0.059847828621665634\n",
      "test_test\n",
      "test mean loss=1160.75146484375\n",
      "epoch 7810\n",
      "test_train\n",
      "train mean loss=0.055063236660013594\n",
      "test_test\n",
      "test mean loss=1160.2307739257812\n",
      "epoch 7811\n",
      "test_train\n",
      "train mean loss=0.06217785862584909\n",
      "test_test\n",
      "test mean loss=1161.0186157226562\n",
      "epoch 7812\n",
      "test_train\n",
      "train mean loss=0.05286509838576118\n",
      "test_test\n",
      "test mean loss=1159.1141357421875\n",
      "epoch 7813\n",
      "test_train\n",
      "train mean loss=0.058174349212398134\n",
      "test_test\n",
      "test mean loss=1159.275146484375\n",
      "epoch 7814\n",
      "test_train\n",
      "train mean loss=0.058385539799928665\n",
      "test_test\n",
      "test mean loss=1160.6288757324219\n",
      "epoch 7815\n",
      "test_train\n",
      "train mean loss=0.0621064497778813\n",
      "test_test\n",
      "test mean loss=1162.1185302734375\n",
      "epoch 7816\n",
      "test_train\n",
      "train mean loss=0.05821758167197307\n",
      "test_test\n",
      "test mean loss=1161.4312744140625\n",
      "epoch 7817\n",
      "test_train\n",
      "train mean loss=0.060014947627981506\n",
      "test_test\n",
      "test mean loss=1160.7458801269531\n",
      "epoch 7818\n",
      "test_train\n",
      "train mean loss=0.05954691922912995\n",
      "test_test\n",
      "test mean loss=1161.6365356445312\n",
      "epoch 7819\n",
      "test_train\n",
      "train mean loss=0.061504202894866467\n",
      "test_test\n",
      "test mean loss=1160.6969299316406\n",
      "epoch 7820\n",
      "test_train\n",
      "train mean loss=0.12405685770014922\n",
      "test_test\n",
      "test mean loss=1154.8115234375\n",
      "epoch 7821\n",
      "test_train\n",
      "train mean loss=0.06676258674512307\n",
      "test_test\n",
      "test mean loss=1162.367919921875\n",
      "epoch 7822\n",
      "test_train\n",
      "train mean loss=0.05852642562240362\n",
      "test_test\n",
      "test mean loss=1161.4067993164062\n",
      "epoch 7823\n",
      "test_train\n",
      "train mean loss=0.05762416093299786\n",
      "test_test\n",
      "test mean loss=1161.9469909667969\n",
      "epoch 7824\n",
      "test_train\n",
      "train mean loss=0.055897243010501065\n",
      "test_test\n",
      "test mean loss=1160.8590087890625\n",
      "epoch 7825\n",
      "test_train\n",
      "train mean loss=0.0543629868576924\n",
      "test_test\n",
      "test mean loss=1161.1524658203125\n",
      "epoch 7826\n",
      "test_train\n",
      "train mean loss=0.06028702793021997\n",
      "test_test\n",
      "test mean loss=1161.8301391601562\n",
      "epoch 7827\n",
      "test_train\n",
      "train mean loss=0.7395031799872717\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1160.3431396484375\n",
      "epoch 7828\n",
      "test_train\n",
      "train mean loss=0.16550629027187824\n",
      "test_test\n",
      "test mean loss=1160.8638610839844\n",
      "epoch 7829\n",
      "test_train\n",
      "train mean loss=0.061582096541921295\n",
      "test_test\n",
      "test mean loss=1160.558837890625\n",
      "epoch 7830\n",
      "test_train\n",
      "train mean loss=0.06974430878957112\n",
      "test_test\n",
      "test mean loss=1161.4330444335938\n",
      "epoch 7831\n",
      "test_train\n",
      "train mean loss=0.10654945857822895\n",
      "test_test\n",
      "test mean loss=1161.5550537109375\n",
      "epoch 7832\n",
      "test_train\n",
      "train mean loss=0.0673178384701411\n",
      "test_test\n",
      "test mean loss=1161.595947265625\n",
      "epoch 7833\n",
      "test_train\n",
      "train mean loss=0.06449039932340384\n",
      "test_test\n",
      "test mean loss=1161.3239135742188\n",
      "epoch 7834\n",
      "test_train\n",
      "train mean loss=0.05876843476047119\n",
      "test_test\n",
      "test mean loss=1160.032470703125\n",
      "epoch 7835\n",
      "test_train\n",
      "train mean loss=0.09020012896507978\n",
      "test_test\n",
      "test mean loss=1161.3491821289062\n",
      "epoch 7836\n",
      "test_train\n",
      "train mean loss=0.06241479919602474\n",
      "test_test\n",
      "test mean loss=1159.3246154785156\n",
      "epoch 7837\n",
      "test_train\n",
      "train mean loss=0.05642016977071762\n",
      "test_test\n",
      "test mean loss=1160.04638671875\n",
      "epoch 7838\n",
      "test_train\n",
      "train mean loss=0.05479532899335027\n",
      "test_test\n",
      "test mean loss=1159.9833374023438\n",
      "epoch 7839\n",
      "test_train\n",
      "train mean loss=0.05522273356715838\n",
      "test_test\n",
      "test mean loss=1160.51123046875\n",
      "epoch 7840\n",
      "test_train\n",
      "train mean loss=0.12283419010539849\n",
      "test_test\n",
      "test mean loss=1162.2637939453125\n",
      "epoch 7841\n",
      "test_train\n",
      "train mean loss=0.0696674898887674\n",
      "test_test\n",
      "test mean loss=1160.8091430664062\n",
      "epoch 7842\n",
      "test_train\n",
      "train mean loss=0.08640533934036891\n",
      "test_test\n",
      "test mean loss=1157.9473266601562\n",
      "epoch 7843\n",
      "test_train\n",
      "train mean loss=0.07081291048477094\n",
      "test_test\n",
      "test mean loss=1159.622802734375\n",
      "epoch 7844\n",
      "test_train\n",
      "train mean loss=0.05913610104471445\n",
      "test_test\n",
      "test mean loss=1159.3289184570312\n",
      "epoch 7845\n",
      "test_train\n",
      "train mean loss=0.05808299376318852\n",
      "test_test\n",
      "test mean loss=1159.1910400390625\n",
      "epoch 7846\n",
      "test_train\n",
      "train mean loss=0.05800181068480015\n",
      "test_test\n",
      "test mean loss=1159.0221557617188\n",
      "epoch 7847\n",
      "test_train\n",
      "train mean loss=0.0808490077033639\n",
      "test_test\n",
      "test mean loss=1160.60400390625\n",
      "epoch 7848\n",
      "test_train\n",
      "train mean loss=0.06296689963589112\n",
      "test_test\n",
      "test mean loss=1159.5137329101562\n",
      "epoch 7849\n",
      "test_train\n",
      "train mean loss=0.06390616794427235\n",
      "test_test\n",
      "test mean loss=1159.9872436523438\n",
      "epoch 7850\n",
      "test_train\n",
      "train mean loss=0.07302085713793834\n",
      "test_test\n",
      "test mean loss=1160.7988891601562\n",
      "epoch 7851\n",
      "test_train\n",
      "train mean loss=0.06012607210626205\n",
      "test_test\n",
      "test mean loss=1159.2376098632812\n",
      "epoch 7852\n",
      "test_train\n",
      "train mean loss=0.07256180482606094\n",
      "test_test\n",
      "test mean loss=1158.4473876953125\n",
      "epoch 7853\n",
      "test_train\n",
      "train mean loss=0.055442306523521744\n",
      "test_test\n",
      "test mean loss=1158.7215270996094\n",
      "epoch 7854\n",
      "test_train\n",
      "train mean loss=0.055057509491840996\n",
      "test_test\n",
      "test mean loss=1160.0115356445312\n",
      "epoch 7855\n",
      "test_train\n",
      "train mean loss=0.06055686033020417\n",
      "test_test\n",
      "test mean loss=1160.5730590820312\n",
      "epoch 7856\n",
      "test_train\n",
      "train mean loss=0.054593980157126985\n",
      "test_test\n",
      "test mean loss=1158.9173889160156\n",
      "epoch 7857\n",
      "test_train\n",
      "train mean loss=0.05641308054327965\n",
      "test_test\n",
      "test mean loss=1159.8925170898438\n",
      "epoch 7858\n",
      "test_train\n",
      "train mean loss=0.061542440516253315\n",
      "test_test\n",
      "test mean loss=1159.0514526367188\n",
      "epoch 7859\n",
      "test_train\n",
      "train mean loss=0.06033172179013491\n",
      "test_test\n",
      "test mean loss=1160.1946411132812\n",
      "epoch 7860\n",
      "test_train\n",
      "train mean loss=0.0996442021181186\n",
      "test_test\n",
      "test mean loss=1159.5045776367188\n",
      "epoch 7861\n",
      "test_train\n",
      "train mean loss=0.05250789954637488\n",
      "test_test\n",
      "test mean loss=1158.5985107421875\n",
      "epoch 7862\n",
      "test_train\n",
      "train mean loss=0.05893066789334019\n",
      "test_test\n",
      "test mean loss=1159.2171630859375\n",
      "epoch 7863\n",
      "test_train\n",
      "train mean loss=0.05204475329567989\n",
      "test_test\n",
      "test mean loss=1158.9046020507812\n",
      "epoch 7864\n",
      "test_train\n",
      "train mean loss=0.05301431193947792\n",
      "test_test\n",
      "test mean loss=1158.70068359375\n",
      "epoch 7865\n",
      "test_train\n",
      "train mean loss=0.0542989835763971\n",
      "test_test\n",
      "test mean loss=1159.467529296875\n",
      "epoch 7866\n",
      "test_train\n",
      "train mean loss=0.062493554316461086\n",
      "test_test\n",
      "test mean loss=1160.5042114257812\n",
      "epoch 7867\n",
      "test_train\n",
      "train mean loss=0.06671554346879323\n",
      "test_test\n",
      "test mean loss=1157.776611328125\n",
      "epoch 7868\n",
      "test_train\n",
      "train mean loss=0.05602874358495077\n",
      "test_test\n",
      "test mean loss=1158.5222778320312\n",
      "epoch 7869\n",
      "test_train\n",
      "train mean loss=0.05709975926826397\n",
      "test_test\n",
      "test mean loss=1159.3257446289062\n",
      "epoch 7870\n",
      "test_train\n",
      "train mean loss=0.05270548242454728\n",
      "test_test\n",
      "test mean loss=1159.040283203125\n",
      "epoch 7871\n",
      "test_train\n",
      "train mean loss=0.06194584568341573\n",
      "test_test\n",
      "test mean loss=1160.80126953125\n",
      "epoch 7872\n",
      "test_train\n",
      "train mean loss=0.07895152550190687\n",
      "test_test\n",
      "test mean loss=1155.2054748535156\n",
      "epoch 7873\n",
      "test_train\n",
      "train mean loss=0.05886228599896034\n",
      "test_test\n",
      "test mean loss=1160.0406494140625\n",
      "epoch 7874\n",
      "test_train\n",
      "train mean loss=0.9426653832197189\n",
      "test_test\n",
      "test mean loss=1159.2681274414062\n",
      "epoch 7875\n",
      "test_train\n",
      "train mean loss=0.11447444247702758\n",
      "test_test\n",
      "test mean loss=1158.9813537597656\n",
      "epoch 7876\n",
      "test_train\n",
      "train mean loss=0.06472280078257124\n",
      "test_test\n",
      "test mean loss=1158.1900634765625\n",
      "epoch 7877\n",
      "test_train\n",
      "train mean loss=0.059508499689400196\n",
      "test_test\n",
      "test mean loss=1156.5974731445312\n",
      "epoch 7878\n",
      "test_train\n",
      "train mean loss=0.055992222391068935\n",
      "test_test\n",
      "test mean loss=1157.1058959960938\n",
      "epoch 7879\n",
      "test_train\n",
      "train mean loss=0.05656933303301533\n",
      "test_test\n",
      "test mean loss=1156.6513671875\n",
      "epoch 7880\n",
      "test_train\n",
      "train mean loss=0.05855184607207775\n",
      "test_test\n",
      "test mean loss=1157.60986328125\n",
      "epoch 7881\n",
      "test_train\n",
      "train mean loss=0.05808752992500862\n",
      "test_test\n",
      "test mean loss=1156.7020263671875\n",
      "epoch 7882\n",
      "test_train\n",
      "train mean loss=0.05986734262357155\n",
      "test_test\n",
      "test mean loss=1157.1044311523438\n",
      "epoch 7883\n",
      "test_train\n",
      "train mean loss=0.06553360385199387\n",
      "test_test\n",
      "test mean loss=1157.4962768554688\n",
      "epoch 7884\n",
      "test_train\n",
      "train mean loss=0.062433365577210985\n",
      "test_test\n",
      "test mean loss=1157.780517578125\n",
      "epoch 7885\n",
      "test_train\n",
      "train mean loss=0.0565002616494894\n",
      "test_test\n",
      "test mean loss=1157.9518432617188\n",
      "epoch 7886\n",
      "test_train\n",
      "train mean loss=0.05880634145190319\n",
      "test_test\n",
      "test mean loss=1157.3408508300781\n",
      "epoch 7887\n",
      "test_train\n",
      "train mean loss=0.05405540096883973\n",
      "test_test\n",
      "test mean loss=1157.4791259765625\n",
      "epoch 7888\n",
      "test_train\n",
      "train mean loss=0.05475907400250435\n",
      "test_test\n",
      "test mean loss=1158.1531982421875\n",
      "epoch 7889\n",
      "test_train\n",
      "train mean loss=0.06483438548942407\n",
      "test_test\n",
      "test mean loss=1158.4349365234375\n",
      "epoch 7890\n",
      "test_train\n",
      "train mean loss=0.06407688899586599\n",
      "test_test\n",
      "test mean loss=1158.3615112304688\n",
      "epoch 7891\n",
      "test_train\n",
      "train mean loss=0.06634984910488129\n",
      "test_test\n",
      "test mean loss=1158.3536682128906\n",
      "epoch 7892\n",
      "test_train\n",
      "train mean loss=0.0551158431917429\n",
      "test_test\n",
      "test mean loss=1158.2340698242188\n",
      "epoch 7893\n",
      "test_train\n",
      "train mean loss=0.05116344072545568\n",
      "test_test\n",
      "test mean loss=1158.5114135742188\n",
      "epoch 7894\n",
      "test_train\n",
      "train mean loss=0.05043123879780372\n",
      "test_test\n",
      "test mean loss=1158.4613952636719\n",
      "epoch 7895\n",
      "test_train\n",
      "train mean loss=0.05731459769109885\n",
      "test_test\n",
      "test mean loss=1158.8002319335938\n",
      "epoch 7896\n",
      "test_train\n",
      "train mean loss=0.05460972432047129\n",
      "test_test\n",
      "test mean loss=1159.071533203125\n",
      "epoch 7897\n",
      "test_train\n",
      "train mean loss=0.05310796697934469\n",
      "test_test\n",
      "test mean loss=1159.0469360351562\n",
      "epoch 7898\n",
      "test_train\n",
      "train mean loss=0.05535798737158378\n",
      "test_test\n",
      "test mean loss=1159.01171875\n",
      "epoch 7899\n",
      "test_train\n",
      "train mean loss=0.05527161263550321\n",
      "test_test\n",
      "test mean loss=1159.1984252929688\n",
      "epoch 7900\n",
      "test_train\n",
      "train mean loss=0.05277021027480563\n",
      "test_test\n",
      "test mean loss=1158.0841064453125\n",
      "epoch 7901\n",
      "test_train\n",
      "train mean loss=0.06716444731379549\n",
      "test_test\n",
      "test mean loss=1158.9856262207031\n",
      "epoch 7902\n",
      "test_train\n",
      "train mean loss=0.055449019807080425\n",
      "test_test\n",
      "test mean loss=1158.7927856445312\n",
      "epoch 7903\n",
      "test_train\n",
      "train mean loss=0.05778719329585632\n",
      "test_test\n",
      "test mean loss=1159.7592163085938\n",
      "epoch 7904\n",
      "test_train\n",
      "train mean loss=0.06394319205234449\n",
      "test_test\n",
      "test mean loss=1158.687255859375\n",
      "epoch 7905\n",
      "test_train\n",
      "train mean loss=0.05505438086887201\n",
      "test_test\n",
      "test mean loss=1160.0987548828125\n",
      "epoch 7906\n",
      "test_train\n",
      "train mean loss=0.05616898462176323\n",
      "test_test\n",
      "test mean loss=1160.1472473144531\n",
      "epoch 7907\n",
      "test_train\n",
      "train mean loss=0.05697952459255854\n",
      "test_test\n",
      "test mean loss=1160.5268859863281\n",
      "epoch 7908\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.05175284078965584\n",
      "test_test\n",
      "test mean loss=1160.0077819824219\n",
      "epoch 7909\n",
      "test_train\n",
      "train mean loss=0.05531882029026747\n",
      "test_test\n",
      "test mean loss=1160.0301513671875\n",
      "epoch 7910\n",
      "test_train\n",
      "train mean loss=0.06683229903380077\n",
      "test_test\n",
      "test mean loss=1159.340576171875\n",
      "epoch 7911\n",
      "test_train\n",
      "train mean loss=0.063732269530495\n",
      "test_test\n",
      "test mean loss=1160.3485107421875\n",
      "epoch 7912\n",
      "test_train\n",
      "train mean loss=0.061957959085702896\n",
      "test_test\n",
      "test mean loss=1160.796875\n",
      "epoch 7913\n",
      "test_train\n",
      "train mean loss=0.058261679174999394\n",
      "test_test\n",
      "test mean loss=1160.5084838867188\n",
      "epoch 7914\n",
      "test_train\n",
      "train mean loss=0.05814749468117952\n",
      "test_test\n",
      "test mean loss=1160.8397216796875\n",
      "epoch 7915\n",
      "test_train\n",
      "train mean loss=0.06087252373496691\n",
      "test_test\n",
      "test mean loss=1159.533935546875\n",
      "epoch 7916\n",
      "test_train\n",
      "train mean loss=0.06149454694241285\n",
      "test_test\n",
      "test mean loss=1160.2803039550781\n",
      "epoch 7917\n",
      "test_train\n",
      "train mean loss=0.052463589080919824\n",
      "test_test\n",
      "test mean loss=1159.7848510742188\n",
      "epoch 7918\n",
      "test_train\n",
      "train mean loss=0.05180409892151753\n",
      "test_test\n",
      "test mean loss=1159.883056640625\n",
      "epoch 7919\n",
      "test_train\n",
      "train mean loss=0.05498650980492433\n",
      "test_test\n",
      "test mean loss=1158.6697998046875\n",
      "epoch 7920\n",
      "test_train\n",
      "train mean loss=0.05611672562857469\n",
      "test_test\n",
      "test mean loss=1160.5765075683594\n",
      "epoch 7921\n",
      "test_train\n",
      "train mean loss=0.0693936264142394\n",
      "test_test\n",
      "test mean loss=1155.638671875\n",
      "epoch 7922\n",
      "test_train\n",
      "train mean loss=0.052591754434009395\n",
      "test_test\n",
      "test mean loss=1160.5609741210938\n",
      "epoch 7923\n",
      "test_train\n",
      "train mean loss=0.05704931728541851\n",
      "test_test\n",
      "test mean loss=1161.2576293945312\n",
      "epoch 7924\n",
      "test_train\n",
      "train mean loss=0.0541774855616192\n",
      "test_test\n",
      "test mean loss=1160.2590637207031\n",
      "epoch 7925\n",
      "test_train\n",
      "train mean loss=0.05474450315038363\n",
      "test_test\n",
      "test mean loss=1160.7003784179688\n",
      "epoch 7926\n",
      "test_train\n",
      "train mean loss=0.05008479145665964\n",
      "test_test\n",
      "test mean loss=1160.3797607421875\n",
      "epoch 7927\n",
      "test_train\n",
      "train mean loss=0.050451946134368576\n",
      "test_test\n",
      "test mean loss=1161.1695861816406\n",
      "epoch 7928\n",
      "test_train\n",
      "train mean loss=0.055462041248877846\n",
      "test_test\n",
      "test mean loss=1160.5001831054688\n",
      "epoch 7929\n",
      "test_train\n",
      "train mean loss=0.05575411859899759\n",
      "test_test\n",
      "test mean loss=1160.0305786132812\n",
      "epoch 7930\n",
      "test_train\n",
      "train mean loss=0.05365455523133278\n",
      "test_test\n",
      "test mean loss=1160.9859924316406\n",
      "epoch 7931\n",
      "test_train\n",
      "train mean loss=0.054255510990818344\n",
      "test_test\n",
      "test mean loss=1159.789794921875\n",
      "epoch 7932\n",
      "test_train\n",
      "train mean loss=0.05605558988948663\n",
      "test_test\n",
      "test mean loss=1160.2775268554688\n",
      "epoch 7933\n",
      "test_train\n",
      "train mean loss=0.059141688980162144\n",
      "test_test\n",
      "test mean loss=1161.07373046875\n",
      "epoch 7934\n",
      "test_train\n",
      "train mean loss=0.058892217464745045\n",
      "test_test\n",
      "test mean loss=1162.1184692382812\n",
      "epoch 7935\n",
      "test_train\n",
      "train mean loss=0.054881966672837734\n",
      "test_test\n",
      "test mean loss=1161.532470703125\n",
      "epoch 7936\n",
      "test_train\n",
      "train mean loss=0.05385218778004249\n",
      "test_test\n",
      "test mean loss=1161.31640625\n",
      "epoch 7937\n",
      "test_train\n",
      "train mean loss=0.049012371649344764\n",
      "test_test\n",
      "test mean loss=1160.9157104492188\n",
      "epoch 7938\n",
      "test_train\n",
      "train mean loss=0.0529469158500433\n",
      "test_test\n",
      "test mean loss=1161.7457275390625\n",
      "epoch 7939\n",
      "test_train\n",
      "train mean loss=0.0766071497152249\n",
      "test_test\n",
      "test mean loss=1162.4796142578125\n",
      "epoch 7940\n",
      "test_train\n",
      "train mean loss=0.053825413808226585\n",
      "test_test\n",
      "test mean loss=1161.745849609375\n",
      "epoch 7941\n",
      "test_train\n",
      "train mean loss=0.05248290983339151\n",
      "test_test\n",
      "test mean loss=1160.9275207519531\n",
      "epoch 7942\n",
      "test_train\n",
      "train mean loss=0.054556808123985924\n",
      "test_test\n",
      "test mean loss=1161.1171569824219\n",
      "epoch 7943\n",
      "test_train\n",
      "train mean loss=0.05432712069402138\n",
      "test_test\n",
      "test mean loss=1160.8658142089844\n",
      "epoch 7944\n",
      "test_train\n",
      "train mean loss=0.05336905705432097\n",
      "test_test\n",
      "test mean loss=1160.043701171875\n",
      "epoch 7945\n",
      "test_train\n",
      "train mean loss=0.0583688598126173\n",
      "test_test\n",
      "test mean loss=1161.6800537109375\n",
      "epoch 7946\n",
      "test_train\n",
      "train mean loss=0.056626972121497\n",
      "test_test\n",
      "test mean loss=1161.9403686523438\n",
      "epoch 7947\n",
      "test_train\n",
      "train mean loss=0.05498817966630062\n",
      "test_test\n",
      "test mean loss=1160.7615966796875\n",
      "epoch 7948\n",
      "test_train\n",
      "train mean loss=0.05662901047617197\n",
      "test_test\n",
      "test mean loss=1161.9894104003906\n",
      "epoch 7949\n",
      "test_train\n",
      "train mean loss=0.05628137414654096\n",
      "test_test\n",
      "test mean loss=1161.1835021972656\n",
      "epoch 7950\n",
      "test_train\n",
      "train mean loss=0.06009895044068495\n",
      "test_test\n",
      "test mean loss=1160.3438720703125\n",
      "epoch 7951\n",
      "test_train\n",
      "train mean loss=0.06412208173424006\n",
      "test_test\n",
      "test mean loss=1159.7357177734375\n",
      "epoch 7952\n",
      "test_train\n",
      "train mean loss=0.05941401980817318\n",
      "test_test\n",
      "test mean loss=1160.1989135742188\n",
      "epoch 7953\n",
      "test_train\n",
      "train mean loss=0.06384514768918355\n",
      "test_test\n",
      "test mean loss=1160.0761108398438\n",
      "epoch 7954\n",
      "test_train\n",
      "train mean loss=0.05410716123878956\n",
      "test_test\n",
      "test mean loss=1158.61669921875\n",
      "epoch 7955\n",
      "test_train\n",
      "train mean loss=0.05601372942328453\n",
      "test_test\n",
      "test mean loss=1158.9891357421875\n",
      "epoch 7956\n",
      "test_train\n",
      "train mean loss=0.06358534501244624\n",
      "test_test\n",
      "test mean loss=1159.8863525390625\n",
      "epoch 7957\n",
      "test_train\n",
      "train mean loss=0.06008287208775679\n",
      "test_test\n",
      "test mean loss=1158.9124145507812\n",
      "epoch 7958\n",
      "test_train\n",
      "train mean loss=0.05391124108185371\n",
      "test_test\n",
      "test mean loss=1159.7696228027344\n",
      "epoch 7959\n",
      "test_train\n",
      "train mean loss=0.05805157404392958\n",
      "test_test\n",
      "test mean loss=1160.2401123046875\n",
      "epoch 7960\n",
      "test_train\n",
      "train mean loss=0.05955652271707853\n",
      "test_test\n",
      "test mean loss=1159.8801879882812\n",
      "epoch 7961\n",
      "test_train\n",
      "train mean loss=0.05147925019264221\n",
      "test_test\n",
      "test mean loss=1159.6368408203125\n",
      "epoch 7962\n",
      "test_train\n",
      "train mean loss=0.05657833473136028\n",
      "test_test\n",
      "test mean loss=1160.4497680664062\n",
      "epoch 7963\n",
      "test_train\n",
      "train mean loss=0.050338251826663814\n",
      "test_test\n",
      "test mean loss=1158.6685791015625\n",
      "epoch 7964\n",
      "test_train\n",
      "train mean loss=0.05347380073120197\n",
      "test_test\n",
      "test mean loss=1158.9116821289062\n",
      "epoch 7965\n",
      "test_train\n",
      "train mean loss=0.05570172984153032\n",
      "test_test\n",
      "test mean loss=1159.7957153320312\n",
      "epoch 7966\n",
      "test_train\n",
      "train mean loss=0.05212757736444473\n",
      "test_test\n",
      "test mean loss=1160.24658203125\n",
      "epoch 7967\n",
      "test_train\n",
      "train mean loss=0.055281580736239753\n",
      "test_test\n",
      "test mean loss=1158.53369140625\n",
      "epoch 7968\n",
      "test_train\n",
      "train mean loss=0.051277005734543\n",
      "test_test\n",
      "test mean loss=1159.6956787109375\n",
      "epoch 7969\n",
      "test_train\n",
      "train mean loss=0.05601297474155823\n",
      "test_test\n",
      "test mean loss=1160.6002197265625\n",
      "epoch 7970\n",
      "test_train\n",
      "train mean loss=0.05288208834826946\n",
      "test_test\n",
      "test mean loss=1160.1452026367188\n",
      "epoch 7971\n",
      "test_train\n",
      "train mean loss=0.059720506270726524\n",
      "test_test\n",
      "test mean loss=1159.4207153320312\n",
      "epoch 7972\n",
      "test_train\n",
      "train mean loss=0.06352024866888921\n",
      "test_test\n",
      "test mean loss=1160.1800231933594\n",
      "epoch 7973\n",
      "test_train\n",
      "train mean loss=0.06018113593260447\n",
      "test_test\n",
      "test mean loss=1159.1455383300781\n",
      "epoch 7974\n",
      "test_train\n",
      "train mean loss=0.0598819355169932\n",
      "test_test\n",
      "test mean loss=1159.014892578125\n",
      "epoch 7975\n",
      "test_train\n",
      "train mean loss=0.057047221499184765\n",
      "test_test\n",
      "test mean loss=1158.9832458496094\n",
      "epoch 7976\n",
      "test_train\n",
      "train mean loss=0.06175239197909832\n",
      "test_test\n",
      "test mean loss=1159.338623046875\n",
      "epoch 7977\n",
      "test_train\n",
      "train mean loss=0.06164728384464979\n",
      "test_test\n",
      "test mean loss=1159.2516479492188\n",
      "epoch 7978\n",
      "test_train\n",
      "train mean loss=0.06198905874043703\n",
      "test_test\n",
      "test mean loss=1160.430419921875\n",
      "epoch 7979\n",
      "test_train\n",
      "train mean loss=0.057699729378024735\n",
      "test_test\n",
      "test mean loss=1159.69384765625\n",
      "epoch 7980\n",
      "test_train\n",
      "train mean loss=0.05557591778536638\n",
      "test_test\n",
      "test mean loss=1158.989990234375\n",
      "epoch 7981\n",
      "test_train\n",
      "train mean loss=0.06576958888520797\n",
      "test_test\n",
      "test mean loss=1159.6102294921875\n",
      "epoch 7982\n",
      "test_train\n",
      "train mean loss=0.05984279358138641\n",
      "test_test\n",
      "test mean loss=1158.6560668945312\n",
      "epoch 7983\n",
      "test_train\n",
      "train mean loss=0.06609114228437345\n",
      "test_test\n",
      "test mean loss=1159.898681640625\n",
      "epoch 7984\n",
      "test_train\n",
      "train mean loss=0.06792803232868512\n",
      "test_test\n",
      "test mean loss=1160.0605773925781\n",
      "epoch 7985\n",
      "test_train\n",
      "train mean loss=0.05600608605891466\n",
      "test_test\n",
      "test mean loss=1160.5064086914062\n",
      "epoch 7986\n",
      "test_train\n",
      "train mean loss=0.05674889404326677\n",
      "test_test\n",
      "test mean loss=1160.6495971679688\n",
      "epoch 7987\n",
      "test_train\n",
      "train mean loss=0.06015485431998968\n",
      "test_test\n",
      "test mean loss=1161.0668334960938\n",
      "epoch 7988\n",
      "test_train\n",
      "train mean loss=0.05612310953438282\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1160.197998046875\n",
      "epoch 7989\n",
      "test_train\n",
      "train mean loss=0.05013755817587177\n",
      "test_test\n",
      "test mean loss=1159.4855346679688\n",
      "epoch 7990\n",
      "test_train\n",
      "train mean loss=0.05487541016191244\n",
      "test_test\n",
      "test mean loss=1159.4305419921875\n",
      "epoch 7991\n",
      "test_train\n",
      "train mean loss=0.05234043082843224\n",
      "test_test\n",
      "test mean loss=1158.822509765625\n",
      "epoch 7992\n",
      "test_train\n",
      "train mean loss=0.051223892252892256\n",
      "test_test\n",
      "test mean loss=1159.583984375\n",
      "epoch 7993\n",
      "test_train\n",
      "train mean loss=0.05839686437199513\n",
      "test_test\n",
      "test mean loss=1159.2271728515625\n",
      "epoch 7994\n",
      "test_train\n",
      "train mean loss=0.05644331375757853\n",
      "test_test\n",
      "test mean loss=1158.901611328125\n",
      "epoch 7995\n",
      "test_train\n",
      "train mean loss=0.05239078588783741\n",
      "test_test\n",
      "test mean loss=1158.8000183105469\n",
      "epoch 7996\n",
      "test_train\n",
      "train mean loss=0.051389796659350395\n",
      "test_test\n",
      "test mean loss=1158.8468017578125\n",
      "epoch 7997\n",
      "test_train\n",
      "train mean loss=0.05785582090417544\n",
      "test_test\n",
      "test mean loss=1159.720947265625\n",
      "epoch 7998\n",
      "test_train\n",
      "train mean loss=0.05582184297963977\n",
      "test_test\n",
      "test mean loss=1158.638427734375\n",
      "epoch 7999\n",
      "test_train\n",
      "train mean loss=0.06003671480963627\n",
      "test_test\n",
      "test mean loss=1160.4198913574219\n",
      "epoch 8000\n",
      "test_train\n",
      "train mean loss=0.05088259450470408\n",
      "test_test\n",
      "test mean loss=1158.6420288085938\n",
      "epoch 8001\n",
      "test_train\n",
      "train mean loss=0.05591294324646393\n",
      "test_test\n",
      "test mean loss=1160.6714782714844\n",
      "epoch 8002\n",
      "test_train\n",
      "train mean loss=0.05414428903410832\n",
      "test_test\n",
      "test mean loss=1160.4630126953125\n",
      "epoch 8003\n",
      "test_train\n",
      "train mean loss=0.05552028305828571\n",
      "test_test\n",
      "test mean loss=1160.0286254882812\n",
      "epoch 8004\n",
      "test_train\n",
      "train mean loss=0.06176988004396359\n",
      "test_test\n",
      "test mean loss=1160.4529724121094\n",
      "epoch 8005\n",
      "test_train\n",
      "train mean loss=0.06112090374032656\n",
      "test_test\n",
      "test mean loss=1160.2742919921875\n",
      "epoch 8006\n",
      "test_train\n",
      "train mean loss=0.05606790414700905\n",
      "test_test\n",
      "test mean loss=1160.26318359375\n",
      "epoch 8007\n",
      "test_train\n",
      "train mean loss=0.06207994216432174\n",
      "test_test\n",
      "test mean loss=1159.6921997070312\n",
      "epoch 8008\n",
      "test_train\n",
      "train mean loss=0.05383612650136153\n",
      "test_test\n",
      "test mean loss=1159.1327514648438\n",
      "epoch 8009\n",
      "test_train\n",
      "train mean loss=0.052593604661524296\n",
      "test_test\n",
      "test mean loss=1159.7022705078125\n",
      "epoch 8010\n",
      "test_train\n",
      "train mean loss=0.058498846677442394\n",
      "test_test\n",
      "test mean loss=1160.0967407226562\n",
      "epoch 8011\n",
      "test_train\n",
      "train mean loss=0.05461484411110481\n",
      "test_test\n",
      "test mean loss=1160.0052490234375\n",
      "epoch 8012\n",
      "test_train\n",
      "train mean loss=0.0550002862388889\n",
      "test_test\n",
      "test mean loss=1160.9453125\n",
      "epoch 8013\n",
      "test_train\n",
      "train mean loss=0.05754374464352926\n",
      "test_test\n",
      "test mean loss=1159.808837890625\n",
      "epoch 8014\n",
      "test_train\n",
      "train mean loss=0.054512622145315014\n",
      "test_test\n",
      "test mean loss=1159.8571472167969\n",
      "epoch 8015\n",
      "test_train\n",
      "train mean loss=0.05631201403836409\n",
      "test_test\n",
      "test mean loss=1159.4284057617188\n",
      "epoch 8016\n",
      "test_train\n",
      "train mean loss=0.055023948196321726\n",
      "test_test\n",
      "test mean loss=1159.8248596191406\n",
      "epoch 8017\n",
      "test_train\n",
      "train mean loss=0.055949184422691665\n",
      "test_test\n",
      "test mean loss=1158.9602661132812\n",
      "epoch 8018\n",
      "test_train\n",
      "train mean loss=0.061142572201788425\n",
      "test_test\n",
      "test mean loss=1159.9864501953125\n",
      "epoch 8019\n",
      "test_train\n",
      "train mean loss=0.06277659876892965\n",
      "test_test\n",
      "test mean loss=1159.556640625\n",
      "epoch 8020\n",
      "test_train\n",
      "train mean loss=0.053989690418044724\n",
      "test_test\n",
      "test mean loss=1158.9749755859375\n",
      "epoch 8021\n",
      "test_train\n",
      "train mean loss=0.05295910810430845\n",
      "test_test\n",
      "test mean loss=1159.4986877441406\n",
      "epoch 8022\n",
      "test_train\n",
      "train mean loss=0.05278788413852453\n",
      "test_test\n",
      "test mean loss=1160.5335083007812\n",
      "epoch 8023\n",
      "test_train\n",
      "train mean loss=0.05332570491979519\n",
      "test_test\n",
      "test mean loss=1159.4447631835938\n",
      "epoch 8024\n",
      "test_train\n",
      "train mean loss=0.04766278558721145\n",
      "test_test\n",
      "test mean loss=1158.4921875\n",
      "epoch 8025\n",
      "test_train\n",
      "train mean loss=0.049014030024409294\n",
      "test_test\n",
      "test mean loss=1159.4249267578125\n",
      "epoch 8026\n",
      "test_train\n",
      "train mean loss=0.05173659262557825\n",
      "test_test\n",
      "test mean loss=1160.2711181640625\n",
      "epoch 8027\n",
      "test_train\n",
      "train mean loss=0.059049393981695175\n",
      "test_test\n",
      "test mean loss=1160.4492797851562\n",
      "epoch 8028\n",
      "test_train\n",
      "train mean loss=0.04992712071786324\n",
      "test_test\n",
      "test mean loss=1160.2406005859375\n",
      "epoch 8029\n",
      "test_train\n",
      "train mean loss=0.0534627353772521\n",
      "test_test\n",
      "test mean loss=1158.8892822265625\n",
      "epoch 8030\n",
      "test_train\n",
      "train mean loss=0.050547136925160885\n",
      "test_test\n",
      "test mean loss=1159.9037170410156\n",
      "epoch 8031\n",
      "test_train\n",
      "train mean loss=0.6627161502838135\n",
      "test_test\n",
      "test mean loss=1160.2306213378906\n",
      "epoch 8032\n",
      "test_train\n",
      "train mean loss=0.07259425427764654\n",
      "test_test\n",
      "test mean loss=1160.3907470703125\n",
      "epoch 8033\n",
      "test_train\n",
      "train mean loss=0.04580938691894213\n",
      "test_test\n",
      "test mean loss=1159.3231506347656\n",
      "epoch 8034\n",
      "test_train\n",
      "train mean loss=0.06058395467698574\n",
      "test_test\n",
      "test mean loss=1159.4926147460938\n",
      "epoch 8035\n",
      "test_train\n",
      "train mean loss=0.06234111450612545\n",
      "test_test\n",
      "test mean loss=1161.6943969726562\n",
      "epoch 8036\n",
      "test_train\n",
      "train mean loss=0.05772371621181568\n",
      "test_test\n",
      "test mean loss=1160.1924133300781\n",
      "epoch 8037\n",
      "test_train\n",
      "train mean loss=0.0633168291921417\n",
      "test_test\n",
      "test mean loss=1160.6175537109375\n",
      "epoch 8038\n",
      "test_train\n",
      "train mean loss=0.058194179398318134\n",
      "test_test\n",
      "test mean loss=1160.1045532226562\n",
      "epoch 8039\n",
      "test_train\n",
      "train mean loss=0.054311828687787056\n",
      "test_test\n",
      "test mean loss=1158.8551635742188\n",
      "epoch 8040\n",
      "test_train\n",
      "train mean loss=0.05167745783304175\n",
      "test_test\n",
      "test mean loss=1158.38525390625\n",
      "epoch 8041\n",
      "test_train\n",
      "train mean loss=0.05566780548542738\n",
      "test_test\n",
      "test mean loss=1158.2158813476562\n",
      "epoch 8042\n",
      "test_train\n",
      "train mean loss=0.05873250185201565\n",
      "test_test\n",
      "test mean loss=1160.14208984375\n",
      "epoch 8043\n",
      "test_train\n",
      "train mean loss=0.05594131164252758\n",
      "test_test\n",
      "test mean loss=1160.4667358398438\n",
      "epoch 8044\n",
      "test_train\n",
      "train mean loss=0.05885621719062328\n",
      "test_test\n",
      "test mean loss=1159.3091125488281\n",
      "epoch 8045\n",
      "test_train\n",
      "train mean loss=0.06267093494534492\n",
      "test_test\n",
      "test mean loss=1158.0240478515625\n",
      "epoch 8046\n",
      "test_train\n",
      "train mean loss=0.05554114809880654\n",
      "test_test\n",
      "test mean loss=1158.8111267089844\n",
      "epoch 8047\n",
      "test_train\n",
      "train mean loss=0.06308896063516538\n",
      "test_test\n",
      "test mean loss=1159.2615051269531\n",
      "epoch 8048\n",
      "test_train\n",
      "train mean loss=0.05359703799088796\n",
      "test_test\n",
      "test mean loss=1159.82275390625\n",
      "epoch 8049\n",
      "test_train\n",
      "train mean loss=0.05748840949187676\n",
      "test_test\n",
      "test mean loss=1159.2413635253906\n",
      "epoch 8050\n",
      "test_train\n",
      "train mean loss=0.052814009909828506\n",
      "test_test\n",
      "test mean loss=1158.9335327148438\n",
      "epoch 8051\n",
      "test_train\n",
      "train mean loss=0.05048635974526405\n",
      "test_test\n",
      "test mean loss=1158.8803100585938\n",
      "epoch 8052\n",
      "test_train\n",
      "train mean loss=0.053203378493587174\n",
      "test_test\n",
      "test mean loss=1159.1031494140625\n",
      "epoch 8053\n",
      "test_train\n",
      "train mean loss=0.06422931049019098\n",
      "test_test\n",
      "test mean loss=1160.1143188476562\n",
      "epoch 8054\n",
      "test_train\n",
      "train mean loss=0.05919109657406807\n",
      "test_test\n",
      "test mean loss=1158.5346069335938\n",
      "epoch 8055\n",
      "test_train\n",
      "train mean loss=0.06091250261912743\n",
      "test_test\n",
      "test mean loss=1159.2342834472656\n",
      "epoch 8056\n",
      "test_train\n",
      "train mean loss=0.054287692066282034\n",
      "test_test\n",
      "test mean loss=1159.97216796875\n",
      "epoch 8057\n",
      "test_train\n",
      "train mean loss=0.056064934780200325\n",
      "test_test\n",
      "test mean loss=1159.5292053222656\n",
      "epoch 8058\n",
      "test_train\n",
      "train mean loss=0.05088742356747389\n",
      "test_test\n",
      "test mean loss=1158.612060546875\n",
      "epoch 8059\n",
      "test_train\n",
      "train mean loss=0.050439941231161356\n",
      "test_test\n",
      "test mean loss=1159.9476318359375\n",
      "epoch 8060\n",
      "test_train\n",
      "train mean loss=0.05820278450846672\n",
      "test_test\n",
      "test mean loss=1160.1631774902344\n",
      "epoch 8061\n",
      "test_train\n",
      "train mean loss=0.05808399788414439\n",
      "test_test\n",
      "test mean loss=1157.8507690429688\n",
      "epoch 8062\n",
      "test_train\n",
      "train mean loss=0.05050290531168381\n",
      "test_test\n",
      "test mean loss=1159.1003723144531\n",
      "epoch 8063\n",
      "test_train\n",
      "train mean loss=0.054360230142871536\n",
      "test_test\n",
      "test mean loss=1160.0528564453125\n",
      "epoch 8064\n",
      "test_train\n",
      "train mean loss=0.05136297456920147\n",
      "test_test\n",
      "test mean loss=1158.7110290527344\n",
      "epoch 8065\n",
      "test_train\n",
      "train mean loss=0.05190932936966419\n",
      "test_test\n",
      "test mean loss=1159.7635498046875\n",
      "epoch 8066\n",
      "test_train\n",
      "train mean loss=0.04959875609104832\n",
      "test_test\n",
      "test mean loss=1159.5850219726562\n",
      "epoch 8067\n",
      "test_train\n",
      "train mean loss=0.05242574525376161\n",
      "test_test\n",
      "test mean loss=1160.2642822265625\n",
      "epoch 8068\n",
      "test_train\n",
      "train mean loss=0.05310783457631866\n",
      "test_test\n",
      "test mean loss=1160.56298828125\n",
      "epoch 8069\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.05421852165212234\n",
      "test_test\n",
      "test mean loss=1162.0841064453125\n",
      "epoch 8070\n",
      "test_train\n",
      "train mean loss=0.056896050771077476\n",
      "test_test\n",
      "test mean loss=1161.0786743164062\n",
      "epoch 8071\n",
      "test_train\n",
      "train mean loss=0.0525220554942886\n",
      "test_test\n",
      "test mean loss=1160.7038879394531\n",
      "epoch 8072\n",
      "test_train\n",
      "train mean loss=0.05365131547053655\n",
      "test_test\n",
      "test mean loss=1160.9600830078125\n",
      "epoch 8073\n",
      "test_train\n",
      "train mean loss=0.05800771495948235\n",
      "test_test\n",
      "test mean loss=1161.3821411132812\n",
      "epoch 8074\n",
      "test_train\n",
      "train mean loss=0.05574531356493632\n",
      "test_test\n",
      "test mean loss=1161.0064392089844\n",
      "epoch 8075\n",
      "test_train\n",
      "train mean loss=0.0533942844097813\n",
      "test_test\n",
      "test mean loss=1159.958251953125\n",
      "epoch 8076\n",
      "test_train\n",
      "train mean loss=0.05102574794242779\n",
      "test_test\n",
      "test mean loss=1159.5843200683594\n",
      "epoch 8077\n",
      "test_train\n",
      "train mean loss=0.05586412642151117\n",
      "test_test\n",
      "test mean loss=1160.631103515625\n",
      "epoch 8078\n",
      "test_train\n",
      "train mean loss=0.0578763239706556\n",
      "test_test\n",
      "test mean loss=1160.550048828125\n",
      "epoch 8079\n",
      "test_train\n",
      "train mean loss=0.05130729669084152\n",
      "test_test\n",
      "test mean loss=1160.3093872070312\n",
      "epoch 8080\n",
      "test_train\n",
      "train mean loss=0.052772147580981255\n",
      "test_test\n",
      "test mean loss=1159.6361083984375\n",
      "epoch 8081\n",
      "test_train\n",
      "train mean loss=0.0582921466169258\n",
      "test_test\n",
      "test mean loss=1158.3209228515625\n",
      "epoch 8082\n",
      "test_train\n",
      "train mean loss=0.05890822783112526\n",
      "test_test\n",
      "test mean loss=1158.8860473632812\n",
      "epoch 8083\n",
      "test_train\n",
      "train mean loss=0.053364461908737816\n",
      "test_test\n",
      "test mean loss=1160.1553344726562\n",
      "epoch 8084\n",
      "test_train\n",
      "train mean loss=0.0545177577684323\n",
      "test_test\n",
      "test mean loss=1161.1287231445312\n",
      "epoch 8085\n",
      "test_train\n",
      "train mean loss=0.059996145156522594\n",
      "test_test\n",
      "test mean loss=1162.2880249023438\n",
      "epoch 8086\n",
      "test_train\n",
      "train mean loss=0.05237182307367524\n",
      "test_test\n",
      "test mean loss=1160.3995361328125\n",
      "epoch 8087\n",
      "test_train\n",
      "train mean loss=0.05334573518484831\n",
      "test_test\n",
      "test mean loss=1159.1896362304688\n",
      "epoch 8088\n",
      "test_train\n",
      "train mean loss=0.05210426573952039\n",
      "test_test\n",
      "test mean loss=1159.30517578125\n",
      "epoch 8089\n",
      "test_train\n",
      "train mean loss=0.05340589117258787\n",
      "test_test\n",
      "test mean loss=1160.172119140625\n",
      "epoch 8090\n",
      "test_train\n",
      "train mean loss=0.05834191075215737\n",
      "test_test\n",
      "test mean loss=1159.4609985351562\n",
      "epoch 8091\n",
      "test_train\n",
      "train mean loss=0.05410623084753752\n",
      "test_test\n",
      "test mean loss=1160.5703125\n",
      "epoch 8092\n",
      "test_train\n",
      "train mean loss=0.048437208558122315\n",
      "test_test\n",
      "test mean loss=1159.8759155273438\n",
      "epoch 8093\n",
      "test_train\n",
      "train mean loss=0.04839177072669069\n",
      "test_test\n",
      "test mean loss=1159.8892211914062\n",
      "epoch 8094\n",
      "test_train\n",
      "train mean loss=0.051408706698566675\n",
      "test_test\n",
      "test mean loss=1160.1763305664062\n",
      "epoch 8095\n",
      "test_train\n",
      "train mean loss=0.048679268918931484\n",
      "test_test\n",
      "test mean loss=1159.8995971679688\n",
      "epoch 8096\n",
      "test_train\n",
      "train mean loss=0.05289377303173145\n",
      "test_test\n",
      "test mean loss=1158.9602355957031\n",
      "epoch 8097\n",
      "test_train\n",
      "train mean loss=0.048270803255339466\n",
      "test_test\n",
      "test mean loss=1159.3797607421875\n",
      "epoch 8098\n",
      "test_train\n",
      "train mean loss=0.04979399094978968\n",
      "test_test\n",
      "test mean loss=1159.6470947265625\n",
      "epoch 8099\n",
      "test_train\n",
      "train mean loss=0.051976614321271576\n",
      "test_test\n",
      "test mean loss=1159.8341674804688\n",
      "epoch 8100\n",
      "test_train\n",
      "train mean loss=0.061156997146705784\n",
      "test_test\n",
      "test mean loss=1159.9990539550781\n",
      "epoch 8101\n",
      "test_train\n",
      "train mean loss=0.05756967018047968\n",
      "test_test\n",
      "test mean loss=1160.9154663085938\n",
      "epoch 8102\n",
      "test_train\n",
      "train mean loss=0.052909184557696186\n",
      "test_test\n",
      "test mean loss=1159.1458435058594\n",
      "epoch 8103\n",
      "test_train\n",
      "train mean loss=0.054890286177396774\n",
      "test_test\n",
      "test mean loss=1157.8290405273438\n",
      "epoch 8104\n",
      "test_train\n",
      "train mean loss=0.04750148936485251\n",
      "test_test\n",
      "test mean loss=1158.6424560546875\n",
      "epoch 8105\n",
      "test_train\n",
      "train mean loss=0.07647228768716256\n",
      "test_test\n",
      "test mean loss=1160.5322265625\n",
      "epoch 8106\n",
      "test_train\n",
      "train mean loss=0.05271107299874226\n",
      "test_test\n",
      "test mean loss=1158.615966796875\n",
      "epoch 8107\n",
      "test_train\n",
      "train mean loss=0.05593605494747559\n",
      "test_test\n",
      "test mean loss=1158.8140258789062\n",
      "epoch 8108\n",
      "test_train\n",
      "train mean loss=0.054688477888703346\n",
      "test_test\n",
      "test mean loss=1159.2301940917969\n",
      "epoch 8109\n",
      "test_train\n",
      "train mean loss=0.05525470431894064\n",
      "test_test\n",
      "test mean loss=1160.11474609375\n",
      "epoch 8110\n",
      "test_train\n",
      "train mean loss=0.052600884499649204\n",
      "test_test\n",
      "test mean loss=1158.9193115234375\n",
      "epoch 8111\n",
      "test_train\n",
      "train mean loss=0.047012278654923044\n",
      "test_test\n",
      "test mean loss=1158.7523498535156\n",
      "epoch 8112\n",
      "test_train\n",
      "train mean loss=0.053278197844823204\n",
      "test_test\n",
      "test mean loss=1159.1864318847656\n",
      "epoch 8113\n",
      "test_train\n",
      "train mean loss=0.05374129411454002\n",
      "test_test\n",
      "test mean loss=1159.98974609375\n",
      "epoch 8114\n",
      "test_train\n",
      "train mean loss=0.050689811197419964\n",
      "test_test\n",
      "test mean loss=1160.2422485351562\n",
      "epoch 8115\n",
      "test_train\n",
      "train mean loss=0.057312880642712116\n",
      "test_test\n",
      "test mean loss=1160.258544921875\n",
      "epoch 8116\n",
      "test_train\n",
      "train mean loss=0.05285302006329099\n",
      "test_test\n",
      "test mean loss=1159.8578491210938\n",
      "epoch 8117\n",
      "test_train\n",
      "train mean loss=0.058281773080428444\n",
      "test_test\n",
      "test mean loss=1159.6724243164062\n",
      "epoch 8118\n",
      "test_train\n",
      "train mean loss=0.052422468550503254\n",
      "test_test\n",
      "test mean loss=1158.697021484375\n",
      "epoch 8119\n",
      "test_train\n",
      "train mean loss=0.05747600784525275\n",
      "test_test\n",
      "test mean loss=1158.9037780761719\n",
      "epoch 8120\n",
      "test_train\n",
      "train mean loss=0.05483106911803285\n",
      "test_test\n",
      "test mean loss=1158.6349487304688\n",
      "epoch 8121\n",
      "test_train\n",
      "train mean loss=0.059949617832899094\n",
      "test_test\n",
      "test mean loss=1158.8926391601562\n",
      "epoch 8122\n",
      "test_train\n",
      "train mean loss=0.054049602088828884\n",
      "test_test\n",
      "test mean loss=1158.9414672851562\n",
      "epoch 8123\n",
      "test_train\n",
      "train mean loss=0.05226961926867565\n",
      "test_test\n",
      "test mean loss=1158.5560302734375\n",
      "epoch 8124\n",
      "test_train\n",
      "train mean loss=0.0553467475498716\n",
      "test_test\n",
      "test mean loss=1159.974365234375\n",
      "epoch 8125\n",
      "test_train\n",
      "train mean loss=0.07780052938808997\n",
      "test_test\n",
      "test mean loss=1159.12548828125\n",
      "epoch 8126\n",
      "test_train\n",
      "train mean loss=0.07181915423522393\n",
      "test_test\n",
      "test mean loss=1159.9706420898438\n",
      "epoch 8127\n",
      "test_train\n",
      "train mean loss=0.05816516652703285\n",
      "test_test\n",
      "test mean loss=1159.2246398925781\n",
      "epoch 8128\n",
      "test_train\n",
      "train mean loss=0.049022959700475134\n",
      "test_test\n",
      "test mean loss=1158.7925415039062\n",
      "epoch 8129\n",
      "test_train\n",
      "train mean loss=0.05195543092365066\n",
      "test_test\n",
      "test mean loss=1159.0082397460938\n",
      "epoch 8130\n",
      "test_train\n",
      "train mean loss=0.04918259878953298\n",
      "test_test\n",
      "test mean loss=1158.1321411132812\n",
      "epoch 8131\n",
      "test_train\n",
      "train mean loss=0.0512641758347551\n",
      "test_test\n",
      "test mean loss=1157.729736328125\n",
      "epoch 8132\n",
      "test_train\n",
      "train mean loss=0.05314731535812219\n",
      "test_test\n",
      "test mean loss=1158.7014465332031\n",
      "epoch 8133\n",
      "test_train\n",
      "train mean loss=0.055186382650087275\n",
      "test_test\n",
      "test mean loss=1158.2819213867188\n",
      "epoch 8134\n",
      "test_train\n",
      "train mean loss=0.04825060783574978\n",
      "test_test\n",
      "test mean loss=1157.7732543945312\n",
      "epoch 8135\n",
      "test_train\n",
      "train mean loss=0.16683954559266567\n",
      "test_test\n",
      "test mean loss=1151.2250366210938\n",
      "epoch 8136\n",
      "test_train\n",
      "train mean loss=0.053866873340060316\n",
      "test_test\n",
      "test mean loss=1160.026611328125\n",
      "epoch 8137\n",
      "test_train\n",
      "train mean loss=0.05247836218525966\n",
      "test_test\n",
      "test mean loss=1159.5624389648438\n",
      "epoch 8138\n",
      "test_train\n",
      "train mean loss=0.049458773185809456\n",
      "test_test\n",
      "test mean loss=1159.135009765625\n",
      "epoch 8139\n",
      "test_train\n",
      "train mean loss=0.05228783733521899\n",
      "test_test\n",
      "test mean loss=1160.2687683105469\n",
      "epoch 8140\n",
      "test_train\n",
      "train mean loss=0.10616078600287437\n",
      "test_test\n",
      "test mean loss=1160.2206726074219\n",
      "epoch 8141\n",
      "test_train\n",
      "train mean loss=0.05672551350047191\n",
      "test_test\n",
      "test mean loss=1159.7905883789062\n",
      "epoch 8142\n",
      "test_train\n",
      "train mean loss=0.05895999725908041\n",
      "test_test\n",
      "test mean loss=1159.3192138671875\n",
      "epoch 8143\n",
      "test_train\n",
      "train mean loss=0.053096575352052845\n",
      "test_test\n",
      "test mean loss=1159.1430969238281\n",
      "epoch 8144\n",
      "test_train\n",
      "train mean loss=0.05024392157793045\n",
      "test_test\n",
      "test mean loss=1157.822265625\n",
      "epoch 8145\n",
      "test_train\n",
      "train mean loss=0.05703919970740875\n",
      "test_test\n",
      "test mean loss=1159.6636657714844\n",
      "epoch 8146\n",
      "test_train\n",
      "train mean loss=0.0609789602458477\n",
      "test_test\n",
      "test mean loss=1159.4169311523438\n",
      "epoch 8147\n",
      "test_train\n",
      "train mean loss=0.05717702334125837\n",
      "test_test\n",
      "test mean loss=1159.7005310058594\n",
      "epoch 8148\n",
      "test_train\n",
      "train mean loss=0.059297334092358746\n",
      "test_test\n",
      "test mean loss=1160.1534118652344\n",
      "epoch 8149\n",
      "test_train\n",
      "train mean loss=0.05258588151385387\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_test\n",
      "test mean loss=1158.9481811523438\n",
      "epoch 8150\n",
      "test_train\n",
      "train mean loss=0.05200921883806586\n",
      "test_test\n",
      "test mean loss=1159.3135681152344\n",
      "epoch 8151\n",
      "test_train\n",
      "train mean loss=0.04745318507775664\n",
      "test_test\n",
      "test mean loss=1159.531982421875\n",
      "epoch 8152\n",
      "test_train\n",
      "train mean loss=0.0510091632604599\n",
      "test_test\n",
      "test mean loss=1159.382080078125\n",
      "epoch 8153\n",
      "test_train\n",
      "train mean loss=0.05214631992081801\n",
      "test_test\n",
      "test mean loss=1159.3930053710938\n",
      "epoch 8154\n",
      "test_train\n",
      "train mean loss=0.05001301706458131\n",
      "test_test\n",
      "test mean loss=1159.1495971679688\n",
      "epoch 8155\n",
      "test_train\n",
      "train mean loss=0.059298232197761536\n",
      "test_test\n",
      "test mean loss=1160.4536743164062\n",
      "epoch 8156\n",
      "test_train\n",
      "train mean loss=0.055949716828763485\n",
      "test_test\n",
      "test mean loss=1159.7643127441406\n",
      "epoch 8157\n",
      "test_train\n",
      "train mean loss=0.05134581339855989\n",
      "test_test\n",
      "test mean loss=1159.5456237792969\n",
      "epoch 8158\n",
      "test_train\n",
      "train mean loss=0.04940589237958193\n",
      "test_test\n",
      "test mean loss=1159.2368774414062\n",
      "epoch 8159\n",
      "test_train\n",
      "train mean loss=0.05699306773021817\n",
      "test_test\n",
      "test mean loss=1159.4465942382812\n",
      "epoch 8160\n",
      "test_train\n",
      "train mean loss=0.04685393224159876\n",
      "test_test\n",
      "test mean loss=1158.9652709960938\n",
      "epoch 8161\n",
      "test_train\n",
      "train mean loss=0.05230355371410648\n",
      "test_test\n",
      "test mean loss=1158.8648681640625\n",
      "epoch 8162\n",
      "test_train\n",
      "train mean loss=0.0499694423439602\n",
      "test_test\n",
      "test mean loss=1159.1090393066406\n",
      "epoch 8163\n",
      "test_train\n",
      "train mean loss=0.05095947037140528\n",
      "test_test\n",
      "test mean loss=1159.6829833984375\n",
      "epoch 8164\n",
      "test_train\n",
      "train mean loss=0.055653430676708616\n",
      "test_test\n",
      "test mean loss=1159.2228088378906\n",
      "epoch 8165\n",
      "test_train\n",
      "train mean loss=0.05786280365039905\n",
      "test_test\n",
      "test mean loss=1159.4476928710938\n",
      "epoch 8166\n",
      "test_train\n",
      "train mean loss=0.11736158343652885\n",
      "test_test\n",
      "test mean loss=1161.1445617675781\n",
      "epoch 8167\n",
      "test_train\n",
      "train mean loss=0.055358756644030414\n",
      "test_test\n",
      "test mean loss=1159.0137939453125\n",
      "epoch 8168\n",
      "test_train\n",
      "train mean loss=0.05444922763854265\n",
      "test_test\n",
      "test mean loss=1160.3556823730469\n",
      "epoch 8169\n",
      "test_train\n",
      "train mean loss=0.053152572674055897\n",
      "test_test\n",
      "test mean loss=1158.7994384765625\n",
      "epoch 8170\n",
      "test_train\n",
      "train mean loss=0.05136901590352257\n",
      "test_test\n",
      "test mean loss=1158.9827880859375\n",
      "epoch 8171\n",
      "test_train\n",
      "train mean loss=0.05214017676189542\n",
      "test_test\n",
      "test mean loss=1158.390869140625\n",
      "epoch 8172\n",
      "test_train\n",
      "train mean loss=0.1256823753938079\n",
      "test_test\n",
      "test mean loss=1157.7589111328125\n",
      "epoch 8173\n",
      "test_train\n",
      "train mean loss=0.059873636811971664\n",
      "test_test\n",
      "test mean loss=1160.1526184082031\n",
      "epoch 8174\n",
      "test_train\n",
      "train mean loss=0.05471379371980826\n",
      "test_test\n",
      "test mean loss=1159.6039733886719\n",
      "epoch 8175\n",
      "test_train\n",
      "train mean loss=0.05183125256250302\n",
      "test_test\n",
      "test mean loss=1158.5966491699219\n",
      "epoch 8176\n",
      "test_train\n",
      "train mean loss=0.0574103764568766\n",
      "test_test\n",
      "test mean loss=1158.3721313476562\n",
      "epoch 8177\n",
      "test_train\n",
      "train mean loss=0.05839089738825957\n",
      "test_test\n",
      "test mean loss=1159.7110595703125\n",
      "epoch 8178\n",
      "test_train\n",
      "train mean loss=0.05319567148884138\n",
      "test_test\n",
      "test mean loss=1158.4297485351562\n",
      "epoch 8179\n",
      "test_train\n",
      "train mean loss=0.06112629516671101\n",
      "test_test\n",
      "test mean loss=1160.1932067871094\n",
      "epoch 8180\n",
      "test_train\n",
      "train mean loss=0.04882355546578765\n",
      "test_test\n",
      "test mean loss=1158.9804077148438\n",
      "epoch 8181\n",
      "test_train\n",
      "train mean loss=0.05063707412530979\n",
      "test_test\n",
      "test mean loss=1159.3023681640625\n",
      "epoch 8182\n",
      "test_train\n",
      "train mean loss=0.052688610119124256\n",
      "test_test\n",
      "test mean loss=1158.7354736328125\n",
      "epoch 8183\n",
      "test_train\n",
      "train mean loss=2.109418342510859\n",
      "test_test\n",
      "test mean loss=1157.6361083984375\n",
      "epoch 8184\n",
      "test_train\n",
      "train mean loss=0.32888350263237953\n",
      "test_test\n",
      "test mean loss=1157.3624877929688\n",
      "epoch 8185\n",
      "test_train\n",
      "train mean loss=0.06518436409533024\n",
      "test_test\n",
      "test mean loss=1158.5563354492188\n",
      "epoch 8186\n",
      "test_train\n",
      "train mean loss=0.06537757503489654\n",
      "test_test\n",
      "test mean loss=1158.2957763671875\n",
      "epoch 8187\n",
      "test_train\n",
      "train mean loss=0.06900888681411743\n",
      "test_test\n",
      "test mean loss=1160.3502502441406\n",
      "epoch 8188\n",
      "test_train\n",
      "train mean loss=0.06390831215927999\n",
      "test_test\n",
      "test mean loss=1158.8178100585938\n",
      "epoch 8189\n",
      "test_train\n",
      "train mean loss=0.06617265443007152\n",
      "test_test\n",
      "test mean loss=1159.8507385253906\n",
      "epoch 8190\n",
      "test_train\n",
      "train mean loss=0.06587728889038165\n",
      "test_test\n",
      "test mean loss=1158.185791015625\n",
      "epoch 8191\n",
      "test_train\n",
      "train mean loss=0.05352137548228105\n",
      "test_test\n",
      "test mean loss=1158.0818176269531\n",
      "epoch 8192\n",
      "test_train\n",
      "train mean loss=0.05713531840592623\n",
      "test_test\n",
      "test mean loss=1160.2855224609375\n",
      "epoch 8193\n",
      "test_train\n",
      "train mean loss=0.06190665066242218\n",
      "test_test\n",
      "test mean loss=1160.81982421875\n",
      "epoch 8194\n",
      "test_train\n",
      "train mean loss=0.06504010657469432\n",
      "test_test\n",
      "test mean loss=1160.8507690429688\n",
      "epoch 8195\n",
      "test_train\n",
      "train mean loss=0.05242077478518089\n",
      "test_test\n",
      "test mean loss=1160.3301696777344\n",
      "epoch 8196\n",
      "test_train\n",
      "train mean loss=0.06305534578859806\n",
      "test_test\n",
      "test mean loss=1158.6844482421875\n",
      "epoch 8197\n",
      "test_train\n",
      "train mean loss=0.05547401309013367\n",
      "test_test\n",
      "test mean loss=1160.4476623535156\n",
      "epoch 8198\n",
      "test_train\n",
      "train mean loss=0.08016168760756652\n",
      "test_test\n",
      "test mean loss=1160.9662475585938\n",
      "epoch 8199\n",
      "test_train\n",
      "train mean loss=0.056020231607059635\n",
      "test_test\n",
      "test mean loss=1160.1422729492188\n",
      "epoch 8200\n",
      "test_train\n",
      "train mean loss=0.05697811239709457\n",
      "test_test\n",
      "test mean loss=1160.0813293457031\n",
      "epoch 8201\n",
      "test_train\n",
      "train mean loss=0.0724379535143574\n",
      "test_test\n",
      "test mean loss=1159.4446716308594\n",
      "epoch 8202\n",
      "test_train\n",
      "train mean loss=0.05674579242865244\n",
      "test_test\n",
      "test mean loss=1159.787353515625\n",
      "epoch 8203\n",
      "test_train\n",
      "train mean loss=0.054825544667740665\n",
      "test_test\n",
      "test mean loss=1159.9095764160156\n",
      "epoch 8204\n",
      "test_train\n",
      "train mean loss=0.058106852074464165\n",
      "test_test\n",
      "test mean loss=1161.1051635742188\n",
      "epoch 8205\n",
      "test_train\n",
      "train mean loss=0.05518278650318583\n",
      "test_test\n",
      "test mean loss=1159.5114135742188\n",
      "epoch 8206\n",
      "test_train\n",
      "train mean loss=0.05953444757809242\n",
      "test_test\n",
      "test mean loss=1160.4724731445312\n",
      "epoch 8207\n",
      "test_train\n",
      "train mean loss=0.0545798894794037\n",
      "test_test\n",
      "test mean loss=1159.0169677734375\n",
      "epoch 8208\n",
      "test_train\n",
      "train mean loss=0.07765366975218058\n",
      "test_test\n",
      "test mean loss=1160.6992797851562\n",
      "epoch 8209\n",
      "test_train\n",
      "train mean loss=0.05101763022442659\n",
      "test_test\n",
      "test mean loss=1159.7119445800781\n",
      "epoch 8210\n",
      "test_train\n",
      "train mean loss=0.06157377144942681\n",
      "test_test\n",
      "test mean loss=1159.843017578125\n",
      "epoch 8211\n",
      "test_train\n",
      "train mean loss=0.05939137749373913\n",
      "test_test\n",
      "test mean loss=1160.5223388671875\n",
      "epoch 8212\n",
      "test_train\n",
      "train mean loss=0.05682077119126916\n",
      "test_test\n",
      "test mean loss=1160.9226379394531\n",
      "epoch 8213\n",
      "test_train\n",
      "train mean loss=0.05747071746736765\n",
      "test_test\n",
      "test mean loss=1160.8681640625\n",
      "epoch 8214\n",
      "test_train\n",
      "train mean loss=0.05836020347972711\n",
      "test_test\n",
      "test mean loss=1160.5627136230469\n",
      "epoch 8215\n",
      "test_train\n",
      "train mean loss=0.06146244890987873\n",
      "test_test\n",
      "test mean loss=1160.6823120117188\n",
      "epoch 8216\n",
      "test_train\n",
      "train mean loss=0.059489872927467026\n",
      "test_test\n",
      "test mean loss=1160.0134887695312\n",
      "epoch 8217\n",
      "test_train\n",
      "train mean loss=0.053287741262465715\n",
      "test_test\n",
      "test mean loss=1159.6785888671875\n",
      "epoch 8218\n",
      "test_train\n",
      "train mean loss=0.07799229181061189\n",
      "test_test\n",
      "test mean loss=1159.4114379882812\n",
      "epoch 8219\n",
      "test_train\n",
      "train mean loss=0.06288583111017942\n",
      "test_test\n",
      "test mean loss=1160.218017578125\n",
      "epoch 8220\n",
      "test_train\n",
      "train mean loss=0.05528152361512184\n",
      "test_test\n",
      "test mean loss=1158.9898071289062\n",
      "epoch 8221\n",
      "test_train\n",
      "train mean loss=0.054579646326601505\n",
      "test_test\n",
      "test mean loss=1159.3297424316406\n",
      "epoch 8222\n",
      "test_train\n",
      "train mean loss=0.06117488847424587\n",
      "test_test\n",
      "test mean loss=1159.8950805664062\n",
      "epoch 8223\n",
      "test_train\n",
      "train mean loss=0.06105174186329047\n",
      "test_test\n",
      "test mean loss=1160.031982421875\n",
      "epoch 8224\n",
      "test_train\n",
      "train mean loss=0.05190323293209076\n",
      "test_test\n",
      "test mean loss=1159.4268188476562\n",
      "epoch 8225\n",
      "test_train\n",
      "train mean loss=0.04871230572462082\n",
      "test_test\n",
      "test mean loss=1157.9625549316406\n",
      "epoch 8226\n",
      "test_train\n",
      "train mean loss=0.05936297277609507\n",
      "test_test\n",
      "test mean loss=1158.8859252929688\n",
      "epoch 8227\n",
      "test_train\n",
      "train mean loss=0.05926169486095508\n",
      "test_test\n",
      "test mean loss=1159.989990234375\n",
      "epoch 8228\n",
      "test_train\n",
      "train mean loss=0.05462782643735409\n",
      "test_test\n",
      "test mean loss=1159.2599487304688\n",
      "epoch 8229\n",
      "test_train\n",
      "train mean loss=0.056001707911491394\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1158.847900390625\n",
      "epoch 8230\n",
      "test_train\n",
      "train mean loss=0.06144745058069626\n",
      "test_test\n",
      "test mean loss=1159.4591369628906\n",
      "epoch 8231\n",
      "test_train\n",
      "train mean loss=0.06409281771630049\n",
      "test_test\n",
      "test mean loss=1158.7413330078125\n",
      "epoch 8232\n",
      "test_train\n",
      "train mean loss=0.05300006767114004\n",
      "test_test\n",
      "test mean loss=1159.5531005859375\n",
      "epoch 8233\n",
      "test_train\n",
      "train mean loss=0.054355188738554716\n",
      "test_test\n",
      "test mean loss=1158.964111328125\n",
      "epoch 8234\n",
      "test_train\n",
      "train mean loss=0.05110082340737184\n",
      "test_test\n",
      "test mean loss=1158.2649536132812\n",
      "epoch 8235\n",
      "test_train\n",
      "train mean loss=0.051797522542377315\n",
      "test_test\n",
      "test mean loss=1158.3706665039062\n",
      "epoch 8236\n",
      "test_train\n",
      "train mean loss=0.05558463868995508\n",
      "test_test\n",
      "test mean loss=1158.5310668945312\n",
      "epoch 8237\n",
      "test_train\n",
      "train mean loss=0.05209799141933521\n",
      "test_test\n",
      "test mean loss=1158.2208557128906\n",
      "epoch 8238\n",
      "test_train\n",
      "train mean loss=0.049376690139373146\n",
      "test_test\n",
      "test mean loss=1159.0699157714844\n",
      "epoch 8239\n",
      "test_train\n",
      "train mean loss=0.08846806424359481\n",
      "test_test\n",
      "test mean loss=1160.5022583007812\n",
      "epoch 8240\n",
      "test_train\n",
      "train mean loss=0.057944714557379484\n",
      "test_test\n",
      "test mean loss=1160.1231994628906\n",
      "epoch 8241\n",
      "test_train\n",
      "train mean loss=0.04993179704373082\n",
      "test_test\n",
      "test mean loss=1159.8041687011719\n",
      "epoch 8242\n",
      "test_train\n",
      "train mean loss=0.062114969827234745\n",
      "test_test\n",
      "test mean loss=1160.2257080078125\n",
      "epoch 8243\n",
      "test_train\n",
      "train mean loss=0.05551580727721254\n",
      "test_test\n",
      "test mean loss=1159.7586059570312\n",
      "epoch 8244\n",
      "test_train\n",
      "train mean loss=0.052799749188125134\n",
      "test_test\n",
      "test mean loss=1158.270263671875\n",
      "epoch 8245\n",
      "test_train\n",
      "train mean loss=0.05906150055428346\n",
      "test_test\n",
      "test mean loss=1159.15185546875\n",
      "epoch 8246\n",
      "test_train\n",
      "train mean loss=0.05005326711883148\n",
      "test_test\n",
      "test mean loss=1159.069580078125\n",
      "epoch 8247\n",
      "test_train\n",
      "train mean loss=0.058779517809549965\n",
      "test_test\n",
      "test mean loss=1158.2349548339844\n",
      "epoch 8248\n",
      "test_train\n",
      "train mean loss=0.05713870997230212\n",
      "test_test\n",
      "test mean loss=1159.7865905761719\n",
      "epoch 8249\n",
      "test_train\n",
      "train mean loss=0.148280152430137\n",
      "test_test\n",
      "test mean loss=1162.3665771484375\n",
      "epoch 8250\n",
      "test_train\n",
      "train mean loss=0.05726003445064028\n",
      "test_test\n",
      "test mean loss=1160.1697998046875\n",
      "epoch 8251\n",
      "test_train\n",
      "train mean loss=0.05209770270933708\n",
      "test_test\n",
      "test mean loss=1160.3701782226562\n",
      "epoch 8252\n",
      "test_train\n",
      "train mean loss=0.13994284253567457\n",
      "test_test\n",
      "test mean loss=1155.4286499023438\n",
      "epoch 8253\n",
      "test_train\n",
      "train mean loss=0.050425815706451736\n",
      "test_test\n",
      "test mean loss=1159.0992736816406\n",
      "epoch 8254\n",
      "test_train\n",
      "train mean loss=0.05505177782227596\n",
      "test_test\n",
      "test mean loss=1159.8634643554688\n",
      "epoch 8255\n",
      "test_train\n",
      "train mean loss=0.05545430568357309\n",
      "test_test\n",
      "test mean loss=1158.2306823730469\n",
      "epoch 8256\n",
      "test_train\n",
      "train mean loss=0.04850157257169485\n",
      "test_test\n",
      "test mean loss=1158.6958312988281\n",
      "epoch 8257\n",
      "test_train\n",
      "train mean loss=0.047732590697705746\n",
      "test_test\n",
      "test mean loss=1159.120849609375\n",
      "epoch 8258\n",
      "test_train\n",
      "train mean loss=0.05917388402546445\n",
      "test_test\n",
      "test mean loss=1156.9266357421875\n",
      "epoch 8259\n",
      "test_train\n",
      "train mean loss=0.05281678028404713\n",
      "test_test\n",
      "test mean loss=1159.8187255859375\n",
      "epoch 8260\n",
      "test_train\n",
      "train mean loss=0.06591143428037564\n",
      "test_test\n",
      "test mean loss=1160.0298156738281\n",
      "epoch 8261\n",
      "test_train\n",
      "train mean loss=0.05332853924483061\n",
      "test_test\n",
      "test mean loss=1158.5433349609375\n",
      "epoch 8262\n",
      "test_train\n",
      "train mean loss=0.05117119196802378\n",
      "test_test\n",
      "test mean loss=1159.0704956054688\n",
      "epoch 8263\n",
      "test_train\n",
      "train mean loss=0.05983390845358372\n",
      "test_test\n",
      "test mean loss=1159.3554992675781\n",
      "epoch 8264\n",
      "test_train\n",
      "train mean loss=0.06337325957914193\n",
      "test_test\n",
      "test mean loss=1161.5198974609375\n",
      "epoch 8265\n",
      "test_train\n",
      "train mean loss=0.057879029773175716\n",
      "test_test\n",
      "test mean loss=1160.7420654296875\n",
      "epoch 8266\n",
      "test_train\n",
      "train mean loss=0.061165662171940006\n",
      "test_test\n",
      "test mean loss=1160.7025756835938\n",
      "epoch 8267\n",
      "test_train\n",
      "train mean loss=0.06316363997757435\n",
      "test_test\n",
      "test mean loss=1161.0446472167969\n",
      "epoch 8268\n",
      "test_train\n",
      "train mean loss=0.06914326331267755\n",
      "test_test\n",
      "test mean loss=1160.8643798828125\n",
      "epoch 8269\n",
      "test_train\n",
      "train mean loss=0.3408445951839288\n",
      "test_test\n",
      "test mean loss=1161.2239074707031\n",
      "epoch 8270\n",
      "test_train\n",
      "train mean loss=0.0644799955189228\n",
      "test_test\n",
      "test mean loss=1159.8975219726562\n",
      "epoch 8271\n",
      "test_train\n",
      "train mean loss=0.056104485876858234\n",
      "test_test\n",
      "test mean loss=1158.8778686523438\n",
      "epoch 8272\n",
      "test_train\n",
      "train mean loss=0.05988461462159952\n",
      "test_test\n",
      "test mean loss=1159.1610717773438\n",
      "epoch 8273\n",
      "test_train\n",
      "train mean loss=0.05966736702248454\n",
      "test_test\n",
      "test mean loss=1159.0843505859375\n",
      "epoch 8274\n",
      "test_train\n",
      "train mean loss=0.07678574540962775\n",
      "test_test\n",
      "test mean loss=1158.27099609375\n",
      "epoch 8275\n",
      "test_train\n",
      "train mean loss=0.061674452386796474\n",
      "test_test\n",
      "test mean loss=1159.5512084960938\n",
      "epoch 8276\n",
      "test_train\n",
      "train mean loss=0.06170129651824633\n",
      "test_test\n",
      "test mean loss=1159.27001953125\n",
      "epoch 8277\n",
      "test_train\n",
      "train mean loss=0.05570028225580851\n",
      "test_test\n",
      "test mean loss=1159.2434692382812\n",
      "epoch 8278\n",
      "test_train\n",
      "train mean loss=0.049203754092256226\n",
      "test_test\n",
      "test mean loss=1158.1754150390625\n",
      "epoch 8279\n",
      "test_train\n",
      "train mean loss=0.047785228273520865\n",
      "test_test\n",
      "test mean loss=1158.3515014648438\n",
      "epoch 8280\n",
      "test_train\n",
      "train mean loss=0.05278169581045707\n",
      "test_test\n",
      "test mean loss=1158.8174133300781\n",
      "epoch 8281\n",
      "test_train\n",
      "train mean loss=0.04854106313238541\n",
      "test_test\n",
      "test mean loss=1158.3187866210938\n",
      "epoch 8282\n",
      "test_train\n",
      "train mean loss=0.05152741866186261\n",
      "test_test\n",
      "test mean loss=1156.535888671875\n",
      "epoch 8283\n",
      "test_train\n",
      "train mean loss=0.05418060068041086\n",
      "test_test\n",
      "test mean loss=1153.8621215820312\n",
      "epoch 8284\n",
      "test_train\n",
      "train mean loss=0.06481901214768489\n",
      "test_test\n",
      "test mean loss=1160.9425659179688\n",
      "epoch 8285\n",
      "test_train\n",
      "train mean loss=0.05118047446012497\n",
      "test_test\n",
      "test mean loss=1158.7058410644531\n",
      "epoch 8286\n",
      "test_train\n",
      "train mean loss=0.05269237048923969\n",
      "test_test\n",
      "test mean loss=1158.3501586914062\n",
      "epoch 8287\n",
      "test_train\n",
      "train mean loss=0.05397670933355888\n",
      "test_test\n",
      "test mean loss=1158.2344360351562\n",
      "epoch 8288\n",
      "test_train\n",
      "train mean loss=0.04838005422304074\n",
      "test_test\n",
      "test mean loss=1158.1397705078125\n",
      "epoch 8289\n",
      "test_train\n",
      "train mean loss=0.058331893446544804\n",
      "test_test\n",
      "test mean loss=1156.9521789550781\n",
      "epoch 8290\n",
      "test_train\n",
      "train mean loss=0.057710019095490374\n",
      "test_test\n",
      "test mean loss=1158.8151245117188\n",
      "epoch 8291\n",
      "test_train\n",
      "train mean loss=0.047150903226186834\n",
      "test_test\n",
      "test mean loss=1157.6401977539062\n",
      "epoch 8292\n",
      "test_train\n",
      "train mean loss=0.05029243975877762\n",
      "test_test\n",
      "test mean loss=1157.0696716308594\n",
      "epoch 8293\n",
      "test_train\n",
      "train mean loss=0.053720736565689244\n",
      "test_test\n",
      "test mean loss=1158.81396484375\n",
      "epoch 8294\n",
      "test_train\n",
      "train mean loss=0.06343885449071725\n",
      "test_test\n",
      "test mean loss=1158.3917846679688\n",
      "epoch 8295\n",
      "test_train\n",
      "train mean loss=0.05604501844694217\n",
      "test_test\n",
      "test mean loss=1157.6942138671875\n",
      "epoch 8296\n",
      "test_train\n",
      "train mean loss=0.058109396137297153\n",
      "test_test\n",
      "test mean loss=1157.9736022949219\n",
      "epoch 8297\n",
      "test_train\n",
      "train mean loss=0.06007884023711085\n",
      "test_test\n",
      "test mean loss=1157.1160888671875\n",
      "epoch 8298\n",
      "test_train\n",
      "train mean loss=0.06117773444081346\n",
      "test_test\n",
      "test mean loss=1159.1539306640625\n",
      "epoch 8299\n",
      "test_train\n",
      "train mean loss=0.04788334791858991\n",
      "test_test\n",
      "test mean loss=1158.54052734375\n",
      "epoch 8300\n",
      "test_train\n",
      "train mean loss=0.04976963655402263\n",
      "test_test\n",
      "test mean loss=1158.6595764160156\n",
      "epoch 8301\n",
      "test_train\n",
      "train mean loss=0.052318769972771406\n",
      "test_test\n",
      "test mean loss=1158.796630859375\n",
      "epoch 8302\n",
      "test_train\n",
      "train mean loss=0.04705161197731892\n",
      "test_test\n",
      "test mean loss=1159.0547485351562\n",
      "epoch 8303\n",
      "test_train\n",
      "train mean loss=0.05136932417129477\n",
      "test_test\n",
      "test mean loss=1159.8074951171875\n",
      "epoch 8304\n",
      "test_train\n",
      "train mean loss=0.04496844314659635\n",
      "test_test\n",
      "test mean loss=1159.0089721679688\n",
      "epoch 8305\n",
      "test_train\n",
      "train mean loss=0.055810293182730675\n",
      "test_test\n",
      "test mean loss=1158.3349609375\n",
      "epoch 8306\n",
      "test_train\n",
      "train mean loss=0.050463881033162274\n",
      "test_test\n",
      "test mean loss=1158.6890563964844\n",
      "epoch 8307\n",
      "test_train\n",
      "train mean loss=0.05528875192006429\n",
      "test_test\n",
      "test mean loss=1159.158935546875\n",
      "epoch 8308\n",
      "test_train\n",
      "train mean loss=0.056408545623222985\n",
      "test_test\n",
      "test mean loss=1158.0011596679688\n",
      "epoch 8309\n",
      "test_train\n",
      "train mean loss=0.05298928916454315\n",
      "test_test\n",
      "test mean loss=1159.2356567382812\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8310\n",
      "test_train\n",
      "train mean loss=0.056883225527902447\n",
      "test_test\n",
      "test mean loss=1159.6329345703125\n",
      "epoch 8311\n",
      "test_train\n",
      "train mean loss=0.057230247339854635\n",
      "test_test\n",
      "test mean loss=1159.1253662109375\n",
      "epoch 8312\n",
      "test_train\n",
      "train mean loss=0.05388008678952853\n",
      "test_test\n",
      "test mean loss=1159.54638671875\n",
      "epoch 8313\n",
      "test_train\n",
      "train mean loss=0.28372808297475177\n",
      "test_test\n",
      "test mean loss=1155.8660278320312\n",
      "epoch 8314\n",
      "test_train\n",
      "train mean loss=0.08252608807136615\n",
      "test_test\n",
      "test mean loss=1160.0001831054688\n",
      "epoch 8315\n",
      "test_train\n",
      "train mean loss=0.06371508600811164\n",
      "test_test\n",
      "test mean loss=1151.4073791503906\n",
      "epoch 8316\n",
      "test_train\n",
      "train mean loss=0.061216300042967\n",
      "test_test\n",
      "test mean loss=1145.2411804199219\n",
      "epoch 8317\n",
      "test_train\n",
      "train mean loss=0.0626084425797065\n",
      "test_test\n",
      "test mean loss=1154.4754638671875\n",
      "epoch 8318\n",
      "test_train\n",
      "train mean loss=0.059818683192133904\n",
      "test_test\n",
      "test mean loss=1197.1042785644531\n",
      "epoch 8319\n",
      "test_train\n",
      "train mean loss=0.06104914704337716\n",
      "test_test\n",
      "test mean loss=1164.9633178710938\n",
      "epoch 8320\n",
      "test_train\n",
      "train mean loss=0.0659906327103575\n",
      "test_test\n",
      "test mean loss=1156.458740234375\n",
      "epoch 8321\n",
      "test_train\n",
      "train mean loss=0.060181908309459686\n",
      "test_test\n",
      "test mean loss=1151.0437927246094\n",
      "epoch 8322\n",
      "test_train\n",
      "train mean loss=0.05548081764330467\n",
      "test_test\n",
      "test mean loss=1147.6846923828125\n",
      "epoch 8323\n",
      "test_train\n",
      "train mean loss=0.0545277651399374\n",
      "test_test\n",
      "test mean loss=1146.6188354492188\n",
      "epoch 8324\n",
      "test_train\n",
      "train mean loss=0.055132330084840454\n",
      "test_test\n",
      "test mean loss=1152.0233459472656\n",
      "epoch 8325\n",
      "test_train\n",
      "train mean loss=0.05088348717739185\n",
      "test_test\n",
      "test mean loss=1198.8143920898438\n",
      "epoch 8326\n",
      "test_train\n",
      "train mean loss=0.05227149402101835\n",
      "test_test\n",
      "test mean loss=1272.5086059570312\n",
      "epoch 8327\n",
      "test_train\n",
      "train mean loss=0.05326104521130522\n",
      "test_test\n",
      "test mean loss=1306.771240234375\n",
      "epoch 8328\n",
      "test_train\n",
      "train mean loss=0.056663201190531254\n",
      "test_test\n",
      "test mean loss=1149.1138916015625\n",
      "epoch 8329\n",
      "test_train\n",
      "train mean loss=0.057685560236374535\n",
      "test_test\n",
      "test mean loss=1147.3812866210938\n",
      "epoch 8330\n",
      "test_train\n",
      "train mean loss=0.05946531674514214\n",
      "test_test\n",
      "test mean loss=1149.4393310546875\n",
      "epoch 8331\n",
      "test_train\n",
      "train mean loss=0.05713364730278651\n",
      "test_test\n",
      "test mean loss=1145.4629821777344\n",
      "epoch 8332\n",
      "test_train\n",
      "train mean loss=0.052449642991026245\n",
      "test_test\n",
      "test mean loss=1152.4116821289062\n",
      "epoch 8333\n",
      "test_train\n",
      "train mean loss=0.04997077972317735\n",
      "test_test\n",
      "test mean loss=1187.3237915039062\n",
      "epoch 8334\n",
      "test_train\n",
      "train mean loss=0.05183395557105541\n",
      "test_test\n",
      "test mean loss=1254.4763793945312\n",
      "epoch 8335\n",
      "test_train\n",
      "train mean loss=0.047888374887406826\n",
      "test_test\n",
      "test mean loss=1324.9097290039062\n",
      "epoch 8336\n",
      "test_train\n",
      "train mean loss=0.05279428279027343\n",
      "test_test\n",
      "test mean loss=1156.2419738769531\n",
      "epoch 8337\n",
      "test_train\n",
      "train mean loss=0.057342013654609524\n",
      "test_test\n",
      "test mean loss=1151.5258178710938\n",
      "epoch 8338\n",
      "test_train\n",
      "train mean loss=0.05539451306685805\n",
      "test_test\n",
      "test mean loss=1151.3107604980469\n",
      "epoch 8339\n",
      "test_train\n",
      "train mean loss=0.05648910937209924\n",
      "test_test\n",
      "test mean loss=1157.5426635742188\n",
      "epoch 8340\n",
      "test_train\n",
      "train mean loss=0.058161272667348385\n",
      "test_test\n",
      "test mean loss=1155.8652954101562\n",
      "epoch 8341\n",
      "test_train\n",
      "train mean loss=0.05281781575952967\n",
      "test_test\n",
      "test mean loss=1147.7246704101562\n",
      "epoch 8342\n",
      "test_train\n",
      "train mean loss=0.057036189983288445\n",
      "test_test\n",
      "test mean loss=1145.0325012207031\n",
      "epoch 8343\n",
      "test_train\n",
      "train mean loss=0.05197630310431123\n",
      "test_test\n",
      "test mean loss=1148.0543823242188\n",
      "epoch 8344\n",
      "test_train\n",
      "train mean loss=0.05515138618648052\n",
      "test_test\n",
      "test mean loss=1149.8644409179688\n",
      "epoch 8345\n",
      "test_train\n",
      "train mean loss=0.053860895025233425\n",
      "test_test\n",
      "test mean loss=1171.52490234375\n",
      "epoch 8346\n",
      "test_train\n",
      "train mean loss=0.05020169448107481\n",
      "test_test\n",
      "test mean loss=1175.7686767578125\n",
      "epoch 8347\n",
      "test_train\n",
      "train mean loss=0.05604752137636145\n",
      "test_test\n",
      "test mean loss=1222.18115234375\n",
      "epoch 8348\n",
      "test_train\n",
      "train mean loss=0.05313414769868056\n",
      "test_test\n",
      "test mean loss=1158.5643310546875\n",
      "epoch 8349\n",
      "test_train\n",
      "train mean loss=0.05549050743381182\n",
      "test_test\n",
      "test mean loss=1158.9761047363281\n",
      "epoch 8350\n",
      "test_train\n",
      "train mean loss=0.04660620090241233\n",
      "test_test\n",
      "test mean loss=1155.5086059570312\n",
      "epoch 8351\n",
      "test_train\n",
      "train mean loss=0.05553747620433569\n",
      "test_test\n",
      "test mean loss=1153.9473876953125\n",
      "epoch 8352\n",
      "test_train\n",
      "train mean loss=0.05697995486358801\n",
      "test_test\n",
      "test mean loss=1151.9337768554688\n",
      "epoch 8353\n",
      "test_train\n",
      "train mean loss=0.0504253312634925\n",
      "test_test\n",
      "test mean loss=1158.13671875\n",
      "epoch 8354\n",
      "test_train\n",
      "train mean loss=0.056868515287836395\n",
      "test_test\n",
      "test mean loss=1155.1015930175781\n",
      "epoch 8355\n",
      "test_train\n",
      "train mean loss=0.05684673351546129\n",
      "test_test\n",
      "test mean loss=1151.4815673828125\n",
      "epoch 8356\n",
      "test_train\n",
      "train mean loss=0.054833464324474335\n",
      "test_test\n",
      "test mean loss=1149.0030212402344\n",
      "epoch 8357\n",
      "test_train\n",
      "train mean loss=0.057661842089146376\n",
      "test_test\n",
      "test mean loss=1150.2838134765625\n",
      "epoch 8358\n",
      "test_train\n",
      "train mean loss=0.06002914346754551\n",
      "test_test\n",
      "test mean loss=1165.9756164550781\n",
      "epoch 8359\n",
      "test_train\n",
      "train mean loss=0.06503809429705143\n",
      "test_test\n",
      "test mean loss=1159.7990112304688\n",
      "epoch 8360\n",
      "test_train\n",
      "train mean loss=0.05762078504388531\n",
      "test_test\n",
      "test mean loss=1158.0327758789062\n",
      "epoch 8361\n",
      "test_train\n",
      "train mean loss=0.05772401144107183\n",
      "test_test\n",
      "test mean loss=1156.3230590820312\n",
      "epoch 8362\n",
      "test_train\n",
      "train mean loss=0.09890609172483285\n",
      "test_test\n",
      "test mean loss=1160.1415405273438\n",
      "epoch 8363\n",
      "test_train\n",
      "train mean loss=0.05719592468813062\n",
      "test_test\n",
      "test mean loss=1156.6801147460938\n",
      "epoch 8364\n",
      "test_train\n",
      "train mean loss=0.0575252715498209\n",
      "test_test\n",
      "test mean loss=1158.0983276367188\n",
      "epoch 8365\n",
      "test_train\n",
      "train mean loss=0.055842134480675064\n",
      "test_test\n",
      "test mean loss=1154.2335205078125\n",
      "epoch 8366\n",
      "test_train\n",
      "train mean loss=0.05516475501159827\n",
      "test_test\n",
      "test mean loss=1150.4542541503906\n",
      "epoch 8367\n",
      "test_train\n",
      "train mean loss=0.05613479080299536\n",
      "test_test\n",
      "test mean loss=1148.874267578125\n",
      "epoch 8368\n",
      "test_train\n",
      "train mean loss=0.048470861899356045\n",
      "test_test\n",
      "test mean loss=1146.467529296875\n",
      "epoch 8369\n",
      "test_train\n",
      "train mean loss=0.05009980561832587\n",
      "test_test\n",
      "test mean loss=1148.8052978515625\n",
      "epoch 8370\n",
      "test_train\n",
      "train mean loss=0.07297921786084771\n",
      "test_test\n",
      "test mean loss=1160.936767578125\n",
      "epoch 8371\n",
      "test_train\n",
      "train mean loss=0.054023196920752525\n",
      "test_test\n",
      "test mean loss=1158.7016296386719\n",
      "epoch 8372\n",
      "test_train\n",
      "train mean loss=0.0630009826272726\n",
      "test_test\n",
      "test mean loss=1157.6329956054688\n",
      "epoch 8373\n",
      "test_train\n",
      "train mean loss=0.05576626118272543\n",
      "test_test\n",
      "test mean loss=1151.7528686523438\n",
      "epoch 8374\n",
      "test_train\n",
      "train mean loss=0.05735115831096967\n",
      "test_test\n",
      "test mean loss=1147.6956176757812\n",
      "epoch 8375\n",
      "test_train\n",
      "train mean loss=0.1299666166305542\n",
      "test_test\n",
      "test mean loss=1145.6450805664062\n",
      "epoch 8376\n",
      "test_train\n",
      "train mean loss=0.05826768216987451\n",
      "test_test\n",
      "test mean loss=1163.0502319335938\n",
      "epoch 8377\n",
      "test_train\n",
      "train mean loss=0.05305812694132328\n",
      "test_test\n",
      "test mean loss=1190.4576416015625\n",
      "epoch 8378\n",
      "test_train\n",
      "train mean loss=0.05459401539216439\n",
      "test_test\n",
      "test mean loss=1148.1814575195312\n",
      "epoch 8379\n",
      "test_train\n",
      "train mean loss=0.05657636156926552\n",
      "test_test\n",
      "test mean loss=1154.8850708007812\n",
      "epoch 8380\n",
      "test_train\n",
      "train mean loss=0.05519897506261865\n",
      "test_test\n",
      "test mean loss=1187.351806640625\n",
      "epoch 8381\n",
      "test_train\n",
      "train mean loss=0.061764540150761604\n",
      "test_test\n",
      "test mean loss=1225.0845947265625\n",
      "epoch 8382\n",
      "test_train\n",
      "train mean loss=0.06308850801239411\n",
      "test_test\n",
      "test mean loss=1154.9362182617188\n",
      "epoch 8383\n",
      "test_train\n",
      "train mean loss=0.051744047862788044\n",
      "test_test\n",
      "test mean loss=1190.127685546875\n",
      "epoch 8384\n",
      "test_train\n",
      "train mean loss=0.049150802505513035\n",
      "test_test\n",
      "test mean loss=1150.4312133789062\n",
      "epoch 8385\n",
      "test_train\n",
      "train mean loss=0.0798013840491573\n",
      "test_test\n",
      "test mean loss=1163.8082885742188\n",
      "epoch 8386\n",
      "test_train\n",
      "train mean loss=0.05665986364086469\n",
      "test_test\n",
      "test mean loss=1203.483154296875\n",
      "epoch 8387\n",
      "test_train\n",
      "train mean loss=0.058026946149766445\n",
      "test_test\n",
      "test mean loss=1235.6231384277344\n",
      "epoch 8388\n",
      "test_train\n",
      "train mean loss=0.056330555118620396\n",
      "test_test\n",
      "test mean loss=1266.4444885253906\n",
      "epoch 8389\n",
      "test_train\n",
      "train mean loss=0.06040429106603066\n",
      "test_test\n",
      "test mean loss=1152.2752380371094\n",
      "epoch 8390\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.08266375710566838\n",
      "test_test\n",
      "test mean loss=1139.76318359375\n",
      "epoch 8391\n",
      "test_train\n",
      "train mean loss=0.055089593244095646\n",
      "test_test\n",
      "test mean loss=1152.9070434570312\n",
      "epoch 8392\n",
      "test_train\n",
      "train mean loss=0.0538381248091658\n",
      "test_test\n",
      "test mean loss=1151.3603210449219\n",
      "epoch 8393\n",
      "test_train\n",
      "train mean loss=0.05610210789988438\n",
      "test_test\n",
      "test mean loss=1156.9333190917969\n",
      "epoch 8394\n",
      "test_train\n",
      "train mean loss=0.055023376209040485\n",
      "test_test\n",
      "test mean loss=1159.320068359375\n",
      "epoch 8395\n",
      "test_train\n",
      "train mean loss=0.05079509085044265\n",
      "test_test\n",
      "test mean loss=1157.9705810546875\n",
      "epoch 8396\n",
      "test_train\n",
      "train mean loss=0.05516699297974507\n",
      "test_test\n",
      "test mean loss=1157.9457397460938\n",
      "epoch 8397\n",
      "test_train\n",
      "train mean loss=0.0626371456310153\n",
      "test_test\n",
      "test mean loss=1161.0667724609375\n",
      "epoch 8398\n",
      "test_train\n",
      "train mean loss=0.12478087656199932\n",
      "test_test\n",
      "test mean loss=1155.0061645507812\n",
      "epoch 8399\n",
      "test_train\n",
      "train mean loss=0.06829513143748045\n",
      "test_test\n",
      "test mean loss=1156.4120483398438\n",
      "epoch 8400\n",
      "test_train\n",
      "train mean loss=0.05362438953792056\n",
      "test_test\n",
      "test mean loss=1147.99853515625\n",
      "epoch 8401\n",
      "test_train\n",
      "train mean loss=0.0540868992296358\n",
      "test_test\n",
      "test mean loss=1144.3460693359375\n",
      "epoch 8402\n",
      "test_train\n",
      "train mean loss=0.055632561445236206\n",
      "test_test\n",
      "test mean loss=1145.2640991210938\n",
      "epoch 8403\n",
      "test_train\n",
      "train mean loss=0.056829113978892565\n",
      "test_test\n",
      "test mean loss=1155.7105712890625\n",
      "epoch 8404\n",
      "test_train\n",
      "train mean loss=0.06423081861188014\n",
      "test_test\n",
      "test mean loss=1159.3453369140625\n",
      "epoch 8405\n",
      "test_train\n",
      "train mean loss=0.05921715529014667\n",
      "test_test\n",
      "test mean loss=1157.241455078125\n",
      "epoch 8406\n",
      "test_train\n",
      "train mean loss=0.05668313754722476\n",
      "test_test\n",
      "test mean loss=1156.0094299316406\n",
      "epoch 8407\n",
      "test_train\n",
      "train mean loss=0.06412635122736295\n",
      "test_test\n",
      "test mean loss=1160.7649536132812\n",
      "epoch 8408\n",
      "test_train\n",
      "train mean loss=0.0648704959700505\n",
      "test_test\n",
      "test mean loss=1157.18115234375\n",
      "epoch 8409\n",
      "test_train\n",
      "train mean loss=0.06137400694812337\n",
      "test_test\n",
      "test mean loss=1158.0293579101562\n",
      "epoch 8410\n",
      "test_train\n",
      "train mean loss=0.051221040077507496\n",
      "test_test\n",
      "test mean loss=1157.5349731445312\n",
      "epoch 8411\n",
      "test_train\n",
      "train mean loss=0.05419209972023964\n",
      "test_test\n",
      "test mean loss=1157.40576171875\n",
      "epoch 8412\n",
      "test_train\n",
      "train mean loss=0.06623845578481753\n",
      "test_test\n",
      "test mean loss=1153.8489990234375\n",
      "epoch 8413\n",
      "test_train\n",
      "train mean loss=0.06118002083773414\n",
      "test_test\n",
      "test mean loss=1149.2046813964844\n",
      "epoch 8414\n",
      "test_train\n",
      "train mean loss=0.048752085926632084\n",
      "test_test\n",
      "test mean loss=1144.7720336914062\n",
      "epoch 8415\n",
      "test_train\n",
      "train mean loss=0.06264052850504716\n",
      "test_test\n",
      "test mean loss=1155.5591430664062\n",
      "epoch 8416\n",
      "test_train\n",
      "train mean loss=0.05526532419025898\n",
      "test_test\n",
      "test mean loss=1159.3598022460938\n",
      "epoch 8417\n",
      "test_train\n",
      "train mean loss=0.049440884962677956\n",
      "test_test\n",
      "test mean loss=1157.4127197265625\n",
      "epoch 8418\n",
      "test_train\n",
      "train mean loss=0.053370073127249874\n",
      "test_test\n",
      "test mean loss=1156.5094909667969\n",
      "epoch 8419\n",
      "test_train\n",
      "train mean loss=0.0562149027052025\n",
      "test_test\n",
      "test mean loss=1157.1889343261719\n",
      "epoch 8420\n",
      "test_train\n",
      "train mean loss=0.054980516278495394\n",
      "test_test\n",
      "test mean loss=1157.2107543945312\n",
      "epoch 8421\n",
      "test_train\n",
      "train mean loss=0.05821492988616228\n",
      "test_test\n",
      "test mean loss=1156.6675109863281\n",
      "epoch 8422\n",
      "test_train\n",
      "train mean loss=0.05659944377839565\n",
      "test_test\n",
      "test mean loss=1157.70166015625\n",
      "epoch 8423\n",
      "test_train\n",
      "train mean loss=0.05914502777159214\n",
      "test_test\n",
      "test mean loss=1157.962890625\n",
      "epoch 8424\n",
      "test_train\n",
      "train mean loss=0.04873405505592624\n",
      "test_test\n",
      "test mean loss=1158.8173828125\n",
      "epoch 8425\n",
      "test_train\n",
      "train mean loss=0.06489514838904142\n",
      "test_test\n",
      "test mean loss=1160.7615966796875\n",
      "epoch 8426\n",
      "test_train\n",
      "train mean loss=0.05540693768610557\n",
      "test_test\n",
      "test mean loss=1158.7533569335938\n",
      "epoch 8427\n",
      "test_train\n",
      "train mean loss=0.06391951721161604\n",
      "test_test\n",
      "test mean loss=1160.0648803710938\n",
      "epoch 8428\n",
      "test_train\n",
      "train mean loss=0.0596843222156167\n",
      "test_test\n",
      "test mean loss=1158.4080810546875\n",
      "epoch 8429\n",
      "test_train\n",
      "train mean loss=0.05764477731039127\n",
      "test_test\n",
      "test mean loss=1157.18603515625\n",
      "epoch 8430\n",
      "test_train\n",
      "train mean loss=0.05448205955326557\n",
      "test_test\n",
      "test mean loss=1160.025390625\n",
      "epoch 8431\n",
      "test_train\n",
      "train mean loss=0.05121608590707183\n",
      "test_test\n",
      "test mean loss=1160.5811462402344\n",
      "epoch 8432\n",
      "test_train\n",
      "train mean loss=0.05691241597135862\n",
      "test_test\n",
      "test mean loss=1158.0927734375\n",
      "epoch 8433\n",
      "test_train\n",
      "train mean loss=0.056642510928213596\n",
      "test_test\n",
      "test mean loss=1158.9450073242188\n",
      "epoch 8434\n",
      "test_train\n",
      "train mean loss=0.06319050615032513\n",
      "test_test\n",
      "test mean loss=1159.0887145996094\n",
      "epoch 8435\n",
      "test_train\n",
      "train mean loss=0.05312012229114771\n",
      "test_test\n",
      "test mean loss=1156.8202514648438\n",
      "epoch 8436\n",
      "test_train\n",
      "train mean loss=0.05662590777501464\n",
      "test_test\n",
      "test mean loss=1156.5883178710938\n",
      "epoch 8437\n",
      "test_train\n",
      "train mean loss=0.05233601030583183\n",
      "test_test\n",
      "test mean loss=1155.0146484375\n",
      "epoch 8438\n",
      "test_train\n",
      "train mean loss=0.050895188779880605\n",
      "test_test\n",
      "test mean loss=1149.8524780273438\n",
      "epoch 8439\n",
      "test_train\n",
      "train mean loss=0.054260387706259884\n",
      "test_test\n",
      "test mean loss=1149.2539672851562\n",
      "epoch 8440\n",
      "test_train\n",
      "train mean loss=0.049199722862492\n",
      "test_test\n",
      "test mean loss=1148.5090942382812\n",
      "epoch 8441\n",
      "test_train\n",
      "train mean loss=0.05155343717585007\n",
      "test_test\n",
      "test mean loss=1157.1625366210938\n",
      "epoch 8442\n",
      "test_train\n",
      "train mean loss=0.05813129898160696\n",
      "test_test\n",
      "test mean loss=1156.8512573242188\n",
      "epoch 8443\n",
      "test_train\n",
      "train mean loss=0.05054570299883684\n",
      "test_test\n",
      "test mean loss=1157.7704772949219\n",
      "epoch 8444\n",
      "test_train\n",
      "train mean loss=0.05449789700408777\n",
      "test_test\n",
      "test mean loss=1160.255615234375\n",
      "epoch 8445\n",
      "test_train\n",
      "train mean loss=0.050942687007288136\n",
      "test_test\n",
      "test mean loss=1159.5975952148438\n",
      "epoch 8446\n",
      "test_train\n",
      "train mean loss=0.05871467043956121\n",
      "test_test\n",
      "test mean loss=1160.3963623046875\n",
      "epoch 8447\n",
      "test_train\n",
      "train mean loss=0.049961027378837265\n",
      "test_test\n",
      "test mean loss=1157.4516906738281\n",
      "epoch 8448\n",
      "test_train\n",
      "train mean loss=0.056289164970318474\n",
      "test_test\n",
      "test mean loss=1158.3689270019531\n",
      "epoch 8449\n",
      "test_train\n",
      "train mean loss=0.053270577608297266\n",
      "test_test\n",
      "test mean loss=1158.301025390625\n",
      "epoch 8450\n",
      "test_train\n",
      "train mean loss=0.054714761363963284\n",
      "test_test\n",
      "test mean loss=1159.194091796875\n",
      "epoch 8451\n",
      "test_train\n",
      "train mean loss=0.0509778360525767\n",
      "test_test\n",
      "test mean loss=1158.6133117675781\n",
      "epoch 8452\n",
      "test_train\n",
      "train mean loss=0.05119082781796654\n",
      "test_test\n",
      "test mean loss=1156.1615600585938\n",
      "epoch 8453\n",
      "test_train\n",
      "train mean loss=0.0626138998195529\n",
      "test_test\n",
      "test mean loss=1159.7020874023438\n",
      "epoch 8454\n",
      "test_train\n",
      "train mean loss=0.05596139095723629\n",
      "test_test\n",
      "test mean loss=1156.0752563476562\n",
      "epoch 8455\n",
      "test_train\n",
      "train mean loss=0.055529072104642786\n",
      "test_test\n",
      "test mean loss=1156.9395141601562\n",
      "epoch 8456\n",
      "test_train\n",
      "train mean loss=0.05891752367218336\n",
      "test_test\n",
      "test mean loss=1153.1032104492188\n",
      "epoch 8457\n",
      "test_train\n",
      "train mean loss=0.05482933965201179\n",
      "test_test\n",
      "test mean loss=1152.4384460449219\n",
      "epoch 8458\n",
      "test_train\n",
      "train mean loss=0.0592008987441659\n",
      "test_test\n",
      "test mean loss=1150.6143493652344\n",
      "epoch 8459\n",
      "test_train\n",
      "train mean loss=0.05492726651330789\n",
      "test_test\n",
      "test mean loss=1157.25634765625\n",
      "epoch 8460\n",
      "test_train\n",
      "train mean loss=0.05736981922139724\n",
      "test_test\n",
      "test mean loss=1154.1062622070312\n",
      "epoch 8461\n",
      "test_train\n",
      "train mean loss=0.053235145596166454\n",
      "test_test\n",
      "test mean loss=1159.18017578125\n",
      "epoch 8462\n",
      "test_train\n",
      "train mean loss=0.050645421259105206\n",
      "test_test\n",
      "test mean loss=1159.0762329101562\n",
      "epoch 8463\n",
      "test_train\n",
      "train mean loss=0.058161476937433086\n",
      "test_test\n",
      "test mean loss=1161.5480346679688\n",
      "epoch 8464\n",
      "test_train\n",
      "train mean loss=0.055906396669646106\n",
      "test_test\n",
      "test mean loss=1159.9263916015625\n",
      "epoch 8465\n",
      "test_train\n",
      "train mean loss=0.06010342203080654\n",
      "test_test\n",
      "test mean loss=1159.96240234375\n",
      "epoch 8466\n",
      "test_train\n",
      "train mean loss=0.054773690489431225\n",
      "test_test\n",
      "test mean loss=1159.998046875\n",
      "epoch 8467\n",
      "test_train\n",
      "train mean loss=0.04832240426912904\n",
      "test_test\n",
      "test mean loss=1157.4877319335938\n",
      "epoch 8468\n",
      "test_train\n",
      "train mean loss=0.059052285738289356\n",
      "test_test\n",
      "test mean loss=1160.5457153320312\n",
      "epoch 8469\n",
      "test_train\n",
      "train mean loss=0.060083103366196156\n",
      "test_test\n",
      "test mean loss=1159.7957153320312\n",
      "epoch 8470\n",
      "test_train\n",
      "train mean loss=0.05740818427875638\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1159.458984375\n",
      "epoch 8471\n",
      "test_train\n",
      "train mean loss=0.06293093971908092\n",
      "test_test\n",
      "test mean loss=1158.240234375\n",
      "epoch 8472\n",
      "test_train\n",
      "train mean loss=0.06456058907012145\n",
      "test_test\n",
      "test mean loss=1157.60693359375\n",
      "epoch 8473\n",
      "test_train\n",
      "train mean loss=0.05473865351329247\n",
      "test_test\n",
      "test mean loss=1159.7430419921875\n",
      "epoch 8474\n",
      "test_train\n",
      "train mean loss=0.05362998663137356\n",
      "test_test\n",
      "test mean loss=1158.2004699707031\n",
      "epoch 8475\n",
      "test_train\n",
      "train mean loss=0.051734477281570435\n",
      "test_test\n",
      "test mean loss=1159.862060546875\n",
      "epoch 8476\n",
      "test_train\n",
      "train mean loss=0.05646470903108517\n",
      "test_test\n",
      "test mean loss=1157.6524047851562\n",
      "epoch 8477\n",
      "test_train\n",
      "train mean loss=0.050095293050011\n",
      "test_test\n",
      "test mean loss=1156.8153076171875\n",
      "epoch 8478\n",
      "test_train\n",
      "train mean loss=0.05301838181912899\n",
      "test_test\n",
      "test mean loss=1157.4710693359375\n",
      "epoch 8479\n",
      "test_train\n",
      "train mean loss=0.05815910408273339\n",
      "test_test\n",
      "test mean loss=1158.9830932617188\n",
      "epoch 8480\n",
      "test_train\n",
      "train mean loss=0.05543410902221998\n",
      "test_test\n",
      "test mean loss=1159.8968200683594\n",
      "epoch 8481\n",
      "test_train\n",
      "train mean loss=0.05589742539450526\n",
      "test_test\n",
      "test mean loss=1160.8925476074219\n",
      "epoch 8482\n",
      "test_train\n",
      "train mean loss=0.047942617597679295\n",
      "test_test\n",
      "test mean loss=1158.1911315917969\n",
      "epoch 8483\n",
      "test_train\n",
      "train mean loss=0.05162722337990999\n",
      "test_test\n",
      "test mean loss=1156.7886047363281\n",
      "epoch 8484\n",
      "test_train\n",
      "train mean loss=0.0512210705007116\n",
      "test_test\n",
      "test mean loss=1157.682861328125\n",
      "epoch 8485\n",
      "test_train\n",
      "train mean loss=0.05469237578411897\n",
      "test_test\n",
      "test mean loss=1155.8619995117188\n",
      "epoch 8486\n",
      "test_train\n",
      "train mean loss=0.050614937829474606\n",
      "test_test\n",
      "test mean loss=1158.0869140625\n",
      "epoch 8487\n",
      "test_train\n",
      "train mean loss=0.0508331498131156\n",
      "test_test\n",
      "test mean loss=1159.4801635742188\n",
      "epoch 8488\n",
      "test_train\n",
      "train mean loss=0.047839256624380745\n",
      "test_test\n",
      "test mean loss=1157.6378173828125\n",
      "epoch 8489\n",
      "test_train\n",
      "train mean loss=0.05501348897814751\n",
      "test_test\n",
      "test mean loss=1157.650390625\n",
      "epoch 8490\n",
      "test_train\n",
      "train mean loss=0.05142057749132315\n",
      "test_test\n",
      "test mean loss=1156.7445678710938\n",
      "epoch 8491\n",
      "test_train\n",
      "train mean loss=0.05396578957637151\n",
      "test_test\n",
      "test mean loss=1155.5111083984375\n",
      "epoch 8492\n",
      "test_train\n",
      "train mean loss=0.06153277556101481\n",
      "test_test\n",
      "test mean loss=1154.3321228027344\n",
      "epoch 8493\n",
      "test_train\n",
      "train mean loss=0.06275292920569579\n",
      "test_test\n",
      "test mean loss=1156.6447143554688\n",
      "epoch 8494\n",
      "test_train\n",
      "train mean loss=0.055863404646515846\n",
      "test_test\n",
      "test mean loss=1158.3573608398438\n",
      "epoch 8495\n",
      "test_train\n",
      "train mean loss=0.055326937697827816\n",
      "test_test\n",
      "test mean loss=1159.2506103515625\n",
      "epoch 8496\n",
      "test_train\n",
      "train mean loss=0.05021313996985555\n",
      "test_test\n",
      "test mean loss=1158.6887512207031\n",
      "epoch 8497\n",
      "test_train\n",
      "train mean loss=0.059360120755930744\n",
      "test_test\n",
      "test mean loss=1159.7730712890625\n",
      "epoch 8498\n",
      "test_train\n",
      "train mean loss=0.054938960199554764\n",
      "test_test\n",
      "test mean loss=1157.7902221679688\n",
      "epoch 8499\n",
      "test_train\n",
      "train mean loss=0.05300025021036466\n",
      "test_test\n",
      "test mean loss=1158.0162963867188\n",
      "epoch 8500\n",
      "test_train\n",
      "train mean loss=0.05822972301393747\n",
      "test_test\n",
      "test mean loss=1160.1476440429688\n",
      "epoch 8501\n",
      "test_train\n",
      "train mean loss=0.0554479262791574\n",
      "test_test\n",
      "test mean loss=1159.920166015625\n",
      "epoch 8502\n",
      "test_train\n",
      "train mean loss=0.054671673104166985\n",
      "test_test\n",
      "test mean loss=1158.8759460449219\n",
      "epoch 8503\n",
      "test_train\n",
      "train mean loss=0.05245875737940272\n",
      "test_test\n",
      "test mean loss=1158.345947265625\n",
      "epoch 8504\n",
      "test_train\n",
      "train mean loss=0.053856583312153816\n",
      "test_test\n",
      "test mean loss=1157.587158203125\n",
      "epoch 8505\n",
      "test_train\n",
      "train mean loss=0.05061492106566826\n",
      "test_test\n",
      "test mean loss=1156.6375122070312\n",
      "epoch 8506\n",
      "test_train\n",
      "train mean loss=0.05532184708863497\n",
      "test_test\n",
      "test mean loss=1152.6048583984375\n",
      "epoch 8507\n",
      "test_train\n",
      "train mean loss=0.06523055831591289\n",
      "test_test\n",
      "test mean loss=1155.8300170898438\n",
      "epoch 8508\n",
      "test_train\n",
      "train mean loss=0.053711674020936094\n",
      "test_test\n",
      "test mean loss=1156.1374206542969\n",
      "epoch 8509\n",
      "test_train\n",
      "train mean loss=0.05072098675494393\n",
      "test_test\n",
      "test mean loss=1156.0726623535156\n",
      "epoch 8510\n",
      "test_train\n",
      "train mean loss=0.05119171024610599\n",
      "test_test\n",
      "test mean loss=1155.6610412597656\n",
      "epoch 8511\n",
      "test_train\n",
      "train mean loss=0.05411989505713185\n",
      "test_test\n",
      "test mean loss=1160.8591918945312\n",
      "epoch 8512\n",
      "test_train\n",
      "train mean loss=0.055972008034586906\n",
      "test_test\n",
      "test mean loss=1159.6023559570312\n",
      "epoch 8513\n",
      "test_train\n",
      "train mean loss=0.05241870453270773\n",
      "test_test\n",
      "test mean loss=1158.5802612304688\n",
      "epoch 8514\n",
      "test_train\n",
      "train mean loss=0.054925459592292704\n",
      "test_test\n",
      "test mean loss=1160.2307739257812\n",
      "epoch 8515\n",
      "test_train\n",
      "train mean loss=0.05075615116705497\n",
      "test_test\n",
      "test mean loss=1158.3125305175781\n",
      "epoch 8516\n",
      "test_train\n",
      "train mean loss=0.05189672686780492\n",
      "test_test\n",
      "test mean loss=1157.0217590332031\n",
      "epoch 8517\n",
      "test_train\n",
      "train mean loss=0.05129534471780062\n",
      "test_test\n",
      "test mean loss=1156.0953979492188\n",
      "epoch 8518\n",
      "test_train\n",
      "train mean loss=0.05750311445444822\n",
      "test_test\n",
      "test mean loss=1157.7625122070312\n",
      "epoch 8519\n",
      "test_train\n",
      "train mean loss=0.05872400819013516\n",
      "test_test\n",
      "test mean loss=1158.1829528808594\n",
      "epoch 8520\n",
      "test_train\n",
      "train mean loss=0.052293109241873026\n",
      "test_test\n",
      "test mean loss=1158.7645568847656\n",
      "epoch 8521\n",
      "test_train\n",
      "train mean loss=0.04894002325211962\n",
      "test_test\n",
      "test mean loss=1157.1466064453125\n",
      "epoch 8522\n",
      "test_train\n",
      "train mean loss=0.054835309429715075\n",
      "test_test\n",
      "test mean loss=1158.7733154296875\n",
      "epoch 8523\n",
      "test_train\n",
      "train mean loss=0.05981841993828615\n",
      "test_test\n",
      "test mean loss=1159.1393432617188\n",
      "epoch 8524\n",
      "test_train\n",
      "train mean loss=0.05437739115829269\n",
      "test_test\n",
      "test mean loss=1158.9147338867188\n",
      "epoch 8525\n",
      "test_train\n",
      "train mean loss=0.05695088425030311\n",
      "test_test\n",
      "test mean loss=1160.1412353515625\n",
      "epoch 8526\n",
      "test_train\n",
      "train mean loss=0.053646355556945004\n",
      "test_test\n",
      "test mean loss=1160.767578125\n",
      "epoch 8527\n",
      "test_train\n",
      "train mean loss=0.049632739586134754\n",
      "test_test\n",
      "test mean loss=1159.3424682617188\n",
      "epoch 8528\n",
      "test_train\n",
      "train mean loss=0.05655110285927852\n",
      "test_test\n",
      "test mean loss=1159.0665893554688\n",
      "epoch 8529\n",
      "test_train\n",
      "train mean loss=0.049894403045376144\n",
      "test_test\n",
      "test mean loss=1158.9324645996094\n",
      "epoch 8530\n",
      "test_train\n",
      "train mean loss=0.05452129400024811\n",
      "test_test\n",
      "test mean loss=1156.29443359375\n",
      "epoch 8531\n",
      "test_train\n",
      "train mean loss=0.05496764834970236\n",
      "test_test\n",
      "test mean loss=1158.4812927246094\n",
      "epoch 8532\n",
      "test_train\n",
      "train mean loss=0.04845816952486833\n",
      "test_test\n",
      "test mean loss=1159.3909606933594\n",
      "epoch 8533\n",
      "test_train\n",
      "train mean loss=0.050156373685846724\n",
      "test_test\n",
      "test mean loss=1158.4658203125\n",
      "epoch 8534\n",
      "test_train\n",
      "train mean loss=0.05150395166128874\n",
      "test_test\n",
      "test mean loss=1159.2090454101562\n",
      "epoch 8535\n",
      "test_train\n",
      "train mean loss=0.0572091368958354\n",
      "test_test\n",
      "test mean loss=1160.1514587402344\n",
      "epoch 8536\n",
      "test_train\n",
      "train mean loss=0.06317038865139087\n",
      "test_test\n",
      "test mean loss=1160.2929077148438\n",
      "epoch 8537\n",
      "test_train\n",
      "train mean loss=0.05709272902458906\n",
      "test_test\n",
      "test mean loss=1158.7341918945312\n",
      "epoch 8538\n",
      "test_train\n",
      "train mean loss=0.055852776393294334\n",
      "test_test\n",
      "test mean loss=1157.8318481445312\n",
      "epoch 8539\n",
      "test_train\n",
      "train mean loss=0.052971052626768746\n",
      "test_test\n",
      "test mean loss=1158.9013671875\n",
      "epoch 8540\n",
      "test_train\n",
      "train mean loss=0.05292746548851331\n",
      "test_test\n",
      "test mean loss=1159.01708984375\n",
      "epoch 8541\n",
      "test_train\n",
      "train mean loss=0.0633300847063462\n",
      "test_test\n",
      "test mean loss=1150.056884765625\n",
      "epoch 8542\n",
      "test_train\n",
      "train mean loss=0.047202988527715206\n",
      "test_test\n",
      "test mean loss=1150.4249877929688\n",
      "epoch 8543\n",
      "test_train\n",
      "train mean loss=0.04343549767509103\n",
      "test_test\n",
      "test mean loss=1157.9027709960938\n",
      "epoch 8544\n",
      "test_train\n",
      "train mean loss=0.050771182092527546\n",
      "test_test\n",
      "test mean loss=1156.0339965820312\n",
      "epoch 8545\n",
      "test_train\n",
      "train mean loss=0.049255826200048126\n",
      "test_test\n",
      "test mean loss=1158.06298828125\n",
      "epoch 8546\n",
      "test_train\n",
      "train mean loss=0.04830747935920954\n",
      "test_test\n",
      "test mean loss=1157.9839477539062\n",
      "epoch 8547\n",
      "test_train\n",
      "train mean loss=0.047845470098157726\n",
      "test_test\n",
      "test mean loss=1154.4017639160156\n",
      "epoch 8548\n",
      "test_train\n",
      "train mean loss=0.052129972260445356\n",
      "test_test\n",
      "test mean loss=1158.8310546875\n",
      "epoch 8549\n",
      "test_train\n",
      "train mean loss=0.050490486746033035\n",
      "test_test\n",
      "test mean loss=1158.6056518554688\n",
      "epoch 8550\n",
      "test_train\n",
      "train mean loss=0.05245588580146432\n",
      "test_test\n",
      "test mean loss=1156.2554321289062\n",
      "epoch 8551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_train\n",
      "train mean loss=0.1314293916026751\n",
      "test_test\n",
      "test mean loss=1160.84033203125\n",
      "epoch 8552\n",
      "test_train\n",
      "train mean loss=0.053933131974190474\n",
      "test_test\n",
      "test mean loss=1157.4302978515625\n",
      "epoch 8553\n",
      "test_train\n",
      "train mean loss=0.05112958916773399\n",
      "test_test\n",
      "test mean loss=1150.1240234375\n",
      "epoch 8554\n",
      "test_train\n",
      "train mean loss=0.050914006618162\n",
      "test_test\n",
      "test mean loss=1158.9313354492188\n",
      "epoch 8555\n",
      "test_train\n",
      "train mean loss=0.0541968890465796\n",
      "test_test\n",
      "test mean loss=1159.1337890625\n",
      "epoch 8556\n",
      "test_train\n",
      "train mean loss=0.048338350063810744\n",
      "test_test\n",
      "test mean loss=1159.151123046875\n",
      "epoch 8557\n",
      "test_train\n",
      "train mean loss=0.05926374097665151\n",
      "test_test\n",
      "test mean loss=1160.685302734375\n",
      "epoch 8558\n",
      "test_train\n",
      "train mean loss=0.05534807965159416\n",
      "test_test\n",
      "test mean loss=1157.4393920898438\n",
      "epoch 8559\n",
      "test_train\n",
      "train mean loss=0.05069440354903539\n",
      "test_test\n",
      "test mean loss=1158.5429077148438\n",
      "epoch 8560\n",
      "test_train\n",
      "train mean loss=0.056935535122950874\n",
      "test_test\n",
      "test mean loss=1158.927734375\n",
      "epoch 8561\n",
      "test_train\n",
      "train mean loss=0.12657188499967256\n",
      "test_test\n",
      "test mean loss=1158.0233764648438\n",
      "epoch 8562\n",
      "test_train\n",
      "train mean loss=0.061387755597631134\n",
      "test_test\n",
      "test mean loss=1160.1796569824219\n",
      "epoch 8563\n",
      "test_train\n",
      "train mean loss=0.057596202939748764\n",
      "test_test\n",
      "test mean loss=1159.549560546875\n",
      "epoch 8564\n",
      "test_train\n",
      "train mean loss=0.051582884043455124\n",
      "test_test\n",
      "test mean loss=1158.0594787597656\n",
      "epoch 8565\n",
      "test_train\n",
      "train mean loss=0.051361508977909885\n",
      "test_test\n",
      "test mean loss=1157.6981506347656\n",
      "epoch 8566\n",
      "test_train\n",
      "train mean loss=0.05178901366889477\n",
      "test_test\n",
      "test mean loss=1159.5716552734375\n",
      "epoch 8567\n",
      "test_train\n",
      "train mean loss=0.04984137477974097\n",
      "test_test\n",
      "test mean loss=1158.46044921875\n",
      "epoch 8568\n",
      "test_train\n",
      "train mean loss=0.05176796795179447\n",
      "test_test\n",
      "test mean loss=1160.0711364746094\n",
      "epoch 8569\n",
      "test_train\n",
      "train mean loss=0.05386689569180211\n",
      "test_test\n",
      "test mean loss=1158.58203125\n",
      "epoch 8570\n",
      "test_train\n",
      "train mean loss=0.05299383013819655\n",
      "test_test\n",
      "test mean loss=1157.6319580078125\n",
      "epoch 8571\n",
      "test_train\n",
      "train mean loss=0.04812889158104857\n",
      "test_test\n",
      "test mean loss=1158.2539367675781\n",
      "epoch 8572\n",
      "test_train\n",
      "train mean loss=0.05593430995941162\n",
      "test_test\n",
      "test mean loss=1157.9625854492188\n",
      "epoch 8573\n",
      "test_train\n",
      "train mean loss=0.05980802498136958\n",
      "test_test\n",
      "test mean loss=1159.9539184570312\n",
      "epoch 8574\n",
      "test_train\n",
      "train mean loss=0.0520475764448444\n",
      "test_test\n",
      "test mean loss=1158.7962646484375\n",
      "epoch 8575\n",
      "test_train\n",
      "train mean loss=0.05176575652634104\n",
      "test_test\n",
      "test mean loss=1158.2730712890625\n",
      "epoch 8576\n",
      "test_train\n",
      "train mean loss=0.05208430842806896\n",
      "test_test\n",
      "test mean loss=1158.5739135742188\n",
      "epoch 8577\n",
      "test_train\n",
      "train mean loss=0.05520069024836024\n",
      "test_test\n",
      "test mean loss=1160.5618896484375\n",
      "epoch 8578\n",
      "test_train\n",
      "train mean loss=0.0576392801788946\n",
      "test_test\n",
      "test mean loss=1159.5767822265625\n",
      "epoch 8579\n",
      "test_train\n",
      "train mean loss=0.048059167340397835\n",
      "test_test\n",
      "test mean loss=1158.2012329101562\n",
      "epoch 8580\n",
      "test_train\n",
      "train mean loss=0.05307762480030457\n",
      "test_test\n",
      "test mean loss=1158.9495239257812\n",
      "epoch 8581\n",
      "test_train\n",
      "train mean loss=0.05479016030828158\n",
      "test_test\n",
      "test mean loss=1157.9837036132812\n",
      "epoch 8582\n",
      "test_train\n",
      "train mean loss=0.05467348468179504\n",
      "test_test\n",
      "test mean loss=1157.9766540527344\n",
      "epoch 8583\n",
      "test_train\n",
      "train mean loss=0.05546956493829688\n",
      "test_test\n",
      "test mean loss=1159.3893432617188\n",
      "epoch 8584\n",
      "test_train\n",
      "train mean loss=0.052383857468763985\n",
      "test_test\n",
      "test mean loss=1158.2441711425781\n",
      "epoch 8585\n",
      "test_train\n",
      "train mean loss=0.0526301379625996\n",
      "test_test\n",
      "test mean loss=1159.1597290039062\n",
      "epoch 8586\n",
      "test_train\n",
      "train mean loss=0.057007305013636746\n",
      "test_test\n",
      "test mean loss=1158.6795654296875\n",
      "epoch 8587\n",
      "test_train\n",
      "train mean loss=0.0648127772534887\n",
      "test_test\n",
      "test mean loss=1156.9860534667969\n",
      "epoch 8588\n",
      "test_train\n",
      "train mean loss=0.058078047819435596\n",
      "test_test\n",
      "test mean loss=1158.6481018066406\n",
      "epoch 8589\n",
      "test_train\n",
      "train mean loss=0.05758625641465187\n",
      "test_test\n",
      "test mean loss=1158.3771362304688\n",
      "epoch 8590\n",
      "test_train\n",
      "train mean loss=0.05996061768382788\n",
      "test_test\n",
      "test mean loss=1159.0222473144531\n",
      "epoch 8591\n",
      "test_train\n",
      "train mean loss=0.05749047423402468\n",
      "test_test\n",
      "test mean loss=1159.76806640625\n",
      "epoch 8592\n",
      "test_train\n",
      "train mean loss=0.0556918295721213\n",
      "test_test\n",
      "test mean loss=1157.9615478515625\n",
      "epoch 8593\n",
      "test_train\n",
      "train mean loss=0.08012450020760298\n",
      "test_test\n",
      "test mean loss=1158.718994140625\n",
      "epoch 8594\n",
      "test_train\n",
      "train mean loss=0.058149468464155994\n",
      "test_test\n",
      "test mean loss=1156.6752624511719\n",
      "epoch 8595\n",
      "test_train\n",
      "train mean loss=0.0583324208855629\n",
      "test_test\n",
      "test mean loss=1159.3359375\n",
      "epoch 8596\n",
      "test_train\n",
      "train mean loss=0.05603257566690445\n",
      "test_test\n",
      "test mean loss=1158.6585083007812\n",
      "epoch 8597\n",
      "test_train\n",
      "train mean loss=0.0636125464613239\n",
      "test_test\n",
      "test mean loss=1159.5179138183594\n",
      "epoch 8598\n",
      "test_train\n",
      "train mean loss=0.05386974072704712\n",
      "test_test\n",
      "test mean loss=1159.7392578125\n",
      "epoch 8599\n",
      "test_train\n",
      "train mean loss=0.05545754792789618\n",
      "test_test\n",
      "test mean loss=1158.9647216796875\n",
      "epoch 8600\n",
      "test_train\n",
      "train mean loss=0.06205600189665953\n",
      "test_test\n",
      "test mean loss=1156.8427734375\n",
      "epoch 8601\n",
      "test_train\n",
      "train mean loss=0.08155902723471324\n",
      "test_test\n",
      "test mean loss=1153.6934204101562\n",
      "epoch 8602\n",
      "test_train\n",
      "train mean loss=0.05059484004353484\n",
      "test_test\n",
      "test mean loss=1154.8553466796875\n",
      "epoch 8603\n",
      "test_train\n",
      "train mean loss=0.043339415763815246\n",
      "test_test\n",
      "test mean loss=1157.5495910644531\n",
      "epoch 8604\n",
      "test_train\n",
      "train mean loss=0.055791789665818214\n",
      "test_test\n",
      "test mean loss=1158.9661865234375\n",
      "epoch 8605\n",
      "test_train\n",
      "train mean loss=0.05850197188556194\n",
      "test_test\n",
      "test mean loss=1157.8455200195312\n",
      "epoch 8606\n",
      "test_train\n",
      "train mean loss=0.06711442908272147\n",
      "test_test\n",
      "test mean loss=1159.2969360351562\n",
      "epoch 8607\n",
      "test_train\n",
      "train mean loss=0.05632006501158079\n",
      "test_test\n",
      "test mean loss=1158.2879638671875\n",
      "epoch 8608\n",
      "test_train\n",
      "train mean loss=0.05379255178074042\n",
      "test_test\n",
      "test mean loss=1158.9911499023438\n",
      "epoch 8609\n",
      "test_train\n",
      "train mean loss=0.04936394530038039\n",
      "test_test\n",
      "test mean loss=1158.9874267578125\n",
      "epoch 8610\n",
      "test_train\n",
      "train mean loss=0.05125710709641377\n",
      "test_test\n",
      "test mean loss=1158.4163208007812\n",
      "epoch 8611\n",
      "test_train\n",
      "train mean loss=0.054330588318407536\n",
      "test_test\n",
      "test mean loss=1160.2227172851562\n",
      "epoch 8612\n",
      "test_train\n",
      "train mean loss=0.0518729854375124\n",
      "test_test\n",
      "test mean loss=1159.9916381835938\n",
      "epoch 8613\n",
      "test_train\n",
      "train mean loss=0.05093434282268087\n",
      "test_test\n",
      "test mean loss=1158.7766723632812\n",
      "epoch 8614\n",
      "test_train\n",
      "train mean loss=0.04752233220885197\n",
      "test_test\n",
      "test mean loss=1159.6180419921875\n",
      "epoch 8615\n",
      "test_train\n",
      "train mean loss=0.05183992969493071\n",
      "test_test\n",
      "test mean loss=1159.3162536621094\n",
      "epoch 8616\n",
      "test_train\n",
      "train mean loss=0.06479394560058911\n",
      "test_test\n",
      "test mean loss=1160.0732116699219\n",
      "epoch 8617\n",
      "test_train\n",
      "train mean loss=0.053734194642553725\n",
      "test_test\n",
      "test mean loss=1158.6281127929688\n",
      "epoch 8618\n",
      "test_train\n",
      "train mean loss=0.05688767150665323\n",
      "test_test\n",
      "test mean loss=1158.786865234375\n",
      "epoch 8619\n",
      "test_train\n",
      "train mean loss=0.05163371562957764\n",
      "test_test\n",
      "test mean loss=1159.2425537109375\n",
      "epoch 8620\n",
      "test_train\n",
      "train mean loss=0.05859980018188556\n",
      "test_test\n",
      "test mean loss=1159.3433227539062\n",
      "epoch 8621\n",
      "test_train\n",
      "train mean loss=0.05940470223625501\n",
      "test_test\n",
      "test mean loss=1158.7506103515625\n",
      "epoch 8622\n",
      "test_train\n",
      "train mean loss=0.05700450080136458\n",
      "test_test\n",
      "test mean loss=1158.3534545898438\n",
      "epoch 8623\n",
      "test_train\n",
      "train mean loss=0.05670748092234135\n",
      "test_test\n",
      "test mean loss=1157.94482421875\n",
      "epoch 8624\n",
      "test_train\n",
      "train mean loss=0.05007537190491954\n",
      "test_test\n",
      "test mean loss=1158.01806640625\n",
      "epoch 8625\n",
      "test_train\n",
      "train mean loss=0.05655608233064413\n",
      "test_test\n",
      "test mean loss=1160.2503662109375\n",
      "epoch 8626\n",
      "test_train\n",
      "train mean loss=0.052682507472733654\n",
      "test_test\n",
      "test mean loss=1157.0823364257812\n",
      "epoch 8627\n",
      "test_train\n",
      "train mean loss=0.05036558257415891\n",
      "test_test\n",
      "test mean loss=1158.4044189453125\n",
      "epoch 8628\n",
      "test_train\n",
      "train mean loss=0.08840213405589263\n",
      "test_test\n",
      "test mean loss=1161.0029602050781\n",
      "epoch 8629\n",
      "test_train\n",
      "train mean loss=0.061735039576888084\n",
      "test_test\n",
      "test mean loss=1158.930419921875\n",
      "epoch 8630\n",
      "test_train\n",
      "train mean loss=0.058647870707015194\n",
      "test_test\n",
      "test mean loss=1158.484619140625\n",
      "epoch 8631\n",
      "test_train\n",
      "train mean loss=0.04749630453685919\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1158.598876953125\n",
      "epoch 8632\n",
      "test_train\n",
      "train mean loss=0.05332632393886646\n",
      "test_test\n",
      "test mean loss=1160.2329711914062\n",
      "epoch 8633\n",
      "test_train\n",
      "train mean loss=0.051833599184950195\n",
      "test_test\n",
      "test mean loss=1159.0677490234375\n",
      "epoch 8634\n",
      "test_train\n",
      "train mean loss=0.055738204158842564\n",
      "test_test\n",
      "test mean loss=1159.1857299804688\n",
      "epoch 8635\n",
      "test_train\n",
      "train mean loss=0.05833257300158342\n",
      "test_test\n",
      "test mean loss=1159.2687683105469\n",
      "epoch 8636\n",
      "test_train\n",
      "train mean loss=0.05492805534352859\n",
      "test_test\n",
      "test mean loss=1159.3550415039062\n",
      "epoch 8637\n",
      "test_train\n",
      "train mean loss=0.05175248098870119\n",
      "test_test\n",
      "test mean loss=1158.3269348144531\n",
      "epoch 8638\n",
      "test_train\n",
      "train mean loss=0.05862586914251248\n",
      "test_test\n",
      "test mean loss=1159.5025634765625\n",
      "epoch 8639\n",
      "test_train\n",
      "train mean loss=0.05462624505162239\n",
      "test_test\n",
      "test mean loss=1159.465087890625\n",
      "epoch 8640\n",
      "test_train\n",
      "train mean loss=0.05579717162375649\n",
      "test_test\n",
      "test mean loss=1158.8971252441406\n",
      "epoch 8641\n",
      "test_train\n",
      "train mean loss=0.05814862282325824\n",
      "test_test\n",
      "test mean loss=1158.855224609375\n",
      "epoch 8642\n",
      "test_train\n",
      "train mean loss=0.06145970926930507\n",
      "test_test\n",
      "test mean loss=1159.6231994628906\n",
      "epoch 8643\n",
      "test_train\n",
      "train mean loss=0.05152518426378568\n",
      "test_test\n",
      "test mean loss=1158.7222595214844\n",
      "epoch 8644\n",
      "test_train\n",
      "train mean loss=0.04964392787466446\n",
      "test_test\n",
      "test mean loss=1157.7944946289062\n",
      "epoch 8645\n",
      "test_train\n",
      "train mean loss=0.05152208156262835\n",
      "test_test\n",
      "test mean loss=1157.6734619140625\n",
      "epoch 8646\n",
      "test_train\n",
      "train mean loss=0.050243028439581394\n",
      "test_test\n",
      "test mean loss=1157.9018249511719\n",
      "epoch 8647\n",
      "test_train\n",
      "train mean loss=0.05093798149997989\n",
      "test_test\n",
      "test mean loss=1158.674072265625\n",
      "epoch 8648\n",
      "test_train\n",
      "train mean loss=0.054041529850413404\n",
      "test_test\n",
      "test mean loss=1158.5048828125\n",
      "epoch 8649\n",
      "test_train\n",
      "train mean loss=0.05127809398497144\n",
      "test_test\n",
      "test mean loss=1158.4285278320312\n",
      "epoch 8650\n",
      "test_train\n",
      "train mean loss=0.055246612367530666\n",
      "test_test\n",
      "test mean loss=1158.4799194335938\n",
      "epoch 8651\n",
      "test_train\n",
      "train mean loss=0.052370110526680946\n",
      "test_test\n",
      "test mean loss=1158.7252807617188\n",
      "epoch 8652\n",
      "test_train\n",
      "train mean loss=0.06085216129819552\n",
      "test_test\n",
      "test mean loss=1158.8703918457031\n",
      "epoch 8653\n",
      "test_train\n",
      "train mean loss=0.12813197573026022\n",
      "test_test\n",
      "test mean loss=1160.6112670898438\n",
      "epoch 8654\n",
      "test_train\n",
      "train mean loss=0.053517148829996586\n",
      "test_test\n",
      "test mean loss=1159.7520141601562\n",
      "epoch 8655\n",
      "test_train\n",
      "train mean loss=0.054021080955863\n",
      "test_test\n",
      "test mean loss=1159.1715698242188\n",
      "epoch 8656\n",
      "test_train\n",
      "train mean loss=0.052840834793945156\n",
      "test_test\n",
      "test mean loss=1158.5105590820312\n",
      "epoch 8657\n",
      "test_train\n",
      "train mean loss=0.05849296599626541\n",
      "test_test\n",
      "test mean loss=1158.8111572265625\n",
      "epoch 8658\n",
      "test_train\n",
      "train mean loss=0.057371707477917276\n",
      "test_test\n",
      "test mean loss=1158.4216918945312\n",
      "epoch 8659\n",
      "test_train\n",
      "train mean loss=0.0712195374071598\n",
      "test_test\n",
      "test mean loss=1156.7401733398438\n",
      "epoch 8660\n",
      "test_train\n",
      "train mean loss=0.06222671736031771\n",
      "test_test\n",
      "test mean loss=1158.8045043945312\n",
      "epoch 8661\n",
      "test_train\n",
      "train mean loss=0.05714683995271722\n",
      "test_test\n",
      "test mean loss=1158.8883972167969\n",
      "epoch 8662\n",
      "test_train\n",
      "train mean loss=0.05753852799534798\n",
      "test_test\n",
      "test mean loss=1158.3617858886719\n",
      "epoch 8663\n",
      "test_train\n",
      "train mean loss=0.056241652773072325\n",
      "test_test\n",
      "test mean loss=1159.1854553222656\n",
      "epoch 8664\n",
      "test_train\n",
      "train mean loss=0.05309876302878062\n",
      "test_test\n",
      "test mean loss=1158.177001953125\n",
      "epoch 8665\n",
      "test_train\n",
      "train mean loss=0.055124021135270596\n",
      "test_test\n",
      "test mean loss=1157.1390991210938\n",
      "epoch 8666\n",
      "test_train\n",
      "train mean loss=0.05355654004961252\n",
      "test_test\n",
      "test mean loss=1157.72802734375\n",
      "epoch 8667\n",
      "test_train\n",
      "train mean loss=0.06270091670254867\n",
      "test_test\n",
      "test mean loss=1158.1596069335938\n",
      "epoch 8668\n",
      "test_train\n",
      "train mean loss=0.05733678303658962\n",
      "test_test\n",
      "test mean loss=1158.518310546875\n",
      "epoch 8669\n",
      "test_train\n",
      "train mean loss=0.05523750915502509\n",
      "test_test\n",
      "test mean loss=1157.987548828125\n",
      "epoch 8670\n",
      "test_train\n",
      "train mean loss=0.05947165749967098\n",
      "test_test\n",
      "test mean loss=1158.4722900390625\n",
      "epoch 8671\n",
      "test_train\n",
      "train mean loss=0.04891193502893051\n",
      "test_test\n",
      "test mean loss=1158.5340881347656\n",
      "epoch 8672\n",
      "test_train\n",
      "train mean loss=0.05377912940457463\n",
      "test_test\n",
      "test mean loss=1157.3853149414062\n",
      "epoch 8673\n",
      "test_train\n",
      "train mean loss=0.056220056799550853\n",
      "test_test\n",
      "test mean loss=1158.5016479492188\n",
      "epoch 8674\n",
      "test_train\n",
      "train mean loss=0.0560690239071846\n",
      "test_test\n",
      "test mean loss=1158.6072387695312\n",
      "epoch 8675\n",
      "test_train\n",
      "train mean loss=0.05747497221454978\n",
      "test_test\n",
      "test mean loss=1157.9398803710938\n",
      "epoch 8676\n",
      "test_train\n",
      "train mean loss=0.05338926830639442\n",
      "test_test\n",
      "test mean loss=1158.0500793457031\n",
      "epoch 8677\n",
      "test_train\n",
      "train mean loss=0.05170696321874857\n",
      "test_test\n",
      "test mean loss=1158.5357055664062\n",
      "epoch 8678\n",
      "test_train\n",
      "train mean loss=0.05753330234438181\n",
      "test_test\n",
      "test mean loss=1157.8946838378906\n",
      "epoch 8679\n",
      "test_train\n",
      "train mean loss=0.05614442750811577\n",
      "test_test\n",
      "test mean loss=1158.0074157714844\n",
      "epoch 8680\n",
      "test_train\n",
      "train mean loss=0.05777371705820163\n",
      "test_test\n",
      "test mean loss=1158.7432250976562\n",
      "epoch 8681\n",
      "test_train\n",
      "train mean loss=0.055055828454593815\n",
      "test_test\n",
      "test mean loss=1158.5459594726562\n",
      "epoch 8682\n",
      "test_train\n",
      "train mean loss=0.05375802656635642\n",
      "test_test\n",
      "test mean loss=1158.6150512695312\n",
      "epoch 8683\n",
      "test_train\n",
      "train mean loss=0.05549054670458039\n",
      "test_test\n",
      "test mean loss=1158.5685729980469\n",
      "epoch 8684\n",
      "test_train\n",
      "train mean loss=0.053728601119170584\n",
      "test_test\n",
      "test mean loss=1158.1961669921875\n",
      "epoch 8685\n",
      "test_train\n",
      "train mean loss=0.06099771832426389\n",
      "test_test\n",
      "test mean loss=1159.8092651367188\n",
      "epoch 8686\n",
      "test_train\n",
      "train mean loss=0.05321878148242831\n",
      "test_test\n",
      "test mean loss=1158.672607421875\n",
      "epoch 8687\n",
      "test_train\n",
      "train mean loss=0.049914774329711996\n",
      "test_test\n",
      "test mean loss=1159.0743103027344\n",
      "epoch 8688\n",
      "test_train\n",
      "train mean loss=0.04734192524726192\n",
      "test_test\n",
      "test mean loss=1158.3429565429688\n",
      "epoch 8689\n",
      "test_train\n",
      "train mean loss=0.05100172199308872\n",
      "test_test\n",
      "test mean loss=1158.9969177246094\n",
      "epoch 8690\n",
      "test_train\n",
      "train mean loss=0.04490032015989224\n",
      "test_test\n",
      "test mean loss=1159.00244140625\n",
      "epoch 8691\n",
      "test_train\n",
      "train mean loss=0.057188363280147314\n",
      "test_test\n",
      "test mean loss=1159.3710021972656\n",
      "epoch 8692\n",
      "test_train\n",
      "train mean loss=0.06315340132762988\n",
      "test_test\n",
      "test mean loss=1159.9332275390625\n",
      "epoch 8693\n",
      "test_train\n",
      "train mean loss=0.053552115646501385\n",
      "test_test\n",
      "test mean loss=1159.5390625\n",
      "epoch 8694\n",
      "test_train\n",
      "train mean loss=0.0525489067658782\n",
      "test_test\n",
      "test mean loss=1159.0574340820312\n",
      "epoch 8695\n",
      "test_train\n",
      "train mean loss=0.04937503207474947\n",
      "test_test\n",
      "test mean loss=1158.9219055175781\n",
      "epoch 8696\n",
      "test_train\n",
      "train mean loss=0.05341831346352895\n",
      "test_test\n",
      "test mean loss=1158.6350708007812\n",
      "epoch 8697\n",
      "test_train\n",
      "train mean loss=0.054928130159775414\n",
      "test_test\n",
      "test mean loss=1159.3367004394531\n",
      "epoch 8698\n",
      "test_train\n",
      "train mean loss=0.053837137607236706\n",
      "test_test\n",
      "test mean loss=1159.1488952636719\n",
      "epoch 8699\n",
      "test_train\n",
      "train mean loss=0.05933439421157042\n",
      "test_test\n",
      "test mean loss=1158.5767211914062\n",
      "epoch 8700\n",
      "test_train\n",
      "train mean loss=0.05769603575269381\n",
      "test_test\n",
      "test mean loss=1159.2998352050781\n",
      "epoch 8701\n",
      "test_train\n",
      "train mean loss=0.05325138211871187\n",
      "test_test\n",
      "test mean loss=1158.3868408203125\n",
      "epoch 8702\n",
      "test_train\n",
      "train mean loss=0.04940305122484764\n",
      "test_test\n",
      "test mean loss=1158.5169982910156\n",
      "epoch 8703\n",
      "test_train\n",
      "train mean loss=0.050802317137519516\n",
      "test_test\n",
      "test mean loss=1159.1944580078125\n",
      "epoch 8704\n",
      "test_train\n",
      "train mean loss=0.05641037505120039\n",
      "test_test\n",
      "test mean loss=1159.6123657226562\n",
      "epoch 8705\n",
      "test_train\n",
      "train mean loss=0.0528327285622557\n",
      "test_test\n",
      "test mean loss=1159.4186401367188\n",
      "epoch 8706\n",
      "test_train\n",
      "train mean loss=0.05610325001180172\n",
      "test_test\n",
      "test mean loss=1158.744873046875\n",
      "epoch 8707\n",
      "test_train\n",
      "train mean loss=0.0533301893932124\n",
      "test_test\n",
      "test mean loss=1159.6600646972656\n",
      "epoch 8708\n",
      "test_train\n",
      "train mean loss=0.0494518947477142\n",
      "test_test\n",
      "test mean loss=1159.38671875\n",
      "epoch 8709\n",
      "test_train\n",
      "train mean loss=0.04779839143157005\n",
      "test_test\n",
      "test mean loss=1158.8450012207031\n",
      "epoch 8710\n",
      "test_train\n",
      "train mean loss=0.05454815489550432\n",
      "test_test\n",
      "test mean loss=1158.0670776367188\n",
      "epoch 8711\n",
      "test_train\n",
      "train mean loss=0.05774074203024308\n",
      "test_test\n",
      "test mean loss=1158.5658569335938\n",
      "epoch 8712\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_train\n",
      "train mean loss=0.06845860245327155\n",
      "test_test\n",
      "test mean loss=1159.7976379394531\n",
      "epoch 8713\n",
      "test_train\n",
      "train mean loss=0.05006100935861468\n",
      "test_test\n",
      "test mean loss=1159.23681640625\n",
      "epoch 8714\n",
      "test_train\n",
      "train mean loss=0.05653771913299958\n",
      "test_test\n",
      "test mean loss=1160.3088989257812\n",
      "epoch 8715\n",
      "test_train\n",
      "train mean loss=0.05687652140234908\n",
      "test_test\n",
      "test mean loss=1159.6228332519531\n",
      "epoch 8716\n",
      "test_train\n",
      "train mean loss=0.062375169868270554\n",
      "test_test\n",
      "test mean loss=1158.9833068847656\n",
      "epoch 8717\n",
      "test_train\n",
      "train mean loss=0.049595621724923454\n",
      "test_test\n",
      "test mean loss=1157.8564453125\n",
      "epoch 8718\n",
      "test_train\n",
      "train mean loss=0.05408367856095234\n",
      "test_test\n",
      "test mean loss=1158.5189208984375\n",
      "epoch 8719\n",
      "test_train\n",
      "train mean loss=0.050443742889910936\n",
      "test_test\n",
      "test mean loss=1158.15478515625\n",
      "epoch 8720\n",
      "test_train\n",
      "train mean loss=0.049106152883420386\n",
      "test_test\n",
      "test mean loss=1158.0637817382812\n",
      "epoch 8721\n",
      "test_train\n",
      "train mean loss=0.05104248753438393\n",
      "test_test\n",
      "test mean loss=1158.04052734375\n",
      "epoch 8722\n",
      "test_train\n",
      "train mean loss=0.04995897194991509\n",
      "test_test\n",
      "test mean loss=1158.3163452148438\n",
      "epoch 8723\n",
      "test_train\n",
      "train mean loss=0.05347111433123549\n",
      "test_test\n",
      "test mean loss=1158.1754150390625\n",
      "epoch 8724\n",
      "test_train\n",
      "train mean loss=0.04557099953914682\n",
      "test_test\n",
      "test mean loss=1158.4550170898438\n",
      "epoch 8725\n",
      "test_train\n",
      "train mean loss=0.04989749084537228\n",
      "test_test\n",
      "test mean loss=1158.455810546875\n",
      "epoch 8726\n",
      "test_train\n",
      "train mean loss=0.04453475043798486\n",
      "test_test\n",
      "test mean loss=1157.2949829101562\n",
      "epoch 8727\n",
      "test_train\n",
      "train mean loss=0.04671056242659688\n",
      "test_test\n",
      "test mean loss=1158.1409912109375\n",
      "epoch 8728\n",
      "test_train\n",
      "train mean loss=0.04625146804998318\n",
      "test_test\n",
      "test mean loss=1158.4046020507812\n",
      "epoch 8729\n",
      "test_train\n",
      "train mean loss=0.05591121812661489\n",
      "test_test\n",
      "test mean loss=1158.8983764648438\n",
      "epoch 8730\n",
      "test_train\n",
      "train mean loss=0.04786162730306387\n",
      "test_test\n",
      "test mean loss=1157.9296264648438\n",
      "epoch 8731\n",
      "test_train\n",
      "train mean loss=0.04740689291308323\n",
      "test_test\n",
      "test mean loss=1157.7222290039062\n",
      "epoch 8732\n",
      "test_train\n",
      "train mean loss=0.04784251873691877\n",
      "test_test\n",
      "test mean loss=1158.5648803710938\n",
      "epoch 8733\n",
      "test_train\n",
      "train mean loss=0.04545192482570807\n",
      "test_test\n",
      "test mean loss=1158.1582641601562\n",
      "epoch 8734\n",
      "test_train\n",
      "train mean loss=0.049916362700363\n",
      "test_test\n",
      "test mean loss=1157.7147827148438\n",
      "epoch 8735\n",
      "test_train\n",
      "train mean loss=0.049104344410200916\n",
      "test_test\n",
      "test mean loss=1158.2289123535156\n",
      "epoch 8736\n",
      "test_train\n",
      "train mean loss=0.049385824240744114\n",
      "test_test\n",
      "test mean loss=1158.2007141113281\n",
      "epoch 8737\n",
      "test_train\n",
      "train mean loss=0.052400563222666584\n",
      "test_test\n",
      "test mean loss=1158.9336853027344\n",
      "epoch 8738\n",
      "test_train\n",
      "train mean loss=0.03975360902647177\n",
      "test_test\n",
      "test mean loss=1157.4391479492188\n",
      "epoch 8739\n",
      "test_train\n",
      "train mean loss=0.04182377550750971\n",
      "test_test\n",
      "test mean loss=1156.6710815429688\n",
      "epoch 8740\n",
      "test_train\n",
      "train mean loss=0.055402468579510845\n",
      "test_test\n",
      "test mean loss=1159.2071533203125\n",
      "epoch 8741\n",
      "test_train\n",
      "train mean loss=0.04935600282624364\n",
      "test_test\n",
      "test mean loss=1157.6101684570312\n",
      "epoch 8742\n",
      "test_train\n",
      "train mean loss=0.05071758603056272\n",
      "test_test\n",
      "test mean loss=1158.4788208007812\n",
      "epoch 8743\n",
      "test_train\n",
      "train mean loss=0.05035832151770592\n",
      "test_test\n",
      "test mean loss=1158.5654296875\n",
      "epoch 8744\n",
      "test_train\n",
      "train mean loss=0.04959582661588987\n",
      "test_test\n",
      "test mean loss=1158.0081176757812\n",
      "epoch 8745\n",
      "test_train\n",
      "train mean loss=0.04873551350707809\n",
      "test_test\n",
      "test mean loss=1157.0108642578125\n",
      "epoch 8746\n",
      "test_train\n",
      "train mean loss=0.05298195934544007\n",
      "test_test\n",
      "test mean loss=1156.5460815429688\n",
      "epoch 8747\n",
      "test_train\n",
      "train mean loss=0.04975862087061008\n",
      "test_test\n",
      "test mean loss=1156.4882202148438\n",
      "epoch 8748\n",
      "test_train\n",
      "train mean loss=0.04949182163303097\n",
      "test_test\n",
      "test mean loss=1157.6644592285156\n",
      "epoch 8749\n",
      "test_train\n",
      "train mean loss=0.05471337338288625\n",
      "test_test\n",
      "test mean loss=1159.1868286132812\n",
      "epoch 8750\n",
      "test_train\n",
      "train mean loss=0.04976598390688499\n",
      "test_test\n",
      "test mean loss=1158.79638671875\n",
      "epoch 8751\n",
      "test_train\n",
      "train mean loss=0.05073563350985447\n",
      "test_test\n",
      "test mean loss=1159.905029296875\n",
      "epoch 8752\n",
      "test_train\n",
      "train mean loss=0.047771538607776165\n",
      "test_test\n",
      "test mean loss=1156.8668823242188\n",
      "epoch 8753\n",
      "test_train\n",
      "train mean loss=0.05314523633569479\n",
      "test_test\n",
      "test mean loss=1157.270751953125\n",
      "epoch 8754\n",
      "test_train\n",
      "train mean loss=0.053182869063069425\n",
      "test_test\n",
      "test mean loss=1159.3720703125\n",
      "epoch 8755\n",
      "test_train\n",
      "train mean loss=0.055240203626453876\n",
      "test_test\n",
      "test mean loss=1160.8272094726562\n",
      "epoch 8756\n",
      "test_train\n",
      "train mean loss=0.046090712460378803\n",
      "test_test\n",
      "test mean loss=1160.0164184570312\n",
      "epoch 8757\n",
      "test_train\n",
      "train mean loss=0.052886495677133404\n",
      "test_test\n",
      "test mean loss=1160.32568359375\n",
      "epoch 8758\n",
      "test_train\n",
      "train mean loss=0.049029122572392225\n",
      "test_test\n",
      "test mean loss=1159.2583618164062\n",
      "epoch 8759\n",
      "test_train\n",
      "train mean loss=0.0539892598365744\n",
      "test_test\n",
      "test mean loss=1159.2297973632812\n",
      "epoch 8760\n",
      "test_train\n",
      "train mean loss=0.049787401842574276\n",
      "test_test\n",
      "test mean loss=1159.7796630859375\n",
      "epoch 8761\n",
      "test_train\n",
      "train mean loss=0.05645701102912426\n",
      "test_test\n",
      "test mean loss=1160.3038940429688\n",
      "epoch 8762\n",
      "test_train\n",
      "train mean loss=0.05291991742948691\n",
      "test_test\n",
      "test mean loss=1159.8790893554688\n",
      "epoch 8763\n",
      "test_train\n",
      "train mean loss=0.05058346036821604\n",
      "test_test\n",
      "test mean loss=1159.27099609375\n",
      "epoch 8764\n",
      "test_train\n",
      "train mean loss=0.05034351504097382\n",
      "test_test\n",
      "test mean loss=1160.1472778320312\n",
      "epoch 8765\n",
      "test_train\n",
      "train mean loss=0.048594964357713856\n",
      "test_test\n",
      "test mean loss=1158.2528076171875\n",
      "epoch 8766\n",
      "test_train\n",
      "train mean loss=0.054146958670268454\n",
      "test_test\n",
      "test mean loss=1158.2490234375\n",
      "epoch 8767\n",
      "test_train\n",
      "train mean loss=0.05024762342994412\n",
      "test_test\n",
      "test mean loss=1158.6147155761719\n",
      "epoch 8768\n",
      "test_train\n",
      "train mean loss=0.05333200003951788\n",
      "test_test\n",
      "test mean loss=1158.568603515625\n",
      "epoch 8769\n",
      "test_train\n",
      "train mean loss=0.05380924309914311\n",
      "test_test\n",
      "test mean loss=1158.2891235351562\n",
      "epoch 8770\n",
      "test_train\n",
      "train mean loss=0.05189634564643105\n",
      "test_test\n",
      "test mean loss=1158.9262084960938\n",
      "epoch 8771\n",
      "test_train\n",
      "train mean loss=0.05135492111245791\n",
      "test_test\n",
      "test mean loss=1159.2835693359375\n",
      "epoch 8772\n",
      "test_train\n",
      "train mean loss=0.04933058610185981\n",
      "test_test\n",
      "test mean loss=1158.5346984863281\n",
      "epoch 8773\n",
      "test_train\n",
      "train mean loss=0.05847397353500128\n",
      "test_test\n",
      "test mean loss=1159.6372985839844\n",
      "epoch 8774\n",
      "test_train\n",
      "train mean loss=0.05393789056688547\n",
      "test_test\n",
      "test mean loss=1159.3594970703125\n",
      "epoch 8775\n",
      "test_train\n",
      "train mean loss=0.051566231374939285\n",
      "test_test\n",
      "test mean loss=1159.3259582519531\n",
      "epoch 8776\n",
      "test_train\n",
      "train mean loss=0.05336041779567798\n",
      "test_test\n",
      "test mean loss=1158.14208984375\n",
      "epoch 8777\n",
      "test_train\n",
      "train mean loss=0.050561534551282726\n",
      "test_test\n",
      "test mean loss=1159.0016479492188\n",
      "epoch 8778\n",
      "test_train\n",
      "train mean loss=0.05040811483437816\n",
      "test_test\n",
      "test mean loss=1158.5604858398438\n",
      "epoch 8779\n",
      "test_train\n",
      "train mean loss=0.05478405021131039\n",
      "test_test\n",
      "test mean loss=1158.7734375\n",
      "epoch 8780\n",
      "test_train\n",
      "train mean loss=0.049827360858519874\n",
      "test_test\n",
      "test mean loss=1159.2675170898438\n",
      "epoch 8781\n",
      "test_train\n",
      "train mean loss=0.05765454781552156\n",
      "test_test\n",
      "test mean loss=1159.7861633300781\n",
      "epoch 8782\n",
      "test_train\n",
      "train mean loss=0.05240877748777469\n",
      "test_test\n",
      "test mean loss=1158.505126953125\n",
      "epoch 8783\n",
      "test_train\n",
      "train mean loss=0.058726100251078606\n",
      "test_test\n",
      "test mean loss=1158.6078491210938\n",
      "epoch 8784\n",
      "test_train\n",
      "train mean loss=0.0573874336356918\n",
      "test_test\n",
      "test mean loss=1159.78369140625\n",
      "epoch 8785\n",
      "test_train\n",
      "train mean loss=0.06735157625128825\n",
      "test_test\n",
      "test mean loss=1160.0119018554688\n",
      "epoch 8786\n",
      "test_train\n",
      "train mean loss=0.050815136482318245\n",
      "test_test\n",
      "test mean loss=1158.737060546875\n",
      "epoch 8787\n",
      "test_train\n",
      "train mean loss=0.0556500181555748\n",
      "test_test\n",
      "test mean loss=1157.8729858398438\n",
      "epoch 8788\n",
      "test_train\n",
      "train mean loss=0.053006308153271675\n",
      "test_test\n",
      "test mean loss=1158.6815185546875\n",
      "epoch 8789\n",
      "test_train\n",
      "train mean loss=0.055701157388587795\n",
      "test_test\n",
      "test mean loss=1159.404541015625\n",
      "epoch 8790\n",
      "test_train\n",
      "train mean loss=0.04932863467062513\n",
      "test_test\n",
      "test mean loss=1159.705810546875\n",
      "epoch 8791\n",
      "test_train\n",
      "train mean loss=0.056440660574783884\n",
      "test_test\n",
      "test mean loss=1158.3500671386719\n",
      "epoch 8792\n",
      "test_train\n",
      "train mean loss=0.050794365194936596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_test\n",
      "test mean loss=1157.4523315429688\n",
      "epoch 8793\n",
      "test_train\n",
      "train mean loss=0.0467981961555779\n",
      "test_test\n",
      "test mean loss=1157.836669921875\n",
      "epoch 8794\n",
      "test_train\n",
      "train mean loss=0.045276194966087736\n",
      "test_test\n",
      "test mean loss=1157.38232421875\n",
      "epoch 8795\n",
      "test_train\n",
      "train mean loss=0.05201828914384047\n",
      "test_test\n",
      "test mean loss=1160.2169494628906\n",
      "epoch 8796\n",
      "test_train\n",
      "train mean loss=0.05289027513936162\n",
      "test_test\n",
      "test mean loss=1158.8699951171875\n",
      "epoch 8797\n",
      "test_train\n",
      "train mean loss=0.052971430433293186\n",
      "test_test\n",
      "test mean loss=1158.709716796875\n",
      "epoch 8798\n",
      "test_train\n",
      "train mean loss=0.053145295629898705\n",
      "test_test\n",
      "test mean loss=1159.3174438476562\n",
      "epoch 8799\n",
      "test_train\n",
      "train mean loss=0.04756797136118015\n",
      "test_test\n",
      "test mean loss=1158.4765014648438\n",
      "epoch 8800\n",
      "test_train\n",
      "train mean loss=0.052410367565850415\n",
      "test_test\n",
      "test mean loss=1159.4768676757812\n",
      "epoch 8801\n",
      "test_train\n",
      "train mean loss=0.05021155873934428\n",
      "test_test\n",
      "test mean loss=1160.1654663085938\n",
      "epoch 8802\n",
      "test_train\n",
      "train mean loss=0.05380110784123341\n",
      "test_test\n",
      "test mean loss=1159.581298828125\n",
      "epoch 8803\n",
      "test_train\n",
      "train mean loss=0.050552710269888244\n",
      "test_test\n",
      "test mean loss=1158.9044799804688\n",
      "epoch 8804\n",
      "test_train\n",
      "train mean loss=0.06750506442040205\n",
      "test_test\n",
      "test mean loss=1157.78662109375\n",
      "epoch 8805\n",
      "test_train\n",
      "train mean loss=0.05477710347622633\n",
      "test_test\n",
      "test mean loss=1157.7500915527344\n",
      "epoch 8806\n",
      "test_train\n",
      "train mean loss=0.05281413905322552\n",
      "test_test\n",
      "test mean loss=1158.1535034179688\n",
      "epoch 8807\n",
      "test_train\n",
      "train mean loss=0.05594148517896732\n",
      "test_test\n",
      "test mean loss=1158.15478515625\n",
      "epoch 8808\n",
      "test_train\n",
      "train mean loss=0.05073280337577065\n",
      "test_test\n",
      "test mean loss=1158.8406372070312\n",
      "epoch 8809\n",
      "test_train\n",
      "train mean loss=0.04370105483879646\n",
      "test_test\n",
      "test mean loss=1158.2048950195312\n",
      "epoch 8810\n",
      "test_train\n",
      "train mean loss=0.05410992121323943\n",
      "test_test\n",
      "test mean loss=1158.1371459960938\n",
      "epoch 8811\n",
      "test_train\n",
      "train mean loss=0.054698302720983825\n",
      "test_test\n",
      "test mean loss=1159.2688598632812\n",
      "epoch 8812\n",
      "test_train\n",
      "train mean loss=0.05452004758020242\n",
      "test_test\n",
      "test mean loss=1159.7078552246094\n",
      "epoch 8813\n",
      "test_train\n",
      "train mean loss=0.058087896555662155\n",
      "test_test\n",
      "test mean loss=1160.0551147460938\n",
      "epoch 8814\n",
      "test_train\n",
      "train mean loss=0.05216119314233462\n",
      "test_test\n",
      "test mean loss=1159.0130615234375\n",
      "epoch 8815\n",
      "test_train\n",
      "train mean loss=0.048186754497388996\n",
      "test_test\n",
      "test mean loss=1158.4706420898438\n",
      "epoch 8816\n",
      "test_train\n",
      "train mean loss=0.05283047320942084\n",
      "test_test\n",
      "test mean loss=1158.1754760742188\n",
      "epoch 8817\n",
      "test_train\n",
      "train mean loss=0.07187684501210849\n",
      "test_test\n",
      "test mean loss=1161.4524230957031\n",
      "epoch 8818\n",
      "test_train\n",
      "train mean loss=0.056045256089419127\n",
      "test_test\n",
      "test mean loss=1158.5568237304688\n",
      "epoch 8819\n",
      "test_train\n",
      "train mean loss=0.0476950746960938\n",
      "test_test\n",
      "test mean loss=1158.1603698730469\n",
      "epoch 8820\n",
      "test_train\n",
      "train mean loss=0.04811776988208294\n",
      "test_test\n",
      "test mean loss=1158.6850280761719\n",
      "epoch 8821\n",
      "test_train\n",
      "train mean loss=0.04871648550033569\n",
      "test_test\n",
      "test mean loss=1158.4551391601562\n",
      "epoch 8822\n",
      "test_train\n",
      "train mean loss=0.06246790693451961\n",
      "test_test\n",
      "test mean loss=1157.9071655273438\n",
      "epoch 8823\n",
      "test_train\n",
      "train mean loss=0.04764457140117884\n",
      "test_test\n",
      "test mean loss=1158.5418090820312\n",
      "epoch 8824\n",
      "test_train\n",
      "train mean loss=0.05183093622326851\n",
      "test_test\n",
      "test mean loss=1158.1646423339844\n",
      "epoch 8825\n",
      "test_train\n",
      "train mean loss=0.06244113389402628\n",
      "test_test\n",
      "test mean loss=1157.9867553710938\n",
      "epoch 8826\n",
      "test_train\n",
      "train mean loss=0.09000422370930512\n",
      "test_test\n",
      "test mean loss=1152.8650207519531\n",
      "epoch 8827\n",
      "test_train\n",
      "train mean loss=0.0578437764197588\n",
      "test_test\n",
      "test mean loss=1158.3150939941406\n",
      "epoch 8828\n",
      "test_train\n",
      "train mean loss=0.05572744272649288\n",
      "test_test\n",
      "test mean loss=1158.3942260742188\n",
      "epoch 8829\n",
      "test_train\n",
      "train mean loss=0.049781936686486006\n",
      "test_test\n",
      "test mean loss=1158.262939453125\n",
      "epoch 8830\n",
      "test_train\n",
      "train mean loss=0.05440814203272263\n",
      "test_test\n",
      "test mean loss=1158.0565185546875\n",
      "epoch 8831\n",
      "test_train\n",
      "train mean loss=0.0512704288897415\n",
      "test_test\n",
      "test mean loss=1158.2461853027344\n",
      "epoch 8832\n",
      "test_train\n",
      "train mean loss=0.048964842998733125\n",
      "test_test\n",
      "test mean loss=1158.5758056640625\n",
      "epoch 8833\n",
      "test_train\n",
      "train mean loss=0.05097397758315007\n",
      "test_test\n",
      "test mean loss=1157.9140625\n",
      "epoch 8834\n",
      "test_train\n",
      "train mean loss=0.04973429845025142\n",
      "test_test\n",
      "test mean loss=1157.661376953125\n",
      "epoch 8835\n",
      "test_train\n",
      "train mean loss=0.05347689768920342\n",
      "test_test\n",
      "test mean loss=1157.9745788574219\n",
      "epoch 8836\n",
      "test_train\n",
      "train mean loss=0.045053021516650915\n",
      "test_test\n",
      "test mean loss=1157.8406372070312\n",
      "epoch 8837\n",
      "test_train\n",
      "train mean loss=0.04813428626706203\n",
      "test_test\n",
      "test mean loss=1158.9207763671875\n",
      "epoch 8838\n",
      "test_train\n",
      "train mean loss=0.053068083710968494\n",
      "test_test\n",
      "test mean loss=1158.1757202148438\n",
      "epoch 8839\n",
      "test_train\n",
      "train mean loss=0.05550654946515957\n",
      "test_test\n",
      "test mean loss=1157.983154296875\n",
      "epoch 8840\n",
      "test_train\n",
      "train mean loss=0.049705447939534984\n",
      "test_test\n",
      "test mean loss=1157.572998046875\n",
      "epoch 8841\n",
      "test_train\n",
      "train mean loss=0.05269684394200643\n",
      "test_test\n",
      "test mean loss=1158.4809875488281\n",
      "epoch 8842\n",
      "test_train\n",
      "train mean loss=0.05129982763901353\n",
      "test_test\n",
      "test mean loss=1158.9126586914062\n",
      "epoch 8843\n",
      "test_train\n",
      "train mean loss=0.04897743354861935\n",
      "test_test\n",
      "test mean loss=1158.531494140625\n",
      "epoch 8844\n",
      "test_train\n",
      "train mean loss=0.05482845567166805\n",
      "test_test\n",
      "test mean loss=1157.9274291992188\n",
      "epoch 8845\n",
      "test_train\n",
      "train mean loss=0.05430358927696943\n",
      "test_test\n",
      "test mean loss=1158.0759887695312\n",
      "epoch 8846\n",
      "test_train\n",
      "train mean loss=0.051041345888127886\n",
      "test_test\n",
      "test mean loss=1158.1242980957031\n",
      "epoch 8847\n",
      "test_train\n",
      "train mean loss=0.048042693796257176\n",
      "test_test\n",
      "test mean loss=1157.6768188476562\n",
      "epoch 8848\n",
      "test_train\n",
      "train mean loss=0.04964539222419262\n",
      "test_test\n",
      "test mean loss=1158.8306274414062\n",
      "epoch 8849\n",
      "test_train\n",
      "train mean loss=0.05987569379309813\n",
      "test_test\n",
      "test mean loss=1158.7947692871094\n",
      "epoch 8850\n",
      "test_train\n",
      "train mean loss=0.055018188431859016\n",
      "test_test\n",
      "test mean loss=1157.7998046875\n",
      "epoch 8851\n",
      "test_train\n",
      "train mean loss=0.05110965482890606\n",
      "test_test\n",
      "test mean loss=1157.8453979492188\n",
      "epoch 8852\n",
      "test_train\n",
      "train mean loss=0.06081632633383075\n",
      "test_test\n",
      "test mean loss=1158.8359985351562\n",
      "epoch 8853\n",
      "test_train\n",
      "train mean loss=0.05779955070465803\n",
      "test_test\n",
      "test mean loss=1157.9505004882812\n",
      "epoch 8854\n",
      "test_train\n",
      "train mean loss=0.05715246871113777\n",
      "test_test\n",
      "test mean loss=1158.0782470703125\n",
      "epoch 8855\n",
      "test_train\n",
      "train mean loss=0.05336435573796431\n",
      "test_test\n",
      "test mean loss=1159.1548767089844\n",
      "epoch 8856\n",
      "test_train\n",
      "train mean loss=0.050190817875166736\n",
      "test_test\n",
      "test mean loss=1159.146240234375\n",
      "epoch 8857\n",
      "test_train\n",
      "train mean loss=0.05465995861838261\n",
      "test_test\n",
      "test mean loss=1156.9727172851562\n",
      "epoch 8858\n",
      "test_train\n",
      "train mean loss=0.05477054029082259\n",
      "test_test\n",
      "test mean loss=1158.2507934570312\n",
      "epoch 8859\n",
      "test_train\n",
      "train mean loss=0.04937794152647257\n",
      "test_test\n",
      "test mean loss=1157.6308898925781\n",
      "epoch 8860\n",
      "test_train\n",
      "train mean loss=0.052458994245777525\n",
      "test_test\n",
      "test mean loss=1158.0905151367188\n",
      "epoch 8861\n",
      "test_train\n",
      "train mean loss=0.045731854935487114\n",
      "test_test\n",
      "test mean loss=1158.0987243652344\n",
      "epoch 8862\n",
      "test_train\n",
      "train mean loss=0.05176119009653727\n",
      "test_test\n",
      "test mean loss=1157.55224609375\n",
      "epoch 8863\n",
      "test_train\n",
      "train mean loss=0.04811152722686529\n",
      "test_test\n",
      "test mean loss=1157.5487670898438\n",
      "epoch 8864\n",
      "test_train\n",
      "train mean loss=0.043766705164064966\n",
      "test_test\n",
      "test mean loss=1157.1388244628906\n",
      "epoch 8865\n",
      "test_train\n",
      "train mean loss=0.04865187872201204\n",
      "test_test\n",
      "test mean loss=1157.9988403320312\n",
      "epoch 8866\n",
      "test_train\n",
      "train mean loss=0.054047171492129564\n",
      "test_test\n",
      "test mean loss=1158.34912109375\n",
      "epoch 8867\n",
      "test_train\n",
      "train mean loss=0.05127121678863963\n",
      "test_test\n",
      "test mean loss=1158.1163940429688\n",
      "epoch 8868\n",
      "test_train\n",
      "train mean loss=0.047773932262013354\n",
      "test_test\n",
      "test mean loss=1158.5935668945312\n",
      "epoch 8869\n",
      "test_train\n",
      "train mean loss=0.057072452579935394\n",
      "test_test\n",
      "test mean loss=1159.3106079101562\n",
      "epoch 8870\n",
      "test_train\n",
      "train mean loss=0.05470878165215254\n",
      "test_test\n",
      "test mean loss=1159.1605834960938\n",
      "epoch 8871\n",
      "test_train\n",
      "train mean loss=0.04884870598713557\n",
      "test_test\n",
      "test mean loss=1158.4506225585938\n",
      "epoch 8872\n",
      "test_train\n",
      "train mean loss=0.05883647749821345\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1159.0442504882812\n",
      "epoch 8873\n",
      "test_train\n",
      "train mean loss=0.05304196445892254\n",
      "test_test\n",
      "test mean loss=1157.907958984375\n",
      "epoch 8874\n",
      "test_train\n",
      "train mean loss=0.05265695555135608\n",
      "test_test\n",
      "test mean loss=1158.5729675292969\n",
      "epoch 8875\n",
      "test_train\n",
      "train mean loss=0.04724175731341044\n",
      "test_test\n",
      "test mean loss=1156.51708984375\n",
      "epoch 8876\n",
      "test_train\n",
      "train mean loss=0.04699375371759137\n",
      "test_test\n",
      "test mean loss=1157.7970275878906\n",
      "epoch 8877\n",
      "test_train\n",
      "train mean loss=0.05262042426814636\n",
      "test_test\n",
      "test mean loss=1158.357177734375\n",
      "epoch 8878\n",
      "test_train\n",
      "train mean loss=0.07198125341286261\n",
      "test_test\n",
      "test mean loss=1159.9317932128906\n",
      "epoch 8879\n",
      "test_train\n",
      "train mean loss=0.0547992253365616\n",
      "test_test\n",
      "test mean loss=1158.8881225585938\n",
      "epoch 8880\n",
      "test_train\n",
      "train mean loss=0.05253397207707167\n",
      "test_test\n",
      "test mean loss=1158.0460815429688\n",
      "epoch 8881\n",
      "test_train\n",
      "train mean loss=0.047189103439450264\n",
      "test_test\n",
      "test mean loss=1157.7638549804688\n",
      "epoch 8882\n",
      "test_train\n",
      "train mean loss=0.04885772801935673\n",
      "test_test\n",
      "test mean loss=1157.681884765625\n",
      "epoch 8883\n",
      "test_train\n",
      "train mean loss=0.05204590378950039\n",
      "test_test\n",
      "test mean loss=1157.6030883789062\n",
      "epoch 8884\n",
      "test_train\n",
      "train mean loss=0.056904831901192665\n",
      "test_test\n",
      "test mean loss=1159.0697021484375\n",
      "epoch 8885\n",
      "test_train\n",
      "train mean loss=0.050716339300076164\n",
      "test_test\n",
      "test mean loss=1158.1088256835938\n",
      "epoch 8886\n",
      "test_train\n",
      "train mean loss=0.052451057670017086\n",
      "test_test\n",
      "test mean loss=1158.3209228515625\n",
      "epoch 8887\n",
      "test_train\n",
      "train mean loss=0.04971040335173408\n",
      "test_test\n",
      "test mean loss=1157.9379272460938\n",
      "epoch 8888\n",
      "test_train\n",
      "train mean loss=0.04987466397384802\n",
      "test_test\n",
      "test mean loss=1158.0244140625\n",
      "epoch 8889\n",
      "test_train\n",
      "train mean loss=0.05087669069568316\n",
      "test_test\n",
      "test mean loss=1159.3804016113281\n",
      "epoch 8890\n",
      "test_train\n",
      "train mean loss=0.047982435363034405\n",
      "test_test\n",
      "test mean loss=1158.822998046875\n",
      "epoch 8891\n",
      "test_train\n",
      "train mean loss=0.05042722293486198\n",
      "test_test\n",
      "test mean loss=1158.8265991210938\n",
      "epoch 8892\n",
      "test_train\n",
      "train mean loss=0.04640521497155229\n",
      "test_test\n",
      "test mean loss=1157.758056640625\n",
      "epoch 8893\n",
      "test_train\n",
      "train mean loss=0.04773981620868047\n",
      "test_test\n",
      "test mean loss=1158.0111694335938\n",
      "epoch 8894\n",
      "test_train\n",
      "train mean loss=0.05296710195640723\n",
      "test_test\n",
      "test mean loss=1158.4824829101562\n",
      "epoch 8895\n",
      "test_train\n",
      "train mean loss=0.05113273300230503\n",
      "test_test\n",
      "test mean loss=1157.5316162109375\n",
      "epoch 8896\n",
      "test_train\n",
      "train mean loss=0.050636262322465576\n",
      "test_test\n",
      "test mean loss=1156.8916320800781\n",
      "epoch 8897\n",
      "test_train\n",
      "train mean loss=0.04745049308985472\n",
      "test_test\n",
      "test mean loss=1157.8341064453125\n",
      "epoch 8898\n",
      "test_train\n",
      "train mean loss=0.05280917246515552\n",
      "test_test\n",
      "test mean loss=1159.1874389648438\n",
      "epoch 8899\n",
      "test_train\n",
      "train mean loss=0.05447274229178826\n",
      "test_test\n",
      "test mean loss=1158.6021118164062\n",
      "epoch 8900\n",
      "test_train\n",
      "train mean loss=0.04584818364431461\n",
      "test_test\n",
      "test mean loss=1157.3719482421875\n",
      "epoch 8901\n",
      "test_train\n",
      "train mean loss=0.052274030012389026\n",
      "test_test\n",
      "test mean loss=1157.9713439941406\n",
      "epoch 8902\n",
      "test_train\n",
      "train mean loss=0.061050349536041416\n",
      "test_test\n",
      "test mean loss=1159.6790161132812\n",
      "epoch 8903\n",
      "test_train\n",
      "train mean loss=0.058589671117564045\n",
      "test_test\n",
      "test mean loss=1159.2447509765625\n",
      "epoch 8904\n",
      "test_train\n",
      "train mean loss=0.05599597375839949\n",
      "test_test\n",
      "test mean loss=1158.4935607910156\n",
      "epoch 8905\n",
      "test_train\n",
      "train mean loss=0.05317140991489092\n",
      "test_test\n",
      "test mean loss=1158.5597839355469\n",
      "epoch 8906\n",
      "test_train\n",
      "train mean loss=0.05180750507861376\n",
      "test_test\n",
      "test mean loss=1158.8128967285156\n",
      "epoch 8907\n",
      "test_train\n",
      "train mean loss=0.054548331536352634\n",
      "test_test\n",
      "test mean loss=1158.5804748535156\n",
      "epoch 8908\n",
      "test_train\n",
      "train mean loss=0.051823489367961884\n",
      "test_test\n",
      "test mean loss=1157.759033203125\n",
      "epoch 8909\n",
      "test_train\n",
      "train mean loss=0.05389155292262634\n",
      "test_test\n",
      "test mean loss=1158.2633361816406\n",
      "epoch 8910\n",
      "test_train\n",
      "train mean loss=0.05296734472115835\n",
      "test_test\n",
      "test mean loss=1158.6400451660156\n",
      "epoch 8911\n",
      "test_train\n",
      "train mean loss=0.05541034756849209\n",
      "test_test\n",
      "test mean loss=1159.2174682617188\n",
      "epoch 8912\n",
      "test_train\n",
      "train mean loss=0.05619958803678552\n",
      "test_test\n",
      "test mean loss=1159.9360046386719\n",
      "epoch 8913\n",
      "test_train\n",
      "train mean loss=0.05643689384063085\n",
      "test_test\n",
      "test mean loss=1159.5775451660156\n",
      "epoch 8914\n",
      "test_train\n",
      "train mean loss=0.05475795610497395\n",
      "test_test\n",
      "test mean loss=1158.9214477539062\n",
      "epoch 8915\n",
      "test_train\n",
      "train mean loss=0.056700367790957294\n",
      "test_test\n",
      "test mean loss=1159.8558349609375\n",
      "epoch 8916\n",
      "test_train\n",
      "train mean loss=0.04948628724863132\n",
      "test_test\n",
      "test mean loss=1158.5119018554688\n",
      "epoch 8917\n",
      "test_train\n",
      "train mean loss=0.058639522176235914\n",
      "test_test\n",
      "test mean loss=1157.9664306640625\n",
      "epoch 8918\n",
      "test_train\n",
      "train mean loss=0.04858212716256579\n",
      "test_test\n",
      "test mean loss=1157.2918395996094\n",
      "epoch 8919\n",
      "test_train\n",
      "train mean loss=0.04315099182228247\n",
      "test_test\n",
      "test mean loss=1158.7830810546875\n",
      "epoch 8920\n",
      "test_train\n",
      "train mean loss=0.04355066874995828\n",
      "test_test\n",
      "test mean loss=1158.9968872070312\n",
      "epoch 8921\n",
      "test_train\n",
      "train mean loss=0.05371478324135145\n",
      "test_test\n",
      "test mean loss=1158.8344116210938\n",
      "epoch 8922\n",
      "test_train\n",
      "train mean loss=0.05096499032030503\n",
      "test_test\n",
      "test mean loss=1158.4938049316406\n",
      "epoch 8923\n",
      "test_train\n",
      "train mean loss=0.05099310074001551\n",
      "test_test\n",
      "test mean loss=1158.3601684570312\n",
      "epoch 8924\n",
      "test_train\n",
      "train mean loss=0.051949347369372845\n",
      "test_test\n",
      "test mean loss=1157.9678955078125\n",
      "epoch 8925\n",
      "test_train\n",
      "train mean loss=0.05423386674374342\n",
      "test_test\n",
      "test mean loss=1158.8363647460938\n",
      "epoch 8926\n",
      "test_train\n",
      "train mean loss=0.04906858829781413\n",
      "test_test\n",
      "test mean loss=1157.9000854492188\n",
      "epoch 8927\n",
      "test_train\n",
      "train mean loss=0.04795557539910078\n",
      "test_test\n",
      "test mean loss=1157.3955993652344\n",
      "epoch 8928\n",
      "test_train\n",
      "train mean loss=0.050867072927455105\n",
      "test_test\n",
      "test mean loss=1158.0167846679688\n",
      "epoch 8929\n",
      "test_train\n",
      "train mean loss=0.04645251218850414\n",
      "test_test\n",
      "test mean loss=1158.0491638183594\n",
      "epoch 8930\n",
      "test_train\n",
      "train mean loss=0.04928649061669906\n",
      "test_test\n",
      "test mean loss=1158.4280395507812\n",
      "epoch 8931\n",
      "test_train\n",
      "train mean loss=0.048565680937220655\n",
      "test_test\n",
      "test mean loss=1157.9270935058594\n",
      "epoch 8932\n",
      "test_train\n",
      "train mean loss=0.04987847773979107\n",
      "test_test\n",
      "test mean loss=1158.2769775390625\n",
      "epoch 8933\n",
      "test_train\n",
      "train mean loss=0.05555645531664292\n",
      "test_test\n",
      "test mean loss=1157.7550659179688\n",
      "epoch 8934\n",
      "test_train\n",
      "train mean loss=0.059613344414780535\n",
      "test_test\n",
      "test mean loss=1158.9677734375\n",
      "epoch 8935\n",
      "test_train\n",
      "train mean loss=0.05617184595515331\n",
      "test_test\n",
      "test mean loss=1158.724609375\n",
      "epoch 8936\n",
      "test_train\n",
      "train mean loss=0.05259894703825315\n",
      "test_test\n",
      "test mean loss=1158.5718078613281\n",
      "epoch 8937\n",
      "test_train\n",
      "train mean loss=0.05987452638025085\n",
      "test_test\n",
      "test mean loss=1159.4136962890625\n",
      "epoch 8938\n",
      "test_train\n",
      "train mean loss=0.05339455263068279\n",
      "test_test\n",
      "test mean loss=1158.0462646484375\n",
      "epoch 8939\n",
      "test_train\n",
      "train mean loss=0.05126007863630851\n",
      "test_test\n",
      "test mean loss=1159.1549072265625\n",
      "epoch 8940\n",
      "test_train\n",
      "train mean loss=0.052285794634371996\n",
      "test_test\n",
      "test mean loss=1159.359130859375\n",
      "epoch 8941\n",
      "test_train\n",
      "train mean loss=0.047953700025876365\n",
      "test_test\n",
      "test mean loss=1158.9425048828125\n",
      "epoch 8942\n",
      "test_train\n",
      "train mean loss=0.04890345005939404\n",
      "test_test\n",
      "test mean loss=1159.5309753417969\n",
      "epoch 8943\n",
      "test_train\n",
      "train mean loss=0.04879295639693737\n",
      "test_test\n",
      "test mean loss=1158.819091796875\n",
      "epoch 8944\n",
      "test_train\n",
      "train mean loss=0.0512502136019369\n",
      "test_test\n",
      "test mean loss=1158.913818359375\n",
      "epoch 8945\n",
      "test_train\n",
      "train mean loss=0.0523959215109547\n",
      "test_test\n",
      "test mean loss=1158.6701049804688\n",
      "epoch 8946\n",
      "test_train\n",
      "train mean loss=0.04581856308504939\n",
      "test_test\n",
      "test mean loss=1159.3275146484375\n",
      "epoch 8947\n",
      "test_train\n",
      "train mean loss=0.046247221839924656\n",
      "test_test\n",
      "test mean loss=1159.2277221679688\n",
      "epoch 8948\n",
      "test_train\n",
      "train mean loss=0.05039356338481108\n",
      "test_test\n",
      "test mean loss=1159.1027221679688\n",
      "epoch 8949\n",
      "test_train\n",
      "train mean loss=0.05566656030714512\n",
      "test_test\n",
      "test mean loss=1159.75537109375\n",
      "epoch 8950\n",
      "test_train\n",
      "train mean loss=0.05952986671278874\n",
      "test_test\n",
      "test mean loss=1160.7839965820312\n",
      "epoch 8951\n",
      "test_train\n",
      "train mean loss=0.05611306708306074\n",
      "test_test\n",
      "test mean loss=1160.0389404296875\n",
      "epoch 8952\n",
      "test_train\n",
      "train mean loss=0.04578630564113458\n",
      "test_test\n",
      "test mean loss=1158.3346557617188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8953\n",
      "test_train\n",
      "train mean loss=0.051453663501888514\n",
      "test_test\n",
      "test mean loss=1158.7838745117188\n",
      "epoch 8954\n",
      "test_train\n",
      "train mean loss=0.05589312563339869\n",
      "test_test\n",
      "test mean loss=1159.7311096191406\n",
      "epoch 8955\n",
      "test_train\n",
      "train mean loss=0.058615785712997116\n",
      "test_test\n",
      "test mean loss=1157.6030578613281\n",
      "epoch 8956\n",
      "test_train\n",
      "train mean loss=0.05531727243214846\n",
      "test_test\n",
      "test mean loss=1158.6533813476562\n",
      "epoch 8957\n",
      "test_train\n",
      "train mean loss=0.048558658454567194\n",
      "test_test\n",
      "test mean loss=1158.4643859863281\n",
      "epoch 8958\n",
      "test_train\n",
      "train mean loss=0.052696247274676956\n",
      "test_test\n",
      "test mean loss=1159.235107421875\n",
      "epoch 8959\n",
      "test_train\n",
      "train mean loss=0.05129560440157851\n",
      "test_test\n",
      "test mean loss=1158.9993286132812\n",
      "epoch 8960\n",
      "test_train\n",
      "train mean loss=0.05020218497763077\n",
      "test_test\n",
      "test mean loss=1159.0054016113281\n",
      "epoch 8961\n",
      "test_train\n",
      "train mean loss=0.04631025639052192\n",
      "test_test\n",
      "test mean loss=1158.0203857421875\n",
      "epoch 8962\n",
      "test_train\n",
      "train mean loss=0.05455606089284023\n",
      "test_test\n",
      "test mean loss=1156.6209106445312\n",
      "epoch 8963\n",
      "test_train\n",
      "train mean loss=0.05248231409738461\n",
      "test_test\n",
      "test mean loss=1159.1544189453125\n",
      "epoch 8964\n",
      "test_train\n",
      "train mean loss=0.04833311277131239\n",
      "test_test\n",
      "test mean loss=1158.8950805664062\n",
      "epoch 8965\n",
      "test_train\n",
      "train mean loss=0.05344966178139051\n",
      "test_test\n",
      "test mean loss=1159.1471557617188\n",
      "epoch 8966\n",
      "test_train\n",
      "train mean loss=0.05246633073935906\n",
      "test_test\n",
      "test mean loss=1159.2758178710938\n",
      "epoch 8967\n",
      "test_train\n",
      "train mean loss=0.05449384947617849\n",
      "test_test\n",
      "test mean loss=1160.2855224609375\n",
      "epoch 8968\n",
      "test_train\n",
      "train mean loss=0.04898813413456082\n",
      "test_test\n",
      "test mean loss=1160.1526489257812\n",
      "epoch 8969\n",
      "test_train\n",
      "train mean loss=0.04945736316343149\n",
      "test_test\n",
      "test mean loss=1160.15966796875\n",
      "epoch 8970\n",
      "test_train\n",
      "train mean loss=0.04729526272664467\n",
      "test_test\n",
      "test mean loss=1159.2228698730469\n",
      "epoch 8971\n",
      "test_train\n",
      "train mean loss=0.049103305054207645\n",
      "test_test\n",
      "test mean loss=1159.0921630859375\n",
      "epoch 8972\n",
      "test_train\n",
      "train mean loss=0.04916604763517777\n",
      "test_test\n",
      "test mean loss=1158.2656860351562\n",
      "epoch 8973\n",
      "test_train\n",
      "train mean loss=0.05112918931990862\n",
      "test_test\n",
      "test mean loss=1158.1687622070312\n",
      "epoch 8974\n",
      "test_train\n",
      "train mean loss=0.051652076498915754\n",
      "test_test\n",
      "test mean loss=1158.4311828613281\n",
      "epoch 8975\n",
      "test_train\n",
      "train mean loss=0.051858111595114074\n",
      "test_test\n",
      "test mean loss=1159.0737915039062\n",
      "epoch 8976\n",
      "test_train\n",
      "train mean loss=0.0532512734644115\n",
      "test_test\n",
      "test mean loss=1158.24365234375\n",
      "epoch 8977\n",
      "test_train\n",
      "train mean loss=0.05451727844774723\n",
      "test_test\n",
      "test mean loss=1159.2374572753906\n",
      "epoch 8978\n",
      "test_train\n",
      "train mean loss=0.049740108040471874\n",
      "test_test\n",
      "test mean loss=1158.7633361816406\n",
      "epoch 8979\n",
      "test_train\n",
      "train mean loss=0.04788613629837831\n",
      "test_test\n",
      "test mean loss=1158.383056640625\n",
      "epoch 8980\n",
      "test_train\n",
      "train mean loss=0.047429904186477266\n",
      "test_test\n",
      "test mean loss=1158.6501770019531\n",
      "epoch 8981\n",
      "test_train\n",
      "train mean loss=0.05094862884531418\n",
      "test_test\n",
      "test mean loss=1158.7262573242188\n",
      "epoch 8982\n",
      "test_train\n",
      "train mean loss=0.05108076520264149\n",
      "test_test\n",
      "test mean loss=1159.3302001953125\n",
      "epoch 8983\n",
      "test_train\n",
      "train mean loss=0.05513617427398761\n",
      "test_test\n",
      "test mean loss=1158.2777709960938\n",
      "epoch 8984\n",
      "test_train\n",
      "train mean loss=0.061530284117907286\n",
      "test_test\n",
      "test mean loss=1158.73583984375\n",
      "epoch 8985\n",
      "test_train\n",
      "train mean loss=0.05828363448381424\n",
      "test_test\n",
      "test mean loss=1158.6798095703125\n",
      "epoch 8986\n",
      "test_train\n",
      "train mean loss=0.054910613844792046\n",
      "test_test\n",
      "test mean loss=1158.7214965820312\n",
      "epoch 8987\n",
      "test_train\n",
      "train mean loss=0.04542921328296264\n",
      "test_test\n",
      "test mean loss=1157.393798828125\n",
      "epoch 8988\n",
      "test_train\n",
      "train mean loss=0.054885956148306526\n",
      "test_test\n",
      "test mean loss=1158.6347045898438\n",
      "epoch 8989\n",
      "test_train\n",
      "train mean loss=0.05581601709127426\n",
      "test_test\n",
      "test mean loss=1159.6541137695312\n",
      "epoch 8990\n",
      "test_train\n",
      "train mean loss=0.057962432193259396\n",
      "test_test\n",
      "test mean loss=1159.4382934570312\n",
      "epoch 8991\n",
      "test_train\n",
      "train mean loss=0.11057391514380772\n",
      "test_test\n",
      "test mean loss=1160.4941101074219\n",
      "epoch 8992\n",
      "test_train\n",
      "train mean loss=0.1439804546535015\n",
      "test_test\n",
      "test mean loss=1153.9769592285156\n",
      "epoch 8993\n",
      "test_train\n",
      "train mean loss=0.05410405543322364\n",
      "test_test\n",
      "test mean loss=1158.1705932617188\n",
      "epoch 8994\n",
      "test_train\n",
      "train mean loss=0.04881872143596411\n",
      "test_test\n",
      "test mean loss=1159.4804992675781\n",
      "epoch 8995\n",
      "test_train\n",
      "train mean loss=0.05370748555287719\n",
      "test_test\n",
      "test mean loss=1160.6022338867188\n",
      "epoch 8996\n",
      "test_train\n",
      "train mean loss=0.05512335834403833\n",
      "test_test\n",
      "test mean loss=1159.698486328125\n",
      "epoch 8997\n",
      "test_train\n",
      "train mean loss=0.05140056274831295\n",
      "test_test\n",
      "test mean loss=1159.4401245117188\n",
      "epoch 8998\n",
      "test_train\n",
      "train mean loss=0.05999002357323965\n",
      "test_test\n",
      "test mean loss=1158.987060546875\n",
      "epoch 8999\n",
      "test_train\n",
      "train mean loss=0.06019591602186362\n",
      "test_test\n",
      "test mean loss=1159.9584045410156\n",
      "epoch 9000\n",
      "test_train\n",
      "train mean loss=0.05758210411295295\n",
      "test_test\n",
      "test mean loss=1159.1787109375\n",
      "epoch 9001\n",
      "test_train\n",
      "train mean loss=0.04673492815345526\n",
      "test_test\n",
      "test mean loss=1158.9445190429688\n",
      "epoch 9002\n",
      "test_train\n",
      "train mean loss=0.05384393750379483\n",
      "test_test\n",
      "test mean loss=1159.7484436035156\n",
      "epoch 9003\n",
      "test_train\n",
      "train mean loss=0.050791931338608265\n",
      "test_test\n",
      "test mean loss=1159.4124145507812\n",
      "epoch 9004\n",
      "test_train\n",
      "train mean loss=0.055472764652222395\n",
      "test_test\n",
      "test mean loss=1159.4753112792969\n",
      "epoch 9005\n",
      "test_train\n",
      "train mean loss=0.12335906426111858\n",
      "test_test\n",
      "test mean loss=1157.8814086914062\n",
      "epoch 9006\n",
      "test_train\n",
      "train mean loss=0.04678340349346399\n",
      "test_test\n",
      "test mean loss=1159.615234375\n",
      "epoch 9007\n",
      "test_train\n",
      "train mean loss=0.04300731513649225\n",
      "test_test\n",
      "test mean loss=1158.9501647949219\n",
      "epoch 9008\n",
      "test_train\n",
      "train mean loss=0.04618195785830418\n",
      "test_test\n",
      "test mean loss=1159.0081787109375\n",
      "epoch 9009\n",
      "test_train\n",
      "train mean loss=0.05542561194549004\n",
      "test_test\n",
      "test mean loss=1159.9022827148438\n",
      "epoch 9010\n",
      "test_train\n",
      "train mean loss=0.10657025376955669\n",
      "test_test\n",
      "test mean loss=1151.5967102050781\n",
      "epoch 9011\n",
      "test_train\n",
      "train mean loss=0.055485126872857414\n",
      "test_test\n",
      "test mean loss=1159.6519775390625\n",
      "epoch 9012\n",
      "test_train\n",
      "train mean loss=0.06202769993493954\n",
      "test_test\n",
      "test mean loss=1160.6968383789062\n",
      "epoch 9013\n",
      "test_train\n",
      "train mean loss=0.0613632258027792\n",
      "test_test\n",
      "test mean loss=1159.8569946289062\n",
      "epoch 9014\n",
      "test_train\n",
      "train mean loss=0.047868091613054276\n",
      "test_test\n",
      "test mean loss=1159.0935668945312\n",
      "epoch 9015\n",
      "test_train\n",
      "train mean loss=0.05547790850202242\n",
      "test_test\n",
      "test mean loss=1160.1324462890625\n",
      "epoch 9016\n",
      "test_train\n",
      "train mean loss=0.05294101685285568\n",
      "test_test\n",
      "test mean loss=1160.7130126953125\n",
      "epoch 9017\n",
      "test_train\n",
      "train mean loss=0.05819270759820938\n",
      "test_test\n",
      "test mean loss=1161.1760559082031\n",
      "epoch 9018\n",
      "test_train\n",
      "train mean loss=0.12007139561076959\n",
      "test_test\n",
      "test mean loss=1163.2516174316406\n",
      "epoch 9019\n",
      "test_train\n",
      "train mean loss=0.06305547958860795\n",
      "test_test\n",
      "test mean loss=1161.1524353027344\n",
      "epoch 9020\n",
      "test_train\n",
      "train mean loss=0.053887082263827324\n",
      "test_test\n",
      "test mean loss=1159.03759765625\n",
      "epoch 9021\n",
      "test_train\n",
      "train mean loss=0.05017982764790455\n",
      "test_test\n",
      "test mean loss=1160.0852355957031\n",
      "epoch 9022\n",
      "test_train\n",
      "train mean loss=0.04980767332017422\n",
      "test_test\n",
      "test mean loss=1159.9435424804688\n",
      "epoch 9023\n",
      "test_train\n",
      "train mean loss=0.05183168717970451\n",
      "test_test\n",
      "test mean loss=1160.9212036132812\n",
      "epoch 9024\n",
      "test_train\n",
      "train mean loss=0.0520594563956062\n",
      "test_test\n",
      "test mean loss=1160.7899475097656\n",
      "epoch 9025\n",
      "test_train\n",
      "train mean loss=0.0679404716938734\n",
      "test_test\n",
      "test mean loss=1161.7095642089844\n",
      "epoch 9026\n",
      "test_train\n",
      "train mean loss=0.057820418228705726\n",
      "test_test\n",
      "test mean loss=1160.1668090820312\n",
      "epoch 9027\n",
      "test_train\n",
      "train mean loss=0.048190068608770766\n",
      "test_test\n",
      "test mean loss=1159.8873901367188\n",
      "epoch 9028\n",
      "test_train\n",
      "train mean loss=0.05829155476142963\n",
      "test_test\n",
      "test mean loss=1159.7058715820312\n",
      "epoch 9029\n",
      "test_train\n",
      "train mean loss=0.05328157156084975\n",
      "test_test\n",
      "test mean loss=1158.8645935058594\n",
      "epoch 9030\n",
      "test_train\n",
      "train mean loss=0.0672392478833596\n",
      "test_test\n",
      "test mean loss=1158.3961181640625\n",
      "epoch 9031\n",
      "test_train\n",
      "train mean loss=0.060590870988865696\n",
      "test_test\n",
      "test mean loss=1158.27880859375\n",
      "epoch 9032\n",
      "test_train\n",
      "train mean loss=0.05713037556658188\n",
      "test_test\n",
      "test mean loss=1159.3638305664062\n",
      "epoch 9033\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.049215079129983984\n",
      "test_test\n",
      "test mean loss=1158.8495178222656\n",
      "epoch 9034\n",
      "test_train\n",
      "train mean loss=0.054979719842473664\n",
      "test_test\n",
      "test mean loss=1159.9714965820312\n",
      "epoch 9035\n",
      "test_train\n",
      "train mean loss=0.05266408994793892\n",
      "test_test\n",
      "test mean loss=1160.3421936035156\n",
      "epoch 9036\n",
      "test_train\n",
      "train mean loss=0.0507113717806836\n",
      "test_test\n",
      "test mean loss=1160.166015625\n",
      "epoch 9037\n",
      "test_train\n",
      "train mean loss=0.0494054788723588\n",
      "test_test\n",
      "test mean loss=1158.9121398925781\n",
      "epoch 9038\n",
      "test_train\n",
      "train mean loss=0.056124195301284395\n",
      "test_test\n",
      "test mean loss=1160.4891662597656\n",
      "epoch 9039\n",
      "test_train\n",
      "train mean loss=0.047365159882853426\n",
      "test_test\n",
      "test mean loss=1158.7122497558594\n",
      "epoch 9040\n",
      "test_train\n",
      "train mean loss=0.05481861128161351\n",
      "test_test\n",
      "test mean loss=1159.2344055175781\n",
      "epoch 9041\n",
      "test_train\n",
      "train mean loss=0.05584849929437041\n",
      "test_test\n",
      "test mean loss=1158.5670776367188\n",
      "epoch 9042\n",
      "test_train\n",
      "train mean loss=0.05557835924749573\n",
      "test_test\n",
      "test mean loss=1159.1085205078125\n",
      "epoch 9043\n",
      "test_train\n",
      "train mean loss=0.05766395448396603\n",
      "test_test\n",
      "test mean loss=1159.171142578125\n",
      "epoch 9044\n",
      "test_train\n",
      "train mean loss=0.05462779228885969\n",
      "test_test\n",
      "test mean loss=1158.8002319335938\n",
      "epoch 9045\n",
      "test_train\n",
      "train mean loss=0.056596153881400824\n",
      "test_test\n",
      "test mean loss=1160.0339965820312\n",
      "epoch 9046\n",
      "test_train\n",
      "train mean loss=0.05553500882039467\n",
      "test_test\n",
      "test mean loss=1159.8712158203125\n",
      "epoch 9047\n",
      "test_train\n",
      "train mean loss=0.05323823650057117\n",
      "test_test\n",
      "test mean loss=1159.2153930664062\n",
      "epoch 9048\n",
      "test_train\n",
      "train mean loss=0.06371297625203927\n",
      "test_test\n",
      "test mean loss=1160.0846557617188\n",
      "epoch 9049\n",
      "test_train\n",
      "train mean loss=0.054765325505286455\n",
      "test_test\n",
      "test mean loss=1158.5880737304688\n",
      "epoch 9050\n",
      "test_train\n",
      "train mean loss=0.05001787546401223\n",
      "test_test\n",
      "test mean loss=1158.4097595214844\n",
      "epoch 9051\n",
      "test_train\n",
      "train mean loss=0.05314166688670715\n",
      "test_test\n",
      "test mean loss=1159.6064453125\n",
      "epoch 9052\n",
      "test_train\n",
      "train mean loss=0.051191235116372504\n",
      "test_test\n",
      "test mean loss=1158.7225341796875\n",
      "epoch 9053\n",
      "test_train\n",
      "train mean loss=0.05161045274386803\n",
      "test_test\n",
      "test mean loss=1158.960693359375\n",
      "epoch 9054\n",
      "test_train\n",
      "train mean loss=0.0554837491363287\n",
      "test_test\n",
      "test mean loss=1159.6141662597656\n",
      "epoch 9055\n",
      "test_train\n",
      "train mean loss=0.05548159250368675\n",
      "test_test\n",
      "test mean loss=1159.9433898925781\n",
      "epoch 9056\n",
      "test_train\n",
      "train mean loss=0.050731540812800326\n",
      "test_test\n",
      "test mean loss=1158.5663757324219\n",
      "epoch 9057\n",
      "test_train\n",
      "train mean loss=0.059793323278427124\n",
      "test_test\n",
      "test mean loss=1161.0582580566406\n",
      "epoch 9058\n",
      "test_train\n",
      "train mean loss=0.05078563016528884\n",
      "test_test\n",
      "test mean loss=1159.3788757324219\n",
      "epoch 9059\n",
      "test_train\n",
      "train mean loss=0.05500716017559171\n",
      "test_test\n",
      "test mean loss=1160.2462158203125\n",
      "epoch 9060\n",
      "test_train\n",
      "train mean loss=0.046774703388412796\n",
      "test_test\n",
      "test mean loss=1158.7948913574219\n",
      "epoch 9061\n",
      "test_train\n",
      "train mean loss=0.05579055783649286\n",
      "test_test\n",
      "test mean loss=1159.1522521972656\n",
      "epoch 9062\n",
      "test_train\n",
      "train mean loss=0.054229079435269036\n",
      "test_test\n",
      "test mean loss=1158.9127197265625\n",
      "epoch 9063\n",
      "test_train\n",
      "train mean loss=0.05072438313315312\n",
      "test_test\n",
      "test mean loss=1158.2726440429688\n",
      "epoch 9064\n",
      "test_train\n",
      "train mean loss=0.04842024249956012\n",
      "test_test\n",
      "test mean loss=1158.4178771972656\n",
      "epoch 9065\n",
      "test_train\n",
      "train mean loss=0.05000431804607312\n",
      "test_test\n",
      "test mean loss=1158.6749877929688\n",
      "epoch 9066\n",
      "test_train\n",
      "train mean loss=0.04500302982827028\n",
      "test_test\n",
      "test mean loss=1158.7734985351562\n",
      "epoch 9067\n",
      "test_train\n",
      "train mean loss=0.048313369043171406\n",
      "test_test\n",
      "test mean loss=1158.3130798339844\n",
      "epoch 9068\n",
      "test_train\n",
      "train mean loss=0.04895483252281944\n",
      "test_test\n",
      "test mean loss=1158.8368530273438\n",
      "epoch 9069\n",
      "test_train\n",
      "train mean loss=0.04969931207597256\n",
      "test_test\n",
      "test mean loss=1159.6795959472656\n",
      "epoch 9070\n",
      "test_train\n",
      "train mean loss=0.051012461384137474\n",
      "test_test\n",
      "test mean loss=1158.1049194335938\n",
      "epoch 9071\n",
      "test_train\n",
      "train mean loss=0.04634600318968296\n",
      "test_test\n",
      "test mean loss=1158.7565612792969\n",
      "epoch 9072\n",
      "test_train\n",
      "train mean loss=0.05622312348956863\n",
      "test_test\n",
      "test mean loss=1159.3900146484375\n",
      "epoch 9073\n",
      "test_train\n",
      "train mean loss=0.05710930749773979\n",
      "test_test\n",
      "test mean loss=1159.8421630859375\n",
      "epoch 9074\n",
      "test_train\n",
      "train mean loss=0.0527109003936251\n",
      "test_test\n",
      "test mean loss=1158.936279296875\n",
      "epoch 9075\n",
      "test_train\n",
      "train mean loss=0.04996353015303612\n",
      "test_test\n",
      "test mean loss=1158.1104125976562\n",
      "epoch 9076\n",
      "test_train\n",
      "train mean loss=0.05674961597348253\n",
      "test_test\n",
      "test mean loss=1158.4217529296875\n",
      "epoch 9077\n",
      "test_train\n",
      "train mean loss=0.050028258779396616\n",
      "test_test\n",
      "test mean loss=1157.828857421875\n",
      "epoch 9078\n",
      "test_train\n",
      "train mean loss=0.04980476169536511\n",
      "test_test\n",
      "test mean loss=1158.5050964355469\n",
      "epoch 9079\n",
      "test_train\n",
      "train mean loss=0.051516158040612936\n",
      "test_test\n",
      "test mean loss=1158.1677551269531\n",
      "epoch 9080\n",
      "test_train\n",
      "train mean loss=0.049868110256890454\n",
      "test_test\n",
      "test mean loss=1157.9411315917969\n",
      "epoch 9081\n",
      "test_train\n",
      "train mean loss=0.05468586537366112\n",
      "test_test\n",
      "test mean loss=1159.6560363769531\n",
      "epoch 9082\n",
      "test_train\n",
      "train mean loss=0.057216168381273746\n",
      "test_test\n",
      "test mean loss=1159.8534545898438\n",
      "epoch 9083\n",
      "test_train\n",
      "train mean loss=0.055938865368564926\n",
      "test_test\n",
      "test mean loss=1159.0726623535156\n",
      "epoch 9084\n",
      "test_train\n",
      "train mean loss=0.049315512645989656\n",
      "test_test\n",
      "test mean loss=1158.4015808105469\n",
      "epoch 9085\n",
      "test_train\n",
      "train mean loss=0.05241192318499088\n",
      "test_test\n",
      "test mean loss=1158.6654052734375\n",
      "epoch 9086\n",
      "test_train\n",
      "train mean loss=0.049809529135624565\n",
      "test_test\n",
      "test mean loss=1158.8160400390625\n",
      "epoch 9087\n",
      "test_train\n",
      "train mean loss=0.05127182292441527\n",
      "test_test\n",
      "test mean loss=1158.0687866210938\n",
      "epoch 9088\n",
      "test_train\n",
      "train mean loss=0.053582604974508286\n",
      "test_test\n",
      "test mean loss=1159.3260498046875\n",
      "epoch 9089\n",
      "test_train\n",
      "train mean loss=0.051842900924384594\n",
      "test_test\n",
      "test mean loss=1158.8547973632812\n",
      "epoch 9090\n",
      "test_train\n",
      "train mean loss=0.04808771268775066\n",
      "test_test\n",
      "test mean loss=1159.0657348632812\n",
      "epoch 9091\n",
      "test_train\n",
      "train mean loss=0.04752190178260207\n",
      "test_test\n",
      "test mean loss=1158.1417236328125\n",
      "epoch 9092\n",
      "test_train\n",
      "train mean loss=0.04997848765924573\n",
      "test_test\n",
      "test mean loss=1158.653564453125\n",
      "epoch 9093\n",
      "test_train\n",
      "train mean loss=0.058162455447018147\n",
      "test_test\n",
      "test mean loss=1158.8405456542969\n",
      "epoch 9094\n",
      "test_train\n",
      "train mean loss=0.056314000549415745\n",
      "test_test\n",
      "test mean loss=1158.9318542480469\n",
      "epoch 9095\n",
      "test_train\n",
      "train mean loss=0.05728262150660157\n",
      "test_test\n",
      "test mean loss=1158.9419250488281\n",
      "epoch 9096\n",
      "test_train\n",
      "train mean loss=0.05079600991060337\n",
      "test_test\n",
      "test mean loss=1157.6431274414062\n",
      "epoch 9097\n",
      "test_train\n",
      "train mean loss=0.04886166208113233\n",
      "test_test\n",
      "test mean loss=1156.175048828125\n",
      "epoch 9098\n",
      "test_train\n",
      "train mean loss=0.049548047905166946\n",
      "test_test\n",
      "test mean loss=1157.947998046875\n",
      "epoch 9099\n",
      "test_train\n",
      "train mean loss=0.05183510451267163\n",
      "test_test\n",
      "test mean loss=1157.5922241210938\n",
      "epoch 9100\n",
      "test_train\n",
      "train mean loss=0.05200097539151708\n",
      "test_test\n",
      "test mean loss=1158.7131958007812\n",
      "epoch 9101\n",
      "test_train\n",
      "train mean loss=0.13065072211126486\n",
      "test_test\n",
      "test mean loss=1160.2374572753906\n",
      "epoch 9102\n",
      "test_train\n",
      "train mean loss=0.05349453973273436\n",
      "test_test\n",
      "test mean loss=1160.1621704101562\n",
      "epoch 9103\n",
      "test_train\n",
      "train mean loss=0.05527993384748697\n",
      "test_test\n",
      "test mean loss=1158.9838256835938\n",
      "epoch 9104\n",
      "test_train\n",
      "train mean loss=0.05847468009839455\n",
      "test_test\n",
      "test mean loss=1159.8887939453125\n",
      "epoch 9105\n",
      "test_train\n",
      "train mean loss=0.05002123583108187\n",
      "test_test\n",
      "test mean loss=1159.1290283203125\n",
      "epoch 9106\n",
      "test_train\n",
      "train mean loss=0.04631940539305409\n",
      "test_test\n",
      "test mean loss=1158.204345703125\n",
      "epoch 9107\n",
      "test_train\n",
      "train mean loss=0.05368130840361118\n",
      "test_test\n",
      "test mean loss=1159.0296630859375\n",
      "epoch 9108\n",
      "test_train\n",
      "train mean loss=0.058808062225580215\n",
      "test_test\n",
      "test mean loss=1159.7186279296875\n",
      "epoch 9109\n",
      "test_train\n",
      "train mean loss=0.04896421233812968\n",
      "test_test\n",
      "test mean loss=1159.4559326171875\n",
      "epoch 9110\n",
      "test_train\n",
      "train mean loss=0.05216059414669871\n",
      "test_test\n",
      "test mean loss=1159.7210693359375\n",
      "epoch 9111\n",
      "test_train\n",
      "train mean loss=0.06123817774156729\n",
      "test_test\n",
      "test mean loss=1160.2249145507812\n",
      "epoch 9112\n",
      "test_train\n",
      "train mean loss=0.05841168621554971\n",
      "test_test\n",
      "test mean loss=1159.6243591308594\n",
      "epoch 9113\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.10530856500069301\n",
      "test_test\n",
      "test mean loss=1156.1197814941406\n",
      "epoch 9114\n",
      "test_train\n",
      "train mean loss=0.07028494682163\n",
      "test_test\n",
      "test mean loss=1160.806884765625\n",
      "epoch 9115\n",
      "test_train\n",
      "train mean loss=0.0544532003502051\n",
      "test_test\n",
      "test mean loss=1160.4161987304688\n",
      "epoch 9116\n",
      "test_train\n",
      "train mean loss=0.05337138784428438\n",
      "test_test\n",
      "test mean loss=1159.8934936523438\n",
      "epoch 9117\n",
      "test_train\n",
      "train mean loss=0.049891147296875715\n",
      "test_test\n",
      "test mean loss=1160.0381469726562\n",
      "epoch 9118\n",
      "test_train\n",
      "train mean loss=0.0554770176919798\n",
      "test_test\n",
      "test mean loss=1159.8302001953125\n",
      "epoch 9119\n",
      "test_train\n",
      "train mean loss=0.04911990246425072\n",
      "test_test\n",
      "test mean loss=1158.9191284179688\n",
      "epoch 9120\n",
      "test_train\n",
      "train mean loss=0.05787881681074699\n",
      "test_test\n",
      "test mean loss=1159.6673889160156\n",
      "epoch 9121\n",
      "test_train\n",
      "train mean loss=0.0718948938883841\n",
      "test_test\n",
      "test mean loss=1157.8609008789062\n",
      "epoch 9122\n",
      "test_train\n",
      "train mean loss=0.04506730381399393\n",
      "test_test\n",
      "test mean loss=1158.1104431152344\n",
      "epoch 9123\n",
      "test_train\n",
      "train mean loss=0.05710413741568724\n",
      "test_test\n",
      "test mean loss=1160.083251953125\n",
      "epoch 9124\n",
      "test_train\n",
      "train mean loss=0.05636033664147059\n",
      "test_test\n",
      "test mean loss=1161.1571044921875\n",
      "epoch 9125\n",
      "test_train\n",
      "train mean loss=0.052521055874725185\n",
      "test_test\n",
      "test mean loss=1159.7310791015625\n",
      "epoch 9126\n",
      "test_train\n",
      "train mean loss=0.05466614073763291\n",
      "test_test\n",
      "test mean loss=1160.1362915039062\n",
      "epoch 9127\n",
      "test_train\n",
      "train mean loss=0.07669251567373674\n",
      "test_test\n",
      "test mean loss=1160.6624755859375\n",
      "epoch 9128\n",
      "test_train\n",
      "train mean loss=0.052522433611253895\n",
      "test_test\n",
      "test mean loss=1160.4965209960938\n",
      "epoch 9129\n",
      "test_train\n",
      "train mean loss=0.0561972128537794\n",
      "test_test\n",
      "test mean loss=1159.11474609375\n",
      "epoch 9130\n",
      "test_train\n",
      "train mean loss=0.04852014112596711\n",
      "test_test\n",
      "test mean loss=1158.815185546875\n",
      "epoch 9131\n",
      "test_train\n",
      "train mean loss=0.05890322104096413\n",
      "test_test\n",
      "test mean loss=1159.4891967773438\n",
      "epoch 9132\n",
      "test_train\n",
      "train mean loss=0.055132199389239155\n",
      "test_test\n",
      "test mean loss=1161.3854064941406\n",
      "epoch 9133\n",
      "test_train\n",
      "train mean loss=0.049930410304417215\n",
      "test_test\n",
      "test mean loss=1159.993896484375\n",
      "epoch 9134\n",
      "test_train\n",
      "train mean loss=0.05299114637697736\n",
      "test_test\n",
      "test mean loss=1160.188720703125\n",
      "epoch 9135\n",
      "test_train\n",
      "train mean loss=0.04985840277125438\n",
      "test_test\n",
      "test mean loss=1160.4617614746094\n",
      "epoch 9136\n",
      "test_train\n",
      "train mean loss=0.05565109352270762\n",
      "test_test\n",
      "test mean loss=1160.3550415039062\n",
      "epoch 9137\n",
      "test_train\n",
      "train mean loss=0.05438763772447904\n",
      "test_test\n",
      "test mean loss=1160.9843139648438\n",
      "epoch 9138\n",
      "test_train\n",
      "train mean loss=0.05511890212073922\n",
      "test_test\n",
      "test mean loss=1160.456787109375\n",
      "epoch 9139\n",
      "test_train\n",
      "train mean loss=0.05531713956346115\n",
      "test_test\n",
      "test mean loss=1159.78515625\n",
      "epoch 9140\n",
      "test_train\n",
      "train mean loss=0.05869433159629504\n",
      "test_test\n",
      "test mean loss=1159.5048828125\n",
      "epoch 9141\n",
      "test_train\n",
      "train mean loss=0.058693639313181244\n",
      "test_test\n",
      "test mean loss=1160.0019836425781\n",
      "epoch 9142\n",
      "test_train\n",
      "train mean loss=0.05572522742052873\n",
      "test_test\n",
      "test mean loss=1161.0350341796875\n",
      "epoch 9143\n",
      "test_train\n",
      "train mean loss=0.05462318332865834\n",
      "test_test\n",
      "test mean loss=1160.3811645507812\n",
      "epoch 9144\n",
      "test_train\n",
      "train mean loss=0.04820637792969743\n",
      "test_test\n",
      "test mean loss=1159.3108215332031\n",
      "epoch 9145\n",
      "test_train\n",
      "train mean loss=0.053482563545306526\n",
      "test_test\n",
      "test mean loss=1159.4720153808594\n",
      "epoch 9146\n",
      "test_train\n",
      "train mean loss=0.050724190970261894\n",
      "test_test\n",
      "test mean loss=1159.6976928710938\n",
      "epoch 9147\n",
      "test_train\n",
      "train mean loss=0.04978542154033979\n",
      "test_test\n",
      "test mean loss=1159.3316345214844\n",
      "epoch 9148\n",
      "test_train\n",
      "train mean loss=0.05403120412180821\n",
      "test_test\n",
      "test mean loss=1159.2671813964844\n",
      "epoch 9149\n",
      "test_train\n",
      "train mean loss=0.06344739999622107\n",
      "test_test\n",
      "test mean loss=1160.3272705078125\n",
      "epoch 9150\n",
      "test_train\n",
      "train mean loss=0.05958396724114815\n",
      "test_test\n",
      "test mean loss=1159.3507690429688\n",
      "epoch 9151\n",
      "test_train\n",
      "train mean loss=0.054946248419582844\n",
      "test_test\n",
      "test mean loss=1159.5133056640625\n",
      "epoch 9152\n",
      "test_train\n",
      "train mean loss=0.04942253356178602\n",
      "test_test\n",
      "test mean loss=1159.3239135742188\n",
      "epoch 9153\n",
      "test_train\n",
      "train mean loss=0.05435954096416632\n",
      "test_test\n",
      "test mean loss=1160.6508483886719\n",
      "epoch 9154\n",
      "test_train\n",
      "train mean loss=0.059749452552447714\n",
      "test_test\n",
      "test mean loss=1159.7271423339844\n",
      "epoch 9155\n",
      "test_train\n",
      "train mean loss=0.048596234836926065\n",
      "test_test\n",
      "test mean loss=1159.4502868652344\n",
      "epoch 9156\n",
      "test_train\n",
      "train mean loss=0.049246614488462605\n",
      "test_test\n",
      "test mean loss=1159.0061645507812\n",
      "epoch 9157\n",
      "test_train\n",
      "train mean loss=0.05348785578583678\n",
      "test_test\n",
      "test mean loss=1158.8475952148438\n",
      "epoch 9158\n",
      "test_train\n",
      "train mean loss=0.051901123486459255\n",
      "test_test\n",
      "test mean loss=1158.8407592773438\n",
      "epoch 9159\n",
      "test_train\n",
      "train mean loss=0.13031903840601444\n",
      "test_test\n",
      "test mean loss=1160.2323608398438\n",
      "epoch 9160\n",
      "test_train\n",
      "train mean loss=0.05203024856746197\n",
      "test_test\n",
      "test mean loss=1160.0316162109375\n",
      "epoch 9161\n",
      "test_train\n",
      "train mean loss=0.052137662967046104\n",
      "test_test\n",
      "test mean loss=1158.454833984375\n",
      "epoch 9162\n",
      "test_train\n",
      "train mean loss=0.048595354271431766\n",
      "test_test\n",
      "test mean loss=1158.5608520507812\n",
      "epoch 9163\n",
      "test_train\n",
      "train mean loss=0.051050314058860145\n",
      "test_test\n",
      "test mean loss=1159.5540771484375\n",
      "epoch 9164\n",
      "test_train\n",
      "train mean loss=0.05583349987864494\n",
      "test_test\n",
      "test mean loss=1159.1549072265625\n",
      "epoch 9165\n",
      "test_train\n",
      "train mean loss=0.054444723607351385\n",
      "test_test\n",
      "test mean loss=1159.0752563476562\n",
      "epoch 9166\n",
      "test_train\n",
      "train mean loss=0.060178645265599094\n",
      "test_test\n",
      "test mean loss=1158.8494262695312\n",
      "epoch 9167\n",
      "test_train\n",
      "train mean loss=0.0524214725010097\n",
      "test_test\n",
      "test mean loss=1158.3704833984375\n",
      "epoch 9168\n",
      "test_train\n",
      "train mean loss=0.04864290449768305\n",
      "test_test\n",
      "test mean loss=1158.6599731445312\n",
      "epoch 9169\n",
      "test_train\n",
      "train mean loss=0.049604189271728195\n",
      "test_test\n",
      "test mean loss=1158.6311645507812\n",
      "epoch 9170\n",
      "test_train\n",
      "train mean loss=0.05110450057933728\n",
      "test_test\n",
      "test mean loss=1157.5112915039062\n",
      "epoch 9171\n",
      "test_train\n",
      "train mean loss=0.04758582667758068\n",
      "test_test\n",
      "test mean loss=1158.0345764160156\n",
      "epoch 9172\n",
      "test_train\n",
      "train mean loss=0.05530795517067114\n",
      "test_test\n",
      "test mean loss=1159.1694946289062\n",
      "epoch 9173\n",
      "test_train\n",
      "train mean loss=0.05364156157399217\n",
      "test_test\n",
      "test mean loss=1158.6757202148438\n",
      "epoch 9174\n",
      "test_train\n",
      "train mean loss=0.04793721716850996\n",
      "test_test\n",
      "test mean loss=1158.4351501464844\n",
      "epoch 9175\n",
      "test_train\n",
      "train mean loss=0.050414325669407845\n",
      "test_test\n",
      "test mean loss=1158.0335693359375\n",
      "epoch 9176\n",
      "test_train\n",
      "train mean loss=0.048688325410087906\n",
      "test_test\n",
      "test mean loss=1159.32177734375\n",
      "epoch 9177\n",
      "test_train\n",
      "train mean loss=0.04806451949601372\n",
      "test_test\n",
      "test mean loss=1159.4486999511719\n",
      "epoch 9178\n",
      "test_train\n",
      "train mean loss=0.049963937141001225\n",
      "test_test\n",
      "test mean loss=1159.1455078125\n",
      "epoch 9179\n",
      "test_train\n",
      "train mean loss=0.05595203364888827\n",
      "test_test\n",
      "test mean loss=1158.9727783203125\n",
      "epoch 9180\n",
      "test_train\n",
      "train mean loss=0.04969471041113138\n",
      "test_test\n",
      "test mean loss=1158.5949096679688\n",
      "epoch 9181\n",
      "test_train\n",
      "train mean loss=0.04693305321658651\n",
      "test_test\n",
      "test mean loss=1158.0504760742188\n",
      "epoch 9182\n",
      "test_train\n",
      "train mean loss=0.05184801404053966\n",
      "test_test\n",
      "test mean loss=1158.6166687011719\n",
      "epoch 9183\n",
      "test_train\n",
      "train mean loss=0.05917227423439423\n",
      "test_test\n",
      "test mean loss=1156.207275390625\n",
      "epoch 9184\n",
      "test_train\n",
      "train mean loss=0.056179213958481945\n",
      "test_test\n",
      "test mean loss=1158.4141845703125\n",
      "epoch 9185\n",
      "test_train\n",
      "train mean loss=0.05755871472259363\n",
      "test_test\n",
      "test mean loss=1158.3311767578125\n",
      "epoch 9186\n",
      "test_train\n",
      "train mean loss=0.06454478421558936\n",
      "test_test\n",
      "test mean loss=1159.0586547851562\n",
      "epoch 9187\n",
      "test_train\n",
      "train mean loss=0.051328759640455246\n",
      "test_test\n",
      "test mean loss=1157.9590454101562\n",
      "epoch 9188\n",
      "test_train\n",
      "train mean loss=0.04527403196940819\n",
      "test_test\n",
      "test mean loss=1158.1932373046875\n",
      "epoch 9189\n",
      "test_train\n",
      "train mean loss=0.049909111888458334\n",
      "test_test\n",
      "test mean loss=1158.1064453125\n",
      "epoch 9190\n",
      "test_train\n",
      "train mean loss=0.051002473259965576\n",
      "test_test\n",
      "test mean loss=1157.814453125\n",
      "epoch 9191\n",
      "test_train\n",
      "train mean loss=0.04904107035448154\n",
      "test_test\n",
      "test mean loss=1158.6906127929688\n",
      "epoch 9192\n",
      "test_train\n",
      "train mean loss=0.047473924700170755\n",
      "test_test\n",
      "test mean loss=1158.8604431152344\n",
      "epoch 9193\n",
      "test_train\n",
      "train mean loss=0.09474481766422589\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_test\n",
      "test mean loss=1151.7301025390625\n",
      "epoch 9194\n",
      "test_train\n",
      "train mean loss=0.048899054527282715\n",
      "test_test\n",
      "test mean loss=1157.5726318359375\n",
      "epoch 9195\n",
      "test_train\n",
      "train mean loss=0.04619960921506087\n",
      "test_test\n",
      "test mean loss=1158.69580078125\n",
      "epoch 9196\n",
      "test_train\n",
      "train mean loss=0.05837207163373629\n",
      "test_test\n",
      "test mean loss=1159.0589599609375\n",
      "epoch 9197\n",
      "test_train\n",
      "train mean loss=0.05063538330917557\n",
      "test_test\n",
      "test mean loss=1158.9859924316406\n",
      "epoch 9198\n",
      "test_train\n",
      "train mean loss=0.060220795994003616\n",
      "test_test\n",
      "test mean loss=1159.9580078125\n",
      "epoch 9199\n",
      "test_train\n",
      "train mean loss=0.048867530189454556\n",
      "test_test\n",
      "test mean loss=1159.1144409179688\n",
      "epoch 9200\n",
      "test_train\n",
      "train mean loss=0.05545374006032944\n",
      "test_test\n",
      "test mean loss=1159.4047241210938\n",
      "epoch 9201\n",
      "test_train\n",
      "train mean loss=0.05325217933083574\n",
      "test_test\n",
      "test mean loss=1159.5728149414062\n",
      "epoch 9202\n",
      "test_train\n",
      "train mean loss=0.054637437841544546\n",
      "test_test\n",
      "test mean loss=1158.8114318847656\n",
      "epoch 9203\n",
      "test_train\n",
      "train mean loss=0.0491081642297407\n",
      "test_test\n",
      "test mean loss=1158.2303466796875\n",
      "epoch 9204\n",
      "test_train\n",
      "train mean loss=0.05060578168680271\n",
      "test_test\n",
      "test mean loss=1159.1448974609375\n",
      "epoch 9205\n",
      "test_train\n",
      "train mean loss=0.04776284207279483\n",
      "test_test\n",
      "test mean loss=1158.999267578125\n",
      "epoch 9206\n",
      "test_train\n",
      "train mean loss=0.04878644738346338\n",
      "test_test\n",
      "test mean loss=1158.6375122070312\n",
      "epoch 9207\n",
      "test_train\n",
      "train mean loss=0.050667886001368366\n",
      "test_test\n",
      "test mean loss=1159.1433715820312\n",
      "epoch 9208\n",
      "test_train\n",
      "train mean loss=0.05273589647064606\n",
      "test_test\n",
      "test mean loss=1159.4019165039062\n",
      "epoch 9209\n",
      "test_train\n",
      "train mean loss=0.05205350462347269\n",
      "test_test\n",
      "test mean loss=1159.1221618652344\n",
      "epoch 9210\n",
      "test_train\n",
      "train mean loss=0.05395185388624668\n",
      "test_test\n",
      "test mean loss=1158.6975708007812\n",
      "epoch 9211\n",
      "test_train\n",
      "train mean loss=0.0505170871814092\n",
      "test_test\n",
      "test mean loss=1158.2830505371094\n",
      "epoch 9212\n",
      "test_train\n",
      "train mean loss=0.04902839784820875\n",
      "test_test\n",
      "test mean loss=1159.0731811523438\n",
      "epoch 9213\n",
      "test_train\n",
      "train mean loss=0.04821542029579481\n",
      "test_test\n",
      "test mean loss=1158.6304321289062\n",
      "epoch 9214\n",
      "test_train\n",
      "train mean loss=0.04832308708379666\n",
      "test_test\n",
      "test mean loss=1159.00634765625\n",
      "epoch 9215\n",
      "test_train\n",
      "train mean loss=0.052245241279403366\n",
      "test_test\n",
      "test mean loss=1158.3478393554688\n",
      "epoch 9216\n",
      "test_train\n",
      "train mean loss=0.04760034196078777\n",
      "test_test\n",
      "test mean loss=1157.4503173828125\n",
      "epoch 9217\n",
      "test_train\n",
      "train mean loss=0.04730546195060015\n",
      "test_test\n",
      "test mean loss=1157.1531982421875\n",
      "epoch 9218\n",
      "test_train\n",
      "train mean loss=0.053214323396484055\n",
      "test_test\n",
      "test mean loss=1158.86083984375\n",
      "epoch 9219\n",
      "test_train\n",
      "train mean loss=0.04898793840159973\n",
      "test_test\n",
      "test mean loss=1158.6146850585938\n",
      "epoch 9220\n",
      "test_train\n",
      "train mean loss=0.05149212712422013\n",
      "test_test\n",
      "test mean loss=1159.2347412109375\n",
      "epoch 9221\n",
      "test_train\n",
      "train mean loss=0.049896824173629284\n",
      "test_test\n",
      "test mean loss=1158.9725341796875\n",
      "epoch 9222\n",
      "test_train\n",
      "train mean loss=0.05478666753818592\n",
      "test_test\n",
      "test mean loss=1158.6638488769531\n",
      "epoch 9223\n",
      "test_train\n",
      "train mean loss=0.05416365650792917\n",
      "test_test\n",
      "test mean loss=1159.0411682128906\n",
      "epoch 9224\n",
      "test_train\n",
      "train mean loss=0.07540606738378604\n",
      "test_test\n",
      "test mean loss=1156.5206298828125\n",
      "epoch 9225\n",
      "test_train\n",
      "train mean loss=0.057501183822751045\n",
      "test_test\n",
      "test mean loss=1159.3992919921875\n",
      "epoch 9226\n",
      "test_train\n",
      "train mean loss=0.05306166193137566\n",
      "test_test\n",
      "test mean loss=1158.4786376953125\n",
      "epoch 9227\n",
      "test_train\n",
      "train mean loss=0.048421744567652546\n",
      "test_test\n",
      "test mean loss=1158.5291137695312\n",
      "epoch 9228\n",
      "test_train\n",
      "train mean loss=0.05330587504431605\n",
      "test_test\n",
      "test mean loss=1160.0577392578125\n",
      "epoch 9229\n",
      "test_train\n",
      "train mean loss=0.05256744318952163\n",
      "test_test\n",
      "test mean loss=1160.3236083984375\n",
      "epoch 9230\n",
      "test_train\n",
      "train mean loss=0.056243096167842545\n",
      "test_test\n",
      "test mean loss=1159.8797912597656\n",
      "epoch 9231\n",
      "test_train\n",
      "train mean loss=0.052268451234946646\n",
      "test_test\n",
      "test mean loss=1159.7791137695312\n",
      "epoch 9232\n",
      "test_train\n",
      "train mean loss=0.04896346153691411\n",
      "test_test\n",
      "test mean loss=1158.5124816894531\n",
      "epoch 9233\n",
      "test_train\n",
      "train mean loss=0.0508283240099748\n",
      "test_test\n",
      "test mean loss=1159.064208984375\n",
      "epoch 9234\n",
      "test_train\n",
      "train mean loss=0.050641353552540146\n",
      "test_test\n",
      "test mean loss=1158.662841796875\n",
      "epoch 9235\n",
      "test_train\n",
      "train mean loss=0.05793393185983101\n",
      "test_test\n",
      "test mean loss=1159.70361328125\n",
      "epoch 9236\n",
      "test_train\n",
      "train mean loss=0.06294050579890609\n",
      "test_test\n",
      "test mean loss=1161.56982421875\n",
      "epoch 9237\n",
      "test_train\n",
      "train mean loss=0.054996165446937084\n",
      "test_test\n",
      "test mean loss=1159.3595275878906\n",
      "epoch 9238\n",
      "test_train\n",
      "train mean loss=0.051456717774271965\n",
      "test_test\n",
      "test mean loss=1160.23876953125\n",
      "epoch 9239\n",
      "test_train\n",
      "train mean loss=0.05897918747117122\n",
      "test_test\n",
      "test mean loss=1161.1002807617188\n",
      "epoch 9240\n",
      "test_train\n",
      "train mean loss=0.04697301145642996\n",
      "test_test\n",
      "test mean loss=1159.5631713867188\n",
      "epoch 9241\n",
      "test_train\n",
      "train mean loss=0.05212115899970134\n",
      "test_test\n",
      "test mean loss=1159.4490966796875\n",
      "epoch 9242\n",
      "test_train\n",
      "train mean loss=0.05577088085313638\n",
      "test_test\n",
      "test mean loss=1158.5588989257812\n",
      "epoch 9243\n",
      "test_train\n",
      "train mean loss=0.05810167143742243\n",
      "test_test\n",
      "test mean loss=1159.2443237304688\n",
      "epoch 9244\n",
      "test_train\n",
      "train mean loss=0.049886363403250776\n",
      "test_test\n",
      "test mean loss=1158.869140625\n",
      "epoch 9245\n",
      "test_train\n",
      "train mean loss=0.04998940462246537\n",
      "test_test\n",
      "test mean loss=1159.2025451660156\n",
      "epoch 9246\n",
      "test_train\n",
      "train mean loss=0.04279817749435703\n",
      "test_test\n",
      "test mean loss=1157.7875061035156\n",
      "epoch 9247\n",
      "test_train\n",
      "train mean loss=0.048524511978030205\n",
      "test_test\n",
      "test mean loss=1158.5447998046875\n",
      "epoch 9248\n",
      "test_train\n",
      "train mean loss=0.04907237598672509\n",
      "test_test\n",
      "test mean loss=1158.3720703125\n",
      "epoch 9249\n",
      "test_train\n",
      "train mean loss=0.050610260029012956\n",
      "test_test\n",
      "test mean loss=1159.3497314453125\n",
      "epoch 9250\n",
      "test_train\n",
      "train mean loss=0.04566821735352278\n",
      "test_test\n",
      "test mean loss=1159.1102294921875\n",
      "epoch 9251\n",
      "test_train\n",
      "train mean loss=0.04868807441865405\n",
      "test_test\n",
      "test mean loss=1160.1651611328125\n",
      "epoch 9252\n",
      "test_train\n",
      "train mean loss=0.04937065578997135\n",
      "test_test\n",
      "test mean loss=1160.0096435546875\n",
      "epoch 9253\n",
      "test_train\n",
      "train mean loss=0.053931065990279116\n",
      "test_test\n",
      "test mean loss=1160.4452819824219\n",
      "epoch 9254\n",
      "test_train\n",
      "train mean loss=0.0492815850302577\n",
      "test_test\n",
      "test mean loss=1159.35205078125\n",
      "epoch 9255\n",
      "test_train\n",
      "train mean loss=0.04731628252193332\n",
      "test_test\n",
      "test mean loss=1158.8587036132812\n",
      "epoch 9256\n",
      "test_train\n",
      "train mean loss=0.05471035713950793\n",
      "test_test\n",
      "test mean loss=1158.751708984375\n",
      "epoch 9257\n",
      "test_train\n",
      "train mean loss=0.053043898195028305\n",
      "test_test\n",
      "test mean loss=1159.5546264648438\n",
      "epoch 9258\n",
      "test_train\n",
      "train mean loss=0.0593599375958244\n",
      "test_test\n",
      "test mean loss=1160.3103942871094\n",
      "epoch 9259\n",
      "test_train\n",
      "train mean loss=0.050217948077867426\n",
      "test_test\n",
      "test mean loss=1158.8704833984375\n",
      "epoch 9260\n",
      "test_train\n",
      "train mean loss=0.0506239770911634\n",
      "test_test\n",
      "test mean loss=1158.0966186523438\n",
      "epoch 9261\n",
      "test_train\n",
      "train mean loss=0.05026114033535123\n",
      "test_test\n",
      "test mean loss=1157.6343994140625\n",
      "epoch 9262\n",
      "test_train\n",
      "train mean loss=0.04976680222898722\n",
      "test_test\n",
      "test mean loss=1159.7250671386719\n",
      "epoch 9263\n",
      "test_train\n",
      "train mean loss=0.045487755443900824\n",
      "test_test\n",
      "test mean loss=1158.8825988769531\n",
      "epoch 9264\n",
      "test_train\n",
      "train mean loss=0.045177669574817024\n",
      "test_test\n",
      "test mean loss=1159.1299438476562\n",
      "epoch 9265\n",
      "test_train\n",
      "train mean loss=0.04602451374133428\n",
      "test_test\n",
      "test mean loss=1158.455078125\n",
      "epoch 9266\n",
      "test_train\n",
      "train mean loss=0.04600214694316188\n",
      "test_test\n",
      "test mean loss=1157.79541015625\n",
      "epoch 9267\n",
      "test_train\n",
      "train mean loss=0.04710052736724416\n",
      "test_test\n",
      "test mean loss=1158.0862426757812\n",
      "epoch 9268\n",
      "test_train\n",
      "train mean loss=0.04916285195698341\n",
      "test_test\n",
      "test mean loss=1158.55615234375\n",
      "epoch 9269\n",
      "test_train\n",
      "train mean loss=0.05377007105077306\n",
      "test_test\n",
      "test mean loss=1158.5726928710938\n",
      "epoch 9270\n",
      "test_train\n",
      "train mean loss=0.04825476665670673\n",
      "test_test\n",
      "test mean loss=1157.991455078125\n",
      "epoch 9271\n",
      "test_train\n",
      "train mean loss=0.050876167602837086\n",
      "test_test\n",
      "test mean loss=1157.9860229492188\n",
      "epoch 9272\n",
      "test_train\n",
      "train mean loss=0.04816536294917265\n",
      "test_test\n",
      "test mean loss=1158.9619750976562\n",
      "epoch 9273\n",
      "test_train\n",
      "train mean loss=0.04615994884322087\n",
      "test_test\n",
      "test mean loss=1158.9697875976562\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9274\n",
      "test_train\n",
      "train mean loss=0.05290081196775039\n",
      "test_test\n",
      "test mean loss=1159.8447570800781\n",
      "epoch 9275\n",
      "test_train\n",
      "train mean loss=0.04709323061009248\n",
      "test_test\n",
      "test mean loss=1159.4862976074219\n",
      "epoch 9276\n",
      "test_train\n",
      "train mean loss=0.045093330244223274\n",
      "test_test\n",
      "test mean loss=1159.0937805175781\n",
      "epoch 9277\n",
      "test_train\n",
      "train mean loss=0.05074235238134861\n",
      "test_test\n",
      "test mean loss=1159.2386474609375\n",
      "epoch 9278\n",
      "test_train\n",
      "train mean loss=0.0560564836487174\n",
      "test_test\n",
      "test mean loss=1158.8794555664062\n",
      "epoch 9279\n",
      "test_train\n",
      "train mean loss=0.05788454972207546\n",
      "test_test\n",
      "test mean loss=1157.6368408203125\n",
      "epoch 9280\n",
      "test_train\n",
      "train mean loss=0.06027941654125849\n",
      "test_test\n",
      "test mean loss=1159.3394775390625\n",
      "epoch 9281\n",
      "test_train\n",
      "train mean loss=0.05099837357799212\n",
      "test_test\n",
      "test mean loss=1159.1435546875\n",
      "epoch 9282\n",
      "test_train\n",
      "train mean loss=0.05287739634513855\n",
      "test_test\n",
      "test mean loss=1157.9389343261719\n",
      "epoch 9283\n",
      "test_train\n",
      "train mean loss=0.04518595337867737\n",
      "test_test\n",
      "test mean loss=1157.7870483398438\n",
      "epoch 9284\n",
      "test_train\n",
      "train mean loss=0.04816516566400727\n",
      "test_test\n",
      "test mean loss=1159.4389953613281\n",
      "epoch 9285\n",
      "test_train\n",
      "train mean loss=0.06165271904319525\n",
      "test_test\n",
      "test mean loss=1158.9149169921875\n",
      "epoch 9286\n",
      "test_train\n",
      "train mean loss=0.04962437444676956\n",
      "test_test\n",
      "test mean loss=1159.2073974609375\n",
      "epoch 9287\n",
      "test_train\n",
      "train mean loss=0.04647131760915121\n",
      "test_test\n",
      "test mean loss=1158.5898132324219\n",
      "epoch 9288\n",
      "test_train\n",
      "train mean loss=0.05229194834828377\n",
      "test_test\n",
      "test mean loss=1159.3585815429688\n",
      "epoch 9289\n",
      "test_train\n",
      "train mean loss=0.05328032824521264\n",
      "test_test\n",
      "test mean loss=1160.6613159179688\n",
      "epoch 9290\n",
      "test_train\n",
      "train mean loss=0.044863698383172355\n",
      "test_test\n",
      "test mean loss=1157.6093444824219\n",
      "epoch 9291\n",
      "test_train\n",
      "train mean loss=0.04808151116594672\n",
      "test_test\n",
      "test mean loss=1158.9333190917969\n",
      "epoch 9292\n",
      "test_train\n",
      "train mean loss=0.047587828089793525\n",
      "test_test\n",
      "test mean loss=1159.0870666503906\n",
      "epoch 9293\n",
      "test_train\n",
      "train mean loss=0.05032243967677156\n",
      "test_test\n",
      "test mean loss=1159.2437133789062\n",
      "epoch 9294\n",
      "test_train\n",
      "train mean loss=0.049197406663248934\n",
      "test_test\n",
      "test mean loss=1158.9487915039062\n",
      "epoch 9295\n",
      "test_train\n",
      "train mean loss=0.05132479500025511\n",
      "test_test\n",
      "test mean loss=1159.4779052734375\n",
      "epoch 9296\n",
      "test_train\n",
      "train mean loss=0.04781897412613034\n",
      "test_test\n",
      "test mean loss=1159.2356567382812\n",
      "epoch 9297\n",
      "test_train\n",
      "train mean loss=0.04944166044394175\n",
      "test_test\n",
      "test mean loss=1159.0717163085938\n",
      "epoch 9298\n",
      "test_train\n",
      "train mean loss=0.05565041241546472\n",
      "test_test\n",
      "test mean loss=1159.7770385742188\n",
      "epoch 9299\n",
      "test_train\n",
      "train mean loss=0.05407402028019229\n",
      "test_test\n",
      "test mean loss=1159.7175903320312\n",
      "epoch 9300\n",
      "test_train\n",
      "train mean loss=0.046126378079255424\n",
      "test_test\n",
      "test mean loss=1158.7169189453125\n",
      "epoch 9301\n",
      "test_train\n",
      "train mean loss=0.05649608435730139\n",
      "test_test\n",
      "test mean loss=1160.420654296875\n",
      "epoch 9302\n",
      "test_train\n",
      "train mean loss=0.0527050889407595\n",
      "test_test\n",
      "test mean loss=1160.0432434082031\n",
      "epoch 9303\n",
      "test_train\n",
      "train mean loss=0.0481025418266654\n",
      "test_test\n",
      "test mean loss=1159.5732116699219\n",
      "epoch 9304\n",
      "test_train\n",
      "train mean loss=0.04930256058772405\n",
      "test_test\n",
      "test mean loss=1158.5664672851562\n",
      "epoch 9305\n",
      "test_train\n",
      "train mean loss=0.04726591566577554\n",
      "test_test\n",
      "test mean loss=1159.595947265625\n",
      "epoch 9306\n",
      "test_train\n",
      "train mean loss=0.04955330522110065\n",
      "test_test\n",
      "test mean loss=1159.055419921875\n",
      "epoch 9307\n",
      "test_train\n",
      "train mean loss=0.05066628381609917\n",
      "test_test\n",
      "test mean loss=1158.7247924804688\n",
      "epoch 9308\n",
      "test_train\n",
      "train mean loss=0.04869369727869829\n",
      "test_test\n",
      "test mean loss=1158.7267456054688\n",
      "epoch 9309\n",
      "test_train\n",
      "train mean loss=0.0473461071960628\n",
      "test_test\n",
      "test mean loss=1159.1307983398438\n",
      "epoch 9310\n",
      "test_train\n",
      "train mean loss=0.04653832083567977\n",
      "test_test\n",
      "test mean loss=1158.8133544921875\n",
      "epoch 9311\n",
      "test_train\n",
      "train mean loss=0.06985494525482257\n",
      "test_test\n",
      "test mean loss=1159.3523559570312\n",
      "epoch 9312\n",
      "test_train\n",
      "train mean loss=0.05115303210914135\n",
      "test_test\n",
      "test mean loss=1159.4085693359375\n",
      "epoch 9313\n",
      "test_train\n",
      "train mean loss=0.05371857434511185\n",
      "test_test\n",
      "test mean loss=1160.0841064453125\n",
      "epoch 9314\n",
      "test_train\n",
      "train mean loss=0.05216862866654992\n",
      "test_test\n",
      "test mean loss=1159.119384765625\n",
      "epoch 9315\n",
      "test_train\n",
      "train mean loss=0.05387649250527223\n",
      "test_test\n",
      "test mean loss=1160.1080932617188\n",
      "epoch 9316\n",
      "test_train\n",
      "train mean loss=0.047420049707094826\n",
      "test_test\n",
      "test mean loss=1158.9459228515625\n",
      "epoch 9317\n",
      "test_train\n",
      "train mean loss=0.04664659903695186\n",
      "test_test\n",
      "test mean loss=1159.4183349609375\n",
      "epoch 9318\n",
      "test_train\n",
      "train mean loss=0.0487277889624238\n",
      "test_test\n",
      "test mean loss=1159.1316528320312\n",
      "epoch 9319\n",
      "test_train\n",
      "train mean loss=0.0497968460743626\n",
      "test_test\n",
      "test mean loss=1159.9585571289062\n",
      "epoch 9320\n",
      "test_train\n",
      "train mean loss=0.04933860090871652\n",
      "test_test\n",
      "test mean loss=1159.500244140625\n",
      "epoch 9321\n",
      "test_train\n",
      "train mean loss=0.04882769876470169\n",
      "test_test\n",
      "test mean loss=1159.5638427734375\n",
      "epoch 9322\n",
      "test_train\n",
      "train mean loss=0.0479591799279054\n",
      "test_test\n",
      "test mean loss=1159.77294921875\n",
      "epoch 9323\n",
      "test_train\n",
      "train mean loss=0.049939658803244434\n",
      "test_test\n",
      "test mean loss=1158.3963012695312\n",
      "epoch 9324\n",
      "test_train\n",
      "train mean loss=0.05377377398932973\n",
      "test_test\n",
      "test mean loss=1158.6020202636719\n",
      "epoch 9325\n",
      "test_train\n",
      "train mean loss=0.04880818553889791\n",
      "test_test\n",
      "test mean loss=1159.6696472167969\n",
      "epoch 9326\n",
      "test_train\n",
      "train mean loss=0.04822290254135927\n",
      "test_test\n",
      "test mean loss=1159.0674743652344\n",
      "epoch 9327\n",
      "test_train\n",
      "train mean loss=0.048575742014994226\n",
      "test_test\n",
      "test mean loss=1158.9426574707031\n",
      "epoch 9328\n",
      "test_train\n",
      "train mean loss=0.0511659091959397\n",
      "test_test\n",
      "test mean loss=1158.9411010742188\n",
      "epoch 9329\n",
      "test_train\n",
      "train mean loss=0.04918766984095176\n",
      "test_test\n",
      "test mean loss=1159.4925842285156\n",
      "epoch 9330\n",
      "test_train\n",
      "train mean loss=0.04963227485617002\n",
      "test_test\n",
      "test mean loss=1159.5186157226562\n",
      "epoch 9331\n",
      "test_train\n",
      "train mean loss=0.0509848278015852\n",
      "test_test\n",
      "test mean loss=1159.2208862304688\n",
      "epoch 9332\n",
      "test_train\n",
      "train mean loss=0.05289072543382645\n",
      "test_test\n",
      "test mean loss=1159.3630981445312\n",
      "epoch 9333\n",
      "test_train\n",
      "train mean loss=0.05347880627959967\n",
      "test_test\n",
      "test mean loss=1159.3558349609375\n",
      "epoch 9334\n",
      "test_train\n",
      "train mean loss=0.05422929208725691\n",
      "test_test\n",
      "test mean loss=1160.2011108398438\n",
      "epoch 9335\n",
      "test_train\n",
      "train mean loss=0.04660681371266643\n",
      "test_test\n",
      "test mean loss=1158.5892639160156\n",
      "epoch 9336\n",
      "test_train\n",
      "train mean loss=0.046473403150836624\n",
      "test_test\n",
      "test mean loss=1159.4326782226562\n",
      "epoch 9337\n",
      "test_train\n",
      "train mean loss=0.048602875166883074\n",
      "test_test\n",
      "test mean loss=1160.0545654296875\n",
      "epoch 9338\n",
      "test_train\n",
      "train mean loss=0.04712376262371739\n",
      "test_test\n",
      "test mean loss=1159.4098205566406\n",
      "epoch 9339\n",
      "test_train\n",
      "train mean loss=0.04974032907436291\n",
      "test_test\n",
      "test mean loss=1159.2439575195312\n",
      "epoch 9340\n",
      "test_train\n",
      "train mean loss=0.04469870186100403\n",
      "test_test\n",
      "test mean loss=1159.445556640625\n",
      "epoch 9341\n",
      "test_train\n",
      "train mean loss=0.04551343092073997\n",
      "test_test\n",
      "test mean loss=1158.3884582519531\n",
      "epoch 9342\n",
      "test_train\n",
      "train mean loss=0.04537932916233937\n",
      "test_test\n",
      "test mean loss=1158.5879516601562\n",
      "epoch 9343\n",
      "test_train\n",
      "train mean loss=0.04250923668344816\n",
      "test_test\n",
      "test mean loss=1159.46484375\n",
      "epoch 9344\n",
      "test_train\n",
      "train mean loss=0.0532040026349326\n",
      "test_test\n",
      "test mean loss=1160.84765625\n",
      "epoch 9345\n",
      "test_train\n",
      "train mean loss=0.049711438516775765\n",
      "test_test\n",
      "test mean loss=1160.1538391113281\n",
      "epoch 9346\n",
      "test_train\n",
      "train mean loss=0.04726905127366384\n",
      "test_test\n",
      "test mean loss=1159.7093505859375\n",
      "epoch 9347\n",
      "test_train\n",
      "train mean loss=0.04919801310946544\n",
      "test_test\n",
      "test mean loss=1159.1797790527344\n",
      "epoch 9348\n",
      "test_train\n",
      "train mean loss=0.09616999048739672\n",
      "test_test\n",
      "test mean loss=1160.0249938964844\n",
      "epoch 9349\n",
      "test_train\n",
      "train mean loss=0.05279997829347849\n",
      "test_test\n",
      "test mean loss=1157.4556884765625\n",
      "epoch 9350\n",
      "test_train\n",
      "train mean loss=0.04583707436298331\n",
      "test_test\n",
      "test mean loss=1158.5950012207031\n",
      "epoch 9351\n",
      "test_train\n",
      "train mean loss=0.048079285925875105\n",
      "test_test\n",
      "test mean loss=1159.3131103515625\n",
      "epoch 9352\n",
      "test_train\n",
      "train mean loss=0.3443015043934186\n",
      "test_test\n",
      "test mean loss=1143.62109375\n",
      "epoch 9353\n",
      "test_train\n",
      "train mean loss=0.05885206488892436\n",
      "test_test\n",
      "test mean loss=1159.8115234375\n",
      "epoch 9354\n",
      "test_train\n",
      "train mean loss=0.052769529012342296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_test\n",
      "test mean loss=1160.9918823242188\n",
      "epoch 9355\n",
      "test_train\n",
      "train mean loss=0.052841840932766594\n",
      "test_test\n",
      "test mean loss=1160.392822265625\n",
      "epoch 9356\n",
      "test_train\n",
      "train mean loss=0.05623876955360174\n",
      "test_test\n",
      "test mean loss=1160.2276000976562\n",
      "epoch 9357\n",
      "test_train\n",
      "train mean loss=0.05855133353422085\n",
      "test_test\n",
      "test mean loss=1159.2318115234375\n",
      "epoch 9358\n",
      "test_train\n",
      "train mean loss=0.05357970576733351\n",
      "test_test\n",
      "test mean loss=1159.5939331054688\n",
      "epoch 9359\n",
      "test_train\n",
      "train mean loss=0.04722501042609414\n",
      "test_test\n",
      "test mean loss=1158.1958312988281\n",
      "epoch 9360\n",
      "test_train\n",
      "train mean loss=0.04877949909617504\n",
      "test_test\n",
      "test mean loss=1159.8027954101562\n",
      "epoch 9361\n",
      "test_train\n",
      "train mean loss=0.04967773767809073\n",
      "test_test\n",
      "test mean loss=1159.2947998046875\n",
      "epoch 9362\n",
      "test_train\n",
      "train mean loss=0.056061848221967615\n",
      "test_test\n",
      "test mean loss=1159.9414978027344\n",
      "epoch 9363\n",
      "test_train\n",
      "train mean loss=0.04641819093376398\n",
      "test_test\n",
      "test mean loss=1159.6015625\n",
      "epoch 9364\n",
      "test_train\n",
      "train mean loss=0.050982888167103134\n",
      "test_test\n",
      "test mean loss=1159.7349243164062\n",
      "epoch 9365\n",
      "test_train\n",
      "train mean loss=0.05211053043603897\n",
      "test_test\n",
      "test mean loss=1159.6813354492188\n",
      "epoch 9366\n",
      "test_train\n",
      "train mean loss=0.052806072402745485\n",
      "test_test\n",
      "test mean loss=1160.0348510742188\n",
      "epoch 9367\n",
      "test_train\n",
      "train mean loss=0.048851255948344864\n",
      "test_test\n",
      "test mean loss=1159.7968139648438\n",
      "epoch 9368\n",
      "test_train\n",
      "train mean loss=0.05690401699393988\n",
      "test_test\n",
      "test mean loss=1160.8889770507812\n",
      "epoch 9369\n",
      "test_train\n",
      "train mean loss=0.047849380411207676\n",
      "test_test\n",
      "test mean loss=1159.4305725097656\n",
      "epoch 9370\n",
      "test_train\n",
      "train mean loss=0.05438311708470186\n",
      "test_test\n",
      "test mean loss=1160.2522583007812\n",
      "epoch 9371\n",
      "test_train\n",
      "train mean loss=0.0629580852886041\n",
      "test_test\n",
      "test mean loss=1159.4009399414062\n",
      "epoch 9372\n",
      "test_train\n",
      "train mean loss=0.056379358284175396\n",
      "test_test\n",
      "test mean loss=1160.1199340820312\n",
      "epoch 9373\n",
      "test_train\n",
      "train mean loss=0.05387477111071348\n",
      "test_test\n",
      "test mean loss=1160.5873413085938\n",
      "epoch 9374\n",
      "test_train\n",
      "train mean loss=0.0504890630642573\n",
      "test_test\n",
      "test mean loss=1159.9798583984375\n",
      "epoch 9375\n",
      "test_train\n",
      "train mean loss=0.0661139360939463\n",
      "test_test\n",
      "test mean loss=1161.5704956054688\n",
      "epoch 9376\n",
      "test_train\n",
      "train mean loss=0.05505567944298188\n",
      "test_test\n",
      "test mean loss=1160.36181640625\n",
      "epoch 9377\n",
      "test_train\n",
      "train mean loss=0.04864482426395019\n",
      "test_test\n",
      "test mean loss=1160.3678588867188\n",
      "epoch 9378\n",
      "test_train\n",
      "train mean loss=0.0527908056974411\n",
      "test_test\n",
      "test mean loss=1160.1521911621094\n",
      "epoch 9379\n",
      "test_train\n",
      "train mean loss=0.04572671201700965\n",
      "test_test\n",
      "test mean loss=1159.6459350585938\n",
      "epoch 9380\n",
      "test_train\n",
      "train mean loss=0.04624283531059822\n",
      "test_test\n",
      "test mean loss=1159.4610900878906\n",
      "epoch 9381\n",
      "test_train\n",
      "train mean loss=0.04772682022303343\n",
      "test_test\n",
      "test mean loss=1158.9419555664062\n",
      "epoch 9382\n",
      "test_train\n",
      "train mean loss=0.05527169102181991\n",
      "test_test\n",
      "test mean loss=1160.3853149414062\n",
      "epoch 9383\n",
      "test_train\n",
      "train mean loss=0.054366412262121834\n",
      "test_test\n",
      "test mean loss=1160.3506164550781\n",
      "epoch 9384\n",
      "test_train\n",
      "train mean loss=0.04782236025979122\n",
      "test_test\n",
      "test mean loss=1158.78857421875\n",
      "epoch 9385\n",
      "test_train\n",
      "train mean loss=0.05598255215833584\n",
      "test_test\n",
      "test mean loss=1159.8069152832031\n",
      "epoch 9386\n",
      "test_train\n",
      "train mean loss=0.05151865134636561\n",
      "test_test\n",
      "test mean loss=1159.6438598632812\n",
      "epoch 9387\n",
      "test_train\n",
      "train mean loss=0.05117823354279002\n",
      "test_test\n",
      "test mean loss=1158.6726379394531\n",
      "epoch 9388\n",
      "test_train\n",
      "train mean loss=0.048944473111381136\n",
      "test_test\n",
      "test mean loss=1159.5196533203125\n",
      "epoch 9389\n",
      "test_train\n",
      "train mean loss=0.046653376736988626\n",
      "test_test\n",
      "test mean loss=1160.12841796875\n",
      "epoch 9390\n",
      "test_train\n",
      "train mean loss=0.05050991351405779\n",
      "test_test\n",
      "test mean loss=1159.7294006347656\n",
      "epoch 9391\n",
      "test_train\n",
      "train mean loss=0.04703348937133948\n",
      "test_test\n",
      "test mean loss=1159.5280151367188\n",
      "epoch 9392\n",
      "test_train\n",
      "train mean loss=0.05278557073324919\n",
      "test_test\n",
      "test mean loss=1158.7938842773438\n",
      "epoch 9393\n",
      "test_train\n",
      "train mean loss=0.05831050996979078\n",
      "test_test\n",
      "test mean loss=1160.0747375488281\n",
      "epoch 9394\n",
      "test_train\n",
      "train mean loss=0.04882947510729233\n",
      "test_test\n",
      "test mean loss=1159.8441162109375\n",
      "epoch 9395\n",
      "test_train\n",
      "train mean loss=0.047902077746888004\n",
      "test_test\n",
      "test mean loss=1160.7156372070312\n",
      "epoch 9396\n",
      "test_train\n",
      "train mean loss=0.052114403496185936\n",
      "test_test\n",
      "test mean loss=1160.7006225585938\n",
      "epoch 9397\n",
      "test_train\n",
      "train mean loss=0.05115460557863116\n",
      "test_test\n",
      "test mean loss=1160.3951110839844\n",
      "epoch 9398\n",
      "test_train\n",
      "train mean loss=0.0468077597518762\n",
      "test_test\n",
      "test mean loss=1160.1067199707031\n",
      "epoch 9399\n",
      "test_train\n",
      "train mean loss=0.04910933878272772\n",
      "test_test\n",
      "test mean loss=1160.0074157714844\n",
      "epoch 9400\n",
      "test_train\n",
      "train mean loss=0.05113299780835708\n",
      "test_test\n",
      "test mean loss=1159.9510498046875\n",
      "epoch 9401\n",
      "test_train\n",
      "train mean loss=0.051005709605912365\n",
      "test_test\n",
      "test mean loss=1159.34228515625\n",
      "epoch 9402\n",
      "test_train\n",
      "train mean loss=0.05184576256821553\n",
      "test_test\n",
      "test mean loss=1159.779296875\n",
      "epoch 9403\n",
      "test_train\n",
      "train mean loss=0.04485062789171934\n",
      "test_test\n",
      "test mean loss=1159.5290222167969\n",
      "epoch 9404\n",
      "test_train\n",
      "train mean loss=0.04556379374116659\n",
      "test_test\n",
      "test mean loss=1160.2845764160156\n",
      "epoch 9405\n",
      "test_train\n",
      "train mean loss=0.04757270263507962\n",
      "test_test\n",
      "test mean loss=1159.8735961914062\n",
      "epoch 9406\n",
      "test_train\n",
      "train mean loss=0.050383180379867554\n",
      "test_test\n",
      "test mean loss=1160.9630126953125\n",
      "epoch 9407\n",
      "test_train\n",
      "train mean loss=0.053690152863661446\n",
      "test_test\n",
      "test mean loss=1160.6077880859375\n",
      "epoch 9408\n",
      "test_train\n",
      "train mean loss=0.05232644795129696\n",
      "test_test\n",
      "test mean loss=1160.8890991210938\n",
      "epoch 9409\n",
      "test_train\n",
      "train mean loss=0.05392020537207524\n",
      "test_test\n",
      "test mean loss=1160.2476196289062\n",
      "epoch 9410\n",
      "test_train\n",
      "train mean loss=0.04893482274686297\n",
      "test_test\n",
      "test mean loss=1159.2003784179688\n",
      "epoch 9411\n",
      "test_train\n",
      "train mean loss=0.05074858805164695\n",
      "test_test\n",
      "test mean loss=1159.7915649414062\n",
      "epoch 9412\n",
      "test_train\n",
      "train mean loss=0.04711948428303003\n",
      "test_test\n",
      "test mean loss=1159.2104187011719\n",
      "epoch 9413\n",
      "test_train\n",
      "train mean loss=0.04343267514680823\n",
      "test_test\n",
      "test mean loss=1158.5196533203125\n",
      "epoch 9414\n",
      "test_train\n",
      "train mean loss=0.04379912931472063\n",
      "test_test\n",
      "test mean loss=1159.083740234375\n",
      "epoch 9415\n",
      "test_train\n",
      "train mean loss=0.04398148863886794\n",
      "test_test\n",
      "test mean loss=1159.4417724609375\n",
      "epoch 9416\n",
      "test_train\n",
      "train mean loss=0.116020359719793\n",
      "test_test\n",
      "test mean loss=1162.5715942382812\n",
      "epoch 9417\n",
      "test_train\n",
      "train mean loss=0.053477500565350056\n",
      "test_test\n",
      "test mean loss=1160.70849609375\n",
      "epoch 9418\n",
      "test_train\n",
      "train mean loss=0.047157359309494495\n",
      "test_test\n",
      "test mean loss=1158.4744873046875\n",
      "epoch 9419\n",
      "test_train\n",
      "train mean loss=0.04364802191654841\n",
      "test_test\n",
      "test mean loss=1158.8907470703125\n",
      "epoch 9420\n",
      "test_train\n",
      "train mean loss=0.046544268572082124\n",
      "test_test\n",
      "test mean loss=1158.5038452148438\n",
      "epoch 9421\n",
      "test_train\n",
      "train mean loss=0.05308726243674755\n",
      "test_test\n",
      "test mean loss=1158.4824829101562\n",
      "epoch 9422\n",
      "test_train\n",
      "train mean loss=0.045962489365289606\n",
      "test_test\n",
      "test mean loss=1159.2767944335938\n",
      "epoch 9423\n",
      "test_train\n",
      "train mean loss=0.05064011489351591\n",
      "test_test\n",
      "test mean loss=1158.4974670410156\n",
      "epoch 9424\n",
      "test_train\n",
      "train mean loss=0.04860145319253206\n",
      "test_test\n",
      "test mean loss=1158.152099609375\n",
      "epoch 9425\n",
      "test_train\n",
      "train mean loss=0.06604096759110689\n",
      "test_test\n",
      "test mean loss=1161.70849609375\n",
      "epoch 9426\n",
      "test_train\n",
      "train mean loss=0.05658909399062395\n",
      "test_test\n",
      "test mean loss=1159.2930297851562\n",
      "epoch 9427\n",
      "test_train\n",
      "train mean loss=0.05253349772344033\n",
      "test_test\n",
      "test mean loss=1158.708984375\n",
      "epoch 9428\n",
      "test_train\n",
      "train mean loss=0.057234556414186954\n",
      "test_test\n",
      "test mean loss=1157.9913940429688\n",
      "epoch 9429\n",
      "test_train\n",
      "train mean loss=0.0559815278587242\n",
      "test_test\n",
      "test mean loss=1158.0813598632812\n",
      "epoch 9430\n",
      "test_train\n",
      "train mean loss=0.0491629756676654\n",
      "test_test\n",
      "test mean loss=1158.3800354003906\n",
      "epoch 9431\n",
      "test_train\n",
      "train mean loss=0.0512660175251464\n",
      "test_test\n",
      "test mean loss=1158.2094116210938\n",
      "epoch 9432\n",
      "test_train\n",
      "train mean loss=0.05192156260212263\n",
      "test_test\n",
      "test mean loss=1157.9399108886719\n",
      "epoch 9433\n",
      "test_train\n",
      "train mean loss=0.04904345857600371\n",
      "test_test\n",
      "test mean loss=1157.7306823730469\n",
      "epoch 9434\n",
      "test_train\n",
      "train mean loss=0.05437699860582749\n",
      "test_test\n",
      "test mean loss=1159.3996276855469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9435\n",
      "test_train\n",
      "train mean loss=0.047774643947680794\n",
      "test_test\n",
      "test mean loss=1157.7128295898438\n",
      "epoch 9436\n",
      "test_train\n",
      "train mean loss=0.04817675224815806\n",
      "test_test\n",
      "test mean loss=1158.7952575683594\n",
      "epoch 9437\n",
      "test_train\n",
      "train mean loss=0.049853916900853314\n",
      "test_test\n",
      "test mean loss=1158.4202270507812\n",
      "epoch 9438\n",
      "test_train\n",
      "train mean loss=0.04676547801742951\n",
      "test_test\n",
      "test mean loss=1158.7626953125\n",
      "epoch 9439\n",
      "test_train\n",
      "train mean loss=0.05009189403305451\n",
      "test_test\n",
      "test mean loss=1158.4656982421875\n",
      "epoch 9440\n",
      "test_train\n",
      "train mean loss=0.3996147910753886\n",
      "test_test\n",
      "test mean loss=1158.6005859375\n",
      "epoch 9441\n",
      "test_train\n",
      "train mean loss=0.06122403064121803\n",
      "test_test\n",
      "test mean loss=1158.7694702148438\n",
      "epoch 9442\n",
      "test_train\n",
      "train mean loss=0.05237570280830065\n",
      "test_test\n",
      "test mean loss=1159.1868286132812\n",
      "epoch 9443\n",
      "test_train\n",
      "train mean loss=0.060021938756108284\n",
      "test_test\n",
      "test mean loss=1160.4329833984375\n",
      "epoch 9444\n",
      "test_train\n",
      "train mean loss=0.05312834959477186\n",
      "test_test\n",
      "test mean loss=1160.2409057617188\n",
      "epoch 9445\n",
      "test_train\n",
      "train mean loss=0.04957612479726473\n",
      "test_test\n",
      "test mean loss=1160.7477722167969\n",
      "epoch 9446\n",
      "test_train\n",
      "train mean loss=0.04448980838060379\n",
      "test_test\n",
      "test mean loss=1159.6842041015625\n",
      "epoch 9447\n",
      "test_train\n",
      "train mean loss=0.05344975910459956\n",
      "test_test\n",
      "test mean loss=1158.710693359375\n",
      "epoch 9448\n",
      "test_train\n",
      "train mean loss=0.05165473651140928\n",
      "test_test\n",
      "test mean loss=1159.3724060058594\n",
      "epoch 9449\n",
      "test_train\n",
      "train mean loss=0.04858663616081079\n",
      "test_test\n",
      "test mean loss=1158.2085571289062\n",
      "epoch 9450\n",
      "test_train\n",
      "train mean loss=0.047267563020189605\n",
      "test_test\n",
      "test mean loss=1159.5684814453125\n",
      "epoch 9451\n",
      "test_train\n",
      "train mean loss=0.04925470085193714\n",
      "test_test\n",
      "test mean loss=1158.644775390625\n",
      "epoch 9452\n",
      "test_train\n",
      "train mean loss=0.046598805425067745\n",
      "test_test\n",
      "test mean loss=1158.6456909179688\n",
      "epoch 9453\n",
      "test_train\n",
      "train mean loss=0.05055003318314751\n",
      "test_test\n",
      "test mean loss=1159.8014831542969\n",
      "epoch 9454\n",
      "test_train\n",
      "train mean loss=0.048153677955269814\n",
      "test_test\n",
      "test mean loss=1159.9887084960938\n",
      "epoch 9455\n",
      "test_train\n",
      "train mean loss=0.04603995165477196\n",
      "test_test\n",
      "test mean loss=1160.2379150390625\n",
      "epoch 9456\n",
      "test_train\n",
      "train mean loss=0.056691507498423256\n",
      "test_test\n",
      "test mean loss=1160.6253356933594\n",
      "epoch 9457\n",
      "test_train\n",
      "train mean loss=0.05404115840792656\n",
      "test_test\n",
      "test mean loss=1159.3157958984375\n",
      "epoch 9458\n",
      "test_train\n",
      "train mean loss=0.048550943533579506\n",
      "test_test\n",
      "test mean loss=1159.64306640625\n",
      "epoch 9459\n",
      "test_train\n",
      "train mean loss=0.06081160685668389\n",
      "test_test\n",
      "test mean loss=1160.8660278320312\n",
      "epoch 9460\n",
      "test_train\n",
      "train mean loss=0.04572688151771823\n",
      "test_test\n",
      "test mean loss=1159.7036743164062\n",
      "epoch 9461\n",
      "test_train\n",
      "train mean loss=0.04897849323848883\n",
      "test_test\n",
      "test mean loss=1159.0078735351562\n",
      "epoch 9462\n",
      "test_train\n",
      "train mean loss=0.05197225076456865\n",
      "test_test\n",
      "test mean loss=1159.5007019042969\n",
      "epoch 9463\n",
      "test_train\n",
      "train mean loss=0.05112828376392523\n",
      "test_test\n",
      "test mean loss=1158.6172485351562\n",
      "epoch 9464\n",
      "test_train\n",
      "train mean loss=0.05044844591369232\n",
      "test_test\n",
      "test mean loss=1159.5581359863281\n",
      "epoch 9465\n",
      "test_train\n",
      "train mean loss=0.05147499001274506\n",
      "test_test\n",
      "test mean loss=1159.1463623046875\n",
      "epoch 9466\n",
      "test_train\n",
      "train mean loss=0.05536024489750465\n",
      "test_test\n",
      "test mean loss=1160.3555297851562\n",
      "epoch 9467\n",
      "test_train\n",
      "train mean loss=0.04916997409115235\n",
      "test_test\n",
      "test mean loss=1160.1653442382812\n",
      "epoch 9468\n",
      "test_train\n",
      "train mean loss=0.05656567355617881\n",
      "test_test\n",
      "test mean loss=1159.4249877929688\n",
      "epoch 9469\n",
      "test_train\n",
      "train mean loss=0.047968704563875995\n",
      "test_test\n",
      "test mean loss=1158.0440673828125\n",
      "epoch 9470\n",
      "test_train\n",
      "train mean loss=0.054445257410407066\n",
      "test_test\n",
      "test mean loss=1159.1259155273438\n",
      "epoch 9471\n",
      "test_train\n",
      "train mean loss=0.04973879953225454\n",
      "test_test\n",
      "test mean loss=1158.4830932617188\n",
      "epoch 9472\n",
      "test_train\n",
      "train mean loss=0.052840485547979675\n",
      "test_test\n",
      "test mean loss=1159.6117553710938\n",
      "epoch 9473\n",
      "test_train\n",
      "train mean loss=0.0498935484016935\n",
      "test_test\n",
      "test mean loss=1159.6032104492188\n",
      "epoch 9474\n",
      "test_train\n",
      "train mean loss=0.05286938759187857\n",
      "test_test\n",
      "test mean loss=1160.07666015625\n",
      "epoch 9475\n",
      "test_train\n",
      "train mean loss=0.04860890501489242\n",
      "test_test\n",
      "test mean loss=1159.1837158203125\n",
      "epoch 9476\n",
      "test_train\n",
      "train mean loss=0.04654196805010239\n",
      "test_test\n",
      "test mean loss=1161.1029968261719\n",
      "epoch 9477\n",
      "test_train\n",
      "train mean loss=0.8192733377218246\n",
      "test_test\n",
      "test mean loss=1155.5264282226562\n",
      "epoch 9478\n",
      "test_train\n",
      "train mean loss=0.06607410032302141\n",
      "test_test\n",
      "test mean loss=1158.6277465820312\n",
      "epoch 9479\n",
      "test_train\n",
      "train mean loss=0.04833860540141662\n",
      "test_test\n",
      "test mean loss=1161.1085205078125\n",
      "epoch 9480\n",
      "test_train\n",
      "train mean loss=0.044282751778761544\n",
      "test_test\n",
      "test mean loss=1160.861572265625\n",
      "epoch 9481\n",
      "test_train\n",
      "train mean loss=0.047793771140277386\n",
      "test_test\n",
      "test mean loss=1160.2081909179688\n",
      "epoch 9482\n",
      "test_train\n",
      "train mean loss=0.04926331449920932\n",
      "test_test\n",
      "test mean loss=1160.7738037109375\n",
      "epoch 9483\n",
      "test_train\n",
      "train mean loss=0.047116835756848253\n",
      "test_test\n",
      "test mean loss=1161.3037719726562\n",
      "epoch 9484\n",
      "test_train\n",
      "train mean loss=0.051067651715129614\n",
      "test_test\n",
      "test mean loss=1161.6817932128906\n",
      "epoch 9485\n",
      "test_train\n",
      "train mean loss=0.04926240739102165\n",
      "test_test\n",
      "test mean loss=1161.0809936523438\n",
      "epoch 9486\n",
      "test_train\n",
      "train mean loss=0.058642622704307236\n",
      "test_test\n",
      "test mean loss=1161.39404296875\n",
      "epoch 9487\n",
      "test_train\n",
      "train mean loss=0.05296375478307406\n",
      "test_test\n",
      "test mean loss=1160.7652893066406\n",
      "epoch 9488\n",
      "test_train\n",
      "train mean loss=0.050557222527762256\n",
      "test_test\n",
      "test mean loss=1160.4815673828125\n",
      "epoch 9489\n",
      "test_train\n",
      "train mean loss=0.055301954659322895\n",
      "test_test\n",
      "test mean loss=1161.3040771484375\n",
      "epoch 9490\n",
      "test_train\n",
      "train mean loss=0.0563556452592214\n",
      "test_test\n",
      "test mean loss=1161.66552734375\n",
      "epoch 9491\n",
      "test_train\n",
      "train mean loss=0.05525833632176121\n",
      "test_test\n",
      "test mean loss=1160.9226684570312\n",
      "epoch 9492\n",
      "test_train\n",
      "train mean loss=0.05130820364380876\n",
      "test_test\n",
      "test mean loss=1160.217041015625\n",
      "epoch 9493\n",
      "test_train\n",
      "train mean loss=0.0482735683520635\n",
      "test_test\n",
      "test mean loss=1157.661865234375\n",
      "epoch 9494\n",
      "test_train\n",
      "train mean loss=0.05039234707752863\n",
      "test_test\n",
      "test mean loss=1159.84814453125\n",
      "epoch 9495\n",
      "test_train\n",
      "train mean loss=0.05037061171606183\n",
      "test_test\n",
      "test mean loss=1160.4905395507812\n",
      "epoch 9496\n",
      "test_train\n",
      "train mean loss=0.05045839802672466\n",
      "test_test\n",
      "test mean loss=1159.7479858398438\n",
      "epoch 9497\n",
      "test_train\n",
      "train mean loss=0.04769063632314404\n",
      "test_test\n",
      "test mean loss=1159.567138671875\n",
      "epoch 9498\n",
      "test_train\n",
      "train mean loss=0.0446362493870159\n",
      "test_test\n",
      "test mean loss=1160.4229431152344\n",
      "epoch 9499\n",
      "test_train\n",
      "train mean loss=0.04905150458216667\n",
      "test_test\n",
      "test mean loss=1160.2234497070312\n",
      "epoch 9500\n",
      "test_train\n",
      "train mean loss=0.062163472486039005\n",
      "test_test\n",
      "test mean loss=1156.6950988769531\n",
      "epoch 9501\n",
      "test_train\n",
      "train mean loss=0.05257229538013538\n",
      "test_test\n",
      "test mean loss=1159.5967407226562\n",
      "epoch 9502\n",
      "test_train\n",
      "train mean loss=0.060108367974559464\n",
      "test_test\n",
      "test mean loss=1159.9103088378906\n",
      "epoch 9503\n",
      "test_train\n",
      "train mean loss=0.05282063161333402\n",
      "test_test\n",
      "test mean loss=1159.9857482910156\n",
      "epoch 9504\n",
      "test_train\n",
      "train mean loss=0.052931101682285465\n",
      "test_test\n",
      "test mean loss=1158.5650634765625\n",
      "epoch 9505\n",
      "test_train\n",
      "train mean loss=0.05150702285269896\n",
      "test_test\n",
      "test mean loss=1159.1634826660156\n",
      "epoch 9506\n",
      "test_train\n",
      "train mean loss=0.046505517326295376\n",
      "test_test\n",
      "test mean loss=1160.465576171875\n",
      "epoch 9507\n",
      "test_train\n",
      "train mean loss=0.050205507315695286\n",
      "test_test\n",
      "test mean loss=1159.78662109375\n",
      "epoch 9508\n",
      "test_train\n",
      "train mean loss=0.05588857286299268\n",
      "test_test\n",
      "test mean loss=1159.4421997070312\n",
      "epoch 9509\n",
      "test_train\n",
      "train mean loss=0.04988716046015421\n",
      "test_test\n",
      "test mean loss=1159.7786254882812\n",
      "epoch 9510\n",
      "test_train\n",
      "train mean loss=0.04405228110651175\n",
      "test_test\n",
      "test mean loss=1159.3087768554688\n",
      "epoch 9511\n",
      "test_train\n",
      "train mean loss=0.0484849534307917\n",
      "test_test\n",
      "test mean loss=1159.4637756347656\n",
      "epoch 9512\n",
      "test_train\n",
      "train mean loss=0.048865584656596184\n",
      "test_test\n",
      "test mean loss=1158.7680358886719\n",
      "epoch 9513\n",
      "test_train\n",
      "train mean loss=0.05005872327213486\n",
      "test_test\n",
      "test mean loss=1159.0616760253906\n",
      "epoch 9514\n",
      "test_train\n",
      "train mean loss=0.052593858912587166\n",
      "test_test\n",
      "test mean loss=1159.0838012695312\n",
      "epoch 9515\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.05010379912952582\n",
      "test_test\n",
      "test mean loss=1159.33984375\n",
      "epoch 9516\n",
      "test_train\n",
      "train mean loss=0.045000417002787195\n",
      "test_test\n",
      "test mean loss=1158.5101623535156\n",
      "epoch 9517\n",
      "test_train\n",
      "train mean loss=0.04829042994727691\n",
      "test_test\n",
      "test mean loss=1158.8876953125\n",
      "epoch 9518\n",
      "test_train\n",
      "train mean loss=0.043429742101579905\n",
      "test_test\n",
      "test mean loss=1159.5230102539062\n",
      "epoch 9519\n",
      "test_train\n",
      "train mean loss=0.051227417308837175\n",
      "test_test\n",
      "test mean loss=1159.8856201171875\n",
      "epoch 9520\n",
      "test_train\n",
      "train mean loss=0.048827942771216236\n",
      "test_test\n",
      "test mean loss=1159.144287109375\n",
      "epoch 9521\n",
      "test_train\n",
      "train mean loss=0.05149550875648856\n",
      "test_test\n",
      "test mean loss=1160.6148986816406\n",
      "epoch 9522\n",
      "test_train\n",
      "train mean loss=0.050270178665717445\n",
      "test_test\n",
      "test mean loss=1159.8611450195312\n",
      "epoch 9523\n",
      "test_train\n",
      "train mean loss=0.04806914118429025\n",
      "test_test\n",
      "test mean loss=1159.3355712890625\n",
      "epoch 9524\n",
      "test_train\n",
      "train mean loss=0.04561029886826873\n",
      "test_test\n",
      "test mean loss=1158.9597778320312\n",
      "epoch 9525\n",
      "test_train\n",
      "train mean loss=0.050910497239480414\n",
      "test_test\n",
      "test mean loss=1160.9219970703125\n",
      "epoch 9526\n",
      "test_train\n",
      "train mean loss=0.053266923098514475\n",
      "test_test\n",
      "test mean loss=1160.1969909667969\n",
      "epoch 9527\n",
      "test_train\n",
      "train mean loss=0.05242480104789138\n",
      "test_test\n",
      "test mean loss=1159.3901977539062\n",
      "epoch 9528\n",
      "test_train\n",
      "train mean loss=0.05345576535910368\n",
      "test_test\n",
      "test mean loss=1159.29296875\n",
      "epoch 9529\n",
      "test_train\n",
      "train mean loss=0.05927768753220638\n",
      "test_test\n",
      "test mean loss=1160.4569702148438\n",
      "epoch 9530\n",
      "test_train\n",
      "train mean loss=0.05096176825463772\n",
      "test_test\n",
      "test mean loss=1159.6484375\n",
      "epoch 9531\n",
      "test_train\n",
      "train mean loss=0.05896551379313072\n",
      "test_test\n",
      "test mean loss=1160.1631469726562\n",
      "epoch 9532\n",
      "test_train\n",
      "train mean loss=0.050265006410578884\n",
      "test_test\n",
      "test mean loss=1159.793701171875\n",
      "epoch 9533\n",
      "test_train\n",
      "train mean loss=0.0477540991269052\n",
      "test_test\n",
      "test mean loss=1159.6963500976562\n",
      "epoch 9534\n",
      "test_train\n",
      "train mean loss=0.0469715508321921\n",
      "test_test\n",
      "test mean loss=1160.426025390625\n",
      "epoch 9535\n",
      "test_train\n",
      "train mean loss=0.05246787269910177\n",
      "test_test\n",
      "test mean loss=1159.7286071777344\n",
      "epoch 9536\n",
      "test_train\n",
      "train mean loss=0.050297574140131474\n",
      "test_test\n",
      "test mean loss=1158.7138977050781\n",
      "epoch 9537\n",
      "test_train\n",
      "train mean loss=0.056181079552819334\n",
      "test_test\n",
      "test mean loss=1160.0675964355469\n",
      "epoch 9538\n",
      "test_train\n",
      "train mean loss=0.052381133660674095\n",
      "test_test\n",
      "test mean loss=1159.0744018554688\n",
      "epoch 9539\n",
      "test_train\n",
      "train mean loss=0.04750485345721245\n",
      "test_test\n",
      "test mean loss=1160.2150268554688\n",
      "epoch 9540\n",
      "test_train\n",
      "train mean loss=0.040894712787121534\n",
      "test_test\n",
      "test mean loss=1159.4774780273438\n",
      "epoch 9541\n",
      "test_train\n",
      "train mean loss=0.04063312135015925\n",
      "test_test\n",
      "test mean loss=1159.0790405273438\n",
      "epoch 9542\n",
      "test_train\n",
      "train mean loss=0.04773283222069343\n",
      "test_test\n",
      "test mean loss=1159.6622619628906\n",
      "epoch 9543\n",
      "test_train\n",
      "train mean loss=0.04981886704141895\n",
      "test_test\n",
      "test mean loss=1158.9284973144531\n",
      "epoch 9544\n",
      "test_train\n",
      "train mean loss=0.04680733957017461\n",
      "test_test\n",
      "test mean loss=1159.07373046875\n",
      "epoch 9545\n",
      "test_train\n",
      "train mean loss=0.04359561391174793\n",
      "test_test\n",
      "test mean loss=1158.5574340820312\n",
      "epoch 9546\n",
      "test_train\n",
      "train mean loss=0.045019441905121006\n",
      "test_test\n",
      "test mean loss=1160.0728454589844\n",
      "epoch 9547\n",
      "test_train\n",
      "train mean loss=0.042096123564988375\n",
      "test_test\n",
      "test mean loss=1159.6448364257812\n",
      "epoch 9548\n",
      "test_train\n",
      "train mean loss=0.046139781984190144\n",
      "test_test\n",
      "test mean loss=1158.9569702148438\n",
      "epoch 9549\n",
      "test_train\n",
      "train mean loss=0.054233573377132416\n",
      "test_test\n",
      "test mean loss=1159.9551696777344\n",
      "epoch 9550\n",
      "test_train\n",
      "train mean loss=0.0500819788624843\n",
      "test_test\n",
      "test mean loss=1160.2115478515625\n",
      "epoch 9551\n",
      "test_train\n",
      "train mean loss=0.045268794521689415\n",
      "test_test\n",
      "test mean loss=1159.0469970703125\n",
      "epoch 9552\n",
      "test_train\n",
      "train mean loss=0.05005352245643735\n",
      "test_test\n",
      "test mean loss=1159.0474243164062\n",
      "epoch 9553\n",
      "test_train\n",
      "train mean loss=0.04754455806687474\n",
      "test_test\n",
      "test mean loss=1159.7286376953125\n",
      "epoch 9554\n",
      "test_train\n",
      "train mean loss=0.056022873148322105\n",
      "test_test\n",
      "test mean loss=1158.0492553710938\n",
      "epoch 9555\n",
      "test_train\n",
      "train mean loss=0.052068030927330256\n",
      "test_test\n",
      "test mean loss=1159.7783203125\n",
      "epoch 9556\n",
      "test_train\n",
      "train mean loss=0.05114545005684098\n",
      "test_test\n",
      "test mean loss=1159.2317199707031\n",
      "epoch 9557\n",
      "test_train\n",
      "train mean loss=0.0548537983559072\n",
      "test_test\n",
      "test mean loss=1159.8929443359375\n",
      "epoch 9558\n",
      "test_train\n",
      "train mean loss=0.05215462824950615\n",
      "test_test\n",
      "test mean loss=1159.8429565429688\n",
      "epoch 9559\n",
      "test_train\n",
      "train mean loss=0.04802456498146057\n",
      "test_test\n",
      "test mean loss=1158.4848022460938\n",
      "epoch 9560\n",
      "test_train\n",
      "train mean loss=0.05095233954489231\n",
      "test_test\n",
      "test mean loss=1159.1947021484375\n",
      "epoch 9561\n",
      "test_train\n",
      "train mean loss=0.05393598352869352\n",
      "test_test\n",
      "test mean loss=1160.2142333984375\n",
      "epoch 9562\n",
      "test_train\n",
      "train mean loss=0.042250897269696\n",
      "test_test\n",
      "test mean loss=1159.5013122558594\n",
      "epoch 9563\n",
      "test_train\n",
      "train mean loss=0.04706071394806107\n",
      "test_test\n",
      "test mean loss=1159.8734130859375\n",
      "epoch 9564\n",
      "test_train\n",
      "train mean loss=0.04955909866839647\n",
      "test_test\n",
      "test mean loss=1160.4248046875\n",
      "epoch 9565\n",
      "test_train\n",
      "train mean loss=0.051553407373527683\n",
      "test_test\n",
      "test mean loss=1159.9550476074219\n",
      "epoch 9566\n",
      "test_train\n",
      "train mean loss=0.06521013022089998\n",
      "test_test\n",
      "test mean loss=1159.4129638671875\n",
      "epoch 9567\n",
      "test_train\n",
      "train mean loss=0.052516017109155655\n",
      "test_test\n",
      "test mean loss=1159.31787109375\n",
      "epoch 9568\n",
      "test_train\n",
      "train mean loss=0.044406676975389324\n",
      "test_test\n",
      "test mean loss=1159.093017578125\n",
      "epoch 9569\n",
      "test_train\n",
      "train mean loss=0.05028286358962456\n",
      "test_test\n",
      "test mean loss=1158.2362976074219\n",
      "epoch 9570\n",
      "test_train\n",
      "train mean loss=0.056050428189337254\n",
      "test_test\n",
      "test mean loss=1158.6797485351562\n",
      "epoch 9571\n",
      "test_train\n",
      "train mean loss=0.04609858136003216\n",
      "test_test\n",
      "test mean loss=1158.5521850585938\n",
      "epoch 9572\n",
      "test_train\n",
      "train mean loss=0.046099604573100805\n",
      "test_test\n",
      "test mean loss=1159.4529724121094\n",
      "epoch 9573\n",
      "test_train\n",
      "train mean loss=0.04723445946971575\n",
      "test_test\n",
      "test mean loss=1159.3519592285156\n",
      "epoch 9574\n",
      "test_train\n",
      "train mean loss=0.040289855717370905\n",
      "test_test\n",
      "test mean loss=1158.8153076171875\n",
      "epoch 9575\n",
      "test_train\n",
      "train mean loss=0.047059583167235054\n",
      "test_test\n",
      "test mean loss=1158.3603515625\n",
      "epoch 9576\n",
      "test_train\n",
      "train mean loss=0.04745245724916458\n",
      "test_test\n",
      "test mean loss=1159.4371337890625\n",
      "epoch 9577\n",
      "test_train\n",
      "train mean loss=0.046555541610966124\n",
      "test_test\n",
      "test mean loss=1159.6888122558594\n",
      "epoch 9578\n",
      "test_train\n",
      "train mean loss=0.05083469689513246\n",
      "test_test\n",
      "test mean loss=1158.83984375\n",
      "epoch 9579\n",
      "test_train\n",
      "train mean loss=0.048101613918940224\n",
      "test_test\n",
      "test mean loss=1159.7334899902344\n",
      "epoch 9580\n",
      "test_train\n",
      "train mean loss=0.04959157140304645\n",
      "test_test\n",
      "test mean loss=1159.811279296875\n",
      "epoch 9581\n",
      "test_train\n",
      "train mean loss=0.05146080426250895\n",
      "test_test\n",
      "test mean loss=1159.8898010253906\n",
      "epoch 9582\n",
      "test_train\n",
      "train mean loss=0.047440871906777225\n",
      "test_test\n",
      "test mean loss=1159.7963562011719\n",
      "epoch 9583\n",
      "test_train\n",
      "train mean loss=0.04300865965584914\n",
      "test_test\n",
      "test mean loss=1158.3341064453125\n",
      "epoch 9584\n",
      "test_train\n",
      "train mean loss=0.050866127479821444\n",
      "test_test\n",
      "test mean loss=1157.7387084960938\n",
      "epoch 9585\n",
      "test_train\n",
      "train mean loss=0.04749400603274504\n",
      "test_test\n",
      "test mean loss=1158.640625\n",
      "epoch 9586\n",
      "test_train\n",
      "train mean loss=0.05498246103525162\n",
      "test_test\n",
      "test mean loss=1158.7628784179688\n",
      "epoch 9587\n",
      "test_train\n",
      "train mean loss=0.0553360857690374\n",
      "test_test\n",
      "test mean loss=1159.5751342773438\n",
      "epoch 9588\n",
      "test_train\n",
      "train mean loss=0.048313132797678314\n",
      "test_test\n",
      "test mean loss=1159.0834350585938\n",
      "epoch 9589\n",
      "test_train\n",
      "train mean loss=0.048778069826463856\n",
      "test_test\n",
      "test mean loss=1158.4310913085938\n",
      "epoch 9590\n",
      "test_train\n",
      "train mean loss=0.0575108101281027\n",
      "test_test\n",
      "test mean loss=1160.377197265625\n",
      "epoch 9591\n",
      "test_train\n",
      "train mean loss=0.04719318045924107\n",
      "test_test\n",
      "test mean loss=1158.8711853027344\n",
      "epoch 9592\n",
      "test_train\n",
      "train mean loss=0.04540207454313835\n",
      "test_test\n",
      "test mean loss=1159.1022338867188\n",
      "epoch 9593\n",
      "test_train\n",
      "train mean loss=0.0913406228646636\n",
      "test_test\n",
      "test mean loss=1160.2706298828125\n",
      "epoch 9594\n",
      "test_train\n",
      "train mean loss=0.04834877327084541\n",
      "test_test\n",
      "test mean loss=1159.3671569824219\n",
      "epoch 9595\n",
      "test_train\n",
      "train mean loss=0.047402086202055216\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1158.6690673828125\n",
      "epoch 9596\n",
      "test_train\n",
      "train mean loss=0.04687479635079702\n",
      "test_test\n",
      "test mean loss=1159.20458984375\n",
      "epoch 9597\n",
      "test_train\n",
      "train mean loss=0.04865879270558556\n",
      "test_test\n",
      "test mean loss=1159.63623046875\n",
      "epoch 9598\n",
      "test_train\n",
      "train mean loss=0.049556682196756206\n",
      "test_test\n",
      "test mean loss=1158.9100036621094\n",
      "epoch 9599\n",
      "test_train\n",
      "train mean loss=0.04230092636620005\n",
      "test_test\n",
      "test mean loss=1158.1360168457031\n",
      "epoch 9600\n",
      "test_train\n",
      "train mean loss=0.05680850117156903\n",
      "test_test\n",
      "test mean loss=1157.8833618164062\n",
      "epoch 9601\n",
      "test_train\n",
      "train mean loss=0.04950917108605305\n",
      "test_test\n",
      "test mean loss=1159.3246459960938\n",
      "epoch 9602\n",
      "test_train\n",
      "train mean loss=0.04875181335955858\n",
      "test_test\n",
      "test mean loss=1159.6627502441406\n",
      "epoch 9603\n",
      "test_train\n",
      "train mean loss=0.05541424142817656\n",
      "test_test\n",
      "test mean loss=1159.4468383789062\n",
      "epoch 9604\n",
      "test_train\n",
      "train mean loss=0.05396702419966459\n",
      "test_test\n",
      "test mean loss=1158.8582153320312\n",
      "epoch 9605\n",
      "test_train\n",
      "train mean loss=0.046369225873301424\n",
      "test_test\n",
      "test mean loss=1157.5757446289062\n",
      "epoch 9606\n",
      "test_train\n",
      "train mean loss=0.045365380899359785\n",
      "test_test\n",
      "test mean loss=1159.55908203125\n",
      "epoch 9607\n",
      "test_train\n",
      "train mean loss=0.04797821041817466\n",
      "test_test\n",
      "test mean loss=1158.8365783691406\n",
      "epoch 9608\n",
      "test_train\n",
      "train mean loss=0.04883234094207486\n",
      "test_test\n",
      "test mean loss=1159.1157836914062\n",
      "epoch 9609\n",
      "test_train\n",
      "train mean loss=0.048567628022283316\n",
      "test_test\n",
      "test mean loss=1158.5794982910156\n",
      "epoch 9610\n",
      "test_train\n",
      "train mean loss=0.04690296947956085\n",
      "test_test\n",
      "test mean loss=1157.5781860351562\n",
      "epoch 9611\n",
      "test_train\n",
      "train mean loss=0.049273782720168434\n",
      "test_test\n",
      "test mean loss=1158.0982971191406\n",
      "epoch 9612\n",
      "test_train\n",
      "train mean loss=0.04697223581994573\n",
      "test_test\n",
      "test mean loss=1157.5977783203125\n",
      "epoch 9613\n",
      "test_train\n",
      "train mean loss=0.04830358549952507\n",
      "test_test\n",
      "test mean loss=1158.2301330566406\n",
      "epoch 9614\n",
      "test_train\n",
      "train mean loss=0.043668799412747226\n",
      "test_test\n",
      "test mean loss=1157.8451232910156\n",
      "epoch 9615\n",
      "test_train\n",
      "train mean loss=0.04256696409235398\n",
      "test_test\n",
      "test mean loss=1157.2582397460938\n",
      "epoch 9616\n",
      "test_train\n",
      "train mean loss=0.046479056434084974\n",
      "test_test\n",
      "test mean loss=1158.9695434570312\n",
      "epoch 9617\n",
      "test_train\n",
      "train mean loss=0.04799651727080345\n",
      "test_test\n",
      "test mean loss=1159.0985717773438\n",
      "epoch 9618\n",
      "test_train\n",
      "train mean loss=0.0456448153903087\n",
      "test_test\n",
      "test mean loss=1157.106689453125\n",
      "epoch 9619\n",
      "test_train\n",
      "train mean loss=0.05040625218922893\n",
      "test_test\n",
      "test mean loss=1158.2200317382812\n",
      "epoch 9620\n",
      "test_train\n",
      "train mean loss=0.04947173409163952\n",
      "test_test\n",
      "test mean loss=1158.6724853515625\n",
      "epoch 9621\n",
      "test_train\n",
      "train mean loss=0.041435546396921076\n",
      "test_test\n",
      "test mean loss=1157.6806640625\n",
      "epoch 9622\n",
      "test_train\n",
      "train mean loss=0.05266982425625125\n",
      "test_test\n",
      "test mean loss=1159.0991821289062\n",
      "epoch 9623\n",
      "test_train\n",
      "train mean loss=0.04895722990234693\n",
      "test_test\n",
      "test mean loss=1158.9486694335938\n",
      "epoch 9624\n",
      "test_train\n",
      "train mean loss=0.05029863445088267\n",
      "test_test\n",
      "test mean loss=1157.5195922851562\n",
      "epoch 9625\n",
      "test_train\n",
      "train mean loss=0.04419295179347197\n",
      "test_test\n",
      "test mean loss=1157.1382446289062\n",
      "epoch 9626\n",
      "test_train\n",
      "train mean loss=0.0486104137574633\n",
      "test_test\n",
      "test mean loss=1157.026611328125\n",
      "epoch 9627\n",
      "test_train\n",
      "train mean loss=0.041347605641931295\n",
      "test_test\n",
      "test mean loss=1157.0286254882812\n",
      "epoch 9628\n",
      "test_train\n",
      "train mean loss=0.049077742733061314\n",
      "test_test\n",
      "test mean loss=1157.5931396484375\n",
      "epoch 9629\n",
      "test_train\n",
      "train mean loss=0.050898466259241104\n",
      "test_test\n",
      "test mean loss=1158.4365844726562\n",
      "epoch 9630\n",
      "test_train\n",
      "train mean loss=0.05093101101617018\n",
      "test_test\n",
      "test mean loss=1158.7378845214844\n",
      "epoch 9631\n",
      "test_train\n",
      "train mean loss=0.046488613511125244\n",
      "test_test\n",
      "test mean loss=1158.7284545898438\n",
      "epoch 9632\n",
      "test_train\n",
      "train mean loss=0.04951583221554756\n",
      "test_test\n",
      "test mean loss=1159.0338745117188\n",
      "epoch 9633\n",
      "test_train\n",
      "train mean loss=0.04493270364279548\n",
      "test_test\n",
      "test mean loss=1157.4855346679688\n",
      "epoch 9634\n",
      "test_train\n",
      "train mean loss=0.04947608212629954\n",
      "test_test\n",
      "test mean loss=1158.6812133789062\n",
      "epoch 9635\n",
      "test_train\n",
      "train mean loss=0.051421412732452154\n",
      "test_test\n",
      "test mean loss=1158.7877807617188\n",
      "epoch 9636\n",
      "test_train\n",
      "train mean loss=0.046385906636714935\n",
      "test_test\n",
      "test mean loss=1158.9922485351562\n",
      "epoch 9637\n",
      "test_train\n",
      "train mean loss=0.053449179045856\n",
      "test_test\n",
      "test mean loss=1159.3328857421875\n",
      "epoch 9638\n",
      "test_train\n",
      "train mean loss=0.054074546322226524\n",
      "test_test\n",
      "test mean loss=1157.2154541015625\n",
      "epoch 9639\n",
      "test_train\n",
      "train mean loss=0.04526422110696634\n",
      "test_test\n",
      "test mean loss=1158.6827392578125\n",
      "epoch 9640\n",
      "test_train\n",
      "train mean loss=0.04444107816865047\n",
      "test_test\n",
      "test mean loss=1158.2838134765625\n",
      "epoch 9641\n",
      "test_train\n",
      "train mean loss=0.045196642788747944\n",
      "test_test\n",
      "test mean loss=1158.5648803710938\n",
      "epoch 9642\n",
      "test_train\n",
      "train mean loss=0.045296365239967905\n",
      "test_test\n",
      "test mean loss=1157.4765930175781\n",
      "epoch 9643\n",
      "test_train\n",
      "train mean loss=0.049625820169846215\n",
      "test_test\n",
      "test mean loss=1157.7342529296875\n",
      "epoch 9644\n",
      "test_train\n",
      "train mean loss=0.04756011658658584\n",
      "test_test\n",
      "test mean loss=1158.2238159179688\n",
      "epoch 9645\n",
      "test_train\n",
      "train mean loss=0.046846647281199694\n",
      "test_test\n",
      "test mean loss=1158.6461181640625\n",
      "epoch 9646\n",
      "test_train\n",
      "train mean loss=0.04344078556944927\n",
      "test_test\n",
      "test mean loss=1158.0808715820312\n",
      "epoch 9647\n",
      "test_train\n",
      "train mean loss=0.04706956539303064\n",
      "test_test\n",
      "test mean loss=1158.7671203613281\n",
      "epoch 9648\n",
      "test_train\n",
      "train mean loss=0.04854722445209821\n",
      "test_test\n",
      "test mean loss=1158.3707885742188\n",
      "epoch 9649\n",
      "test_train\n",
      "train mean loss=0.04852246477579077\n",
      "test_test\n",
      "test mean loss=1158.411865234375\n",
      "epoch 9650\n",
      "test_train\n",
      "train mean loss=0.04955673466126124\n",
      "test_test\n",
      "test mean loss=1158.5816040039062\n",
      "epoch 9651\n",
      "test_train\n",
      "train mean loss=0.04978270549327135\n",
      "test_test\n",
      "test mean loss=1158.3846435546875\n",
      "epoch 9652\n",
      "test_train\n",
      "train mean loss=0.048908865079283714\n",
      "test_test\n",
      "test mean loss=1158.7084350585938\n",
      "epoch 9653\n",
      "test_train\n",
      "train mean loss=0.048992809684326254\n",
      "test_test\n",
      "test mean loss=1157.931640625\n",
      "epoch 9654\n",
      "test_train\n",
      "train mean loss=0.04333625718330344\n",
      "test_test\n",
      "test mean loss=1157.9760131835938\n",
      "epoch 9655\n",
      "test_train\n",
      "train mean loss=0.044463301387925945\n",
      "test_test\n",
      "test mean loss=1157.463623046875\n",
      "epoch 9656\n",
      "test_train\n",
      "train mean loss=0.050196606355408825\n",
      "test_test\n",
      "test mean loss=1158.626953125\n",
      "epoch 9657\n",
      "test_train\n",
      "train mean loss=0.04775417409837246\n",
      "test_test\n",
      "test mean loss=1158.4351196289062\n",
      "epoch 9658\n",
      "test_train\n",
      "train mean loss=0.04569207892442743\n",
      "test_test\n",
      "test mean loss=1158.4924011230469\n",
      "epoch 9659\n",
      "test_train\n",
      "train mean loss=0.04905699364220103\n",
      "test_test\n",
      "test mean loss=1157.91455078125\n",
      "epoch 9660\n",
      "test_train\n",
      "train mean loss=0.046103726141154766\n",
      "test_test\n",
      "test mean loss=1157.8378295898438\n",
      "epoch 9661\n",
      "test_train\n",
      "train mean loss=0.04424446184809009\n",
      "test_test\n",
      "test mean loss=1158.0179443359375\n",
      "epoch 9662\n",
      "test_train\n",
      "train mean loss=0.05062933266162872\n",
      "test_test\n",
      "test mean loss=1157.61279296875\n",
      "epoch 9663\n",
      "test_train\n",
      "train mean loss=0.056936425467332206\n",
      "test_test\n",
      "test mean loss=1158.0698852539062\n",
      "epoch 9664\n",
      "test_train\n",
      "train mean loss=0.047102936853965126\n",
      "test_test\n",
      "test mean loss=1158.2726135253906\n",
      "epoch 9665\n",
      "test_train\n",
      "train mean loss=0.04482997783149282\n",
      "test_test\n",
      "test mean loss=1157.7361755371094\n",
      "epoch 9666\n",
      "test_train\n",
      "train mean loss=0.04723716496179501\n",
      "test_test\n",
      "test mean loss=1158.0476379394531\n",
      "epoch 9667\n",
      "test_train\n",
      "train mean loss=0.042351745845129095\n",
      "test_test\n",
      "test mean loss=1157.8394775390625\n",
      "epoch 9668\n",
      "test_train\n",
      "train mean loss=0.04641228215768933\n",
      "test_test\n",
      "test mean loss=1158.8110656738281\n",
      "epoch 9669\n",
      "test_train\n",
      "train mean loss=0.044930846275140844\n",
      "test_test\n",
      "test mean loss=1158.0408020019531\n",
      "epoch 9670\n",
      "test_train\n",
      "train mean loss=0.043062783777713776\n",
      "test_test\n",
      "test mean loss=1158.3060302734375\n",
      "epoch 9671\n",
      "test_train\n",
      "train mean loss=0.04967371684809526\n",
      "test_test\n",
      "test mean loss=1158.4089660644531\n",
      "epoch 9672\n",
      "test_train\n",
      "train mean loss=0.04896056558936834\n",
      "test_test\n",
      "test mean loss=1157.9886474609375\n",
      "epoch 9673\n",
      "test_train\n",
      "train mean loss=0.04900357546284795\n",
      "test_test\n",
      "test mean loss=1158.3627319335938\n",
      "epoch 9674\n",
      "test_train\n",
      "train mean loss=0.044856188197930656\n",
      "test_test\n",
      "test mean loss=1158.5878601074219\n",
      "epoch 9675\n",
      "test_train\n",
      "train mean loss=0.04748491679007808\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1157.9049682617188\n",
      "epoch 9676\n",
      "test_train\n",
      "train mean loss=0.047956557944417\n",
      "test_test\n",
      "test mean loss=1158.4310913085938\n",
      "epoch 9677\n",
      "test_train\n",
      "train mean loss=0.0486623952165246\n",
      "test_test\n",
      "test mean loss=1157.6912841796875\n",
      "epoch 9678\n",
      "test_train\n",
      "train mean loss=0.043933811907966934\n",
      "test_test\n",
      "test mean loss=1157.8699340820312\n",
      "epoch 9679\n",
      "test_train\n",
      "train mean loss=0.04202677573387822\n",
      "test_test\n",
      "test mean loss=1158.2280883789062\n",
      "epoch 9680\n",
      "test_train\n",
      "train mean loss=0.04437644065668186\n",
      "test_test\n",
      "test mean loss=1157.948974609375\n",
      "epoch 9681\n",
      "test_train\n",
      "train mean loss=0.05384313780814409\n",
      "test_test\n",
      "test mean loss=1159.2273864746094\n",
      "epoch 9682\n",
      "test_train\n",
      "train mean loss=0.04897383057201902\n",
      "test_test\n",
      "test mean loss=1159.8484497070312\n",
      "epoch 9683\n",
      "test_train\n",
      "train mean loss=0.04652159304047624\n",
      "test_test\n",
      "test mean loss=1158.7344970703125\n",
      "epoch 9684\n",
      "test_train\n",
      "train mean loss=0.045811346576859556\n",
      "test_test\n",
      "test mean loss=1158.5496826171875\n",
      "epoch 9685\n",
      "test_train\n",
      "train mean loss=0.04608821248014768\n",
      "test_test\n",
      "test mean loss=1159.2240905761719\n",
      "epoch 9686\n",
      "test_train\n",
      "train mean loss=0.13729288056492805\n",
      "test_test\n",
      "test mean loss=1160.8057556152344\n",
      "epoch 9687\n",
      "test_train\n",
      "train mean loss=0.05023652253051599\n",
      "test_test\n",
      "test mean loss=1158.513671875\n",
      "epoch 9688\n",
      "test_train\n",
      "train mean loss=0.047158902355780206\n",
      "test_test\n",
      "test mean loss=1158.88232421875\n",
      "epoch 9689\n",
      "test_train\n",
      "train mean loss=0.048820139995465674\n",
      "test_test\n",
      "test mean loss=1159.9215698242188\n",
      "epoch 9690\n",
      "test_train\n",
      "train mean loss=0.05086955257381002\n",
      "test_test\n",
      "test mean loss=1158.5659790039062\n",
      "epoch 9691\n",
      "test_train\n",
      "train mean loss=0.04735296995689472\n",
      "test_test\n",
      "test mean loss=1158.612548828125\n",
      "epoch 9692\n",
      "test_train\n",
      "train mean loss=0.045884953190883\n",
      "test_test\n",
      "test mean loss=1159.2070007324219\n",
      "epoch 9693\n",
      "test_train\n",
      "train mean loss=0.048086307011544704\n",
      "test_test\n",
      "test mean loss=1158.3087158203125\n",
      "epoch 9694\n",
      "test_train\n",
      "train mean loss=0.04507573880255222\n",
      "test_test\n",
      "test mean loss=1157.8850708007812\n",
      "epoch 9695\n",
      "test_train\n",
      "train mean loss=0.048715888522565365\n",
      "test_test\n",
      "test mean loss=1158.09033203125\n",
      "epoch 9696\n",
      "test_train\n",
      "train mean loss=0.044546961629142366\n",
      "test_test\n",
      "test mean loss=1157.771484375\n",
      "epoch 9697\n",
      "test_train\n",
      "train mean loss=0.0478099932273229\n",
      "test_test\n",
      "test mean loss=1158.29931640625\n",
      "epoch 9698\n",
      "test_train\n",
      "train mean loss=0.05065039498731494\n",
      "test_test\n",
      "test mean loss=1158.9666748046875\n",
      "epoch 9699\n",
      "test_train\n",
      "train mean loss=0.04619937219346563\n",
      "test_test\n",
      "test mean loss=1158.6922607421875\n",
      "epoch 9700\n",
      "test_train\n",
      "train mean loss=0.04575028006608287\n",
      "test_test\n",
      "test mean loss=1159.1308898925781\n",
      "epoch 9701\n",
      "test_train\n",
      "train mean loss=0.048057899034271635\n",
      "test_test\n",
      "test mean loss=1158.7401428222656\n",
      "epoch 9702\n",
      "test_train\n",
      "train mean loss=0.054511042311787605\n",
      "test_test\n",
      "test mean loss=1158.2413940429688\n",
      "epoch 9703\n",
      "test_train\n",
      "train mean loss=0.048294431840380035\n",
      "test_test\n",
      "test mean loss=1158.2752685546875\n",
      "epoch 9704\n",
      "test_train\n",
      "train mean loss=0.04916589163864652\n",
      "test_test\n",
      "test mean loss=1159.6721496582031\n",
      "epoch 9705\n",
      "test_train\n",
      "train mean loss=0.0523553000142177\n",
      "test_test\n",
      "test mean loss=1160.1281127929688\n",
      "epoch 9706\n",
      "test_train\n",
      "train mean loss=0.05693961369494597\n",
      "test_test\n",
      "test mean loss=1160.2188110351562\n",
      "epoch 9707\n",
      "test_train\n",
      "train mean loss=0.050389548453191914\n",
      "test_test\n",
      "test mean loss=1158.9277954101562\n",
      "epoch 9708\n",
      "test_train\n",
      "train mean loss=0.04441203052798907\n",
      "test_test\n",
      "test mean loss=1159.8627624511719\n",
      "epoch 9709\n",
      "test_train\n",
      "train mean loss=0.04467879235744476\n",
      "test_test\n",
      "test mean loss=1158.866943359375\n",
      "epoch 9710\n",
      "test_train\n",
      "train mean loss=0.04991802293807268\n",
      "test_test\n",
      "test mean loss=1159.6620483398438\n",
      "epoch 9711\n",
      "test_train\n",
      "train mean loss=0.05206902325153351\n",
      "test_test\n",
      "test mean loss=1160.2071533203125\n",
      "epoch 9712\n",
      "test_train\n",
      "train mean loss=0.04691552401830753\n",
      "test_test\n",
      "test mean loss=1159.4077758789062\n",
      "epoch 9713\n",
      "test_train\n",
      "train mean loss=0.04814715916290879\n",
      "test_test\n",
      "test mean loss=1159.70654296875\n",
      "epoch 9714\n",
      "test_train\n",
      "train mean loss=0.04488349317883452\n",
      "test_test\n",
      "test mean loss=1159.7039794921875\n",
      "epoch 9715\n",
      "test_train\n",
      "train mean loss=0.04747263963023821\n",
      "test_test\n",
      "test mean loss=1159.4124145507812\n",
      "epoch 9716\n",
      "test_train\n",
      "train mean loss=0.04515617014840245\n",
      "test_test\n",
      "test mean loss=1159.4375\n",
      "epoch 9717\n",
      "test_train\n",
      "train mean loss=0.045357244865347944\n",
      "test_test\n",
      "test mean loss=1158.5804443359375\n",
      "epoch 9718\n",
      "test_train\n",
      "train mean loss=0.04477113081763188\n",
      "test_test\n",
      "test mean loss=1159.3368530273438\n",
      "epoch 9719\n",
      "test_train\n",
      "train mean loss=0.0430235726137956\n",
      "test_test\n",
      "test mean loss=1158.3873291015625\n",
      "epoch 9720\n",
      "test_train\n",
      "train mean loss=0.04823063469181458\n",
      "test_test\n",
      "test mean loss=1159.4954528808594\n",
      "epoch 9721\n",
      "test_train\n",
      "train mean loss=0.04438255354762077\n",
      "test_test\n",
      "test mean loss=1159.1336669921875\n",
      "epoch 9722\n",
      "test_train\n",
      "train mean loss=0.04929350192348162\n",
      "test_test\n",
      "test mean loss=1158.9698791503906\n",
      "epoch 9723\n",
      "test_train\n",
      "train mean loss=0.04614884313195944\n",
      "test_test\n",
      "test mean loss=1158.9164733886719\n",
      "epoch 9724\n",
      "test_train\n",
      "train mean loss=0.04082588308180372\n",
      "test_test\n",
      "test mean loss=1158.8265380859375\n",
      "epoch 9725\n",
      "test_train\n",
      "train mean loss=0.04431377723813057\n",
      "test_test\n",
      "test mean loss=1159.3438720703125\n",
      "epoch 9726\n",
      "test_train\n",
      "train mean loss=0.05008600807438294\n",
      "test_test\n",
      "test mean loss=1159.5541381835938\n",
      "epoch 9727\n",
      "test_train\n",
      "train mean loss=0.04343021040161451\n",
      "test_test\n",
      "test mean loss=1159.1428527832031\n",
      "epoch 9728\n",
      "test_train\n",
      "train mean loss=0.04512495485444864\n",
      "test_test\n",
      "test mean loss=1159.164306640625\n",
      "epoch 9729\n",
      "test_train\n",
      "train mean loss=0.04820881846050421\n",
      "test_test\n",
      "test mean loss=1158.9919128417969\n",
      "epoch 9730\n",
      "test_train\n",
      "train mean loss=0.04261622733126084\n",
      "test_test\n",
      "test mean loss=1158.9374389648438\n",
      "epoch 9731\n",
      "test_train\n",
      "train mean loss=0.045876300893723965\n",
      "test_test\n",
      "test mean loss=1158.534423828125\n",
      "epoch 9732\n",
      "test_train\n",
      "train mean loss=0.0493266706665357\n",
      "test_test\n",
      "test mean loss=1159.03564453125\n",
      "epoch 9733\n",
      "test_train\n",
      "train mean loss=0.050685216983159385\n",
      "test_test\n",
      "test mean loss=1158.9689025878906\n",
      "epoch 9734\n",
      "test_train\n",
      "train mean loss=0.227111225326856\n",
      "test_test\n",
      "test mean loss=1156.1903076171875\n",
      "epoch 9735\n",
      "test_train\n",
      "train mean loss=0.04630678566172719\n",
      "test_test\n",
      "test mean loss=1158.4006042480469\n",
      "epoch 9736\n",
      "test_train\n",
      "train mean loss=0.04604947908471028\n",
      "test_test\n",
      "test mean loss=1159.841796875\n",
      "epoch 9737\n",
      "test_train\n",
      "train mean loss=0.04979005083441734\n",
      "test_test\n",
      "test mean loss=1160.3927307128906\n",
      "epoch 9738\n",
      "test_train\n",
      "train mean loss=0.044452426955103874\n",
      "test_test\n",
      "test mean loss=1158.3608703613281\n",
      "epoch 9739\n",
      "test_train\n",
      "train mean loss=0.050418719494094454\n",
      "test_test\n",
      "test mean loss=1159.8753051757812\n",
      "epoch 9740\n",
      "test_train\n",
      "train mean loss=0.041222961619496346\n",
      "test_test\n",
      "test mean loss=1158.8340454101562\n",
      "epoch 9741\n",
      "test_train\n",
      "train mean loss=0.04743079390997688\n",
      "test_test\n",
      "test mean loss=1159.7462768554688\n",
      "epoch 9742\n",
      "test_train\n",
      "train mean loss=0.04858930595219135\n",
      "test_test\n",
      "test mean loss=1158.9950561523438\n",
      "epoch 9743\n",
      "test_train\n",
      "train mean loss=0.05862048640847206\n",
      "test_test\n",
      "test mean loss=1160.2001037597656\n",
      "epoch 9744\n",
      "test_train\n",
      "train mean loss=0.0510156435581545\n",
      "test_test\n",
      "test mean loss=1159.0895690917969\n",
      "epoch 9745\n",
      "test_train\n",
      "train mean loss=0.045706823778649174\n",
      "test_test\n",
      "test mean loss=1158.7879028320312\n",
      "epoch 9746\n",
      "test_train\n",
      "train mean loss=0.046724480111151934\n",
      "test_test\n",
      "test mean loss=1158.47509765625\n",
      "epoch 9747\n",
      "test_train\n",
      "train mean loss=0.045568174216896296\n",
      "test_test\n",
      "test mean loss=1158.4520874023438\n",
      "epoch 9748\n",
      "test_train\n",
      "train mean loss=0.04965646751224995\n",
      "test_test\n",
      "test mean loss=1159.88330078125\n",
      "epoch 9749\n",
      "test_train\n",
      "train mean loss=2.1691854695479074\n",
      "test_test\n",
      "test mean loss=1151.4147338867188\n",
      "epoch 9750\n",
      "test_train\n",
      "train mean loss=0.06276779032001893\n",
      "test_test\n",
      "test mean loss=1160.576904296875\n",
      "epoch 9751\n",
      "test_train\n",
      "train mean loss=0.05428360775113106\n",
      "test_test\n",
      "test mean loss=1163.1300354003906\n",
      "epoch 9752\n",
      "test_train\n",
      "train mean loss=0.06108265897879998\n",
      "test_test\n",
      "test mean loss=1161.7623596191406\n",
      "epoch 9753\n",
      "test_train\n",
      "train mean loss=0.04847930604591966\n",
      "test_test\n",
      "test mean loss=1161.5659790039062\n",
      "epoch 9754\n",
      "test_train\n",
      "train mean loss=0.05148699848602215\n",
      "test_test\n",
      "test mean loss=1161.9469604492188\n",
      "epoch 9755\n",
      "test_train\n",
      "train mean loss=0.05275600776076317\n",
      "test_test\n",
      "test mean loss=1162.1582946777344\n",
      "epoch 9756\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.04779729153960943\n",
      "test_test\n",
      "test mean loss=1161.7343139648438\n",
      "epoch 9757\n",
      "test_train\n",
      "train mean loss=0.05300019836674134\n",
      "test_test\n",
      "test mean loss=1160.943359375\n",
      "epoch 9758\n",
      "test_train\n",
      "train mean loss=0.055434162418047585\n",
      "test_test\n",
      "test mean loss=1161.6725463867188\n",
      "epoch 9759\n",
      "test_train\n",
      "train mean loss=0.050691531815876566\n",
      "test_test\n",
      "test mean loss=1161.4498596191406\n",
      "epoch 9760\n",
      "test_train\n",
      "train mean loss=0.05729077197611332\n",
      "test_test\n",
      "test mean loss=1160.0130615234375\n",
      "epoch 9761\n",
      "test_train\n",
      "train mean loss=0.047312427001694836\n",
      "test_test\n",
      "test mean loss=1160.0068359375\n",
      "epoch 9762\n",
      "test_train\n",
      "train mean loss=0.09779652891059716\n",
      "test_test\n",
      "test mean loss=1159.4977722167969\n",
      "epoch 9763\n",
      "test_train\n",
      "train mean loss=0.049166073091328144\n",
      "test_test\n",
      "test mean loss=1161.5719299316406\n",
      "epoch 9764\n",
      "test_train\n",
      "train mean loss=0.10343483400841554\n",
      "test_test\n",
      "test mean loss=1158.5999450683594\n",
      "epoch 9765\n",
      "test_train\n",
      "train mean loss=0.04950035146127144\n",
      "test_test\n",
      "test mean loss=1160.7495727539062\n",
      "epoch 9766\n",
      "test_train\n",
      "train mean loss=0.047192320227622986\n",
      "test_test\n",
      "test mean loss=1161.624755859375\n",
      "epoch 9767\n",
      "test_train\n",
      "train mean loss=0.04589140570412079\n",
      "test_test\n",
      "test mean loss=1161.6259155273438\n",
      "epoch 9768\n",
      "test_train\n",
      "train mean loss=0.058078380301594734\n",
      "test_test\n",
      "test mean loss=1161.4389953613281\n",
      "epoch 9769\n",
      "test_train\n",
      "train mean loss=48.52189829945564\n",
      "test_test\n",
      "test mean loss=1156.7158203125\n",
      "epoch 9770\n",
      "test_train\n",
      "train mean loss=0.04804705254112681\n",
      "test_test\n",
      "test mean loss=1160.9180908203125\n",
      "epoch 9771\n",
      "test_train\n",
      "train mean loss=0.08082899575432141\n",
      "test_test\n",
      "test mean loss=1162.8017578125\n",
      "epoch 9772\n",
      "test_train\n",
      "train mean loss=0.053541986271739006\n",
      "test_test\n",
      "test mean loss=1162.1971435546875\n",
      "epoch 9773\n",
      "test_train\n",
      "train mean loss=0.0546076005945603\n",
      "test_test\n",
      "test mean loss=1161.693603515625\n",
      "epoch 9774\n",
      "test_train\n",
      "train mean loss=0.05500976058344046\n",
      "test_test\n",
      "test mean loss=1161.7678833007812\n",
      "epoch 9775\n",
      "test_train\n",
      "train mean loss=0.0491204964928329\n",
      "test_test\n",
      "test mean loss=1161.1080322265625\n",
      "epoch 9776\n",
      "test_train\n",
      "train mean loss=0.07210318185389042\n",
      "test_test\n",
      "test mean loss=1161.4134216308594\n",
      "epoch 9777\n",
      "test_train\n",
      "train mean loss=0.05260646529495716\n",
      "test_test\n",
      "test mean loss=1160.96533203125\n",
      "epoch 9778\n",
      "test_train\n",
      "train mean loss=0.05137882940471172\n",
      "test_test\n",
      "test mean loss=1161.5798645019531\n",
      "epoch 9779\n",
      "test_train\n",
      "train mean loss=0.05976490800579389\n",
      "test_test\n",
      "test mean loss=1162.2199401855469\n",
      "epoch 9780\n",
      "test_train\n",
      "train mean loss=0.05189239947746197\n",
      "test_test\n",
      "test mean loss=1162.594482421875\n",
      "epoch 9781\n",
      "test_train\n",
      "train mean loss=0.053162481946249805\n",
      "test_test\n",
      "test mean loss=1161.0435485839844\n",
      "epoch 9782\n",
      "test_train\n",
      "train mean loss=0.05453732547660669\n",
      "test_test\n",
      "test mean loss=1160.8253479003906\n",
      "epoch 9783\n",
      "test_train\n",
      "train mean loss=0.05600349853436152\n",
      "test_test\n",
      "test mean loss=1160.3395080566406\n",
      "epoch 9784\n",
      "test_train\n",
      "train mean loss=0.05257865134626627\n",
      "test_test\n",
      "test mean loss=1160.9964294433594\n",
      "epoch 9785\n",
      "test_train\n",
      "train mean loss=0.054436310194432735\n",
      "test_test\n",
      "test mean loss=1159.5541687011719\n",
      "epoch 9786\n",
      "test_train\n",
      "train mean loss=0.050704415421932936\n",
      "test_test\n",
      "test mean loss=1159.6077880859375\n",
      "epoch 9787\n",
      "test_train\n",
      "train mean loss=0.056624456929663815\n",
      "test_test\n",
      "test mean loss=1160.6998901367188\n",
      "epoch 9788\n",
      "test_train\n",
      "train mean loss=0.051990846482415996\n",
      "test_test\n",
      "test mean loss=1159.8705444335938\n",
      "epoch 9789\n",
      "test_train\n",
      "train mean loss=0.04794061494370302\n",
      "test_test\n",
      "test mean loss=1159.2494812011719\n",
      "epoch 9790\n",
      "test_train\n",
      "train mean loss=0.05175407168765863\n",
      "test_test\n",
      "test mean loss=1158.7982788085938\n",
      "epoch 9791\n",
      "test_train\n",
      "train mean loss=0.04934496742983659\n",
      "test_test\n",
      "test mean loss=1160.6533203125\n",
      "epoch 9792\n",
      "test_train\n",
      "train mean loss=0.0446192134792606\n",
      "test_test\n",
      "test mean loss=1159.0477905273438\n",
      "epoch 9793\n",
      "test_train\n",
      "train mean loss=0.04970249657829603\n",
      "test_test\n",
      "test mean loss=1160.4788818359375\n",
      "epoch 9794\n",
      "test_train\n",
      "train mean loss=0.046928937236467995\n",
      "test_test\n",
      "test mean loss=1159.5208129882812\n",
      "epoch 9795\n",
      "test_train\n",
      "train mean loss=0.046073719238241516\n",
      "test_test\n",
      "test mean loss=1160.1934814453125\n",
      "epoch 9796\n",
      "test_train\n",
      "train mean loss=0.046203718055039644\n",
      "test_test\n",
      "test mean loss=1158.8523559570312\n",
      "epoch 9797\n",
      "test_train\n",
      "train mean loss=0.049221717907736696\n",
      "test_test\n",
      "test mean loss=1159.6672973632812\n",
      "epoch 9798\n",
      "test_train\n",
      "train mean loss=0.044450832375635706\n",
      "test_test\n",
      "test mean loss=1158.8752136230469\n",
      "epoch 9799\n",
      "test_train\n",
      "train mean loss=0.049612767063081264\n",
      "test_test\n",
      "test mean loss=1160.0047302246094\n",
      "epoch 9800\n",
      "test_train\n",
      "train mean loss=0.047796804923564196\n",
      "test_test\n",
      "test mean loss=1159.2490539550781\n",
      "epoch 9801\n",
      "test_train\n",
      "train mean loss=0.04379135416820645\n",
      "test_test\n",
      "test mean loss=1160.65673828125\n",
      "epoch 9802\n",
      "test_train\n",
      "train mean loss=0.04965941980481148\n",
      "test_test\n",
      "test mean loss=1160.4930419921875\n",
      "epoch 9803\n",
      "test_train\n",
      "train mean loss=0.044328972697257996\n",
      "test_test\n",
      "test mean loss=1160.0032348632812\n",
      "epoch 9804\n",
      "test_train\n",
      "train mean loss=0.047520874378581844\n",
      "test_test\n",
      "test mean loss=1160.6713256835938\n",
      "epoch 9805\n",
      "test_train\n",
      "train mean loss=0.05473754027237495\n",
      "test_test\n",
      "test mean loss=1160.5806274414062\n",
      "epoch 9806\n",
      "test_train\n",
      "train mean loss=0.046258809665838875\n",
      "test_test\n",
      "test mean loss=1159.7396240234375\n",
      "epoch 9807\n",
      "test_train\n",
      "train mean loss=0.05349623256673416\n",
      "test_test\n",
      "test mean loss=1160.1985473632812\n",
      "epoch 9808\n",
      "test_train\n",
      "train mean loss=0.04747796834756931\n",
      "test_test\n",
      "test mean loss=1160.291748046875\n",
      "epoch 9809\n",
      "test_train\n",
      "train mean loss=0.057697893430789314\n",
      "test_test\n",
      "test mean loss=1161.2498168945312\n",
      "epoch 9810\n",
      "test_train\n",
      "train mean loss=0.0525408120205005\n",
      "test_test\n",
      "test mean loss=1160.0706176757812\n",
      "epoch 9811\n",
      "test_train\n",
      "train mean loss=0.04802995175123215\n",
      "test_test\n",
      "test mean loss=1159.6821899414062\n",
      "epoch 9812\n",
      "test_train\n",
      "train mean loss=0.04401281693329414\n",
      "test_test\n",
      "test mean loss=1160.3092651367188\n",
      "epoch 9813\n",
      "test_train\n",
      "train mean loss=0.04288258543238044\n",
      "test_test\n",
      "test mean loss=1159.5202026367188\n",
      "epoch 9814\n",
      "test_train\n",
      "train mean loss=0.05121809523552656\n",
      "test_test\n",
      "test mean loss=1160.43505859375\n",
      "epoch 9815\n",
      "test_train\n",
      "train mean loss=0.049449486347536244\n",
      "test_test\n",
      "test mean loss=1158.9398193359375\n",
      "epoch 9816\n",
      "test_train\n",
      "train mean loss=0.04873117059469223\n",
      "test_test\n",
      "test mean loss=1160.1063537597656\n",
      "epoch 9817\n",
      "test_train\n",
      "train mean loss=0.04730461987977227\n",
      "test_test\n",
      "test mean loss=1160.48828125\n",
      "epoch 9818\n",
      "test_train\n",
      "train mean loss=0.04251743868614236\n",
      "test_test\n",
      "test mean loss=1160.325927734375\n",
      "epoch 9819\n",
      "test_train\n",
      "train mean loss=0.0474572873984774\n",
      "test_test\n",
      "test mean loss=1160.3823852539062\n",
      "epoch 9820\n",
      "test_train\n",
      "train mean loss=0.0474270839865009\n",
      "test_test\n",
      "test mean loss=1160.1392822265625\n",
      "epoch 9821\n",
      "test_train\n",
      "train mean loss=0.04633902572095394\n",
      "test_test\n",
      "test mean loss=1159.9458618164062\n",
      "epoch 9822\n",
      "test_train\n",
      "train mean loss=0.046561439211169876\n",
      "test_test\n",
      "test mean loss=1160.23779296875\n",
      "epoch 9823\n",
      "test_train\n",
      "train mean loss=0.04496686781446139\n",
      "test_test\n",
      "test mean loss=1159.9226684570312\n",
      "epoch 9824\n",
      "test_train\n",
      "train mean loss=0.04471480924015244\n",
      "test_test\n",
      "test mean loss=1159.5330810546875\n",
      "epoch 9825\n",
      "test_train\n",
      "train mean loss=0.05013287222633759\n",
      "test_test\n",
      "test mean loss=1160.4984130859375\n",
      "epoch 9826\n",
      "test_train\n",
      "train mean loss=0.04251198129107555\n",
      "test_test\n",
      "test mean loss=1159.898681640625\n",
      "epoch 9827\n",
      "test_train\n",
      "train mean loss=0.04408041170487801\n",
      "test_test\n",
      "test mean loss=1159.2019653320312\n",
      "epoch 9828\n",
      "test_train\n",
      "train mean loss=0.05440613984440764\n",
      "test_test\n",
      "test mean loss=1161.0540771484375\n",
      "epoch 9829\n",
      "test_train\n",
      "train mean loss=0.04729235048095385\n",
      "test_test\n",
      "test mean loss=1160.329345703125\n",
      "epoch 9830\n",
      "test_train\n",
      "train mean loss=0.049613434821367264\n",
      "test_test\n",
      "test mean loss=1159.8380432128906\n",
      "epoch 9831\n",
      "test_train\n",
      "train mean loss=0.05101161419103543\n",
      "test_test\n",
      "test mean loss=1159.9212036132812\n",
      "epoch 9832\n",
      "test_train\n",
      "train mean loss=0.05038526343802611\n",
      "test_test\n",
      "test mean loss=1160.3037109375\n",
      "epoch 9833\n",
      "test_train\n",
      "train mean loss=0.057195201981812716\n",
      "test_test\n",
      "test mean loss=1158.1524658203125\n",
      "epoch 9834\n",
      "test_train\n",
      "train mean loss=0.05115972521404425\n",
      "test_test\n",
      "test mean loss=1159.2406005859375\n",
      "epoch 9835\n",
      "test_train\n",
      "train mean loss=0.06676911003887653\n",
      "test_test\n",
      "test mean loss=1157.7653198242188\n",
      "epoch 9836\n",
      "test_train\n",
      "train mean loss=0.05480969324707985\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=1160.7830505371094\n",
      "epoch 9837\n",
      "test_train\n",
      "train mean loss=0.04541710903868079\n",
      "test_test\n",
      "test mean loss=1159.6116638183594\n",
      "epoch 9838\n",
      "test_train\n",
      "train mean loss=0.04878523852676153\n",
      "test_test\n",
      "test mean loss=1160.3896484375\n",
      "epoch 9839\n",
      "test_train\n",
      "train mean loss=0.04623609439780315\n",
      "test_test\n",
      "test mean loss=1160.6914367675781\n",
      "epoch 9840\n",
      "test_train\n",
      "train mean loss=0.05116301386927565\n",
      "test_test\n",
      "test mean loss=1160.1677856445312\n",
      "epoch 9841\n",
      "test_train\n",
      "train mean loss=0.04779066704213619\n",
      "test_test\n",
      "test mean loss=1159.0610046386719\n",
      "epoch 9842\n",
      "test_train\n",
      "train mean loss=0.05796470989783605\n",
      "test_test\n",
      "test mean loss=1158.2639770507812\n",
      "epoch 9843\n",
      "test_train\n",
      "train mean loss=0.048504069137076535\n",
      "test_test\n",
      "test mean loss=1158.8583984375\n",
      "epoch 9844\n",
      "test_train\n",
      "train mean loss=0.045741723384708166\n",
      "test_test\n",
      "test mean loss=1160.5044860839844\n",
      "epoch 9845\n",
      "test_train\n",
      "train mean loss=0.053011506951103606\n",
      "test_test\n",
      "test mean loss=1161.14111328125\n",
      "epoch 9846\n",
      "test_train\n",
      "train mean loss=0.05680793942883611\n",
      "test_test\n",
      "test mean loss=1160.2244262695312\n",
      "epoch 9847\n",
      "test_train\n",
      "train mean loss=0.04828128544613719\n",
      "test_test\n",
      "test mean loss=1159.2014770507812\n",
      "epoch 9848\n",
      "test_train\n",
      "train mean loss=0.04493254500751694\n",
      "test_test\n",
      "test mean loss=1159.6891479492188\n",
      "epoch 9849\n",
      "test_train\n",
      "train mean loss=0.04678227053955197\n",
      "test_test\n",
      "test mean loss=1160.2561950683594\n",
      "epoch 9850\n",
      "test_train\n",
      "train mean loss=0.04857183061540127\n",
      "test_test\n",
      "test mean loss=1160.6793212890625\n",
      "epoch 9851\n",
      "test_train\n",
      "train mean loss=0.0706768484475712\n",
      "test_test\n",
      "test mean loss=1162.3400268554688\n",
      "epoch 9852\n",
      "test_train\n",
      "train mean loss=0.051019737807412945\n",
      "test_test\n",
      "test mean loss=1161.2324523925781\n",
      "epoch 9853\n",
      "test_train\n",
      "train mean loss=0.05244718429942926\n",
      "test_test\n",
      "test mean loss=1159.9254150390625\n",
      "epoch 9854\n",
      "test_train\n",
      "train mean loss=0.04623512846107284\n",
      "test_test\n",
      "test mean loss=1159.6914672851562\n",
      "epoch 9855\n",
      "test_train\n",
      "train mean loss=0.04253225649396578\n",
      "test_test\n",
      "test mean loss=1157.7589416503906\n",
      "epoch 9856\n",
      "test_train\n",
      "train mean loss=0.044536009430885315\n",
      "test_test\n",
      "test mean loss=1159.5091552734375\n",
      "epoch 9857\n",
      "test_train\n",
      "train mean loss=0.04841832506159941\n",
      "test_test\n",
      "test mean loss=1159.9235229492188\n",
      "epoch 9858\n",
      "test_train\n",
      "train mean loss=0.04965827877943715\n",
      "test_test\n",
      "test mean loss=1160.1559448242188\n",
      "epoch 9859\n",
      "test_train\n",
      "train mean loss=0.055306095319489636\n",
      "test_test\n",
      "test mean loss=1160.3170776367188\n",
      "epoch 9860\n",
      "test_train\n",
      "train mean loss=0.044175219256430864\n",
      "test_test\n",
      "test mean loss=1158.8826293945312\n",
      "epoch 9861\n",
      "test_train\n",
      "train mean loss=0.04502609030654033\n",
      "test_test\n",
      "test mean loss=1159.3268432617188\n",
      "epoch 9862\n",
      "test_train\n",
      "train mean loss=0.04513227737819155\n",
      "test_test\n",
      "test mean loss=1158.6033020019531\n",
      "epoch 9863\n",
      "test_train\n",
      "train mean loss=0.045906036626547575\n",
      "test_test\n",
      "test mean loss=1158.6250915527344\n",
      "epoch 9864\n",
      "test_train\n",
      "train mean loss=0.05253455229103565\n",
      "test_test\n",
      "test mean loss=1160.4963073730469\n",
      "epoch 9865\n",
      "test_train\n",
      "train mean loss=0.050262921024113894\n",
      "test_test\n",
      "test mean loss=1160.0390319824219\n",
      "epoch 9866\n",
      "test_train\n",
      "train mean loss=0.041403244559963547\n",
      "test_test\n",
      "test mean loss=1159.9358520507812\n",
      "epoch 9867\n",
      "test_train\n",
      "train mean loss=0.046811724392076336\n",
      "test_test\n",
      "test mean loss=1159.269287109375\n",
      "epoch 9868\n",
      "test_train\n",
      "train mean loss=0.04375468877454599\n",
      "test_test\n",
      "test mean loss=1159.1052856445312\n",
      "epoch 9869\n",
      "test_train\n",
      "train mean loss=0.0539866058776776\n",
      "test_test\n",
      "test mean loss=1159.0318603515625\n",
      "epoch 9870\n",
      "test_train\n",
      "train mean loss=0.043145847506821156\n",
      "test_test\n",
      "test mean loss=1158.7720031738281\n",
      "epoch 9871\n",
      "test_train\n",
      "train mean loss=0.053726994122068085\n",
      "test_test\n",
      "test mean loss=1159.3739624023438\n",
      "epoch 9872\n",
      "test_train\n",
      "train mean loss=0.056581330951303244\n",
      "test_test\n",
      "test mean loss=1159.8156127929688\n",
      "epoch 9873\n",
      "test_train\n",
      "train mean loss=0.05281326655919353\n",
      "test_test\n",
      "test mean loss=1160.2332763671875\n",
      "epoch 9874\n",
      "test_train\n",
      "train mean loss=0.0479947238539656\n",
      "test_test\n",
      "test mean loss=1160.0364685058594\n",
      "epoch 9875\n",
      "test_train\n",
      "train mean loss=0.04577454039826989\n",
      "test_test\n",
      "test mean loss=1159.9085083007812\n",
      "epoch 9876\n",
      "test_train\n",
      "train mean loss=0.04723357626547416\n",
      "test_test\n",
      "test mean loss=1159.466552734375\n",
      "epoch 9877\n",
      "test_train\n",
      "train mean loss=0.046381582816441856\n",
      "test_test\n",
      "test mean loss=1159.6826782226562\n",
      "epoch 9878\n",
      "test_train\n",
      "train mean loss=0.04674830939620733\n",
      "test_test\n",
      "test mean loss=1159.0696411132812\n",
      "epoch 9879\n",
      "test_train\n",
      "train mean loss=0.04958152615775665\n",
      "test_test\n",
      "test mean loss=1159.6214294433594\n",
      "epoch 9880\n",
      "test_train\n",
      "train mean loss=0.044773598201572895\n",
      "test_test\n",
      "test mean loss=1159.0198059082031\n",
      "epoch 9881\n",
      "test_train\n",
      "train mean loss=0.04818173125386238\n",
      "test_test\n",
      "test mean loss=1159.3866577148438\n",
      "epoch 9882\n",
      "test_train\n",
      "train mean loss=0.047645018280794225\n",
      "test_test\n",
      "test mean loss=1159.3547058105469\n",
      "epoch 9883\n",
      "test_train\n",
      "train mean loss=0.04798542816812793\n",
      "test_test\n",
      "test mean loss=1159.068115234375\n",
      "epoch 9884\n",
      "test_train\n",
      "train mean loss=0.04666898104672631\n",
      "test_test\n",
      "test mean loss=1158.7640991210938\n",
      "epoch 9885\n",
      "test_train\n",
      "train mean loss=0.046174085699021816\n",
      "test_test\n",
      "test mean loss=1159.9709777832031\n",
      "epoch 9886\n",
      "test_train\n",
      "train mean loss=0.05723465715224544\n",
      "test_test\n",
      "test mean loss=1159.9321899414062\n",
      "epoch 9887\n",
      "test_train\n",
      "train mean loss=0.0473977280780673\n",
      "test_test\n",
      "test mean loss=1158.98046875\n",
      "epoch 9888\n",
      "test_train\n",
      "train mean loss=0.04768606647849083\n",
      "test_test\n",
      "test mean loss=1159.6557006835938\n",
      "epoch 9889\n",
      "test_train\n",
      "train mean loss=0.051007024478167295\n",
      "test_test\n",
      "test mean loss=1159.2955932617188\n",
      "epoch 9890\n",
      "test_train\n",
      "train mean loss=0.04314924372980992\n",
      "test_test\n",
      "test mean loss=1159.501708984375\n",
      "epoch 9891\n",
      "test_train\n",
      "train mean loss=0.057605214727421604\n",
      "test_test\n",
      "test mean loss=1160.0323181152344\n",
      "epoch 9892\n",
      "test_train\n",
      "train mean loss=0.05579392487804095\n",
      "test_test\n",
      "test mean loss=1158.3431396484375\n",
      "epoch 9893\n",
      "test_train\n",
      "train mean loss=0.04824821821724375\n",
      "test_test\n",
      "test mean loss=1159.0177612304688\n",
      "epoch 9894\n",
      "test_train\n",
      "train mean loss=0.04822568750629822\n",
      "test_test\n",
      "test mean loss=1159.7210083007812\n",
      "epoch 9895\n",
      "test_train\n",
      "train mean loss=0.05080694332718849\n",
      "test_test\n",
      "test mean loss=1159.05224609375\n",
      "epoch 9896\n",
      "test_train\n",
      "train mean loss=0.05245488082679609\n",
      "test_test\n",
      "test mean loss=1158.7811279296875\n",
      "epoch 9897\n",
      "test_train\n",
      "train mean loss=0.043363048850248255\n",
      "test_test\n",
      "test mean loss=1158.1031494140625\n",
      "epoch 9898\n",
      "test_train\n",
      "train mean loss=0.04534484352916479\n",
      "test_test\n",
      "test mean loss=1159.3927307128906\n",
      "epoch 9899\n",
      "test_train\n",
      "train mean loss=0.0540677037400504\n",
      "test_test\n",
      "test mean loss=1160.0963439941406\n",
      "epoch 9900\n",
      "test_train\n",
      "train mean loss=0.05004272206375996\n",
      "test_test\n",
      "test mean loss=1159.0776977539062\n",
      "epoch 9901\n",
      "test_train\n",
      "train mean loss=0.05583694111555815\n",
      "test_test\n",
      "test mean loss=1159.7086181640625\n",
      "epoch 9902\n",
      "test_train\n",
      "train mean loss=0.05423119540015856\n",
      "test_test\n",
      "test mean loss=1158.7151489257812\n",
      "epoch 9903\n",
      "test_train\n",
      "train mean loss=0.0588007738503317\n",
      "test_test\n",
      "test mean loss=1159.4069519042969\n",
      "epoch 9904\n",
      "test_train\n",
      "train mean loss=0.0584523289774855\n",
      "test_test\n",
      "test mean loss=1158.1142578125\n",
      "epoch 9905\n",
      "test_train\n",
      "train mean loss=0.043114260925600924\n",
      "test_test\n",
      "test mean loss=1158.3015441894531\n",
      "epoch 9906\n",
      "test_train\n",
      "train mean loss=0.050983890891075134\n",
      "test_test\n",
      "test mean loss=1159.1704711914062\n",
      "epoch 9907\n",
      "test_train\n",
      "train mean loss=0.04688391430924336\n",
      "test_test\n",
      "test mean loss=1158.3002319335938\n",
      "epoch 9908\n",
      "test_train\n",
      "train mean loss=0.047632772785921894\n",
      "test_test\n",
      "test mean loss=1158.3723449707031\n",
      "epoch 9909\n",
      "test_train\n",
      "train mean loss=0.0460952534340322\n",
      "test_test\n",
      "test mean loss=1158.3304748535156\n",
      "epoch 9910\n",
      "test_train\n",
      "train mean loss=0.04832466101894776\n",
      "test_test\n",
      "test mean loss=1159.3832397460938\n",
      "epoch 9911\n",
      "test_train\n",
      "train mean loss=0.046288827899843454\n",
      "test_test\n",
      "test mean loss=1159.3018188476562\n",
      "epoch 9912\n",
      "test_train\n",
      "train mean loss=0.04700545718272527\n",
      "test_test\n",
      "test mean loss=1159.3560180664062\n",
      "epoch 9913\n",
      "test_train\n",
      "train mean loss=0.0489757404041787\n",
      "test_test\n",
      "test mean loss=1159.2782592773438\n",
      "epoch 9914\n",
      "test_train\n",
      "train mean loss=0.05252768161396185\n",
      "test_test\n",
      "test mean loss=1159.6108703613281\n",
      "epoch 9915\n",
      "test_train\n",
      "train mean loss=0.04564754075060288\n",
      "test_test\n",
      "test mean loss=1157.9046630859375\n",
      "epoch 9916\n",
      "test_train\n",
      "train mean loss=0.06176025917132696\n",
      "test_test\n",
      "test mean loss=1160.58349609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9917\n",
      "test_train\n",
      "train mean loss=0.04642792387555043\n",
      "test_test\n",
      "test mean loss=1159.0117492675781\n",
      "epoch 9918\n",
      "test_train\n",
      "train mean loss=0.04175097386663159\n",
      "test_test\n",
      "test mean loss=1158.2481079101562\n",
      "epoch 9919\n",
      "test_train\n",
      "train mean loss=0.04722803613791863\n",
      "test_test\n",
      "test mean loss=1158.0059204101562\n",
      "epoch 9920\n",
      "test_train\n",
      "train mean loss=0.050427519250661135\n",
      "test_test\n",
      "test mean loss=1158.1472778320312\n",
      "epoch 9921\n",
      "test_train\n",
      "train mean loss=0.04501670257498821\n",
      "test_test\n",
      "test mean loss=1159.7566528320312\n",
      "epoch 9922\n",
      "test_train\n",
      "train mean loss=0.05953337469448646\n",
      "test_test\n",
      "test mean loss=1159.2132568359375\n",
      "epoch 9923\n",
      "test_train\n",
      "train mean loss=0.0450558178126812\n",
      "test_test\n",
      "test mean loss=1159.0242919921875\n",
      "epoch 9924\n",
      "test_train\n",
      "train mean loss=0.04101951730748018\n",
      "test_test\n",
      "test mean loss=1159.2632141113281\n",
      "epoch 9925\n",
      "test_train\n",
      "train mean loss=0.04554067629699906\n",
      "test_test\n",
      "test mean loss=1157.8984985351562\n",
      "epoch 9926\n",
      "test_train\n",
      "train mean loss=0.0426259464584291\n",
      "test_test\n",
      "test mean loss=1158.7707824707031\n",
      "epoch 9927\n",
      "test_train\n",
      "train mean loss=0.0476512402916948\n",
      "test_test\n",
      "test mean loss=1158.971435546875\n",
      "epoch 9928\n",
      "test_train\n",
      "train mean loss=0.04579760258396467\n",
      "test_test\n",
      "test mean loss=1158.416748046875\n",
      "epoch 9929\n",
      "test_train\n",
      "train mean loss=0.04909594294925531\n",
      "test_test\n",
      "test mean loss=1158.8218994140625\n",
      "epoch 9930\n",
      "test_train\n",
      "train mean loss=0.051783062517642975\n",
      "test_test\n",
      "test mean loss=1159.0142822265625\n",
      "epoch 9931\n",
      "test_train\n",
      "train mean loss=0.05093977196762959\n",
      "test_test\n",
      "test mean loss=1159.4346923828125\n",
      "epoch 9932\n",
      "test_train\n",
      "train mean loss=0.04582195760061344\n",
      "test_test\n",
      "test mean loss=1159.8614501953125\n",
      "epoch 9933\n",
      "test_train\n",
      "train mean loss=0.04967768924931685\n",
      "test_test\n",
      "test mean loss=1159.6925354003906\n",
      "epoch 9934\n",
      "test_train\n",
      "train mean loss=0.052695189602673054\n",
      "test_test\n",
      "test mean loss=1159.54638671875\n",
      "epoch 9935\n",
      "test_train\n",
      "train mean loss=0.05027781163031856\n",
      "test_test\n",
      "test mean loss=1159.7040405273438\n",
      "epoch 9936\n",
      "test_train\n",
      "train mean loss=0.04489927816515168\n",
      "test_test\n",
      "test mean loss=1159.6814575195312\n",
      "epoch 9937\n",
      "test_train\n",
      "train mean loss=0.04943624402706822\n",
      "test_test\n",
      "test mean loss=1159.420166015625\n",
      "epoch 9938\n",
      "test_train\n",
      "train mean loss=0.050113403548796974\n",
      "test_test\n",
      "test mean loss=1159.86572265625\n",
      "epoch 9939\n",
      "test_train\n",
      "train mean loss=0.04972509170571963\n",
      "test_test\n",
      "test mean loss=1160.4028015136719\n",
      "epoch 9940\n",
      "test_train\n",
      "train mean loss=0.0444344412535429\n",
      "test_test\n",
      "test mean loss=1159.6233520507812\n",
      "epoch 9941\n",
      "test_train\n",
      "train mean loss=0.05519657302647829\n",
      "test_test\n",
      "test mean loss=1159.2651062011719\n",
      "epoch 9942\n",
      "test_train\n",
      "train mean loss=0.0475760872165362\n",
      "test_test\n",
      "test mean loss=1158.635986328125\n",
      "epoch 9943\n",
      "test_train\n",
      "train mean loss=0.04700211497644583\n",
      "test_test\n",
      "test mean loss=1158.1234741210938\n",
      "epoch 9944\n",
      "test_train\n",
      "train mean loss=0.043929340007404484\n",
      "test_test\n",
      "test mean loss=1159.1705932617188\n",
      "epoch 9945\n",
      "test_train\n",
      "train mean loss=0.0504254267240564\n",
      "test_test\n",
      "test mean loss=1160.2490539550781\n",
      "epoch 9946\n",
      "test_train\n",
      "train mean loss=0.05046003917232156\n",
      "test_test\n",
      "test mean loss=1160.2548217773438\n",
      "epoch 9947\n",
      "test_train\n",
      "train mean loss=0.04782703829308351\n",
      "test_test\n",
      "test mean loss=1159.8103637695312\n",
      "epoch 9948\n",
      "test_train\n",
      "train mean loss=0.043583891509721674\n",
      "test_test\n",
      "test mean loss=1159.83544921875\n",
      "epoch 9949\n",
      "test_train\n",
      "train mean loss=0.050725863159944616\n",
      "test_test\n",
      "test mean loss=1159.5333862304688\n",
      "epoch 9950\n",
      "test_train\n",
      "train mean loss=0.05563050384322802\n",
      "test_test\n",
      "test mean loss=1159.9335021972656\n",
      "epoch 9951\n",
      "test_train\n",
      "train mean loss=0.03963765098402897\n",
      "test_test\n",
      "test mean loss=1158.8538818359375\n",
      "epoch 9952\n",
      "test_train\n",
      "train mean loss=0.05002850263069073\n",
      "test_test\n",
      "test mean loss=1159.7086181640625\n",
      "epoch 9953\n",
      "test_train\n",
      "train mean loss=0.04391209284464518\n",
      "test_test\n",
      "test mean loss=1159.3556518554688\n",
      "epoch 9954\n",
      "test_train\n",
      "train mean loss=0.051835449412465096\n",
      "test_test\n",
      "test mean loss=1160.7944946289062\n",
      "epoch 9955\n",
      "test_train\n",
      "train mean loss=0.04909747031827768\n",
      "test_test\n",
      "test mean loss=1160.4890747070312\n",
      "epoch 9956\n",
      "test_train\n",
      "train mean loss=0.05851891419539849\n",
      "test_test\n",
      "test mean loss=1160.7167358398438\n",
      "epoch 9957\n",
      "test_train\n",
      "train mean loss=0.05145809054374695\n",
      "test_test\n",
      "test mean loss=1160.2601318359375\n",
      "epoch 9958\n",
      "test_train\n",
      "train mean loss=0.04622914486875137\n",
      "test_test\n",
      "test mean loss=1159.5951538085938\n",
      "epoch 9959\n",
      "test_train\n",
      "train mean loss=0.0476838294416666\n",
      "test_test\n",
      "test mean loss=1158.6409912109375\n",
      "epoch 9960\n",
      "test_train\n",
      "train mean loss=0.04755151535694798\n",
      "test_test\n",
      "test mean loss=1159.259033203125\n",
      "epoch 9961\n",
      "test_train\n",
      "train mean loss=0.04674625210464001\n",
      "test_test\n",
      "test mean loss=1159.0401000976562\n",
      "epoch 9962\n",
      "test_train\n",
      "train mean loss=0.04752375278621912\n",
      "test_test\n",
      "test mean loss=1159.9863891601562\n",
      "epoch 9963\n",
      "test_train\n",
      "train mean loss=0.05547099622587363\n",
      "test_test\n",
      "test mean loss=1158.6337280273438\n",
      "epoch 9964\n",
      "test_train\n",
      "train mean loss=0.05598679495354494\n",
      "test_test\n",
      "test mean loss=1158.6048583984375\n",
      "epoch 9965\n",
      "test_train\n",
      "train mean loss=0.04783474110687772\n",
      "test_test\n",
      "test mean loss=1159.61572265625\n",
      "epoch 9966\n",
      "test_train\n",
      "train mean loss=0.05274029262363911\n",
      "test_test\n",
      "test mean loss=1160.183837890625\n",
      "epoch 9967\n",
      "test_train\n",
      "train mean loss=0.06213003831605116\n",
      "test_test\n",
      "test mean loss=1158.0326538085938\n",
      "epoch 9968\n",
      "test_train\n",
      "train mean loss=0.048503313368807234\n",
      "test_test\n",
      "test mean loss=1159.3375854492188\n",
      "epoch 9969\n",
      "test_train\n",
      "train mean loss=0.05157504417002201\n",
      "test_test\n",
      "test mean loss=1160.0067138671875\n",
      "epoch 9970\n",
      "test_train\n",
      "train mean loss=0.059805265783021845\n",
      "test_test\n",
      "test mean loss=1160.0264282226562\n",
      "epoch 9971\n",
      "test_train\n",
      "train mean loss=0.052569231328864895\n",
      "test_test\n",
      "test mean loss=1159.5013732910156\n",
      "epoch 9972\n",
      "test_train\n",
      "train mean loss=0.043536778849860035\n",
      "test_test\n",
      "test mean loss=1158.5860290527344\n",
      "epoch 9973\n",
      "test_train\n",
      "train mean loss=0.0505862746698161\n",
      "test_test\n",
      "test mean loss=1160.4194946289062\n",
      "epoch 9974\n",
      "test_train\n",
      "train mean loss=0.047143447833756603\n",
      "test_test\n",
      "test mean loss=1160.05712890625\n",
      "epoch 9975\n",
      "test_train\n",
      "train mean loss=0.044688331273694835\n",
      "test_test\n",
      "test mean loss=1160.1898498535156\n",
      "epoch 9976\n",
      "test_train\n",
      "train mean loss=0.04891821307440599\n",
      "test_test\n",
      "test mean loss=1161.3177795410156\n",
      "epoch 9977\n",
      "test_train\n",
      "train mean loss=0.04999467761566242\n",
      "test_test\n",
      "test mean loss=1160.7914428710938\n",
      "epoch 9978\n",
      "test_train\n",
      "train mean loss=0.04930354608222842\n",
      "test_test\n",
      "test mean loss=1159.6726379394531\n",
      "epoch 9979\n",
      "test_train\n",
      "train mean loss=0.042325427290052176\n",
      "test_test\n",
      "test mean loss=1157.57666015625\n",
      "epoch 9980\n",
      "test_train\n",
      "train mean loss=0.04899884977688392\n",
      "test_test\n",
      "test mean loss=1159.351806640625\n",
      "epoch 9981\n",
      "test_train\n",
      "train mean loss=0.04880576689417163\n",
      "test_test\n",
      "test mean loss=1159.2844543457031\n",
      "epoch 9982\n",
      "test_train\n",
      "train mean loss=0.049900736970206104\n",
      "test_test\n",
      "test mean loss=1159.908203125\n",
      "epoch 9983\n",
      "test_train\n",
      "train mean loss=0.04544590118651589\n",
      "test_test\n",
      "test mean loss=1159.5406494140625\n",
      "epoch 9984\n",
      "test_train\n",
      "train mean loss=0.04775231688593825\n",
      "test_test\n",
      "test mean loss=1159.4366455078125\n",
      "epoch 9985\n",
      "test_train\n",
      "train mean loss=0.04547896794974804\n",
      "test_test\n",
      "test mean loss=1159.7301025390625\n",
      "epoch 9986\n",
      "test_train\n",
      "train mean loss=0.0491780818750461\n",
      "test_test\n",
      "test mean loss=1159.15869140625\n",
      "epoch 9987\n",
      "test_train\n",
      "train mean loss=0.05321767584731182\n",
      "test_test\n",
      "test mean loss=1160.0335998535156\n",
      "epoch 9988\n",
      "test_train\n",
      "train mean loss=0.05041650775820017\n",
      "test_test\n",
      "test mean loss=1159.0279541015625\n",
      "epoch 9989\n",
      "test_train\n",
      "train mean loss=0.051441682347406946\n",
      "test_test\n",
      "test mean loss=1159.8262939453125\n",
      "epoch 9990\n",
      "test_train\n",
      "train mean loss=0.048355870259304844\n",
      "test_test\n",
      "test mean loss=1159.3641357421875\n",
      "epoch 9991\n",
      "test_train\n",
      "train mean loss=0.048194234569867454\n",
      "test_test\n",
      "test mean loss=1160.6453857421875\n",
      "epoch 9992\n",
      "test_train\n",
      "train mean loss=0.04527711713065704\n",
      "test_test\n",
      "test mean loss=1159.6929321289062\n",
      "epoch 9993\n",
      "test_train\n",
      "train mean loss=0.046769374360640846\n",
      "test_test\n",
      "test mean loss=1159.2565307617188\n",
      "epoch 9994\n",
      "test_train\n",
      "train mean loss=0.041464011650532484\n",
      "test_test\n",
      "test mean loss=1157.8411254882812\n",
      "epoch 9995\n",
      "test_train\n",
      "train mean loss=0.23250659431020418\n",
      "test_test\n",
      "test mean loss=1152.9406127929688\n",
      "epoch 9996\n",
      "test_train\n",
      "train mean loss=0.0711155952885747\n",
      "test_test\n",
      "test mean loss=1157.9896850585938\n",
      "epoch 9997\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=0.04926689124355713\n",
      "test_test\n",
      "test mean loss=1160.5518493652344\n",
      "epoch 9998\n",
      "test_train\n",
      "train mean loss=0.049099065363407135\n",
      "test_test\n",
      "test mean loss=1160.8777160644531\n",
      "epoch 9999\n",
      "test_train\n",
      "train mean loss=0.053690229542553425\n",
      "test_test\n",
      "test mean loss=1161.1055603027344\n",
      "epoch 10000\n",
      "test_train\n",
      "train mean loss=0.05285975088675817\n",
      "test_test\n",
      "test mean loss=1160.7058715820312\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 10000\n",
    "\n",
    "train_100_loss = []\n",
    "test_100_loss = []\n",
    "train_100_state = []\n",
    "test_100_state = []\n",
    "\n",
    "confmode = False\n",
    "cmpDesc = True\n",
    "for epoch in range(EPOCH):#EPOCH):\n",
    "    print('epoch', epoch+1)    #epoch数の出力\n",
    "    num = 0\n",
    "    net.train()\n",
    "    for (img, immask, inputs, mask, mask2, labels, lmask, inputc, maskc, maskc2, labelc, lmaskc, inum, lnum) in trainloader:\n",
    "    #for batch in trainloader:\n",
    "        #num += 1\n",
    "        #print(num)\n",
    "        optimizer.zero_grad()\n",
    "        if not confmode:\n",
    "            img, immask, inputs, mask, mask2, labels, lmask = \\\n",
    "            img.to(device), immask.to(device), inputs.to(device), mask.to(device), mask2.to(device), labels.to(device), lmask.to(device)\n",
    "        else:\n",
    "            img, immask, inputs, mask, mask2, labels, lmask = \\\n",
    "            img.to(device), immask.to(device), inputc.to(device), maskc.to(device), mask2.to(device), labels.to(device), lmask.to(device)\n",
    "        if cmpDesc:\n",
    "            labelc = labelc.to(device)\n",
    "            #物体位置→手首位置(基準座標変換)\n",
    "            lhandloc = torch.zeros(labelc.size()[0],2).to(device)\n",
    "            sub = torch.zeros_like(labelc).to(device)\n",
    "            for bsize in range(labelc.size()[0]):\n",
    "                lhandloc[bsize][0] = labelc[bsize][0].item()\n",
    "                lhandloc[bsize][1] = labelc[bsize][1].item()\n",
    "                #zval = handloc[bsize][2].item()\n",
    "                for i in range(int(labelc.size()[1] / 3)):\n",
    "                    sub[bsize][i*3+0] = lhandloc[bsize][0]\n",
    "                    sub[bsize][i*3+1] = lhandloc[bsize][1]\n",
    "                    #sub[bsize][i*3+2] = zval\n",
    "            labelc_h = (labelc - sub).to(device)\n",
    "            handloc, posedesc, ldesc = net(img, immask, inputs, mask, labelc_h)\n",
    "            loss = criterion(posedesc, ldesc) + criterion(handloc[:,0], lhandloc[:,0]) + criterion(handloc[:,1], lhandloc[:,1])\n",
    "        else:\n",
    "            handloc, pose_h, posedesc = net(img, immask, inputs, mask)\n",
    "            #手首位置→物体位置(基準座標変換)\n",
    "            add = torch.zeros_like(pose_h).to(device)\n",
    "            for bsize in range(pose_h.size()[0]):\n",
    "                xval = handloc[bsize][0].item()\n",
    "                yval = handloc[bsize][1].item()\n",
    "                #zval = handloc[bsize][2].item()\n",
    "                for i in range(int(pose_h.size()[1] / 2)):\n",
    "                    add[bsize][i*2+0] = xval\n",
    "                    add[bsize][i*2+1] = yval\n",
    "                    #add[bsize][i*3+2] = zval\n",
    "            pose_o = (pose_h + add).to(device)\n",
    "            loss = criterionM(pose_o, labels, mask2, lmask)#crit_outputs, crit_labels)\n",
    "            #print(\"loss: \", loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    sum_loss = 0.0          #lossの合計\n",
    "    sum_total = 0           #dataの数の合計\n",
    "\n",
    "    print(\"test_train\")\n",
    "    ttrain = 0\n",
    "    net.eval()\n",
    "    #train dataを使ってテストをする(パラメータ更新がないようになっている)\n",
    "    for (img, immask, inputs, mask, mask2, labels, lmask, inputc, maskc, maskc2, labelc, lmaskc, inum, lnum) in trainloader:\n",
    "        ttrain += 1\n",
    "        optimizer.zero_grad()\n",
    "        if not confmode:\n",
    "            img, immask, inputs, mask, mask2, labels, lmask = \\\n",
    "            img.to(device), immask.to(device), inputs.to(device), mask.to(device), mask2.to(device), labels.to(device), lmask.to(device)\n",
    "        else:\n",
    "            img, immask, inputs, mask, mask2, labels, lmask = \\\n",
    "            img.to(device), immask.to(device), inputc.to(device), maskc.to(device), mask2.to(device), labels.to(device), lmask.to(device)\n",
    "        if cmpDesc:\n",
    "            labelc = labelc.to(device)\n",
    "            #物体位置→手首位置(基準座標変換)\n",
    "            lhandloc = torch.zeros(labelc.size()[0],2).to(device)\n",
    "            sub = torch.zeros_like(labelc).to(device)\n",
    "            for bsize in range(labelc.size()[0]):\n",
    "                lhandloc[bsize][0] = labelc[bsize][0].item()\n",
    "                lhandloc[bsize][1] = labelc[bsize][1].item()\n",
    "                #zval = handloc[bsize][2].item()\n",
    "                for i in range(int(labelc.size()[1] / 3)):\n",
    "                    sub[bsize][i*3+0] = lhandloc[bsize][0]\n",
    "                    sub[bsize][i*3+1] = lhandloc[bsize][1]\n",
    "                    #sub[bsize][i*3+2] = zval\n",
    "            labelc_h = (labelc - sub).to(device)\n",
    "            handloc, posedesc, ldesc = net(img, immask, inputs, mask, labelc_h)\n",
    "            loss = criterion(posedesc, ldesc) + criterion(handloc[:,0], lhandloc[:,0]) + criterion(handloc[:,1], lhandloc[:,1])\n",
    "        else:\n",
    "            handloc, pose_h, posedesc = net(img, immask, inputs, mask)\n",
    "            #手首位置→物体位置(基準座標変換)\n",
    "            add = torch.zeros_like(pose_h).to(device)\n",
    "            for bsize in range(pose_h.size()[0]):\n",
    "                xval = handloc[bsize][0].item()\n",
    "                yval = handloc[bsize][1].item()\n",
    "                #zval = handloc[bsize][2].item()\n",
    "                for i in range(int(pose_h.size()[1] / 2)):\n",
    "                    add[bsize][i*2+0] = xval\n",
    "                    add[bsize][i*2+1] = yval\n",
    "                    #add[bsize][i*3+2] = zval\n",
    "            pose_o = (pose_h + add).to(device)\n",
    "            loss = criterionM(pose_o*100, labels*100, mask2, lmask)#crit_outputs, crit_labels)\n",
    "            #print(\"loss: \", loss)\n",
    "        if ttrain == int(train_size / BATCH_SIZE):\n",
    "            train_inum.append(inum.to(device_cpu).detach().numpy().copy())\n",
    "            train_input_value.append(inputs.to(device_cpu).detach().numpy().copy()*100)\n",
    "            train_desc_value.append(posedesc.to(device_cpu).detach().numpy().copy())\n",
    "            train_handloc_value.append(handloc.to(device_cpu).detach().numpy().copy()*100)\n",
    "            if cmpDesc:\n",
    "                train_ldesc_value.append(ldesc.to(device_cpu).detach().numpy().copy())\n",
    "                train_lhandloc_value.append(lhandloc.to(device_cpu).detach().numpy().copy()*100)\n",
    "            else:\n",
    "                train_output_value.append(pose_o.to(device_cpu).detach().numpy().copy()*100)          \n",
    "        sum_loss += loss.item()                            #lossを足していく\n",
    "        sum_total += labels.size(0)                        #labelの数を足していくことでデータの総和を取る\n",
    "    #print(\"len train dataset: \", len(trainloader.dataset))\n",
    "    train_mean_loss = sum_loss*BATCH_SIZE/len(trainloader.dataset)\n",
    "    print(\"train mean loss={}\".format(train_mean_loss))  #loss出力\n",
    "    train_loss_value.append(train_mean_loss)  #traindataのlossをグラフ描画のためにlistに保持\n",
    "    train_100_loss.append(train_mean_loss)\n",
    "    train_100_state.append(net.state_dict())\n",
    "    if train_mean_loss > max_train_loss_value:\n",
    "        max_train_loss_value = train_mean_loss\n",
    "    if len(train_100_loss) == 100:\n",
    "        tr_idx = train_100_loss.index(min(train_100_loss))\n",
    "        torch.save(train_100_state[tr_idx], PATH + \"\\\\model_epoch\" + str(epoch+1) + \"_trainloss_\" + str(train_100_loss[tr_idx]))\n",
    "        train_100_loss.clear()\n",
    "        train_100_state.clear()\n",
    "\n",
    "    sum_loss = 0.0\n",
    "    sum_total = 0\n",
    "\n",
    "    print(\"test_test\")\n",
    "    ttest = 0\n",
    "    net.eval()\n",
    "    #test dataを使ってテストをする\n",
    "    for (img, immask, inputs, mask, mask2, labels, lmask, inputc, maskc, maskc2, labelc, lmaskc, inum, lnum) in testloader:\n",
    "        ttest += 1\n",
    "        optimizer.zero_grad()\n",
    "        if not confmode:\n",
    "            img, immask, inputs, mask, mask2, labels, lmask = \\\n",
    "            img.to(device), immask.to(device), inputs.to(device), mask.to(device), mask2.to(device), labels.to(device), lmask.to(device)\n",
    "        else:\n",
    "            img, immask, inputs, mask, mask2, labels, lmask = \\\n",
    "            img.to(device), immask.to(device), inputc.to(device), maskc.to(device), mask2.to(device), labels.to(device), lmask.to(device)\n",
    "        if cmpDesc:\n",
    "            labelc = labelc.to(device)\n",
    "            #物体位置→手首位置(基準座標変換)\n",
    "            lhandloc = torch.zeros(labelc.size()[0],2).to(device)\n",
    "            sub = torch.zeros_like(labelc).to(device)\n",
    "            for bsize in range(labelc.size()[0]):\n",
    "                lhandloc[bsize][0] = labelc[bsize][0].item()\n",
    "                lhandloc[bsize][1] = labelc[bsize][1].item()\n",
    "                #zval = handloc[bsize][2].item()\n",
    "                for i in range(int(labelc.size()[1] / 3)):\n",
    "                    sub[bsize][i*3+0] = lhandloc[bsize][0]\n",
    "                    sub[bsize][i*3+1] = lhandloc[bsize][1]\n",
    "                    #sub[bsize][i*3+2] = zval\n",
    "            labelc_h = (labelc - sub).to(device)\n",
    "            handloc, posedesc, ldesc = net(img, immask, inputs, mask, labelc_h)\n",
    "            loss = criterion(posedesc, ldesc) + criterion(handloc[:,0], lhandloc[:,0]) + criterion(handloc[:,1], lhandloc[:,1])\n",
    "        else:\n",
    "            handloc, pose_h, posedesc = net(img, immask, inputs, mask)\n",
    "            #手首位置→物体位置(基準座標変換)\n",
    "            add = torch.zeros_like(pose_h).to(device)\n",
    "            for bsize in range(pose_h.size()[0]):\n",
    "                xval = handloc[bsize][0].item()\n",
    "                yval = handloc[bsize][1].item()\n",
    "                #zval = handloc[bsize][2].item()\n",
    "                for i in range(int(pose_h.size()[1] / 2)):\n",
    "                    add[bsize][i*2+0] = xval\n",
    "                    add[bsize][i*2+1] = yval\n",
    "                    #add[bsize][i*3+2] = zval\n",
    "            pose_o = (pose_h + add).to(device)\n",
    "            loss = criterionM(pose_o*100, labels*100, mask2, lmask)#crit_outputs, crit_labels)\n",
    "            #print(\"loss: \", loss)\n",
    "        if ttest == int(test_size / BATCH_SIZE):\n",
    "            test_inum.append(inum.to(device_cpu).detach().numpy().copy())\n",
    "            test_input_value.append(inputs.to(device_cpu).detach().numpy().copy()*100)\n",
    "            test_desc_value.append(posedesc.to(device_cpu).detach().numpy().copy())\n",
    "            test_handloc_value.append(handloc.to(device_cpu).detach().numpy().copy()*100)\n",
    "            if cmpDesc:\n",
    "                test_ldesc_value.append(ldesc.to(device_cpu).detach().numpy().copy())\n",
    "                test_lhandloc_value.append(lhandloc.to(device_cpu).detach().numpy().copy()*100)\n",
    "            else:\n",
    "                test_output_value.append(pose_o.to(device_cpu).detach().numpy().copy()*100)    \n",
    "        sum_loss += loss.item()\n",
    "        sum_total += labels.size(0)\n",
    "    #print(\"len test dataset: \", len(testloader.dataset))\n",
    "    test_mean_loss = sum_loss*BATCH_SIZE/len(testloader.dataset)\n",
    "    print(\"test mean loss={}\".format(test_mean_loss))\n",
    "    test_loss_value.append(test_mean_loss)\n",
    "    test_100_loss.append(test_mean_loss)\n",
    "    test_100_state.append(net.state_dict())\n",
    "    if test_mean_loss > max_test_loss_value:\n",
    "        max_test_loss_value = test_mean_loss\n",
    "    if len(test_100_loss) == 100:\n",
    "        te_idx = test_100_loss.index(min(test_100_loss))\n",
    "        torch.save(test_100_state[te_idx], PATH + \"\\\\model_epoch\" + str(epoch+1) + \"_testloss_\" + str(test_100_loss[te_idx]))\n",
    "        test_100_loss.clear()\n",
    "        test_100_state.clear()\n",
    "    #outcsv(epoch+1, train_input_value, train_output_value, train_desc_value, train_handloc_value,\\\n",
    "    #       test_input_value, test_output_value, test_desc_value, test_handloc_value)\n",
    "    if cmpDesc:\n",
    "        outcsv(epoch+1, train_input_value, train_desc_value, train_handloc_value, train_inum, \"train\", outputs=None, ldescs=train_ldesc_value, lhlocs=train_lhandloc_value)\n",
    "        outcsv(epoch+1, test_input_value, test_desc_value, test_handloc_value, test_inum, \"test\", outputs=None, ldescs=test_ldesc_value, lhlocs=test_lhandloc_value)\n",
    "    else:\n",
    "        outcsv(epoch+1, train_input_value, train_desc_value, train_handloc_value, train_inum, \"train\", outputs=train_output_value, ldescs=None, lhlocs=None)\n",
    "        outcsv(epoch+1, test_input_value, test_desc_value, test_handloc_value, test_inum, \"test\", outputs=test_output_value, ldescs=None, lhlocs=None)\n",
    "    saveloss(train_mean_loss, test_mean_loss)\n",
    "    train_input_value.clear()\n",
    "    train_output_value.clear()\n",
    "    train_desc_value.clear()\n",
    "    train_handloc_value.clear()\n",
    "    train_ldesc_value.clear()\n",
    "    train_lhandloc_value.clear()\n",
    "    train_inum.clear()\n",
    "    test_input_value.clear()\n",
    "    test_output_value.clear()\n",
    "    test_desc_value.clear()\n",
    "    test_handloc_value.clear()\n",
    "    test_ldesc_value.clear()\n",
    "    test_lhandloc_value.clear()\n",
    "    test_inum.clear()\n",
    "    #if (min_test_loss_value != None and test_mean_loss < min_test_loss_value) or min_test_loss_value == None:\n",
    "    #      min_test_loss_value = test_mean_loss\n",
    "    #      torch.save(net.state_dict(), PATH + \"\\\\model_epoch\" + str(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvidia-smi' は、内部コマンドまたは外部コマンド、\n",
      "操作可能なプログラムまたはバッチ ファイルとして認識されていません。\n"
     ]
    }
   ],
   "source": [
    "#for k, p in zip(keys, net.parameters()):\n",
    "#    print(k, \"\\n\", p, \"\\n\")\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 504x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 504x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#グラフ描画用\n",
    "train_loss_value = []\n",
    "test_loss_value = []\n",
    "\n",
    "with open(PATH + \"\\\\outputs\\\\loss_values.csv\", mode=\"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        train_loss_value.append(float(row[0]))\n",
    "        test_loss_value.append(float(row[1]))\n",
    "max_train_loss_value = max(train_loss_value)\n",
    "max_test_loss_value = max(test_loss_value)\n",
    "ylim = max(max_train_loss_value, max_test_loss_value)\n",
    "ylimtrain = max_train_loss_value\n",
    "ylimtest = max_test_loss_value\n",
    "legend = [\"train\",\"test\"]\n",
    "legendtrain = [\"train\"]\n",
    "legendtest = [\"test\"]\n",
    "\n",
    "baseEPOCH = 100\n",
    "num_epoch = 1\n",
    "#act_num_epoch = baseEPOCH * num_epoch\n",
    "act_num_epoch = len(train_loss_value)\n",
    "\n",
    "#以下グラフ描画\n",
    "def plotloss(mode, epoch, trainloss, testloss, ylim, legend):\n",
    "    plt.figure(figsize=(7,7))\n",
    "    if mode == \"train\": #train\n",
    "        plt.plot(range(act_num_epoch), train_loss_value)\n",
    "    elif mode == \"test\": #test\n",
    "        plt.plot(range(act_num_epoch), test_loss_value, c='#00ff00')\n",
    "    elif mode == \"both\": #train test\n",
    "        plt.plot(range(act_num_epoch), train_loss_value)\n",
    "        plt.plot(range(act_num_epoch), test_loss_value, c='#00ff00')\n",
    "    plt.xlim(0, act_num_epoch)\n",
    "    plt.ylim(0, ylim)\n",
    "    plt.xlabel('EPOCH')\n",
    "    plt.ylabel('LOSS(mm^2)')\n",
    "    plt.legend(legend)\n",
    "    plt.title('loocation and pose LOSS')\n",
    "    plt.savefig(PATH + \"\\\\loss_image_\" + str(act_num_epoch) + mode + \".png\")\n",
    "    plt.clf()\n",
    "    \n",
    "plotloss('both', act_num_epoch, train_loss_value, test_loss_value, ylim, legend)\n",
    "plotloss('train', act_num_epoch, train_loss_value, test_loss_value, ylim=ylimtrain, legend=legendtrain)\n",
    "plotloss('test', act_num_epoch, train_loss_value, test_loss_value, ylim=ylimtest, legend=legendtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "#結果画像出力\n",
    "target_epoch = 19\n",
    "\n",
    "HAND_PNT_NUM = 21\n",
    "\n",
    "#fig = plt.figure(figsize=(6,6))\n",
    "fig = plt.figure()\n",
    "for i in range(len(train_input_value[target_epoch])):\n",
    "    input_x = []\n",
    "    input_y = []\n",
    "    input_z = []\n",
    "    mid = []\n",
    "    output_x = []\n",
    "    output_y = []\n",
    "    output_z = []\n",
    "    connect_x = []\n",
    "    connect_y = []\n",
    "    connect_z = []\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    for j in range(int(len(train_input_value[target_epoch][0])/3)):\n",
    "        input_x.append(train_input_value[target_epoch][i][j*3+0].item())\n",
    "        input_y.append(-1*train_input_value[target_epoch][i][j*3+1].item())\n",
    "        input_z.append(train_input_value[target_epoch][i][j*3+2].item())\n",
    "        output_x.append(train_output_value[target_epoch][i][j*3+0].item())\n",
    "        output_y.append(-1*train_output_value[target_epoch][i][j*3+1].item())\n",
    "        output_z.append(train_output_value[target_epoch][i][j*3+2].item())\n",
    "    x_max = max([max(input_x), max(output_x)], default = -10000)\n",
    "    x_min = min([min(input_x), min(output_x)], default = 10000)\n",
    "    y_max = max([max(input_y), max(output_y)], default = -10000)\n",
    "    y_min = min([min(input_y), min(output_y)], default = 10000)\n",
    "    z_max = max([max(input_z), max(output_z)], default = -10000)\n",
    "    z_min = min([min(input_z), min(output_z)], default = 10000)\n",
    "    \n",
    "    #print(x_min, x_max, y_min, y_max, z_min, z_max, \"(fixed: x_min, x_max, y_min, y_max, z_min, z_max)\")\n",
    "    \n",
    "    #点が描画範囲内かどうか\n",
    "    isInputPointsIn = [False] * HAND_PNT_NUM\n",
    "    isOutputPointsIn = [False] * HAND_PNT_NUM\n",
    "    #print(isPointsIn)\n",
    "    \n",
    "    for p in range(HAND_PNT_NUM):\n",
    "        if x_min <= input_x[p] <= x_max and y_min <= input_y[p] <= y_max and z_min <= input_z[p] <= z_max:\n",
    "            isInputPointsIn[p] = True\n",
    "        if x_min <= output_x[p] <= x_max and y_min <= output_y[p] <= y_max and z_min <= output_z[p] <= z_max:\n",
    "            isOutputPointsIn[p] = True\n",
    "    \n",
    "    #各点をプロット\n",
    "    ax.scatter(input_x[0], input_y[0], zs=input_z[0], zdir='y', s=10, c='#e53528', marker = \".\")\n",
    "    ax.scatter(input_x[1], input_y[1], zs=input_z[1], zdir='y', s=10, c='#e77340', marker = \".\")\n",
    "    ax.scatter(input_x[2], input_y[2], zs=input_z[2], zdir='y', s=10, c='#eb8e25', marker = \".\")\n",
    "    ax.scatter(input_x[3], input_y[3], zs=input_z[3], zdir='y', s=10, c='#d7a10e', marker = \".\")\n",
    "    ax.scatter(input_x[4], input_y[4], zs=input_z[4], zdir='y', s=10, c='#d9c812', marker = \".\")\n",
    "    ax.scatter(input_x[5], input_y[5], zs=input_z[5], zdir='y', s=10, c='#a7cf21', marker = \".\")\n",
    "    ax.scatter(input_x[6], input_y[6], zs=input_z[6], zdir='y', s=10, c='#7fe545', marker = \".\")\n",
    "    ax.scatter(input_x[7], input_y[7], zs=input_z[7], zdir='y', s=10, c='#53d62d', marker = \".\")\n",
    "    ax.scatter(input_x[8], input_y[8], zs=input_z[8], zdir='y', s=10, c='#4abc2f', marker = \".\")\n",
    "    ax.scatter(input_x[9], input_y[9], zs=input_z[9], zdir='y', s=10, c='#52d686', marker = \".\")\n",
    "    ax.scatter(input_x[10], input_y[10], zs=input_z[10], zdir='y', s=10, c='#52dfbe', marker = \".\")\n",
    "    ax.scatter(input_x[11], input_y[11], zs=input_z[11], zdir='y', s=10, c='#52b9c5', marker = \".\")\n",
    "    ax.scatter(input_x[12], input_y[12], zs=input_z[12], zdir='y', s=10, c='#508ab7', marker = \".\")\n",
    "    ax.scatter(input_x[13], input_y[13], zs=input_z[13], zdir='y', s=10, c='#556fd0', marker = \".\")\n",
    "    ax.scatter(input_x[14], input_y[14], zs=input_z[14], zdir='y', s=10, c='#5245d5', marker = \".\")\n",
    "    ax.scatter(input_x[15], input_y[15], zs=input_z[15], zdir='y', s=10, c='#7e2fba', marker = \".\")\n",
    "    ax.scatter(input_x[16], input_y[16], zs=input_z[16], zdir='y', s=10, c='#bc64fb', marker = \".\")\n",
    "    ax.scatter(input_x[17], input_y[17], zs=input_z[17], zdir='y', s=10, c='#da53e8', marker = \".\")\n",
    "    ax.scatter(input_x[18], input_y[18], zs=input_z[18], zdir='y', s=10, c='#eb45bc', marker = \".\")\n",
    "    ax.scatter(input_x[19], input_y[19], zs=input_z[19], zdir='y', s=10, c='#ec3c89', marker = \".\")\n",
    "    ax.scatter(input_x[20], input_y[20], zs=input_z[20], zdir='y', s=10, c='#ff6691', marker = \".\")\n",
    "    \n",
    "    #点同士を結ぶ\n",
    "    if isInputPointsIn[0] and isInputPointsIn[1]:\n",
    "        ax.plot([input_x[0],input_x[1]], [input_y[0],input_y[1]], [input_z[0],input_z[1]], zdir='y', c='#cc0000')\n",
    "    if isInputPointsIn[1] and isInputPointsIn[2]:\n",
    "        ax.plot([input_x[1],input_x[2]], [input_y[1],input_y[2]], [input_z[1],input_z[2]], zdir='y', c='#b30000')\n",
    "    if isInputPointsIn[2] and isInputPointsIn[3]:\n",
    "        ax.plot([input_x[2],input_x[3]], [input_y[2],input_y[3]], [input_z[2],input_z[3]], zdir='y', c='#e60000')\n",
    "    if isInputPointsIn[3] and isInputPointsIn[4]:\n",
    "        ax.plot([input_x[3],input_x[4]], [input_y[3],input_y[4]], [input_z[3],input_z[4]], zdir='y', c='#ff0000')\n",
    "    if isInputPointsIn[0] and isInputPointsIn[5]:\n",
    "        ax.plot([input_x[0],input_x[5]], [input_y[0],input_y[5]], [input_z[0],input_z[5]], zdir='y', c='#a3cc00')\n",
    "    if isInputPointsIn[5] and isInputPointsIn[6]:\n",
    "        ax.plot([input_x[5],input_x[6]], [input_y[5],input_y[6]], [input_z[5],input_z[6]], zdir='y', c='#8fb300')\n",
    "    if isInputPointsIn[6] and isInputPointsIn[7]:        \n",
    "        ax.plot([input_x[6],input_x[7]], [input_y[6],input_y[7]], [input_z[6],input_z[7]], zdir='y', c='#b8e600')\n",
    "    if isInputPointsIn[7] and isInputPointsIn[8]:\n",
    "        ax.plot([input_x[7],input_x[8]], [input_y[7],input_y[8]], [input_z[7],input_z[8]], zdir='y', c='#ccff00')\n",
    "    if isInputPointsIn[0] and isInputPointsIn[9]:\n",
    "        ax.plot([input_x[0],input_x[9]], [input_y[0],input_y[9]], [input_z[0],input_z[9]], zdir='y', c='#00cc52')\n",
    "    if isInputPointsIn[9] and isInputPointsIn[10]:\n",
    "        ax.plot([input_x[9],input_x[10]], [input_y[9],input_y[10]], [input_z[9],input_z[10]], zdir='y', c='#00b347')\n",
    "    if isInputPointsIn[10] and isInputPointsIn[11]:\n",
    "        ax.plot([input_x[10],input_x[11]], [input_y[10],input_y[11]], [input_z[10],input_z[11]], zdir='y', c='#00e65c')\n",
    "    if isInputPointsIn[11] and isInputPointsIn[12]:\n",
    "        ax.plot([input_x[11],input_x[12]], [input_y[11],input_y[12]], [input_z[11],input_z[12]], zdir='y', c='#00ff66')\n",
    "    if isInputPointsIn[0] and isInputPointsIn[13]:\n",
    "        ax.plot([input_x[0],input_x[13]], [input_y[0],input_y[13]], [input_z[0],input_z[13]], zdir='y', c='#0052cc')\n",
    "    if isInputPointsIn[13] and isInputPointsIn[14]:\n",
    "        ax.plot([input_x[13],input_x[14]], [input_y[13],input_y[14]], [input_z[13],input_z[14]], zdir='y', c='#0047b3')\n",
    "    if isInputPointsIn[14] and isInputPointsIn[15]:\n",
    "        ax.plot([input_x[14],input_x[15]], [input_y[14],input_y[15]], [input_z[14],input_z[15]], zdir='y', c='#005ce6')\n",
    "    if isInputPointsIn[15] and isInputPointsIn[16]:\n",
    "        ax.plot([input_x[15],input_x[16]], [input_y[15],input_y[16]], [input_z[15],input_z[16]], zdir='y', c='#0066ff')\n",
    "    if isInputPointsIn[0] and isInputPointsIn[17]:\n",
    "        ax.plot([input_x[0],input_x[17]], [input_y[0],input_y[17]], [input_z[0],input_z[17]], zdir='y', c='#a300cc')\n",
    "    if isInputPointsIn[17] and isInputPointsIn[18]:\n",
    "        ax.plot([input_x[17],input_x[18]], [input_y[17],input_y[18]], [input_z[17],input_z[18]], zdir='y', c='#8f00b3')\n",
    "    if isInputPointsIn[18] and isInputPointsIn[19]:\n",
    "        ax.plot([input_x[18],input_x[19]], [input_y[18],input_y[19]], [input_z[18],input_z[19]], zdir='y', c='#b800e6')\n",
    "    if isInputPointsIn[19] and isInputPointsIn[20]:\n",
    "        ax.plot([input_x[19],input_x[20]], [input_y[19],input_y[20]], [input_z[19],input_z[20]], zdir='y', c='#cc00ff')\n",
    "    \n",
    "    ##stradrs = str(train_adrs[target_epoch][i].item()) #202011221813290002\n",
    "    ##d_adrs = \"dataset_\" + stradrs[4:8] + \"_\" + stradrs[8:14] + \"_\" + stradrs[14:]\n",
    "    ##ax.set_title('input(train data, ' + str(target_epoch+1) + 'th epoch)\\n' + d_adrs)\n",
    "    ax.set_title('input(train data, ' + str(target_epoch+1) + 'th epoch)\\n' + str(i))\n",
    "    ax.set_xlim([x_min, x_max])\n",
    "    ax.set_ylim([z_min, z_max])\n",
    "    ax.set_zlim([y_min, y_max])\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('z')\n",
    "    ax.set_zlabel('y')\n",
    "    #plt.subplots_adjust(left=0.04, right=0.80, bottom=0.04, top=0.80)\n",
    "    #ax.legend(loc='upper right')\n",
    "    fig.savefig(PATH + \"\\\\outputs\\\\Input_train_\" + str(target_epoch) + \"th_epoch_\" + str(i) + \".png\", dpi = 300, transparent = False, bbox_inches = 'tight', pad_inches = 0)\n",
    "    fig.clf()\n",
    "    \n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    #各点をプロット\n",
    "    ax.scatter(output_x[0], output_y[0], zs=output_z[0], zdir='y', s=10, c='#e53528', marker = \".\")\n",
    "    ax.scatter(output_x[1], output_y[1], zs=output_z[1], zdir='y', s=10, c='#e77340', marker = \".\")\n",
    "    ax.scatter(output_x[2], output_y[2], zs=output_z[2], zdir='y', s=10, c='#eb8e25', marker = \".\")\n",
    "    ax.scatter(output_x[3], output_y[3], zs=output_z[3], zdir='y', s=10, c='#d7a10e', marker = \".\")\n",
    "    ax.scatter(output_x[4], output_y[4], zs=output_z[4], zdir='y', s=10, c='#d9c812', marker = \".\")\n",
    "    ax.scatter(output_x[5], output_y[5], zs=output_z[5], zdir='y', s=10, c='#a7cf21', marker = \".\")\n",
    "    ax.scatter(output_x[6], output_y[6], zs=output_z[6], zdir='y', s=10, c='#7fe545', marker = \".\")\n",
    "    ax.scatter(output_x[7], output_y[7], zs=output_z[7], zdir='y', s=10, c='#53d62d', marker = \".\")\n",
    "    ax.scatter(output_x[8], output_y[8], zs=output_z[8], zdir='y', s=10, c='#4abc2f', marker = \".\")\n",
    "    ax.scatter(output_x[9], output_y[9], zs=output_z[9], zdir='y', s=10, c='#52d686', marker = \".\")\n",
    "    ax.scatter(output_x[10], output_y[10], zs=output_z[10], zdir='y', s=10, c='#52dfbe', marker = \".\")\n",
    "    ax.scatter(output_x[11], output_y[11], zs=output_z[11], zdir='y', s=10, c='#52b9c5', marker = \".\")\n",
    "    ax.scatter(output_x[12], output_y[12], zs=output_z[12], zdir='y', s=10, c='#508ab7', marker = \".\")\n",
    "    ax.scatter(output_x[13], output_y[13], zs=output_z[13], zdir='y', s=10, c='#556fd0', marker = \".\")\n",
    "    ax.scatter(output_x[14], output_y[14], zs=output_z[14], zdir='y', s=10, c='#5245d5', marker = \".\")\n",
    "    ax.scatter(output_x[15], output_y[15], zs=output_z[15], zdir='y', s=10, c='#7e2fba', marker = \".\")\n",
    "    ax.scatter(output_x[16], output_y[16], zs=output_z[16], zdir='y', s=10, c='#bc64fb', marker = \".\")\n",
    "    ax.scatter(output_x[17], output_y[17], zs=output_z[17], zdir='y', s=10, c='#da53e8', marker = \".\")\n",
    "    ax.scatter(output_x[18], output_y[18], zs=output_z[18], zdir='y', s=10, c='#eb45bc', marker = \".\")\n",
    "    ax.scatter(output_x[19], output_y[19], zs=output_z[19], zdir='y', s=10, c='#ec3c89', marker = \".\")\n",
    "    ax.scatter(output_x[20], output_y[20], zs=output_z[20], zdir='y', s=10, c='#ff6691', marker = \".\")\n",
    "    \n",
    "    #点同士を結ぶ\n",
    "    if isOutputPointsIn[0] and isOutputPointsIn[1]:\n",
    "        ax.plot([output_x[0],output_x[1]], [output_y[0],output_y[1]], [output_z[0],output_z[1]], zdir='y', c='#cc0000')\n",
    "    if isOutputPointsIn[1] and isOutputPointsIn[2]:\n",
    "        ax.plot([output_x[1],output_x[2]], [output_y[1],output_y[2]], [output_z[1],output_z[2]], zdir='y', c='#b30000')\n",
    "    if isOutputPointsIn[2] and isOutputPointsIn[3]:\n",
    "        ax.plot([output_x[2],output_x[3]], [output_y[2],output_y[3]], [output_z[2],output_z[3]], zdir='y', c='#e60000')\n",
    "    if isOutputPointsIn[3] and isOutputPointsIn[4]:\n",
    "        ax.plot([output_x[3],output_x[4]], [output_y[3],output_y[4]], [output_z[3],output_z[4]], zdir='y', c='#ff0000')\n",
    "    if isOutputPointsIn[0] and isOutputPointsIn[5]:\n",
    "        ax.plot([output_x[0],output_x[5]], [output_y[0],output_y[5]], [output_z[0],output_z[5]], zdir='y', c='#a3cc00')\n",
    "    if isOutputPointsIn[5] and isOutputPointsIn[6]:\n",
    "        ax.plot([output_x[5],output_x[6]], [output_y[5],output_y[6]], [output_z[5],output_z[6]], zdir='y', c='#8fb300')\n",
    "    if isOutputPointsIn[6] and isOutputPointsIn[7]:        \n",
    "        ax.plot([output_x[6],output_x[7]], [output_y[6],output_y[7]], [output_z[6],output_z[7]], zdir='y', c='#b8e600')\n",
    "    if isOutputPointsIn[7] and isOutputPointsIn[8]:\n",
    "        ax.plot([output_x[7],output_x[8]], [output_y[7],output_y[8]], [output_z[7],output_z[8]], zdir='y', c='#ccff00')\n",
    "    if isOutputPointsIn[0] and isOutputPointsIn[9]:\n",
    "        ax.plot([output_x[0],output_x[9]], [output_y[0],output_y[9]], [output_z[0],output_z[9]], zdir='y', c='#00cc52')\n",
    "    if isOutputPointsIn[9] and isOutputPointsIn[10]:\n",
    "        ax.plot([output_x[9],output_x[10]], [output_y[9],output_y[10]], [output_z[9],output_z[10]], zdir='y', c='#00b347')\n",
    "    if isOutputPointsIn[10] and isOutputPointsIn[11]:\n",
    "        ax.plot([output_x[10],output_x[11]], [output_y[10],output_y[11]], [output_z[10],output_z[11]], zdir='y', c='#00e65c')\n",
    "    if isOutputPointsIn[11] and isOutputPointsIn[12]:\n",
    "        ax.plot([output_x[11],output_x[12]], [output_y[11],output_y[12]], [output_z[11],output_z[12]], zdir='y', c='#00ff66')\n",
    "    if isOutputPointsIn[0] and isOutputPointsIn[13]:\n",
    "        ax.plot([output_x[0],output_x[13]], [output_y[0],output_y[13]], [output_z[0],output_z[13]], zdir='y', c='#0052cc')\n",
    "    if isOutputPointsIn[13] and isOutputPointsIn[14]:\n",
    "        ax.plot([output_x[13],output_x[14]], [output_y[13],output_y[14]], [output_z[13],output_z[14]], zdir='y', c='#0047b3')\n",
    "    if isOutputPointsIn[14] and isOutputPointsIn[15]:\n",
    "        ax.plot([output_x[14],output_x[15]], [output_y[14],output_y[15]], [output_z[14],output_z[15]], zdir='y', c='#005ce6')\n",
    "    if isOutputPointsIn[15] and isOutputPointsIn[16]:\n",
    "        ax.plot([output_x[15],output_x[16]], [output_y[15],output_y[16]], [output_z[15],output_z[16]], zdir='y', c='#0066ff')\n",
    "    if isOutputPointsIn[0] and isOutputPointsIn[17]:\n",
    "        ax.plot([output_x[0],output_x[17]], [output_y[0],output_y[17]], [output_z[0],output_z[17]], zdir='y', c='#a300cc')\n",
    "    if isOutputPointsIn[17] and isOutputPointsIn[18]:\n",
    "        ax.plot([output_x[17],output_x[18]], [output_y[17],output_y[18]], [output_z[17],output_z[18]], zdir='y', c='#8f00b3')\n",
    "    if isOutputPointsIn[18] and isOutputPointsIn[19]:\n",
    "        ax.plot([output_x[18],output_x[19]], [output_y[18],output_y[19]], [output_z[18],output_z[19]], zdir='y', c='#b800e6')\n",
    "    if isOutputPointsIn[19] and isOutputPointsIn[20]:\n",
    "        ax.plot([output_x[19],output_x[20]], [output_y[19],output_y[20]], [output_z[19],output_z[20]], zdir='y', c='#cc00ff')\n",
    "    #ax.scatter(input_x, input_y, c='red', label = 'input')\n",
    "    #ax.scatter(output_x, output_y, c='blue', label = 'output')\n",
    "    \n",
    "    #3stradrs = str(train_adrs[target_epoch][i].item()) #202011221813290002\n",
    "    ##d_adrs = \"dataset_\" + stradrs[4:8] + \"_\" + stradrs[8:14] + \"_\" + stradrs[14:]\n",
    "    ##ax.set_title('output(train data, ' + str(target_epoch+1) + 'th epoch)\\n' + d_adrs)\n",
    "    ax.set_title('output(train data, ' + str(target_epoch+1) + 'th epoch)\\n' + str(i))\n",
    "    ax.set_xlim([x_min, x_max])\n",
    "    ax.set_ylim([z_min, z_max])\n",
    "    ax.set_zlim([y_min, y_max])\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('z')\n",
    "    ax.set_zlabel('y')\n",
    "    #plt.subplots_adjust(left=0.04, right=0.80, bottom=0.04, top=0.80)\n",
    "    #ax.legend(loc='upper right')\n",
    "    fig.savefig(PATH + \"\\\\outputs\\\\Output_train_\" + str(target_epoch) + \"th_epoch_\" + str(i) + \".png\", dpi = 300,transparent = False, bbox_inches = 'tight', pad_inches = 0)\n",
    "    fig.clf()\n",
    "for i in range(len(test_input_value[target_epoch])):\n",
    "    input_x = []\n",
    "    input_y = []\n",
    "    input_z = []\n",
    "    mid = []\n",
    "    output_x = []\n",
    "    output_y = []\n",
    "    output_z = []\n",
    "    connect_x = []\n",
    "    connect_y = []\n",
    "    connect_z = []\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    for j in range(int(len(test_input_value[target_epoch][0])/3)):\n",
    "        input_x.append(test_input_value[target_epoch][i][j*3+0].item())\n",
    "        input_y.append(-1*test_input_value[target_epoch][i][j*3+1].item())\n",
    "        input_z.append(test_input_value[target_epoch][i][j*3+2].item())\n",
    "        output_x.append(test_output_value[target_epoch][i][j*3+0].item())\n",
    "        output_y.append(-1*test_output_value[target_epoch][i][j*3+1].item())\n",
    "        output_z.append(test_output_value[target_epoch][i][j*3+2].item())\n",
    "    x_max = max([max(input_x), max(output_x)], default = -10000)\n",
    "    x_min = min([min(input_x), min(output_x)], default = 10000)\n",
    "    y_max = max([max(input_y), max(output_y)], default = -10000)\n",
    "    y_min = min([min(input_y), min(output_y)], default = 10000)\n",
    "    z_max = max([max(input_z), max(output_z)], default = -10000)\n",
    "    z_min = min([min(input_z), min(output_z)], default = 10000)\n",
    "    \n",
    "    #print(x_min, x_max, y_min, y_max, z_min, z_max, \"(fixed: x_min, x_max, y_min, y_max, z_min, z_max)\")\n",
    "    \n",
    "    #点が描画範囲内かどうか\n",
    "    isInputPointsIn = [False] * HAND_PNT_NUM\n",
    "    isOutputPointsIn = [False] * HAND_PNT_NUM\n",
    "    #print(isPointsIn)\n",
    "    \n",
    "    for p in range(HAND_PNT_NUM):\n",
    "        if x_min <= input_x[p] <= x_max and y_min <= input_y[p] <= y_max and z_min <= input_z[p] <= z_max:\n",
    "            isInputPointsIn[p] = True\n",
    "        if x_min <= output_x[p] <= x_max and y_min <= output_y[p] <= y_max and z_min <= output_z[p] <= z_max:\n",
    "            isOutputPointsIn[p] = True\n",
    "    \n",
    "    #各点をプロット\n",
    "    ax.scatter(input_x[0], input_y[0], zs=input_z[0], zdir='y', s=10, c='#e53528', marker = \".\")\n",
    "    ax.scatter(input_x[1], input_y[1], zs=input_z[1], zdir='y', s=10, c='#e77340', marker = \".\")\n",
    "    ax.scatter(input_x[2], input_y[2], zs=input_z[2], zdir='y', s=10, c='#eb8e25', marker = \".\")\n",
    "    ax.scatter(input_x[3], input_y[3], zs=input_z[3], zdir='y', s=10, c='#d7a10e', marker = \".\")\n",
    "    ax.scatter(input_x[4], input_y[4], zs=input_z[4], zdir='y', s=10, c='#d9c812', marker = \".\")\n",
    "    ax.scatter(input_x[5], input_y[5], zs=input_z[5], zdir='y', s=10, c='#a7cf21', marker = \".\")\n",
    "    ax.scatter(input_x[6], input_y[6], zs=input_z[6], zdir='y', s=10, c='#7fe545', marker = \".\")\n",
    "    ax.scatter(input_x[7], input_y[7], zs=input_z[7], zdir='y', s=10, c='#53d62d', marker = \".\")\n",
    "    ax.scatter(input_x[8], input_y[8], zs=input_z[8], zdir='y', s=10, c='#4abc2f', marker = \".\")\n",
    "    ax.scatter(input_x[9], input_y[9], zs=input_z[9], zdir='y', s=10, c='#52d686', marker = \".\")\n",
    "    ax.scatter(input_x[10], input_y[10], zs=input_z[10], zdir='y', s=10, c='#52dfbe', marker = \".\")\n",
    "    ax.scatter(input_x[11], input_y[11], zs=input_z[11], zdir='y', s=10, c='#52b9c5', marker = \".\")\n",
    "    ax.scatter(input_x[12], input_y[12], zs=input_z[12], zdir='y', s=10, c='#508ab7', marker = \".\")\n",
    "    ax.scatter(input_x[13], input_y[13], zs=input_z[13], zdir='y', s=10, c='#556fd0', marker = \".\")\n",
    "    ax.scatter(input_x[14], input_y[14], zs=input_z[14], zdir='y', s=10, c='#5245d5', marker = \".\")\n",
    "    ax.scatter(input_x[15], input_y[15], zs=input_z[15], zdir='y', s=10, c='#7e2fba', marker = \".\")\n",
    "    ax.scatter(input_x[16], input_y[16], zs=input_z[16], zdir='y', s=10, c='#bc64fb', marker = \".\")\n",
    "    ax.scatter(input_x[17], input_y[17], zs=input_z[17], zdir='y', s=10, c='#da53e8', marker = \".\")\n",
    "    ax.scatter(input_x[18], input_y[18], zs=input_z[18], zdir='y', s=10, c='#eb45bc', marker = \".\")\n",
    "    ax.scatter(input_x[19], input_y[19], zs=input_z[19], zdir='y', s=10, c='#ec3c89', marker = \".\")\n",
    "    ax.scatter(input_x[20], input_y[20], zs=input_z[20], zdir='y', s=10, c='#ff6691', marker = \".\")\n",
    "    \n",
    "    #点同士を結ぶ\n",
    "    if isInputPointsIn[0] and isInputPointsIn[1]:\n",
    "        ax.plot([input_x[0],input_x[1]], [input_y[0],input_y[1]], [input_z[0],input_z[1]], zdir='y', c='#cc0000')\n",
    "    if isInputPointsIn[1] and isInputPointsIn[2]:\n",
    "        ax.plot([input_x[1],input_x[2]], [input_y[1],input_y[2]], [input_z[1],input_z[2]], zdir='y', c='#b30000')\n",
    "    if isInputPointsIn[2] and isInputPointsIn[3]:\n",
    "        ax.plot([input_x[2],input_x[3]], [input_y[2],input_y[3]], [input_z[2],input_z[3]], zdir='y', c='#e60000')\n",
    "    if isInputPointsIn[3] and isInputPointsIn[4]:\n",
    "        ax.plot([input_x[3],input_x[4]], [input_y[3],input_y[4]], [input_z[3],input_z[4]], zdir='y', c='#ff0000')\n",
    "    if isInputPointsIn[0] and isInputPointsIn[5]:\n",
    "        ax.plot([input_x[0],input_x[5]], [input_y[0],input_y[5]], [input_z[0],input_z[5]], zdir='y', c='#a3cc00')\n",
    "    if isInputPointsIn[5] and isInputPointsIn[6]:\n",
    "        ax.plot([input_x[5],input_x[6]], [input_y[5],input_y[6]], [input_z[5],input_z[6]], zdir='y', c='#8fb300')\n",
    "    if isInputPointsIn[6] and isInputPointsIn[7]:        \n",
    "        ax.plot([input_x[6],input_x[7]], [input_y[6],input_y[7]], [input_z[6],input_z[7]], zdir='y', c='#b8e600')\n",
    "    if isInputPointsIn[7] and isInputPointsIn[8]:\n",
    "        ax.plot([input_x[7],input_x[8]], [input_y[7],input_y[8]], [input_z[7],input_z[8]], zdir='y', c='#ccff00')\n",
    "    if isInputPointsIn[0] and isInputPointsIn[9]:\n",
    "        ax.plot([input_x[0],input_x[9]], [input_y[0],input_y[9]], [input_z[0],input_z[9]], zdir='y', c='#00cc52')\n",
    "    if isInputPointsIn[9] and isInputPointsIn[10]:\n",
    "        ax.plot([input_x[9],input_x[10]], [input_y[9],input_y[10]], [input_z[9],input_z[10]], zdir='y', c='#00b347')\n",
    "    if isInputPointsIn[10] and isInputPointsIn[11]:\n",
    "        ax.plot([input_x[10],input_x[11]], [input_y[10],input_y[11]], [input_z[10],input_z[11]], zdir='y', c='#00e65c')\n",
    "    if isInputPointsIn[11] and isInputPointsIn[12]:\n",
    "        ax.plot([input_x[11],input_x[12]], [input_y[11],input_y[12]], [input_z[11],input_z[12]], zdir='y', c='#00ff66')\n",
    "    if isInputPointsIn[0] and isInputPointsIn[13]:\n",
    "        ax.plot([input_x[0],input_x[13]], [input_y[0],input_y[13]], [input_z[0],input_z[13]], zdir='y', c='#0052cc')\n",
    "    if isInputPointsIn[13] and isInputPointsIn[14]:\n",
    "        ax.plot([input_x[13],input_x[14]], [input_y[13],input_y[14]], [input_z[13],input_z[14]], zdir='y', c='#0047b3')\n",
    "    if isInputPointsIn[14] and isInputPointsIn[15]:\n",
    "        ax.plot([input_x[14],input_x[15]], [input_y[14],input_y[15]], [input_z[14],input_z[15]], zdir='y', c='#005ce6')\n",
    "    if isInputPointsIn[15] and isInputPointsIn[16]:\n",
    "        ax.plot([input_x[15],input_x[16]], [input_y[15],input_y[16]], [input_z[15],input_z[16]], zdir='y', c='#0066ff')\n",
    "    if isInputPointsIn[0] and isInputPointsIn[17]:\n",
    "        ax.plot([input_x[0],input_x[17]], [input_y[0],input_y[17]], [input_z[0],input_z[17]], zdir='y', c='#a300cc')\n",
    "    if isInputPointsIn[17] and isInputPointsIn[18]:\n",
    "        ax.plot([input_x[17],input_x[18]], [input_y[17],input_y[18]], [input_z[17],input_z[18]], zdir='y', c='#8f00b3')\n",
    "    if isInputPointsIn[18] and isInputPointsIn[19]:\n",
    "        ax.plot([input_x[18],input_x[19]], [input_y[18],input_y[19]], [input_z[18],input_z[19]], zdir='y', c='#b800e6')\n",
    "    if isInputPointsIn[19] and isInputPointsIn[20]:\n",
    "        ax.plot([input_x[19],input_x[20]], [input_y[19],input_y[20]], [input_z[19],input_z[20]], zdir='y', c='#cc00ff')\n",
    "    \n",
    "    ##stradrs = str(test_adrs[target_epoch][i].item()) #202011221813290002\n",
    "    ##d_adrs = \"dataset_\" + stradrs[4:8] + \"_\" + stradrs[8:14] + \"_\" + stradrs[14:]\n",
    "    ##ax.set_title('input(test data, ' + str(target_epoch+1) + 'th epoch)\\n' + d_adrs)\n",
    "    ax.set_title('input(test data, ' + str(target_epoch+1) + 'th epoch)\\n' + str(i))\n",
    "    ax.set_xlim([x_min, x_max])\n",
    "    ax.set_ylim([z_min, z_max])\n",
    "    ax.set_zlim([y_min, y_max])\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('z')\n",
    "    ax.set_zlabel('y')\n",
    "    #plt.subplots_adjust(left=0.04, right=0.80, bottom=0.04, top=0.80)\n",
    "    #ax.legend(loc='upper right')\n",
    "    fig.savefig(PATH + \"\\\\outputs\\\\Input_test_\" + str(target_epoch) + \"th_epoch_\" + str(i) + \".png\", dpi = 300, transparent = False, bbox_inches = 'tight', pad_inches = 0)\n",
    "    fig.clf()\n",
    "    \n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    #各点をプロット\n",
    "    ax.scatter(output_x[0], output_y[0], zs=output_z[0], zdir='y', s=10, c='#e53528', marker = \".\")\n",
    "    ax.scatter(output_x[1], output_y[1], zs=output_z[1], zdir='y', s=10, c='#e77340', marker = \".\")\n",
    "    ax.scatter(output_x[2], output_y[2], zs=output_z[2], zdir='y', s=10, c='#eb8e25', marker = \".\")\n",
    "    ax.scatter(output_x[3], output_y[3], zs=output_z[3], zdir='y', s=10, c='#d7a10e', marker = \".\")\n",
    "    ax.scatter(output_x[4], output_y[4], zs=output_z[4], zdir='y', s=10, c='#d9c812', marker = \".\")\n",
    "    ax.scatter(output_x[5], output_y[5], zs=output_z[5], zdir='y', s=10, c='#a7cf21', marker = \".\")\n",
    "    ax.scatter(output_x[6], output_y[6], zs=output_z[6], zdir='y', s=10, c='#7fe545', marker = \".\")\n",
    "    ax.scatter(output_x[7], output_y[7], zs=output_z[7], zdir='y', s=10, c='#53d62d', marker = \".\")\n",
    "    ax.scatter(output_x[8], output_y[8], zs=output_z[8], zdir='y', s=10, c='#4abc2f', marker = \".\")\n",
    "    ax.scatter(output_x[9], output_y[9], zs=output_z[9], zdir='y', s=10, c='#52d686', marker = \".\")\n",
    "    ax.scatter(output_x[10], output_y[10], zs=output_z[10], zdir='y', s=10, c='#52dfbe', marker = \".\")\n",
    "    ax.scatter(output_x[11], output_y[11], zs=output_z[11], zdir='y', s=10, c='#52b9c5', marker = \".\")\n",
    "    ax.scatter(output_x[12], output_y[12], zs=output_z[12], zdir='y', s=10, c='#508ab7', marker = \".\")\n",
    "    ax.scatter(output_x[13], output_y[13], zs=output_z[13], zdir='y', s=10, c='#556fd0', marker = \".\")\n",
    "    ax.scatter(output_x[14], output_y[14], zs=output_z[14], zdir='y', s=10, c='#5245d5', marker = \".\")\n",
    "    ax.scatter(output_x[15], output_y[15], zs=output_z[15], zdir='y', s=10, c='#7e2fba', marker = \".\")\n",
    "    ax.scatter(output_x[16], output_y[16], zs=output_z[16], zdir='y', s=10, c='#bc64fb', marker = \".\")\n",
    "    ax.scatter(output_x[17], output_y[17], zs=output_z[17], zdir='y', s=10, c='#da53e8', marker = \".\")\n",
    "    ax.scatter(output_x[18], output_y[18], zs=output_z[18], zdir='y', s=10, c='#eb45bc', marker = \".\")\n",
    "    ax.scatter(output_x[19], output_y[19], zs=output_z[19], zdir='y', s=10, c='#ec3c89', marker = \".\")\n",
    "    ax.scatter(output_x[20], output_y[20], zs=output_z[20], zdir='y', s=10, c='#ff6691', marker = \".\")\n",
    "    \n",
    "    #点同士を結ぶ\n",
    "    if isOutputPointsIn[0] and isOutputPointsIn[1]:\n",
    "        ax.plot([output_x[0],output_x[1]], [output_y[0],output_y[1]], [output_z[0],output_z[1]], zdir='y', c='#cc0000')\n",
    "    if isOutputPointsIn[1] and isOutputPointsIn[2]:\n",
    "        ax.plot([output_x[1],output_x[2]], [output_y[1],output_y[2]], [output_z[1],output_z[2]], zdir='y', c='#b30000')\n",
    "    if isOutputPointsIn[2] and isOutputPointsIn[3]:\n",
    "        ax.plot([output_x[2],output_x[3]], [output_y[2],output_y[3]], [output_z[2],output_z[3]], zdir='y', c='#e60000')\n",
    "    if isOutputPointsIn[3] and isOutputPointsIn[4]:\n",
    "        ax.plot([output_x[3],output_x[4]], [output_y[3],output_y[4]], [output_z[3],output_z[4]], zdir='y', c='#ff0000')\n",
    "    if isOutputPointsIn[0] and isOutputPointsIn[5]:\n",
    "        ax.plot([output_x[0],output_x[5]], [output_y[0],output_y[5]], [output_z[0],output_z[5]], zdir='y', c='#a3cc00')\n",
    "    if isOutputPointsIn[5] and isOutputPointsIn[6]:\n",
    "        ax.plot([output_x[5],output_x[6]], [output_y[5],output_y[6]], [output_z[5],output_z[6]], zdir='y', c='#8fb300')\n",
    "    if isOutputPointsIn[6] and isOutputPointsIn[7]:        \n",
    "        ax.plot([output_x[6],output_x[7]], [output_y[6],output_y[7]], [output_z[6],output_z[7]], zdir='y', c='#b8e600')\n",
    "    if isOutputPointsIn[7] and isOutputPointsIn[8]:\n",
    "        ax.plot([output_x[7],output_x[8]], [output_y[7],output_y[8]], [output_z[7],output_z[8]], zdir='y', c='#ccff00')\n",
    "    if isOutputPointsIn[0] and isOutputPointsIn[9]:\n",
    "        ax.plot([output_x[0],output_x[9]], [output_y[0],output_y[9]], [output_z[0],output_z[9]], zdir='y', c='#00cc52')\n",
    "    if isOutputPointsIn[9] and isOutputPointsIn[10]:\n",
    "        ax.plot([output_x[9],output_x[10]], [output_y[9],output_y[10]], [output_z[9],output_z[10]], zdir='y', c='#00b347')\n",
    "    if isOutputPointsIn[10] and isOutputPointsIn[11]:\n",
    "        ax.plot([output_x[10],output_x[11]], [output_y[10],output_y[11]], [output_z[10],output_z[11]], zdir='y', c='#00e65c')\n",
    "    if isOutputPointsIn[11] and isOutputPointsIn[12]:\n",
    "        ax.plot([output_x[11],output_x[12]], [output_y[11],output_y[12]], [output_z[11],output_z[12]], zdir='y', c='#00ff66')\n",
    "    if isOutputPointsIn[0] and isOutputPointsIn[13]:\n",
    "        ax.plot([output_x[0],output_x[13]], [output_y[0],output_y[13]], [output_z[0],output_z[13]], zdir='y', c='#0052cc')\n",
    "    if isOutputPointsIn[13] and isOutputPointsIn[14]:\n",
    "        ax.plot([output_x[13],output_x[14]], [output_y[13],output_y[14]], [output_z[13],output_z[14]], zdir='y', c='#0047b3')\n",
    "    if isOutputPointsIn[14] and isOutputPointsIn[15]:\n",
    "        ax.plot([output_x[14],output_x[15]], [output_y[14],output_y[15]], [output_z[14],output_z[15]], zdir='y', c='#005ce6')\n",
    "    if isOutputPointsIn[15] and isOutputPointsIn[16]:\n",
    "        ax.plot([output_x[15],output_x[16]], [output_y[15],output_y[16]], [output_z[15],output_z[16]], zdir='y', c='#0066ff')\n",
    "    if isOutputPointsIn[0] and isOutputPointsIn[17]:\n",
    "        ax.plot([output_x[0],output_x[17]], [output_y[0],output_y[17]], [output_z[0],output_z[17]], zdir='y', c='#a300cc')\n",
    "    if isOutputPointsIn[17] and isOutputPointsIn[18]:\n",
    "        ax.plot([output_x[17],output_x[18]], [output_y[17],output_y[18]], [output_z[17],output_z[18]], zdir='y', c='#8f00b3')\n",
    "    if isOutputPointsIn[18] and isOutputPointsIn[19]:\n",
    "        ax.plot([output_x[18],output_x[19]], [output_y[18],output_y[19]], [output_z[18],output_z[19]], zdir='y', c='#b800e6')\n",
    "    if isOutputPointsIn[19] and isOutputPointsIn[20]:\n",
    "        ax.plot([output_x[19],output_x[20]], [output_y[19],output_y[20]], [output_z[19],output_z[20]], zdir='y', c='#cc00ff')\n",
    "    #ax.scatter(input_x, input_y, c='red', label = 'input')\n",
    "    #ax.scatter(output_x, output_y, c='blue', label = 'output')\n",
    "    \n",
    "    ##stradrs = str(test_adrs[target_epoch][i].item()) #11221813290002\n",
    "    ##d_adrs = \"dataset_\" + stradrs[4:8] + \"_\" + stradrs[8:14] + \"_\" + stradrs[14:]\n",
    "    ##ax.set_title('output(test data, ' + str(target_epoch+1) + 'th epoch)\\n' + d_adrs)\n",
    "    ax.set_title('output(test data, ' + str(target_epoch+1) + 'th epoch)\\n' + str(i))\n",
    "    ax.set_xlim([x_min, x_max])\n",
    "    ax.set_ylim([z_min, z_max])\n",
    "    ax.set_zlim([y_min, y_max])\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('z')\n",
    "    ax.set_zlabel('y')\n",
    "    #plt.subplots_adjust(left=0.04, right=0.80, bottom=0.04, top=0.80)\n",
    "    #ax.legend(loc='upper right')\n",
    "    fig.savefig(PATH + \"\\\\outputs\\\\Output_test_\" + str(target_epoch) + \"th_epoch_\" + str(i) + \".png\", dpi = 300, transparent = False, bbox_inches = 'tight', pad_inches = 0)\n",
    "    fig.clf()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fin loading\n",
      "data [-267. -214.  151.    0.    0.    0. -229. -102.  -87. -228.  -74.  -66.\n",
      "    0.    0.    0. -247. -151.  192. -249. -108.  208. -224.  -48.   -8.\n",
      " -225.  -33.  -62. -247. -145.  180.    0.    0.    0. -225.  -42.  -62.\n",
      " -234.  -34.  -73. -250. -145.  180. -224.  -73.  -36. -231.  -49.  -79.\n",
      " -239.  -40.  -96. -225.  -97.  -60. -228.  -74.  -66. -235.  -56.  -96.\n",
      " -238.  -51. -105.    0.]\n",
      "img [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "dmask [1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "imgmask [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "sean_firsts = []\n",
    "for sean in train_seanset:\n",
    "    #sean_imgcfile = glob.glob(sean + \"\\\\object*.png\")[0]\n",
    "    sean_imgdfile = glob.glob(sean + \"\\\\objectd*.png\")[0]\n",
    "    s_datafile = glob.glob(sean + \"\\\\data\\\\*0.csv\")[0]\n",
    "    #s_labelfile = glob.glob(sean + \"\\\\label\\\\*.csv\")[0]\n",
    "    pair = []\n",
    "    pair.append(s_datafile)\n",
    "    #pair.append(s_labelfile)\n",
    "    pair.append(sean_imgdfile)\n",
    "    sean_firsts.append(pair)\n",
    "\n",
    "data_recall = []\n",
    "img_recall = []\n",
    "mask_recall = []\n",
    "imgmask_recall = []\n",
    "for i in range(len(sean_firsts)):\n",
    "    # 画像読み込み\n",
    "    image = Image.open(sean_firsts[i][1])\n",
    "    # グレイスケール変換\n",
    "    #image = image.convert('L')\n",
    "    # リサイズ\n",
    "    image = image.resize((image_size, image_size))\n",
    "    ## 画像から配列に変換\n",
    "    #img_recall.append(np.asarray(image))\n",
    "    # 画像から配列に変換\n",
    "    img_array = np.asarray(image)\n",
    "    img_recall.append(img_array)\n",
    "    img_mask_array = np.zeros((image_size, image_size), np.uint8) #画像マスク\n",
    "    \n",
    "    #元画像の画素値が0の部分のみマスク画像の画素値を1にする\n",
    "    for h in range(img_array.shape[0]):\n",
    "        for w in range(img_array.shape[1]):\n",
    "            if 0 <= img_array[h,w] < 500:\n",
    "                img_mask_array[h,w] = 1\n",
    "    #img_names.append(os.path.basename(imgfile))\n",
    "    #file_split = [i for i in file.split('_')]\n",
    "    imgmask_recall.append(img_mask_array)\n",
    "    \n",
    "    data_points = []\n",
    "    data_masks = []\n",
    "    with open(sean_firsts[i][0]) as f:\n",
    "        reader = csv.reader(f)\n",
    "        num = 0\n",
    "        for row in reader:\n",
    "            if num == 0:\n",
    "                for point in row:\n",
    "                    if int(point) == -10000:\n",
    "                        data_points.append(float(0))\n",
    "                        data_masks.append(0)\n",
    "                    else:\n",
    "                        data_points.append(float(point))\n",
    "                        data_masks.append(1)\n",
    "                data_points = np.asarray(data_points)\n",
    "                data_masks = np.asarray(data_masks)\n",
    "                num += 1\n",
    "    data_recall.append(np.asarray(data_points))\n",
    "    mask_recall.append(np.asarray(data_masks))\n",
    "\n",
    "print(\"fin loading\")\n",
    "\n",
    "data_recall = np.array(data_recall).astype('float32')\n",
    "img_recall = np.array(img_recall).astype('float32')/1000\n",
    "mask_recall = np.array(mask_recall).astype('float32')\n",
    "imgmask_recall = np.array(imgmask_recall).astype('float32')\n",
    "\n",
    "print(\"data\",data_recall[0])\n",
    "print(\"img\",img_recall[0])\n",
    "print(\"dmask\",mask_recall[0])\n",
    "print(\"imgmask\",imgmask_recall[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trans = torchvision.transforms.Compose(\n",
    "#    [torchvision.transforms.ToTensor()]#,torchvision.transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))]\n",
    "#)\n",
    "\n",
    "class Mydatasets2(torch.utils.data.Dataset):\n",
    "    def __init__(self, datas, img_array, data_masks, img_masks, transform = None):\n",
    "        self.transform = transform\n",
    "        #self.transform2 = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "        self.data = datas\n",
    "        self.img_array = img_array\n",
    "        self.masks = data_masks\n",
    "        self.img_masks = img_masks\n",
    "\n",
    "        self.datanum = datas.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.datanum\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #batch_set = []\n",
    "        \n",
    "        i_data = self.data\n",
    "        i_img = self.img_array\n",
    "        i_mask = self.masks\n",
    "        i_imgmask = self.img_masks\n",
    "        \n",
    "        #print(out_label)\n",
    "        #print(type(i_label))\n",
    "        out_data = np.array(i_data.astype(np.float32))\n",
    "        out_img = np.array(i_img.astype(np.float32))\n",
    "        out_mask = np.array(i_mask.astype(np.float32))\n",
    "        out_imgmask = np.array(i_imgmask.astype(np.float32))\n",
    "        #out_label.append(i_label.astype(np.float32))\n",
    "        #print(type(out_label))\n",
    "\n",
    "        if self.transform:\n",
    "            #out_data = self.transform(i_data)\n",
    "            out_img = self.transform(out_img)\n",
    "            out_imgmask = self.transform(out_imgmask)\n",
    "            #out_label = self.transform2(out_label)\n",
    "        \n",
    "        #batch_set.append(out_data)\n",
    "        #batch_set.append(out_label)\n",
    "        #batch_set.append(out_img)\n",
    "        #batch_set.append(out_mask)\n",
    "        #batch_set.append(out_lmask)\n",
    "\n",
    "        return out_data, out_img, out_mask, out_imgmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: [-2.67 -2.14  1.51  0.    0.    0.   -2.29 -1.02 -0.87 -2.28 -0.74 -0.66\n",
      "  0.    0.    0.   -2.47 -1.51  1.92 -2.49 -1.08  2.08 -2.24 -0.48 -0.08\n",
      " -2.25 -0.33 -0.62 -2.47 -1.45  1.8   0.    0.    0.   -2.25 -0.42 -0.62\n",
      " -2.34 -0.34 -0.73 -2.5  -1.45  1.8  -2.24 -0.73 -0.36 -2.31 -0.49 -0.79\n",
      " -2.39 -0.4  -0.96 -2.25 -0.97 -0.6  -2.28 -0.74 -0.66 -2.35 -0.56 -0.96\n",
      " -2.38 -0.51 -1.05  0.  ]\n",
      "mask: [1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[-0.0860,  0.1340,  0.0328,  ...,  0.0711, -0.1427, -0.2274],\n",
      "        [-0.0860,  0.1340,  0.0328,  ...,  0.0711, -0.1427, -0.2274],\n",
      "        [-0.0860,  0.1340,  0.0328,  ...,  0.0711, -0.1427, -0.2274],\n",
      "        ...,\n",
      "        [ 0.3463, -0.4288,  1.2898,  ..., -1.1044,  0.0302,  0.9177],\n",
      "        [ 0.3201, -0.4484,  1.2825,  ..., -1.1012, -0.0286,  0.8106],\n",
      "        [ 0.3201, -0.4484,  1.2825,  ..., -1.1012, -0.0286,  0.8106]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.08597917  0.13398013  0.03284734 -0.2238421  -0.04775222 -0.2922598\n",
      " -0.36770087 -0.22261012 -0.50042355 -0.45858705 -0.37620264 -0.5588087\n",
      " -0.54167795 -0.5281545  -0.61268413 -0.36605376 -0.18920404 -0.7838677\n",
      " -0.2628851  -0.27281672 -0.4279192  -0.3213694  -0.4122167  -0.44215828\n",
      " -0.32549918 -0.48252574 -0.51983476 -0.28749037 -0.07497916 -0.77171046\n",
      " -0.323761   -0.23467702 -0.72324586 -0.30025572 -0.3496486  -0.7174445\n",
      " -0.19910835 -0.47472093 -0.68265104 -0.21936345 -0.02476467 -0.6186186\n",
      " -0.26692802 -0.07169417 -0.60641974 -0.19495836 -0.20871592 -0.58904445\n",
      " -0.01565662 -0.30983743 -0.42578673 -0.18403143  0.10871729 -0.5133198\n",
      " -0.11204502  0.03398013 -0.40560213 -0.06528944 -0.03204098 -0.4173532\n",
      "  0.071097   -0.14273044 -0.22741136]\n",
      "init: [-0.08597917  0.13398013  0.03284734 -0.2238421  -0.04775222 -0.2922598\n",
      " -0.36770087 -0.22261012 -0.50042355 -0.45858705 -0.37620264 -0.5588087\n",
      " -0.54167795 -0.5281545  -0.61268413 -0.36605376 -0.18920404 -0.7838677\n",
      " -0.2628851  -0.27281672 -0.4279192  -0.3213694  -0.4122167  -0.44215828\n",
      " -0.32549918 -0.48252574 -0.51983476 -0.28749037 -0.07497916 -0.77171046\n",
      " -0.323761   -0.23467702 -0.72324586 -0.30025572 -0.3496486  -0.7174445\n",
      " -0.19910835 -0.47472093 -0.68265104 -0.21936345 -0.02476467 -0.6186186\n",
      " -0.26692802 -0.07169417 -0.60641974 -0.19495836 -0.20871592 -0.58904445\n",
      " -0.01565662 -0.30983743 -0.42578673 -0.18403143  0.10871729 -0.5133198\n",
      " -0.11204502  0.03398013 -0.40560213 -0.06528944 -0.03204098 -0.4173532\n",
      "  0.071097   -0.14273044 -0.22741136]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [-0.08597918  0.13398013  0.03284734 -0.2238421  -0.04775222 -0.2922598\n",
      " -0.36770087 -0.22261012 -0.50042355 -0.45858705 -0.37620267 -0.5588087\n",
      " -0.54167795 -0.5281545  -0.61268413 -0.36605376 -0.18920404 -0.7838677\n",
      " -0.2628851  -0.27281672 -0.4279192  -0.3213694  -0.4122167  -0.44215828\n",
      " -0.32549918 -0.48252574 -0.51983476 -0.28749037 -0.07497916 -0.77171046\n",
      " -0.323761   -0.23467702 -0.72324586 -0.30025572 -0.3496486  -0.7174445\n",
      " -0.19910835 -0.47472093 -0.68265104 -0.21936344 -0.02476467 -0.6186186\n",
      " -0.26692802 -0.07169417 -0.60641974 -0.19495836 -0.20871592 -0.58904445\n",
      " -0.01565662 -0.30983743 -0.42578673 -0.18403143  0.10871729 -0.5133198\n",
      " -0.11204502  0.03398013 -0.4056021  -0.06528944 -0.03204098 -0.4173532\n",
      "  0.071097   -0.14273044 -0.22741136  0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FDA0>\n",
      "tensor([[ 0.1491, -0.2437,  0.3445,  ...,  0.2580, -0.4064, -0.7267],\n",
      "        [ 0.1491, -0.2437,  0.3445,  ...,  0.2580, -0.4064, -0.7267],\n",
      "        [ 0.1491, -0.2437,  0.3445,  ...,  0.2580, -0.4064, -0.7267],\n",
      "        ...,\n",
      "        [ 0.2593, -0.2058, -0.3711,  ..., -0.1222,  0.4656, -0.6661],\n",
      "        [-0.3658,  0.1735,  0.2365,  ..., -0.9804,  1.0799, -0.3212],\n",
      "        [-0.3658,  0.1735,  0.2365,  ..., -0.9804,  1.0799, -0.3212]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.1491305  -0.24365897  0.3444673   0.13450278 -0.4040655  -0.04541725\n",
      " -0.05680074 -0.6011403  -0.7496413  -0.21032171 -0.6777573  -0.96631074\n",
      " -0.39172965 -0.7471763  -1.399001   -0.06907193 -0.85724676 -0.9219812\n",
      "  0.0408899  -0.88717747 -0.7843728   0.0916306  -0.7786629  -0.81302595\n",
      "  0.16463493 -0.90831864 -0.8880998  -0.03256339 -0.7288414  -0.888672\n",
      "  0.06478751 -0.77906907 -0.8111974   0.12203465 -0.7327889  -0.86319315\n",
      "  0.40195885 -0.7160346  -0.95672596  0.05297945 -0.6893811  -0.76610386\n",
      "  0.00772129 -0.44120762 -1.168393    0.17801066 -0.57505786 -1.1632432\n",
      "  0.4269132  -0.50683737 -0.8698549  -0.02877736 -0.4288116  -0.6961113\n",
      "  0.00515783 -0.36748904 -0.76567495  0.11535676 -0.3621868  -0.8974221\n",
      "  0.25802037 -0.40644443 -0.7266755 ]\n",
      "data: [ 0.1491305  -0.24365897  0.3444673   0.13450278 -0.4040655  -0.04541725\n",
      " -0.05680074 -0.6011403  -0.74964124 -0.21032171 -0.6777573  -0.96631074\n",
      " -0.39172965 -0.7471763  -1.399001   -0.06907193 -0.85724676 -0.9219812\n",
      "  0.0408899  -0.8871774  -0.7843728   0.0916306  -0.7786629  -0.81302595\n",
      "  0.16463493 -0.90831864 -0.88809985 -0.03256339 -0.7288414  -0.88867205\n",
      "  0.06478751 -0.77906907 -0.81119746  0.12203465 -0.7327889  -0.86319315\n",
      "  0.40195885 -0.71603465 -0.9567259   0.05297945 -0.6893811  -0.7661039\n",
      "  0.00772129 -0.44120762 -1.168393    0.17801066 -0.57505786 -1.1632432\n",
      "  0.42691317 -0.50683737 -0.86985487 -0.02877736 -0.4288116  -0.6961113\n",
      "  0.00515783 -0.36748904 -0.76567495  0.11535676 -0.3621868  -0.8974221\n",
      "  0.25802037 -0.40644443 -0.7266755   0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[ 0.0960, -0.0523, -0.0680,  ...,  0.0507, -0.2375, -1.1908],\n",
      "        [ 0.0960, -0.0523, -0.0680,  ...,  0.0507, -0.2375, -1.1908],\n",
      "        [ 0.0960, -0.0523, -0.0680,  ...,  0.0507, -0.2375, -1.1908],\n",
      "        ...,\n",
      "        [-0.2718,  0.1218,  0.4762,  ..., -0.1439,  0.7968,  0.0094],\n",
      "        [-0.2433,  0.3189,  0.5029,  ..., -0.2702,  0.7665,  0.2391],\n",
      "        [-0.2433,  0.3189,  0.5029,  ..., -0.2702,  0.7665,  0.2391]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 9.6038580e-02 -5.2291222e-02 -6.7999817e-02  5.1687039e-02\n",
      " -2.3939218e-01 -5.0626493e-01  1.0077007e-02 -3.8684389e-01\n",
      " -1.0978034e+00 -1.6531838e-01 -4.4782996e-01 -1.4219295e+00\n",
      " -4.1501081e-01 -5.8628190e-01 -1.8885095e+00 -1.7112000e-01\n",
      " -6.1159968e-01 -1.3764247e+00  1.6435236e-03 -6.4138615e-01\n",
      " -1.2573211e+00 -5.2158400e-02 -5.5940002e-01 -1.3180797e+00\n",
      " -1.8985391e-02 -6.9690025e-01 -1.3816382e+00 -1.1860241e-01\n",
      " -4.7981763e-01 -1.3040875e+00 -4.9213707e-02 -5.4546475e-01\n",
      " -1.2597202e+00 -9.6074477e-02 -5.7732505e-01 -1.4004545e+00\n",
      "  5.4986775e-03 -5.2787882e-01 -1.4430389e+00 -1.9105569e-02\n",
      " -4.3280280e-01 -1.1492953e+00 -7.8854278e-02 -2.6317918e-01\n",
      " -1.5595404e+00 -2.4113759e-02 -3.8943660e-01 -1.5284729e+00\n",
      "  9.1003396e-02 -3.7618202e-01 -1.2865201e+00 -7.4549094e-02\n",
      " -2.0443019e-01 -1.1287098e+00 -3.0365989e-02 -2.1793890e-01\n",
      " -1.1821213e+00  9.5929950e-03 -2.4661072e-01 -1.2809902e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5.0687633e-02 -2.3753284e-01 -1.1907634e+00]\n",
      "data: [ 9.6038580e-02 -5.2291222e-02 -6.7999817e-02  5.1687039e-02\n",
      " -2.3939219e-01 -5.0626493e-01  1.0077007e-02 -3.8684386e-01\n",
      " -1.0978034e+00 -1.6531840e-01 -4.4782996e-01 -1.4219295e+00\n",
      " -4.1501081e-01 -5.8628190e-01 -1.8885095e+00 -1.7111999e-01\n",
      " -6.1159968e-01 -1.3764247e+00  1.6435236e-03 -6.4138621e-01\n",
      " -1.2573211e+00 -5.2158400e-02 -5.5940002e-01 -1.3180797e+00\n",
      " -1.8985391e-02 -6.9690025e-01 -1.3816382e+00 -1.1860241e-01\n",
      " -4.7981763e-01 -1.3040875e+00 -4.9213704e-02 -5.4546475e-01\n",
      " -1.2597202e+00 -9.6074477e-02 -5.7732505e-01 -1.4004545e+00\n",
      "  5.4986775e-03 -5.2787882e-01 -1.4430389e+00 -1.9105569e-02\n",
      " -4.3280280e-01 -1.1492953e+00 -7.8854278e-02 -2.6317918e-01\n",
      " -1.5595404e+00 -2.4113759e-02 -3.8943660e-01 -1.5284729e+00\n",
      "  9.1003396e-02 -3.7618202e-01 -1.2865201e+00 -7.4549094e-02\n",
      " -2.0443019e-01 -1.1287098e+00 -3.0365989e-02 -2.1793890e-01\n",
      " -1.1821213e+00  9.5929950e-03 -2.4661072e-01 -1.2809902e+00\n",
      "  5.0687633e-02 -2.3753284e-01 -1.1907634e+00  2.9999999e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F400>\n",
      "tensor([[ 0.0517, -0.1195, -0.2515,  ...,  0.0938, -0.2959, -1.2988],\n",
      "        [ 0.0517, -0.1195, -0.2515,  ...,  0.0938, -0.2959, -1.2988],\n",
      "        [ 0.0517, -0.1195, -0.2515,  ...,  0.0938, -0.2959, -1.2988],\n",
      "        ...,\n",
      "        [-0.1652,  0.4453, -0.0036,  ..., -0.4342,  1.0224, -0.3573],\n",
      "        [-0.1283, -0.0405,  0.6267,  ..., -0.3206,  0.7289,  0.2536],\n",
      "        [-0.1283, -0.0405,  0.6267,  ..., -0.3206,  0.7289,  0.2536]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.05170729 -0.11946306 -0.25146177  0.07439709 -0.26663268 -0.6698185\n",
      " -0.02113421 -0.44802582 -1.4049542  -0.16715124 -0.50781727 -1.6923715\n",
      " -0.33744368 -0.6230785  -2.157974   -0.15572062 -0.72213465 -1.5714961\n",
      "  0.06470686 -0.74647266 -1.3723397   0.02478246 -0.6757747  -1.4218055\n",
      "  0.03174589 -0.8012068  -1.5336429  -0.11246248 -0.6101552  -1.494319\n",
      " -0.02147976 -0.66381603 -1.4599551  -0.01979355 -0.6344015  -1.5412269\n",
      "  0.12551402 -0.6550004  -1.5942454  -0.0166036  -0.5321289  -1.3227704\n",
      " -0.12631305 -0.29151246 -1.941459    0.03436853 -0.4532817  -1.9322101\n",
      "  0.20034423 -0.40837586 -1.4543331  -0.12133425 -0.28988224 -1.2590694\n",
      " -0.03955041 -0.25902027 -1.3332468   0.0172718  -0.2766142  -1.4525557\n",
      "  0.09380374 -0.29593563 -1.2987741 ]\n",
      "data: [ 0.05170729 -0.11946306 -0.25146177  0.07439709 -0.26663268 -0.6698185\n",
      " -0.02113421 -0.44802582 -1.4049542  -0.16715124 -0.50781727 -1.6923715\n",
      " -0.3374437  -0.6230785  -2.157974   -0.15572062 -0.72213465 -1.5714961\n",
      "  0.06470686 -0.7464726  -1.3723397   0.02478246 -0.6757747  -1.4218056\n",
      "  0.03174589 -0.8012068  -1.5336429  -0.11246248 -0.6101552  -1.494319\n",
      " -0.02147976 -0.6638161  -1.4599551  -0.01979355 -0.6344015  -1.5412269\n",
      "  0.12551402 -0.6550004  -1.5942454  -0.0166036  -0.5321289  -1.3227704\n",
      " -0.12631305 -0.29151246 -1.941459    0.03436853 -0.4532817  -1.9322101\n",
      "  0.20034423 -0.40837586 -1.4543331  -0.12133425 -0.28988224 -1.2590694\n",
      " -0.03955041 -0.25902027 -1.3332467   0.0172718  -0.2766142  -1.4525557\n",
      "  0.09380374 -0.29593563 -1.2987741   0.04      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B320>\n",
      "tensor([[ 0.0380, -0.1556, -0.2420,  ...,  0.0770, -0.3407, -1.2998],\n",
      "        [ 0.0380, -0.1556, -0.2420,  ...,  0.0770, -0.3407, -1.2998],\n",
      "        [ 0.0380, -0.1556, -0.2420,  ...,  0.0770, -0.3407, -1.2998],\n",
      "        ...,\n",
      "        [-0.0930,  0.4554, -0.1095,  ..., -0.6148,  0.9472, -0.4325],\n",
      "        [-0.1379, -0.0513,  0.6226,  ..., -0.2056,  0.7047,  0.2742],\n",
      "        [-0.1379, -0.0513,  0.6226,  ..., -0.2056,  0.7047,  0.2742]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03795699 -0.15555266 -0.24200672  0.05743864 -0.29964176 -0.6476401\n",
      " -0.01988611 -0.49178782 -1.4056079  -0.1666744  -0.5544102  -1.7140906\n",
      " -0.3400792  -0.681386   -2.185159   -0.17322038 -0.7627593  -1.5851539\n",
      "  0.07524262 -0.79819214 -1.3767084   0.01663141 -0.7403382  -1.4245104\n",
      "  0.00875751 -0.87122    -1.5435308  -0.12116672 -0.6526816  -1.4904157\n",
      " -0.02940217 -0.71626925 -1.4676257  -0.0341679  -0.69218683 -1.5640594\n",
      "  0.08570001 -0.72597635 -1.6132058  -0.01717698 -0.5624913  -1.3122189\n",
      " -0.13964127 -0.33529326 -1.9580334   0.02002636 -0.5028813  -1.9498049\n",
      "  0.17467405 -0.46362105 -1.4609582  -0.13316567 -0.3215391  -1.2467562\n",
      " -0.0346853  -0.3021739  -1.3244467   0.01424332 -0.3319726  -1.4377847\n",
      "  0.07695127 -0.34066582 -1.2998099 ]\n",
      "data: [ 0.03795699 -0.15555266 -0.24200672  0.05743863 -0.29964176 -0.64764005\n",
      " -0.01988611 -0.49178782 -1.4056079  -0.1666744  -0.5544102  -1.7140906\n",
      " -0.3400792  -0.68138593 -2.185159   -0.17322038 -0.7627593  -1.5851539\n",
      "  0.07524262 -0.79819214 -1.3767084   0.01663141 -0.7403382  -1.4245104\n",
      "  0.00875751 -0.87122    -1.543531   -0.12116673 -0.6526816  -1.4904157\n",
      " -0.02940217 -0.71626925 -1.4676257  -0.0341679  -0.69218683 -1.5640595\n",
      "  0.08570001 -0.72597635 -1.6132057  -0.01717698 -0.5624913  -1.3122189\n",
      " -0.13964127 -0.33529326 -1.9580334   0.02002636 -0.5028813  -1.9498048\n",
      "  0.17467405 -0.46362105 -1.4609582  -0.13316567 -0.3215391  -1.2467562\n",
      " -0.0346853  -0.3021739  -1.3244467   0.01424332 -0.33197257 -1.4377847\n",
      "  0.07695127 -0.34066582 -1.2998099   0.05      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FB70>\n",
      "tensor([[ 0.0257, -0.1406, -0.2046,  ...,  0.0690, -0.3370, -1.1910],\n",
      "        [ 0.0257, -0.1406, -0.2046,  ...,  0.0690, -0.3370, -1.1910],\n",
      "        [ 0.0257, -0.1406, -0.2046,  ...,  0.0690, -0.3370, -1.1910],\n",
      "        ...,\n",
      "        [-0.0457,  0.4998, -0.1163,  ..., -0.4902,  1.0347, -0.4927],\n",
      "        [-0.1237, -0.0380,  0.6224,  ..., -0.2079,  0.6663,  0.2787],\n",
      "        [-0.1237, -0.0380,  0.6224,  ..., -0.2079,  0.6663,  0.2787]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.5730249e-02 -1.4060399e-01 -2.0463538e-01  5.8656860e-02\n",
      " -2.4520200e-01 -4.9579999e-01 -8.2119428e-02 -4.7766930e-01\n",
      " -1.3501356e+00 -2.3825027e-01 -5.4416931e-01 -1.6405212e+00\n",
      " -3.8466990e-01 -6.4039922e-01 -2.1518991e+00 -1.6676651e-01\n",
      " -7.7880025e-01 -1.5363030e+00  1.2954071e-02 -8.4877813e-01\n",
      " -1.3861394e+00 -4.3935135e-02 -7.7385831e-01 -1.4352542e+00\n",
      " -5.2355930e-02 -9.4461143e-01 -1.5604768e+00 -1.1822359e-01\n",
      " -6.9223118e-01 -1.4325460e+00 -6.0313076e-02 -7.4817026e-01\n",
      " -1.4056648e+00 -6.9597527e-02 -7.1392894e-01 -1.4858637e+00\n",
      "  6.4905971e-02 -7.5272739e-01 -1.4982280e+00 -2.8449707e-02\n",
      " -5.7736778e-01 -1.2687986e+00 -1.9063140e-01 -3.3866975e-01\n",
      " -2.0409422e+00  4.2874366e-04 -5.2188027e-01 -2.0645864e+00\n",
      "  1.7584090e-01 -4.7852436e-01 -1.3652276e+00 -1.5443091e-01\n",
      " -3.4993386e-01 -1.1884551e+00 -7.7305838e-02 -3.1976962e-01\n",
      " -1.2773614e+00 -4.3809175e-02 -3.2594058e-01 -1.3891813e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6.9013499e-02 -3.3703291e-01 -1.1909983e+00]\n",
      "data: [ 2.5730247e-02 -1.4060399e-01 -2.0463540e-01  5.8656860e-02\n",
      " -2.4520200e-01 -4.9579999e-01 -8.2119428e-02 -4.7766930e-01\n",
      " -1.3501354e+00 -2.3825027e-01 -5.4416931e-01 -1.6405213e+00\n",
      " -3.8466990e-01 -6.4039922e-01 -2.1518991e+00 -1.6676651e-01\n",
      " -7.7880025e-01 -1.5363030e+00  1.2954070e-02 -8.4877813e-01\n",
      " -1.3861394e+00 -4.3935135e-02 -7.7385831e-01 -1.4352542e+00\n",
      " -5.2355930e-02 -9.4461143e-01 -1.5604768e+00 -1.1822359e-01\n",
      " -6.9223112e-01 -1.4325461e+00 -6.0313076e-02 -7.4817026e-01\n",
      " -1.4056648e+00 -6.9597527e-02 -7.1392894e-01 -1.4858637e+00\n",
      "  6.4905971e-02 -7.5272733e-01 -1.4982280e+00 -2.8449707e-02\n",
      " -5.7736778e-01 -1.2687986e+00 -1.9063140e-01 -3.3866975e-01\n",
      " -2.0409422e+00  4.2874366e-04 -5.2188027e-01 -2.0645864e+00\n",
      "  1.7584090e-01 -4.7852436e-01 -1.3652275e+00 -1.5443091e-01\n",
      " -3.4993386e-01 -1.1884551e+00 -7.7305838e-02 -3.1976962e-01\n",
      " -1.2773614e+00 -4.3809175e-02 -3.2594058e-01 -1.3891813e+00\n",
      "  6.9013499e-02 -3.3703291e-01 -1.1909983e+00  5.9999999e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0139, -0.0638, -0.1882,  ...,  0.0297, -0.2533, -1.1683],\n",
      "        [-0.0139, -0.0638, -0.1882,  ...,  0.0297, -0.2533, -1.1683],\n",
      "        [-0.0139, -0.0638, -0.1882,  ...,  0.0297, -0.2533, -1.1683],\n",
      "        ...,\n",
      "        [-0.1627,  0.3758,  0.0143,  ..., -0.7044,  0.9467, -0.3858],\n",
      "        [-0.0911, -0.0405,  0.6090,  ..., -0.1961,  0.6513,  0.2416],\n",
      "        [-0.0911, -0.0405,  0.6090,  ..., -0.1961,  0.6513,  0.2416]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-1.3876754e-02 -6.3771307e-02 -1.8822914e-01  1.3270367e-02\n",
      " -1.7788915e-01 -4.7703427e-01 -1.0728800e-01 -4.0041131e-01\n",
      " -1.3239269e+00 -2.6284224e-01 -4.6242693e-01 -1.6289883e+00\n",
      " -4.3067086e-01 -5.7259107e-01 -2.1302638e+00 -2.2180603e-01\n",
      " -6.9373572e-01 -1.5099089e+00 -1.4320314e-03 -7.4882376e-01\n",
      " -1.3240731e+00 -5.7948202e-02 -6.8343109e-01 -1.3697226e+00\n",
      " -6.0290620e-02 -8.3902746e-01 -1.4995049e+00 -1.7008436e-01\n",
      " -5.9603840e-01 -1.4004632e+00 -9.3163364e-02 -6.5570039e-01\n",
      " -1.3767358e+00 -8.8775486e-02 -6.2227798e-01 -1.4707146e+00\n",
      "  5.3144544e-02 -6.6327888e-01 -1.5017090e+00 -7.0022948e-02\n",
      " -4.8664042e-01 -1.2251292e+00 -2.2902830e-01 -2.5099140e-01\n",
      " -1.9896284e+00 -3.0143298e-02 -4.3228027e-01 -2.0031240e+00\n",
      "  1.5404172e-01 -3.8843554e-01 -1.3478401e+00 -2.0112698e-01\n",
      " -2.5140196e-01 -1.1487209e+00 -1.0981971e-01 -2.2801712e-01\n",
      " -1.2287613e+00 -6.9668025e-02 -2.4472743e-01 -1.3443445e+00\n",
      "  2.9733084e-02 -2.5328368e-01 -1.1682668e+00]\n",
      "data: [-1.38767539e-02 -6.37713075e-02 -1.88229144e-01  1.32703669e-02\n",
      " -1.77889153e-01 -4.77034271e-01 -1.07287996e-01 -4.00411308e-01\n",
      " -1.32392704e+00 -2.62842238e-01 -4.62426960e-01 -1.62898839e+00\n",
      " -4.30670857e-01 -5.72591066e-01 -2.13026381e+00 -2.21806034e-01\n",
      " -6.93735719e-01 -1.50990891e+00 -1.43203139e-03 -7.48823762e-01\n",
      " -1.32407308e+00 -5.79482019e-02 -6.83431089e-01 -1.36972260e+00\n",
      " -6.02906197e-02 -8.39027464e-01 -1.49950480e+00 -1.70084357e-01\n",
      " -5.96038401e-01 -1.40046322e+00 -9.31633636e-02 -6.55700386e-01\n",
      " -1.37673581e+00 -8.87754858e-02 -6.22277975e-01 -1.47071457e+00\n",
      "  5.31445444e-02 -6.63278878e-01 -1.50170898e+00 -7.00229481e-02\n",
      " -4.86640424e-01 -1.22512925e+00 -2.29028299e-01 -2.50991404e-01\n",
      " -1.98962843e+00 -3.01432982e-02 -4.32280272e-01 -2.00312400e+00\n",
      "  1.54041722e-01 -3.88435543e-01 -1.34784007e+00 -2.01126978e-01\n",
      " -2.51401961e-01 -1.14872086e+00 -1.09819710e-01 -2.28017122e-01\n",
      " -1.22876132e+00 -6.96680248e-02 -2.44727433e-01 -1.34434450e+00\n",
      "  2.97330841e-02 -2.53283679e-01 -1.16826677e+00  7.00000003e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[-1.0087e-03, -8.4842e-02, -2.5648e-01,  ..., -8.8715e-03,\n",
      "         -2.4809e-01, -1.2953e+00],\n",
      "        [-1.0087e-03, -8.4842e-02, -2.5648e-01,  ..., -8.8715e-03,\n",
      "         -2.4809e-01, -1.2953e+00],\n",
      "        [-1.0087e-03, -8.4842e-02, -2.5648e-01,  ..., -8.8715e-03,\n",
      "         -2.4809e-01, -1.2953e+00],\n",
      "        ...,\n",
      "        [-2.6754e-01,  2.3781e-01, -1.4234e-01,  ..., -6.7272e-01,\n",
      "          7.1797e-01, -4.3869e-01],\n",
      "        [-5.0797e-02,  2.4181e-03,  6.7341e-01,  ..., -1.7392e-01,\n",
      "          7.7135e-01,  3.2186e-01],\n",
      "        [-5.0797e-02,  2.4181e-03,  6.7341e-01,  ..., -1.7392e-01,\n",
      "          7.7135e-01,  3.2186e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-1.00868475e-03 -8.48416537e-02 -2.56480098e-01  2.48454250e-02\n",
      " -2.06156239e-01 -6.37540817e-01 -9.50557217e-02 -4.07911897e-01\n",
      " -1.42587519e+00 -2.45064884e-01 -4.68462050e-01 -1.72141671e+00\n",
      " -4.08176839e-01 -5.58960676e-01 -2.21309519e+00 -2.02247307e-01\n",
      " -7.06532001e-01 -1.57842815e+00 -2.05951929e-02 -7.47577310e-01\n",
      " -1.39404833e+00 -6.66933358e-02 -6.78790748e-01 -1.45280707e+00\n",
      " -7.98221380e-02 -8.29724908e-01 -1.57897854e+00 -1.66841760e-01\n",
      " -6.10492527e-01 -1.48816752e+00 -1.03575572e-01 -6.58003688e-01\n",
      " -1.45968282e+00 -1.17697120e-01 -6.23752654e-01 -1.55550969e+00\n",
      "  2.62253284e-02 -6.47030354e-01 -1.59065652e+00 -9.02500227e-02\n",
      " -5.04711747e-01 -1.32391703e+00 -2.28123188e-01 -2.73421645e-01\n",
      " -2.03083992e+00 -5.93100488e-02 -4.27047610e-01 -2.05036211e+00\n",
      "  1.08567715e-01 -3.91930163e-01 -1.45127881e+00 -1.98347732e-01\n",
      " -2.72338331e-01 -1.25221479e+00 -1.41074717e-01 -2.39351049e-01\n",
      " -1.33900928e+00 -1.05349377e-01 -2.36848578e-01 -1.46082127e+00\n",
      " -8.87148082e-03 -2.48091221e-01 -1.29528534e+00]\n",
      "data: [-1.00868475e-03 -8.48416537e-02 -2.56480098e-01  2.48454269e-02\n",
      " -2.06156239e-01 -6.37540817e-01 -9.50557217e-02 -4.07911897e-01\n",
      " -1.42587519e+00 -2.45064884e-01 -4.68462080e-01 -1.72141683e+00\n",
      " -4.08176839e-01 -5.58960676e-01 -2.21309519e+00 -2.02247322e-01\n",
      " -7.06532001e-01 -1.57842815e+00 -2.05951929e-02 -7.47577310e-01\n",
      " -1.39404833e+00 -6.66933358e-02 -6.78790748e-01 -1.45280695e+00\n",
      " -7.98221380e-02 -8.29724908e-01 -1.57897854e+00 -1.66841760e-01\n",
      " -6.10492527e-01 -1.48816752e+00 -1.03575572e-01 -6.58003688e-01\n",
      " -1.45968282e+00 -1.17697127e-01 -6.23752654e-01 -1.55550969e+00\n",
      "  2.62253284e-02 -6.47030354e-01 -1.59065664e+00 -9.02500227e-02\n",
      " -5.04711747e-01 -1.32391703e+00 -2.28123188e-01 -2.73421645e-01\n",
      " -2.03083992e+00 -5.93100488e-02 -4.27047610e-01 -2.05036211e+00\n",
      "  1.08567715e-01 -3.91930163e-01 -1.45127881e+00 -1.98347747e-01\n",
      " -2.72338331e-01 -1.25221479e+00 -1.41074717e-01 -2.39351049e-01\n",
      " -1.33900928e+00 -1.05349377e-01 -2.36848578e-01 -1.46082127e+00\n",
      " -8.87148082e-03 -2.48091221e-01 -1.29528534e+00  7.99999982e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F198>\n",
      "tensor([[ 0.0351, -0.0222, -0.1994,  ...,  0.0352, -0.2148, -1.2256],\n",
      "        [ 0.0351, -0.0222, -0.1994,  ...,  0.0352, -0.2148, -1.2256],\n",
      "        [ 0.0351, -0.0222, -0.1994,  ...,  0.0352, -0.2148, -1.2256],\n",
      "        ...,\n",
      "        [-0.2375,  0.3523, -0.1429,  ..., -0.8935,  0.8591, -0.3615],\n",
      "        [-0.1459, -0.1740,  0.5588,  ..., -0.2204,  0.5775,  0.2597],\n",
      "        [-0.1459, -0.1740,  0.5588,  ..., -0.2204,  0.5775,  0.2597]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03507571 -0.02217044 -0.19935161  0.05034405 -0.1386372  -0.5647582\n",
      " -0.07828549 -0.33181655 -1.3458166  -0.23150101 -0.3966332  -1.6337163\n",
      " -0.39514634 -0.4803506  -2.1395338  -0.15575352 -0.6514964  -1.5005147\n",
      " -0.01187785 -0.6993803  -1.3609922  -0.06082909 -0.62053776 -1.425339\n",
      " -0.06160775 -0.7817609  -1.5416181  -0.12078133 -0.5644287  -1.4168632\n",
      " -0.06788393 -0.60624874 -1.3853378  -0.09689394 -0.5774303  -1.4809196\n",
      "  0.04489978 -0.58815604 -1.4992704  -0.05218808 -0.46751106 -1.2604277\n",
      " -0.17539936 -0.23938526 -1.9414468  -0.02616435 -0.38380224 -1.9661252\n",
      "  0.1371652  -0.36215842 -1.3712687  -0.14776783 -0.24019973 -1.1909404\n",
      " -0.10166125 -0.21535783 -1.2838671  -0.07532749 -0.2012226  -1.4014685\n",
      "  0.03516836 -0.21477407 -1.2256479 ]\n",
      "data: [ 0.03507571 -0.02217044 -0.19935161  0.05034405 -0.1386372  -0.5647582\n",
      " -0.07828549 -0.33181655 -1.3458166  -0.23150101 -0.39663324 -1.6337162\n",
      " -0.39514634 -0.4803506  -2.1395338  -0.15575352 -0.6514964  -1.5005146\n",
      " -0.01187785 -0.6993803  -1.3609921  -0.06082909 -0.62053776 -1.4253391\n",
      " -0.06160775 -0.7817609  -1.541618   -0.12078133 -0.5644287  -1.4168632\n",
      " -0.06788393 -0.60624874 -1.3853378  -0.09689394 -0.5774303  -1.4809196\n",
      "  0.04489978 -0.58815604 -1.4992704  -0.05218808 -0.46751106 -1.2604277\n",
      " -0.17539936 -0.23938526 -1.9414468  -0.02616435 -0.38380224 -1.9661251\n",
      "  0.1371652  -0.36215842 -1.3712687  -0.14776783 -0.24019974 -1.1909404\n",
      " -0.10166125 -0.21535783 -1.2838672  -0.07532749 -0.2012226  -1.4014685\n",
      "  0.03516836 -0.21477407 -1.2256479   0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B320>\n",
      "tensor([[ 0.0250, -0.0627, -0.2426,  ...,  0.0312, -0.2463, -1.2969],\n",
      "        [ 0.0250, -0.0627, -0.2426,  ...,  0.0312, -0.2463, -1.2969],\n",
      "        [ 0.0250, -0.0627, -0.2426,  ...,  0.0312, -0.2463, -1.2969],\n",
      "        ...,\n",
      "        [-0.2666,  0.2449, -0.1916,  ..., -0.7968,  0.6594, -0.3203],\n",
      "        [-0.1487, -0.1058,  0.5424,  ..., -0.2431,  0.6788,  0.2608],\n",
      "        [-0.1487, -0.1058,  0.5424,  ..., -0.2431,  0.6788,  0.2608]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0249923  -0.06267391 -0.24257971  0.04633604 -0.20032646 -0.6567104\n",
      " -0.06556109 -0.38695255 -1.4216447  -0.21118894 -0.4548484  -1.7020816\n",
      " -0.37591034 -0.5543032  -2.188117   -0.17363372 -0.67525244 -1.5715396\n",
      "  0.0022566  -0.7127839  -1.3921955  -0.04325658 -0.64176905 -1.4491018\n",
      " -0.04758931 -0.7805176  -1.5600841  -0.13804361 -0.57593334 -1.4949554\n",
      " -0.07005025 -0.62617975 -1.4559921  -0.09312885 -0.59943974 -1.5434619\n",
      "  0.0429154  -0.6115702  -1.5788007  -0.06478358 -0.49390295 -1.3322514\n",
      " -0.17384617 -0.26438954 -1.9605533  -0.03054584 -0.41066968 -1.9678513\n",
      "  0.12193918 -0.3844598  -1.4447172  -0.1567909  -0.258793   -1.2663392\n",
      " -0.09985889 -0.2338386  -1.3462411  -0.05667391 -0.23233655 -1.4617989\n",
      "  0.03116909 -0.24632965 -1.2968881 ]\n",
      "data: [ 0.0249923  -0.06267391 -0.24257971  0.04633604 -0.20032646 -0.6567104\n",
      " -0.06556109 -0.38695255 -1.4216447  -0.21118894 -0.4548484  -1.7020816\n",
      " -0.37591034 -0.5543032  -2.188117   -0.17363372 -0.67525244 -1.5715396\n",
      "  0.0022566  -0.7127839  -1.3921955  -0.04325658 -0.64176905 -1.4491019\n",
      " -0.04758931 -0.7805176  -1.5600841  -0.13804361 -0.57593334 -1.4949554\n",
      " -0.07005025 -0.62617975 -1.4559921  -0.09312885 -0.59943974 -1.5434619\n",
      "  0.0429154  -0.6115702  -1.5788007  -0.06478358 -0.49390298 -1.3322514\n",
      " -0.17384617 -0.26438954 -1.9605533  -0.03054584 -0.41066968 -1.9678513\n",
      "  0.12193918 -0.3844598  -1.444717   -0.1567909  -0.258793   -1.2663392\n",
      " -0.09985889 -0.2338386  -1.3462411  -0.05667391 -0.23233657 -1.4617989\n",
      "  0.03116909 -0.24632965 -1.2968881   0.1       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FE80>\n",
      "tensor([[ 0.0273, -0.0723, -0.2512,  ...,  0.0545, -0.2603, -1.2833],\n",
      "        [ 0.0273, -0.0723, -0.2512,  ...,  0.0545, -0.2603, -1.2833],\n",
      "        [ 0.0273, -0.0723, -0.2512,  ...,  0.0545, -0.2603, -1.2833],\n",
      "        ...,\n",
      "        [-0.1147,  0.3829, -0.1070,  ..., -0.7222,  0.8922, -0.3708],\n",
      "        [-0.1350, -0.1530,  0.5647,  ..., -0.2409,  0.6200,  0.2245],\n",
      "        [-0.1350, -0.1530,  0.5647,  ..., -0.2409,  0.6200,  0.2245]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02732201 -0.07232016 -0.2512137   0.05029817 -0.19940645 -0.6430003\n",
      " -0.05081048 -0.38769922 -1.4050951  -0.19401923 -0.4491844  -1.6987998\n",
      " -0.35390437 -0.5533388  -2.182774   -0.1674723  -0.6832994  -1.5639303\n",
      "  0.02628723 -0.7204339  -1.3973858  -0.02389716 -0.6529386  -1.4549313\n",
      " -0.02448418 -0.79695314 -1.572959   -0.12612775 -0.5876136  -1.4772487\n",
      " -0.05276941 -0.6380237  -1.4517019  -0.06739634 -0.61080235 -1.5438981\n",
      "  0.06535512 -0.6338418  -1.5793803  -0.04310311 -0.4960271  -1.309813\n",
      " -0.16274446 -0.26742136 -1.9758792  -0.00504131 -0.42237768 -1.9847386\n",
      "  0.15353785 -0.3926072  -1.4395666  -0.145431   -0.26548567 -1.2423384\n",
      " -0.07331772 -0.24156529 -1.3264349  -0.03345931 -0.2473535  -1.4432251\n",
      "  0.05451205 -0.26034933 -1.2833054 ]\n",
      "data: [ 0.02732201 -0.07232016 -0.2512137   0.05029817 -0.19940645 -0.64300036\n",
      " -0.05081048 -0.38769922 -1.4050951  -0.19401923 -0.4491844  -1.6987998\n",
      " -0.35390437 -0.5533388  -2.182774   -0.1674723  -0.6832994  -1.5639302\n",
      "  0.02628723 -0.7204339  -1.3973858  -0.02389716 -0.6529386  -1.4549314\n",
      " -0.02448418 -0.79695314 -1.572959   -0.12612775 -0.5876136  -1.4772487\n",
      " -0.05276941 -0.6380237  -1.4517018  -0.06739634 -0.61080235 -1.5438981\n",
      "  0.06535512 -0.6338418  -1.5793804  -0.04310311 -0.4960271  -1.309813\n",
      " -0.16274446 -0.26742136 -1.9758792  -0.00504131 -0.42237768 -1.9847386\n",
      "  0.15353785 -0.39260718 -1.4395666  -0.145431   -0.26548567 -1.2423384\n",
      " -0.07331772 -0.24156529 -1.3264347  -0.03345931 -0.2473535  -1.4432251\n",
      "  0.05451205 -0.26034933 -1.2833054   0.11      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63EB8>\n",
      "tensor([[ 0.0187, -0.0485, -0.2510,  ...,  0.0491, -0.2421, -1.2870],\n",
      "        [ 0.0187, -0.0485, -0.2510,  ...,  0.0491, -0.2421, -1.2870],\n",
      "        [ 0.0187, -0.0485, -0.2510,  ...,  0.0491, -0.2421, -1.2870],\n",
      "        ...,\n",
      "        [-0.1197,  0.3711, -0.0781,  ..., -0.6859,  0.8580, -0.3422],\n",
      "        [-0.1402, -0.1497,  0.5552,  ..., -0.2179,  0.6167,  0.2140],\n",
      "        [-0.1402, -0.1497,  0.5552,  ..., -0.2179,  0.6167,  0.2140]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01874799 -0.04850404 -0.25096795  0.03320645 -0.1838903  -0.6518812\n",
      " -0.06039329 -0.36836034 -1.3959366  -0.20543364 -0.42977303 -1.6945834\n",
      " -0.37793696 -0.541868   -2.1683137  -0.1842438  -0.6591872  -1.5560855\n",
      "  0.02207795 -0.6930299  -1.3712317  -0.02787951 -0.6272257  -1.428272\n",
      " -0.02681943 -0.76745605 -1.5446892  -0.14011277 -0.55752414 -1.470197\n",
      " -0.06127507 -0.6113831  -1.4443246  -0.07275748 -0.5884774  -1.5408065\n",
      "  0.06173359 -0.60828066 -1.5823805  -0.0512602  -0.4712786  -1.3008949\n",
      " -0.16524501 -0.2474503  -1.946117   -0.01156202 -0.40139365 -1.9481653\n",
      "  0.14849731 -0.37148708 -1.438381   -0.15189523 -0.23799118 -1.237548\n",
      " -0.07693371 -0.21852031 -1.3211024  -0.03380622 -0.22933227 -1.4379308\n",
      "  0.04907358 -0.24213773 -1.2869728 ]\n",
      "data: [ 0.01874799 -0.04850404 -0.25096795  0.03320645 -0.1838903  -0.6518813\n",
      " -0.06039329 -0.36836034 -1.3959366  -0.20543364 -0.42977303 -1.6945834\n",
      " -0.37793696 -0.541868   -2.1683137  -0.1842438  -0.65918714 -1.5560855\n",
      "  0.02207795 -0.6930299  -1.3712317  -0.0278795  -0.6272257  -1.4282719\n",
      " -0.02681943 -0.76745605 -1.5446892  -0.14011277 -0.55752414 -1.470197\n",
      " -0.06127507 -0.6113831  -1.4443246  -0.07275748 -0.5884774  -1.5408065\n",
      "  0.06173359 -0.60828066 -1.5823805  -0.0512602  -0.4712786  -1.300895\n",
      " -0.16524501 -0.2474503  -1.946117   -0.01156202 -0.40139365 -1.9481653\n",
      "  0.14849731 -0.37148708 -1.4383808  -0.15189523 -0.23799118 -1.237548\n",
      " -0.07693371 -0.21852031 -1.3211025  -0.03380622 -0.22933227 -1.4379307\n",
      "  0.04907359 -0.24213773 -1.2869728   0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[ 0.0145, -0.0753, -0.2504,  ...,  0.0355, -0.2645, -1.2998],\n",
      "        [ 0.0145, -0.0753, -0.2504,  ...,  0.0355, -0.2645, -1.2998],\n",
      "        [ 0.0145, -0.0753, -0.2504,  ...,  0.0355, -0.2645, -1.2998],\n",
      "        ...,\n",
      "        [-0.1586,  0.3989, -0.1210,  ..., -0.7198,  0.8820, -0.3590],\n",
      "        [-0.1607, -0.1410,  0.5707,  ..., -0.2516,  0.6394,  0.2268],\n",
      "        [-0.1607, -0.1410,  0.5707,  ..., -0.2516,  0.6394,  0.2268]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01448518 -0.07533549 -0.250422    0.03403421 -0.20885229 -0.6604619\n",
      " -0.06322769 -0.39482063 -1.4190624  -0.20539202 -0.45834577 -1.7123097\n",
      " -0.3699121  -0.5641551  -2.1922314  -0.18258895 -0.68556786 -1.5751933\n",
      "  0.01494904 -0.7207495  -1.3918016  -0.0340876  -0.65404534 -1.4494851\n",
      " -0.03683443 -0.79367685 -1.5663205  -0.1424328  -0.5859747  -1.4906396\n",
      " -0.06813048 -0.63730097 -1.4626365  -0.08441047 -0.61252296 -1.5555032\n",
      "  0.04793979 -0.63130164 -1.5956916  -0.06070674 -0.49977285 -1.3229884\n",
      " -0.17439969 -0.27319485 -1.9684286  -0.02453074 -0.42404366 -1.9736928\n",
      "  0.13134307 -0.3953394  -1.4535506  -0.1598148  -0.2662546  -1.256148\n",
      " -0.08988532 -0.24389663 -1.3397253  -0.04742311 -0.25075737 -1.455316\n",
      "  0.0355012  -0.2644673  -1.2997947 ]\n",
      "data: [ 0.01448518 -0.07533549 -0.250422    0.03403421 -0.20885229 -0.6604619\n",
      " -0.06322769 -0.39482063 -1.4190624  -0.20539202 -0.45834577 -1.7123097\n",
      " -0.36991206 -0.5641551  -2.1922314  -0.18258896 -0.68556786 -1.5751933\n",
      "  0.01494904 -0.7207495  -1.3918016  -0.0340876  -0.65404534 -1.4494851\n",
      " -0.03683443 -0.79367685 -1.5663205  -0.1424328  -0.5859747  -1.4906394\n",
      " -0.06813048 -0.63730097 -1.4626365  -0.08441047 -0.61252296 -1.5555032\n",
      "  0.04793979 -0.63130164 -1.5956916  -0.06070675 -0.49977285 -1.3229884\n",
      " -0.17439967 -0.27319485 -1.9684286  -0.02453074 -0.42404366 -1.9736928\n",
      "  0.13134307 -0.3953394  -1.4535506  -0.1598148  -0.2662546  -1.256148\n",
      " -0.08988532 -0.24389663 -1.3397251  -0.04742311 -0.25075737 -1.4553161\n",
      "  0.0355012  -0.2644673  -1.2997947   0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[ 0.0173, -0.0354, -0.2431,  ...,  0.0361, -0.2307, -1.2651],\n",
      "        [ 0.0173, -0.0354, -0.2431,  ...,  0.0361, -0.2307, -1.2651],\n",
      "        [ 0.0173, -0.0354, -0.2431,  ...,  0.0361, -0.2307, -1.2651],\n",
      "        ...,\n",
      "        [-0.1204,  0.3861, -0.1149,  ..., -0.6878,  0.8834, -0.3846],\n",
      "        [-0.1407, -0.1778,  0.5557,  ..., -0.2263,  0.5851,  0.2194],\n",
      "        [-0.1407, -0.1778,  0.5557,  ..., -0.2263,  0.5851,  0.2194]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.7261777e-02 -3.5385914e-02 -2.4313793e-01  3.4169208e-02\n",
      " -1.5928105e-01 -6.2569642e-01 -7.6377816e-02 -3.5100621e-01\n",
      " -1.3878474e+00 -2.2231638e-01 -4.1319871e-01 -1.6798260e+00\n",
      " -3.8684031e-01 -5.1150036e-01 -2.1649861e+00 -1.7806679e-01\n",
      " -6.5361428e-01 -1.5442851e+00 -2.0855069e-03 -6.9554728e-01\n",
      " -1.3818297e+00 -5.0241113e-02 -6.2423861e-01 -1.4418741e+00\n",
      " -4.9515508e-02 -7.7639484e-01 -1.5584356e+00 -1.3836181e-01\n",
      " -5.5977356e-01 -1.4584433e+00 -7.3275611e-02 -6.0868520e-01\n",
      " -1.4295902e+00 -9.1111757e-02 -5.8413875e-01 -1.5226591e+00\n",
      "  4.6438947e-02 -6.0105306e-01 -1.5532525e+00 -5.9567921e-02\n",
      " -4.6746880e-01 -1.2960186e+00 -1.8156470e-01 -2.4276485e-01\n",
      " -1.9691582e+00 -2.5783688e-02 -3.9514589e-01 -1.9823489e+00\n",
      "  1.3565096e-01 -3.6713660e-01 -1.4163207e+00 -1.5803590e-01\n",
      " -2.3945588e-01 -1.2286668e+00 -9.6747592e-02 -2.1677272e-01\n",
      " -1.3153106e+00 -6.0539231e-02 -2.1657723e-01 -1.4318361e+00\n",
      "  3.6081918e-02 -2.3069325e-01 -1.2650706e+00]\n",
      "data: [ 1.7261777e-02 -3.5385914e-02 -2.4313793e-01  3.4169208e-02\n",
      " -1.5928105e-01 -6.2569642e-01 -7.6377816e-02 -3.5100621e-01\n",
      " -1.3878474e+00 -2.2231638e-01 -4.1319871e-01 -1.6798260e+00\n",
      " -3.8684031e-01 -5.1150036e-01 -2.1649861e+00 -1.7806679e-01\n",
      " -6.5361428e-01 -1.5442852e+00 -2.0855069e-03 -6.9554728e-01\n",
      " -1.3818297e+00 -5.0241113e-02 -6.2423861e-01 -1.4418740e+00\n",
      " -4.9515508e-02 -7.7639478e-01 -1.5584356e+00 -1.3836181e-01\n",
      " -5.5977356e-01 -1.4584433e+00 -7.3275611e-02 -6.0868520e-01\n",
      " -1.4295901e+00 -9.1111757e-02 -5.8413875e-01 -1.5226589e+00\n",
      "  4.6438947e-02 -6.0105306e-01 -1.5532525e+00 -5.9567917e-02\n",
      " -4.6746880e-01 -1.2960187e+00 -1.8156472e-01 -2.4276486e-01\n",
      " -1.9691582e+00 -2.5783686e-02 -3.9514586e-01 -1.9823489e+00\n",
      "  1.3565096e-01 -3.6713660e-01 -1.4163207e+00 -1.5803590e-01\n",
      " -2.3945588e-01 -1.2286668e+00 -9.6747592e-02 -2.1677274e-01\n",
      " -1.3153107e+00 -6.0539231e-02 -2.1657723e-01 -1.4318361e+00\n",
      "  3.6081918e-02 -2.3069325e-01 -1.2650706e+00  1.4000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[ 0.0170, -0.0300, -0.2272,  ...,  0.0267, -0.2212, -1.2757],\n",
      "        [ 0.0170, -0.0300, -0.2272,  ...,  0.0267, -0.2212, -1.2757],\n",
      "        [ 0.0170, -0.0300, -0.2272,  ...,  0.0267, -0.2212, -1.2757],\n",
      "        ...,\n",
      "        [-0.3493,  0.1591, -0.3064,  ..., -0.8789,  0.5628, -0.4436],\n",
      "        [-0.1160, -0.0984,  0.5654,  ..., -0.1994,  0.6887,  0.2471],\n",
      "        [-0.1160, -0.0984,  0.5654,  ..., -0.1994,  0.6887,  0.2471]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.69519149e-02 -2.99693812e-02 -2.27203429e-01  2.84996741e-02\n",
      " -1.71295568e-01 -6.51422977e-01 -7.21160993e-02 -3.49619448e-01\n",
      " -1.38884068e+00 -2.16424778e-01 -4.14399147e-01 -1.67734456e+00\n",
      " -3.90652895e-01 -5.18220782e-01 -2.15308690e+00 -1.85134366e-01\n",
      " -6.38769507e-01 -1.53820324e+00 -1.96789205e-03 -6.69143796e-01\n",
      " -1.35329664e+00 -4.54071611e-02 -6.00442767e-01 -1.41392112e+00\n",
      " -4.43481505e-02 -7.37146616e-01 -1.52524352e+00 -1.48511320e-01\n",
      " -5.35856247e-01 -1.46138787e+00 -7.61550665e-02 -5.85995674e-01\n",
      " -1.42662668e+00 -9.60064530e-02 -5.64546227e-01 -1.52090657e+00\n",
      "  4.33887541e-02 -5.72460651e-01 -1.56280649e+00 -7.11591467e-02\n",
      " -4.57448483e-01 -1.29666734e+00 -1.72260955e-01 -2.36700028e-01\n",
      " -1.90188646e+00 -3.45960408e-02 -3.77856702e-01 -1.90494418e+00\n",
      "  1.20547384e-01 -3.53629619e-01 -1.42095757e+00 -1.59079447e-01\n",
      " -2.24041060e-01 -1.23478997e+00 -1.01063952e-01 -2.03981832e-01\n",
      " -1.31345785e+00 -5.78167289e-02 -2.05514938e-01 -1.42992735e+00\n",
      "  2.66869441e-02 -2.21198395e-01 -1.27567112e+00]\n",
      "data: [ 1.69519149e-02 -2.99693830e-02 -2.27203429e-01  2.84996741e-02\n",
      " -1.71295568e-01 -6.51422977e-01 -7.21160993e-02 -3.49619448e-01\n",
      " -1.38884068e+00 -2.16424763e-01 -4.14399147e-01 -1.67734456e+00\n",
      " -3.90652895e-01 -5.18220782e-01 -2.15308690e+00 -1.85134366e-01\n",
      " -6.38769507e-01 -1.53820324e+00 -1.96789205e-03 -6.69143856e-01\n",
      " -1.35329664e+00 -4.54071611e-02 -6.00442767e-01 -1.41392100e+00\n",
      " -4.43481505e-02 -7.37146616e-01 -1.52524352e+00 -1.48511320e-01\n",
      " -5.35856247e-01 -1.46138799e+00 -7.61550665e-02 -5.85995674e-01\n",
      " -1.42662668e+00 -9.60064530e-02 -5.64546227e-01 -1.52090657e+00\n",
      "  4.33887541e-02 -5.72460651e-01 -1.56280661e+00 -7.11591467e-02\n",
      " -4.57448512e-01 -1.29666734e+00 -1.72260955e-01 -2.36700013e-01\n",
      " -1.90188646e+00 -3.45960408e-02 -3.77856702e-01 -1.90494418e+00\n",
      "  1.20547384e-01 -3.53629619e-01 -1.42095768e+00 -1.59079447e-01\n",
      " -2.24041060e-01 -1.23478997e+00 -1.01063944e-01 -2.03981832e-01\n",
      " -1.31345785e+00 -5.78167289e-02 -2.05514953e-01 -1.42992735e+00\n",
      "  2.66869441e-02 -2.21198380e-01 -1.27567112e+00  1.50000006e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63A58>\n",
      "tensor([[ 0.0386, -0.0751, -0.2299,  ...,  0.0435, -0.2616, -1.2800],\n",
      "        [ 0.0386, -0.0751, -0.2299,  ...,  0.0435, -0.2616, -1.2800],\n",
      "        [ 0.0386, -0.0751, -0.2299,  ...,  0.0435, -0.2616, -1.2800],\n",
      "        ...,\n",
      "        [-0.3091,  0.2773, -0.3181,  ..., -0.8438,  0.7381, -0.4869],\n",
      "        [-0.1214, -0.0881,  0.6083,  ..., -0.2262,  0.7038,  0.2859],\n",
      "        [-0.1214, -0.0881,  0.6083,  ..., -0.2262,  0.7038,  0.2859]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03857948 -0.07513815 -0.22987834  0.06133197 -0.2067047  -0.6382133\n",
      " -0.05068244 -0.3898953  -1.3959136  -0.19415426 -0.45553184 -1.6787052\n",
      " -0.35366735 -0.5465573  -2.1706254  -0.15021402 -0.6898576  -1.5476344\n",
      "  0.01294938 -0.72448444 -1.3831147  -0.0295637  -0.6522169  -1.445961\n",
      " -0.03236635 -0.79542255 -1.5589366  -0.11827615 -0.5947976  -1.4722121\n",
      " -0.05357993 -0.6397846  -1.4371079  -0.08008794 -0.61281943 -1.52795\n",
      "  0.05875532 -0.621994   -1.5617527  -0.04986887 -0.5082443  -1.3114879\n",
      " -0.15661398 -0.28333616 -1.9438337  -0.01621469 -0.42335236 -1.9570093\n",
      "  0.13713777 -0.3990592  -1.4283487  -0.13784538 -0.27869904 -1.2467731\n",
      " -0.08774139 -0.25263906 -1.3274988  -0.04965791 -0.24545856 -1.4454632\n",
      "  0.04346736 -0.26160258 -1.2800086 ]\n",
      "data: [ 0.03857948 -0.07513815 -0.22987834  0.06133197 -0.2067047  -0.6382133\n",
      " -0.05068244 -0.3898953  -1.3959136  -0.19415426 -0.45553184 -1.6787051\n",
      " -0.35366735 -0.5465573  -2.1706254  -0.15021402 -0.68985766 -1.5476345\n",
      "  0.01294938 -0.7244844  -1.3831146  -0.02956369 -0.652217   -1.445961\n",
      " -0.03236635 -0.7954225  -1.5589366  -0.11827615 -0.5947976  -1.4722121\n",
      " -0.05357994 -0.6397846  -1.4371078  -0.08008794 -0.61281943 -1.5279499\n",
      "  0.05875532 -0.621994   -1.5617527  -0.04986887 -0.5082443  -1.3114879\n",
      " -0.15661398 -0.28333616 -1.9438338  -0.01621469 -0.42335236 -1.9570093\n",
      "  0.13713777 -0.3990592  -1.4283487  -0.13784538 -0.27869904 -1.2467731\n",
      " -0.0877414  -0.25263906 -1.3274988  -0.04965791 -0.24545856 -1.4454633\n",
      "  0.04346736 -0.26160258 -1.2800086   0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F5C0>\n",
      "tensor([[ 0.0298, -0.0746, -0.2468,  ...,  0.0630, -0.2643, -1.2804],\n",
      "        [ 0.0298, -0.0746, -0.2468,  ...,  0.0630, -0.2643, -1.2804],\n",
      "        [ 0.0298, -0.0746, -0.2468,  ...,  0.0630, -0.2643, -1.2804],\n",
      "        ...,\n",
      "        [-0.1325,  0.3728, -0.0746,  ..., -0.7433,  0.8639, -0.3324],\n",
      "        [-0.1396, -0.1354,  0.5763,  ..., -0.2280,  0.6424,  0.2201],\n",
      "        [-0.1396, -0.1354,  0.5763,  ..., -0.2280,  0.6424,  0.2201]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.9819656e-02 -7.4626081e-02 -2.4682638e-01  5.0947558e-02\n",
      " -2.0512022e-01 -6.4604533e-01 -4.8014976e-02 -3.9857802e-01\n",
      " -1.4111958e+00 -1.9253074e-01 -4.6227273e-01 -1.7086776e+00\n",
      " -3.5668975e-01 -5.7275516e-01 -2.1868243e+00 -1.6964625e-01\n",
      " -6.8745595e-01 -1.5682746e+00  3.6602303e-02 -7.2769701e-01\n",
      " -1.3838881e+00 -1.6951680e-02 -6.6248238e-01 -1.4392496e+00\n",
      " -2.3693070e-02 -8.0678111e-01 -1.5589192e+00 -1.2472798e-01\n",
      " -5.8938146e-01 -1.4777297e+00 -4.9420416e-02 -6.4451146e-01\n",
      " -1.4519429e+00 -6.3015945e-02 -6.1809176e-01 -1.5440259e+00\n",
      "  6.6588238e-02 -6.4491481e-01 -1.5809865e+00 -3.6519669e-02\n",
      " -4.9691001e-01 -1.3075234e+00 -1.5977582e-01 -2.6866546e-01\n",
      " -1.9780556e+00  2.1839887e-04 -4.2845002e-01 -1.9837867e+00\n",
      "  1.5893404e-01 -3.9664054e-01 -1.4377582e+00 -1.4217435e-01\n",
      " -2.6400059e-01 -1.2382743e+00 -6.4016089e-02 -2.4123509e-01\n",
      " -1.3237092e+00 -2.1665990e-02 -2.5244457e-01 -1.4392008e+00\n",
      "  6.2972002e-02 -2.6427943e-01 -1.2804472e+00]\n",
      "data: [ 2.9819656e-02 -7.4626081e-02 -2.4682638e-01  5.0947558e-02\n",
      " -2.0512022e-01 -6.4604533e-01 -4.8014976e-02 -3.9857805e-01\n",
      " -1.4111956e+00 -1.9253072e-01 -4.6227273e-01 -1.7086776e+00\n",
      " -3.5668975e-01 -5.7275516e-01 -2.1868243e+00 -1.6964625e-01\n",
      " -6.8745595e-01 -1.5682747e+00  3.6602303e-02 -7.2769701e-01\n",
      " -1.3838881e+00 -1.6951680e-02 -6.6248238e-01 -1.4392495e+00\n",
      " -2.3693070e-02 -8.0678105e-01 -1.5589192e+00 -1.2472799e-01\n",
      " -5.8938146e-01 -1.4777297e+00 -4.9420413e-02 -6.4451146e-01\n",
      " -1.4519429e+00 -6.3015945e-02 -6.1809176e-01 -1.5440259e+00\n",
      "  6.6588238e-02 -6.4491481e-01 -1.5809865e+00 -3.6519669e-02\n",
      " -4.9691001e-01 -1.3075234e+00 -1.5977582e-01 -2.6866546e-01\n",
      " -1.9780556e+00  2.1839887e-04 -4.2845002e-01 -1.9837868e+00\n",
      "  1.5893404e-01 -3.9664054e-01 -1.4377582e+00 -1.4217435e-01\n",
      " -2.6400059e-01 -1.2382743e+00 -6.4016089e-02 -2.4123508e-01\n",
      " -1.3237092e+00 -2.1665990e-02 -2.5244457e-01 -1.4392008e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6.2972002e-02 -2.6427943e-01 -1.2804472e+00  1.7000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[ 0.0259, -0.0872, -0.2544,  ...,  0.0662, -0.2757, -1.2994],\n",
      "        [ 0.0259, -0.0872, -0.2544,  ...,  0.0662, -0.2757, -1.2994],\n",
      "        [ 0.0259, -0.0872, -0.2544,  ...,  0.0662, -0.2757, -1.2994],\n",
      "        ...,\n",
      "        [-0.1313,  0.3851, -0.1198,  ..., -0.7582,  0.8743, -0.3614],\n",
      "        [-0.1339, -0.1134,  0.5809,  ..., -0.2222,  0.6557,  0.2212],\n",
      "        [-0.1339, -0.1134,  0.5809,  ..., -0.2222,  0.6557,  0.2212]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02588398 -0.08715253 -0.25438562  0.04626234 -0.22595072 -0.66037667\n",
      " -0.03643303 -0.41060978 -1.4077094  -0.17847724 -0.47177112 -1.7101657\n",
      " -0.34778523 -0.5911978  -2.180196   -0.1766006  -0.6929511  -1.5722888\n",
      "  0.050726   -0.7243571  -1.3829188  -0.00289744 -0.66406846 -1.4359193\n",
      " -0.00465088 -0.7983529  -1.5538218  -0.12916629 -0.5885216  -1.4833288\n",
      " -0.04193226 -0.64610976 -1.4611421  -0.05006805 -0.6218126  -1.5572429\n",
      "  0.07684715 -0.65046364 -1.6043265  -0.03432382 -0.50096834 -1.3088682\n",
      " -0.15036273 -0.27491647 -1.9584079   0.00759219 -0.43481416 -1.9558158\n",
      "  0.16326609 -0.40151995 -1.4563942  -0.14107299 -0.2648769  -1.2448671\n",
      " -0.05323659 -0.24519199 -1.3265877  -0.00635345 -0.26445693 -1.4435072\n",
      "  0.06620256 -0.2757413  -1.2993793 ]\n",
      "data: [ 0.02588398 -0.08715253 -0.25438562  0.04626234 -0.22595072 -0.66037667\n",
      " -0.03643303 -0.41060978 -1.4077094  -0.17847724 -0.47177112 -1.7101657\n",
      " -0.34778523 -0.5911978  -2.180196   -0.1766006  -0.692951   -1.5722889\n",
      "  0.05072599 -0.7243571  -1.3829188  -0.00289744 -0.66406846 -1.4359193\n",
      " -0.00465088 -0.7983529  -1.5538219  -0.12916629 -0.5885216  -1.4833288\n",
      " -0.04193226 -0.64610976 -1.4611421  -0.05006805 -0.6218126  -1.5572429\n",
      "  0.07684715 -0.65046364 -1.6043265  -0.03432382 -0.50096834 -1.308868\n",
      " -0.15036273 -0.27491647 -1.9584079   0.00759219 -0.43481416 -1.9558158\n",
      "  0.16326609 -0.40151995 -1.4563942  -0.14107299 -0.2648769  -1.2448671\n",
      " -0.05323659 -0.24519199 -1.3265877  -0.00635345 -0.26445693 -1.4435072\n",
      "  0.06620256 -0.2757413  -1.2993792   0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0226, -0.1044, -0.2622,  ...,  0.0652, -0.2911, -1.3121],\n",
      "        [ 0.0226, -0.1044, -0.2622,  ...,  0.0652, -0.2911, -1.3121],\n",
      "        [ 0.0226, -0.1044, -0.2622,  ...,  0.0652, -0.2911, -1.3121],\n",
      "        ...,\n",
      "        [-0.1008,  0.4293, -0.1373,  ..., -0.6559,  0.9307, -0.4308],\n",
      "        [-0.1350, -0.1073,  0.5940,  ..., -0.2325,  0.6575,  0.2294],\n",
      "        [-0.1350, -0.1073,  0.5940,  ..., -0.2325,  0.6575,  0.2294]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.25977264e-02 -1.04401916e-01 -2.62196511e-01  4.42381017e-02\n",
      " -2.46924862e-01 -6.68742955e-01 -3.15579921e-02 -4.31958765e-01\n",
      " -1.41585469e+00 -1.73063248e-01 -4.92870986e-01 -1.72113705e+00\n",
      " -3.43282402e-01 -6.16792262e-01 -2.18898726e+00 -1.81993753e-01\n",
      " -7.08323777e-01 -1.58590722e+00  5.95096424e-02 -7.38010466e-01\n",
      " -1.38683426e+00  4.30025905e-03 -6.80703402e-01 -1.43722653e+00\n",
      "  9.02414322e-05 -8.10525060e-01 -1.55570221e+00 -1.32788301e-01\n",
      " -6.00404263e-01 -1.49533677e+00 -4.04967964e-02 -6.60409570e-01\n",
      " -1.47498667e+00 -4.59268317e-02 -6.35925531e-01 -1.57121670e+00\n",
      "  7.69936070e-02 -6.68141663e-01 -1.62262607e+00 -3.30610871e-02\n",
      " -5.12665629e-01 -1.31835556e+00 -1.49672717e-01 -2.86810994e-01\n",
      " -1.96153450e+00  8.67974013e-03 -4.49475765e-01 -1.95480108e+00\n",
      "  1.61927968e-01 -4.12792861e-01 -1.47170877e+00 -1.43499553e-01\n",
      " -2.74528444e-01 -1.25498092e+00 -4.88245413e-02 -2.55202293e-01\n",
      " -1.33402133e+00  5.04776835e-05 -2.80350327e-01 -1.45040882e+00\n",
      "  6.52384609e-02 -2.91149914e-01 -1.31211197e+00]\n",
      "data: [ 2.25977246e-02 -1.04401916e-01 -2.62196511e-01  4.42381017e-02\n",
      " -2.46924862e-01 -6.68742955e-01 -3.15579921e-02 -4.31958765e-01\n",
      " -1.41585469e+00 -1.73063233e-01 -4.92870986e-01 -1.72113705e+00\n",
      " -3.43282402e-01 -6.16792262e-01 -2.18898726e+00 -1.81993753e-01\n",
      " -7.08323717e-01 -1.58590734e+00  5.95096461e-02 -7.38010466e-01\n",
      " -1.38683426e+00  4.30025905e-03 -6.80703402e-01 -1.43722653e+00\n",
      "  9.02414322e-05 -8.10525060e-01 -1.55570221e+00 -1.32788301e-01\n",
      " -6.00404263e-01 -1.49533677e+00 -4.04967964e-02 -6.60409570e-01\n",
      " -1.47498667e+00 -4.59268317e-02 -6.35925531e-01 -1.57121670e+00\n",
      "  7.69936070e-02 -6.68141603e-01 -1.62262607e+00 -3.30610871e-02\n",
      " -5.12665629e-01 -1.31835556e+00 -1.49672717e-01 -2.86810994e-01\n",
      " -1.96153438e+00  8.67974013e-03 -4.49475795e-01 -1.95480108e+00\n",
      "  1.61927968e-01 -4.12792861e-01 -1.47170877e+00 -1.43499553e-01\n",
      " -2.74528444e-01 -1.25498092e+00 -4.88245375e-02 -2.55202293e-01\n",
      " -1.33402133e+00  5.04776835e-05 -2.80350327e-01 -1.45040882e+00\n",
      "  6.52384609e-02 -2.91149914e-01 -1.31211197e+00  1.89999998e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63FD0>\n",
      "tensor([[ 0.0090, -0.1131, -0.2335,  ...,  0.0542, -0.2974, -1.2914],\n",
      "        [ 0.0090, -0.1131, -0.2335,  ...,  0.0542, -0.2974, -1.2914],\n",
      "        [ 0.0090, -0.1131, -0.2335,  ...,  0.0542, -0.2974, -1.2914],\n",
      "        ...,\n",
      "        [-0.0897,  0.4511, -0.1500,  ..., -0.6360,  0.9345, -0.4249],\n",
      "        [-0.1324, -0.0972,  0.5988,  ..., -0.2360,  0.6382,  0.2624],\n",
      "        [-0.1324, -0.0972,  0.5988,  ..., -0.2360,  0.6382,  0.2624]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 9.0141715e-03 -1.1312097e-01 -2.3348421e-01  3.0680601e-02\n",
      " -2.5773668e-01 -6.3660949e-01 -3.7923351e-02 -4.4357717e-01\n",
      " -1.3829203e+00 -1.8011741e-01 -5.0364399e-01 -1.6925247e+00\n",
      " -3.5141981e-01 -6.3284039e-01 -2.1596243e+00 -1.9917084e-01\n",
      " -7.1543181e-01 -1.5642771e+00  5.6436703e-02 -7.4570012e-01\n",
      " -1.3637466e+00 -2.5160313e-03 -6.9257188e-01 -1.4105352e+00\n",
      " -6.9022179e-03 -8.2077575e-01 -1.5296371e+00 -1.4636782e-01\n",
      " -6.0487974e-01 -1.4711919e+00 -4.9271159e-02 -6.6868132e-01\n",
      " -1.4538028e+00 -5.1734917e-02 -6.4522231e-01 -1.5522280e+00\n",
      "  6.5968782e-02 -6.8427467e-01 -1.6054389e+00 -4.1091673e-02\n",
      " -5.1455957e-01 -1.2922649e+00 -1.6133398e-01 -2.8952056e-01\n",
      " -1.9393276e+00  9.6559525e-05 -4.5764118e-01 -1.9302826e+00\n",
      "  1.5175794e-01 -4.1931468e-01 -1.4529577e+00 -1.5716989e-01\n",
      " -2.7418742e-01 -1.2286062e+00 -5.3842992e-02 -2.5643346e-01\n",
      " -1.3069291e+00 -4.8837662e-03 -2.8806657e-01 -1.4234759e+00\n",
      "  5.4249786e-02 -2.9737088e-01 -1.2914088e+00]\n",
      "data: [ 9.0141715e-03 -1.1312097e-01 -2.3348421e-01  3.0680602e-02\n",
      " -2.5773668e-01 -6.3660949e-01 -3.7923351e-02 -4.4357717e-01\n",
      " -1.3829203e+00 -1.8011741e-01 -5.0364399e-01 -1.6925247e+00\n",
      " -3.5141981e-01 -6.3284039e-01 -2.1596243e+00 -1.9917084e-01\n",
      " -7.1543181e-01 -1.5642771e+00  5.6436703e-02 -7.4570012e-01\n",
      " -1.3637466e+00 -2.5160313e-03 -6.9257188e-01 -1.4105353e+00\n",
      " -6.9022179e-03 -8.2077575e-01 -1.5296371e+00 -1.4636782e-01\n",
      " -6.0487974e-01 -1.4711919e+00 -4.9271159e-02 -6.6868132e-01\n",
      " -1.4538028e+00 -5.1734913e-02 -6.4522231e-01 -1.5522280e+00\n",
      "  6.5968782e-02 -6.8427467e-01 -1.6054389e+00 -4.1091669e-02\n",
      " -5.1455957e-01 -1.2922651e+00 -1.6133398e-01 -2.8952056e-01\n",
      " -1.9393276e+00  9.6559525e-05 -4.5764118e-01 -1.9302826e+00\n",
      "  1.5175794e-01 -4.1931468e-01 -1.4529577e+00 -1.5716989e-01\n",
      " -2.7418742e-01 -1.2286062e+00 -5.3842992e-02 -2.5643346e-01\n",
      " -1.3069291e+00 -4.8837662e-03 -2.8806657e-01 -1.4234757e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5.4249786e-02 -2.9737088e-01 -1.2914089e+00  2.0000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0342, -0.1050, -0.2405,  ...,  0.0577, -0.2947, -1.2622],\n",
      "        [ 0.0342, -0.1050, -0.2405,  ...,  0.0577, -0.2947, -1.2622],\n",
      "        [ 0.0342, -0.1050, -0.2405,  ...,  0.0577, -0.2947, -1.2622],\n",
      "        ...,\n",
      "        [-0.1026,  0.4213, -0.1311,  ..., -0.6193,  0.9290, -0.4598],\n",
      "        [-0.1241, -0.1126,  0.6135,  ..., -0.2092,  0.6470,  0.2430],\n",
      "        [-0.1241, -0.1126,  0.6135,  ..., -0.2092,  0.6470,  0.2430]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0342036  -0.10504125 -0.2404619   0.05964918 -0.23213796 -0.6128378\n",
      " -0.04763417 -0.44040835 -1.4085243  -0.1931315  -0.5059398  -1.7054672\n",
      " -0.35421264 -0.61241627 -2.1896567  -0.16354333 -0.72758675 -1.5703604\n",
      "  0.03954951 -0.77576816 -1.3818561  -0.01655474 -0.7117801  -1.4348028\n",
      " -0.03114222 -0.8623034  -1.5570683  -0.11925372 -0.6287842  -1.4746377\n",
      " -0.05040395 -0.6854348  -1.4477929  -0.06548917 -0.65829444 -1.5363334\n",
      "  0.05959456 -0.6894864  -1.5697329  -0.03145251 -0.5279356  -1.3058387\n",
      " -0.17139868 -0.299464   -2.0143576  -0.00388039 -0.46667245 -2.0238032\n",
      "  0.1523678  -0.42916176 -1.4247906  -0.14341184 -0.29567558 -1.2335042\n",
      " -0.06725806 -0.27132958 -1.3167198  -0.02814963 -0.28249246 -1.4308361\n",
      "  0.05771741 -0.2946912  -1.2622112 ]\n",
      "data: [-4.09 -5.15  4.49 -4.01 -4.93  4.55 -4.03 -4.86  4.55 -3.59 -3.45  1.68\n",
      " -3.22 -4.39  2.39  0.    0.    0.   -3.42 -3.95  2.02 -3.57 -3.48  1.68\n",
      " -3.38 -4.1   2.17 -3.41 -3.75  2.12 -3.38 -3.89  2.02 -3.59 -3.45  1.68\n",
      " -3.59 -3.35  1.77 -3.39 -3.75  2.12 -3.38 -3.79  2.19 -3.39 -3.78  2.12\n",
      " -3.34 -4.1   2.17 -4.07 -5.    4.6  -4.01 -4.86  4.55 -3.26 -4.11  2.36\n",
      " -3.38 -4.13  2.17  0.  ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.1135,  0.1386, -0.3019,  ..., -0.0672, -0.0924, -0.7998],\n",
      "        [ 0.1135,  0.1386, -0.3019,  ..., -0.0672, -0.0924, -0.7998],\n",
      "        [ 0.1135,  0.1386, -0.3019,  ..., -0.0672, -0.0924, -0.7998],\n",
      "        ...,\n",
      "        [ 0.6224, -1.0931,  1.0334,  ...,  0.0474, -1.1104,  1.3214],\n",
      "        [ 0.0039, -0.1968,  0.3351,  ..., -0.4219, -0.6519,  2.3795],\n",
      "        [ 0.0039, -0.1968,  0.3351,  ..., -0.4219, -0.6519,  2.3795]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.1135028   0.13860197 -0.3018914  -0.0383043   0.01270307 -0.657121\n",
      " -0.14454655 -0.1252211  -0.9100406  -0.1892139  -0.27022737 -0.8628144\n",
      " -0.18323639 -0.32835796 -0.92522657 -0.14317006 -0.10651645 -1.1907085\n",
      " -0.02395029 -0.17912084 -0.5287641  -0.07348701 -0.32355568 -0.4983814\n",
      " -0.1793763  -0.29161876 -0.5860312  -0.13472009 -0.01953173 -1.212257\n",
      " -0.21418369 -0.12854114 -1.1554188  -0.2194294  -0.20533776 -1.1055541\n",
      " -0.18965736 -0.30985492 -1.0899811  -0.13139957  0.00138968 -1.1712888\n",
      " -0.19471124 -0.05988425 -0.974097   -0.22262213 -0.11195624 -0.9656918\n",
      " -0.13276473 -0.20883414 -0.9476019  -0.12287658  0.13136432 -1.0271984\n",
      " -0.10651629  0.06642249 -0.9368485  -0.10360169  0.01052997 -0.8962343\n",
      " -0.06717324 -0.09240885 -0.79979235]\n",
      "init: [ 0.1135028   0.13860197 -0.3018914  -0.0383043   0.01270307 -0.657121\n",
      " -0.14454655 -0.1252211  -0.9100406  -0.1892139  -0.27022737 -0.8628144\n",
      " -0.18323639 -0.32835796 -0.92522657 -0.14317006 -0.10651645 -1.1907085\n",
      " -0.02395029 -0.17912084 -0.5287641  -0.07348701 -0.32355568 -0.4983814\n",
      " -0.1793763  -0.29161876 -0.5860312  -0.13472009 -0.01953173 -1.212257\n",
      " -0.21418369 -0.12854114 -1.1554188  -0.2194294  -0.20533776 -1.1055541\n",
      " -0.18965736 -0.30985492 -1.0899811  -0.13139957  0.00138968 -1.1712888\n",
      " -0.19471124 -0.05988425 -0.974097   -0.22262213 -0.11195624 -0.9656918\n",
      " -0.13276473 -0.20883414 -0.9476019  -0.12287658  0.13136432 -1.0271984\n",
      " -0.10651629  0.06642249 -0.9368485  -0.10360169  0.01052997 -0.8962343\n",
      " -0.06717324 -0.09240885 -0.79979235]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [ 0.1135028   0.13860197 -0.3018914  -0.0383043   0.01270307 -0.65712094\n",
      " -0.14454655 -0.1252211  -0.9100406  -0.1892139  -0.27022737 -0.8628144\n",
      " -0.18323639 -0.32835796 -0.92522657 -0.14317006 -0.10651645 -1.1907085\n",
      " -0.02395029 -0.17912084 -0.5287641  -0.07348701 -0.32355568 -0.49838144\n",
      " -0.1793763  -0.29161876 -0.5860312  -0.13472009 -0.01953173 -1.212257\n",
      " -0.21418369 -0.12854114 -1.1554188  -0.2194294  -0.20533775 -1.1055541\n",
      " -0.18965736 -0.30985492 -1.0899811  -0.13139957  0.00138968 -1.1712888\n",
      " -0.19471125 -0.05988425 -0.974097   -0.22262213 -0.11195623 -0.9656918\n",
      " -0.13276473 -0.20883413 -0.9476019  -0.12287658  0.13136432 -1.0271984\n",
      " -0.10651629  0.06642249 -0.9368485  -0.10360169  0.01052997 -0.8962343\n",
      " -0.06717324 -0.09240885 -0.79979235  0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.1602, -0.4051,  0.1639,  ...,  0.2574, -0.5467, -0.9587],\n",
      "        [ 0.1602, -0.4051,  0.1639,  ...,  0.2574, -0.5467, -0.9587],\n",
      "        [ 0.1602, -0.4051,  0.1639,  ...,  0.2574, -0.5467, -0.9587],\n",
      "        ...,\n",
      "        [-0.1657,  0.2956, -0.8783,  ..., -0.8114,  0.5911, -0.9623],\n",
      "        [-0.3673,  0.2040, -0.2801,  ..., -0.6720,  1.0207, -0.6437],\n",
      "        [-0.3673,  0.2040, -0.2801,  ..., -0.6720,  1.0207, -0.6437]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.16017921 -0.4051434   0.16393928  0.19989458 -0.5483488  -0.2678945\n",
      "  0.1538266  -0.67075384 -0.9363775   0.01539564 -0.70503473 -1.2366107\n",
      " -0.12487699 -0.8357067  -1.7311622  -0.04807936 -0.9568534  -1.1009752\n",
      "  0.24393708 -0.93193793 -0.8956922   0.19163254 -0.85586333 -0.94736576\n",
      "  0.17359374 -0.9367373  -1.064082    0.00215216 -0.8616656  -1.0392659\n",
      "  0.13916296 -0.8920789  -1.0571449   0.14297588 -0.8241582  -1.1460712\n",
      "  0.2535962  -0.8573941  -1.2169355   0.13315192 -0.79181087 -0.87051237\n",
      "  0.07833014 -0.53297067 -1.3399767   0.21397133 -0.6714797  -1.3130996\n",
      "  0.34281176 -0.614589   -1.1168182   0.029211   -0.56486773 -0.83082485\n",
      "  0.15746891 -0.5233587  -0.91869533  0.21676601 -0.5512974  -1.047764\n",
      "  0.25736678 -0.54666686 -0.9587301 ]\n",
      "data: [ 0.16017921 -0.40514338  0.16393928  0.19989458 -0.5483488  -0.2678945\n",
      "  0.1538266  -0.67075384 -0.9363776   0.01539564 -0.70503473 -1.2366107\n",
      " -0.124877   -0.8357067  -1.7311623  -0.04807936 -0.9568534  -1.1009752\n",
      "  0.24393708 -0.93193793 -0.8956922   0.19163254 -0.85586333 -0.9473657\n",
      "  0.17359374 -0.9367373  -1.064082    0.00215216 -0.86166555 -1.0392659\n",
      "  0.13916296 -0.8920789  -1.0571449   0.14297588 -0.8241582  -1.1460712\n",
      "  0.2535962  -0.8573941  -1.2169355   0.13315192 -0.7918108  -0.87051237\n",
      "  0.07833014 -0.53297067 -1.3399767   0.21397133 -0.6714797  -1.3130996\n",
      "  0.34281176 -0.614589   -1.1168182   0.029211   -0.56486773 -0.8308249\n",
      "  0.15746891 -0.5233587  -0.9186953   0.21676601 -0.5512974  -1.047764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.25736678 -0.54666686 -0.9587301   0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[-0.0334, -0.0939, -0.1177,  ..., -0.3148, -0.3309, -1.2189],\n",
      "        [-0.0334, -0.0939, -0.1177,  ..., -0.3148, -0.3309, -1.2189],\n",
      "        [-0.0334, -0.0939, -0.1177,  ..., -0.3148, -0.3309, -1.2189],\n",
      "        ...,\n",
      "        [-0.3577,  0.1258,  0.0942,  ..., -0.4307,  0.7695, -0.4187],\n",
      "        [-0.0446,  0.1069,  0.5536,  ...,  0.4018,  0.6670,  0.2595],\n",
      "        [-0.0446,  0.1069,  0.5536,  ...,  0.4018,  0.6670,  0.2595]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.0334381  -0.09391993 -0.11766744 -0.17232025 -0.25477058 -0.54740334\n",
      " -0.33839718 -0.47608477 -1.2631865  -0.5332308  -0.55949205 -1.572409\n",
      " -0.85768014 -0.60890007 -2.046666   -0.31841648 -0.76885104 -1.443176\n",
      " -0.42913505 -0.8730893  -1.5050011  -0.44774643 -0.74057925 -1.5858111\n",
      " -0.36683384 -0.9899876  -1.623803   -0.31002054 -0.6351512  -1.3546723\n",
      " -0.36689416 -0.675948   -1.2605525  -0.44795763 -0.73495173 -1.4098656\n",
      " -0.26952147 -0.6045157  -1.4210923  -0.2961398  -0.5866374  -1.2691082\n",
      " -0.41421524 -0.44543156 -1.7740445  -0.38393357 -0.530101   -1.8063436\n",
      " -0.23448169 -0.52898633 -1.2754089  -0.33568156 -0.358482   -1.2046802\n",
      " -0.448632   -0.38101828 -1.3032202  -0.45365098 -0.32424164 -1.3995064\n",
      " -0.3147705  -0.33086842 -1.2188908 ]\n",
      "data: [-0.0334381  -0.09391993 -0.11766744 -0.17232025 -0.25477058 -0.54740334\n",
      " -0.33839718 -0.4760848  -1.2631865  -0.5332308  -0.55949205 -1.572409\n",
      " -0.85768014 -0.60890007 -2.046666   -0.31841648 -0.76885104 -1.4431759\n",
      " -0.42913505 -0.8730893  -1.5050011  -0.44774643 -0.74057925 -1.5858111\n",
      " -0.36683384 -0.9899876  -1.6238029  -0.31002054 -0.6351512  -1.3546722\n",
      " -0.36689416 -0.675948   -1.2605525  -0.44795763 -0.73495173 -1.4098656\n",
      " -0.26952147 -0.6045157  -1.4210923  -0.2961398  -0.5866374  -1.2691082\n",
      " -0.41421524 -0.44543156 -1.7740445  -0.38393357 -0.530101   -1.8063436\n",
      " -0.23448169 -0.52898633 -1.2754089  -0.33568156 -0.358482   -1.2046802\n",
      " -0.448632   -0.38101828 -1.3032203  -0.45365098 -0.32424164 -1.3995063\n",
      " -0.3147705  -0.33086842 -1.2188908   0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0699,  0.1512, -0.2614,  ...,  0.2533, -0.0417, -1.2337],\n",
      "        [ 0.0699,  0.1512, -0.2614,  ...,  0.2533, -0.0417, -1.2337],\n",
      "        [ 0.0699,  0.1512, -0.2614,  ...,  0.2533, -0.0417, -1.2337],\n",
      "        ...,\n",
      "        [-0.0379,  0.0048,  0.4350,  ..., -0.9046,  0.5665,  0.3202],\n",
      "        [-0.1648, -0.2547,  0.5143,  ..., -0.7425,  0.1045,  0.3385],\n",
      "        [-0.1648, -0.2547,  0.5143,  ..., -0.7425,  0.1045,  0.3385]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 6.99033663e-02  1.51156783e-01 -2.61448890e-01  1.19549111e-01\n",
      "  2.93130279e-02 -5.43207288e-01  2.97788009e-02 -1.23320520e-01\n",
      " -1.33725369e+00 -1.12143606e-01 -1.74609363e-01 -1.62533951e+00\n",
      " -2.59303629e-01 -3.10584307e-01 -2.12210464e+00 -1.39170125e-01\n",
      " -4.02989984e-01 -1.56105995e+00  1.49341673e-01 -4.11797643e-01\n",
      " -1.42315733e+00  1.09756425e-01 -3.57660472e-01 -1.45302606e+00\n",
      "  1.56548947e-01 -4.57286179e-01 -1.56990659e+00 -6.86003864e-02\n",
      " -3.04624677e-01 -1.47157073e+00  7.36121312e-02 -3.74638259e-01\n",
      " -1.46953475e+00  1.15439117e-01 -3.32537591e-01 -1.55637383e+00\n",
      "  2.84997582e-01 -3.95836830e-01 -1.63124931e+00  5.75557575e-02\n",
      " -2.46782362e-01 -1.26469517e+00 -3.84383425e-02  1.84829533e-02\n",
      " -1.91711617e+00  1.76382765e-01 -1.70586467e-01 -1.90179276e+00\n",
      "  3.76626849e-01 -1.33134842e-01 -1.45201302e+00 -6.14939630e-02\n",
      " -7.02887774e-04 -1.19445586e+00  8.96493942e-02  2.35058814e-02\n",
      " -1.23936772e+00  1.74811944e-01 -1.79033577e-02 -1.36716247e+00\n",
      "  2.53294051e-01 -4.17291075e-02 -1.23367190e+00]\n",
      "data: [ 6.99033663e-02  1.51156783e-01 -2.61448890e-01  1.19549111e-01\n",
      "  2.93130279e-02 -5.43207288e-01  2.97788009e-02 -1.23320520e-01\n",
      " -1.33725369e+00 -1.12143606e-01 -1.74609363e-01 -1.62533951e+00\n",
      " -2.59303629e-01 -3.10584307e-01 -2.12210464e+00 -1.39170125e-01\n",
      " -4.02989984e-01 -1.56105983e+00  1.49341673e-01 -4.11797643e-01\n",
      " -1.42315733e+00  1.09756425e-01 -3.57660472e-01 -1.45302618e+00\n",
      "  1.56548947e-01 -4.57286179e-01 -1.56990659e+00 -6.86003864e-02\n",
      " -3.04624677e-01 -1.47157073e+00  7.36121312e-02 -3.74638259e-01\n",
      " -1.46953475e+00  1.15439117e-01 -3.32537562e-01 -1.55637395e+00\n",
      "  2.84997582e-01 -3.95836830e-01 -1.63124919e+00  5.75557575e-02\n",
      " -2.46782362e-01 -1.26469517e+00 -3.84383425e-02  1.84829533e-02\n",
      " -1.91711605e+00  1.76382765e-01 -1.70586467e-01 -1.90179276e+00\n",
      "  3.76626849e-01 -1.33134842e-01 -1.45201290e+00 -6.14939630e-02\n",
      " -7.02887774e-04 -1.19445586e+00  8.96493942e-02  2.35058814e-02\n",
      " -1.23936772e+00  1.74811929e-01 -1.79033577e-02 -1.36716247e+00\n",
      "  2.53294051e-01 -4.17291075e-02 -1.23367190e+00  3.99999991e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.1432, -0.2105, -0.1863,  ...,  0.1663, -0.3578, -1.3294],\n",
      "        [ 0.1432, -0.2105, -0.1863,  ...,  0.1663, -0.3578, -1.3294],\n",
      "        [ 0.1432, -0.2105, -0.1863,  ...,  0.1663, -0.3578, -1.3294],\n",
      "        ...,\n",
      "        [-0.3827,  0.2049, -0.1858,  ..., -1.0910,  0.5998, -0.3408],\n",
      "        [-0.2558,  0.2660,  0.3116,  ..., -0.3240,  1.1376, -0.0852],\n",
      "        [-0.2558,  0.2660,  0.3116,  ..., -0.3240,  1.1376, -0.0852]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.1432059  -0.21052748 -0.18632755  0.16941363 -0.36954445 -0.70796597\n",
      "  0.13952586 -0.4963228  -1.3714465   0.02088247 -0.5427698  -1.6643\n",
      " -0.12015444 -0.66731083 -2.1403348  -0.0557498  -0.7637105  -1.5074732\n",
      "  0.2129384  -0.7399956  -1.2719747   0.1601766  -0.67541873 -1.3332368\n",
      "  0.13040993 -0.7536354  -1.4495611  -0.02629492 -0.6586012  -1.4488463\n",
      "  0.0916284  -0.6914902  -1.4551237   0.06852809 -0.64058363 -1.5415162\n",
      "  0.16484347 -0.65823144 -1.6112019   0.07757672 -0.59314096 -1.2880424\n",
      "  0.0172157  -0.35452387 -1.7699162   0.12665832 -0.4777042  -1.7455903\n",
      "  0.23267397 -0.43849966 -1.4892144  -0.00810279 -0.36607325 -1.233816\n",
      "  0.0935331  -0.3348303  -1.3075162   0.14117527 -0.35381395 -1.4255501\n",
      "  0.1662721  -0.35780275 -1.3294244 ]\n",
      "data: [ 0.1432059  -0.21052748 -0.18632755  0.16941363 -0.36954445 -0.707966\n",
      "  0.13952586 -0.4963228  -1.3714465   0.02088247 -0.5427698  -1.6643\n",
      " -0.12015444 -0.6673109  -2.1403348  -0.0557498  -0.7637105  -1.5074733\n",
      "  0.2129384  -0.7399956  -1.2719747   0.1601766  -0.6754187  -1.3332368\n",
      "  0.13040993 -0.7536354  -1.4495611  -0.02629492 -0.6586012  -1.4488463\n",
      "  0.0916284  -0.6914902  -1.4551235   0.06852809 -0.64058363 -1.5415161\n",
      "  0.16484347 -0.65823144 -1.6112019   0.07757672 -0.59314096 -1.2880424\n",
      "  0.0172157  -0.35452384 -1.7699162   0.12665832 -0.4777042  -1.7455903\n",
      "  0.23267397 -0.43849963 -1.4892144  -0.00810279 -0.36607325 -1.233816\n",
      "  0.0935331  -0.3348303  -1.3075162   0.14117527 -0.35381395 -1.4255501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.1662721  -0.35780275 -1.3294244   0.05      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0278, -0.1576, -0.1970,  ...,  0.0048, -0.3358, -1.2338],\n",
      "        [ 0.0278, -0.1576, -0.1970,  ...,  0.0048, -0.3358, -1.2338],\n",
      "        [ 0.0278, -0.1576, -0.1970,  ...,  0.0048, -0.3358, -1.2338],\n",
      "        ...,\n",
      "        [-0.0623,  0.5207, -0.0932,  ..., -0.3492,  0.9612, -0.5547],\n",
      "        [-0.1563, -0.0172,  0.5468,  ..., -0.1780,  0.7615,  0.0187],\n",
      "        [-0.1563, -0.0172,  0.5468,  ..., -0.1780,  0.7615,  0.0187]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02779173 -0.15759471 -0.1970347   0.0464009  -0.28490627 -0.59267724\n",
      " -0.05449248 -0.51010156 -1.3987176  -0.20909393 -0.5735185  -1.714052\n",
      " -0.3852718  -0.68400836 -2.2039046  -0.1930222  -0.76981056 -1.592379\n",
      "  0.01309989 -0.8305828  -1.3959595  -0.05128671 -0.7680013  -1.4445158\n",
      " -0.07859538 -0.9356681  -1.5655506  -0.14664741 -0.66544193 -1.4796745\n",
      " -0.08946232 -0.73312527 -1.4383212  -0.11418641 -0.71886706 -1.5327303\n",
      " -0.00642267 -0.75250196 -1.559629   -0.05359244 -0.55503434 -1.3105865\n",
      " -0.22077163 -0.33699724 -2.0436525  -0.05459569 -0.5216341  -2.0512648\n",
      "  0.09026657 -0.4783132  -1.3981428  -0.17483659 -0.326905   -1.2311004\n",
      " -0.10210972 -0.30614147 -1.2978581  -0.06997655 -0.32984078 -1.407114\n",
      "  0.00484529 -0.33580637 -1.233827  ]\n",
      "data: [ 0.02779173 -0.15759471 -0.1970347   0.0464009  -0.28490627 -0.59267724\n",
      " -0.05449248 -0.51010156 -1.3987176  -0.20909393 -0.5735185  -1.714052\n",
      " -0.3852718  -0.68400836 -2.2039046  -0.1930222  -0.76981056 -1.592379\n",
      "  0.01309989 -0.8305828  -1.3959595  -0.05128671 -0.7680013  -1.4445158\n",
      " -0.07859538 -0.9356681  -1.5655506  -0.14664741 -0.6654419  -1.4796746\n",
      " -0.08946232 -0.7331253  -1.4383212  -0.1141864  -0.71886706 -1.5327305\n",
      " -0.00642267 -0.75250196 -1.559629   -0.05359243 -0.55503434 -1.3105865\n",
      " -0.22077161 -0.3369972  -2.0436525  -0.05459569 -0.5216341  -2.0512648\n",
      "  0.09026657 -0.4783132  -1.3981428  -0.17483659 -0.326905   -1.2311004\n",
      " -0.10210972 -0.30614147 -1.2978581  -0.06997655 -0.32984078 -1.4071139\n",
      "  0.00484529 -0.33580634 -1.233827    0.06      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FB00>\n",
      "tensor([[-0.0082, -0.0334, -0.1715,  ...,  0.0353, -0.2252, -1.1483],\n",
      "        [-0.0082, -0.0334, -0.1715,  ...,  0.0353, -0.2252, -1.1483],\n",
      "        [-0.0082, -0.0334, -0.1715,  ...,  0.0353, -0.2252, -1.1483],\n",
      "        ...,\n",
      "        [-0.1368,  0.3876, -0.0391,  ..., -0.7826,  0.9739, -0.4153],\n",
      "        [-0.0802, -0.1087,  0.6058,  ..., -0.1693,  0.5522,  0.2898],\n",
      "        [-0.0802, -0.1087,  0.6058,  ..., -0.1693,  0.5522,  0.2898]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.00819958 -0.03343464 -0.1714707   0.01353532 -0.1426571  -0.45122483\n",
      " -0.11433256 -0.36654255 -1.2956767  -0.26699692 -0.42696962 -1.5947983\n",
      " -0.42568326 -0.5307266  -2.0961304  -0.21379419 -0.66565853 -1.4844841\n",
      " -0.01268597 -0.722515   -1.3249288  -0.06503347 -0.65499383 -1.3724076\n",
      " -0.05569609 -0.8153595  -1.5015239  -0.16429432 -0.57028395 -1.3787768\n",
      " -0.09208129 -0.6261864  -1.3560662  -0.08446524 -0.5934911  -1.4475945\n",
      "  0.06409857 -0.63318443 -1.4741794  -0.06775572 -0.458564   -1.2112051\n",
      " -0.22670807 -0.22621831 -1.9775367  -0.02544835 -0.40479004 -1.9971625\n",
      "  0.16472362 -0.36239117 -1.3288504  -0.19663133 -0.22726871 -1.1325954\n",
      " -0.1102545  -0.20329028 -1.2150395  -0.07383424 -0.21407631 -1.3314275\n",
      "  0.03526255 -0.22515719 -1.1482692 ]\n",
      "data: [-0.00819958 -0.03343464 -0.1714707   0.01353532 -0.1426571  -0.45122483\n",
      " -0.11433256 -0.36654255 -1.2956767  -0.26699692 -0.42696962 -1.5947983\n",
      " -0.42568326 -0.5307266  -2.0961304  -0.21379419 -0.6656586  -1.4844841\n",
      " -0.01268597 -0.7225149  -1.3249288  -0.06503347 -0.65499383 -1.3724076\n",
      " -0.05569609 -0.8153595  -1.5015239  -0.16429432 -0.57028395 -1.3787769\n",
      " -0.09208129 -0.6261864  -1.3560662  -0.08446524 -0.5934911  -1.4475944\n",
      "  0.06409857 -0.63318443 -1.4741794  -0.06775572 -0.45856398 -1.2112051\n",
      " -0.22670807 -0.22621831 -1.9775367  -0.02544835 -0.40479004 -1.9971625\n",
      "  0.16472362 -0.36239117 -1.3288504  -0.19663134 -0.22726871 -1.1325954\n",
      " -0.1102545  -0.20329028 -1.2150395  -0.07383424 -0.21407631 -1.3314275\n",
      "  0.03526255 -0.22515719 -1.1482692   0.07      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[-0.0226, -0.0523, -0.2686,  ..., -0.0048, -0.2205, -1.3349],\n",
      "        [-0.0226, -0.0523, -0.2686,  ..., -0.0048, -0.2205, -1.3349],\n",
      "        [-0.0226, -0.0523, -0.2686,  ..., -0.0048, -0.2205, -1.3349],\n",
      "        ...,\n",
      "        [-0.2505,  0.3023, -0.0786,  ..., -0.7184,  0.7760, -0.2955],\n",
      "        [-0.1565, -0.0883,  0.5919,  ..., -0.2880,  0.6795,  0.3154],\n",
      "        [-0.1565, -0.0883,  0.5919,  ..., -0.2880,  0.6795,  0.3154]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-2.2600356e-02 -5.2307822e-02 -2.6859143e-01  1.4869310e-03\n",
      " -1.9255911e-01 -7.0027220e-01 -8.9733101e-02 -3.6624268e-01\n",
      " -1.4296548e+00 -2.3699170e-01 -4.2377803e-01 -1.7260404e+00\n",
      " -4.0848893e-01 -5.3445041e-01 -2.2008295e+00 -2.2972642e-01\n",
      " -6.5435570e-01 -1.5852687e+00 -1.5936449e-02 -6.7993045e-01\n",
      " -1.3908867e+00 -6.4611316e-02 -6.1319870e-01 -1.4474344e+00\n",
      " -6.7567118e-02 -7.4280524e-01 -1.5632819e+00 -1.8770707e-01\n",
      " -5.5111617e-01 -1.5056241e+00 -1.0559043e-01 -6.0171652e-01\n",
      " -1.4802194e+00 -1.1590132e-01 -5.7328403e-01 -1.5765589e+00\n",
      "  1.8424764e-02 -5.9237343e-01 -1.6227341e+00 -1.0230053e-01\n",
      " -4.6706015e-01 -1.3328280e+00 -2.1128561e-01 -2.3160255e-01\n",
      " -1.9654030e+00 -5.8145046e-02 -3.8296765e-01 -1.9653114e+00\n",
      "  9.8024309e-02 -3.5053569e-01 -1.4823465e+00 -2.0199871e-01\n",
      " -2.2867984e-01 -1.2723328e+00 -1.2899975e-01 -2.0095889e-01\n",
      " -1.3564904e+00 -8.1598088e-02 -2.0979324e-01 -1.4776871e+00\n",
      " -4.7581941e-03 -2.2046980e-01 -1.3349354e+00]\n",
      "data: [-2.2600358e-02 -5.2307822e-02 -2.6859143e-01  1.4869310e-03\n",
      " -1.9255911e-01 -7.0027220e-01 -8.9733101e-02 -3.6624268e-01\n",
      " -1.4296548e+00 -2.3699170e-01 -4.2377803e-01 -1.7260404e+00\n",
      " -4.0848893e-01 -5.3445041e-01 -2.2008295e+00 -2.2972640e-01\n",
      " -6.5435570e-01 -1.5852687e+00 -1.5936449e-02 -6.7993045e-01\n",
      " -1.3908867e+00 -6.4611316e-02 -6.1319870e-01 -1.4474344e+00\n",
      " -6.7567118e-02 -7.4280524e-01 -1.5632819e+00 -1.8770707e-01\n",
      " -5.5111617e-01 -1.5056241e+00 -1.0559043e-01 -6.0171652e-01\n",
      " -1.4802194e+00 -1.1590132e-01 -5.7328403e-01 -1.5765589e+00\n",
      "  1.8424764e-02 -5.9237343e-01 -1.6227341e+00 -1.0230053e-01\n",
      " -4.6706018e-01 -1.3328280e+00 -2.1128561e-01 -2.3160255e-01\n",
      " -1.9654030e+00 -5.8145046e-02 -3.8296765e-01 -1.9653114e+00\n",
      "  9.8024309e-02 -3.5053569e-01 -1.4823465e+00 -2.0199871e-01\n",
      " -2.2867984e-01 -1.2723328e+00 -1.2899975e-01 -2.0095891e-01\n",
      " -1.3564904e+00 -8.1598088e-02 -2.0979324e-01 -1.4776871e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -4.7581941e-03 -2.2046980e-01 -1.3349354e+00  7.9999998e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[ 0.0596, -0.1176, -0.2143,  ...,  0.0643, -0.2948, -1.3023],\n",
      "        [ 0.0596, -0.1176, -0.2143,  ...,  0.0643, -0.2948, -1.3023],\n",
      "        [ 0.0596, -0.1176, -0.2143,  ...,  0.0643, -0.2948, -1.3023],\n",
      "        ...,\n",
      "        [-0.3674,  0.2082, -0.4376,  ..., -0.8666,  0.6508, -0.5823],\n",
      "        [-0.1475, -0.0656,  0.5776,  ..., -0.2274,  0.6872,  0.2935],\n",
      "        [-0.1475, -0.0656,  0.5776,  ..., -0.2274,  0.6872,  0.2935]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 5.96457459e-02 -1.17640719e-01 -2.14345634e-01  8.24525952e-02\n",
      " -2.51705855e-01 -6.15646124e-01  4.89874184e-03 -4.22789603e-01\n",
      " -1.36882377e+00 -1.41683877e-01 -4.80409384e-01 -1.67711508e+00\n",
      " -3.09059709e-01 -5.91980040e-01 -2.17833948e+00 -1.47638917e-01\n",
      " -7.15536594e-01 -1.55112123e+00  7.67873749e-02 -7.40836561e-01\n",
      " -1.36925459e+00  1.83089599e-02 -6.81398869e-01 -1.42535651e+00\n",
      "  7.67754018e-03 -8.10687423e-01 -1.54457378e+00 -1.04438789e-01\n",
      " -6.15440428e-01 -1.46383190e+00 -2.09475085e-02 -6.66535914e-01\n",
      " -1.45200503e+00 -3.92624661e-02 -6.38852179e-01 -1.55846012e+00\n",
      "  7.73941502e-02 -6.65098608e-01 -1.60580754e+00 -1.50423795e-02\n",
      " -5.28153062e-01 -1.29061294e+00 -1.24691539e-01 -3.00639808e-01\n",
      " -1.90944231e+00  1.73903704e-02 -4.49576676e-01 -1.91080570e+00\n",
      "  1.59155786e-01 -4.22375500e-01 -1.45797098e+00 -1.20187052e-01\n",
      " -2.93921530e-01 -1.23102677e+00 -3.83670405e-02 -2.74247646e-01\n",
      " -1.30974185e+00 -6.50547445e-04 -2.88246781e-01 -1.42817032e+00\n",
      "  6.42787069e-02 -2.94822156e-01 -1.30231369e+00]\n",
      "data: [ 5.9645750e-02 -1.1764071e-01 -2.1434563e-01  8.2452595e-02\n",
      " -2.5170586e-01 -6.1564612e-01  4.8987418e-03 -4.2278960e-01\n",
      " -1.3688236e+00 -1.4168388e-01 -4.8040938e-01 -1.6771150e+00\n",
      " -3.0905971e-01 -5.9198004e-01 -2.1783395e+00 -1.4763892e-01\n",
      " -7.1553659e-01 -1.5511212e+00  7.6787375e-02 -7.4083656e-01\n",
      " -1.3692546e+00  1.8308960e-02 -6.8139887e-01 -1.4253564e+00\n",
      "  7.6775402e-03 -8.1068742e-01 -1.5445738e+00 -1.0443879e-01\n",
      " -6.1544043e-01 -1.4638319e+00 -2.0947509e-02 -6.6653597e-01\n",
      " -1.4520050e+00 -3.9262466e-02 -6.3885218e-01 -1.5584601e+00\n",
      "  7.7394150e-02 -6.6509855e-01 -1.6058075e+00 -1.5042379e-02\n",
      " -5.2815306e-01 -1.2906129e+00 -1.2469153e-01 -3.0063981e-01\n",
      " -1.9094423e+00  1.7390370e-02 -4.4957668e-01 -1.9108057e+00\n",
      "  1.5915579e-01 -4.2237550e-01 -1.4579711e+00 -1.2018705e-01\n",
      " -2.9392153e-01 -1.2310268e+00 -3.8367040e-02 -2.7424765e-01\n",
      " -1.3097419e+00 -6.5054744e-04 -2.8824678e-01 -1.4281703e+00\n",
      "  6.4278707e-02 -2.9482216e-01 -1.3023137e+00  9.0000004e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0303, -0.1228, -0.1985,  ...,  0.0862, -0.3237, -1.2027],\n",
      "        [ 0.0303, -0.1228, -0.1985,  ...,  0.0862, -0.3237, -1.2027],\n",
      "        [ 0.0303, -0.1228, -0.1985,  ...,  0.0862, -0.3237, -1.2027],\n",
      "        ...,\n",
      "        [-0.1382,  0.4364, -0.0655,  ..., -0.6589,  0.9591, -0.4086],\n",
      "        [-0.1886, -0.0659,  0.5941,  ..., -0.2734,  0.6847,  0.2042],\n",
      "        [-0.1886, -0.0659,  0.5941,  ..., -0.2734,  0.6847,  0.2042]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03030055 -0.12284511 -0.19853176  0.05869651 -0.24294102 -0.539866\n",
      " -0.05225748 -0.46127164 -1.3530447  -0.19959484 -0.52779156 -1.6508893\n",
      " -0.35673815 -0.6398021  -2.1352882  -0.16517214 -0.747419   -1.5285672\n",
      "  0.04743916 -0.8046612  -1.3522646  -0.00888327 -0.7386512  -1.399524\n",
      " -0.01712462 -0.89423615 -1.5211601  -0.11311483 -0.65152377 -1.4259443\n",
      " -0.03945835 -0.7136482  -1.4005822  -0.04477409 -0.68572116 -1.4855134\n",
      "  0.08309081 -0.72391427 -1.5176634  -0.01663242 -0.54979694 -1.2549803\n",
      " -0.16284151 -0.31718925 -1.9846568   0.01908871 -0.4967401  -1.9926947\n",
      "  0.18481411 -0.45388383 -1.3732296  -0.13817324 -0.31756097 -1.1799595\n",
      " -0.0487459  -0.29313937 -1.2643037  -0.00372848 -0.31255922 -1.37522\n",
      "  0.08623118 -0.32369906 -1.2026589 ]\n",
      "data: [ 0.03030055 -0.12284511 -0.19853176  0.05869651 -0.24294102 -0.539866\n",
      " -0.05225748 -0.46127164 -1.3530447  -0.19959484 -0.52779156 -1.6508893\n",
      " -0.35673818 -0.6398021  -2.1352882  -0.16517214 -0.747419   -1.5285672\n",
      "  0.04743915 -0.80466115 -1.3522648  -0.00888327 -0.7386512  -1.399524\n",
      " -0.01712462 -0.89423615 -1.5211601  -0.11311483 -0.65152377 -1.4259443\n",
      " -0.03945835 -0.7136482  -1.4005821  -0.04477409 -0.68572116 -1.4855134\n",
      "  0.08309081 -0.72391427 -1.5176635  -0.01663242 -0.54979694 -1.2549803\n",
      " -0.16284151 -0.31718925 -1.9846568   0.01908871 -0.4967401  -1.9926947\n",
      "  0.18481411 -0.45388383 -1.3732296  -0.13817324 -0.31756097 -1.1799595\n",
      " -0.0487459  -0.29313937 -1.2643037  -0.00372848 -0.31255922 -1.3752198\n",
      "  0.08623119 -0.3236991  -1.2026589   0.1       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0096, -0.0901, -0.1872,  ...,  0.0464, -0.2933, -1.1650],\n",
      "        [ 0.0096, -0.0901, -0.1872,  ...,  0.0464, -0.2933, -1.1650],\n",
      "        [ 0.0096, -0.0901, -0.1872,  ...,  0.0464, -0.2933, -1.1650],\n",
      "        ...,\n",
      "        [-0.1430,  0.3701, -0.0841,  ..., -0.6822,  0.8937, -0.4106],\n",
      "        [-0.0861, -0.0529,  0.6024,  ..., -0.1710,  0.6869,  0.2310],\n",
      "        [-0.0861, -0.0529,  0.6024,  ..., -0.1710,  0.6869,  0.2310]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00963612 -0.09008961 -0.18717673  0.04569377 -0.18766327 -0.47119838\n",
      " -0.10660978 -0.42386115 -1.3433268  -0.26219937 -0.49402434 -1.6301234\n",
      " -0.40931845 -0.58136237 -2.1478498  -0.17567629 -0.7329436  -1.5185766\n",
      " -0.01330282 -0.80719537 -1.3652346  -0.06731093 -0.7305334  -1.4172721\n",
      " -0.08255896 -0.908142   -1.5433712  -0.13102916 -0.65197235 -1.4138153\n",
      " -0.08193601 -0.7065499  -1.3832529  -0.0980024  -0.6720361  -1.4631948\n",
      "  0.04104792 -0.7061639  -1.4735956  -0.05114567 -0.538066   -1.2514443\n",
      " -0.21659298 -0.29929495 -2.047228   -0.02454271 -0.47902638 -2.0769827\n",
      "  0.15065625 -0.43936336 -1.3379292  -0.17221004 -0.31344825 -1.1691978\n",
      " -0.10732059 -0.28274596 -1.2588141  -0.07434496 -0.28077638 -1.3706312\n",
      "  0.04639412 -0.29334444 -1.1649671 ]\n",
      "data: [ 0.00963612 -0.0900896  -0.18717675  0.04569377 -0.18766327 -0.47119838\n",
      " -0.10660978 -0.42386115 -1.3433269  -0.26219937 -0.49402437 -1.6301235\n",
      " -0.40931848 -0.58136237 -2.1478498  -0.17567629 -0.7329436  -1.5185766\n",
      " -0.01330282 -0.80719537 -1.3652347  -0.06731093 -0.7305334  -1.4172721\n",
      " -0.08255896 -0.9081419  -1.5433713  -0.13102916 -0.65197235 -1.4138153\n",
      " -0.08193601 -0.7065499  -1.3832529  -0.0980024  -0.6720361  -1.4631948\n",
      "  0.04104792 -0.7061639  -1.4735956  -0.05114566 -0.538066   -1.2514443\n",
      " -0.21659298 -0.29929495 -2.047228   -0.02454271 -0.47902638 -2.0769827\n",
      "  0.15065625 -0.43936336 -1.3379292  -0.17221004 -0.31344825 -1.1691978\n",
      " -0.10732059 -0.28274596 -1.2588141  -0.07434496 -0.28077638 -1.3706312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.04639412 -0.29334444 -1.1649671   0.11      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0251,  0.0077, -0.2003,  ...,  0.0163, -0.1805, -1.1829],\n",
      "        [-0.0251,  0.0077, -0.2003,  ...,  0.0163, -0.1805, -1.1829],\n",
      "        [-0.0251,  0.0077, -0.2003,  ...,  0.0163, -0.1805, -1.1829],\n",
      "        ...,\n",
      "        [-0.1698,  0.3071,  0.0230,  ..., -0.7215,  0.8649, -0.3488],\n",
      "        [-0.1090, -0.1313,  0.5701,  ..., -0.2348,  0.5769,  0.2266],\n",
      "        [-0.1090, -0.1313,  0.5701,  ..., -0.2348,  0.5769,  0.2266]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.02506301  0.00767981 -0.20029971 -0.00299393 -0.10513404 -0.5064422\n",
      " -0.14155167 -0.32573846 -1.3429211  -0.29832292 -0.38956454 -1.6374122\n",
      " -0.4633646  -0.48742545 -2.136681   -0.22734502 -0.6292278  -1.511663\n",
      " -0.03892125 -0.68462205 -1.3337073  -0.08613478 -0.6100898  -1.3859998\n",
      " -0.08369921 -0.7711586  -1.5146451  -0.18182799 -0.53464335 -1.4112207\n",
      " -0.11357761 -0.587212   -1.3815132  -0.11188478 -0.5515962  -1.471473\n",
      "  0.04684195 -0.5816051  -1.4974954  -0.09196217 -0.42755795 -1.2429688\n",
      " -0.24232952 -0.1892187  -1.9948983  -0.04813685 -0.3603575  -2.0153096\n",
      "  0.14626318 -0.3201536  -1.3545833  -0.21330693 -0.19315888 -1.1645849\n",
      " -0.13956638 -0.16429117 -1.2522075  -0.10018086 -0.16713041 -1.3705217\n",
      "  0.01629459 -0.18048699 -1.1828576 ]\n",
      "data: [-0.02506301  0.00767981 -0.2002997  -0.00299393 -0.10513404 -0.5064422\n",
      " -0.14155167 -0.32573846 -1.3429211  -0.29832292 -0.38956454 -1.6374123\n",
      " -0.4633646  -0.48742545 -2.136681   -0.22734503 -0.6292278  -1.511663\n",
      " -0.03892125 -0.68462205 -1.3337073  -0.08613478 -0.6100898  -1.3859998\n",
      " -0.0836992  -0.7711586  -1.5146451  -0.18182798 -0.53464335 -1.4112207\n",
      " -0.11357761 -0.587212   -1.3815132  -0.11188479 -0.5515962  -1.471473\n",
      "  0.04684195 -0.5816051  -1.4974954  -0.09196217 -0.42755795 -1.2429688\n",
      " -0.24232952 -0.1892187  -1.9948983  -0.04813685 -0.36035746 -2.0153096\n",
      "  0.14626318 -0.3201536  -1.3545833  -0.21330695 -0.19315888 -1.1645849\n",
      " -0.13956638 -0.16429117 -1.2522075  -0.10018086 -0.16713041 -1.3705217\n",
      "  0.01629459 -0.18048698 -1.1828576   0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0135, -0.0862, -0.2031,  ...,  0.0043, -0.2437, -1.3270],\n",
      "        [-0.0135, -0.0862, -0.2031,  ...,  0.0043, -0.2437, -1.3270],\n",
      "        [-0.0135, -0.0862, -0.2031,  ...,  0.0043, -0.2437, -1.3270],\n",
      "        ...,\n",
      "        [-0.2669,  0.3239, -0.1873,  ..., -0.7800,  0.7758, -0.3572],\n",
      "        [-0.1776, -0.0958,  0.5226,  ..., -0.2633,  0.6621,  0.2441],\n",
      "        [-0.1776, -0.0958,  0.5226,  ..., -0.2633,  0.6621,  0.2441]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-1.3468411e-02 -8.6243801e-02 -2.0310763e-01 -4.2848662e-04\n",
      " -2.5184369e-01 -6.8247825e-01 -4.0245004e-02 -3.9169395e-01\n",
      " -1.3502425e+00 -1.7991562e-01 -4.4308913e-01 -1.6606810e+00\n",
      " -3.6528736e-01 -5.7971394e-01 -2.1199713e+00 -2.3970166e-01\n",
      " -6.6138756e-01 -1.5110071e+00  3.8483813e-02 -6.5453577e-01\n",
      " -1.2797641e+00 -1.0931879e-02 -6.0126138e-01 -1.3325801e+00\n",
      " -1.1248082e-02 -6.9266069e-01 -1.4477191e+00 -1.9542858e-01\n",
      " -5.4269671e-01 -1.4386098e+00 -7.7489488e-02 -5.9619772e-01\n",
      " -1.4298600e+00 -7.7368036e-02 -5.6549776e-01 -1.5406710e+00\n",
      "  4.8474640e-02 -5.8662772e-01 -1.6183753e+00 -8.9746125e-02\n",
      " -4.7535866e-01 -1.2596284e+00 -1.6332206e-01 -2.4888664e-01\n",
      " -1.7709616e+00 -3.2793388e-02 -3.8447624e-01 -1.7466403e+00\n",
      "  1.1125071e-01 -3.5403863e-01 -1.4711313e+00 -1.8834177e-01\n",
      " -2.2843115e-01 -1.2124146e+00 -8.8113666e-02 -2.0988655e-01\n",
      " -1.2893416e+00 -3.2016829e-02 -2.3892835e-01 -1.4130062e+00\n",
      "  4.3363944e-03 -2.4371727e-01 -1.3270196e+00]\n",
      "data: [-1.3468411e-02 -8.6243801e-02 -2.0310763e-01 -4.2848662e-04\n",
      " -2.5184369e-01 -6.8247825e-01 -4.0245004e-02 -3.9169395e-01\n",
      " -1.3502425e+00 -1.7991562e-01 -4.4308913e-01 -1.6606810e+00\n",
      " -3.6528736e-01 -5.7971394e-01 -2.1199713e+00 -2.3970166e-01\n",
      " -6.6138756e-01 -1.5110071e+00  3.8483813e-02 -6.5453577e-01\n",
      " -1.2797641e+00 -1.0931879e-02 -6.0126138e-01 -1.3325801e+00\n",
      " -1.1248082e-02 -6.9266069e-01 -1.4477191e+00 -1.9542858e-01\n",
      " -5.4269671e-01 -1.4386097e+00 -7.7489488e-02 -5.9619772e-01\n",
      " -1.4298599e+00 -7.7368036e-02 -5.6549776e-01 -1.5406709e+00\n",
      "  4.8474640e-02 -5.8662772e-01 -1.6183753e+00 -8.9746125e-02\n",
      " -4.7535866e-01 -1.2596284e+00 -1.6332206e-01 -2.4888664e-01\n",
      " -1.7709616e+00 -3.2793388e-02 -3.8447624e-01 -1.7466403e+00\n",
      "  1.1125071e-01 -3.5403863e-01 -1.4711313e+00 -1.8834177e-01\n",
      " -2.2843115e-01 -1.2124146e+00 -8.8113673e-02 -2.0988655e-01\n",
      " -1.2893416e+00 -3.2016829e-02 -2.3892836e-01 -1.4130062e+00\n",
      "  4.3363944e-03 -2.4371727e-01 -1.3270195e+00  1.3000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[ 4.8055e-02, -1.5091e-01, -2.8487e-01,  ...,  4.6260e-02,\n",
      "         -3.2083e-01, -1.3532e+00],\n",
      "        [ 4.8055e-02, -1.5091e-01, -2.8487e-01,  ...,  4.6260e-02,\n",
      "         -3.2083e-01, -1.3532e+00],\n",
      "        [ 4.8055e-02, -1.5091e-01, -2.8487e-01,  ...,  4.6260e-02,\n",
      "         -3.2083e-01, -1.3532e+00],\n",
      "        ...,\n",
      "        [-7.2021e-02,  5.8000e-01, -1.0430e-03,  ..., -6.7258e-01,\n",
      "          1.1112e+00, -3.0882e-01],\n",
      "        [-1.4100e-01, -2.8695e-02,  6.7268e-01,  ..., -2.5122e-01,\n",
      "          7.5562e-01,  3.3042e-01],\n",
      "        [-1.4100e-01, -2.8695e-02,  6.7268e-01,  ..., -2.5122e-01,\n",
      "          7.5562e-01,  3.3042e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04805486 -0.15091251 -0.28487065  0.07932787 -0.27578476 -0.6898874\n",
      " -0.02692776 -0.47194755 -1.4729586  -0.170616   -0.53402066 -1.7652043\n",
      " -0.31711966 -0.62788653 -2.26736    -0.14637534 -0.7639618  -1.639223\n",
      "  0.03992005 -0.80343306 -1.4732802  -0.01054409 -0.73642576 -1.5308204\n",
      " -0.02659941 -0.8807397  -1.6520678  -0.11039403 -0.6692821  -1.5519323\n",
      " -0.04426868 -0.7174239  -1.5282845  -0.06542212 -0.6841042  -1.6170274\n",
      "  0.05905686 -0.7109908  -1.6522796  -0.03232472 -0.567825   -1.3891727\n",
      " -0.1608751  -0.33578435 -2.061142   -0.00513659 -0.4904355  -2.0757077\n",
      "  0.14247015 -0.45508894 -1.5167933  -0.1377099  -0.33846816 -1.3166729\n",
      " -0.07171547 -0.30571795 -1.3956816  -0.03562343 -0.30908024 -1.512522\n",
      "  0.04625954 -0.32083225 -1.3531711 ]\n",
      "data: [ 0.04805486 -0.15091251 -0.28487065  0.07932787 -0.27578476 -0.6898874\n",
      " -0.02692776 -0.47194755 -1.4729586  -0.170616   -0.53402066 -1.7652043\n",
      " -0.31711966 -0.62788653 -2.26736    -0.14637534 -0.7639618  -1.639223\n",
      "  0.03992005 -0.80343306 -1.4732802  -0.01054409 -0.73642576 -1.5308204\n",
      " -0.02659941 -0.8807397  -1.6520677  -0.11039403 -0.6692821  -1.5519323\n",
      " -0.04426868 -0.7174239  -1.5282845  -0.06542212 -0.6841042  -1.6170274\n",
      "  0.05905686 -0.7109907  -1.6522796  -0.03232472 -0.567825   -1.3891727\n",
      " -0.1608751  -0.33578435 -2.061142   -0.00513659 -0.4904355  -2.0757077\n",
      "  0.14247015 -0.45508897 -1.5167933  -0.1377099  -0.33846816 -1.3166729\n",
      " -0.07171547 -0.30571795 -1.3956816  -0.03562343 -0.30908024 -1.512522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.04625954 -0.32083225 -1.3531711   0.14      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0087, -0.1074, -0.1901,  ...,  0.0840, -0.3039, -1.2325],\n",
      "        [ 0.0087, -0.1074, -0.1901,  ...,  0.0840, -0.3039, -1.2325],\n",
      "        [ 0.0087, -0.1074, -0.1901,  ...,  0.0840, -0.3039, -1.2325],\n",
      "        ...,\n",
      "        [-0.1142,  0.4405, -0.0984,  ..., -0.7780,  0.9554, -0.3937],\n",
      "        [-0.1143, -0.0833,  0.5506,  ..., -0.1935,  0.5963,  0.2004],\n",
      "        [-0.1143, -0.0833,  0.5506,  ..., -0.1935,  0.5963,  0.2004]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00865267 -0.10735635 -0.19006687  0.02649902 -0.25265473 -0.5630299\n",
      " -0.02545842 -0.43534392 -1.3157665  -0.16937472 -0.49155992 -1.6410501\n",
      " -0.3535143  -0.63827217 -2.1025443  -0.20841713 -0.7026583  -1.5183188\n",
      "  0.08191426 -0.73091686 -1.32217     0.0170621  -0.6838362  -1.3633372\n",
      "  0.02723789 -0.8087214  -1.4827918  -0.14349209 -0.5871717  -1.4144418\n",
      " -0.03126264 -0.65886676 -1.4040053  -0.02103614 -0.64217603 -1.5122614\n",
      "  0.09525347 -0.6887965  -1.5738946  -0.02280102 -0.5020576  -1.2226593\n",
      " -0.14572354 -0.278133   -1.8847485   0.02688552 -0.45792648 -1.8665873\n",
      "  0.18634851 -0.41920277 -1.4028906  -0.14851972 -0.25760484 -1.1619514\n",
      " -0.02222894 -0.24961415 -1.2368594   0.03292446 -0.29707006 -1.3526368\n",
      "  0.08403292 -0.3039196  -1.2324789 ]\n",
      "data: [ 0.00865267 -0.10735635 -0.19006687  0.02649902 -0.25265473 -0.5630299\n",
      " -0.02545842 -0.43534392 -1.3157665  -0.16937472 -0.4915599  -1.6410501\n",
      " -0.3535143  -0.63827217 -2.1025443  -0.20841713 -0.7026583  -1.5183188\n",
      "  0.08191426 -0.7309168  -1.3221699   0.0170621  -0.6838362  -1.363337\n",
      "  0.02723789 -0.80872136 -1.4827918  -0.14349209 -0.5871717  -1.4144418\n",
      " -0.03126264 -0.6588667  -1.4040053  -0.02103614 -0.64217603 -1.5122614\n",
      "  0.09525347 -0.6887965  -1.5738946  -0.02280102 -0.5020576  -1.2226593\n",
      " -0.14572354 -0.278133   -1.8847486   0.02688552 -0.45792648 -1.8665872\n",
      "  0.18634851 -0.41920277 -1.4028907  -0.14851972 -0.25760484 -1.1619514\n",
      " -0.02222894 -0.24961415 -1.2368594   0.03292446 -0.29707006 -1.3526368\n",
      "  0.08403292 -0.3039196  -1.2324789   0.15      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63EB8>\n",
      "tensor([[ 0.0114, -0.0999, -0.1867,  ...,  0.0416, -0.3001, -1.1721],\n",
      "        [ 0.0114, -0.0999, -0.1867,  ...,  0.0416, -0.3001, -1.1721],\n",
      "        [ 0.0114, -0.0999, -0.1867,  ...,  0.0416, -0.3001, -1.1721],\n",
      "        ...,\n",
      "        [-0.1307,  0.4531, -0.1307,  ..., -0.4649,  0.9923, -0.5054],\n",
      "        [-0.1384, -0.0584,  0.5994,  ..., -0.2428,  0.6902,  0.2195],\n",
      "        [-0.1384, -0.0584,  0.5994,  ..., -0.2428,  0.6902,  0.2195]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01141683 -0.09993247 -0.18670729  0.04650087 -0.19860561 -0.48099715\n",
      " -0.10717803 -0.43402037 -1.3472028  -0.26081643 -0.5044422  -1.6310844\n",
      " -0.4042293  -0.5879251  -2.1482275  -0.17213456 -0.7446693  -1.5179377\n",
      " -0.01599708 -0.8166703  -1.364825   -0.06711902 -0.7385831  -1.4175105\n",
      " -0.08248418 -0.9162408  -1.5434246  -0.13040435 -0.6624323  -1.4166133\n",
      " -0.08303383 -0.7140721  -1.3848524  -0.10021477 -0.67837083 -1.4618139\n",
      "  0.04109006 -0.71146786 -1.4744923  -0.05289594 -0.5485877  -1.2580938\n",
      " -0.21731484 -0.30739698 -2.0478108  -0.02801073 -0.48496374 -2.0784173\n",
      "  0.14616245 -0.44438663 -1.3431973  -0.17264456 -0.32280856 -1.1748242\n",
      " -0.11159906 -0.28902262 -1.2649305  -0.07933672 -0.2844589  -1.3781321\n",
      "  0.04160044 -0.300072   -1.1721332 ]\n",
      "data: [ 0.01141683 -0.09993247 -0.18670729  0.04650087 -0.19860561 -0.48099717\n",
      " -0.10717803 -0.4340204  -1.3472028  -0.26081643 -0.5044422  -1.6310844\n",
      " -0.4042293  -0.5879251  -2.1482275  -0.17213458 -0.7446693  -1.5179377\n",
      " -0.01599708 -0.8166703  -1.364825   -0.06711902 -0.7385831  -1.4175105\n",
      " -0.08248418 -0.9162409  -1.5434247  -0.13040435 -0.6624323  -1.4166133\n",
      " -0.08303383 -0.7140721  -1.3848524  -0.10021476 -0.67837083 -1.4618139\n",
      "  0.04109006 -0.7114679  -1.4744923  -0.05289594 -0.5485877  -1.2580938\n",
      " -0.21731484 -0.30739698 -2.0478108  -0.02801073 -0.48496377 -2.0784173\n",
      "  0.14616245 -0.44438663 -1.3431973  -0.17264456 -0.32280856 -1.1748242\n",
      " -0.11159906 -0.28902262 -1.2649305  -0.07933672 -0.2844589  -1.3781322\n",
      "  0.04160044 -0.300072   -1.1721332   0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FDD8>\n",
      "tensor([[-0.0247,  0.0115, -0.1925,  ...,  0.0195, -0.1763, -1.1737],\n",
      "        [-0.0247,  0.0115, -0.1925,  ...,  0.0195, -0.1763, -1.1737],\n",
      "        [-0.0247,  0.0115, -0.1925,  ...,  0.0195, -0.1763, -1.1737],\n",
      "        ...,\n",
      "        [-0.1777,  0.3095,  0.0042,  ..., -0.7333,  0.8745, -0.3764],\n",
      "        [-0.1078, -0.1395,  0.5792,  ..., -0.2367,  0.5620,  0.2348],\n",
      "        [-0.1078, -0.1395,  0.5792,  ..., -0.2367,  0.5620,  0.2348]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.02468424  0.01146082 -0.1925053  -0.00212982 -0.10373852 -0.49652576\n",
      " -0.13639319 -0.32432267 -1.3339226  -0.29270023 -0.38778785 -1.6302752\n",
      " -0.45918489 -0.48945794 -2.1277828  -0.22908966 -0.6237427  -1.5059549\n",
      " -0.03084973 -0.6775615  -1.3226165  -0.07908294 -0.60567975 -1.3729503\n",
      " -0.07648388 -0.7636235  -1.5019853  -0.18209907 -0.52668524 -1.4042203\n",
      " -0.10979872 -0.5812137  -1.3751223  -0.10542218 -0.54592717 -1.4654043\n",
      "  0.0516434  -0.5786946  -1.494257   -0.08887643 -0.41991702 -1.233668\n",
      " -0.24025573 -0.1818071  -1.9855635  -0.04380989 -0.35548747 -2.0031605\n",
      "  0.15005653 -0.31376496 -1.3479531  -0.21253    -0.18421969 -1.1557239\n",
      " -0.1336402  -0.15642917 -1.2402334  -0.09267758 -0.16315015 -1.3584547\n",
      "  0.01954701 -0.1763254  -1.1737242 ]\n",
      "data: [-0.02468424  0.01146082 -0.1925053  -0.00212982 -0.10373852 -0.49652576\n",
      " -0.13639319 -0.32432267 -1.3339226  -0.29270023 -0.38778785 -1.6302752\n",
      " -0.45918489 -0.48945794 -2.1277828  -0.22908966 -0.6237427  -1.5059549\n",
      " -0.03084972 -0.6775615  -1.3226165  -0.07908294 -0.60567975 -1.3729503\n",
      " -0.07648388 -0.7636235  -1.5019853  -0.18209907 -0.52668524 -1.4042202\n",
      " -0.10979871 -0.5812137  -1.3751224  -0.10542217 -0.54592717 -1.4654042\n",
      "  0.0516434  -0.5786946  -1.4942569  -0.08887644 -0.41991702 -1.233668\n",
      " -0.24025574 -0.1818071  -1.9855635  -0.04380989 -0.35548747 -2.0031605\n",
      "  0.15005653 -0.31376496 -1.3479531  -0.21253    -0.18421969 -1.1557239\n",
      " -0.1336402  -0.15642917 -1.2402334  -0.09267757 -0.16315013 -1.3584547\n",
      "  0.01954701 -0.1763254  -1.1737242   0.17      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0043, -0.1056, -0.2007,  ...,  0.0256, -0.2619, -1.3209],\n",
      "        [-0.0043, -0.1056, -0.2007,  ...,  0.0256, -0.2619, -1.3209],\n",
      "        [-0.0043, -0.1056, -0.2007,  ...,  0.0256, -0.2619, -1.3209],\n",
      "        ...,\n",
      "        [-0.2704,  0.3295, -0.2187,  ..., -0.7519,  0.7566, -0.3918],\n",
      "        [-0.1855, -0.1040,  0.5011,  ..., -0.2684,  0.6442,  0.2162],\n",
      "        [-0.1855, -0.1040,  0.5011,  ..., -0.2684,  0.6442,  0.2162]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.00427515 -0.10563953 -0.200748    0.0085842  -0.27272475 -0.6754503\n",
      " -0.02927957 -0.41506582 -1.3411218  -0.16988008 -0.46486863 -1.6539208\n",
      " -0.3554112  -0.6072756  -2.111018   -0.23319218 -0.6826782  -1.4992207\n",
      "  0.0593389  -0.6743258  -1.2498568   0.00601623 -0.6198305  -1.3013797\n",
      " -0.00224013 -0.7096442  -1.41925    -0.18638355 -0.5640447  -1.4263815\n",
      " -0.06296831 -0.6175035  -1.421144   -0.06149351 -0.5815568  -1.5296355\n",
      "  0.05996765 -0.6066197  -1.6055317  -0.07129753 -0.4929802  -1.2486863\n",
      " -0.14768827 -0.26447856 -1.765989   -0.01298191 -0.40411606 -1.7387694\n",
      "  0.1300439  -0.36785814 -1.4648434  -0.1736828  -0.2474949  -1.2024821\n",
      " -0.0651193  -0.22804274 -1.2836045  -0.00953631 -0.2603566  -1.4079671\n",
      "  0.02555553 -0.2619446  -1.3209368 ]\n",
      "data: [-0.00427515 -0.10563953 -0.20074801  0.0085842  -0.27272475 -0.67545027\n",
      " -0.02927957 -0.41506585 -1.3411218  -0.16988009 -0.46486863 -1.6539208\n",
      " -0.35541117 -0.6072756  -2.111018   -0.23319218 -0.6826782  -1.4992207\n",
      "  0.0593389  -0.67432576 -1.2498568   0.00601623 -0.6198305  -1.3013797\n",
      " -0.00224013 -0.70964414 -1.41925    -0.18638355 -0.5640447  -1.4263816\n",
      " -0.06296831 -0.6175035  -1.421144   -0.0614935  -0.5815568  -1.5296357\n",
      "  0.05996765 -0.6066197  -1.6055316  -0.07129753 -0.49298018 -1.2486863\n",
      " -0.14768827 -0.26447856 -1.765989   -0.01298191 -0.40411606 -1.7387694\n",
      "  0.1300439  -0.3678581  -1.4648434  -0.17368278 -0.2474949  -1.2024821\n",
      " -0.0651193  -0.22804274 -1.2836044  -0.00953631 -0.2603566  -1.4079671\n",
      "  0.02555553 -0.2619446  -1.3209367   0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F9E8>\n",
      "tensor([[ 0.0326, -0.1335, -0.2903,  ...,  0.0494, -0.3053, -1.3505],\n",
      "        [ 0.0326, -0.1335, -0.2903,  ...,  0.0494, -0.3053, -1.3505],\n",
      "        [ 0.0326, -0.1335, -0.2903,  ...,  0.0494, -0.3053, -1.3505],\n",
      "        ...,\n",
      "        [-0.1099,  0.5298, -0.0924,  ..., -0.6706,  1.0577, -0.4248],\n",
      "        [-0.1639, -0.0416,  0.6425,  ..., -0.2696,  0.7291,  0.2749],\n",
      "        [-0.1639, -0.0416,  0.6425,  ..., -0.2696,  0.7291,  0.2749]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03262119 -0.13346234 -0.2902773   0.06460452 -0.2590211  -0.68614\n",
      " -0.03514447 -0.46212494 -1.4838027  -0.17938146 -0.5238657  -1.784474\n",
      " -0.32906452 -0.6298678  -2.2819731  -0.16937038 -0.7437218  -1.6591263\n",
      "  0.04759867 -0.7856762  -1.4713885  -0.00784097 -0.7238554  -1.5232136\n",
      " -0.02654514 -0.86726516 -1.6496315  -0.12616608 -0.64534235 -1.5622057\n",
      " -0.05131063 -0.70120984 -1.5426208  -0.06300519 -0.66837656 -1.6315877\n",
      "  0.05946875 -0.7068192  -1.6711092  -0.03567176 -0.54230285 -1.3913068\n",
      " -0.17422667 -0.30695254 -2.085402   -0.00465276 -0.47550794 -2.0944152\n",
      "  0.14902043 -0.43518645 -1.5242803  -0.15265068 -0.3094076  -1.3145016\n",
      " -0.06858455 -0.27878976 -1.3914398  -0.02777866 -0.29450187 -1.5074515\n",
      "  0.04936224 -0.305301   -1.3504504 ]\n",
      "data: [ 0.03262119 -0.13346234 -0.2902773   0.06460452 -0.2590211  -0.68614\n",
      " -0.03514447 -0.46212494 -1.4838027  -0.17938146 -0.5238657  -1.784474\n",
      " -0.32906452 -0.6298678  -2.2819731  -0.16937038 -0.7437218  -1.6591263\n",
      "  0.04759867 -0.7856762  -1.4713883  -0.00784097 -0.7238554  -1.5232136\n",
      " -0.02654514 -0.86726516 -1.6496315  -0.12616608 -0.64534235 -1.5622057\n",
      " -0.05131063 -0.70120984 -1.5426209  -0.06300519 -0.66837656 -1.6315876\n",
      "  0.05946876 -0.7068192  -1.6711092  -0.03567176 -0.54230285 -1.3913068\n",
      " -0.17422667 -0.30695254 -2.085402   -0.00465276 -0.47550792 -2.0944152\n",
      "  0.14902043 -0.43518648 -1.5242802  -0.15265068 -0.3094076  -1.3145016\n",
      " -0.06858455 -0.27878976 -1.3914398  -0.02777866 -0.29450187 -1.5074515\n",
      "  0.04936224 -0.305301   -1.3504504   0.19      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0070, -0.0969, -0.2178,  ...,  0.0426, -0.2761, -1.3033],\n",
      "        [ 0.0070, -0.0969, -0.2178,  ...,  0.0426, -0.2761, -1.3033],\n",
      "        [ 0.0070, -0.0969, -0.2178,  ...,  0.0426, -0.2761, -1.3033],\n",
      "        ...,\n",
      "        [-0.1417,  0.4637, -0.1617,  ..., -0.8217,  0.9503, -0.3850],\n",
      "        [-0.1136, -0.0762,  0.5604,  ..., -0.1843,  0.6370,  0.2317],\n",
      "        [-0.1136, -0.0762,  0.5604,  ..., -0.1843,  0.6370,  0.2317]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 7.0356922e-03 -9.6850961e-02 -2.1775162e-01  1.6732913e-02\n",
      " -2.5604385e-01 -6.6719341e-01 -1.0255657e-02 -4.1734356e-01\n",
      " -1.3684937e+00 -1.4995214e-01 -4.6944270e-01 -1.6994272e+00\n",
      " -3.4173989e-01 -6.1784828e-01 -2.1504321e+00 -2.1762656e-01\n",
      " -6.7805791e-01 -1.5557268e+00  8.1927404e-02 -6.8830776e-01\n",
      " -1.3402852e+00  1.7713621e-02 -6.4463603e-01 -1.3869878e+00\n",
      "  2.2388577e-02 -7.5384057e-01 -1.5053779e+00 -1.6076607e-01\n",
      " -5.5554396e-01 -1.4588927e+00 -4.3784901e-02 -6.2239307e-01\n",
      " -1.4486797e+00 -4.0666036e-02 -6.0662127e-01 -1.5638949e+00\n",
      "  6.7910567e-02 -6.4450192e-01 -1.6356707e+00 -4.3288015e-02\n",
      " -4.7666311e-01 -1.2680669e+00 -1.4948016e-01 -2.5795731e-01\n",
      " -1.8649697e+00 -5.2103400e-04 -4.2076701e-01 -1.8392006e+00\n",
      "  1.4441626e-01 -3.8673025e-01 -1.4627355e+00 -1.6073099e-01\n",
      " -2.2998556e-01 -1.2110412e+00 -3.9932221e-02 -2.2243495e-01\n",
      " -1.2816963e+00  1.2054920e-02 -2.7045509e-01 -1.3983492e+00\n",
      "  4.2617314e-02 -2.7607578e-01 -1.3033262e+00]\n",
      "data: [ 7.0356922e-03 -9.6850961e-02 -2.1775162e-01  1.6732913e-02\n",
      " -2.5604385e-01 -6.6719347e-01 -1.0255657e-02 -4.1734356e-01\n",
      " -1.3684937e+00 -1.4995214e-01 -4.6944273e-01 -1.6994271e+00\n",
      " -3.4173989e-01 -6.1784828e-01 -2.1504321e+00 -2.1762656e-01\n",
      " -6.7805791e-01 -1.5557268e+00  8.1927404e-02 -6.8830782e-01\n",
      " -1.3402852e+00  1.7713621e-02 -6.4463598e-01 -1.3869878e+00\n",
      "  2.2388577e-02 -7.5384057e-01 -1.5053780e+00 -1.6076607e-01\n",
      " -5.5554396e-01 -1.4588927e+00 -4.3784901e-02 -6.2239307e-01\n",
      " -1.4486797e+00 -4.0666036e-02 -6.0662127e-01 -1.5638947e+00\n",
      "  6.7910567e-02 -6.4450192e-01 -1.6356707e+00 -4.3288015e-02\n",
      " -4.7666314e-01 -1.2680669e+00 -1.4948016e-01 -2.5795731e-01\n",
      " -1.8649697e+00 -5.2103400e-04 -4.2076701e-01 -1.8392006e+00\n",
      "  1.4441626e-01 -3.8673028e-01 -1.4627357e+00 -1.6073099e-01\n",
      " -2.2998556e-01 -1.2110412e+00 -3.9932221e-02 -2.2243495e-01\n",
      " -1.2816963e+00  1.2054920e-02 -2.7045509e-01 -1.3983492e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4.2617310e-02 -2.7607578e-01 -1.3033262e+00  2.0000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[ 0.0247, -0.0935, -0.2560,  ...,  0.0486, -0.2782, -1.3111],\n",
      "        [ 0.0247, -0.0935, -0.2560,  ...,  0.0486, -0.2782, -1.3111],\n",
      "        [ 0.0247, -0.0935, -0.2560,  ...,  0.0486, -0.2782, -1.3111],\n",
      "        ...,\n",
      "        [-0.1838,  0.4493, -0.1534,  ..., -0.7209,  0.9508, -0.4417],\n",
      "        [-0.1854, -0.1253,  0.6214,  ..., -0.2596,  0.6475,  0.2765],\n",
      "        [-0.1854, -0.1253,  0.6214,  ..., -0.2596,  0.6475,  0.2765]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02468301 -0.0935058  -0.25598815  0.04193247 -0.23445457 -0.67044806\n",
      " -0.05205783 -0.42976588 -1.4321262  -0.19475989 -0.49445963 -1.7265804\n",
      " -0.36017787 -0.60776424 -2.1978452  -0.18055582 -0.70741737 -1.5925772\n",
      "  0.03215575 -0.74585176 -1.395459   -0.01981468 -0.68114626 -1.447797\n",
      " -0.0254728  -0.81775475 -1.5645902  -0.1365512  -0.6010356  -1.5054306\n",
      " -0.05887941 -0.6566522  -1.4769921  -0.06915159 -0.63132966 -1.5655944\n",
      "  0.05767934 -0.65512025 -1.6083504  -0.04612709 -0.5116872  -1.3379695\n",
      " -0.16618462 -0.2846583  -1.9813769  -0.01197887 -0.44267532 -1.9813204\n",
      "  0.14267875 -0.4050835  -1.4680167  -0.15213948 -0.27443224 -1.2694407\n",
      " -0.07292378 -0.25093564 -1.3525494  -0.02728613 -0.26594535 -1.46591\n",
      "  0.04860941 -0.2782368  -1.3111407 ]\n",
      "data: [-1.57 -5.38  2.26 -1.57 -5.38  2.26 -1.48 -5.35  2.   -1.18 -5.19  1.49\n",
      " -1.06 -5.2   1.69 -1.17 -5.62  1.67 -0.95 -5.44  1.39 -0.87 -5.22  1.4\n",
      " -0.9  -5.06  1.56 -1.03 -5.53  1.54 -0.8  -5.37  1.33 -0.77 -5.11  1.4\n",
      " -0.81 -4.96  1.75 -0.98 -5.38  1.48 -0.76 -5.31  1.43 -0.74 -5.12  1.54\n",
      " -0.77 -4.93  1.75 -1.03 -5.25  1.8  -0.74 -5.23  1.42 -0.72 -5.11  1.53\n",
      " -0.71 -5.02  1.64  0.  ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.1447,  0.4578, -0.2134,  ..., -0.6502,  0.3539, -0.9377],\n",
      "        [-0.1447,  0.4578, -0.2134,  ..., -0.6502,  0.3539, -0.9377],\n",
      "        [-0.1447,  0.4578, -0.2134,  ..., -0.6502,  0.3539, -0.9377],\n",
      "        ...,\n",
      "        [ 0.1771, -1.4245,  0.6418,  ...,  0.9812, -1.8877,  0.8260],\n",
      "        [ 0.6873, -0.0614,  0.8035,  ...,  0.7089, -0.5549,  2.6446],\n",
      "        [ 0.6873, -0.0614,  0.8035,  ...,  0.7089, -0.5549,  2.6446]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.14470384  0.4577782  -0.21339183 -0.29177222  0.23722306 -0.81913614\n",
      " -0.3141812   0.14809576 -0.974751   -0.37062156  0.02301043 -0.95745224\n",
      " -0.3906479  -0.02304527 -1.0514605  -0.41679344  0.19915307 -1.208922\n",
      " -0.3548407   0.14050919 -0.7058409  -0.43382907 -0.03274691 -0.7115595\n",
      " -0.5454329   0.01152238 -0.79704905 -0.47145742  0.33365065 -1.250814\n",
      " -0.5801183   0.24696335 -1.2654159  -0.6311618   0.12989506 -1.2546251\n",
      " -0.6881596   0.03914297 -1.2015773  -0.5265731   0.39771166 -1.2173185\n",
      " -0.599712    0.3149409  -1.0559056  -0.6900051   0.2768198  -1.0546579\n",
      " -0.7100867   0.14577702 -1.0422747  -0.4990098   0.543129   -1.0824943\n",
      " -0.55345535  0.4712126  -1.003942   -0.6220791   0.4476981  -0.98603624\n",
      " -0.65017104  0.35392675 -0.9377027 ]\n",
      "init: [-0.14470384  0.4577782  -0.21339183 -0.29177222  0.23722306 -0.81913614\n",
      " -0.3141812   0.14809576 -0.974751   -0.37062156  0.02301043 -0.95745224\n",
      " -0.3906479  -0.02304527 -1.0514605  -0.41679344  0.19915307 -1.208922\n",
      " -0.3548407   0.14050919 -0.7058409  -0.43382907 -0.03274691 -0.7115595\n",
      " -0.5454329   0.01152238 -0.79704905 -0.47145742  0.33365065 -1.250814\n",
      " -0.5801183   0.24696335 -1.2654159  -0.6311618   0.12989506 -1.2546251\n",
      " -0.6881596   0.03914297 -1.2015773  -0.5265731   0.39771166 -1.2173185\n",
      " -0.599712    0.3149409  -1.0559056  -0.6900051   0.2768198  -1.0546579\n",
      " -0.7100867   0.14577702 -1.0422747  -0.4990098   0.543129   -1.0824943\n",
      " -0.55345535  0.4712126  -1.003942   -0.6220791   0.4476981  -0.98603624\n",
      " -0.65017104  0.35392675 -0.9377027 ]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [-0.14470384  0.45777816 -0.21339183 -0.29177222  0.23722306 -0.81913614\n",
      " -0.3141812   0.14809576 -0.974751   -0.37062156  0.02301043 -0.95745224\n",
      " -0.3906479  -0.02304527 -1.0514605  -0.41679344  0.19915307 -1.208922\n",
      " -0.3548407   0.14050919 -0.7058409  -0.43382907 -0.03274691 -0.7115595\n",
      " -0.5454329   0.01152238 -0.79704905 -0.4714574   0.33365068 -1.250814\n",
      " -0.5801183   0.24696335 -1.2654159  -0.6311618   0.12989506 -1.2546251\n",
      " -0.6881596   0.03914297 -1.2015773  -0.5265731   0.39771166 -1.2173185\n",
      " -0.599712    0.3149409  -1.0559056  -0.6900051   0.2768198  -1.0546579\n",
      " -0.71008664  0.14577702 -1.0422747  -0.4990098   0.543129   -1.0824943\n",
      " -0.55345535  0.47121257 -1.003942   -0.6220791   0.4476981  -0.98603624\n",
      " -0.65017104  0.35392675 -0.9377027   0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F4A8>\n",
      "tensor([[-0.0364, -0.3380, -0.1397,  ...,  0.0187, -0.4481, -1.2069],\n",
      "        [-0.0364, -0.3380, -0.1397,  ...,  0.0187, -0.4481, -1.2069],\n",
      "        [-0.0364, -0.3380, -0.1397,  ...,  0.0187, -0.4481, -1.2069],\n",
      "        ...,\n",
      "        [ 0.1806,  0.3661, -0.0942,  ..., -0.7425,  0.7939, -0.0380],\n",
      "        [-0.1895,  0.1565,  0.4940,  ..., -0.6909,  0.9880,  0.0776],\n",
      "        [-0.1895,  0.1565,  0.4940,  ..., -0.6909,  0.9880,  0.0776]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.03642026 -0.3380056  -0.13965856 -0.00929187 -0.44483206 -0.5141993\n",
      " -0.11908264 -0.60154176 -1.2071812  -0.22776811 -0.6201043  -1.426877\n",
      " -0.34060055 -0.6968729  -1.847966   -0.24547952 -0.8740549  -1.2843134\n",
      " -0.0945859  -0.8630572  -1.2353566  -0.09029917 -0.7401204  -1.2661052\n",
      " -0.05413382 -0.8279687  -1.3454041  -0.21874423 -0.7940334  -1.2456641\n",
      " -0.11718924 -0.7899364  -1.2410796  -0.07729789 -0.6940919  -1.2730057\n",
      "  0.07492493 -0.68703663 -1.3495975  -0.11029968 -0.7378117  -1.1564541\n",
      " -0.17086203 -0.47995842 -1.5893025  -0.0190953  -0.5923694  -1.5758367\n",
      "  0.11955222 -0.4868039  -1.3446546  -0.20530854 -0.5341603  -1.1092417\n",
      " -0.13170344 -0.46239197 -1.2380917  -0.05344532 -0.46021757 -1.3540683\n",
      "  0.01866261 -0.44810966 -1.2068787 ]\n",
      "data: [-0.03642026 -0.3380056  -0.13965856 -0.00929187 -0.44483203 -0.5141993\n",
      " -0.11908264 -0.60154176 -1.2071812  -0.22776812 -0.6201043  -1.426877\n",
      " -0.34060055 -0.6968729  -1.847966   -0.24547952 -0.87405485 -1.2843136\n",
      " -0.0945859  -0.8630572  -1.2353566  -0.09029917 -0.7401204  -1.2661052\n",
      " -0.05413382 -0.8279688  -1.3454041  -0.21874423 -0.7940334  -1.2456641\n",
      " -0.11718924 -0.7899364  -1.2410796  -0.07729789 -0.694092   -1.2730057\n",
      "  0.07492493 -0.6870367  -1.3495975  -0.11029968 -0.7378117  -1.1564541\n",
      " -0.17086202 -0.47995842 -1.5893025  -0.0190953  -0.5923694  -1.5758367\n",
      "  0.11955222 -0.4868039  -1.3446546  -0.20530853 -0.5341603  -1.1092417\n",
      " -0.13170344 -0.46239197 -1.2380917  -0.05344532 -0.46021757 -1.3540683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.01866261 -0.44810966 -1.2068787   0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63438>\n",
      "tensor([[-0.0029, -0.0019, -0.2214,  ...,  0.0233, -0.1648, -1.3025],\n",
      "        [-0.0029, -0.0019, -0.2214,  ...,  0.0233, -0.1648, -1.3025],\n",
      "        [-0.0029, -0.0019, -0.2214,  ...,  0.0233, -0.1648, -1.3025],\n",
      "        ...,\n",
      "        [-0.2341,  0.4323,  0.1254,  ..., -0.1321,  1.2427, -0.4316],\n",
      "        [-0.1449,  0.0446,  0.5125,  ..., -0.4511,  0.6057,  0.1903],\n",
      "        [-0.1449,  0.0446,  0.5125,  ..., -0.4511,  0.6057,  0.1903]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-2.9453887e-03 -1.9448176e-03 -2.2138436e-01  2.5224801e-02\n",
      " -1.3184737e-01 -5.6970191e-01 -3.8254149e-02 -3.3038998e-01\n",
      " -1.3757561e+00 -1.9337918e-01 -3.8292208e-01 -1.7068348e+00\n",
      " -3.7391940e-01 -5.1553571e-01 -2.2041979e+00 -2.3189062e-01\n",
      " -5.9662181e-01 -1.6202488e+00  8.1667066e-02 -6.2857097e-01\n",
      " -1.3696659e+00  2.3589000e-02 -5.7714641e-01 -1.3997867e+00\n",
      "  1.8675044e-02 -7.0416284e-01 -1.5342171e+00 -1.7606561e-01\n",
      " -4.7951877e-01 -1.5055285e+00 -6.1120123e-02 -5.5053085e-01\n",
      " -1.4862926e+00 -3.7958317e-02 -5.1828200e-01 -1.5921278e+00\n",
      "  9.6385598e-02 -5.7774711e-01 -1.6577042e+00 -5.1971801e-02\n",
      " -3.7959170e-01 -1.3169435e+00 -2.0650208e-01 -1.3539600e-01\n",
      " -2.0202236e+00 -9.3507320e-03 -3.2981706e-01 -2.0085647e+00\n",
      "  1.7311314e-01 -2.7517515e-01 -1.4860572e+00 -2.0974392e-01\n",
      " -1.2606372e-01 -1.2390251e+00 -8.0463037e-02 -1.0273780e-01\n",
      " -1.3025372e+00 -3.0307129e-02 -1.5617599e-01 -1.4217057e+00\n",
      "  2.3289450e-02 -1.6483845e-01 -1.3025465e+00]\n",
      "data: [-2.9453887e-03 -1.9448176e-03 -2.2138435e-01  2.5224799e-02\n",
      " -1.3184737e-01 -5.6970191e-01 -3.8254149e-02 -3.3038998e-01\n",
      " -1.3757560e+00 -1.9337918e-01 -3.8292208e-01 -1.7068347e+00\n",
      " -3.7391940e-01 -5.1553571e-01 -2.2041979e+00 -2.3189062e-01\n",
      " -5.9662181e-01 -1.6202487e+00  8.1667058e-02 -6.2857097e-01\n",
      " -1.3696659e+00  2.3589000e-02 -5.7714641e-01 -1.3997867e+00\n",
      "  1.8675044e-02 -7.0416284e-01 -1.5342171e+00 -1.7606562e-01\n",
      " -4.7951877e-01 -1.5055285e+00 -6.1120123e-02 -5.5053085e-01\n",
      " -1.4862926e+00 -3.7958317e-02 -5.1828200e-01 -1.5921278e+00\n",
      "  9.6385591e-02 -5.7774711e-01 -1.6577041e+00 -5.1971804e-02\n",
      " -3.7959170e-01 -1.3169435e+00 -2.0650208e-01 -1.3539600e-01\n",
      " -2.0202236e+00 -9.3507320e-03 -3.2981706e-01 -2.0085647e+00\n",
      "  1.7311314e-01 -2.7517515e-01 -1.4860572e+00 -2.0974392e-01\n",
      " -1.2606372e-01 -1.2390251e+00 -8.0463037e-02 -1.0273780e-01\n",
      " -1.3025372e+00 -3.0307129e-02 -1.5617599e-01 -1.4217057e+00\n",
      "  2.3289450e-02 -1.6483845e-01 -1.3025465e+00  2.9999999e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B9B0>\n",
      "tensor([[-0.0095, -0.1327, -0.2922,  ...,  0.0168, -0.2928, -1.3986],\n",
      "        [-0.0095, -0.1327, -0.2922,  ...,  0.0168, -0.2928, -1.3986],\n",
      "        [-0.0095, -0.1327, -0.2922,  ...,  0.0168, -0.2928, -1.3986],\n",
      "        ...,\n",
      "        [-0.1785,  0.4093, -0.1256,  ..., -0.7288,  0.9351, -0.3186],\n",
      "        [-0.1858, -0.0477,  0.5880,  ..., -0.2673,  0.6956,  0.3003],\n",
      "        [-0.1858, -0.0477,  0.5880,  ..., -0.2673,  0.6956,  0.3003]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-9.5029054e-03 -1.3266036e-01 -2.9215938e-01  9.9590458e-03\n",
      " -2.9414850e-01 -7.5806499e-01 -1.5735574e-02 -4.3794119e-01\n",
      " -1.4431326e+00 -1.4873692e-01 -4.8744434e-01 -1.7543347e+00\n",
      " -3.1505787e-01 -6.3069117e-01 -2.2241631e+00 -2.2744022e-01\n",
      " -7.0537615e-01 -1.6010759e+00  6.8266436e-02 -6.9656676e-01\n",
      " -1.3719404e+00  1.6524941e-03 -6.4269584e-01 -1.4235665e+00\n",
      " -1.4923170e-02 -7.2895485e-01 -1.5430046e+00 -1.8269597e-01\n",
      " -5.9190500e-01 -1.5238608e+00 -6.1133668e-02 -6.3941443e-01\n",
      " -1.5253142e+00 -7.0674442e-02 -5.9794146e-01 -1.6241639e+00\n",
      "  2.2958502e-02 -6.3020122e-01 -1.6896045e+00 -6.4182572e-02\n",
      " -5.1505935e-01 -1.3481183e+00 -1.4807066e-01 -2.8303319e-01\n",
      " -1.8755178e+00 -2.0254463e-02 -4.2501950e-01 -1.8478971e+00\n",
      "  1.0181968e-01 -3.8651174e-01 -1.5531133e+00 -1.7170271e-01\n",
      " -2.7619642e-01 -1.2969444e+00 -5.0924629e-02 -2.5757238e-01\n",
      " -1.3745879e+00 -6.3944757e-03 -2.9262573e-01 -1.4909886e+00\n",
      "  1.6826771e-02 -2.9276624e-01 -1.3985637e+00]\n",
      "data: [-9.5029054e-03 -1.3266036e-01 -2.9215938e-01  9.9590458e-03\n",
      " -2.9414850e-01 -7.5806499e-01 -1.5735574e-02 -4.3794119e-01\n",
      " -1.4431326e+00 -1.4873692e-01 -4.8744434e-01 -1.7543347e+00\n",
      " -3.1505787e-01 -6.3069117e-01 -2.2241631e+00 -2.2744022e-01\n",
      " -7.0537615e-01 -1.6010759e+00  6.8266436e-02 -6.9656676e-01\n",
      " -1.3719403e+00  1.6524941e-03 -6.4269584e-01 -1.4235665e+00\n",
      " -1.4923169e-02 -7.2895485e-01 -1.5430046e+00 -1.8269596e-01\n",
      " -5.9190500e-01 -1.5238608e+00 -6.1133668e-02 -6.3941443e-01\n",
      " -1.5253142e+00 -7.0674442e-02 -5.9794146e-01 -1.6241639e+00\n",
      "  2.2958502e-02 -6.3020122e-01 -1.6896045e+00 -6.4182572e-02\n",
      " -5.1505935e-01 -1.3481183e+00 -1.4807066e-01 -2.8303319e-01\n",
      " -1.8755178e+00 -2.0254465e-02 -4.2501950e-01 -1.8478971e+00\n",
      "  1.0181968e-01 -3.8651171e-01 -1.5531135e+00 -1.7170271e-01\n",
      " -2.7619642e-01 -1.2969444e+00 -5.0924629e-02 -2.5757238e-01\n",
      " -1.3745879e+00 -6.3944757e-03 -2.9262573e-01 -1.4909886e+00\n",
      "  1.6826771e-02 -2.9276624e-01 -1.3985637e+00  3.9999999e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63630>\n",
      "tensor([[ 0.0591, -0.1850, -0.2498,  ...,  0.0747, -0.3560, -1.3406],\n",
      "        [ 0.0591, -0.1850, -0.2498,  ...,  0.0747, -0.3560, -1.3406],\n",
      "        [ 0.0591, -0.1850, -0.2498,  ...,  0.0747, -0.3560, -1.3406],\n",
      "        ...,\n",
      "        [-0.0927,  0.5011, -0.1290,  ..., -0.6795,  1.0145, -0.4270],\n",
      "        [-0.1968, -0.0605,  0.6418,  ..., -0.2772,  0.6648,  0.3495],\n",
      "        [-0.1968, -0.0605,  0.6418,  ..., -0.2772,  0.6648,  0.3495]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 5.90724163e-02 -1.85014576e-01 -2.49761194e-01  8.61811191e-02\n",
      " -3.21497858e-01 -6.59040809e-01  2.06348151e-02 -5.08428097e-01\n",
      " -1.42037725e+00 -1.23126484e-01 -5.62249184e-01 -1.73551369e+00\n",
      " -2.86538631e-01 -6.83504224e-01 -2.22129941e+00 -1.51128471e-01\n",
      " -7.83803105e-01 -1.61817408e+00  1.03809260e-01 -8.14338505e-01\n",
      " -1.43205595e+00  4.45636734e-02 -7.60929525e-01 -1.47899294e+00\n",
      "  3.77988145e-02 -8.90317023e-01 -1.60123324e+00 -1.01848610e-01\n",
      " -6.75648868e-01 -1.52047372e+00 -8.23934376e-03 -7.35937417e-01\n",
      " -1.50785470e+00 -9.63964313e-03 -7.09882975e-01 -1.60902810e+00\n",
      "  1.02227770e-01 -7.52042115e-01 -1.66209507e+00  4.56675887e-04\n",
      " -5.77978015e-01 -1.34337354e+00 -1.29447073e-01 -3.49623859e-01\n",
      " -2.00255156e+00  3.51215079e-02 -5.19485295e-01 -1.99796176e+00\n",
      "  1.81821436e-01 -4.77096856e-01 -1.50967789e+00 -1.23567857e-01\n",
      " -3.40013683e-01 -1.27600121e+00 -2.24439874e-02 -3.17164183e-01\n",
      " -1.34985781e+00  2.15338841e-02 -3.49722683e-01 -1.46630096e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7.47092366e-02 -3.55993867e-01 -1.34063792e+00]\n",
      "data: [ 5.90724200e-02 -1.85014576e-01 -2.49761194e-01  8.61811191e-02\n",
      " -3.21497828e-01 -6.59040809e-01  2.06348151e-02 -5.08428097e-01\n",
      " -1.42037725e+00 -1.23126484e-01 -5.62249184e-01 -1.73551357e+00\n",
      " -2.86538631e-01 -6.83504283e-01 -2.22129941e+00 -1.51128471e-01\n",
      " -7.83803105e-01 -1.61817408e+00  1.03809260e-01 -8.14338505e-01\n",
      " -1.43205595e+00  4.45636734e-02 -7.60929465e-01 -1.47899294e+00\n",
      "  3.77988145e-02 -8.90317023e-01 -1.60123324e+00 -1.01848610e-01\n",
      " -6.75648868e-01 -1.52047384e+00 -8.23934376e-03 -7.35937417e-01\n",
      " -1.50785482e+00 -9.63964313e-03 -7.09882975e-01 -1.60902822e+00\n",
      "  1.02227777e-01 -7.52042055e-01 -1.66209507e+00  4.56675887e-04\n",
      " -5.77978015e-01 -1.34337354e+00 -1.29447073e-01 -3.49623859e-01\n",
      " -2.00255156e+00  3.51215079e-02 -5.19485295e-01 -1.99796176e+00\n",
      "  1.81821436e-01 -4.77096856e-01 -1.50967789e+00 -1.23567857e-01\n",
      " -3.40013683e-01 -1.27600121e+00 -2.24439874e-02 -3.17164183e-01\n",
      " -1.34985781e+00  2.15338841e-02 -3.49722683e-01 -1.46630096e+00\n",
      "  7.47092366e-02 -3.55993867e-01 -1.34063792e+00  5.00000007e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0175, -0.1731, -0.1889,  ...,  0.0709, -0.3640, -1.2235],\n",
      "        [ 0.0175, -0.1731, -0.1889,  ...,  0.0709, -0.3640, -1.2235],\n",
      "        [ 0.0175, -0.1731, -0.1889,  ...,  0.0709, -0.3640, -1.2235],\n",
      "        ...,\n",
      "        [-0.0186,  0.5448, -0.1421,  ..., -0.4881,  1.0903, -0.5259],\n",
      "        [-0.1184,  0.0146,  0.5961,  ..., -0.1574,  0.6931,  0.2581],\n",
      "        [-0.1184,  0.0146,  0.5961,  ..., -0.1574,  0.6931,  0.2581]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.7520551e-02 -1.7305997e-01 -1.8892342e-01  4.3140542e-02\n",
      " -3.1027788e-01 -5.4719007e-01 -3.9128691e-02 -5.1713634e-01\n",
      " -1.3400429e+00 -1.8925482e-01 -5.8056587e-01 -1.6545188e+00\n",
      " -3.6258161e-01 -7.1238732e-01 -2.1322975e+00 -1.9424441e-01\n",
      " -7.8704071e-01 -1.5376487e+00  6.5750591e-02 -8.3259642e-01\n",
      " -1.3321809e+00  8.1776828e-04 -7.7762711e-01 -1.3747048e+00\n",
      " -8.0283061e-03 -9.1732001e-01 -1.4975944e+00 -1.3600215e-01\n",
      " -6.7791820e-01 -1.4325269e+00 -4.4030651e-02 -7.4764800e-01\n",
      " -1.4127330e+00 -4.3999910e-02 -7.2421181e-01 -1.5092771e+00\n",
      "  7.2996907e-02 -7.6945555e-01 -1.5541321e+00 -2.5182158e-02\n",
      " -5.7943124e-01 -1.2491406e+00 -1.6731223e-01 -3.4982216e-01\n",
      " -1.9519949e+00  1.0497734e-02 -5.3378803e-01 -1.9460123e+00\n",
      "  1.7090085e-01 -4.8954383e-01 -1.3948077e+00 -1.5363240e-01\n",
      " -3.3829355e-01 -1.1803831e+00 -4.4569053e-02 -3.2073373e-01\n",
      " -1.2579411e+00  3.6885664e-03 -3.5671863e-01 -1.3710475e+00\n",
      "  7.0917115e-02 -3.6404783e-01 -1.2235252e+00]\n",
      "data: [ 1.7520551e-02 -1.7305999e-01 -1.8892342e-01  4.3140542e-02\n",
      " -3.1027788e-01 -5.4719007e-01 -3.9128691e-02 -5.1713634e-01\n",
      " -1.3400428e+00 -1.8925482e-01 -5.8056587e-01 -1.6545188e+00\n",
      " -3.6258161e-01 -7.1238732e-01 -2.1322975e+00 -1.9424443e-01\n",
      " -7.8704071e-01 -1.5376487e+00  6.5750591e-02 -8.3259642e-01\n",
      " -1.3321807e+00  8.1776828e-04 -7.7762711e-01 -1.3747048e+00\n",
      " -8.0283061e-03 -9.1732001e-01 -1.4975944e+00 -1.3600215e-01\n",
      " -6.7791820e-01 -1.4325271e+00 -4.4030651e-02 -7.4764800e-01\n",
      " -1.4127330e+00 -4.3999910e-02 -7.2421181e-01 -1.5092770e+00\n",
      "  7.2996907e-02 -7.6945555e-01 -1.5541321e+00 -2.5182156e-02\n",
      " -5.7943124e-01 -1.2491406e+00 -1.6731223e-01 -3.4982216e-01\n",
      " -1.9519949e+00  1.0497735e-02 -5.3378803e-01 -1.9460123e+00\n",
      "  1.7090087e-01 -4.8954383e-01 -1.3948077e+00 -1.5363240e-01\n",
      " -3.3829352e-01 -1.1803831e+00 -4.4569053e-02 -3.2073373e-01\n",
      " -1.2579411e+00  3.6885664e-03 -3.5671863e-01 -1.3710475e+00\n",
      "  7.0917115e-02 -3.6404783e-01 -1.2235252e+00  5.9999999e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0102, -0.1086, -0.1792,  ...,  0.0185, -0.2989, -1.1794],\n",
      "        [ 0.0102, -0.1086, -0.1792,  ...,  0.0185, -0.2989, -1.1794],\n",
      "        [ 0.0102, -0.1086, -0.1792,  ...,  0.0185, -0.2989, -1.1794],\n",
      "        ...,\n",
      "        [-0.1258,  0.4809, -0.1308,  ..., -0.3168,  1.1075, -0.5877],\n",
      "        [-0.0777, -0.0060,  0.6431,  ..., -0.1611,  0.6827,  0.2745],\n",
      "        [-0.0777, -0.0060,  0.6431,  ..., -0.1611,  0.6827,  0.2745]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01020281 -0.10859967 -0.17924003  0.03775402 -0.21249242 -0.4711085\n",
      " -0.10941502 -0.4491854  -1.3348416  -0.26971966 -0.5184037  -1.6225156\n",
      " -0.42213053 -0.60580385 -2.141693   -0.18874867 -0.7539109  -1.5202556\n",
      " -0.02658065 -0.8280952  -1.3788602  -0.07987402 -0.74971914 -1.4255798\n",
      " -0.08511242 -0.9218252  -1.5475569  -0.14502168 -0.66612434 -1.416309\n",
      " -0.09471361 -0.71899045 -1.3801761  -0.10585975 -0.6831758  -1.4621166\n",
      "  0.03314781 -0.71537054 -1.4743974  -0.06271941 -0.55023646 -1.2596669\n",
      " -0.2255962  -0.31304535 -2.0102632  -0.04211506 -0.48792133 -2.0376616\n",
      "  0.13468952 -0.44518873 -1.3474199  -0.1903201  -0.31852698 -1.1775383\n",
      " -0.12454188 -0.28722548 -1.2661086  -0.09475225 -0.2889618  -1.3758003\n",
      "  0.01853719 -0.29891276 -1.1794188 ]\n",
      "data: [ 0.01020281 -0.10859967 -0.17924003  0.03775402 -0.21249242 -0.47110853\n",
      " -0.10941502 -0.4491854  -1.3348416  -0.26971966 -0.5184037  -1.6225156\n",
      " -0.4221305  -0.60580385 -2.141693   -0.18874866 -0.7539109  -1.5202556\n",
      " -0.02658065 -0.8280952  -1.3788601  -0.07987402 -0.74971914 -1.4255798\n",
      " -0.08511242 -0.9218252  -1.5475569  -0.14502168 -0.66612434 -1.416309\n",
      " -0.09471361 -0.7189905  -1.3801761  -0.10585975 -0.6831758  -1.4621166\n",
      "  0.03314781 -0.71537054 -1.4743974  -0.06271941 -0.55023646 -1.2596669\n",
      " -0.2255962  -0.31304535 -2.0102632  -0.04211506 -0.48792133 -2.0376616\n",
      "  0.13468952 -0.4451887  -1.3474199  -0.1903201  -0.31852698 -1.1775383\n",
      " -0.12454187 -0.28722548 -1.2661086  -0.09475225 -0.2889618  -1.3758004\n",
      "  0.01853719 -0.29891276 -1.1794188   0.07      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[-1.6819e-02, -5.6355e-04, -1.9779e-01,  ...,  1.4863e-02,\n",
      "         -1.9508e-01, -1.1660e+00],\n",
      "        [-1.6819e-02, -5.6355e-04, -1.9779e-01,  ...,  1.4863e-02,\n",
      "         -1.9508e-01, -1.1660e+00],\n",
      "        [-1.6819e-02, -5.6355e-04, -1.9779e-01,  ...,  1.4863e-02,\n",
      "         -1.9508e-01, -1.1660e+00],\n",
      "        ...,\n",
      "        [-1.7181e-01,  3.3961e-01,  4.2966e-02,  ..., -6.7701e-01,\n",
      "          9.2376e-01, -3.3824e-01],\n",
      "        [-1.0294e-01, -1.2261e-01,  5.7994e-01,  ..., -2.2720e-01,\n",
      "          5.7772e-01,  2.4540e-01],\n",
      "        [-1.0294e-01, -1.2261e-01,  5.7994e-01,  ..., -2.2720e-01,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          5.7772e-01,  2.4540e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-1.6819250e-02 -5.6354608e-04 -1.9778728e-01  4.2392500e-03\n",
      " -1.0545981e-01 -4.8524234e-01 -1.5276209e-01 -3.3418426e-01\n",
      " -1.3384398e+00 -3.1080359e-01 -4.0058574e-01 -1.6215489e+00\n",
      " -4.6952236e-01 -4.8567009e-01 -2.1286128e+00 -2.1157922e-01\n",
      " -6.4726603e-01 -1.5055493e+00 -5.3436264e-02 -7.1177757e-01\n",
      " -1.3420292e+00 -9.5812842e-02 -6.2929577e-01 -1.3957763e+00\n",
      " -8.8554740e-02 -7.9929519e-01 -1.5223240e+00 -1.7154750e-01\n",
      " -5.5794948e-01 -1.4080766e+00 -1.1524980e-01 -6.0582870e-01\n",
      " -1.3704023e+00 -1.1663039e-01 -5.6920660e-01 -1.4536875e+00\n",
      "  5.0062254e-02 -5.9229314e-01 -1.4682957e+00 -9.1434501e-02\n",
      " -4.4893262e-01 -1.2487530e+00 -2.4506116e-01 -2.1025494e-01\n",
      " -2.0089550e+00 -5.1548831e-02 -3.7826920e-01 -2.0378401e+00\n",
      "  1.4930539e-01 -3.3915848e-01 -1.3357584e+00 -2.1081254e-01\n",
      " -2.1743996e-01 -1.1663624e+00 -1.5110576e-01 -1.8633360e-01\n",
      " -1.2565464e+00 -1.1694752e-01 -1.7885359e-01 -1.3722122e+00\n",
      "  1.4862604e-02 -1.9508068e-01 -1.1660423e+00]\n",
      "data: [-1.6819250e-02 -5.6354608e-04 -1.9778728e-01  4.2392500e-03\n",
      " -1.0545980e-01 -4.8524234e-01 -1.5276209e-01 -3.3418426e-01\n",
      " -1.3384398e+00 -3.1080359e-01 -4.0058574e-01 -1.6215489e+00\n",
      " -4.6952236e-01 -4.8567009e-01 -2.1286128e+00 -2.1157923e-01\n",
      " -6.4726603e-01 -1.5055493e+00 -5.3436264e-02 -7.1177757e-01\n",
      " -1.3420292e+00 -9.5812842e-02 -6.2929577e-01 -1.3957763e+00\n",
      " -8.8554747e-02 -7.9929519e-01 -1.5223240e+00 -1.7154750e-01\n",
      " -5.5794948e-01 -1.4080766e+00 -1.1524980e-01 -6.0582870e-01\n",
      " -1.3704023e+00 -1.1663039e-01 -5.6920660e-01 -1.4536875e+00\n",
      "  5.0062254e-02 -5.9229314e-01 -1.4682957e+00 -9.1434501e-02\n",
      " -4.4893262e-01 -1.2487530e+00 -2.4506114e-01 -2.1025494e-01\n",
      " -2.0089550e+00 -5.1548827e-02 -3.7826920e-01 -2.0378401e+00\n",
      "  1.4930539e-01 -3.3915848e-01 -1.3357586e+00 -2.1081252e-01\n",
      " -2.1743995e-01 -1.1663624e+00 -1.5110576e-01 -1.8633360e-01\n",
      " -1.2565464e+00 -1.1694752e-01 -1.7885359e-01 -1.3722122e+00\n",
      "  1.4862604e-02 -1.9508068e-01 -1.1660423e+00  7.9999998e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0133, -0.0649, -0.2082,  ...,  0.0030, -0.2226, -1.3257],\n",
      "        [-0.0133, -0.0649, -0.2082,  ...,  0.0030, -0.2226, -1.3257],\n",
      "        [-0.0133, -0.0649, -0.2082,  ...,  0.0030, -0.2226, -1.3257],\n",
      "        ...,\n",
      "        [-0.2492,  0.2933, -0.1269,  ..., -0.7698,  0.7566, -0.3114],\n",
      "        [-0.1814, -0.0993,  0.5137,  ..., -0.2818,  0.6559,  0.2478],\n",
      "        [-0.1814, -0.0993,  0.5137,  ..., -0.2818,  0.6559,  0.2478]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-1.33090056e-02 -6.48792386e-02 -2.08212957e-01 -8.76832753e-04\n",
      " -2.27402657e-01 -6.71548545e-01 -5.03395200e-02 -3.75289053e-01\n",
      " -1.35564137e+00 -1.93037108e-01 -4.28318441e-01 -1.66474867e+00\n",
      " -3.80682737e-01 -5.60806394e-01 -2.12577677e+00 -2.38848686e-01\n",
      " -6.45482957e-01 -1.52087712e+00  3.12743336e-02 -6.44653320e-01\n",
      " -1.29398561e+00 -1.56930387e-02 -5.89426696e-01 -1.34533715e+00\n",
      " -1.40166283e-02 -6.86631680e-01 -1.46043849e+00 -1.94471866e-01\n",
      " -5.26352644e-01 -1.44586325e+00 -8.03589821e-02 -5.81020951e-01\n",
      " -1.43315411e+00 -7.81932175e-02 -5.50911725e-01 -1.54322147e+00\n",
      "  5.40527552e-02 -5.71516693e-01 -1.61921358e+00 -9.04940292e-02\n",
      " -4.56933528e-01 -1.26774573e+00 -1.71444520e-01 -2.29048550e-01\n",
      " -1.79868698e+00 -3.47393528e-02 -3.68194282e-01 -1.77741122e+00\n",
      "  1.16013795e-01 -3.36047173e-01 -1.47055268e+00 -1.92479044e-01\n",
      " -2.08598286e-01 -1.21786189e+00 -9.60744023e-02 -1.88822895e-01\n",
      " -1.29480004e+00 -3.95839959e-02 -2.16573611e-01 -1.41807985e+00\n",
      "  2.96448916e-03 -2.22594485e-01 -1.32566500e+00]\n",
      "data: [-1.33090056e-02 -6.48792386e-02 -2.08212942e-01 -8.76832753e-04\n",
      " -2.27402642e-01 -6.71548545e-01 -5.03395163e-02 -3.75289053e-01\n",
      " -1.35564137e+00 -1.93037108e-01 -4.28318441e-01 -1.66474867e+00\n",
      " -3.80682766e-01 -5.60806394e-01 -2.12577677e+00 -2.38848686e-01\n",
      " -6.45482957e-01 -1.52087712e+00  3.12743336e-02 -6.44653320e-01\n",
      " -1.29398561e+00 -1.56930387e-02 -5.89426696e-01 -1.34533727e+00\n",
      " -1.40166283e-02 -6.86631680e-01 -1.46043849e+00 -1.94471881e-01\n",
      " -5.26352644e-01 -1.44586325e+00 -8.03589821e-02 -5.81020951e-01\n",
      " -1.43315411e+00 -7.81932175e-02 -5.50911725e-01 -1.54322147e+00\n",
      "  5.40527552e-02 -5.71516693e-01 -1.61921358e+00 -9.04940292e-02\n",
      " -4.56933528e-01 -1.26774573e+00 -1.71444505e-01 -2.29048550e-01\n",
      " -1.79868698e+00 -3.47393528e-02 -3.68194282e-01 -1.77741122e+00\n",
      "  1.16013795e-01 -3.36047173e-01 -1.47055268e+00 -1.92479044e-01\n",
      " -2.08598286e-01 -1.21786189e+00 -9.60744023e-02 -1.88822895e-01\n",
      " -1.29480016e+00 -3.95839959e-02 -2.16573626e-01 -1.41807985e+00\n",
      "  2.96448916e-03 -2.22594485e-01 -1.32566500e+00  9.00000036e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0465, -0.1490, -0.2877,  ...,  0.0420, -0.3204, -1.3552],\n",
      "        [ 0.0465, -0.1490, -0.2877,  ...,  0.0420, -0.3204, -1.3552],\n",
      "        [ 0.0465, -0.1490, -0.2877,  ...,  0.0420, -0.3204, -1.3552],\n",
      "        ...,\n",
      "        [-0.3064,  0.3552, -0.2983,  ..., -0.8380,  0.8516, -0.5328],\n",
      "        [-0.1424, -0.0267,  0.6755,  ..., -0.2370,  0.7585,  0.3522],\n",
      "        [-0.1424, -0.0267,  0.6755,  ..., -0.2370,  0.7585,  0.3522]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04647163 -0.14900476 -0.28769627  0.07747386 -0.27098387 -0.6900381\n",
      " -0.03444604 -0.4623539  -1.470678   -0.17962055 -0.5238558  -1.7590039\n",
      " -0.32527888 -0.612857   -2.265153   -0.14699674 -0.760885   -1.6354606\n",
      "  0.02748543 -0.7997848  -1.4783206  -0.0203504  -0.7296723  -1.5379416\n",
      " -0.03197715 -0.87412953 -1.6572409  -0.11248966 -0.66919816 -1.5517142\n",
      " -0.0496574  -0.7144563  -1.5264516  -0.07241561 -0.6814035  -1.6156499\n",
      "  0.05659296 -0.703192   -1.6488023  -0.03927139 -0.5712695  -1.390132\n",
      " -0.16209415 -0.33824018 -2.051125   -0.01051659 -0.48794416 -2.0680134\n",
      "  0.13915189 -0.45647874 -1.5157169  -0.13985172 -0.34269977 -1.3195381\n",
      " -0.08041924 -0.3095029  -1.3991727  -0.04477857 -0.30771592 -1.5161792\n",
      "  0.04198956 -0.32035112 -1.3551668 ]\n",
      "data: [ 0.04647163 -0.14900476 -0.28769627  0.07747386 -0.27098387 -0.6900381\n",
      " -0.03444604 -0.4623539  -1.470678   -0.17962055 -0.5238558  -1.7590039\n",
      " -0.32527888 -0.612857   -2.265153   -0.14699674 -0.760885   -1.6354606\n",
      "  0.02748543 -0.7997848  -1.4783206  -0.0203504  -0.7296723  -1.5379416\n",
      " -0.03197715 -0.87412953 -1.6572409  -0.11248966 -0.66919816 -1.5517142\n",
      " -0.0496574  -0.7144563  -1.5264516  -0.07241561 -0.6814035  -1.6156498\n",
      "  0.05659296 -0.703192   -1.6488023  -0.03927139 -0.5712695  -1.390132\n",
      " -0.16209416 -0.33824018 -2.051125   -0.01051659 -0.48794416 -2.0680134\n",
      "  0.13915189 -0.45647871 -1.5157169  -0.13985172 -0.34269977 -1.3195381\n",
      " -0.08041924 -0.3095029  -1.3991727  -0.04477857 -0.30771592 -1.5161792\n",
      "  0.04198956 -0.3203511  -1.3551668   0.1       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0240, -0.1530, -0.2037,  ...,  0.0913, -0.3390, -1.2781],\n",
      "        [ 0.0240, -0.1530, -0.2037,  ...,  0.0913, -0.3390, -1.2781],\n",
      "        [ 0.0240, -0.1530, -0.2037,  ...,  0.0913, -0.3390, -1.2781],\n",
      "        ...,\n",
      "        [-0.0529,  0.4615, -0.0894,  ..., -0.6785,  0.9912, -0.4075],\n",
      "        [-0.1286, -0.0434,  0.5628,  ..., -0.2094,  0.6323,  0.2412],\n",
      "        [-0.1286, -0.0434,  0.5628,  ..., -0.2094,  0.6323,  0.2412]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.40258165e-02 -1.52990878e-01 -2.03694165e-01  4.84417565e-02\n",
      " -2.96729624e-01 -5.77549696e-01  8.22087377e-03 -4.77489591e-01\n",
      " -1.34058177e+00 -1.37368292e-01 -5.30560970e-01 -1.67688048e+00\n",
      " -3.21060956e-01 -6.80165529e-01 -2.15042973e+00 -1.97223857e-01\n",
      " -7.40165114e-01 -1.56408465e+00  1.18897393e-01 -7.65230179e-01\n",
      " -1.35188413e+00  5.04586697e-02 -7.23143697e-01 -1.38988924e+00\n",
      "  5.09654731e-02 -8.43318582e-01 -1.51394999e+00 -1.30514175e-01\n",
      " -6.23310804e-01 -1.45412481e+00 -1.11821145e-02 -6.97905064e-01\n",
      " -1.45071030e+00  1.25468522e-03 -6.78989649e-01 -1.56530130e+00\n",
      "  1.10216767e-01 -7.33552217e-01 -1.63440263e+00 -4.28303331e-03\n",
      " -5.35384178e-01 -1.25673258e+00 -1.31954700e-01 -3.08096230e-01\n",
      " -1.92088330e+00  4.34994251e-02 -4.92971867e-01 -1.89990568e+00\n",
      "  1.98266521e-01 -4.50474948e-01 -1.45524585e+00 -1.39653206e-01\n",
      " -2.88967907e-01 -1.19564974e+00 -3.54677439e-03 -2.79498875e-01\n",
      " -1.26526368e+00  5.24904430e-02 -3.35767508e-01 -1.38210881e+00\n",
      "  9.13379714e-02 -3.39022279e-01 -1.27807760e+00]\n",
      "data: [ 2.4025816e-02 -1.5299088e-01 -2.0369416e-01  4.8441757e-02\n",
      " -2.9672962e-01 -5.7754970e-01  8.2208738e-03 -4.7748959e-01\n",
      " -1.3405818e+00 -1.3736829e-01 -5.3056097e-01 -1.6768805e+00\n",
      " -3.2106096e-01 -6.8016553e-01 -2.1504297e+00 -1.9722386e-01\n",
      " -7.4016511e-01 -1.5640846e+00  1.1889739e-01 -7.6523018e-01\n",
      " -1.3518841e+00  5.0458670e-02 -7.2314370e-01 -1.3898892e+00\n",
      "  5.0965473e-02 -8.4331858e-01 -1.5139500e+00 -1.3051417e-01\n",
      " -6.2331080e-01 -1.4541248e+00 -1.1182115e-02 -6.9790506e-01\n",
      " -1.4507103e+00  1.2546852e-03 -6.7898965e-01 -1.5653014e+00\n",
      "  1.1021677e-01 -7.3355222e-01 -1.6344026e+00 -4.2830333e-03\n",
      " -5.3538418e-01 -1.2567326e+00 -1.3195470e-01 -3.0809623e-01\n",
      " -1.9208833e+00  4.3499425e-02 -4.9297187e-01 -1.8999057e+00\n",
      "  1.9826652e-01 -4.5047492e-01 -1.4552459e+00 -1.3965321e-01\n",
      " -2.8896791e-01 -1.1956497e+00 -3.5467744e-03 -2.7949888e-01\n",
      " -1.2652637e+00  5.2490443e-02 -3.3576751e-01 -1.3821088e+00\n",
      "  9.1337964e-02 -3.3902228e-01 -1.2780776e+00  1.1000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63828>\n",
      "tensor([[ 0.0150, -0.1440, -0.1727,  ...,  0.0488, -0.3396, -1.1698],\n",
      "        [ 0.0150, -0.1440, -0.1727,  ...,  0.0488, -0.3396, -1.1698],\n",
      "        [ 0.0150, -0.1440, -0.1727,  ...,  0.0488, -0.3396, -1.1698],\n",
      "        ...,\n",
      "        [-0.0950,  0.4782, -0.1017,  ..., -0.3899,  1.0060, -0.4982],\n",
      "        [-0.1797, -0.0275,  0.6249,  ..., -0.2608,  0.6778,  0.2649],\n",
      "        [-0.1797, -0.0275,  0.6249,  ..., -0.2608,  0.6778,  0.2649]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01501909 -0.14399457 -0.17271474  0.04632432 -0.25660253 -0.47988537\n",
      " -0.0903391  -0.49197322 -1.3307326  -0.24538396 -0.56210107 -1.6213887\n",
      " -0.3948462  -0.66149735 -2.1271744  -0.18064664 -0.785351   -1.5135846\n",
      "  0.00794476 -0.85418516 -1.3417704  -0.04856071 -0.78290325 -1.3891534\n",
      " -0.06421585 -0.94921637 -1.5147893  -0.1334615  -0.6927298  -1.4103565\n",
      " -0.07417632 -0.7516148  -1.381612   -0.08379225 -0.71786904 -1.459806\n",
      "  0.0486418  -0.7574029  -1.4786395  -0.04239341 -0.57890093 -1.2463672\n",
      " -0.20512198 -0.34091175 -2.0062103  -0.01749465 -0.52428955 -2.0253987\n",
      "  0.15389709 -0.47855693 -1.3426952  -0.16941963 -0.34730256 -1.1658779\n",
      " -0.09162812 -0.31679553 -1.2513003  -0.05599073 -0.32653835 -1.3622516\n",
      "  0.04880612 -0.33964533 -1.16976   ]\n",
      "data: [ 0.01501909 -0.14399457 -0.17271475  0.04632432 -0.25660253 -0.47988537\n",
      " -0.09033909 -0.49197322 -1.3307326  -0.24538396 -0.56210107 -1.6213887\n",
      " -0.3948462  -0.66149735 -2.1271744  -0.18064664 -0.785351   -1.5135846\n",
      "  0.00794476 -0.85418516 -1.3417705  -0.04856071 -0.7829033  -1.3891532\n",
      " -0.06421585 -0.94921637 -1.5147892  -0.1334615  -0.6927298  -1.4103564\n",
      " -0.07417632 -0.7516148  -1.381612   -0.08379225 -0.71786904 -1.459806\n",
      "  0.0486418  -0.7574029  -1.4786395  -0.04239341 -0.57890093 -1.2463672\n",
      " -0.20512198 -0.34091175 -2.0062103  -0.01749465 -0.52428955 -2.0253987\n",
      "  0.15389709 -0.47855693 -1.3426954  -0.16941963 -0.34730256 -1.1658779\n",
      " -0.09162812 -0.31679553 -1.2513003  -0.05599073 -0.32653835 -1.3622516\n",
      "  0.04880612 -0.3396453  -1.16976     0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B320>\n",
      "tensor([[-0.0372, -0.0448, -0.2262,  ..., -0.0014, -0.2329, -1.1884],\n",
      "        [-0.0372, -0.0448, -0.2262,  ..., -0.0014, -0.2329, -1.1884],\n",
      "        [-0.0372, -0.0448, -0.2262,  ..., -0.0014, -0.2329, -1.1884],\n",
      "        ...,\n",
      "        [-0.1542,  0.3764,  0.0155,  ..., -0.5991,  0.9921, -0.4012],\n",
      "        [-0.0590, -0.0509,  0.6532,  ..., -0.1968,  0.6442,  0.2988],\n",
      "        [-0.0590, -0.0509,  0.6532,  ..., -0.1968,  0.6442,  0.2988]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-3.71553786e-02 -4.48319763e-02 -2.26187214e-01 -5.76576963e-03\n",
      " -1.50408953e-01 -4.94719386e-01 -1.46658391e-01 -3.86159599e-01\n",
      " -1.36786890e+00 -3.02451491e-01 -4.51026082e-01 -1.65996528e+00\n",
      " -4.56575751e-01 -5.49570024e-01 -2.16960216e+00 -2.38347009e-01\n",
      " -6.83065176e-01 -1.54983997e+00 -4.38196808e-02 -7.47960389e-01\n",
      " -1.37790632e+00 -9.77991372e-02 -6.75449491e-01 -1.42263246e+00\n",
      " -1.01008266e-01 -8.39084625e-01 -1.55236387e+00 -1.91583037e-01\n",
      " -5.90628982e-01 -1.44154453e+00 -1.26563281e-01 -6.45783067e-01\n",
      " -1.41098237e+00 -1.24382205e-01 -6.07077718e-01 -1.49264097e+00\n",
      "  2.09633410e-02 -6.47435904e-01 -1.51170969e+00 -9.81171355e-02\n",
      " -4.75363314e-01 -1.27470756e+00 -2.66839504e-01 -2.34197274e-01\n",
      " -2.05710101e+00 -6.36155829e-02 -4.17730629e-01 -2.07873392e+00\n",
      "  1.24136373e-01 -3.70183468e-01 -1.37005091e+00 -2.31817216e-01\n",
      " -2.43032560e-01 -1.19195461e+00 -1.49294272e-01 -2.13453427e-01\n",
      " -1.27360129e+00 -1.13946393e-01 -2.21788228e-01 -1.38655829e+00\n",
      " -1.38758868e-03 -2.32911408e-01 -1.18840790e+00]\n",
      "data: [-3.71553786e-02 -4.48319763e-02 -2.26187214e-01 -5.76576963e-03\n",
      " -1.50408953e-01 -4.94719386e-01 -1.46658391e-01 -3.86159599e-01\n",
      " -1.36786890e+00 -3.02451491e-01 -4.51026082e-01 -1.65996516e+00\n",
      " -4.56575751e-01 -5.49570024e-01 -2.16960216e+00 -2.38347009e-01\n",
      " -6.83065176e-01 -1.54983997e+00 -4.38196808e-02 -7.47960329e-01\n",
      " -1.37790632e+00 -9.77991372e-02 -6.75449550e-01 -1.42263246e+00\n",
      " -1.01008266e-01 -8.39084625e-01 -1.55236387e+00 -1.91583037e-01\n",
      " -5.90628982e-01 -1.44154453e+00 -1.26563281e-01 -6.45783067e-01\n",
      " -1.41098237e+00 -1.24382213e-01 -6.07077718e-01 -1.49264097e+00\n",
      "  2.09633391e-02 -6.47435904e-01 -1.51170969e+00 -9.81171355e-02\n",
      " -4.75363314e-01 -1.27470756e+00 -2.66839504e-01 -2.34197274e-01\n",
      " -2.05710101e+00 -6.36155829e-02 -4.17730629e-01 -2.07873392e+00\n",
      "  1.24136373e-01 -3.70183498e-01 -1.37005091e+00 -2.31817201e-01\n",
      " -2.43032545e-01 -1.19195461e+00 -1.49294272e-01 -2.13453427e-01\n",
      " -1.27360129e+00 -1.13946393e-01 -2.21788228e-01 -1.38655818e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -1.38758868e-03 -2.32911408e-01 -1.18840790e+00  1.29999995e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0265, -0.0516, -0.1624,  ...,  0.0279, -0.2119, -1.2493],\n",
      "        [ 0.0265, -0.0516, -0.1624,  ...,  0.0279, -0.2119, -1.2493],\n",
      "        [ 0.0265, -0.0516, -0.1624,  ...,  0.0279, -0.2119, -1.2493],\n",
      "        ...,\n",
      "        [-0.2809,  0.2497, -0.2050,  ..., -0.7615,  0.7611, -0.4509],\n",
      "        [-0.2170, -0.1474,  0.5268,  ..., -0.3284,  0.5615,  0.2854],\n",
      "        [-0.2170, -0.1474,  0.5268,  ..., -0.3284,  0.5615,  0.2854]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02650787 -0.05161843 -0.1623535   0.04003753 -0.20217451 -0.60606134\n",
      " -0.02674905 -0.37451464 -1.3255734  -0.16986959 -0.42948943 -1.6331747\n",
      " -0.35415345 -0.5519863  -2.0921469  -0.1956976  -0.64936936 -1.4804482\n",
      "  0.05792084 -0.6658148  -1.258643    0.00977057 -0.61184597 -1.3068986\n",
      "  0.00580392 -0.726618   -1.4265264  -0.1517129  -0.53318566 -1.3946203\n",
      " -0.05286826 -0.59013045 -1.3764503  -0.04897276 -0.5607705  -1.4803816\n",
      "  0.08372834 -0.58931506 -1.5481089  -0.05341145 -0.44875413 -1.2213382\n",
      " -0.16522196 -0.22079514 -1.8341304  -0.0080751  -0.3723384  -1.8237265\n",
      "  0.14708433 -0.33424383 -1.399098   -0.16522127 -0.20208582 -1.1601884\n",
      " -0.0758498  -0.1789908  -1.2398511  -0.02456805 -0.20359538 -1.3613939\n",
      "  0.02786615 -0.21194579 -1.2493348 ]\n",
      "data: [ 0.02650787 -0.05161843 -0.1623535   0.04003753 -0.20217451 -0.60606134\n",
      " -0.02674905 -0.37451467 -1.3255734  -0.1698696  -0.42948943 -1.6331745\n",
      " -0.35415345 -0.5519863  -2.0921469  -0.1956976  -0.64936936 -1.4804482\n",
      "  0.05792084 -0.6658148  -1.258643    0.00977057 -0.61184597 -1.3068986\n",
      "  0.00580392 -0.726618   -1.4265265  -0.1517129  -0.53318566 -1.3946204\n",
      " -0.05286826 -0.59013045 -1.3764503  -0.04897276 -0.5607705  -1.4803816\n",
      "  0.08372834 -0.58931506 -1.5481089  -0.05341145 -0.44875413 -1.2213382\n",
      " -0.16522196 -0.22079514 -1.8341304  -0.0080751  -0.3723384  -1.8237265\n",
      "  0.14708433 -0.33424386 -1.399098   -0.16522127 -0.20208582 -1.1601884\n",
      " -0.0758498  -0.1789908  -1.2398511  -0.02456805 -0.20359538 -1.3613939\n",
      "  0.02786615 -0.21194579 -1.2493348   0.14      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F630B8>\n",
      "tensor([[ 0.0083, -0.0579, -0.2560,  ...,  0.0195, -0.2354, -1.2954],\n",
      "        [ 0.0083, -0.0579, -0.2560,  ...,  0.0195, -0.2354, -1.2954],\n",
      "        [ 0.0083, -0.0579, -0.2560,  ...,  0.0195, -0.2354, -1.2954],\n",
      "        ...,\n",
      "        [-0.1059,  0.4795, -0.0518,  ..., -0.6687,  1.0010, -0.3326],\n",
      "        [-0.1309, -0.0632,  0.6311,  ..., -0.2337,  0.7368,  0.2933],\n",
      "        [-0.1309, -0.0632,  0.6311,  ..., -0.2337,  0.7368,  0.2933]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00825763 -0.05785453 -0.25601447  0.03414811 -0.18941998 -0.6541708\n",
      " -0.08828551 -0.38576865 -1.4348245  -0.23327143 -0.4528693  -1.7126966\n",
      " -0.3866433  -0.5460757  -2.2041464  -0.1875109  -0.67297125 -1.5896004\n",
      " -0.01818214 -0.7130439  -1.4138547  -0.0598051  -0.6397002  -1.4717423\n",
      " -0.06501586 -0.7824435  -1.5871472  -0.15368997 -0.5754032  -1.5108773\n",
      " -0.08893299 -0.6236831  -1.4730749  -0.10793693 -0.59256244 -1.5553004\n",
      "  0.03451487 -0.6073642  -1.5879875  -0.07986187 -0.4854985  -1.3495215\n",
      " -0.19651534 -0.25371543 -1.9946752  -0.04403173 -0.40327218 -2.0071049\n",
      "  0.11651768 -0.37123045 -1.4539583  -0.17493677 -0.25367898 -1.2789217\n",
      " -0.11875986 -0.22244039 -1.3552816  -0.07625508 -0.2189771  -1.4712019\n",
      "  0.01945891 -0.23536338 -1.29538   ]\n",
      "data: [ 0.00825763 -0.05785452 -0.25601447  0.03414811 -0.18941997 -0.6541708\n",
      " -0.08828551 -0.38576865 -1.4348245  -0.23327142 -0.4528693  -1.7126966\n",
      " -0.3866433  -0.5460757  -2.2041464  -0.1875109  -0.67297125 -1.5896003\n",
      " -0.01818214 -0.7130439  -1.4138547  -0.0598051  -0.6397002  -1.4717423\n",
      " -0.06501586 -0.7824435  -1.5871472  -0.15368997 -0.5754032  -1.5108773\n",
      " -0.08893299 -0.6236831  -1.4730749  -0.10793693 -0.59256244 -1.5553002\n",
      "  0.03451487 -0.6073642  -1.5879875  -0.07986187 -0.48549852 -1.3495215\n",
      " -0.19651534 -0.25371543 -1.9946752  -0.04403173 -0.40327218 -2.0071049\n",
      "  0.11651768 -0.37123048 -1.4539583  -0.17493677 -0.25367898 -1.2789217\n",
      " -0.11875985 -0.22244039 -1.3552815  -0.07625508 -0.2189771  -1.4712019\n",
      "  0.01945891 -0.2353634  -1.29538     0.15      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FDD8>\n",
      "tensor([[ 0.0239, -0.0313, -0.2153,  ...,  0.0466, -0.2257, -1.2533],\n",
      "        [ 0.0239, -0.0313, -0.2153,  ...,  0.0466, -0.2257, -1.2533],\n",
      "        [ 0.0239, -0.0313, -0.2153,  ...,  0.0466, -0.2257, -1.2533],\n",
      "        ...,\n",
      "        [-0.2045,  0.3466, -0.1601,  ..., -0.8942,  0.8334, -0.3581],\n",
      "        [-0.1498, -0.2145,  0.5325,  ..., -0.2322,  0.5498,  0.2224],\n",
      "        [-0.1498, -0.2145,  0.5325,  ..., -0.2322,  0.5498,  0.2224]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02394261 -0.03128098 -0.21532257  0.03637404 -0.1681694  -0.6227683\n",
      " -0.05996666 -0.34400576 -1.3553085  -0.20370115 -0.40528393 -1.6477247\n",
      " -0.37546217 -0.51093745 -2.1244552  -0.17421854 -0.642357   -1.5093186\n",
      "  0.01337433 -0.67149985 -1.3432794  -0.03198099 -0.6029171  -1.4039216\n",
      " -0.02280718 -0.7411097  -1.5164633  -0.13506074 -0.54164445 -1.4308519\n",
      " -0.058431   -0.58994484 -1.4025795  -0.07318492 -0.5670427  -1.49912\n",
      "  0.06658228 -0.5792142  -1.5393516  -0.05409939 -0.45963398 -1.2652963\n",
      " -0.15782407 -0.23696697 -1.8896902  -0.0120737  -0.38116112 -1.8941714\n",
      "  0.14714827 -0.35620752 -1.4001485  -0.14658166 -0.22734568 -1.2042611\n",
      " -0.08139986 -0.20800751 -1.2869941  -0.04046783 -0.2105462  -1.4054716\n",
      "  0.0466109  -0.22568719 -1.253287  ]\n",
      "data: [ 0.02394261 -0.03128098 -0.21532257  0.03637404 -0.16816941 -0.6227683\n",
      " -0.05996666 -0.34400576 -1.3553085  -0.20370115 -0.40528393 -1.6477247\n",
      " -0.37546217 -0.51093745 -2.1244552  -0.17421854 -0.64235705 -1.5093186\n",
      "  0.01337433 -0.67149985 -1.3432794  -0.03198099 -0.6029171  -1.4039216\n",
      " -0.02280718 -0.74110967 -1.5164633  -0.13506074 -0.54164445 -1.4308519\n",
      " -0.058431   -0.58994484 -1.4025795  -0.07318492 -0.5670427  -1.49912\n",
      "  0.06658228 -0.5792142  -1.5393517  -0.05409939 -0.45963398 -1.2652963\n",
      " -0.15782407 -0.23696697 -1.88969    -0.0120737  -0.38116112 -1.8941712\n",
      "  0.14714827 -0.3562075  -1.4001485  -0.14658166 -0.22734568 -1.2042611\n",
      " -0.08139986 -0.20800751 -1.2869942  -0.04046783 -0.2105462  -1.4054714\n",
      "  0.0466109  -0.2256872  -1.253287    0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0114, -0.0664, -0.2472,  ...,  0.0271, -0.2479, -1.2942],\n",
      "        [ 0.0114, -0.0664, -0.2472,  ...,  0.0271, -0.2479, -1.2942],\n",
      "        [ 0.0114, -0.0664, -0.2472,  ...,  0.0271, -0.2479, -1.2942],\n",
      "        ...,\n",
      "        [-0.3090,  0.2513, -0.3000,  ..., -0.8169,  0.7164, -0.4880],\n",
      "        [-0.1167, -0.0562,  0.6014,  ..., -0.2349,  0.7367,  0.2640],\n",
      "        [-0.1167, -0.0562,  0.6014,  ..., -0.2349,  0.7367,  0.2640]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01137023 -0.06637156 -0.24724682  0.03717667 -0.2006263  -0.6557169\n",
      " -0.06741492 -0.38653135 -1.4218414  -0.2095192  -0.45125014 -1.7087492\n",
      " -0.36842257 -0.5515937  -2.1957266  -0.18361127 -0.6741159  -1.576788\n",
      "  0.00678496 -0.7067818  -1.3900076  -0.03898333 -0.63905835 -1.4477748\n",
      " -0.04697705 -0.7761368  -1.5642627  -0.14754039 -0.57521445 -1.4961427\n",
      " -0.07387318 -0.6254903  -1.4638149  -0.09414987 -0.59658694 -1.5528859\n",
      "  0.04088284 -0.6148165  -1.5926446  -0.06920344 -0.48886538 -1.3293898\n",
      " -0.18104565 -0.25976968 -1.9672958  -0.03287525 -0.4088452  -1.9741385\n",
      "  0.12095606 -0.3796543  -1.4511735  -0.16502725 -0.2561427  -1.2621231\n",
      " -0.10020116 -0.22984187 -1.3379502  -0.0571526  -0.23282947 -1.4550656\n",
      "  0.02710215 -0.24791595 -1.2941653 ]\n",
      "data: [ 0.01137023 -0.06637156 -0.24724682  0.03717667 -0.2006263  -0.65571684\n",
      " -0.06741492 -0.38653138 -1.4218414  -0.2095192  -0.45125017 -1.7087493\n",
      " -0.3684226  -0.5515937  -2.1957266  -0.18361127 -0.6741159  -1.5767881\n",
      "  0.00678496 -0.70678174 -1.3900076  -0.03898333 -0.63905835 -1.4477748\n",
      " -0.04697705 -0.77613676 -1.5642627  -0.14754039 -0.57521445 -1.4961427\n",
      " -0.07387318 -0.6254903  -1.4638149  -0.09414987 -0.59658694 -1.5528859\n",
      "  0.04088284 -0.6148165  -1.5926445  -0.06920344 -0.48886535 -1.3293898\n",
      " -0.18104565 -0.25976968 -1.9672959  -0.03287525 -0.4088452  -1.9741385\n",
      "  0.12095606 -0.3796543  -1.4511735  -0.16502723 -0.2561427  -1.2621231\n",
      " -0.10020116 -0.22984189 -1.3379502  -0.0571526  -0.23282948 -1.4550656\n",
      "  0.02710215 -0.24791595 -1.2941651   0.17      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0059, -0.0363, -0.2393,  ...,  0.0432, -0.2288, -1.2763],\n",
      "        [ 0.0059, -0.0363, -0.2393,  ...,  0.0432, -0.2288, -1.2763],\n",
      "        [ 0.0059, -0.0363, -0.2393,  ...,  0.0432, -0.2288, -1.2763],\n",
      "        ...,\n",
      "        [-0.1916,  0.3516, -0.1647,  ..., -0.8527,  0.8390, -0.3785],\n",
      "        [-0.1482, -0.1960,  0.5444,  ..., -0.2414,  0.5629,  0.2211],\n",
      "        [-0.1482, -0.1960,  0.5444,  ..., -0.2414,  0.5629,  0.2211]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00594495 -0.03628188 -0.23926434  0.01956272 -0.17675601 -0.64458066\n",
      " -0.06395949 -0.35437202 -1.3756526  -0.20502402 -0.4139031  -1.6746788\n",
      " -0.37849376 -0.5316376  -2.1417735  -0.19833997 -0.6414379  -1.535551\n",
      "  0.01967691 -0.6680681  -1.3521104  -0.02939759 -0.60582614 -1.4073044\n",
      " -0.0223679  -0.73816717 -1.5223368  -0.15324207 -0.53597724 -1.4519552\n",
      " -0.06607234 -0.5901132  -1.4291724  -0.07234344 -0.5673207  -1.526197\n",
      "  0.06175731 -0.58898973 -1.5746136  -0.06079417 -0.45368046 -1.2812234\n",
      " -0.1692028  -0.2302889  -1.9131179  -0.01478368 -0.38345462 -1.9102216\n",
      "  0.14368656 -0.35286033 -1.4290503  -0.16120842 -0.21877007 -1.2202986\n",
      " -0.07925028 -0.20104183 -1.3010587  -0.03297161 -0.21558803 -1.4191822\n",
      "  0.04322781 -0.22881411 -1.276276  ]\n",
      "data: [ 0.00594495 -0.03628188 -0.23926434  0.01956272 -0.176756   -0.64458066\n",
      " -0.06395949 -0.35437202 -1.3756527  -0.20502402 -0.4139031  -1.6746788\n",
      " -0.37849376 -0.5316376  -2.1417735  -0.19833998 -0.6414379  -1.535551\n",
      "  0.01967691 -0.6680681  -1.3521104  -0.02939759 -0.60582614 -1.4073044\n",
      " -0.0223679  -0.73816717 -1.5223368  -0.15324207 -0.53597724 -1.4519553\n",
      " -0.06607234 -0.5901132  -1.4291724  -0.07234344 -0.5673207  -1.526197\n",
      "  0.06175731 -0.58898973 -1.5746137  -0.06079417 -0.45368046 -1.2812234\n",
      " -0.1692028  -0.2302889  -1.9131179  -0.01478368 -0.38345462 -1.9102216\n",
      "  0.14368656 -0.35286033 -1.4290503  -0.16120842 -0.21877007 -1.2202986\n",
      " -0.07925028 -0.20104183 -1.3010587  -0.03297161 -0.21558803 -1.4191822\n",
      "  0.04322781 -0.22881411 -1.276276    0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[ 0.0057, -0.0886, -0.2359,  ...,  0.0261, -0.2717, -1.2943],\n",
      "        [ 0.0057, -0.0886, -0.2359,  ...,  0.0261, -0.2717, -1.2943],\n",
      "        [ 0.0057, -0.0886, -0.2359,  ...,  0.0261, -0.2717, -1.2943],\n",
      "        ...,\n",
      "        [-0.3265,  0.2158, -0.3643,  ..., -0.8209,  0.6672, -0.5315],\n",
      "        [-0.1376, -0.0841,  0.5991,  ..., -0.2498,  0.7055,  0.2568],\n",
      "        [-0.1376, -0.0841,  0.5991,  ..., -0.2498,  0.7055,  0.2568]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00568414 -0.08858857 -0.23594591  0.02708668 -0.2279847  -0.65670484\n",
      " -0.06226032 -0.40786123 -1.4051393  -0.20208333 -0.46989155 -1.6989813\n",
      " -0.36750725 -0.57930267 -2.1756296  -0.19350389 -0.6918194  -1.5617558\n",
      "  0.0149745  -0.71934307 -1.3706614  -0.03245257 -0.6554198  -1.4275925\n",
      " -0.03641355 -0.78672576 -1.5437948  -0.15420489 -0.58839476 -1.4798814\n",
      " -0.07327312 -0.64031243 -1.4541439  -0.08784895 -0.61454046 -1.5474602\n",
      "  0.04346867 -0.6337117  -1.5950457  -0.06997847 -0.5055869  -1.3102418\n",
      " -0.17821549 -0.2789694  -1.9375938  -0.03078853 -0.42823297 -1.937951\n",
      "  0.12104359 -0.39785472 -1.4496744  -0.16768987 -0.27090073 -1.246061\n",
      " -0.09451103 -0.24803594 -1.3246398  -0.04862496 -0.25800133 -1.4417293\n",
      "  0.02608547 -0.27168834 -1.2943256 ]\n",
      "data: [ 0.00568414 -0.08858857 -0.23594591  0.02708668 -0.2279847  -0.65670484\n",
      " -0.06226032 -0.40786126 -1.4051393  -0.20208333 -0.46989155 -1.6989813\n",
      " -0.36750725 -0.57930267 -2.1756296  -0.1935039  -0.6918194  -1.5617558\n",
      "  0.0149745  -0.719343   -1.3706613  -0.03245257 -0.6554198  -1.4275925\n",
      " -0.03641355 -0.78672576 -1.5437948  -0.15420489 -0.58839476 -1.4798814\n",
      " -0.07327312 -0.64031243 -1.4541439  -0.08784895 -0.61454046 -1.5474602\n",
      "  0.04346867 -0.6337117  -1.5950456  -0.06997847 -0.5055869  -1.3102418\n",
      " -0.17821549 -0.2789694  -1.9375938  -0.03078853 -0.42823297 -1.9379508\n",
      "  0.12104359 -0.39785472 -1.4496744  -0.16768987 -0.27090073 -1.246061\n",
      " -0.09451103 -0.24803595 -1.3246398  -0.04862496 -0.25800133 -1.4417293\n",
      "  0.02608547 -0.27168834 -1.2943256   0.19      ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[ 0.0294, -0.0693, -0.2301,  ...,  0.0464, -0.2594, -1.2498],\n",
      "        [ 0.0294, -0.0693, -0.2301,  ...,  0.0464, -0.2594, -1.2498],\n",
      "        [ 0.0294, -0.0693, -0.2301,  ...,  0.0464, -0.2594, -1.2498],\n",
      "        ...,\n",
      "        [-0.1352,  0.3906, -0.1465,  ..., -0.7293,  0.8910, -0.4097],\n",
      "        [-0.1420, -0.1668,  0.5806,  ..., -0.2436,  0.6062,  0.2322],\n",
      "        [-0.1420, -0.1668,  0.5806,  ..., -0.2436,  0.6062,  0.2322]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02938665 -0.06927525 -0.23013915  0.05357434 -0.18804555 -0.607044\n",
      " -0.0640386  -0.3907786  -1.3932365  -0.20841219 -0.45499748 -1.6820849\n",
      " -0.36351842 -0.549121   -2.171799   -0.16020803 -0.6925251  -1.54549\n",
      "  0.01063946 -0.74131995 -1.3874277  -0.03959849 -0.6697106  -1.4459944\n",
      " -0.04561781 -0.8266799  -1.5651968  -0.12134619 -0.6016968  -1.4559704\n",
      " -0.06166451 -0.6503561  -1.426917   -0.08157521 -0.6221718  -1.5144693\n",
      "  0.05159412 -0.64442396 -1.5404295  -0.04536697 -0.5020546  -1.2950352\n",
      " -0.17873527 -0.27298957 -2.0009127  -0.015772   -0.43052006 -2.0190442\n",
      "  0.1434416  -0.39915    -1.4064761  -0.14858724 -0.27468848 -1.2219706\n",
      " -0.08742175 -0.24769586 -1.31113    -0.05260602 -0.2459687  -1.4263986\n",
      "  0.04635625 -0.2594483  -1.2498344 ]\n",
      "data: [ 0.02938665 -0.06927525 -0.23013917  0.05357434 -0.18804555 -0.607044\n",
      " -0.0640386  -0.39077863 -1.3932365  -0.20841219 -0.45499748 -1.6820849\n",
      " -0.36351842 -0.549121   -2.171799   -0.16020803 -0.6925251  -1.5454899\n",
      "  0.01063946 -0.74131995 -1.3874277  -0.03959849 -0.6697105  -1.4459944\n",
      " -0.04561781 -0.82667994 -1.5651966  -0.12134619 -0.6016968  -1.4559704\n",
      " -0.06166451 -0.6503561  -1.426917   -0.08157521 -0.6221718  -1.5144693\n",
      "  0.05159412 -0.64442396 -1.5404296  -0.04536697 -0.5020546  -1.2950352\n",
      " -0.17873527 -0.27298957 -2.0009127  -0.015772   -0.43052006 -2.0190442\n",
      "  0.1434416  -0.39915    -1.4064761  -0.14858724 -0.27468848 -1.2219706\n",
      " -0.08742175 -0.24769586 -1.31113    -0.05260602 -0.2459687  -1.4263986\n",
      "  0.04635625 -0.2594483  -1.2498344   0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[ 0.0171, -0.0174, -0.2292,  ...,  0.0401, -0.2102, -1.2607],\n",
      "        [ 0.0171, -0.0174, -0.2292,  ...,  0.0401, -0.2102, -1.2607],\n",
      "        [ 0.0171, -0.0174, -0.2292,  ...,  0.0401, -0.2102, -1.2607],\n",
      "        ...,\n",
      "        [-0.1845,  0.2965, -0.0777,  ..., -0.8214,  0.7397, -0.2555],\n",
      "        [-0.1385, -0.1582,  0.5493,  ..., -0.1973,  0.6088,  0.2082],\n",
      "        [-0.1385, -0.1582,  0.5493,  ..., -0.1973,  0.6088,  0.2082]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0171468  -0.01736991 -0.22917752  0.02947116 -0.14984067 -0.63332725\n",
      " -0.07441956 -0.34151226 -1.3867683  -0.22118196 -0.40572643 -1.6834462\n",
      " -0.3937736  -0.51333815 -2.1581042  -0.18709925 -0.6344318  -1.5374537\n",
      "  0.00638203 -0.6742419  -1.352134   -0.04383609 -0.60712045 -1.4101381\n",
      " -0.04730592 -0.7542515  -1.527811   -0.14397165 -0.5351474  -1.4500821\n",
      " -0.07279253 -0.5890913  -1.4203639  -0.08814267 -0.565513   -1.515707\n",
      "  0.04846983 -0.58500344 -1.55269    -0.05920677 -0.44498008 -1.2837472\n",
      " -0.17926139 -0.22122796 -1.9460714  -0.02347808 -0.37505108 -1.953327\n",
      "  0.13838166 -0.3467728  -1.4108584  -0.15868115 -0.21216497 -1.2165134\n",
      " -0.09033271 -0.19130832 -1.3028767  -0.04933346 -0.1974168  -1.4194694\n",
      "  0.04006791 -0.2101889  -1.2607293 ]\n",
      "data: [ 0.    0.    0.    0.    0.    0.   -8.46 -0.61  0.1  -8.42 -0.3   0.38\n",
      " -8.44 -0.14  0.72 -8.53 -0.65  0.58 -8.52 -0.31  1.02 -8.48 -0.06  0.95\n",
      "  0.    0.    0.   -8.45 -0.52  0.06 -8.61 -0.14  0.8  -8.82  0.09  1.5\n",
      "  0.    0.    0.   -8.75 -0.47  0.62 -8.81 -0.1   1.07 -8.8   0.15  1.05\n",
      "  0.    0.    0.    0.    0.    0.   -7.6   0.17 -2.81 -7.63  0.31 -2.71\n",
      "  0.    0.    0.    0.  ]\n",
      "mask: [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[-0.2816, -0.0488, -0.1691,  ..., -0.2471, -0.2301, -0.6500],\n",
      "        [-0.2816, -0.0488, -0.1691,  ..., -0.2471, -0.2301, -0.6500],\n",
      "        [-0.2816, -0.0488, -0.1691,  ..., -0.2471, -0.2301, -0.6500],\n",
      "        ...,\n",
      "        [ 0.4689,  0.1797,  0.1205,  ..., -0.8369,  0.3846,  1.1313],\n",
      "        [ 0.4761,  0.1755,  0.1468,  ..., -0.8331,  0.4379,  1.0892],\n",
      "        [ 0.4761,  0.1755,  0.1468,  ..., -0.8331,  0.4379,  1.0892]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.28158638 -0.0488023  -0.16910145 -0.36200875 -0.17189893 -0.58977807\n",
      " -0.39095274 -0.26041842 -0.7993145  -0.41816318 -0.36564514 -0.8408325\n",
      " -0.4198986  -0.42162788 -1.005614   -0.41485903 -0.28842625 -1.0799657\n",
      " -0.23579425 -0.31075013 -0.49964848 -0.28054255 -0.43200815 -0.510266\n",
      " -0.36073685 -0.44608524 -0.61491203 -0.39232093 -0.21030739 -1.0786285\n",
      " -0.40137398 -0.2793372  -1.0371735  -0.41426477 -0.35568026 -1.035018\n",
      " -0.386344   -0.46170193 -1.0029961  -0.38529998 -0.15418561 -0.9845083\n",
      " -0.39196604 -0.18104032 -0.90971226 -0.38979036 -0.24522579 -0.91184944\n",
      " -0.30398172 -0.34240836 -0.82105136 -0.3675751  -0.03947402 -0.8587854\n",
      " -0.31246522 -0.09233785 -0.76397    -0.31390652 -0.13705117 -0.7680932\n",
      " -0.24709597 -0.23008211 -0.6500087 ]\n",
      "init: [-0.28158638 -0.0488023  -0.16910145 -0.36200875 -0.17189893 -0.58977807\n",
      " -0.39095274 -0.26041842 -0.7993145  -0.41816318 -0.36564514 -0.8408325\n",
      " -0.4198986  -0.42162788 -1.005614   -0.41485903 -0.28842625 -1.0799657\n",
      " -0.23579425 -0.31075013 -0.49964848 -0.28054255 -0.43200815 -0.510266\n",
      " -0.36073685 -0.44608524 -0.61491203 -0.39232093 -0.21030739 -1.0786285\n",
      " -0.40137398 -0.2793372  -1.0371735  -0.41426477 -0.35568026 -1.035018\n",
      " -0.386344   -0.46170193 -1.0029961  -0.38529998 -0.15418561 -0.9845083\n",
      " -0.39196604 -0.18104032 -0.90971226 -0.38979036 -0.24522579 -0.91184944\n",
      " -0.30398172 -0.34240836 -0.82105136 -0.3675751  -0.03947402 -0.8587854\n",
      " -0.31246522 -0.09233785 -0.76397    -0.31390652 -0.13705117 -0.7680932\n",
      " -0.24709597 -0.23008211 -0.6500087 ]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [-0.28158638 -0.0488023  -0.16910145 -0.36200875 -0.17189893 -0.58977807\n",
      " -0.3909527  -0.26041842 -0.7993145  -0.41816318 -0.36564514 -0.8408325\n",
      " -0.4198986  -0.42162788 -1.005614   -0.414859   -0.28842625 -1.0799657\n",
      " -0.23579425 -0.31075013 -0.49964848 -0.28054255 -0.43200815 -0.510266\n",
      " -0.36073685 -0.44608524 -0.61491203 -0.39232093 -0.21030739 -1.0786285\n",
      " -0.40137398 -0.2793372  -1.0371735  -0.41426477 -0.3556803  -1.035018\n",
      " -0.386344   -0.46170193 -1.0029961  -0.38529998 -0.15418561 -0.9845083\n",
      " -0.39196604 -0.18104033 -0.9097122  -0.38979036 -0.24522579 -0.91184944\n",
      " -0.30398172 -0.34240836 -0.82105136 -0.3675751  -0.03947402 -0.8587854\n",
      " -0.31246522 -0.09233785 -0.76397    -0.31390652 -0.13705117 -0.7680933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.24709597 -0.23008211 -0.6500087   0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.1319, -0.2304,  0.1002,  ...,  0.2415, -0.3807, -0.9350],\n",
      "        [ 0.1319, -0.2304,  0.1002,  ...,  0.2415, -0.3807, -0.9350],\n",
      "        [ 0.1319, -0.2304,  0.1002,  ...,  0.2415, -0.3807, -0.9350],\n",
      "        ...,\n",
      "        [-0.0282,  0.0057, -0.4391,  ..., -0.3467,  0.8690, -1.0598],\n",
      "        [-0.1855,  0.1991,  0.4314,  ..., -1.0253,  0.7348,  0.2183],\n",
      "        [-0.1855,  0.1991,  0.4314,  ..., -1.0253,  0.7348,  0.2183]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.1318639  -0.2303869   0.10023476  0.17880651 -0.37416744 -0.3468114\n",
      "  0.14634539 -0.5011836  -1.0269408   0.02203929 -0.521203   -1.3388352\n",
      " -0.12351906 -0.665187   -1.8197253  -0.08164009 -0.77383995 -1.180109\n",
      "  0.21407175 -0.73845387 -1.0411699   0.16478896 -0.67560184 -1.0969927\n",
      "  0.18121313 -0.7677082  -1.2208765  -0.03224665 -0.6703857  -1.0992777\n",
      "  0.11265976 -0.7065619  -1.1191392   0.13930449 -0.6510037  -1.205003\n",
      "  0.25780737 -0.7011914  -1.276401    0.10365962 -0.5913057  -0.90933543\n",
      "  0.01557708 -0.33712527 -1.5076783   0.20399016 -0.5052834  -1.4797626\n",
      "  0.34336966 -0.4425589  -1.1323743  -0.00536409 -0.3755792  -0.85421306\n",
      "  0.1346611  -0.3408438  -0.91461223  0.19618735 -0.37667382 -1.0537164\n",
      "  0.2415272  -0.3806727  -0.93498284]\n",
      "data: [ 0.1318639  -0.23038691  0.10023477  0.17880651 -0.37416744 -0.3468114\n",
      "  0.14634539 -0.5011836  -1.0269408   0.02203929 -0.521203   -1.3388352\n",
      " -0.12351906 -0.665187   -1.8197254  -0.08164009 -0.77383995 -1.180109\n",
      "  0.21407175 -0.7384538  -1.0411699   0.16478898 -0.6756018  -1.0969927\n",
      "  0.18121313 -0.7677082  -1.2208765  -0.03224665 -0.6703857  -1.0992777\n",
      "  0.11265976 -0.70656186 -1.1191392   0.13930449 -0.6510037  -1.205003\n",
      "  0.25780737 -0.7011914  -1.276401    0.10365962 -0.5913057  -0.9093354\n",
      "  0.01557708 -0.33712527 -1.5076783   0.20399016 -0.5052834  -1.4797626\n",
      "  0.34336966 -0.44255888 -1.1323743  -0.00536409 -0.37557924 -0.854213\n",
      "  0.1346611  -0.3408438  -0.9146122   0.19618735 -0.37667382 -1.0537164\n",
      "  0.2415272  -0.3806727  -0.93498284  0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0404, -0.0882, -0.1656,  ..., -0.0390, -0.3125, -1.2017],\n",
      "        [ 0.0404, -0.0882, -0.1656,  ..., -0.0390, -0.3125, -1.2017],\n",
      "        [ 0.0404, -0.0882, -0.1656,  ..., -0.0390, -0.3125, -1.2017],\n",
      "        ...,\n",
      "        [-0.3536,  0.3142, -0.3092,  ..., -0.5533,  0.8565, -0.7709],\n",
      "        [-0.2351,  0.0553,  0.4538,  ..., -0.0258,  0.8021,  0.0126],\n",
      "        [-0.2351,  0.0553,  0.4538,  ..., -0.0258,  0.8021,  0.0126]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04043444 -0.08818559 -0.1655556  -0.00940496 -0.24634272 -0.58488333\n",
      " -0.17071691 -0.4665178  -1.3535826  -0.3520116  -0.5553601  -1.64114\n",
      " -0.5846191  -0.64058894 -2.1336603  -0.20067713 -0.73461276 -1.5513\n",
      " -0.14889485 -0.81729454 -1.4135203  -0.18941629 -0.71243703 -1.4818952\n",
      " -0.16330263 -0.9150678  -1.5643425  -0.17030716 -0.61426246 -1.4681392\n",
      " -0.16375771 -0.6716799  -1.3718851  -0.22296324 -0.69595444 -1.4719095\n",
      " -0.06244195 -0.64612144 -1.4722996  -0.11599431 -0.5491049  -1.3249655\n",
      " -0.23585594 -0.34925702 -1.9117243  -0.14222038 -0.4924497  -1.9262285\n",
      "  0.02804362 -0.48233837 -1.3169415  -0.18182054 -0.3116151  -1.2506561\n",
      " -0.19515532 -0.30905378 -1.317559   -0.17171761 -0.2878957  -1.4191027\n",
      " -0.03904781 -0.31254452 -1.2017195 ]\n",
      "data: [ 0.04043444 -0.08818559 -0.1655556  -0.00940496 -0.24634272 -0.58488333\n",
      " -0.17071691 -0.4665178  -1.3535826  -0.3520116  -0.5553601  -1.64114\n",
      " -0.5846191  -0.64058894 -2.1336603  -0.20067713 -0.7346127  -1.5513\n",
      " -0.14889485 -0.81729454 -1.4135203  -0.18941629 -0.71243703 -1.4818951\n",
      " -0.16330263 -0.91506785 -1.5643425  -0.17030716 -0.61426246 -1.4681392\n",
      " -0.16375771 -0.6716799  -1.3718851  -0.22296324 -0.69595444 -1.4719095\n",
      " -0.06244196 -0.64612144 -1.4722995  -0.11599431 -0.5491049  -1.3249655\n",
      " -0.23585594 -0.34925702 -1.9117244  -0.14222038 -0.49244967 -1.9262285\n",
      "  0.02804362 -0.48233837 -1.3169415  -0.18182054 -0.3116151  -1.2506561\n",
      " -0.19515532 -0.30905378 -1.317559   -0.1717176  -0.2878957  -1.4191027\n",
      " -0.03904781 -0.31254452 -1.2017195   0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[-4.6998e-04,  9.8541e-02, -1.6500e-01,  ...,  6.6502e-02,\n",
      "         -1.1896e-01, -1.1011e+00],\n",
      "        [-4.6998e-04,  9.8541e-02, -1.6500e-01,  ...,  6.6502e-02,\n",
      "         -1.1896e-01, -1.1011e+00],\n",
      "        [-4.6998e-04,  9.8541e-02, -1.6500e-01,  ...,  6.6502e-02,\n",
      "         -1.1896e-01, -1.1011e+00],\n",
      "        ...,\n",
      "        [-1.6090e-01,  2.9696e-01, -7.7101e-03,  ..., -9.3079e-01,\n",
      "          8.8677e-01, -3.5259e-01],\n",
      "        [-1.6641e-01, -2.7535e-01,  5.2900e-01,  ..., -3.0949e-01,\n",
      "          3.8612e-01,  2.1143e-01],\n",
      "        [-1.6641e-01, -2.7535e-01,  5.2900e-01,  ..., -3.0949e-01,\n",
      "          3.8612e-01,  2.1143e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-4.69977967e-04  9.85407159e-02 -1.65001303e-01  6.51182607e-03\n",
      "  8.72448087e-04 -4.65353817e-01 -1.56562731e-01 -2.11984575e-01\n",
      " -1.28988194e+00 -3.06411147e-01 -2.79586732e-01 -1.56761098e+00\n",
      " -4.68125820e-01 -3.58485401e-01 -2.05538511e+00 -1.82920128e-01\n",
      " -5.41720748e-01 -1.44247341e+00 -6.07262552e-02 -6.01284921e-01\n",
      " -1.33194852e+00 -9.03936923e-02 -5.15671015e-01 -1.39327097e+00\n",
      " -4.84537035e-02 -6.97652340e-01 -1.51530766e+00 -1.44376308e-01\n",
      " -4.57875371e-01 -1.35094976e+00 -8.73658434e-02 -5.04446328e-01\n",
      " -1.30595160e+00 -8.69422257e-02 -4.77377355e-01 -1.39417434e+00\n",
      "  1.10577956e-01 -4.93685961e-01 -1.41076899e+00 -7.48550519e-02\n",
      " -3.62383842e-01 -1.19140625e+00 -2.13302895e-01 -1.28966749e-01\n",
      " -1.96381402e+00 -1.59293413e-02 -2.89068788e-01 -2.00007653e+00\n",
      "  2.09441572e-01 -2.68140912e-01 -1.27079725e+00 -1.78569883e-01\n",
      " -1.33016527e-01 -1.10173166e+00 -1.27531126e-01 -1.08462438e-01\n",
      " -1.19555140e+00 -8.94266069e-02 -9.06354636e-02 -1.31738997e+00\n",
      "  6.65019527e-02 -1.18960276e-01 -1.10107398e+00]\n",
      "data: [-4.69977967e-04  9.85407159e-02 -1.65001303e-01  6.51182607e-03\n",
      "  8.72448087e-04 -4.65353817e-01 -1.56562731e-01 -2.11984575e-01\n",
      " -1.28988194e+00 -3.06411147e-01 -2.79586732e-01 -1.56761098e+00\n",
      " -4.68125850e-01 -3.58485401e-01 -2.05538511e+00 -1.82920128e-01\n",
      " -5.41720748e-01 -1.44247341e+00 -6.07262552e-02 -6.01284921e-01\n",
      " -1.33194852e+00 -9.03936923e-02 -5.15671015e-01 -1.39327097e+00\n",
      " -4.84537035e-02 -6.97652340e-01 -1.51530766e+00 -1.44376308e-01\n",
      " -4.57875371e-01 -1.35094976e+00 -8.73658434e-02 -5.04446328e-01\n",
      " -1.30595160e+00 -8.69422257e-02 -4.77377355e-01 -1.39417434e+00\n",
      "  1.10577956e-01 -4.93685961e-01 -1.41076899e+00 -7.48550519e-02\n",
      " -3.62383842e-01 -1.19140625e+00 -2.13302895e-01 -1.28966749e-01\n",
      " -1.96381414e+00 -1.59293413e-02 -2.89068788e-01 -2.00007653e+00\n",
      "  2.09441572e-01 -2.68140912e-01 -1.27079725e+00 -1.78569883e-01\n",
      " -1.33016527e-01 -1.10173166e+00 -1.27531126e-01 -1.08462438e-01\n",
      " -1.19555140e+00 -8.94266069e-02 -9.06354636e-02 -1.31738997e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6.65019527e-02 -1.18960276e-01 -1.10107398e+00  3.99999991e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0449, -0.0780, -0.1768,  ...,  0.0860, -0.2435, -1.2960],\n",
      "        [ 0.0449, -0.0780, -0.1768,  ...,  0.0860, -0.2435, -1.2960],\n",
      "        [ 0.0449, -0.0780, -0.1768,  ...,  0.0860, -0.2435, -1.2960],\n",
      "        ...,\n",
      "        [-0.3044,  0.3837, -0.0086,  ..., -0.9048,  0.8060, -0.1288],\n",
      "        [-0.2819,  0.0716,  0.3699,  ..., -0.3789,  0.8282,  0.1045],\n",
      "        [-0.2819,  0.0716,  0.3699,  ..., -0.3789,  0.8282,  0.1045]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04491925 -0.07803901 -0.17680395  0.04724599 -0.24454732 -0.6642203\n",
      "  0.007253   -0.3808941  -1.3073819  -0.13302815 -0.42567867 -1.6111269\n",
      " -0.3152041  -0.5647667  -2.0653884  -0.18280578 -0.6566229  -1.4575593\n",
      "  0.08149973 -0.65212715 -1.2398472   0.02178811 -0.5810133  -1.2938523\n",
      "  0.02492026 -0.67839915 -1.3990304  -0.13195926 -0.5428573  -1.3934603\n",
      " -0.01906124 -0.5844814  -1.3823087  -0.02807032 -0.55256224 -1.4823711\n",
      "  0.07715163 -0.5639212  -1.5413382  -0.01723249 -0.4778277  -1.2291074\n",
      " -0.08378207 -0.24698463 -1.7241089   0.03295127 -0.38188127 -1.6965528\n",
      "  0.16123998 -0.3433109  -1.4277079  -0.1075724  -0.23862782 -1.1861551\n",
      " -0.00521214 -0.21997078 -1.2814205   0.04494075 -0.24512349 -1.4002957\n",
      "  0.08604647 -0.24348076 -1.2960072 ]\n",
      "data: [ 0.04491925 -0.07803901 -0.17680395  0.04724599 -0.24454732 -0.6642203\n",
      "  0.007253   -0.3808941  -1.3073819  -0.13302815 -0.42567867 -1.6111269\n",
      " -0.3152041  -0.5647667  -2.0653884  -0.18280579 -0.65662295 -1.4575593\n",
      "  0.08149973 -0.65212715 -1.2398472   0.02178811 -0.5810133  -1.2938523\n",
      "  0.02492026 -0.67839915 -1.3990304  -0.13195926 -0.5428573  -1.3934603\n",
      " -0.01906124 -0.5844814  -1.3823086  -0.02807032 -0.55256224 -1.4823711\n",
      "  0.07715163 -0.5639212  -1.5413382  -0.01723249 -0.47782767 -1.2291074\n",
      " -0.08378207 -0.24698463 -1.7241089   0.03295127 -0.38188127 -1.6965528\n",
      "  0.16123998 -0.3433109  -1.427708   -0.10757241 -0.23862782 -1.1861551\n",
      " -0.00521214 -0.21997078 -1.2814205   0.04494075 -0.24512348 -1.4002957\n",
      "  0.08604648 -0.24348076 -1.296007    0.05      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0510, -0.0838, -0.3019,  ...,  0.0710, -0.2628, -1.3410],\n",
      "        [ 0.0510, -0.0838, -0.3019,  ...,  0.0710, -0.2628, -1.3410],\n",
      "        [ 0.0510, -0.0838, -0.3019,  ...,  0.0710, -0.2628, -1.3410],\n",
      "        ...,\n",
      "        [-0.1515,  0.4691, -0.0997,  ..., -0.6862,  0.9805, -0.4128],\n",
      "        [-0.1861, -0.0917,  0.5990,  ..., -0.2894,  0.7068,  0.2233],\n",
      "        [-0.1861, -0.0917,  0.5990,  ..., -0.2894,  0.7068,  0.2233]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.05103404 -0.08380418 -0.30193368  0.08089772 -0.21199858 -0.68441975\n",
      " -0.03867421 -0.4133027  -1.4905689  -0.18734647 -0.47819763 -1.7771769\n",
      " -0.34239668 -0.57614017 -2.276234   -0.14830728 -0.6968262  -1.6627011\n",
      "  0.04275323 -0.73992956 -1.474252   -0.00376567 -0.66901064 -1.5283866\n",
      " -0.01159112 -0.81252074 -1.6486404  -0.10933118 -0.5980408  -1.5744762\n",
      " -0.03967734 -0.6506561  -1.5395975  -0.05323449 -0.62013376 -1.6233339\n",
      "  0.08592072 -0.6435907  -1.6564484  -0.02740473 -0.5054305  -1.4045434\n",
      " -0.15445136 -0.26936856 -2.072768    0.00771895 -0.43095773 -2.0828118\n",
      "  0.17242621 -0.3945618  -1.5105653  -0.13360634 -0.27151018 -1.3300269\n",
      " -0.06525558 -0.2412515  -1.4025078  -0.02158034 -0.24692848 -1.5174711\n",
      "  0.07101654 -0.26282603 -1.3409743 ]\n",
      "data: [ 0.05103404 -0.08380418 -0.30193368  0.08089772 -0.21199858 -0.6844198\n",
      " -0.03867421 -0.4133027  -1.4905689  -0.18734647 -0.47819763 -1.7771769\n",
      " -0.34239665 -0.57614017 -2.276234   -0.14830728 -0.6968262  -1.6627011\n",
      "  0.04275323 -0.73992956 -1.474252   -0.00376567 -0.66901064 -1.5283866\n",
      " -0.01159112 -0.81252074 -1.6486404  -0.10933118 -0.5980408  -1.5744764\n",
      " -0.03967734 -0.6506561  -1.5395975  -0.05323449 -0.62013376 -1.6233339\n",
      "  0.08592072 -0.6435907  -1.6564484  -0.02740473 -0.5054305  -1.4045434\n",
      " -0.15445136 -0.26936856 -2.072768    0.00771895 -0.4309577  -2.0828118\n",
      "  0.17242621 -0.3945618  -1.5105653  -0.13360634 -0.27151018 -1.3300269\n",
      " -0.06525558 -0.24125151 -1.4025078  -0.02158034 -0.24692848 -1.517471\n",
      "  0.07101654 -0.26282603 -1.3409743   0.06      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[-0.0089, -0.0991, -0.2427,  ...,  0.0565, -0.2851, -1.3054],\n",
      "        [-0.0089, -0.0991, -0.2427,  ...,  0.0565, -0.2851, -1.3054],\n",
      "        [-0.0089, -0.0991, -0.2427,  ...,  0.0565, -0.2851, -1.3054],\n",
      "        ...,\n",
      "        [-0.0786,  0.4825, -0.1180,  ..., -0.7055,  0.9671, -0.3189],\n",
      "        [-0.1318, -0.0591,  0.5813,  ..., -0.2361,  0.6446,  0.2756],\n",
      "        [-0.1318, -0.0591,  0.5813,  ..., -0.2361,  0.6446,  0.2756]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-8.9161834e-03 -9.9076636e-02 -2.4265632e-01  1.5095931e-02\n",
      " -2.5559777e-01 -6.7174685e-01  4.6350714e-04 -4.0464479e-01\n",
      " -1.3726841e+00 -1.3258477e-01 -4.5167291e-01 -1.7013468e+00\n",
      " -3.0324626e-01 -6.0851091e-01 -2.1638045e+00 -2.2266352e-01\n",
      " -6.6576946e-01 -1.5659418e+00  1.0200712e-01 -6.6310126e-01\n",
      " -1.3402822e+00  2.7866200e-02 -6.1958158e-01 -1.3888507e+00\n",
      "  2.1125406e-02 -7.1698302e-01 -1.5113436e+00 -1.6604748e-01\n",
      " -5.4968643e-01 -1.4735817e+00 -3.6010534e-02 -6.1297029e-01\n",
      " -1.4755629e+00 -3.9905213e-02 -5.8805120e-01 -1.5812194e+00\n",
      "  5.0433740e-02 -6.3538677e-01 -1.6469053e+00 -3.5929359e-02\n",
      " -4.7232956e-01 -1.2781849e+00 -1.3752732e-01 -2.4516389e-01\n",
      " -1.8724041e+00  8.9370310e-03 -4.1428459e-01 -1.8399656e+00\n",
      "  1.3970935e-01 -3.7796116e-01 -1.4766790e+00 -1.5382294e-01\n",
      " -2.3450546e-01 -1.2247902e+00 -1.3567388e-02 -2.2686227e-01\n",
      " -1.2879192e+00  3.4134984e-02 -2.7933446e-01 -1.4042242e+00\n",
      "  5.6518398e-02 -2.8508288e-01 -1.3053516e+00]\n",
      "data: [-8.9161834e-03 -9.9076636e-02 -2.4265632e-01  1.5095931e-02\n",
      " -2.5559777e-01 -6.7174685e-01  4.6350714e-04 -4.0464479e-01\n",
      " -1.3726841e+00 -1.3258477e-01 -4.5167291e-01 -1.7013468e+00\n",
      " -3.0324626e-01 -6.0851091e-01 -2.1638045e+00 -2.2266352e-01\n",
      " -6.6576940e-01 -1.5659418e+00  1.0200712e-01 -6.6310126e-01\n",
      " -1.3402821e+00  2.7866200e-02 -6.1958158e-01 -1.3888507e+00\n",
      "  2.1125408e-02 -7.1698302e-01 -1.5113435e+00 -1.6604748e-01\n",
      " -5.4968643e-01 -1.4735817e+00 -3.6010534e-02 -6.1297029e-01\n",
      " -1.4755629e+00 -3.9905213e-02 -5.8805120e-01 -1.5812194e+00\n",
      "  5.0433740e-02 -6.3538677e-01 -1.6469054e+00 -3.5929359e-02\n",
      " -4.7232956e-01 -1.2781849e+00 -1.3752732e-01 -2.4516387e-01\n",
      " -1.8724042e+00  8.9370310e-03 -4.1428459e-01 -1.8399655e+00\n",
      "  1.3970935e-01 -3.7796116e-01 -1.4766790e+00 -1.5382294e-01\n",
      " -2.3450546e-01 -1.2247902e+00 -1.3567388e-02 -2.2686225e-01\n",
      " -1.2879192e+00  3.4134984e-02 -2.7933446e-01 -1.4042240e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5.6518398e-02 -2.8508288e-01 -1.3053516e+00  7.0000000e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FAC8>\n",
      "tensor([[ 0.0418, -0.1188, -0.2645,  ...,  0.0624, -0.3007, -1.3431],\n",
      "        [ 0.0418, -0.1188, -0.2645,  ...,  0.0624, -0.3007, -1.3431],\n",
      "        [ 0.0418, -0.1188, -0.2645,  ...,  0.0624, -0.3007, -1.3431],\n",
      "        ...,\n",
      "        [-0.1847,  0.4511, -0.1289,  ..., -0.7168,  0.9648, -0.4159],\n",
      "        [-0.1849, -0.1220,  0.6352,  ..., -0.2521,  0.6449,  0.2897],\n",
      "        [-0.1849, -0.1220,  0.6352,  ..., -0.2521,  0.6449,  0.2897]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 4.17801999e-02 -1.18841186e-01 -2.64512271e-01  5.61653785e-02\n",
      " -2.69047052e-01 -7.03698039e-01 -1.98578984e-02 -4.54274893e-01\n",
      " -1.44417644e+00 -1.60279542e-01 -5.16141891e-01 -1.74335504e+00\n",
      " -3.33897710e-01 -6.37135863e-01 -2.20442557e+00 -1.68985754e-01\n",
      " -7.23729551e-01 -1.60918927e+00  6.51101544e-02 -7.53362715e-01\n",
      " -1.39930415e+00  1.46699771e-02 -6.93006992e-01 -1.44911480e+00\n",
      "  1.28940120e-02 -8.17836404e-01 -1.56364298e+00 -1.24130033e-01\n",
      " -6.10297024e-01 -1.52357554e+00 -3.56027558e-02 -6.68171823e-01\n",
      " -1.49668479e+00 -3.98165807e-02 -6.45457506e-01 -1.58925962e+00\n",
      "  8.49436447e-02 -6.68452978e-01 -1.64359736e+00 -2.91736871e-02\n",
      " -5.27997017e-01 -1.35271764e+00 -1.40249789e-01 -3.03778023e-01\n",
      " -1.96283484e+00  8.84733349e-03 -4.59426641e-01 -1.95341587e+00\n",
      "  1.60147548e-01 -4.20041919e-01 -1.49823999e+00 -1.36133075e-01\n",
      " -2.86612988e-01 -1.28775072e+00 -5.00724688e-02 -2.65774906e-01\n",
      " -1.36735439e+00  8.69609416e-04 -2.89280683e-01 -1.48073387e+00\n",
      "  6.23656362e-02 -3.00749660e-01 -1.34310746e+00]\n",
      "data: [ 4.1780200e-02 -1.1884119e-01 -2.6451227e-01  5.6165382e-02\n",
      " -2.6904705e-01 -7.0369804e-01 -1.9857898e-02 -4.5427489e-01\n",
      " -1.4441764e+00 -1.6027954e-01 -5.1614189e-01 -1.7433552e+00\n",
      " -3.3389771e-01 -6.3713586e-01 -2.2044256e+00 -1.6898575e-01\n",
      " -7.2372955e-01 -1.6091893e+00  6.5110154e-02 -7.5336272e-01\n",
      " -1.3993042e+00  1.4669977e-02 -6.9300699e-01 -1.4491148e+00\n",
      "  1.2894012e-02 -8.1783640e-01 -1.5636430e+00 -1.2413003e-01\n",
      " -6.1029702e-01 -1.5235755e+00 -3.5602756e-02 -6.6817182e-01\n",
      " -1.4966847e+00 -3.9816581e-02 -6.4545751e-01 -1.5892596e+00\n",
      "  8.4943645e-02 -6.6845298e-01 -1.6435974e+00 -2.9173687e-02\n",
      " -5.2799702e-01 -1.3527176e+00 -1.4024979e-01 -3.0377802e-01\n",
      " -1.9628348e+00  8.8473335e-03 -4.5942664e-01 -1.9534159e+00\n",
      "  1.6014755e-01 -4.2004192e-01 -1.4982400e+00 -1.3613307e-01\n",
      " -2.8661299e-01 -1.2877507e+00 -5.0072469e-02 -2.6577491e-01\n",
      " -1.3673544e+00  8.6960942e-04 -2.8928068e-01 -1.4807340e+00\n",
      "  6.2365636e-02 -3.0074966e-01 -1.3431075e+00  7.9999998e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63630>\n",
      "tensor([[ 0.0233, -0.1423, -0.2335,  ...,  0.0644, -0.3238, -1.3001],\n",
      "        [ 0.0233, -0.1423, -0.2335,  ...,  0.0644, -0.3238, -1.3001],\n",
      "        [ 0.0233, -0.1423, -0.2335,  ...,  0.0644, -0.3238, -1.3001],\n",
      "        ...,\n",
      "        [-0.1060,  0.4684, -0.1557,  ..., -0.6788,  0.9399, -0.4287],\n",
      "        [-0.1368, -0.0762,  0.6080,  ..., -0.2123,  0.6564,  0.2963],\n",
      "        [-0.1368, -0.0762,  0.6080,  ..., -0.2123,  0.6564,  0.2963]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02328847 -0.14233115 -0.23353784  0.04170341 -0.29083514 -0.64477384\n",
      " -0.02275998 -0.47621903 -1.3832507  -0.16696884 -0.5357582  -1.6947656\n",
      " -0.3416217  -0.6684576  -2.1586952  -0.18971875 -0.74408567 -1.569447\n",
      "  0.06950581 -0.7743348  -1.3703933   0.00908111 -0.7208065  -1.4164302\n",
      "  0.00718683 -0.8469019  -1.5336587  -0.13566393 -0.63064945 -1.4765458\n",
      " -0.03732016 -0.6954237  -1.4579959  -0.03869403 -0.673437   -1.5574901\n",
      "  0.07640131 -0.7109847  -1.6108103  -0.02786327 -0.54077506 -1.2976258\n",
      " -0.14767194 -0.3164076  -1.9357827   0.01157595 -0.48480836 -1.9239635\n",
      "  0.16239107 -0.44523218 -1.4594748  -0.1451122  -0.2987786  -1.2351544\n",
      " -0.03981361 -0.28161287 -1.3132193   0.00939146 -0.31615782 -1.4282908\n",
      "  0.06439696 -0.3238203  -1.3001001 ]\n",
      "data: [ 0.02328847 -0.14233115 -0.23353785  0.04170341 -0.29083514 -0.64477384\n",
      " -0.02275998 -0.47621903 -1.3832507  -0.16696884 -0.5357582  -1.6947656\n",
      " -0.3416217  -0.6684576  -2.1586952  -0.18971877 -0.74408567 -1.569447\n",
      "  0.06950581 -0.7743348  -1.3703933   0.00908111 -0.7208065  -1.4164302\n",
      "  0.00718683 -0.84690183 -1.5336587  -0.13566393 -0.63064945 -1.4765458\n",
      " -0.03732016 -0.6954237  -1.4579959  -0.03869403 -0.67343694 -1.5574901\n",
      "  0.07640131 -0.7109847  -1.6108103  -0.02786327 -0.54077506 -1.2976258\n",
      " -0.14767194 -0.3164076  -1.9357827   0.01157595 -0.48480836 -1.9239637\n",
      "  0.16239107 -0.4452322  -1.4594748  -0.1451122  -0.2987786  -1.2351544\n",
      " -0.03981361 -0.28161287 -1.3132193   0.00939146 -0.31615782 -1.4282908\n",
      "  0.06439696 -0.3238203  -1.3001001   0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FA90>\n",
      "tensor([[ 0.0291, -0.1134, -0.1765,  ...,  0.0643, -0.3142, -1.1620],\n",
      "        [ 0.0291, -0.1134, -0.1765,  ...,  0.0643, -0.3142, -1.1620],\n",
      "        [ 0.0291, -0.1134, -0.1765,  ...,  0.0643, -0.3142, -1.1620],\n",
      "        ...,\n",
      "        [-0.0891,  0.4621, -0.1212,  ..., -0.5568,  0.9766, -0.4609],\n",
      "        [-0.1439, -0.0739,  0.6067,  ..., -0.2362,  0.6465,  0.2659],\n",
      "        [-0.1439, -0.0739,  0.6067,  ..., -0.2362,  0.6465,  0.2659]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02910377 -0.11335324 -0.17653164  0.05939888 -0.21521993 -0.47578412\n",
      " -0.08689307 -0.45018682 -1.328801   -0.24083997 -0.5183469  -1.6137425\n",
      " -0.38492543 -0.60772085 -2.1232882  -0.15850185 -0.75555384 -1.5060815\n",
      "  0.0041668  -0.8295232  -1.3620396  -0.05034915 -0.7516253  -1.4126823\n",
      " -0.05955356 -0.9276444  -1.5357558  -0.11330631 -0.6716521  -1.4043387\n",
      " -0.06267364 -0.72547877 -1.3737702  -0.07637963 -0.6920366  -1.4508778\n",
      "  0.058935   -0.72661984 -1.4596604  -0.03005718 -0.55699086 -1.2469647\n",
      " -0.19272494 -0.32005647 -2.0219092  -0.00502396 -0.49990043 -2.0493004\n",
      "  0.16812672 -0.45780197 -1.3325596  -0.15228245 -0.3318128  -1.1639485\n",
      " -0.0842903  -0.30087775 -1.2556064  -0.05304717 -0.30165422 -1.3659396\n",
      "  0.06425186 -0.31421363 -1.1619902 ]\n",
      "data: [ 0.02910377 -0.11335323 -0.17653164  0.05939888 -0.21521993 -0.47578412\n",
      " -0.08689307 -0.45018682 -1.3288009  -0.24083997 -0.5183469  -1.6137425\n",
      " -0.38492543 -0.60772085 -2.1232882  -0.15850185 -0.75555384 -1.5060813\n",
      "  0.0041668  -0.82952327 -1.3620394  -0.05034915 -0.7516253  -1.4126823\n",
      " -0.05955357 -0.9276444  -1.5357558  -0.11330631 -0.6716521  -1.4043387\n",
      " -0.06267364 -0.72547877 -1.3737702  -0.07637963 -0.69203657 -1.4508778\n",
      "  0.058935   -0.7266199  -1.4596603  -0.03005718 -0.55699086 -1.2469647\n",
      " -0.19272496 -0.32005647 -2.0219092  -0.00502396 -0.49990043 -2.0493004\n",
      "  0.16812672 -0.45780197 -1.3325595  -0.15228245 -0.33181277 -1.1639485\n",
      " -0.0842903  -0.30087775 -1.2556064  -0.05304717 -0.30165422 -1.3659396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.06425186 -0.31421363 -1.1619902   0.1       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0447, -0.0099, -0.2112,  ...,  0.0023, -0.1994, -1.1810],\n",
      "        [-0.0447, -0.0099, -0.2112,  ...,  0.0023, -0.1994, -1.1810],\n",
      "        [-0.0447, -0.0099, -0.2112,  ...,  0.0023, -0.1994, -1.1810],\n",
      "        ...,\n",
      "        [-0.1630,  0.3232,  0.0319,  ..., -0.6999,  0.8846, -0.3683],\n",
      "        [-0.0943, -0.0882,  0.5888,  ..., -0.2202,  0.6221,  0.2271],\n",
      "        [-0.0943, -0.0882,  0.5888,  ..., -0.2202,  0.6221,  0.2271]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.04466238 -0.00991441 -0.21122311 -0.01890791 -0.11908093 -0.501126\n",
      " -0.15346298 -0.3441281  -1.3487312  -0.3097052  -0.40708205 -1.6476009\n",
      " -0.47122014 -0.5098951  -2.1500366  -0.24854417 -0.64459354 -1.5228227\n",
      " -0.04913591 -0.70261925 -1.3478032  -0.10254259 -0.63101    -1.3976724\n",
      " -0.10438426 -0.7934896  -1.5282651  -0.19930679 -0.55144995 -1.416248\n",
      " -0.13011697 -0.6067312  -1.3918399  -0.12824294 -0.570586   -1.4813042\n",
      "  0.02118631 -0.6080713  -1.5060737  -0.1037811  -0.44058526 -1.2452269\n",
      " -0.2627347  -0.20094705 -2.0170534  -0.0629913  -0.3797381  -2.0365658\n",
      "  0.12675755 -0.3372528  -1.3591261  -0.23078512 -0.20797381 -1.165863\n",
      " -0.14787358 -0.18020898 -1.2515088  -0.1096863  -0.1883061  -1.3680953\n",
      "  0.00227641 -0.19939159 -1.1810211 ]\n",
      "data: [-0.04466238 -0.00991441 -0.21122311 -0.01890791 -0.11908093 -0.501126\n",
      " -0.15346298 -0.3441281  -1.3487313  -0.3097052  -0.40708205 -1.6476009\n",
      " -0.47122014 -0.5098951  -2.1500366  -0.24854417 -0.6445935  -1.5228227\n",
      " -0.04913591 -0.70261925 -1.3478032  -0.10254259 -0.63101    -1.3976724\n",
      " -0.10438426 -0.79348963 -1.5282651  -0.19930679 -0.55144995 -1.416248\n",
      " -0.13011697 -0.6067312  -1.3918399  -0.12824294 -0.570586   -1.4813042\n",
      "  0.02118631 -0.6080713  -1.5060737  -0.1037811  -0.44058526 -1.2452269\n",
      " -0.2627347  -0.20094703 -2.0170534  -0.0629913  -0.3797381  -2.0365658\n",
      "  0.12675755 -0.3372528  -1.3591261  -0.23078512 -0.20797381 -1.165863\n",
      " -0.14787358 -0.18020898 -1.2515088  -0.1096863  -0.18830608 -1.3680953\n",
      "  0.00227641 -0.19939159 -1.1810211   0.11      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63EB8>\n",
      "tensor([[-0.0071, -0.0854, -0.1918,  ...,  0.0123, -0.2413, -1.3160],\n",
      "        [-0.0071, -0.0854, -0.1918,  ...,  0.0123, -0.2413, -1.3160],\n",
      "        [-0.0071, -0.0854, -0.1918,  ...,  0.0123, -0.2413, -1.3160],\n",
      "        ...,\n",
      "        [-0.2620,  0.3032, -0.1823,  ..., -0.7650,  0.7891, -0.3902],\n",
      "        [-0.1901, -0.1139,  0.5259,  ..., -0.2995,  0.6235,  0.2653],\n",
      "        [-0.1901, -0.1139,  0.5259,  ..., -0.2995,  0.6235,  0.2653]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.00710196 -0.08544847 -0.19175628  0.00689047 -0.24859251 -0.66455984\n",
      " -0.02927459 -0.3917185  -1.3328781  -0.16832565 -0.44094014 -1.6465324\n",
      " -0.3562644  -0.5791039  -2.0991259  -0.23400325 -0.66077095 -1.4965847\n",
      "  0.05403343 -0.65575945 -1.2659844   0.00606884 -0.6051889  -1.314957\n",
      "  0.00799252 -0.6972367  -1.4308643  -0.18721217 -0.5403768  -1.4200785\n",
      " -0.06654487 -0.5965224  -1.4145501  -0.05805758 -0.5664909  -1.526382\n",
      "  0.06942295 -0.5923652  -1.6097248  -0.07891139 -0.4711054  -1.240496\n",
      " -0.16029449 -0.24344303 -1.7734765  -0.0192635  -0.3850494  -1.7481052\n",
      "  0.12775147 -0.3499766  -1.4605434  -0.18464401 -0.2221608  -1.1924318\n",
      " -0.07989353 -0.20267934 -1.2714406  -0.02071533 -0.2367297  -1.3956954\n",
      "  0.01226703 -0.24125206 -1.3159512 ]\n",
      "data: [-0.00710196 -0.08544847 -0.1917563   0.00689047 -0.24859251 -0.66455984\n",
      " -0.02927459 -0.3917185  -1.3328781  -0.16832565 -0.44094014 -1.6465324\n",
      " -0.3562644  -0.5791039  -2.0991259  -0.23400325 -0.66077095 -1.4965847\n",
      "  0.05403343 -0.65575945 -1.2659844   0.00606884 -0.6051889  -1.314957\n",
      "  0.00799252 -0.6972367  -1.4308642  -0.18721217 -0.5403768  -1.4200786\n",
      " -0.06654487 -0.5965224  -1.4145501  -0.05805758 -0.5664909  -1.526382\n",
      "  0.06942295 -0.5923652  -1.6097248  -0.07891139 -0.4711054  -1.240496\n",
      " -0.16029449 -0.24344303 -1.7734764  -0.0192635  -0.3850494  -1.7481052\n",
      "  0.12775147 -0.34997663 -1.4605434  -0.18464401 -0.2221608  -1.1924318\n",
      " -0.07989353 -0.20267934 -1.2714406  -0.02071533 -0.2367297  -1.3956954\n",
      "  0.01226703 -0.24125206 -1.3159512   0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FC50>\n",
      "tensor([[ 0.0348, -0.1272, -0.2980,  ...,  0.0456, -0.2974, -1.3525],\n",
      "        [ 0.0348, -0.1272, -0.2980,  ...,  0.0456, -0.2974, -1.3525],\n",
      "        [ 0.0348, -0.1272, -0.2980,  ...,  0.0456, -0.2974, -1.3525],\n",
      "        ...,\n",
      "        [-0.1554,  0.4809, -0.1023,  ..., -0.7234,  1.0083, -0.4150],\n",
      "        [-0.1839, -0.0729,  0.6280,  ..., -0.2774,  0.7054,  0.2781],\n",
      "        [-0.1839, -0.0729,  0.6280,  ..., -0.2774,  0.7054,  0.2781]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03479575 -0.12716934 -0.2980082   0.06816307 -0.24769329 -0.6868527\n",
      " -0.04168709 -0.44789168 -1.4854026  -0.18676606 -0.50911796 -1.7798524\n",
      " -0.33176348 -0.6062664  -2.2837603  -0.16396332 -0.7378944  -1.655648\n",
      "  0.0329927  -0.7797581  -1.4808252  -0.0190076  -0.71329165 -1.535991\n",
      " -0.03463219 -0.858744   -1.6609514  -0.12417128 -0.64434814 -1.5632508\n",
      " -0.05580775 -0.6949662  -1.5411422  -0.07134379 -0.6605401  -1.6293509\n",
      "  0.05624149 -0.6927711  -1.6642585  -0.0411061  -0.54218066 -1.3958988\n",
      " -0.17495298 -0.30594853 -2.0829067  -0.00986494 -0.46749887 -2.0973337\n",
      "  0.14547694 -0.4308587  -1.5231369  -0.15175262 -0.311927   -1.32079\n",
      " -0.07814237 -0.27901924 -1.3989279  -0.03971011 -0.2858339  -1.5156388\n",
      "  0.04561578 -0.2973566  -1.35253   ]\n",
      "data: [ 0.03479575 -0.12716934 -0.2980082   0.06816307 -0.24769329 -0.6868527\n",
      " -0.04168709 -0.44789168 -1.4854026  -0.18676606 -0.50911796 -1.7798524\n",
      " -0.33176345 -0.6062664  -2.2837603  -0.16396332 -0.7378944  -1.655648\n",
      "  0.0329927  -0.7797581  -1.4808252  -0.0190076  -0.71329165 -1.535991\n",
      " -0.03463219 -0.858744   -1.6609514  -0.12417128 -0.64434814 -1.5632508\n",
      " -0.05580775 -0.6949662  -1.5411422  -0.07134379 -0.6605401  -1.6293509\n",
      "  0.05624149 -0.6927711  -1.6642585  -0.0411061  -0.54218066 -1.3958987\n",
      " -0.17495298 -0.30594853 -2.0829067  -0.00986494 -0.46749887 -2.0973337\n",
      "  0.14547694 -0.4308587  -1.5231369  -0.15175262 -0.311927   -1.32079\n",
      " -0.07814237 -0.27901924 -1.3989279  -0.03971011 -0.2858339  -1.5156388\n",
      "  0.04561578 -0.2973566  -1.35253     0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0068, -0.0981, -0.2198,  ...,  0.0444, -0.2776, -1.3065],\n",
      "        [ 0.0068, -0.0981, -0.2198,  ...,  0.0444, -0.2776, -1.3065],\n",
      "        [ 0.0068, -0.0981, -0.2198,  ...,  0.0444, -0.2776, -1.3065],\n",
      "        ...,\n",
      "        [-0.1340,  0.4523, -0.1283,  ..., -0.8093,  0.9405, -0.3509],\n",
      "        [-0.1165, -0.0782,  0.5533,  ..., -0.1983,  0.6356,  0.2372],\n",
      "        [-0.1165, -0.0782,  0.5533,  ..., -0.1983,  0.6356,  0.2372]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 6.8180235e-03 -9.8123841e-02 -2.1978985e-01  1.6795430e-02\n",
      " -2.5753403e-01 -6.7051750e-01 -8.4934160e-03 -4.1815364e-01\n",
      " -1.3703275e+00 -1.4733003e-01 -4.7023582e-01 -1.7014606e+00\n",
      " -3.3831617e-01 -6.1956018e-01 -2.1516662e+00 -2.1743491e-01\n",
      " -6.7795700e-01 -1.5586362e+00  8.5143089e-02 -6.8759763e-01\n",
      " -1.3398592e+00  2.0501986e-02 -6.4455611e-01 -1.3863173e+00\n",
      "  2.4438471e-02 -7.5300252e-01 -1.5050209e+00 -1.6035941e-01\n",
      " -5.5530649e-01 -1.4619217e+00 -4.2370424e-02 -6.2247169e-01\n",
      " -1.4522295e+00 -3.9060436e-02 -6.0676759e-01 -1.5671775e+00\n",
      "  6.8648905e-02 -6.4543301e-01 -1.6395242e+00 -4.2191707e-02\n",
      " -4.7692567e-01 -1.2707615e+00 -1.4805509e-01 -2.5797176e-01\n",
      " -1.8669505e+00  9.6100569e-04 -4.2129111e-01 -1.8404675e+00\n",
      "  1.4539075e-01 -3.8713688e-01 -1.4662571e+00 -1.5994033e-01\n",
      " -2.3028283e-01 -1.2136528e+00 -3.7574723e-02 -2.2289427e-01\n",
      " -1.2840316e+00  1.4714792e-02 -2.7177471e-01 -1.4005921e+00\n",
      "  4.4389077e-02 -2.7758071e-01 -1.3064964e+00]\n",
      "data: [ 6.8180235e-03 -9.8123834e-02 -2.1978985e-01  1.6795430e-02\n",
      " -2.5753403e-01 -6.7051750e-01 -8.4934160e-03 -4.1815364e-01\n",
      " -1.3703275e+00 -1.4733003e-01 -4.7023582e-01 -1.7014606e+00\n",
      " -3.3831614e-01 -6.1956018e-01 -2.1516662e+00 -2.1743493e-01\n",
      " -6.7795700e-01 -1.5586362e+00  8.5143089e-02 -6.8759763e-01\n",
      " -1.3398594e+00  2.0501986e-02 -6.4455611e-01 -1.3863173e+00\n",
      "  2.4438472e-02 -7.5300252e-01 -1.5050209e+00 -1.6035943e-01\n",
      " -5.5530649e-01 -1.4619217e+00 -4.2370424e-02 -6.2247169e-01\n",
      " -1.4522295e+00 -3.9060436e-02 -6.0676759e-01 -1.5671775e+00\n",
      "  6.8648905e-02 -6.4543307e-01 -1.6395242e+00 -4.2191707e-02\n",
      " -4.7692567e-01 -1.2707615e+00 -1.4805509e-01 -2.5797176e-01\n",
      " -1.8669505e+00  9.6100569e-04 -4.2129111e-01 -1.8404676e+00\n",
      "  1.4539075e-01 -3.8713688e-01 -1.4662570e+00 -1.5994033e-01\n",
      " -2.3028283e-01 -1.2136528e+00 -3.7574723e-02 -2.2289427e-01\n",
      " -1.2840316e+00  1.4714791e-02 -2.7177471e-01 -1.4005921e+00\n",
      "  4.4389077e-02 -2.7758071e-01 -1.3064964e+00  1.4000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0288, -0.0976, -0.2605,  ...,  0.0463, -0.2823, -1.3142],\n",
      "        [ 0.0288, -0.0976, -0.2605,  ...,  0.0463, -0.2823, -1.3142],\n",
      "        [ 0.0288, -0.0976, -0.2605,  ...,  0.0463, -0.2823, -1.3142],\n",
      "        ...,\n",
      "        [-0.1758,  0.4528, -0.1444,  ..., -0.7083,  0.9520, -0.4326],\n",
      "        [-0.1791, -0.1274,  0.6284,  ..., -0.2488,  0.6463,  0.2859],\n",
      "        [-0.1791, -0.1274,  0.6284,  ..., -0.2488,  0.6463,  0.2859]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02881786 -0.09755558 -0.2605119   0.04628595 -0.23547585 -0.67168856\n",
      " -0.05501786 -0.43342078 -1.4390726  -0.19891363 -0.49899018 -1.7301688\n",
      " -0.3622626  -0.60667384 -2.2061715  -0.17418915 -0.7150379  -1.5982358\n",
      "  0.02568904 -0.7566886  -1.4067383  -0.02515845 -0.68909484 -1.4604459\n",
      " -0.03131668 -0.8296802  -1.5768359  -0.13247122 -0.6112688  -1.512181\n",
      " -0.06033859 -0.6648136  -1.4809844  -0.07370999 -0.63875026 -1.568189\n",
      "  0.05492058 -0.6598557  -1.6060262  -0.04649133 -0.5200242  -1.3479186\n",
      " -0.16794789 -0.2930768  -1.9955894  -0.01488914 -0.4491341  -1.999625\n",
      "  0.14062056 -0.4124893  -1.4696878  -0.15081161 -0.28434992 -1.2780819\n",
      " -0.07826245 -0.25952646 -1.3624914  -0.03531438 -0.26972023 -1.4754897\n",
      "  0.04625187 -0.28229505 -1.3141934 ]\n",
      "data: [ 0.02881786 -0.09755558 -0.2605119   0.04628595 -0.23547584 -0.67168856\n",
      " -0.05501786 -0.43342078 -1.4390726  -0.19891363 -0.49899018 -1.7301688\n",
      " -0.3622626  -0.60667384 -2.2061715  -0.17418915 -0.71503794 -1.5982357\n",
      "  0.02568903 -0.7566886  -1.4067383  -0.02515845 -0.68909484 -1.4604459\n",
      " -0.03131668 -0.8296802  -1.576836   -0.13247122 -0.6112688  -1.512181\n",
      " -0.06033859 -0.66481364 -1.4809844  -0.07370999 -0.63875026 -1.5681891\n",
      "  0.05492058 -0.6598557  -1.6060262  -0.04649133 -0.5200242  -1.3479187\n",
      " -0.16794789 -0.2930768  -1.9955895  -0.01488914 -0.4491341  -1.999625\n",
      "  0.14062056 -0.4124893  -1.4696878  -0.15081161 -0.28434992 -1.2780819\n",
      " -0.07826245 -0.25952646 -1.3624913  -0.03531438 -0.26972023 -1.4754899\n",
      "  0.04625187 -0.28229505 -1.3141934   0.15      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[ 3.1886e-04, -4.8311e-02, -2.1638e-01,  ...,  3.8449e-02,\n",
      "         -2.3808e-01, -1.2554e+00],\n",
      "        [ 3.1886e-04, -4.8311e-02, -2.1638e-01,  ...,  3.8449e-02,\n",
      "         -2.3808e-01, -1.2554e+00],\n",
      "        [ 3.1886e-04, -4.8311e-02, -2.1638e-01,  ...,  3.8449e-02,\n",
      "         -2.3808e-01, -1.2554e+00],\n",
      "        ...,\n",
      "        [-1.2968e-01,  3.9781e-01, -1.3685e-01,  ..., -7.5204e-01,\n",
      "          8.7439e-01, -3.7451e-01],\n",
      "        [-1.3274e-01, -1.4971e-01,  5.7057e-01,  ..., -2.2266e-01,\n",
      "          5.7863e-01,  2.5948e-01],\n",
      "        [-1.3274e-01, -1.4971e-01,  5.7057e-01,  ..., -2.2266e-01,\n",
      "          5.7863e-01,  2.5948e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 3.1885970e-04 -4.8311271e-02 -2.1637717e-01  1.7045598e-02\n",
      " -1.8425995e-01 -6.0566938e-01 -6.4464368e-02 -3.6973351e-01\n",
      " -1.3490306e+00 -2.0923923e-01 -4.2810249e-01 -1.6551596e+00\n",
      " -3.7990928e-01 -5.4835325e-01 -2.1275864e+00 -2.0586888e-01\n",
      " -6.5534592e-01 -1.5241964e+00  2.3285031e-02 -6.8885499e-01\n",
      " -1.3431900e+00 -3.3422902e-02 -6.2934637e-01 -1.3951894e+00\n",
      " -3.3196367e-02 -7.6717335e-01 -1.5133837e+00 -1.5590288e-01\n",
      " -5.5117172e-01 -1.4334040e+00 -6.9122016e-02 -6.0971731e-01\n",
      " -1.4152445e+00 -7.5942419e-02 -5.8684754e-01 -1.5140942e+00\n",
      "  4.8336819e-02 -6.1884469e-01 -1.5581280e+00 -5.6946628e-02\n",
      " -4.5946640e-01 -1.2608051e+00 -1.7892669e-01 -2.3533897e-01\n",
      " -1.9216877e+00 -1.8025234e-02 -3.9926338e-01 -1.9203882e+00\n",
      "  1.3794176e-01 -3.6548972e-01 -1.4116827e+00 -1.6729531e-01\n",
      " -2.2471626e-01 -1.1974972e+00 -7.6779932e-02 -2.0679168e-01\n",
      " -1.2798890e+00 -3.4347400e-02 -2.2778177e-01 -1.3971599e+00\n",
      "  3.8449265e-02 -2.3808324e-01 -1.2554359e+00]\n",
      "data: [ 3.1885970e-04 -4.8311271e-02 -2.1637717e-01  1.7045598e-02\n",
      " -1.8425995e-01 -6.0566938e-01 -6.4464368e-02 -3.6973351e-01\n",
      " -1.3490306e+00 -2.0923923e-01 -4.2810249e-01 -1.6551596e+00\n",
      " -3.7990928e-01 -5.4835325e-01 -2.1275864e+00 -2.0586890e-01\n",
      " -6.5534592e-01 -1.5241963e+00  2.3285031e-02 -6.8885499e-01\n",
      " -1.3431900e+00 -3.3422902e-02 -6.2934637e-01 -1.3951894e+00\n",
      " -3.3196367e-02 -7.6717341e-01 -1.5133837e+00 -1.5590288e-01\n",
      " -5.5117172e-01 -1.4334040e+00 -6.9122016e-02 -6.0971731e-01\n",
      " -1.4152445e+00 -7.5942419e-02 -5.8684754e-01 -1.5140942e+00\n",
      "  4.8336819e-02 -6.1884469e-01 -1.5581280e+00 -5.6946624e-02\n",
      " -4.5946640e-01 -1.2608051e+00 -1.7892669e-01 -2.3533897e-01\n",
      " -1.9216877e+00 -1.8025234e-02 -3.9926338e-01 -1.9203882e+00\n",
      "  1.3794176e-01 -3.6548972e-01 -1.4116827e+00 -1.6729531e-01\n",
      " -2.2471626e-01 -1.1974972e+00 -7.6779932e-02 -2.0679168e-01\n",
      " -1.2798890e+00 -3.4347400e-02 -2.2778177e-01 -1.3971599e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3.8449265e-02 -2.3808324e-01 -1.2554359e+00  1.6000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0172, -0.0667, -0.2470,  ...,  0.0199, -0.2493, -1.2865],\n",
      "        [ 0.0172, -0.0667, -0.2470,  ...,  0.0199, -0.2493, -1.2865],\n",
      "        [ 0.0172, -0.0667, -0.2470,  ...,  0.0199, -0.2493, -1.2865],\n",
      "        ...,\n",
      "        [-0.3572,  0.1935, -0.3323,  ..., -0.8209,  0.6218, -0.5109],\n",
      "        [-0.1114, -0.0612,  0.6160,  ..., -0.2128,  0.7280,  0.2779],\n",
      "        [-0.1114, -0.0612,  0.6160,  ..., -0.2128,  0.7280,  0.2779]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01717216 -0.06672306 -0.24698877  0.04282324 -0.1920174  -0.6456078\n",
      " -0.07636719 -0.3884147  -1.4292643  -0.22077706 -0.4549068  -1.7139211\n",
      " -0.3764491  -0.54615116 -2.206637   -0.17550704 -0.68470454 -1.5776258\n",
      " -0.00711485 -0.7276391  -1.4007967  -0.05455852 -0.6568361  -1.4607122\n",
      " -0.06699421 -0.80667007 -1.5790746  -0.14117235 -0.5915387  -1.4941926\n",
      " -0.08148327 -0.6397402  -1.4594116  -0.1074842  -0.61080533 -1.5470643\n",
      "  0.02747693 -0.62840056 -1.5772064  -0.07023528 -0.49758807 -1.3324556\n",
      " -0.19439891 -0.2682377  -2.007444   -0.04226754 -0.41843295 -2.0239167\n",
      "  0.11255118 -0.39052886 -1.4409914  -0.16627085 -0.26783958 -1.2609932\n",
      " -0.11223782 -0.2394356  -1.3436275  -0.0752892  -0.23444788 -1.4602132\n",
      "  0.01986508 -0.24927376 -1.2865    ]\n",
      "data: [ 0.01717216 -0.06672306 -0.24698877  0.04282324 -0.1920174  -0.6456078\n",
      " -0.07636719 -0.38841474 -1.4292644  -0.22077708 -0.45490682 -1.7139211\n",
      " -0.37644914 -0.54615116 -2.206637   -0.17550702 -0.68470454 -1.5776258\n",
      " -0.00711485 -0.7276391  -1.4007967  -0.05455853 -0.6568361  -1.4607121\n",
      " -0.06699421 -0.80667007 -1.5790745  -0.14117235 -0.5915387  -1.4941926\n",
      " -0.08148327 -0.6397402  -1.4594116  -0.1074842  -0.61080533 -1.5470643\n",
      "  0.02747693 -0.62840056 -1.5772064  -0.07023528 -0.49758807 -1.3324556\n",
      " -0.19439892 -0.2682377  -2.007444   -0.04226754 -0.41843295 -2.0239167\n",
      "  0.11255118 -0.39052886 -1.4409914  -0.16627085 -0.26783958 -1.2609932\n",
      " -0.11223782 -0.2394356  -1.3436275  -0.0752892  -0.23444788 -1.4602132\n",
      "  0.01986508 -0.24927376 -1.2865      0.17      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0363, -0.0199, -0.2101,  ...,  0.0521, -0.2156, -1.2395],\n",
      "        [ 0.0363, -0.0199, -0.2101,  ...,  0.0521, -0.2156, -1.2395],\n",
      "        [ 0.0363, -0.0199, -0.2101,  ...,  0.0521, -0.2156, -1.2395],\n",
      "        ...,\n",
      "        [-0.2047,  0.3285, -0.1399,  ..., -0.8833,  0.7973, -0.3254],\n",
      "        [-0.1438, -0.2110,  0.5418,  ..., -0.2173,  0.5558,  0.2194],\n",
      "        [-0.1438, -0.2110,  0.5418,  ..., -0.2173,  0.5558,  0.2194]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03627275 -0.01990418 -0.21006435  0.04883624 -0.15114179 -0.60978734\n",
      " -0.0617114  -0.33568987 -1.3536876  -0.20773649 -0.39943114 -1.6418747\n",
      " -0.3764325  -0.49675244 -2.122766   -0.1581668  -0.6394461  -1.5032092\n",
      "  0.00865642 -0.6766433  -1.3424815  -0.03602809 -0.6041948  -1.405287\n",
      " -0.03070365 -0.7525334  -1.5182843  -0.12113331 -0.54306084 -1.4246709\n",
      " -0.05536785 -0.58983827 -1.3913026  -0.07584118 -0.5668515  -1.4852614\n",
      "  0.06617888 -0.57652396 -1.5168452  -0.04645373 -0.45559487 -1.2639717\n",
      " -0.15718678 -0.2336781  -1.910546   -0.01023859 -0.37782133 -1.922479\n",
      "  0.1508441  -0.3538342  -1.3833165  -0.13686523 -0.22612381 -1.2003347\n",
      " -0.08230048 -0.20452516 -1.2867551  -0.04548328 -0.19981205 -1.4047902\n",
      "  0.052093   -0.21562843 -1.2395489 ]\n",
      "data: [ 0.03627275 -0.01990418 -0.21006435  0.04883624 -0.15114179 -0.60978734\n",
      " -0.0617114  -0.3356899  -1.3536876  -0.20773649 -0.39943114 -1.6418747\n",
      " -0.3764325  -0.49675244 -2.122766   -0.1581668  -0.6394461  -1.5032092\n",
      "  0.00865642 -0.6766433  -1.3424815  -0.03602809 -0.6041948  -1.405287\n",
      " -0.03070365 -0.7525333  -1.5182843  -0.12113331 -0.54306084 -1.4246708\n",
      " -0.05536785 -0.58983827 -1.3913026  -0.07584118 -0.5668515  -1.4852614\n",
      "  0.06617888 -0.57652396 -1.5168452  -0.04645373 -0.45559487 -1.2639717\n",
      " -0.15718678 -0.23367809 -1.910546   -0.01023859 -0.37782133 -1.9224792\n",
      "  0.1508441  -0.35383424 -1.3833165  -0.13686523 -0.22612381 -1.2003347\n",
      " -0.08230047 -0.20452517 -1.2867551  -0.04548328 -0.19981205 -1.4047902\n",
      "  0.052093   -0.21562843 -1.2395489   0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0109, -0.0659, -0.2377,  ...,  0.0323, -0.2474, -1.2868],\n",
      "        [ 0.0109, -0.0659, -0.2377,  ...,  0.0323, -0.2474, -1.2868],\n",
      "        [ 0.0109, -0.0659, -0.2377,  ...,  0.0323, -0.2474, -1.2868],\n",
      "        ...,\n",
      "        [-0.3327,  0.2297, -0.2980,  ..., -0.8713,  0.6586, -0.4468],\n",
      "        [-0.1220, -0.0559,  0.5827,  ..., -0.2404,  0.7425,  0.2450],\n",
      "        [-0.1220, -0.0559,  0.5827,  ..., -0.2404,  0.7425,  0.2450]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01090908 -0.06592315 -0.23774406  0.03691807 -0.20456097 -0.6542568\n",
      " -0.05912696 -0.3860446  -1.4130268  -0.19941014 -0.4497704  -1.7023133\n",
      " -0.36018163 -0.5565107  -2.1846428  -0.18621841 -0.6688101  -1.5673097\n",
      "  0.01791365 -0.6967647  -1.3727038  -0.02880234 -0.63182473 -1.4292709\n",
      " -0.0360641  -0.7629993  -1.5456527  -0.14871919 -0.56717    -1.4867613\n",
      " -0.0682091  -0.61935854 -1.4559184  -0.08611922 -0.5909852  -1.5459585\n",
      "  0.04674046 -0.6110302  -1.5904617  -0.0663797  -0.4841186  -1.316765\n",
      " -0.1747534  -0.25489062 -1.9458338  -0.02671438 -0.405032   -1.9476631\n",
      "  0.12519515 -0.37572947 -1.4452381  -0.16271287 -0.24987616 -1.2511406\n",
      " -0.09127849 -0.22533754 -1.3240632  -0.04527774 -0.23294008 -1.441414\n",
      "  0.03225398 -0.24743976 -1.2868003 ]\n",
      "data: [ 0.01090908 -0.06592315 -0.23774406  0.03691807 -0.20456097 -0.6542568\n",
      " -0.05912696 -0.3860446  -1.4130267  -0.19941014 -0.4497704  -1.7023132\n",
      " -0.36018163 -0.5565107  -2.1846428  -0.18621841 -0.6688101  -1.5673097\n",
      "  0.01791365 -0.6967647  -1.3727039  -0.02880234 -0.63182473 -1.429271\n",
      " -0.0360641  -0.7629993  -1.5456527  -0.14871919 -0.56717    -1.4867613\n",
      " -0.0682091  -0.61935854 -1.4559184  -0.08611922 -0.5909852  -1.5459585\n",
      "  0.04674046 -0.6110302  -1.5904617  -0.0663797  -0.4841186  -1.316765\n",
      " -0.1747534  -0.25489062 -1.9458337  -0.02671438 -0.405032   -1.9476631\n",
      "  0.12519515 -0.37572947 -1.445238   -0.16271287 -0.24987616 -1.2511406\n",
      " -0.09127849 -0.22533755 -1.3240631  -0.04527774 -0.23294008 -1.441414\n",
      "  0.03225398 -0.24743977 -1.2868003   0.19      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B320>\n",
      "tensor([[ 0.0167, -0.0719, -0.2385,  ...,  0.0548, -0.2576, -1.2927],\n",
      "        [ 0.0167, -0.0719, -0.2385,  ...,  0.0548, -0.2576, -1.2927],\n",
      "        [ 0.0167, -0.0719, -0.2385,  ...,  0.0548, -0.2576, -1.2927],\n",
      "        ...,\n",
      "        [-0.1714,  0.3802, -0.1756,  ..., -0.8114,  0.8724, -0.3900],\n",
      "        [-0.1454, -0.1637,  0.5690,  ..., -0.2468,  0.6062,  0.2353],\n",
      "        [-0.1454, -0.1637,  0.5690,  ..., -0.2468,  0.6062,  0.2353]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.6667534e-02 -7.1930282e-02 -2.3846328e-01  3.4477551e-02\n",
      " -2.1622261e-01 -6.5814352e-01 -4.1843377e-02 -3.9561301e-01\n",
      " -1.3942775e+00 -1.8044338e-01 -4.5627028e-01 -1.6940213e+00\n",
      " -3.5114777e-01 -5.7800204e-01 -2.1580336e+00 -1.8712647e-01\n",
      " -6.7387122e-01 -1.5549089e+00  4.4343442e-02 -7.0012474e-01\n",
      " -1.3626275e+00 -6.6201240e-03 -6.4046162e-01 -1.4147683e+00\n",
      " -3.9515793e-03 -7.6750702e-01 -1.5303699e+00 -1.4107139e-01\n",
      " -5.6566453e-01 -1.4696307e+00 -4.9788103e-02 -6.2203598e-01\n",
      " -1.4477836e+00 -5.4930747e-02 -5.9790117e-01 -1.5429060e+00\n",
      "  7.3002607e-02 -6.2355167e-01 -1.5954995e+00 -4.6468250e-02\n",
      " -4.8340148e-01 -1.2965751e+00 -1.5571813e-01 -2.5720042e-01\n",
      " -1.9259683e+00 -1.1917949e-03 -4.1298491e-01 -1.9195025e+00\n",
      "  1.5275852e-01 -3.7931705e-01 -1.4486051e+00 -1.5100384e-01\n",
      " -2.4503931e-01 -1.2336488e+00 -6.2211707e-02 -2.2571073e-01\n",
      " -1.3143731e+00 -1.2451872e-02 -2.4583481e-01 -1.4308788e+00\n",
      "  5.4836191e-02 -2.5762028e-01 -1.2927065e+00]\n",
      "data: [ 1.6667534e-02 -7.1930282e-02 -2.3846328e-01  3.4477551e-02\n",
      " -2.1622261e-01 -6.5814352e-01 -4.1843377e-02 -3.9561301e-01\n",
      " -1.3942775e+00 -1.8044338e-01 -4.5627031e-01 -1.6940213e+00\n",
      " -3.5114777e-01 -5.7800204e-01 -2.1580336e+00 -1.8712646e-01\n",
      " -6.7387122e-01 -1.5549089e+00  4.4343442e-02 -7.0012474e-01\n",
      " -1.3626275e+00 -6.6201240e-03 -6.4046168e-01 -1.4147683e+00\n",
      " -3.9515793e-03 -7.6750702e-01 -1.5303699e+00 -1.4107139e-01\n",
      " -5.6566453e-01 -1.4696307e+00 -4.9788103e-02 -6.2203598e-01\n",
      " -1.4477837e+00 -5.4930743e-02 -5.9790117e-01 -1.5429060e+00\n",
      "  7.3002607e-02 -6.2355167e-01 -1.5954995e+00 -4.6468247e-02\n",
      " -4.8340148e-01 -1.2965751e+00 -1.5571813e-01 -2.5720042e-01\n",
      " -1.9259683e+00 -1.1917949e-03 -4.1298494e-01 -1.9195026e+00\n",
      "  1.5275852e-01 -3.7931705e-01 -1.4486051e+00 -1.5100384e-01\n",
      " -2.4503931e-01 -1.2336488e+00 -6.2211707e-02 -2.2571073e-01\n",
      " -1.3143731e+00 -1.2451873e-02 -2.4583481e-01 -1.4308788e+00\n",
      "  5.4836191e-02 -2.5762028e-01 -1.2927065e+00  2.0000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B9B0>\n",
      "tensor([[ 0.0141, -0.0910, -0.2445,  ...,  0.0470, -0.2786, -1.2964],\n",
      "        [ 0.0141, -0.0910, -0.2445,  ...,  0.0470, -0.2786, -1.2964],\n",
      "        [ 0.0141, -0.0910, -0.2445,  ...,  0.0470, -0.2786, -1.2964],\n",
      "        ...,\n",
      "        [-0.1516,  0.4268, -0.1444,  ..., -0.6985,  0.9139, -0.4008],\n",
      "        [-0.1699, -0.1378,  0.5848,  ..., -0.2604,  0.6359,  0.2366],\n",
      "        [-0.1699, -0.1378,  0.5848,  ..., -0.2604,  0.6359,  0.2366]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01414412 -0.09095238 -0.24446525  0.03410833 -0.23069283 -0.6537484\n",
      " -0.05203328 -0.41806698 -1.4101839  -0.19317636 -0.48119527 -1.7091125\n",
      " -0.35997617 -0.5977383  -2.182426   -0.18761429 -0.6992029  -1.5722935\n",
      "  0.03527329 -0.73189706 -1.3746928  -0.01771186 -0.670208   -1.4281751\n",
      " -0.02300245 -0.80359876 -1.5464501  -0.14261985 -0.5941044  -1.4845359\n",
      " -0.05884726 -0.65009224 -1.4611396  -0.06947879 -0.62501323 -1.5543411\n",
      "  0.05678671 -0.65084404 -1.6008776  -0.05061331 -0.50726676 -1.3124893\n",
      " -0.16672543 -0.28018552 -1.9583124  -0.01230714 -0.43760198 -1.9566069\n",
      "  0.14140397 -0.40377283 -1.4543616  -0.15592727 -0.2705272  -1.2466781\n",
      " -0.07184707 -0.24961914 -1.3283111  -0.02560469 -0.2663999  -1.4435781\n",
      "  0.04697931 -0.2786168  -1.2964313 ]\n",
      "data: [-4.31  0.45 -3.01 -4.2  -0.8  -1.49 -4.15 -1.02 -0.83  0.    0.    0.\n",
      " -4.31 -0.81  0.8  -4.24 -0.29 -0.5  -4.26 -0.23 -0.63 -4.18 -0.28 -0.36\n",
      "  0.    0.    0.   -4.26 -0.23 -0.63 -4.25 -0.09 -0.67 -4.19  0.01 -0.95\n",
      " -3.49  0.43 -3.72 -4.21  0.04 -0.95 -4.21  0.01 -0.95 -4.21  0.04 -0.95\n",
      " -4.21  0.01 -0.95  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.  ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[-0.0824, -0.2970, -0.1044,  ..., -0.0085, -0.5555, -0.3624],\n",
      "        [-0.0824, -0.2970, -0.1044,  ..., -0.0085, -0.5555, -0.3624],\n",
      "        [-0.0824, -0.2970, -0.1044,  ..., -0.0085, -0.5555, -0.3624],\n",
      "        ...,\n",
      "        [ 0.5776, -0.6314,  0.8774,  ..., -0.2719,  0.0573, -0.4911],\n",
      "        [ 0.2051,  0.1425,  0.5105,  ..., -1.4844,  0.6257,  0.3251],\n",
      "        [ 0.2051,  0.1425,  0.5105,  ..., -1.4844,  0.6257,  0.3251]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.08237121 -0.29699743 -0.10435835 -0.11440335 -0.42347357 -0.41711944\n",
      " -0.1088664  -0.51018816 -0.5419266  -0.07272343 -0.60548276 -0.5273174\n",
      " -0.0580902  -0.71269    -0.6310861  -0.15591393 -0.5839396  -0.67682296\n",
      "  0.02365306 -0.6048101  -0.23506126  0.00440232 -0.694944   -0.22132674\n",
      " -0.00637174 -0.7220081  -0.27433777 -0.15036274 -0.51101935 -0.7066076\n",
      " -0.11853023 -0.6017456  -0.6648519  -0.12004836 -0.6601113  -0.62445855\n",
      " -0.0708528  -0.76427734 -0.6074215  -0.14505261 -0.5001761  -0.6499835\n",
      " -0.13694173 -0.48995697 -0.61410785 -0.10715327 -0.5834606  -0.5920764\n",
      " -0.04734404 -0.6748611  -0.50016886 -0.14453387 -0.37566528 -0.5491251\n",
      " -0.0839733  -0.43928185 -0.4812569  -0.0694702  -0.47564512 -0.4980647\n",
      " -0.00849488 -0.55551827 -0.36244005]\n",
      "init: [-0.08237121 -0.29699743 -0.10435835 -0.11440335 -0.42347357 -0.41711944\n",
      " -0.1088664  -0.51018816 -0.5419266  -0.07272343 -0.60548276 -0.5273174\n",
      " -0.0580902  -0.71269    -0.6310861  -0.15591393 -0.5839396  -0.67682296\n",
      "  0.02365306 -0.6048101  -0.23506126  0.00440232 -0.694944   -0.22132674\n",
      " -0.00637174 -0.7220081  -0.27433777 -0.15036274 -0.51101935 -0.7066076\n",
      " -0.11853023 -0.6017456  -0.6648519  -0.12004836 -0.6601113  -0.62445855\n",
      " -0.0708528  -0.76427734 -0.6074215  -0.14505261 -0.5001761  -0.6499835\n",
      " -0.13694173 -0.48995697 -0.61410785 -0.10715327 -0.5834606  -0.5920764\n",
      " -0.04734404 -0.6748611  -0.50016886 -0.14453387 -0.37566528 -0.5491251\n",
      " -0.0839733  -0.43928185 -0.4812569  -0.0694702  -0.47564512 -0.4980647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.00849488 -0.55551827 -0.36244005]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [-0.08237121 -0.29699743 -0.10435835 -0.11440335 -0.42347354 -0.41711944\n",
      " -0.10886641 -0.51018816 -0.5419266  -0.07272343 -0.60548276 -0.5273174\n",
      " -0.0580902  -0.71269    -0.6310861  -0.15591393 -0.5839396  -0.67682296\n",
      "  0.02365306 -0.6048101  -0.23506126  0.00440232 -0.694944   -0.22132674\n",
      " -0.00637174 -0.7220081  -0.27433777 -0.15036274 -0.51101935 -0.7066076\n",
      " -0.11853023 -0.6017456  -0.6648519  -0.12004836 -0.6601113  -0.62445855\n",
      " -0.0708528  -0.76427734 -0.6074215  -0.14505261 -0.5001761  -0.6499835\n",
      " -0.13694173 -0.48995697 -0.61410785 -0.10715327 -0.5834606  -0.5920764\n",
      " -0.04734404 -0.6748611  -0.50016886 -0.14453387 -0.37566528 -0.5491251\n",
      " -0.0839733  -0.43928185 -0.4812569  -0.0694702  -0.47564515 -0.4980647\n",
      " -0.00849488 -0.55551827 -0.36244002  0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B9B0>\n",
      "tensor([[ 0.0898, -0.1905,  0.0605,  ...,  0.1530, -0.3372, -1.0051],\n",
      "        [ 0.0898, -0.1905,  0.0605,  ...,  0.1530, -0.3372, -1.0051],\n",
      "        [ 0.0898, -0.1905,  0.0605,  ...,  0.1530, -0.3372, -1.0051],\n",
      "        ...,\n",
      "        [ 0.2155,  0.0387, -0.3475,  ...,  0.3806,  0.7636, -0.8347],\n",
      "        [-0.2069,  0.2102,  0.2662,  ..., -0.4850,  0.8166, -0.0660],\n",
      "        [-0.2069,  0.2102,  0.2662,  ..., -0.4850,  0.8166, -0.0660]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.08975942 -0.1904518   0.06051809  0.09272462 -0.34948695 -0.32752\n",
      "  0.006835   -0.5210867  -0.9992012  -0.16646835 -0.5669707  -1.2986106\n",
      " -0.37283796 -0.70134056 -1.7678319  -0.17017686 -0.7605741  -1.2416204\n",
      "  0.0731533  -0.78222156 -1.0771552   0.0402689  -0.6886784  -1.104684\n",
      "  0.071819   -0.8111019  -1.1905549  -0.10850534 -0.6378715  -1.1653081\n",
      "  0.00823242 -0.70085    -1.1198783   0.02917005 -0.66838026 -1.2096457\n",
      "  0.18430918 -0.68043804 -1.2692374   0.0272565  -0.571288   -1.006074\n",
      " -0.06774734 -0.32742304 -1.5171233   0.09148137 -0.50402796 -1.4863981\n",
      "  0.26704034 -0.4341736  -1.150228   -0.0872279  -0.32614547 -0.95402527\n",
      "  0.01552914 -0.29306525 -1.0137415   0.0861415  -0.3359058  -1.1344341\n",
      "  0.15304619 -0.33723998 -1.0050874 ]\n",
      "data: [ 0.08975942 -0.1904518   0.06051808  0.09272462 -0.34948695 -0.32752\n",
      "  0.006835   -0.5210867  -0.9992012  -0.16646835 -0.5669707  -1.2986106\n",
      " -0.37283793 -0.70134056 -1.7678319  -0.17017686 -0.7605741  -1.2416204\n",
      "  0.0731533  -0.78222156 -1.0771552   0.0402689  -0.6886784  -1.104684\n",
      "  0.071819   -0.8111019  -1.1905549  -0.10850534 -0.6378715  -1.1653081\n",
      "  0.00823242 -0.70085    -1.1198783   0.02917005 -0.66838026 -1.2096457\n",
      "  0.18430918 -0.6804381  -1.2692374   0.0272565  -0.571288   -1.006074\n",
      " -0.06774734 -0.327423   -1.5171235   0.09148137 -0.50402796 -1.4863982\n",
      "  0.26704034 -0.4341736  -1.150228   -0.0872279  -0.32614547 -0.95402527\n",
      "  0.01552914 -0.29306525 -1.0137415   0.0861415  -0.3359058  -1.1344341\n",
      "  0.15304619 -0.33723998 -1.0050874   0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F978>\n",
      "tensor([[ 1.6096e-02, -8.3678e-02, -2.1286e-01,  ..., -1.7652e-02,\n",
      "         -2.8729e-01, -1.2199e+00],\n",
      "        [ 1.6096e-02, -8.3678e-02, -2.1286e-01,  ..., -1.7652e-02,\n",
      "         -2.8729e-01, -1.2199e+00],\n",
      "        [ 1.6096e-02, -8.3678e-02, -2.1286e-01,  ..., -1.7652e-02,\n",
      "         -2.8729e-01, -1.2199e+00],\n",
      "        ...,\n",
      "        [-2.3710e-01,  3.1786e-01, -2.0161e-02,  ..., -3.4848e-01,\n",
      "          1.0062e+00, -5.6351e-01],\n",
      "        [-2.4335e-01,  1.0544e-01,  4.7116e-01,  ..., -3.3326e-01,\n",
      "          8.4172e-01,  1.1861e-05],\n",
      "        [-2.4335e-01,  1.0544e-01,  4.7116e-01,  ..., -3.3326e-01,\n",
      "          8.4172e-01,  1.1861e-05]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01609566 -0.08367828 -0.21285805  0.01086555 -0.22035709 -0.5713349\n",
      " -0.15149462 -0.44472337 -1.3819046  -0.32226086 -0.5258864  -1.6548996\n",
      " -0.50887936 -0.6063216  -2.158615   -0.19463512 -0.7257307  -1.5750622\n",
      " -0.08460354 -0.79695696 -1.3902259  -0.12400409 -0.6987848  -1.44657\n",
      " -0.1215019  -0.877606   -1.5477921  -0.16463622 -0.61711854 -1.4934759\n",
      " -0.13176936 -0.6711462  -1.412159   -0.17221332 -0.6608914  -1.4892333\n",
      " -0.01253979 -0.647681   -1.4961687  -0.09640018 -0.5342941  -1.344714\n",
      " -0.23184454 -0.30536819 -1.9860142  -0.10258348 -0.4653074  -2.0016003\n",
      "  0.07516586 -0.43550217 -1.3581618  -0.19106844 -0.2945233  -1.2657759\n",
      " -0.16972858 -0.27073342 -1.3328286  -0.14113432 -0.2594539  -1.4384191\n",
      " -0.0176519  -0.28729123 -1.2198604 ]\n",
      "data: [ 0.01609566 -0.08367828 -0.21285805  0.01086555 -0.22035709 -0.5713349\n",
      " -0.15149462 -0.44472337 -1.3819046  -0.32226086 -0.5258864  -1.6548996\n",
      " -0.50887936 -0.6063216  -2.158615   -0.19463512 -0.7257307  -1.5750622\n",
      " -0.08460354 -0.79695696 -1.3902259  -0.12400409 -0.69878477 -1.4465699\n",
      " -0.1215019  -0.877606   -1.5477921  -0.16463622 -0.61711854 -1.4934759\n",
      " -0.13176936 -0.6711462  -1.412159   -0.17221333 -0.6608914  -1.4892333\n",
      " -0.01253979 -0.647681   -1.4961686  -0.09640017 -0.5342941  -1.344714\n",
      " -0.23184454 -0.30536819 -1.9860142  -0.10258348 -0.4653074  -2.0016003\n",
      "  0.07516586 -0.43550217 -1.3581618  -0.19106844 -0.2945233  -1.2657759\n",
      " -0.16972858 -0.27073342 -1.3328286  -0.14113432 -0.2594539  -1.438419\n",
      " -0.0176519  -0.28729123 -1.2198604   0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[ 0.0071, -0.0096, -0.1690,  ...,  0.0410, -0.1923, -1.1759],\n",
      "        [ 0.0071, -0.0096, -0.1690,  ...,  0.0410, -0.1923, -1.1759],\n",
      "        [ 0.0071, -0.0096, -0.1690,  ...,  0.0410, -0.1923, -1.1759],\n",
      "        ...,\n",
      "        [-0.1572,  0.3806,  0.0180,  ..., -0.9372,  0.9660, -0.3112],\n",
      "        [-0.1122, -0.1055,  0.5879,  ..., -0.2618,  0.5605,  0.2835],\n",
      "        [-0.1122, -0.1055,  0.5879,  ..., -0.2618,  0.5605,  0.2835]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0070612  -0.00956214 -0.1690342   0.0287354  -0.1301223  -0.50828874\n",
      " -0.07570503 -0.32814047 -1.3165054  -0.22013377 -0.38606796 -1.6197591\n",
      " -0.39126134 -0.49087954 -2.105123   -0.19429183 -0.62354547 -1.4941965\n",
      "  0.02514653 -0.6592959  -1.307265   -0.02078466 -0.6005319  -1.3567239\n",
      " -0.00865631 -0.7456844  -1.486061   -0.15092732 -0.5207265  -1.3951892\n",
      " -0.0643739  -0.57636416 -1.3675096  -0.05740287 -0.5475953  -1.4678167\n",
      "  0.09826046 -0.5851557  -1.5130727  -0.06094325 -0.42185032 -1.2189964\n",
      " -0.20320486 -0.19145143 -1.9576037  -0.01074833 -0.35956404 -1.9698801\n",
      "  0.1775616  -0.32512766 -1.3519754  -0.18231817 -0.18365154 -1.140848\n",
      " -0.09716664 -0.1624268  -1.216015   -0.05456793 -0.17543465 -1.3392179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.04099769 -0.19231091 -1.1758525 ]\n",
      "data: [ 0.0070612  -0.00956214 -0.1690342   0.02873539 -0.1301223  -0.50828874\n",
      " -0.07570503 -0.32814044 -1.3165054  -0.22013377 -0.38606796 -1.6197591\n",
      " -0.39126134 -0.4908795  -2.105123   -0.19429184 -0.62354547 -1.4941964\n",
      "  0.02514653 -0.65929586 -1.307265   -0.02078466 -0.6005319  -1.3567239\n",
      " -0.00865631 -0.7456844  -1.486061   -0.15092732 -0.5207265  -1.3951892\n",
      " -0.0643739  -0.57636416 -1.3675096  -0.05740287 -0.5475953  -1.4678168\n",
      "  0.09826046 -0.5851557  -1.5130726  -0.06094326 -0.42185032 -1.2189964\n",
      " -0.20320486 -0.19145143 -1.9576038  -0.01074833 -0.359564   -1.9698801\n",
      "  0.17756158 -0.3251277  -1.3519754  -0.18231817 -0.18365154 -1.140848\n",
      " -0.09716664 -0.1624268  -1.216015   -0.05456793 -0.17543465 -1.3392178\n",
      "  0.04099769 -0.1923109  -1.1758525   0.04      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63320>\n",
      "tensor([[ 0.0068, -0.0978, -0.2305,  ...,  0.0260, -0.2605, -1.3255],\n",
      "        [ 0.0068, -0.0978, -0.2305,  ...,  0.0260, -0.2605, -1.3255],\n",
      "        [ 0.0068, -0.0978, -0.2305,  ...,  0.0260, -0.2605, -1.3255],\n",
      "        ...,\n",
      "        [-0.3267,  0.2852, -0.2436,  ..., -0.8019,  0.7460, -0.3921],\n",
      "        [-0.1839,  0.0041,  0.5745,  ..., -0.2882,  0.7726,  0.2922],\n",
      "        [-0.1839,  0.0041,  0.5745,  ..., -0.2882,  0.7726,  0.2922]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00679338 -0.09782396 -0.23051181  0.02775209 -0.256637   -0.69127935\n",
      " -0.0272936  -0.41734925 -1.3986435  -0.1653002  -0.47322857 -1.7016163\n",
      " -0.3381601  -0.6054168  -2.1669176  -0.21188144 -0.68163025 -1.5576272\n",
      "  0.04640853 -0.69116306 -1.3412938  -0.00979798 -0.63474613 -1.3920443\n",
      " -0.01586368 -0.74035335 -1.5055001  -0.16647097 -0.56714904 -1.4791822\n",
      " -0.06419982 -0.6215716  -1.4614162  -0.07265335 -0.5935215  -1.5596578\n",
      "  0.03980562 -0.6178428  -1.6218817  -0.06604845 -0.49227378 -1.3027873\n",
      " -0.16002169 -0.2622275  -1.870539   -0.0219647  -0.41047424 -1.8524294\n",
      "  0.1132068  -0.37562943 -1.4768994  -0.1666619  -0.25009283 -1.2484658\n",
      " -0.07014756 -0.2295617  -1.3231287  -0.01767449 -0.2553013  -1.4409909\n",
      "  0.02603606 -0.2604615  -1.3255241 ]\n",
      "data: [ 0.00679338 -0.09782396 -0.23051181  0.02775209 -0.256637   -0.69127935\n",
      " -0.0272936  -0.41734925 -1.3986435  -0.16530019 -0.47322857 -1.7016162\n",
      " -0.3381601  -0.6054168  -2.1669176  -0.21188144 -0.68163025 -1.5576272\n",
      "  0.04640853 -0.691163   -1.3412938  -0.00979798 -0.63474613 -1.3920444\n",
      " -0.01586368 -0.74035335 -1.5055001  -0.16647096 -0.56714904 -1.4791822\n",
      " -0.06419982 -0.6215716  -1.4614164  -0.07265335 -0.5935215  -1.5596577\n",
      "  0.03980562 -0.6178428  -1.6218817  -0.06604845 -0.49227378 -1.3027873\n",
      " -0.16002169 -0.2622275  -1.870539   -0.0219647  -0.41047424 -1.8524294\n",
      "  0.1132068  -0.37562943 -1.4768994  -0.16666192 -0.25009283 -1.2484658\n",
      " -0.07014756 -0.22956172 -1.3231287  -0.01767449 -0.2553013  -1.4409909\n",
      "  0.02603606 -0.2604615  -1.3255241   0.05      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B320>\n",
      "tensor([[ 0.0490, -0.1444, -0.2975,  ...,  0.0581, -0.3210, -1.3622],\n",
      "        [ 0.0490, -0.1444, -0.2975,  ...,  0.0581, -0.3210, -1.3622],\n",
      "        [ 0.0490, -0.1444, -0.2975,  ...,  0.0581, -0.3210, -1.3622],\n",
      "        ...,\n",
      "        [-0.1579,  0.4551, -0.1086,  ..., -0.7319,  0.9623, -0.4062],\n",
      "        [-0.1905, -0.0919,  0.6372,  ..., -0.2588,  0.6664,  0.3070],\n",
      "        [-0.1905, -0.0919,  0.6372,  ..., -0.2588,  0.6664,  0.3070]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04901105 -0.14436866 -0.2974565   0.07847281 -0.269755   -0.6889219\n",
      " -0.01751412 -0.47094125 -1.4841844  -0.16235405 -0.5322577  -1.7855381\n",
      " -0.31481415 -0.63844275 -2.2831569  -0.15302175 -0.756219   -1.660805\n",
      "  0.06240993 -0.7997719  -1.4751387   0.00389858 -0.73728156 -1.5267875\n",
      " -0.01376478 -0.88043916 -1.6504494  -0.10913789 -0.6583656  -1.5644424\n",
      " -0.03653064 -0.713254   -1.5440123  -0.05156519 -0.6832229  -1.6353072\n",
      "  0.06428257 -0.7180401  -1.672878   -0.0199912  -0.55713236 -1.3956195\n",
      " -0.15717942 -0.32456392 -2.0841439   0.00557747 -0.49032655 -2.0923755\n",
      "  0.15348518 -0.45184526 -1.5296317  -0.13596892 -0.32429928 -1.3224219\n",
      " -0.05373294 -0.29691625 -1.4023025  -0.01545603 -0.31246728 -1.5158187\n",
      "  0.05813035 -0.32103753 -1.3622139 ]\n",
      "data: [ 0.04901105 -0.14436866 -0.2974565   0.07847281 -0.269755   -0.688922\n",
      " -0.01751412 -0.47094125 -1.4841844  -0.16235405 -0.5322577  -1.7855381\n",
      " -0.31481415 -0.63844275 -2.2831569  -0.15302175 -0.756219   -1.6608051\n",
      "  0.06240993 -0.7997719  -1.4751387   0.00389858 -0.73728156 -1.5267875\n",
      " -0.01376478 -0.88043916 -1.6504494  -0.10913789 -0.6583656  -1.5644424\n",
      " -0.03653064 -0.7132539  -1.5440123  -0.05156519 -0.6832229  -1.6353072\n",
      "  0.06428257 -0.7180401  -1.6728779  -0.0199912  -0.55713236 -1.3956195\n",
      " -0.15717942 -0.3245639  -2.0841439   0.00557747 -0.49032652 -2.0923755\n",
      "  0.15348518 -0.45184526 -1.5296319  -0.13596892 -0.32429928 -1.3224219\n",
      " -0.05373294 -0.29691625 -1.4023025  -0.01545603 -0.31246728 -1.5158188\n",
      "  0.05813035 -0.32103753 -1.3622139   0.06      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[-0.0102, -0.1129, -0.2447,  ...,  0.0237, -0.2924, -1.3263],\n",
      "        [-0.0102, -0.1129, -0.2447,  ...,  0.0237, -0.2924, -1.3263],\n",
      "        [-0.0102, -0.1129, -0.2447,  ...,  0.0237, -0.2924, -1.3263],\n",
      "        ...,\n",
      "        [-0.0586,  0.5023, -0.0740,  ..., -0.6704,  1.0038, -0.3310],\n",
      "        [-0.0788, -0.0354,  0.5829,  ..., -0.1539,  0.6644,  0.2853],\n",
      "        [-0.0788, -0.0354,  0.5829,  ..., -0.1539,  0.6644,  0.2853]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-1.0195184e-02 -1.1290607e-01 -2.4472378e-01  1.2085028e-03\n",
      " -2.7172238e-01 -6.8915188e-01 -2.5258832e-02 -4.4046989e-01\n",
      " -1.3921995e+00 -1.6639888e-01 -4.9140063e-01 -1.7269707e+00\n",
      " -3.6099601e-01 -6.4298528e-01 -2.1741908e+00 -2.3846789e-01\n",
      " -6.9436550e-01 -1.5868394e+00  6.5321580e-02 -7.1010810e-01\n",
      " -1.3671191e+00 -1.9726604e-03 -6.6668701e-01 -1.4118826e+00\n",
      " -2.3453459e-03 -7.8149849e-01 -1.5293047e+00 -1.7855382e-01\n",
      " -5.7046670e-01 -1.4856796e+00 -6.5604538e-02 -6.4079010e-01\n",
      " -1.4758008e+00 -6.2120661e-02 -6.2877035e-01 -1.5897098e+00\n",
      "  3.9272189e-02 -6.6816080e-01 -1.6602263e+00 -5.7961695e-02\n",
      " -4.8884740e-01 -1.2942610e+00 -1.7467068e-01 -2.7090302e-01\n",
      " -1.9120128e+00 -2.1075986e-02 -4.4252533e-01 -1.8844888e+00\n",
      "  1.1890848e-01 -4.0226680e-01 -1.4849963e+00 -1.7878935e-01\n",
      " -2.4427377e-01 -1.2382863e+00 -5.7324007e-02 -2.3648718e-01\n",
      " -1.3088837e+00 -4.7258586e-03 -2.8852350e-01 -1.4243824e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.3677029e-02 -2.9235220e-01 -1.3263414e+00]\n",
      "data: [-1.0195184e-02 -1.1290607e-01 -2.4472378e-01  1.2085028e-03\n",
      " -2.7172238e-01 -6.8915194e-01 -2.5258832e-02 -4.4046989e-01\n",
      " -1.3921995e+00 -1.6639888e-01 -4.9140063e-01 -1.7269707e+00\n",
      " -3.6099601e-01 -6.4298528e-01 -2.1741908e+00 -2.3846789e-01\n",
      " -6.9436556e-01 -1.5868394e+00  6.5321580e-02 -7.1010810e-01\n",
      " -1.3671192e+00 -1.9726604e-03 -6.6668701e-01 -1.4118826e+00\n",
      " -2.3453459e-03 -7.8149849e-01 -1.5293049e+00 -1.7855380e-01\n",
      " -5.7046670e-01 -1.4856796e+00 -6.5604538e-02 -6.4079010e-01\n",
      " -1.4758008e+00 -6.2120661e-02 -6.2877035e-01 -1.5897098e+00\n",
      "  3.9272189e-02 -6.6816080e-01 -1.6602263e+00 -5.7961691e-02\n",
      " -4.8884737e-01 -1.2942610e+00 -1.7467068e-01 -2.7090302e-01\n",
      " -1.9120128e+00 -2.1075986e-02 -4.4252533e-01 -1.8844888e+00\n",
      "  1.1890848e-01 -4.0226680e-01 -1.4849963e+00 -1.7878935e-01\n",
      " -2.4427375e-01 -1.2382863e+00 -5.7324007e-02 -2.3648718e-01\n",
      " -1.3088837e+00 -4.7258586e-03 -2.8852350e-01 -1.4243824e+00\n",
      "  2.3677029e-02 -2.9235220e-01 -1.3263414e+00  7.0000000e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0523, -0.1376, -0.2577,  ...,  0.0403, -0.3134, -1.3075],\n",
      "        [ 0.0523, -0.1376, -0.2577,  ...,  0.0403, -0.3134, -1.3075],\n",
      "        [ 0.0523, -0.1376, -0.2577,  ...,  0.0403, -0.3134, -1.3075],\n",
      "        ...,\n",
      "        [-0.1003,  0.4500, -0.1453,  ..., -0.6384,  0.9246, -0.4373],\n",
      "        [-0.1599, -0.0911,  0.6303,  ..., -0.2123,  0.6456,  0.3282],\n",
      "        [-0.1599, -0.0911,  0.6303,  ..., -0.2123,  0.6456,  0.3282]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.05227468 -0.13757041 -0.25769007  0.08277778 -0.24887583 -0.62255293\n",
      " -0.03740469 -0.4669207  -1.4441328  -0.18579145 -0.5298965  -1.7386718\n",
      " -0.33113688 -0.6193746  -2.2489133  -0.14323752 -0.76504093 -1.6178327\n",
      "  0.03303571 -0.824106   -1.4586799  -0.02562512 -0.75476176 -1.5127516\n",
      " -0.0476957  -0.9179377  -1.6372023  -0.10419726 -0.6761972  -1.5195689\n",
      " -0.05176958 -0.726771   -1.4951305  -0.0752093  -0.6944747  -1.5825067\n",
      "  0.04217016 -0.72781867 -1.6026502  -0.02620622 -0.5614302  -1.3624179\n",
      " -0.18208246 -0.32921326 -2.104256   -0.0124675  -0.49694723 -2.1282837\n",
      "  0.1369895  -0.4581747  -1.4722352  -0.14331563 -0.33521822 -1.2828493\n",
      " -0.07919806 -0.30353683 -1.3705664  -0.05211587 -0.30565754 -1.4837084\n",
      "  0.04034097 -0.31338835 -1.3074653 ]\n",
      "data: [ 0.05227468 -0.13757041 -0.25769007  0.08277778 -0.24887583 -0.62255293\n",
      " -0.03740469 -0.4669207  -1.4441328  -0.18579145 -0.5298965  -1.7386718\n",
      " -0.33113688 -0.6193746  -2.2489133  -0.14323752 -0.765041   -1.6178327\n",
      "  0.03303571 -0.824106   -1.4586799  -0.02562512 -0.75476176 -1.5127516\n",
      " -0.0476957  -0.9179377  -1.6372023  -0.10419726 -0.67619723 -1.5195689\n",
      " -0.05176958 -0.726771   -1.4951307  -0.0752093  -0.6944747  -1.5825067\n",
      "  0.04217016 -0.72781867 -1.6026502  -0.02620622 -0.5614302  -1.3624179\n",
      " -0.18208246 -0.32921326 -2.104256   -0.0124675  -0.4969472  -2.1282837\n",
      "  0.1369895  -0.4581747  -1.4722352  -0.14331563 -0.33521825 -1.2828493\n",
      " -0.07919806 -0.30353683 -1.3705664  -0.05211587 -0.30565754 -1.4837084\n",
      "  0.04034097 -0.31338835 -1.3074653   0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0120, -0.0695, -0.1824,  ...,  0.0673, -0.2704, -1.1748],\n",
      "        [ 0.0120, -0.0695, -0.1824,  ...,  0.0673, -0.2704, -1.1748],\n",
      "        [ 0.0120, -0.0695, -0.1824,  ...,  0.0673, -0.2704, -1.1748],\n",
      "        ...,\n",
      "        [-0.1276,  0.3669, -0.0470,  ..., -0.8188,  0.8687, -0.3267],\n",
      "        [-0.1010, -0.0887,  0.5476,  ..., -0.1804,  0.6049,  0.1863],\n",
      "        [-0.1010, -0.0887,  0.5476,  ..., -0.1804,  0.6049,  0.1863]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01196193 -0.06946506 -0.1823968   0.03724331 -0.18598138 -0.50577456\n",
      " -0.06375476 -0.39208707 -1.3105845  -0.21190123 -0.45128256 -1.6194286\n",
      " -0.3747337  -0.56682223 -2.108869   -0.18716174 -0.68784755 -1.4935473\n",
      "  0.03258489 -0.7370684  -1.3345361  -0.02961127 -0.6750138  -1.3851194\n",
      " -0.02924164 -0.83039516 -1.5097519  -0.13299723 -0.59313387 -1.3885874\n",
      " -0.05496302 -0.6529089  -1.3729815  -0.06057993 -0.62777877 -1.4692798\n",
      "  0.06494133 -0.6689718  -1.500152   -0.03322989 -0.48969448 -1.2124082\n",
      " -0.1805309  -0.26017663 -1.9590275   0.0031127  -0.43934524 -1.9686645\n",
      "  0.16964194 -0.4032339  -1.3468858  -0.15474968 -0.25994092 -1.1410322\n",
      " -0.06033179 -0.24195564 -1.2256444  -0.02252643 -0.2608995  -1.3411716\n",
      "  0.06726096 -0.27043426 -1.1748115 ]\n",
      "data: [ 0.01196193 -0.06946506 -0.1823968   0.03724331 -0.18598136 -0.50577456\n",
      " -0.06375476 -0.39208707 -1.3105845  -0.21190123 -0.4512826  -1.6194288\n",
      " -0.3747337  -0.56682223 -2.108869   -0.18716174 -0.6878475  -1.4935473\n",
      "  0.03258489 -0.7370684  -1.3345361  -0.02961127 -0.6750138  -1.3851194\n",
      " -0.02924164 -0.8303951  -1.5097519  -0.13299723 -0.59313387 -1.3885874\n",
      " -0.05496302 -0.6529089  -1.3729815  -0.06057993 -0.62777877 -1.4692798\n",
      "  0.06494133 -0.6689718  -1.500152   -0.03322989 -0.48969448 -1.2124082\n",
      " -0.1805309  -0.26017663 -1.9590275   0.0031127  -0.43934524 -1.9686645\n",
      "  0.16964193 -0.4032339  -1.3468858  -0.15474968 -0.25994092 -1.1410322\n",
      " -0.06033179 -0.24195564 -1.2256444  -0.02252643 -0.2608995  -1.3411716\n",
      "  0.06726096 -0.27043426 -1.1748115   0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[-0.0111, -0.0481, -0.2307,  ...,  0.0174, -0.2464, -1.2138],\n",
      "        [-0.0111, -0.0481, -0.2307,  ...,  0.0174, -0.2464, -1.2138],\n",
      "        [-0.0111, -0.0481, -0.2307,  ...,  0.0174, -0.2464, -1.2138],\n",
      "        ...,\n",
      "        [-0.1528,  0.3385, -0.0458,  ..., -0.7414,  0.8445, -0.3099],\n",
      "        [-0.0999, -0.0677,  0.5620,  ..., -0.2015,  0.7000,  0.2104],\n",
      "        [-0.0999, -0.0677,  0.5620,  ..., -0.2015,  0.7000,  0.2104]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01106288 -0.04814006 -0.23074704  0.02109117 -0.13927417 -0.53565294\n",
      " -0.14791541 -0.37001473 -1.3969936  -0.3021707  -0.43950582 -1.6724608\n",
      " -0.44238815 -0.51093125 -2.1917012  -0.19012907 -0.6933391  -1.5519218\n",
      " -0.0671266  -0.7673876  -1.4228098  -0.11245176 -0.68006676 -1.481736\n",
      " -0.11971563 -0.8647664  -1.6054249  -0.15277249 -0.619576   -1.4561591\n",
      " -0.11484372 -0.6640094  -1.4206145  -0.13612694 -0.62638736 -1.4976702\n",
      "  0.01719002 -0.6492382  -1.5012398  -0.08677063 -0.5080017  -1.3035505\n",
      " -0.24275728 -0.2656985  -2.0881665  -0.0570116  -0.43264157 -2.1280596\n",
      "  0.12507376 -0.39888406 -1.3797944  -0.1965508  -0.28633273 -1.217766\n",
      " -0.15120533 -0.24974783 -1.3167655  -0.12120485 -0.2310207  -1.4315307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.017386   -0.24640486 -1.2138195 ]\n",
      "data: [-0.01106288 -0.04814006 -0.23074704  0.02109117 -0.13927417 -0.53565294\n",
      " -0.14791541 -0.37001473 -1.3969938  -0.3021707  -0.43950582 -1.6724608\n",
      " -0.44238815 -0.51093125 -2.1917012  -0.19012907 -0.6933391  -1.5519218\n",
      " -0.0671266  -0.7673876  -1.42281    -0.11245176 -0.68006676 -1.481736\n",
      " -0.11971563 -0.86476636 -1.6054248  -0.15277249 -0.619576   -1.4561591\n",
      " -0.11484372 -0.6640094  -1.4206145  -0.13612694 -0.62638736 -1.4976702\n",
      "  0.01719002 -0.6492382  -1.5012398  -0.08677063 -0.5080017  -1.3035504\n",
      " -0.24275728 -0.2656985  -2.0881665  -0.0570116  -0.43264157 -2.1280596\n",
      "  0.12507376 -0.39888406 -1.3797944  -0.1965508  -0.28633273 -1.217766\n",
      " -0.15120533 -0.24974783 -1.3167655  -0.12120485 -0.2310207  -1.4315307\n",
      "  0.017386   -0.24640486 -1.2138195   0.1       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0405, -0.0333, -0.1659,  ...,  0.0497, -0.2025, -1.2270],\n",
      "        [ 0.0405, -0.0333, -0.1659,  ...,  0.0497, -0.2025, -1.2270],\n",
      "        [ 0.0405, -0.0333, -0.1659,  ...,  0.0497, -0.2025, -1.2270],\n",
      "        ...,\n",
      "        [-0.2884,  0.1779, -0.1911,  ..., -0.8343,  0.6624, -0.4320],\n",
      "        [-0.2020, -0.1137,  0.5042,  ..., -0.3401,  0.6008,  0.2278],\n",
      "        [-0.2020, -0.1137,  0.5042,  ..., -0.3401,  0.6008,  0.2278]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04051511 -0.03331693 -0.16585918  0.0563082  -0.185063   -0.6009881\n",
      " -0.00945718 -0.35896045 -1.3281316  -0.1501046  -0.4144498  -1.6354041\n",
      " -0.3411782  -0.5383667  -2.086541   -0.17509025 -0.6302021  -1.482865\n",
      "  0.07982121 -0.64688396 -1.2582588   0.03329584 -0.5950565  -1.3054379\n",
      "  0.03452403 -0.71259004 -1.4234896  -0.13159764 -0.51140124 -1.3949006\n",
      " -0.03049249 -0.5716732  -1.3690025  -0.02585199 -0.5478838  -1.4722245\n",
      "  0.11021738 -0.5764422  -1.540108   -0.03525838 -0.43008345 -1.2166646\n",
      " -0.15188654 -0.2043712  -1.8558314   0.01159874 -0.3618912  -1.8434794\n",
      "  0.16964552 -0.32443857 -1.379777   -0.14719029 -0.18333419 -1.1541538\n",
      " -0.05854526 -0.16430357 -1.2270813  -0.00492485 -0.19071041 -1.3487628\n",
      "  0.04966798 -0.20252138 -1.227001  ]\n",
      "data: [ 0.04051511 -0.03331693 -0.16585918  0.0563082  -0.185063   -0.6009881\n",
      " -0.00945718 -0.35896045 -1.3281316  -0.1501046  -0.4144498  -1.6354041\n",
      " -0.3411782  -0.5383667  -2.086541   -0.17509025 -0.6302021  -1.482865\n",
      "  0.07982121 -0.646884   -1.2582588   0.03329584 -0.5950565  -1.3054379\n",
      "  0.03452403 -0.71259004 -1.4234896  -0.13159764 -0.51140124 -1.3949006\n",
      " -0.03049249 -0.5716732  -1.3690026  -0.02585199 -0.5478838  -1.4722245\n",
      "  0.11021738 -0.5764422  -1.5401081  -0.03525838 -0.43008345 -1.2166646\n",
      " -0.15188654 -0.2043712  -1.8558315   0.01159874 -0.3618912  -1.8434795\n",
      "  0.16964552 -0.32443854 -1.379777   -0.14719029 -0.18333417 -1.1541538\n",
      " -0.05854526 -0.16430357 -1.2270813  -0.00492485 -0.19071041 -1.3487629\n",
      "  0.04966798 -0.20252138 -1.227001    0.11      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0321, -0.0784, -0.2616,  ...,  0.0655, -0.2560, -1.3231],\n",
      "        [ 0.0321, -0.0784, -0.2616,  ...,  0.0655, -0.2560, -1.3231],\n",
      "        [ 0.0321, -0.0784, -0.2616,  ...,  0.0655, -0.2560, -1.3231],\n",
      "        ...,\n",
      "        [-0.1653,  0.4291, -0.1562,  ..., -0.7107,  0.9082, -0.3957],\n",
      "        [-0.1782, -0.1029,  0.5775,  ..., -0.2504,  0.6891,  0.2397],\n",
      "        [-0.1782, -0.1029,  0.5775,  ..., -0.2504,  0.6891,  0.2397]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 3.2126892e-02 -7.8365751e-02 -2.6157391e-01  5.0605293e-02\n",
      " -2.3104967e-01 -6.9401491e-01 -4.2091094e-02 -4.1548041e-01\n",
      " -1.4395804e+00 -1.8397093e-01 -4.8127779e-01 -1.7274630e+00\n",
      " -3.5331357e-01 -5.9952140e-01 -2.1935902e+00 -1.7774202e-01\n",
      " -6.8221319e-01 -1.5965146e+00  4.2446151e-02 -7.0950985e-01\n",
      " -1.3826318e+00 -1.9155592e-03 -6.4527124e-01 -1.4343685e+00\n",
      " -2.6525259e-03 -7.6813829e-01 -1.5477480e+00 -1.3540186e-01\n",
      " -5.7020038e-01 -1.5184039e+00 -4.7486842e-02 -6.2673306e-01\n",
      " -1.4844522e+00 -5.3459980e-02 -6.0018420e-01 -1.5716742e+00\n",
      "  8.4018782e-02 -6.1851227e-01 -1.6233308e+00 -4.4696800e-02\n",
      " -4.9244615e-01 -1.3471968e+00 -1.4681137e-01 -2.6341835e-01\n",
      " -1.9439993e+00  2.7487278e-03 -4.1533726e-01 -1.9365720e+00\n",
      "  1.6119909e-01 -3.7953687e-01 -1.4797662e+00 -1.4254825e-01\n",
      " -2.5113428e-01 -1.2835582e+00 -6.3111007e-02 -2.2685800e-01\n",
      " -1.3574060e+00 -7.7206641e-03 -2.4202543e-01 -1.4733531e+00\n",
      "  6.5487571e-02 -2.5601739e-01 -1.3231045e+00]\n",
      "data: [ 3.2126892e-02 -7.8365751e-02 -2.6157391e-01  5.0605293e-02\n",
      " -2.3104967e-01 -6.9401491e-01 -4.2091094e-02 -4.1548043e-01\n",
      " -1.4395804e+00 -1.8397093e-01 -4.8127782e-01 -1.7274631e+00\n",
      " -3.5331357e-01 -5.9952140e-01 -2.1935902e+00 -1.7774202e-01\n",
      " -6.8221319e-01 -1.5965146e+00  4.2446151e-02 -7.0950991e-01\n",
      " -1.3826318e+00 -1.9155592e-03 -6.4527124e-01 -1.4343685e+00\n",
      " -2.6525259e-03 -7.6813829e-01 -1.5477480e+00 -1.3540186e-01\n",
      " -5.7020038e-01 -1.5184039e+00 -4.7486838e-02 -6.2673306e-01\n",
      " -1.4844522e+00 -5.3459980e-02 -6.0018420e-01 -1.5716742e+00\n",
      "  8.4018782e-02 -6.1851227e-01 -1.6233308e+00 -4.4696797e-02\n",
      " -4.9244612e-01 -1.3471968e+00 -1.4681137e-01 -2.6341835e-01\n",
      " -1.9439993e+00  2.7487278e-03 -4.1533726e-01 -1.9365720e+00\n",
      "  1.6119909e-01 -3.7953687e-01 -1.4797662e+00 -1.4254825e-01\n",
      " -2.5113428e-01 -1.2835582e+00 -6.3111007e-02 -2.2685800e-01\n",
      " -1.3574060e+00 -7.7206641e-03 -2.4202543e-01 -1.4733531e+00\n",
      "  6.5487571e-02 -2.5601739e-01 -1.3231045e+00  1.2000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[ 0.0183, -0.1217, -0.2625,  ...,  0.0616, -0.3032, -1.3330],\n",
      "        [ 0.0183, -0.1217, -0.2625,  ...,  0.0616, -0.3032, -1.3330],\n",
      "        [ 0.0183, -0.1217, -0.2625,  ...,  0.0616, -0.3032, -1.3330],\n",
      "        ...,\n",
      "        [-0.1362,  0.4464, -0.1807,  ..., -0.7349,  0.9462, -0.4391],\n",
      "        [-0.1592, -0.1137,  0.6000,  ..., -0.2451,  0.6499,  0.2730],\n",
      "        [-0.1592, -0.1137,  0.6000,  ..., -0.2451,  0.6499,  0.2730]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01833197 -0.12169342 -0.26254633  0.03670681 -0.27322268 -0.6849513\n",
      " -0.02159786 -0.44560555 -1.4133418  -0.16257131 -0.50306225 -1.7234606\n",
      " -0.33734646 -0.63663816 -2.1883721  -0.19369712 -0.71586007 -1.5919485\n",
      "  0.06820505 -0.73484445 -1.392395    0.01172181 -0.680145   -1.441654\n",
      "  0.01578388 -0.7960535  -1.558208   -0.14276072 -0.60168546 -1.5037456\n",
      " -0.03844635 -0.66147697 -1.4876562  -0.03825776 -0.6375552  -1.5882906\n",
      "  0.08140712 -0.6688032  -1.6479235  -0.03633447 -0.52075636 -1.3222588\n",
      " -0.14161265 -0.29435617 -1.9269966   0.01051336 -0.45339167 -1.9113119\n",
      "  0.161576   -0.41685176 -1.493564   -0.14766476 -0.27850115 -1.2633781\n",
      " -0.04243248 -0.26183552 -1.3383275   0.00961874 -0.29432705 -1.4543355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.06156902 -0.3031764  -1.3330042 ]\n",
      "data: [ 0.01833197 -0.12169342 -0.26254633  0.03670681 -0.27322268 -0.6849513\n",
      " -0.02159786 -0.44560555 -1.4133419  -0.16257131 -0.50306225 -1.7234606\n",
      " -0.33734646 -0.63663816 -2.1883721  -0.19369712 -0.71586007 -1.5919485\n",
      "  0.06820505 -0.73484445 -1.392395    0.01172181 -0.680145   -1.4416538\n",
      "  0.01578388 -0.7960535  -1.558208   -0.14276072 -0.60168546 -1.5037456\n",
      " -0.03844635 -0.66147697 -1.4876562  -0.03825776 -0.6375552  -1.5882906\n",
      "  0.08140711 -0.6688033  -1.6479235  -0.03633447 -0.52075636 -1.3222587\n",
      " -0.14161265 -0.29435617 -1.9269966   0.01051336 -0.45339167 -1.9113117\n",
      "  0.161576   -0.41685176 -1.493564   -0.14766476 -0.27850115 -1.2633781\n",
      " -0.04243248 -0.26183552 -1.3383275   0.00961874 -0.29432705 -1.4543355\n",
      "  0.06156902 -0.3031764  -1.3330044   0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F908>\n",
      "tensor([[ 0.0431, -0.1784, -0.2640,  ...,  0.0680, -0.3526, -1.3439],\n",
      "        [ 0.0431, -0.1784, -0.2640,  ...,  0.0680, -0.3526, -1.3439],\n",
      "        [ 0.0431, -0.1784, -0.2640,  ...,  0.0680, -0.3526, -1.3439],\n",
      "        ...,\n",
      "        [-0.0950,  0.4859, -0.1712,  ..., -0.6246,  0.9719, -0.4834],\n",
      "        [-0.1657, -0.0456,  0.6339,  ..., -0.2319,  0.6788,  0.3177],\n",
      "        [-0.1657, -0.0456,  0.6339,  ..., -0.2319,  0.6788,  0.3177]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 4.3133002e-02 -1.7844738e-01 -2.6399603e-01  7.1498990e-02\n",
      " -3.1658936e-01 -6.5668720e-01  6.4850599e-04 -5.1223689e-01\n",
      " -1.4318393e+00 -1.4581265e-01 -5.7121140e-01 -1.7476627e+00\n",
      " -3.1332865e-01 -6.9696188e-01 -2.2328131e+00 -1.6907847e-01\n",
      " -7.8243136e-01 -1.6308755e+00  9.3427777e-02 -8.1872272e-01\n",
      " -1.4228979e+00  3.0685261e-02 -7.6689446e-01 -1.4671458e+00\n",
      "  1.4635935e-02 -8.9909530e-01 -1.5908984e+00 -1.1649102e-01\n",
      " -6.7329001e-01 -1.5302067e+00 -2.3317128e-02 -7.3890865e-01\n",
      " -1.5151459e+00 -2.6917778e-02 -7.1291983e-01 -1.6156092e+00\n",
      "  8.3741203e-02 -7.5799310e-01 -1.6675618e+00 -1.0812797e-02\n",
      " -5.7421994e-01 -1.3508896e+00 -1.4696577e-01 -3.4505779e-01\n",
      " -2.0286548e+00  2.1733873e-02 -5.2064168e-01 -2.0232255e+00\n",
      "  1.6951013e-01 -4.7745439e-01 -1.5122226e+00 -1.3692483e-01\n",
      " -3.3400184e-01 -1.2834655e+00 -3.2656461e-02 -3.1248200e-01\n",
      " -1.3578473e+00  1.3227642e-02 -3.4714368e-01 -1.4734805e+00\n",
      "  6.7983039e-02 -3.5260022e-01 -1.3438920e+00]\n",
      "data: [ 4.31330018e-02 -1.78447381e-01 -2.63996035e-01  7.14989901e-02\n",
      " -3.16589355e-01 -6.56687140e-01  6.48505986e-04 -5.12236893e-01\n",
      " -1.43183935e+00 -1.45812646e-01 -5.71211398e-01 -1.74766266e+00\n",
      " -3.13328654e-01 -6.96961880e-01 -2.23281312e+00 -1.69078469e-01\n",
      " -7.82431364e-01 -1.63087535e+00  9.34277698e-02 -8.18722665e-01\n",
      " -1.42289793e+00  3.06852609e-02 -7.66894460e-01 -1.46714580e+00\n",
      "  1.46359345e-02 -8.99095297e-01 -1.59089839e+00 -1.16491020e-01\n",
      " -6.73290014e-01 -1.53020656e+00 -2.33171266e-02 -7.38908589e-01\n",
      " -1.51514590e+00 -2.69177780e-02 -7.12919831e-01 -1.61560917e+00\n",
      "  8.37412104e-02 -7.57993102e-01 -1.66756177e+00 -1.08127967e-02\n",
      " -5.74219942e-01 -1.35088956e+00 -1.46965772e-01 -3.45057786e-01\n",
      " -2.02865481e+00  2.17338726e-02 -5.20641685e-01 -2.02322555e+00\n",
      "  1.69510111e-01 -4.77454364e-01 -1.51222265e+00 -1.36924833e-01\n",
      " -3.34001839e-01 -1.28346562e+00 -3.26564610e-02 -3.12481999e-01\n",
      " -1.35784733e+00  1.32276416e-02 -3.47143680e-01 -1.47348058e+00\n",
      "  6.79830387e-02 -3.52600217e-01 -1.34389186e+00  1.40000001e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0141, -0.1614, -0.1976,  ...,  0.0807, -0.3529, -1.2358],\n",
      "        [ 0.0141, -0.1614, -0.1976,  ...,  0.0807, -0.3529, -1.2358],\n",
      "        [ 0.0141, -0.1614, -0.1976,  ...,  0.0807, -0.3529, -1.2358],\n",
      "        ...,\n",
      "        [-0.0487,  0.5011, -0.1459,  ..., -0.5827,  1.0526, -0.5165],\n",
      "        [-0.0918, -0.0128,  0.6130,  ..., -0.1644,  0.6521,  0.2734],\n",
      "        [-0.0918, -0.0128,  0.6130,  ..., -0.1644,  0.6521,  0.2734]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01407174 -0.16144022 -0.19762897  0.04109814 -0.30192578 -0.5487237\n",
      " -0.02560877 -0.5006217  -1.3426574  -0.17409918 -0.5613394  -1.6669002\n",
      " -0.35365027 -0.7024965  -2.1448877  -0.20104942 -0.76755524 -1.5493103\n",
      "  0.08645503 -0.80496967 -1.3375238   0.01810515 -0.7569853  -1.3768582\n",
      "  0.01249434 -0.88866293 -1.5020943  -0.13826998 -0.65471566 -1.4398733\n",
      " -0.03274129 -0.72733235 -1.4266667  -0.02675994 -0.70415163 -1.5304207\n",
      "  0.08766393 -0.7567775  -1.584638   -0.01916706 -0.559183   -1.2474753\n",
      " -0.1578108  -0.3298821  -1.944666    0.02320004 -0.51654446 -1.9326125\n",
      "  0.18369043 -0.4726139  -1.4135206  -0.15269308 -0.3146929  -1.1806177\n",
      " -0.0285642  -0.30199653 -1.2544312   0.02292581 -0.3468952  -1.3701074\n",
      "  0.08065914 -0.35293704 -1.2357852 ]\n",
      "data: [ 0.01407174 -0.16144022 -0.19762897  0.04109814 -0.30192578 -0.5487237\n",
      " -0.02560877 -0.5006217  -1.3426574  -0.17409918 -0.5613394  -1.6669002\n",
      " -0.35365027 -0.70249647 -2.1448877  -0.20104942 -0.76755524 -1.5493103\n",
      "  0.08645503 -0.8049696  -1.3375238   0.01810515 -0.7569853  -1.3768582\n",
      "  0.01249434 -0.88866293 -1.5020943  -0.13826998 -0.65471566 -1.4398733\n",
      " -0.03274129 -0.72733235 -1.4266667  -0.02675994 -0.70415163 -1.5304207\n",
      "  0.08766393 -0.7567775  -1.5846381  -0.01916706 -0.559183   -1.2474753\n",
      " -0.1578108  -0.3298821  -1.944666    0.02320004 -0.51654446 -1.9326127\n",
      "  0.18369043 -0.4726139  -1.4135205  -0.15269308 -0.3146929  -1.1806177\n",
      " -0.0285642  -0.30199653 -1.2544312   0.02292581 -0.3468952  -1.3701074\n",
      "  0.08065914 -0.35293704 -1.2357852   0.15      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0116, -0.1015, -0.1694,  ...,  0.0299, -0.2975, -1.1612],\n",
      "        [ 0.0116, -0.1015, -0.1694,  ...,  0.0299, -0.2975, -1.1612],\n",
      "        [ 0.0116, -0.1015, -0.1694,  ...,  0.0299, -0.2975, -1.1612],\n",
      "        ...,\n",
      "        [-0.0798,  0.4560, -0.1052,  ..., -0.2859,  1.0222, -0.5019],\n",
      "        [-0.1082, -0.0545,  0.6358,  ..., -0.1976,  0.6422,  0.3010],\n",
      "        [-0.1082, -0.0545,  0.6358,  ..., -0.1976,  0.6422,  0.3010]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01161902 -0.10150626 -0.16938762  0.04399347 -0.20451166 -0.45262778\n",
      " -0.10740155 -0.44534987 -1.3278879  -0.26587224 -0.51640606 -1.612954\n",
      " -0.41139832 -0.60463154 -2.133138   -0.18137434 -0.7485421  -1.5121411\n",
      " -0.01605096 -0.82421887 -1.359814   -0.07061887 -0.7473978  -1.4076535\n",
      " -0.08365624 -0.92027104 -1.5324342  -0.13771072 -0.6615418  -1.4083054\n",
      " -0.08852495 -0.7159529  -1.3758937  -0.10135207 -0.6798086  -1.4525379\n",
      "  0.03519589 -0.7153151  -1.4638599  -0.05453257 -0.545318   -1.249712\n",
      " -0.22183023 -0.3051797  -2.0187492  -0.03472895 -0.4853955  -2.045906\n",
      "  0.13970548 -0.44147608 -1.3336768  -0.18230279 -0.31544518 -1.1669536\n",
      " -0.11497317 -0.28298584 -1.2540272  -0.08433278 -0.28469083 -1.363255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.02994648 -0.29750496 -1.1611731 ]\n",
      "data: [ 0.01161902 -0.10150626 -0.16938762  0.04399347 -0.20451166 -0.45262778\n",
      " -0.10740155 -0.44534987 -1.3278879  -0.26587224 -0.51640606 -1.6129539\n",
      " -0.41139832 -0.60463154 -2.133138   -0.18137434 -0.7485421  -1.5121411\n",
      " -0.01605096 -0.8242189  -1.359814   -0.07061887 -0.7473978  -1.4076535\n",
      " -0.08365624 -0.9202711  -1.5324342  -0.13771072 -0.6615418  -1.4083054\n",
      " -0.08852495 -0.71595293 -1.3758937  -0.10135207 -0.6798087  -1.4525379\n",
      "  0.03519589 -0.7153151  -1.4638599  -0.05453257 -0.545318   -1.249712\n",
      " -0.22183023 -0.3051797  -2.0187492  -0.03472895 -0.48539552 -2.045906\n",
      "  0.13970548 -0.44147605 -1.3336768  -0.18230277 -0.31544518 -1.1669536\n",
      " -0.11497317 -0.28298584 -1.2540272  -0.08433278 -0.28469083 -1.363255\n",
      "  0.02994648 -0.29750496 -1.1611731   0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[-4.5275e-02,  4.9877e-03, -2.0802e-01,  ...,  8.5229e-04,\n",
      "         -1.8313e-01, -1.1819e+00],\n",
      "        [-4.5275e-02,  4.9877e-03, -2.0802e-01,  ...,  8.5229e-04,\n",
      "         -1.8313e-01, -1.1819e+00],\n",
      "        [-4.5275e-02,  4.9877e-03, -2.0802e-01,  ...,  8.5229e-04,\n",
      "         -1.8313e-01, -1.1819e+00],\n",
      "        ...,\n",
      "        [-1.8381e-01,  3.2847e-01,  1.6680e-02,  ..., -6.6333e-01,\n",
      "          9.1168e-01, -3.6608e-01],\n",
      "        [-1.0052e-01, -1.0788e-01,  5.8840e-01,  ..., -2.3807e-01,\n",
      "          5.8078e-01,  2.5969e-01],\n",
      "        [-1.0052e-01, -1.0788e-01,  5.8840e-01,  ..., -2.3807e-01,\n",
      "          5.8078e-01,  2.5969e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-4.52751331e-02  4.98770364e-03 -2.08019689e-01 -2.12291293e-02\n",
      " -1.05974615e-01 -5.05237401e-01 -1.56887576e-01 -3.28140259e-01\n",
      " -1.34534800e+00 -3.11975121e-01 -3.90600741e-01 -1.63933420e+00\n",
      " -4.73405182e-01 -4.91414309e-01 -2.13744593e+00 -2.48081461e-01\n",
      " -6.30874217e-01 -1.51511014e+00 -5.05636334e-02 -6.86444581e-01\n",
      " -1.33768821e+00 -9.87808257e-02 -6.13001466e-01 -1.38692105e+00\n",
      " -9.39136297e-02 -7.71586359e-01 -1.51655793e+00 -2.01142281e-01\n",
      " -5.36046326e-01 -1.41270065e+00 -1.29853368e-01 -5.88849723e-01\n",
      " -1.38603210e+00 -1.22440509e-01 -5.51289082e-01 -1.47291040e+00\n",
      "  3.48831117e-02 -5.85999310e-01 -1.50007498e+00 -1.07742377e-01\n",
      " -4.28134561e-01 -1.24404871e+00 -2.61707485e-01 -1.86525837e-01\n",
      " -2.00199223e+00 -6.15230352e-02 -3.61850798e-01 -2.02083921e+00\n",
      "  1.34223729e-01 -3.18446577e-01 -1.35785973e+00 -2.34505758e-01\n",
      " -1.92858189e-01 -1.16422260e+00 -1.53533489e-01 -1.63309351e-01\n",
      " -1.25160420e+00 -1.13351122e-01 -1.69673219e-01 -1.36884916e+00\n",
      "  8.52294266e-04 -1.83131427e-01 -1.18189025e+00]\n",
      "data: [-4.52751368e-02  4.98770364e-03 -2.08019689e-01 -2.12291293e-02\n",
      " -1.05974615e-01 -5.05237401e-01 -1.56887576e-01 -3.28140259e-01\n",
      " -1.34534800e+00 -3.11975121e-01 -3.90600741e-01 -1.63933420e+00\n",
      " -4.73405182e-01 -4.91414309e-01 -2.13744593e+00 -2.48081461e-01\n",
      " -6.30874217e-01 -1.51511014e+00 -5.05636297e-02 -6.86444521e-01\n",
      " -1.33768809e+00 -9.87808257e-02 -6.13001466e-01 -1.38692105e+00\n",
      " -9.39136297e-02 -7.71586359e-01 -1.51655793e+00 -2.01142266e-01\n",
      " -5.36046326e-01 -1.41270065e+00 -1.29853368e-01 -5.88849723e-01\n",
      " -1.38603210e+00 -1.22440509e-01 -5.51289082e-01 -1.47291040e+00\n",
      "  3.48831117e-02 -5.85999310e-01 -1.50007486e+00 -1.07742377e-01\n",
      " -4.28134561e-01 -1.24404871e+00 -2.61707485e-01 -1.86525837e-01\n",
      " -2.00199223e+00 -6.15230352e-02 -3.61850828e-01 -2.02083921e+00\n",
      "  1.34223729e-01 -3.18446577e-01 -1.35785985e+00 -2.34505743e-01\n",
      " -1.92858174e-01 -1.16422260e+00 -1.53533489e-01 -1.63309351e-01\n",
      " -1.25160420e+00 -1.13351129e-01 -1.69673219e-01 -1.36884916e+00\n",
      "  8.52294266e-04 -1.83131427e-01 -1.18189025e+00  1.70000002e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[-0.0129, -0.0862, -0.1910,  ...,  0.0065, -0.2418, -1.3167],\n",
      "        [-0.0129, -0.0862, -0.1910,  ...,  0.0065, -0.2418, -1.3167],\n",
      "        [-0.0129, -0.0862, -0.1910,  ...,  0.0065, -0.2418, -1.3167],\n",
      "        ...,\n",
      "        [-0.2810,  0.3271, -0.2271,  ..., -0.7754,  0.7892, -0.4094],\n",
      "        [-0.1947, -0.1115,  0.5114,  ..., -0.2907,  0.6281,  0.2555],\n",
      "        [-0.1947, -0.1115,  0.5114,  ..., -0.2907,  0.6281,  0.2555]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01293548 -0.08616158 -0.19099958  0.00233452 -0.24991387 -0.6654668\n",
      " -0.03392708 -0.38915497 -1.3341639  -0.17272905 -0.43889868 -1.6457642\n",
      " -0.35559756 -0.5769253  -2.1060114  -0.23951985 -0.65964997 -1.496665\n",
      "  0.04729854 -0.6517259  -1.2642229  -0.00348477 -0.6001809  -1.3150786\n",
      " -0.0056577  -0.68921924 -1.4316676  -0.19420226 -0.5415384  -1.4230345\n",
      " -0.07326676 -0.5952524  -1.4188854  -0.07035038 -0.5621864  -1.5291986\n",
      "  0.05275446 -0.5877898  -1.608901   -0.08556502 -0.47265917 -1.2440338\n",
      " -0.16211501 -0.2438476  -1.7631187  -0.02733286 -0.3821156  -1.7380269\n",
      "  0.11514717 -0.34941965 -1.462751   -0.1879636  -0.22556108 -1.1965119\n",
      " -0.0824239  -0.20609805 -1.2740413  -0.0261928  -0.23774974 -1.398045\n",
      "  0.00646745 -0.24176735 -1.3166628 ]\n",
      "data: [-0.01293548 -0.08616158 -0.19099958  0.00233452 -0.24991387 -0.6654668\n",
      " -0.03392708 -0.38915497 -1.334164   -0.17272906 -0.43889868 -1.6457641\n",
      " -0.3555976  -0.5769253  -2.1060114  -0.23951985 -0.65964997 -1.496665\n",
      "  0.04729854 -0.65172595 -1.2642229  -0.00348477 -0.6001809  -1.3150786\n",
      " -0.0056577  -0.68921924 -1.4316677  -0.19420224 -0.5415384  -1.4230345\n",
      " -0.07326676 -0.5952524  -1.4188854  -0.07035038 -0.5621864  -1.5291986\n",
      "  0.05275446 -0.5877898  -1.608901   -0.08556502 -0.4726592  -1.2440338\n",
      " -0.16211501 -0.2438476  -1.7631187  -0.02733286 -0.3821156  -1.7380269\n",
      "  0.11514717 -0.34941968 -1.462751   -0.1879636  -0.22556108 -1.1965119\n",
      " -0.0824239  -0.20609803 -1.2740413  -0.0261928  -0.23774976 -1.398045\n",
      "  0.00646745 -0.24176735 -1.3166628   0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[ 0.0289, -0.1397, -0.2842,  ...,  0.0359, -0.3068, -1.3549],\n",
      "        [ 0.0289, -0.1397, -0.2842,  ...,  0.0359, -0.3068, -1.3549],\n",
      "        [ 0.0289, -0.1397, -0.2842,  ...,  0.0359, -0.3068, -1.3549],\n",
      "        ...,\n",
      "        [-0.1457,  0.4959, -0.1226,  ..., -0.7337,  1.0270, -0.4277],\n",
      "        [-0.1346,  0.0036,  0.6783,  ..., -0.2558,  0.7868,  0.3231],\n",
      "        [-0.1346,  0.0036,  0.6783,  ..., -0.2558,  0.7868,  0.3231]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02887894 -0.13969381 -0.2841589   0.06031522 -0.27013916 -0.6964988\n",
      " -0.03581865 -0.46394864 -1.4745903  -0.17804566 -0.525068   -1.7712995\n",
      " -0.32741365 -0.6281934  -2.266608   -0.17105725 -0.74591446 -1.6445297\n",
      "  0.0370397  -0.78090453 -1.4659113  -0.0148375  -0.7187002  -1.5204043\n",
      " -0.03075027 -0.8562783  -1.642901   -0.13181096 -0.6461954  -1.55491\n",
      " -0.05667228 -0.6986165  -1.5342062  -0.07190858 -0.66599905 -1.6238704\n",
      "  0.05082641 -0.6982244  -1.6664776  -0.04622811 -0.54739463 -1.3864366\n",
      " -0.17391291 -0.31427774 -2.0509005  -0.01478708 -0.47368678 -2.0587204\n",
      "  0.13304126 -0.43616286 -1.5231029  -0.1555275  -0.31485063 -1.3141557\n",
      " -0.07829446 -0.2835114  -1.3888729  -0.03738826 -0.29529834 -1.5060043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.03588054 -0.3068446  -1.3549037 ]\n",
      "data: [ 0.02887894 -0.13969381 -0.2841589   0.06031522 -0.27013916 -0.6964988\n",
      " -0.03581865 -0.46394864 -1.4745903  -0.17804566 -0.525068   -1.7712995\n",
      " -0.32741365 -0.6281934  -2.266608   -0.17105727 -0.74591446 -1.6445297\n",
      "  0.0370397  -0.78090453 -1.4659113  -0.0148375  -0.7187002  -1.5204043\n",
      " -0.03075027 -0.8562783  -1.642901   -0.13181096 -0.64619535 -1.55491\n",
      " -0.05667228 -0.6986165  -1.534206   -0.07190858 -0.66599905 -1.6238704\n",
      "  0.05082641 -0.6982244  -1.6664776  -0.04622811 -0.54739463 -1.3864366\n",
      " -0.17391291 -0.31427774 -2.0509005  -0.01478708 -0.47368678 -2.0587204\n",
      "  0.13304126 -0.43616286 -1.5231029  -0.1555275  -0.31485063 -1.3141557\n",
      " -0.07829446 -0.2835114  -1.3888729  -0.03738826 -0.29529834 -1.5060043\n",
      "  0.03588054 -0.3068446  -1.3549037   0.19      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FC50>\n",
      "tensor([[ 0.0112, -0.0977, -0.2234,  ...,  0.0524, -0.2787, -1.3026],\n",
      "        [ 0.0112, -0.0977, -0.2234,  ...,  0.0524, -0.2787, -1.3026],\n",
      "        [ 0.0112, -0.0977, -0.2234,  ...,  0.0524, -0.2787, -1.3026],\n",
      "        ...,\n",
      "        [-0.1421,  0.4689, -0.1453,  ..., -0.8235,  0.9658, -0.3905],\n",
      "        [-0.1153, -0.0810,  0.5647,  ..., -0.1959,  0.6285,  0.2374],\n",
      "        [-0.1153, -0.0810,  0.5647,  ..., -0.1959,  0.6285,  0.2374]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01116294 -0.09773988 -0.2233786   0.02391948 -0.25376058 -0.659579\n",
      " -0.00671173 -0.41911578 -1.3733609  -0.14740062 -0.47184873 -1.7046274\n",
      " -0.33712274 -0.6200443  -2.1598668  -0.21230908 -0.6809305  -1.5637126\n",
      "  0.08935295 -0.694084   -1.3465967   0.02400428 -0.65068024 -1.3920867\n",
      "  0.02649561 -0.76226836 -1.5121745  -0.15399921 -0.55995744 -1.464362\n",
      " -0.03733712 -0.6280211  -1.4547523  -0.03349166 -0.61118376 -1.5690241\n",
      "  0.07510632 -0.6524685  -1.6394346  -0.03535705 -0.47891074 -1.2721862\n",
      " -0.14616634 -0.25819677 -1.8840928   0.00776023 -0.42502737 -1.8597107\n",
      "  0.1544527  -0.38992035 -1.4653195  -0.15570788 -0.23235674 -1.2138156\n",
      " -0.03257193 -0.22423926 -1.2842914   0.01962624 -0.2729988  -1.4009775\n",
      "  0.05236875 -0.27866948 -1.302626  ]\n",
      "data: [ 0.01116294 -0.09773988 -0.2233786   0.02391948 -0.25376058 -0.65957904\n",
      " -0.00671173 -0.41911578 -1.3733609  -0.14740062 -0.47184873 -1.7046274\n",
      " -0.33712274 -0.6200443  -2.1598668  -0.21230908 -0.6809305  -1.5637126\n",
      "  0.08935295 -0.694084   -1.3465967   0.02400428 -0.65068024 -1.3920867\n",
      "  0.0264956  -0.76226836 -1.5121745  -0.15399921 -0.55995744 -1.464362\n",
      " -0.03733712 -0.6280211  -1.4547523  -0.03349166 -0.61118376 -1.5690241\n",
      "  0.07510632 -0.6524685  -1.6394345  -0.03535705 -0.47891074 -1.2721862\n",
      " -0.14616634 -0.25819677 -1.8840928   0.00776023 -0.4250274  -1.8597107\n",
      "  0.1544527  -0.38992035 -1.4653195  -0.15570788 -0.23235674 -1.2138156\n",
      " -0.03257193 -0.22423926 -1.2842914   0.01962624 -0.2729988  -1.4009775\n",
      "  0.05236875 -0.27866948 -1.302626    0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[ 0.0259, -0.1042, -0.2516,  ...,  0.0540, -0.2881, -1.3168],\n",
      "        [ 0.0259, -0.1042, -0.2516,  ...,  0.0540, -0.2881, -1.3168],\n",
      "        [ 0.0259, -0.1042, -0.2516,  ...,  0.0540, -0.2881, -1.3168],\n",
      "        ...,\n",
      "        [-0.1856,  0.4437, -0.1490,  ..., -0.7171,  0.9419, -0.4367],\n",
      "        [-0.1887, -0.1157,  0.6227,  ..., -0.2596,  0.6527,  0.2752],\n",
      "        [-0.1887, -0.1157,  0.6227,  ..., -0.2596,  0.6527,  0.2752]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02588347 -0.10417892 -0.25157315  0.04169027 -0.2519546  -0.6773747\n",
      " -0.03918517 -0.44254965 -1.4262443  -0.1807177  -0.50630873 -1.7258308\n",
      " -0.35155576 -0.6280795  -2.1895545  -0.18370488 -0.7131373  -1.5903127\n",
      "  0.0489249  -0.74660087 -1.381367   -0.00441311 -0.6863876  -1.4312525\n",
      " -0.00962619 -0.8157153  -1.5475552  -0.13690403 -0.6016119  -1.5024488\n",
      " -0.05054782 -0.6606753  -1.476176   -0.05678135 -0.63718057 -1.5677941\n",
      "  0.06647419 -0.6634749  -1.6183529  -0.04046439 -0.5155306  -1.331042\n",
      " -0.15661544 -0.29012728 -1.9589643  -0.00374021 -0.44941157 -1.951833\n",
      "  0.1482957  -0.41050255 -1.4732754  -0.14864641 -0.2749883  -1.2652261\n",
      " -0.06069051 -0.254005   -1.3459289  -0.01116986 -0.27684313 -1.4593089\n",
      "  0.05399385 -0.2881008  -1.316798  ]\n",
      "data: [ 0.07 -5.18  4.36 -0.07 -4.86  4.42 -0.09 -4.34  4.07 -0.25 -4.17  5.19\n",
      " -0.37 -4.11  6.12  0.1  -4.29  4.91  0.03 -4.03  5.43 -0.13 -3.99  6.02\n",
      " -0.25 -4.    6.13  0.23 -4.36  4.88  0.14 -4.06  5.19  0.   -4.05  5.53\n",
      " -0.14 -4.14  5.85  0.24 -4.48  5.17  0.    0.    0.    0.14 -4.12  4.96\n",
      " -0.02 -4.24  5.38  0.24 -4.58  5.15  0.22 -4.37  5.34  0.19 -4.27  4.96\n",
      "  0.13 -4.26  4.91  0.  ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[-0.1313,  0.2668, -0.3321,  ..., -0.4889,  0.2409, -1.0635],\n",
      "        [-0.1313,  0.2668, -0.3321,  ..., -0.4889,  0.2409, -1.0635],\n",
      "        [-0.1313,  0.2668, -0.3321,  ..., -0.4889,  0.2409, -1.0635],\n",
      "        ...,\n",
      "        [ 0.5644, -0.4018,  0.0255,  ...,  0.6400, -1.0223,  0.5235],\n",
      "        [ 0.1801,  0.1892,  0.5448,  ...,  0.4550, -0.4193,  2.6268],\n",
      "        [ 0.1801,  0.1892,  0.5448,  ...,  0.4550, -0.4193,  2.6268]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.13131122  0.26684088 -0.3321457  -0.20357439  0.17586857 -0.8251105\n",
      " -0.13206083  0.19812423 -0.96739686 -0.12470044  0.16002871 -0.98988044\n",
      " -0.14350963  0.08384265 -1.055459   -0.3185823   0.13467434 -1.2187941\n",
      " -0.08369426  0.17409024 -0.6864928  -0.22920217  0.02708977 -0.69133997\n",
      " -0.3637696   0.08694395 -0.80460584 -0.35110754  0.20040882 -1.2635796\n",
      " -0.39429605  0.15287791 -1.3545265  -0.47969204  0.11543077 -1.3646631\n",
      " -0.5790258  -0.02553907 -1.3210701  -0.37057632  0.24490364 -1.2015908\n",
      " -0.52419937  0.28540665 -1.5145547  -0.5272008   0.21424055 -1.5244136\n",
      " -0.55760914  0.10447921 -1.1829424  -0.40608367  0.3679836  -1.0490392\n",
      " -0.36844307  0.31105953 -1.0949754  -0.45909768  0.29299983 -1.1147907\n",
      " -0.48891163  0.24086948 -1.0635377 ]\n",
      "init: [-0.13131122  0.26684088 -0.3321457  -0.20357439  0.17586857 -0.8251105\n",
      " -0.13206083  0.19812423 -0.96739686 -0.12470044  0.16002871 -0.98988044\n",
      " -0.14350963  0.08384265 -1.055459   -0.3185823   0.13467434 -1.2187941\n",
      " -0.08369426  0.17409024 -0.6864928  -0.22920217  0.02708977 -0.69133997\n",
      " -0.3637696   0.08694395 -0.80460584 -0.35110754  0.20040882 -1.2635796\n",
      " -0.39429605  0.15287791 -1.3545265  -0.47969204  0.11543077 -1.3646631\n",
      " -0.5790258  -0.02553907 -1.3210701  -0.37057632  0.24490364 -1.2015908\n",
      " -0.52419937  0.28540665 -1.5145547  -0.5272008   0.21424055 -1.5244136\n",
      " -0.55760914  0.10447921 -1.1829424  -0.40608367  0.3679836  -1.0490392\n",
      " -0.36844307  0.31105953 -1.0949754  -0.45909768  0.29299983 -1.1147907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.48891163  0.24086948 -1.0635377 ]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [-0.13131122  0.26684088 -0.3321457  -0.20357439  0.17586857 -0.8251105\n",
      " -0.13206083  0.19812423 -0.96739686 -0.12470044  0.16002871 -0.98988044\n",
      " -0.14350963  0.08384265 -1.055459   -0.3185823   0.13467434 -1.2187941\n",
      " -0.08369426  0.17409024 -0.68649274 -0.22920218  0.02708977 -0.69133997\n",
      " -0.36376962  0.08694395 -0.80460584 -0.3511075   0.20040882 -1.2635796\n",
      " -0.39429605  0.15287791 -1.3545265  -0.47969204  0.11543077 -1.3646631\n",
      " -0.5790258  -0.02553907 -1.3210701  -0.37057632  0.24490364 -1.2015908\n",
      " -0.52419937  0.28540665 -1.5145547  -0.5272008   0.21424055 -1.5244136\n",
      " -0.55760914  0.10447921 -1.1829424  -0.40608367  0.36798364 -1.0490392\n",
      " -0.36844307  0.31105953 -1.0949754  -0.45909768  0.29299983 -1.1147907\n",
      " -0.48891163  0.24086948 -1.0635377   0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0780, -0.4615, -0.1435,  ...,  0.1161, -0.5943, -1.3255],\n",
      "        [ 0.0780, -0.4615, -0.1435,  ...,  0.1161, -0.5943, -1.3255],\n",
      "        [ 0.0780, -0.4615, -0.1435,  ...,  0.1161, -0.5943, -1.3255],\n",
      "        ...,\n",
      "        [ 0.1827,  0.9463, -0.6333,  ..., -0.4682,  1.3564, -0.2478],\n",
      "        [-0.3769,  0.1389,  0.3689,  ..., -0.6832,  0.9041,  0.0694],\n",
      "        [-0.3769,  0.1389,  0.3689,  ..., -0.6832,  0.9041,  0.0694]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.07797337 -0.46151918 -0.14351742  0.12669742 -0.5956478  -0.64614195\n",
      "  0.08706301 -0.694955   -1.29885    -0.0344871  -0.70765066 -1.5677675\n",
      " -0.14371414 -0.8217268  -2.0552423  -0.10910903 -1.0037204  -1.399955\n",
      "  0.15067019 -0.9633715  -1.2277076   0.10391927 -0.85796875 -1.2895536\n",
      "  0.08775273 -0.9180926  -1.3999715  -0.08570549 -0.9230405  -1.3617578\n",
      "  0.04230224 -0.9196608  -1.3961233   0.04116368 -0.8308356  -1.4535825\n",
      "  0.13257083 -0.83789337 -1.507941    0.03103743 -0.8661082  -1.2229435\n",
      " -0.01292143 -0.5865034  -1.6621457   0.10185961 -0.70573616 -1.6323248\n",
      "  0.20086071 -0.63387704 -1.4651016  -0.06906918 -0.65462786 -1.1843313\n",
      "  0.03713952 -0.59885406 -1.3085859   0.08377418 -0.60624504 -1.4309857\n",
      "  0.11612727 -0.5942701  -1.3255041 ]\n",
      "data: [ 0.07797337 -0.46151915 -0.14351742  0.12669742 -0.5956478  -0.64614195\n",
      "  0.08706301 -0.694955   -1.29885    -0.0344871  -0.70765066 -1.5677675\n",
      " -0.14371414 -0.82172686 -2.0552423  -0.10910903 -1.0037204  -1.399955\n",
      "  0.15067019 -0.9633715  -1.2277076   0.10391927 -0.85796875 -1.2895536\n",
      "  0.08775273 -0.91809255 -1.3999715  -0.08570549 -0.92304057 -1.3617578\n",
      "  0.04230224 -0.9196608  -1.3961234   0.04116368 -0.8308356  -1.4535824\n",
      "  0.13257083 -0.83789337 -1.507941    0.03103743 -0.8661082  -1.2229435\n",
      " -0.01292143 -0.5865034  -1.6621457   0.10185961 -0.70573616 -1.6323248\n",
      "  0.20086071 -0.63387704 -1.4651016  -0.06906918 -0.65462786 -1.1843313\n",
      "  0.03713952 -0.59885406 -1.3085858   0.08377418 -0.60624504 -1.4309857\n",
      "  0.11612727 -0.5942701  -1.325504    0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F828>\n",
      "tensor([[ 0.0889, -0.1151, -0.2429,  ..., -0.0232, -0.3031, -1.3155],\n",
      "        [ 0.0889, -0.1151, -0.2429,  ..., -0.0232, -0.3031, -1.3155],\n",
      "        [ 0.0889, -0.1151, -0.2429,  ..., -0.0232, -0.3031, -1.3155],\n",
      "        ...,\n",
      "        [-0.2314,  0.2979,  0.0766,  ..., -0.2975,  0.8261, -0.3997],\n",
      "        [-0.0384, -0.1331,  0.6428,  ...,  0.1266,  0.4924,  0.2279],\n",
      "        [-0.0384, -0.1331,  0.6428,  ...,  0.1266,  0.4924,  0.2279]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.08890659 -0.11509757 -0.24287666  0.0524612  -0.2553821  -0.6037266\n",
      " -0.09238604 -0.48585334 -1.4098663  -0.2666728  -0.55822265 -1.6996529\n",
      " -0.48684442 -0.631822   -2.1948977  -0.15089394 -0.76102674 -1.6267493\n",
      " -0.0658737  -0.83891654 -1.503622   -0.10760312 -0.7472695  -1.556053\n",
      " -0.0828775  -0.93119276 -1.646802   -0.12086122 -0.6435946  -1.5370518\n",
      " -0.09998924 -0.69380164 -1.4559522  -0.1352484  -0.69712496 -1.5598042\n",
      "  0.00990142 -0.66984856 -1.5684116  -0.05879907 -0.5489265  -1.4072291\n",
      " -0.20421018 -0.35785523 -2.0388932  -0.08429523 -0.4995473  -2.0606668\n",
      "  0.08079307 -0.46696362 -1.4384658  -0.15413491 -0.31387234 -1.3338099\n",
      " -0.14950965 -0.30446115 -1.4110918  -0.13333073 -0.29392335 -1.5124625\n",
      " -0.02322017 -0.3031497  -1.3155193 ]\n",
      "data: [ 0.08890659 -0.11509757 -0.24287666  0.0524612  -0.2553821  -0.6037266\n",
      " -0.09238604 -0.48585334 -1.4098663  -0.2666728  -0.55822265 -1.6996529\n",
      " -0.48684442 -0.631822   -2.1948977  -0.15089394 -0.76102674 -1.6267493\n",
      " -0.0658737  -0.83891654 -1.5036222  -0.10760312 -0.7472695  -1.556053\n",
      " -0.0828775  -0.93119276 -1.646802   -0.12086122 -0.64359456 -1.5370518\n",
      " -0.09998924 -0.69380164 -1.4559522  -0.1352484  -0.69712496 -1.5598042\n",
      "  0.00990142 -0.66984856 -1.5684116  -0.05879907 -0.5489265  -1.407229\n",
      " -0.20421019 -0.35785523 -2.0388932  -0.08429523 -0.4995473  -2.0606668\n",
      "  0.08079307 -0.46696362 -1.4384658  -0.15413491 -0.31387234 -1.3338099\n",
      " -0.14950965 -0.30446115 -1.4110918  -0.13333073 -0.29392335 -1.5124625\n",
      " -0.02322017 -0.3031497  -1.3155195   0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0186, -0.0374, -0.1240,  ...,  0.1098, -0.2513, -1.0896],\n",
      "        [ 0.0186, -0.0374, -0.1240,  ...,  0.1098, -0.2513, -1.0896],\n",
      "        [ 0.0186, -0.0374, -0.1240,  ...,  0.1098, -0.2513, -1.0896],\n",
      "        ...,\n",
      "        [-0.1478,  0.3676, -0.0648,  ..., -1.0061,  0.9566, -0.4229],\n",
      "        [-0.1304, -0.1395,  0.4743,  ..., -0.2698,  0.4997,  0.1553],\n",
      "        [-0.1304, -0.1395,  0.4743,  ..., -0.2698,  0.4997,  0.1553]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01859073 -0.03741525 -0.12398805  0.03769226 -0.16221449 -0.4436254\n",
      " -0.04447546 -0.35830164 -1.2470963  -0.18617155 -0.4155643  -1.5626894\n",
      " -0.36633107 -0.54859287 -2.0296354  -0.18646654 -0.6459663  -1.4305701\n",
      "  0.07635118 -0.6817394  -1.2476158   0.01933715 -0.6299746  -1.2903587\n",
      "  0.0428519  -0.770414   -1.4174303  -0.12684838 -0.5398508  -1.3205329\n",
      " -0.02188656 -0.6069093  -1.3016521  -0.00301179 -0.5849774  -1.4020959\n",
      "  0.14103542 -0.6345351  -1.4530712  -0.01495729 -0.44996452 -1.1294067\n",
      " -0.15734895 -0.21978481 -1.8792238   0.04646978 -0.40573555 -1.87558\n",
      "  0.23506042 -0.36881787 -1.2759765  -0.1449479  -0.21022728 -1.0542012\n",
      " -0.02613071 -0.2014002  -1.1277299   0.02593949 -0.23562635 -1.2461511\n",
      "  0.10978905 -0.2512817  -1.0895762 ]\n",
      "data: [ 0.01859073 -0.03741525 -0.12398805  0.03769226 -0.16221449 -0.44362536\n",
      " -0.04447546 -0.3583016  -1.2470963  -0.18617155 -0.4155643  -1.5626893\n",
      " -0.36633107 -0.54859287 -2.0296354  -0.18646654 -0.6459663  -1.4305701\n",
      "  0.07635118 -0.68173945 -1.2476158   0.01933715 -0.6299746  -1.2903588\n",
      "  0.0428519  -0.770414   -1.4174303  -0.12684838 -0.5398508  -1.320533\n",
      " -0.02188656 -0.6069093  -1.3016521  -0.00301179 -0.5849774  -1.4020959\n",
      "  0.14103542 -0.6345351  -1.4530712  -0.01495729 -0.44996452 -1.1294067\n",
      " -0.15734895 -0.21978481 -1.8792238   0.04646978 -0.40573555 -1.87558\n",
      "  0.23506042 -0.36881787 -1.2759765  -0.1449479  -0.21022728 -1.0542012\n",
      " -0.0261307  -0.2014002  -1.1277299   0.02593949 -0.23562635 -1.2461511\n",
      "  0.10978904 -0.2512817  -1.0895762   0.04      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0024, -0.0525, -0.2105,  ...,  0.0323, -0.2359, -1.2378],\n",
      "        [ 0.0024, -0.0525, -0.2105,  ...,  0.0323, -0.2359, -1.2378],\n",
      "        [ 0.0024, -0.0525, -0.2105,  ...,  0.0323, -0.2359, -1.2378],\n",
      "        ...,\n",
      "        [-0.2827,  0.3230, -0.2540,  ..., -0.5575,  0.8512, -0.5883],\n",
      "        [-0.1310,  0.0399,  0.5800,  ..., -0.2716,  0.8063,  0.1938],\n",
      "        [-0.1310,  0.0399,  0.5800,  ..., -0.2716,  0.8063,  0.1938]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.4004402e-03 -5.2469276e-02 -2.1054636e-01  2.6526649e-02\n",
      " -1.7794006e-01 -5.7041180e-01 -9.1079108e-02 -3.7996998e-01\n",
      " -1.3713770e+00 -2.4366844e-01 -4.4257858e-01 -1.6695242e+00\n",
      " -4.1144875e-01 -5.4738533e-01 -2.1591682e+00 -2.0135695e-01\n",
      " -6.6872448e-01 -1.5461018e+00 -8.2470477e-04 -7.1315563e-01\n",
      " -1.3542540e+00 -5.1776797e-02 -6.4109546e-01 -1.4085841e+00\n",
      " -5.7836205e-02 -7.9193044e-01 -1.5305657e+00 -1.5649363e-01\n",
      " -5.6780940e-01 -1.4525318e+00 -8.7443843e-02 -6.2127447e-01\n",
      " -1.4252136e+00 -9.7230442e-02 -5.9454203e-01 -1.5150588e+00\n",
      "  4.3931529e-02 -6.1822355e-01 -1.5518646e+00 -6.7890383e-02\n",
      " -4.7624803e-01 -1.2789280e+00 -2.0502383e-01 -2.3562121e-01\n",
      " -1.9840479e+00 -3.4859635e-02 -4.0451497e-01 -1.9921229e+00\n",
      "  1.3563344e-01 -3.6548841e-01 -1.4002976e+00 -1.7998061e-01\n",
      " -2.4017937e-01 -1.2080982e+00 -1.0736729e-01 -2.1215096e-01\n",
      " -1.2917194e+00 -6.3581526e-02 -2.2025593e-01 -1.4094305e+00\n",
      "  3.2285742e-02 -2.3589696e-01 -1.2377837e+00]\n",
      "data: [ 2.4004402e-03 -5.2469276e-02 -2.1054636e-01  2.6526649e-02\n",
      " -1.7794007e-01 -5.7041180e-01 -9.1079108e-02 -3.7996998e-01\n",
      " -1.3713770e+00 -2.4366844e-01 -4.4257858e-01 -1.6695242e+00\n",
      " -4.1144875e-01 -5.4738533e-01 -2.1591682e+00 -2.0135695e-01\n",
      " -6.6872442e-01 -1.5461018e+00 -8.2470477e-04 -7.1315557e-01\n",
      " -1.3542540e+00 -5.1776797e-02 -6.4109540e-01 -1.4085841e+00\n",
      " -5.7836205e-02 -7.9193044e-01 -1.5305657e+00 -1.5649363e-01\n",
      " -5.6780940e-01 -1.4525317e+00 -8.7443851e-02 -6.2127447e-01\n",
      " -1.4252136e+00 -9.7230442e-02 -5.9454203e-01 -1.5150588e+00\n",
      "  4.3931529e-02 -6.1822355e-01 -1.5518646e+00 -6.7890383e-02\n",
      " -4.7624803e-01 -1.2789280e+00 -2.0502383e-01 -2.3562123e-01\n",
      " -1.9840479e+00 -3.4859635e-02 -4.0451497e-01 -1.9921230e+00\n",
      "  1.3563344e-01 -3.6548841e-01 -1.4002976e+00 -1.7998061e-01\n",
      " -2.4017936e-01 -1.2080982e+00 -1.0736730e-01 -2.1215096e-01\n",
      " -1.2917193e+00 -6.3581526e-02 -2.2025593e-01 -1.4094305e+00\n",
      "  3.2285742e-02 -2.3589697e-01 -1.2377837e+00  5.0000001e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[ 0.0285, -0.0545, -0.2480,  ...,  0.0386, -0.2360, -1.2863],\n",
      "        [ 0.0285, -0.0545, -0.2480,  ...,  0.0386, -0.2360, -1.2863],\n",
      "        [ 0.0285, -0.0545, -0.2480,  ...,  0.0386, -0.2360, -1.2863],\n",
      "        ...,\n",
      "        [-0.1843,  0.3777, -0.0750,  ..., -0.8113,  0.8884, -0.3167],\n",
      "        [-0.1149, -0.1144,  0.6104,  ..., -0.2031,  0.6555,  0.2815],\n",
      "        [-0.1149, -0.1144,  0.6104,  ..., -0.2031,  0.6555,  0.2815]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.8459396e-02 -5.4488972e-02 -2.4800380e-01  5.0045643e-02\n",
      " -1.7730090e-01 -6.4191920e-01 -6.9005966e-02 -3.6683589e-01\n",
      " -1.4063766e+00 -2.1868089e-01 -4.2992967e-01 -1.6961807e+00\n",
      " -3.8071093e-01 -5.2237642e-01 -2.1898856e+00 -1.6701788e-01\n",
      " -6.7559183e-01 -1.5564665e+00  9.6565485e-04 -7.1718371e-01\n",
      " -1.3919774e+00 -4.7668070e-02 -6.4397162e-01 -1.4542314e+00\n",
      " -5.2519493e-02 -7.9607666e-01 -1.5734242e+00 -1.3015422e-01\n",
      " -5.8546150e-01 -1.4740049e+00 -6.8237454e-02 -6.3079369e-01\n",
      " -1.4448234e+00 -8.9785382e-02 -5.9989899e-01 -1.5393622e+00\n",
      "  5.1284522e-02 -6.1695057e-01 -1.5653751e+00 -5.7229303e-02\n",
      " -4.8896134e-01 -1.3116413e+00 -1.7718336e-01 -2.5883859e-01\n",
      " -1.9841636e+00 -2.1743134e-02 -4.0619928e-01 -2.0032353e+00\n",
      "  1.4226292e-01 -3.8070816e-01 -1.4348590e+00 -1.5431064e-01\n",
      " -2.5932565e-01 -1.2430301e+00 -9.8855093e-02 -2.3162575e-01\n",
      " -1.3352277e+00 -6.4983457e-02 -2.2382660e-01 -1.4555666e+00\n",
      "  3.8626187e-02 -2.3602596e-01 -1.2862610e+00]\n",
      "data: [ 2.8459396e-02 -5.4488972e-02 -2.4800378e-01  5.0045643e-02\n",
      " -1.7730089e-01 -6.4191920e-01 -6.9005966e-02 -3.6683589e-01\n",
      " -1.4063766e+00 -2.1868090e-01 -4.2992964e-01 -1.6961807e+00\n",
      " -3.8071096e-01 -5.2237642e-01 -2.1898856e+00 -1.6701788e-01\n",
      " -6.7559183e-01 -1.5564666e+00  9.6565485e-04 -7.1718371e-01\n",
      " -1.3919774e+00 -4.7668070e-02 -6.4397162e-01 -1.4542314e+00\n",
      " -5.2519493e-02 -7.9607666e-01 -1.5734242e+00 -1.3015422e-01\n",
      " -5.8546150e-01 -1.4740049e+00 -6.8237454e-02 -6.3079369e-01\n",
      " -1.4448235e+00 -8.9785382e-02 -5.9989899e-01 -1.5393622e+00\n",
      "  5.1284522e-02 -6.1695057e-01 -1.5653751e+00 -5.7229303e-02\n",
      " -4.8896134e-01 -1.3116413e+00 -1.7718336e-01 -2.5883859e-01\n",
      " -1.9841636e+00 -2.1743134e-02 -4.0619928e-01 -2.0032353e+00\n",
      "  1.4226292e-01 -3.8070816e-01 -1.4348590e+00 -1.5431064e-01\n",
      " -2.5932565e-01 -1.2430301e+00 -9.8855093e-02 -2.3162575e-01\n",
      " -1.3352276e+00 -6.4983457e-02 -2.2382660e-01 -1.4555668e+00\n",
      "  3.8626187e-02 -2.3602596e-01 -1.2862610e+00  5.9999999e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[ 0.0296, -0.0495, -0.2385,  ...,  0.0474, -0.2453, -1.2741],\n",
      "        [ 0.0296, -0.0495, -0.2385,  ...,  0.0474, -0.2453, -1.2741],\n",
      "        [ 0.0296, -0.0495, -0.2385,  ...,  0.0474, -0.2453, -1.2741],\n",
      "        ...,\n",
      "        [-0.1305,  0.3449, -0.0749,  ..., -0.7322,  0.8116, -0.2744],\n",
      "        [-0.1445, -0.1691,  0.5284,  ..., -0.2175,  0.5916,  0.2271],\n",
      "        [-0.1445, -0.1691,  0.5284,  ..., -0.2175,  0.5916,  0.2271]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.029555   -0.0494762  -0.23850775  0.04286772 -0.17893426 -0.6213522\n",
      " -0.06982951 -0.36702776 -1.3808866  -0.21867895 -0.43199095 -1.6698903\n",
      " -0.39102352 -0.5316111  -2.1565187  -0.1682101  -0.6683316  -1.5412889\n",
      "  0.00282039 -0.7100748  -1.3797472  -0.04392172 -0.6368667  -1.439258\n",
      " -0.03893005 -0.7865442  -1.5515081  -0.12860963 -0.57220376 -1.4598526\n",
      " -0.06302428 -0.6210793  -1.427733   -0.08189876 -0.59813845 -1.5226734\n",
      "  0.05917923 -0.6087167  -1.553519   -0.05222074 -0.4861949  -1.2983568\n",
      " -0.16619119 -0.2617968  -1.951499   -0.01628309 -0.40959597 -1.9630132\n",
      "  0.14600073 -0.38441697 -1.4189692  -0.14675501 -0.2551632  -1.2341659\n",
      " -0.08930446 -0.23479572 -1.3226897  -0.05112523 -0.23213163 -1.4392787\n",
      "  0.04740117 -0.24534042 -1.2740542 ]\n",
      "data: [ 0.029555   -0.0494762  -0.23850775  0.04286772 -0.17893428 -0.6213522\n",
      " -0.06982951 -0.36702773 -1.3808866  -0.21867895 -0.43199098 -1.6698903\n",
      " -0.39102352 -0.5316111  -2.1565187  -0.1682101  -0.6683316  -1.5412889\n",
      "  0.00282039 -0.7100748  -1.3797472  -0.04392172 -0.6368667  -1.439258\n",
      " -0.03893005 -0.7865442  -1.5515081  -0.12860963 -0.57220376 -1.4598526\n",
      " -0.06302428 -0.6210793  -1.427733   -0.08189876 -0.59813845 -1.5226734\n",
      "  0.05917923 -0.6087167  -1.553519   -0.05222074 -0.4861949  -1.2983568\n",
      " -0.16619119 -0.2617968  -1.951499   -0.01628309 -0.40959594 -1.9630132\n",
      "  0.14600073 -0.38441697 -1.4189692  -0.14675501 -0.2551632  -1.2341659\n",
      " -0.08930447 -0.23479572 -1.3226897  -0.05112523 -0.23213163 -1.4392787\n",
      "  0.04740117 -0.24534042 -1.2740542   0.07      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0250, -0.0656, -0.2523,  ...,  0.0402, -0.2551, -1.2855],\n",
      "        [ 0.0250, -0.0656, -0.2523,  ...,  0.0402, -0.2551, -1.2855],\n",
      "        [ 0.0250, -0.0656, -0.2523,  ...,  0.0402, -0.2551, -1.2855],\n",
      "        ...,\n",
      "        [-0.1196,  0.3698, -0.0673,  ..., -0.6800,  0.8633, -0.3295],\n",
      "        [-0.1328, -0.1385,  0.5663,  ..., -0.2342,  0.6484,  0.2230],\n",
      "        [-0.1328, -0.1385,  0.5663,  ..., -0.2342,  0.6484,  0.2230]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02498245 -0.06561577 -0.2523011   0.04632837 -0.18923333 -0.6485467\n",
      " -0.07177518 -0.3836341  -1.4238882  -0.21817046 -0.44930667 -1.7110274\n",
      " -0.37769383 -0.5434416  -2.2012362  -0.1681664  -0.68368745 -1.5755328\n",
      "  0.00298312 -0.7276396  -1.4017028  -0.04363105 -0.6549643  -1.4623301\n",
      " -0.04915162 -0.80658114 -1.5808403  -0.13119486 -0.59149003 -1.4907123\n",
      " -0.06915385 -0.6400418  -1.4572761  -0.09017872 -0.61262614 -1.5467426\n",
      "  0.05007503 -0.62917274 -1.5754932  -0.05732073 -0.49936077 -1.3274378\n",
      " -0.17798191 -0.27053803 -1.9962262  -0.02388521 -0.42122597 -2.0117934\n",
      "  0.13925189 -0.3945802  -1.438868   -0.15466207 -0.26963025 -1.2559501\n",
      " -0.09721903 -0.24320014 -1.3421671  -0.05951866 -0.23992534 -1.4581625\n",
      "  0.04024833 -0.2550931  -1.2854755 ]\n",
      "data: [ 0.02498245 -0.06561577 -0.2523011   0.04632837 -0.18923335 -0.6485467\n",
      " -0.07177518 -0.38363412 -1.4238882  -0.21817046 -0.44930667 -1.7110274\n",
      " -0.37769383 -0.5434416  -2.2012362  -0.16816638 -0.68368745 -1.5755328\n",
      "  0.00298312 -0.7276396  -1.4017028  -0.04363105 -0.65496427 -1.4623302\n",
      " -0.04915162 -0.80658114 -1.5808403  -0.13119486 -0.59149003 -1.4907123\n",
      " -0.06915385 -0.6400418  -1.4572761  -0.09017872 -0.61262614 -1.5467426\n",
      "  0.05007503 -0.62917274 -1.5754932  -0.05732073 -0.49936077 -1.3274378\n",
      " -0.17798191 -0.27053803 -1.9962262  -0.02388521 -0.42122597 -2.0117934\n",
      "  0.13925189 -0.3945802  -1.438868   -0.15466207 -0.26963025 -1.2559501\n",
      " -0.09721903 -0.24320012 -1.3421673  -0.05951866 -0.23992534 -1.4581625\n",
      "  0.04024834 -0.2550931  -1.2854755   0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F9B0>\n",
      "tensor([[ 0.0218, -0.0327, -0.2394,  ...,  0.0427, -0.2277, -1.2656],\n",
      "        [ 0.0218, -0.0327, -0.2394,  ...,  0.0427, -0.2277, -1.2656],\n",
      "        [ 0.0218, -0.0327, -0.2394,  ...,  0.0427, -0.2277, -1.2656],\n",
      "        ...,\n",
      "        [-0.1407,  0.3517, -0.0911,  ..., -0.7677,  0.8399, -0.3260],\n",
      "        [-0.1449, -0.1712,  0.5434,  ..., -0.2285,  0.5936,  0.2126],\n",
      "        [-0.1449, -0.1712,  0.5434,  ..., -0.2285,  0.5936,  0.2126]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02179097 -0.03273828 -0.23939703  0.03784536 -0.15938029 -0.62897956\n",
      " -0.06860159 -0.34693247 -1.3837492  -0.21421827 -0.4089015  -1.6764987\n",
      " -0.38128036 -0.50983506 -2.1591911  -0.17472701 -0.6479188  -1.539678\n",
      "  0.00614242 -0.68683606 -1.3751613  -0.04142439 -0.6165704  -1.4349756\n",
      " -0.03893708 -0.76508826 -1.5507035  -0.13460228 -0.5527167  -1.4549181\n",
      " -0.06604457 -0.6021432  -1.426331   -0.08255999 -0.5780206  -1.5207032\n",
      "  0.05567208 -0.5942672  -1.5541263  -0.05488571 -0.46339256 -1.2909824\n",
      " -0.17235088 -0.2389433  -1.9523554  -0.0182829  -0.38982737 -1.9630119\n",
      "  0.14306022 -0.3628508  -1.4157146  -0.15241042 -0.23418657 -1.2251278\n",
      " -0.08919218 -0.21253036 -1.3108704  -0.05113369 -0.21379818 -1.4277343\n",
      "  0.04274907 -0.22772795 -1.2656206 ]\n",
      "data: [ 0.02179097 -0.03273828 -0.23939703  0.03784536 -0.15938029 -0.62897956\n",
      " -0.06860159 -0.3469325  -1.3837492  -0.21421827 -0.4089015  -1.6764988\n",
      " -0.38128036 -0.50983506 -2.1591911  -0.17472701 -0.6479189  -1.5396781\n",
      "  0.00614242 -0.68683606 -1.3751613  -0.04142439 -0.6165704  -1.4349756\n",
      " -0.03893708 -0.76508826 -1.5507035  -0.13460228 -0.5527167  -1.4549183\n",
      " -0.06604457 -0.6021432  -1.426331   -0.08255999 -0.5780206  -1.5207031\n",
      "  0.05567208 -0.5942672  -1.5541263  -0.05488571 -0.46339256 -1.2909824\n",
      " -0.17235088 -0.2389433  -1.9523554  -0.0182829  -0.38982737 -1.963012\n",
      "  0.14306022 -0.3628508  -1.4157146  -0.15241042 -0.23418657 -1.2251278\n",
      " -0.08919218 -0.21253036 -1.3108704  -0.05113369 -0.21379818 -1.4277343\n",
      "  0.04274907 -0.22772795 -1.2656206   0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0200, -0.0629, -0.2471,  ...,  0.0342, -0.2463, -1.2989],\n",
      "        [ 0.0200, -0.0629, -0.2471,  ...,  0.0342, -0.2463, -1.2989],\n",
      "        [ 0.0200, -0.0629, -0.2471,  ...,  0.0342, -0.2463, -1.2989],\n",
      "        ...,\n",
      "        [-0.3266,  0.1797, -0.3363,  ..., -0.8186,  0.6072, -0.4861],\n",
      "        [-0.0997, -0.0691,  0.5904,  ..., -0.2076,  0.7206,  0.2567],\n",
      "        [-0.0997, -0.0691,  0.5904,  ..., -0.2076,  0.7206,  0.2567]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02004509 -0.06286658 -0.2471314   0.04286398 -0.19991899 -0.6642761\n",
      " -0.0548116  -0.3806484  -1.4167211  -0.19646841 -0.44458267 -1.7053664\n",
      " -0.36009023 -0.5487107  -2.1868782  -0.17737004 -0.66775227 -1.5704575\n",
      "  0.01685742 -0.6984422  -1.3857539  -0.02994931 -0.6323887  -1.4433935\n",
      " -0.03464258 -0.76689506 -1.5578463  -0.1401363  -0.56761706 -1.4907548\n",
      " -0.06462499 -0.61858726 -1.4594417  -0.08415366 -0.59237707 -1.5512502\n",
      "  0.04850768 -0.6093323  -1.5929747  -0.06133769 -0.48444763 -1.3233259\n",
      " -0.16868186 -0.25810936 -1.9481716  -0.0243478  -0.40503535 -1.9522676\n",
      "  0.12711105 -0.377979   -1.4513297  -0.15572897 -0.25096804 -1.2588203\n",
      " -0.08965395 -0.22756363 -1.3364499  -0.04605635 -0.23231798 -1.4532113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.03424303 -0.24626745 -1.2988584 ]\n",
      "data: [ 0.02004509 -0.06286658 -0.2471314   0.04286398 -0.19991897 -0.6642761\n",
      " -0.05481161 -0.38064843 -1.416721   -0.19646841 -0.44458267 -1.7053664\n",
      " -0.36009023 -0.5487107  -2.1868782  -0.17737003 -0.6677522  -1.5704575\n",
      "  0.01685742 -0.6984422  -1.385754   -0.02994931 -0.6323887  -1.4433933\n",
      " -0.03464258 -0.76689506 -1.5578464  -0.1401363  -0.56761706 -1.4907548\n",
      " -0.06462499 -0.61858726 -1.4594417  -0.08415366 -0.59237707 -1.5512501\n",
      "  0.04850768 -0.6093323  -1.5929747  -0.06133769 -0.48444763 -1.3233258\n",
      " -0.16868187 -0.25810936 -1.9481717  -0.0243478  -0.40503538 -1.9522676\n",
      "  0.12711105 -0.377979   -1.4513297  -0.15572897 -0.25096804 -1.2588203\n",
      " -0.08965395 -0.22756363 -1.3364499  -0.04605635 -0.23231798 -1.4532113\n",
      "  0.03424303 -0.24626745 -1.2988583   0.1       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0209, -0.0736, -0.2606,  ...,  0.0503, -0.2600, -1.3039],\n",
      "        [ 0.0209, -0.0736, -0.2606,  ...,  0.0503, -0.2600, -1.3039],\n",
      "        [ 0.0209, -0.0736, -0.2606,  ...,  0.0503, -0.2600, -1.3039],\n",
      "        ...,\n",
      "        [-0.1285,  0.3940, -0.1201,  ..., -0.7297,  0.9032, -0.3817],\n",
      "        [-0.1327, -0.1513,  0.5710,  ..., -0.2362,  0.6243,  0.2287],\n",
      "        [-0.1327, -0.1513,  0.5710,  ..., -0.2362,  0.6243,  0.2287]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02085179 -0.07360557 -0.26063535  0.04266701 -0.20766534 -0.6636574\n",
      " -0.0477009  -0.3899204  -1.4153547  -0.18932346 -0.450543   -1.711653\n",
      " -0.35296056 -0.5610534  -2.1904602  -0.1773915  -0.67923486 -1.5768955\n",
      "  0.03027225 -0.7105043  -1.4032688  -0.02032479 -0.64590836 -1.4595289\n",
      " -0.01867863 -0.781842   -1.5762892  -0.13477686 -0.5787792  -1.4914215\n",
      " -0.05434673 -0.6305214  -1.4677508  -0.06618202 -0.6046686  -1.5618887\n",
      "  0.0639779  -0.6276102  -1.6041465  -0.04798326 -0.4918401  -1.3207529\n",
      " -0.16107872 -0.2642687  -1.9648032  -0.00743221 -0.41779917 -1.967454\n",
      "  0.14826444 -0.38737622 -1.4605057  -0.1500662  -0.25849515 -1.2560668\n",
      " -0.07203796 -0.23653665 -1.3376443  -0.02872517 -0.24746099 -1.454365\n",
      "  0.05034178 -0.2599845  -1.3039098 ]\n",
      "data: [ 0.0208518  -0.07360557 -0.26063535  0.04266701 -0.20766535 -0.6636574\n",
      " -0.0477009  -0.3899204  -1.4153547  -0.18932347 -0.450543   -1.711653\n",
      " -0.35296056 -0.5610534  -2.1904602  -0.17739148 -0.67923486 -1.5768955\n",
      "  0.03027225 -0.7105043  -1.4032687  -0.02032479 -0.64590836 -1.4595289\n",
      " -0.01867863 -0.781842   -1.5762892  -0.13477686 -0.5787792  -1.4914215\n",
      " -0.05434673 -0.6305214  -1.4677509  -0.06618202 -0.6046686  -1.5618887\n",
      "  0.0639779  -0.6276102  -1.6041465  -0.04798326 -0.4918401  -1.3207529\n",
      " -0.16107872 -0.2642687  -1.9648032  -0.00743222 -0.41779917 -1.967454\n",
      "  0.14826444 -0.38737622 -1.4605057  -0.1500662  -0.25849515 -1.2560668\n",
      " -0.07203796 -0.23653665 -1.3376443  -0.02872517 -0.24746099 -1.4543651\n",
      "  0.05034179 -0.2599845  -1.3039098   0.11      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B320>\n",
      "tensor([[ 0.0198, -0.0893, -0.2668,  ...,  0.0553, -0.2735, -1.3226],\n",
      "        [ 0.0198, -0.0893, -0.2668,  ...,  0.0553, -0.2735, -1.3226],\n",
      "        [ 0.0198, -0.0893, -0.2668,  ...,  0.0553, -0.2735, -1.3226],\n",
      "        ...,\n",
      "        [-0.1246,  0.3995, -0.1224,  ..., -0.7093,  0.9053, -0.3871],\n",
      "        [-0.1362, -0.1349,  0.5849,  ..., -0.2385,  0.6321,  0.2429],\n",
      "        [-0.1362, -0.1349,  0.5849,  ..., -0.2385,  0.6321,  0.2429]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.9806292e-02 -8.9340813e-02 -2.6684347e-01  3.9792668e-02\n",
      " -2.3255445e-01 -6.8242949e-01 -3.4254432e-02 -4.1098458e-01\n",
      " -1.4192148e+00 -1.7476511e-01 -4.7032636e-01 -1.7221634e+00\n",
      " -3.4482101e-01 -5.9187758e-01 -2.1904950e+00 -1.8448377e-01\n",
      " -6.8992227e-01 -1.5864729e+00  5.0428875e-02 -7.1566677e-01\n",
      " -1.3954810e+00 -2.7310178e-03 -6.5661865e-01 -1.4477462e+00\n",
      " -2.3531541e-03 -7.8343982e-01 -1.5642316e+00 -1.3790447e-01\n",
      " -5.8237934e-01 -1.4996927e+00 -4.6065226e-02 -6.3881552e-01\n",
      " -1.4790105e+00 -5.2391239e-02 -6.1418277e-01 -1.5758491e+00\n",
      "  7.1940221e-02 -6.4168739e-01 -1.6273247e+00 -4.1541532e-02\n",
      " -4.9771333e-01 -1.3247122e+00 -1.5179208e-01 -2.7209324e-01\n",
      " -1.9510574e+00  1.1701658e-03 -4.2876172e-01 -1.9444716e+00\n",
      "  1.5324804e-01 -3.9433026e-01 -1.4792132e+00 -1.4810675e-01\n",
      " -2.6019120e-01 -1.2628772e+00 -5.7497390e-02 -2.4073476e-01\n",
      " -1.3419600e+00 -9.7132847e-03 -2.6260060e-01 -1.4585819e+00\n",
      "  5.5323854e-02 -2.7348334e-01 -1.3225535e+00]\n",
      "data: [ 1.9806292e-02 -8.9340813e-02 -2.6684347e-01  3.9792668e-02\n",
      " -2.3255445e-01 -6.8242949e-01 -3.4254432e-02 -4.1098458e-01\n",
      " -1.4192147e+00 -1.7476511e-01 -4.7032633e-01 -1.7221634e+00\n",
      " -3.4482101e-01 -5.9187758e-01 -2.1904950e+00 -1.8448375e-01\n",
      " -6.8992227e-01 -1.5864730e+00  5.0428879e-02 -7.1566683e-01\n",
      " -1.3954810e+00 -2.7310178e-03 -6.5661865e-01 -1.4477462e+00\n",
      " -2.3531541e-03 -7.8343982e-01 -1.5642315e+00 -1.3790447e-01\n",
      " -5.8237934e-01 -1.4996927e+00 -4.6065226e-02 -6.3881552e-01\n",
      " -1.4790105e+00 -5.2391239e-02 -6.1418277e-01 -1.5758491e+00\n",
      "  7.1940221e-02 -6.4168739e-01 -1.6273247e+00 -4.1541532e-02\n",
      " -4.9771333e-01 -1.3247123e+00 -1.5179208e-01 -2.7209324e-01\n",
      " -1.9510574e+00  1.1701658e-03 -4.2876172e-01 -1.9444716e+00\n",
      "  1.5324804e-01 -3.9433026e-01 -1.4792132e+00 -1.4810675e-01\n",
      " -2.6019120e-01 -1.2628772e+00 -5.7497393e-02 -2.4073476e-01\n",
      " -1.3419600e+00 -9.7132847e-03 -2.6260060e-01 -1.4585818e+00\n",
      "  5.5323854e-02 -2.7348334e-01 -1.3225535e+00  1.2000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BB38>\n",
      "tensor([[ 0.0280, -0.1061, -0.2600,  ...,  0.0593, -0.2897, -1.3158],\n",
      "        [ 0.0280, -0.1061, -0.2600,  ...,  0.0593, -0.2897, -1.3158],\n",
      "        [ 0.0280, -0.1061, -0.2600,  ...,  0.0593, -0.2897, -1.3158],\n",
      "        ...,\n",
      "        [-0.1378,  0.4206, -0.1584,  ..., -0.7166,  0.9185, -0.4352],\n",
      "        [-0.1583, -0.1244,  0.6022,  ..., -0.2427,  0.6439,  0.2583],\n",
      "        [-0.1583, -0.1244,  0.6022,  ..., -0.2427,  0.6439,  0.2583]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.7974132e-02 -1.0609810e-01 -2.5996795e-01  4.6471741e-02\n",
      " -2.4999669e-01 -6.7578405e-01 -2.9528715e-02 -4.3309683e-01\n",
      " -1.4153857e+00 -1.7142163e-01 -4.9308419e-01 -1.7181695e+00\n",
      " -3.4214139e-01 -6.1496800e-01 -2.1850827e+00 -1.7839268e-01\n",
      " -7.1027130e-01 -1.5838301e+00  5.3676233e-02 -7.3949492e-01\n",
      " -1.3952961e+00 -3.3211708e-04 -6.7973292e-01 -1.4470923e+00\n",
      "  8.3375722e-04 -8.0873096e-01 -1.5629501e+00 -1.3131766e-01\n",
      " -6.0159713e-01 -1.4960122e+00 -4.2176351e-02 -6.5880346e-01\n",
      " -1.4733639e+00 -4.8128024e-02 -6.3535613e-01 -1.5692990e+00\n",
      "  7.4999541e-02 -6.6237730e-01 -1.6187730e+00 -3.4941532e-02\n",
      " -5.1492083e-01 -1.3220918e+00 -1.4925683e-01 -2.8976297e-01\n",
      " -1.9550838e+00  4.9514547e-03 -4.4818085e-01 -1.9489136e+00\n",
      "  1.5738487e-01 -4.1227061e-01 -1.4720788e+00 -1.4289922e-01\n",
      " -2.7686855e-01 -1.2594488e+00 -5.3326443e-02 -2.5708044e-01\n",
      " -1.3391752e+00 -6.0373396e-03 -2.7942979e-01 -1.4543834e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5.9285350e-02 -2.8972203e-01 -1.3158231e+00]\n",
      "data: [ 2.7974134e-02 -1.0609810e-01 -2.5996795e-01  4.6471737e-02\n",
      " -2.4999671e-01 -6.7578405e-01 -2.9528715e-02 -4.3309680e-01\n",
      " -1.4153857e+00 -1.7142162e-01 -4.9308419e-01 -1.7181695e+00\n",
      " -3.4214139e-01 -6.1496800e-01 -2.1850827e+00 -1.7839268e-01\n",
      " -7.1027130e-01 -1.5838301e+00  5.3676233e-02 -7.3949492e-01\n",
      " -1.3952960e+00 -3.3211708e-04 -6.7973292e-01 -1.4470923e+00\n",
      "  8.3375722e-04 -8.0873090e-01 -1.5629501e+00 -1.3131766e-01\n",
      " -6.0159713e-01 -1.4960122e+00 -4.2176351e-02 -6.5880346e-01\n",
      " -1.4733640e+00 -4.8128024e-02 -6.3535613e-01 -1.5692990e+00\n",
      "  7.4999541e-02 -6.6237730e-01 -1.6187730e+00 -3.4941532e-02\n",
      " -5.1492083e-01 -1.3220918e+00 -1.4925683e-01 -2.8976297e-01\n",
      " -1.9550840e+00  4.9514547e-03 -4.4818085e-01 -1.9489136e+00\n",
      "  1.5738487e-01 -4.1227064e-01 -1.4720788e+00 -1.4289922e-01\n",
      " -2.7686855e-01 -1.2594488e+00 -5.3326443e-02 -2.5708044e-01\n",
      " -1.3391752e+00 -6.0373396e-03 -2.7942979e-01 -1.4543834e+00\n",
      "  5.9285350e-02 -2.8972203e-01 -1.3158231e+00  1.3000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63FD0>\n",
      "tensor([[ 0.0222, -0.1217, -0.2596,  ...,  0.0613, -0.3063, -1.3149],\n",
      "        [ 0.0222, -0.1217, -0.2596,  ...,  0.0613, -0.3063, -1.3149],\n",
      "        [ 0.0222, -0.1217, -0.2596,  ...,  0.0613, -0.3063, -1.3149],\n",
      "        ...,\n",
      "        [-0.0955,  0.4454, -0.1227,  ..., -0.6611,  0.9561, -0.4356],\n",
      "        [-0.1176, -0.0992,  0.6059,  ..., -0.2171,  0.6557,  0.2444],\n",
      "        [-0.1176, -0.0992,  0.6059,  ..., -0.2171,  0.6557,  0.2444]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.2179071e-02 -1.2165586e-01 -2.5963202e-01  4.4881996e-02\n",
      " -2.6407656e-01 -6.6449344e-01 -2.5116928e-02 -4.4830883e-01\n",
      " -1.4132899e+00 -1.6742781e-01 -5.0779933e-01 -1.7230346e+00\n",
      " -3.3874297e-01 -6.3381195e-01 -2.1934900e+00 -1.8440965e-01\n",
      " -7.2332335e-01 -1.5908544e+00  6.5170184e-02 -7.5258482e-01\n",
      " -1.3932904e+00  6.8937540e-03 -6.9749582e-01 -1.4422778e+00\n",
      "  1.8134564e-03 -8.2611299e-01 -1.5613419e+00 -1.3372673e-01\n",
      " -6.1453879e-01 -1.4974471e+00 -3.9462641e-02 -6.7573023e-01\n",
      " -1.4793631e+00 -4.4515550e-02 -6.5176392e-01 -1.5780286e+00\n",
      "  7.3335990e-02 -6.8715358e-01 -1.6303444e+00 -3.1493641e-02\n",
      " -5.2516258e-01 -1.3182297e+00 -1.5092319e-01 -2.9946715e-01\n",
      " -1.9640555e+00  7.8546479e-03 -4.6457568e-01 -1.9561019e+00\n",
      "  1.5826687e-01 -4.2697635e-01 -1.4763362e+00 -1.4557113e-01\n",
      " -2.8639865e-01 -1.2549042e+00 -4.6469092e-02 -2.6803690e-01\n",
      " -1.3323094e+00  1.2634546e-03 -2.9688868e-01 -1.4483851e+00\n",
      "  6.1333410e-02 -3.0629295e-01 -1.3149033e+00]\n",
      "data: [ 2.2179073e-02 -1.2165585e-01 -2.5963202e-01  4.4881996e-02\n",
      " -2.6407656e-01 -6.6449338e-01 -2.5116928e-02 -4.4830883e-01\n",
      " -1.4132899e+00 -1.6742781e-01 -5.0779933e-01 -1.7230346e+00\n",
      " -3.3874297e-01 -6.3381195e-01 -2.1934900e+00 -1.8440966e-01\n",
      " -7.2332335e-01 -1.5908543e+00  6.5170184e-02 -7.5258482e-01\n",
      " -1.3932904e+00  6.8937540e-03 -6.9749582e-01 -1.4422778e+00\n",
      "  1.8134564e-03 -8.2611299e-01 -1.5613419e+00 -1.3372673e-01\n",
      " -6.1453879e-01 -1.4974473e+00 -3.9462641e-02 -6.7573023e-01\n",
      " -1.4793631e+00 -4.4515554e-02 -6.5176392e-01 -1.5780286e+00\n",
      "  7.3335990e-02 -6.8715358e-01 -1.6303444e+00 -3.1493641e-02\n",
      " -5.2516258e-01 -1.3182297e+00 -1.5092319e-01 -2.9946715e-01\n",
      " -1.9640555e+00  7.8546479e-03 -4.6457568e-01 -1.9561019e+00\n",
      "  1.5826687e-01 -4.2697635e-01 -1.4763362e+00 -1.4557113e-01\n",
      " -2.8639865e-01 -1.2549042e+00 -4.6469092e-02 -2.6803690e-01\n",
      " -1.3323094e+00  1.2634546e-03 -2.9688868e-01 -1.4483851e+00\n",
      "  6.1333407e-02 -3.0629295e-01 -1.3149033e+00  1.4000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0191, -0.1206, -0.2348,  ...,  0.0545, -0.3031, -1.2826],\n",
      "        [ 0.0191, -0.1206, -0.2348,  ...,  0.0545, -0.3031, -1.2826],\n",
      "        [ 0.0191, -0.1206, -0.2348,  ...,  0.0545, -0.3031, -1.2826],\n",
      "        ...,\n",
      "        [-0.0847,  0.4585, -0.1335,  ..., -0.6200,  0.9519, -0.4358],\n",
      "        [-0.1213, -0.0876,  0.6119,  ..., -0.2218,  0.6416,  0.2724],\n",
      "        [-0.1213, -0.0876,  0.6119,  ..., -0.2218,  0.6416,  0.2724]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.9068975e-02 -1.2062649e-01 -2.3482934e-01  4.4032205e-02\n",
      " -2.5815281e-01 -6.2456918e-01 -3.4969024e-02 -4.5178017e-01\n",
      " -1.3886253e+00 -1.7915487e-01 -5.1232779e-01 -1.6961621e+00\n",
      " -3.4581488e-01 -6.3455075e-01 -2.1720004e+00 -1.8650030e-01\n",
      " -7.2858715e-01 -1.5686785e+00  5.5350527e-02 -7.6536179e-01\n",
      " -1.3763475e+00 -5.2346289e-03 -7.0964831e-01 -1.4240876e+00\n",
      " -1.4065884e-02 -8.4542423e-01 -1.5448596e+00 -1.3562590e-01\n",
      " -6.2252152e-01 -1.4730344e+00 -4.7305606e-02 -6.8433934e-01\n",
      " -1.4541163e+00 -5.4055676e-02 -6.5886962e-01 -1.5501496e+00\n",
      "  6.2054187e-02 -6.9860309e-01 -1.5952107e+00 -3.4638770e-02\n",
      " -5.2551246e-01 -1.2968732e+00 -1.6478162e-01 -2.9885551e-01\n",
      " -1.9703783e+00  2.8972328e-04 -4.6904710e-01 -1.9679791e+00\n",
      "  1.5150531e-01 -4.3000984e-01 -1.4457126e+00 -1.5237474e-01\n",
      " -2.8809065e-01 -1.2299658e+00 -5.5176362e-02 -2.6784551e-01\n",
      " -1.3096399e+00 -1.1347979e-02 -2.9437989e-01 -1.4255058e+00\n",
      "  5.4528646e-02 -3.0312133e-01 -1.2826473e+00]\n",
      "data: [ 1.9068975e-02 -1.2062649e-01 -2.3482934e-01  4.4032205e-02\n",
      " -2.5815281e-01 -6.2456918e-01 -3.4969024e-02 -4.5178017e-01\n",
      " -1.3886254e+00 -1.7915487e-01 -5.1232779e-01 -1.6961621e+00\n",
      " -3.4581488e-01 -6.3455075e-01 -2.1720004e+00 -1.8650030e-01\n",
      " -7.2858721e-01 -1.5686784e+00  5.5350527e-02 -7.6536179e-01\n",
      " -1.3763475e+00 -5.2346289e-03 -7.0964831e-01 -1.4240876e+00\n",
      " -1.4065884e-02 -8.4542429e-01 -1.5448596e+00 -1.3562590e-01\n",
      " -6.2252152e-01 -1.4730344e+00 -4.7305606e-02 -6.8433934e-01\n",
      " -1.4541163e+00 -5.4055676e-02 -6.5886962e-01 -1.5501496e+00\n",
      "  6.2054187e-02 -6.9860303e-01 -1.5952107e+00 -3.4638770e-02\n",
      " -5.2551246e-01 -1.2968732e+00 -1.6478162e-01 -2.9885551e-01\n",
      " -1.9703783e+00  2.8972328e-04 -4.6904710e-01 -1.9679791e+00\n",
      "  1.5150531e-01 -4.3000984e-01 -1.4457126e+00 -1.5237474e-01\n",
      " -2.8809065e-01 -1.2299658e+00 -5.5176362e-02 -2.6784551e-01\n",
      " -1.3096399e+00 -1.1347979e-02 -2.9437989e-01 -1.4255059e+00\n",
      "  5.4528646e-02 -3.0312133e-01 -1.2826473e+00  1.5000001e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[ 0.0208, -0.1155, -0.1932,  ...,  0.0782, -0.3184, -1.1855],\n",
      "        [ 0.0208, -0.1155, -0.1932,  ...,  0.0782, -0.3184, -1.1855],\n",
      "        [ 0.0208, -0.1155, -0.1932,  ...,  0.0782, -0.3184, -1.1855],\n",
      "        ...,\n",
      "        [-0.1107,  0.4063, -0.1154,  ..., -0.6958,  0.9285, -0.4328],\n",
      "        [-0.1197, -0.0938,  0.5955,  ..., -0.2204,  0.6443,  0.2116],\n",
      "        [-0.1197, -0.0938,  0.5955,  ..., -0.2204,  0.6443,  0.2116]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02076234 -0.11554987 -0.19323188  0.05162613 -0.22868487 -0.5159041\n",
      " -0.06688136 -0.44753    -1.3421701  -0.21448651 -0.5133164  -1.6398156\n",
      " -0.3692633  -0.62004936 -2.1321115  -0.17019033 -0.7431458  -1.5151669\n",
      "  0.03293404 -0.80174816 -1.3470148  -0.02447768 -0.73477256 -1.3964511\n",
      " -0.03346081 -0.8962983  -1.5206339  -0.11904231 -0.65186715 -1.411636\n",
      " -0.04965153 -0.71118045 -1.3889208  -0.0580548  -0.6819402  -1.4749953\n",
      "  0.07200594 -0.7214118  -1.5026494  -0.0261412  -0.54727083 -1.2408282\n",
      " -0.17699204 -0.31266153 -1.9970622   0.00914684 -0.49266854 -2.0111628\n",
      "  0.17675474 -0.45253977 -1.3576858  -0.14691915 -0.31755596 -1.1645371\n",
      " -0.06135127 -0.29303944 -1.2519422  -0.02025194 -0.30641675 -1.365459\n",
      "  0.07821331 -0.318389   -1.1855217 ]\n",
      "data: [ 0.02076234 -0.11554987 -0.19323188  0.05162613 -0.22868486 -0.5159041\n",
      " -0.06688136 -0.44752997 -1.3421701  -0.21448651 -0.5133164  -1.6398156\n",
      " -0.3692633  -0.62004936 -2.1321115  -0.17019033 -0.7431458  -1.5151669\n",
      "  0.03293404 -0.8017481  -1.3470148  -0.02447768 -0.73477256 -1.3964511\n",
      " -0.03346081 -0.8962983  -1.520634   -0.11904231 -0.65186715 -1.411636\n",
      " -0.04965153 -0.71118045 -1.3889208  -0.0580548  -0.68194026 -1.4749953\n",
      "  0.07200594 -0.7214118  -1.5026494  -0.0261412  -0.54727083 -1.2408282\n",
      " -0.17699203 -0.31266153 -1.9970622   0.00914684 -0.49266854 -2.0111628\n",
      "  0.17675474 -0.4525398  -1.3576858  -0.14691915 -0.31755596 -1.1645371\n",
      " -0.06135127 -0.29303944 -1.2519422  -0.02025194 -0.30641675 -1.365459\n",
      "  0.07821331 -0.318389   -1.1855217   0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0161, -0.0848, -0.1965,  ...,  0.0238, -0.2757, -1.1735],\n",
      "        [-0.0161, -0.0848, -0.1965,  ...,  0.0238, -0.2757, -1.1735],\n",
      "        [-0.0161, -0.0848, -0.1965,  ...,  0.0238, -0.2757, -1.1735],\n",
      "        ...,\n",
      "        [-0.1383,  0.3537, -0.0413,  ..., -0.6952,  0.8798, -0.3789],\n",
      "        [-0.0827, -0.0718,  0.6043,  ..., -0.1852,  0.6666,  0.2036],\n",
      "        [-0.0827, -0.0718,  0.6043,  ..., -0.1852,  0.6666,  0.2036]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.0161082  -0.08479025 -0.19649318  0.01924631 -0.18687966 -0.48409247\n",
      " -0.12139267 -0.4175508  -1.3475928  -0.2749479  -0.48349    -1.6418552\n",
      " -0.427649   -0.577641   -2.150852   -0.20719695 -0.7209214  -1.5218829\n",
      " -0.02671632 -0.7872152  -1.3625989  -0.08167918 -0.7142662  -1.4137422\n",
      " -0.09082498 -0.8855884  -1.5419854  -0.16022593 -0.6342895  -1.4149613\n",
      " -0.10262374 -0.68910235 -1.3880627  -0.11244115 -0.65540665 -1.474734\n",
      "  0.02809374 -0.6917231  -1.4932207  -0.07565006 -0.5208614  -1.2467139\n",
      " -0.24044716 -0.2812931  -2.0459733  -0.04435429 -0.4611103  -2.072033\n",
      "  0.13438526 -0.42087948 -1.3492758  -0.19925404 -0.292057   -1.1660696\n",
      " -0.12643553 -0.2623977  -1.2551355  -0.09057418 -0.26504245 -1.3699021\n",
      "  0.02376709 -0.27571115 -1.1735349 ]\n",
      "data: [-0.0161082  -0.08479025 -0.1964932   0.01924631 -0.18687968 -0.48409247\n",
      " -0.12139268 -0.4175508  -1.3475928  -0.2749479  -0.48349    -1.6418551\n",
      " -0.427649   -0.577641   -2.150852   -0.20719697 -0.7209214  -1.5218829\n",
      " -0.02671632 -0.7872152  -1.3625989  -0.08167918 -0.7142662  -1.4137422\n",
      " -0.09082498 -0.8855884  -1.5419853  -0.16022593 -0.6342895  -1.4149613\n",
      " -0.10262374 -0.68910235 -1.3880627  -0.11244115 -0.65540665 -1.4747338\n",
      "  0.02809374 -0.6917231  -1.4932207  -0.07565006 -0.5208614  -1.2467139\n",
      " -0.24044716 -0.2812931  -2.0459733  -0.04435429 -0.4611103  -2.072033\n",
      "  0.13438526 -0.42087948 -1.3492758  -0.19925404 -0.292057   -1.1660696\n",
      " -0.12643553 -0.2623977  -1.2551355  -0.09057418 -0.26504245 -1.3699021\n",
      "  0.02376709 -0.27571115 -1.1735349   0.17      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[-0.0171, -0.0052, -0.1702,  ...,  0.0152, -0.1890, -1.1710],\n",
      "        [-0.0171, -0.0052, -0.1702,  ...,  0.0152, -0.1890, -1.1710],\n",
      "        [-0.0171, -0.0052, -0.1702,  ...,  0.0152, -0.1890, -1.1710],\n",
      "        ...,\n",
      "        [-0.2262,  0.3031, -0.0597,  ..., -0.7933,  0.8930, -0.4146],\n",
      "        [-0.0916, -0.0733,  0.5937,  ..., -0.2262,  0.6323,  0.2772],\n",
      "        [-0.0916, -0.0733,  0.5937,  ..., -0.2262,  0.6323,  0.2772]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01713358 -0.00520281 -0.17016529  0.00651519 -0.11924312 -0.50037277\n",
      " -0.11998077 -0.33265823 -1.3202505  -0.2720919  -0.39361596 -1.616462\n",
      " -0.43576822 -0.49264264 -2.1092439  -0.21966389 -0.63360834 -1.4843912\n",
      " -0.02199416 -0.6840774  -1.3025086  -0.06792545 -0.6128134  -1.3540491\n",
      " -0.0674849  -0.76795495 -1.481817   -0.17530817 -0.53836995 -1.3848363\n",
      " -0.10393951 -0.5912355  -1.3591431  -0.10099854 -0.55629694 -1.4507093\n",
      "  0.05300172 -0.5870941  -1.4845538  -0.0864606  -0.4345281  -1.2168722\n",
      " -0.23221052 -0.19749789 -1.9516388  -0.04236075 -0.3658331  -1.9687028\n",
      "  0.1445775  -0.3253091  -1.340984   -0.20737451 -0.19993386 -1.1398013\n",
      " -0.13235748 -0.17051871 -1.2271832  -0.09057043 -0.1767665  -1.3455138\n",
      "  0.01518101 -0.1890373  -1.170988  ]\n",
      "data: [-0.01713358 -0.00520281 -0.17016529  0.00651519 -0.11924312 -0.50037277\n",
      " -0.11998077 -0.33265823 -1.3202505  -0.2720919  -0.39361596 -1.616462\n",
      " -0.43576822 -0.49264264 -2.1092439  -0.21966389 -0.63360834 -1.4843912\n",
      " -0.02199416 -0.6840774  -1.3025086  -0.06792545 -0.6128134  -1.3540491\n",
      " -0.0674849  -0.76795495 -1.481817   -0.17530817 -0.53836995 -1.3848363\n",
      " -0.10393951 -0.5912355  -1.359143   -0.10099854 -0.55629694 -1.4507093\n",
      "  0.05300172 -0.5870941  -1.4845538  -0.0864606  -0.4345281  -1.2168722\n",
      " -0.23221052 -0.19749789 -1.9516388  -0.04236075 -0.3658331  -1.9687028\n",
      "  0.1445775  -0.3253091  -1.340984   -0.20737451 -0.19993386 -1.1398013\n",
      " -0.13235748 -0.1705187  -1.2271832  -0.09057043 -0.17676648 -1.3455138\n",
      "  0.01518101 -0.18903728 -1.170988    0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0016, -0.1228, -0.2080,  ...,  0.0268, -0.2753, -1.3359],\n",
      "        [-0.0016, -0.1228, -0.2080,  ...,  0.0268, -0.2753, -1.3359],\n",
      "        [-0.0016, -0.1228, -0.2080,  ...,  0.0268, -0.2753, -1.3359],\n",
      "        ...,\n",
      "        [-0.2471,  0.3487, -0.1725,  ..., -0.7297,  0.7795, -0.3365],\n",
      "        [-0.1643, -0.0921,  0.5396,  ..., -0.2601,  0.6759,  0.2383],\n",
      "        [-0.1643, -0.0921,  0.5396,  ..., -0.2601,  0.6759,  0.2383]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-1.57500431e-03 -1.22788697e-01 -2.08031043e-01  1.35069378e-02\n",
      " -2.93230653e-01 -6.88530922e-01 -2.57101282e-02 -4.40162688e-01\n",
      " -1.36224771e+00 -1.67331070e-01 -4.92547184e-01 -1.67478395e+00\n",
      " -3.55569243e-01 -6.34993672e-01 -2.12861204e+00 -2.29479596e-01\n",
      " -7.00441599e-01 -1.52668011e+00  6.23579472e-02 -6.95588708e-01\n",
      " -1.27869451e+00  1.06976405e-02 -6.42475009e-01 -1.32801259e+00\n",
      "  5.36759198e-03 -7.33887672e-01 -1.44408011e+00 -1.82117924e-01\n",
      " -5.78035593e-01 -1.45232844e+00 -5.90120479e-02 -6.35235786e-01\n",
      " -1.43990469e+00 -5.63490391e-02 -6.03021860e-01 -1.54876828e+00\n",
      "  6.74112737e-02 -6.28411889e-01 -1.62634718e+00 -6.97825775e-02\n",
      " -5.07533789e-01 -1.27138925e+00 -1.49066523e-01 -2.78530806e-01\n",
      " -1.79622841e+00 -1.18993148e-02 -4.21880990e-01 -1.76834106e+00\n",
      "  1.33575186e-01 -3.85320514e-01 -1.48042107e+00 -1.74283385e-01\n",
      " -2.57959068e-01 -1.22347701e+00 -6.70192987e-02 -2.38042429e-01\n",
      " -1.30120337e+00 -7.62644410e-03 -2.72749424e-01 -1.42512190e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.68243477e-02 -2.75309443e-01 -1.33592010e+00]\n",
      "data: [-1.57500431e-03 -1.22788697e-01 -2.08031043e-01  1.35069378e-02\n",
      " -2.93230653e-01 -6.88530862e-01 -2.57101282e-02 -4.40162688e-01\n",
      " -1.36224782e+00 -1.67331070e-01 -4.92547184e-01 -1.67478395e+00\n",
      " -3.55569243e-01 -6.34993672e-01 -2.12861204e+00 -2.29479596e-01\n",
      " -7.00441599e-01 -1.52668011e+00  6.23579472e-02 -6.95588708e-01\n",
      " -1.27869451e+00  1.06976405e-02 -6.42474949e-01 -1.32801259e+00\n",
      "  5.36759198e-03 -7.33887613e-01 -1.44408000e+00 -1.82117924e-01\n",
      " -5.78035593e-01 -1.45232844e+00 -5.90120442e-02 -6.35235786e-01\n",
      " -1.43990469e+00 -5.63490391e-02 -6.03021860e-01 -1.54876828e+00\n",
      "  6.74112737e-02 -6.28411889e-01 -1.62634718e+00 -6.97825775e-02\n",
      " -5.07533789e-01 -1.27138925e+00 -1.49066523e-01 -2.78530806e-01\n",
      " -1.79622829e+00 -1.18993148e-02 -4.21880990e-01 -1.76834106e+00\n",
      "  1.33575186e-01 -3.85320514e-01 -1.48042119e+00 -1.74283385e-01\n",
      " -2.57959068e-01 -1.22347701e+00 -6.70192987e-02 -2.38042429e-01\n",
      " -1.30120325e+00 -7.62644410e-03 -2.72749424e-01 -1.42512190e+00\n",
      "  2.68243477e-02 -2.75309443e-01 -1.33592010e+00  1.89999998e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B320>\n",
      "tensor([[ 0.0448, -0.1389, -0.2748,  ...,  0.0655, -0.3150, -1.3291],\n",
      "        [ 0.0448, -0.1389, -0.2748,  ...,  0.0655, -0.3150, -1.3291],\n",
      "        [ 0.0448, -0.1389, -0.2748,  ...,  0.0655, -0.3150, -1.3291],\n",
      "        ...,\n",
      "        [-0.1507,  0.4982, -0.1630,  ..., -0.6904,  1.0289, -0.5046],\n",
      "        [-0.1968, -0.0779,  0.6310,  ..., -0.2957,  0.6777,  0.2758],\n",
      "        [-0.1968, -0.0779,  0.6310,  ..., -0.2957,  0.6777,  0.2758]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04483519 -0.13894367 -0.27477312  0.07653293 -0.26266122 -0.6519392\n",
      " -0.02165029 -0.4700315  -1.4576868  -0.16729905 -0.53117955 -1.761611\n",
      " -0.31883568 -0.6399447  -2.2594273  -0.15879393 -0.7521367  -1.6395637\n",
      "  0.06680647 -0.79749084 -1.447395    0.00836594 -0.73683405 -1.4964573\n",
      " -0.01113412 -0.88172674 -1.6235396  -0.11211836 -0.6532601  -1.538878\n",
      " -0.03610945 -0.7112553  -1.52113    -0.04521462 -0.6793786  -1.6112503\n",
      "  0.0737164  -0.7209972  -1.6507322  -0.01722089 -0.548241   -1.3673391\n",
      " -0.16143852 -0.3134263  -2.0738673   0.01196866 -0.4867822  -2.0818052\n",
      "  0.1656402  -0.44395086 -1.5033349  -0.13929018 -0.31471363 -1.2915419\n",
      " -0.05011059 -0.2859285  -1.3696964  -0.00961234 -0.30568826 -1.4844204\n",
      "  0.06550712 -0.3150133  -1.3290858 ]\n",
      "data: [ 0.04483519 -0.13894367 -0.27477312  0.07653293 -0.26266122 -0.6519392\n",
      " -0.02165029 -0.4700315  -1.4576868  -0.16729905 -0.53117955 -1.761611\n",
      " -0.31883568 -0.6399447  -2.2594273  -0.15879393 -0.7521367  -1.6395638\n",
      "  0.06680647 -0.79749084 -1.447395    0.00836594 -0.73683405 -1.4964573\n",
      " -0.01113412 -0.88172674 -1.6235396  -0.11211836 -0.6532601  -1.538878\n",
      " -0.03610945 -0.7112553  -1.52113    -0.04521462 -0.6793787  -1.6112503\n",
      "  0.0737164  -0.7209972  -1.6507322  -0.01722089 -0.548241   -1.3673391\n",
      " -0.16143852 -0.3134263  -2.0738673   0.01196866 -0.4867822  -2.0818052\n",
      "  0.1656402  -0.44395083 -1.5033348  -0.13929018 -0.31471363 -1.2915419\n",
      " -0.05011059 -0.2859285  -1.3696964  -0.00961234 -0.30568826 -1.4844204\n",
      "  0.06550712 -0.3150133  -1.3290858   0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0059, -0.1053, -0.2080,  ...,  0.0758, -0.3016, -1.2572],\n",
      "        [-0.0059, -0.1053, -0.2080,  ...,  0.0758, -0.3016, -1.2572],\n",
      "        [-0.0059, -0.1053, -0.2080,  ...,  0.0758, -0.3016, -1.2572],\n",
      "        ...,\n",
      "        [-0.1203,  0.4641, -0.1363,  ..., -0.7790,  0.9758, -0.3999],\n",
      "        [-0.1322, -0.0592,  0.5853,  ..., -0.2176,  0.6323,  0.2211],\n",
      "        [-0.1322, -0.0592,  0.5853,  ..., -0.2176,  0.6323,  0.2211]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.00589226 -0.10527686 -0.20799479  0.01410538 -0.25463045 -0.59474325\n",
      " -0.02856343 -0.43193808 -1.342303   -0.17142266 -0.48805636 -1.6713251\n",
      " -0.35918468 -0.6413442  -2.1297154  -0.2254204  -0.69411874 -1.5425447\n",
      "  0.0853124  -0.71672845 -1.3260566   0.02096292 -0.67291117 -1.3655556\n",
      "  0.02760006 -0.78980064 -1.4865718  -0.15916452 -0.57603705 -1.437167\n",
      " -0.03812887 -0.6506368  -1.4286597  -0.02417506 -0.6328579  -1.538307\n",
      "  0.09240843 -0.6818886  -1.6085197  -0.03403895 -0.4960668  -1.2394097\n",
      " -0.1516784  -0.26967707 -1.8857156   0.02100952 -0.45021603 -1.8610604\n",
      "  0.18024777 -0.41098526 -1.4300447  -0.16166022 -0.24836491 -1.1795317\n",
      " -0.02753232 -0.24093994 -1.2506227   0.03326871 -0.29476774 -1.3666298\n",
      "  0.07584568 -0.3015582  -1.2572083 ]\n",
      "data: [-3.78 -1.77  0.15 -3.73 -1.65  0.38 -3.71 -1.59  0.78 -3.71 -1.44  0.52\n",
      " -2.9  -0.44 -2.63 -3.68 -1.45  0.74 -3.68 -1.52  0.74 -2.9  -0.5  -2.63\n",
      " -2.86 -0.31 -2.86  0.    0.    0.   -3.65 -1.13  0.11 -3.61 -0.89  0.11\n",
      " -3.6  -0.71 -0.15 -3.72 -1.17 -0.03 -3.74 -1.07 -0.01 -3.72 -0.86  0.09\n",
      " -3.13 -0.19 -2.83 -3.84 -1.09 -0.11 -3.84 -0.93 -0.09 -3.87 -0.87 -0.05\n",
      " -3.88 -0.62 -0.11  0.  ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63EB8>\n",
      "tensor([[-2.2872e-02,  2.3618e-02, -7.8218e-02,  ...,  1.1192e-01,\n",
      "         -1.2782e-01,  6.1546e-02],\n",
      "        [-2.2872e-02,  2.3618e-02, -7.8218e-02,  ...,  1.1192e-01,\n",
      "         -1.2782e-01,  6.1546e-02],\n",
      "        [-2.2872e-02,  2.3618e-02, -7.8218e-02,  ...,  1.1192e-01,\n",
      "         -1.2782e-01,  6.1546e-02],\n",
      "        ...,\n",
      "        [ 3.1518e-01, -3.1658e-01,  2.8978e-01,  ..., -7.0223e-01,\n",
      "          3.1426e-01, -1.2030e+00],\n",
      "        [ 8.5601e-02, -2.6553e-01,  8.0389e-01,  ..., -1.7331e+00,\n",
      "          8.8608e-04,  2.0593e-01],\n",
      "        [ 8.5601e-02, -2.6553e-01,  8.0389e-01,  ..., -1.7331e+00,\n",
      "          8.8608e-04,  2.0593e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.02287174  0.0236178  -0.07821809 -0.13006057 -0.1030415  -0.31843805\n",
      " -0.25111228 -0.24064997 -0.27722025 -0.3249942  -0.3453246  -0.24057369\n",
      " -0.38636005 -0.45104963 -0.15432982 -0.2641229  -0.19156004 -0.3922787\n",
      " -0.25985166 -0.25964168 -0.21330342 -0.2683786  -0.31767145 -0.17483836\n",
      " -0.21058527 -0.35169053 -0.15724617 -0.17983556 -0.10931963 -0.38570037\n",
      " -0.23097385 -0.21402046 -0.27665016 -0.19235133 -0.294295   -0.23262484\n",
      " -0.1077879  -0.35366404 -0.21773532 -0.13411969 -0.09286426 -0.30883992\n",
      " -0.17119844 -0.0956842  -0.21898708 -0.10855745 -0.19746071 -0.18139914\n",
      "  0.01338646 -0.25115776 -0.07334489 -0.08554555  0.02650047 -0.22428383\n",
      " -0.05416055  0.00420878 -0.09896394  0.03704031 -0.06643352 -0.0704305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.11192182 -0.12782021  0.06154594]\n",
      "init: [-0.02287174  0.0236178  -0.07821809 -0.13006057 -0.1030415  -0.31843805\n",
      " -0.25111228 -0.24064997 -0.27722025 -0.3249942  -0.3453246  -0.24057369\n",
      " -0.38636005 -0.45104963 -0.15432982 -0.2641229  -0.19156004 -0.3922787\n",
      " -0.25985166 -0.25964168 -0.21330342 -0.2683786  -0.31767145 -0.17483836\n",
      " -0.21058527 -0.35169053 -0.15724617 -0.17983556 -0.10931963 -0.38570037\n",
      " -0.23097385 -0.21402046 -0.27665016 -0.19235133 -0.294295   -0.23262484\n",
      " -0.1077879  -0.35366404 -0.21773532 -0.13411969 -0.09286426 -0.30883992\n",
      " -0.17119844 -0.0956842  -0.21898708 -0.10855745 -0.19746071 -0.18139914\n",
      "  0.01338646 -0.25115776 -0.07334489 -0.08554555  0.02650047 -0.22428383\n",
      " -0.05416055  0.00420878 -0.09896394  0.03704031 -0.06643352 -0.0704305\n",
      "  0.11192182 -0.12782021  0.06154594]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [-0.02287174  0.0236178  -0.07821809 -0.13006057 -0.1030415  -0.31843805\n",
      " -0.25111228 -0.24064997 -0.27722025 -0.3249942  -0.3453246  -0.24057369\n",
      " -0.38636005 -0.45104963 -0.15432982 -0.2641229  -0.19156004 -0.3922787\n",
      " -0.25985166 -0.25964168 -0.21330342 -0.2683786  -0.31767145 -0.17483836\n",
      " -0.21058527 -0.35169053 -0.15724617 -0.17983554 -0.10931963 -0.38570037\n",
      " -0.23097385 -0.21402046 -0.27665016 -0.19235133 -0.294295   -0.23262483\n",
      " -0.10778789 -0.35366404 -0.21773534 -0.13411969 -0.09286425 -0.30883992\n",
      " -0.17119844 -0.0956842  -0.21898708 -0.10855744 -0.19746071 -0.18139914\n",
      "  0.01338646 -0.25115776 -0.07334489 -0.08554555  0.02650047 -0.22428383\n",
      " -0.05416055  0.00420878 -0.09896394  0.03704031 -0.06643352 -0.0704305\n",
      "  0.11192182 -0.12782021  0.06154594  0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[-7.1087e-02,  2.8606e-02,  2.6926e-01,  ..., -9.0672e-02,\n",
      "         -2.1867e-01, -6.3703e-01],\n",
      "        [-7.1087e-02,  2.8606e-02,  2.6926e-01,  ..., -9.0672e-02,\n",
      "         -2.1867e-01, -6.3703e-01],\n",
      "        [-7.1087e-02,  2.8606e-02,  2.6926e-01,  ..., -9.0672e-02,\n",
      "         -2.1867e-01, -6.3703e-01],\n",
      "        ...,\n",
      "        [ 2.7665e-01,  3.6741e-01, -1.2242e+00,  ...,  2.7383e-01,\n",
      "          6.8035e-01, -1.1779e+00],\n",
      "        [ 1.9737e-01,  4.5175e-02,  4.7931e-01,  ..., -2.0244e-01,\n",
      "          8.9640e-01,  8.3864e-05],\n",
      "        [ 1.9737e-01,  4.5175e-02,  4.7931e-01,  ..., -2.0244e-01,\n",
      "          8.9640e-01,  8.3864e-05]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.07108749  0.0286062   0.2692597  -0.13103773 -0.11035398 -0.11255223\n",
      " -0.35340744 -0.23849337 -0.6225368  -0.51095986 -0.3305269  -0.82062525\n",
      " -0.80428356 -0.383696   -1.211344   -0.3177144  -0.5412359  -0.7958235\n",
      " -0.43664432 -0.55614996 -0.8739651  -0.39253855 -0.45363584 -0.9296077\n",
      " -0.28615904 -0.6465516  -0.92694765 -0.27669483 -0.42949057 -0.79053444\n",
      " -0.2948637  -0.48762465 -0.65793407 -0.344324   -0.5106363  -0.74962753\n",
      " -0.07208019 -0.42564523 -0.85689765 -0.27402914 -0.46728635 -0.660711\n",
      " -0.3059523  -0.2692365  -0.98230916 -0.23444389 -0.34801653 -0.9923616\n",
      " -0.06039128 -0.34912065 -0.70724463 -0.25289392 -0.23987299 -0.62967956\n",
      " -0.35711932 -0.22162658 -0.6694462  -0.25864094 -0.15919502 -0.8086857\n",
      " -0.09067167 -0.21866979 -0.63702786]\n",
      "data: [-0.07108749  0.0286062   0.2692597  -0.13103773 -0.11035398 -0.11255223\n",
      " -0.35340744 -0.23849337 -0.6225368  -0.51095986 -0.3305269  -0.82062525\n",
      " -0.8042835  -0.383696   -1.211344   -0.3177144  -0.5412359  -0.7958235\n",
      " -0.43664432 -0.55614996 -0.8739651  -0.39253852 -0.4536358  -0.9296077\n",
      " -0.28615904 -0.6465516  -0.92694765 -0.27669483 -0.4294906  -0.79053444\n",
      " -0.2948637  -0.48762468 -0.657934   -0.344324   -0.5106363  -0.74962753\n",
      " -0.07208019 -0.42564523 -0.85689765 -0.27402914 -0.46728635 -0.660711\n",
      " -0.3059523  -0.2692365  -0.98230916 -0.23444389 -0.34801656 -0.9923616\n",
      " -0.06039128 -0.34912065 -0.70724463 -0.25289392 -0.23987299 -0.62967956\n",
      " -0.35711932 -0.22162658 -0.6694462  -0.25864094 -0.15919502 -0.80868566\n",
      " -0.09067167 -0.2186698  -0.63702786  0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.1095, -0.1939,  0.0374,  ...,  0.2946, -0.4030, -0.9804],\n",
      "        [ 0.1095, -0.1939,  0.0374,  ...,  0.2946, -0.4030, -0.9804],\n",
      "        [ 0.1095, -0.1939,  0.0374,  ...,  0.2946, -0.4030, -0.9804],\n",
      "        ...,\n",
      "        [-0.1641,  0.2720,  0.3255,  ..., -0.7129,  1.0207, -0.1143],\n",
      "        [-0.2287,  0.2781,  0.2978,  ..., -1.0771,  0.8759, -0.0138],\n",
      "        [-0.2287,  0.2781,  0.2978,  ..., -1.0771,  0.8759, -0.0138]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.10947028 -0.19391641  0.03742057  0.1258912  -0.33519176 -0.3754995\n",
      "  0.04337148 -0.48569807 -1.0604043  -0.08991688 -0.53200495 -1.350066\n",
      " -0.25286177 -0.6586332  -1.8091955  -0.09537277 -0.74937516 -1.2791455\n",
      "  0.14443952 -0.7539001  -1.1546586   0.14028119 -0.6838155  -1.2015643\n",
      "  0.21318327 -0.8057067  -1.303807   -0.03521048 -0.6392809  -1.2018952\n",
      "  0.10052909 -0.7033358  -1.1811275   0.15377152 -0.6844084  -1.2706988\n",
      "  0.35353374 -0.710535   -1.3540435   0.08032271 -0.59243774 -1.0155776\n",
      "  0.01857451 -0.35668847 -1.5678027   0.21741031 -0.5287279  -1.5468109\n",
      "  0.42813852 -0.4844231  -1.1840179  -0.01188256 -0.36236924 -0.94719344\n",
      "  0.10203969 -0.33628747 -0.98499066  0.1990021  -0.37325737 -1.1144516\n",
      "  0.2946094  -0.40304762 -0.98038906]\n",
      "data: [ 0.10947028 -0.19391641  0.03742057  0.1258912  -0.33519176 -0.3754995\n",
      "  0.04337148 -0.4856981  -1.0604043  -0.08991688 -0.53200495 -1.350066\n",
      " -0.25286177 -0.6586332  -1.8091955  -0.09537277 -0.74937516 -1.2791455\n",
      "  0.14443952 -0.7539002  -1.1546586   0.14028119 -0.6838155  -1.2015643\n",
      "  0.21318327 -0.80570674 -1.303807   -0.03521048 -0.6392809  -1.2018952\n",
      "  0.10052909 -0.7033358  -1.1811275   0.15377152 -0.6844084  -1.2706988\n",
      "  0.35353374 -0.710535   -1.3540435   0.08032271 -0.59243774 -1.0155776\n",
      "  0.01857451 -0.35668847 -1.5678028   0.21741031 -0.5287279  -1.5468109\n",
      "  0.42813855 -0.4844231  -1.1840179  -0.01188256 -0.36236924 -0.94719344\n",
      "  0.1020397  -0.33628747 -0.9849907   0.19900209 -0.37325737 -1.1144516\n",
      "  0.2946094  -0.40304765 -0.980389    0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0265, -0.1037, -0.2013,  ..., -0.0113, -0.3141, -1.2326],\n",
      "        [ 0.0265, -0.1037, -0.2013,  ..., -0.0113, -0.3141, -1.2326],\n",
      "        [ 0.0265, -0.1037, -0.2013,  ..., -0.0113, -0.3141, -1.2326],\n",
      "        ...,\n",
      "        [-0.3077,  0.3463, -0.2095,  ..., -0.5366,  0.8630, -0.6625],\n",
      "        [-0.2753,  0.0761,  0.4427,  ..., -0.1580,  0.8740, -0.0103],\n",
      "        [-0.2753,  0.0761,  0.4427,  ..., -0.1580,  0.8740, -0.0103]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02653239 -0.10374554 -0.2012932   0.00684976 -0.25699484 -0.6044653\n",
      " -0.14654832 -0.46943438 -1.3865197  -0.3164493  -0.5537051  -1.6626561\n",
      " -0.5232927  -0.6441692  -2.1536183  -0.19949943 -0.73784065 -1.5780597\n",
      " -0.09531161 -0.80496144 -1.4064837  -0.12965362 -0.71121144 -1.4645016\n",
      " -0.11017141 -0.8872191  -1.5567765  -0.16833463 -0.6206825  -1.5000472\n",
      " -0.13242878 -0.68141973 -1.4151981  -0.17088541 -0.6849575  -1.5030854\n",
      " -0.00286003 -0.6611788  -1.5200922  -0.10483903 -0.5544605  -1.3473592\n",
      " -0.22181436 -0.33613512 -1.9461071  -0.10130957 -0.48884118 -1.9550941\n",
      "  0.07680187 -0.47000828 -1.3677566  -0.18521844 -0.31093457 -1.2711582\n",
      " -0.17014395 -0.29722038 -1.3319066  -0.13237369 -0.28664255 -1.4394815\n",
      " -0.01128817 -0.31409174 -1.2325785 ]\n",
      "data: [ 0.02653239 -0.10374555 -0.2012932   0.00684976 -0.25699484 -0.6044653\n",
      " -0.14654832 -0.46943438 -1.3865197  -0.3164493  -0.5537051  -1.6626561\n",
      " -0.5232927  -0.6441692  -2.1536183  -0.19949943 -0.73784065 -1.5780597\n",
      " -0.09531161 -0.80496144 -1.4064837  -0.12965362 -0.71121144 -1.4645016\n",
      " -0.11017141 -0.8872191  -1.5567765  -0.16833463 -0.6206825  -1.5000472\n",
      " -0.13242878 -0.68141973 -1.4151981  -0.17088541 -0.6849575  -1.5030854\n",
      " -0.00286003 -0.6611788  -1.5200924  -0.10483903 -0.5544605  -1.3473592\n",
      " -0.22181436 -0.3361351  -1.9461071  -0.10130957 -0.48884118 -1.9550941\n",
      "  0.07680187 -0.47000828 -1.3677566  -0.18521842 -0.31093457 -1.2711582\n",
      " -0.17014395 -0.29722038 -1.3319066  -0.13237369 -0.28664255 -1.4394815\n",
      " -0.01128817 -0.31409174 -1.2325785   0.04      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B9B0>\n",
      "tensor([[ 0.0107, -0.0458, -0.1336,  ...,  0.0797, -0.2479, -1.0970],\n",
      "        [ 0.0107, -0.0458, -0.1336,  ...,  0.0797, -0.2479, -1.0970],\n",
      "        [ 0.0107, -0.0458, -0.1336,  ...,  0.0797, -0.2479, -1.0970],\n",
      "        ...,\n",
      "        [-0.1359,  0.3933, -0.0387,  ..., -0.9356,  1.0070, -0.4114],\n",
      "        [-0.0997, -0.1192,  0.5777,  ..., -0.2512,  0.5186,  0.2494],\n",
      "        [-0.0997, -0.1192,  0.5777,  ..., -0.2512,  0.5186,  0.2494]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.0699254e-02 -4.5813747e-02 -1.3364871e-01  4.4006769e-02\n",
      " -1.3690728e-01 -3.8682240e-01 -9.1158293e-02 -3.5551038e-01\n",
      " -1.2637039e+00 -2.3958592e-01 -4.1306216e-01 -1.5612280e+00\n",
      " -3.9151174e-01 -5.1002920e-01 -2.0737996e+00 -1.8058039e-01\n",
      " -6.7094648e-01 -1.4561385e+00  2.4333149e-02 -7.2560203e-01\n",
      " -1.3032863e+00 -2.0161346e-02 -6.5856767e-01 -1.3497810e+00\n",
      " -1.2824684e-03 -8.2174742e-01 -1.4854296e+00 -1.3223219e-01\n",
      " -5.8440566e-01 -1.3459554e+00 -5.3729773e-02 -6.3941288e-01\n",
      " -1.3275523e+00 -3.5234660e-02 -6.0326600e-01 -1.4181774e+00\n",
      "  1.3283351e-01 -6.5060580e-01 -1.4504299e+00 -4.0966667e-02\n",
      " -4.7810903e-01 -1.1710396e+00 -2.0576061e-01 -2.3354059e-01\n",
      " -1.9957701e+00  1.9821629e-02 -4.1955051e-01 -2.0213132e+00\n",
      "  2.2827791e-01 -3.7989047e-01 -1.2930381e+00 -1.7579752e-01\n",
      " -2.4735148e-01 -1.0836060e+00 -8.4900960e-02 -2.2129640e-01\n",
      " -1.1647197e+00 -4.2197540e-02 -2.2990732e-01 -1.2861688e+00\n",
      "  7.9677872e-02 -2.4786510e-01 -1.0970443e+00]\n",
      "data: [ 1.0699254e-02 -4.5813747e-02 -1.3364871e-01  4.4006769e-02\n",
      " -1.3690728e-01 -3.8682240e-01 -9.1158293e-02 -3.5551035e-01\n",
      " -1.2637039e+00 -2.3958592e-01 -4.1306219e-01 -1.5612280e+00\n",
      " -3.9151174e-01 -5.1002920e-01 -2.0737996e+00 -1.8058039e-01\n",
      " -6.7094648e-01 -1.4561385e+00  2.4333147e-02 -7.2560203e-01\n",
      " -1.3032863e+00 -2.0161346e-02 -6.5856767e-01 -1.3497810e+00\n",
      " -1.2824684e-03 -8.2174742e-01 -1.4854296e+00 -1.3223219e-01\n",
      " -5.8440566e-01 -1.3459554e+00 -5.3729773e-02 -6.3941288e-01\n",
      " -1.3275523e+00 -3.5234660e-02 -6.0326600e-01 -1.4181774e+00\n",
      "  1.3283351e-01 -6.5060580e-01 -1.4504300e+00 -4.0966667e-02\n",
      " -4.7810900e-01 -1.1710396e+00 -2.0576061e-01 -2.3354059e-01\n",
      " -1.9957701e+00  1.9821629e-02 -4.1955051e-01 -2.0213132e+00\n",
      "  2.2827791e-01 -3.7989047e-01 -1.2930381e+00 -1.7579752e-01\n",
      " -2.4735147e-01 -1.0836060e+00 -8.4900960e-02 -2.2129640e-01\n",
      " -1.1647197e+00 -4.2197540e-02 -2.2990732e-01 -1.2861688e+00\n",
      "  7.9677872e-02 -2.4786511e-01 -1.0970443e+00  5.0000001e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[-0.0475, -0.0320, -0.2333,  ...,  0.0066, -0.2019, -1.2741],\n",
      "        [-0.0475, -0.0320, -0.2333,  ...,  0.0066, -0.2019, -1.2741],\n",
      "        [-0.0475, -0.0320, -0.2333,  ...,  0.0066, -0.2019, -1.2741],\n",
      "        ...,\n",
      "        [-0.2316,  0.2349, -0.0593,  ..., -0.7409,  0.7375, -0.3244],\n",
      "        [-0.1692, -0.0103,  0.5452,  ..., -0.3207,  0.7383,  0.2169],\n",
      "        [-0.1692, -0.0103,  0.5452,  ..., -0.3207,  0.7383,  0.2169]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.04752785 -0.03200503 -0.23328978 -0.01514558 -0.16059017 -0.60648334\n",
      " -0.10071696 -0.34789467 -1.3795729  -0.24850366 -0.40154594 -1.6900026\n",
      " -0.416875   -0.52501225 -2.1680596  -0.25726795 -0.6287259  -1.5595663\n",
      " -0.00815848 -0.6615672  -1.3749864  -0.06553559 -0.5999764  -1.4227345\n",
      " -0.0662524  -0.73406506 -1.5452021  -0.20185554 -0.5254713  -1.4608823\n",
      " -0.11108772 -0.58363986 -1.4509254  -0.10602114 -0.55458856 -1.5482898\n",
      "  0.02183574 -0.59265375 -1.5995536  -0.09900825 -0.4354535  -1.2762628\n",
      " -0.23180766 -0.19039646 -1.9792148  -0.05022798 -0.3662008  -1.9761844\n",
      "  0.11296238 -0.32307783 -1.4423035  -0.22019865 -0.19597182 -1.2108392\n",
      " -0.11895038 -0.16903682 -1.295348   -0.06590825 -0.19439606 -1.4148331\n",
      "  0.00658488 -0.2019359  -1.274089  ]\n",
      "data: [-0.04752785 -0.03200503 -0.23328978 -0.01514558 -0.16059017 -0.60648334\n",
      " -0.10071696 -0.34789467 -1.3795729  -0.24850364 -0.40154594 -1.6900026\n",
      " -0.416875   -0.52501225 -2.1680596  -0.25726795 -0.6287259  -1.5595661\n",
      " -0.00815848 -0.6615672  -1.3749864  -0.06553559 -0.5999764  -1.4227345\n",
      " -0.0662524  -0.7340651  -1.5452021  -0.20185554 -0.5254713  -1.4608823\n",
      " -0.11108771 -0.58363986 -1.4509254  -0.10602114 -0.55458856 -1.5482898\n",
      "  0.02183574 -0.59265375 -1.5995536  -0.09900825 -0.4354535  -1.2762628\n",
      " -0.23180766 -0.19039646 -1.9792148  -0.05022798 -0.3662008  -1.9761844\n",
      "  0.11296238 -0.3230778  -1.4423034  -0.22019865 -0.19597182 -1.2108392\n",
      " -0.11895039 -0.16903682 -1.295348   -0.06590825 -0.19439606 -1.4148331\n",
      "  0.00658488 -0.2019359  -1.274089    0.06      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F438>\n",
      "tensor([[ 0.0365, -0.0798, -0.2212,  ...,  0.0371, -0.2591, -1.3077],\n",
      "        [ 0.0365, -0.0798, -0.2212,  ...,  0.0371, -0.2591, -1.3077],\n",
      "        [ 0.0365, -0.0798, -0.2212,  ...,  0.0371, -0.2591, -1.3077],\n",
      "        ...,\n",
      "        [-0.3575,  0.2666, -0.3234,  ..., -0.8858,  0.7256, -0.4618],\n",
      "        [-0.1854, -0.1214,  0.5699,  ..., -0.2421,  0.6227,  0.3286],\n",
      "        [-0.1854, -0.1214,  0.5699,  ..., -0.2421,  0.6227,  0.3286]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0365052  -0.07984552 -0.22115575  0.04539549 -0.2322418  -0.66459405\n",
      " -0.02870939 -0.39366323 -1.3684523  -0.17061414 -0.45241562 -1.6635758\n",
      " -0.34975907 -0.5686581  -2.1348226  -0.17760056 -0.67879075 -1.5226529\n",
      "  0.03491077 -0.6948919  -1.3374801  -0.01351397 -0.6323047  -1.3942139\n",
      " -0.00956421 -0.7501761  -1.5031315  -0.13865176 -0.56977737 -1.4504694\n",
      " -0.05142246 -0.6183265  -1.4280252  -0.06496051 -0.5932516  -1.5286942\n",
      "  0.06178106 -0.6045284  -1.5822287  -0.05180723 -0.49497396 -1.2859669\n",
      " -0.14109585 -0.2753058  -1.844538   -0.01093895 -0.41032913 -1.8374751\n",
      "  0.1315474  -0.38297647 -1.4476005  -0.14245355 -0.25781876 -1.2327956\n",
      " -0.07015041 -0.24028197 -1.3142384  -0.02593727 -0.25014827 -1.4329195\n",
      "  0.0371315  -0.2590586  -1.3076867 ]\n",
      "data: [ 0.0365052  -0.07984552 -0.22115573  0.04539549 -0.23224181 -0.66459405\n",
      " -0.02870939 -0.39366323 -1.3684523  -0.17061415 -0.45241562 -1.6635758\n",
      " -0.34975907 -0.5686581  -2.1348226  -0.17760056 -0.67879075 -1.5226529\n",
      "  0.03491077 -0.694892   -1.3374801  -0.01351397 -0.6323047  -1.3942139\n",
      " -0.00956421 -0.7501761  -1.5031315  -0.13865176 -0.56977737 -1.4504694\n",
      " -0.05142246 -0.6183265  -1.4280252  -0.06496051 -0.5932516  -1.5286942\n",
      "  0.06178106 -0.6045284  -1.5822287  -0.05180723 -0.49497396 -1.2859668\n",
      " -0.14109585 -0.2753058  -1.844538   -0.01093895 -0.41032913 -1.8374752\n",
      "  0.1315474  -0.38297644 -1.4476006  -0.14245355 -0.25781876 -1.2327956\n",
      " -0.07015041 -0.24028197 -1.3142384  -0.02593727 -0.25014827 -1.4329195\n",
      "  0.0371315  -0.2590586  -1.3076866   0.07      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0300, -0.0855, -0.2662,  ...,  0.0435, -0.2721, -1.3026],\n",
      "        [ 0.0300, -0.0855, -0.2662,  ...,  0.0435, -0.2721, -1.3026],\n",
      "        [ 0.0300, -0.0855, -0.2662,  ...,  0.0435, -0.2721, -1.3026],\n",
      "        ...,\n",
      "        [-0.1621,  0.4260, -0.0616,  ..., -0.7210,  0.9296, -0.3488],\n",
      "        [-0.1717, -0.1178,  0.6036,  ..., -0.2575,  0.6753,  0.2504],\n",
      "        [-0.1717, -0.1178,  0.6036,  ..., -0.2575,  0.6753,  0.2504]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03001116 -0.08546736 -0.2661975   0.05286911 -0.20814876 -0.6520318\n",
      " -0.06945959 -0.4110108  -1.445709   -0.21771476 -0.47756594 -1.7318786\n",
      " -0.3715291  -0.5708638  -2.229093   -0.16492987 -0.7074373  -1.6056985\n",
      "  0.0062091  -0.7565116  -1.4342749  -0.04280115 -0.68256783 -1.4927124\n",
      " -0.0504147  -0.835293   -1.6119447  -0.12670735 -0.614723   -1.5182621\n",
      " -0.06695084 -0.66360694 -1.4844162  -0.08759505 -0.63449764 -1.570353\n",
      "  0.04819461 -0.6536054  -1.5955487  -0.05037387 -0.51800954 -1.3562906\n",
      " -0.17715997 -0.28734082 -2.0302758  -0.02137205 -0.4419517  -2.0469222\n",
      "  0.1407601  -0.41104484 -1.4614493  -0.15223348 -0.2878842  -1.2821951\n",
      " -0.09190849 -0.25941417 -1.3668846  -0.05545958 -0.25802174 -1.4802126\n",
      "  0.04352298 -0.27212676 -1.3025512 ]\n",
      "data: [ 0.03001116 -0.08546736 -0.2661975   0.0528691  -0.20814876 -0.6520318\n",
      " -0.06945959 -0.41101083 -1.4457089  -0.21771474 -0.47756594 -1.7318786\n",
      " -0.37152907 -0.5708638  -2.229093   -0.16492987 -0.7074373  -1.6056983\n",
      "  0.0062091  -0.7565116  -1.4342749  -0.04280115 -0.68256783 -1.4927124\n",
      " -0.0504147  -0.835293   -1.6119447  -0.12670735 -0.614723   -1.5182621\n",
      " -0.06695084 -0.66360694 -1.4844162  -0.08759505 -0.63449764 -1.570353\n",
      "  0.04819461 -0.6536054  -1.5955487  -0.05037387 -0.51800954 -1.3562906\n",
      " -0.17715997 -0.28734082 -2.0302758  -0.02137205 -0.44195166 -2.0469222\n",
      "  0.1407601  -0.41104484 -1.4614493  -0.15223348 -0.2878842  -1.2821951\n",
      " -0.09190849 -0.25941417 -1.3668846  -0.05545958 -0.25802174 -1.4802126\n",
      "  0.04352298 -0.27212676 -1.3025512   0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0160, -0.0404, -0.2333,  ...,  0.0518, -0.2287, -1.2800],\n",
      "        [ 0.0160, -0.0404, -0.2333,  ...,  0.0518, -0.2287, -1.2800],\n",
      "        [ 0.0160, -0.0404, -0.2333,  ...,  0.0518, -0.2287, -1.2800],\n",
      "        ...,\n",
      "        [-0.1548,  0.3516, -0.1062,  ..., -0.8125,  0.8441, -0.3372],\n",
      "        [-0.1364, -0.1505,  0.5539,  ..., -0.2297,  0.5905,  0.2307],\n",
      "        [-0.1364, -0.1505,  0.5539,  ..., -0.2297,  0.5905,  0.2307]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.6022500e-02 -4.0387843e-02 -2.3332985e-01  3.1469058e-02\n",
      " -1.8228397e-01 -6.4529467e-01 -3.5978615e-02 -3.5702634e-01\n",
      " -1.3698310e+00 -1.7715789e-01 -4.1346478e-01 -1.6796170e+00\n",
      " -3.5310623e-01 -5.3878474e-01 -2.1438079e+00 -1.9196373e-01\n",
      " -6.3931721e-01 -1.5390723e+00  4.9977630e-02 -6.6318631e-01\n",
      " -1.3498473e+00 -5.6901276e-03 -6.0701001e-01 -1.4024655e+00\n",
      " -2.7487725e-03 -7.3537612e-01 -1.5197453e+00 -1.4290661e-01\n",
      " -5.3142589e-01 -1.4497210e+00 -4.8702948e-02 -5.8961642e-01\n",
      " -1.4321742e+00 -5.3668946e-02 -5.6805879e-01 -1.5344608e+00\n",
      "  6.9533989e-02 -5.9774613e-01 -1.5872433e+00 -4.2942144e-02\n",
      " -4.4611031e-01 -1.2731590e+00 -1.5631101e-01 -2.2346018e-01\n",
      " -1.9113375e+00 -4.7753751e-04 -3.8243544e-01 -1.9037454e+00\n",
      "  1.5221033e-01 -3.5012603e-01 -1.4346929e+00 -1.5079901e-01\n",
      " -2.0942369e-01 -1.2130054e+00 -5.6753948e-02 -1.9370966e-01\n",
      " -1.2917308e+00 -1.1056855e-02 -2.1828811e-01 -1.4095503e+00\n",
      "  5.1759548e-02 -2.2866932e-01 -1.2799913e+00]\n",
      "data: [ 1.6022500e-02 -4.0387847e-02 -2.3332985e-01  3.1469058e-02\n",
      " -1.8228397e-01 -6.4529467e-01 -3.5978615e-02 -3.5702634e-01\n",
      " -1.3698310e+00 -1.7715789e-01 -4.1346478e-01 -1.6796170e+00\n",
      " -3.5310623e-01 -5.3878474e-01 -2.1438079e+00 -1.9196373e-01\n",
      " -6.3931721e-01 -1.5390723e+00  4.9977630e-02 -6.6318631e-01\n",
      " -1.3498473e+00 -5.6901276e-03 -6.0701001e-01 -1.4024655e+00\n",
      " -2.7487725e-03 -7.3537612e-01 -1.5197453e+00 -1.4290661e-01\n",
      " -5.3142589e-01 -1.4497209e+00 -4.8702944e-02 -5.8961642e-01\n",
      " -1.4321742e+00 -5.3668946e-02 -5.6805879e-01 -1.5344608e+00\n",
      "  6.9533989e-02 -5.9774613e-01 -1.5872433e+00 -4.2942144e-02\n",
      " -4.4611031e-01 -1.2731590e+00 -1.5631101e-01 -2.2346018e-01\n",
      " -1.9113374e+00 -4.7753751e-04 -3.8243544e-01 -1.9037454e+00\n",
      "  1.5221033e-01 -3.5012603e-01 -1.4346929e+00 -1.5079901e-01\n",
      " -2.0942369e-01 -1.2130054e+00 -5.6753948e-02 -1.9370966e-01\n",
      " -1.2917308e+00 -1.1056854e-02 -2.1828812e-01 -1.4095503e+00\n",
      "  5.1759548e-02 -2.2866932e-01 -1.2799913e+00  9.0000004e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[ 0.0073, -0.0835, -0.2645,  ...,  0.0326, -0.2676, -1.3298],\n",
      "        [ 0.0073, -0.0835, -0.2645,  ...,  0.0326, -0.2676, -1.3298],\n",
      "        [ 0.0073, -0.0835, -0.2645,  ...,  0.0326, -0.2676, -1.3298],\n",
      "        ...,\n",
      "        [-0.1589,  0.4164, -0.1045,  ..., -0.7288,  0.9021, -0.3336],\n",
      "        [-0.1565, -0.1272,  0.5840,  ..., -0.2358,  0.6603,  0.2389],\n",
      "        [-0.1565, -0.1272,  0.5840,  ..., -0.2358,  0.6603,  0.2389]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00731288 -0.08350725 -0.26453796  0.02522214 -0.22800419 -0.6923003\n",
      " -0.05959295 -0.40450117 -1.4343832  -0.19971764 -0.46650782 -1.7290659\n",
      " -0.36926585 -0.580518   -2.2015793  -0.19554037 -0.6855203  -1.5928788\n",
      "  0.01873082 -0.7106441  -1.4007244  -0.02858114 -0.64672816 -1.4569228\n",
      " -0.02640221 -0.7735262  -1.5713642  -0.15460242 -0.5788188  -1.5122528\n",
      " -0.06952529 -0.63097703 -1.4857979  -0.08062269 -0.60667765 -1.5802765\n",
      "  0.05174457 -0.6236774  -1.6303947  -0.06798903 -0.5000991  -1.340869\n",
      " -0.17027193 -0.2739504  -1.9504261  -0.02526122 -0.4214587  -1.9469404\n",
      "  0.12857524 -0.39116302 -1.4844217  -0.16510099 -0.26277813 -1.2783201\n",
      " -0.08835128 -0.24184215 -1.3572636  -0.03978822 -0.2542853  -1.4737508\n",
      "  0.03260317 -0.26756114 -1.3298178 ]\n",
      "data: [ 0.00731288 -0.08350725 -0.26453796  0.02522214 -0.22800419 -0.6923003\n",
      " -0.05959295 -0.40450114 -1.434383   -0.19971764 -0.46650782 -1.7290659\n",
      " -0.36926585 -0.580518   -2.2015793  -0.19554037 -0.68552035 -1.5928788\n",
      "  0.01873082 -0.7106441  -1.4007245  -0.02858114 -0.64672816 -1.4569228\n",
      " -0.02640221 -0.77352613 -1.5713642  -0.15460242 -0.5788188  -1.5122528\n",
      " -0.06952529 -0.63097703 -1.4857979  -0.0806227  -0.60667765 -1.5802765\n",
      "  0.05174457 -0.6236774  -1.6303947  -0.06798903 -0.5000991  -1.340869\n",
      " -0.17027193 -0.2739504  -1.950426   -0.02526122 -0.4214587  -1.9469404\n",
      "  0.12857524 -0.39116302 -1.4844217  -0.16510099 -0.26277813 -1.2783201\n",
      " -0.08835128 -0.24184215 -1.3572634  -0.03978822 -0.2542853  -1.4737507\n",
      "  0.03260317 -0.26756114 -1.3298178   0.1       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0442, -0.1407, -0.2769,  ...,  0.0571, -0.3139, -1.3468],\n",
      "        [ 0.0442, -0.1407, -0.2769,  ...,  0.0571, -0.3139, -1.3468],\n",
      "        [ 0.0442, -0.1407, -0.2769,  ...,  0.0571, -0.3139, -1.3468],\n",
      "        ...,\n",
      "        [-0.1298,  0.4192, -0.1651,  ..., -0.7336,  0.9255, -0.4533],\n",
      "        [-0.1769, -0.1050,  0.6035,  ..., -0.2547,  0.6488,  0.2805],\n",
      "        [-0.1769, -0.1050,  0.6035,  ..., -0.2547,  0.6488,  0.2805]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0442343  -0.14072695 -0.276866    0.07345359 -0.26916862 -0.6740781\n",
      " -0.00991322 -0.46117404 -1.4498541  -0.15397242 -0.51878846 -1.7580119\n",
      " -0.31267235 -0.63114405 -2.2495568  -0.16033176 -0.745718   -1.6291776\n",
      "  0.07051743 -0.7814219  -1.4420729   0.01184989 -0.7225317  -1.4936262\n",
      " -0.00240553 -0.8600856  -1.6175839  -0.11490089 -0.6454574  -1.5329305\n",
      " -0.03357298 -0.70125973 -1.5173595  -0.0442099  -0.67181134 -1.6150436\n",
      "  0.07189813 -0.7082546  -1.6595271  -0.02153668 -0.5462886  -1.360018\n",
      " -0.1542494  -0.315119   -2.0407212   0.00964979 -0.4800514  -2.044565\n",
      "  0.15781844 -0.44196835 -1.5120784  -0.13872564 -0.31243515 -1.2911707\n",
      " -0.05035467 -0.2870557  -1.3708166  -0.01005387 -0.30707356 -1.487267\n",
      "  0.05708508 -0.3138907  -1.3467529 ]\n",
      "data: [ 0.0442343  -0.14072695 -0.276866    0.07345359 -0.26916862 -0.67407817\n",
      " -0.00991322 -0.46117404 -1.4498541  -0.15397242 -0.51878846 -1.7580119\n",
      " -0.31267235 -0.63114405 -2.2495568  -0.16033177 -0.745718   -1.6291776\n",
      "  0.07051743 -0.7814219  -1.4420729   0.01184989 -0.7225317  -1.4936262\n",
      " -0.00240553 -0.8600856  -1.6175839  -0.11490089 -0.6454574  -1.5329305\n",
      " -0.03357298 -0.7012598  -1.5173595  -0.0442099  -0.67181134 -1.6150436\n",
      "  0.07189813 -0.7082546  -1.6595272  -0.02153668 -0.5462886  -1.360018\n",
      " -0.1542494  -0.315119   -2.0407212   0.00964979 -0.4800514  -2.044565\n",
      "  0.15781844 -0.44196835 -1.5120784  -0.13872564 -0.31243515 -1.2911706\n",
      " -0.05035467 -0.2870557  -1.3708167  -0.01005387 -0.30707356 -1.487267\n",
      "  0.05708508 -0.3138907  -1.3467529   0.11      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0199, -0.1134, -0.2325,  ...,  0.0737, -0.2932, -1.3197],\n",
      "        [ 0.0199, -0.1134, -0.2325,  ...,  0.0737, -0.2932, -1.3197],\n",
      "        [ 0.0199, -0.1134, -0.2325,  ...,  0.0737, -0.2932, -1.3197],\n",
      "        ...,\n",
      "        [-0.0769,  0.4385, -0.0781,  ..., -0.6320,  0.9308, -0.3614],\n",
      "        [-0.0985, -0.0664,  0.5868,  ..., -0.1681,  0.6229,  0.2804],\n",
      "        [-0.0985, -0.0664,  0.5868,  ..., -0.1681,  0.6229,  0.2804]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0198884  -0.11342624 -0.23247993  0.03353779 -0.27724114 -0.6588017\n",
      "  0.0027499  -0.44499847 -1.3701278  -0.14011428 -0.49986196 -1.6982958\n",
      " -0.33118314 -0.6533985  -2.150717   -0.20608792 -0.6998179  -1.5706323\n",
      "  0.10434181 -0.7135947  -1.3467054   0.03889339 -0.67104447 -1.3880447\n",
      "  0.04192138 -0.77777386 -1.5052147  -0.14416862 -0.57427096 -1.4751954\n",
      " -0.02199395 -0.6456108  -1.4646983  -0.01461438 -0.62828803 -1.5766133\n",
      "  0.0929865  -0.6712128  -1.6490145  -0.02001281 -0.4938425  -1.283363\n",
      " -0.12752095 -0.27336147 -1.8819734   0.0265715  -0.44293195 -1.8533182\n",
      "  0.1729101  -0.40348938 -1.4805117  -0.14120278 -0.24378324 -1.2290552\n",
      " -0.01264223 -0.23547098 -1.2997345   0.04391415 -0.28825825 -1.4166347\n",
      "  0.07371712 -0.29319733 -1.3196865 ]\n",
      "data: [ 0.0198884  -0.11342624 -0.23247993  0.03353779 -0.27724114 -0.6588017\n",
      "  0.0027499  -0.44499847 -1.3701279  -0.14011428 -0.49986196 -1.698296\n",
      " -0.33118314 -0.6533985  -2.150717   -0.20608792 -0.6998179  -1.5706323\n",
      "  0.10434181 -0.7135947  -1.3467054   0.03889339 -0.67104447 -1.3880447\n",
      "  0.04192139 -0.7777739  -1.5052147  -0.14416862 -0.57427096 -1.4751954\n",
      " -0.02199395 -0.6456108  -1.4646983  -0.01461438 -0.62828803 -1.5766133\n",
      "  0.09298649 -0.6712128  -1.6490145  -0.02001281 -0.4938425  -1.283363\n",
      " -0.12752095 -0.27336147 -1.8819734   0.0265715  -0.44293195 -1.8533182\n",
      "  0.1729101  -0.40348938 -1.4805117  -0.14120278 -0.24378322 -1.2290552\n",
      " -0.01264223 -0.23547098 -1.2997345   0.04391415 -0.28825825 -1.4166347\n",
      "  0.07371712 -0.29319733 -1.3196865   0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0334, -0.1408, -0.2452,  ...,  0.0551, -0.3268, -1.2961],\n",
      "        [ 0.0334, -0.1408, -0.2452,  ...,  0.0551, -0.3268, -1.2961],\n",
      "        [ 0.0334, -0.1408, -0.2452,  ...,  0.0551, -0.3268, -1.2961],\n",
      "        ...,\n",
      "        [-0.1498,  0.4670, -0.1360,  ..., -0.6433,  0.9644, -0.4673],\n",
      "        [-0.1747, -0.0930,  0.6333,  ..., -0.2406,  0.6699,  0.2668],\n",
      "        [-0.1747, -0.0930,  0.6333,  ..., -0.2406,  0.6699,  0.2668]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03337443 -0.14081204 -0.24520311  0.05340763 -0.27913582 -0.6448836\n",
      " -0.04398429 -0.48262063 -1.4232676  -0.18985343 -0.5488033  -1.720706\n",
      " -0.355391   -0.661993   -2.1986635  -0.17258534 -0.7595471  -1.5919206\n",
      "  0.04394668 -0.80380404 -1.3880548  -0.01141208 -0.74065775 -1.4385564\n",
      " -0.02354239 -0.88172144 -1.5578752  -0.12696537 -0.65383154 -1.4998229\n",
      " -0.0514404  -0.7124413  -1.470639   -0.06284167 -0.68701226 -1.5594604\n",
      "  0.06049979 -0.7155316  -1.5988476  -0.0347292  -0.5586611  -1.3308668\n",
      " -0.16431123 -0.33183306 -1.9950731  -0.00527975 -0.49596912 -1.9968452\n",
      "  0.14933231 -0.45645636 -1.4559219  -0.14601463 -0.32145533 -1.260459\n",
      " -0.06484921 -0.2980708  -1.3418903  -0.02130768 -0.3153522  -1.4544008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.05514967 -0.32676554 -1.2961006 ]\n",
      "data: [ 0.03337443 -0.14081204 -0.24520311  0.05340762 -0.27913582 -0.6448836\n",
      " -0.04398429 -0.48262063 -1.4232677  -0.18985344 -0.5488033  -1.720706\n",
      " -0.355391   -0.661993   -2.1986635  -0.17258534 -0.7595471  -1.5919206\n",
      "  0.04394668 -0.80380404 -1.3880548  -0.01141208 -0.74065775 -1.4385563\n",
      " -0.02354239 -0.88172144 -1.5578752  -0.12696537 -0.65383154 -1.4998229\n",
      " -0.0514404  -0.7124413  -1.470639   -0.06284167 -0.68701226 -1.5594604\n",
      "  0.0604998  -0.7155316  -1.5988476  -0.0347292  -0.5586611  -1.3308668\n",
      " -0.16431123 -0.33183306 -1.9950731  -0.00527975 -0.49596912 -1.9968452\n",
      "  0.14933231 -0.45645636 -1.4559219  -0.14601463 -0.32145536 -1.260459\n",
      " -0.06484921 -0.2980708  -1.3418902  -0.02130768 -0.3153522  -1.4544008\n",
      "  0.05514967 -0.3267655  -1.2961006   0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[ 0.0220, -0.1075, -0.2002,  ...,  0.0765, -0.3063, -1.1808],\n",
      "        [ 0.0220, -0.1075, -0.2002,  ...,  0.0765, -0.3063, -1.1808],\n",
      "        [ 0.0220, -0.1075, -0.2002,  ...,  0.0765, -0.3063, -1.1808],\n",
      "        ...,\n",
      "        [-0.0722,  0.4364, -0.1034,  ..., -0.6443,  0.9817, -0.4514],\n",
      "        [-0.1130, -0.0750,  0.6048,  ..., -0.2226,  0.6278,  0.2503],\n",
      "        [-0.1130, -0.0750,  0.6048,  ..., -0.2226,  0.6278,  0.2503]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02196462 -0.10750688 -0.2001517   0.05891377 -0.2101639  -0.48762792\n",
      " -0.06946833 -0.43459263 -1.3409092  -0.22157387 -0.49802777 -1.6389079\n",
      " -0.36903954 -0.5993389  -2.150459   -0.16811745 -0.737298   -1.5277975\n",
      "  0.02860849 -0.800633   -1.3777139  -0.03167365 -0.7317887  -1.4268277\n",
      " -0.04015756 -0.8989055  -1.5549066  -0.11723518 -0.6519225  -1.4201655\n",
      " -0.05126228 -0.7091822  -1.4006689  -0.0593684  -0.67527235 -1.4866774\n",
      "  0.07094985 -0.7203642  -1.5044243  -0.02415771 -0.53836    -1.2492917\n",
      " -0.18526445 -0.30042762 -2.03259     0.00961658 -0.48537827 -2.0541375\n",
      "  0.18208544 -0.4446069  -1.3609595  -0.15150814 -0.31212234 -1.1698174\n",
      " -0.06488454 -0.28568152 -1.2562087  -0.03044236 -0.29614982 -1.3704946\n",
      "  0.07648835 -0.30627674 -1.1807768 ]\n",
      "data: [ 0.02196462 -0.10750688 -0.2001517   0.05891377 -0.21016389 -0.4876279\n",
      " -0.06946833 -0.43459263 -1.3409092  -0.22157387 -0.49802777 -1.6389079\n",
      " -0.36903954 -0.5993389  -2.150459   -0.16811745 -0.73729795 -1.5277973\n",
      "  0.02860849 -0.800633   -1.3777139  -0.03167365 -0.7317887  -1.4268277\n",
      " -0.04015756 -0.8989055  -1.5549066  -0.11723518 -0.6519225  -1.4201655\n",
      " -0.05126228 -0.7091822  -1.4006687  -0.0593684  -0.67527235 -1.4866774\n",
      "  0.07094985 -0.7203642  -1.5044243  -0.02415771 -0.53836    -1.2492917\n",
      " -0.18526445 -0.30042762 -2.03259     0.00961658 -0.48537827 -2.0541375\n",
      "  0.18208544 -0.4446069  -1.3609595  -0.15150814 -0.31212234 -1.1698174\n",
      " -0.06488454 -0.28568152 -1.2562087  -0.03044236 -0.29614982 -1.3704945\n",
      "  0.07648835 -0.30627674 -1.1807768   0.14      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[-0.0174, -0.0707, -0.1800,  ...,  0.0470, -0.2599, -1.1807],\n",
      "        [-0.0174, -0.0707, -0.1800,  ...,  0.0470, -0.2599, -1.1807],\n",
      "        [-0.0174, -0.0707, -0.1800,  ...,  0.0470, -0.2599, -1.1807],\n",
      "        ...,\n",
      "        [-0.1285,  0.3190, -0.0127,  ..., -0.6724,  0.8439, -0.3405],\n",
      "        [-0.1039, -0.0675,  0.5708,  ..., -0.2200,  0.6337,  0.2167],\n",
      "        [-0.1039, -0.0675,  0.5708,  ..., -0.2200,  0.6337,  0.2167]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01738298 -0.07068688 -0.18001726  0.00997797 -0.19773917 -0.5068219\n",
      " -0.08457222 -0.40487918 -1.3121611  -0.2345083  -0.46479127 -1.6246824\n",
      " -0.41087726 -0.59168136 -2.1021366  -0.2277962  -0.68646145 -1.4949126\n",
      "  0.02835561 -0.73002446 -1.2872285  -0.03046602 -0.67371285 -1.3303776\n",
      " -0.03405957 -0.81656575 -1.4577973  -0.16946508 -0.5810826  -1.3880618\n",
      " -0.07722964 -0.6475121  -1.3717637  -0.0681501  -0.619959   -1.4698539\n",
      "  0.06595103 -0.66572976 -1.5178413  -0.06099596 -0.48231024 -1.2038423\n",
      " -0.20941085 -0.24658713 -1.9505427  -0.01313177 -0.43124357 -1.9502238\n",
      "  0.16185942 -0.3872945  -1.3550609  -0.18993509 -0.24166879 -1.1340882\n",
      " -0.08402763 -0.22170246 -1.2151088  -0.03291407 -0.25099444 -1.3331661\n",
      "  0.04696316 -0.25987768 -1.1807243 ]\n",
      "data: [-0.01738298 -0.07068688 -0.18001726  0.00997797 -0.19773917 -0.5068219\n",
      " -0.08457222 -0.40487918 -1.3121611  -0.2345083  -0.46479127 -1.6246824\n",
      " -0.41087726 -0.59168136 -2.1021366  -0.2277962  -0.6864615  -1.4949126\n",
      "  0.02835561 -0.7300245  -1.2872283  -0.03046602 -0.67371285 -1.3303775\n",
      " -0.03405957 -0.81656575 -1.4577973  -0.16946508 -0.5810826  -1.3880619\n",
      " -0.07722964 -0.6475121  -1.3717637  -0.0681501  -0.619959   -1.4698539\n",
      "  0.06595103 -0.66572976 -1.5178413  -0.06099596 -0.4823102  -1.2038423\n",
      " -0.20941085 -0.24658713 -1.9505428  -0.01313177 -0.43124354 -1.9502238\n",
      "  0.16185942 -0.3872945  -1.3550609  -0.18993509 -0.24166879 -1.1340882\n",
      " -0.08402763 -0.22170246 -1.2151088  -0.03291407 -0.25099444 -1.3331662\n",
      "  0.04696316 -0.25987768 -1.1807243   0.15      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FF28>\n",
      "tensor([[-0.0294, -0.0585, -0.2561,  ..., -0.0165, -0.2226, -1.2956],\n",
      "        [-0.0294, -0.0585, -0.2561,  ..., -0.0165, -0.2226, -1.2956],\n",
      "        [-0.0294, -0.0585, -0.2561,  ..., -0.0165, -0.2226, -1.2956],\n",
      "        ...,\n",
      "        [-0.1867,  0.3754, -0.0860,  ..., -0.6953,  0.8866, -0.3945],\n",
      "        [-0.0909, -0.0796,  0.6451,  ..., -0.1942,  0.6883,  0.2504],\n",
      "        [-0.0909, -0.0796,  0.6451,  ..., -0.1942,  0.6883,  0.2504]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.02942339 -0.05851199 -0.25613755 -0.00293386 -0.18086953 -0.6257148\n",
      " -0.11008658 -0.384264   -1.4254098  -0.25885904 -0.44430116 -1.7319013\n",
      " -0.42489704 -0.5486962  -2.2229888  -0.23894912 -0.6740234  -1.5900537\n",
      " -0.02613577 -0.71416885 -1.3980272  -0.07816748 -0.6518375  -1.4517076\n",
      " -0.08928872 -0.79907376 -1.5815668  -0.19502814 -0.5746202  -1.4903814\n",
      " -0.12134207 -0.6279523  -1.4703873  -0.12634471 -0.5946407  -1.5709118\n",
      "  0.01283352 -0.62825185 -1.6141744  -0.10662896 -0.46969625 -1.3169208\n",
      " -0.24754962 -0.23623428 -2.0306742  -0.06958606 -0.39851263 -2.0442085\n",
      "  0.10093769 -0.36114055 -1.4626015  -0.22380322 -0.2336064  -1.2439167\n",
      " -0.14617819 -0.20444179 -1.3294038  -0.10488859 -0.21434967 -1.4505628\n",
      " -0.01650789 -0.22260843 -1.2956134 ]\n",
      "data: [-0.02942339 -0.05851199 -0.25613755 -0.00293386 -0.18086953 -0.6257148\n",
      " -0.11008658 -0.384264   -1.4254098  -0.25885904 -0.44430116 -1.7319013\n",
      " -0.42489704 -0.5486962  -2.2229888  -0.23894912 -0.6740234  -1.5900537\n",
      " -0.02613577 -0.71416885 -1.3980272  -0.07816748 -0.6518375  -1.4517076\n",
      " -0.08928872 -0.7990738  -1.5815668  -0.19502813 -0.5746202  -1.4903814\n",
      " -0.12134207 -0.6279523  -1.4703872  -0.12634471 -0.5946407  -1.5709118\n",
      "  0.01283352 -0.62825185 -1.6141744  -0.10662896 -0.46969622 -1.3169208\n",
      " -0.24754962 -0.23623428 -2.0306742  -0.06958606 -0.39851266 -2.0442085\n",
      "  0.10093769 -0.36114055 -1.4626014  -0.22380322 -0.2336064  -1.2439167\n",
      " -0.14617819 -0.2044418  -1.3294036  -0.10488859 -0.21434967 -1.450563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.01650789 -0.22260843 -1.2956134   0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[ 0.0449, -0.0638, -0.1822,  ...,  0.0326, -0.2522, -1.2240],\n",
      "        [ 0.0449, -0.0638, -0.1822,  ...,  0.0326, -0.2522, -1.2240],\n",
      "        [ 0.0449, -0.0638, -0.1822,  ...,  0.0326, -0.2522, -1.2240],\n",
      "        ...,\n",
      "        [-0.4283,  0.1272, -0.4285,  ..., -0.9319,  0.5326, -0.5907],\n",
      "        [-0.1339, -0.1094,  0.5698,  ..., -0.2039,  0.6495,  0.2870],\n",
      "        [-0.1339, -0.1094,  0.5698,  ..., -0.2039,  0.6495,  0.2870]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04488851 -0.06375446 -0.18215117  0.05527742 -0.19230963 -0.5832061\n",
      " -0.06098487 -0.3768145  -1.3326105  -0.20929474 -0.44102618 -1.6184021\n",
      " -0.37899673 -0.5296615  -2.1077352  -0.15166295 -0.6859376  -1.4762589\n",
      " -0.00368777 -0.72560537 -1.328981   -0.04978207 -0.649938   -1.3928956\n",
      " -0.0493612  -0.8012313  -1.5037017  -0.11901276 -0.59240276 -1.3991326\n",
      " -0.06243594 -0.63479006 -1.3652725  -0.0915537  -0.60902363 -1.4609815\n",
      "  0.04655309 -0.61411506 -1.4882457  -0.05123544 -0.5029135  -1.2451984\n",
      " -0.1631194  -0.28123188 -1.884267   -0.02508973 -0.4181239  -1.9014267\n",
      "  0.12840326 -0.39613277 -1.361805   -0.13953008 -0.27441087 -1.1809915\n",
      " -0.09615248 -0.251477   -1.2711673  -0.06586297 -0.23931676 -1.388767\n",
      "  0.03262962 -0.25216877 -1.2239504 ]\n",
      "data: [ 0.04488851 -0.06375446 -0.18215117  0.05527742 -0.19230963 -0.5832061\n",
      " -0.06098487 -0.37681448 -1.3326105  -0.20929474 -0.44102618 -1.6184021\n",
      " -0.37899673 -0.5296615  -2.1077352  -0.15166295 -0.6859376  -1.4762589\n",
      " -0.00368777 -0.72560537 -1.328981   -0.04978207 -0.649938   -1.3928955\n",
      " -0.0493612  -0.8012313  -1.5037017  -0.11901276 -0.59240276 -1.3991325\n",
      " -0.06243594 -0.63479006 -1.3652725  -0.09155371 -0.60902363 -1.4609815\n",
      "  0.04655309 -0.61411506 -1.4882457  -0.05123545 -0.5029135  -1.2451984\n",
      " -0.1631194  -0.28123188 -1.884267   -0.02508973 -0.4181239  -1.9014267\n",
      "  0.12840326 -0.39613277 -1.361805   -0.13953008 -0.27441087 -1.1809915\n",
      " -0.09615248 -0.251477   -1.2711673  -0.06586297 -0.23931676 -1.3887669\n",
      "  0.03262962 -0.25216877 -1.2239504   0.17      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FA58>\n",
      "tensor([[-0.0147, -0.0399, -0.2009,  ...,  0.0104, -0.2475, -1.1818],\n",
      "        [-0.0147, -0.0399, -0.2009,  ...,  0.0104, -0.2475, -1.1818],\n",
      "        [-0.0147, -0.0399, -0.2009,  ...,  0.0104, -0.2475, -1.1818],\n",
      "        ...,\n",
      "        [-0.2731,  0.2822, -0.1979,  ..., -0.8437,  0.7694, -0.4451],\n",
      "        [-0.1241, -0.0781,  0.5691,  ..., -0.2441,  0.7079,  0.2290],\n",
      "        [-0.1241, -0.0781,  0.5691,  ..., -0.2441,  0.7079,  0.2290]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01468043 -0.03994243 -0.20087151  0.01651802 -0.13222301 -0.5151653\n",
      " -0.15067913 -0.35898247 -1.3706665  -0.3023232  -0.43038324 -1.6430578\n",
      " -0.4424686  -0.4989596  -2.1600275  -0.18821758 -0.6827426  -1.5202235\n",
      " -0.07109059 -0.7560701  -1.3883553  -0.11398026 -0.66857994 -1.4480468\n",
      " -0.12385739 -0.85266066 -1.5685134  -0.15374081 -0.60997486 -1.4269744\n",
      " -0.11624099 -0.65585417 -1.3875543  -0.14400041 -0.6205798  -1.463772\n",
      "  0.00869764 -0.63991356 -1.468853   -0.09131496 -0.50387347 -1.2762176\n",
      " -0.24056652 -0.26615787 -2.041606   -0.06479672 -0.42921126 -2.0802178\n",
      "  0.11183268 -0.39898938 -1.3458047  -0.19571911 -0.28355476 -1.1904899\n",
      " -0.15545443 -0.24935898 -1.2851318  -0.12526536 -0.22980618 -1.3985293\n",
      "  0.01035555 -0.24754305 -1.1818293 ]\n",
      "data: [-0.01468043 -0.03994243 -0.20087151  0.01651802 -0.13222301 -0.5151653\n",
      " -0.15067913 -0.35898247 -1.3706665  -0.3023232  -0.43038324 -1.6430578\n",
      " -0.4424686  -0.49895963 -2.1600275  -0.18821758 -0.6827426  -1.5202235\n",
      " -0.07109059 -0.7560701  -1.3883553  -0.11398026 -0.66857994 -1.4480469\n",
      " -0.12385739 -0.85266066 -1.5685134  -0.15374081 -0.60997486 -1.4269745\n",
      " -0.11624099 -0.65585417 -1.3875543  -0.14400041 -0.6205798  -1.4637722\n",
      "  0.00869764 -0.63991356 -1.468853   -0.09131496 -0.50387347 -1.2762176\n",
      " -0.24056652 -0.26615787 -2.041606   -0.06479672 -0.42921126 -2.0802178\n",
      "  0.11183268 -0.39898938 -1.3458047  -0.19571911 -0.28355476 -1.1904899\n",
      " -0.15545443 -0.24935898 -1.2851318  -0.12526536 -0.22980617 -1.3985294\n",
      "  0.01035555 -0.24754305 -1.1818293   0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[-0.0128,  0.0170, -0.2028,  ...,  0.0043, -0.1524, -1.2759],\n",
      "        [-0.0128,  0.0170, -0.2028,  ...,  0.0043, -0.1524, -1.2759],\n",
      "        [-0.0128,  0.0170, -0.2028,  ...,  0.0043, -0.1524, -1.2759],\n",
      "        ...,\n",
      "        [-0.2461,  0.2061, -0.1054,  ..., -0.8080,  0.7046, -0.3650],\n",
      "        [-0.2041, -0.2139,  0.5309,  ..., -0.3344,  0.5134,  0.2616],\n",
      "        [-0.2041, -0.2139,  0.5309,  ..., -0.3344,  0.5134,  0.2616]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-1.28494091e-02  1.70329046e-02 -2.02845231e-01 -1.58371404e-03\n",
      " -1.34092718e-01 -6.49278164e-01 -7.11460486e-02 -3.04924011e-01\n",
      " -1.35934174e+00 -2.15329304e-01 -3.61425042e-01 -1.66638196e+00\n",
      " -4.06155556e-01 -4.85077024e-01 -2.11680055e+00 -2.30345637e-01\n",
      " -5.82253218e-01 -1.51137459e+00  1.48954988e-02 -6.00909472e-01\n",
      " -1.29944599e+00 -3.09942961e-02 -5.44003069e-01 -1.34941638e+00\n",
      " -2.65007019e-02 -6.65155828e-01 -1.46563649e+00 -1.84587881e-01\n",
      " -4.66501415e-01 -1.42644107e+00 -8.59926194e-02 -5.25319636e-01\n",
      " -1.40231073e+00 -8.27361792e-02 -5.01032710e-01 -1.50750971e+00\n",
      "  5.71960062e-02 -5.25905073e-01 -1.57305622e+00 -8.82986858e-02\n",
      " -3.86425912e-01 -1.25057006e+00 -1.96733385e-01 -1.58980563e-01\n",
      " -1.87116992e+00 -3.86345908e-02 -3.12088847e-01 -1.86058295e+00\n",
      "  1.23388052e-01 -2.77869344e-01 -1.42155826e+00 -1.96446478e-01\n",
      " -1.39041036e-01 -1.18959022e+00 -1.10148594e-01 -1.18247151e-01\n",
      " -1.27197921e+00 -5.59413433e-02 -1.41752094e-01 -1.39426899e+00\n",
      "  4.32602316e-03 -1.52362436e-01 -1.27589071e+00]\n",
      "data: [-1.28494091e-02  1.70329046e-02 -2.02845231e-01 -1.58371404e-03\n",
      " -1.34092718e-01 -6.49278164e-01 -7.11460486e-02 -3.04924011e-01\n",
      " -1.35934174e+00 -2.15329304e-01 -3.61425042e-01 -1.66638196e+00\n",
      " -4.06155556e-01 -4.85077024e-01 -2.11680055e+00 -2.30345637e-01\n",
      " -5.82253218e-01 -1.51137471e+00  1.48954988e-02 -6.00909472e-01\n",
      " -1.29944599e+00 -3.09942961e-02 -5.44003069e-01 -1.34941638e+00\n",
      " -2.65007019e-02 -6.65155768e-01 -1.46563649e+00 -1.84587881e-01\n",
      " -4.66501415e-01 -1.42644107e+00 -8.59926194e-02 -5.25319636e-01\n",
      " -1.40231085e+00 -8.27361792e-02 -5.01032710e-01 -1.50750971e+00\n",
      "  5.71960062e-02 -5.25905073e-01 -1.57305622e+00 -8.82986858e-02\n",
      " -3.86425883e-01 -1.25057006e+00 -1.96733385e-01 -1.58980563e-01\n",
      " -1.87116992e+00 -3.86345908e-02 -3.12088847e-01 -1.86058283e+00\n",
      "  1.23388052e-01 -2.77869344e-01 -1.42155826e+00 -1.96446478e-01\n",
      " -1.39041036e-01 -1.18959022e+00 -1.10148594e-01 -1.18247144e-01\n",
      " -1.27197921e+00 -5.59413433e-02 -1.41752094e-01 -1.39426899e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4.32602316e-03 -1.52362436e-01 -1.27589071e+00  1.89999998e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0356, -0.1437, -0.2385,  ...,  0.0725, -0.3206, -1.3492],\n",
      "        [ 0.0356, -0.1437, -0.2385,  ...,  0.0725, -0.3206, -1.3492],\n",
      "        [ 0.0356, -0.1437, -0.2385,  ...,  0.0725, -0.3206, -1.3492],\n",
      "        ...,\n",
      "        [-0.3355,  0.3865, -0.4010,  ..., -0.8996,  0.8564, -0.5135],\n",
      "        [-0.2014, -0.1088,  0.5540,  ..., -0.2816,  0.6462,  0.2670],\n",
      "        [-0.2014, -0.1088,  0.5540,  ..., -0.2816,  0.6462,  0.2670]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03563064 -0.14373541 -0.23847345  0.0474264  -0.3108539  -0.7136316\n",
      "  0.00867407 -0.4568517  -1.3876653  -0.12401839 -0.51100004 -1.6906998\n",
      " -0.29909503 -0.6502576  -2.146566   -0.18141392 -0.723657   -1.5455358\n",
      "  0.09295275 -0.7210425  -1.3124661   0.03732642 -0.66531754 -1.3640411\n",
      "  0.03255896 -0.75994134 -1.4758368  -0.1363863  -0.60736775 -1.475981\n",
      " -0.01984906 -0.65952253 -1.4634123  -0.02697849 -0.62918854 -1.5622101\n",
      "  0.08343694 -0.65181553 -1.6300802  -0.02682653 -0.5401614  -1.3041499\n",
      " -0.10075656 -0.3176099  -1.8158813   0.02457352 -0.4570189  -1.7892785\n",
      "  0.15602818 -0.42209718 -1.4953282  -0.12278336 -0.3001662  -1.2552469\n",
      " -0.0174017  -0.2851457  -1.3336082   0.03538885 -0.31502077 -1.4524477\n",
      "  0.07250905 -0.32057077 -1.3491585 ]\n",
      "data: [ 0.03563064 -0.14373541 -0.23847346  0.0474264  -0.3108539  -0.7136316\n",
      "  0.00867407 -0.4568517  -1.3876653  -0.12401839 -0.51100004 -1.6906998\n",
      " -0.29909503 -0.6502576  -2.146566   -0.18141392 -0.723657   -1.5455357\n",
      "  0.09295275 -0.72104245 -1.3124661   0.03732642 -0.66531754 -1.3640411\n",
      "  0.03255896 -0.75994134 -1.4758368  -0.1363863  -0.60736775 -1.475981\n",
      " -0.01984906 -0.65952253 -1.4634123  -0.02697849 -0.62918854 -1.5622101\n",
      "  0.08343694 -0.6518156  -1.6300802  -0.02682653 -0.5401614  -1.30415\n",
      " -0.10075656 -0.3176099  -1.8158813   0.02457352 -0.45701894 -1.7892785\n",
      "  0.15602818 -0.42209718 -1.4953282  -0.12278336 -0.3001662  -1.2552469\n",
      " -0.0174017  -0.2851457  -1.3336082   0.03538885 -0.31502077 -1.4524477\n",
      "  0.07250905 -0.32057077 -1.3491585   0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0534, -0.1822, -0.2548,  ...,  0.0675, -0.3562, -1.3312],\n",
      "        [ 0.0534, -0.1822, -0.2548,  ...,  0.0675, -0.3562, -1.3312],\n",
      "        [ 0.0534, -0.1822, -0.2548,  ...,  0.0675, -0.3562, -1.3312],\n",
      "        ...,\n",
      "        [-0.1045,  0.5252, -0.1602,  ..., -0.6263,  1.0236, -0.5049],\n",
      "        [-0.1943, -0.0615,  0.6411,  ..., -0.2628,  0.6835,  0.2669],\n",
      "        [-0.1943, -0.0615,  0.6411,  ..., -0.2628,  0.6835,  0.2669]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 5.3352732e-02 -1.8224874e-01 -2.5484672e-01  8.2711115e-02\n",
      " -3.1759256e-01 -6.4467120e-01 -8.0762804e-04 -5.2436829e-01\n",
      " -1.4402292e+00 -1.4838850e-01 -5.8751893e-01 -1.7495164e+00\n",
      " -3.1422698e-01 -7.0417875e-01 -2.2412505e+00 -1.5659600e-01\n",
      " -7.9388201e-01 -1.6365192e+00  8.9842118e-02 -8.3791053e-01\n",
      " -1.4238133e+00  2.9923223e-02 -7.8320301e-01 -1.4661958e+00\n",
      "  8.4325597e-03 -9.2184758e-01 -1.5890737e+00 -1.0694704e-01\n",
      " -6.8643510e-01 -1.5349815e+00 -2.1460906e-02 -7.5198215e-01\n",
      " -1.5088803e+00 -2.9780939e-02 -7.2460079e-01 -1.6044853e+00\n",
      "  8.3012022e-02 -7.6805604e-01 -1.6513741e+00 -7.2336644e-03\n",
      " -5.8315599e-01 -1.3613770e+00 -1.4975086e-01 -3.5507947e-01\n",
      " -2.0509453e+00  1.9727863e-02 -5.3071421e-01 -2.0507774e+00\n",
      "  1.6755873e-01 -4.8591220e-01 -1.5004377e+00 -1.3254350e-01\n",
      " -3.4328431e-01 -1.2885712e+00 -3.7286378e-02 -3.1924212e-01\n",
      " -1.3598524e+00  7.2373822e-03 -3.4972861e-01 -1.4735067e+00\n",
      "  6.7519262e-02 -3.5620058e-01 -1.3311603e+00]\n",
      "data: [-4.06 -1.74  1.69 -3.84 -1.67  1.69 -3.74 -1.47  2.15 -3.81 -1.25  2.66\n",
      " -3.88 -1.    2.83 -3.9  -0.97  2.13 -4.05 -0.75  3.07 -4.   -0.79  3.07\n",
      " -3.93 -0.86  2.79 -4.08 -0.95  2.27  0.    0.    0.   -4.07 -0.8   2.85\n",
      " -3.95 -0.93  2.46  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " -3.99 -0.94  2.16  0.    0.    0.   -5.13 -1.15  5.56 -5.03 -1.17  5.43\n",
      "  0.    0.    0.    0.  ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.1246, -0.1674, -0.4082,  ..., -0.2131, -0.5120, -0.7893],\n",
      "        [ 0.1246, -0.1674, -0.4082,  ..., -0.2131, -0.5120, -0.7893],\n",
      "        [ 0.1246, -0.1674, -0.4082,  ..., -0.2131, -0.5120, -0.7893],\n",
      "        ...,\n",
      "        [ 0.0729, -0.0423,  0.5140,  ..., -0.3009,  0.4032,  0.9369],\n",
      "        [ 0.0637, -0.0097,  0.8974,  ..., -0.7454,  0.2927,  2.5236],\n",
      "        [ 0.0637, -0.0097,  0.8974,  ..., -0.7454,  0.2927,  2.5236]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.12457618 -0.16744567 -0.40818998 -0.03858797 -0.26423645 -0.8977829\n",
      " -0.25700724 -0.46851498 -1.0062759  -0.37010467 -0.60207415 -0.96980506\n",
      " -0.4486248  -0.6772622  -0.9189416  -0.22000834 -0.52316356 -1.1180179\n",
      " -0.3639927  -0.6830907  -0.9627583  -0.42474508 -0.78803134 -0.92770994\n",
      " -0.5241852  -0.88506305 -0.9248816  -0.18845847 -0.49121976 -1.1224666\n",
      " -0.37158838 -0.6695696  -1.0258155  -0.43081594 -0.7407836  -0.9657111\n",
      " -0.42061836 -0.8518667  -0.9117202  -0.1893698  -0.43843046 -1.1166737\n",
      " -0.35496038 -0.54681    -1.0281308  -0.35795826 -0.6553829  -1.0399141\n",
      " -0.33592942 -0.71092105 -0.85933745 -0.18180025 -0.36325467 -0.9928709\n",
      " -0.27468237 -0.42119578 -0.9605049  -0.2721507  -0.46199983 -0.947366\n",
      " -0.21307313 -0.5119543  -0.7892921 ]\n",
      "init: [ 0.12457618 -0.16744567 -0.40818998 -0.03858797 -0.26423645 -0.8977829\n",
      " -0.25700724 -0.46851498 -1.0062759  -0.37010467 -0.60207415 -0.96980506\n",
      " -0.4486248  -0.6772622  -0.9189416  -0.22000834 -0.52316356 -1.1180179\n",
      " -0.3639927  -0.6830907  -0.9627583  -0.42474508 -0.78803134 -0.92770994\n",
      " -0.5241852  -0.88506305 -0.9248816  -0.18845847 -0.49121976 -1.1224666\n",
      " -0.37158838 -0.6695696  -1.0258155  -0.43081594 -0.7407836  -0.9657111\n",
      " -0.42061836 -0.8518667  -0.9117202  -0.1893698  -0.43843046 -1.1166737\n",
      " -0.35496038 -0.54681    -1.0281308  -0.35795826 -0.6553829  -1.0399141\n",
      " -0.33592942 -0.71092105 -0.85933745 -0.18180025 -0.36325467 -0.9928709\n",
      " -0.27468237 -0.42119578 -0.9605049  -0.2721507  -0.46199983 -0.947366\n",
      " -0.21307313 -0.5119543  -0.7892921 ]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [ 0.12457618 -0.16744567 -0.40818995 -0.03858797 -0.26423645 -0.8977829\n",
      " -0.25700724 -0.46851498 -1.0062759  -0.37010467 -0.60207415 -0.96980506\n",
      " -0.4486248  -0.6772622  -0.9189417  -0.22000833 -0.52316356 -1.1180179\n",
      " -0.3639927  -0.6830907  -0.9627583  -0.4247451  -0.78803134 -0.92770994\n",
      " -0.5241852  -0.885063   -0.9248816  -0.18845849 -0.49121976 -1.1224666\n",
      " -0.37158835 -0.6695696  -1.0258155  -0.43081594 -0.7407835  -0.9657111\n",
      " -0.42061836 -0.8518668  -0.9117202  -0.1893698  -0.43843043 -1.1166737\n",
      " -0.35496035 -0.54681    -1.0281308  -0.35795826 -0.6553829  -1.0399141\n",
      " -0.33592942 -0.71092105 -0.85933745 -0.18180025 -0.36325467 -0.9928709\n",
      " -0.27468237 -0.4211958  -0.9605049  -0.2721507  -0.4619998  -0.947366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.21307313 -0.5119543  -0.7892921   0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.1532,  0.0680,  0.0706,  ...,  0.4898, -0.1340, -0.9593],\n",
      "        [ 0.1532,  0.0680,  0.0706,  ...,  0.4898, -0.1340, -0.9593],\n",
      "        [ 0.1532,  0.0680,  0.0706,  ...,  0.4898, -0.1340, -0.9593],\n",
      "        ...,\n",
      "        [-0.0217,  0.2819, -0.2402,  ..., -0.4023,  1.0496, -0.3862],\n",
      "        [-0.2173,  0.1031,  0.1539,  ..., -0.8286,  0.3192,  0.0961],\n",
      "        [-0.2173,  0.1031,  0.1539,  ..., -0.8286,  0.3192,  0.0961]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.15316097  0.06802428  0.07064845  0.22508655 -0.01648793 -0.3755719\n",
      "  0.16633722 -0.13540909 -1.0532936   0.0871969  -0.14391983 -1.3311495\n",
      " -0.03011671 -0.25229356 -1.7438483  -0.04658887 -0.35818148 -1.2945629\n",
      "  0.19940059 -0.3665173  -1.2263399   0.18293346 -0.31787762 -1.2805471\n",
      "  0.21069123 -0.4232187  -1.3704323   0.03266825 -0.33629665 -1.2098519\n",
      "  0.19252655 -0.43357208 -1.2212728   0.22905365 -0.39202568 -1.3531381\n",
      "  0.36902994 -0.42032906 -1.3949333   0.14762771 -0.2778049  -1.0186365\n",
      "  0.13437928 -0.15432015 -1.594706    0.36747277 -0.28855234 -1.6023711\n",
      "  0.5274465  -0.23682109 -1.2343383   0.12784396 -0.15780035 -0.9476877\n",
      "  0.25640562 -0.15456003 -0.9819543   0.3827138  -0.18830419 -1.1082095\n",
      "  0.48980796 -0.13400735 -0.959276  ]\n",
      "data: [ 0.15316097  0.06802428  0.07064845  0.22508655 -0.01648793 -0.3755719\n",
      "  0.16633722 -0.13540909 -1.0532936   0.0871969  -0.14391983 -1.3311495\n",
      " -0.03011671 -0.25229356 -1.7438483  -0.04658887 -0.35818145 -1.2945629\n",
      "  0.1994006  -0.3665173  -1.2263399   0.18293346 -0.31787762 -1.2805471\n",
      "  0.21069123 -0.4232187  -1.3704323   0.03266825 -0.33629665 -1.2098519\n",
      "  0.19252655 -0.43357208 -1.2212728   0.22905365 -0.39202568 -1.3531381\n",
      "  0.3690299  -0.42032906 -1.3949333   0.14762771 -0.2778049  -1.0186365\n",
      "  0.13437928 -0.15432015 -1.594706    0.36747277 -0.28855234 -1.6023711\n",
      "  0.5274465  -0.23682109 -1.2343383   0.12784396 -0.15780035 -0.9476877\n",
      "  0.25640562 -0.15456003 -0.9819543   0.38271376 -0.18830417 -1.1082095\n",
      "  0.48980796 -0.13400735 -0.959276    0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B320>\n",
      "tensor([[ 0.2056, -0.1267, -0.3259,  ...,  0.1925, -0.2884, -1.3641],\n",
      "        [ 0.2056, -0.1267, -0.3259,  ...,  0.1925, -0.2884, -1.3641],\n",
      "        [ 0.2056, -0.1267, -0.3259,  ...,  0.1925, -0.2884, -1.3641],\n",
      "        ...,\n",
      "        [-0.3916,  0.1969,  0.2953,  ..., -0.9736,  0.7130, -0.2067],\n",
      "        [-0.3175,  0.1933,  0.2928,  ..., -0.2262,  1.1085, -0.2226],\n",
      "        [-0.3175,  0.1933,  0.2928,  ..., -0.2262,  1.1085, -0.2226]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.20561634 -0.1267463  -0.32585594  0.2174306  -0.29196414 -0.8640643\n",
      "  0.16297212 -0.44861245 -1.5089755   0.04601528 -0.5035804  -1.7919288\n",
      " -0.10937119 -0.62345135 -2.2263222  -0.0108389  -0.672598   -1.6416419\n",
      "  0.20968299 -0.66971076 -1.4177299   0.16928053 -0.6140163  -1.4762328\n",
      "  0.14235824 -0.7239872  -1.5809705   0.0167242  -0.55179787 -1.5737438\n",
      "  0.10109666 -0.6068677  -1.5486948   0.07341595 -0.5906353  -1.6188443\n",
      "  0.17975903 -0.60495985 -1.6890752   0.11001495 -0.4905601  -1.4134407\n",
      "  0.00998858 -0.266061   -1.9667847   0.13410315 -0.42029783 -1.9407182\n",
      "  0.23736748 -0.38140914 -1.5241768   0.03700453 -0.26859224 -1.349016\n",
      "  0.10807209 -0.24036752 -1.380413    0.16103485 -0.26211652 -1.4931586\n",
      "  0.19248202 -0.28842133 -1.3640926 ]\n",
      "data: [ 0.20561634 -0.1267463  -0.32585594  0.2174306  -0.29196414 -0.8640643\n",
      "  0.16297212 -0.44861245 -1.5089755   0.04601528 -0.5035804  -1.7919288\n",
      " -0.10937119 -0.62345135 -2.2263222  -0.0108389  -0.67259806 -1.6416419\n",
      "  0.20968299 -0.66971076 -1.4177299   0.16928053 -0.6140163  -1.4762328\n",
      "  0.14235824 -0.7239872  -1.5809704   0.0167242  -0.55179787 -1.5737439\n",
      "  0.10109666 -0.6068677  -1.548695    0.07341595 -0.5906353  -1.6188443\n",
      "  0.17975903 -0.60495985 -1.6890751   0.11001495 -0.4905601  -1.4134407\n",
      "  0.00998858 -0.266061   -1.9667847   0.13410315 -0.4202978  -1.9407182\n",
      "  0.23736748 -0.38140914 -1.5241768   0.03700453 -0.26859224 -1.349016\n",
      "  0.10807209 -0.2403675  -1.380413    0.16103485 -0.26211652 -1.4931586\n",
      "  0.19248204 -0.28842133 -1.3640926   0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0017, -0.1971, -0.2630,  ..., -0.0209, -0.3546, -1.4456],\n",
      "        [-0.0017, -0.1971, -0.2630,  ..., -0.0209, -0.3546, -1.4456],\n",
      "        [-0.0017, -0.1971, -0.2630,  ..., -0.0209, -0.3546, -1.4456],\n",
      "        ...,\n",
      "        [-0.0029,  0.4784,  0.0122,  ..., -0.7864,  1.0794, -0.3011],\n",
      "        [-0.0361,  0.1139,  0.6523,  ...,  0.0948,  0.8362,  0.2858],\n",
      "        [-0.0361,  0.1139,  0.6523,  ...,  0.0948,  0.8362,  0.2858]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-1.7246110e-03 -1.9712248e-01 -2.6298231e-01  1.9614477e-02\n",
      " -3.5371822e-01 -8.3105367e-01  2.5909752e-02 -4.6811524e-01\n",
      " -1.4809704e+00 -1.0398390e-01 -5.0527024e-01 -1.8011189e+00\n",
      " -2.4295920e-01 -6.3246417e-01 -2.3042903e+00 -2.0322642e-01\n",
      " -7.5025862e-01 -1.6589222e+00  9.5673449e-02 -7.2661740e-01\n",
      " -1.4341509e+00  2.1869756e-02 -6.6313446e-01 -1.4969081e+00\n",
      " -9.4125494e-03 -7.4039263e-01 -1.6185430e+00 -1.7636704e-01\n",
      " -6.5061867e-01 -1.5881770e+00 -4.4311792e-02 -6.8783802e-01\n",
      " -1.5862927e+00 -8.3471671e-02 -6.3670933e-01 -1.6890047e+00\n",
      " -1.5191250e-02 -6.6696435e-01 -1.7336075e+00 -5.9651271e-02\n",
      " -5.6754589e-01 -1.4209409e+00 -1.2270992e-01 -3.4040478e-01\n",
      " -1.8638315e+00 -3.5214640e-02 -4.6840444e-01 -1.8377913e+00\n",
      "  6.4072721e-02 -4.3893600e-01 -1.6106384e+00 -1.6648406e-01\n",
      " -3.4157771e-01 -1.3573372e+00 -4.5446254e-02 -3.2154405e-01\n",
      " -1.4173621e+00 -2.6029833e-02 -3.5852969e-01 -1.5289501e+00\n",
      " -2.0923488e-02 -3.5458577e-01 -1.4456378e+00]\n",
      "data: [-1.7246110e-03 -1.9712248e-01 -2.6298231e-01  1.9614477e-02\n",
      " -3.5371822e-01 -8.3105367e-01  2.5909754e-02 -4.6811524e-01\n",
      " -1.4809705e+00 -1.0398390e-01 -5.0527024e-01 -1.8011187e+00\n",
      " -2.4295920e-01 -6.3246417e-01 -2.3042903e+00 -2.0322642e-01\n",
      " -7.5025862e-01 -1.6589221e+00  9.5673449e-02 -7.2661746e-01\n",
      " -1.4341511e+00  2.1869756e-02 -6.6313446e-01 -1.4969081e+00\n",
      " -9.4125494e-03 -7.4039263e-01 -1.6185431e+00 -1.7636703e-01\n",
      " -6.5061867e-01 -1.5881771e+00 -4.4311792e-02 -6.8783796e-01\n",
      " -1.5862927e+00 -8.3471671e-02 -6.3670933e-01 -1.6890047e+00\n",
      " -1.5191250e-02 -6.6696435e-01 -1.7336075e+00 -5.9651271e-02\n",
      " -5.6754589e-01 -1.4209409e+00 -1.2270992e-01 -3.4040478e-01\n",
      " -1.8638315e+00 -3.5214640e-02 -4.6840441e-01 -1.8377913e+00\n",
      "  6.4072721e-02 -4.3893600e-01 -1.6106384e+00 -1.6648406e-01\n",
      " -3.4157771e-01 -1.3573372e+00 -4.5446254e-02 -3.2154405e-01\n",
      " -1.4173621e+00 -2.6029833e-02 -3.5852969e-01 -1.5289501e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -2.0923488e-02 -3.5458577e-01 -1.4456378e+00  3.9999999e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0710, -0.2007, -0.1987,  ...,  0.0262, -0.3684, -1.2477],\n",
      "        [ 0.0710, -0.2007, -0.1987,  ...,  0.0262, -0.3684, -1.2477],\n",
      "        [ 0.0710, -0.2007, -0.1987,  ...,  0.0262, -0.3684, -1.2477],\n",
      "        ...,\n",
      "        [ 0.0502,  0.4812, -0.1278,  ..., -0.5159,  1.0352, -0.4933],\n",
      "        [-0.1600, -0.0911,  0.5778,  ..., -0.1713,  0.6182,  0.2783],\n",
      "        [-0.1600, -0.0911,  0.5778,  ..., -0.1713,  0.6182,  0.2783]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.07098235 -0.20065702 -0.19874617  0.09717244 -0.31589222 -0.56715417\n",
      " -0.01812366 -0.53394693 -1.3816117  -0.16754174 -0.5916972  -1.6755621\n",
      " -0.31774265 -0.67863667 -2.1851315  -0.12927838 -0.82510114 -1.565721\n",
      "  0.03296457 -0.88305426 -1.4370985  -0.02397667 -0.8127452  -1.4920232\n",
      " -0.0329383  -0.9755902  -1.6110126  -0.09496044 -0.7306825  -1.4681133\n",
      " -0.04722203 -0.77855384 -1.4384309  -0.06975378 -0.7522621  -1.5267024\n",
      "  0.0435946  -0.7786615  -1.5420667  -0.02071778 -0.6135831  -1.3145807\n",
      " -0.18059455 -0.3890217  -2.0467937  -0.01577534 -0.5551464  -2.0702076\n",
      "  0.12891479 -0.5147743  -1.4106504  -0.13790555 -0.38999838 -1.2370071\n",
      " -0.08241728 -0.3604529  -1.3166584  -0.06152359 -0.36217588 -1.427211\n",
      "  0.02624584 -0.3684134  -1.2477365 ]\n",
      "data: [ 0.07098235 -0.20065702 -0.19874616  0.09717244 -0.31589222 -0.56715417\n",
      " -0.01812366 -0.53394693 -1.3816116  -0.16754173 -0.5916972  -1.6755621\n",
      " -0.31774265 -0.6786367  -2.1851315  -0.12927838 -0.82510114 -1.565721\n",
      "  0.03296457 -0.88305426 -1.4370985  -0.02397667 -0.8127452  -1.4920231\n",
      " -0.0329383  -0.9755902  -1.6110126  -0.09496043 -0.73068255 -1.4681133\n",
      " -0.04722203 -0.77855384 -1.4384309  -0.06975378 -0.7522621  -1.5267024\n",
      "  0.0435946  -0.7786615  -1.5420667  -0.02071778 -0.6135831  -1.3145807\n",
      " -0.18059453 -0.3890217  -2.0467937  -0.01577534 -0.5551464  -2.0702076\n",
      "  0.12891479 -0.5147743  -1.4106504  -0.13790555 -0.38999835 -1.2370071\n",
      " -0.08241728 -0.3604529  -1.3166584  -0.06152359 -0.36217585 -1.427211\n",
      "  0.02624584 -0.3684134  -1.2477365   0.05      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[-2.8816e-04, -7.8245e-02, -2.0835e-01,  ...,  6.0636e-02,\n",
      "         -2.7091e-01, -1.1902e+00],\n",
      "        [-2.8816e-04, -7.8245e-02, -2.0835e-01,  ...,  6.0636e-02,\n",
      "         -2.7091e-01, -1.1902e+00],\n",
      "        [-2.8816e-04, -7.8245e-02, -2.0835e-01,  ...,  6.0636e-02,\n",
      "         -2.7091e-01, -1.1902e+00],\n",
      "        ...,\n",
      "        [-7.8939e-02,  4.9025e-01,  6.1110e-03,  ..., -6.7190e-01,\n",
      "          1.0987e+00, -4.1289e-01],\n",
      "        [-6.0985e-02,  1.7164e-02,  6.4313e-01,  ..., -1.3693e-01,\n",
      "          6.8168e-01,  2.8827e-01],\n",
      "        [-6.0985e-02,  1.7164e-02,  6.4313e-01,  ..., -1.3693e-01,\n",
      "          6.8168e-01,  2.8827e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-2.8816145e-04 -7.8244701e-02 -2.0834839e-01  3.0296627e-02\n",
      " -1.9350792e-01 -5.0990105e-01 -8.1127964e-02 -4.1298035e-01\n",
      " -1.3400736e+00 -2.3486842e-01 -4.7469005e-01 -1.6471393e+00\n",
      " -3.9693016e-01 -5.8988875e-01 -2.1377954e+00 -2.0558679e-01\n",
      " -6.9965720e-01 -1.5316067e+00  2.2740990e-02 -7.5558406e-01\n",
      " -1.3570969e+00 -3.6030054e-02 -6.9239295e-01 -1.4008436e+00\n",
      " -3.7185788e-02 -8.4726453e-01 -1.5271595e+00 -1.4832230e-01\n",
      " -6.0273618e-01 -1.4215450e+00 -6.7461282e-02 -6.6823024e-01\n",
      " -1.3971338e+00 -6.5330841e-02 -6.3919079e-01 -1.4907584e+00\n",
      "  6.8612710e-02 -6.8503481e-01 -1.5238259e+00 -4.3523349e-02\n",
      " -4.9506301e-01 -1.2424030e+00 -1.9775018e-01 -2.6225379e-01\n",
      " -1.9922521e+00 -4.7521591e-03 -4.4825235e-01 -2.0014691e+00\n",
      "  1.7396051e-01 -4.0547144e-01 -1.3687036e+00 -1.7376582e-01\n",
      " -2.5972247e-01 -1.1679802e+00 -7.4447781e-02 -2.3710234e-01\n",
      " -1.2470529e+00 -3.0209109e-02 -2.6218182e-01 -1.3609467e+00\n",
      "  6.0636140e-02 -2.7091247e-01 -1.1901610e+00]\n",
      "data: [-2.8816145e-04 -7.8244701e-02 -2.0834839e-01  3.0296629e-02\n",
      " -1.9350792e-01 -5.0990105e-01 -8.1127971e-02 -4.1298035e-01\n",
      " -1.3400736e+00 -2.3486844e-01 -4.7469005e-01 -1.6471393e+00\n",
      " -3.9693016e-01 -5.8988875e-01 -2.1377954e+00 -2.0558679e-01\n",
      " -6.9965720e-01 -1.5316068e+00  2.2740988e-02 -7.5558400e-01\n",
      " -1.3570969e+00 -3.6030054e-02 -6.9239295e-01 -1.4008436e+00\n",
      " -3.7185788e-02 -8.4726453e-01 -1.5271595e+00 -1.4832230e-01\n",
      " -6.0273618e-01 -1.4215451e+00 -6.7461282e-02 -6.6823024e-01\n",
      " -1.3971338e+00 -6.5330841e-02 -6.3919079e-01 -1.4907584e+00\n",
      "  6.8612710e-02 -6.8503481e-01 -1.5238259e+00 -4.3523349e-02\n",
      " -4.9506301e-01 -1.2424030e+00 -1.9775018e-01 -2.6225379e-01\n",
      " -1.9922520e+00 -4.7521591e-03 -4.4825232e-01 -2.0014691e+00\n",
      "  1.7396051e-01 -4.0547144e-01 -1.3687036e+00 -1.7376584e-01\n",
      " -2.5972247e-01 -1.1679802e+00 -7.4447781e-02 -2.3710233e-01\n",
      " -1.2470529e+00 -3.0209109e-02 -2.6218182e-01 -1.3609467e+00\n",
      "  6.0636140e-02 -2.7091247e-01 -1.1901610e+00  5.9999999e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE3F7CB2E8>\n",
      "tensor([[ 0.0069, -0.0731, -0.2552,  ...,  0.0254, -0.2466, -1.2884],\n",
      "        [ 0.0069, -0.0731, -0.2552,  ...,  0.0254, -0.2466, -1.2884],\n",
      "        [ 0.0069, -0.0731, -0.2552,  ...,  0.0254, -0.2466, -1.2884],\n",
      "        ...,\n",
      "        [-0.1737,  0.3378, -0.0388,  ..., -0.7255,  0.8349, -0.3068],\n",
      "        [-0.1025, -0.0603,  0.6335,  ..., -0.1993,  0.6942,  0.2810],\n",
      "        [-0.1025, -0.0603,  0.6335,  ..., -0.1993,  0.6942,  0.2810]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00693184 -0.07312375 -0.25519192  0.0338409  -0.19775279 -0.6240763\n",
      " -0.07516725 -0.40196913 -1.4216702  -0.22493798 -0.46414962 -1.7243755\n",
      " -0.39245376 -0.57036173 -2.2140884  -0.19919994 -0.69261205 -1.5850296\n",
      "  0.01198927 -0.73576653 -1.390243   -0.04302116 -0.67291    -1.4428637\n",
      " -0.05747928 -0.82091653 -1.5698214  -0.15455776 -0.59413487 -1.4877648\n",
      " -0.08173444 -0.6488105  -1.464942   -0.0902743  -0.6161322  -1.5607762\n",
      "  0.04353598 -0.64984107 -1.5984306  -0.06584588 -0.49046147 -1.3156085\n",
      " -0.20755064 -0.25699514 -2.0335405  -0.03050487 -0.42245418 -2.0454123\n",
      "  0.13481227 -0.38442314 -1.451431   -0.18179697 -0.25561345 -1.2436991\n",
      " -0.10413255 -0.22832805 -1.3298655  -0.06392586 -0.23782161 -1.449646\n",
      "  0.02536982 -0.2466418  -1.288353  ]\n",
      "data: [ 0.00693184 -0.07312375 -0.25519192  0.0338409  -0.19775277 -0.6240763\n",
      " -0.07516725 -0.40196913 -1.4216702  -0.22493798 -0.46414962 -1.7243755\n",
      " -0.39245376 -0.57036173 -2.2140884  -0.19919994 -0.69261205 -1.5850296\n",
      "  0.01198927 -0.73576653 -1.390243   -0.04302116 -0.67291    -1.4428638\n",
      " -0.05747928 -0.82091653 -1.5698214  -0.15455776 -0.59413487 -1.4877648\n",
      " -0.08173444 -0.6488105  -1.464942   -0.0902743  -0.6161322  -1.5607762\n",
      "  0.04353598 -0.64984107 -1.5984306  -0.06584588 -0.49046147 -1.3156085\n",
      " -0.20755064 -0.25699514 -2.0335405  -0.03050487 -0.42245418 -2.0454123\n",
      "  0.13481227 -0.38442314 -1.4514309  -0.18179697 -0.25561345 -1.2436991\n",
      " -0.10413255 -0.22832805 -1.3298655  -0.06392586 -0.23782162 -1.449646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.02536982 -0.24664181 -1.288353    0.07      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0206, -0.0512, -0.2339,  ...,  0.0447, -0.2390, -1.2835],\n",
      "        [ 0.0206, -0.0512, -0.2339,  ...,  0.0447, -0.2390, -1.2835],\n",
      "        [ 0.0206, -0.0512, -0.2339,  ...,  0.0447, -0.2390, -1.2835],\n",
      "        ...,\n",
      "        [-0.2038,  0.3420, -0.1343,  ..., -0.8412,  0.8290, -0.3407],\n",
      "        [-0.1423, -0.1444,  0.5655,  ..., -0.2168,  0.5954,  0.2655],\n",
      "        [-0.1423, -0.1444,  0.5655,  ..., -0.2168,  0.5954,  0.2655]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02061682 -0.05123156 -0.2338967   0.03339513 -0.187438   -0.62721217\n",
      " -0.056782   -0.36866647 -1.3688675  -0.2046199  -0.42889202 -1.670072\n",
      " -0.38000596 -0.5414489  -2.149585   -0.18556695 -0.6631499  -1.5349848\n",
      "  0.02186118 -0.69586146 -1.3647192  -0.03099135 -0.6303347  -1.4198515\n",
      " -0.02769423 -0.76896405 -1.5347166  -0.14012454 -0.5610841  -1.4495957\n",
      " -0.05892262 -0.6135132  -1.4271408  -0.07052164 -0.58820176 -1.5279993\n",
      "  0.06057656 -0.6097616  -1.569523   -0.04942181 -0.47281015 -1.2822802\n",
      " -0.16263036 -0.24802113 -1.92189    -0.0104873  -0.4002017  -1.924466\n",
      "  0.14657031 -0.37060046 -1.4311826  -0.15300661 -0.23748977 -1.2210665\n",
      " -0.07543932 -0.21867007 -1.307975   -0.035134   -0.22965056 -1.4262615\n",
      "  0.04472884 -0.23896663 -1.2834977 ]\n",
      "data: [ 0.02061682 -0.05123157 -0.23389669  0.03339513 -0.187438   -0.62721217\n",
      " -0.056782   -0.36866647 -1.3688675  -0.2046199  -0.42889202 -1.6700721\n",
      " -0.38000596 -0.5414489  -2.149585   -0.18556695 -0.6631499  -1.534985\n",
      "  0.02186118 -0.69586146 -1.364719   -0.03099134 -0.6303347  -1.4198515\n",
      " -0.02769423 -0.76896405 -1.5347166  -0.14012454 -0.5610841  -1.4495957\n",
      " -0.05892262 -0.6135132  -1.4271408  -0.07052164 -0.58820176 -1.5279993\n",
      "  0.06057656 -0.6097616  -1.569523   -0.04942181 -0.47281015 -1.2822803\n",
      " -0.16263036 -0.24802113 -1.9218899  -0.0104873  -0.4002017  -1.9244659\n",
      "  0.14657031 -0.37060046 -1.4311825  -0.15300661 -0.23748977 -1.2210665\n",
      " -0.07543932 -0.21867007 -1.307975   -0.035134   -0.22965056 -1.4262615\n",
      "  0.04472884 -0.23896664 -1.2834976   0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0176, -0.0769, -0.2618,  ...,  0.0341, -0.2650, -1.3035],\n",
      "        [ 0.0176, -0.0769, -0.2618,  ...,  0.0341, -0.2650, -1.3035],\n",
      "        [ 0.0176, -0.0769, -0.2618,  ...,  0.0341, -0.2650, -1.3035],\n",
      "        ...,\n",
      "        [-0.1501,  0.3906, -0.0677,  ..., -0.6999,  0.8816, -0.3236],\n",
      "        [-0.1567, -0.1302,  0.5797,  ..., -0.2528,  0.6573,  0.2347],\n",
      "        [-0.1567, -0.1302,  0.5797,  ..., -0.2528,  0.6573,  0.2347]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01764074 -0.07691947 -0.26175305  0.03876178 -0.20488122 -0.6636975\n",
      " -0.07300584 -0.3972026  -1.4355066  -0.21798725 -0.46263903 -1.7243217\n",
      " -0.37824482 -0.5602844  -2.2124414  -0.17699905 -0.69306684 -1.5894244\n",
      "  0.0029342  -0.73378795 -1.4094226  -0.04433124 -0.66284573 -1.4692048\n",
      " -0.04998554 -0.8098095  -1.5873946  -0.13935092 -0.59773874 -1.5051744\n",
      " -0.07331599 -0.6468817  -1.4728477  -0.09336017 -0.6199497  -1.562979\n",
      "  0.04406197 -0.63671285 -1.5957992  -0.06293736 -0.50733477 -1.3405836\n",
      " -0.18091556 -0.27896047 -1.9994549  -0.02913272 -0.4291771  -2.0115287\n",
      "  0.13114294 -0.40127456 -1.457605   -0.16043958 -0.275987   -1.2706504\n",
      " -0.09918444 -0.25028774 -1.3551548  -0.0597197  -0.25014114 -1.4710006\n",
      "  0.03407051 -0.2649547  -1.3034732 ]\n",
      "data: [ 0.01764074 -0.07691947 -0.26175305  0.03876178 -0.20488124 -0.6636975\n",
      " -0.07300584 -0.3972026  -1.4355066  -0.21798725 -0.46263903 -1.7243217\n",
      " -0.37824482 -0.5602844  -2.2124414  -0.17699905 -0.69306684 -1.5894245\n",
      "  0.0029342  -0.7337879  -1.4094226  -0.04433124 -0.6628458  -1.4692047\n",
      " -0.04998554 -0.8098095  -1.5873946  -0.13935092 -0.59773874 -1.5051744\n",
      " -0.07331599 -0.6468817  -1.4728477  -0.09336016 -0.6199497  -1.562979\n",
      "  0.04406197 -0.63671285 -1.5957992  -0.06293736 -0.50733477 -1.3405834\n",
      " -0.18091556 -0.27896047 -1.9994549  -0.02913272 -0.4291771  -2.0115287\n",
      "  0.13114294 -0.40127456 -1.457605   -0.16043958 -0.275987   -1.2706504\n",
      " -0.09918444 -0.25028774 -1.3551548  -0.0597197  -0.25014114 -1.4710006\n",
      "  0.03407051 -0.2649547  -1.3034732   0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0396, -0.0307, -0.2197,  ...,  0.0438, -0.2261, -1.2483],\n",
      "        [ 0.0396, -0.0307, -0.2197,  ...,  0.0438, -0.2261, -1.2483],\n",
      "        [ 0.0396, -0.0307, -0.2197,  ...,  0.0438, -0.2261, -1.2483],\n",
      "        ...,\n",
      "        [-0.1333,  0.4074, -0.1154,  ..., -0.7357,  0.9094, -0.3662],\n",
      "        [-0.1395, -0.1856,  0.5567,  ..., -0.2131,  0.5807,  0.2373],\n",
      "        [-0.1395, -0.1856,  0.5567,  ..., -0.2131,  0.5807,  0.2373]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 3.9554793e-02 -3.0700687e-02 -2.1971285e-01  5.5047784e-02\n",
      " -1.5267843e-01 -6.0419416e-01 -6.6313073e-02 -3.4291872e-01\n",
      " -1.3684505e+00 -2.1562465e-01 -4.0728951e-01 -1.6555097e+00\n",
      " -3.7987083e-01 -4.9485171e-01 -2.1505108e+00 -1.5052521e-01\n",
      " -6.5516782e-01 -1.5224102e+00  3.3263862e-04 -6.9911450e-01\n",
      " -1.3703965e+00 -4.5102298e-02 -6.2231553e-01 -1.4353728e+00\n",
      " -4.4252962e-02 -7.7892083e-01 -1.5502266e+00 -1.1620939e-01\n",
      " -5.6465787e-01 -1.4413657e+00 -5.9980638e-02 -6.0843539e-01\n",
      " -1.4074320e+00 -8.6334616e-02 -5.8355516e-01 -1.5012065e+00\n",
      "  5.5836231e-02 -5.9162343e-01 -1.5247008e+00 -4.7283642e-02\n",
      " -4.7201356e-01 -1.2833179e+00 -1.6484386e-01 -2.4814522e-01\n",
      " -1.9480189e+00 -1.8292896e-02 -3.9176285e-01 -1.9676088e+00\n",
      "  1.4380154e-01 -3.6878663e-01 -1.3934249e+00 -1.3908082e-01\n",
      " -2.4530245e-01 -1.2162215e+00 -9.2661977e-02 -2.2120884e-01\n",
      " -1.3050120e+00 -6.1696097e-02 -2.1058507e-01 -1.4218773e+00\n",
      "  4.3757498e-02 -2.2612001e-01 -1.2483425e+00]\n",
      "data: [ 3.95547934e-02 -3.07006892e-02 -2.19712853e-01  5.50477840e-02\n",
      " -1.52678430e-01 -6.04194164e-01 -6.63130730e-02 -3.42918754e-01\n",
      " -1.36845052e+00 -2.15624630e-01 -4.07289505e-01 -1.65550959e+00\n",
      " -3.79870832e-01 -4.94851708e-01 -2.15051079e+00 -1.50525212e-01\n",
      " -6.55167818e-01 -1.52241015e+00  3.32638621e-04 -6.99114561e-01\n",
      " -1.37039638e+00 -4.51023020e-02 -6.22315526e-01 -1.43537283e+00\n",
      " -4.42529619e-02 -7.78920829e-01 -1.55022657e+00 -1.16209395e-01\n",
      " -5.64657867e-01 -1.44136572e+00 -5.99806421e-02 -6.08435392e-01\n",
      " -1.40743196e+00 -8.63346159e-02 -5.83555162e-01 -1.50120652e+00\n",
      "  5.58362305e-02 -5.91623425e-01 -1.52470076e+00 -4.72836383e-02\n",
      " -4.72013563e-01 -1.28331792e+00 -1.64843857e-01 -2.48145223e-01\n",
      " -1.94801891e+00 -1.82928964e-02 -3.91762853e-01 -1.96760881e+00\n",
      "  1.43801540e-01 -3.68786633e-01 -1.39342487e+00 -1.39080822e-01\n",
      " -2.45302454e-01 -1.21622145e+00 -9.26619694e-02 -2.21208841e-01\n",
      " -1.30501211e+00 -6.16960973e-02 -2.10585073e-01 -1.42187726e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4.37574945e-02 -2.26120010e-01 -1.24834251e+00  1.00000001e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0259, -0.0757, -0.2354,  ...,  0.0412, -0.2612, -1.2841],\n",
      "        [ 0.0259, -0.0757, -0.2354,  ...,  0.0412, -0.2612, -1.2841],\n",
      "        [ 0.0259, -0.0757, -0.2354,  ...,  0.0412, -0.2612, -1.2841],\n",
      "        ...,\n",
      "        [-0.2950,  0.1945, -0.2660,  ..., -0.8057,  0.6007, -0.4010],\n",
      "        [-0.0940, -0.0552,  0.5778,  ..., -0.1920,  0.7291,  0.2698],\n",
      "        [-0.0940, -0.0552,  0.5778,  ..., -0.1920,  0.7291,  0.2698]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02586486 -0.07570703 -0.23542497  0.04845307 -0.21181838 -0.6395237\n",
      " -0.05732866 -0.399418   -1.4057759  -0.20256127 -0.46625668 -1.6921952\n",
      " -0.36817378 -0.56997395 -2.1777635  -0.17191945 -0.686086   -1.5622929\n",
      "  0.01599388 -0.7236451  -1.3800709  -0.03293823 -0.655286   -1.4359087\n",
      " -0.03993655 -0.794979   -1.5489324  -0.13330491 -0.58692604 -1.4814683\n",
      " -0.06160935 -0.639482   -1.4469689  -0.08370976 -0.6131764  -1.5369128\n",
      "  0.04802267 -0.6302095  -1.5731308  -0.05478662 -0.50235695 -1.3158859\n",
      " -0.16756791 -0.2741602  -1.9558747  -0.02078802 -0.4249742  -1.9617965\n",
      "  0.1308217  -0.3973992  -1.4347656  -0.1508456  -0.26833647 -1.2501667\n",
      " -0.08644167 -0.24522679 -1.33011    -0.04372957 -0.24855451 -1.4457091\n",
      "  0.04117716 -0.26120114 -1.284127  ]\n",
      "data: [ 0.02586486 -0.07570703 -0.23542495  0.04845307 -0.2118184  -0.6395237\n",
      " -0.05732866 -0.399418   -1.4057759  -0.20256129 -0.46625668 -1.6921952\n",
      " -0.36817378 -0.56997395 -2.1777635  -0.17191944 -0.68608594 -1.5622929\n",
      "  0.01599388 -0.7236451  -1.3800709  -0.03293823 -0.655286   -1.4359087\n",
      " -0.03993655 -0.7949789  -1.5489326  -0.13330491 -0.58692604 -1.4814683\n",
      " -0.06160935 -0.639482   -1.4469688  -0.08370976 -0.6131764  -1.5369128\n",
      "  0.04802267 -0.6302095  -1.5731308  -0.05478662 -0.50235695 -1.3158859\n",
      " -0.16756791 -0.2741602  -1.9558747  -0.02078802 -0.4249742  -1.9617965\n",
      "  0.1308217  -0.3973992  -1.4347656  -0.1508456  -0.26833647 -1.2501667\n",
      " -0.08644167 -0.24522679 -1.3301101  -0.04372957 -0.24855451 -1.4457091\n",
      "  0.04117716 -0.26120114 -1.284127    0.11      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0319, -0.0778, -0.2540,  ...,  0.0584, -0.2681, -1.2743],\n",
      "        [ 0.0319, -0.0778, -0.2540,  ...,  0.0584, -0.2681, -1.2743],\n",
      "        [ 0.0319, -0.0778, -0.2540,  ...,  0.0584, -0.2681, -1.2743],\n",
      "        ...,\n",
      "        [-0.1098,  0.3836, -0.0908,  ..., -0.6954,  0.8916, -0.3789],\n",
      "        [-0.1307, -0.1360,  0.5851,  ..., -0.2291,  0.6374,  0.2297],\n",
      "        [-0.1307, -0.1360,  0.5851,  ..., -0.2291,  0.6374,  0.2297]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03191924 -0.07780524 -0.25396112  0.05700387 -0.19805448 -0.6315129\n",
      " -0.05666979 -0.39691186 -1.4126797  -0.20228262 -0.46038187 -1.7045873\n",
      " -0.35861275 -0.5591865  -2.1938665  -0.16021326 -0.69655836 -1.5696398\n",
      "  0.02202997 -0.7423494  -1.4043906  -0.02936265 -0.67215    -1.4624634\n",
      " -0.03552668 -0.82575035 -1.5827873  -0.11905046 -0.60524076 -1.4797041\n",
      " -0.05385678 -0.65574974 -1.4521623  -0.07158168 -0.6271442  -1.5414187\n",
      "  0.06197867 -0.65180165 -1.5693429  -0.03849702 -0.5073671  -1.3144873\n",
      " -0.16834621 -0.2774065  -2.0104496  -0.00496545 -0.43648487 -2.025482\n",
      "  0.15642548 -0.40552056 -1.4321457  -0.14286269 -0.27919483 -1.2430071\n",
      " -0.07543036 -0.25306463 -1.3304828  -0.03856866 -0.25503945 -1.4465874\n",
      "  0.05841889 -0.26813373 -1.2742743 ]\n",
      "data: [ 0.03191924 -0.07780524 -0.25396112  0.05700387 -0.19805449 -0.6315129\n",
      " -0.05666979 -0.39691186 -1.4126798  -0.20228262 -0.46038187 -1.7045875\n",
      " -0.35861275 -0.5591865  -2.1938665  -0.16021326 -0.69655836 -1.5696397\n",
      "  0.02202997 -0.7423494  -1.4043906  -0.02936265 -0.67215    -1.4624634\n",
      " -0.03552668 -0.82575035 -1.5827873  -0.11905046 -0.60524076 -1.4797041\n",
      " -0.05385678 -0.65574974 -1.4521623  -0.07158168 -0.6271442  -1.5414186\n",
      "  0.06197867 -0.6518017  -1.5693429  -0.03849702 -0.5073671  -1.3144873\n",
      " -0.16834621 -0.2774065  -2.0104496  -0.00496545 -0.43648487 -2.025482\n",
      "  0.15642548 -0.40552056 -1.4321457  -0.14286269 -0.27919483 -1.2430071\n",
      " -0.07543036 -0.25306463 -1.3304828  -0.03856866 -0.25503945 -1.4465873\n",
      "  0.05841889 -0.26813373 -1.2742743   0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[ 0.0225, -0.0474, -0.2435,  ...,  0.0554, -0.2396, -1.2800],\n",
      "        [ 0.0225, -0.0474, -0.2435,  ...,  0.0554, -0.2396, -1.2800],\n",
      "        [ 0.0225, -0.0474, -0.2435,  ...,  0.0554, -0.2396, -1.2800],\n",
      "        ...,\n",
      "        [-0.1427,  0.3342, -0.0655,  ..., -0.7756,  0.8112, -0.2965],\n",
      "        [-0.1368, -0.1370,  0.5552,  ..., -0.2108,  0.6212,  0.2118],\n",
      "        [-0.1368, -0.1370,  0.5552,  ..., -0.2108,  0.6212,  0.2118]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0224926  -0.04740129 -0.24346773  0.03669121 -0.18455344 -0.64603984\n",
      " -0.05133313 -0.3684476  -1.3863907  -0.19623104 -0.42899567 -1.6890154\n",
      " -0.3710543  -0.5452343  -2.1587944  -0.1827237  -0.656632   -1.5474932\n",
      "  0.03370523 -0.68899536 -1.3591919  -0.01855845 -0.6261292  -1.4148376\n",
      " -0.01870918 -0.76455235 -1.5320652  -0.13641801 -0.55318755 -1.4597063\n",
      " -0.05392998 -0.609098   -1.4358296  -0.0638551  -0.5865107  -1.5341558\n",
      "  0.06759008 -0.60986096 -1.5783529  -0.04374026 -0.46587116 -1.2882142\n",
      " -0.15991578 -0.2425055  -1.9386022  -0.00391047 -0.3991366  -1.9383852\n",
      "  0.15473971 -0.36817008 -1.4317489  -0.14694616 -0.23148897 -1.2255538\n",
      " -0.06660164 -0.21305239 -1.3087866  -0.02277472 -0.2277653  -1.4261727\n",
      "  0.05539964 -0.23958132 -1.2800481 ]\n",
      "data: [ 0.0224926  -0.04740129 -0.24346773  0.03669121 -0.18455344 -0.6460398\n",
      " -0.05133313 -0.3684476  -1.3863907  -0.19623104 -0.42899567 -1.6890154\n",
      " -0.3710543  -0.5452343  -2.1587944  -0.1827237  -0.656632   -1.5474933\n",
      "  0.03370523 -0.68899536 -1.3591919  -0.01855845 -0.6261292  -1.4148376\n",
      " -0.01870918 -0.76455235 -1.5320652  -0.13641801 -0.55318755 -1.4597063\n",
      " -0.05392998 -0.609098   -1.4358296  -0.0638551  -0.5865107  -1.5341558\n",
      "  0.06759008 -0.60986096 -1.5783529  -0.04374026 -0.46587116 -1.2882142\n",
      " -0.15991578 -0.2425055  -1.9386021  -0.00391047 -0.39913663 -1.9383854\n",
      "  0.15473971 -0.36817008 -1.4317489  -0.14694616 -0.23148897 -1.2255538\n",
      " -0.06660164 -0.21305239 -1.3087866  -0.02277472 -0.2277653  -1.4261727\n",
      "  0.05539964 -0.23958132 -1.280048    0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BB38>\n",
      "tensor([[ 0.0127, -0.0782, -0.2520,  ...,  0.0358, -0.2665, -1.3050],\n",
      "        [ 0.0127, -0.0782, -0.2520,  ...,  0.0358, -0.2665, -1.3050],\n",
      "        [ 0.0127, -0.0782, -0.2520,  ...,  0.0358, -0.2665, -1.3050],\n",
      "        ...,\n",
      "        [-0.1579,  0.4060, -0.1178,  ..., -0.7136,  0.8861, -0.3556],\n",
      "        [-0.1614, -0.1326,  0.5758,  ..., -0.2471,  0.6514,  0.2271],\n",
      "        [-0.1614, -0.1326,  0.5758,  ..., -0.2471,  0.6514,  0.2271]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01266809 -0.07819182 -0.25200248  0.03189504 -0.21438259 -0.66579556\n",
      " -0.06349955 -0.3994083  -1.422724   -0.20568416 -0.46333832 -1.7166173\n",
      " -0.37147674 -0.57132816 -2.195214   -0.18593821 -0.68732107 -1.5797563\n",
      "  0.0160656  -0.7210394  -1.391171   -0.03291378 -0.655056   -1.4485366\n",
      " -0.03586134 -0.79240525 -1.5653634  -0.14528501 -0.58603203 -1.4956055\n",
      " -0.06879639 -0.6382052  -1.4675448  -0.08433041 -0.61363566 -1.5607708\n",
      "  0.04822189 -0.6323495  -1.602942   -0.06215775 -0.50121284 -1.3265829\n",
      " -0.17383558 -0.2745788  -1.9654155  -0.02484202 -0.42529842 -1.9687884\n",
      "  0.13118431 -0.39637217 -1.4591978  -0.16101333 -0.26650417 -1.2603319\n",
      " -0.08932298 -0.24445412 -1.3428454  -0.04528075 -0.25279438 -1.4585466\n",
      "  0.03577855 -0.26651782 -1.3049543 ]\n",
      "data: [ 0.01266809 -0.07819182 -0.25200248  0.03189504 -0.21438259 -0.66579556\n",
      " -0.06349955 -0.3994083  -1.422724   -0.20568414 -0.46333832 -1.7166172\n",
      " -0.37147674 -0.57132816 -2.195214   -0.18593821 -0.68732107 -1.5797563\n",
      "  0.0160656  -0.7210394  -1.391171   -0.03291378 -0.655056   -1.4485366\n",
      " -0.03586134 -0.79240525 -1.5653634  -0.14528501 -0.58603203 -1.4956055\n",
      " -0.06879639 -0.6382052  -1.4675449  -0.08433041 -0.61363566 -1.5607708\n",
      "  0.04822189 -0.6323495  -1.602942   -0.06215775 -0.50121284 -1.3265829\n",
      " -0.17383558 -0.2745788  -1.9654155  -0.02484202 -0.42529842 -1.9687885\n",
      "  0.13118431 -0.3963722  -1.4591976  -0.16101333 -0.26650417 -1.2603319\n",
      " -0.08932298 -0.24445412 -1.3428454  -0.04528075 -0.25279438 -1.4585466\n",
      "  0.03577855 -0.26651782 -1.3049542   0.14      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0245, -0.0682, -0.2512,  ...,  0.0475, -0.2573, -1.2771],\n",
      "        [ 0.0245, -0.0682, -0.2512,  ...,  0.0475, -0.2573, -1.2771],\n",
      "        [ 0.0245, -0.0682, -0.2512,  ...,  0.0475, -0.2573, -1.2771],\n",
      "        ...,\n",
      "        [-0.1208,  0.3970, -0.1408,  ..., -0.7033,  0.9076, -0.4181],\n",
      "        [-0.1378, -0.1560,  0.5788,  ..., -0.2411,  0.6107,  0.2308],\n",
      "        [-0.1378, -0.1560,  0.5788,  ..., -0.2411,  0.6107,  0.2308]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02445738 -0.06816401 -0.2511709   0.0483727  -0.19147842 -0.6343865\n",
      " -0.0567168  -0.38473248 -1.4039546  -0.20020677 -0.44620702 -1.6974615\n",
      " -0.35838974 -0.5471072  -2.1831555  -0.1682894  -0.68302464 -1.5623564\n",
      "  0.01891011 -0.72423625 -1.4011705  -0.03230137 -0.6558573  -1.458909\n",
      " -0.03509964 -0.80500543 -1.5773765  -0.12730747 -0.5892155  -1.4738201\n",
      " -0.05868091 -0.6392524  -1.448383   -0.07538804 -0.612149   -1.5396607\n",
      "  0.05546083 -0.6359205  -1.5718321  -0.0458683  -0.4938031  -1.3084327\n",
      " -0.17210081 -0.26562062 -1.9929082  -0.01212032 -0.42265573 -2.0049262\n",
      "  0.14521272 -0.39171562 -1.4335097  -0.14941554 -0.2650239  -1.2395433\n",
      " -0.08025628 -0.24036482 -1.3254249  -0.04297754 -0.24445578 -1.4417623\n",
      "  0.0475233  -0.25730687 -1.2770543 ]\n",
      "data: [ 0.02445738 -0.06816401 -0.2511709   0.0483727  -0.19147843 -0.6343865\n",
      " -0.0567168  -0.38473248 -1.4039546  -0.20020677 -0.44620702 -1.6974616\n",
      " -0.35838974 -0.5471072  -2.1831555  -0.1682894  -0.68302464 -1.5623565\n",
      "  0.01891011 -0.72423625 -1.4011705  -0.03230137 -0.6558573  -1.458909\n",
      " -0.03509964 -0.80500543 -1.5773766  -0.12730747 -0.5892155  -1.4738201\n",
      " -0.05868091 -0.6392524  -1.448383   -0.07538804 -0.612149   -1.5396607\n",
      "  0.05546083 -0.6359205  -1.5718322  -0.0458683  -0.4938031  -1.3084328\n",
      " -0.17210081 -0.26562062 -1.9929081  -0.01212032 -0.4226557  -2.0049262\n",
      "  0.14521272 -0.39171562 -1.4335097  -0.14941554 -0.2650239  -1.2395433\n",
      " -0.08025628 -0.24036482 -1.3254249  -0.04297754 -0.24445577 -1.4417624\n",
      "  0.0475233  -0.25730687 -1.2770543   0.15      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BB38>\n",
      "tensor([[ 0.0175, -0.0389, -0.2461,  ...,  0.0503, -0.2326, -1.2818],\n",
      "        [ 0.0175, -0.0389, -0.2461,  ...,  0.0503, -0.2326, -1.2818],\n",
      "        [ 0.0175, -0.0389, -0.2461,  ...,  0.0503, -0.2326, -1.2818],\n",
      "        ...,\n",
      "        [-0.1620,  0.3278, -0.0819,  ..., -0.8080,  0.8038, -0.3004],\n",
      "        [-0.1383, -0.1528,  0.5461,  ..., -0.2130,  0.6123,  0.2026],\n",
      "        [-0.1383, -0.1528,  0.5461,  ..., -0.2130,  0.6123,  0.2026]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01749822 -0.03885467 -0.24606802  0.03110893 -0.17516889 -0.64991504\n",
      " -0.06018484 -0.35796055 -1.390233   -0.20437393 -0.41902834 -1.6895933\n",
      " -0.37775636 -0.53280634 -2.1609123  -0.18625014 -0.6482671  -1.5484056\n",
      "  0.02266484 -0.6807347  -1.3644145  -0.02748345 -0.6160805  -1.4210465\n",
      " -0.02513615 -0.75522995 -1.5371966  -0.1413074  -0.54606605 -1.4626031\n",
      " -0.0606357  -0.6004028  -1.4372935  -0.07128536 -0.5778674  -1.5345352\n",
      "  0.06305721 -0.5985688  -1.5777097  -0.05161173 -0.46070948 -1.2928257\n",
      " -0.1645357  -0.2371426  -1.9373512  -0.01030147 -0.39113265 -1.9384992\n",
      "  0.14938183 -0.36190677 -1.4330587  -0.15191112 -0.22695498 -1.2298341\n",
      " -0.07515422 -0.20826907 -1.3133163  -0.03118204 -0.21994229 -1.43066\n",
      "  0.05031001 -0.23260312 -1.2818303 ]\n",
      "data: [ 0.01749822 -0.03885467 -0.24606802  0.03110893 -0.1751689  -0.649915\n",
      " -0.06018485 -0.35796055 -1.390233   -0.20437393 -0.41902837 -1.6895933\n",
      " -0.37775636 -0.53280634 -2.1609123  -0.18625014 -0.64826703 -1.5484056\n",
      "  0.02266484 -0.6807347  -1.3644146  -0.02748345 -0.6160805  -1.4210465\n",
      " -0.02513615 -0.75522995 -1.5371966  -0.1413074  -0.54606605 -1.4626031\n",
      " -0.0606357  -0.6004028  -1.4372935  -0.07128536 -0.5778674  -1.5345352\n",
      "  0.06305721 -0.5985688  -1.5777097  -0.05161173 -0.46070948 -1.2928256\n",
      " -0.1645357  -0.23714261 -1.9373512  -0.01030147 -0.39113265 -1.9384991\n",
      "  0.14938183 -0.36190677 -1.4330587  -0.15191112 -0.22695498 -1.2298341\n",
      " -0.07515422 -0.20826907 -1.3133163  -0.03118204 -0.21994229 -1.4306599\n",
      "  0.05031    -0.23260312 -1.2818303   0.16      ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0090, -0.0754, -0.2484,  ...,  0.0341, -0.2629, -1.3047],\n",
      "        [ 0.0090, -0.0754, -0.2484,  ...,  0.0341, -0.2629, -1.3047],\n",
      "        [ 0.0090, -0.0754, -0.2484,  ...,  0.0341, -0.2629, -1.3047],\n",
      "        ...,\n",
      "        [-0.1670,  0.4051, -0.1333,  ..., -0.7359,  0.8851, -0.3576],\n",
      "        [-0.1662, -0.1393,  0.5654,  ..., -0.2582,  0.6445,  0.2183],\n",
      "        [-0.1662, -0.1393,  0.5654,  ..., -0.2582,  0.6445,  0.2183]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00901554 -0.0753895  -0.24839976  0.02754251 -0.2143466  -0.6683464\n",
      " -0.06110238 -0.39471376 -1.4164444  -0.20151022 -0.4571202  -1.7118838\n",
      " -0.3690345  -0.5683577  -2.186548   -0.19094369 -0.6804039  -1.573265\n",
      "  0.01864725 -0.7097265  -1.383503   -0.02991622 -0.6455381  -1.4402881\n",
      " -0.03063198 -0.7784951  -1.5564888  -0.14983594 -0.5770702  -1.4899224\n",
      " -0.06872751 -0.62955135 -1.4638631  -0.08191585 -0.6053721  -1.5583285\n",
      "  0.05002014 -0.6245393  -1.6048709  -0.06456473 -0.4948599  -1.3195938\n",
      " -0.17277229 -0.26872897 -1.9489118  -0.02455866 -0.4187064  -1.9490732\n",
      "  0.1300878  -0.38949096 -1.4592155  -0.1632458  -0.2593761  -1.2548786\n",
      " -0.08809706 -0.23834133 -1.3359764  -0.04224917 -0.24926822 -1.4523165\n",
      "  0.0340766  -0.262859   -1.3047135 ]\n",
      "data: [ 0.00901554 -0.0753895  -0.24839978  0.02754251 -0.2143466  -0.6683464\n",
      " -0.06110238 -0.39471376 -1.4164444  -0.20151022 -0.4571202  -1.7118839\n",
      " -0.3690345  -0.5683577  -2.186548   -0.19094367 -0.6804039  -1.573265\n",
      "  0.01864725 -0.7097265  -1.383503   -0.02991622 -0.6455381  -1.4402881\n",
      " -0.03063198 -0.7784951  -1.5564888  -0.14983594 -0.5770702  -1.4899223\n",
      " -0.06872751 -0.62955135 -1.463863   -0.08191585 -0.6053721  -1.5583285\n",
      "  0.05002014 -0.6245393  -1.6048709  -0.06456473 -0.49485987 -1.3195938\n",
      " -0.17277229 -0.26872897 -1.9489118  -0.02455866 -0.4187064  -1.9490732\n",
      "  0.1300878  -0.38949096 -1.4592155  -0.1632458  -0.2593761  -1.2548786\n",
      " -0.08809706 -0.23834133 -1.3359764  -0.04224917 -0.24926823 -1.4523166\n",
      "  0.0340766  -0.262859   -1.3047135   0.17      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0146, -0.0828, -0.2502,  ...,  0.0441, -0.2700, -1.2819],\n",
      "        [ 0.0146, -0.0828, -0.2502,  ...,  0.0441, -0.2700, -1.2819],\n",
      "        [ 0.0146, -0.0828, -0.2502,  ...,  0.0441, -0.2700, -1.2819],\n",
      "        ...,\n",
      "        [-0.1289,  0.3950, -0.1601,  ..., -0.7184,  0.9027, -0.4279],\n",
      "        [-0.1426, -0.1648,  0.5690,  ..., -0.2557,  0.6055,  0.2192],\n",
      "        [-0.1426, -0.1648,  0.5690,  ..., -0.2557,  0.6055,  0.2192]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0146401  -0.08282666 -0.25022078  0.03781169 -0.2130603  -0.64322984\n",
      " -0.05811159 -0.40316033 -1.403413   -0.19915274 -0.46421802 -1.6987783\n",
      " -0.36015636 -0.5720587  -2.176453   -0.18081522 -0.69378257 -1.5621743\n",
      "  0.02158169 -0.7299849  -1.3899186  -0.02964649 -0.6650505  -1.4457308\n",
      " -0.03136892 -0.807372   -1.5639343  -0.13826248 -0.5948942  -1.4744539\n",
      " -0.06218364 -0.6470791  -1.4504218  -0.07471199 -0.6207653  -1.5419949\n",
      "  0.05478214 -0.6463783  -1.580857   -0.05214384 -0.5025066  -1.3063173\n",
      " -0.17472994 -0.27495918 -1.9788146  -0.01464602 -0.43291596 -1.9849733\n",
      "  0.14140129 -0.39992318 -1.4393436  -0.15650144 -0.2710446  -1.2390916\n",
      " -0.08036641 -0.24763659 -1.3228897  -0.03899098 -0.257116   -1.4397578\n",
      "  0.04414354 -0.27003527 -1.2818772 ]\n",
      "data: [ 0.0146401  -0.08282666 -0.25022078  0.03781169 -0.2130603  -0.64322984\n",
      " -0.05811159 -0.40316033 -1.403413   -0.19915274 -0.46421802 -1.6987783\n",
      " -0.36015636 -0.5720587  -2.176453   -0.18081522 -0.69378257 -1.5621743\n",
      "  0.02158169 -0.7299849  -1.3899186  -0.02964649 -0.6650505  -1.4457307\n",
      " -0.03136892 -0.807372   -1.5639343  -0.13826248 -0.5948942  -1.4744539\n",
      " -0.06218364 -0.6470791  -1.4504218  -0.07471199 -0.6207653  -1.5419949\n",
      "  0.05478214 -0.6463783  -1.580857   -0.05214384 -0.5025066  -1.3063173\n",
      " -0.17472994 -0.27495918 -1.9788146  -0.01464602 -0.43291596 -1.9849733\n",
      "  0.14140129 -0.39992318 -1.4393436  -0.15650144 -0.2710446  -1.2390916\n",
      " -0.08036641 -0.24763659 -1.3228897  -0.03899098 -0.257116   -1.4397578\n",
      "  0.04414354 -0.27003527 -1.2818772   0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EC24D30>\n",
      "tensor([[ 0.0163, -0.0354, -0.2438,  ...,  0.0422, -0.2306, -1.2669],\n",
      "        [ 0.0163, -0.0354, -0.2438,  ...,  0.0422, -0.2306, -1.2669],\n",
      "        [ 0.0163, -0.0354, -0.2438,  ...,  0.0422, -0.2306, -1.2669],\n",
      "        ...,\n",
      "        [-0.1648,  0.3497, -0.1159,  ..., -0.7980,  0.8360, -0.3628],\n",
      "        [-0.1343, -0.1592,  0.5594,  ..., -0.2083,  0.6042,  0.2111],\n",
      "        [-0.1343, -0.1592,  0.5594,  ..., -0.2083,  0.6042,  0.2111]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01634895 -0.03536431 -0.2437821   0.03237461 -0.16249605 -0.6285298\n",
      " -0.07464354 -0.35488054 -1.3911381  -0.22106193 -0.41725707 -1.6866217\n",
      " -0.388712   -0.5212332  -2.168163   -0.18281862 -0.6531066  -1.5481012\n",
      "  0.00531502 -0.6940441  -1.3745048  -0.0448359  -0.6250204  -1.4330745\n",
      " -0.04564257 -0.7751199  -1.5510643  -0.14034028 -0.5567144  -1.4603903\n",
      " -0.07086929 -0.6083541  -1.4326065  -0.08626992 -0.5841311  -1.5268664\n",
      "  0.05029771 -0.60412765 -1.5602789  -0.05672132 -0.4647218  -1.2947631\n",
      " -0.17954212 -0.2396546  -1.9696836  -0.02114645 -0.3951763  -1.9797914\n",
      "  0.14133663 -0.36604938 -1.4198308  -0.15743075 -0.23463982 -1.2275689\n",
      " -0.08996364 -0.21317643 -1.3139796  -0.05140688 -0.21718675 -1.4309716\n",
      "  0.04215037 -0.23055185 -1.2669382 ]\n",
      "data: [ 0.01634895 -0.03536431 -0.2437821   0.03237461 -0.16249605 -0.6285298\n",
      " -0.07464354 -0.3548805  -1.391138   -0.22106193 -0.41725707 -1.6866217\n",
      " -0.38871202 -0.5212332  -2.168163   -0.18281862 -0.6531065  -1.5481012\n",
      "  0.00531502 -0.6940441  -1.3745048  -0.0448359  -0.6250204  -1.4330745\n",
      " -0.04564257 -0.77511996 -1.5510643  -0.14034028 -0.5567144  -1.4603903\n",
      " -0.07086929 -0.6083541  -1.4326065  -0.08626992 -0.5841311  -1.5268664\n",
      "  0.05029771 -0.60412765 -1.5602789  -0.05672132 -0.4647218  -1.2947631\n",
      " -0.17954212 -0.2396546  -1.9696836  -0.02114644 -0.3951763  -1.9797914\n",
      "  0.14133663 -0.36604938 -1.4198308  -0.15743075 -0.23463982 -1.2275689\n",
      " -0.08996364 -0.21317643 -1.3139796  -0.05140688 -0.21718675 -1.4309716\n",
      "  0.04215037 -0.23055185 -1.2669382   0.19      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0096, -0.0346, -0.2194,  ...,  0.0302, -0.2247, -1.2712],\n",
      "        [ 0.0096, -0.0346, -0.2194,  ...,  0.0302, -0.2247, -1.2712],\n",
      "        [ 0.0096, -0.0346, -0.2194,  ...,  0.0302, -0.2247, -1.2712],\n",
      "        ...,\n",
      "        [-0.3681,  0.1263, -0.3718,  ..., -0.8805,  0.5080, -0.4874],\n",
      "        [-0.1253, -0.1146,  0.5544,  ..., -0.2174,  0.6677,  0.2290],\n",
      "        [-0.1253, -0.1146,  0.5544,  ..., -0.2174,  0.6677,  0.2290]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00961383 -0.03462193 -0.2193536   0.02134905 -0.18017454 -0.6474037\n",
      " -0.06555381 -0.35506684 -1.3762587  -0.20706505 -0.41763753 -1.6707585\n",
      " -0.38427204 -0.531331   -2.137722   -0.19566298 -0.6380266  -1.5277835\n",
      "  0.01272658 -0.6631999  -1.33064    -0.0329464  -0.59960306 -1.3881931\n",
      " -0.03172531 -0.72924227 -1.5011411  -0.15535349 -0.5309379  -1.4485703\n",
      " -0.07247034 -0.5845391  -1.4200126  -0.08571316 -0.5630896  -1.5165019\n",
      "  0.05025741 -0.5769147  -1.5666412  -0.06966811 -0.45419565 -1.2793493\n",
      " -0.17066228 -0.23285913 -1.8847431  -0.02834982 -0.37832367 -1.8811524\n",
      "  0.12594372 -0.35120445 -1.4195054  -0.1625875  -0.21807997 -1.2187663\n",
      " -0.09169679 -0.19994244 -1.2969224  -0.04435911 -0.21027932 -1.4140259\n",
      "  0.0301535  -0.22468571 -1.2711734 ]\n",
      "data: [ 0.00961383 -0.03462193 -0.2193536   0.02134905 -0.18017454 -0.6474037\n",
      " -0.06555381 -0.35506684 -1.3762587  -0.20706505 -0.41763753 -1.6707585\n",
      " -0.38427204 -0.531331   -2.137722   -0.19566298 -0.6380266  -1.5277835\n",
      "  0.01272658 -0.6631999  -1.33064    -0.0329464  -0.59960306 -1.388193\n",
      " -0.03172531 -0.72924227 -1.5011411  -0.15535349 -0.5309379  -1.4485703\n",
      " -0.07247034 -0.5845391  -1.4200127  -0.08571316 -0.5630896  -1.5165019\n",
      "  0.05025741 -0.5769147  -1.5666412  -0.06966811 -0.45419562 -1.2793493\n",
      " -0.17066228 -0.23285913 -1.8847431  -0.02834982 -0.37832367 -1.8811524\n",
      "  0.12594372 -0.35120445 -1.4195054  -0.1625875  -0.21807997 -1.2187663\n",
      " -0.09169678 -0.19994244 -1.2969224  -0.04435911 -0.21027932 -1.4140259\n",
      "  0.0301535  -0.22468571 -1.2711734   0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0097, -0.0695, -0.2384,  ...,  0.0284, -0.2532, -1.2849],\n",
      "        [ 0.0097, -0.0695, -0.2384,  ...,  0.0284, -0.2532, -1.2849],\n",
      "        [ 0.0097, -0.0695, -0.2384,  ...,  0.0284, -0.2532, -1.2849],\n",
      "        ...,\n",
      "        [-0.3018,  0.2578, -0.3489,  ..., -0.8187,  0.7273, -0.5316],\n",
      "        [-0.1221, -0.0817,  0.6030,  ..., -0.2406,  0.7048,  0.2657],\n",
      "        [-0.1221, -0.0817,  0.6030,  ..., -0.2406,  0.7048,  0.2657]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00974167 -0.06951777 -0.23844057  0.03536976 -0.20366427 -0.645017\n",
      " -0.06443296 -0.3879806  -1.4062817  -0.20442767 -0.45143464 -1.6949706\n",
      " -0.36408463 -0.55377185 -2.1786885  -0.18406737 -0.6766789  -1.5615869\n",
      "  0.00983548 -0.7080239  -1.3799312  -0.03620642 -0.6419158  -1.4374008\n",
      " -0.04153369 -0.7786435  -1.5535281  -0.14717926 -0.5773326  -1.4805315\n",
      " -0.07162677 -0.6278124  -1.4514313  -0.08998322 -0.6000533  -1.5418079\n",
      "  0.04375985 -0.619385   -1.5838559  -0.06796005 -0.49131277 -1.3136439\n",
      " -0.180284   -0.26330182 -1.9576614  -0.03011636 -0.4131665  -1.9636335\n",
      "  0.12249269 -0.38364843 -1.4417596  -0.16441862 -0.25899506 -1.2474856\n",
      " -0.09737396 -0.2339989  -1.32476    -0.05391999 -0.23837045 -1.4424849\n",
      "  0.02835346 -0.2532267  -1.2848909 ]\n",
      "data: [ -3.12  -6.    -3.05  -3.31  -5.91  -3.09  -5.54 -11.71  12.72  -5.69\n",
      " -11.88  12.68  -5.71 -12.14  12.55  -3.38  -6.51  -2.85  -5.21 -12.15\n",
      "  11.5   -3.3   -6.71  -3.21  -3.1   -6.7   -3.23  -3.23  -6.4   -3.15\n",
      "  -3.45  -6.82  -2.27  -3.18  -6.42  -3.08  -5.53 -11.92  12.58  -3.15\n",
      "  -6.59  -3.13  -3.45  -6.84  -2.27  -3.1   -6.45  -3.01  -3.04  -6.41\n",
      "  -3.04  -3.16  -6.6   -3.18  -5.07 -11.84  10.86  -2.87  -6.49  -3.09\n",
      "  -3.04  -6.41  -3.04   0.  ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[-0.0959,  0.3393,  0.1782,  ..., -0.4975,  0.4853,  0.0264],\n",
      "        [-0.0959,  0.3393,  0.1782,  ..., -0.4975,  0.4853,  0.0264],\n",
      "        [-0.0959,  0.3393,  0.1782,  ..., -0.4975,  0.4853,  0.0264],\n",
      "        ...,\n",
      "        [ 0.6064, -0.5028, -0.0627,  ...,  1.4272, -1.0623,  0.9649],\n",
      "        [-0.0206,  0.0412,  0.1958,  ..., -0.3113, -0.4862,  1.0442],\n",
      "        [-0.0206,  0.0412,  0.1958,  ..., -0.3113, -0.4862,  1.0442]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.09588498  0.33933505  0.17822628 -0.13561109  0.20744446 -0.08641519\n",
      " -0.14085823  0.0897413  -0.21759875 -0.12622632  0.02765691 -0.15547378\n",
      " -0.14042312  0.05705383 -0.12595959 -0.23920351  0.17295767 -0.28438783\n",
      " -0.26574963  0.16623993 -0.03393926 -0.27575022  0.09162943  0.00237499\n",
      " -0.2922717   0.13285947 -0.01172023 -0.29630262  0.2972217  -0.29162812\n",
      " -0.39321992  0.3077833  -0.22486366 -0.40902936  0.26669273 -0.19448079\n",
      " -0.4338729   0.25281742 -0.19075878 -0.3773014   0.37603694 -0.29370433\n",
      " -0.49377903  0.37943023 -0.35852462 -0.50265443  0.37718394 -0.36518657\n",
      " -0.5267516   0.358216   -0.07618202 -0.37325045  0.5083277  -0.18435933\n",
      " -0.44931015  0.521183   -0.08992253 -0.46498612  0.52180177 -0.0595212\n",
      " -0.49754247  0.4852832   0.02640893]\n",
      "init: [-0.09588498  0.33933505  0.17822628 -0.13561109  0.20744446 -0.08641519\n",
      " -0.14085823  0.0897413  -0.21759875 -0.12622632  0.02765691 -0.15547378\n",
      " -0.14042312  0.05705383 -0.12595959 -0.23920351  0.17295767 -0.28438783\n",
      " -0.26574963  0.16623993 -0.03393926 -0.27575022  0.09162943  0.00237499\n",
      " -0.2922717   0.13285947 -0.01172023 -0.29630262  0.2972217  -0.29162812\n",
      " -0.39321992  0.3077833  -0.22486366 -0.40902936  0.26669273 -0.19448079\n",
      " -0.4338729   0.25281742 -0.19075878 -0.3773014   0.37603694 -0.29370433\n",
      " -0.49377903  0.37943023 -0.35852462 -0.50265443  0.37718394 -0.36518657\n",
      " -0.5267516   0.358216   -0.07618202 -0.37325045  0.5083277  -0.18435933\n",
      " -0.44931015  0.521183   -0.08992253 -0.46498612  0.52180177 -0.0595212\n",
      " -0.49754247  0.4852832   0.02640893]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [-0.09588498  0.33933505  0.17822628 -0.13561109  0.20744446 -0.08641519\n",
      " -0.14085823  0.0897413  -0.21759874 -0.12622632  0.02765691 -0.15547378\n",
      " -0.14042312  0.05705383 -0.12595959 -0.23920351  0.17295767 -0.28438783\n",
      " -0.26574963  0.16623993 -0.03393926 -0.27575022  0.09162943  0.00237499\n",
      " -0.2922717   0.13285947 -0.01172023 -0.29630262  0.2972217  -0.29162812\n",
      " -0.39321992  0.3077833  -0.22486366 -0.40902936  0.26669273 -0.1944808\n",
      " -0.4338729   0.25281742 -0.19075878 -0.3773014   0.37603694 -0.29370433\n",
      " -0.49377903  0.37943023 -0.35852462 -0.50265443  0.37718394 -0.36518657\n",
      " -0.5267516   0.358216   -0.07618202 -0.37325045  0.5083277  -0.18435933\n",
      " -0.44931015  0.521183   -0.08992253 -0.46498612  0.52180177 -0.0595212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.49754247  0.4852832   0.02640893  0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.1284, -0.1580,  0.3342,  ..., -0.3797, -0.2014, -0.5997],\n",
      "        [-0.1284, -0.1580,  0.3342,  ..., -0.3797, -0.2014, -0.5997],\n",
      "        [-0.1284, -0.1580,  0.3342,  ..., -0.3797, -0.2014, -0.5997],\n",
      "        ...,\n",
      "        [ 0.7673,  0.4883, -0.1009,  ...,  1.0541,  1.4822, -0.3900],\n",
      "        [ 0.2719, -0.1170, -0.2855,  ..., -0.5790,  0.5586, -0.4219],\n",
      "        [ 0.2719, -0.1170, -0.2855,  ..., -0.5790,  0.5586, -0.4219]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.12844321 -0.15796086  0.3342011  -0.2078867  -0.28025484  0.00124824\n",
      " -0.46653694 -0.4099047  -0.44003618 -0.68458277 -0.47860345 -0.58624834\n",
      " -0.90198433 -0.40902066 -0.8842688  -0.48351592 -0.6006197  -0.6016426\n",
      " -0.7501477  -0.61524045 -0.7470787  -0.7009128  -0.5122543  -0.7885756\n",
      " -0.6926131  -0.5890269  -0.7669249  -0.4554786  -0.5216597  -0.5952644\n",
      " -0.5650479  -0.50085914 -0.51414204 -0.61948323 -0.48810944 -0.60812116\n",
      " -0.46771008 -0.3434801  -0.72462004 -0.4607011  -0.48957476 -0.5454801\n",
      " -0.49706763 -0.39831397 -0.6371445  -0.5138722  -0.35845506 -0.65919906\n",
      " -0.44782197 -0.28895342 -0.6605437  -0.3665381  -0.334109   -0.55264163\n",
      " -0.54627365 -0.25440383 -0.5719088  -0.43741632 -0.20231777 -0.6495332\n",
      " -0.37968808 -0.20143455 -0.5997115 ]\n",
      "data: [-0.12844321 -0.15796086  0.3342011  -0.2078867  -0.28025484  0.00124824\n",
      " -0.46653694 -0.40990466 -0.44003618 -0.68458277 -0.47860345 -0.58624834\n",
      " -0.90198433 -0.40902066 -0.8842688  -0.48351592 -0.6006197  -0.6016426\n",
      " -0.7501477  -0.61524045 -0.7470787  -0.7009128  -0.5122543  -0.7885756\n",
      " -0.6926131  -0.5890269  -0.7669249  -0.45547858 -0.5216597  -0.5952644\n",
      " -0.5650479  -0.50085914 -0.51414204 -0.61948323 -0.48810944 -0.60812116\n",
      " -0.46771008 -0.3434801  -0.72462004 -0.4607011  -0.4895748  -0.5454801\n",
      " -0.49706763 -0.39831397 -0.6371445  -0.5138722  -0.35845506 -0.65919906\n",
      " -0.44782197 -0.28895342 -0.6605437  -0.36653814 -0.334109   -0.55264163\n",
      " -0.54627365 -0.25440383 -0.5719088  -0.43741632 -0.20231777 -0.6495332\n",
      " -0.37968808 -0.20143455 -0.5997115   0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[-0.0199, -0.0436, -0.2045,  ...,  0.1247, -0.3252, -0.8159],\n",
      "        [-0.0199, -0.0436, -0.2045,  ...,  0.1247, -0.3252, -0.8159],\n",
      "        [-0.0199, -0.0436, -0.2045,  ...,  0.1247, -0.3252, -0.8159],\n",
      "        ...,\n",
      "        [ 0.6790, -0.5045,  0.4298,  ...,  0.3237,  0.5177, -0.4708],\n",
      "        [ 0.1501,  0.1070,  0.4322,  ..., -0.7412,  0.6616, -0.0132],\n",
      "        [ 0.1501,  0.1070,  0.4322,  ..., -0.7412,  0.6616, -0.0132]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01986989 -0.04362129 -0.20454869 -0.06629926 -0.14116774 -0.34588432\n",
      " -0.4199581  -0.3756634  -1.0206356  -0.57241595 -0.47755727 -1.1566021\n",
      " -0.8247602  -0.525777   -1.5251483  -0.2568499  -0.6590239  -1.1851447\n",
      " -0.4202403  -0.7131994  -1.2636923  -0.3565696  -0.6006738  -1.2951167\n",
      " -0.24129194 -0.82738173 -1.2947142  -0.18194866 -0.5562327  -1.1604391\n",
      " -0.22490579 -0.6290668  -0.9980945  -0.22901714 -0.6223415  -1.0304666\n",
      "  0.09750497 -0.5699149  -1.122717   -0.1567775  -0.5716976  -1.0309868\n",
      " -0.25393447 -0.35971418 -1.473564   -0.08354088 -0.48553064 -1.5042855\n",
      "  0.15331978 -0.43927458 -0.9731609  -0.15916482 -0.36493284 -0.9707051\n",
      " -0.2537428  -0.32636866 -0.9806111  -0.12162629 -0.2607879  -1.1116315\n",
      "  0.12465676 -0.32523048 -0.8159044 ]\n",
      "data: [-0.01986989 -0.04362129 -0.20454869 -0.06629926 -0.14116774 -0.34588432\n",
      " -0.4199581  -0.3756634  -1.0206356  -0.57241595 -0.47755727 -1.1566021\n",
      " -0.8247602  -0.525777   -1.5251483  -0.2568499  -0.6590239  -1.1851447\n",
      " -0.4202403  -0.7131994  -1.2636923  -0.3565696  -0.6006738  -1.2951168\n",
      " -0.24129194 -0.82738173 -1.2947142  -0.18194866 -0.5562327  -1.1604391\n",
      " -0.22490579 -0.6290668  -0.9980945  -0.22901714 -0.6223415  -1.0304666\n",
      "  0.09750498 -0.5699149  -1.122717   -0.1567775  -0.5716976  -1.0309868\n",
      " -0.25393447 -0.35971415 -1.473564   -0.08354088 -0.48553067 -1.5042855\n",
      "  0.15331978 -0.4392746  -0.9731609  -0.15916482 -0.36493284 -0.9707051\n",
      " -0.2537428  -0.3263687  -0.9806111  -0.12162629 -0.2607879  -1.1116315\n",
      "  0.12465677 -0.32523048 -0.8159044   0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.1136, -0.1264, -0.1228,  ...,  0.2267, -0.3060, -1.1822],\n",
      "        [ 0.1136, -0.1264, -0.1228,  ...,  0.2267, -0.3060, -1.1822],\n",
      "        [ 0.1136, -0.1264, -0.1228,  ...,  0.2267, -0.3060, -1.1822],\n",
      "        ...,\n",
      "        [-0.0644,  0.4213,  0.1635,  ...,  0.0976,  1.2057, -0.2102],\n",
      "        [-0.2454,  0.3473,  0.1858,  ..., -0.7488,  0.9250, -0.1145],\n",
      "        [-0.2454,  0.3473,  0.1858,  ..., -0.7488,  0.9250, -0.1145]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.11355506 -0.12642398 -0.12278675  0.1548535  -0.2636586  -0.4847131\n",
      "  0.09484801 -0.41450688 -1.2540419  -0.055084   -0.46168646 -1.5720645\n",
      " -0.21322203 -0.6058042  -2.0798886  -0.10441671 -0.69093436 -1.4755361\n",
      "  0.22263673 -0.6906815  -1.2491157   0.16884261 -0.6362446  -1.2916309\n",
      "  0.17136443 -0.73485994 -1.423803   -0.04276361 -0.581641   -1.380758\n",
      "  0.09783005 -0.64833456 -1.3887737   0.11870988 -0.6079541  -1.4878051\n",
      "  0.26062512 -0.6666898  -1.5647445   0.09259276 -0.51293445 -1.1726913\n",
      " -0.01060972 -0.24755219 -1.7983954   0.173091   -0.4341615  -1.7732816\n",
      "  0.34940815 -0.39509827 -1.3817695  -0.03691729 -0.26314402 -1.1074308\n",
      "  0.1100335  -0.23777308 -1.1596063   0.1773892  -0.28781605 -1.2865962\n",
      "  0.22674507 -0.306      -1.1821921 ]\n",
      "data: [ 0.11355506 -0.12642398 -0.12278674  0.1548535  -0.2636586  -0.4847131\n",
      "  0.09484801 -0.41450688 -1.2540419  -0.055084   -0.4616865  -1.5720645\n",
      " -0.21322203 -0.6058042  -2.0798886  -0.10441671 -0.69093436 -1.475536\n",
      "  0.22263674 -0.6906815  -1.2491157   0.16884261 -0.6362446  -1.2916309\n",
      "  0.17136443 -0.73485994 -1.423803   -0.04276361 -0.581641   -1.380758\n",
      "  0.09783005 -0.64833456 -1.3887737   0.11870989 -0.6079541  -1.4878051\n",
      "  0.26062512 -0.6666898  -1.5647445   0.09259276 -0.51293445 -1.1726913\n",
      " -0.01060972 -0.24755219 -1.7983954   0.173091   -0.43416154 -1.7732816\n",
      "  0.34940815 -0.39509827 -1.3817695  -0.03691729 -0.26314402 -1.1074308\n",
      "  0.11003349 -0.23777308 -1.1596063   0.1773892  -0.28781605 -1.2865962\n",
      "  0.22674507 -0.306      -1.1821921   0.04      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0447, -0.1212, -0.1628,  ..., -0.0054, -0.2952, -1.2394],\n",
      "        [ 0.0447, -0.1212, -0.1628,  ..., -0.0054, -0.2952, -1.2394],\n",
      "        [ 0.0447, -0.1212, -0.1628,  ..., -0.0054, -0.2952, -1.2394],\n",
      "        ...,\n",
      "        [-0.1592,  0.3219, -0.0666,  ..., -0.3789,  0.7838, -0.4852],\n",
      "        [-0.1530,  0.1452,  0.4291,  ..., -0.0630,  0.9699, -0.0450],\n",
      "        [-0.1530,  0.1452,  0.4291,  ..., -0.0630,  0.9699, -0.0450]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 4.4678550e-02 -1.2118217e-01 -1.6280021e-01  5.7038736e-02\n",
      " -2.7043074e-01 -5.8852422e-01 -6.6713706e-02 -4.8921734e-01\n",
      " -1.4073153e+00 -2.2686452e-01 -5.7034731e-01 -1.7025681e+00\n",
      " -4.0841883e-01 -6.7178893e-01 -2.2128854e+00 -1.7894155e-01\n",
      " -7.4310398e-01 -1.5952668e+00 -1.2221336e-03 -8.0061126e-01\n",
      " -1.3588521e+00 -5.6725934e-02 -7.3464680e-01 -1.4135823e+00\n",
      " -9.1236919e-02 -8.8994670e-01 -1.5310123e+00 -1.4532183e-01\n",
      " -6.2961709e-01 -1.5012429e+00 -9.6895725e-02 -6.9431329e-01\n",
      " -1.4469304e+00 -1.3697894e-01 -6.8055403e-01 -1.5371566e+00\n",
      " -1.1641741e-02 -6.9310892e-01 -1.5650823e+00 -7.1714610e-02\n",
      " -5.3666115e-01 -1.3335850e+00 -2.1356770e-01 -3.1244791e-01\n",
      " -1.9965267e+00 -7.4137762e-02 -4.7594839e-01 -2.0049684e+00\n",
      "  7.2584957e-02 -4.4778070e-01 -1.3987567e+00 -1.7111711e-01\n",
      " -2.9612482e-01 -1.2537415e+00 -1.2391144e-01 -2.7424854e-01\n",
      " -1.3090658e+00 -8.9042664e-02 -2.7924812e-01 -1.4181418e+00\n",
      " -5.3810179e-03 -2.9519194e-01 -1.2394080e+00]\n",
      "data: [ 4.4678550e-02 -1.2118217e-01 -1.6280022e-01  5.7038736e-02\n",
      " -2.7043074e-01 -5.8852422e-01 -6.6713706e-02 -4.8921734e-01\n",
      " -1.4073153e+00 -2.2686452e-01 -5.7034731e-01 -1.7025681e+00\n",
      " -4.0841883e-01 -6.7178893e-01 -2.2128854e+00 -1.7894155e-01\n",
      " -7.4310392e-01 -1.5952668e+00 -1.2221336e-03 -8.0061126e-01\n",
      " -1.3588520e+00 -5.6725934e-02 -7.3464674e-01 -1.4135823e+00\n",
      " -9.1236919e-02 -8.8994670e-01 -1.5310123e+00 -1.4532183e-01\n",
      " -6.2961709e-01 -1.5012429e+00 -9.6895725e-02 -6.9431329e-01\n",
      " -1.4469304e+00 -1.3697894e-01 -6.8055403e-01 -1.5371566e+00\n",
      " -1.1641741e-02 -6.9310892e-01 -1.5650822e+00 -7.1714610e-02\n",
      " -5.3666115e-01 -1.3335850e+00 -2.1356769e-01 -3.1244791e-01\n",
      " -1.9965268e+00 -7.4137762e-02 -4.7594842e-01 -2.0049684e+00\n",
      "  7.2584957e-02 -4.4778070e-01 -1.3987567e+00 -1.7111711e-01\n",
      " -2.9612482e-01 -1.2537415e+00 -1.2391144e-01 -2.7424854e-01\n",
      " -1.3090658e+00 -8.9042664e-02 -2.7924812e-01 -1.4181418e+00\n",
      " -5.3810179e-03 -2.9519194e-01 -1.2394080e+00  5.0000001e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0206, -0.0353, -0.1457,  ...,  0.0613, -0.2384, -1.1256],\n",
      "        [ 0.0206, -0.0353, -0.1457,  ...,  0.0613, -0.2384, -1.1256],\n",
      "        [ 0.0206, -0.0353, -0.1457,  ...,  0.0613, -0.2384, -1.1256],\n",
      "        ...,\n",
      "        [-0.1993,  0.3797, -0.1035,  ..., -0.8998,  0.9326, -0.3674],\n",
      "        [-0.0932, -0.1040,  0.6362,  ..., -0.1651,  0.5868,  0.3336],\n",
      "        [-0.0932, -0.1040,  0.6362,  ..., -0.1651,  0.5868,  0.3336]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02055803 -0.03529049 -0.14569111  0.04598026 -0.13252631 -0.43591362\n",
      " -0.09971413 -0.35927004 -1.2826493  -0.2511838  -0.4245358  -1.566051\n",
      " -0.3962022  -0.5119556  -2.0749195  -0.16876072 -0.67557716 -1.4565424\n",
      " -0.00889413 -0.74407774 -1.3288758  -0.05881231 -0.6676096  -1.3790438\n",
      " -0.05236159 -0.8398059  -1.5028577  -0.1243234  -0.5947411  -1.3571082\n",
      " -0.06760375 -0.64521223 -1.3277608  -0.07238234 -0.6086842  -1.4094632\n",
      "  0.07517847 -0.6438014  -1.4202691  -0.04252692 -0.48161203 -1.2018836\n",
      " -0.19792105 -0.24775754 -1.9687017  -0.00410437 -0.42021185 -1.9994614\n",
      "  0.18098937 -0.38291878 -1.2971518  -0.1639407  -0.2567724  -1.1184815\n",
      " -0.09376325 -0.22865658 -1.2124394  -0.06282127 -0.22604738 -1.3259554\n",
      "  0.06125202 -0.23841283 -1.1255889 ]\n",
      "data: [ 0.02055803 -0.03529049 -0.14569111  0.04598026 -0.13252631 -0.43591362\n",
      " -0.09971413 -0.35927    -1.2826493  -0.2511838  -0.42453584 -1.566051\n",
      " -0.3962022  -0.5119556  -2.0749195  -0.16876072 -0.67557716 -1.4565424\n",
      " -0.00889413 -0.74407774 -1.3288758  -0.05881231 -0.6676096  -1.3790439\n",
      " -0.05236159 -0.8398059  -1.5028577  -0.1243234  -0.5947411  -1.3571084\n",
      " -0.06760375 -0.64521223 -1.3277608  -0.07238234 -0.6086842  -1.4094632\n",
      "  0.07517847 -0.64380145 -1.4202691  -0.04252692 -0.48161203 -1.2018836\n",
      " -0.19792105 -0.24775752 -1.9687018  -0.00410437 -0.42021188 -1.9994614\n",
      "  0.18098935 -0.38291878 -1.2971518  -0.1639407  -0.2567724  -1.1184815\n",
      " -0.09376325 -0.22865658 -1.2124394  -0.06282127 -0.22604738 -1.3259554\n",
      "  0.06125202 -0.23841281 -1.1255889   0.06      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[-0.0490, -0.0260, -0.2513,  ...,  0.0115, -0.2117, -1.2626],\n",
      "        [-0.0490, -0.0260, -0.2513,  ...,  0.0115, -0.2117, -1.2626],\n",
      "        [-0.0490, -0.0260, -0.2513,  ...,  0.0115, -0.2117, -1.2626],\n",
      "        ...,\n",
      "        [-0.2497,  0.2575, -0.0670,  ..., -0.7732,  0.7604, -0.3402],\n",
      "        [-0.1592, -0.0648,  0.5561,  ..., -0.3294,  0.6951,  0.2299],\n",
      "        [-0.1592, -0.0648,  0.5561,  ..., -0.3294,  0.6951,  0.2299]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.04902385 -0.02596682 -0.2513163  -0.01678148 -0.13903493 -0.60098505\n",
      " -0.13137388 -0.33697528 -1.392656   -0.27966    -0.39538318 -1.6879363\n",
      " -0.43080282 -0.50176954 -2.17834    -0.24529628 -0.6357199  -1.5624102\n",
      " -0.03995641 -0.6813828  -1.4020817  -0.09270807 -0.6093863  -1.4544728\n",
      " -0.09377302 -0.7606534  -1.5772513  -0.19542238 -0.5466492  -1.4676583\n",
      " -0.1199623  -0.60005987 -1.4508423  -0.12390662 -0.5661546  -1.5383044\n",
      "  0.01438683 -0.60119045 -1.5704824  -0.10241141 -0.4508223  -1.2954129\n",
      " -0.23721749 -0.206155   -2.013503   -0.0553723  -0.37908784 -2.0251179\n",
      "  0.11658041 -0.34122375 -1.4306601  -0.21786511 -0.22023804 -1.2227467\n",
      " -0.13194153 -0.18985972 -1.3130376  -0.08705316 -0.20001811 -1.4312073\n",
      "  0.0115219  -0.21165417 -1.2626157 ]\n",
      "data: [-0.04902385 -0.02596682 -0.2513163  -0.01678148 -0.13903493 -0.60098505\n",
      " -0.13137388 -0.33697528 -1.392656   -0.27966    -0.39538318 -1.6879363\n",
      " -0.43080285 -0.50176954 -2.17834    -0.24529628 -0.6357199  -1.5624102\n",
      " -0.03995641 -0.6813828  -1.4020817  -0.09270807 -0.6093863  -1.4544728\n",
      " -0.09377302 -0.7606534  -1.5772513  -0.19542238 -0.5466492  -1.4676583\n",
      " -0.1199623  -0.60005987 -1.4508423  -0.12390662 -0.5661546  -1.5383044\n",
      "  0.01438683 -0.60119045 -1.5704824  -0.10241141 -0.4508223  -1.2954129\n",
      " -0.23721749 -0.206155   -2.013503   -0.05537229 -0.37908784 -2.0251179\n",
      "  0.11658041 -0.34122375 -1.4306601  -0.21786511 -0.22023803 -1.2227467\n",
      " -0.13194153 -0.18985972 -1.3130375  -0.08705316 -0.20001811 -1.4312073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.0115219  -0.21165417 -1.2626157   0.07      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0429, -0.0560, -0.1944,  ...,  0.0350, -0.2317, -1.2778],\n",
      "        [ 0.0429, -0.0560, -0.1944,  ...,  0.0350, -0.2317, -1.2778],\n",
      "        [ 0.0429, -0.0560, -0.1944,  ...,  0.0350, -0.2317, -1.2778],\n",
      "        ...,\n",
      "        [-0.3331,  0.2584, -0.3037,  ..., -0.8907,  0.7197, -0.4499],\n",
      "        [-0.2016, -0.1351,  0.5164,  ..., -0.2714,  0.6004,  0.2849],\n",
      "        [-0.2016, -0.1351,  0.5164,  ..., -0.2714,  0.6004,  0.2849]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04293198 -0.05600019 -0.19435638  0.05821944 -0.20269641 -0.62756324\n",
      " -0.0194987  -0.36409873 -1.3417984  -0.16064003 -0.4213637  -1.6353647\n",
      " -0.33796042 -0.5317843  -2.1100082  -0.16634123 -0.65444136 -1.493975\n",
      "  0.0415376  -0.6715268  -1.3137097  -0.00563535 -0.6088203  -1.3699312\n",
      " -0.00316897 -0.7282498  -1.4793717  -0.12994848 -0.54843634 -1.4210796\n",
      " -0.04545712 -0.59581375 -1.3994217  -0.05999064 -0.5691339  -1.5003923\n",
      "  0.06815776 -0.58096105 -1.5534382  -0.04846784 -0.47253025 -1.2566166\n",
      " -0.1432031  -0.24964868 -1.8375527  -0.00863773 -0.38573128 -1.8340721\n",
      "  0.13322692 -0.35851234 -1.417643   -0.1408231  -0.23578647 -1.202772\n",
      " -0.07323597 -0.21639349 -1.2849665  -0.0301434  -0.22282064 -1.4051503\n",
      "  0.03495732 -0.23171234 -1.2777932 ]\n",
      "data: [ 0.04293198 -0.05600019 -0.19435638  0.05821944 -0.20269641 -0.62756324\n",
      " -0.0194987  -0.36409873 -1.3417984  -0.16064003 -0.4213637  -1.6353647\n",
      " -0.33796042 -0.5317843  -2.1100082  -0.16634123 -0.65444136 -1.493975\n",
      "  0.0415376  -0.6715268  -1.3137097  -0.00563535 -0.6088203  -1.3699312\n",
      " -0.00316897 -0.7282498  -1.4793717  -0.12994848 -0.54843634 -1.4210798\n",
      " -0.04545711 -0.59581375 -1.3994217  -0.05999064 -0.5691339  -1.5003923\n",
      "  0.06815776 -0.58096105 -1.5534381  -0.04846784 -0.47253025 -1.2566166\n",
      " -0.1432031  -0.24964866 -1.8375527  -0.00863773 -0.38573128 -1.8340721\n",
      "  0.13322692 -0.35851234 -1.417643   -0.1408231  -0.23578648 -1.202772\n",
      " -0.07323597 -0.21639349 -1.2849665  -0.0301434  -0.22282064 -1.4051503\n",
      "  0.03495732 -0.23171234 -1.2777932   0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0229, -0.0665, -0.2676,  ...,  0.0405, -0.2487, -1.3078],\n",
      "        [ 0.0229, -0.0665, -0.2676,  ...,  0.0405, -0.2487, -1.3078],\n",
      "        [ 0.0229, -0.0665, -0.2676,  ...,  0.0405, -0.2487, -1.3078],\n",
      "        ...,\n",
      "        [-0.1648,  0.4161, -0.0696,  ..., -0.7338,  0.9229, -0.3418],\n",
      "        [-0.1606, -0.1059,  0.5904,  ..., -0.2506,  0.6946,  0.2418],\n",
      "        [-0.1606, -0.1059,  0.5904,  ..., -0.2506,  0.6946,  0.2418]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.2893857e-02 -6.6513412e-02 -2.6758397e-01  4.6483558e-02\n",
      " -1.9676276e-01 -6.6643351e-01 -7.3028825e-02 -3.9251146e-01\n",
      " -1.4464246e+00 -2.1902639e-01 -4.5937172e-01 -1.7272682e+00\n",
      " -3.7392282e-01 -5.5472457e-01 -2.2193525e+00 -1.7277181e-01\n",
      " -6.8349856e-01 -1.6023072e+00  1.8778443e-03 -7.2513306e-01\n",
      " -1.4245373e+00 -4.2203560e-02 -6.5151376e-01 -1.4820956e+00\n",
      " -4.5764983e-02 -7.9523170e-01 -1.5985007e+00 -1.3665424e-01\n",
      " -5.8724171e-01 -1.5215001e+00 -6.9913536e-02 -6.3579875e-01\n",
      " -1.4843062e+00 -8.7885350e-02 -6.0497588e-01 -1.5684315e+00\n",
      "  5.3431347e-02 -6.2127757e-01 -1.5989370e+00 -6.0572542e-02\n",
      " -4.9662644e-01 -1.3593060e+00 -1.7636855e-01 -2.6531732e-01\n",
      " -2.0045197e+00 -2.3628160e-02 -4.1541749e-01 -2.0168722e+00\n",
      "  1.3941088e-01 -3.8471317e-01 -1.4660906e+00 -1.5788662e-01\n",
      " -2.6411867e-01 -1.2876292e+00 -9.7339988e-02 -2.3491815e-01\n",
      " -1.3675028e+00 -5.5955902e-02 -2.3337947e-01 -1.4825311e+00\n",
      "  4.0453948e-02 -2.4869989e-01 -1.3078494e+00]\n",
      "data: [ 2.2893857e-02 -6.6513412e-02 -2.6758397e-01  4.6483561e-02\n",
      " -1.9676276e-01 -6.6643351e-01 -7.3028825e-02 -3.9251146e-01\n",
      " -1.4464246e+00 -2.1902639e-01 -4.5937172e-01 -1.7272682e+00\n",
      " -3.7392280e-01 -5.5472457e-01 -2.2193525e+00 -1.7277181e-01\n",
      " -6.8349856e-01 -1.6023071e+00  1.8778443e-03 -7.2513306e-01\n",
      " -1.4245373e+00 -4.2203560e-02 -6.5151376e-01 -1.4820956e+00\n",
      " -4.5764979e-02 -7.9523170e-01 -1.5985007e+00 -1.3665424e-01\n",
      " -5.8724171e-01 -1.5215001e+00 -6.9913536e-02 -6.3579875e-01\n",
      " -1.4843062e+00 -8.7885350e-02 -6.0497588e-01 -1.5684315e+00\n",
      "  5.3431347e-02 -6.2127757e-01 -1.5989370e+00 -6.0572542e-02\n",
      " -4.9662644e-01 -1.3593060e+00 -1.7636853e-01 -2.6531732e-01\n",
      " -2.0045197e+00 -2.3628160e-02 -4.1541749e-01 -2.0168722e+00\n",
      "  1.3941088e-01 -3.8471317e-01 -1.4660906e+00 -1.5788662e-01\n",
      " -2.6411867e-01 -1.2876292e+00 -9.7339995e-02 -2.3491816e-01\n",
      " -1.3675027e+00 -5.5955902e-02 -2.3337945e-01 -1.4825311e+00\n",
      "  4.0453948e-02 -2.4869989e-01 -1.3078494e+00  9.0000004e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0087, -0.0438, -0.2390,  ...,  0.0437, -0.2339, -1.2846],\n",
      "        [ 0.0087, -0.0438, -0.2390,  ...,  0.0437, -0.2339, -1.2846],\n",
      "        [ 0.0087, -0.0438, -0.2390,  ...,  0.0437, -0.2339, -1.2846],\n",
      "        ...,\n",
      "        [-0.1266,  0.3836, -0.1363,  ..., -0.7338,  0.8887, -0.3828],\n",
      "        [-0.1497, -0.1705,  0.5386,  ..., -0.2467,  0.5822,  0.2194],\n",
      "        [-0.1497, -0.1705,  0.5386,  ..., -0.2467,  0.5822,  0.2194]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00869123 -0.04381669 -0.23899508  0.02384539 -0.18549626 -0.65011346\n",
      " -0.04620216 -0.35708424 -1.3730557  -0.18654516 -0.41382766 -1.6787719\n",
      " -0.36101735 -0.53641474 -2.1450973  -0.19729622 -0.6414099  -1.5404295\n",
      "  0.03679949 -0.66350454 -1.3571563  -0.01559883 -0.60493374 -1.4113203\n",
      " -0.00934181 -0.7316382  -1.5268265  -0.15053229 -0.5343197  -1.4541999\n",
      " -0.05746375 -0.59002835 -1.4364895  -0.06281489 -0.5679687  -1.5373566\n",
      "  0.06408462 -0.5930636  -1.5904806  -0.05355228 -0.4529126  -1.2790699\n",
      " -0.16092959 -0.22971627 -1.9019177  -0.00909837 -0.38419843 -1.8945485\n",
      "  0.14429371 -0.35329318 -1.4390959  -0.15766191 -0.2170419  -1.219912\n",
      " -0.06774877 -0.20084003 -1.2976722  -0.02143386 -0.22216982 -1.4150461\n",
      "  0.04367381 -0.23387913 -1.2846212 ]\n",
      "data: [ 0.00869123 -0.04381669 -0.23899508  0.02384539 -0.18549626 -0.65011346\n",
      " -0.04620216 -0.35708424 -1.3730557  -0.18654516 -0.41382766 -1.6787719\n",
      " -0.36101735 -0.53641474 -2.1450973  -0.19729622 -0.64140993 -1.5404296\n",
      "  0.03679949 -0.66350454 -1.3571563  -0.01559883 -0.60493374 -1.4113203\n",
      " -0.00934181 -0.7316382  -1.5268265  -0.15053229 -0.5343197  -1.4542\n",
      " -0.05746375 -0.59002835 -1.4364895  -0.06281489 -0.5679687  -1.5373566\n",
      "  0.06408462 -0.5930636  -1.5904804  -0.05355228 -0.4529126  -1.2790699\n",
      " -0.16092959 -0.22971626 -1.9019177  -0.00909837 -0.38419843 -1.8945485\n",
      "  0.14429371 -0.35329318 -1.439096   -0.15766191 -0.2170419  -1.219912\n",
      " -0.06774877 -0.20084004 -1.2976722  -0.02143386 -0.22216982 -1.4150461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.04367381 -0.23387913 -1.2846212   0.1       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0113, -0.0754, -0.2593,  ...,  0.0232, -0.2594, -1.3177],\n",
      "        [ 0.0113, -0.0754, -0.2593,  ...,  0.0232, -0.2594, -1.3177],\n",
      "        [ 0.0113, -0.0754, -0.2593,  ...,  0.0232, -0.2594, -1.3177],\n",
      "        ...,\n",
      "        [-0.1827,  0.4003, -0.1189,  ..., -0.7540,  0.8876, -0.3530],\n",
      "        [-0.1782, -0.1433,  0.5851,  ..., -0.2519,  0.6497,  0.2487],\n",
      "        [-0.1782, -0.1433,  0.5851,  ..., -0.2519,  0.6497,  0.2487]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01134766 -0.07537445 -0.2593313   0.02651504 -0.21381357 -0.6843128\n",
      " -0.07481544 -0.39899153 -1.4344118  -0.21707289 -0.46254534 -1.7215364\n",
      " -0.3829146  -0.5655398  -2.1974661  -0.18897322 -0.68657744 -1.58628\n",
      " -0.00347005 -0.72017735 -1.40773    -0.04712865 -0.6494527  -1.46635\n",
      " -0.04338137 -0.78654593 -1.5794895  -0.15208428 -0.5839854  -1.5072718\n",
      " -0.07986848 -0.6323798  -1.4739394  -0.09448218 -0.6076336  -1.5640628\n",
      "  0.04370219 -0.6186808  -1.6045793  -0.07384814 -0.5008426  -1.344286\n",
      " -0.1816917  -0.27496666 -1.967402   -0.03620583 -0.41994482 -1.9721767\n",
      "  0.12184066 -0.38991696 -1.4684224  -0.16832897 -0.2664076  -1.2779268\n",
      " -0.10586603 -0.24196215 -1.3610656  -0.06179565 -0.24507122 -1.4762039\n",
      "  0.02321655 -0.25937486 -1.317698  ]\n",
      "data: [ 0.01134766 -0.07537445 -0.2593313   0.02651504 -0.21381357 -0.6843128\n",
      " -0.07481544 -0.3989915  -1.4344118  -0.21707289 -0.4625453  -1.7215364\n",
      " -0.38291463 -0.5655398  -2.1974661  -0.18897322 -0.68657744 -1.5862801\n",
      " -0.00347005 -0.7201774  -1.40773    -0.04712865 -0.6494527  -1.46635\n",
      " -0.04338137 -0.78654593 -1.5794895  -0.15208428 -0.5839854  -1.5072718\n",
      " -0.07986848 -0.6323798  -1.4739394  -0.09448218 -0.6076336  -1.5640628\n",
      "  0.04370218 -0.6186808  -1.6045793  -0.07384814 -0.5008426  -1.3442858\n",
      " -0.1816917  -0.27496666 -1.967402   -0.03620583 -0.41994485 -1.9721767\n",
      "  0.12184066 -0.38991696 -1.4684224  -0.16832897 -0.2664076  -1.2779268\n",
      " -0.10586603 -0.24196215 -1.3610656  -0.06179566 -0.24507122 -1.4762039\n",
      "  0.02321655 -0.25937486 -1.317698    0.11      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0344, -0.0348, -0.2263,  ...,  0.0372, -0.2311, -1.2530],\n",
      "        [ 0.0344, -0.0348, -0.2263,  ...,  0.0372, -0.2311, -1.2530],\n",
      "        [ 0.0344, -0.0348, -0.2263,  ...,  0.0372, -0.2311, -1.2530],\n",
      "        ...,\n",
      "        [-0.1223,  0.4303, -0.1253,  ..., -0.7191,  0.9394, -0.3850],\n",
      "        [-0.1356, -0.1958,  0.5561,  ..., -0.2149,  0.5731,  0.2425],\n",
      "        [-0.1356, -0.1958,  0.5561,  ..., -0.2149,  0.5731,  0.2425]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03437415 -0.03479657 -0.22628166  0.04960844 -0.15520956 -0.6065546\n",
      " -0.07587175 -0.3460755  -1.3758826  -0.22549526 -0.4109621  -1.6608918\n",
      " -0.38836545 -0.49562564 -2.1596098  -0.1547906  -0.6604092  -1.5301185\n",
      " -0.0105163  -0.7053205  -1.3820946  -0.05478525 -0.6269307  -1.4476941\n",
      " -0.05259833 -0.78504634 -1.5622967  -0.12156855 -0.57092917 -1.4496765\n",
      " -0.06752485 -0.6133783  -1.414712   -0.09465675 -0.5881108  -1.5077288\n",
      "  0.04983231 -0.59469235 -1.5296338  -0.05471838 -0.47862676 -1.2927644\n",
      " -0.1716802  -0.2541765  -1.956193   -0.02579252 -0.39647463 -1.9776475\n",
      "  0.13775826 -0.37429532 -1.3990868  -0.14542554 -0.25240523 -1.2246797\n",
      " -0.10182466 -0.22785148 -1.3130037  -0.07163507 -0.21472695 -1.4297678\n",
      "  0.03724033 -0.23107828 -1.2529676 ]\n",
      "data: [ 0.03437415 -0.03479657 -0.22628166  0.04960845 -0.15520956 -0.6065546\n",
      " -0.07587175 -0.3460755  -1.3758826  -0.22549526 -0.4109621  -1.6608918\n",
      " -0.38836545 -0.49562564 -2.1596098  -0.1547906  -0.6604092  -1.5301185\n",
      " -0.0105163  -0.70532054 -1.3820946  -0.05478525 -0.6269307  -1.4476941\n",
      " -0.05259833 -0.78504634 -1.5622967  -0.12156855 -0.57092917 -1.4496765\n",
      " -0.06752485 -0.6133783  -1.414712   -0.09465675 -0.5881108  -1.5077289\n",
      "  0.04983231 -0.59469235 -1.5296338  -0.05471839 -0.47862676 -1.2927644\n",
      " -0.1716802  -0.2541765  -1.956193   -0.02579252 -0.39647466 -1.9776475\n",
      "  0.13775826 -0.37429532 -1.3990867  -0.14542554 -0.25240523 -1.2246797\n",
      " -0.10182466 -0.22785148 -1.3130037  -0.07163507 -0.21472697 -1.429768\n",
      "  0.03724033 -0.23107828 -1.2529676   0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EC24898>\n",
      "tensor([[ 0.0127, -0.0180, -0.2336,  ...,  0.0262, -0.2084, -1.2714],\n",
      "        [ 0.0127, -0.0180, -0.2336,  ...,  0.0262, -0.2084, -1.2714],\n",
      "        [ 0.0127, -0.0180, -0.2336,  ...,  0.0262, -0.2084, -1.2714],\n",
      "        ...,\n",
      "        [-0.3143,  0.1772, -0.2588,  ..., -0.8449,  0.5940, -0.4149],\n",
      "        [-0.0983, -0.0848,  0.5543,  ..., -0.1930,  0.7003,  0.2367],\n",
      "        [-0.0983, -0.0848,  0.5543,  ..., -0.1930,  0.7003,  0.2367]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01267451 -0.01800735 -0.23358738  0.02904833 -0.15497193 -0.64437044\n",
      " -0.07718209 -0.3378286  -1.3956981  -0.22150081 -0.40328166 -1.6816084\n",
      " -0.390618   -0.50496733 -2.1618564  -0.18678346 -0.62779963 -1.5455997\n",
      " -0.00403567 -0.66115475 -1.3598571  -0.04778043 -0.59189045 -1.4187446\n",
      " -0.04959375 -0.7305236  -1.5316002  -0.15035486 -0.52763736 -1.4672077\n",
      " -0.07852821 -0.57845235 -1.4315956  -0.09832551 -0.5538317  -1.5228808\n",
      "  0.04193773 -0.56551874 -1.5618799  -0.07304594 -0.44646594 -1.302664\n",
      " -0.17938039 -0.22239518 -1.9242404  -0.03580207 -0.36743858 -1.9297311\n",
      "  0.12127987 -0.34194562 -1.4209313  -0.16399825 -0.21369019 -1.2379916\n",
      " -0.10452008 -0.19172028 -1.3152812  -0.06159423 -0.19264822 -1.4316597\n",
      "  0.02624342 -0.20838903 -1.2713952 ]\n",
      "data: [ 0.01267451 -0.01800735 -0.23358738  0.02904833 -0.15497193 -0.64437044\n",
      " -0.07718209 -0.3378286  -1.3956981  -0.22150081 -0.40328166 -1.6816084\n",
      " -0.39061797 -0.50496733 -2.1618564  -0.18678346 -0.62779963 -1.5455997\n",
      " -0.00403567 -0.6611548  -1.3598571  -0.04778043 -0.59189045 -1.4187446\n",
      " -0.04959374 -0.7305236  -1.5316002  -0.15035486 -0.52763736 -1.4672077\n",
      " -0.07852821 -0.57845235 -1.4315956  -0.09832551 -0.5538317  -1.5228809\n",
      "  0.04193773 -0.56551874 -1.5618799  -0.07304594 -0.44646594 -1.302664\n",
      " -0.17938037 -0.22239517 -1.9242405  -0.03580207 -0.36743858 -1.9297311\n",
      "  0.12127987 -0.34194562 -1.4209313  -0.16399825 -0.21369019 -1.2379916\n",
      " -0.10452008 -0.19172028 -1.3152813  -0.06159423 -0.19264822 -1.4316597\n",
      "  0.02624342 -0.20838903 -1.2713952   0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0474, -0.0921, -0.2239,  ...,  0.0570, -0.2804, -1.2840],\n",
      "        [ 0.0474, -0.0921, -0.2239,  ...,  0.0570, -0.2804, -1.2840],\n",
      "        [ 0.0474, -0.0921, -0.2239,  ...,  0.0570, -0.2804, -1.2840],\n",
      "        ...,\n",
      "        [-0.3341,  0.2522, -0.3685,  ..., -0.8526,  0.6720, -0.4759],\n",
      "        [-0.1266, -0.0778,  0.5951,  ..., -0.2138,  0.6986,  0.3055],\n",
      "        [-0.1266, -0.0778,  0.5951,  ..., -0.2138,  0.6986,  0.3055]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 4.74411510e-02 -9.21186134e-02 -2.23933548e-01  7.05920607e-02\n",
      " -2.30003670e-01 -6.28013134e-01 -2.95977294e-02 -4.10167724e-01\n",
      " -1.38327086e+00 -1.72041148e-01 -4.75905538e-01 -1.66852212e+00\n",
      " -3.36021990e-01 -5.77151597e-01 -2.15711713e+00 -1.45121306e-01\n",
      " -7.03375399e-01 -1.54198313e+00  3.57258394e-02 -7.36251056e-01\n",
      " -1.37499285e+00 -1.20001212e-02 -6.68136954e-01 -1.43334901e+00\n",
      " -1.38604417e-02 -8.04462016e-01 -1.54331470e+00 -1.09044544e-01\n",
      " -6.04214132e-01 -1.46626544e+00 -3.76305357e-02 -6.52565897e-01\n",
      " -1.43476605e+00 -6.21587560e-02 -6.27707243e-01 -1.52684844e+00\n",
      "  6.66260943e-02 -6.39778554e-01 -1.56497204e+00 -3.50837111e-02\n",
      " -5.21944880e-01 -1.30308974e+00 -1.40463054e-01 -2.96940446e-01\n",
      " -1.92940307e+00 -1.22114271e-03 -4.40402985e-01 -1.93557155e+00\n",
      "  1.43818974e-01 -4.14744854e-01 -1.43063498e+00 -1.25899166e-01\n",
      " -2.89406240e-01 -1.24271524e+00 -6.59100041e-02 -2.67630219e-01\n",
      " -1.32351661e+00 -2.50524804e-02 -2.67414421e-01 -1.44008172e+00\n",
      "  5.69590479e-02 -2.80420303e-01 -1.28401673e+00]\n",
      "data: [ 4.74411473e-02 -9.21186134e-02 -2.23933548e-01  7.05920607e-02\n",
      " -2.30003655e-01 -6.28013134e-01 -2.95977313e-02 -4.10167724e-01\n",
      " -1.38327086e+00 -1.72041148e-01 -4.75905538e-01 -1.66852224e+00\n",
      " -3.36021990e-01 -5.77151597e-01 -2.15711713e+00 -1.45121306e-01\n",
      " -7.03375399e-01 -1.54198313e+00  3.57258394e-02 -7.36251056e-01\n",
      " -1.37499285e+00 -1.20001212e-02 -6.68136954e-01 -1.43334901e+00\n",
      " -1.38604417e-02 -8.04462075e-01 -1.54331470e+00 -1.09044544e-01\n",
      " -6.04214132e-01 -1.46626544e+00 -3.76305357e-02 -6.52565897e-01\n",
      " -1.43476605e+00 -6.21587560e-02 -6.27707243e-01 -1.52684844e+00\n",
      "  6.66260943e-02 -6.39778554e-01 -1.56497204e+00 -3.50837111e-02\n",
      " -5.21944880e-01 -1.30308974e+00 -1.40463054e-01 -2.96940446e-01\n",
      " -1.92940307e+00 -1.22114271e-03 -4.40402985e-01 -1.93557155e+00\n",
      "  1.43818974e-01 -4.14744884e-01 -1.43063498e+00 -1.25899166e-01\n",
      " -2.89406240e-01 -1.24271524e+00 -6.59100041e-02 -2.67630219e-01\n",
      " -1.32351649e+00 -2.50524804e-02 -2.67414421e-01 -1.44008183e+00\n",
      "  5.69590479e-02 -2.80420303e-01 -1.28401673e+00  1.40000001e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0297, -0.0976, -0.2359,  ...,  0.0698, -0.2921, -1.2571],\n",
      "        [ 0.0297, -0.0976, -0.2359,  ...,  0.0698, -0.2921, -1.2571],\n",
      "        [ 0.0297, -0.0976, -0.2359,  ...,  0.0698, -0.2921, -1.2571],\n",
      "        ...,\n",
      "        [-0.1252,  0.4097, -0.0496,  ..., -0.6598,  0.9111, -0.3652],\n",
      "        [-0.1617, -0.0987,  0.5827,  ..., -0.2505,  0.6673,  0.2102],\n",
      "        [-0.1617, -0.0987,  0.5827,  ..., -0.2505,  0.6673,  0.2102]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0297207  -0.09762029 -0.23586306  0.0570922  -0.22198139 -0.6037137\n",
      " -0.04699404 -0.42785874 -1.4001379  -0.19326015 -0.49313694 -1.7002915\n",
      " -0.35325924 -0.6035516  -2.1865666  -0.16674861 -0.71661794 -1.5669737\n",
      "  0.04651171 -0.7646712  -1.3781251  -0.0108467  -0.7008033  -1.4302204\n",
      " -0.02477763 -0.85044706 -1.5534451  -0.11882289 -0.6202365  -1.4688288\n",
      " -0.04495604 -0.6788056  -1.445071   -0.05776574 -0.65094185 -1.5349308\n",
      "  0.06743369 -0.68523216 -1.569533   -0.02675117 -0.52134216 -1.296232\n",
      " -0.16395557 -0.29046062 -2.0033243   0.00585893 -0.4604377  -2.010923\n",
      "  0.16489708 -0.42381504 -1.4222687  -0.14107412 -0.2889001  -1.2240788\n",
      " -0.05711499 -0.26539287 -1.3079695  -0.01534708 -0.28062364 -1.4216216\n",
      "  0.06979873 -0.29207367 -1.2570596 ]\n",
      "data: [ 0.0297207  -0.09762029 -0.23586306  0.0570922  -0.22198139 -0.6037137\n",
      " -0.04699404 -0.42785874 -1.4001379  -0.19326015 -0.49313694 -1.7002914\n",
      " -0.35325924 -0.6035516  -2.1865666  -0.16674861 -0.71661794 -1.5669737\n",
      "  0.04651171 -0.76467115 -1.378125   -0.0108467  -0.7008033  -1.4302204\n",
      " -0.02477763 -0.85044706 -1.5534451  -0.11882289 -0.6202365  -1.4688287\n",
      " -0.04495604 -0.6788056  -1.445071   -0.05776574 -0.65094185 -1.5349308\n",
      "  0.06743369 -0.68523216 -1.5695329  -0.02675117 -0.52134216 -1.296232\n",
      " -0.16395557 -0.29046062 -2.0033243   0.00585893 -0.4604377  -2.010923\n",
      "  0.16489708 -0.42381504 -1.4222686  -0.14107412 -0.2889001  -1.2240788\n",
      " -0.05711499 -0.26539287 -1.3079696  -0.01534708 -0.28062364 -1.4216216\n",
      "  0.06979873 -0.29207367 -1.2570596   0.15      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0216, -0.1001, -0.1883,  ...,  0.0842, -0.3007, -1.1957],\n",
      "        [ 0.0216, -0.1001, -0.1883,  ...,  0.0842, -0.3007, -1.1957],\n",
      "        [ 0.0216, -0.1001, -0.1883,  ...,  0.0842, -0.3007, -1.1957],\n",
      "        ...,\n",
      "        [-0.1288,  0.3788, -0.1007,  ..., -0.7443,  0.8786, -0.3674],\n",
      "        [-0.1277, -0.0870,  0.5861,  ..., -0.2243,  0.6525,  0.2078],\n",
      "        [-0.1277, -0.0870,  0.5861,  ..., -0.2243,  0.6525,  0.2078]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0215845  -0.10008666 -0.18833153  0.04896341 -0.22168635 -0.53043175\n",
      " -0.0539468  -0.4308194  -1.3348722  -0.19996364 -0.49506107 -1.6385573\n",
      " -0.36238477 -0.61106026 -2.1214013  -0.17528462 -0.72015566 -1.5089295\n",
      "  0.04861136 -0.7696949  -1.3296267  -0.00847521 -0.70751166 -1.3776858\n",
      " -0.01438555 -0.8590732  -1.5011394  -0.12167604 -0.62317854 -1.4064732\n",
      " -0.04092657 -0.6851499  -1.3863484  -0.04451375 -0.65747577 -1.4778123\n",
      "  0.08517818 -0.6977914  -1.5163202  -0.02276111 -0.52422726 -1.2312124\n",
      " -0.1643703  -0.29187414 -1.9605954   0.01849714 -0.4695109  -1.9667072\n",
      "  0.18507773 -0.43005502 -1.3660538  -0.14325108 -0.29058975 -1.1589482\n",
      " -0.04903577 -0.26903903 -1.2440099  -0.0028225  -0.28975776 -1.3589333\n",
      "  0.08424785 -0.3007236  -1.1957289 ]\n",
      "data: [ 0.0215845  -0.10008666 -0.18833153  0.04896341 -0.22168635 -0.53043175\n",
      " -0.0539468  -0.4308194  -1.3348722  -0.19996364 -0.49506107 -1.6385573\n",
      " -0.36238477 -0.61106026 -2.1214013  -0.17528461 -0.72015566 -1.5089295\n",
      "  0.04861136 -0.7696949  -1.3296266  -0.00847521 -0.70751166 -1.3776859\n",
      " -0.01438555 -0.8590733  -1.5011394  -0.12167604 -0.62317854 -1.406473\n",
      " -0.04092656 -0.6851499  -1.3863484  -0.04451375 -0.6574757  -1.4778123\n",
      "  0.08517818 -0.69779134 -1.5163202  -0.02276111 -0.52422726 -1.2312124\n",
      " -0.16437031 -0.29187414 -1.9605954   0.01849714 -0.4695109  -1.9667071\n",
      "  0.18507773 -0.43005502 -1.3660538  -0.14325108 -0.29058975 -1.1589482\n",
      " -0.04903577 -0.26903903 -1.2440099  -0.0028225  -0.28975776 -1.3589332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.08424785 -0.3007236  -1.1957289   0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 8.1335e-05, -6.7738e-02, -1.9696e-01,  ...,  3.5129e-02,\n",
      "         -2.6927e-01, -1.1773e+00],\n",
      "        [ 8.1335e-05, -6.7738e-02, -1.9696e-01,  ...,  3.5129e-02,\n",
      "         -2.6927e-01, -1.1773e+00],\n",
      "        [ 8.1335e-05, -6.7738e-02, -1.9696e-01,  ...,  3.5129e-02,\n",
      "         -2.6927e-01, -1.1773e+00],\n",
      "        ...,\n",
      "        [-1.5383e-01,  3.7015e-01, -1.0372e-01,  ..., -7.0066e-01,\n",
      "          8.8449e-01, -4.0268e-01],\n",
      "        [-9.2620e-02, -6.4269e-02,  5.9221e-01,  ..., -1.8017e-01,\n",
      "          6.9246e-01,  2.1699e-01],\n",
      "        [-9.2620e-02, -6.4269e-02,  5.9221e-01,  ..., -1.8017e-01,\n",
      "          6.9246e-01,  2.1699e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 8.1335194e-05 -6.7737833e-02 -1.9696428e-01  3.4546230e-02\n",
      " -1.6252276e-01 -4.9152231e-01 -1.2451114e-01 -3.9689609e-01\n",
      " -1.3596554e+00 -2.7959439e-01 -4.6693498e-01 -1.6428275e+00\n",
      " -4.2337924e-01 -5.4831302e-01 -2.1617756e+00 -1.8274829e-01\n",
      " -7.1127319e-01 -1.5268972e+00 -3.6571428e-02 -7.8567874e-01\n",
      " -1.3842943e+00 -8.7313592e-02 -7.0473957e-01 -1.4398811e+00\n",
      " -9.9361956e-02 -8.8627887e-01 -1.5654447e+00 -1.4051728e-01\n",
      " -6.3329649e-01 -1.4250617e+00 -9.6518978e-02 -6.8394816e-01\n",
      " -1.3927937e+00 -1.1512319e-01 -6.4903831e-01 -1.4719176e+00\n",
      "  2.9433981e-02 -6.7866278e-01 -1.4795506e+00 -6.6196360e-02\n",
      " -5.2026486e-01 -1.2657490e+00 -2.2788039e-01 -2.7985018e-01\n",
      " -2.0585792e+00 -3.8418941e-02 -4.5492402e-01 -2.0925510e+00\n",
      "  1.3960251e-01 -4.1832182e-01 -1.3481619e+00 -1.8222710e-01\n",
      " -2.9703933e-01 -1.1819217e+00 -1.2509015e-01 -2.6392591e-01\n",
      " -1.2751069e+00 -9.3034878e-02 -2.5539368e-01 -1.3880341e+00\n",
      "  3.5128601e-02 -2.6926857e-01 -1.1773305e+00]\n",
      "data: [ 8.1335194e-05 -6.7737833e-02 -1.9696428e-01  3.4546230e-02\n",
      " -1.6252275e-01 -4.9152228e-01 -1.2451114e-01 -3.9689609e-01\n",
      " -1.3596555e+00 -2.7959439e-01 -4.6693498e-01 -1.6428275e+00\n",
      " -4.2337924e-01 -5.4831302e-01 -2.1617756e+00 -1.8274827e-01\n",
      " -7.1127319e-01 -1.5268971e+00 -3.6571428e-02 -7.8567868e-01\n",
      " -1.3842943e+00 -8.7313592e-02 -7.0473951e-01 -1.4398811e+00\n",
      " -9.9361956e-02 -8.8627887e-01 -1.5654446e+00 -1.4051728e-01\n",
      " -6.3329649e-01 -1.4250617e+00 -9.6518971e-02 -6.8394816e-01\n",
      " -1.3927935e+00 -1.1512318e-01 -6.4903831e-01 -1.4719176e+00\n",
      "  2.9433981e-02 -6.7866278e-01 -1.4795506e+00 -6.6196360e-02\n",
      " -5.2026486e-01 -1.2657490e+00 -2.2788039e-01 -2.7985018e-01\n",
      " -2.0585792e+00 -3.8418941e-02 -4.5492402e-01 -2.0925510e+00\n",
      "  1.3960251e-01 -4.1832179e-01 -1.3481619e+00 -1.8222709e-01\n",
      " -2.9703933e-01 -1.1819217e+00 -1.2509015e-01 -2.6392591e-01\n",
      " -1.2751069e+00 -9.3034878e-02 -2.5539368e-01 -1.3880341e+00\n",
      "  3.5128601e-02 -2.6926857e-01 -1.1773305e+00  1.7000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE3F7CB278>\n",
      "tensor([[-0.0168,  0.0112, -0.1703,  ...,  0.0217, -0.1734, -1.1715],\n",
      "        [-0.0168,  0.0112, -0.1703,  ...,  0.0217, -0.1734, -1.1715],\n",
      "        [-0.0168,  0.0112, -0.1703,  ...,  0.0217, -0.1734, -1.1715],\n",
      "        ...,\n",
      "        [-0.2923,  0.1575, -0.1459,  ..., -0.8181,  0.6873, -0.4892],\n",
      "        [-0.0972, -0.0851,  0.5742,  ..., -0.2408,  0.6306,  0.2503],\n",
      "        [-0.0972, -0.0851,  0.5742,  ..., -0.2408,  0.6306,  0.2503]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01681967  0.01115839 -0.17025842  0.00445499 -0.11176124 -0.5173107\n",
      " -0.10952898 -0.31889474 -1.3193583  -0.25904256 -0.37960804 -1.6192629\n",
      " -0.42931032 -0.48732597 -2.0998785  -0.22210567 -0.61142653 -1.4800096\n",
      " -0.00872025 -0.65486574 -1.287113   -0.05573989 -0.58831483 -1.3376153\n",
      " -0.05506863 -0.73667645 -1.464087   -0.17596547 -0.5104003  -1.3813734\n",
      " -0.09624939 -0.5666808  -1.3554523  -0.09231485 -0.53456104 -1.4488399\n",
      "  0.05864497 -0.5667969  -1.4901862  -0.0820101  -0.4112566  -1.2091341\n",
      " -0.22312267 -0.17661725 -1.9315939  -0.03583352 -0.34580207 -1.9411175\n",
      "  0.1470552  -0.30553186 -1.3400736  -0.2014831  -0.17416926 -1.1348243\n",
      " -0.11977589 -0.14799975 -1.2181592  -0.0741652  -0.16042005 -1.3373764\n",
      "  0.02167965 -0.17337772 -1.1715417 ]\n",
      "data: [-0.01681967  0.01115839 -0.17025843  0.00445499 -0.11176124 -0.5173107\n",
      " -0.10952898 -0.31889474 -1.3193583  -0.25904256 -0.37960804 -1.619263\n",
      " -0.4293103  -0.48732597 -2.0998785  -0.22210568 -0.61142653 -1.4800096\n",
      " -0.00872025 -0.65486574 -1.2871128  -0.05573989 -0.58831483 -1.3376153\n",
      " -0.05506863 -0.73667645 -1.464087   -0.17596549 -0.5104003  -1.3813734\n",
      " -0.09624939 -0.5666808  -1.3554523  -0.09231485 -0.53456104 -1.4488399\n",
      "  0.05864497 -0.5667969  -1.4901862  -0.0820101  -0.4112566  -1.2091341\n",
      " -0.22312267 -0.17661723 -1.9315939  -0.03583352 -0.34580207 -1.9411175\n",
      "  0.1470552  -0.30553186 -1.3400736  -0.2014831  -0.17416926 -1.1348243\n",
      " -0.11977588 -0.14799975 -1.2181592  -0.0741652  -0.16042003 -1.3373764\n",
      "  0.02167965 -0.17337772 -1.1715417   0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0136, -0.1174, -0.2057,  ...,  0.0388, -0.2795, -1.3322],\n",
      "        [ 0.0136, -0.1174, -0.2057,  ...,  0.0388, -0.2795, -1.3322],\n",
      "        [ 0.0136, -0.1174, -0.2057,  ...,  0.0388, -0.2795, -1.3322],\n",
      "        ...,\n",
      "        [-0.2979,  0.3828, -0.2395,  ..., -0.7983,  0.7915, -0.3285],\n",
      "        [-0.1983, -0.0678,  0.5481,  ..., -0.2842,  0.6936,  0.2883],\n",
      "        [-0.1983, -0.0678,  0.5481,  ..., -0.2842,  0.6936,  0.2883]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.3561707e-02 -1.1742346e-01 -2.0567784e-01  2.6642416e-02\n",
      " -2.8898138e-01 -6.9678855e-01 -1.8098138e-02 -4.3846202e-01\n",
      " -1.3681977e+00 -1.5690538e-01 -4.9325585e-01 -1.6721621e+00\n",
      " -3.4094256e-01 -6.3314950e-01 -2.1234703e+00 -2.1246122e-01\n",
      " -6.9930208e-01 -1.5244801e+00  6.0292110e-02 -7.0029509e-01\n",
      " -1.2865846e+00  7.6336116e-03 -6.4374554e-01 -1.3363800e+00\n",
      "  4.3933466e-03 -7.3922992e-01 -1.4463637e+00 -1.6589706e-01\n",
      " -5.7903051e-01 -1.4544258e+00 -5.2489981e-02 -6.3423944e-01\n",
      " -1.4359424e+00 -5.5505984e-02 -6.0604107e-01 -1.5377336e+00\n",
      "  6.1449423e-02 -6.2548912e-01 -1.6085143e+00 -6.0075261e-02\n",
      " -5.1199508e-01 -1.2798090e+00 -1.3694584e-01 -2.8560489e-01\n",
      " -1.7969985e+00 -6.9430247e-03 -4.2676064e-01 -1.7703495e+00\n",
      "  1.2961926e-01 -3.9052293e-01 -1.4720786e+00 -1.5689576e-01\n",
      " -2.6574171e-01 -1.2323418e+00 -5.7675958e-02 -2.4701008e-01\n",
      " -1.3126297e+00  7.8208745e-04 -2.7637148e-01 -1.4333720e+00\n",
      "  3.8783483e-02 -2.7953863e-01 -1.3322442e+00]\n",
      "data: [ 1.3561707e-02 -1.1742346e-01 -2.0567784e-01  2.6642416e-02\n",
      " -2.8898138e-01 -6.9678855e-01 -1.8098138e-02 -4.3846202e-01\n",
      " -1.3681977e+00 -1.5690538e-01 -4.9325585e-01 -1.6721621e+00\n",
      " -3.4094256e-01 -6.3314950e-01 -2.1234703e+00 -2.1246122e-01\n",
      " -6.9930208e-01 -1.5244801e+00  6.0292110e-02 -7.0029509e-01\n",
      " -1.2865846e+00  7.6336116e-03 -6.4374560e-01 -1.3363800e+00\n",
      "  4.3933466e-03 -7.3922992e-01 -1.4463637e+00 -1.6589707e-01\n",
      " -5.7903051e-01 -1.4544258e+00 -5.2489981e-02 -6.3423944e-01\n",
      " -1.4359424e+00 -5.5505980e-02 -6.0604107e-01 -1.5377336e+00\n",
      "  6.1449423e-02 -6.2548912e-01 -1.6085143e+00 -6.0075261e-02\n",
      " -5.1199508e-01 -1.2798090e+00 -1.3694584e-01 -2.8560489e-01\n",
      " -1.7969985e+00 -6.9430242e-03 -4.2676064e-01 -1.7703494e+00\n",
      "  1.2961926e-01 -3.9052293e-01 -1.4720786e+00 -1.5689576e-01\n",
      " -2.6574171e-01 -1.2323418e+00 -5.7675958e-02 -2.4701008e-01\n",
      " -1.3126297e+00  7.8208745e-04 -2.7637148e-01 -1.4333720e+00\n",
      "  3.8783483e-02 -2.7953863e-01 -1.3322442e+00  1.9000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BB38>\n",
      "tensor([[ 0.0437, -0.1450, -0.2726,  ...,  0.0666, -0.3192, -1.3373],\n",
      "        [ 0.0437, -0.1450, -0.2726,  ...,  0.0666, -0.3192, -1.3373],\n",
      "        [ 0.0437, -0.1450, -0.2726,  ...,  0.0666, -0.3192, -1.3373],\n",
      "        ...,\n",
      "        [-0.1344,  0.4945, -0.1323,  ..., -0.7032,  1.0155, -0.4696],\n",
      "        [-0.1980, -0.0673,  0.6327,  ..., -0.2956,  0.6857,  0.2677],\n",
      "        [-0.1980, -0.0673,  0.6327,  ..., -0.2956,  0.6857,  0.2677]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 4.36643027e-02 -1.44957423e-01 -2.72578239e-01  7.53858238e-02\n",
      " -2.74201632e-01 -6.57149553e-01 -1.21112913e-02 -4.76994395e-01\n",
      " -1.45236778e+00 -1.57624453e-01 -5.37874281e-01 -1.75910068e+00\n",
      " -3.15044194e-01 -6.51503682e-01 -2.25321198e+00 -1.61823273e-01\n",
      " -7.54060209e-01 -1.64091706e+00  7.74040744e-02 -7.96004057e-01\n",
      " -1.44226766e+00  1.81699619e-02 -7.38791049e-01 -1.48773956e+00\n",
      " -5.36367297e-05 -8.78470659e-01 -1.61233616e+00 -1.12821855e-01\n",
      " -6.51431322e-01 -1.54069018e+00 -2.90412754e-02 -7.12673426e-01\n",
      " -1.52011299e+00 -3.70070115e-02 -6.82592928e-01 -1.61358929e+00\n",
      "  7.85506293e-02 -7.26448476e-01 -1.65829873e+00 -1.46626234e-02\n",
      " -5.48633933e-01 -1.36706257e+00 -1.55078143e-01 -3.15955371e-01\n",
      " -2.06185699e+00  1.62071437e-02 -4.90076959e-01 -2.06489444e+00\n",
      "  1.66497439e-01 -4.47226405e-01 -1.50936532e+00 -1.37910396e-01\n",
      " -3.11569750e-01 -1.29349303e+00 -4.28937003e-02 -2.85179794e-01\n",
      " -1.36820841e+00  5.20981848e-04 -3.11153889e-01 -1.48320985e+00\n",
      "  6.65895492e-02 -3.19170535e-01 -1.33732152e+00]\n",
      "data: [ 4.36643027e-02 -1.44957423e-01 -2.72578239e-01  7.53858238e-02\n",
      " -2.74201632e-01 -6.57149553e-01 -1.21112922e-02 -4.76994395e-01\n",
      " -1.45236790e+00 -1.57624453e-01 -5.37874281e-01 -1.75910068e+00\n",
      " -3.15044194e-01 -6.51503682e-01 -2.25321198e+00 -1.61823273e-01\n",
      " -7.54060209e-01 -1.64091706e+00  7.74040744e-02 -7.96004057e-01\n",
      " -1.44226766e+00  1.81699619e-02 -7.38791049e-01 -1.48773956e+00\n",
      " -5.36367297e-05 -8.78470659e-01 -1.61233616e+00 -1.12821855e-01\n",
      " -6.51431322e-01 -1.54069018e+00 -2.90412754e-02 -7.12673426e-01\n",
      " -1.52011287e+00 -3.70070115e-02 -6.82592928e-01 -1.61358929e+00\n",
      "  7.85506293e-02 -7.26448417e-01 -1.65829885e+00 -1.46626234e-02\n",
      " -5.48633933e-01 -1.36706257e+00 -1.55078143e-01 -3.15955371e-01\n",
      " -2.06185699e+00  1.62071437e-02 -4.90076929e-01 -2.06489444e+00\n",
      "  1.66497439e-01 -4.47226405e-01 -1.50936544e+00 -1.37910396e-01\n",
      " -3.11569750e-01 -1.29349303e+00 -4.28937003e-02 -2.85179794e-01\n",
      " -1.36820841e+00  5.20981848e-04 -3.11153889e-01 -1.48320985e+00\n",
      "  6.65895492e-02 -3.19170535e-01 -1.33732152e+00  2.00000003e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[-0.0053, -0.1118, -0.2065,  ...,  0.0755, -0.3081, -1.2545],\n",
      "        [-0.0053, -0.1118, -0.2065,  ...,  0.0755, -0.3081, -1.2545],\n",
      "        [-0.0053, -0.1118, -0.2065,  ...,  0.0755, -0.3081, -1.2545],\n",
      "        ...,\n",
      "        [-0.1089,  0.4738, -0.1385,  ..., -0.7536,  0.9913, -0.4219],\n",
      "        [-0.1278, -0.0530,  0.5905,  ..., -0.2064,  0.6372,  0.2258],\n",
      "        [-0.1278, -0.0530,  0.5905,  ..., -0.2064,  0.6372,  0.2258]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.00532214 -0.11175766 -0.20645382  0.01566501 -0.2593744  -0.5875651\n",
      " -0.03050163 -0.43882245 -1.3411478  -0.17470899 -0.495224   -1.6698234\n",
      " -0.3618263  -0.646929   -2.1316018  -0.22440624 -0.7022873  -1.5428935\n",
      "  0.0828606  -0.72701573 -1.3286064   0.01816772 -0.6818768  -1.3683171\n",
      "  0.02372622 -0.8009882  -1.4895223  -0.15822308 -0.5853714  -1.4368482\n",
      " -0.03933805 -0.6596645  -1.4282575  -0.02643575 -0.6414192  -1.5375354\n",
      "  0.09024157 -0.69016683 -1.6055883  -0.03380185 -0.5042144  -1.2394601\n",
      " -0.15341626 -0.27692136 -1.8912263   0.01994222 -0.45828345 -1.868083\n",
      "  0.1795927  -0.41871783 -1.4277571  -0.16190769 -0.25705314 -1.1791123\n",
      " -0.02933681 -0.24896744 -1.25093     0.03061229 -0.30159605 -1.3667786\n",
      "  0.0755013  -0.30805564 -1.2545106 ]\n",
      "data: [-4.42 -4.54  4.07 -4.32 -4.29  4.15 -4.27 -3.87  4.13 -4.34 -3.59  4.56\n",
      " -4.45 -3.43  5.1  -4.6  -3.7   4.58 -4.65 -3.45  5.03 -4.64 -3.29  5.34\n",
      "  0.    0.    0.   -4.6  -3.82  4.5  -4.61 -3.48  4.7  -4.58 -3.36  5.11\n",
      "  0.    0.    0.   -4.59 -3.94  4.41 -4.6  -3.66  4.58 -4.54 -3.47  4.92\n",
      "  0.    0.    0.   -4.73 -4.14  4.86 -4.52 -3.78  4.44 -4.51 -3.67  4.64\n",
      " -4.47 -3.55  4.76  0.  ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[-0.2694,  0.2166,  0.3244,  ..., -0.5547,  0.1386, -0.4497],\n",
      "        [-0.2694,  0.2166,  0.3244,  ..., -0.5547,  0.1386, -0.4497],\n",
      "        [-0.2694,  0.2166,  0.3244,  ..., -0.5547,  0.1386, -0.4497],\n",
      "        ...,\n",
      "        [ 1.2722, -1.3827,  0.3074,  ...,  0.9557, -1.8180,  1.5290],\n",
      "        [ 0.5244, -0.2045,  0.0365,  ...,  0.5266, -0.6894,  2.2485],\n",
      "        [ 0.5244, -0.2045,  0.0365,  ...,  0.5266, -0.6894,  2.2485]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.26942667  0.21662493  0.32443678 -0.39767104  0.13034719 -0.03699443\n",
      " -0.4205271   0.07727423 -0.4300734  -0.46135038  0.01156199 -0.47127554\n",
      " -0.48828515 -0.02628796 -0.62915516 -0.500653    0.02128519 -0.724648\n",
      " -0.2856469   0.03902201 -0.09990224 -0.39478886 -0.07275261 -0.09671256\n",
      " -0.53685176 -0.00522082 -0.23397473 -0.5204128   0.09827949 -0.7301388\n",
      " -0.5559708   0.07399456 -0.78255486 -0.59376574  0.06912723 -0.7804668\n",
      " -0.6252326  -0.0372733  -0.75874555 -0.49387112  0.14833197 -0.677331\n",
      " -0.62044257  0.17528091 -0.7878821  -0.62938386  0.13659307 -0.7950733\n",
      " -0.58041507  0.07751553 -0.6173223  -0.5459279   0.2750555  -0.51408875\n",
      " -0.49184278  0.22938535 -0.52580476 -0.55749935  0.20015985 -0.5236653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.5546796   0.13858978 -0.4497014 ]\n",
      "init: [-0.26942667  0.21662493  0.32443678 -0.39767104  0.13034719 -0.03699443\n",
      " -0.4205271   0.07727423 -0.4300734  -0.46135038  0.01156199 -0.47127554\n",
      " -0.48828515 -0.02628796 -0.62915516 -0.500653    0.02128519 -0.724648\n",
      " -0.2856469   0.03902201 -0.09990224 -0.39478886 -0.07275261 -0.09671256\n",
      " -0.53685176 -0.00522082 -0.23397473 -0.5204128   0.09827949 -0.7301388\n",
      " -0.5559708   0.07399456 -0.78255486 -0.59376574  0.06912723 -0.7804668\n",
      " -0.6252326  -0.0372733  -0.75874555 -0.49387112  0.14833197 -0.677331\n",
      " -0.62044257  0.17528091 -0.7878821  -0.62938386  0.13659307 -0.7950733\n",
      " -0.58041507  0.07751553 -0.6173223  -0.5459279   0.2750555  -0.51408875\n",
      " -0.49184278  0.22938535 -0.52580476 -0.55749935  0.20015985 -0.5236653\n",
      " -0.5546796   0.13858978 -0.4497014 ]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [-0.26942667  0.21662493  0.32443678 -0.39767104  0.13034719 -0.03699443\n",
      " -0.4205271   0.07727423 -0.43007338 -0.46135035  0.01156199 -0.4712755\n",
      " -0.48828515 -0.02628796 -0.62915516 -0.500653    0.02128519 -0.724648\n",
      " -0.2856469   0.03902201 -0.09990224 -0.39478886 -0.07275261 -0.09671256\n",
      " -0.53685176 -0.00522082 -0.23397473 -0.5204128   0.0982795  -0.7301388\n",
      " -0.5559708   0.07399456 -0.78255486 -0.59376574  0.06912723 -0.7804668\n",
      " -0.6252326  -0.0372733  -0.75874555 -0.49387112  0.14833197 -0.6773309\n",
      " -0.62044257  0.17528091 -0.7878821  -0.62938386  0.13659307 -0.7950733\n",
      " -0.58041507  0.07751553 -0.6173223  -0.5459279   0.2750555  -0.51408875\n",
      " -0.49184278  0.22938533 -0.52580476 -0.55749935  0.20015985 -0.5236653\n",
      " -0.5546796   0.13858978 -0.4497014   0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[ 0.0388, -0.0258, -0.1067,  ..., -0.0427, -0.1669, -1.1981],\n",
      "        [ 0.0388, -0.0258, -0.1067,  ..., -0.0427, -0.1669, -1.1981],\n",
      "        [ 0.0388, -0.0258, -0.1067,  ..., -0.0427, -0.1669, -1.1981],\n",
      "        ...,\n",
      "        [ 0.8512, -0.3419,  0.3190,  ...,  0.3274,  0.6532, -0.2666],\n",
      "        [ 0.1883,  0.0146, -0.1447,  ..., -0.8520,  0.6531, -0.3563],\n",
      "        [ 0.1883,  0.0146, -0.1447,  ..., -0.8520,  0.6531, -0.3563]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 3.8824461e-02 -2.5808427e-02 -1.0671432e-01  1.8171966e-04\n",
      " -1.9991353e-01 -5.9560251e-01 -1.9765943e-01 -3.2255009e-01\n",
      " -1.1156625e+00 -3.4184253e-01 -4.1168073e-01 -1.2795627e+00\n",
      " -5.8443367e-01 -4.1784063e-01 -1.6384592e+00 -1.9513750e-01\n",
      " -5.7920796e-01 -1.2057110e+00 -3.0993944e-01 -5.8637160e-01\n",
      " -1.2434381e+00 -2.2450718e-01 -4.8798707e-01 -1.2967086e+00\n",
      " -1.3494374e-01 -5.9537381e-01 -1.3019736e+00 -1.9198170e-01\n",
      " -4.6623412e-01 -1.2232418e+00 -1.8070316e-01 -4.9183282e-01\n",
      " -1.1256690e+00 -1.9014725e-01 -4.8588064e-01 -1.2176884e+00\n",
      "  7.6784395e-02 -3.6639556e-01 -1.3445718e+00 -2.1587288e-01\n",
      " -4.7988367e-01 -1.1367997e+00 -1.8835160e-01 -3.1887022e-01\n",
      " -1.3682708e+00 -1.2673306e-01 -3.2770145e-01 -1.3805751e+00\n",
      "  3.2093212e-02 -3.0819982e-01 -1.2598028e+00 -1.6550156e-01\n",
      " -2.5186574e-01 -1.1169246e+00 -2.8582901e-01 -2.0516777e-01\n",
      " -1.1804845e+00 -1.6176769e-01 -1.3502936e-01 -1.3060205e+00\n",
      " -4.2720228e-02 -1.6689759e-01 -1.1980647e+00]\n",
      "data: [ 3.8824461e-02 -2.5808427e-02 -1.0671432e-01  1.8171966e-04\n",
      " -1.9991355e-01 -5.9560251e-01 -1.9765943e-01 -3.2255009e-01\n",
      " -1.1156625e+00 -3.4184253e-01 -4.1168073e-01 -1.2795627e+00\n",
      " -5.8443367e-01 -4.1784060e-01 -1.6384592e+00 -1.9513750e-01\n",
      " -5.7920796e-01 -1.2057110e+00 -3.0993944e-01 -5.8637160e-01\n",
      " -1.2434381e+00 -2.2450718e-01 -4.8798707e-01 -1.2967086e+00\n",
      " -1.3494374e-01 -5.9537381e-01 -1.3019736e+00 -1.9198170e-01\n",
      " -4.6623412e-01 -1.2232418e+00 -1.8070316e-01 -4.9183282e-01\n",
      " -1.1256690e+00 -1.9014725e-01 -4.8588067e-01 -1.2176884e+00\n",
      "  7.6784395e-02 -3.6639556e-01 -1.3445718e+00 -2.1587288e-01\n",
      " -4.7988364e-01 -1.1367997e+00 -1.8835159e-01 -3.1887022e-01\n",
      " -1.3682708e+00 -1.2673306e-01 -3.2770145e-01 -1.3805751e+00\n",
      "  3.2093212e-02 -3.0819982e-01 -1.2598028e+00 -1.6550155e-01\n",
      " -2.5186574e-01 -1.1169246e+00 -2.8582901e-01 -2.0516777e-01\n",
      " -1.1804845e+00 -1.6176769e-01 -1.3502936e-01 -1.3060205e+00\n",
      " -4.2720228e-02 -1.6689759e-01 -1.1980647e+00  2.0000000e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B9B0>\n",
      "tensor([[ 0.1782,  0.0294, -0.2892,  ...,  0.2739, -0.1419, -1.3617],\n",
      "        [ 0.1782,  0.0294, -0.2892,  ...,  0.2739, -0.1419, -1.3617],\n",
      "        [ 0.1782,  0.0294, -0.2892,  ...,  0.2739, -0.1419, -1.3617],\n",
      "        ...,\n",
      "        [-0.1859,  0.4669,  0.1215,  ..., -0.6852,  0.9991, -0.1963],\n",
      "        [-0.2428,  0.1077,  0.5531,  ..., -0.5720,  0.7918,  0.3498],\n",
      "        [-0.2428,  0.1077,  0.5531,  ..., -0.5720,  0.7918,  0.3498]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.17820437  0.02937775 -0.2892322   0.22050864 -0.11240822 -0.68987846\n",
      "  0.15938696 -0.27118254 -1.394234    0.01469222 -0.31525648 -1.6913378\n",
      " -0.12870027 -0.45081115 -2.1740136  -0.03329523 -0.54732007 -1.5982776\n",
      "  0.26789576 -0.5561495  -1.3752625   0.21752125 -0.49287802 -1.4127405\n",
      "  0.21613646 -0.5949397  -1.5309424   0.02420819 -0.4425922  -1.5217319\n",
      "  0.15391016 -0.5021913  -1.5130494   0.1731528  -0.4580328  -1.5944312\n",
      "  0.29780403 -0.51041627 -1.6556499   0.15296122 -0.36190933 -1.3433905\n",
      "  0.05475079 -0.10864358 -1.9253807   0.22764277 -0.28829455 -1.902039\n",
      "  0.38425553 -0.23332031 -1.5312467   0.02931738 -0.12166227 -1.2870791\n",
      "  0.16146569 -0.08732855 -1.3546278   0.22393782 -0.13123728 -1.4784079\n",
      "  0.2738503  -0.14192814 -1.3616767 ]\n",
      "data: [ 0.17820436  0.02937775 -0.2892322   0.22050864 -0.11240822 -0.68987846\n",
      "  0.15938696 -0.27118254 -1.3942341   0.01469222 -0.31525648 -1.691338\n",
      " -0.12870027 -0.45081115 -2.1740136  -0.03329523 -0.54732007 -1.5982776\n",
      "  0.26789576 -0.5561495  -1.3752625   0.21752125 -0.49287805 -1.4127405\n",
      "  0.21613646 -0.5949397  -1.5309424   0.02420819 -0.4425922  -1.5217319\n",
      "  0.15391016 -0.5021913  -1.5130494   0.1731528  -0.4580328  -1.5944312\n",
      "  0.29780403 -0.51041627 -1.6556499   0.15296122 -0.36190933 -1.3433905\n",
      "  0.05475079 -0.10864358 -1.9253807   0.22764279 -0.28829455 -1.902039\n",
      "  0.38425553 -0.23332031 -1.5312467   0.02931738 -0.12166227 -1.2870792\n",
      "  0.16146569 -0.08732855 -1.3546278   0.22393781 -0.13123728 -1.4784079\n",
      "  0.2738503  -0.14192814 -1.3616767   0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 9.5032e-03, -1.8255e-01, -2.8268e-01,  ...,  6.2809e-02,\n",
      "         -3.6057e-01, -1.3810e+00],\n",
      "        [ 9.5032e-03, -1.8255e-01, -2.8268e-01,  ...,  6.2809e-02,\n",
      "         -3.6057e-01, -1.3810e+00],\n",
      "        [ 9.5032e-03, -1.8255e-01, -2.8268e-01,  ...,  6.2809e-02,\n",
      "         -3.6057e-01, -1.3810e+00],\n",
      "        ...,\n",
      "        [-1.2893e-03,  3.3753e-01,  1.9201e-01,  ..., -7.9782e-01,\n",
      "          8.1780e-01, -1.0525e-01],\n",
      "        [-1.4467e-01,  1.9947e-01,  4.7333e-01,  ..., -2.0056e-01,\n",
      "          1.0264e+00,  1.6449e-02],\n",
      "        [-1.4467e-01,  1.9947e-01,  4.7333e-01,  ..., -2.0056e-01,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          1.0264e+00,  1.6449e-02]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00950315 -0.18255346 -0.2826765   0.03997717 -0.3385645  -0.7321834\n",
      "  0.01423992 -0.49760598 -1.4823761  -0.11360616 -0.5530639  -1.801172\n",
      " -0.26737422 -0.70005035 -2.2990496  -0.2003541  -0.74040186 -1.6851459\n",
      "  0.1216912  -0.73649824 -1.416425    0.05251863 -0.69150877 -1.4631672\n",
      "  0.0162043  -0.78570366 -1.5911584  -0.1550172  -0.62718487 -1.5934253\n",
      " -0.02475128 -0.6893815  -1.5880003  -0.04069036 -0.65203774 -1.6806753\n",
      "  0.04792883 -0.7019688  -1.7465107  -0.02824886 -0.5497062  -1.406879\n",
      " -0.1296199  -0.31862554 -1.9815521   0.01343117 -0.48581263 -1.9520066\n",
      "  0.13359362 -0.44462332 -1.5755141  -0.14397278 -0.31845653 -1.3379431\n",
      " -0.00646252 -0.3042044  -1.378166    0.04149991 -0.35341018 -1.4919088\n",
      "  0.06280948 -0.360573   -1.3810132 ]\n",
      "data: [ 0.00950315 -0.18255347 -0.2826765   0.03997717 -0.3385645  -0.7321834\n",
      "  0.01423992 -0.49760598 -1.4823761  -0.11360617 -0.5530639  -1.801172\n",
      " -0.26737422 -0.70005035 -2.2990496  -0.2003541  -0.74040186 -1.6851459\n",
      "  0.1216912  -0.73649824 -1.416425    0.05251863 -0.69150877 -1.4631671\n",
      "  0.0162043  -0.78570366 -1.5911584  -0.1550172  -0.62718487 -1.5934253\n",
      " -0.02475128 -0.6893815  -1.5880003  -0.04069036 -0.65203774 -1.6806751\n",
      "  0.04792883 -0.7019688  -1.7465107  -0.02824886 -0.5497062  -1.406879\n",
      " -0.1296199  -0.31862554 -1.9815521   0.01343117 -0.48581263 -1.9520066\n",
      "  0.13359362 -0.44462335 -1.5755141  -0.14397278 -0.31845653 -1.3379431\n",
      " -0.00646252 -0.3042044  -1.3781658   0.04149991 -0.35341018 -1.4919087\n",
      "  0.06280948 -0.360573   -1.3810132   0.04      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[ 0.0164, -0.1957, -0.2253,  ...,  0.0323, -0.3681, -1.3448],\n",
      "        [ 0.0164, -0.1957, -0.2253,  ...,  0.0323, -0.3681, -1.3448],\n",
      "        [ 0.0164, -0.1957, -0.2253,  ...,  0.0323, -0.3681, -1.3448],\n",
      "        ...,\n",
      "        [-0.0143,  0.5213, -0.1871,  ..., -0.5732,  1.0558, -0.5264],\n",
      "        [-0.1428,  0.0204,  0.6001,  ..., -0.1609,  0.7148,  0.3227],\n",
      "        [-0.1428,  0.0204,  0.6001,  ..., -0.1609,  0.7148,  0.3227]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.6417395e-02 -1.9568130e-01 -2.2525011e-01  3.8195316e-02\n",
      " -3.5525620e-01 -6.5964556e-01  1.1870413e-02 -5.3146446e-01\n",
      " -1.4000125e+00 -1.3098672e-01 -5.8666599e-01 -1.7317024e+00\n",
      " -3.1814727e-01 -7.3545051e-01 -2.2019854e+00 -2.1073157e-01\n",
      " -7.7948612e-01 -1.6177211e+00  1.1032105e-01 -7.9785883e-01\n",
      " -1.3696787e+00  4.4195257e-02 -7.5957745e-01 -1.4081899e+00\n",
      "  3.2335617e-02 -8.6575425e-01 -1.5301088e+00 -1.5462074e-01\n",
      " -6.5336579e-01 -1.5148821e+00 -3.6641181e-02 -7.2712898e-01\n",
      " -1.5031995e+00 -3.0148782e-02 -7.0933181e-01 -1.6149704e+00\n",
      "  6.8892084e-02 -7.5608647e-01 -1.6895424e+00 -3.5275936e-02\n",
      " -5.6827903e-01 -1.3227359e+00 -1.5574834e-01 -3.4701276e-01\n",
      " -1.9314148e+00  2.6370585e-04 -5.2082956e-01 -1.9035735e+00\n",
      "  1.3861847e-01 -4.7712618e-01 -1.5134963e+00 -1.6681203e-01\n",
      " -3.1844014e-01 -1.2626812e+00 -4.0814959e-02 -3.0760711e-01\n",
      " -1.3227743e+00  1.3146602e-02 -3.6514062e-01 -1.4356316e+00\n",
      "  3.2301307e-02 -3.6813414e-01 -1.3448132e+00]\n",
      "data: [ 1.6417395e-02 -1.9568130e-01 -2.2525011e-01  3.8195316e-02\n",
      " -3.5525620e-01 -6.5964556e-01  1.1870413e-02 -5.3146446e-01\n",
      " -1.4000125e+00 -1.3098672e-01 -5.8666599e-01 -1.7317024e+00\n",
      " -3.1814727e-01 -7.3545051e-01 -2.2019854e+00 -2.1073157e-01\n",
      " -7.7948606e-01 -1.6177211e+00  1.1032105e-01 -7.9785883e-01\n",
      " -1.3696789e+00  4.4195257e-02 -7.5957751e-01 -1.4081899e+00\n",
      "  3.2335617e-02 -8.6575425e-01 -1.5301088e+00 -1.5462074e-01\n",
      " -6.5336579e-01 -1.5148821e+00 -3.6641181e-02 -7.2712898e-01\n",
      " -1.5031995e+00 -3.0148782e-02 -7.0933181e-01 -1.6149704e+00\n",
      "  6.8892084e-02 -7.5608653e-01 -1.6895424e+00 -3.5275936e-02\n",
      " -5.6827903e-01 -1.3227359e+00 -1.5574834e-01 -3.4701276e-01\n",
      " -1.9314148e+00  2.6370585e-04 -5.2082956e-01 -1.9035735e+00\n",
      "  1.3861847e-01 -4.7712621e-01 -1.5134963e+00 -1.6681203e-01\n",
      " -3.1844014e-01 -1.2626812e+00 -4.0814959e-02 -3.0760711e-01\n",
      " -1.3227744e+00  1.3146602e-02 -3.6514062e-01 -1.4356315e+00\n",
      "  3.2301307e-02 -3.6813414e-01 -1.3448132e+00  5.0000001e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[ 0.0357, -0.1919, -0.2129,  ...,  0.0613, -0.3752, -1.2345],\n",
      "        [ 0.0357, -0.1919, -0.2129,  ...,  0.0613, -0.3752, -1.2345],\n",
      "        [ 0.0357, -0.1919, -0.2129,  ...,  0.0613, -0.3752, -1.2345],\n",
      "        ...,\n",
      "        [ 0.0243,  0.6106, -0.1445,  ..., -0.3745,  1.1604, -0.5759],\n",
      "        [-0.1289,  0.0078,  0.6562,  ..., -0.1783,  0.6883,  0.3277],\n",
      "        [-0.1289,  0.0078,  0.6562,  ..., -0.1783,  0.6883,  0.3277]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03570373 -0.19186175 -0.2128982   0.07115582 -0.30436462 -0.51228684\n",
      " -0.04828145 -0.5352888  -1.3672603  -0.20491973 -0.59854054 -1.670747\n",
      " -0.35839385 -0.7051563  -2.18463    -0.1692427  -0.8215331  -1.5749971\n",
      "  0.04780889 -0.8855562  -1.4031383  -0.01341006 -0.8195572  -1.4454685\n",
      " -0.02913085 -0.97937167 -1.5726557  -0.11823907 -0.72572076 -1.4650723\n",
      " -0.04880424 -0.7875824  -1.444825   -0.05198222 -0.7534592  -1.5318478\n",
      "  0.07128516 -0.8004886  -1.5579596  -0.01855261 -0.60979974 -1.2956556\n",
      " -0.18592997 -0.37127987 -2.0555453   0.00642008 -0.56070995 -2.0698366\n",
      "  0.17274658 -0.5101154  -1.414156   -0.1562577  -0.37687486 -1.2173446\n",
      " -0.06525405 -0.34792033 -1.2972944  -0.02896813 -0.3687609  -1.409356\n",
      "  0.06132969 -0.37521005 -1.2345325 ]\n",
      "data: [ 0.03570373 -0.19186175 -0.2128982   0.07115582 -0.30436462 -0.51228684\n",
      " -0.04828145 -0.5352888  -1.3672603  -0.20491973 -0.59854054 -1.670747\n",
      " -0.35839385 -0.7051563  -2.18463    -0.16924268 -0.821533   -1.5749971\n",
      "  0.04780889 -0.88555616 -1.4031383  -0.01341006 -0.8195572  -1.4454685\n",
      " -0.02913084 -0.97937167 -1.5726557  -0.11823907 -0.72572076 -1.4650723\n",
      " -0.04880424 -0.7875824  -1.4448249  -0.05198222 -0.7534592  -1.5318478\n",
      "  0.07128516 -0.8004886  -1.5579596  -0.01855261 -0.60979974 -1.2956557\n",
      " -0.18592997 -0.37127987 -2.0555453   0.00642008 -0.56070995 -2.0698366\n",
      "  0.17274658 -0.5101154  -1.4141558  -0.1562577  -0.37687483 -1.2173446\n",
      " -0.06525405 -0.34792033 -1.2972943  -0.02896812 -0.3687609  -1.4093559\n",
      "  0.06132969 -0.37521005 -1.2345325   0.06      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[-0.0117, -0.1009, -0.1717,  ...,  0.0351, -0.2854, -1.1601],\n",
      "        [-0.0117, -0.1009, -0.1717,  ...,  0.0351, -0.2854, -1.1601],\n",
      "        [-0.0117, -0.1009, -0.1717,  ...,  0.0351, -0.2854, -1.1601],\n",
      "        ...,\n",
      "        [-0.1496,  0.4833, -0.0303,  ..., -0.6352,  1.0875, -0.4779],\n",
      "        [-0.0828,  0.0409,  0.6568,  ..., -0.1585,  0.7076,  0.2797],\n",
      "        [-0.0828,  0.0409,  0.6568,  ..., -0.1585,  0.7076,  0.2797]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.0117179  -0.10094411 -0.1716576   0.01665957 -0.2140667  -0.46033937\n",
      " -0.0991802  -0.43551454 -1.3043066  -0.25625998 -0.49584028 -1.6159401\n",
      " -0.4181875  -0.6079758  -2.1197567  -0.22276798 -0.7250132  -1.5029424\n",
      "  0.00518331 -0.7780074  -1.3242295  -0.05289553 -0.714202   -1.3705851\n",
      " -0.05575633 -0.8682375  -1.502746   -0.16862568 -0.62703735 -1.3908057\n",
      " -0.08915357 -0.68823296 -1.3714329  -0.08444531 -0.65477467 -1.4682657\n",
      "  0.05484013 -0.6996898  -1.5018767  -0.06287206 -0.5146377  -1.2117219\n",
      " -0.2204985  -0.2803182  -1.9599028  -0.02545553 -0.4628354  -1.972321\n",
      "  0.15942997 -0.41846538 -1.3437676  -0.19673021 -0.27980056 -1.1364746\n",
      " -0.09896173 -0.25509378 -1.2136464  -0.05919972 -0.27710336 -1.3293287\n",
      "  0.03513806 -0.2854386  -1.1601342 ]\n",
      "data: [-0.0117179  -0.10094411 -0.1716576   0.01665957 -0.2140667  -0.46033937\n",
      " -0.0991802  -0.43551454 -1.3043066  -0.25625998 -0.49584025 -1.6159401\n",
      " -0.4181875  -0.6079758  -2.1197567  -0.22276798 -0.7250132  -1.5029426\n",
      "  0.00518331 -0.7780073  -1.3242295  -0.05289553 -0.714202   -1.370585\n",
      " -0.05575633 -0.86823744 -1.502746   -0.16862568 -0.62703735 -1.3908057\n",
      " -0.08915357 -0.68823296 -1.3714329  -0.08444531 -0.6547746  -1.4682657\n",
      "  0.05484013 -0.6996898  -1.5018767  -0.06287206 -0.5146377  -1.2117219\n",
      " -0.2204985  -0.2803182  -1.9599028  -0.02545553 -0.4628354  -1.972321\n",
      "  0.15942997 -0.41846538 -1.3437676  -0.19673021 -0.27980056 -1.1364746\n",
      " -0.09896173 -0.25509378 -1.2136464  -0.05919972 -0.27710336 -1.3293287\n",
      "  0.03513806 -0.2854386  -1.1601342   0.07      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[-0.0196, -0.0650, -0.2203,  ..., -0.0053, -0.2509, -1.2084],\n",
      "        [-0.0196, -0.0650, -0.2203,  ..., -0.0053, -0.2509, -1.2084],\n",
      "        [-0.0196, -0.0650, -0.2203,  ..., -0.0053, -0.2509, -1.2084],\n",
      "        ...,\n",
      "        [-0.1684,  0.3798,  0.0192,  ..., -0.6535,  0.9453, -0.3307],\n",
      "        [-0.0788, -0.0689,  0.6254,  ..., -0.1878,  0.6740,  0.2701],\n",
      "        [-0.0788, -0.0689,  0.6254,  ..., -0.1878,  0.6740,  0.2701]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01958204 -0.06504403 -0.22033338  0.00880626 -0.15836978 -0.51172704\n",
      " -0.15809946 -0.39032596 -1.3750397  -0.31628847 -0.45732343 -1.6556894\n",
      " -0.46115255 -0.52812827 -2.1788287  -0.20672578 -0.7136265  -1.5396831\n",
      " -0.07604654 -0.7836733  -1.4036242  -0.11825232 -0.69636035 -1.4619863\n",
      " -0.11911669 -0.8757305  -1.5894532  -0.17130993 -0.6348624  -1.4423993\n",
      " -0.12851128 -0.67681557 -1.4067161  -0.14119872 -0.6356298  -1.4903257\n",
      "  0.0210139  -0.6568032  -1.4973902  -0.10193425 -0.5178781  -1.2895968\n",
      " -0.2569973  -0.27856475 -2.0542722  -0.07031597 -0.43973476 -2.0945418\n",
      "  0.12360656 -0.40316552 -1.3757272  -0.2180652  -0.29237643 -1.2053112\n",
      " -0.17114852 -0.2548548  -1.3025693  -0.1434137  -0.23763059 -1.4186443\n",
      " -0.00532139 -0.25087452 -1.2084426 ]\n",
      "data: [-0.01958204 -0.06504403 -0.22033338  0.00880626 -0.15836978 -0.51172704\n",
      " -0.15809946 -0.39032596 -1.3750397  -0.31628847 -0.45732343 -1.6556894\n",
      " -0.46115258 -0.52812827 -2.1788287  -0.20672578 -0.7136265  -1.5396831\n",
      " -0.07604654 -0.7836732  -1.403624   -0.11825232 -0.69636035 -1.4619862\n",
      " -0.11911669 -0.8757305  -1.5894532  -0.17130993 -0.6348624  -1.4423993\n",
      " -0.12851128 -0.67681557 -1.4067161  -0.14119872 -0.6356298  -1.4903256\n",
      "  0.0210139  -0.6568032  -1.4973902  -0.10193424 -0.5178781  -1.2895969\n",
      " -0.2569973  -0.27856475 -2.0542722  -0.07031597 -0.43973476 -2.0945418\n",
      "  0.12360657 -0.40316552 -1.3757272  -0.2180652  -0.29237643 -1.2053112\n",
      " -0.17114852 -0.2548548  -1.3025693  -0.1434137  -0.23763059 -1.4186443\n",
      " -0.00532139 -0.25087452 -1.2084426   0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0344, -0.0292, -0.1622,  ...,  0.0355, -0.2003, -1.2060],\n",
      "        [ 0.0344, -0.0292, -0.1622,  ...,  0.0355, -0.2003, -1.2060],\n",
      "        [ 0.0344, -0.0292, -0.1622,  ...,  0.0355, -0.2003, -1.2060],\n",
      "        ...,\n",
      "        [-0.2612,  0.2528, -0.1245,  ..., -0.8410,  0.8145, -0.4302],\n",
      "        [-0.2290, -0.1556,  0.4936,  ..., -0.3717,  0.5532,  0.2066],\n",
      "        [-0.2290, -0.1556,  0.4936,  ..., -0.3717,  0.5532,  0.2066]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03443883 -0.02917637 -0.16217165  0.05279319 -0.16751541 -0.56908935\n",
      " -0.03580736 -0.35216105 -1.3264158  -0.17923367 -0.40930232 -1.6269314\n",
      " -0.3619634  -0.51825166 -2.0930777  -0.1741635  -0.6365222  -1.4802103\n",
      "  0.0511858  -0.66270113 -1.2685837   0.00723392 -0.6042272  -1.3190826\n",
      "  0.00753248 -0.7346097  -1.4403838  -0.13532907 -0.52595544 -1.3911178\n",
      " -0.04821464 -0.5809884  -1.3613837  -0.04781176 -0.5538533  -1.4606683\n",
      "  0.09665811 -0.5796646  -1.5161432  -0.04839598 -0.4370892  -1.2186476\n",
      " -0.17564084 -0.2088235  -1.8945239  -0.00582657 -0.36565384 -1.8950416\n",
      "  0.1608689  -0.32931152 -1.3615673  -0.16004454 -0.19500999 -1.1501976\n",
      " -0.08475773 -0.17185992 -1.2266424  -0.03805226 -0.18620984 -1.348327\n",
      "  0.03553287 -0.20027702 -1.205969  ]\n",
      "data: [ 0.03443883 -0.02917638 -0.16217165  0.05279319 -0.16751541 -0.56908935\n",
      " -0.03580736 -0.35216105 -1.3264157  -0.17923367 -0.40930232 -1.6269314\n",
      " -0.3619634  -0.51825166 -2.0930777  -0.17416352 -0.6365222  -1.4802103\n",
      "  0.0511858  -0.66270113 -1.2685837   0.00723392 -0.6042272  -1.3190826\n",
      "  0.00753248 -0.7346098  -1.4403838  -0.13532907 -0.52595544 -1.3911178\n",
      " -0.04821464 -0.5809884  -1.3613837  -0.04781176 -0.5538533  -1.4606683\n",
      "  0.09665812 -0.5796646  -1.5161432  -0.04839598 -0.4370892  -1.2186476\n",
      " -0.17564084 -0.2088235  -1.894524   -0.00582657 -0.36565384 -1.8950417\n",
      "  0.1608689  -0.32931152 -1.3615673  -0.16004454 -0.19500999 -1.1501976\n",
      " -0.08475773 -0.17185992 -1.2266424  -0.03805226 -0.18620986 -1.348327\n",
      "  0.03553287 -0.20027703 -1.205969    0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[-0.0020, -0.0821, -0.2420,  ...,  0.0191, -0.2546, -1.3110],\n",
      "        [-0.0020, -0.0821, -0.2420,  ...,  0.0191, -0.2546, -1.3110],\n",
      "        [-0.0020, -0.0821, -0.2420,  ...,  0.0191, -0.2546, -1.3110],\n",
      "        ...,\n",
      "        [-0.3267,  0.3005, -0.3064,  ..., -0.7773,  0.7597, -0.4916],\n",
      "        [-0.1128,  0.0110,  0.6347,  ..., -0.2203,  0.7935,  0.3113],\n",
      "        [-0.1128,  0.0110,  0.6347,  ..., -0.2203,  0.7935,  0.3113]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-1.9895993e-03 -8.2074568e-02 -2.4196243e-01  2.1624226e-02\n",
      " -2.2987129e-01 -6.6401106e-01 -6.1770067e-02 -4.1003260e-01\n",
      " -1.4167665e+00 -2.0396030e-01 -4.7342941e-01 -1.7129022e+00\n",
      " -3.7126967e-01 -5.9273708e-01 -2.1925187e+00 -2.1237367e-01\n",
      " -6.8088472e-01 -1.5788983e+00  1.4778219e-02 -7.0638907e-01\n",
      " -1.3758930e+00 -3.9044209e-02 -6.4560580e-01 -1.4277750e+00\n",
      " -4.8936807e-02 -7.6898736e-01 -1.5434024e+00 -1.6917387e-01\n",
      " -5.7284087e-01 -1.4959593e+00 -8.1840888e-02 -6.2826037e-01\n",
      " -1.4711186e+00 -9.6062630e-02 -5.9953028e-01 -1.5644521e+00\n",
      "  2.5954790e-02 -6.2411237e-01 -1.6146513e+00 -7.6965749e-02\n",
      " -4.9053875e-01 -1.3226727e+00 -1.8417129e-01 -2.6052448e-01\n",
      " -1.9313414e+00 -3.8366564e-02 -4.1323978e-01 -1.9255748e+00\n",
      "  1.0657295e-01 -3.7982887e-01 -1.4687171e+00 -1.7839453e-01\n",
      " -2.5161880e-01 -1.2604486e+00 -9.4175063e-02 -2.2912520e-01\n",
      " -1.3351378e+00 -4.5653977e-02 -2.4558093e-01 -1.4518863e+00\n",
      "  1.9096255e-02 -2.5456810e-01 -1.3110158e+00]\n",
      "data: [-1.98959932e-03 -8.20745677e-02 -2.41962433e-01  2.16242261e-02\n",
      " -2.29871288e-01 -6.64011061e-01 -6.17700666e-02 -4.10032630e-01\n",
      " -1.41676652e+00 -2.03960299e-01 -4.73429412e-01 -1.71290219e+00\n",
      " -3.71269673e-01 -5.92737079e-01 -2.19251871e+00 -2.12373674e-01\n",
      " -6.80884719e-01 -1.57889831e+00  1.47782192e-02 -7.06389070e-01\n",
      " -1.37589300e+00 -3.90442088e-02 -6.45605803e-01 -1.42777491e+00\n",
      " -4.89368066e-02 -7.68987358e-01 -1.54340243e+00 -1.69173867e-01\n",
      " -5.72840869e-01 -1.49595928e+00 -8.18408877e-02 -6.28260374e-01\n",
      " -1.47111857e+00 -9.60626304e-02 -5.99530280e-01 -1.56445205e+00\n",
      "  2.59547904e-02 -6.24112368e-01 -1.61465132e+00 -7.69657493e-02\n",
      " -4.90538746e-01 -1.32267272e+00 -1.84171289e-01 -2.60524482e-01\n",
      " -1.93134141e+00 -3.83665636e-02 -4.13239777e-01 -1.92557478e+00\n",
      "  1.06572956e-01 -3.79828870e-01 -1.46871710e+00 -1.78394526e-01\n",
      " -2.51618803e-01 -1.26044858e+00 -9.41750631e-02 -2.29125202e-01\n",
      " -1.33513784e+00 -4.56539765e-02 -2.45580927e-01 -1.45188630e+00\n",
      "  1.90962553e-02 -2.54568100e-01 -1.31101573e+00  1.00000001e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0448, -0.0870, -0.2538,  ...,  0.0514, -0.2756, -1.2861],\n",
      "        [ 0.0448, -0.0870, -0.2538,  ...,  0.0514, -0.2756, -1.2861],\n",
      "        [ 0.0448, -0.0870, -0.2538,  ...,  0.0514, -0.2756, -1.2861],\n",
      "        ...,\n",
      "        [-0.1156,  0.4445, -0.1254,  ..., -0.7044,  0.9729, -0.4096],\n",
      "        [-0.1175, -0.1579,  0.6068,  ..., -0.2105,  0.6160,  0.2783],\n",
      "        [-0.1175, -0.1579,  0.6068,  ..., -0.2105,  0.6160,  0.2783]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04481024 -0.08696093 -0.2538104   0.06867351 -0.2051842  -0.6330174\n",
      " -0.05448855 -0.40049756 -1.4150109  -0.20165968 -0.46506625 -1.6997969\n",
      " -0.35492536 -0.5509033  -2.2014072  -0.14127682 -0.71119654 -1.5703924\n",
      "  0.01162057 -0.75752604 -1.4243175  -0.03609988 -0.6812594  -1.4872692\n",
      " -0.03921943 -0.8377198  -1.6042913  -0.10689262 -0.6231197  -1.4872468\n",
      " -0.05134324 -0.66609573 -1.4557667  -0.0776943  -0.6368607  -1.5451093\n",
      "  0.05907543 -0.6512219  -1.566678   -0.03821034 -0.52567756 -1.3289472\n",
      " -0.16164176 -0.29643425 -2.0097947  -0.00991419 -0.44415084 -2.031783\n",
      "  0.148998   -0.417959   -1.4380962  -0.13460086 -0.29920626 -1.2582959\n",
      " -0.08377291 -0.2711116  -1.3474361  -0.05295208 -0.2611208  -1.4637417\n",
      "  0.05135506 -0.27564335 -1.2860682 ]\n",
      "data: [ 0.04481024 -0.08696093 -0.2538104   0.06867351 -0.2051842  -0.6330174\n",
      " -0.05448855 -0.40049756 -1.4150109  -0.20165968 -0.46506625 -1.6997969\n",
      " -0.35492533 -0.5509033  -2.2014072  -0.14127682 -0.71119654 -1.5703923\n",
      "  0.01162057 -0.75752604 -1.4243175  -0.03609988 -0.6812594  -1.4872692\n",
      " -0.03921943 -0.8377198  -1.6042914  -0.10689262 -0.6231197  -1.4872468\n",
      " -0.05134324 -0.66609573 -1.4557666  -0.0776943  -0.6368607  -1.5451093\n",
      "  0.05907543 -0.6512219  -1.566678   -0.03821034 -0.52567756 -1.3289472\n",
      " -0.16164178 -0.29643425 -2.0097947  -0.00991419 -0.44415084 -2.031783\n",
      "  0.148998   -0.41795903 -1.4380962  -0.13460086 -0.29920626 -1.2582959\n",
      " -0.08377292 -0.2711116  -1.3474361  -0.05295208 -0.2611208  -1.4637417\n",
      "  0.05135506 -0.27564335 -1.2860683   0.11      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0291, -0.0506, -0.2422,  ...,  0.0641, -0.2411, -1.2785],\n",
      "        [ 0.0291, -0.0506, -0.2422,  ...,  0.0641, -0.2411, -1.2785],\n",
      "        [ 0.0291, -0.0506, -0.2422,  ...,  0.0641, -0.2411, -1.2785],\n",
      "        ...,\n",
      "        [-0.1385,  0.3405, -0.0325,  ..., -0.7789,  0.8248, -0.2791],\n",
      "        [-0.1379, -0.1293,  0.5497,  ..., -0.2182,  0.6256,  0.2040],\n",
      "        [-0.1379, -0.1293,  0.5497,  ..., -0.2182,  0.6256,  0.2040]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02910891 -0.05064695 -0.24215181  0.04456759 -0.18841302 -0.6438534\n",
      " -0.03736605 -0.37154394 -1.3834112  -0.18235357 -0.43088853 -1.6904974\n",
      " -0.35758978 -0.5506157  -2.1595306  -0.17762634 -0.6574499  -1.5487034\n",
      "  0.05038269 -0.68804455 -1.3563335  -0.0046403  -0.62804645 -1.4107664\n",
      " -0.00680544 -0.764142   -1.5297585  -0.12962268 -0.5528879  -1.4583027\n",
      " -0.04309924 -0.61049855 -1.4368935  -0.0516347  -0.5873558  -1.5368857\n",
      "  0.07611208 -0.6151171  -1.5829237  -0.03266173 -0.4636445  -1.2836976\n",
      " -0.1510979  -0.2404414  -1.9366078   0.00673638 -0.39986473 -1.9343481\n",
      "  0.16430023 -0.3675068  -1.4327686  -0.13958268 -0.22867891 -1.2210555\n",
      " -0.05275509 -0.21088625 -1.3024414  -0.0091324  -0.2300746  -1.4199986\n",
      "  0.06408361 -0.24108624 -1.2784724 ]\n",
      "data: [ 0.02910891 -0.05064695 -0.24215181  0.04456759 -0.18841302 -0.6438534\n",
      " -0.03736605 -0.37154397 -1.383411   -0.18235357 -0.43088853 -1.6904974\n",
      " -0.3575898  -0.5506157  -2.1595306  -0.17762634 -0.6574499  -1.5487034\n",
      "  0.05038269 -0.6880446  -1.3563335  -0.0046403  -0.62804645 -1.4107662\n",
      " -0.00680544 -0.764142   -1.5297585  -0.12962268 -0.5528879  -1.4583027\n",
      " -0.04309924 -0.61049855 -1.4368935  -0.0516347  -0.5873558  -1.5368857\n",
      "  0.07611208 -0.6151171  -1.5829235  -0.03266173 -0.46364447 -1.2836976\n",
      " -0.1510979  -0.2404414  -1.9366078   0.00673637 -0.39986473 -1.9343481\n",
      "  0.16430023 -0.3675068  -1.4327686  -0.13958268 -0.22867891 -1.2210555\n",
      " -0.05275509 -0.21088625 -1.3024414  -0.0091324  -0.2300746  -1.4199986\n",
      "  0.06408361 -0.24108623 -1.2784724   0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[ 0.0144, -0.0870, -0.2550,  ...,  0.0434, -0.2745, -1.3154],\n",
      "        [ 0.0144, -0.0870, -0.2550,  ...,  0.0434, -0.2745, -1.3154],\n",
      "        [ 0.0144, -0.0870, -0.2550,  ...,  0.0434, -0.2745, -1.3154],\n",
      "        ...,\n",
      "        [-0.1533,  0.4140, -0.1118,  ..., -0.7046,  0.8918, -0.3496],\n",
      "        [-0.1611, -0.1223,  0.5835,  ..., -0.2396,  0.6611,  0.2331],\n",
      "        [-0.1611, -0.1223,  0.5835,  ..., -0.2396,  0.6611,  0.2331]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01441265 -0.08701726 -0.2550401   0.03279186 -0.22950405 -0.6769546\n",
      " -0.05278543 -0.41070414 -1.4250143  -0.19420286 -0.47428972 -1.7222033\n",
      " -0.36343867 -0.58970296 -2.1953773  -0.18776157 -0.69210833 -1.5850217\n",
      "  0.03068817 -0.7215523  -1.3862014  -0.01983027 -0.6587514  -1.4416995\n",
      " -0.02268343 -0.78917646 -1.5581672  -0.14474595 -0.58659124 -1.5008829\n",
      " -0.06084394 -0.64126986 -1.4749124  -0.07334987 -0.6174224  -1.5696077\n",
      "  0.05604684 -0.63802135 -1.6173759  -0.05609355 -0.50474393 -1.3283348\n",
      " -0.16350037 -0.2787463  -1.9511685  -0.01630513 -0.43027085 -1.9484501\n",
      "  0.1376931  -0.40007198 -1.4701903  -0.15632537 -0.267322   -1.2643378\n",
      " -0.07672304 -0.24711487 -1.3448796  -0.02940166 -0.26161247 -1.4603376\n",
      "  0.04337765 -0.27452788 -1.3153665 ]\n",
      "data: [ 0.01441265 -0.08701726 -0.2550401   0.03279186 -0.22950405 -0.6769546\n",
      " -0.05278543 -0.4107041  -1.4250141  -0.19420286 -0.47428972 -1.7222033\n",
      " -0.3634387  -0.58970296 -2.1953773  -0.18776157 -0.69210833 -1.5850216\n",
      "  0.03068817 -0.72155225 -1.3862014  -0.01983027 -0.6587514  -1.4416995\n",
      " -0.02268343 -0.78917646 -1.5581672  -0.14474595 -0.58659124 -1.5008829\n",
      " -0.06084393 -0.64126986 -1.4749124  -0.07334987 -0.6174224  -1.5696077\n",
      "  0.05604684 -0.63802135 -1.6173759  -0.05609355 -0.50474393 -1.3283348\n",
      " -0.16350037 -0.2787463  -1.9511685  -0.01630513 -0.43027085 -1.94845\n",
      "  0.1376931  -0.40007198 -1.4701903  -0.15632537 -0.267322   -1.2643378\n",
      " -0.07672304 -0.24711487 -1.3448796  -0.02940166 -0.26161247 -1.4603376\n",
      "  0.04337765 -0.27452788 -1.3153665   0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[ 0.0236, -0.0885, -0.2617,  ...,  0.0516, -0.2759, -1.2933],\n",
      "        [ 0.0236, -0.0885, -0.2617,  ...,  0.0516, -0.2759, -1.2933],\n",
      "        [ 0.0236, -0.0885, -0.2617,  ...,  0.0516, -0.2759, -1.2933],\n",
      "        ...,\n",
      "        [-0.1131,  0.4218, -0.1488,  ..., -0.6943,  0.9351, -0.4390],\n",
      "        [-0.1341, -0.1409,  0.5942,  ..., -0.2399,  0.6251,  0.2376],\n",
      "        [-0.1341, -0.1409,  0.5942,  ..., -0.2399,  0.6251,  0.2376]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02363414 -0.0885215  -0.2617367   0.04882866 -0.2151089  -0.6463182\n",
      " -0.0479551  -0.40727958 -1.4156952  -0.19093065 -0.4681718  -1.7133927\n",
      " -0.35039422 -0.5750171  -2.1972544  -0.17180482 -0.7000013  -1.5798434\n",
      "  0.03121121 -0.7390425  -1.4126601  -0.02264579 -0.6741696  -1.4678973\n",
      " -0.02645693 -0.8186624  -1.5870818  -0.12809779 -0.60324246 -1.4889644\n",
      " -0.05350145 -0.65591156 -1.4665664  -0.06727019 -0.6288741  -1.5592262\n",
      "  0.05906717 -0.65703213 -1.5957457  -0.04133687 -0.5082036  -1.3196604\n",
      " -0.16757977 -0.2796607  -1.9992125  -0.00658064 -0.43978235 -2.006978\n",
      "  0.1486086  -0.4067346  -1.4530957  -0.14875594 -0.27723694 -1.2513579\n",
      " -0.07092753 -0.25369292 -1.3351433  -0.03142911 -0.2641583  -1.4511396\n",
      "  0.05157245 -0.27588332 -1.2933142 ]\n",
      "data: [ 0.02363414 -0.0885215  -0.2617367   0.04882866 -0.21510892 -0.6463182\n",
      " -0.0479551  -0.40727958 -1.4156952  -0.19093065 -0.4681718  -1.7133927\n",
      " -0.35039422 -0.5750171  -2.1972544  -0.17180482 -0.7000013  -1.5798434\n",
      "  0.03121121 -0.7390425  -1.4126601  -0.02264579 -0.6741696  -1.4678973\n",
      " -0.02645693 -0.8186624  -1.5870818  -0.12809779 -0.60324246 -1.4889644\n",
      " -0.05350145 -0.65591156 -1.4665664  -0.06727019 -0.6288741  -1.5592263\n",
      "  0.05906717 -0.6570322  -1.5957457  -0.04133687 -0.5082036  -1.3196605\n",
      " -0.16757977 -0.2796607  -1.9992125  -0.00658064 -0.43978232 -2.006978\n",
      "  0.1486086  -0.4067346  -1.4530957  -0.14875594 -0.27723694 -1.2513579\n",
      " -0.07092753 -0.25369292 -1.3351433  -0.03142911 -0.2641583  -1.4511396\n",
      "  0.05157245 -0.27588332 -1.2933142   0.14      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0191, -0.0541, -0.2467,  ...,  0.0563, -0.2441, -1.2937],\n",
      "        [ 0.0191, -0.0541, -0.2467,  ...,  0.0563, -0.2441, -1.2937],\n",
      "        [ 0.0191, -0.0541, -0.2467,  ...,  0.0563, -0.2441, -1.2937],\n",
      "        ...,\n",
      "        [-0.1466,  0.3524, -0.0943,  ..., -0.7771,  0.8382, -0.3357],\n",
      "        [-0.1349, -0.1440,  0.5641,  ..., -0.2130,  0.6068,  0.2250],\n",
      "        [-0.1349, -0.1440,  0.5641,  ..., -0.2130,  0.6068,  0.2250]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.9147266e-02 -5.4116830e-02 -2.4669215e-01  3.2639254e-02\n",
      " -1.9792415e-01 -6.5725142e-01 -4.2179629e-02 -3.7693363e-01\n",
      " -1.3859426e+00 -1.8518695e-01 -4.3586561e-01 -1.6924486e+00\n",
      " -3.6328340e-01 -5.5973411e-01 -2.1556082e+00 -1.8965784e-01\n",
      " -6.5803838e-01 -1.5524602e+00  4.5896597e-02 -6.8495440e-01\n",
      " -1.3562717e+00 -7.6256916e-03 -6.2608236e-01 -1.4089707e+00\n",
      " -6.1112791e-03 -7.5642967e-01 -1.5252047e+00 -1.4087346e-01\n",
      " -5.4934335e-01 -1.4647601e+00 -4.9392879e-02 -6.0777271e-01\n",
      " -1.4437096e+00 -5.4945245e-02 -5.8624727e-01 -1.5439897e+00\n",
      "  7.2181247e-02 -6.1235338e-01 -1.5956835e+00 -4.1973993e-02\n",
      " -4.6494207e-01 -1.2903390e+00 -1.5428245e-01 -2.4260321e-01\n",
      " -1.9244272e+00  3.1522661e-04 -4.0053099e-01 -1.9173150e+00\n",
      "  1.5552148e-01 -3.6715269e-01 -1.4460455e+00 -1.4769205e-01\n",
      " -2.2747327e-01 -1.2303137e+00 -5.8133252e-02 -2.1094809e-01\n",
      " -1.3109601e+00 -1.0870449e-02 -2.3327269e-01 -1.4283714e+00\n",
      "  5.6269735e-02 -2.4413975e-01 -1.2937095e+00]\n",
      "data: [ 1.9147266e-02 -5.4116830e-02 -2.4669214e-01  3.2639254e-02\n",
      " -1.9792415e-01 -6.5725142e-01 -4.2179629e-02 -3.7693363e-01\n",
      " -1.3859426e+00 -1.8518695e-01 -4.3586558e-01 -1.6924486e+00\n",
      " -3.6328340e-01 -5.5973411e-01 -2.1556082e+00 -1.8965784e-01\n",
      " -6.5803838e-01 -1.5524602e+00  4.5896597e-02 -6.8495440e-01\n",
      " -1.3562716e+00 -7.6256921e-03 -6.2608236e-01 -1.4089706e+00\n",
      " -6.1112791e-03 -7.5642967e-01 -1.5252047e+00 -1.4087346e-01\n",
      " -5.4934335e-01 -1.4647602e+00 -4.9392883e-02 -6.0777271e-01\n",
      " -1.4437096e+00 -5.4945245e-02 -5.8624727e-01 -1.5439897e+00\n",
      "  7.2181247e-02 -6.1235338e-01 -1.5956835e+00 -4.1973993e-02\n",
      " -4.6494207e-01 -1.2903390e+00 -1.5428245e-01 -2.4260321e-01\n",
      " -1.9244272e+00  3.1522661e-04 -4.0053099e-01 -1.9173150e+00\n",
      "  1.5552148e-01 -3.6715272e-01 -1.4460455e+00 -1.4769205e-01\n",
      " -2.2747327e-01 -1.2303137e+00 -5.8133256e-02 -2.1094808e-01\n",
      " -1.3109601e+00 -1.0870449e-02 -2.3327269e-01 -1.4283714e+00\n",
      "  5.6269735e-02 -2.4413975e-01 -1.2937095e+00  1.5000001e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0098, -0.0853, -0.2560,  ...,  0.0376, -0.2727, -1.3140],\n",
      "        [ 0.0098, -0.0853, -0.2560,  ...,  0.0376, -0.2727, -1.3140],\n",
      "        [ 0.0098, -0.0853, -0.2560,  ...,  0.0376, -0.2727, -1.3140],\n",
      "        ...,\n",
      "        [-0.1574,  0.4252, -0.1345,  ..., -0.7131,  0.9080, -0.3805],\n",
      "        [-0.1618, -0.1328,  0.5836,  ..., -0.2457,  0.6479,  0.2323],\n",
      "        [-0.1618, -0.1328,  0.5836,  ..., -0.2457,  0.6479,  0.2323]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00979756 -0.08534234 -0.25604704  0.02874798 -0.22511514 -0.67324466\n",
      " -0.05876075 -0.40816054 -1.4258978  -0.20005603 -0.47097313 -1.7231925\n",
      " -0.36741108 -0.5844661  -2.1983135  -0.1915929  -0.69170463 -1.585856\n",
      "  0.02409086 -0.72250533 -1.3912654  -0.0267984  -0.65905064 -1.4467816\n",
      " -0.02993965 -0.79182    -1.5639114  -0.14868918 -0.5874989  -1.5006468\n",
      " -0.0665268  -0.6413318  -1.4755564  -0.07915774 -0.61679846 -1.569772\n",
      "  0.04977964 -0.6384229  -1.6161313  -0.06039969 -0.50360143 -1.3292058\n",
      " -0.17100748 -0.27700076 -1.961304   -0.02174044 -0.42962658 -1.9604459\n",
      "  0.13224563 -0.3985262  -1.4700732  -0.1617785  -0.26724127 -1.2640367\n",
      " -0.08277406 -0.2462757  -1.3455639  -0.03679326 -0.2598687  -1.4612234\n",
      "  0.03759938 -0.2726673  -1.3140106 ]\n",
      "data: [ 0.00979756 -0.08534234 -0.25604704  0.02874798 -0.22511512 -0.67324466\n",
      " -0.05876075 -0.40816057 -1.4258978  -0.20005603 -0.47097313 -1.7231925\n",
      " -0.36741108 -0.5844661  -2.1983135  -0.1915929  -0.69170463 -1.585856\n",
      "  0.02409086 -0.72250533 -1.3912654  -0.0267984  -0.6590507  -1.4467816\n",
      " -0.02993965 -0.79182    -1.5639114  -0.14868918 -0.5874989  -1.5006468\n",
      " -0.0665268  -0.6413318  -1.4755564  -0.07915774 -0.61679846 -1.569772\n",
      "  0.04977964 -0.6384229  -1.6161313  -0.06039969 -0.50360143 -1.3292058\n",
      " -0.17100748 -0.27700076 -1.9613041  -0.02174044 -0.42962658 -1.9604459\n",
      "  0.13224563 -0.3985262  -1.4700732  -0.1617785  -0.26724127 -1.2640367\n",
      " -0.08277406 -0.2462757  -1.345564   -0.03679326 -0.2598687  -1.4612232\n",
      "  0.03759938 -0.2726673  -1.3140106   0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0216, -0.0880, -0.2518,  ...,  0.0513, -0.2748, -1.2857],\n",
      "        [ 0.0216, -0.0880, -0.2518,  ...,  0.0513, -0.2748, -1.2857],\n",
      "        [ 0.0216, -0.0880, -0.2518,  ...,  0.0513, -0.2748, -1.2857],\n",
      "        ...,\n",
      "        [-0.1195,  0.4045, -0.1611,  ..., -0.7076,  0.9184, -0.4413],\n",
      "        [-0.1421, -0.1548,  0.5825,  ..., -0.2539,  0.6094,  0.2276],\n",
      "        [-0.1421, -0.1548,  0.5825,  ..., -0.2539,  0.6094,  0.2276]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02155556 -0.08799843 -0.2517904   0.04513012 -0.2180867  -0.64466417\n",
      " -0.04583708 -0.40768188 -1.4035848  -0.18711841 -0.46781278 -1.7025702\n",
      " -0.34910795 -0.5780374  -2.1797757  -0.17532319 -0.69717467 -1.5660269\n",
      "  0.03448601 -0.7331929  -1.3942357  -0.01892933 -0.67028666 -1.4487761\n",
      " -0.02165741 -0.8118148  -1.5674026  -0.13098541 -0.5978011  -1.4759021\n",
      " -0.05283545 -0.65151906 -1.4540899  -0.06449672 -0.6256132  -1.5474209\n",
      "  0.06131159 -0.6542486  -1.5878042  -0.04216198 -0.50440454 -1.3060325\n",
      " -0.16650909 -0.2772661  -1.9799389  -0.00568667 -0.4374049  -1.9846755\n",
      "  0.14840314 -0.40364113 -1.4440768  -0.14934447 -0.27248055 -1.2389894\n",
      " -0.06892657 -0.24989572 -1.3222842  -0.02763642 -0.262941   -1.4388489\n",
      "  0.05125112 -0.27482265 -1.2856978 ]\n",
      "data: [ 0.02155556 -0.08799843 -0.2517904   0.04513012 -0.2180867  -0.64466417\n",
      " -0.04583708 -0.40768188 -1.403585   -0.18711841 -0.46781278 -1.7025702\n",
      " -0.34910792 -0.5780374  -2.1797757  -0.17532319 -0.69717467 -1.5660269\n",
      "  0.03448601 -0.7331929  -1.3942357  -0.01892933 -0.67028666 -1.4487761\n",
      " -0.02165741 -0.8118148  -1.5674026  -0.13098541 -0.5978011  -1.4759021\n",
      " -0.05283545 -0.65151906 -1.4540898  -0.06449672 -0.6256132  -1.5474209\n",
      "  0.06131159 -0.6542486  -1.5878043  -0.04216198 -0.50440454 -1.3060325\n",
      " -0.16650909 -0.2772661  -1.9799389  -0.00568667 -0.4374049  -1.9846756\n",
      "  0.14840314 -0.40364113 -1.4440769  -0.14934447 -0.27248055 -1.2389894\n",
      " -0.06892657 -0.24989572 -1.3222842  -0.02763642 -0.262941   -1.4388489\n",
      "  0.05125112 -0.27482265 -1.2856978   0.17      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0267, -0.0745, -0.2518,  ...,  0.0616, -0.2637, -1.2875],\n",
      "        [ 0.0267, -0.0745, -0.2518,  ...,  0.0616, -0.2637, -1.2875],\n",
      "        [ 0.0267, -0.0745, -0.2518,  ...,  0.0616, -0.2637, -1.2875],\n",
      "        ...,\n",
      "        [-0.1430,  0.3697, -0.1058,  ..., -0.7723,  0.8638, -0.3621],\n",
      "        [-0.1319, -0.1247,  0.5793,  ..., -0.2169,  0.6399,  0.2192],\n",
      "        [-0.1319, -0.1247,  0.5793,  ..., -0.2169,  0.6399,  0.2192]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.66596861e-02 -7.45211542e-02 -2.51809657e-01  4.72224094e-02\n",
      " -2.08643422e-01 -6.46659255e-01 -4.37846184e-02 -3.98203969e-01\n",
      " -1.40419137e+00 -1.87445104e-01 -4.59539860e-01 -1.70517600e+00\n",
      " -3.55117470e-01 -5.74024081e-01 -2.17981100e+00 -1.74618125e-01\n",
      " -6.85161531e-01 -1.56706154e+00  4.13789377e-02 -7.20779181e-01\n",
      " -1.38343227e+00 -1.24976411e-02 -6.58199966e-01 -1.43770921e+00\n",
      " -1.54820755e-02 -7.98376083e-01 -1.55653560e+00 -1.28344148e-01\n",
      " -5.83409846e-01 -1.47696590e+00 -4.74668518e-02 -6.39338195e-01\n",
      " -1.45373344e+00 -5.79559281e-02 -6.14526093e-01 -1.54878187e+00\n",
      "  7.01190755e-02 -6.42247856e-01 -1.59062076e+00 -3.64625007e-02\n",
      " -4.92152184e-01 -1.30483210e+00 -1.58483982e-01 -2.65671939e-01\n",
      " -1.97217965e+00  1.87456608e-03 -4.26257014e-01 -1.97427094e+00\n",
      "  1.58999085e-01 -3.93020093e-01 -1.44457865e+00 -1.43186539e-01\n",
      " -2.58093983e-01 -1.23919046e+00 -6.07734695e-02 -2.37279266e-01\n",
      " -1.32253408e+00 -1.72721371e-02 -2.52205312e-01 -1.43937087e+00\n",
      "  6.15795702e-02 -2.63724387e-01 -1.28746521e+00]\n",
      "data: [ 2.66596861e-02 -7.45211542e-02 -2.51809657e-01  4.72224094e-02\n",
      " -2.08643422e-01 -6.46659255e-01 -4.37846184e-02 -3.98203969e-01\n",
      " -1.40419149e+00 -1.87445104e-01 -4.59539860e-01 -1.70517588e+00\n",
      " -3.55117440e-01 -5.74024081e-01 -2.17981100e+00 -1.74618125e-01\n",
      " -6.85161531e-01 -1.56706166e+00  4.13789377e-02 -7.20779181e-01\n",
      " -1.38343227e+00 -1.24976411e-02 -6.58200026e-01 -1.43770921e+00\n",
      " -1.54820755e-02 -7.98376083e-01 -1.55653560e+00 -1.28344148e-01\n",
      " -5.83409846e-01 -1.47696590e+00 -4.74668518e-02 -6.39338195e-01\n",
      " -1.45373356e+00 -5.79559281e-02 -6.14526093e-01 -1.54878187e+00\n",
      "  7.01190755e-02 -6.42247856e-01 -1.59062076e+00 -3.64625007e-02\n",
      " -4.92152184e-01 -1.30483210e+00 -1.58483982e-01 -2.65671939e-01\n",
      " -1.97217977e+00  1.87456608e-03 -4.26257014e-01 -1.97427094e+00\n",
      "  1.58999085e-01 -3.93020093e-01 -1.44457865e+00 -1.43186539e-01\n",
      " -2.58093983e-01 -1.23919046e+00 -6.07734695e-02 -2.37279266e-01\n",
      " -1.32253408e+00 -1.72721371e-02 -2.52205312e-01 -1.43937087e+00\n",
      "  6.15795702e-02 -2.63724387e-01 -1.28746521e+00  1.80000007e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0228, -0.0937, -0.2587,  ...,  0.0648, -0.2806, -1.3090],\n",
      "        [ 0.0228, -0.0937, -0.2587,  ...,  0.0648, -0.2806, -1.3090],\n",
      "        [ 0.0228, -0.0937, -0.2587,  ...,  0.0648, -0.2806, -1.3090],\n",
      "        ...,\n",
      "        [-0.1297,  0.3927, -0.1327,  ..., -0.7385,  0.8841, -0.3854],\n",
      "        [-0.1351, -0.1126,  0.5834,  ..., -0.2276,  0.6569,  0.2227],\n",
      "        [-0.1351, -0.1126,  0.5834,  ..., -0.2276,  0.6569,  0.2227]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.2790048e-02 -9.3665145e-02 -2.5866684e-01  4.3068234e-02\n",
      " -2.3542109e-01 -6.6946101e-01 -3.4695223e-02 -4.1799769e-01\n",
      " -1.4127164e+00 -1.7603922e-01 -4.7865656e-01 -1.7165400e+00\n",
      " -3.4636995e-01 -6.0100192e-01 -2.1843691e+00 -1.8135086e-01\n",
      " -6.9709468e-01 -1.5789149e+00  5.4150708e-02 -7.2588485e-01\n",
      " -1.3840250e+00  3.2157451e-04 -6.6703862e-01 -1.4360014e+00\n",
      " -1.4551580e-03 -7.9746968e-01 -1.5539261e+00 -1.3321531e-01\n",
      " -5.9047043e-01 -1.4901447e+00 -4.2138375e-02 -6.4883173e-01\n",
      " -1.4690961e+00 -4.8363209e-02 -6.2435633e-01 -1.5657111e+00\n",
      "  7.7404074e-02 -6.5400577e-01 -1.6161094e+00 -3.5828650e-02\n",
      " -5.0423545e-01 -1.3142766e+00 -1.4959037e-01 -2.7820212e-01\n",
      " -1.9543848e+00  7.4728429e-03 -4.3810919e-01 -1.9489222e+00\n",
      "  1.6223219e-01 -4.0363866e-01 -1.4668273e+00 -1.4351529e-01\n",
      " -2.6674515e-01 -1.2510531e+00 -5.1954962e-02 -2.4737945e-01\n",
      " -1.3315669e+00 -3.4103468e-03 -2.6958123e-01 -1.4485669e+00\n",
      "  6.4845011e-02 -2.8060073e-01 -1.3090119e+00]\n",
      "data: [ 2.2790048e-02 -9.3665145e-02 -2.5866684e-01  4.3068234e-02\n",
      " -2.3542109e-01 -6.6946101e-01 -3.4695223e-02 -4.1799772e-01\n",
      " -1.4127164e+00 -1.7603922e-01 -4.7865659e-01 -1.7165399e+00\n",
      " -3.4636992e-01 -6.0100192e-01 -2.1843691e+00 -1.8135086e-01\n",
      " -6.9709468e-01 -1.5789150e+00  5.4150712e-02 -7.2588485e-01\n",
      " -1.3840250e+00  3.2157451e-04 -6.6703868e-01 -1.4360014e+00\n",
      " -1.4551580e-03 -7.9746974e-01 -1.5539261e+00 -1.3321531e-01\n",
      " -5.9047043e-01 -1.4901446e+00 -4.2138375e-02 -6.4883173e-01\n",
      " -1.4690961e+00 -4.8363209e-02 -6.2435633e-01 -1.5657113e+00\n",
      "  7.7404074e-02 -6.5400577e-01 -1.6161094e+00 -3.5828650e-02\n",
      " -5.0423545e-01 -1.3142766e+00 -1.4959037e-01 -2.7820212e-01\n",
      " -1.9543848e+00  7.4728429e-03 -4.3810922e-01 -1.9489222e+00\n",
      "  1.6223219e-01 -4.0363866e-01 -1.4668273e+00 -1.4351529e-01\n",
      " -2.6674515e-01 -1.2510531e+00 -5.1954962e-02 -2.4737945e-01\n",
      " -1.3315669e+00 -3.4103468e-03 -2.6958123e-01 -1.4485669e+00\n",
      "  6.4845011e-02 -2.8060073e-01 -1.3090119e+00  1.9000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B320>\n",
      "tensor([[ 0.0187, -0.1118, -0.2623,  ...,  0.0642, -0.2976, -1.3198],\n",
      "        [ 0.0187, -0.1118, -0.2623,  ...,  0.0642, -0.2976, -1.3198],\n",
      "        [ 0.0187, -0.1118, -0.2623,  ...,  0.0642, -0.2976, -1.3198],\n",
      "        ...,\n",
      "        [-0.1043,  0.4404, -0.1511,  ..., -0.6623,  0.9450, -0.4459],\n",
      "        [-0.1338, -0.1062,  0.5976,  ..., -0.2350,  0.6534,  0.2357],\n",
      "        [-0.1338, -0.1062,  0.5976,  ..., -0.2350,  0.6534,  0.2357]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0187417  -0.11178748 -0.26233035  0.03975062 -0.25822473 -0.6740254\n",
      " -0.02708629 -0.43964612 -1.4140104  -0.16778842 -0.49947345 -1.7227721\n",
      " -0.34083283 -0.62855387 -2.187072   -0.18853998 -0.7117657  -1.5886711\n",
      "  0.06620666 -0.7379508  -1.3842821   0.00985072 -0.68353266 -1.4328368\n",
      "  0.00662347 -0.80835205 -1.550938   -0.13737962 -0.60060203 -1.4975445\n",
      " -0.03916363 -0.66250694 -1.4793253  -0.04178505 -0.6390441  -1.5775918\n",
      "  0.07832319 -0.67332995 -1.6340481  -0.03346999 -0.5149359  -1.3179355\n",
      " -0.14764035 -0.2897334  -1.9508648   0.00982589 -0.4534397  -1.939649\n",
      "  0.161116   -0.41567272 -1.4799676  -0.14579985 -0.27470666 -1.2561733\n",
      " -0.04475991 -0.2569614  -1.333394    0.00630728 -0.28739962 -1.4498261\n",
      "  0.06424299 -0.29758084 -1.3197663 ]\n",
      "data: [ 0.0187417  -0.11178747 -0.26233035  0.03975062 -0.25822473 -0.6740254\n",
      " -0.02708629 -0.43964612 -1.4140105  -0.16778842 -0.49947345 -1.7227721\n",
      " -0.34083283 -0.62855387 -2.187072   -0.18853998 -0.71176565 -1.5886711\n",
      "  0.06620666 -0.7379508  -1.3842821   0.00985072 -0.68353266 -1.4328368\n",
      "  0.00662347 -0.80835205 -1.550938   -0.13737962 -0.60060203 -1.4975445\n",
      " -0.03916363 -0.66250694 -1.4793253  -0.04178505 -0.6390441  -1.5775917\n",
      "  0.07832319 -0.67332995 -1.6340481  -0.03346999 -0.5149359  -1.3179355\n",
      " -0.14764035 -0.2897334  -1.9508649   0.00982589 -0.4534397  -1.9396491\n",
      "  0.161116   -0.41567272 -1.4799676  -0.14579985 -0.27470666 -1.2561733\n",
      " -0.04475991 -0.2569614  -1.333394    0.00630728 -0.28739962 -1.449826\n",
      "  0.06424299 -0.29758084 -1.3197663   0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EC24128>\n",
      "tensor([[ 0.0107, -0.1209, -0.2329,  ...,  0.0553, -0.3046, -1.2934],\n",
      "        [ 0.0107, -0.1209, -0.2329,  ...,  0.0553, -0.3046, -1.2934],\n",
      "        [ 0.0107, -0.1209, -0.2329,  ...,  0.0553, -0.3046, -1.2934],\n",
      "        ...,\n",
      "        [-0.0867,  0.4630, -0.1521,  ..., -0.6260,  0.9501, -0.4395],\n",
      "        [-0.1320, -0.0913,  0.6008,  ..., -0.2338,  0.6414,  0.2619],\n",
      "        [-0.1320, -0.0913,  0.6008,  ..., -0.2338,  0.6414,  0.2619]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.0747355e-02 -1.2086733e-01 -2.3288471e-01  3.2391179e-02\n",
      " -2.6641792e-01 -6.3673991e-01 -3.3183910e-02 -4.5182100e-01\n",
      " -1.3842502e+00 -1.7543073e-01 -5.1145267e-01 -1.6959044e+00\n",
      " -3.4823155e-01 -6.4238441e-01 -2.1628923e+00 -1.9892603e-01\n",
      " -7.2207576e-01 -1.5678689e+00  6.1579391e-02 -7.5168908e-01\n",
      " -1.3656708e+00  1.7198026e-03 -6.9966501e-01 -1.4117060e+00\n",
      " -2.3851916e-03 -8.2666659e-01 -1.5310097e+00 -1.4534575e-01\n",
      " -6.1029077e-01 -1.4734609e+00 -4.6659730e-02 -6.7489481e-01\n",
      " -1.4566370e+00 -4.8249148e-02 -6.5206885e-01 -1.5562258e+00\n",
      "  6.8043992e-02 -6.9206911e-01 -1.6110382e+00 -3.8721584e-02\n",
      " -5.2034068e-01 -1.2929678e+00 -1.5948184e-01 -2.9531658e-01\n",
      " -1.9395802e+00  2.1195337e-03 -4.6439105e-01 -1.9291844e+00\n",
      "  1.5314448e-01 -4.2565900e-01 -1.4560546e+00 -1.5621090e-01\n",
      " -2.7900887e-01 -1.2293390e+00 -5.0608814e-02 -2.6199806e-01\n",
      " -1.3066518e+00 -1.1245906e-03 -2.9575279e-01 -1.4229956e+00\n",
      "  5.5306979e-02 -3.0463696e-01 -1.2933563e+00]\n",
      "data: [-5.03 -1.58  0.23 -4.97 -1.29  0.29 -4.84 -0.89  0.34 -4.82 -0.63  0.59\n",
      " -4.75 -0.49  0.73 -4.73 -0.96  0.49 -4.72 -0.89  0.82 -4.7  -0.68  0.82\n",
      " -4.71 -0.55  0.89 -4.79 -1.05  0.43 -4.75 -0.88  0.59 -4.8  -0.6   0.6\n",
      " -4.8  -0.5   0.62 -4.84 -1.08  0.43 -4.81 -0.87  0.41 -4.85 -0.69  0.52\n",
      " -4.96 -0.55  0.68 -4.91 -1.06  0.31 -4.89 -0.89  0.34 -4.91 -0.81  0.43\n",
      " -4.99 -0.63  0.6   0.  ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[-0.0220, -0.1485, -0.0824,  ...,  0.1750, -0.3778,  0.3966],\n",
      "        [-0.0220, -0.1485, -0.0824,  ...,  0.1750, -0.3778,  0.3966],\n",
      "        [-0.0220, -0.1485, -0.0824,  ...,  0.1750, -0.3778,  0.3966],\n",
      "        ...,\n",
      "        [ 0.5679, -0.2300,  0.3031,  ..., -0.3848, -0.0208, -1.0176],\n",
      "        [ 0.5208, -0.0399,  0.4498,  ..., -1.3733,  0.3408,  0.2080],\n",
      "        [ 0.5208, -0.0399,  0.4498,  ..., -1.3733,  0.3408,  0.2080]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.02203892 -0.14847013 -0.08239771 -0.09786526 -0.19388586  0.14393665\n",
      " -0.13162321 -0.29562902  0.41966397 -0.16307239 -0.394193    0.51031625\n",
      " -0.17947794 -0.48861048  0.64644164 -0.13204214 -0.34152865  0.3038357\n",
      " -0.01853922 -0.40470243  0.74248284 -0.04276893 -0.46830335  0.81810933\n",
      " -0.08977643 -0.4617856   0.850975   -0.04722678 -0.32737818  0.2729063\n",
      " -0.0646996  -0.4193705   0.36396503 -0.06307495 -0.45561704  0.4024707\n",
      " -0.0589146  -0.51507384  0.43600404  0.02221567 -0.29364443  0.25402272\n",
      "  0.03393324 -0.3802956   0.5278718   0.01270431 -0.41187653  0.5707005\n",
      "  0.06138134 -0.46626386  0.41165525  0.05680291 -0.22590259  0.24474226\n",
      "  0.11416757 -0.280189    0.32085013  0.1513608  -0.35925826  0.38467985\n",
      "  0.17500323 -0.37775344  0.39664453]\n",
      "init: [-0.02203892 -0.14847013 -0.08239771 -0.09786526 -0.19388586  0.14393665\n",
      " -0.13162321 -0.29562902  0.41966397 -0.16307239 -0.394193    0.51031625\n",
      " -0.17947794 -0.48861048  0.64644164 -0.13204214 -0.34152865  0.3038357\n",
      " -0.01853922 -0.40470243  0.74248284 -0.04276893 -0.46830335  0.81810933\n",
      " -0.08977643 -0.4617856   0.850975   -0.04722678 -0.32737818  0.2729063\n",
      " -0.0646996  -0.4193705   0.36396503 -0.06307495 -0.45561704  0.4024707\n",
      " -0.0589146  -0.51507384  0.43600404  0.02221567 -0.29364443  0.25402272\n",
      "  0.03393324 -0.3802956   0.5278718   0.01270431 -0.41187653  0.5707005\n",
      "  0.06138134 -0.46626386  0.41165525  0.05680291 -0.22590259  0.24474226\n",
      "  0.11416757 -0.280189    0.32085013  0.1513608  -0.35925826  0.38467985\n",
      "  0.17500323 -0.37775344  0.39664453]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [-0.02203892 -0.14847013 -0.08239772 -0.09786525 -0.19388586  0.14393665\n",
      " -0.13162321 -0.29562902  0.41966397 -0.16307239 -0.394193    0.51031625\n",
      " -0.17947794 -0.48861045  0.64644164 -0.13204214 -0.34152865  0.3038357\n",
      " -0.01853922 -0.40470243  0.74248284 -0.04276893 -0.46830332  0.81810933\n",
      " -0.08977643 -0.4617856   0.850975   -0.04722678 -0.32737818  0.2729063\n",
      " -0.0646996  -0.4193705   0.36396503 -0.06307495 -0.45561704  0.4024707\n",
      " -0.05891461 -0.51507384  0.43600404  0.02221567 -0.29364443  0.25402272\n",
      "  0.03393324 -0.3802956   0.5278718   0.01270431 -0.41187653  0.5707005\n",
      "  0.06138134 -0.46626386  0.41165525  0.05680291 -0.2259026   0.24474226\n",
      "  0.11416758 -0.280189    0.32085013  0.1513608  -0.35925826  0.38467988\n",
      "  0.17500323 -0.37775344  0.3966445   0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[-0.1396,  0.1728,  0.0422,  ..., -0.3158, -0.1302,  0.3634],\n",
      "        [-0.1396,  0.1728,  0.0422,  ..., -0.3158, -0.1302,  0.3634],\n",
      "        [-0.1396,  0.1728,  0.0422,  ..., -0.3158, -0.1302,  0.3634],\n",
      "        ...,\n",
      "        [-0.1515,  0.2714, -0.3596,  ...,  0.6372,  1.0794, -1.0275],\n",
      "        [ 0.2300,  0.0337, -0.0611,  ...,  0.2862,  0.4354, -0.1735],\n",
      "        [ 0.2300,  0.0337, -0.0611,  ...,  0.2862,  0.4354, -0.1735]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.13957773  0.17277494  0.04215441 -0.37018335  0.09502184 -0.17346565\n",
      " -0.63497055 -0.05770025  0.0745471  -0.8074146  -0.18253088  0.21732225\n",
      " -0.9059439  -0.28141698  0.42403263 -0.6218772  -0.05763263  0.05462362\n",
      " -0.8783119  -0.21616328 -0.00096289 -0.9100226  -0.2877568   0.09214177\n",
      " -0.84405065 -0.34222844  0.1876138  -0.52265716 -0.0420748   0.0238563\n",
      " -0.70055234 -0.20736867  0.24020393 -0.6681517  -0.28982118  0.33891696\n",
      " -0.6098287  -0.37617412  0.40533882 -0.47043782 -0.03316161 -0.00552755\n",
      " -0.56690955 -0.15362129  0.35488153 -0.54154927 -0.23667231  0.38227606\n",
      " -0.45334262 -0.2986047   0.36193162 -0.39465392  0.03376476  0.05843648\n",
      " -0.4472692  -0.01479521  0.18920453 -0.38031605 -0.08481315  0.25030082\n",
      " -0.31580806 -0.13021559  0.36344165]\n",
      "data: [-0.13957773  0.17277494  0.04215441 -0.37018335  0.09502184 -0.17346565\n",
      " -0.63497055 -0.05770025  0.0745471  -0.80741465 -0.18253088  0.21732226\n",
      " -0.90594393 -0.28141698  0.42403263 -0.6218772  -0.05763263  0.05462362\n",
      " -0.8783119  -0.21616328 -0.00096289 -0.91002256 -0.2877568   0.09214177\n",
      " -0.84405065 -0.34222844  0.18761379 -0.52265716 -0.0420748   0.02385629\n",
      " -0.70055234 -0.20736867  0.24020393 -0.6681517  -0.28982118  0.33891696\n",
      " -0.6098287  -0.37617412  0.40533882 -0.47043782 -0.03316161 -0.00552755\n",
      " -0.56690955 -0.15362129  0.35488153 -0.54154927 -0.23667231  0.3822761\n",
      " -0.45334262 -0.2986047   0.36193162 -0.39465392  0.03376476  0.05843648\n",
      " -0.4472692  -0.01479521  0.18920451 -0.38031605 -0.08481315  0.25030082\n",
      " -0.31580806 -0.13021559  0.36344165  0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[-0.0271, -0.0941,  0.2410,  ..., -0.6211, -0.3614,  0.1077],\n",
      "        [-0.0271, -0.0941,  0.2410,  ..., -0.6211, -0.3614,  0.1077],\n",
      "        [-0.0271, -0.0941,  0.2410,  ..., -0.6211, -0.3614,  0.1077],\n",
      "        ...,\n",
      "        [ 0.5215, -0.0390, -0.1046,  ...,  0.4457,  0.5467, -0.1850],\n",
      "        [ 0.2409,  0.2926, -0.0665,  ..., -0.3611,  1.0144, -0.5421],\n",
      "        [ 0.2409,  0.2926, -0.0665,  ..., -0.3611,  1.0144, -0.5421]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.02709696 -0.09411085  0.24103296 -0.24309117 -0.27189466 -0.18392888\n",
      " -0.44828948 -0.46137208 -0.02688396 -0.640167   -0.5873549   0.0495574\n",
      " -0.8116597  -0.6935066   0.19885533 -0.49508217 -0.5097755   0.06252687\n",
      " -0.73562074 -0.6746664   0.0670765  -0.8162395  -0.75365245  0.13117644\n",
      " -0.89389586 -0.786422    0.22028789 -0.4589924  -0.44110778  0.0250982\n",
      " -0.6695757  -0.6083696   0.16891441 -0.73834324 -0.67547274  0.22485964\n",
      " -0.8033116  -0.7169725   0.27942303 -0.44602874 -0.37857354 -0.03862771\n",
      " -0.62446344 -0.5133434   0.14889494 -0.68049085 -0.5716876   0.17974237\n",
      " -0.7649473  -0.60169005  0.19630182 -0.40320346 -0.27849144 -0.01164126\n",
      " -0.551533   -0.33216292  0.03468663 -0.5556865  -0.3687646   0.07310601\n",
      " -0.6211406  -0.36139113  0.10771816]\n",
      "data: [-0.02709696 -0.09411085  0.24103296 -0.24309117 -0.27189466 -0.18392888\n",
      " -0.44828948 -0.46137208 -0.02688396 -0.640167   -0.5873549   0.0495574\n",
      " -0.8116597  -0.6935066   0.19885533 -0.49508217 -0.5097755   0.06252687\n",
      " -0.73562074 -0.67466646  0.0670765  -0.8162395  -0.7536524   0.13117644\n",
      " -0.89389586 -0.786422    0.22028789 -0.4589924  -0.44110778  0.0250982\n",
      " -0.66957563 -0.6083696   0.16891441 -0.7383432  -0.67547274  0.22485964\n",
      " -0.8033116  -0.71697253  0.27942303 -0.44602874 -0.37857354 -0.03862771\n",
      " -0.62446344 -0.5133434   0.14889494 -0.68049085 -0.5716876   0.17974238\n",
      " -0.7649473  -0.60169005  0.19630182 -0.40320346 -0.27849144 -0.01164126\n",
      " -0.551533   -0.33216295  0.03468663 -0.5556865  -0.3687646   0.07310601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.6211406  -0.36139116  0.10771816  0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[ 0.0346, -0.0431,  0.2035,  ..., -0.8331, -0.2051,  0.1267],\n",
      "        [ 0.0346, -0.0431,  0.2035,  ..., -0.8331, -0.2051,  0.1267],\n",
      "        [ 0.0346, -0.0431,  0.2035,  ..., -0.8331, -0.2051,  0.1267],\n",
      "        ...,\n",
      "        [ 0.2970, -0.1191, -0.3571,  ...,  0.2327,  0.5403, -0.8221],\n",
      "        [ 0.1940, -0.0607,  0.3236,  ...,  0.2799,  0.2956,  0.0417],\n",
      "        [ 0.1940, -0.0607,  0.3236,  ...,  0.2799,  0.2956,  0.0417]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03457014 -0.04305787  0.20346849 -0.17992963 -0.19559932 -0.29984015\n",
      " -0.33618072 -0.31490034 -0.03584428 -0.5534885  -0.3869983   0.03581378\n",
      " -0.7674264  -0.43693352  0.18383887 -0.47855178 -0.3776157   0.08695358\n",
      " -0.79636085 -0.51042867 -0.06448172 -0.8796419  -0.55464244  0.00234155\n",
      " -0.93657255 -0.56241393  0.12086131 -0.48752394 -0.32242656  0.05993657\n",
      " -0.7270529  -0.43941343  0.2156211  -0.8118248  -0.48719162  0.25791103\n",
      " -0.91551864 -0.49007887  0.33272117 -0.50137246 -0.25437474 -0.02476826\n",
      " -0.70288897 -0.38335782  0.23461498 -0.7993051  -0.40497202  0.26635477\n",
      " -0.9332808  -0.41187668  0.23643339 -0.46781138 -0.17284882  0.01233403\n",
      " -0.67046857 -0.20793796  0.08326996 -0.7182478  -0.23556037  0.13146415\n",
      " -0.8330885  -0.20514593  0.12672427]\n",
      "data: [ 0.03457014 -0.04305787  0.2034685  -0.17992964 -0.19559933 -0.29984015\n",
      " -0.33618072 -0.31490034 -0.03584428 -0.5534885  -0.3869983   0.03581378\n",
      " -0.7674264  -0.43693352  0.18383889 -0.47855178 -0.3776157   0.08695358\n",
      " -0.79636085 -0.51042867 -0.06448172 -0.8796419  -0.55464244  0.00234155\n",
      " -0.93657255 -0.56241393  0.12086131 -0.48752394 -0.32242656  0.05993657\n",
      " -0.7270529  -0.43941343  0.21562108 -0.8118248  -0.48719162  0.25791103\n",
      " -0.91551864 -0.49007884  0.33272117 -0.50137246 -0.25437474 -0.02476826\n",
      " -0.70288897 -0.38335782  0.23461498 -0.79930514 -0.404972    0.26635477\n",
      " -0.93328077 -0.41187668  0.23643339 -0.4678114  -0.17284882  0.01233403\n",
      " -0.67046857 -0.20793797  0.08326996 -0.7182478  -0.23556037  0.13146415\n",
      " -0.8330885  -0.20514593  0.12672427  0.04      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[-0.0947, -0.1085,  0.1477,  ..., -0.7650, -0.3682,  0.0684],\n",
      "        [-0.0947, -0.1085,  0.1477,  ..., -0.7650, -0.3682,  0.0684],\n",
      "        [-0.0947, -0.1085,  0.1477,  ..., -0.7650, -0.3682,  0.0684],\n",
      "        ...,\n",
      "        [-0.0173, -0.2614, -0.8109,  ..., -0.3477,  0.3615, -1.1332],\n",
      "        [ 0.3117, -0.0513,  0.5699,  ...,  0.0313,  0.4675, -0.1229],\n",
      "        [ 0.3117, -0.0513,  0.5699,  ...,  0.0313,  0.4675, -0.1229]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.09465297 -0.10845713  0.1477142  -0.32122758 -0.27936286 -0.29131445\n",
      " -0.5112361  -0.448784   -0.08841005 -0.7121521  -0.5644694  -0.00207834\n",
      " -0.90807056 -0.6548534   0.15094697 -0.58131677 -0.51231176  0.01526028\n",
      " -0.8247256  -0.6691633   0.0357816  -0.9067219  -0.74154055  0.11398569\n",
      " -0.98316336 -0.7562787   0.21414855 -0.5566673  -0.448254   -0.02394277\n",
      " -0.76501083 -0.60518694  0.14704004 -0.8338218  -0.65828085  0.20906919\n",
      " -0.90669966 -0.6954952   0.27248085 -0.5446466  -0.38393348 -0.10361654\n",
      " -0.7282286  -0.52442425  0.13578683 -0.7945708  -0.56868297  0.1707415\n",
      " -0.8864358  -0.58796513  0.1679045  -0.5088846  -0.28435725 -0.06800842\n",
      " -0.6625738  -0.33823848 -0.00510186 -0.6823885  -0.3776849   0.04162137\n",
      " -0.76501966 -0.36816293  0.06839465]\n",
      "data: [-0.09465297 -0.10845713  0.1477142  -0.32122758 -0.27936286 -0.29131445\n",
      " -0.5112361  -0.448784   -0.08841005 -0.7121521  -0.5644694  -0.00207834\n",
      " -0.9080705  -0.65485346  0.15094697 -0.58131677 -0.51231176  0.01526028\n",
      " -0.8247256  -0.6691633   0.0357816  -0.9067219  -0.74154055  0.11398569\n",
      " -0.98316336 -0.7562787   0.21414857 -0.5566673  -0.448254   -0.02394277\n",
      " -0.76501083 -0.60518694  0.14704004 -0.8338218  -0.65828085  0.20906919\n",
      " -0.90669966 -0.69549525  0.27248085 -0.5446466  -0.38393348 -0.10361654\n",
      " -0.7282286  -0.52442425  0.13578683 -0.79457074 -0.56868297  0.1707415\n",
      " -0.88643575 -0.58796513  0.1679045  -0.5088846  -0.28435725 -0.06800842\n",
      " -0.6625739  -0.33823848 -0.00510186 -0.6823885  -0.3776849   0.04162137\n",
      " -0.76501966 -0.36816293  0.06839465  0.05      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[ 0.0350,  0.0470,  0.2164,  ..., -0.7376, -0.1497,  0.1692],\n",
      "        [ 0.0350,  0.0470,  0.2164,  ..., -0.7376, -0.1497,  0.1692],\n",
      "        [ 0.0350,  0.0470,  0.2164,  ..., -0.7376, -0.1497,  0.1692],\n",
      "        ...,\n",
      "        [ 0.4729, -0.3304, -0.2246,  ...,  0.5584,  0.1101, -0.4571],\n",
      "        [ 0.1504, -0.1990,  0.5255,  ...,  0.0713,  0.1914,  0.1317],\n",
      "        [ 0.1504, -0.1990,  0.5255,  ...,  0.0713,  0.1914,  0.1317]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03497367  0.04699898  0.21635824 -0.18275689 -0.1120549  -0.2554405\n",
      " -0.3580838  -0.25515762  0.01268366 -0.5717442  -0.34107384  0.0929877\n",
      " -0.779796   -0.41830778  0.2524464  -0.47973052 -0.30475456  0.11029817\n",
      " -0.7965882  -0.45444715 -0.06612334 -0.8750204  -0.5033114   0.00615403\n",
      " -0.9042425  -0.5326244   0.13427612 -0.46566102 -0.24585176  0.07688002\n",
      " -0.6966709  -0.39030513  0.25424424 -0.77347755 -0.45264333  0.30087805\n",
      " -0.85720813 -0.4686038   0.3768941  -0.4675751  -0.18377991 -0.00189336\n",
      " -0.65495    -0.3206315   0.28021744 -0.74046063 -0.36135632  0.3138692\n",
      " -0.8506707  -0.3803087   0.27636757 -0.42907456 -0.09663855  0.02794309\n",
      " -0.6154069  -0.14068767  0.10293355 -0.64447856 -0.17744404  0.15004982\n",
      " -0.73764825 -0.14969678  0.16924644]\n",
      "data: [ 0.03497367  0.04699898  0.21635824 -0.18275689 -0.1120549  -0.2554405\n",
      " -0.3580838  -0.25515762  0.01268366 -0.5717442  -0.34107384  0.0929877\n",
      " -0.779796   -0.4183078   0.2524464  -0.47973052 -0.30475456  0.11029818\n",
      " -0.7965882  -0.45444715 -0.06612334 -0.8750204  -0.5033114   0.00615403\n",
      " -0.9042426  -0.5326244   0.13427612 -0.46566102 -0.24585174  0.07688002\n",
      " -0.6966709  -0.39030513  0.25424424 -0.77347755 -0.4526433   0.30087805\n",
      " -0.8572081  -0.4686038   0.3768941  -0.4675751  -0.18377991 -0.00189336\n",
      " -0.65495    -0.32063147  0.28021744 -0.74046063 -0.36135632  0.3138692\n",
      " -0.8506707  -0.3803087   0.27636757 -0.42907456 -0.09663855  0.02794309\n",
      " -0.6154069  -0.14068767  0.10293355 -0.64447856 -0.17744404  0.15004982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.73764825 -0.14969678  0.16924645  0.06      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[-0.0799, -0.0358,  0.1254,  ..., -0.7668, -0.3073,  0.2050],\n",
      "        [-0.0799, -0.0358,  0.1254,  ..., -0.7668, -0.3073,  0.2050],\n",
      "        [-0.0799, -0.0358,  0.1254,  ..., -0.7668, -0.3073,  0.2050],\n",
      "        ...,\n",
      "        [ 0.1213, -0.4496, -0.3459,  ..., -0.0327, -0.0010, -0.4643],\n",
      "        [ 0.3602,  0.0105,  0.4614,  ...,  0.0032,  0.6266, -0.3359],\n",
      "        [ 0.3602,  0.0105,  0.4614,  ...,  0.0032,  0.6266, -0.3359]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-7.9944760e-02 -3.5828367e-02  1.2544835e-01 -3.0459517e-01\n",
      " -2.0464556e-01 -2.8195450e-01 -5.0462401e-01 -3.8817126e-01\n",
      " -6.8494029e-02 -6.9797975e-01 -5.1031250e-01  3.5005800e-02\n",
      " -8.8759106e-01 -6.0523736e-01  2.1212500e-01 -5.7659066e-01\n",
      " -4.2455664e-01  8.0168642e-02 -8.3206409e-01 -5.8770907e-01\n",
      "  1.5136634e-01 -9.1906130e-01 -6.6774535e-01  2.3170362e-01\n",
      " -1.0160842e+00 -6.9112146e-01  3.3545873e-01 -5.5222565e-01\n",
      " -3.5915095e-01  4.5697905e-02 -7.8016591e-01 -5.2643180e-01\n",
      "  2.4661782e-01 -8.6372876e-01 -5.9217119e-01  3.2544148e-01\n",
      " -9.5184511e-01 -6.3216794e-01  3.9364374e-01 -5.4191327e-01\n",
      " -3.0023110e-01 -3.1517453e-02 -7.3826957e-01 -4.5108244e-01\n",
      "  2.1635813e-01 -8.1392962e-01 -5.0286388e-01  2.5757635e-01\n",
      " -9.2492795e-01 -5.2788544e-01  3.0662110e-01 -4.9315774e-01\n",
      " -2.0956095e-01  6.3411146e-04 -6.5606213e-01 -2.6795533e-01\n",
      "  1.0090433e-01 -6.7597252e-01 -3.0927134e-01  1.5927589e-01\n",
      " -7.6678377e-01 -3.0730531e-01  2.0500182e-01]\n",
      "data: [-7.9944760e-02 -3.5828367e-02  1.2544835e-01 -3.0459517e-01\n",
      " -2.0464556e-01 -2.8195450e-01 -5.0462401e-01 -3.8817129e-01\n",
      " -6.8494029e-02 -6.9797975e-01 -5.1031250e-01  3.5005800e-02\n",
      " -8.8759112e-01 -6.0523736e-01  2.1212500e-01 -5.7659066e-01\n",
      " -4.2455664e-01  8.0168635e-02 -8.3206403e-01 -5.8770907e-01\n",
      "  1.5136634e-01 -9.1906130e-01 -6.6774535e-01  2.3170362e-01\n",
      " -1.0160842e+00 -6.9112146e-01  3.3545873e-01 -5.5222565e-01\n",
      " -3.5915098e-01  4.5697905e-02 -7.8016591e-01 -5.2643180e-01\n",
      "  2.4661784e-01 -8.6372876e-01 -5.9217119e-01  3.2544148e-01\n",
      " -9.5184511e-01 -6.3216794e-01  3.9364374e-01 -5.4191327e-01\n",
      " -3.0023110e-01 -3.1517453e-02 -7.3826957e-01 -4.5108241e-01\n",
      "  2.1635813e-01 -8.1392962e-01 -5.0286388e-01  2.5757635e-01\n",
      " -9.2492795e-01 -5.2788544e-01  3.0662110e-01 -4.9315774e-01\n",
      " -2.0956095e-01  6.3411146e-04 -6.5606219e-01 -2.6795533e-01\n",
      "  1.0090433e-01 -6.7597252e-01 -3.0927134e-01  1.5927589e-01\n",
      " -7.6678377e-01 -3.0730531e-01  2.0500182e-01  7.0000000e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 2.6154e-02, -3.1201e-03,  1.6267e-01,  ..., -7.3769e-01,\n",
      "         -2.2505e-01,  1.2682e-01],\n",
      "        [ 2.6154e-02, -3.1201e-03,  1.6267e-01,  ..., -7.3769e-01,\n",
      "         -2.2505e-01,  1.2682e-01],\n",
      "        [ 2.6154e-02, -3.1201e-03,  1.6267e-01,  ..., -7.3769e-01,\n",
      "         -2.2505e-01,  1.2682e-01],\n",
      "        ...,\n",
      "        [ 3.5167e-01, -2.0768e-01, -4.0067e-01,  ...,  3.9898e-02,\n",
      "          5.1103e-01, -7.5590e-01],\n",
      "        [ 2.5068e-01, -6.7729e-04,  4.4217e-01,  ...,  2.2247e-01,\n",
      "          4.1357e-01, -3.7252e-02],\n",
      "        [ 2.5068e-01, -6.7729e-04,  4.4217e-01,  ...,  2.2247e-01,\n",
      "          4.1357e-01, -3.7252e-02]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02615381 -0.00312006  0.16266577 -0.19731009 -0.16536407 -0.2673897\n",
      " -0.38364083 -0.32017162 -0.03808065 -0.6004725  -0.41991806  0.04150049\n",
      " -0.81494313 -0.5036824   0.2045968  -0.49689662 -0.3722459   0.07041261\n",
      " -0.7983236  -0.5292521  -0.03531711 -0.88909346 -0.58609164  0.03600898\n",
      " -0.94908136 -0.6099708   0.157316   -0.47676224 -0.31185955  0.0382772\n",
      " -0.71481484 -0.4652861   0.20927063 -0.8056006  -0.5296357   0.25591812\n",
      " -0.8999735  -0.5443108   0.3246563  -0.47314852 -0.25403637 -0.03624867\n",
      " -0.6716844  -0.3934288   0.19745643 -0.7618332  -0.43319196  0.2334764\n",
      " -0.8799759  -0.4552343   0.23528874 -0.42599666 -0.16197474 -0.01132236\n",
      " -0.6099642  -0.21220976  0.05909198 -0.6357859  -0.24912587  0.11221422\n",
      " -0.737689   -0.22504635  0.12681696]\n",
      "data: [ 0.02615381 -0.00312006  0.16266577 -0.19731009 -0.16536407 -0.2673897\n",
      " -0.38364083 -0.32017162 -0.03808065 -0.6004725  -0.41991806  0.04150049\n",
      " -0.81494313 -0.5036824   0.2045968  -0.49689662 -0.3722459   0.07041261\n",
      " -0.7983236  -0.5292521  -0.03531711 -0.88909346 -0.58609164  0.03600898\n",
      " -0.94908136 -0.6099708   0.157316   -0.47676224 -0.31185955  0.0382772\n",
      " -0.71481484 -0.4652861   0.20927063 -0.8056006  -0.5296357   0.25591812\n",
      " -0.8999735  -0.5443108   0.3246563  -0.47314852 -0.25403637 -0.03624867\n",
      " -0.67168444 -0.3934288   0.19745643 -0.7618332  -0.43319196  0.23347642\n",
      " -0.8799759  -0.4552343   0.23528874 -0.42599666 -0.16197473 -0.01132237\n",
      " -0.6099642  -0.21220976  0.05909198 -0.6357859  -0.24912587  0.11221422\n",
      " -0.7376891  -0.22504635  0.12681696  0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FB38>\n",
      "tensor([[ 0.0705, -0.0066,  0.2066,  ..., -0.6548, -0.2418,  0.1783],\n",
      "        [ 0.0705, -0.0066,  0.2066,  ..., -0.6548, -0.2418,  0.1783],\n",
      "        [ 0.0705, -0.0066,  0.2066,  ..., -0.6548, -0.2418,  0.1783],\n",
      "        ...,\n",
      "        [-0.0063, -0.2840, -0.7920,  ..., -0.1065,  0.2318, -0.9733],\n",
      "        [ 0.1885, -0.0710,  0.5555,  ..., -0.0501,  0.4423, -0.0511],\n",
      "        [ 0.1885, -0.0710,  0.5555,  ..., -0.0501,  0.4423, -0.0511]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.07054701 -0.00655813  0.20661011 -0.14672215 -0.17074218 -0.21439792\n",
      " -0.34146994 -0.3407577  -0.02519865 -0.54620624 -0.45021406  0.06346531\n",
      " -0.75331134 -0.53696513  0.2182855  -0.43687642 -0.39339912  0.11142734\n",
      " -0.6994253  -0.5511162   0.10863429 -0.7857913  -0.6190743   0.18794644\n",
      " -0.8718772  -0.6351354   0.29515606 -0.41519046 -0.3320216   0.07955293\n",
      " -0.6400639  -0.48856968  0.2545091  -0.72112083 -0.5413292   0.31493375\n",
      " -0.80798656 -0.5705515   0.37738872 -0.4087512  -0.27105227  0.00210933\n",
      " -0.60529673 -0.4077468   0.22866912 -0.67940205 -0.45024022  0.26459032\n",
      " -0.79251987 -0.46857703  0.28302285 -0.36753243 -0.17415039  0.03190015\n",
      " -0.5374277  -0.22503957  0.10177962 -0.5578383  -0.26081282  0.15260348\n",
      " -0.6547701  -0.24178338  0.17830107]\n",
      "data: [ 0.07054701 -0.00655813  0.20661011 -0.14672215 -0.17074218 -0.21439792\n",
      " -0.34146994 -0.34075773 -0.02519865 -0.54620624 -0.45021403  0.06346531\n",
      " -0.75331134 -0.53696513  0.2182855  -0.43687642 -0.39339912  0.11142734\n",
      " -0.6994253  -0.5511162   0.10863428 -0.7857912  -0.6190743   0.18794644\n",
      " -0.8718772  -0.6351354   0.29515606 -0.41519046 -0.3320216   0.07955293\n",
      " -0.6400639  -0.48856968  0.2545091  -0.72112083 -0.5413292   0.31493375\n",
      " -0.8079865  -0.5705515   0.37738872 -0.4087512  -0.27105227  0.00210933\n",
      " -0.60529673 -0.40774682  0.22866912 -0.6794021  -0.45024022  0.26459032\n",
      " -0.7925198  -0.46857703  0.28302285 -0.36753243 -0.17415039  0.03190015\n",
      " -0.5374277  -0.22503957  0.10177961 -0.5578383  -0.26081282  0.15260348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.6547701  -0.24178337  0.17830107  0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[-0.0093, -0.0294,  0.2252,  ..., -0.7685, -0.2670,  0.0625],\n",
      "        [-0.0093, -0.0294,  0.2252,  ..., -0.7685, -0.2670,  0.0625],\n",
      "        [-0.0093, -0.0294,  0.2252,  ..., -0.7685, -0.2670,  0.0625],\n",
      "        ...,\n",
      "        [ 0.1983, -0.1947, -0.1129,  ...,  0.0578,  0.5028, -0.5132],\n",
      "        [ 0.2798, -0.0696,  0.4151,  ...,  0.2565,  0.4541, -0.0501],\n",
      "        [ 0.2798, -0.0696,  0.4151,  ...,  0.2565,  0.4541, -0.0501]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.00927791 -0.02944105  0.22515765 -0.23320018 -0.18459499 -0.25558704\n",
      " -0.40820715 -0.33643946 -0.0468597  -0.61886704 -0.43210524  0.01780024\n",
      " -0.8243866  -0.5100954   0.16310737 -0.5251801  -0.41056693  0.04783395\n",
      " -0.80242467 -0.56605726 -0.04865219 -0.88857305 -0.6262763   0.02318518\n",
      " -0.9557811  -0.64537466  0.13337123 -0.5087495  -0.3593198   0.01763023\n",
      " -0.73168063 -0.5102077   0.16796425 -0.8108829  -0.5627424   0.20934884\n",
      " -0.90219295 -0.5852077   0.27091548 -0.50257194 -0.29473808 -0.06572305\n",
      " -0.6967273  -0.4374881   0.16003694 -0.77487063 -0.4746652   0.19127312\n",
      " -0.8890952  -0.48931164  0.16585135 -0.4666281  -0.20644377 -0.03374453\n",
      " -0.6396496  -0.2562452   0.01570313 -0.66658103 -0.2953325   0.06167939\n",
      " -0.7685119  -0.2669722   0.06253792]\n",
      "data: [-0.00927791 -0.02944105  0.22515765 -0.23320016 -0.18459499 -0.25558704\n",
      " -0.40820712 -0.3364395  -0.0468597  -0.61886704 -0.43210524  0.01780024\n",
      " -0.8243866  -0.5100954   0.16310735 -0.5251801  -0.41056693  0.04783395\n",
      " -0.80242467 -0.56605726 -0.04865219 -0.88857305 -0.6262763   0.02318518\n",
      " -0.9557811  -0.64537466  0.13337123 -0.5087495  -0.3593198   0.01763023\n",
      " -0.73168063 -0.5102077   0.16796425 -0.8108829  -0.5627424   0.20934886\n",
      " -0.9021929  -0.5852077   0.27091548 -0.50257194 -0.29473808 -0.06572305\n",
      " -0.6967273  -0.4374881   0.16003695 -0.77487063 -0.4746652   0.19127312\n",
      " -0.8890951  -0.48931164  0.16585137 -0.4666281  -0.20644377 -0.03374453\n",
      " -0.6396496  -0.2562452   0.01570313 -0.66658103 -0.2953325   0.06167939\n",
      " -0.7685119  -0.2669722   0.06253792  0.1       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FE10>\n",
      "tensor([[ 0.0768, -0.0300,  0.1469,  ..., -0.6112, -0.2878,  0.1023],\n",
      "        [ 0.0768, -0.0300,  0.1469,  ..., -0.6112, -0.2878,  0.1023],\n",
      "        [ 0.0768, -0.0300,  0.1469,  ..., -0.6112, -0.2878,  0.1023],\n",
      "        ...,\n",
      "        [-0.0183, -0.2664, -0.5731,  ..., -0.0401,  0.2220, -0.7442],\n",
      "        [ 0.1177, -0.0049,  0.7033,  ..., -0.2730,  0.5874,  0.0124],\n",
      "        [ 0.1177, -0.0049,  0.7033,  ..., -0.2730,  0.5874,  0.0124]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.07683011 -0.03001946  0.1469263  -0.14040521 -0.18711895 -0.27151486\n",
      " -0.34471512 -0.35630566 -0.08313486 -0.54549575 -0.4691401   0.00726722\n",
      " -0.73760325 -0.5559417   0.15172696 -0.42158896 -0.4255604   0.0304963\n",
      " -0.6845091  -0.5811225   0.02498711 -0.76042885 -0.64841944  0.09896169\n",
      " -0.8312828  -0.67169976  0.19997218 -0.39883578 -0.3666777  -0.00602111\n",
      " -0.61862403 -0.52610743  0.16584466 -0.68940943 -0.5791705   0.22670363\n",
      " -0.7491179  -0.61385244  0.2817596  -0.39272273 -0.31133354 -0.07786427\n",
      " -0.5795877  -0.44033462  0.1595447  -0.6442504  -0.48530447  0.19140726\n",
      " -0.73055565 -0.5100794   0.19191048 -0.35348356 -0.21206081 -0.04245472\n",
      " -0.5195103  -0.26025897  0.02919602 -0.5331787  -0.29538935  0.07476912\n",
      " -0.6112435  -0.2878152   0.10227621]\n",
      "data: [ 0.07683011 -0.03001946  0.1469263  -0.14040521 -0.18711895 -0.27151486\n",
      " -0.34471512 -0.35630566 -0.08313486 -0.54549575 -0.46914014  0.00726722\n",
      " -0.73760325 -0.5559417   0.15172696 -0.421589   -0.4255604   0.0304963\n",
      " -0.6845091  -0.5811225   0.02498711 -0.76042885 -0.64841944  0.09896169\n",
      " -0.8312828  -0.67169976  0.1999722  -0.39883578 -0.3666777  -0.00602111\n",
      " -0.61862403 -0.52610743  0.16584466 -0.68940943 -0.5791705   0.22670363\n",
      " -0.7491179  -0.61385244  0.2817596  -0.39272273 -0.31133354 -0.07786427\n",
      " -0.5795877  -0.44033462  0.1595447  -0.6442504  -0.48530447  0.19140726\n",
      " -0.73055565 -0.5100794   0.19191048 -0.35348356 -0.21206081 -0.04245472\n",
      " -0.5195103  -0.26025897  0.02919602 -0.5331787  -0.29538935  0.07476912\n",
      " -0.6112435  -0.2878152   0.10227621  0.11      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[-0.0519, -0.2231,  0.1667,  ..., -0.7593, -0.4672, -0.1658],\n",
      "        [-0.0519, -0.2231,  0.1667,  ..., -0.7593, -0.4672, -0.1658],\n",
      "        [-0.0519, -0.2231,  0.1667,  ..., -0.7593, -0.4672, -0.1658],\n",
      "        ...,\n",
      "        [ 0.0828,  0.1511, -0.3511,  ..., -0.0671,  0.8477, -0.7028],\n",
      "        [ 0.3873,  0.1016,  0.4393,  ...,  0.3725,  0.6124,  0.0017],\n",
      "        [ 0.3873,  0.1016,  0.4393,  ...,  0.3725,  0.6124,  0.0017]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.05191284 -0.2230553   0.1666935  -0.2663554  -0.38318944 -0.33394217\n",
      " -0.44739014 -0.51883817 -0.14237751 -0.6758375  -0.62107253 -0.09206657\n",
      " -0.881364   -0.7038336  -0.01269543 -0.5606526  -0.62090075 -0.1331092\n",
      " -0.82084    -0.7756629  -0.24737988 -0.90154326 -0.8309078  -0.18371691\n",
      " -0.9530598  -0.85285497 -0.08208232 -0.5386392  -0.5743182  -0.17350735\n",
      " -0.741259   -0.7276361  -0.04327597 -0.8099029  -0.7739662  -0.02254447\n",
      " -0.87074447 -0.8011905   0.04052026 -0.53212166 -0.5129911  -0.2406105\n",
      " -0.68763185 -0.6408274   0.05298696 -0.7664887  -0.67392576  0.07709578\n",
      " -0.8453609  -0.7015257  -0.07085691 -0.5034025  -0.4121471  -0.20915781\n",
      " -0.6654401  -0.4597196  -0.18203782 -0.686226   -0.49666044 -0.1516882\n",
      " -0.7593391  -0.4672345  -0.16575693]\n",
      "data: [-0.05191284 -0.2230553   0.1666935  -0.2663554  -0.38318944 -0.33394217\n",
      " -0.44739014 -0.51883817 -0.14237751 -0.6758376  -0.62107253 -0.09206657\n",
      " -0.881364   -0.70383364 -0.01269543 -0.5606526  -0.62090075 -0.1331092\n",
      " -0.82084    -0.7756629  -0.24737987 -0.90154326 -0.8309078  -0.18371691\n",
      " -0.9530598  -0.85285497 -0.08208232 -0.5386392  -0.5743182  -0.17350735\n",
      " -0.741259   -0.7276361  -0.04327597 -0.8099029  -0.7739662  -0.02254448\n",
      " -0.87074447 -0.8011905   0.04052026 -0.53212166 -0.5129911  -0.24061051\n",
      " -0.68763185 -0.6408274   0.05298696 -0.7664887  -0.67392576  0.07709578\n",
      " -0.8453609  -0.70152575 -0.07085691 -0.5034025  -0.4121471  -0.20915781\n",
      " -0.6654401  -0.45971957 -0.18203782 -0.68622607 -0.4966604  -0.1516882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.7593391  -0.4672345  -0.16575693  0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0321, -0.0243, -0.1603,  ..., -0.8209, -0.2318, -0.5273],\n",
      "        [ 0.0321, -0.0243, -0.1603,  ..., -0.8209, -0.2318, -0.5273],\n",
      "        [ 0.0321, -0.0243, -0.1603,  ..., -0.8209, -0.2318, -0.5273],\n",
      "        ...,\n",
      "        [ 0.5465, -0.0594,  0.4925,  ...,  0.6660,  0.5068,  0.1962],\n",
      "        [ 0.4663, -0.1230,  0.9468,  ...,  0.3517,  0.2743,  0.4970],\n",
      "        [ 0.4663, -0.1230,  0.9468,  ...,  0.3517,  0.2743,  0.4970]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03210521 -0.02427653 -0.16030125 -0.17615207 -0.19013318 -0.74042684\n",
      " -0.3190034  -0.29671457 -0.5290947  -0.5376319  -0.3710739  -0.4927695\n",
      " -0.748541   -0.43051228 -0.40668875 -0.45579565 -0.41515264 -0.4830674\n",
      " -0.7585221  -0.5388634  -0.71686065 -0.8303558  -0.5768249  -0.6708101\n",
      " -0.85802215 -0.58929706 -0.5604739  -0.46992743 -0.35502973 -0.521081\n",
      " -0.6822112  -0.48157656 -0.40920314 -0.7679058  -0.52591753 -0.3988787\n",
      " -0.83806336 -0.526006   -0.3497014  -0.48663223 -0.2968371  -0.5889363\n",
      " -0.6535855  -0.41406152 -0.28766    -0.76602495 -0.42893127 -0.26089847\n",
      " -0.8753751  -0.44825426 -0.43988168 -0.46851838 -0.19530264 -0.5508259\n",
      " -0.6698862  -0.23347148 -0.5199418  -0.71280414 -0.26106822 -0.4943884\n",
      " -0.8208581  -0.2317708  -0.5273069 ]\n",
      "data: [ 0.03210521 -0.02427653 -0.16030125 -0.17615205 -0.19013318 -0.74042684\n",
      " -0.3190034  -0.29671457 -0.5290947  -0.5376319  -0.3710739  -0.4927695\n",
      " -0.74854106 -0.43051228 -0.40668878 -0.45579565 -0.41515264 -0.4830674\n",
      " -0.7585221  -0.5388634  -0.71686065 -0.8303558  -0.5768249  -0.6708101\n",
      " -0.85802215 -0.58929706 -0.5604739  -0.46992743 -0.3550297  -0.521081\n",
      " -0.6822112  -0.48157656 -0.40920314 -0.76790583 -0.52591753 -0.3988787\n",
      " -0.83806336 -0.526006   -0.34970137 -0.48663223 -0.2968371  -0.5889363\n",
      " -0.6535855  -0.41406152 -0.28766    -0.76602495 -0.42893127 -0.26089847\n",
      " -0.87537503 -0.44825423 -0.43988168 -0.46851838 -0.19530264 -0.5508259\n",
      " -0.6698862  -0.23347148 -0.5199418  -0.7128041  -0.26106822 -0.4943884\n",
      " -0.8208582  -0.2317708  -0.5273069   0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[-0.0935, -0.1311, -0.0709,  ..., -0.0190, -0.3163, -1.0957],\n",
      "        [-0.0935, -0.1311, -0.0709,  ..., -0.0190, -0.3163, -1.0957],\n",
      "        [-0.0935, -0.1311, -0.0709,  ..., -0.0190, -0.3163, -1.0957],\n",
      "        ...,\n",
      "        [ 0.7236,  0.0845,  0.6075,  ..., -0.1367,  0.9621,  0.1475],\n",
      "        [ 0.0395,  0.1611,  0.5097,  ..., -0.6178,  0.5988,  0.2102],\n",
      "        [ 0.0395,  0.1611,  0.5097,  ..., -0.6178,  0.5988,  0.2102]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.09348794 -0.13108867 -0.0708622  -0.08135821 -0.27132097 -0.42638826\n",
      " -0.1941276  -0.38452813 -1.0068845  -0.31727943 -0.4526649  -1.2197282\n",
      " -0.48983145 -0.526871   -1.6142294  -0.28900915 -0.66977763 -1.1621574\n",
      " -0.1845582  -0.6648903  -1.1176234  -0.16790707 -0.59526134 -1.1494292\n",
      " -0.10629983 -0.67657304 -1.1983802  -0.25525987 -0.5773103  -1.1502317\n",
      " -0.1626113  -0.62042856 -1.1080308  -0.15254013 -0.58480334 -1.1838641\n",
      "  0.03886005 -0.56259644 -1.2890955  -0.19904003 -0.5598968  -1.0282704\n",
      " -0.2216013  -0.35635158 -1.4541783  -0.09399664 -0.44493768 -1.445677\n",
      "  0.05713621 -0.40802026 -1.2056414  -0.22958079 -0.33492923 -1.0026875\n",
      " -0.19622332 -0.30204162 -1.0707804  -0.09771301 -0.28899565 -1.1956248\n",
      " -0.01896397 -0.31631395 -1.0956695 ]\n",
      "data: [-0.09348794 -0.13108867 -0.0708622  -0.08135822 -0.27132097 -0.42638823\n",
      " -0.1941276  -0.38452813 -1.0068845  -0.31727943 -0.4526649  -1.2197282\n",
      " -0.48983148 -0.526871   -1.6142294  -0.28900915 -0.66977763 -1.1621574\n",
      " -0.1845582  -0.6648903  -1.1176234  -0.16790706 -0.59526134 -1.1494292\n",
      " -0.10629983 -0.67657304 -1.1983802  -0.25525987 -0.5773103  -1.1502317\n",
      " -0.1626113  -0.62042856 -1.1080308  -0.15254013 -0.58480334 -1.1838641\n",
      "  0.03886005 -0.56259644 -1.2890954  -0.19904003 -0.5598968  -1.0282704\n",
      " -0.2216013  -0.35635158 -1.4541783  -0.09399664 -0.44493768 -1.445677\n",
      "  0.05713621 -0.40802026 -1.2056414  -0.22958079 -0.33492923 -1.0026875\n",
      " -0.19622332 -0.30204162 -1.0707804  -0.09771302 -0.28899565 -1.1956248\n",
      " -0.01896397 -0.31631395 -1.0956695   0.14      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[ 0.0785,  0.0267, -0.2483,  ...,  0.1859, -0.1518, -1.2855],\n",
      "        [ 0.0785,  0.0267, -0.2483,  ...,  0.1859, -0.1518, -1.2855],\n",
      "        [ 0.0785,  0.0267, -0.2483,  ...,  0.1859, -0.1518, -1.2855],\n",
      "        ...,\n",
      "        [-0.3601,  0.3524, -0.0911,  ..., -0.4316,  1.0776, -0.6258],\n",
      "        [-0.2142,  0.1143,  0.4469,  ..., -0.7600,  0.6851,  0.1285],\n",
      "        [-0.2142,  0.1143,  0.4469,  ..., -0.7600,  0.6851,  0.1285]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.07849728  0.02670345 -0.24827997  0.11761539 -0.11561489 -0.60596\n",
      "  0.06280877 -0.2944824  -1.3716637  -0.07797522 -0.3474572  -1.686413\n",
      " -0.23625141 -0.49647686 -2.1643162  -0.14077055 -0.550462   -1.6026249\n",
      "  0.20320103 -0.5601784  -1.3364884   0.1535762  -0.51447284 -1.3645352\n",
      "  0.15711913 -0.61831737 -1.4982394  -0.08147713 -0.4314789  -1.5039885\n",
      "  0.06273162 -0.50633526 -1.4902905   0.09957389 -0.46620718 -1.577908\n",
      "  0.24511543 -0.5383048  -1.6572603   0.05831745 -0.34727243 -1.3067349\n",
      " -0.06738407 -0.09543532 -1.9564108   0.137101   -0.2944854  -1.9297086\n",
      "  0.3252419  -0.23766968 -1.4859185  -0.08894257 -0.09508374 -1.2326952\n",
      "  0.06678353 -0.06927001 -1.2803456   0.13505217 -0.13087809 -1.4055837\n",
      "  0.18589865 -0.15180506 -1.2855375 ]\n",
      "data: [ 0.07849728  0.02670345 -0.24827997  0.11761539 -0.11561489 -0.60596\n",
      "  0.06280877 -0.2944824  -1.3716637  -0.07797522 -0.3474572  -1.6864132\n",
      " -0.23625141 -0.49647686 -2.1643162  -0.14077055 -0.550462   -1.6026248\n",
      "  0.20320103 -0.5601784  -1.3364884   0.1535762  -0.51447284 -1.3645352\n",
      "  0.15711913 -0.61831737 -1.4982394  -0.08147713 -0.4314789  -1.5039885\n",
      "  0.06273162 -0.50633526 -1.4902905   0.09957389 -0.46620715 -1.577908\n",
      "  0.24511543 -0.5383048  -1.6572603   0.05831745 -0.34727243 -1.3067349\n",
      " -0.06738407 -0.09543532 -1.9564109   0.137101   -0.2944854  -1.9297086\n",
      "  0.3252419  -0.23766968 -1.4859185  -0.08894257 -0.09508374 -1.2326952\n",
      "  0.06678353 -0.06927001 -1.2803456   0.13505217 -0.13087809 -1.4055839\n",
      "  0.18589865 -0.15180506 -1.2855374   0.15      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[ 0.0430, -0.1372, -0.3575,  ..., -0.0108, -0.2716, -1.5163],\n",
      "        [ 0.0430, -0.1372, -0.3575,  ..., -0.0108, -0.2716, -1.5163],\n",
      "        [ 0.0430, -0.1372, -0.3575,  ..., -0.0108, -0.2716, -1.5163],\n",
      "        ...,\n",
      "        [-0.2424,  0.3466, -0.0671,  ..., -0.8532,  0.8417, -0.4099],\n",
      "        [-0.1353,  0.0827,  0.5603,  ..., -0.1381,  0.8821,  0.1526],\n",
      "        [-0.1353,  0.0827,  0.5603,  ..., -0.1381,  0.8821,  0.1526]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04298944 -0.13722867 -0.35745743  0.05286254 -0.3131534  -0.88010067\n",
      "  0.02309337 -0.47309864 -1.6214386  -0.11841311 -0.5301274  -1.9536934\n",
      " -0.3134843  -0.6640891  -2.435056   -0.19428793 -0.7135745  -1.7890732\n",
      "  0.11187011 -0.7078692  -1.4729289   0.0464544  -0.6672108  -1.5273607\n",
      "  0.00256995 -0.7583833  -1.6610947  -0.15983535 -0.57941777 -1.6947044\n",
      " -0.05048344 -0.63604987 -1.6798656  -0.06899585 -0.6075971  -1.7947046\n",
      "  0.03274703 -0.6367936  -1.8740029  -0.05430447 -0.4976743  -1.5042418\n",
      " -0.1628975  -0.2717548  -2.0640202  -0.03767256 -0.4154917  -2.0390158\n",
      "  0.08855881 -0.379994   -1.6849275  -0.1674538  -0.24525522 -1.4357626\n",
      " -0.06699641 -0.22792503 -1.4876686  -0.02466114 -0.264781   -1.6057773\n",
      " -0.01084527 -0.27159223 -1.5163448 ]\n",
      "data: [ 0.04298944 -0.13722867 -0.35745743  0.05286254 -0.3131534  -0.8801006\n",
      "  0.02309337 -0.47309864 -1.6214386  -0.11841311 -0.5301274  -1.9536934\n",
      " -0.3134843  -0.664089   -2.435056   -0.19428793 -0.7135745  -1.7890732\n",
      "  0.11187011 -0.7078692  -1.4729289   0.0464544  -0.6672108  -1.5273607\n",
      "  0.00256995 -0.7583833  -1.6610947  -0.15983535 -0.57941777 -1.6947044\n",
      " -0.05048344 -0.63604987 -1.6798656  -0.06899585 -0.6075971  -1.7947046\n",
      "  0.03274703 -0.6367936  -1.8740029  -0.05430447 -0.4976743  -1.5042418\n",
      " -0.1628975  -0.2717548  -2.0640202  -0.03767256 -0.4154917  -2.0390158\n",
      "  0.08855881 -0.379994   -1.6849275  -0.16745381 -0.24525522 -1.4357626\n",
      " -0.06699641 -0.22792503 -1.4876686  -0.02466114 -0.264781   -1.6057773\n",
      " -0.01084527 -0.27159223 -1.5163448   0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B9B0>\n",
      "tensor([[ 0.0642, -0.1633, -0.1907,  ...,  0.0627, -0.3424, -1.3128],\n",
      "        [ 0.0642, -0.1633, -0.1907,  ...,  0.0627, -0.3424, -1.3128],\n",
      "        [ 0.0642, -0.1633, -0.1907,  ...,  0.0627, -0.3424, -1.3128],\n",
      "        ...,\n",
      "        [-0.0115,  0.5098, -0.1725,  ..., -0.7151,  1.0595, -0.4124],\n",
      "        [-0.2192, -0.1020,  0.5272,  ..., -0.1913,  0.5912,  0.2502],\n",
      "        [-0.2192, -0.1020,  0.5272,  ..., -0.1913,  0.5912,  0.2502]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.06416866 -0.16334614 -0.19070938  0.08303742 -0.3171605  -0.64756936\n",
      "  0.07569323 -0.4660641  -1.3501142  -0.05907074 -0.51184344 -1.6770058\n",
      " -0.22203001 -0.64993536 -2.1674573  -0.14545792 -0.73064077 -1.5640255\n",
      "  0.15072161 -0.7330731  -1.3598037   0.07353961 -0.68349105 -1.410603\n",
      "  0.05584247 -0.78469753 -1.5262932  -0.10011687 -0.61829686 -1.4747347\n",
      "  0.01634976 -0.6744822  -1.4683497  -0.01086207 -0.6508487  -1.5765331\n",
      "  0.05616976 -0.6877716  -1.6293913   0.01841296 -0.53365934 -1.2980632\n",
      " -0.08234159 -0.31749249 -1.8520151   0.03288177 -0.47379553 -1.8259219\n",
      "  0.13616896 -0.44058698 -1.4762601  -0.09663302 -0.30218288 -1.2421516\n",
      "  0.02469967 -0.29468244 -1.2977719   0.05420966 -0.3424951  -1.4056071\n",
      "  0.06268699 -0.3423561  -1.31281   ]\n",
      "data: [ 0.06416866 -0.16334614 -0.19070938  0.08303742 -0.3171605  -0.64756936\n",
      "  0.07569323 -0.4660641  -1.3501143  -0.05907074 -0.51184344 -1.6770058\n",
      " -0.22203001 -0.64993536 -2.1674573  -0.14545792 -0.73064077 -1.5640255\n",
      "  0.15072161 -0.7330731  -1.3598037   0.07353961 -0.68349105 -1.410603\n",
      "  0.05584247 -0.7846976  -1.5262932  -0.10011687 -0.61829686 -1.4747347\n",
      "  0.01634976 -0.67448217 -1.4683498  -0.01086207 -0.6508487  -1.5765331\n",
      "  0.05616976 -0.6877716  -1.6293913   0.01841296 -0.53365934 -1.2980632\n",
      " -0.08234158 -0.31749249 -1.852015    0.03288177 -0.47379553 -1.8259219\n",
      "  0.13616896 -0.44058695 -1.4762601  -0.09663302 -0.30218288 -1.2421516\n",
      "  0.02469967 -0.29468244 -1.2977719   0.05420966 -0.3424951  -1.4056071\n",
      "  0.06268699 -0.3423561  -1.31281     0.17      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FF98>\n",
      "tensor([[ 0.0465, -0.1518, -0.1644,  ...,  0.0527, -0.3399, -1.1940],\n",
      "        [ 0.0465, -0.1518, -0.1644,  ...,  0.0527, -0.3399, -1.1940],\n",
      "        [ 0.0465, -0.1518, -0.1644,  ...,  0.0527, -0.3399, -1.1940],\n",
      "        ...,\n",
      "        [-0.0760,  0.5377, -0.1320,  ..., -0.5208,  1.0409, -0.5161],\n",
      "        [-0.1889, -0.0285,  0.5617,  ..., -0.2538,  0.7014,  0.1635],\n",
      "        [-0.1889, -0.0285,  0.5617,  ..., -0.2538,  0.7014,  0.1635]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04653354 -0.15180117 -0.1643907   0.07239784 -0.27413055 -0.50495243\n",
      " -0.04730438 -0.5079526  -1.3400021  -0.20121706 -0.57781786 -1.6382239\n",
      " -0.36840633 -0.67984396 -2.1344762  -0.15619072 -0.78753734 -1.5300868\n",
      "  0.04057533 -0.85521597 -1.342948   -0.01630812 -0.79040635 -1.3869656\n",
      " -0.03515819 -0.95533055 -1.5077488  -0.10902876 -0.68644094 -1.4244775\n",
      " -0.04930216 -0.750158   -1.386828   -0.0621177  -0.7262625  -1.4735829\n",
      "  0.06077491 -0.7620763  -1.5009068  -0.02117525 -0.57415545 -1.2612923\n",
      " -0.18586853 -0.3479279  -2.0161517  -0.00535379 -0.5293398  -2.030455\n",
      "  0.15333897 -0.4827913  -1.3582311  -0.14633855 -0.3397393  -1.1826867\n",
      " -0.07340071 -0.3142486  -1.2629257  -0.03590474 -0.330402   -1.3729511\n",
      "  0.05274146 -0.33994365 -1.1940296 ]\n",
      "data: [ 0.04653354 -0.15180117 -0.1643907   0.07239784 -0.27413055 -0.50495243\n",
      " -0.04730438 -0.5079526  -1.3400022  -0.20121706 -0.57781786 -1.6382239\n",
      " -0.36840633 -0.67984396 -2.1344762  -0.15619072 -0.78753734 -1.5300869\n",
      "  0.04057533 -0.85521597 -1.342948   -0.01630812 -0.79040635 -1.3869656\n",
      " -0.03515819 -0.9553306  -1.5077488  -0.10902877 -0.68644094 -1.4244773\n",
      " -0.04930216 -0.750158   -1.386828   -0.06211771 -0.7262625  -1.4735829\n",
      "  0.06077491 -0.7620763  -1.5009068  -0.02117525 -0.57415545 -1.2612923\n",
      " -0.18586853 -0.3479279  -2.0161517  -0.00535379 -0.5293398  -2.030455\n",
      "  0.15333897 -0.4827913  -1.3582311  -0.14633855 -0.3397393  -1.1826867\n",
      " -0.07340071 -0.3142486  -1.2629257  -0.03590474 -0.330402   -1.3729511\n",
      "  0.05274146 -0.33994365 -1.1940296   0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0170, -0.1092, -0.2035,  ...,  0.0454, -0.2893, -1.1994],\n",
      "        [-0.0170, -0.1092, -0.2035,  ...,  0.0454, -0.2893, -1.1994],\n",
      "        [-0.0170, -0.1092, -0.2035,  ...,  0.0454, -0.2893, -1.1994],\n",
      "        ...,\n",
      "        [-0.1423,  0.4054, -0.0213,  ..., -0.6657,  1.0243, -0.4668],\n",
      "        [-0.0707, -0.0075,  0.6413,  ..., -0.1913,  0.6681,  0.2793],\n",
      "        [-0.0707, -0.0075,  0.6413,  ..., -0.1913,  0.6681,  0.2793]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.0169681  -0.10921041 -0.2035482   0.01545404 -0.23726472 -0.49577418\n",
      " -0.08383103 -0.45475084 -1.3400081  -0.2375625  -0.516417   -1.6503489\n",
      " -0.40759963 -0.6431359  -2.144284   -0.2306916  -0.72865224 -1.5425026\n",
      "  0.03091525 -0.7752961  -1.3465613  -0.02945989 -0.718638   -1.3830212\n",
      " -0.02771664 -0.85695124 -1.5113229  -0.1719032  -0.6195968  -1.4313139\n",
      " -0.07473605 -0.68637305 -1.4105603  -0.06015553 -0.65259945 -1.5051389\n",
      "  0.07369116 -0.7048358  -1.5500939  -0.0579521  -0.51463884 -1.2453623\n",
      " -0.21186706 -0.27504116 -1.9840974  -0.01087238 -0.4643395  -1.9838774\n",
      "  0.16935895 -0.41458493 -1.3872052  -0.19837199 -0.26953813 -1.1715727\n",
      " -0.08274443 -0.24778247 -1.2427837  -0.03285593 -0.28191674 -1.3582247\n",
      "  0.04544447 -0.28930998 -1.1993834 ]\n",
      "data: [-0.0169681  -0.1092104  -0.20354821  0.01545404 -0.23726472 -0.49577418\n",
      " -0.08383103 -0.45475084 -1.3400081  -0.2375625  -0.516417   -1.650349\n",
      " -0.40759963 -0.6431359  -2.144284   -0.23069161 -0.72865224 -1.5425026\n",
      "  0.03091525 -0.7752961  -1.3465613  -0.02945989 -0.718638   -1.3830212\n",
      " -0.02771664 -0.85695124 -1.5113227  -0.1719032  -0.6195968  -1.431314\n",
      " -0.07473605 -0.68637305 -1.4105603  -0.06015553 -0.6525995  -1.5051389\n",
      "  0.07369116 -0.7048357  -1.5500939  -0.0579521  -0.51463884 -1.2453623\n",
      " -0.21186706 -0.27504116 -1.9840972  -0.01087238 -0.4643395  -1.9838774\n",
      "  0.16935895 -0.41458493 -1.3872052  -0.19837198 -0.26953813 -1.1715727\n",
      " -0.08274443 -0.24778248 -1.2427837  -0.03285593 -0.28191674 -1.3582247\n",
      "  0.04544447 -0.28930998 -1.1993834   0.19      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[-0.0174, -0.1010, -0.2219,  ...,  0.0119, -0.2626, -1.2801],\n",
      "        [-0.0174, -0.1010, -0.2219,  ...,  0.0119, -0.2626, -1.2801],\n",
      "        [-0.0174, -0.1010, -0.2219,  ...,  0.0119, -0.2626, -1.2801],\n",
      "        ...,\n",
      "        [-0.1666,  0.3718, -0.1021,  ..., -0.6876,  0.9159, -0.4292],\n",
      "        [-0.0920, -0.0701,  0.6567,  ..., -0.2055,  0.6598,  0.2822],\n",
      "        [-0.0920, -0.0701,  0.6567,  ..., -0.2055,  0.6598,  0.2822]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01740042 -0.10099137 -0.22186972  0.00435245 -0.2493877  -0.5991764\n",
      " -0.06193729 -0.44445765 -1.378444   -0.2065452  -0.50246406 -1.6985723\n",
      " -0.39229    -0.63664806 -2.1662955  -0.24336903 -0.7036358  -1.566015\n",
      "  0.04283658 -0.72791886 -1.3283578  -0.01266754 -0.68263584 -1.3681954\n",
      " -0.01769295 -0.80181396 -1.4962821  -0.18996987 -0.5812617  -1.4627659\n",
      " -0.08269212 -0.64773774 -1.4461579  -0.06727628 -0.61928827 -1.5528532\n",
      "  0.06292272 -0.6643096  -1.623432   -0.07745039 -0.48610452 -1.2762836\n",
      " -0.21194918 -0.258153   -1.9480014  -0.03016894 -0.42972606 -1.9359256\n",
      "  0.13602726 -0.38210285 -1.4532993  -0.20778824 -0.23635946 -1.2106134\n",
      " -0.09568304 -0.21694192 -1.2802725  -0.0403277  -0.25612688 -1.400624\n",
      "  0.01192794 -0.26258415 -1.280058  ]\n",
      "data: [-0.01740042 -0.10099136 -0.22186972  0.00435245 -0.2493877  -0.5991764\n",
      " -0.06193729 -0.44445765 -1.378444   -0.2065452  -0.50246406 -1.6985723\n",
      " -0.39229    -0.63664806 -2.1662955  -0.24336903 -0.7036358  -1.566015\n",
      "  0.04283658 -0.72791886 -1.3283578  -0.01266754 -0.6826359  -1.3681953\n",
      " -0.01769295 -0.80181396 -1.4962821  -0.18996987 -0.5812617  -1.4627659\n",
      " -0.08269212 -0.64773774 -1.4461579  -0.06727628 -0.61928827 -1.5528532\n",
      "  0.06292272 -0.6643096  -1.623432   -0.07745039 -0.48610452 -1.2762836\n",
      " -0.21194917 -0.258153   -1.9480014  -0.03016894 -0.42972606 -1.9359256\n",
      "  0.13602726 -0.38210285 -1.4532993  -0.20778824 -0.23635946 -1.2106134\n",
      " -0.09568304 -0.21694192 -1.2802725  -0.0403277  -0.25612688 -1.400624\n",
      "  0.01192794 -0.26258415 -1.280058    0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0031, -0.0814, -0.2405,  ...,  0.0329, -0.2608, -1.2804],\n",
      "        [-0.0031, -0.0814, -0.2405,  ...,  0.0329, -0.2608, -1.2804],\n",
      "        [-0.0031, -0.0814, -0.2405,  ...,  0.0329, -0.2608, -1.2804],\n",
      "        ...,\n",
      "        [-0.2130,  0.3851, -0.1762,  ..., -0.7650,  0.9111, -0.4918],\n",
      "        [-0.1218, -0.1256,  0.6510,  ..., -0.2091,  0.6166,  0.2999],\n",
      "        [-0.1218, -0.1256,  0.6510,  ..., -0.2091,  0.6166,  0.2999]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.00313354 -0.08137254 -0.24045369  0.01704896 -0.21632741 -0.62174886\n",
      " -0.07478658 -0.41201147 -1.3927718  -0.22100548 -0.47357583 -1.6972061\n",
      " -0.39077    -0.5914575  -2.1739244  -0.21356183 -0.6940211  -1.561339\n",
      "  0.01722971 -0.729962   -1.3674178  -0.03731374 -0.6700609  -1.4170699\n",
      " -0.04228925 -0.80643463 -1.5399486  -0.16493632 -0.5893165  -1.4669513\n",
      " -0.07870938 -0.64675856 -1.447795   -0.07966281 -0.61563754 -1.5442991\n",
      "  0.05191793 -0.65016234 -1.5906775  -0.06602035 -0.49322385 -1.293289\n",
      " -0.19229327 -0.2644831  -1.9567556  -0.02303444 -0.4272367  -1.9580162\n",
      "  0.14135423 -0.38787052 -1.4441407  -0.1820274  -0.25554314 -1.225396\n",
      " -0.09056342 -0.23261209 -1.3091432  -0.04492001 -0.2522105  -1.4268593\n",
      "  0.0329274  -0.26083785 -1.2804285 ]\n",
      "data: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "mask: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[-0.0333,  0.0448,  0.4349,  ..., -0.2319, -0.0727, -0.3665],\n",
      "        [-0.0333,  0.0448,  0.4349,  ..., -0.2319, -0.0727, -0.3665],\n",
      "        [-0.0333,  0.0448,  0.4349,  ..., -0.2319, -0.0727, -0.3665],\n",
      "        ...,\n",
      "        [ 0.3777,  0.0338, -0.4249,  ...,  0.2617,  0.7308, -0.4466],\n",
      "        [ 0.3953,  0.0267, -0.4035,  ...,  0.2826,  0.7878, -0.4917],\n",
      "        [ 0.3953,  0.0267, -0.4035,  ...,  0.2826,  0.7878, -0.4917]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.03331171  0.04475227  0.43488228 -0.08014037 -0.1283966   0.04251438\n",
      " -0.43275732 -0.30288675 -0.52919793 -0.6339379  -0.4416606  -0.64817005\n",
      " -0.92006445 -0.45257625 -1.0338042  -0.32898337 -0.5638237  -0.5347692\n",
      " -0.48484027 -0.5967127  -0.22969621 -0.4647954  -0.4992316  -0.28106982\n",
      " -0.5385193  -0.63992906 -0.29921997 -0.30783296 -0.44557652 -0.56127876\n",
      " -0.40865445 -0.4935944  -0.37488335 -0.53361404 -0.46619457 -0.43082047\n",
      " -0.28280222 -0.36111313 -0.51204956 -0.349191   -0.46142566 -0.4435553\n",
      " -0.3940547  -0.24101767 -0.6121369  -0.40089983 -0.258882   -0.64137584\n",
      " -0.26609105 -0.26819363 -0.39044648 -0.29307145 -0.20285279 -0.41877973\n",
      " -0.48265147 -0.14345443 -0.4460817  -0.39757866 -0.02279501 -0.5691981\n",
      " -0.23187025 -0.07268029 -0.3664986 ]\n",
      "init: [-0.03331171  0.04475227  0.43488228 -0.08014037 -0.1283966   0.04251438\n",
      " -0.43275732 -0.30288675 -0.52919793 -0.6339379  -0.4416606  -0.64817005\n",
      " -0.92006445 -0.45257625 -1.0338042  -0.32898337 -0.5638237  -0.5347692\n",
      " -0.48484027 -0.5967127  -0.22969621 -0.4647954  -0.4992316  -0.28106982\n",
      " -0.5385193  -0.63992906 -0.29921997 -0.30783296 -0.44557652 -0.56127876\n",
      " -0.40865445 -0.4935944  -0.37488335 -0.53361404 -0.46619457 -0.43082047\n",
      " -0.28280222 -0.36111313 -0.51204956 -0.349191   -0.46142566 -0.4435553\n",
      " -0.3940547  -0.24101767 -0.6121369  -0.40089983 -0.258882   -0.64137584\n",
      " -0.26609105 -0.26819363 -0.39044648 -0.29307145 -0.20285279 -0.41877973\n",
      " -0.48265147 -0.14345443 -0.4460817  -0.39757866 -0.02279501 -0.5691981\n",
      " -0.23187025 -0.07268029 -0.3664986 ]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [-0.03331171  0.04475227  0.43488228 -0.08014037 -0.1283966   0.04251438\n",
      " -0.4327573  -0.30288675 -0.52919793 -0.6339379  -0.4416606  -0.6481701\n",
      " -0.92006445 -0.45257625 -1.0338042  -0.3289834  -0.5638237  -0.5347692\n",
      " -0.48484027 -0.5967127  -0.22969621 -0.4647954  -0.4992316  -0.28106982\n",
      " -0.5385193  -0.63992906 -0.29921997 -0.30783296 -0.44557652 -0.56127876\n",
      " -0.40865445 -0.4935944  -0.37488335 -0.53361404 -0.46619457 -0.43082047\n",
      " -0.28280222 -0.36111313 -0.51204956 -0.349191   -0.46142566 -0.4435553\n",
      " -0.3940547  -0.24101767 -0.6121369  -0.4008998  -0.258882   -0.6413758\n",
      " -0.26609105 -0.26819363 -0.39044648 -0.29307145 -0.20285279 -0.41877973\n",
      " -0.48265147 -0.14345443 -0.4460817  -0.39757866 -0.02279501 -0.5691981\n",
      " -0.23187025 -0.07268029 -0.3664986   0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[ 0.0976, -0.1282, -0.0014,  ..., -0.1768, -0.3206, -0.4777],\n",
      "        [ 0.0976, -0.1282, -0.0014,  ..., -0.1768, -0.3206, -0.4777],\n",
      "        [ 0.0976, -0.1282, -0.0014,  ..., -0.1768, -0.3206, -0.4777],\n",
      "        ...,\n",
      "        [ 0.3807, -0.3220,  0.1800,  ...,  0.0255,  0.4814, -0.7080],\n",
      "        [ 0.2470, -0.0607,  0.3909,  ..., -0.2374,  0.5988, -0.3907],\n",
      "        [ 0.2470, -0.0607,  0.3909,  ..., -0.2374,  0.5988, -0.3907]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.09764333 -0.12818111 -0.00139142  0.01448007 -0.21023431 -0.21530163\n",
      " -0.19374429 -0.3714562  -0.6253542  -0.37554568 -0.43195403 -0.8070229\n",
      " -0.6704508  -0.44929424 -1.1941503  -0.23161386 -0.6267141  -0.80595434\n",
      " -0.49900675 -0.64790744 -1.1695795  -0.50235474 -0.5776095  -1.1860143\n",
      " -0.41920716 -0.7813401  -1.1322979  -0.17645065 -0.54897135 -0.7414032\n",
      " -0.28347117 -0.59008485 -0.56041884 -0.39183152 -0.6059165  -0.66071415\n",
      " -0.27003443 -0.5561799  -0.7184459  -0.17070954 -0.496056   -0.6637727\n",
      " -0.30694145 -0.41535404 -0.9040673  -0.271919   -0.47494265 -0.9372133\n",
      " -0.24233057 -0.4594384  -0.5834764  -0.14623041 -0.35705602 -0.6308223\n",
      " -0.28953373 -0.35680002 -0.5369657  -0.25904596 -0.32209873 -0.6326524\n",
      " -0.17676057 -0.32056063 -0.47769672]\n",
      "data: [ 0.09764333 -0.12818111 -0.00139142  0.01448007 -0.21023431 -0.21530163\n",
      " -0.19374427 -0.37145624 -0.6253542  -0.37554568 -0.43195403 -0.8070229\n",
      " -0.6704508  -0.44929424 -1.1941503  -0.23161386 -0.6267141  -0.80595434\n",
      " -0.49900672 -0.64790744 -1.1695795  -0.50235474 -0.5776095  -1.1860143\n",
      " -0.41920716 -0.7813401  -1.1322979  -0.17645065 -0.54897135 -0.7414032\n",
      " -0.28347117 -0.59008485 -0.56041884 -0.39183152 -0.6059165  -0.6607141\n",
      " -0.27003443 -0.5561799  -0.7184459  -0.17070954 -0.496056   -0.66377276\n",
      " -0.30694145 -0.41535404 -0.9040673  -0.271919   -0.47494265 -0.9372133\n",
      " -0.24233057 -0.4594384  -0.5834764  -0.14623041 -0.35705602 -0.6308223\n",
      " -0.28953373 -0.3568     -0.5369657  -0.25904596 -0.32209873 -0.6326524\n",
      " -0.17676058 -0.32056063 -0.47769672  0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[ 0.0900,  0.1017, -0.2073,  ...,  0.3068, -0.1375, -1.1475],\n",
      "        [ 0.0900,  0.1017, -0.2073,  ...,  0.3068, -0.1375, -1.1475],\n",
      "        [ 0.0900,  0.1017, -0.2073,  ...,  0.3068, -0.1375, -1.1475],\n",
      "        ...,\n",
      "        [ 0.1401, -0.4187,  0.1613,  ...,  0.3673,  0.7864, -0.4577],\n",
      "        [-0.1169,  0.0864,  0.2130,  ..., -0.8328,  0.7281, -0.1858],\n",
      "        [-0.1169,  0.0864,  0.2130,  ..., -0.8328,  0.7281, -0.1858]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.09004354  0.10170863 -0.2072531   0.10468787  0.00330134 -0.5347936\n",
      "  0.00726356 -0.16720459 -1.1657598  -0.10037886 -0.2120057  -1.4103525\n",
      " -0.22976235 -0.3165544  -1.8076682  -0.07890822 -0.4489165  -1.3445523\n",
      "  0.10811283 -0.4684853  -1.2729223   0.13283332 -0.36777702 -1.302366\n",
      "  0.21368803 -0.50388235 -1.3826895  -0.02680372 -0.36518514 -1.2833881\n",
      "  0.09790829 -0.41684842 -1.2526379   0.16122824 -0.3782552  -1.2983732\n",
      "  0.37268096 -0.39036024 -1.3855743   0.09173962 -0.3243102  -1.1600358\n",
      "  0.02003389 -0.08915249 -1.7330775   0.2276017  -0.2581452  -1.7140632\n",
      "  0.43774143 -0.18318337 -1.3041556  -0.00486229 -0.11566274 -1.0981929\n",
      "  0.09842834 -0.07345021 -1.1778378   0.20156622 -0.10605052 -1.2936413\n",
      "  0.30680764 -0.13745171 -1.1474593 ]\n",
      "data: [ 0.09004354  0.10170863 -0.2072531   0.10468787  0.00330134 -0.5347936\n",
      "  0.00726356 -0.16720459 -1.1657598  -0.10037886 -0.2120057  -1.4103525\n",
      " -0.22976235 -0.3165544  -1.8076682  -0.07890822 -0.44891652 -1.3445523\n",
      "  0.10811283 -0.4684853  -1.2729223   0.13283332 -0.36777702 -1.302366\n",
      "  0.21368803 -0.50388235 -1.3826895  -0.02680372 -0.36518514 -1.283388\n",
      "  0.09790829 -0.41684842 -1.2526379   0.16122824 -0.3782552  -1.2983732\n",
      "  0.37268096 -0.39036024 -1.3855743   0.09173962 -0.3243102  -1.1600358\n",
      "  0.02003389 -0.08915249 -1.7330775   0.2276017  -0.2581452  -1.7140632\n",
      "  0.43774143 -0.18318337 -1.3041556  -0.00486229 -0.11566274 -1.0981929\n",
      "  0.09842834 -0.07345021 -1.1778378   0.20156622 -0.10605052 -1.2936413\n",
      "  0.30680764 -0.13745171 -1.1474593   0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BB38>\n",
      "tensor([[ 0.1626, -0.2447, -0.2165,  ...,  0.1342, -0.3837, -1.3979],\n",
      "        [ 0.1626, -0.2447, -0.2165,  ...,  0.1342, -0.3837, -1.3979],\n",
      "        [ 0.1626, -0.2447, -0.2165,  ...,  0.1342, -0.3837, -1.3979],\n",
      "        ...,\n",
      "        [-0.3962,  0.3155, -0.2418,  ..., -0.9098,  0.8485, -0.5920],\n",
      "        [-0.1954,  0.1442,  0.4025,  ..., -0.1335,  0.9645,  0.0509],\n",
      "        [-0.1954,  0.1442,  0.4025,  ..., -0.1335,  0.9645,  0.0509]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.16259731 -0.24474892 -0.21654204  0.17051058 -0.42394608 -0.75639176\n",
      "  0.1134444  -0.5734697  -1.4409375  -0.03744851 -0.6310879  -1.7440678\n",
      " -0.24560687 -0.75492847 -2.2096317  -0.07778284 -0.8134382  -1.6215749\n",
      "  0.17727114 -0.8176117  -1.3409047   0.13588884 -0.75505805 -1.3899015\n",
      "  0.12326978 -0.8522508  -1.492666   -0.03816712 -0.68302584 -1.5522274\n",
      "  0.0609953  -0.7390543  -1.5093521   0.04989593 -0.7221918  -1.6149815\n",
      "  0.17674719 -0.7207309  -1.6925542   0.05065572 -0.6286533  -1.3766742\n",
      " -0.02669583 -0.39854333 -1.8704634   0.09021126 -0.5355292  -1.8423752\n",
      "  0.22470109 -0.49820426 -1.535238   -0.03708974 -0.37536836 -1.3240654\n",
      "  0.03305179 -0.35118255 -1.382289    0.09875719 -0.37684909 -1.4995192\n",
      "  0.13417494 -0.3836607  -1.3978517 ]\n",
      "data: [ 0.16259731 -0.24474892 -0.21654204  0.17051058 -0.42394608 -0.75639176\n",
      "  0.1134444  -0.5734697  -1.4409375  -0.03744851 -0.6310879  -1.7440678\n",
      " -0.24560685 -0.7549284  -2.2096317  -0.07778284 -0.8134382  -1.6215749\n",
      "  0.17727114 -0.8176117  -1.3409047   0.13588884 -0.75505805 -1.3899016\n",
      "  0.12326977 -0.8522508  -1.492666   -0.03816712 -0.68302584 -1.5522274\n",
      "  0.0609953  -0.7390543  -1.5093521   0.04989593 -0.72219175 -1.6149815\n",
      "  0.17674719 -0.7207309  -1.6925541   0.05065572 -0.6286533  -1.3766742\n",
      " -0.02669583 -0.39854333 -1.8704634   0.09021126 -0.5355292  -1.8423752\n",
      "  0.2247011  -0.49820426 -1.535238   -0.03708974 -0.37536836 -1.3240654\n",
      "  0.03305179 -0.35118255 -1.3822892   0.09875719 -0.37684909 -1.4995192\n",
      "  0.13417494 -0.3836607  -1.3978517   0.04      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[-0.0014, -0.2214, -0.1263,  ...,  0.0219, -0.4075, -1.1864],\n",
      "        [-0.0014, -0.2214, -0.1263,  ...,  0.0219, -0.4075, -1.1864],\n",
      "        [-0.0014, -0.2214, -0.1263,  ...,  0.0219, -0.4075, -1.1864],\n",
      "        ...,\n",
      "        [ 0.0067,  0.6645, -0.2338,  ..., -0.3585,  1.1325, -0.6183],\n",
      "        [-0.0874,  0.0135,  0.6353,  ..., -0.0416,  0.7029,  0.2584],\n",
      "        [-0.0874,  0.0135,  0.6353,  ..., -0.0416,  0.7029,  0.2584]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-1.3944982e-03 -2.2139496e-01 -1.2627394e-01  2.3896504e-02\n",
      " -3.5566261e-01 -4.8942316e-01 -6.1672233e-02 -5.7245290e-01\n",
      " -1.3055301e+00 -2.1586958e-01 -6.4056301e-01 -1.6239984e+00\n",
      " -3.9545536e-01 -7.6506054e-01 -2.1170881e+00 -2.1994479e-01\n",
      " -8.3480060e-01 -1.5171304e+00  3.2335058e-02 -8.9029098e-01\n",
      " -1.2990570e+00 -3.5176113e-02 -8.3683205e-01 -1.3376410e+00\n",
      " -5.8789648e-02 -9.8474634e-01 -1.4589331e+00 -1.6269988e-01\n",
      " -7.2757673e-01 -1.4053984e+00 -8.0031395e-02 -8.0164874e-01\n",
      " -1.3744018e+00 -9.1910936e-02 -7.8105390e-01 -1.4764490e+00\n",
      "  1.6207248e-02 -8.2567239e-01 -1.5186138e+00 -5.7775117e-02\n",
      " -6.2455750e-01 -1.2261112e+00 -2.0671402e-01 -4.0292698e-01\n",
      " -1.9258494e+00 -3.7350178e-02 -5.8595496e-01 -1.9243019e+00\n",
      "  1.1297764e-01 -5.4334009e-01 -1.3564241e+00 -1.8654317e-01\n",
      " -3.8413808e-01 -1.1533756e+00 -8.6353734e-02 -3.6845621e-01\n",
      " -1.2241373e+00 -4.1480303e-02 -4.0528905e-01 -1.3338790e+00\n",
      "  2.1869339e-02 -4.0752119e-01 -1.1863778e+00]\n",
      "data: [-1.3944982e-03 -2.2139496e-01 -1.2627394e-01  2.3896504e-02\n",
      " -3.5566261e-01 -4.8942316e-01 -6.1672233e-02 -5.7245290e-01\n",
      " -1.3055301e+00 -2.1586958e-01 -6.4056307e-01 -1.6239984e+00\n",
      " -3.9545536e-01 -7.6506060e-01 -2.1170881e+00 -2.1994478e-01\n",
      " -8.3480054e-01 -1.5171304e+00  3.2335058e-02 -8.9029098e-01\n",
      " -1.2990570e+00 -3.5176113e-02 -8.3683205e-01 -1.3376410e+00\n",
      " -5.8789648e-02 -9.8474634e-01 -1.4589331e+00 -1.6269988e-01\n",
      " -7.2757673e-01 -1.4053984e+00 -8.0031395e-02 -8.0164874e-01\n",
      " -1.3744018e+00 -9.1910936e-02 -7.8105390e-01 -1.4764490e+00\n",
      "  1.6207248e-02 -8.2567239e-01 -1.5186139e+00 -5.7775117e-02\n",
      " -6.2455750e-01 -1.2261112e+00 -2.0671402e-01 -4.0292698e-01\n",
      " -1.9258494e+00 -3.7350178e-02 -5.8595496e-01 -1.9243019e+00\n",
      "  1.1297764e-01 -5.4334009e-01 -1.3564241e+00 -1.8654317e-01\n",
      " -3.8413808e-01 -1.1533756e+00 -8.6353734e-02 -3.6845624e-01\n",
      " -1.2241373e+00 -4.1480303e-02 -4.0528905e-01 -1.3338790e+00\n",
      "  2.1869339e-02 -4.0752116e-01 -1.1863778e+00  5.0000001e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0126, -0.0440, -0.2498,  ..., -0.0144, -0.2194, -1.2621],\n",
      "        [-0.0126, -0.0440, -0.2498,  ..., -0.0144, -0.2194, -1.2621],\n",
      "        [-0.0126, -0.0440, -0.2498,  ..., -0.0144, -0.2194, -1.2621],\n",
      "        ...,\n",
      "        [-0.1622,  0.4425,  0.0162,  ..., -0.4609,  1.0799, -0.4565],\n",
      "        [ 0.0126,  0.0322,  0.7024,  ..., -0.0314,  0.6517,  0.3784],\n",
      "        [ 0.0126,  0.0322,  0.7024,  ..., -0.0314,  0.6517,  0.3784]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01260016 -0.04402129 -0.24975152  0.01478846 -0.15472816 -0.5266131\n",
      " -0.12502363 -0.39141747 -1.3883462  -0.28649244 -0.4564404  -1.6764512\n",
      " -0.44515777 -0.5470189  -2.1928806  -0.21939155 -0.6873365  -1.5933857\n",
      " -0.04077457 -0.75610626 -1.4431407  -0.09004906 -0.6806608  -1.4832897\n",
      " -0.08545484 -0.8435774  -1.6042371  -0.17609191 -0.5906966  -1.4917936\n",
      " -0.11457139 -0.64559436 -1.4508238  -0.11473942 -0.609194   -1.5363119\n",
      "  0.02967812 -0.6430152  -1.5548451  -0.08876392 -0.47219065 -1.336669\n",
      " -0.25466174 -0.23785785 -2.0866678  -0.06368307 -0.41475224 -2.1103518\n",
      "  0.1194841  -0.36610073 -1.4301422  -0.22323063 -0.2350219  -1.257385\n",
      " -0.15236887 -0.2039865  -1.3396013  -0.12047899 -0.21180402 -1.4516761\n",
      " -0.01440995 -0.21942571 -1.2620718 ]\n",
      "data: [-0.01260016 -0.04402129 -0.24975152  0.01478846 -0.15472816 -0.5266131\n",
      " -0.12502363 -0.39141747 -1.3883462  -0.28649244 -0.4564404  -1.6764512\n",
      " -0.44515777 -0.5470189  -2.1928806  -0.21939155 -0.6873365  -1.5933856\n",
      " -0.04077457 -0.75610626 -1.4431407  -0.09004906 -0.6806608  -1.4832898\n",
      " -0.08545484 -0.84357744 -1.6042371  -0.17609192 -0.5906966  -1.4917936\n",
      " -0.11457139 -0.64559436 -1.4508238  -0.11473942 -0.609194   -1.5363117\n",
      "  0.02967812 -0.6430152  -1.5548451  -0.08876392 -0.47219068 -1.336669\n",
      " -0.25466174 -0.23785786 -2.0866678  -0.06368307 -0.41475224 -2.1103518\n",
      "  0.1194841  -0.36610073 -1.4301422  -0.22323063 -0.23502189 -1.257385\n",
      " -0.15236887 -0.2039865  -1.3396013  -0.120479   -0.211804   -1.4516761\n",
      " -0.01440995 -0.21942572 -1.2620718   0.06      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0241, -0.0234, -0.1925,  ...,  0.0487, -0.2037, -1.2475],\n",
      "        [ 0.0241, -0.0234, -0.1925,  ...,  0.0487, -0.2037, -1.2475],\n",
      "        [ 0.0241, -0.0234, -0.1925,  ...,  0.0487, -0.2037, -1.2475],\n",
      "        ...,\n",
      "        [-0.2241,  0.2757, -0.0837,  ..., -0.8886,  0.7851, -0.3009],\n",
      "        [-0.1668, -0.1511,  0.5197,  ..., -0.2715,  0.5750,  0.2545],\n",
      "        [-0.1668, -0.1511,  0.5197,  ..., -0.2715,  0.5750,  0.2545]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.4095450e-02 -2.3397317e-02 -1.9246504e-01  3.6783312e-02\n",
      " -1.6441725e-01 -6.0392940e-01 -4.2973556e-02 -3.3719155e-01\n",
      " -1.3340273e+00 -1.8918999e-01 -3.9412382e-01 -1.6379774e+00\n",
      " -3.6821616e-01 -5.1253116e-01 -2.1097999e+00 -1.8746799e-01\n",
      " -6.2799186e-01 -1.4924631e+00  4.1402489e-02 -6.5166652e-01\n",
      " -1.3033230e+00 -1.1073619e-02 -5.8972663e-01 -1.3564935e+00\n",
      " -7.5356439e-03 -7.1693379e-01 -1.4738281e+00 -1.4160079e-01\n",
      " -5.2175683e-01 -1.4072740e+00 -5.0551347e-02 -5.7420695e-01\n",
      " -1.3881953e+00 -5.4612584e-02 -5.4588443e-01 -1.4897521e+00\n",
      "  7.8031853e-02 -5.7079208e-01 -1.5400798e+00 -4.5987733e-02\n",
      " -4.3723911e-01 -1.2351930e+00 -1.5537095e-01 -2.0841861e-01\n",
      " -1.8606520e+00 -5.9393793e-04 -3.6003166e-01 -1.8570783e+00\n",
      "  1.5815663e-01 -3.2823038e-01 -1.3971918e+00 -1.5282506e-01\n",
      " -1.9761012e-01 -1.1739750e+00 -6.6620931e-02 -1.7802325e-01\n",
      " -1.2591355e+00 -2.2320703e-02 -1.9408941e-01 -1.3791182e+00\n",
      "  4.8713304e-02 -2.0370828e-01 -1.2475183e+00]\n",
      "data: [ 2.4095450e-02 -2.3397317e-02 -1.9246504e-01  3.6783312e-02\n",
      " -1.6441725e-01 -6.0392940e-01 -4.2973556e-02 -3.3719155e-01\n",
      " -1.3340273e+00 -1.8918999e-01 -3.9412385e-01 -1.6379772e+00\n",
      " -3.6821616e-01 -5.1253116e-01 -2.1097999e+00 -1.8746799e-01\n",
      " -6.2799186e-01 -1.4924631e+00  4.1402489e-02 -6.5166646e-01\n",
      " -1.3033230e+00 -1.1073619e-02 -5.8972663e-01 -1.3564935e+00\n",
      " -7.5356434e-03 -7.1693385e-01 -1.4738281e+00 -1.4160079e-01\n",
      " -5.2175683e-01 -1.4072740e+00 -5.0551347e-02 -5.7420695e-01\n",
      " -1.3881954e+00 -5.4612584e-02 -5.4588443e-01 -1.4897521e+00\n",
      "  7.8031853e-02 -5.7079208e-01 -1.5400798e+00 -4.5987736e-02\n",
      " -4.3723911e-01 -1.2351930e+00 -1.5537095e-01 -2.0841862e-01\n",
      " -1.8606520e+00 -5.9393793e-04 -3.6003166e-01 -1.8570782e+00\n",
      "  1.5815663e-01 -3.2823035e-01 -1.3971918e+00 -1.5282506e-01\n",
      " -1.9761012e-01 -1.1739750e+00 -6.6620931e-02 -1.7802325e-01\n",
      " -1.2591355e+00 -2.2320703e-02 -1.9408941e-01 -1.3791182e+00\n",
      "  4.8713304e-02 -2.0370826e-01 -1.2475183e+00  7.0000000e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B320>\n",
      "tensor([[ 0.0102, -0.0693, -0.2598,  ...,  0.0176, -0.2459, -1.3157],\n",
      "        [ 0.0102, -0.0693, -0.2598,  ...,  0.0176, -0.2459, -1.3157],\n",
      "        [ 0.0102, -0.0693, -0.2598,  ...,  0.0176, -0.2459, -1.3157],\n",
      "        ...,\n",
      "        [-0.3330,  0.2517, -0.2988,  ..., -0.7963,  0.7065, -0.4631],\n",
      "        [-0.1239, -0.0322,  0.6275,  ..., -0.2299,  0.7668,  0.3044],\n",
      "        [-0.1239, -0.0322,  0.6275,  ..., -0.2299,  0.7668,  0.3044]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01024572 -0.06931494 -0.2598051   0.03312368 -0.2075434  -0.68211603\n",
      " -0.07930832 -0.39508712 -1.4422097  -0.22210291 -0.460741   -1.7198243\n",
      " -0.37954766 -0.5575431  -2.203863   -0.18865076 -0.6795629  -1.5934205\n",
      " -0.01316372 -0.71378154 -1.4135439  -0.0533497  -0.6419605  -1.4709892\n",
      " -0.05412048 -0.7772885  -1.5830765  -0.15499717 -0.5786366  -1.5188525\n",
      " -0.08566172 -0.6265348  -1.4798243  -0.102837   -0.59772456 -1.5636504\n",
      "  0.03792007 -0.6093027  -1.6019843  -0.08149062 -0.4948063  -1.3575823\n",
      " -0.18831497 -0.26535553 -1.9734454  -0.04275692 -0.40987033 -1.9808154\n",
      "  0.11367745 -0.37895876 -1.4695594  -0.17289576 -0.26083225 -1.2903743\n",
      " -0.11604499 -0.23133117 -1.3662765  -0.07049152 -0.23005366 -1.482204\n",
      "  0.01759061 -0.24590851 -1.3157165 ]\n",
      "data: [ 0.01024572 -0.06931494 -0.2598051   0.03312368 -0.20754342 -0.68211603\n",
      " -0.07930832 -0.39508712 -1.4422097  -0.22210291 -0.460741   -1.7198243\n",
      " -0.37954766 -0.5575431  -2.203863   -0.18865076 -0.6795629  -1.5934205\n",
      " -0.01316372 -0.71378154 -1.413544   -0.0533497  -0.6419605  -1.4709892\n",
      " -0.05412048 -0.7772885  -1.5830765  -0.15499717 -0.5786366  -1.5188526\n",
      " -0.08566172 -0.6265348  -1.4798244  -0.102837   -0.59772456 -1.5636504\n",
      "  0.03792007 -0.6093027  -1.6019843  -0.08149062 -0.4948063  -1.3575824\n",
      " -0.18831497 -0.26535553 -1.9734454  -0.04275693 -0.40987033 -1.9808154\n",
      "  0.11367746 -0.3789588  -1.4695594  -0.17289576 -0.26083225 -1.2903743\n",
      " -0.11604499 -0.23133117 -1.3662765  -0.07049152 -0.23005368 -1.482204\n",
      "  0.01759061 -0.24590851 -1.3157165   0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[ 0.0310, -0.0370, -0.2254,  ...,  0.0422, -0.2325, -1.2599],\n",
      "        [ 0.0310, -0.0370, -0.2254,  ...,  0.0422, -0.2325, -1.2599],\n",
      "        [ 0.0310, -0.0370, -0.2254,  ...,  0.0422, -0.2325, -1.2599],\n",
      "        ...,\n",
      "        [-0.1242,  0.4261, -0.1213,  ..., -0.7403,  0.9402, -0.3746],\n",
      "        [-0.1425, -0.1996,  0.5466,  ..., -0.2242,  0.5669,  0.2386],\n",
      "        [-0.1425, -0.1996,  0.5466,  ..., -0.2242,  0.5669,  0.2386]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03098525 -0.0369584  -0.22536117  0.0457354  -0.1634521  -0.6162344\n",
      " -0.06468469 -0.34620738 -1.3712485  -0.21197489 -0.40877116 -1.6614351\n",
      " -0.37882566 -0.5032124  -2.1528764  -0.16229638 -0.65427005 -1.5283666\n",
      "  0.00432426 -0.69171864 -1.3727202  -0.04136017 -0.61794734 -1.4362378\n",
      " -0.03623128 -0.7666334  -1.550544   -0.1260556  -0.5603209  -1.4475327\n",
      " -0.06136589 -0.60525876 -1.4175541  -0.08286375 -0.58111477 -1.5134637\n",
      "  0.05832118 -0.59067565 -1.5440633  -0.0524356  -0.47312889 -1.2852862\n",
      " -0.16334678 -0.24868193 -1.9304912  -0.01802361 -0.39201474 -1.9440534\n",
      "  0.14322752 -0.36902076 -1.4075608  -0.1451025  -0.24416183 -1.2203326\n",
      " -0.09040126 -0.22229508 -1.3060975  -0.05568475 -0.21716872 -1.4232748\n",
      "  0.04217426 -0.23254047 -1.2598553 ]\n",
      "data: [ 0.03098525 -0.0369584  -0.22536117  0.0457354  -0.1634521  -0.6162344\n",
      " -0.06468469 -0.34620738 -1.3712485  -0.21197489 -0.40877116 -1.6614351\n",
      " -0.3788257  -0.5032124  -2.1528764  -0.16229638 -0.65427    -1.5283666\n",
      "  0.00432426 -0.6917187  -1.3727202  -0.04136017 -0.61794734 -1.4362378\n",
      " -0.03623128 -0.7666334  -1.550544   -0.1260556  -0.5603209  -1.4475327\n",
      " -0.06136589 -0.60525876 -1.4175541  -0.08286375 -0.58111477 -1.5134637\n",
      "  0.05832118 -0.59067565 -1.5440632  -0.0524356  -0.47312889 -1.2852863\n",
      " -0.16334678 -0.24868193 -1.9304912  -0.01802361 -0.39201474 -1.9440533\n",
      "  0.14322752 -0.36902076 -1.4075608  -0.1451025  -0.24416183 -1.2203326\n",
      " -0.09040126 -0.22229508 -1.3060975  -0.05568475 -0.21716872 -1.4232746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.04217426 -0.23254047 -1.2598553   0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0199, -0.0697, -0.2487,  ...,  0.0320, -0.2531, -1.2927],\n",
      "        [ 0.0199, -0.0697, -0.2487,  ...,  0.0320, -0.2531, -1.2927],\n",
      "        [ 0.0199, -0.0697, -0.2487,  ...,  0.0320, -0.2531, -1.2927],\n",
      "        ...,\n",
      "        [-0.3097,  0.2221, -0.2705,  ..., -0.8127,  0.6871, -0.4634],\n",
      "        [-0.1198, -0.0546,  0.5971,  ..., -0.2316,  0.7330,  0.2658],\n",
      "        [-0.1198, -0.0546,  0.5971,  ..., -0.2316,  0.7330,  0.2658]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01993579 -0.06966496 -0.24868593  0.04546595 -0.20132595 -0.65480894\n",
      " -0.06169572 -0.38936648 -1.4213474  -0.20471168 -0.45474204 -1.707409\n",
      " -0.36309698 -0.5531723  -2.1952357  -0.1739611  -0.67992055 -1.5750332\n",
      "  0.01060649 -0.7160629  -1.3920755  -0.03621762 -0.6476884  -1.4501544\n",
      " -0.04519835 -0.7880746  -1.5663325  -0.13796845 -0.5832308  -1.4938437\n",
      " -0.06822199 -0.6332417  -1.4603218  -0.0903716  -0.604864   -1.5490668\n",
      "  0.04306478 -0.62273866 -1.5850796  -0.06169336 -0.4949101  -1.3288889\n",
      " -0.17586058 -0.26691678 -1.972605   -0.02801518 -0.41588277 -1.9816806\n",
      "  0.12506765 -0.38769275 -1.4466456  -0.15750927 -0.26335585 -1.261453\n",
      " -0.09531512 -0.2372543  -1.3397003  -0.05449202 -0.23855072 -1.4558673\n",
      "  0.03199758 -0.25306916 -1.2926606 ]\n",
      "data: [ 0.01993579 -0.06966496 -0.24868593  0.04546595 -0.20132595 -0.65480894\n",
      " -0.06169572 -0.3893665  -1.4213474  -0.20471169 -0.45474204 -1.707409\n",
      " -0.363097   -0.5531723  -2.1952357  -0.1739611  -0.67992055 -1.5750333\n",
      "  0.01060649 -0.7160629  -1.3920755  -0.03621762 -0.6476884  -1.4501544\n",
      " -0.04519835 -0.7880747  -1.5663323  -0.13796845 -0.5832308  -1.4938437\n",
      " -0.06822199 -0.6332417  -1.4603218  -0.0903716  -0.604864   -1.5490668\n",
      "  0.04306478 -0.62273866 -1.5850796  -0.06169336 -0.4949101  -1.3288889\n",
      " -0.17586058 -0.26691678 -1.972605   -0.02801518 -0.41588277 -1.9816806\n",
      "  0.12506765 -0.38769275 -1.4466456  -0.15750927 -0.26335585 -1.261453\n",
      " -0.09531512 -0.23725432 -1.3397003  -0.05449202 -0.23855072 -1.4558673\n",
      "  0.03199758 -0.25306916 -1.2926605   0.1       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F5F8>\n",
      "tensor([[ 0.0187, -0.0340, -0.2442,  ...,  0.0442, -0.2280, -1.2735],\n",
      "        [ 0.0187, -0.0340, -0.2442,  ...,  0.0442, -0.2280, -1.2735],\n",
      "        [ 0.0187, -0.0340, -0.2442,  ...,  0.0442, -0.2280, -1.2735],\n",
      "        ...,\n",
      "        [-0.1402,  0.3682, -0.1050,  ..., -0.7597,  0.8633, -0.3519],\n",
      "        [-0.1398, -0.1774,  0.5514,  ..., -0.2241,  0.5857,  0.2216],\n",
      "        [-0.1398, -0.1774,  0.5514,  ..., -0.2241,  0.5857,  0.2216]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0187253  -0.0340382  -0.24415536  0.03442964 -0.163959   -0.6357593\n",
      " -0.06546284 -0.34910768 -1.38576    -0.21017951 -0.41019332 -1.6806914\n",
      " -0.3784844  -0.516016   -2.160459   -0.18052876 -0.6461446  -1.5448583\n",
      "  0.01111954 -0.6821052  -1.3773452  -0.03746217 -0.61397254 -1.4355869\n",
      " -0.03325067 -0.7581028  -1.5510861  -0.13857403 -0.5482849  -1.4597867\n",
      " -0.06493092 -0.5990529  -1.4332521  -0.07838099 -0.5752411  -1.5285146\n",
      "  0.05787501 -0.59343493 -1.5657237  -0.05484162 -0.46058643 -1.2936817\n",
      " -0.17032844 -0.23605642 -1.9470209  -0.01595812 -0.3881109  -1.9539549\n",
      "  0.14444256 -0.3599206  -1.4251697  -0.1539166  -0.22981551 -1.229129\n",
      " -0.08462662 -0.20924242 -1.313206   -0.0444864  -0.21470958 -1.4300601\n",
      "  0.04417196 -0.2280462  -1.273493  ]\n",
      "data: [ 0.0187253  -0.0340382  -0.24415536  0.03442964 -0.16395898 -0.6357593\n",
      " -0.06546284 -0.34910765 -1.3857598  -0.21017951 -0.41019332 -1.6806914\n",
      " -0.37848437 -0.516016   -2.160459   -0.18052876 -0.6461446  -1.5448585\n",
      "  0.01111954 -0.6821052  -1.3773453  -0.03746217 -0.61397254 -1.4355868\n",
      " -0.03325067 -0.7581028  -1.5510861  -0.13857403 -0.5482849  -1.4597867\n",
      " -0.06493092 -0.5990529  -1.4332521  -0.07838099 -0.5752411  -1.5285145\n",
      "  0.05787501 -0.59343493 -1.5657238  -0.05484162 -0.46058643 -1.2936817\n",
      " -0.17032844 -0.23605642 -1.9470209  -0.01595812 -0.38811094 -1.9539549\n",
      "  0.14444256 -0.3599206  -1.4251697  -0.1539166  -0.22981553 -1.229129\n",
      " -0.08462663 -0.20924242 -1.3132061  -0.04448639 -0.21470958 -1.4300601\n",
      "  0.04417196 -0.2280462  -1.273493    0.11      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[ 0.0132, -0.0842, -0.2445,  ...,  0.0303, -0.2682, -1.3034],\n",
      "        [ 0.0132, -0.0842, -0.2445,  ...,  0.0303, -0.2682, -1.3034],\n",
      "        [ 0.0132, -0.0842, -0.2445,  ...,  0.0303, -0.2682, -1.3034],\n",
      "        ...,\n",
      "        [-0.3820,  0.1613, -0.3620,  ..., -0.8460,  0.5785, -0.5050],\n",
      "        [-0.1389, -0.0780,  0.5941,  ..., -0.2411,  0.7120,  0.2555],\n",
      "        [-0.1389, -0.0780,  0.5941,  ..., -0.2411,  0.7120,  0.2555]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01317122 -0.08420759 -0.24447842  0.03387051 -0.22291018 -0.6670164\n",
      " -0.05781015 -0.40272167 -1.4146664  -0.19922587 -0.46573347 -1.707496\n",
      " -0.3650534  -0.57390565 -2.185775   -0.18652824 -0.6884461  -1.5699589\n",
      "  0.01727763 -0.71784186 -1.3798735  -0.03082883 -0.6531759  -1.4372903\n",
      " -0.03544701 -0.7856607  -1.5528088  -0.14727165 -0.5864631  -1.4885563\n",
      " -0.06896251 -0.63815844 -1.4606987  -0.08568815 -0.6128505  -1.5542698\n",
      "  0.04498531 -0.6306838  -1.5992135  -0.06493799 -0.5036864  -1.3195809\n",
      " -0.17197004 -0.27776727 -1.9419552  -0.02732164 -0.42539236 -1.9434358\n",
      "  0.12402959 -0.39702588 -1.4558326  -0.16129605 -0.2691484  -1.2558676\n",
      " -0.0905993  -0.24664025 -1.3354272  -0.04584904 -0.255022   -1.4517472\n",
      "  0.03030748 -0.26821536 -1.3034326 ]\n",
      "data: [ 0.01317122 -0.08420759 -0.24447842  0.03387051 -0.22291018 -0.6670164\n",
      " -0.05781015 -0.40272167 -1.4146664  -0.19922586 -0.46573344 -1.707496\n",
      " -0.36505336 -0.57390565 -2.185775   -0.18652825 -0.6884461  -1.5699589\n",
      "  0.01727763 -0.71784186 -1.3798735  -0.03082883 -0.6531759  -1.4372903\n",
      " -0.03544701 -0.7856607  -1.5528089  -0.14727165 -0.5864631  -1.4885563\n",
      " -0.06896251 -0.63815844 -1.4606987  -0.08568815 -0.6128505  -1.5542697\n",
      "  0.04498531 -0.6306838  -1.5992134  -0.06493799 -0.5036864  -1.3195808\n",
      " -0.17197004 -0.27776727 -1.9419552  -0.02732164 -0.42539233 -1.9434358\n",
      "  0.12402959 -0.39702588 -1.4558327  -0.16129607 -0.2691484  -1.2558676\n",
      " -0.0905993  -0.24664025 -1.335427   -0.04584904 -0.255022   -1.4517472\n",
      "  0.03030748 -0.26821536 -1.3034326   0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FAC8>\n",
      "tensor([[ 0.0292, -0.0712, -0.2568,  ...,  0.0470, -0.2604, -1.2756],\n",
      "        [ 0.0292, -0.0712, -0.2568,  ...,  0.0470, -0.2604, -1.2756],\n",
      "        [ 0.0292, -0.0712, -0.2568,  ...,  0.0470, -0.2604, -1.2756],\n",
      "        ...,\n",
      "        [-0.1131,  0.4028, -0.1182,  ..., -0.6925,  0.9186, -0.4084],\n",
      "        [-0.1317, -0.1494,  0.5852,  ..., -0.2366,  0.6244,  0.2316],\n",
      "        [-0.1317, -0.1494,  0.5852,  ..., -0.2366,  0.6244,  0.2316]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02916662 -0.07121755 -0.25683823  0.05573737 -0.1874336  -0.6280253\n",
      " -0.061896   -0.38714936 -1.4160516  -0.20724678 -0.45026577 -1.7057368\n",
      " -0.36000913 -0.5431663  -2.2015133  -0.15958752 -0.69123936 -1.5733212\n",
      "  0.01099057 -0.7386838  -1.4203315  -0.04005335 -0.6666436  -1.4796513\n",
      " -0.04582473 -0.8232968  -1.5993981  -0.12081635 -0.6024811  -1.483692\n",
      " -0.06065308 -0.65020525 -1.455825   -0.08193974 -0.6211251  -1.5445349\n",
      "  0.05071092 -0.64407504 -1.5690382  -0.04484559 -0.50279593 -1.321171\n",
      " -0.17687836 -0.27244315 -2.0243282  -0.01500839 -0.42969415 -2.0433455\n",
      "  0.14415224 -0.39983675 -1.4338677  -0.14805438 -0.27652055 -1.2486303\n",
      " -0.08610347 -0.24931505 -1.335945   -0.052626   -0.24709266 -1.4516914\n",
      "  0.04699627 -0.2604264  -1.275606  ]\n",
      "data: [ 0.02916662 -0.07121755 -0.25683823  0.05573737 -0.1874336  -0.6280253\n",
      " -0.061896   -0.38714936 -1.4160516  -0.20724678 -0.45026577 -1.7057366\n",
      " -0.3600091  -0.5431663  -2.2015133  -0.15958752 -0.6912393  -1.5733212\n",
      "  0.01099057 -0.7386839  -1.4203315  -0.04005335 -0.6666436  -1.4796513\n",
      " -0.04582473 -0.8232968  -1.5993981  -0.12081634 -0.6024811  -1.483692\n",
      " -0.06065308 -0.65020525 -1.4558251  -0.08193974 -0.6211251  -1.5445349\n",
      "  0.05071092 -0.64407504 -1.569038   -0.04484559 -0.50279593 -1.3211712\n",
      " -0.17687836 -0.27244315 -2.0243282  -0.01500839 -0.42969415 -2.0433455\n",
      "  0.14415224 -0.39983672 -1.4338677  -0.14805438 -0.27652055 -1.2486303\n",
      " -0.08610347 -0.24931505 -1.335945   -0.052626   -0.24709266 -1.4516914\n",
      "  0.04699627 -0.2604264  -1.275606    0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[ 0.0230, -0.0372, -0.2422,  ...,  0.0576, -0.2269, -1.2875],\n",
      "        [ 0.0230, -0.0372, -0.2422,  ...,  0.0576, -0.2269, -1.2875],\n",
      "        [ 0.0230, -0.0372, -0.2422,  ...,  0.0576, -0.2269, -1.2875],\n",
      "        ...,\n",
      "        [-0.1597,  0.3064, -0.0638,  ..., -0.8163,  0.7750, -0.2602],\n",
      "        [-0.1439, -0.1477,  0.5407,  ..., -0.2249,  0.6090,  0.2045],\n",
      "        [-0.1439, -0.1477,  0.5407,  ..., -0.2249,  0.6090,  0.2045]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.3042787e-02 -3.7230767e-02 -2.4223529e-01  3.5724577e-02\n",
      " -1.8028998e-01 -6.5864050e-01 -4.0733352e-02 -3.5711950e-01\n",
      " -1.3823895e+00 -1.8318781e-01 -4.1604334e-01 -1.6870021e+00\n",
      " -3.6080936e-01 -5.3784776e-01 -2.1495292e+00 -1.8492353e-01\n",
      " -6.4026117e-01 -1.5435262e+00  4.4981636e-02 -6.6600215e-01\n",
      " -1.3499525e+00 -6.9272146e-03 -6.0652733e-01 -1.4039832e+00\n",
      " -4.6802983e-03 -7.3688364e-01 -1.5198811e+00 -1.3772333e-01\n",
      " -5.3281367e-01 -1.4575163e+00 -4.7519006e-02 -5.8990312e-01\n",
      " -1.4353443e+00 -5.4078214e-02 -5.6793535e-01 -1.5353205e+00\n",
      "  7.5322591e-02 -5.9230816e-01 -1.5865121e+00 -4.1371629e-02\n",
      " -4.4928089e-01 -1.2843589e+00 -1.5145689e-01 -2.2720829e-01\n",
      " -1.9146917e+00  1.9137785e-03 -3.8235337e-01 -1.9087580e+00\n",
      "  1.5758198e-01 -3.5089782e-01 -1.4381639e+00 -1.4449716e-01\n",
      " -2.1268624e-01 -1.2242508e+00 -5.8170266e-02 -1.9572136e-01\n",
      " -1.3048688e+00 -1.1379279e-02 -2.1538013e-01 -1.4227263e+00\n",
      "  5.7570726e-02 -2.2686397e-01 -1.2875177e+00]\n",
      "data: [ 2.3042787e-02 -3.7230767e-02 -2.4223527e-01  3.5724577e-02\n",
      " -1.8029000e-01 -6.5864050e-01 -4.0733352e-02 -3.5711947e-01\n",
      " -1.3823895e+00 -1.8318781e-01 -4.1604337e-01 -1.6870021e+00\n",
      " -3.6080936e-01 -5.3784776e-01 -2.1495292e+00 -1.8492353e-01\n",
      " -6.4026117e-01 -1.5435262e+00  4.4981636e-02 -6.6600209e-01\n",
      " -1.3499523e+00 -6.9272150e-03 -6.0652733e-01 -1.4039834e+00\n",
      " -4.6802983e-03 -7.3688364e-01 -1.5198811e+00 -1.3772333e-01\n",
      " -5.3281367e-01 -1.4575163e+00 -4.7519006e-02 -5.8990312e-01\n",
      " -1.4353443e+00 -5.4078210e-02 -5.6793535e-01 -1.5353206e+00\n",
      "  7.5322591e-02 -5.9230816e-01 -1.5865121e+00 -4.1371629e-02\n",
      " -4.4928089e-01 -1.2843589e+00 -1.5145689e-01 -2.2720829e-01\n",
      " -1.9146916e+00  1.9137785e-03 -3.8235337e-01 -1.9087580e+00\n",
      "  1.5758198e-01 -3.5089782e-01 -1.4381639e+00 -1.4449716e-01\n",
      " -2.1268624e-01 -1.2242508e+00 -5.8170266e-02 -1.9572136e-01\n",
      " -1.3048688e+00 -1.1379279e-02 -2.1538013e-01 -1.4227263e+00\n",
      "  5.7570726e-02 -2.2686395e-01 -1.2875177e+00  1.4000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0041, -0.0836, -0.2582,  ...,  0.0346, -0.2694, -1.3243],\n",
      "        [ 0.0041, -0.0836, -0.2582,  ...,  0.0346, -0.2694, -1.3243],\n",
      "        [ 0.0041, -0.0836, -0.2582,  ...,  0.0346, -0.2694, -1.3243],\n",
      "        ...,\n",
      "        [-0.1612,  0.4267, -0.1277,  ..., -0.7379,  0.9055, -0.3494],\n",
      "        [-0.1618, -0.1301,  0.5748,  ..., -0.2441,  0.6576,  0.2250],\n",
      "        [-0.1618, -0.1301,  0.5748,  ..., -0.2441,  0.6576,  0.2250]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00407988 -0.08359344 -0.2582027   0.02187051 -0.22928755 -0.6863927\n",
      " -0.05784484 -0.40370727 -1.426588   -0.1973928  -0.46529534 -1.723791\n",
      " -0.36754414 -0.5827589  -2.1953363  -0.19925562 -0.6832558  -1.5873829\n",
      "  0.02424657 -0.706555   -1.3903131  -0.02450652 -0.6442908  -1.4457728\n",
      " -0.02278657 -0.7686751  -1.5609192  -0.15684618 -0.5756391  -1.5057184\n",
      " -0.0677494  -0.6291536  -1.481269   -0.07786174 -0.60508585 -1.5768788\n",
      "  0.05266879 -0.62423277 -1.6291211  -0.06693908 -0.49808642 -1.3321203\n",
      " -0.16779985 -0.27194118 -1.9375144  -0.02313013 -0.4207144  -1.9315535\n",
      "  0.13012919 -0.39059308 -1.4804531  -0.16552384 -0.25997525 -1.2699429\n",
      " -0.08363894 -0.24044001 -1.3478446  -0.03423342 -0.2562467  -1.464148\n",
      "  0.03460834 -0.26935798 -1.3243209 ]\n",
      "data: [ 0.00407988 -0.08359344 -0.2582027   0.02187051 -0.22928755 -0.6863927\n",
      " -0.05784484 -0.40370727 -1.4265882  -0.1973928  -0.46529534 -1.723791\n",
      " -0.36754414 -0.5827589  -2.1953363  -0.19925562 -0.6832558  -1.5873829\n",
      "  0.02424657 -0.706555   -1.3903131  -0.02450652 -0.64429075 -1.4457726\n",
      " -0.02278657 -0.7686751  -1.5609192  -0.15684618 -0.5756391  -1.5057184\n",
      " -0.0677494  -0.6291536  -1.4812691  -0.07786174 -0.60508585 -1.5768788\n",
      "  0.05266879 -0.62423277 -1.6291211  -0.06693908 -0.49808642 -1.3321204\n",
      " -0.16779986 -0.27194118 -1.9375145  -0.02313013 -0.4207144  -1.9315535\n",
      "  0.13012919 -0.39059308 -1.4804531  -0.16552383 -0.25997525 -1.2699429\n",
      " -0.08363894 -0.24044001 -1.3478446  -0.03423342 -0.2562467  -1.464148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.03460834 -0.26935798 -1.324321    0.15      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0241, -0.0933, -0.2459,  ...,  0.0459, -0.2781, -1.2807],\n",
      "        [ 0.0241, -0.0933, -0.2459,  ...,  0.0459, -0.2781, -1.2807],\n",
      "        [ 0.0241, -0.0933, -0.2459,  ...,  0.0459, -0.2781, -1.2807],\n",
      "        ...,\n",
      "        [-0.1527,  0.3986, -0.1902,  ..., -0.7500,  0.9068, -0.4612],\n",
      "        [-0.1692, -0.1684,  0.5791,  ..., -0.2687,  0.6039,  0.2355],\n",
      "        [-0.1692, -0.1684,  0.5791,  ..., -0.2687,  0.6039,  0.2355]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02405426 -0.09329669 -0.24587399  0.04516376 -0.22385135 -0.6413789\n",
      " -0.05228023 -0.4159141  -1.4008029  -0.19413619 -0.47682616 -1.6946249\n",
      " -0.35476357 -0.5829661  -2.1721427  -0.17270982 -0.7067873  -1.5596671\n",
      "  0.0235682  -0.74467915 -1.3943219  -0.02722746 -0.678051   -1.4503255\n",
      " -0.02631444 -0.8210188  -1.5672812  -0.13112943 -0.607279   -1.4726441\n",
      " -0.0577386  -0.6581544  -1.4470634  -0.07004002 -0.63195837 -1.5378811\n",
      "  0.05928189 -0.65534395 -1.5748246  -0.04646807 -0.5135435  -1.3071845\n",
      " -0.17021157 -0.28638527 -1.9779005  -0.01119384 -0.4428941  -1.9850924\n",
      "  0.14500926 -0.40908748 -1.4369848  -0.15102048 -0.28183347 -1.2394478\n",
      " -0.07761821 -0.2575308  -1.3241556  -0.03760019 -0.26579723 -1.4397407\n",
      "  0.04589526 -0.27813    -1.2807441 ]\n",
      "data: [ 0.02405426 -0.09329669 -0.24587399  0.04516376 -0.22385135 -0.6413789\n",
      " -0.05228023 -0.4159141  -1.400803   -0.19413619 -0.47682616 -1.6946249\n",
      " -0.35476357 -0.5829661  -2.1721427  -0.17270982 -0.7067873  -1.5596671\n",
      "  0.0235682  -0.7446792  -1.3943219  -0.02722746 -0.678051   -1.4503255\n",
      " -0.02631444 -0.8210188  -1.5672812  -0.13112943 -0.607279   -1.4726441\n",
      " -0.0577386  -0.6581544  -1.4470634  -0.07004002 -0.63195837 -1.5378811\n",
      "  0.05928188 -0.65534395 -1.5748246  -0.04646807 -0.5135435  -1.3071845\n",
      " -0.17021157 -0.28638527 -1.9779005  -0.01119384 -0.4428941  -1.9850925\n",
      "  0.14500926 -0.40908748 -1.4369847  -0.15102048 -0.28183347 -1.2394478\n",
      " -0.07761821 -0.2575308  -1.3241556  -0.03760019 -0.26579723 -1.4397407\n",
      "  0.04589526 -0.27813    -1.2807441   0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0203, -0.0423, -0.2425,  ...,  0.0457, -0.2376, -1.2608],\n",
      "        [ 0.0203, -0.0423, -0.2425,  ...,  0.0457, -0.2376, -1.2608],\n",
      "        [ 0.0203, -0.0423, -0.2425,  ...,  0.0457, -0.2376, -1.2608],\n",
      "        ...,\n",
      "        [-0.1507,  0.3545, -0.0864,  ..., -0.7675,  0.8441, -0.3535],\n",
      "        [-0.1277, -0.1458,  0.5647,  ..., -0.1990,  0.6161,  0.2121],\n",
      "        [-0.1277, -0.1458,  0.5647,  ..., -0.1990,  0.6161,  0.2121]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02032201 -0.04232518 -0.24251935  0.03750729 -0.1674389  -0.619884\n",
      " -0.07305197 -0.36381134 -1.3907509  -0.22104084 -0.42669317 -1.6868615\n",
      " -0.38773397 -0.52973783 -2.1714387  -0.17872459 -0.6626768  -1.5492554\n",
      "  0.00834455 -0.70633155 -1.3744185  -0.04324014 -0.6368795  -1.4329362\n",
      " -0.04687808 -0.78968304 -1.5523462  -0.13597015 -0.567352   -1.4596367\n",
      " -0.06841292 -0.6194267  -1.4315226  -0.08480944 -0.5943592  -1.5252087\n",
      "  0.05102829 -0.6158621  -1.5557768  -0.0518491  -0.47231787 -1.2937882\n",
      " -0.17923045 -0.24662167 -1.9799185  -0.01842423 -0.4044822  -1.9916806\n",
      "  0.1449407  -0.37449282 -1.4151249  -0.15448698 -0.24288552 -1.22539\n",
      " -0.08705758 -0.2208285  -1.3118737  -0.05002124 -0.22453347 -1.4285755\n",
      "  0.04565737 -0.23757015 -1.2608013 ]\n",
      "data: [ 0.02032201 -0.04232518 -0.24251933  0.03750729 -0.1674389  -0.619884\n",
      " -0.07305197 -0.36381134 -1.3907509  -0.22104084 -0.42669314 -1.6868615\n",
      " -0.38773397 -0.52973783 -2.1714387  -0.17872459 -0.6626769  -1.5492554\n",
      "  0.00834455 -0.70633155 -1.3744185  -0.04324014 -0.6368795  -1.4329362\n",
      " -0.04687808 -0.7896831  -1.5523462  -0.13597015 -0.567352   -1.4596367\n",
      " -0.06841292 -0.6194267  -1.4315227  -0.08480944 -0.5943592  -1.5252087\n",
      "  0.05102829 -0.6158621  -1.5557768  -0.0518491  -0.47231787 -1.2937882\n",
      " -0.17923047 -0.24662167 -1.9799185  -0.01842423 -0.4044822  -1.9916806\n",
      "  0.1449407  -0.37449282 -1.4151248  -0.15448698 -0.24288552 -1.22539\n",
      " -0.08705758 -0.22082849 -1.3118737  -0.05002124 -0.22453347 -1.4285754\n",
      "  0.04565737 -0.23757015 -1.2608013   0.17      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0097, -0.0175, -0.2367,  ...,  0.0328, -0.2104, -1.2826],\n",
      "        [ 0.0097, -0.0175, -0.2367,  ...,  0.0328, -0.2104, -1.2826],\n",
      "        [ 0.0097, -0.0175, -0.2367,  ...,  0.0328, -0.2104, -1.2826],\n",
      "        ...,\n",
      "        [-0.1950,  0.3170, -0.1135,  ..., -0.8350,  0.7675, -0.2843],\n",
      "        [-0.1441, -0.1694,  0.5389,  ..., -0.2148,  0.6050,  0.2085],\n",
      "        [-0.1441, -0.1694,  0.5389,  ..., -0.2148,  0.6050,  0.2085]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 9.6957423e-03 -1.7540956e-02 -2.3670152e-01  2.0198744e-02\n",
      " -1.5665853e-01 -6.5317059e-01 -7.7152520e-02 -3.3759966e-01\n",
      " -1.3940303e+00 -2.2170720e-01 -4.0134719e-01 -1.6876669e+00\n",
      " -3.9735940e-01 -5.1058763e-01 -2.1608167e+00 -1.9503158e-01\n",
      " -6.2774152e-01 -1.5464107e+00  1.8257424e-03 -6.5968937e-01\n",
      " -1.3583251e+00 -4.3820105e-02 -5.9263766e-01 -1.4164497e+00\n",
      " -4.0410087e-02 -7.3038417e-01 -1.5306120e+00 -1.5384853e-01\n",
      " -5.2475870e-01 -1.4649322e+00 -7.6631814e-02 -5.7720381e-01\n",
      " -1.4345090e+00 -8.9721777e-02 -5.5491596e-01 -1.5307798e+00\n",
      "  5.0859548e-02 -5.6873751e-01 -1.5745070e+00 -7.0448592e-02\n",
      " -4.4422770e-01 -1.2978053e+00 -1.7627239e-01 -2.2107893e-01\n",
      " -1.9210631e+00 -2.8854631e-02 -3.6793989e-01 -1.9232837e+00\n",
      "  1.3230395e-01 -3.4189343e-01 -1.4312024e+00 -1.6485283e-01\n",
      " -2.0893762e-01 -1.2340430e+00 -9.7116463e-02 -1.8972977e-01\n",
      " -1.3166769e+00 -5.2041925e-02 -1.9612694e-01 -1.4336727e+00\n",
      "  3.2794476e-02 -2.1040545e-01 -1.2826364e+00]\n",
      "data: [ 9.6957423e-03 -1.7540956e-02 -2.3670153e-01  2.0198744e-02\n",
      " -1.5665853e-01 -6.5317065e-01 -7.7152520e-02 -3.3759966e-01\n",
      " -1.3940303e+00 -2.2170720e-01 -4.0134719e-01 -1.6876669e+00\n",
      " -3.9735940e-01 -5.1058763e-01 -2.1608167e+00 -1.9503158e-01\n",
      " -6.2774152e-01 -1.5464107e+00  1.8257424e-03 -6.5968931e-01\n",
      " -1.3583252e+00 -4.3820105e-02 -5.9263766e-01 -1.4164498e+00\n",
      " -4.0410087e-02 -7.3038411e-01 -1.5306120e+00 -1.5384853e-01\n",
      " -5.2475870e-01 -1.4649322e+00 -7.6631814e-02 -5.7720381e-01\n",
      " -1.4345089e+00 -8.9721777e-02 -5.5491596e-01 -1.5307798e+00\n",
      "  5.0859548e-02 -5.6873751e-01 -1.5745070e+00 -7.0448592e-02\n",
      " -4.4422767e-01 -1.2978053e+00 -1.7627239e-01 -2.2107893e-01\n",
      " -1.9210631e+00 -2.8854631e-02 -3.6793986e-01 -1.9232837e+00\n",
      "  1.3230395e-01 -3.4189343e-01 -1.4312024e+00 -1.6485283e-01\n",
      " -2.0893760e-01 -1.2340430e+00 -9.7116463e-02 -1.8972977e-01\n",
      " -1.3166767e+00 -5.2041925e-02 -1.9612694e-01 -1.4336727e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3.2794476e-02 -2.1040544e-01 -1.2826364e+00  1.8000001e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0298, -0.0944, -0.2253,  ...,  0.0415, -0.2793, -1.2887],\n",
      "        [ 0.0298, -0.0944, -0.2253,  ...,  0.0415, -0.2793, -1.2887],\n",
      "        [ 0.0298, -0.0944, -0.2253,  ...,  0.0415, -0.2793, -1.2887],\n",
      "        ...,\n",
      "        [-0.3447,  0.2673, -0.3659,  ..., -0.8881,  0.7105, -0.5020],\n",
      "        [-0.1401, -0.0853,  0.6052,  ..., -0.2408,  0.7101,  0.2831],\n",
      "        [-0.1401, -0.0853,  0.6052,  ..., -0.2408,  0.7101,  0.2831]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02980468 -0.0944279  -0.22531241  0.04968468 -0.23617496 -0.65564966\n",
      " -0.04248378 -0.40791294 -1.3882446  -0.182984   -0.47026825 -1.6770884\n",
      " -0.34849173 -0.5740971  -2.1573117  -0.16581956 -0.69838583 -1.5418682\n",
      "  0.02273691 -0.72247857 -1.3683832  -0.02121063 -0.6554276  -1.4299309\n",
      " -0.01921084 -0.78598994 -1.5415591  -0.13077798 -0.59643227 -1.4676651\n",
      " -0.05378554 -0.6437021  -1.4380842  -0.07388707 -0.61944336 -1.5323057\n",
      "  0.06012168 -0.6296937  -1.5767486  -0.05434228 -0.5171677  -1.3011203\n",
      " -0.15129846 -0.2938594  -1.9017724  -0.01491269 -0.43319562 -1.9041388\n",
      "  0.134208   -0.408033   -1.4369583  -0.14240438 -0.28464544 -1.2415241\n",
      " -0.0804932  -0.26217127 -1.319212   -0.03705171 -0.26433507 -1.4374014\n",
      "  0.04149192 -0.2792822  -1.2887274 ]\n",
      "data: [ 0.02980468 -0.0944279  -0.22531241  0.04968468 -0.23617497 -0.65564966\n",
      " -0.04248378 -0.40791294 -1.3882446  -0.182984   -0.47026825 -1.6770883\n",
      " -0.34849176 -0.5740971  -2.1573117  -0.16581956 -0.69838583 -1.5418683\n",
      "  0.02273691 -0.72247857 -1.3683832  -0.02121063 -0.6554276  -1.4299309\n",
      " -0.01921084 -0.78598994 -1.5415591  -0.13077798 -0.59643227 -1.4676651\n",
      " -0.05378554 -0.6437021  -1.4380842  -0.07388707 -0.61944336 -1.5323057\n",
      "  0.06012168 -0.6296937  -1.5767486  -0.05434228 -0.5171677  -1.3011203\n",
      " -0.15129846 -0.2938594  -1.9017723  -0.01491269 -0.43319562 -1.9041388\n",
      "  0.134208   -0.408033   -1.4369583  -0.14240438 -0.28464544 -1.2415241\n",
      " -0.0804932  -0.26217127 -1.3192121  -0.03705171 -0.26433507 -1.4374014\n",
      "  0.04149192 -0.2792822  -1.2887274   0.19      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0282, -0.0811, -0.2347,  ...,  0.0535, -0.2728, -1.2553],\n",
      "        [ 0.0282, -0.0811, -0.2347,  ...,  0.0535, -0.2728, -1.2553],\n",
      "        [ 0.0282, -0.0811, -0.2347,  ...,  0.0535, -0.2728, -1.2553],\n",
      "        ...,\n",
      "        [-0.1342,  0.4133, -0.0857,  ..., -0.6803,  0.9076, -0.3705],\n",
      "        [-0.1709, -0.1329,  0.5785,  ..., -0.2704,  0.6418,  0.2198],\n",
      "        [-0.1709, -0.1329,  0.5785,  ..., -0.2704,  0.6418,  0.2198]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02816815 -0.08113734 -0.23470102  0.05448964 -0.20259416 -0.6067131\n",
      " -0.05689751 -0.40877473 -1.4034604  -0.201745   -0.4741286  -1.6977472\n",
      " -0.3580877  -0.5759067  -2.1875956  -0.1647164  -0.7030825  -1.5625972\n",
      "  0.0276154  -0.75211453 -1.385365   -0.02708234 -0.68484086 -1.440582\n",
      " -0.03968798 -0.83827746 -1.5627589  -0.12207609 -0.6093996  -1.4680835\n",
      " -0.05621065 -0.6630323  -1.4413962  -0.0739717  -0.63447803 -1.5292794\n",
      "  0.05361292 -0.66346437 -1.5588163  -0.038385   -0.508909   -1.301694\n",
      " -0.17596874 -0.27884126 -2.012947   -0.00942268 -0.44306737 -2.0264025\n",
      "  0.14836587 -0.4087786  -1.4176841  -0.14769542 -0.279141   -1.2278215\n",
      " -0.07524806 -0.25375974 -1.3134234  -0.03800599 -0.2602498  -1.4274628\n",
      "  0.05346889 -0.27275142 -1.2552907 ]\n",
      "data: [ 0.02816815 -0.08113734 -0.23470102  0.05448963 -0.20259416 -0.6067131\n",
      " -0.05689751 -0.40877473 -1.4034604  -0.20174499 -0.4741286  -1.6977472\n",
      " -0.3580877  -0.5759067  -2.1875956  -0.1647164  -0.7030825  -1.5625972\n",
      "  0.0276154  -0.75211453 -1.385365   -0.02708234 -0.68484086 -1.4405819\n",
      " -0.03968798 -0.83827746 -1.5627589  -0.12207609 -0.6093996  -1.4680835\n",
      " -0.05621065 -0.6630323  -1.4413962  -0.0739717  -0.63447803 -1.5292794\n",
      "  0.05361292 -0.66346437 -1.5588164  -0.038385   -0.508909   -1.301694\n",
      " -0.17596874 -0.27884126 -2.012947   -0.00942268 -0.44306737 -2.0264025\n",
      "  0.14836587 -0.4087786  -1.4176841  -0.14769542 -0.279141   -1.2278215\n",
      " -0.07524806 -0.25375974 -1.3134235  -0.03800599 -0.2602498  -1.4274628\n",
      "  0.05346889 -0.27275142 -1.2552907   0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0226, -0.0326, -0.2272,  ...,  0.0524, -0.2233, -1.2639],\n",
      "        [ 0.0226, -0.0326, -0.2272,  ...,  0.0524, -0.2233, -1.2639],\n",
      "        [ 0.0226, -0.0326, -0.2272,  ...,  0.0524, -0.2233, -1.2639],\n",
      "        ...,\n",
      "        [-0.1732,  0.3196, -0.0942,  ..., -0.8005,  0.7683, -0.2880],\n",
      "        [-0.1389, -0.1402,  0.5657,  ..., -0.2003,  0.6145,  0.2224],\n",
      "        [-0.1389, -0.1402,  0.5657,  ..., -0.2003,  0.6145,  0.2224]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02261335 -0.03259488 -0.22722827  0.0358988  -0.17118192 -0.6328558\n",
      " -0.05360056 -0.3601619  -1.3790615  -0.1990054  -0.42242756 -1.6825256\n",
      " -0.37526977 -0.53995955 -2.150021   -0.18561791 -0.64506763 -1.5363955\n",
      "  0.03333679 -0.67985415 -1.3402103  -0.02033344 -0.61870426 -1.3946754\n",
      " -0.02466972 -0.7581346  -1.5131634  -0.13847889 -0.5400909  -1.4465063\n",
      " -0.05719346 -0.5980793  -1.4215841  -0.06730608 -0.5754268  -1.5194017\n",
      "  0.06275862 -0.60101813 -1.5643357  -0.0448676  -0.4505403  -1.2748191\n",
      " -0.16581438 -0.22724172 -1.9344547  -0.0074747  -0.38606045 -1.9342352\n",
      "  0.15063585 -0.35405213 -1.4163742  -0.14974532 -0.21457717 -1.2104315\n",
      " -0.06867282 -0.19587041 -1.2937682  -0.02432555 -0.21187077 -1.4106572\n",
      "  0.05238169 -0.22331305 -1.263922  ]\n",
      "data: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "mask: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0333,  0.0448,  0.4349,  ..., -0.2319, -0.0727, -0.3665],\n",
      "        [-0.0333,  0.0448,  0.4349,  ..., -0.2319, -0.0727, -0.3665],\n",
      "        [-0.0333,  0.0448,  0.4349,  ..., -0.2319, -0.0727, -0.3665],\n",
      "        ...,\n",
      "        [ 0.3777,  0.0338, -0.4249,  ...,  0.2617,  0.7308, -0.4466],\n",
      "        [ 0.3953,  0.0267, -0.4035,  ...,  0.2826,  0.7878, -0.4917],\n",
      "        [ 0.3953,  0.0267, -0.4035,  ...,  0.2826,  0.7878, -0.4917]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.03331171  0.04475227  0.43488228 -0.08014037 -0.1283966   0.04251438\n",
      " -0.43275732 -0.30288675 -0.52919793 -0.6339379  -0.4416606  -0.64817005\n",
      " -0.92006445 -0.45257625 -1.0338042  -0.32898337 -0.5638237  -0.5347692\n",
      " -0.48484027 -0.5967127  -0.22969621 -0.4647954  -0.4992316  -0.28106982\n",
      " -0.5385193  -0.63992906 -0.29921997 -0.30783296 -0.44557652 -0.56127876\n",
      " -0.40865445 -0.4935944  -0.37488335 -0.53361404 -0.46619457 -0.43082047\n",
      " -0.28280222 -0.36111313 -0.51204956 -0.349191   -0.46142566 -0.4435553\n",
      " -0.3940547  -0.24101767 -0.6121369  -0.40089983 -0.258882   -0.64137584\n",
      " -0.26609105 -0.26819363 -0.39044648 -0.29307145 -0.20285279 -0.41877973\n",
      " -0.48265147 -0.14345443 -0.4460817  -0.39757866 -0.02279501 -0.5691981\n",
      " -0.23187025 -0.07268029 -0.3664986 ]\n",
      "init: [-0.03331171  0.04475227  0.43488228 -0.08014037 -0.1283966   0.04251438\n",
      " -0.43275732 -0.30288675 -0.52919793 -0.6339379  -0.4416606  -0.64817005\n",
      " -0.92006445 -0.45257625 -1.0338042  -0.32898337 -0.5638237  -0.5347692\n",
      " -0.48484027 -0.5967127  -0.22969621 -0.4647954  -0.4992316  -0.28106982\n",
      " -0.5385193  -0.63992906 -0.29921997 -0.30783296 -0.44557652 -0.56127876\n",
      " -0.40865445 -0.4935944  -0.37488335 -0.53361404 -0.46619457 -0.43082047\n",
      " -0.28280222 -0.36111313 -0.51204956 -0.349191   -0.46142566 -0.4435553\n",
      " -0.3940547  -0.24101767 -0.6121369  -0.40089983 -0.258882   -0.64137584\n",
      " -0.26609105 -0.26819363 -0.39044648 -0.29307145 -0.20285279 -0.41877973\n",
      " -0.48265147 -0.14345443 -0.4460817  -0.39757866 -0.02279501 -0.5691981\n",
      " -0.23187025 -0.07268029 -0.3664986 ]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [-0.03331171  0.04475227  0.43488228 -0.08014037 -0.1283966   0.04251438\n",
      " -0.4327573  -0.30288675 -0.52919793 -0.6339379  -0.4416606  -0.6481701\n",
      " -0.92006445 -0.45257625 -1.0338042  -0.3289834  -0.5638237  -0.5347692\n",
      " -0.48484027 -0.5967127  -0.22969621 -0.4647954  -0.4992316  -0.28106982\n",
      " -0.5385193  -0.63992906 -0.29921997 -0.30783296 -0.44557652 -0.56127876\n",
      " -0.40865445 -0.4935944  -0.37488335 -0.53361404 -0.46619457 -0.43082047\n",
      " -0.28280222 -0.36111313 -0.51204956 -0.349191   -0.46142566 -0.4435553\n",
      " -0.3940547  -0.24101767 -0.6121369  -0.4008998  -0.258882   -0.6413758\n",
      " -0.26609105 -0.26819363 -0.39044648 -0.29307145 -0.20285279 -0.41877973\n",
      " -0.48265147 -0.14345443 -0.4460817  -0.39757866 -0.02279501 -0.5691981\n",
      " -0.23187025 -0.07268029 -0.3664986   0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0976, -0.1282, -0.0014,  ..., -0.1768, -0.3206, -0.4777],\n",
      "        [ 0.0976, -0.1282, -0.0014,  ..., -0.1768, -0.3206, -0.4777],\n",
      "        [ 0.0976, -0.1282, -0.0014,  ..., -0.1768, -0.3206, -0.4777],\n",
      "        ...,\n",
      "        [ 0.3807, -0.3220,  0.1800,  ...,  0.0255,  0.4814, -0.7080],\n",
      "        [ 0.2470, -0.0607,  0.3909,  ..., -0.2374,  0.5988, -0.3907],\n",
      "        [ 0.2470, -0.0607,  0.3909,  ..., -0.2374,  0.5988, -0.3907]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.09764333 -0.12818111 -0.00139142  0.01448007 -0.21023431 -0.21530163\n",
      " -0.19374429 -0.3714562  -0.6253542  -0.37554568 -0.43195403 -0.8070229\n",
      " -0.6704508  -0.44929424 -1.1941503  -0.23161386 -0.6267141  -0.80595434\n",
      " -0.49900675 -0.64790744 -1.1695795  -0.50235474 -0.5776095  -1.1860143\n",
      " -0.41920716 -0.7813401  -1.1322979  -0.17645065 -0.54897135 -0.7414032\n",
      " -0.28347117 -0.59008485 -0.56041884 -0.39183152 -0.6059165  -0.66071415\n",
      " -0.27003443 -0.5561799  -0.7184459  -0.17070954 -0.496056   -0.6637727\n",
      " -0.30694145 -0.41535404 -0.9040673  -0.271919   -0.47494265 -0.9372133\n",
      " -0.24233057 -0.4594384  -0.5834764  -0.14623041 -0.35705602 -0.6308223\n",
      " -0.28953373 -0.35680002 -0.5369657  -0.25904596 -0.32209873 -0.6326524\n",
      " -0.17676057 -0.32056063 -0.47769672]\n",
      "data: [ 0.09764333 -0.12818111 -0.00139142  0.01448007 -0.21023431 -0.21530163\n",
      " -0.19374427 -0.37145624 -0.6253542  -0.37554568 -0.43195403 -0.8070229\n",
      " -0.6704508  -0.44929424 -1.1941503  -0.23161386 -0.6267141  -0.80595434\n",
      " -0.49900672 -0.64790744 -1.1695795  -0.50235474 -0.5776095  -1.1860143\n",
      " -0.41920716 -0.7813401  -1.1322979  -0.17645065 -0.54897135 -0.7414032\n",
      " -0.28347117 -0.59008485 -0.56041884 -0.39183152 -0.6059165  -0.6607141\n",
      " -0.27003443 -0.5561799  -0.7184459  -0.17070954 -0.496056   -0.66377276\n",
      " -0.30694145 -0.41535404 -0.9040673  -0.271919   -0.47494265 -0.9372133\n",
      " -0.24233057 -0.4594384  -0.5834764  -0.14623041 -0.35705602 -0.6308223\n",
      " -0.28953373 -0.3568     -0.5369657  -0.25904596 -0.32209873 -0.6326524\n",
      " -0.17676058 -0.32056063 -0.47769672  0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0900,  0.1017, -0.2073,  ...,  0.3068, -0.1375, -1.1475],\n",
      "        [ 0.0900,  0.1017, -0.2073,  ...,  0.3068, -0.1375, -1.1475],\n",
      "        [ 0.0900,  0.1017, -0.2073,  ...,  0.3068, -0.1375, -1.1475],\n",
      "        ...,\n",
      "        [ 0.1401, -0.4187,  0.1613,  ...,  0.3673,  0.7864, -0.4577],\n",
      "        [-0.1169,  0.0864,  0.2130,  ..., -0.8328,  0.7281, -0.1858],\n",
      "        [-0.1169,  0.0864,  0.2130,  ..., -0.8328,  0.7281, -0.1858]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.09004354  0.10170863 -0.2072531   0.10468787  0.00330134 -0.5347936\n",
      "  0.00726356 -0.16720459 -1.1657598  -0.10037886 -0.2120057  -1.4103525\n",
      " -0.22976235 -0.3165544  -1.8076682  -0.07890822 -0.4489165  -1.3445523\n",
      "  0.10811283 -0.4684853  -1.2729223   0.13283332 -0.36777702 -1.302366\n",
      "  0.21368803 -0.50388235 -1.3826895  -0.02680372 -0.36518514 -1.2833881\n",
      "  0.09790829 -0.41684842 -1.2526379   0.16122824 -0.3782552  -1.2983732\n",
      "  0.37268096 -0.39036024 -1.3855743   0.09173962 -0.3243102  -1.1600358\n",
      "  0.02003389 -0.08915249 -1.7330775   0.2276017  -0.2581452  -1.7140632\n",
      "  0.43774143 -0.18318337 -1.3041556  -0.00486229 -0.11566274 -1.0981929\n",
      "  0.09842834 -0.07345021 -1.1778378   0.20156622 -0.10605052 -1.2936413\n",
      "  0.30680764 -0.13745171 -1.1474593 ]\n",
      "data: [ 0.09004354  0.10170863 -0.2072531   0.10468787  0.00330134 -0.5347936\n",
      "  0.00726356 -0.16720459 -1.1657598  -0.10037886 -0.2120057  -1.4103525\n",
      " -0.22976235 -0.3165544  -1.8076682  -0.07890822 -0.44891652 -1.3445523\n",
      "  0.10811283 -0.4684853  -1.2729223   0.13283332 -0.36777702 -1.302366\n",
      "  0.21368803 -0.50388235 -1.3826895  -0.02680372 -0.36518514 -1.283388\n",
      "  0.09790829 -0.41684842 -1.2526379   0.16122824 -0.3782552  -1.2983732\n",
      "  0.37268096 -0.39036024 -1.3855743   0.09173962 -0.3243102  -1.1600358\n",
      "  0.02003389 -0.08915249 -1.7330775   0.2276017  -0.2581452  -1.7140632\n",
      "  0.43774143 -0.18318337 -1.3041556  -0.00486229 -0.11566274 -1.0981929\n",
      "  0.09842834 -0.07345021 -1.1778378   0.20156622 -0.10605052 -1.2936413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.30680764 -0.13745171 -1.1474593   0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.1626, -0.2447, -0.2165,  ...,  0.1342, -0.3837, -1.3979],\n",
      "        [ 0.1626, -0.2447, -0.2165,  ...,  0.1342, -0.3837, -1.3979],\n",
      "        [ 0.1626, -0.2447, -0.2165,  ...,  0.1342, -0.3837, -1.3979],\n",
      "        ...,\n",
      "        [-0.3962,  0.3155, -0.2418,  ..., -0.9098,  0.8485, -0.5920],\n",
      "        [-0.1954,  0.1442,  0.4025,  ..., -0.1335,  0.9645,  0.0509],\n",
      "        [-0.1954,  0.1442,  0.4025,  ..., -0.1335,  0.9645,  0.0509]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.16259731 -0.24474892 -0.21654204  0.17051058 -0.42394608 -0.75639176\n",
      "  0.1134444  -0.5734697  -1.4409375  -0.03744851 -0.6310879  -1.7440678\n",
      " -0.24560687 -0.75492847 -2.2096317  -0.07778284 -0.8134382  -1.6215749\n",
      "  0.17727114 -0.8176117  -1.3409047   0.13588884 -0.75505805 -1.3899015\n",
      "  0.12326978 -0.8522508  -1.492666   -0.03816712 -0.68302584 -1.5522274\n",
      "  0.0609953  -0.7390543  -1.5093521   0.04989593 -0.7221918  -1.6149815\n",
      "  0.17674719 -0.7207309  -1.6925542   0.05065572 -0.6286533  -1.3766742\n",
      " -0.02669583 -0.39854333 -1.8704634   0.09021126 -0.5355292  -1.8423752\n",
      "  0.22470109 -0.49820426 -1.535238   -0.03708974 -0.37536836 -1.3240654\n",
      "  0.03305179 -0.35118255 -1.382289    0.09875719 -0.37684909 -1.4995192\n",
      "  0.13417494 -0.3836607  -1.3978517 ]\n",
      "data: [ 0.16259731 -0.24474892 -0.21654204  0.17051058 -0.42394608 -0.75639176\n",
      "  0.1134444  -0.5734697  -1.4409375  -0.03744851 -0.6310879  -1.7440678\n",
      " -0.24560685 -0.7549284  -2.2096317  -0.07778284 -0.8134382  -1.6215749\n",
      "  0.17727114 -0.8176117  -1.3409047   0.13588884 -0.75505805 -1.3899016\n",
      "  0.12326977 -0.8522508  -1.492666   -0.03816712 -0.68302584 -1.5522274\n",
      "  0.0609953  -0.7390543  -1.5093521   0.04989593 -0.72219175 -1.6149815\n",
      "  0.17674719 -0.7207309  -1.6925541   0.05065572 -0.6286533  -1.3766742\n",
      " -0.02669583 -0.39854333 -1.8704634   0.09021126 -0.5355292  -1.8423752\n",
      "  0.2247011  -0.49820426 -1.535238   -0.03708974 -0.37536836 -1.3240654\n",
      "  0.03305179 -0.35118255 -1.3822892   0.09875719 -0.37684909 -1.4995192\n",
      "  0.13417494 -0.3836607  -1.3978517   0.04      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[-0.0014, -0.2214, -0.1263,  ...,  0.0219, -0.4075, -1.1864],\n",
      "        [-0.0014, -0.2214, -0.1263,  ...,  0.0219, -0.4075, -1.1864],\n",
      "        [-0.0014, -0.2214, -0.1263,  ...,  0.0219, -0.4075, -1.1864],\n",
      "        ...,\n",
      "        [ 0.0067,  0.6645, -0.2338,  ..., -0.3585,  1.1325, -0.6183],\n",
      "        [-0.0874,  0.0135,  0.6353,  ..., -0.0416,  0.7029,  0.2584],\n",
      "        [-0.0874,  0.0135,  0.6353,  ..., -0.0416,  0.7029,  0.2584]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-1.3944982e-03 -2.2139496e-01 -1.2627394e-01  2.3896504e-02\n",
      " -3.5566261e-01 -4.8942316e-01 -6.1672233e-02 -5.7245290e-01\n",
      " -1.3055301e+00 -2.1586958e-01 -6.4056301e-01 -1.6239984e+00\n",
      " -3.9545536e-01 -7.6506054e-01 -2.1170881e+00 -2.1994479e-01\n",
      " -8.3480060e-01 -1.5171304e+00  3.2335058e-02 -8.9029098e-01\n",
      " -1.2990570e+00 -3.5176113e-02 -8.3683205e-01 -1.3376410e+00\n",
      " -5.8789648e-02 -9.8474634e-01 -1.4589331e+00 -1.6269988e-01\n",
      " -7.2757673e-01 -1.4053984e+00 -8.0031395e-02 -8.0164874e-01\n",
      " -1.3744018e+00 -9.1910936e-02 -7.8105390e-01 -1.4764490e+00\n",
      "  1.6207248e-02 -8.2567239e-01 -1.5186138e+00 -5.7775117e-02\n",
      " -6.2455750e-01 -1.2261112e+00 -2.0671402e-01 -4.0292698e-01\n",
      " -1.9258494e+00 -3.7350178e-02 -5.8595496e-01 -1.9243019e+00\n",
      "  1.1297764e-01 -5.4334009e-01 -1.3564241e+00 -1.8654317e-01\n",
      " -3.8413808e-01 -1.1533756e+00 -8.6353734e-02 -3.6845621e-01\n",
      " -1.2241373e+00 -4.1480303e-02 -4.0528905e-01 -1.3338790e+00\n",
      "  2.1869339e-02 -4.0752119e-01 -1.1863778e+00]\n",
      "data: [-1.3944982e-03 -2.2139496e-01 -1.2627394e-01  2.3896504e-02\n",
      " -3.5566261e-01 -4.8942316e-01 -6.1672233e-02 -5.7245290e-01\n",
      " -1.3055301e+00 -2.1586958e-01 -6.4056307e-01 -1.6239984e+00\n",
      " -3.9545536e-01 -7.6506060e-01 -2.1170881e+00 -2.1994478e-01\n",
      " -8.3480054e-01 -1.5171304e+00  3.2335058e-02 -8.9029098e-01\n",
      " -1.2990570e+00 -3.5176113e-02 -8.3683205e-01 -1.3376410e+00\n",
      " -5.8789648e-02 -9.8474634e-01 -1.4589331e+00 -1.6269988e-01\n",
      " -7.2757673e-01 -1.4053984e+00 -8.0031395e-02 -8.0164874e-01\n",
      " -1.3744018e+00 -9.1910936e-02 -7.8105390e-01 -1.4764490e+00\n",
      "  1.6207248e-02 -8.2567239e-01 -1.5186139e+00 -5.7775117e-02\n",
      " -6.2455750e-01 -1.2261112e+00 -2.0671402e-01 -4.0292698e-01\n",
      " -1.9258494e+00 -3.7350178e-02 -5.8595496e-01 -1.9243019e+00\n",
      "  1.1297764e-01 -5.4334009e-01 -1.3564241e+00 -1.8654317e-01\n",
      " -3.8413808e-01 -1.1533756e+00 -8.6353734e-02 -3.6845624e-01\n",
      " -1.2241373e+00 -4.1480303e-02 -4.0528905e-01 -1.3338790e+00\n",
      "  2.1869339e-02 -4.0752116e-01 -1.1863778e+00  5.0000001e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F630B8>\n",
      "tensor([[-0.0126, -0.0440, -0.2498,  ..., -0.0144, -0.2194, -1.2621],\n",
      "        [-0.0126, -0.0440, -0.2498,  ..., -0.0144, -0.2194, -1.2621],\n",
      "        [-0.0126, -0.0440, -0.2498,  ..., -0.0144, -0.2194, -1.2621],\n",
      "        ...,\n",
      "        [-0.1622,  0.4425,  0.0162,  ..., -0.4609,  1.0799, -0.4565],\n",
      "        [ 0.0126,  0.0322,  0.7024,  ..., -0.0314,  0.6517,  0.3784],\n",
      "        [ 0.0126,  0.0322,  0.7024,  ..., -0.0314,  0.6517,  0.3784]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01260016 -0.04402129 -0.24975152  0.01478846 -0.15472816 -0.5266131\n",
      " -0.12502363 -0.39141747 -1.3883462  -0.28649244 -0.4564404  -1.6764512\n",
      " -0.44515777 -0.5470189  -2.1928806  -0.21939155 -0.6873365  -1.5933857\n",
      " -0.04077457 -0.75610626 -1.4431407  -0.09004906 -0.6806608  -1.4832897\n",
      " -0.08545484 -0.8435774  -1.6042371  -0.17609191 -0.5906966  -1.4917936\n",
      " -0.11457139 -0.64559436 -1.4508238  -0.11473942 -0.609194   -1.5363119\n",
      "  0.02967812 -0.6430152  -1.5548451  -0.08876392 -0.47219065 -1.336669\n",
      " -0.25466174 -0.23785785 -2.0866678  -0.06368307 -0.41475224 -2.1103518\n",
      "  0.1194841  -0.36610073 -1.4301422  -0.22323063 -0.2350219  -1.257385\n",
      " -0.15236887 -0.2039865  -1.3396013  -0.12047899 -0.21180402 -1.4516761\n",
      " -0.01440995 -0.21942571 -1.2620718 ]\n",
      "data: [-0.01260016 -0.04402129 -0.24975152  0.01478846 -0.15472816 -0.5266131\n",
      " -0.12502363 -0.39141747 -1.3883462  -0.28649244 -0.4564404  -1.6764512\n",
      " -0.44515777 -0.5470189  -2.1928806  -0.21939155 -0.6873365  -1.5933856\n",
      " -0.04077457 -0.75610626 -1.4431407  -0.09004906 -0.6806608  -1.4832898\n",
      " -0.08545484 -0.84357744 -1.6042371  -0.17609192 -0.5906966  -1.4917936\n",
      " -0.11457139 -0.64559436 -1.4508238  -0.11473942 -0.609194   -1.5363117\n",
      "  0.02967812 -0.6430152  -1.5548451  -0.08876392 -0.47219068 -1.336669\n",
      " -0.25466174 -0.23785786 -2.0866678  -0.06368307 -0.41475224 -2.1103518\n",
      "  0.1194841  -0.36610073 -1.4301422  -0.22323063 -0.23502189 -1.257385\n",
      " -0.15236887 -0.2039865  -1.3396013  -0.120479   -0.211804   -1.4516761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.01440995 -0.21942572 -1.2620718   0.06      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0241, -0.0234, -0.1925,  ...,  0.0487, -0.2037, -1.2475],\n",
      "        [ 0.0241, -0.0234, -0.1925,  ...,  0.0487, -0.2037, -1.2475],\n",
      "        [ 0.0241, -0.0234, -0.1925,  ...,  0.0487, -0.2037, -1.2475],\n",
      "        ...,\n",
      "        [-0.2241,  0.2757, -0.0837,  ..., -0.8886,  0.7851, -0.3009],\n",
      "        [-0.1668, -0.1511,  0.5197,  ..., -0.2715,  0.5750,  0.2545],\n",
      "        [-0.1668, -0.1511,  0.5197,  ..., -0.2715,  0.5750,  0.2545]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.4095450e-02 -2.3397317e-02 -1.9246504e-01  3.6783312e-02\n",
      " -1.6441725e-01 -6.0392940e-01 -4.2973556e-02 -3.3719155e-01\n",
      " -1.3340273e+00 -1.8918999e-01 -3.9412382e-01 -1.6379774e+00\n",
      " -3.6821616e-01 -5.1253116e-01 -2.1097999e+00 -1.8746799e-01\n",
      " -6.2799186e-01 -1.4924631e+00  4.1402489e-02 -6.5166652e-01\n",
      " -1.3033230e+00 -1.1073619e-02 -5.8972663e-01 -1.3564935e+00\n",
      " -7.5356439e-03 -7.1693379e-01 -1.4738281e+00 -1.4160079e-01\n",
      " -5.2175683e-01 -1.4072740e+00 -5.0551347e-02 -5.7420695e-01\n",
      " -1.3881953e+00 -5.4612584e-02 -5.4588443e-01 -1.4897521e+00\n",
      "  7.8031853e-02 -5.7079208e-01 -1.5400798e+00 -4.5987733e-02\n",
      " -4.3723911e-01 -1.2351930e+00 -1.5537095e-01 -2.0841861e-01\n",
      " -1.8606520e+00 -5.9393793e-04 -3.6003166e-01 -1.8570783e+00\n",
      "  1.5815663e-01 -3.2823038e-01 -1.3971918e+00 -1.5282506e-01\n",
      " -1.9761012e-01 -1.1739750e+00 -6.6620931e-02 -1.7802325e-01\n",
      " -1.2591355e+00 -2.2320703e-02 -1.9408941e-01 -1.3791182e+00\n",
      "  4.8713304e-02 -2.0370828e-01 -1.2475183e+00]\n",
      "data: [ 2.4095450e-02 -2.3397317e-02 -1.9246504e-01  3.6783312e-02\n",
      " -1.6441725e-01 -6.0392940e-01 -4.2973556e-02 -3.3719155e-01\n",
      " -1.3340273e+00 -1.8918999e-01 -3.9412385e-01 -1.6379772e+00\n",
      " -3.6821616e-01 -5.1253116e-01 -2.1097999e+00 -1.8746799e-01\n",
      " -6.2799186e-01 -1.4924631e+00  4.1402489e-02 -6.5166646e-01\n",
      " -1.3033230e+00 -1.1073619e-02 -5.8972663e-01 -1.3564935e+00\n",
      " -7.5356434e-03 -7.1693385e-01 -1.4738281e+00 -1.4160079e-01\n",
      " -5.2175683e-01 -1.4072740e+00 -5.0551347e-02 -5.7420695e-01\n",
      " -1.3881954e+00 -5.4612584e-02 -5.4588443e-01 -1.4897521e+00\n",
      "  7.8031853e-02 -5.7079208e-01 -1.5400798e+00 -4.5987736e-02\n",
      " -4.3723911e-01 -1.2351930e+00 -1.5537095e-01 -2.0841862e-01\n",
      " -1.8606520e+00 -5.9393793e-04 -3.6003166e-01 -1.8570782e+00\n",
      "  1.5815663e-01 -3.2823035e-01 -1.3971918e+00 -1.5282506e-01\n",
      " -1.9761012e-01 -1.1739750e+00 -6.6620931e-02 -1.7802325e-01\n",
      " -1.2591355e+00 -2.2320703e-02 -1.9408941e-01 -1.3791182e+00\n",
      "  4.8713304e-02 -2.0370826e-01 -1.2475183e+00  7.0000000e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0102, -0.0693, -0.2598,  ...,  0.0176, -0.2459, -1.3157],\n",
      "        [ 0.0102, -0.0693, -0.2598,  ...,  0.0176, -0.2459, -1.3157],\n",
      "        [ 0.0102, -0.0693, -0.2598,  ...,  0.0176, -0.2459, -1.3157],\n",
      "        ...,\n",
      "        [-0.3330,  0.2517, -0.2988,  ..., -0.7963,  0.7065, -0.4631],\n",
      "        [-0.1239, -0.0322,  0.6275,  ..., -0.2299,  0.7668,  0.3044],\n",
      "        [-0.1239, -0.0322,  0.6275,  ..., -0.2299,  0.7668,  0.3044]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01024572 -0.06931494 -0.2598051   0.03312368 -0.2075434  -0.68211603\n",
      " -0.07930832 -0.39508712 -1.4422097  -0.22210291 -0.460741   -1.7198243\n",
      " -0.37954766 -0.5575431  -2.203863   -0.18865076 -0.6795629  -1.5934205\n",
      " -0.01316372 -0.71378154 -1.4135439  -0.0533497  -0.6419605  -1.4709892\n",
      " -0.05412048 -0.7772885  -1.5830765  -0.15499717 -0.5786366  -1.5188525\n",
      " -0.08566172 -0.6265348  -1.4798243  -0.102837   -0.59772456 -1.5636504\n",
      "  0.03792007 -0.6093027  -1.6019843  -0.08149062 -0.4948063  -1.3575823\n",
      " -0.18831497 -0.26535553 -1.9734454  -0.04275692 -0.40987033 -1.9808154\n",
      "  0.11367745 -0.37895876 -1.4695594  -0.17289576 -0.26083225 -1.2903743\n",
      " -0.11604499 -0.23133117 -1.3662765  -0.07049152 -0.23005366 -1.482204\n",
      "  0.01759061 -0.24590851 -1.3157165 ]\n",
      "data: [ 0.01024572 -0.06931494 -0.2598051   0.03312368 -0.20754342 -0.68211603\n",
      " -0.07930832 -0.39508712 -1.4422097  -0.22210291 -0.460741   -1.7198243\n",
      " -0.37954766 -0.5575431  -2.203863   -0.18865076 -0.6795629  -1.5934205\n",
      " -0.01316372 -0.71378154 -1.413544   -0.0533497  -0.6419605  -1.4709892\n",
      " -0.05412048 -0.7772885  -1.5830765  -0.15499717 -0.5786366  -1.5188526\n",
      " -0.08566172 -0.6265348  -1.4798244  -0.102837   -0.59772456 -1.5636504\n",
      "  0.03792007 -0.6093027  -1.6019843  -0.08149062 -0.4948063  -1.3575824\n",
      " -0.18831497 -0.26535553 -1.9734454  -0.04275693 -0.40987033 -1.9808154\n",
      "  0.11367746 -0.3789588  -1.4695594  -0.17289576 -0.26083225 -1.2903743\n",
      " -0.11604499 -0.23133117 -1.3662765  -0.07049152 -0.23005368 -1.482204\n",
      "  0.01759061 -0.24590851 -1.3157165   0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0310, -0.0370, -0.2254,  ...,  0.0422, -0.2325, -1.2599],\n",
      "        [ 0.0310, -0.0370, -0.2254,  ...,  0.0422, -0.2325, -1.2599],\n",
      "        [ 0.0310, -0.0370, -0.2254,  ...,  0.0422, -0.2325, -1.2599],\n",
      "        ...,\n",
      "        [-0.1242,  0.4261, -0.1213,  ..., -0.7403,  0.9402, -0.3746],\n",
      "        [-0.1425, -0.1996,  0.5466,  ..., -0.2242,  0.5669,  0.2386],\n",
      "        [-0.1425, -0.1996,  0.5466,  ..., -0.2242,  0.5669,  0.2386]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03098525 -0.0369584  -0.22536117  0.0457354  -0.1634521  -0.6162344\n",
      " -0.06468469 -0.34620738 -1.3712485  -0.21197489 -0.40877116 -1.6614351\n",
      " -0.37882566 -0.5032124  -2.1528764  -0.16229638 -0.65427005 -1.5283666\n",
      "  0.00432426 -0.69171864 -1.3727202  -0.04136017 -0.61794734 -1.4362378\n",
      " -0.03623128 -0.7666334  -1.550544   -0.1260556  -0.5603209  -1.4475327\n",
      " -0.06136589 -0.60525876 -1.4175541  -0.08286375 -0.58111477 -1.5134637\n",
      "  0.05832118 -0.59067565 -1.5440633  -0.0524356  -0.47312889 -1.2852862\n",
      " -0.16334678 -0.24868193 -1.9304912  -0.01802361 -0.39201474 -1.9440534\n",
      "  0.14322752 -0.36902076 -1.4075608  -0.1451025  -0.24416183 -1.2203326\n",
      " -0.09040126 -0.22229508 -1.3060975  -0.05568475 -0.21716872 -1.4232748\n",
      "  0.04217426 -0.23254047 -1.2598553 ]\n",
      "data: [ 0.03098525 -0.0369584  -0.22536117  0.0457354  -0.1634521  -0.6162344\n",
      " -0.06468469 -0.34620738 -1.3712485  -0.21197489 -0.40877116 -1.6614351\n",
      " -0.3788257  -0.5032124  -2.1528764  -0.16229638 -0.65427    -1.5283666\n",
      "  0.00432426 -0.6917187  -1.3727202  -0.04136017 -0.61794734 -1.4362378\n",
      " -0.03623128 -0.7666334  -1.550544   -0.1260556  -0.5603209  -1.4475327\n",
      " -0.06136589 -0.60525876 -1.4175541  -0.08286375 -0.58111477 -1.5134637\n",
      "  0.05832118 -0.59067565 -1.5440632  -0.0524356  -0.47312889 -1.2852863\n",
      " -0.16334678 -0.24868193 -1.9304912  -0.01802361 -0.39201474 -1.9440533\n",
      "  0.14322752 -0.36902076 -1.4075608  -0.1451025  -0.24416183 -1.2203326\n",
      " -0.09040126 -0.22229508 -1.3060975  -0.05568475 -0.21716872 -1.4232746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.04217426 -0.23254047 -1.2598553   0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0199, -0.0697, -0.2487,  ...,  0.0320, -0.2531, -1.2927],\n",
      "        [ 0.0199, -0.0697, -0.2487,  ...,  0.0320, -0.2531, -1.2927],\n",
      "        [ 0.0199, -0.0697, -0.2487,  ...,  0.0320, -0.2531, -1.2927],\n",
      "        ...,\n",
      "        [-0.3097,  0.2221, -0.2705,  ..., -0.8127,  0.6871, -0.4634],\n",
      "        [-0.1198, -0.0546,  0.5971,  ..., -0.2316,  0.7330,  0.2658],\n",
      "        [-0.1198, -0.0546,  0.5971,  ..., -0.2316,  0.7330,  0.2658]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01993579 -0.06966496 -0.24868593  0.04546595 -0.20132595 -0.65480894\n",
      " -0.06169572 -0.38936648 -1.4213474  -0.20471168 -0.45474204 -1.707409\n",
      " -0.36309698 -0.5531723  -2.1952357  -0.1739611  -0.67992055 -1.5750332\n",
      "  0.01060649 -0.7160629  -1.3920755  -0.03621762 -0.6476884  -1.4501544\n",
      " -0.04519835 -0.7880746  -1.5663325  -0.13796845 -0.5832308  -1.4938437\n",
      " -0.06822199 -0.6332417  -1.4603218  -0.0903716  -0.604864   -1.5490668\n",
      "  0.04306478 -0.62273866 -1.5850796  -0.06169336 -0.4949101  -1.3288889\n",
      " -0.17586058 -0.26691678 -1.972605   -0.02801518 -0.41588277 -1.9816806\n",
      "  0.12506765 -0.38769275 -1.4466456  -0.15750927 -0.26335585 -1.261453\n",
      " -0.09531512 -0.2372543  -1.3397003  -0.05449202 -0.23855072 -1.4558673\n",
      "  0.03199758 -0.25306916 -1.2926606 ]\n",
      "data: [ 0.01993579 -0.06966496 -0.24868593  0.04546595 -0.20132595 -0.65480894\n",
      " -0.06169572 -0.3893665  -1.4213474  -0.20471169 -0.45474204 -1.707409\n",
      " -0.363097   -0.5531723  -2.1952357  -0.1739611  -0.67992055 -1.5750333\n",
      "  0.01060649 -0.7160629  -1.3920755  -0.03621762 -0.6476884  -1.4501544\n",
      " -0.04519835 -0.7880747  -1.5663323  -0.13796845 -0.5832308  -1.4938437\n",
      " -0.06822199 -0.6332417  -1.4603218  -0.0903716  -0.604864   -1.5490668\n",
      "  0.04306478 -0.62273866 -1.5850796  -0.06169336 -0.4949101  -1.3288889\n",
      " -0.17586058 -0.26691678 -1.972605   -0.02801518 -0.41588277 -1.9816806\n",
      "  0.12506765 -0.38769275 -1.4466456  -0.15750927 -0.26335585 -1.261453\n",
      " -0.09531512 -0.23725432 -1.3397003  -0.05449202 -0.23855072 -1.4558673\n",
      "  0.03199758 -0.25306916 -1.2926605   0.1       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0187, -0.0340, -0.2442,  ...,  0.0442, -0.2280, -1.2735],\n",
      "        [ 0.0187, -0.0340, -0.2442,  ...,  0.0442, -0.2280, -1.2735],\n",
      "        [ 0.0187, -0.0340, -0.2442,  ...,  0.0442, -0.2280, -1.2735],\n",
      "        ...,\n",
      "        [-0.1402,  0.3682, -0.1050,  ..., -0.7597,  0.8633, -0.3519],\n",
      "        [-0.1398, -0.1774,  0.5514,  ..., -0.2241,  0.5857,  0.2216],\n",
      "        [-0.1398, -0.1774,  0.5514,  ..., -0.2241,  0.5857,  0.2216]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0187253  -0.0340382  -0.24415536  0.03442964 -0.163959   -0.6357593\n",
      " -0.06546284 -0.34910768 -1.38576    -0.21017951 -0.41019332 -1.6806914\n",
      " -0.3784844  -0.516016   -2.160459   -0.18052876 -0.6461446  -1.5448583\n",
      "  0.01111954 -0.6821052  -1.3773452  -0.03746217 -0.61397254 -1.4355869\n",
      " -0.03325067 -0.7581028  -1.5510861  -0.13857403 -0.5482849  -1.4597867\n",
      " -0.06493092 -0.5990529  -1.4332521  -0.07838099 -0.5752411  -1.5285146\n",
      "  0.05787501 -0.59343493 -1.5657237  -0.05484162 -0.46058643 -1.2936817\n",
      " -0.17032844 -0.23605642 -1.9470209  -0.01595812 -0.3881109  -1.9539549\n",
      "  0.14444256 -0.3599206  -1.4251697  -0.1539166  -0.22981551 -1.229129\n",
      " -0.08462662 -0.20924242 -1.313206   -0.0444864  -0.21470958 -1.4300601\n",
      "  0.04417196 -0.2280462  -1.273493  ]\n",
      "data: [ 0.0187253  -0.0340382  -0.24415536  0.03442964 -0.16395898 -0.6357593\n",
      " -0.06546284 -0.34910765 -1.3857598  -0.21017951 -0.41019332 -1.6806914\n",
      " -0.37848437 -0.516016   -2.160459   -0.18052876 -0.6461446  -1.5448585\n",
      "  0.01111954 -0.6821052  -1.3773453  -0.03746217 -0.61397254 -1.4355868\n",
      " -0.03325067 -0.7581028  -1.5510861  -0.13857403 -0.5482849  -1.4597867\n",
      " -0.06493092 -0.5990529  -1.4332521  -0.07838099 -0.5752411  -1.5285145\n",
      "  0.05787501 -0.59343493 -1.5657238  -0.05484162 -0.46058643 -1.2936817\n",
      " -0.17032844 -0.23605642 -1.9470209  -0.01595812 -0.38811094 -1.9539549\n",
      "  0.14444256 -0.3599206  -1.4251697  -0.1539166  -0.22981553 -1.229129\n",
      " -0.08462663 -0.20924242 -1.3132061  -0.04448639 -0.21470958 -1.4300601\n",
      "  0.04417196 -0.2280462  -1.273493    0.11      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F898>\n",
      "tensor([[ 0.0132, -0.0842, -0.2445,  ...,  0.0303, -0.2682, -1.3034],\n",
      "        [ 0.0132, -0.0842, -0.2445,  ...,  0.0303, -0.2682, -1.3034],\n",
      "        [ 0.0132, -0.0842, -0.2445,  ...,  0.0303, -0.2682, -1.3034],\n",
      "        ...,\n",
      "        [-0.3820,  0.1613, -0.3620,  ..., -0.8460,  0.5785, -0.5050],\n",
      "        [-0.1389, -0.0780,  0.5941,  ..., -0.2411,  0.7120,  0.2555],\n",
      "        [-0.1389, -0.0780,  0.5941,  ..., -0.2411,  0.7120,  0.2555]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01317122 -0.08420759 -0.24447842  0.03387051 -0.22291018 -0.6670164\n",
      " -0.05781015 -0.40272167 -1.4146664  -0.19922587 -0.46573347 -1.707496\n",
      " -0.3650534  -0.57390565 -2.185775   -0.18652824 -0.6884461  -1.5699589\n",
      "  0.01727763 -0.71784186 -1.3798735  -0.03082883 -0.6531759  -1.4372903\n",
      " -0.03544701 -0.7856607  -1.5528088  -0.14727165 -0.5864631  -1.4885563\n",
      " -0.06896251 -0.63815844 -1.4606987  -0.08568815 -0.6128505  -1.5542698\n",
      "  0.04498531 -0.6306838  -1.5992135  -0.06493799 -0.5036864  -1.3195809\n",
      " -0.17197004 -0.27776727 -1.9419552  -0.02732164 -0.42539236 -1.9434358\n",
      "  0.12402959 -0.39702588 -1.4558326  -0.16129605 -0.2691484  -1.2558676\n",
      " -0.0905993  -0.24664025 -1.3354272  -0.04584904 -0.255022   -1.4517472\n",
      "  0.03030748 -0.26821536 -1.3034326 ]\n",
      "data: [ 0.01317122 -0.08420759 -0.24447842  0.03387051 -0.22291018 -0.6670164\n",
      " -0.05781015 -0.40272167 -1.4146664  -0.19922586 -0.46573344 -1.707496\n",
      " -0.36505336 -0.57390565 -2.185775   -0.18652825 -0.6884461  -1.5699589\n",
      "  0.01727763 -0.71784186 -1.3798735  -0.03082883 -0.6531759  -1.4372903\n",
      " -0.03544701 -0.7856607  -1.5528089  -0.14727165 -0.5864631  -1.4885563\n",
      " -0.06896251 -0.63815844 -1.4606987  -0.08568815 -0.6128505  -1.5542697\n",
      "  0.04498531 -0.6306838  -1.5992134  -0.06493799 -0.5036864  -1.3195808\n",
      " -0.17197004 -0.27776727 -1.9419552  -0.02732164 -0.42539233 -1.9434358\n",
      "  0.12402959 -0.39702588 -1.4558327  -0.16129607 -0.2691484  -1.2558676\n",
      " -0.0905993  -0.24664025 -1.335427   -0.04584904 -0.255022   -1.4517472\n",
      "  0.03030748 -0.26821536 -1.3034326   0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[ 0.0292, -0.0712, -0.2568,  ...,  0.0470, -0.2604, -1.2756],\n",
      "        [ 0.0292, -0.0712, -0.2568,  ...,  0.0470, -0.2604, -1.2756],\n",
      "        [ 0.0292, -0.0712, -0.2568,  ...,  0.0470, -0.2604, -1.2756],\n",
      "        ...,\n",
      "        [-0.1131,  0.4028, -0.1182,  ..., -0.6925,  0.9186, -0.4084],\n",
      "        [-0.1317, -0.1494,  0.5852,  ..., -0.2366,  0.6244,  0.2316],\n",
      "        [-0.1317, -0.1494,  0.5852,  ..., -0.2366,  0.6244,  0.2316]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02916662 -0.07121755 -0.25683823  0.05573737 -0.1874336  -0.6280253\n",
      " -0.061896   -0.38714936 -1.4160516  -0.20724678 -0.45026577 -1.7057368\n",
      " -0.36000913 -0.5431663  -2.2015133  -0.15958752 -0.69123936 -1.5733212\n",
      "  0.01099057 -0.7386838  -1.4203315  -0.04005335 -0.6666436  -1.4796513\n",
      " -0.04582473 -0.8232968  -1.5993981  -0.12081635 -0.6024811  -1.483692\n",
      " -0.06065308 -0.65020525 -1.455825   -0.08193974 -0.6211251  -1.5445349\n",
      "  0.05071092 -0.64407504 -1.5690382  -0.04484559 -0.50279593 -1.321171\n",
      " -0.17687836 -0.27244315 -2.0243282  -0.01500839 -0.42969415 -2.0433455\n",
      "  0.14415224 -0.39983675 -1.4338677  -0.14805438 -0.27652055 -1.2486303\n",
      " -0.08610347 -0.24931505 -1.335945   -0.052626   -0.24709266 -1.4516914\n",
      "  0.04699627 -0.2604264  -1.275606  ]\n",
      "data: [ 0.02916662 -0.07121755 -0.25683823  0.05573737 -0.1874336  -0.6280253\n",
      " -0.061896   -0.38714936 -1.4160516  -0.20724678 -0.45026577 -1.7057366\n",
      " -0.3600091  -0.5431663  -2.2015133  -0.15958752 -0.6912393  -1.5733212\n",
      "  0.01099057 -0.7386839  -1.4203315  -0.04005335 -0.6666436  -1.4796513\n",
      " -0.04582473 -0.8232968  -1.5993981  -0.12081634 -0.6024811  -1.483692\n",
      " -0.06065308 -0.65020525 -1.4558251  -0.08193974 -0.6211251  -1.5445349\n",
      "  0.05071092 -0.64407504 -1.569038   -0.04484559 -0.50279593 -1.3211712\n",
      " -0.17687836 -0.27244315 -2.0243282  -0.01500839 -0.42969415 -2.0433455\n",
      "  0.14415224 -0.39983672 -1.4338677  -0.14805438 -0.27652055 -1.2486303\n",
      " -0.08610347 -0.24931505 -1.335945   -0.052626   -0.24709266 -1.4516914\n",
      "  0.04699627 -0.2604264  -1.275606    0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F0B8>\n",
      "tensor([[ 0.0230, -0.0372, -0.2422,  ...,  0.0576, -0.2269, -1.2875],\n",
      "        [ 0.0230, -0.0372, -0.2422,  ...,  0.0576, -0.2269, -1.2875],\n",
      "        [ 0.0230, -0.0372, -0.2422,  ...,  0.0576, -0.2269, -1.2875],\n",
      "        ...,\n",
      "        [-0.1597,  0.3064, -0.0638,  ..., -0.8163,  0.7750, -0.2602],\n",
      "        [-0.1439, -0.1477,  0.5407,  ..., -0.2249,  0.6090,  0.2045],\n",
      "        [-0.1439, -0.1477,  0.5407,  ..., -0.2249,  0.6090,  0.2045]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.3042787e-02 -3.7230767e-02 -2.4223529e-01  3.5724577e-02\n",
      " -1.8028998e-01 -6.5864050e-01 -4.0733352e-02 -3.5711950e-01\n",
      " -1.3823895e+00 -1.8318781e-01 -4.1604334e-01 -1.6870021e+00\n",
      " -3.6080936e-01 -5.3784776e-01 -2.1495292e+00 -1.8492353e-01\n",
      " -6.4026117e-01 -1.5435262e+00  4.4981636e-02 -6.6600215e-01\n",
      " -1.3499525e+00 -6.9272146e-03 -6.0652733e-01 -1.4039832e+00\n",
      " -4.6802983e-03 -7.3688364e-01 -1.5198811e+00 -1.3772333e-01\n",
      " -5.3281367e-01 -1.4575163e+00 -4.7519006e-02 -5.8990312e-01\n",
      " -1.4353443e+00 -5.4078214e-02 -5.6793535e-01 -1.5353205e+00\n",
      "  7.5322591e-02 -5.9230816e-01 -1.5865121e+00 -4.1371629e-02\n",
      " -4.4928089e-01 -1.2843589e+00 -1.5145689e-01 -2.2720829e-01\n",
      " -1.9146917e+00  1.9137785e-03 -3.8235337e-01 -1.9087580e+00\n",
      "  1.5758198e-01 -3.5089782e-01 -1.4381639e+00 -1.4449716e-01\n",
      " -2.1268624e-01 -1.2242508e+00 -5.8170266e-02 -1.9572136e-01\n",
      " -1.3048688e+00 -1.1379279e-02 -2.1538013e-01 -1.4227263e+00\n",
      "  5.7570726e-02 -2.2686397e-01 -1.2875177e+00]\n",
      "data: [ 2.3042787e-02 -3.7230767e-02 -2.4223527e-01  3.5724577e-02\n",
      " -1.8029000e-01 -6.5864050e-01 -4.0733352e-02 -3.5711947e-01\n",
      " -1.3823895e+00 -1.8318781e-01 -4.1604337e-01 -1.6870021e+00\n",
      " -3.6080936e-01 -5.3784776e-01 -2.1495292e+00 -1.8492353e-01\n",
      " -6.4026117e-01 -1.5435262e+00  4.4981636e-02 -6.6600209e-01\n",
      " -1.3499523e+00 -6.9272150e-03 -6.0652733e-01 -1.4039834e+00\n",
      " -4.6802983e-03 -7.3688364e-01 -1.5198811e+00 -1.3772333e-01\n",
      " -5.3281367e-01 -1.4575163e+00 -4.7519006e-02 -5.8990312e-01\n",
      " -1.4353443e+00 -5.4078210e-02 -5.6793535e-01 -1.5353206e+00\n",
      "  7.5322591e-02 -5.9230816e-01 -1.5865121e+00 -4.1371629e-02\n",
      " -4.4928089e-01 -1.2843589e+00 -1.5145689e-01 -2.2720829e-01\n",
      " -1.9146916e+00  1.9137785e-03 -3.8235337e-01 -1.9087580e+00\n",
      "  1.5758198e-01 -3.5089782e-01 -1.4381639e+00 -1.4449716e-01\n",
      " -2.1268624e-01 -1.2242508e+00 -5.8170266e-02 -1.9572136e-01\n",
      " -1.3048688e+00 -1.1379279e-02 -2.1538013e-01 -1.4227263e+00\n",
      "  5.7570726e-02 -2.2686395e-01 -1.2875177e+00  1.4000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0041, -0.0836, -0.2582,  ...,  0.0346, -0.2694, -1.3243],\n",
      "        [ 0.0041, -0.0836, -0.2582,  ...,  0.0346, -0.2694, -1.3243],\n",
      "        [ 0.0041, -0.0836, -0.2582,  ...,  0.0346, -0.2694, -1.3243],\n",
      "        ...,\n",
      "        [-0.1612,  0.4267, -0.1277,  ..., -0.7379,  0.9055, -0.3494],\n",
      "        [-0.1618, -0.1301,  0.5748,  ..., -0.2441,  0.6576,  0.2250],\n",
      "        [-0.1618, -0.1301,  0.5748,  ..., -0.2441,  0.6576,  0.2250]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00407988 -0.08359344 -0.2582027   0.02187051 -0.22928755 -0.6863927\n",
      " -0.05784484 -0.40370727 -1.426588   -0.1973928  -0.46529534 -1.723791\n",
      " -0.36754414 -0.5827589  -2.1953363  -0.19925562 -0.6832558  -1.5873829\n",
      "  0.02424657 -0.706555   -1.3903131  -0.02450652 -0.6442908  -1.4457728\n",
      " -0.02278657 -0.7686751  -1.5609192  -0.15684618 -0.5756391  -1.5057184\n",
      " -0.0677494  -0.6291536  -1.481269   -0.07786174 -0.60508585 -1.5768788\n",
      "  0.05266879 -0.62423277 -1.6291211  -0.06693908 -0.49808642 -1.3321203\n",
      " -0.16779985 -0.27194118 -1.9375144  -0.02313013 -0.4207144  -1.9315535\n",
      "  0.13012919 -0.39059308 -1.4804531  -0.16552384 -0.25997525 -1.2699429\n",
      " -0.08363894 -0.24044001 -1.3478446  -0.03423342 -0.2562467  -1.464148\n",
      "  0.03460834 -0.26935798 -1.3243209 ]\n",
      "data: [ 0.00407988 -0.08359344 -0.2582027   0.02187051 -0.22928755 -0.6863927\n",
      " -0.05784484 -0.40370727 -1.4265882  -0.1973928  -0.46529534 -1.723791\n",
      " -0.36754414 -0.5827589  -2.1953363  -0.19925562 -0.6832558  -1.5873829\n",
      "  0.02424657 -0.706555   -1.3903131  -0.02450652 -0.64429075 -1.4457726\n",
      " -0.02278657 -0.7686751  -1.5609192  -0.15684618 -0.5756391  -1.5057184\n",
      " -0.0677494  -0.6291536  -1.4812691  -0.07786174 -0.60508585 -1.5768788\n",
      "  0.05266879 -0.62423277 -1.6291211  -0.06693908 -0.49808642 -1.3321204\n",
      " -0.16779986 -0.27194118 -1.9375145  -0.02313013 -0.4207144  -1.9315535\n",
      "  0.13012919 -0.39059308 -1.4804531  -0.16552383 -0.25997525 -1.2699429\n",
      " -0.08363894 -0.24044001 -1.3478446  -0.03423342 -0.2562467  -1.464148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.03460834 -0.26935798 -1.324321    0.15      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B320>\n",
      "tensor([[ 0.0241, -0.0933, -0.2459,  ...,  0.0459, -0.2781, -1.2807],\n",
      "        [ 0.0241, -0.0933, -0.2459,  ...,  0.0459, -0.2781, -1.2807],\n",
      "        [ 0.0241, -0.0933, -0.2459,  ...,  0.0459, -0.2781, -1.2807],\n",
      "        ...,\n",
      "        [-0.1527,  0.3986, -0.1902,  ..., -0.7500,  0.9068, -0.4612],\n",
      "        [-0.1692, -0.1684,  0.5791,  ..., -0.2687,  0.6039,  0.2355],\n",
      "        [-0.1692, -0.1684,  0.5791,  ..., -0.2687,  0.6039,  0.2355]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02405426 -0.09329669 -0.24587399  0.04516376 -0.22385135 -0.6413789\n",
      " -0.05228023 -0.4159141  -1.4008029  -0.19413619 -0.47682616 -1.6946249\n",
      " -0.35476357 -0.5829661  -2.1721427  -0.17270982 -0.7067873  -1.5596671\n",
      "  0.0235682  -0.74467915 -1.3943219  -0.02722746 -0.678051   -1.4503255\n",
      " -0.02631444 -0.8210188  -1.5672812  -0.13112943 -0.607279   -1.4726441\n",
      " -0.0577386  -0.6581544  -1.4470634  -0.07004002 -0.63195837 -1.5378811\n",
      "  0.05928189 -0.65534395 -1.5748246  -0.04646807 -0.5135435  -1.3071845\n",
      " -0.17021157 -0.28638527 -1.9779005  -0.01119384 -0.4428941  -1.9850924\n",
      "  0.14500926 -0.40908748 -1.4369848  -0.15102048 -0.28183347 -1.2394478\n",
      " -0.07761821 -0.2575308  -1.3241556  -0.03760019 -0.26579723 -1.4397407\n",
      "  0.04589526 -0.27813    -1.2807441 ]\n",
      "data: [ 0.02405426 -0.09329669 -0.24587399  0.04516376 -0.22385135 -0.6413789\n",
      " -0.05228023 -0.4159141  -1.400803   -0.19413619 -0.47682616 -1.6946249\n",
      " -0.35476357 -0.5829661  -2.1721427  -0.17270982 -0.7067873  -1.5596671\n",
      "  0.0235682  -0.7446792  -1.3943219  -0.02722746 -0.678051   -1.4503255\n",
      " -0.02631444 -0.8210188  -1.5672812  -0.13112943 -0.607279   -1.4726441\n",
      " -0.0577386  -0.6581544  -1.4470634  -0.07004002 -0.63195837 -1.5378811\n",
      "  0.05928188 -0.65534395 -1.5748246  -0.04646807 -0.5135435  -1.3071845\n",
      " -0.17021157 -0.28638527 -1.9779005  -0.01119384 -0.4428941  -1.9850925\n",
      "  0.14500926 -0.40908748 -1.4369847  -0.15102048 -0.28183347 -1.2394478\n",
      " -0.07761821 -0.2575308  -1.3241556  -0.03760019 -0.26579723 -1.4397407\n",
      "  0.04589526 -0.27813    -1.2807441   0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BB38>\n",
      "tensor([[ 0.0203, -0.0423, -0.2425,  ...,  0.0457, -0.2376, -1.2608],\n",
      "        [ 0.0203, -0.0423, -0.2425,  ...,  0.0457, -0.2376, -1.2608],\n",
      "        [ 0.0203, -0.0423, -0.2425,  ...,  0.0457, -0.2376, -1.2608],\n",
      "        ...,\n",
      "        [-0.1507,  0.3545, -0.0864,  ..., -0.7675,  0.8441, -0.3535],\n",
      "        [-0.1277, -0.1458,  0.5647,  ..., -0.1990,  0.6161,  0.2121],\n",
      "        [-0.1277, -0.1458,  0.5647,  ..., -0.1990,  0.6161,  0.2121]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02032201 -0.04232518 -0.24251935  0.03750729 -0.1674389  -0.619884\n",
      " -0.07305197 -0.36381134 -1.3907509  -0.22104084 -0.42669317 -1.6868615\n",
      " -0.38773397 -0.52973783 -2.1714387  -0.17872459 -0.6626768  -1.5492554\n",
      "  0.00834455 -0.70633155 -1.3744185  -0.04324014 -0.6368795  -1.4329362\n",
      " -0.04687808 -0.78968304 -1.5523462  -0.13597015 -0.567352   -1.4596367\n",
      " -0.06841292 -0.6194267  -1.4315226  -0.08480944 -0.5943592  -1.5252087\n",
      "  0.05102829 -0.6158621  -1.5557768  -0.0518491  -0.47231787 -1.2937882\n",
      " -0.17923045 -0.24662167 -1.9799185  -0.01842423 -0.4044822  -1.9916806\n",
      "  0.1449407  -0.37449282 -1.4151249  -0.15448698 -0.24288552 -1.22539\n",
      " -0.08705758 -0.2208285  -1.3118737  -0.05002124 -0.22453347 -1.4285755\n",
      "  0.04565737 -0.23757015 -1.2608013 ]\n",
      "data: [ 0.02032201 -0.04232518 -0.24251933  0.03750729 -0.1674389  -0.619884\n",
      " -0.07305197 -0.36381134 -1.3907509  -0.22104084 -0.42669314 -1.6868615\n",
      " -0.38773397 -0.52973783 -2.1714387  -0.17872459 -0.6626769  -1.5492554\n",
      "  0.00834455 -0.70633155 -1.3744185  -0.04324014 -0.6368795  -1.4329362\n",
      " -0.04687808 -0.7896831  -1.5523462  -0.13597015 -0.567352   -1.4596367\n",
      " -0.06841292 -0.6194267  -1.4315227  -0.08480944 -0.5943592  -1.5252087\n",
      "  0.05102829 -0.6158621  -1.5557768  -0.0518491  -0.47231787 -1.2937882\n",
      " -0.17923047 -0.24662167 -1.9799185  -0.01842423 -0.4044822  -1.9916806\n",
      "  0.1449407  -0.37449282 -1.4151248  -0.15448698 -0.24288552 -1.22539\n",
      " -0.08705758 -0.22082849 -1.3118737  -0.05002124 -0.22453347 -1.4285754\n",
      "  0.04565737 -0.23757015 -1.2608013   0.17      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F438>\n",
      "tensor([[ 0.0097, -0.0175, -0.2367,  ...,  0.0328, -0.2104, -1.2826],\n",
      "        [ 0.0097, -0.0175, -0.2367,  ...,  0.0328, -0.2104, -1.2826],\n",
      "        [ 0.0097, -0.0175, -0.2367,  ...,  0.0328, -0.2104, -1.2826],\n",
      "        ...,\n",
      "        [-0.1950,  0.3170, -0.1135,  ..., -0.8350,  0.7675, -0.2843],\n",
      "        [-0.1441, -0.1694,  0.5389,  ..., -0.2148,  0.6050,  0.2085],\n",
      "        [-0.1441, -0.1694,  0.5389,  ..., -0.2148,  0.6050,  0.2085]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 9.6957423e-03 -1.7540956e-02 -2.3670152e-01  2.0198744e-02\n",
      " -1.5665853e-01 -6.5317059e-01 -7.7152520e-02 -3.3759966e-01\n",
      " -1.3940303e+00 -2.2170720e-01 -4.0134719e-01 -1.6876669e+00\n",
      " -3.9735940e-01 -5.1058763e-01 -2.1608167e+00 -1.9503158e-01\n",
      " -6.2774152e-01 -1.5464107e+00  1.8257424e-03 -6.5968937e-01\n",
      " -1.3583251e+00 -4.3820105e-02 -5.9263766e-01 -1.4164497e+00\n",
      " -4.0410087e-02 -7.3038417e-01 -1.5306120e+00 -1.5384853e-01\n",
      " -5.2475870e-01 -1.4649322e+00 -7.6631814e-02 -5.7720381e-01\n",
      " -1.4345090e+00 -8.9721777e-02 -5.5491596e-01 -1.5307798e+00\n",
      "  5.0859548e-02 -5.6873751e-01 -1.5745070e+00 -7.0448592e-02\n",
      " -4.4422770e-01 -1.2978053e+00 -1.7627239e-01 -2.2107893e-01\n",
      " -1.9210631e+00 -2.8854631e-02 -3.6793989e-01 -1.9232837e+00\n",
      "  1.3230395e-01 -3.4189343e-01 -1.4312024e+00 -1.6485283e-01\n",
      " -2.0893762e-01 -1.2340430e+00 -9.7116463e-02 -1.8972977e-01\n",
      " -1.3166769e+00 -5.2041925e-02 -1.9612694e-01 -1.4336727e+00\n",
      "  3.2794476e-02 -2.1040545e-01 -1.2826364e+00]\n",
      "data: [ 9.6957423e-03 -1.7540956e-02 -2.3670153e-01  2.0198744e-02\n",
      " -1.5665853e-01 -6.5317065e-01 -7.7152520e-02 -3.3759966e-01\n",
      " -1.3940303e+00 -2.2170720e-01 -4.0134719e-01 -1.6876669e+00\n",
      " -3.9735940e-01 -5.1058763e-01 -2.1608167e+00 -1.9503158e-01\n",
      " -6.2774152e-01 -1.5464107e+00  1.8257424e-03 -6.5968931e-01\n",
      " -1.3583252e+00 -4.3820105e-02 -5.9263766e-01 -1.4164498e+00\n",
      " -4.0410087e-02 -7.3038411e-01 -1.5306120e+00 -1.5384853e-01\n",
      " -5.2475870e-01 -1.4649322e+00 -7.6631814e-02 -5.7720381e-01\n",
      " -1.4345089e+00 -8.9721777e-02 -5.5491596e-01 -1.5307798e+00\n",
      "  5.0859548e-02 -5.6873751e-01 -1.5745070e+00 -7.0448592e-02\n",
      " -4.4422767e-01 -1.2978053e+00 -1.7627239e-01 -2.2107893e-01\n",
      " -1.9210631e+00 -2.8854631e-02 -3.6793986e-01 -1.9232837e+00\n",
      "  1.3230395e-01 -3.4189343e-01 -1.4312024e+00 -1.6485283e-01\n",
      " -2.0893760e-01 -1.2340430e+00 -9.7116463e-02 -1.8972977e-01\n",
      " -1.3166767e+00 -5.2041925e-02 -1.9612694e-01 -1.4336727e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3.2794476e-02 -2.1040544e-01 -1.2826364e+00  1.8000001e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0298, -0.0944, -0.2253,  ...,  0.0415, -0.2793, -1.2887],\n",
      "        [ 0.0298, -0.0944, -0.2253,  ...,  0.0415, -0.2793, -1.2887],\n",
      "        [ 0.0298, -0.0944, -0.2253,  ...,  0.0415, -0.2793, -1.2887],\n",
      "        ...,\n",
      "        [-0.3447,  0.2673, -0.3659,  ..., -0.8881,  0.7105, -0.5020],\n",
      "        [-0.1401, -0.0853,  0.6052,  ..., -0.2408,  0.7101,  0.2831],\n",
      "        [-0.1401, -0.0853,  0.6052,  ..., -0.2408,  0.7101,  0.2831]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02980468 -0.0944279  -0.22531241  0.04968468 -0.23617496 -0.65564966\n",
      " -0.04248378 -0.40791294 -1.3882446  -0.182984   -0.47026825 -1.6770884\n",
      " -0.34849173 -0.5740971  -2.1573117  -0.16581956 -0.69838583 -1.5418682\n",
      "  0.02273691 -0.72247857 -1.3683832  -0.02121063 -0.6554276  -1.4299309\n",
      " -0.01921084 -0.78598994 -1.5415591  -0.13077798 -0.59643227 -1.4676651\n",
      " -0.05378554 -0.6437021  -1.4380842  -0.07388707 -0.61944336 -1.5323057\n",
      "  0.06012168 -0.6296937  -1.5767486  -0.05434228 -0.5171677  -1.3011203\n",
      " -0.15129846 -0.2938594  -1.9017724  -0.01491269 -0.43319562 -1.9041388\n",
      "  0.134208   -0.408033   -1.4369583  -0.14240438 -0.28464544 -1.2415241\n",
      " -0.0804932  -0.26217127 -1.319212   -0.03705171 -0.26433507 -1.4374014\n",
      "  0.04149192 -0.2792822  -1.2887274 ]\n",
      "data: [ 0.02980468 -0.0944279  -0.22531241  0.04968468 -0.23617497 -0.65564966\n",
      " -0.04248378 -0.40791294 -1.3882446  -0.182984   -0.47026825 -1.6770883\n",
      " -0.34849176 -0.5740971  -2.1573117  -0.16581956 -0.69838583 -1.5418683\n",
      "  0.02273691 -0.72247857 -1.3683832  -0.02121063 -0.6554276  -1.4299309\n",
      " -0.01921084 -0.78598994 -1.5415591  -0.13077798 -0.59643227 -1.4676651\n",
      " -0.05378554 -0.6437021  -1.4380842  -0.07388707 -0.61944336 -1.5323057\n",
      "  0.06012168 -0.6296937  -1.5767486  -0.05434228 -0.5171677  -1.3011203\n",
      " -0.15129846 -0.2938594  -1.9017723  -0.01491269 -0.43319562 -1.9041388\n",
      "  0.134208   -0.408033   -1.4369583  -0.14240438 -0.28464544 -1.2415241\n",
      " -0.0804932  -0.26217127 -1.3192121  -0.03705171 -0.26433507 -1.4374014\n",
      "  0.04149192 -0.2792822  -1.2887274   0.19      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[ 0.0282, -0.0811, -0.2347,  ...,  0.0535, -0.2728, -1.2553],\n",
      "        [ 0.0282, -0.0811, -0.2347,  ...,  0.0535, -0.2728, -1.2553],\n",
      "        [ 0.0282, -0.0811, -0.2347,  ...,  0.0535, -0.2728, -1.2553],\n",
      "        ...,\n",
      "        [-0.1342,  0.4133, -0.0857,  ..., -0.6803,  0.9076, -0.3705],\n",
      "        [-0.1709, -0.1329,  0.5785,  ..., -0.2704,  0.6418,  0.2198],\n",
      "        [-0.1709, -0.1329,  0.5785,  ..., -0.2704,  0.6418,  0.2198]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02816815 -0.08113734 -0.23470102  0.05448964 -0.20259416 -0.6067131\n",
      " -0.05689751 -0.40877473 -1.4034604  -0.201745   -0.4741286  -1.6977472\n",
      " -0.3580877  -0.5759067  -2.1875956  -0.1647164  -0.7030825  -1.5625972\n",
      "  0.0276154  -0.75211453 -1.385365   -0.02708234 -0.68484086 -1.440582\n",
      " -0.03968798 -0.83827746 -1.5627589  -0.12207609 -0.6093996  -1.4680835\n",
      " -0.05621065 -0.6630323  -1.4413962  -0.0739717  -0.63447803 -1.5292794\n",
      "  0.05361292 -0.66346437 -1.5588163  -0.038385   -0.508909   -1.301694\n",
      " -0.17596874 -0.27884126 -2.012947   -0.00942268 -0.44306737 -2.0264025\n",
      "  0.14836587 -0.4087786  -1.4176841  -0.14769542 -0.279141   -1.2278215\n",
      " -0.07524806 -0.25375974 -1.3134234  -0.03800599 -0.2602498  -1.4274628\n",
      "  0.05346889 -0.27275142 -1.2552907 ]\n",
      "data: [ 0.02816815 -0.08113734 -0.23470102  0.05448963 -0.20259416 -0.6067131\n",
      " -0.05689751 -0.40877473 -1.4034604  -0.20174499 -0.4741286  -1.6977472\n",
      " -0.3580877  -0.5759067  -2.1875956  -0.1647164  -0.7030825  -1.5625972\n",
      "  0.0276154  -0.75211453 -1.385365   -0.02708234 -0.68484086 -1.4405819\n",
      " -0.03968798 -0.83827746 -1.5627589  -0.12207609 -0.6093996  -1.4680835\n",
      " -0.05621065 -0.6630323  -1.4413962  -0.0739717  -0.63447803 -1.5292794\n",
      "  0.05361292 -0.66346437 -1.5588164  -0.038385   -0.508909   -1.301694\n",
      " -0.17596874 -0.27884126 -2.012947   -0.00942268 -0.44306737 -2.0264025\n",
      "  0.14836587 -0.4087786  -1.4176841  -0.14769542 -0.279141   -1.2278215\n",
      " -0.07524806 -0.25375974 -1.3134235  -0.03800599 -0.2602498  -1.4274628\n",
      "  0.05346889 -0.27275142 -1.2552907   0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[ 0.0226, -0.0326, -0.2272,  ...,  0.0524, -0.2233, -1.2639],\n",
      "        [ 0.0226, -0.0326, -0.2272,  ...,  0.0524, -0.2233, -1.2639],\n",
      "        [ 0.0226, -0.0326, -0.2272,  ...,  0.0524, -0.2233, -1.2639],\n",
      "        ...,\n",
      "        [-0.1732,  0.3196, -0.0942,  ..., -0.8005,  0.7683, -0.2880],\n",
      "        [-0.1389, -0.1402,  0.5657,  ..., -0.2003,  0.6145,  0.2224],\n",
      "        [-0.1389, -0.1402,  0.5657,  ..., -0.2003,  0.6145,  0.2224]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02261335 -0.03259488 -0.22722827  0.0358988  -0.17118192 -0.6328558\n",
      " -0.05360056 -0.3601619  -1.3790615  -0.1990054  -0.42242756 -1.6825256\n",
      " -0.37526977 -0.53995955 -2.150021   -0.18561791 -0.64506763 -1.5363955\n",
      "  0.03333679 -0.67985415 -1.3402103  -0.02033344 -0.61870426 -1.3946754\n",
      " -0.02466972 -0.7581346  -1.5131634  -0.13847889 -0.5400909  -1.4465063\n",
      " -0.05719346 -0.5980793  -1.4215841  -0.06730608 -0.5754268  -1.5194017\n",
      "  0.06275862 -0.60101813 -1.5643357  -0.0448676  -0.4505403  -1.2748191\n",
      " -0.16581438 -0.22724172 -1.9344547  -0.0074747  -0.38606045 -1.9342352\n",
      "  0.15063585 -0.35405213 -1.4163742  -0.14974532 -0.21457717 -1.2104315\n",
      " -0.06867282 -0.19587041 -1.2937682  -0.02432555 -0.21187077 -1.4106572\n",
      "  0.05238169 -0.22331305 -1.263922  ]\n",
      "data: [-2.82 -3.54  2.29 -2.83 -3.45  2.35 -2.78 -3.34  2.61 -2.76 -3.19  2.53\n",
      " -2.76 -3.19  2.53 -2.76 -3.16  2.53 -2.75 -3.28  2.49 -2.18 -1.89 -0.21\n",
      " -2.21 -1.79 -0.24 -2.15 -2.13  0.03  0.    0.    0.   -2.17 -1.68  0.02\n",
      " -2.13 -1.68  0.02 -2.1  -2.07 -0.01 -2.19 -2.13  0.03  0.    0.    0.\n",
      " -2.03 -1.64  0.15 -2.73 -3.25  2.49 -2.71 -3.28  2.49 -1.99 -1.62  0.24\n",
      " -2.01 -1.64  0.22  0.  ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F470>\n",
      "tensor([[ 0.0400,  0.0021, -0.0558,  ...,  0.0627, -0.2429,  0.0282],\n",
      "        [ 0.0400,  0.0021, -0.0558,  ...,  0.0627, -0.2429,  0.0282],\n",
      "        [ 0.0400,  0.0021, -0.0558,  ...,  0.0627, -0.2429,  0.0282],\n",
      "        ...,\n",
      "        [ 0.8066, -0.8571,  0.3204,  ..., -0.0544, -0.8569, -0.3960],\n",
      "        [-0.2616,  0.0179,  0.4265,  ..., -1.2756, -0.0550,  1.7485],\n",
      "        [-0.2616,  0.0179,  0.4265,  ..., -1.2756, -0.0550,  1.7485]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04004776  0.00208582 -0.05577053 -0.0475677   0.00323168 -0.05274851\n",
      " -0.13392326 -0.09401576 -0.19357686 -0.15984192 -0.18766683 -0.13679738\n",
      " -0.09685885 -0.22255976 -0.14254306 -0.15498358 -0.13278341 -0.39352334\n",
      " -0.08615998 -0.16279338  0.09037852 -0.14676878 -0.2530632   0.11698869\n",
      " -0.22766155 -0.22475386  0.05269196 -0.11958232 -0.14219859 -0.38879833\n",
      " -0.1949876  -0.1880113  -0.3162108  -0.22224298 -0.22063912 -0.25707236\n",
      " -0.24098486 -0.30194354 -0.20591101 -0.07844949 -0.10352759 -0.35479996\n",
      " -0.1411387  -0.17456867 -0.26755187 -0.15239036 -0.20096457 -0.26287365\n",
      " -0.08306831 -0.27297318 -0.11334734 -0.03553226 -0.06724973 -0.2672311\n",
      "  0.01530195 -0.11976935 -0.16405976  0.01690162 -0.17901997 -0.09862569\n",
      "  0.06270769 -0.24291216  0.02818788]\n",
      "init: [ 0.04004776  0.00208582 -0.05577053 -0.0475677   0.00323168 -0.05274851\n",
      " -0.13392326 -0.09401576 -0.19357686 -0.15984192 -0.18766683 -0.13679738\n",
      " -0.09685885 -0.22255976 -0.14254306 -0.15498358 -0.13278341 -0.39352334\n",
      " -0.08615998 -0.16279338  0.09037852 -0.14676878 -0.2530632   0.11698869\n",
      " -0.22766155 -0.22475386  0.05269196 -0.11958232 -0.14219859 -0.38879833\n",
      " -0.1949876  -0.1880113  -0.3162108  -0.22224298 -0.22063912 -0.25707236\n",
      " -0.24098486 -0.30194354 -0.20591101 -0.07844949 -0.10352759 -0.35479996\n",
      " -0.1411387  -0.17456867 -0.26755187 -0.15239036 -0.20096457 -0.26287365\n",
      " -0.08306831 -0.27297318 -0.11334734 -0.03553226 -0.06724973 -0.2672311\n",
      "  0.01530195 -0.11976935 -0.16405976  0.01690162 -0.17901997 -0.09862569\n",
      "  0.06270769 -0.24291216  0.02818788]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [ 0.04004775  0.00208582 -0.05577053 -0.0475677   0.00323168 -0.05274851\n",
      " -0.13392326 -0.09401576 -0.19357686 -0.15984192 -0.18766683 -0.13679738\n",
      " -0.09685885 -0.22255975 -0.14254306 -0.15498358 -0.13278341 -0.39352334\n",
      " -0.08615998 -0.16279338  0.09037852 -0.14676878 -0.2530632   0.11698869\n",
      " -0.22766155 -0.22475386  0.05269196 -0.11958232 -0.14219859 -0.38879833\n",
      " -0.1949876  -0.1880113  -0.3162108  -0.22224298 -0.22063914 -0.25707236\n",
      " -0.24098486 -0.30194354 -0.20591101 -0.07844949 -0.10352759 -0.35479996\n",
      " -0.1411387  -0.17456867 -0.26755187 -0.15239036 -0.20096457 -0.26287365\n",
      " -0.08306831 -0.27297318 -0.11334734 -0.03553226 -0.06724973 -0.2672311\n",
      "  0.01530195 -0.11976936 -0.16405976  0.01690162 -0.17901997 -0.09862569\n",
      "  0.06270769 -0.24291216  0.02818788  0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FF28>\n",
      "tensor([[-0.1413, -0.1303,  0.5330,  ..., -0.6219, -0.4314, -0.0778],\n",
      "        [-0.1413, -0.1303,  0.5330,  ..., -0.6219, -0.4314, -0.0778],\n",
      "        [-0.1413, -0.1303,  0.5330,  ..., -0.6219, -0.4314, -0.0778],\n",
      "        ...,\n",
      "        [ 0.5459, -0.0533, -0.3558,  ...,  0.7800,  0.6452, -0.8529],\n",
      "        [ 0.5309, -0.0549, -0.3646,  ...,  0.7057,  0.7370, -0.9246],\n",
      "        [ 0.5309, -0.0549, -0.3646,  ...,  0.7057,  0.7370, -0.9246]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.14132203 -0.13034119  0.53299993 -0.25339034 -0.20449325 -0.05493146\n",
      " -0.4529305  -0.2659465  -0.05343324 -0.65116936 -0.33885396 -0.09817243\n",
      " -0.77042216 -0.4310981  -0.23234373 -0.5755889  -0.46142218 -0.30828804\n",
      " -0.7623726  -0.51484346 -0.44572127 -0.8609047  -0.57528234 -0.46658385\n",
      " -0.89964205 -0.6632389  -0.46426165 -0.5424788  -0.44982108 -0.3272457\n",
      " -0.7400027  -0.56937873 -0.2674209  -0.8238736  -0.60651547 -0.26192868\n",
      " -0.8184217  -0.7051859  -0.21786302 -0.53407204 -0.41844004 -0.22673178\n",
      " -0.6750842  -0.41916224  0.03103673 -0.7205178  -0.5097996   0.02866256\n",
      " -0.7075326  -0.5673449  -0.14624107 -0.5425234  -0.34367722 -0.15416843\n",
      " -0.65399283 -0.36610413 -0.12381232 -0.6790487  -0.3903907  -0.1707555\n",
      " -0.6218629  -0.43136954 -0.07783943]\n",
      "data: [-0.14132203 -0.13034119  0.53299993 -0.25339034 -0.20449325 -0.05493146\n",
      " -0.45293054 -0.2659465  -0.05343324 -0.65116936 -0.33885396 -0.09817243\n",
      " -0.77042216 -0.4310981  -0.23234373 -0.5755889  -0.46142215 -0.30828804\n",
      " -0.7623726  -0.51484346 -0.44572127 -0.8609047  -0.57528234 -0.46658385\n",
      " -0.89964205 -0.6632389  -0.46426165 -0.5424788  -0.44982108 -0.3272457\n",
      " -0.7400027  -0.56937873 -0.2674209  -0.8238736  -0.60651547 -0.26192868\n",
      " -0.8184217  -0.70518583 -0.21786302 -0.53407204 -0.41844004 -0.22673178\n",
      " -0.6750842  -0.41916224  0.03103673 -0.7205178  -0.5097996   0.02866256\n",
      " -0.7075326  -0.5673449  -0.14624107 -0.5425234  -0.34367722 -0.15416843\n",
      " -0.65399283 -0.36610413 -0.12381231 -0.6790487  -0.3903907  -0.1707555\n",
      " -0.6218629  -0.43136954 -0.07783943  0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B320>\n",
      "tensor([[-0.1208, -0.2412,  0.2246,  ..., -0.6873, -0.5489, -0.0639],\n",
      "        [-0.1208, -0.2412,  0.2246,  ..., -0.6873, -0.5489, -0.0639],\n",
      "        [-0.1208, -0.2412,  0.2246,  ..., -0.6873, -0.5489, -0.0639],\n",
      "        ...,\n",
      "        [ 0.1768, -0.1183,  0.1475,  ...,  0.3976,  0.5811, -0.5567],\n",
      "        [ 0.3350,  0.1681,  0.1965,  ..., -0.1320,  0.8574, -0.2884],\n",
      "        [ 0.3350,  0.1681,  0.1965,  ..., -0.1320,  0.8574, -0.2884]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.12076766 -0.24116221  0.22463691 -0.30799335 -0.3671611  -0.18422788\n",
      " -0.4999165  -0.50985473 -0.08375517 -0.6874712  -0.6167904  -0.03142484\n",
      " -0.81406784 -0.67281187  0.01467423 -0.53501827 -0.6310371  -0.11933488\n",
      " -0.80854744 -0.7818022  -0.27093363 -0.84068936 -0.822155   -0.22519147\n",
      " -0.84915453 -0.8786645  -0.14533445 -0.5223713  -0.58808625 -0.14324725\n",
      " -0.7139488  -0.7330575  -0.04556236 -0.75674206 -0.7933328  -0.01773484\n",
      " -0.7446026  -0.825277    0.00686663 -0.5261207  -0.55446374 -0.1872673\n",
      " -0.6447978  -0.66054136  0.1488347  -0.7206194  -0.7037506   0.16332391\n",
      " -0.7394772  -0.74001265 -0.04331517 -0.5089645  -0.4555872  -0.12819624\n",
      " -0.6643103  -0.49325725 -0.08618388 -0.66053694 -0.53322494 -0.06418741\n",
      " -0.6873252  -0.5488868  -0.06385323]\n",
      "data: [-0.12076766 -0.24116221  0.22463691 -0.30799335 -0.3671611  -0.18422788\n",
      " -0.4999165  -0.50985473 -0.08375517 -0.6874712  -0.6167904  -0.03142484\n",
      " -0.81406784 -0.67281187  0.01467423 -0.53501827 -0.6310371  -0.11933488\n",
      " -0.80854744 -0.78180224 -0.27093363 -0.8406894  -0.822155   -0.22519147\n",
      " -0.84915453 -0.8786645  -0.14533445 -0.5223713  -0.58808625 -0.14324725\n",
      " -0.71394885 -0.7330575  -0.04556236 -0.7567421  -0.7933328  -0.01773484\n",
      " -0.74460256 -0.825277    0.00686663 -0.5261207  -0.55446374 -0.1872673\n",
      " -0.6447978  -0.66054136  0.1488347  -0.7206194  -0.7037506   0.16332392\n",
      " -0.7394772  -0.74001265 -0.04331517 -0.5089645  -0.4555872  -0.12819624\n",
      " -0.6643103  -0.49325725 -0.08618388 -0.66053694 -0.53322494 -0.06418741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.68732524 -0.5488868  -0.06385323  0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0054, -0.0822, -0.0639,  ..., -0.8141, -0.2905, -0.3494],\n",
      "        [ 0.0054, -0.0822, -0.0639,  ..., -0.8141, -0.2905, -0.3494],\n",
      "        [ 0.0054, -0.0822, -0.0639,  ..., -0.8141, -0.2905, -0.3494],\n",
      "        ...,\n",
      "        [ 0.7863, -0.1939,  0.6879,  ...,  0.8519,  0.5072,  0.1610],\n",
      "        [ 0.4787, -0.0755,  0.8172,  ...,  0.4770,  0.1963,  0.6598],\n",
      "        [ 0.4787, -0.0755,  0.8172,  ...,  0.4770,  0.1963,  0.6598]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00536957 -0.08219263 -0.06385716 -0.23318999 -0.25400478 -0.6449901\n",
      " -0.39115775 -0.3814045  -0.39840758 -0.62011623 -0.46674785 -0.35590327\n",
      " -0.82889485 -0.53032005 -0.24276198 -0.5048821  -0.45866334 -0.35213828\n",
      " -0.83162653 -0.5993548  -0.58022696 -0.90415156 -0.6372716  -0.5311308\n",
      " -0.930526   -0.6604192  -0.4160211  -0.5071608  -0.39675328 -0.38425615\n",
      " -0.73128057 -0.5274482  -0.24757537 -0.81484604 -0.58453757 -0.22718945\n",
      " -0.88891065 -0.58246887 -0.16009682 -0.5099298  -0.32981914 -0.46295917\n",
      " -0.669701   -0.474158   -0.09135899 -0.7933053  -0.4886454  -0.06196196\n",
      " -0.89333725 -0.510185   -0.25619268 -0.47805223 -0.23920356 -0.42318493\n",
      " -0.673663   -0.28153428 -0.37442663 -0.7156279  -0.31825522 -0.3328209\n",
      " -0.8141091  -0.29050964 -0.34936288]\n",
      "data: [ 0.00536957 -0.08219263 -0.06385716 -0.23318999 -0.25400478 -0.6449901\n",
      " -0.39115775 -0.3814045  -0.39840758 -0.62011623 -0.46674785 -0.35590327\n",
      " -0.82889485 -0.53032005 -0.242762   -0.5048821  -0.45866334 -0.35213828\n",
      " -0.83162653 -0.5993548  -0.58022696 -0.90415156 -0.6372716  -0.5311308\n",
      " -0.930526   -0.6604192  -0.4160211  -0.5071608  -0.39675328 -0.38425618\n",
      " -0.73128057 -0.5274482  -0.24757537 -0.81484604 -0.58453757 -0.22718945\n",
      " -0.88891065 -0.58246887 -0.16009682 -0.5099298  -0.32981914 -0.46295917\n",
      " -0.669701   -0.474158   -0.09135899 -0.7933053  -0.4886454  -0.06196196\n",
      " -0.89333725 -0.510185   -0.25619268 -0.47805223 -0.23920354 -0.42318493\n",
      " -0.673663   -0.28153428 -0.37442666 -0.7156279  -0.31825522 -0.3328209\n",
      " -0.8141091  -0.29050964 -0.34936288  0.04      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F635F8>\n",
      "tensor([[-0.0535, -0.1993, -0.2012,  ..., -0.1459, -0.3744, -1.1368],\n",
      "        [-0.0535, -0.1993, -0.2012,  ..., -0.1459, -0.3744, -1.1368],\n",
      "        [-0.0535, -0.1993, -0.2012,  ..., -0.1459, -0.3744, -1.1368],\n",
      "        ...,\n",
      "        [ 0.8650, -0.0795,  0.6674,  ...,  0.2480,  0.7313,  0.3526],\n",
      "        [-0.0284,  0.1363,  0.4952,  ..., -0.6182,  0.5730,  0.1319],\n",
      "        [-0.0284,  0.1363,  0.4952,  ..., -0.6182,  0.5730,  0.1319]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.05353475 -0.19928287 -0.20119332 -0.14199124 -0.3569299  -0.5429996\n",
      " -0.40135023 -0.5174073  -1.0198753  -0.5959387  -0.61405146 -1.1613882\n",
      " -0.8454524  -0.6424083  -1.5057788  -0.3830149  -0.7411878  -1.2464119\n",
      " -0.56026745 -0.77358377 -1.3612698  -0.5339621  -0.67326045 -1.3919698\n",
      " -0.467129   -0.7966428  -1.3607199  -0.3227958  -0.6343738  -1.2582479\n",
      " -0.38093042 -0.67999685 -1.1263173  -0.44005927 -0.6776258  -1.1972415\n",
      " -0.24876711 -0.57872605 -1.2824701  -0.2944452  -0.63404    -1.175384\n",
      " -0.3183     -0.50113046 -1.2435364  -0.31275046 -0.5309701  -1.2486812\n",
      " -0.19633017 -0.49477652 -1.2133099  -0.24419732 -0.43290356 -1.1631154\n",
      " -0.35889772 -0.39654082 -1.1867882  -0.25676584 -0.35656098 -1.2790021\n",
      " -0.14585967 -0.3743676  -1.1367517 ]\n",
      "data: [-0.05353475 -0.19928287 -0.20119332 -0.14199124 -0.3569299  -0.5429996\n",
      " -0.4013502  -0.5174073  -1.0198753  -0.5959387  -0.61405146 -1.1613882\n",
      " -0.8454524  -0.6424083  -1.5057788  -0.38301486 -0.7411878  -1.2464119\n",
      " -0.56026745 -0.77358377 -1.3612698  -0.5339621  -0.67326045 -1.3919698\n",
      " -0.467129   -0.7966428  -1.3607199  -0.32279578 -0.6343738  -1.2582479\n",
      " -0.3809304  -0.67999685 -1.1263173  -0.44005927 -0.67762583 -1.1972415\n",
      " -0.24876711 -0.57872605 -1.2824701  -0.2944452  -0.63404    -1.175384\n",
      " -0.3183     -0.50113046 -1.2435364  -0.31275046 -0.5309701  -1.2486812\n",
      " -0.19633016 -0.49477655 -1.2133099  -0.24419732 -0.43290356 -1.1631154\n",
      " -0.35889772 -0.39654082 -1.1867882  -0.25676584 -0.35656098 -1.2790021\n",
      " -0.14585967 -0.3743676  -1.1367517   0.05      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F3C8>\n",
      "tensor([[ 0.0917,  0.0153, -0.0599,  ...,  0.2927, -0.1695, -1.0618],\n",
      "        [ 0.0917,  0.0153, -0.0599,  ...,  0.2927, -0.1695, -1.0618],\n",
      "        [ 0.0917,  0.0153, -0.0599,  ...,  0.2927, -0.1695, -1.0618],\n",
      "        ...,\n",
      "        [ 0.0611,  0.1152,  0.1126,  ..., -0.0164,  0.8036, -0.1487],\n",
      "        [-0.1138,  0.0200,  0.3139,  ..., -1.1259,  0.3159,  0.0561],\n",
      "        [-0.1138,  0.0200,  0.3139,  ..., -1.1259,  0.3159,  0.0561]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.09173343  0.01532535 -0.0599238   0.16701911 -0.09657909 -0.3527511\n",
      "  0.10383905 -0.21498996 -1.1077853  -0.02451687 -0.25434506 -1.4023635\n",
      " -0.15547957 -0.38785854 -1.9217111  -0.09405538 -0.51068735 -1.3314955\n",
      "  0.20052597 -0.4902719  -1.2077187   0.15732478 -0.4342099  -1.2531006\n",
      "  0.17807391 -0.5239706  -1.3732067  -0.03346547 -0.43255714 -1.2534453\n",
      "  0.12301973 -0.49149218 -1.277267    0.14224412 -0.4331607  -1.3742819\n",
      "  0.29160085 -0.49269566 -1.4511986   0.09209777 -0.37371737 -1.0479254\n",
      "  0.01358759 -0.11227933 -1.7209746   0.2225767  -0.28478995 -1.7081686\n",
      "  0.39081478 -0.24736902 -1.2835425  -0.00721951 -0.15411218 -0.9899444\n",
      "  0.1437825  -0.12647267 -1.0363231   0.22471707 -0.15832832 -1.1757449\n",
      "  0.29272407 -0.16953494 -1.0617797 ]\n",
      "data: [ 0.09173343  0.01532535 -0.0599238   0.16701911 -0.0965791  -0.35275114\n",
      "  0.10383905 -0.21498996 -1.1077853  -0.02451687 -0.25434506 -1.4023635\n",
      " -0.15547957 -0.38785854 -1.9217111  -0.09405538 -0.51068735 -1.3314955\n",
      "  0.20052597 -0.49027193 -1.2077187   0.15732478 -0.4342099  -1.2531006\n",
      "  0.17807393 -0.5239706  -1.3732067  -0.03346547 -0.43255714 -1.2534453\n",
      "  0.12301973 -0.49149218 -1.277267    0.14224412 -0.4331607  -1.3742819\n",
      "  0.29160085 -0.49269566 -1.4511986   0.09209777 -0.3737174  -1.0479254\n",
      "  0.01358759 -0.11227933 -1.7209746   0.2225767  -0.28478995 -1.7081686\n",
      "  0.39081478 -0.24736902 -1.2835425  -0.00721951 -0.15411218 -0.9899444\n",
      "  0.1437825  -0.12647267 -1.0363231   0.22471707 -0.15832832 -1.1757449\n",
      "  0.29272407 -0.16953494 -1.0617797   0.06      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[ 0.1359, -0.1062, -0.1538,  ...,  0.1137, -0.2724, -1.2646],\n",
      "        [ 0.1359, -0.1062, -0.1538,  ...,  0.1137, -0.2724, -1.2646],\n",
      "        [ 0.1359, -0.1062, -0.1538,  ...,  0.1137, -0.2724, -1.2646],\n",
      "        ...,\n",
      "        [-0.3498,  0.1110, -0.1918,  ..., -0.6028,  0.6292, -0.5662],\n",
      "        [-0.2108,  0.1635,  0.3892,  ..., -0.2282,  1.0832, -0.0473],\n",
      "        [-0.2108,  0.1635,  0.3892,  ..., -0.2282,  1.0832, -0.0473]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.35869831e-01 -1.06244437e-01 -1.53774783e-01  1.41675428e-01\n",
      " -2.83911526e-01 -6.51843250e-01  3.25495154e-02 -4.60511863e-01\n",
      " -1.37609839e+00 -1.16098359e-01 -5.41682303e-01 -1.65380883e+00\n",
      " -3.21022332e-01 -6.45140529e-01 -2.11458254e+00 -8.43816847e-02\n",
      " -7.08198071e-01 -1.54270983e+00  9.16724056e-02 -7.32801795e-01\n",
      " -1.30051374e+00  6.95873648e-02 -6.68497682e-01 -1.35523367e+00\n",
      "  7.66689777e-02 -7.93353319e-01 -1.45499182e+00 -5.53667545e-02\n",
      " -5.75752139e-01 -1.47876930e+00  1.48130506e-02 -6.35401368e-01\n",
      " -1.41191840e+00 -1.87054276e-04 -6.29691005e-01 -1.50413346e+00\n",
      "  1.69270426e-01 -6.18644118e-01 -1.57522607e+00  3.98443639e-03\n",
      " -5.22925615e-01 -1.30530715e+00 -8.26560855e-02 -2.96566904e-01\n",
      " -1.85021663e+00  4.51654196e-02 -4.32406396e-01 -1.84100246e+00\n",
      "  2.10388020e-01 -4.07018930e-01 -1.40518856e+00 -6.95095658e-02\n",
      " -2.65420556e-01 -1.24102902e+00 -3.51693034e-02 -2.40058273e-01\n",
      " -1.29377079e+00  3.31026167e-02 -2.41124555e-01 -1.41447783e+00\n",
      "  1.13662004e-01 -2.72449553e-01 -1.26461172e+00]\n",
      "data: [ 1.35869831e-01 -1.06244437e-01 -1.53774783e-01  1.41675428e-01\n",
      " -2.83911526e-01 -6.51843250e-01  3.25495154e-02 -4.60511863e-01\n",
      " -1.37609828e+00 -1.16098359e-01 -5.41682303e-01 -1.65380895e+00\n",
      " -3.21022332e-01 -6.45140529e-01 -2.11458254e+00 -8.43816847e-02\n",
      " -7.08198071e-01 -1.54270983e+00  9.16723981e-02 -7.32801795e-01\n",
      " -1.30051374e+00  6.95873648e-02 -6.68497682e-01 -1.35523367e+00\n",
      "  7.66689777e-02 -7.93353319e-01 -1.45499182e+00 -5.53667545e-02\n",
      " -5.75752139e-01 -1.47876918e+00  1.48130516e-02 -6.35401368e-01\n",
      " -1.41191828e+00 -1.87054276e-04 -6.29691005e-01 -1.50413346e+00\n",
      "  1.69270426e-01 -6.18644118e-01 -1.57522619e+00  3.98443639e-03\n",
      " -5.22925615e-01 -1.30530715e+00 -8.26560855e-02 -2.96566904e-01\n",
      " -1.85021663e+00  4.51654196e-02 -4.32406396e-01 -1.84100246e+00\n",
      "  2.10388005e-01 -4.07018930e-01 -1.40518856e+00 -6.95095658e-02\n",
      " -2.65420556e-01 -1.24102902e+00 -3.51693034e-02 -2.40058273e-01\n",
      " -1.29377079e+00  3.31026167e-02 -2.41124555e-01 -1.41447783e+00\n",
      "  1.13662004e-01 -2.72449553e-01 -1.26461172e+00  7.00000003e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[-0.0079, -0.1229, -0.2068,  ...,  0.0915, -0.3226, -1.2368],\n",
      "        [-0.0079, -0.1229, -0.2068,  ...,  0.0915, -0.3226, -1.2368],\n",
      "        [-0.0079, -0.1229, -0.2068,  ...,  0.0915, -0.3226, -1.2368],\n",
      "        ...,\n",
      "        [-0.0894,  0.5043, -0.1213,  ..., -0.6562,  1.0104, -0.4860],\n",
      "        [-0.1347, -0.0074,  0.5935,  ..., -0.1963,  0.7344,  0.2119],\n",
      "        [-0.1347, -0.0074,  0.5935,  ..., -0.1963,  0.7344,  0.2119]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.00787172 -0.12287945 -0.20684683  0.02142398 -0.25611734 -0.56708384\n",
      " -0.06524751 -0.45463142 -1.3477175  -0.21409157 -0.5188125  -1.6547399\n",
      " -0.3807883  -0.65356266 -2.1311405  -0.21504816 -0.7272215  -1.5424409\n",
      "  0.046559   -0.7708417  -1.3485873  -0.01161527 -0.7114999  -1.3889244\n",
      " -0.01236669 -0.8484415  -1.5074546  -0.15065661 -0.62465405 -1.4419165\n",
      " -0.04967893 -0.69614327 -1.4226158  -0.04339428 -0.66958237 -1.5145206\n",
      "  0.08412112 -0.7158992  -1.5636315  -0.03634287 -0.5370381  -1.2573662\n",
      " -0.16187277 -0.30010986 -1.9380856   0.02019068 -0.48500684 -1.9293401\n",
      "  0.18792066 -0.4429815  -1.4102087  -0.15905145 -0.29634994 -1.1896522\n",
      " -0.04202687 -0.27636576 -1.2684026   0.01859549 -0.31398463 -1.3824601\n",
      "  0.09145646 -0.32260823 -1.2368021 ]\n",
      "data: [-0.00787172 -0.12287945 -0.20684683  0.02142398 -0.25611734 -0.56708384\n",
      " -0.06524751 -0.45463142 -1.3477176  -0.21409157 -0.5188125  -1.6547399\n",
      " -0.3807883  -0.6535627  -2.1311405  -0.21504816 -0.72722155 -1.5424409\n",
      "  0.046559   -0.7708418  -1.3485874  -0.01161527 -0.7114999  -1.3889244\n",
      " -0.01236669 -0.8484415  -1.5074546  -0.15065661 -0.62465405 -1.4419165\n",
      " -0.04967893 -0.69614327 -1.4226158  -0.04339428 -0.66958237 -1.5145205\n",
      "  0.08412112 -0.7158992  -1.5636315  -0.03634287 -0.5370381  -1.2573662\n",
      " -0.16187277 -0.30010986 -1.9380857   0.02019068 -0.48500684 -1.92934\n",
      "  0.18792066 -0.44298154 -1.4102087  -0.15905145 -0.29634994 -1.1896522\n",
      " -0.04202687 -0.27636576 -1.2684026   0.01859549 -0.31398463 -1.3824601\n",
      "  0.09145646 -0.32260823 -1.2368021   0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0226, -0.1125, -0.1850,  ...,  0.0516, -0.3130, -1.1640],\n",
      "        [ 0.0226, -0.1125, -0.1850,  ...,  0.0516, -0.3130, -1.1640],\n",
      "        [ 0.0226, -0.1125, -0.1850,  ...,  0.0516, -0.3130, -1.1640],\n",
      "        ...,\n",
      "        [-0.0937,  0.4488, -0.1155,  ..., -0.4218,  1.0075, -0.4983],\n",
      "        [-0.1005, -0.0531,  0.6127,  ..., -0.2236,  0.6814,  0.2399],\n",
      "        [-0.1005, -0.0531,  0.6127,  ..., -0.2236,  0.6814,  0.2399]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02255258 -0.11254258 -0.1849699   0.05702939 -0.20974955 -0.4653347\n",
      " -0.09896144 -0.4471636  -1.337759   -0.25404334 -0.51672614 -1.6211011\n",
      " -0.39872253 -0.5998442  -2.1398456  -0.16267233 -0.7588434  -1.5122609\n",
      " -0.00596832 -0.8319843  -1.3607755  -0.05633812 -0.75348884 -1.4118729\n",
      " -0.06831206 -0.9311716  -1.5380807  -0.12074734 -0.67618096 -1.4099596\n",
      " -0.07285099 -0.7275374  -1.3778372  -0.08603492 -0.69109493 -1.4545615\n",
      "  0.05803034 -0.72476447 -1.4663589  -0.04209451 -0.5613867  -1.2519491\n",
      " -0.20877515 -0.32018206 -2.0433562  -0.01601599 -0.49892896 -2.0743291\n",
      "  0.16218261 -0.45677245 -1.3358064  -0.16501753 -0.33523488 -1.1687033\n",
      " -0.10310996 -0.3018197  -1.2585807  -0.07146977 -0.2976179  -1.371614\n",
      "  0.05156308 -0.31302857 -1.1640077 ]\n",
      "data: [ 0.02255258 -0.11254258 -0.1849699   0.05702939 -0.20974955 -0.4653347\n",
      " -0.09896144 -0.4471636  -1.3377591  -0.25404334 -0.51672614 -1.621101\n",
      " -0.39872253 -0.5998442  -2.1398456  -0.16267233 -0.75884336 -1.5122609\n",
      " -0.00596832 -0.8319843  -1.3607755  -0.05633812 -0.75348884 -1.4118729\n",
      " -0.06831206 -0.9311716  -1.5380807  -0.12074735 -0.67618096 -1.4099596\n",
      " -0.07285099 -0.7275374  -1.3778372  -0.08603492 -0.691095   -1.4545615\n",
      "  0.05803034 -0.72476447 -1.4663589  -0.04209451 -0.5613867  -1.2519491\n",
      " -0.20877513 -0.32018203 -2.0433562  -0.01601599 -0.49892893 -2.0743291\n",
      "  0.16218261 -0.45677245 -1.3358064  -0.16501753 -0.33523488 -1.1687033\n",
      " -0.10310995 -0.3018197  -1.2585807  -0.07146977 -0.2976179  -1.371614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.05156308 -0.31302857 -1.1640077   0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[-4.3596e-02, -9.6100e-03, -2.0823e-01,  ..., -1.1080e-03,\n",
      "         -1.9590e-01, -1.1827e+00],\n",
      "        [-4.3596e-02, -9.6100e-03, -2.0823e-01,  ..., -1.1080e-03,\n",
      "         -1.9590e-01, -1.1827e+00],\n",
      "        [-4.3596e-02, -9.6100e-03, -2.0823e-01,  ..., -1.1080e-03,\n",
      "         -1.9590e-01, -1.1827e+00],\n",
      "        ...,\n",
      "        [-1.7403e-01,  3.3761e-01,  2.7628e-02,  ..., -7.1690e-01,\n",
      "          9.0714e-01, -3.5551e-01],\n",
      "        [-1.0502e-01, -8.5770e-02,  5.8581e-01,  ..., -2.3389e-01,\n",
      "          6.1376e-01,  2.4209e-01],\n",
      "        [-1.0502e-01, -8.5770e-02,  5.8581e-01,  ..., -2.3389e-01,\n",
      "          6.1376e-01,  2.4209e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-4.35958765e-02 -9.61001031e-03 -2.08228499e-01 -1.84678324e-02\n",
      " -1.18316710e-01 -5.01570821e-01 -1.54137403e-01 -3.43110442e-01\n",
      " -1.34951103e+00 -3.10270190e-01 -4.05578762e-01 -1.64638579e+00\n",
      " -4.71071959e-01 -5.06224275e-01 -2.14916468e+00 -2.48346150e-01\n",
      " -6.44537687e-01 -1.52215135e+00 -5.10937423e-02 -7.02512085e-01\n",
      " -1.34888685e+00 -1.02622345e-01 -6.29989862e-01 -1.39786720e+00\n",
      " -1.01931065e-01 -7.90904343e-01 -1.52802145e+00 -2.00168237e-01\n",
      " -5.51444113e-01 -1.41643953e+00 -1.30987570e-01 -6.05360508e-01\n",
      " -1.39076710e+00 -1.26921132e-01 -5.67717850e-01 -1.47962320e+00\n",
      "  2.49530226e-02 -6.04310036e-01 -1.50471365e+00 -1.06171779e-01\n",
      " -4.40568238e-01 -1.24731553e+00 -2.63961077e-01 -2.00265735e-01\n",
      " -2.01301956e+00 -6.39127567e-02 -3.76940489e-01 -2.03337431e+00\n",
      "  1.27802059e-01 -3.33866179e-01 -1.36073935e+00 -2.33773693e-01\n",
      " -2.06958249e-01 -1.16684830e+00 -1.52021587e-01 -1.77984595e-01\n",
      " -1.25305426e+00 -1.13615528e-01 -1.85085610e-01 -1.36943471e+00\n",
      " -1.10799819e-03 -1.95902720e-01 -1.18271089e+00]\n",
      "data: [-4.35958765e-02 -9.61001031e-03 -2.08228499e-01 -1.84678324e-02\n",
      " -1.18316710e-01 -5.01570821e-01 -1.54137403e-01 -3.43110442e-01\n",
      " -1.34951091e+00 -3.10270190e-01 -4.05578762e-01 -1.64638579e+00\n",
      " -4.71071959e-01 -5.06224275e-01 -2.14916468e+00 -2.48346150e-01\n",
      " -6.44537687e-01 -1.52215135e+00 -5.10937423e-02 -7.02512026e-01\n",
      " -1.34888685e+00 -1.02622345e-01 -6.29989862e-01 -1.39786708e+00\n",
      " -1.01931065e-01 -7.90904284e-01 -1.52802134e+00 -2.00168222e-01\n",
      " -5.51444113e-01 -1.41643953e+00 -1.30987570e-01 -6.05360508e-01\n",
      " -1.39076710e+00 -1.26921132e-01 -5.67717850e-01 -1.47962332e+00\n",
      "  2.49530226e-02 -6.04310036e-01 -1.50471354e+00 -1.06171779e-01\n",
      " -4.40568238e-01 -1.24731553e+00 -2.63961077e-01 -2.00265735e-01\n",
      " -2.01301956e+00 -6.39127567e-02 -3.76940489e-01 -2.03337431e+00\n",
      "  1.27802059e-01 -3.33866209e-01 -1.36073923e+00 -2.33773693e-01\n",
      " -2.06958249e-01 -1.16684830e+00 -1.52021587e-01 -1.77984595e-01\n",
      " -1.25305426e+00 -1.13615535e-01 -1.85085595e-01 -1.36943471e+00\n",
      " -1.10799819e-03 -1.95902735e-01 -1.18271089e+00  1.00000001e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[-0.0070, -0.0874, -0.1938,  ...,  0.0108, -0.2425, -1.3173],\n",
      "        [-0.0070, -0.0874, -0.1938,  ...,  0.0108, -0.2425, -1.3173],\n",
      "        [-0.0070, -0.0874, -0.1938,  ...,  0.0108, -0.2425, -1.3173],\n",
      "        ...,\n",
      "        [-0.2620,  0.3055, -0.1741,  ..., -0.7671,  0.7881, -0.3745],\n",
      "        [-0.1888, -0.1098,  0.5251,  ..., -0.2949,  0.6300,  0.2656],\n",
      "        [-0.1888, -0.1098,  0.5251,  ..., -0.2949,  0.6300,  0.2656]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.00696963 -0.08737057 -0.19375019  0.00709195 -0.2506135  -0.66485584\n",
      " -0.03040767 -0.39346886 -1.3339927  -0.16963077 -0.44285345 -1.6463587\n",
      " -0.35671216 -0.5799684  -2.1007552  -0.23363565 -0.66263914 -1.4981916\n",
      "  0.0516469  -0.6572277  -1.2692542   0.00406143 -0.60600823 -1.3185843\n",
      "  0.0061998  -0.6976032  -1.434126   -0.18771972 -0.54249156 -1.4227059\n",
      " -0.06754182 -0.59783566 -1.4164551  -0.059958   -0.5672052  -1.5277756\n",
      "  0.06783554 -0.5920548  -1.6100948  -0.08009913 -0.4732408  -1.2439307\n",
      " -0.16055462 -0.24573113 -1.7734566  -0.02074604 -0.38614613 -1.7485511\n",
      "  0.12602134 -0.3513686  -1.461939   -0.1848961  -0.22480093 -1.1961427\n",
      " -0.081386   -0.20512111 -1.2741858  -0.02291425 -0.23796956 -1.3983427\n",
      "  0.01081919 -0.24251887 -1.3173429 ]\n",
      "data: [-0.00696963 -0.08737057 -0.19375019  0.00709195 -0.2506135  -0.6648558\n",
      " -0.03040767 -0.39346886 -1.3339927  -0.16963078 -0.44285348 -1.6463588\n",
      " -0.35671216 -0.5799684  -2.1007552  -0.23363565 -0.66263914 -1.4981915\n",
      "  0.0516469  -0.6572277  -1.2692542   0.00406143 -0.60600823 -1.3185843\n",
      "  0.0061998  -0.6976032  -1.434126   -0.18771973 -0.54249156 -1.4227059\n",
      " -0.06754182 -0.59783566 -1.416455   -0.059958   -0.5672052  -1.5277755\n",
      "  0.06783554 -0.5920548  -1.6100948  -0.08009913 -0.47324076 -1.2439307\n",
      " -0.16055462 -0.24573113 -1.7734566  -0.02074604 -0.38614613 -1.7485511\n",
      "  0.12602134 -0.3513686  -1.461939   -0.18489608 -0.22480093 -1.1961427\n",
      " -0.081386   -0.20512111 -1.2741858  -0.02291425 -0.23796958 -1.3983427\n",
      "  0.01081919 -0.24251886 -1.3173429   0.11      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B9B0>\n",
      "tensor([[ 0.0355, -0.1280, -0.2997,  ...,  0.0471, -0.2984, -1.3541],\n",
      "        [ 0.0355, -0.1280, -0.2997,  ...,  0.0471, -0.2984, -1.3541],\n",
      "        [ 0.0355, -0.1280, -0.2997,  ...,  0.0471, -0.2984, -1.3541],\n",
      "        ...,\n",
      "        [-0.1556,  0.4786, -0.0962,  ..., -0.7227,  1.0080, -0.4111],\n",
      "        [-0.1837, -0.0734,  0.6296,  ..., -0.2784,  0.7031,  0.2818],\n",
      "        [-0.1837, -0.0734,  0.6296,  ..., -0.2784,  0.7031,  0.2818]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03553629 -0.12798207 -0.29973698  0.0690534  -0.24822588 -0.68749046\n",
      " -0.04083744 -0.4486824  -1.4863861  -0.18605578 -0.5098818  -1.7808557\n",
      " -0.3307591  -0.60709965 -2.2850354  -0.16305068 -0.73897123 -1.6571026\n",
      "  0.03444091 -0.78111887 -1.4820628  -0.01772787 -0.7145686  -1.5370576\n",
      " -0.03351323 -0.86011255 -1.6621277  -0.12305931 -0.64561296 -1.5645769\n",
      " -0.05452805 -0.6963016  -1.5426424  -0.06989551 -0.661674   -1.6307228\n",
      "  0.05752274 -0.69424677 -1.665375   -0.0396513  -0.5431653  -1.3973076\n",
      " -0.17374739 -0.3067713  -2.0849292  -0.00835445 -0.468658   -2.0993862\n",
      "  0.14713329 -0.43182722 -1.5246935  -0.15072057 -0.31291324 -1.3221514\n",
      " -0.07664376 -0.2799444  -1.4005415  -0.038298   -0.28697947 -1.5171647\n",
      "  0.04707335 -0.2984174  -1.354054  ]\n",
      "data: [ 0.03553629 -0.12798207 -0.29973698  0.0690534  -0.24822588 -0.68749046\n",
      " -0.04083744 -0.4486824  -1.4863861  -0.18605578 -0.5098818  -1.7808557\n",
      " -0.33075914 -0.60709965 -2.2850354  -0.1630507  -0.73897123 -1.6571027\n",
      "  0.03444091 -0.78111887 -1.4820628  -0.01772787 -0.7145686  -1.5370576\n",
      " -0.03351323 -0.86011255 -1.6621277  -0.12305931 -0.64561296 -1.5645769\n",
      " -0.05452805 -0.6963016  -1.5426424  -0.06989551 -0.661674   -1.6307228\n",
      "  0.05752274 -0.69424677 -1.6653751  -0.0396513  -0.5431653  -1.3973076\n",
      " -0.17374739 -0.3067713  -2.0849292  -0.00835445 -0.468658   -2.0993862\n",
      "  0.14713329 -0.4318272  -1.5246935  -0.15072057 -0.31291324 -1.3221515\n",
      " -0.07664376 -0.2799444  -1.4005415  -0.038298   -0.28697947 -1.5171647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.04707335 -0.2984174  -1.354054    0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0068, -0.0999, -0.2209,  ...,  0.0438, -0.2792, -1.3086],\n",
      "        [ 0.0068, -0.0999, -0.2209,  ...,  0.0438, -0.2792, -1.3086],\n",
      "        [ 0.0068, -0.0999, -0.2209,  ...,  0.0438, -0.2792, -1.3086],\n",
      "        ...,\n",
      "        [-0.1292,  0.4541, -0.1261,  ..., -0.7992,  0.9425, -0.3518],\n",
      "        [-0.1147, -0.0764,  0.5545,  ..., -0.1949,  0.6370,  0.2395],\n",
      "        [-0.1147, -0.0764,  0.5545,  ..., -0.1949,  0.6370,  0.2395]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 6.7523913e-03 -9.9917516e-02 -2.2090057e-01  1.6533252e-02\n",
      " -2.5974375e-01 -6.7238116e-01 -8.3761886e-03 -4.2036653e-01\n",
      " -1.3716141e+00 -1.4739290e-01 -4.7240973e-01 -1.7029958e+00\n",
      " -3.3879280e-01 -6.2199539e-01 -2.1529264e+00 -2.1797161e-01\n",
      " -6.7954290e-01 -1.5606989e+00  8.5031092e-02 -6.8919176e-01\n",
      " -1.3415071e+00  2.0348504e-02 -6.4617580e-01 -1.3878976e+00\n",
      "  2.4328642e-02 -7.5447947e-01 -1.5064493e+00 -1.6082606e-01\n",
      " -5.5656832e-01 -1.4639491e+00 -4.2776622e-02 -6.2389404e-01\n",
      " -1.4540981e+00 -3.9356619e-02 -6.0844010e-01 -1.5691841e+00\n",
      "  6.8140060e-02 -6.4692605e-01 -1.6416354e+00 -4.2457484e-02\n",
      " -4.7828937e-01 -1.2726717e+00 -1.4816137e-01 -2.5960314e-01\n",
      " -1.8671880e+00  4.7177821e-04 -4.2294830e-01 -1.8403853e+00\n",
      "  1.4479373e-01 -3.8859439e-01 -1.4681959e+00 -1.6028881e-01\n",
      " -2.3157097e-01 -1.2157290e+00 -3.7878230e-02 -2.2426839e-01\n",
      " -1.2859385e+00  1.4498323e-02 -2.7348739e-01 -1.4023861e+00\n",
      "  4.3819748e-02 -2.7918223e-01 -1.3085884e+00]\n",
      "data: [ 6.7523913e-03 -9.9917516e-02 -2.2090058e-01  1.6533252e-02\n",
      " -2.5974375e-01 -6.7238116e-01 -8.3761886e-03 -4.2036653e-01\n",
      " -1.3716141e+00 -1.4739290e-01 -4.7240975e-01 -1.7029958e+00\n",
      " -3.3879280e-01 -6.2199539e-01 -2.1529264e+00 -2.1797161e-01\n",
      " -6.7954290e-01 -1.5606989e+00  8.5031092e-02 -6.8919176e-01\n",
      " -1.3415071e+00  2.0348504e-02 -6.4617574e-01 -1.3878976e+00\n",
      "  2.4328642e-02 -7.5447947e-01 -1.5064492e+00 -1.6082606e-01\n",
      " -5.5656832e-01 -1.4639491e+00 -4.2776622e-02 -6.2389404e-01\n",
      " -1.4540981e+00 -3.9356619e-02 -6.0844010e-01 -1.5691841e+00\n",
      "  6.8140060e-02 -6.4692605e-01 -1.6416354e+00 -4.2457484e-02\n",
      " -4.7828937e-01 -1.2726717e+00 -1.4816137e-01 -2.5960314e-01\n",
      " -1.8671880e+00  4.7177821e-04 -4.2294830e-01 -1.8403853e+00\n",
      "  1.4479373e-01 -3.8859439e-01 -1.4681959e+00 -1.6028881e-01\n",
      " -2.3157097e-01 -1.2157290e+00 -3.7878230e-02 -2.2426839e-01\n",
      " -1.2859386e+00  1.4498323e-02 -2.7348739e-01 -1.4023861e+00\n",
      "  4.3819748e-02 -2.7918223e-01 -1.3085884e+00  1.3000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0302, -0.0996, -0.2609,  ...,  0.0471, -0.2845, -1.3139],\n",
      "        [ 0.0302, -0.0996, -0.2609,  ...,  0.0471, -0.2845, -1.3139],\n",
      "        [ 0.0302, -0.0996, -0.2609,  ...,  0.0471, -0.2845, -1.3139],\n",
      "        ...,\n",
      "        [-0.1736,  0.4545, -0.1433,  ..., -0.7048,  0.9541, -0.4342],\n",
      "        [-0.1787, -0.1274,  0.6300,  ..., -0.2482,  0.6452,  0.2875],\n",
      "        [-0.1787, -0.1274,  0.6300,  ..., -0.2482,  0.6452,  0.2875]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03024617 -0.09955872 -0.260929    0.04788064 -0.23676154 -0.67041826\n",
      " -0.05409755 -0.43538737 -1.4394426  -0.19821636 -0.50098044 -1.7306108\n",
      " -0.36133516 -0.60815835 -2.2073689  -0.17247672 -0.7176158  -1.5989696\n",
      "  0.02651912 -0.7599413  -1.4082863  -0.0245892  -0.6922166  -1.4620324\n",
      " -0.03101647 -0.8335766  -1.5785965  -0.13078244 -0.6142311  -1.5125331\n",
      " -0.05933567 -0.6677001  -1.4813384  -0.07299812 -0.6416192  -1.5685248\n",
      "  0.05540183 -0.6629007  -1.6056857  -0.0450493  -0.5223866  -1.3484267\n",
      " -0.16748357 -0.29541856 -1.9988121  -0.01405384 -0.45178717 -2.0034003\n",
      "  0.1414891  -0.41511917 -1.4694709  -0.14970152 -0.28693512 -1.2783239\n",
      " -0.07747975 -0.26206523 -1.3629842  -0.03502887 -0.2720011  -1.4758883\n",
      "  0.04706001 -0.2845312  -1.3138756 ]\n",
      "data: [ 0.03024617 -0.09955872 -0.260929    0.04788064 -0.23676153 -0.67041826\n",
      " -0.05409755 -0.43538737 -1.4394426  -0.19821636 -0.50098044 -1.7306108\n",
      " -0.36133516 -0.60815835 -2.2073689  -0.17247672 -0.71761584 -1.5989696\n",
      "  0.02651912 -0.7599413  -1.4082863  -0.0245892  -0.6922166  -1.4620324\n",
      " -0.03101647 -0.83357656 -1.5785965  -0.13078244 -0.6142311  -1.5125331\n",
      " -0.05933567 -0.6677001  -1.4813384  -0.07299812 -0.6416192  -1.5685248\n",
      "  0.05540183 -0.6629007  -1.6056857  -0.0450493  -0.5223866  -1.3484267\n",
      " -0.16748355 -0.29541856 -1.9988121  -0.01405384 -0.45178717 -2.0034003\n",
      "  0.1414891  -0.41511917 -1.4694709  -0.14970152 -0.28693512 -1.2783239\n",
      " -0.07747975 -0.26206523 -1.3629842  -0.03502887 -0.2720011  -1.4758883\n",
      "  0.04706    -0.2845312  -1.3138756   0.14      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 4.8645e-04, -5.0108e-02, -2.1543e-01,  ...,  3.7795e-02,\n",
      "         -2.3977e-01, -1.2538e+00],\n",
      "        [ 4.8645e-04, -5.0108e-02, -2.1543e-01,  ...,  3.7795e-02,\n",
      "         -2.3977e-01, -1.2538e+00],\n",
      "        [ 4.8645e-04, -5.0108e-02, -2.1543e-01,  ...,  3.7795e-02,\n",
      "         -2.3977e-01, -1.2538e+00],\n",
      "        ...,\n",
      "        [-1.2514e-01,  4.0004e-01, -1.3160e-01,  ..., -7.4129e-01,\n",
      "          8.7767e-01, -3.7360e-01],\n",
      "        [-1.2958e-01, -1.4733e-01,  5.7200e-01,  ..., -2.1980e-01,\n",
      "          5.8036e-01,  2.5997e-01],\n",
      "        [-1.2958e-01, -1.4733e-01,  5.7200e-01,  ..., -2.1980e-01,\n",
      "          5.8036e-01,  2.5997e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 4.8644561e-04 -5.0108440e-02 -2.1543184e-01  1.7577935e-02\n",
      " -1.8541455e-01 -6.0400528e-01 -6.4554833e-02 -3.7163231e-01\n",
      " -1.3487821e+00 -2.0948839e-01 -4.3000656e-01 -1.6549509e+00\n",
      " -3.7971526e-01 -5.4978645e-01 -2.1280169e+00 -2.0545654e-01\n",
      " -6.5753710e-01 -1.5240016e+00  2.2922039e-02 -6.9168460e-01\n",
      " -1.3433502e+00 -3.4103617e-02 -6.3203120e-01 -1.3954158e+00\n",
      " -3.4503385e-02 -7.7059257e-01 -1.5138273e+00 -1.5557145e-01\n",
      " -5.5375886e-01 -1.4328244e+00 -6.9544509e-02 -6.1225116e-01\n",
      " -1.4145491e+00 -7.6821491e-02 -5.8930647e-01 -1.5131977e+00\n",
      "  4.6986327e-02 -6.2152350e-01 -1.5564873e+00 -5.6861408e-02\n",
      " -4.6136281e-01 -1.2603559e+00 -1.7993416e-01 -2.3712230e-01\n",
      " -1.9240563e+00 -1.8695287e-02 -4.0146056e-01 -1.9232612e+00\n",
      "  1.3705601e-01 -3.6756179e-01 -1.4101760e+00 -1.6748907e-01\n",
      " -2.2689967e-01 -1.1967173e+00 -7.7312991e-02 -2.0877717e-01\n",
      " -1.2792344e+00 -3.5361975e-02 -2.2953868e-01 -1.3963954e+00\n",
      "  3.7795357e-02 -2.3976745e-01 -1.2537971e+00]\n",
      "data: [ 4.8644561e-04 -5.0108444e-02 -2.1543184e-01  1.7577935e-02\n",
      " -1.8541454e-01 -6.0400528e-01 -6.4554833e-02 -3.7163231e-01\n",
      " -1.3487821e+00 -2.0948839e-01 -4.3000656e-01 -1.6549509e+00\n",
      " -3.7971526e-01 -5.4978645e-01 -2.1280169e+00 -2.0545654e-01\n",
      " -6.5753710e-01 -1.5240016e+00  2.2922039e-02 -6.9168454e-01\n",
      " -1.3433502e+00 -3.4103617e-02 -6.3203120e-01 -1.3954158e+00\n",
      " -3.4503385e-02 -7.7059257e-01 -1.5138273e+00 -1.5557145e-01\n",
      " -5.5375886e-01 -1.4328244e+00 -6.9544509e-02 -6.1225116e-01\n",
      " -1.4145491e+00 -7.6821491e-02 -5.8930647e-01 -1.5131977e+00\n",
      "  4.6986327e-02 -6.2152350e-01 -1.5564873e+00 -5.6861412e-02\n",
      " -4.6136281e-01 -1.2603559e+00 -1.7993416e-01 -2.3712231e-01\n",
      " -1.9240563e+00 -1.8695287e-02 -4.0146056e-01 -1.9232612e+00\n",
      "  1.3705601e-01 -3.6756179e-01 -1.4101760e+00 -1.6748907e-01\n",
      " -2.2689967e-01 -1.1967173e+00 -7.7312991e-02 -2.0877717e-01\n",
      " -1.2792344e+00 -3.5361975e-02 -2.2953869e-01 -1.3963954e+00\n",
      "  3.7795357e-02 -2.3976746e-01 -1.2537971e+00  1.5000001e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[ 0.0184, -0.0653, -0.2477,  ...,  0.0187, -0.2481, -1.2839],\n",
      "        [ 0.0184, -0.0653, -0.2477,  ...,  0.0187, -0.2481, -1.2839],\n",
      "        [ 0.0184, -0.0653, -0.2477,  ...,  0.0187, -0.2481, -1.2839],\n",
      "        ...,\n",
      "        [-0.3567,  0.1895, -0.3294,  ..., -0.8150,  0.6174, -0.5095],\n",
      "        [-0.1096, -0.0625,  0.6160,  ..., -0.2092,  0.7257,  0.2791],\n",
      "        [-0.1096, -0.0625,  0.6160,  ..., -0.2092,  0.7257,  0.2791]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01843209 -0.06528413 -0.24774861  0.04456883 -0.18800043 -0.6420953\n",
      " -0.07921866 -0.38690367 -1.430797   -0.22431016 -0.45389503 -1.7140808\n",
      " -0.37853083 -0.5421469  -2.2092206  -0.17284799 -0.6858283  -1.5779155\n",
      " -0.01129421 -0.7312734  -1.404813   -0.05870173 -0.6591159  -1.4653542\n",
      " -0.0719429  -0.81212807 -1.5839758  -0.13930422 -0.594504   -1.4942344\n",
      " -0.08307954 -0.64182746 -1.458472   -0.11070729 -0.6123719  -1.5453175\n",
      "  0.02491223 -0.6294817  -1.5724685  -0.07049564 -0.4986866  -1.3339919\n",
      " -0.19716597 -0.26902118 -2.0170817  -0.04418924 -0.41919616 -2.036267\n",
      "  0.11130092 -0.39158812 -1.4381152  -0.16631791 -0.26995495 -1.2614403\n",
      " -0.11539965 -0.24073131 -1.3453703  -0.08008344 -0.23321515 -1.4618456\n",
      "  0.01865184 -0.24814224 -1.2839229 ]\n",
      "data: [ 0.01843209 -0.06528413 -0.2477486   0.04456883 -0.18800043 -0.6420953\n",
      " -0.07921866 -0.38690367 -1.430797   -0.22431014 -0.45389503 -1.7140808\n",
      " -0.37853086 -0.5421469  -2.2092206  -0.17284797 -0.6858283  -1.5779155\n",
      " -0.01129421 -0.7312734  -1.404813   -0.05870173 -0.6591159  -1.4653542\n",
      " -0.0719429  -0.81212807 -1.5839758  -0.13930422 -0.594504   -1.4942344\n",
      " -0.08307954 -0.64182746 -1.458472   -0.11070729 -0.6123719  -1.5453175\n",
      "  0.02491223 -0.6294817  -1.5724685  -0.07049564 -0.4986866  -1.3339919\n",
      " -0.19716597 -0.26902118 -2.0170817  -0.04418924 -0.41919616 -2.036267\n",
      "  0.11130092 -0.39158812 -1.4381152  -0.1663179  -0.26995495 -1.2614403\n",
      " -0.11539964 -0.24073131 -1.3453703  -0.08008344 -0.23321515 -1.4618458\n",
      "  0.01865184 -0.24814224 -1.2839229   0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[ 0.0478, -0.0253, -0.2009,  ...,  0.0602, -0.2211, -1.2351],\n",
      "        [ 0.0478, -0.0253, -0.2009,  ...,  0.0602, -0.2211, -1.2351],\n",
      "        [ 0.0478, -0.0253, -0.2009,  ...,  0.0602, -0.2211, -1.2351],\n",
      "        ...,\n",
      "        [-0.1993,  0.3226, -0.1449,  ..., -0.8661,  0.7651, -0.2890],\n",
      "        [-0.1445, -0.2093,  0.5267,  ..., -0.2057,  0.5423,  0.2315],\n",
      "        [-0.1445, -0.2093,  0.5267,  ..., -0.2057,  0.5423,  0.2315]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04782018 -0.02530163 -0.20091347  0.05977404 -0.15376446 -0.5862697\n",
      " -0.05774323 -0.34204406 -1.3400537  -0.20715603 -0.40738875 -1.6269753\n",
      " -0.37749457 -0.5012665  -2.113665   -0.14535007 -0.6501957  -1.4944426\n",
      "  0.01097627 -0.6931788  -1.3422176  -0.03570136 -0.6178665  -1.4048015\n",
      " -0.0311304  -0.77173865 -1.516326   -0.10782112 -0.555974   -1.4160583\n",
      " -0.04760138 -0.6018474  -1.3819015  -0.07196441 -0.57906854 -1.4768006\n",
      "  0.06897579 -0.58678746 -1.5028849  -0.03597734 -0.46649987 -1.2584687\n",
      " -0.15051126 -0.24382302 -1.9192094  -0.00400864 -0.38808924 -1.935124\n",
      "  0.15662979 -0.36485085 -1.3745879  -0.1266082  -0.23704249 -1.1949296\n",
      " -0.07666016 -0.2155719  -1.2870772  -0.04272515 -0.20697829 -1.4048253\n",
      "  0.06016214 -0.22112723 -1.2350802 ]\n",
      "data: [ 0.04782018 -0.02530163 -0.20091347  0.05977404 -0.15376446 -0.5862697\n",
      " -0.05774323 -0.34204406 -1.3400537  -0.20715603 -0.40738878 -1.6269753\n",
      " -0.37749457 -0.5012665  -2.113665   -0.14535007 -0.6501957  -1.4944426\n",
      "  0.01097627 -0.6931788  -1.3422176  -0.03570136 -0.6178665  -1.4048015\n",
      " -0.0311304  -0.77173865 -1.516326   -0.10782112 -0.555974   -1.4160583\n",
      " -0.04760138 -0.6018474  -1.3819015  -0.07196441 -0.57906854 -1.4768006\n",
      "  0.06897579 -0.58678746 -1.5028849  -0.03597734 -0.46649987 -1.2584687\n",
      " -0.15051126 -0.243823   -1.9192092  -0.00400864 -0.38808927 -1.935124\n",
      "  0.15662979 -0.36485085 -1.3745879  -0.1266082  -0.23704249 -1.1949296\n",
      " -0.07666016 -0.2155719  -1.2870772  -0.04272514 -0.20697828 -1.4048253\n",
      "  0.06016214 -0.22112723 -1.2350802   0.17      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0042, -0.0581, -0.2507,  ...,  0.0211, -0.2413, -1.2931],\n",
      "        [ 0.0042, -0.0581, -0.2507,  ...,  0.0211, -0.2413, -1.2931],\n",
      "        [ 0.0042, -0.0581, -0.2507,  ...,  0.0211, -0.2413, -1.2931],\n",
      "        ...,\n",
      "        [-0.3317,  0.2183, -0.2585,  ..., -0.8399,  0.6356, -0.4250],\n",
      "        [-0.1054, -0.0360,  0.5903,  ..., -0.2158,  0.7660,  0.2491],\n",
      "        [-0.1054, -0.0360,  0.5903,  ..., -0.2158,  0.7660,  0.2491]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00423134 -0.05812118 -0.2506972   0.03009741 -0.19116499 -0.6586092\n",
      " -0.07975296 -0.38024685 -1.433698   -0.22389875 -0.44647092 -1.7204416\n",
      " -0.38237146 -0.546424   -2.2100153  -0.1918841  -0.6677692  -1.5865968\n",
      " -0.00332409 -0.70337087 -1.3935927  -0.05038379 -0.63461816 -1.4517335\n",
      " -0.06136551 -0.77441686 -1.5695398  -0.15528561 -0.5700844  -1.5044148\n",
      " -0.08382281 -0.6213934  -1.4692065  -0.10619463 -0.5924411  -1.5574368\n",
      "  0.02952556 -0.6111701  -1.5941429  -0.07710101 -0.48314157 -1.3364624\n",
      " -0.19119911 -0.25259474 -1.9804833  -0.04231311 -0.4034977  -1.9885031\n",
      "  0.11345193 -0.37552738 -1.4512858  -0.17310433 -0.25020683 -1.26733\n",
      " -0.10898231 -0.22375639 -1.3425548  -0.06624371 -0.22599249 -1.4590724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.02110634 -0.24126323 -1.2931216 ]\n",
      "data: [ 0.00423134 -0.05812118 -0.2506972   0.03009741 -0.19116499 -0.6586092\n",
      " -0.07975296 -0.38024685 -1.4336982  -0.22389875 -0.44647092 -1.7204416\n",
      " -0.38237146 -0.546424   -2.2100153  -0.1918841  -0.6677692  -1.5865968\n",
      " -0.00332409 -0.70337087 -1.3935927  -0.05038379 -0.63461816 -1.4517334\n",
      " -0.06136551 -0.77441686 -1.5695398  -0.15528561 -0.5700844  -1.5044148\n",
      " -0.08382282 -0.6213934  -1.4692063  -0.10619463 -0.5924411  -1.5574368\n",
      "  0.02952556 -0.6111701  -1.5941429  -0.07710101 -0.48314154 -1.3364624\n",
      " -0.19119911 -0.25259474 -1.9804833  -0.04231311 -0.4034977  -1.9885031\n",
      "  0.11345193 -0.37552738 -1.4512858  -0.17310433 -0.25020683 -1.26733\n",
      " -0.1089823  -0.22375639 -1.3425548  -0.06624371 -0.22599249 -1.4590725\n",
      "  0.02110634 -0.24126321 -1.2931217   0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0271, -0.0299, -0.2160,  ...,  0.0482, -0.2249, -1.2547],\n",
      "        [ 0.0271, -0.0299, -0.2160,  ...,  0.0482, -0.2249, -1.2547],\n",
      "        [ 0.0271, -0.0299, -0.2160,  ...,  0.0482, -0.2249, -1.2547],\n",
      "        ...,\n",
      "        [-0.2114,  0.3609, -0.1867,  ..., -0.8864,  0.8454, -0.3769],\n",
      "        [-0.1499, -0.2162,  0.5446,  ..., -0.2265,  0.5471,  0.2329],\n",
      "        [-0.1499, -0.2162,  0.5446,  ..., -0.2265,  0.5471,  0.2329]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0271304  -0.02985448 -0.21601321  0.03896192 -0.16755281 -0.6250242\n",
      " -0.05871571 -0.34468    -1.3554167  -0.20200667 -0.4066332  -1.6462545\n",
      " -0.3737046  -0.51156783 -2.1210146  -0.1707515  -0.64268804 -1.5080384\n",
      "  0.01311819 -0.6728592  -1.3418932  -0.03175873 -0.6042173  -1.4027268\n",
      " -0.02265531 -0.74342823 -1.5144854  -0.13200594 -0.54177594 -1.4308285\n",
      " -0.05721361 -0.589993   -1.4010975  -0.07267264 -0.5679635  -1.4968733\n",
      "  0.06683527 -0.57906187 -1.5363694  -0.05243542 -0.4593514  -1.2669014\n",
      " -0.15615079 -0.23834568 -1.8911617  -0.01126215 -0.3817635  -1.8962033\n",
      "  0.14709793 -0.3567095  -1.3994843  -0.14340691 -0.22749804 -1.2064732\n",
      " -0.08062929 -0.20818387 -1.2902601  -0.03983466 -0.20958063 -1.4086764\n",
      "  0.04818689 -0.22485428 -1.2547059 ]\n",
      "data: [ 0.0271304  -0.02985448 -0.21601321  0.03896192 -0.16755281 -0.6250242\n",
      " -0.05871571 -0.34468    -1.3554168  -0.20200667 -0.4066332  -1.6462545\n",
      " -0.3737046  -0.51156783 -2.1210146  -0.1707515  -0.64268804 -1.5080383\n",
      "  0.01311819 -0.6728592  -1.3418932  -0.03175873 -0.6042173  -1.4027268\n",
      " -0.02265531 -0.7434282  -1.5144854  -0.13200594 -0.54177594 -1.4308285\n",
      " -0.05721361 -0.589993   -1.4010975  -0.07267264 -0.5679635  -1.4968734\n",
      "  0.06683527 -0.57906187 -1.5363694  -0.05243542 -0.4593514  -1.2669014\n",
      " -0.15615079 -0.23834568 -1.8911617  -0.01126215 -0.3817635  -1.8962033\n",
      "  0.14709793 -0.3567095  -1.3994843  -0.14340691 -0.22749804 -1.2064732\n",
      " -0.08062929 -0.20818385 -1.29026    -0.03983466 -0.20958063 -1.4086765\n",
      "  0.04818689 -0.22485428 -1.2547059   0.19      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0109, -0.0703, -0.2373,  ...,  0.0311, -0.2524, -1.2846],\n",
      "        [ 0.0109, -0.0703, -0.2373,  ...,  0.0311, -0.2524, -1.2846],\n",
      "        [ 0.0109, -0.0703, -0.2373,  ...,  0.0311, -0.2524, -1.2846],\n",
      "        ...,\n",
      "        [-0.3168,  0.2486, -0.3202,  ..., -0.8374,  0.7010, -0.4944],\n",
      "        [-0.1190, -0.0605,  0.5916,  ..., -0.2396,  0.7348,  0.2500],\n",
      "        [-0.1190, -0.0605,  0.5916,  ..., -0.2396,  0.7348,  0.2500]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01092957 -0.07032151 -0.23727548  0.03683756 -0.20593509 -0.647477\n",
      " -0.06341421 -0.39057887 -1.411237   -0.20463558 -0.45480317 -1.7002854\n",
      " -0.3645385  -0.5583599  -2.184968   -0.18440579 -0.6765555  -1.5665805\n",
      "  0.01383831 -0.7075123  -1.3752749  -0.0327335  -0.64118445 -1.4324462\n",
      " -0.04085573 -0.77636826 -1.5495753  -0.14729397 -0.57656723 -1.4851258\n",
      " -0.07011183 -0.62796754 -1.4543514  -0.08896822 -0.5991746  -1.5443025\n",
      "  0.04512769 -0.6190338  -1.5862529  -0.06641459 -0.490915   -1.3166685\n",
      " -0.17782722 -0.2617036  -1.9550068  -0.02851855 -0.41207665 -1.9597874\n",
      "  0.12520422 -0.38248855 -1.4427254  -0.16349977 -0.2574923  -1.2497022\n",
      " -0.09466971 -0.23208424 -1.3251498  -0.05046518 -0.23769377 -1.4425025\n",
      "  0.03105255 -0.2524477  -1.2846277 ]\n",
      "data: [ 0.01092957 -0.07032151 -0.23727548  0.03683756 -0.20593509 -0.647477\n",
      " -0.06341421 -0.39057887 -1.411237   -0.20463558 -0.45480317 -1.7002854\n",
      " -0.3645385  -0.5583599  -2.184968   -0.18440579 -0.67655545 -1.5665805\n",
      "  0.01383831 -0.70751226 -1.375275   -0.0327335  -0.64118445 -1.4324462\n",
      " -0.04085573 -0.77636826 -1.5495753  -0.14729397 -0.57656723 -1.4851258\n",
      " -0.07011183 -0.62796754 -1.4543515  -0.08896822 -0.5991746  -1.5443025\n",
      "  0.04512769 -0.6190338  -1.5862529  -0.06641459 -0.490915   -1.3166685\n",
      " -0.17782722 -0.2617036  -1.9550068  -0.02851855 -0.41207665 -1.9597872\n",
      "  0.12520422 -0.38248855 -1.4427254  -0.16349977 -0.2574923  -1.2497022\n",
      " -0.09466971 -0.23208423 -1.3251499  -0.05046518 -0.23769377 -1.4425025\n",
      "  0.03105255 -0.2524477  -1.2846277   0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[ 0.0194, -0.0720, -0.2337,  ...,  0.0562, -0.2593, -1.2789],\n",
      "        [ 0.0194, -0.0720, -0.2337,  ...,  0.0562, -0.2593, -1.2789],\n",
      "        [ 0.0194, -0.0720, -0.2337,  ...,  0.0562, -0.2593, -1.2789],\n",
      "        ...,\n",
      "        [-0.1781,  0.3670, -0.1631,  ..., -0.8324,  0.8558, -0.3732],\n",
      "        [-0.1453, -0.1622,  0.5684,  ..., -0.2452,  0.6064,  0.2299],\n",
      "        [-0.1453, -0.1622,  0.5684,  ..., -0.2452,  0.6064,  0.2299]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.9400094e-02 -7.2020322e-02 -2.3374008e-01  3.8259584e-02\n",
      " -2.1063039e-01 -6.4504743e-01 -4.6066865e-02 -3.9512926e-01\n",
      " -1.3897607e+00 -1.8581533e-01 -4.5635736e-01 -1.6882262e+00\n",
      " -3.5378119e-01 -5.7353854e-01 -2.1556215e+00 -1.8174559e-01\n",
      " -6.7833775e-01 -1.5476358e+00  3.8956739e-02 -7.0971251e-01\n",
      " -1.3621459e+00 -1.2392350e-02 -6.4808172e-01 -1.4153337e+00\n",
      " -1.1506304e-02 -7.8224307e-01 -1.5319512e+00 -1.3610610e-01\n",
      " -5.7397485e-01 -1.4607565e+00 -5.0853997e-02 -6.2957692e-01\n",
      " -1.4377623e+00 -5.8486111e-02 -6.0500568e-01 -1.5317481e+00\n",
      "  7.0441552e-02 -6.3116968e-01 -1.5789609e+00 -4.4475615e-02\n",
      " -4.8775619e-01 -1.2897882e+00 -1.5972152e-01 -2.6089990e-01\n",
      " -1.9399819e+00 -1.7073080e-03 -4.1842425e-01 -1.9385114e+00\n",
      "  1.5386090e-01 -3.8539600e-01 -1.4345291e+00 -1.4926273e-01\n",
      " -2.5162143e-01 -1.2246728e+00 -6.4873450e-02 -2.3100515e-01\n",
      " -1.3080795e+00 -1.7795004e-02 -2.4735586e-01 -1.4246566e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5.6212917e-02 -2.5926670e-01 -1.2789133e+00]\n",
      "data: [-4.55 -0.89 -0.97 -4.5  -0.6  -0.75 -4.39 -0.46 -0.63  0.    0.    0.\n",
      "  0.    0.    0.   -4.32 -0.26 -0.75 -4.26 -0.08 -0.66 -4.28  0.09 -0.31\n",
      "  0.    0.    0.   -4.39 -0.21 -0.85 -4.46  0.01 -0.61 -4.39  0.38 -0.75\n",
      " -3.69  1.21 -4.34 -4.41 -0.17 -0.85 -4.47  0.08 -0.82 -4.43  0.34 -0.75\n",
      "  0.    0.    0.   -4.47 -0.14 -1.04 -4.47  0.12 -1.04 -4.48  0.24 -1.11\n",
      " -4.47  0.27 -0.92  0.  ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0220, -0.0908, -0.3346,  ...,  0.0045, -0.3220, -0.9701],\n",
      "        [ 0.0220, -0.0908, -0.3346,  ...,  0.0045, -0.3220, -0.9701],\n",
      "        [ 0.0220, -0.0908, -0.3346,  ...,  0.0045, -0.3220, -0.9701],\n",
      "        ...,\n",
      "        [ 0.5007, -0.6346,  0.8601,  ..., -0.1661, -0.1773,  0.2200],\n",
      "        [ 0.6914, -0.3548,  0.6271,  ..., -0.7384,  0.1080,  0.5732],\n",
      "        [ 0.6914, -0.3548,  0.6271,  ..., -0.7384,  0.1080,  0.5732]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02199036 -0.09081455 -0.33456331 -0.04520277 -0.1755104  -0.85874\n",
      " -0.0254509  -0.20061806 -1.0783982  -0.02876845 -0.25930756 -1.1347406\n",
      "  0.04960894 -0.2959764  -1.4404416  -0.08455385 -0.36037898 -1.302093\n",
      "  0.14969015 -0.3316145  -0.6497735   0.10930113 -0.37584436 -0.7033729\n",
      "  0.01044254 -0.35425526 -0.8407132  -0.11717848 -0.33149707 -1.3253376\n",
      " -0.07963635 -0.33518624 -1.3508708  -0.09817354 -0.32199588 -1.3378489\n",
      " -0.06597296 -0.39528793 -1.2816143  -0.08662526 -0.28724205 -1.2637856\n",
      "  0.01515214 -0.27275038 -0.81569177 -0.06987444 -0.2603976  -0.8160255\n",
      "  0.02260585 -0.3362012  -1.1950254  -0.09368794 -0.20029667 -1.1249014\n",
      " -0.01890337 -0.23131406 -1.0724332  -0.06914477 -0.25201863 -1.0720263\n",
      "  0.00447268 -0.32199845 -0.9700713 ]\n",
      "init: [ 0.02199036 -0.09081455 -0.33456331 -0.04520277 -0.1755104  -0.85874\n",
      " -0.0254509  -0.20061806 -1.0783982  -0.02876845 -0.25930756 -1.1347406\n",
      "  0.04960894 -0.2959764  -1.4404416  -0.08455385 -0.36037898 -1.302093\n",
      "  0.14969015 -0.3316145  -0.6497735   0.10930113 -0.37584436 -0.7033729\n",
      "  0.01044254 -0.35425526 -0.8407132  -0.11717848 -0.33149707 -1.3253376\n",
      " -0.07963635 -0.33518624 -1.3508708  -0.09817354 -0.32199588 -1.3378489\n",
      " -0.06597296 -0.39528793 -1.2816143  -0.08662526 -0.28724205 -1.2637856\n",
      "  0.01515214 -0.27275038 -0.81569177 -0.06987444 -0.2603976  -0.8160255\n",
      "  0.02260585 -0.3362012  -1.1950254  -0.09368794 -0.20029667 -1.1249014\n",
      " -0.01890337 -0.23131406 -1.0724332  -0.06914477 -0.25201863 -1.0720263\n",
      "  0.00447268 -0.32199845 -0.9700713 ]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [ 0.02199036 -0.09081455 -0.33456334 -0.04520278 -0.1755104  -0.85874003\n",
      " -0.0254509  -0.20061806 -1.0783982  -0.02876845 -0.25930756 -1.1347406\n",
      "  0.04960893 -0.2959764  -1.4404416  -0.08455385 -0.36037898 -1.302093\n",
      "  0.14969015 -0.3316145  -0.6497735   0.10930113 -0.37584436 -0.7033729\n",
      "  0.01044254 -0.35425526 -0.8407132  -0.11717848 -0.33149707 -1.3253376\n",
      " -0.07963635 -0.33518624 -1.3508708  -0.09817353 -0.32199588 -1.337849\n",
      " -0.06597296 -0.39528793 -1.2816144  -0.08662525 -0.28724205 -1.2637856\n",
      "  0.01515214 -0.27275038 -0.81569177 -0.06987444 -0.2603976  -0.8160255\n",
      "  0.02260585 -0.33620116 -1.1950254  -0.09368794 -0.20029667 -1.1249014\n",
      " -0.01890337 -0.23131406 -1.0724332  -0.06914477 -0.25201863 -1.0720263\n",
      "  0.00447268 -0.32199845 -0.9700713   0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.1655, -0.3909, -0.0546,  ...,  0.2329, -0.5696, -1.1221],\n",
      "        [ 0.1655, -0.3909, -0.0546,  ...,  0.2329, -0.5696, -1.1221],\n",
      "        [ 0.1655, -0.3909, -0.0546,  ...,  0.2329, -0.5696, -1.1221],\n",
      "        ...,\n",
      "        [-0.3485,  0.5644, -0.3067,  ..., -0.7226,  1.0750, -0.5113],\n",
      "        [-0.2352,  0.2255,  0.2772,  ..., -0.5796,  0.9724, -0.0576],\n",
      "        [-0.2352,  0.2255,  0.2772,  ..., -0.5796,  0.9724, -0.0576]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.16554908 -0.39093778 -0.05457255  0.20373905 -0.53673935 -0.51803815\n",
      "  0.16979541 -0.6765113  -1.195638    0.04146597 -0.7165237  -1.4917698\n",
      " -0.08505724 -0.85118675 -1.9845113  -0.03542875 -0.9444951  -1.3787639\n",
      "  0.26396167 -0.93072367 -1.1404078   0.20634411 -0.86728895 -1.1895827\n",
      "  0.18390357 -0.95853317 -1.3103607   0.00566503 -0.84393454 -1.3080022\n",
      "  0.13795201 -0.89108944 -1.2976588   0.1308389  -0.84183633 -1.3692127\n",
      "  0.2263776  -0.88922846 -1.422618    0.1353859  -0.76659876 -1.1376306\n",
      "  0.05129506 -0.5234021  -1.6566144   0.19153357 -0.6881021  -1.6265823\n",
      "  0.31332064 -0.63756895 -1.2991002   0.02493522 -0.54548496 -1.0775723\n",
      "  0.15690379 -0.51579154 -1.1236751   0.20206234 -0.5574591  -1.2415605\n",
      "  0.23289546 -0.56963253 -1.122111  ]\n",
      "data: [ 0.16554908 -0.39093778 -0.05457255  0.20373905 -0.53673935 -0.51803815\n",
      "  0.16979542 -0.6765113  -1.195638    0.04146597 -0.71652377 -1.4917697\n",
      " -0.08505724 -0.85118675 -1.9845113  -0.03542875 -0.9444951  -1.3787639\n",
      "  0.26396167 -0.93072367 -1.1404078   0.20634411 -0.86728895 -1.1895827\n",
      "  0.18390357 -0.95853317 -1.3103607   0.00566503 -0.84393454 -1.3080021\n",
      "  0.13795201 -0.8910895  -1.2976588   0.1308389  -0.84183633 -1.3692127\n",
      "  0.2263776  -0.88922846 -1.4226182   0.1353859  -0.76659876 -1.1376306\n",
      "  0.05129506 -0.5234021  -1.6566144   0.19153357 -0.6881021  -1.6265824\n",
      "  0.31332064 -0.63756895 -1.2991002   0.02493522 -0.54548496 -1.0775723\n",
      "  0.15690379 -0.51579154 -1.1236751   0.20206234 -0.5574591  -1.2415605\n",
      "  0.23289546 -0.56963253 -1.122111    0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0219, -0.1229, -0.2315,  ..., -0.0905, -0.3338, -1.2318],\n",
      "        [ 0.0219, -0.1229, -0.2315,  ..., -0.0905, -0.3338, -1.2318],\n",
      "        [ 0.0219, -0.1229, -0.2315,  ..., -0.0905, -0.3338, -1.2318],\n",
      "        ...,\n",
      "        [-0.1422,  0.3841, -0.1149,  ..., -0.1732,  0.9228, -0.6321],\n",
      "        [-0.0456, -0.0484,  0.6727,  ...,  0.2571,  0.6202,  0.2116],\n",
      "        [-0.0456, -0.0484,  0.6727,  ...,  0.2571,  0.6202,  0.2116]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02191715 -0.12289414 -0.23147227 -0.02479503 -0.2497326  -0.6290325\n",
      " -0.15188658 -0.48129642 -1.393787   -0.32166296 -0.5455261  -1.7138278\n",
      " -0.54612225 -0.6394212  -2.1946487  -0.23326987 -0.7498758  -1.5921425\n",
      " -0.15567419 -0.8379618  -1.492523   -0.21943271 -0.7446959  -1.5602562\n",
      " -0.20123428 -0.9634222  -1.6532578  -0.19553381 -0.64496124 -1.480383\n",
      " -0.19732118 -0.70141983 -1.409347   -0.2535178  -0.7282536  -1.5245783\n",
      " -0.13763267 -0.69779146 -1.5130675  -0.1291092  -0.5483985  -1.3420811\n",
      " -0.29478508 -0.3686353  -2.0434217  -0.17549437 -0.5275248  -2.0661297\n",
      " -0.02869616 -0.5076891  -1.3558493  -0.21377027 -0.33715528 -1.2675712\n",
      " -0.20950425 -0.3417694  -1.3443553  -0.2061958  -0.3332626  -1.4417315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.09051645 -0.3338306  -1.2318392 ]\n",
      "data: [ 0.02191715 -0.12289414 -0.23147227 -0.02479503 -0.24973258 -0.6290325\n",
      " -0.15188658 -0.48129642 -1.393787   -0.321663   -0.5455261  -1.7138278\n",
      " -0.54612225 -0.6394212  -2.1946487  -0.23326987 -0.7498758  -1.5921425\n",
      " -0.15567419 -0.8379618  -1.4925228  -0.21943271 -0.7446959  -1.5602562\n",
      " -0.20123428 -0.9634222  -1.6532578  -0.19553381 -0.64496124 -1.480383\n",
      " -0.19732116 -0.70141983 -1.409347   -0.2535178  -0.7282536  -1.5245785\n",
      " -0.13763267 -0.69779146 -1.5130675  -0.1291092  -0.5483985  -1.342081\n",
      " -0.29478508 -0.3686353  -2.0434217  -0.17549437 -0.5275248  -2.0661297\n",
      " -0.02869616 -0.5076891  -1.3558493  -0.21377027 -0.33715525 -1.2675712\n",
      " -0.20950425 -0.3417694  -1.3443553  -0.20619579 -0.3332626  -1.4417315\n",
      " -0.09051646 -0.3338306  -1.2318392   0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0163,  0.0386, -0.1791,  ...,  0.0582, -0.1614, -1.1970],\n",
      "        [ 0.0163,  0.0386, -0.1791,  ...,  0.0582, -0.1614, -1.1970],\n",
      "        [ 0.0163,  0.0386, -0.1791,  ...,  0.0582, -0.1614, -1.1970],\n",
      "        ...,\n",
      "        [-0.1948,  0.3208, -0.1225,  ..., -0.9434,  0.9108, -0.4402],\n",
      "        [-0.1840, -0.3086,  0.5117,  ..., -0.2917,  0.3182,  0.2752],\n",
      "        [-0.1840, -0.3086,  0.5117,  ..., -0.2917,  0.3182,  0.2752]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01631811  0.03856105 -0.1791219   0.01897672 -0.10233913 -0.57689005\n",
      " -0.05368835 -0.27015865 -1.3193942  -0.19214913 -0.3257495  -1.6274816\n",
      " -0.38866287 -0.44627973 -2.0773702  -0.18899295 -0.5617919  -1.4836707\n",
      "  0.04435348 -0.57875896 -1.3028227   0.00346569 -0.5220822  -1.3550055\n",
      "  0.04239161 -0.6514257  -1.4730448  -0.14515376 -0.44644085 -1.393377\n",
      " -0.04115902 -0.5044582  -1.361355   -0.03035748 -0.48912713 -1.4710515\n",
      "  0.1323196  -0.5128325  -1.5338831  -0.05242072 -0.37364182 -1.2103436\n",
      " -0.16542915 -0.15091854 -1.8818793   0.00729492 -0.3071238  -1.8762873\n",
      "  0.19644144 -0.28320608 -1.3604387  -0.16198722 -0.12705076 -1.1393656\n",
      " -0.07292304 -0.11856222 -1.2130213  -0.02124269 -0.13972946 -1.3360771\n",
      "  0.0582453  -0.16144292 -1.1969686 ]\n",
      "data: [ 0.01631811  0.03856105 -0.1791219   0.01897672 -0.10233913 -0.57689005\n",
      " -0.05368834 -0.27015865 -1.3193942  -0.19214912 -0.3257495  -1.6274816\n",
      " -0.38866287 -0.4462797  -2.0773702  -0.18899293 -0.5617919  -1.4836707\n",
      "  0.04435347 -0.57875896 -1.3028227   0.00346569 -0.5220822  -1.3550055\n",
      "  0.04239161 -0.6514257  -1.4730448  -0.14515376 -0.44644085 -1.393377\n",
      " -0.04115902 -0.5044582  -1.361355   -0.03035748 -0.48912713 -1.4710515\n",
      "  0.1323196  -0.5128325  -1.5338831  -0.05242072 -0.37364182 -1.2103436\n",
      " -0.16542916 -0.15091854 -1.8818793   0.00729492 -0.3071238  -1.8762873\n",
      "  0.19644144 -0.28320608 -1.3604387  -0.16198722 -0.12705076 -1.1393656\n",
      " -0.07292304 -0.11856222 -1.2130213  -0.02124269 -0.13972946 -1.3360771\n",
      "  0.0582453  -0.16144294 -1.1969686   0.04      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0842, -0.1132, -0.1821,  ...,  0.1043, -0.2817, -1.2916],\n",
      "        [ 0.0842, -0.1132, -0.1821,  ...,  0.1043, -0.2817, -1.2916],\n",
      "        [ 0.0842, -0.1132, -0.1821,  ...,  0.1043, -0.2817, -1.2916],\n",
      "        ...,\n",
      "        [-0.2697,  0.3167, -0.2996,  ..., -0.7921,  0.7906, -0.4351],\n",
      "        [-0.2408, -0.0702,  0.4581,  ..., -0.3162,  0.6979,  0.1753],\n",
      "        [-0.2408, -0.0702,  0.4581,  ..., -0.3162,  0.6979,  0.1753]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.08423954 -0.11321427 -0.18212235  0.09338029 -0.28868562 -0.6698061\n",
      "  0.05036802 -0.44518298 -1.3497313  -0.08199449 -0.4996456  -1.6450777\n",
      " -0.26391706 -0.64084446 -2.0851347  -0.14147446 -0.6950208  -1.5004414\n",
      "  0.13019133 -0.69691694 -1.2621738   0.08072944 -0.64032304 -1.3083955\n",
      "  0.08289457 -0.731285   -1.4146082  -0.09693733 -0.56857765 -1.4307535\n",
      "  0.01542749 -0.62342155 -1.4093046   0.01813672 -0.5978749  -1.4999937\n",
      "  0.13170402 -0.614686   -1.5735422   0.0103342  -0.5055688  -1.2611979\n",
      " -0.07132319 -0.28136927 -1.776467    0.05987523 -0.42542532 -1.744472\n",
      "  0.19166458 -0.38164458 -1.4368567  -0.08750518 -0.2601276  -1.2112904\n",
      "  0.01223105 -0.24230874 -1.2853334   0.07307914 -0.2751843  -1.3999467\n",
      "  0.10433841 -0.28173077 -1.2916354 ]\n",
      "data: [ 0.08423954 -0.11321428 -0.18212235  0.09338029 -0.28868562 -0.6698061\n",
      "  0.05036802 -0.44518298 -1.3497313  -0.08199449 -0.4996456  -1.6450777\n",
      " -0.26391706 -0.6408445  -2.0851347  -0.14147446 -0.69502085 -1.5004414\n",
      "  0.13019133 -0.69691694 -1.2621738   0.08072944 -0.64032304 -1.3083955\n",
      "  0.08289457 -0.7312849  -1.4146084  -0.09693733 -0.56857765 -1.4307535\n",
      "  0.01542749 -0.62342155 -1.4093046   0.01813672 -0.5978749  -1.4999938\n",
      "  0.13170402 -0.614686   -1.5735421   0.0103342  -0.5055688  -1.2611979\n",
      " -0.07132319 -0.28136927 -1.776467    0.05987523 -0.42542535 -1.744472\n",
      "  0.19166458 -0.3816446  -1.4368567  -0.08750518 -0.2601276  -1.2112904\n",
      "  0.01223105 -0.24230874 -1.2853334   0.07307914 -0.2751843  -1.3999467\n",
      "  0.10433841 -0.28173077 -1.2916354   0.05      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[-0.0029, -0.1163, -0.2142,  ...,  0.0664, -0.3139, -1.2409],\n",
      "        [-0.0029, -0.1163, -0.2142,  ...,  0.0664, -0.3139, -1.2409],\n",
      "        [-0.0029, -0.1163, -0.2142,  ...,  0.0664, -0.3139, -1.2409],\n",
      "        ...,\n",
      "        [-0.0718,  0.5416, -0.1183,  ..., -0.5777,  1.0507, -0.5030],\n",
      "        [-0.1741, -0.0441,  0.5970,  ..., -0.2567,  0.7276,  0.1669],\n",
      "        [-0.1741, -0.0441,  0.5970,  ..., -0.2567,  0.7276,  0.1669]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.00291843 -0.11630192 -0.21416827  0.02407498 -0.2385868  -0.5827342\n",
      " -0.08726687 -0.4488351  -1.3797779  -0.23743027 -0.5140929  -1.6759217\n",
      " -0.39409888 -0.62819487 -2.1608076  -0.20568354 -0.7293769  -1.5635468\n",
      "  0.00977173 -0.7850406  -1.386716   -0.04339632 -0.7159495  -1.4323773\n",
      " -0.04734256 -0.8694303  -1.5506649  -0.14958675 -0.6338898  -1.4643106\n",
      " -0.07252287 -0.6981927  -1.4364262  -0.07530246 -0.6720504  -1.5200642\n",
      "  0.05692723 -0.7099197  -1.5547462  -0.05050012 -0.53995407 -1.2915562\n",
      " -0.18491976 -0.30330446 -1.9850243  -0.00751837 -0.4841276  -1.989633\n",
      "  0.16119428 -0.4424712  -1.4115412  -0.16800703 -0.30567783 -1.2155967\n",
      " -0.07576975 -0.27907807 -1.2987052  -0.02389432 -0.30169943 -1.4105985\n",
      "  0.06639389 -0.3139118  -1.24092   ]\n",
      "data: [-0.00291843 -0.11630192 -0.21416827  0.02407498 -0.23858681 -0.5827342\n",
      " -0.08726688 -0.4488351  -1.3797778  -0.23743027 -0.5140929  -1.6759217\n",
      " -0.39409888 -0.62819487 -2.1608076  -0.20568353 -0.7293769  -1.5635468\n",
      "  0.00977173 -0.7850406  -1.386716   -0.04339632 -0.7159495  -1.4323773\n",
      " -0.04734256 -0.8694303  -1.550665   -0.14958675 -0.6338898  -1.4643106\n",
      " -0.07252287 -0.6981928  -1.436426   -0.07530246 -0.6720504  -1.5200642\n",
      "  0.05692723 -0.7099197  -1.5547462  -0.05050012 -0.53995407 -1.2915562\n",
      " -0.18491976 -0.30330446 -1.9850242  -0.00751837 -0.4841276  -1.9896331\n",
      "  0.16119428 -0.4424712  -1.4115413  -0.16800703 -0.30567783 -1.2155967\n",
      " -0.07576975 -0.27907807 -1.2987053  -0.02389432 -0.30169943 -1.4105984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.06639389 -0.3139118  -1.24092     0.06      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0327, -0.1023, -0.1849,  ...,  0.0625, -0.3005, -1.1631],\n",
      "        [ 0.0327, -0.1023, -0.1849,  ...,  0.0625, -0.3005, -1.1631],\n",
      "        [ 0.0327, -0.1023, -0.1849,  ...,  0.0625, -0.3005, -1.1631],\n",
      "        ...,\n",
      "        [-0.1226,  0.4297, -0.0813,  ..., -0.6724,  0.9887, -0.4284],\n",
      "        [-0.0836, -0.0715,  0.6142,  ..., -0.1956,  0.6667,  0.2418],\n",
      "        [-0.0836, -0.0715,  0.6142,  ..., -0.1956,  0.6667,  0.2418]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03270439 -0.10226878 -0.18487999  0.06471089 -0.19845061 -0.4631045\n",
      " -0.09354717 -0.4283826  -1.3248663  -0.25012535 -0.4952926  -1.6089139\n",
      " -0.3984542  -0.5749084  -2.130037   -0.15248112 -0.74666226 -1.500169\n",
      " -0.00611103 -0.8158829  -1.3590539  -0.05396762 -0.7354065  -1.4146173\n",
      " -0.05870995 -0.9135417  -1.540359   -0.11216001 -0.6665801  -1.4014158\n",
      " -0.06423239 -0.71433365 -1.368882   -0.0779424  -0.6782484  -1.4521716\n",
      "  0.07307944 -0.7056838  -1.4604726  -0.03726863 -0.55207586 -1.2436335\n",
      " -0.19570453 -0.31600085 -2.0249152  -0.00544894 -0.48649004 -2.0595968\n",
      "  0.17832933 -0.44910875 -1.3315003  -0.15361959 -0.3291821  -1.1638145\n",
      " -0.09801795 -0.2975806  -1.2555149  -0.06862557 -0.28695387 -1.3717549\n",
      "  0.06246717 -0.30049455 -1.1630597 ]\n",
      "data: [ 0.03270439 -0.10226879 -0.18487999  0.06471089 -0.19845061 -0.4631045\n",
      " -0.09354717 -0.4283826  -1.3248663  -0.25012535 -0.49529257 -1.6089139\n",
      " -0.39845422 -0.5749084  -2.130037   -0.15248112 -0.7466623  -1.500169\n",
      " -0.00611103 -0.8158829  -1.3590539  -0.05396762 -0.7354065  -1.4146173\n",
      " -0.05870995 -0.9135416  -1.540359   -0.11216001 -0.66658    -1.4014158\n",
      " -0.06423239 -0.71433365 -1.368882   -0.0779424  -0.67824847 -1.4521717\n",
      "  0.07307944 -0.7056838  -1.4604726  -0.03726863 -0.55207586 -1.2436335\n",
      " -0.19570453 -0.31600085 -2.0249152  -0.00544894 -0.48649007 -2.0595968\n",
      "  0.17832933 -0.44910872 -1.3315003  -0.15361959 -0.3291821  -1.1638145\n",
      " -0.09801795 -0.2975806  -1.2555149  -0.06862557 -0.28695387 -1.3717549\n",
      "  0.06246717 -0.30049455 -1.1630597   0.07      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EC24748>\n",
      "tensor([[-0.0448, -0.0110, -0.2234,  ...,  0.0034, -0.1972, -1.1954],\n",
      "        [-0.0448, -0.0110, -0.2234,  ...,  0.0034, -0.1972, -1.1954],\n",
      "        [-0.0448, -0.0110, -0.2234,  ...,  0.0034, -0.1972, -1.1954],\n",
      "        ...,\n",
      "        [-0.1458,  0.3304,  0.0472,  ..., -0.7240,  0.8867, -0.3374],\n",
      "        [-0.0967, -0.0694,  0.5696,  ..., -0.2252,  0.6537,  0.1917],\n",
      "        [-0.0967, -0.0694,  0.5696,  ..., -0.2252,  0.6537,  0.1917]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.04480878 -0.01104876 -0.22340403 -0.0187601  -0.11873542 -0.5205159\n",
      " -0.15346032 -0.3403821  -1.3622991  -0.3099299  -0.40221107 -1.6633357\n",
      " -0.47220975 -0.5036416  -2.1654983  -0.24773537 -0.64368653 -1.5328379\n",
      " -0.05131288 -0.6997236  -1.3614167  -0.10438935 -0.6274407  -1.4135804\n",
      " -0.10625124 -0.7916666  -1.5450027  -0.1986472  -0.5520941  -1.426503\n",
      " -0.13005078 -0.60608184 -1.4030249  -0.1299909  -0.5699136  -1.4951311\n",
      "  0.02138378 -0.60658944 -1.5201379  -0.10473578 -0.44102493 -1.2543563\n",
      " -0.26256537 -0.20038685 -2.0318615  -0.06276997 -0.37764505 -2.0530908\n",
      "  0.12799697 -0.33725205 -1.3720376  -0.22954084 -0.20903009 -1.1751013\n",
      " -0.14865328 -0.18037356 -1.2628438  -0.11068977 -0.18625626 -1.3816078\n",
      "  0.00341862 -0.19723423 -1.1953719 ]\n",
      "data: [-0.04480878 -0.01104876 -0.22340402 -0.0187601  -0.11873542 -0.5205159\n",
      " -0.15346032 -0.34038207 -1.3622991  -0.3099299  -0.40221107 -1.6633357\n",
      " -0.47220975 -0.5036416  -2.1654983  -0.24773537 -0.64368653 -1.5328379\n",
      " -0.05131288 -0.6997236  -1.3614166  -0.10438935 -0.6274407  -1.4135804\n",
      " -0.10625124 -0.7916666  -1.5450027  -0.1986472  -0.5520941  -1.426503\n",
      " -0.13005078 -0.60608184 -1.4030249  -0.1299909  -0.5699136  -1.495131\n",
      "  0.02138378 -0.60658944 -1.5201379  -0.10473578 -0.44102493 -1.2543563\n",
      " -0.26256537 -0.20038685 -2.0318615  -0.06276997 -0.37764505 -2.0530908\n",
      "  0.12799697 -0.33725205 -1.3720376  -0.22954084 -0.20903009 -1.1751013\n",
      " -0.14865328 -0.18037358 -1.2628438  -0.11068977 -0.18625626 -1.3816078\n",
      "  0.00341862 -0.19723423 -1.1953719   0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0173, -0.0816, -0.1829,  ...,  0.0198, -0.2399, -1.3042],\n",
      "        [ 0.0173, -0.0816, -0.1829,  ...,  0.0198, -0.2399, -1.3042],\n",
      "        [ 0.0173, -0.0816, -0.1829,  ...,  0.0198, -0.2399, -1.3042],\n",
      "        ...,\n",
      "        [-0.2784,  0.3093, -0.1953,  ..., -0.7953,  0.7900, -0.3823],\n",
      "        [-0.2082, -0.1065,  0.4955,  ..., -0.2939,  0.6297,  0.2422],\n",
      "        [-0.2082, -0.1065,  0.4955,  ..., -0.2939,  0.6297,  0.2422]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01725983 -0.08156444 -0.18292859  0.02991903 -0.24283814 -0.6531254\n",
      " -0.01734281 -0.39042327 -1.3330467  -0.15601231 -0.4427774  -1.6392368\n",
      " -0.34192303 -0.5715377  -2.0964293  -0.20605138 -0.6629031  -1.4907438\n",
      "  0.05801407 -0.6620659  -1.2696735   0.01306441 -0.6086117  -1.3206226\n",
      "  0.01483597 -0.7047671  -1.4342462  -0.16469714 -0.54443985 -1.4170023\n",
      " -0.05387006 -0.59765476 -1.4050884  -0.05173731 -0.56797326 -1.5138148\n",
      "  0.0781462  -0.58731747 -1.5919601  -0.06577431 -0.47478226 -1.2432972\n",
      " -0.1480183  -0.25008318 -1.7758837  -0.01234561 -0.38596576 -1.7559205\n",
      "  0.13290766 -0.3532251  -1.4465424  -0.16631341 -0.22788543 -1.193559\n",
      " -0.07493733 -0.20793596 -1.2715492  -0.01945058 -0.23362228 -1.3942488\n",
      "  0.01981949 -0.23986188 -1.3041724 ]\n",
      "data: [ 0.01725983 -0.08156445 -0.1829286   0.02991903 -0.24283813 -0.6531254\n",
      " -0.01734281 -0.39042327 -1.3330467  -0.15601231 -0.4427774  -1.6392368\n",
      " -0.34192303 -0.5715377  -2.0964293  -0.2060514  -0.6629031  -1.4907438\n",
      "  0.05801407 -0.66206586 -1.2696735   0.01306441 -0.6086117  -1.3206226\n",
      "  0.01483597 -0.70476705 -1.4342462  -0.16469713 -0.54443985 -1.4170022\n",
      " -0.05387006 -0.59765476 -1.4050885  -0.05173731 -0.56797326 -1.5138148\n",
      "  0.0781462  -0.58731747 -1.5919602  -0.06577431 -0.47478226 -1.2432972\n",
      " -0.1480183  -0.25008318 -1.7758837  -0.01234561 -0.38596576 -1.7559205\n",
      "  0.13290766 -0.3532251  -1.4465424  -0.1663134  -0.22788543 -1.193559\n",
      " -0.07493733 -0.20793596 -1.2715492  -0.01945058 -0.23362228 -1.3942488\n",
      "  0.01981949 -0.23986188 -1.3041724   0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0403, -0.1335, -0.2991,  ...,  0.0554, -0.3039, -1.3564],\n",
      "        [ 0.0403, -0.1335, -0.2991,  ...,  0.0554, -0.3039, -1.3564],\n",
      "        [ 0.0403, -0.1335, -0.2991,  ...,  0.0554, -0.3039, -1.3564],\n",
      "        ...,\n",
      "        [-0.1460,  0.4791, -0.0613,  ..., -0.7185,  1.0029, -0.3774],\n",
      "        [-0.1868, -0.0588,  0.6240,  ..., -0.2752,  0.7215,  0.2674],\n",
      "        [-0.1868, -0.0588,  0.6240,  ..., -0.2752,  0.7215,  0.2674]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 4.0258739e-02 -1.3351771e-01 -2.9912826e-01  7.3353916e-02\n",
      " -2.5735313e-01 -6.9190836e-01 -3.2836691e-02 -4.5715883e-01\n",
      " -1.4886727e+00 -1.7849307e-01 -5.1883680e-01 -1.7851187e+00\n",
      " -3.2577294e-01 -6.2014908e-01 -2.2866912e+00 -1.6059592e-01\n",
      " -7.4292690e-01 -1.6609011e+00  4.6405077e-02 -7.8370011e-01\n",
      " -1.4747941e+00 -6.5532178e-03 -7.1866673e-01 -1.5287950e+00\n",
      " -2.3997068e-02 -8.6123413e-01 -1.6542677e+00 -1.1929992e-01\n",
      " -6.4723331e-01 -1.5678122e+00 -4.6955355e-02 -7.0016551e-01\n",
      " -1.5454028e+00 -6.1222069e-02 -6.6604966e-01 -1.6341504e+00\n",
      "  6.5375492e-02 -6.9964558e-01 -1.6711448e+00 -3.2728724e-02\n",
      " -5.4617977e-01 -1.3980420e+00 -1.6516109e-01 -3.1021672e-01\n",
      " -2.0781217e+00 -4.8464537e-04 -4.7331178e-01 -2.0893204e+00\n",
      "  1.5508988e-01 -4.3593425e-01 -1.5275421e+00 -1.4474019e-01\n",
      " -3.1425506e-01 -1.3235058e+00 -6.6750333e-02 -2.8230768e-01\n",
      " -1.4001201e+00 -2.6405737e-02 -2.9284561e-01 -1.5164815e+00\n",
      "  5.5395938e-02 -3.0394661e-01 -1.3563614e+00]\n",
      "data: [ 4.0258743e-02 -1.3351771e-01 -2.9912826e-01  7.3353916e-02\n",
      " -2.5735313e-01 -6.9190836e-01 -3.2836691e-02 -4.5715886e-01\n",
      " -1.4886727e+00 -1.7849307e-01 -5.1883680e-01 -1.7851187e+00\n",
      " -3.2577294e-01 -6.2014908e-01 -2.2866912e+00 -1.6059594e-01\n",
      " -7.4292684e-01 -1.6609011e+00  4.6405077e-02 -7.8370011e-01\n",
      " -1.4747941e+00 -6.5532178e-03 -7.1866679e-01 -1.5287950e+00\n",
      " -2.3997068e-02 -8.6123413e-01 -1.6542678e+00 -1.1929992e-01\n",
      " -6.4723325e-01 -1.5678122e+00 -4.6955358e-02 -7.0016551e-01\n",
      " -1.5454029e+00 -6.1222065e-02 -6.6604966e-01 -1.6341504e+00\n",
      "  6.5375492e-02 -6.9964564e-01 -1.6711448e+00 -3.2728724e-02\n",
      " -5.4617977e-01 -1.3980420e+00 -1.6516109e-01 -3.1021672e-01\n",
      " -2.0781217e+00 -4.8464537e-04 -4.7331178e-01 -2.0893204e+00\n",
      "  1.5508988e-01 -4.3593425e-01 -1.5275421e+00 -1.4474019e-01\n",
      " -3.1425506e-01 -1.3235058e+00 -6.6750333e-02 -2.8230768e-01\n",
      " -1.4001201e+00 -2.6405737e-02 -2.9284561e-01 -1.5164815e+00\n",
      "  5.5395938e-02 -3.0394661e-01 -1.3563614e+00  1.0000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 4.0795e-04, -1.0770e-01, -2.3664e-01,  ...,  4.1650e-02,\n",
      "         -2.8744e-01, -1.3250e+00],\n",
      "        [ 4.0795e-04, -1.0770e-01, -2.3664e-01,  ...,  4.1650e-02,\n",
      "         -2.8744e-01, -1.3250e+00],\n",
      "        [ 4.0795e-04, -1.0770e-01, -2.3664e-01,  ...,  4.1650e-02,\n",
      "         -2.8744e-01, -1.3250e+00],\n",
      "        ...,\n",
      "        [-8.1961e-02,  4.9663e-01, -1.2052e-01,  ..., -6.8266e-01,\n",
      "          9.9086e-01, -3.6720e-01],\n",
      "        [-1.0273e-01, -6.2403e-02,  5.7032e-01,  ..., -1.8762e-01,\n",
      "          6.4312e-01,  2.6675e-01],\n",
      "        [-1.0273e-01, -6.2403e-02,  5.7032e-01,  ..., -1.8762e-01,\n",
      "          6.4312e-01,  2.6675e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 4.0794630e-04 -1.0769808e-01 -2.3664057e-01  1.1947263e-02\n",
      " -2.6935616e-01 -6.8729854e-01 -8.5789487e-03 -4.3031859e-01\n",
      " -1.3855879e+00 -1.4752012e-01 -4.8174649e-01 -1.7193925e+00\n",
      " -3.3966374e-01 -6.3568771e-01 -2.1675100e+00 -2.2636150e-01\n",
      " -6.8502283e-01 -1.5796461e+00  8.6510316e-02 -6.9416213e-01\n",
      " -1.3548119e+00  2.0095050e-02 -6.5286708e-01 -1.3996308e+00\n",
      "  2.2565261e-02 -7.5940824e-01 -1.5182354e+00 -1.6712470e-01\n",
      " -5.6035292e-01 -1.4813819e+00 -4.6355963e-02 -6.2994850e-01\n",
      " -1.4729428e+00 -4.1117579e-02 -6.1546564e-01 -1.5877647e+00\n",
      "  6.2762782e-02 -6.5632963e-01 -1.6623046e+00 -4.4987313e-02\n",
      " -4.8257273e-01 -1.2874775e+00 -1.5203804e-01 -2.6363966e-01\n",
      " -1.8820119e+00 -1.9683614e-03 -4.3078297e-01 -1.8519609e+00\n",
      "  1.4025299e-01 -3.9392295e-01 -1.4860997e+00 -1.6496639e-01\n",
      " -2.3550084e-01 -1.2317607e+00 -3.7658647e-02 -2.2874792e-01\n",
      " -1.3002152e+00  1.6583443e-02 -2.8231150e-01 -1.4163234e+00\n",
      "  4.1650318e-02 -2.8744489e-01 -1.3249702e+00]\n",
      "data: [ 4.07946296e-04 -1.07698075e-01 -2.36640573e-01  1.19472630e-02\n",
      " -2.69356161e-01 -6.87298536e-01 -8.57894868e-03 -4.30318594e-01\n",
      " -1.38558793e+00 -1.47520125e-01 -4.81746495e-01 -1.71939254e+00\n",
      " -3.39663744e-01 -6.35687709e-01 -2.16751003e+00 -2.26361498e-01\n",
      " -6.85022831e-01 -1.57964611e+00  8.65103155e-02 -6.94162130e-01\n",
      " -1.35481191e+00  2.00950503e-02 -6.52867079e-01 -1.39963078e+00\n",
      "  2.25652605e-02 -7.59408236e-01 -1.51823545e+00 -1.67124704e-01\n",
      " -5.60352921e-01 -1.48138189e+00 -4.63559628e-02 -6.29948497e-01\n",
      " -1.47294283e+00 -4.11175787e-02 -6.15465641e-01 -1.58776474e+00\n",
      "  6.27627820e-02 -6.56329632e-01 -1.66230464e+00 -4.49873097e-02\n",
      " -4.82572734e-01 -1.28747737e+00 -1.52038038e-01 -2.63639659e-01\n",
      " -1.88201189e+00 -1.96836144e-03 -4.30782974e-01 -1.85196090e+00\n",
      "  1.40252993e-01 -3.93922955e-01 -1.48609972e+00 -1.64966390e-01\n",
      " -2.35500857e-01 -1.23176074e+00 -3.76586467e-02 -2.28747919e-01\n",
      " -1.30021524e+00  1.65834427e-02 -2.82311499e-01 -1.41632342e+00\n",
      "  4.16503176e-02 -2.87444890e-01 -1.32497025e+00  1.09999999e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0377, -0.1147, -0.2553,  ...,  0.0524, -0.3002, -1.3099],\n",
      "        [ 0.0377, -0.1147, -0.2553,  ...,  0.0524, -0.3002, -1.3099],\n",
      "        [ 0.0377, -0.1147, -0.2553,  ...,  0.0524, -0.3002, -1.3099],\n",
      "        ...,\n",
      "        [-0.1622,  0.4557, -0.1511,  ..., -0.6918,  0.9524, -0.4529],\n",
      "        [-0.1806, -0.1273,  0.6283,  ..., -0.2476,  0.6384,  0.2804],\n",
      "        [-0.1806, -0.1273,  0.6283,  ..., -0.2476,  0.6384,  0.2804]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03770148 -0.11467026 -0.25527382  0.05599264 -0.2505998  -0.66240305\n",
      " -0.03896945 -0.4484088  -1.4328828  -0.18231621 -0.51225173 -1.7294238\n",
      " -0.3468125  -0.6219697  -2.206182   -0.16557634 -0.73076296 -1.5959649\n",
      "  0.04159287 -0.77243865 -1.4076555  -0.01231906 -0.7074596  -1.4606996\n",
      " -0.01886564 -0.8486288  -1.5783389  -0.12234612 -0.6268573  -1.5057852\n",
      " -0.04922839 -0.6813609  -1.4781988  -0.06200781 -0.656786   -1.5684388\n",
      "  0.06159757 -0.68106174 -1.6079006  -0.03461107 -0.5339897  -1.3392003\n",
      " -0.16068093 -0.30764696 -1.9992418  -0.00560461 -0.4664661  -2.0026662\n",
      "  0.14711955 -0.42948276 -1.4671466  -0.14267352 -0.29844242 -1.2693367\n",
      " -0.06619854 -0.2752566  -1.3536775  -0.02447271 -0.2888257  -1.4663079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.05242661 -0.30022913 -1.3098819 ]\n",
      "data: [ 0.03770148 -0.11467025 -0.25527382  0.05599264 -0.2505998  -0.66240305\n",
      " -0.03896945 -0.4484088  -1.4328828  -0.18231621 -0.51225173 -1.7294239\n",
      " -0.3468125  -0.6219697  -2.206182   -0.16557634 -0.73076296 -1.5959649\n",
      "  0.04159287 -0.77243865 -1.4076555  -0.01231906 -0.7074596  -1.4606996\n",
      " -0.01886564 -0.8486288  -1.578339   -0.12234612 -0.6268573  -1.5057852\n",
      " -0.04922839 -0.68136096 -1.4781986  -0.06200781 -0.656786   -1.5684388\n",
      "  0.06159757 -0.6810617  -1.6079007  -0.03461107 -0.5339897  -1.3392003\n",
      " -0.16068095 -0.30764696 -1.9992418  -0.00560461 -0.4664661  -2.0026662\n",
      "  0.14711955 -0.42948276 -1.4671466  -0.14267352 -0.29844242 -1.2693367\n",
      " -0.06619854 -0.2752566  -1.3536775  -0.02447271 -0.2888257  -1.4663079\n",
      "  0.05242661 -0.30022913 -1.3098819   0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0109, -0.0671, -0.2147,  ...,  0.0480, -0.2565, -1.2485],\n",
      "        [ 0.0109, -0.0671, -0.2147,  ...,  0.0480, -0.2565, -1.2485],\n",
      "        [ 0.0109, -0.0671, -0.2147,  ...,  0.0480, -0.2565, -1.2485],\n",
      "        ...,\n",
      "        [-0.0993,  0.4195, -0.0936,  ..., -0.6699,  0.9016, -0.3716],\n",
      "        [-0.1191, -0.1236,  0.5802,  ..., -0.2010,  0.5996,  0.2574],\n",
      "        [-0.1191, -0.1236,  0.5802,  ..., -0.2010,  0.5996,  0.2574]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01094527 -0.06711075 -0.21471687  0.03002127 -0.20095831 -0.59529805\n",
      " -0.05553612 -0.39241132 -1.3510572  -0.20209166 -0.45170966 -1.6582191\n",
      " -0.37224928 -0.57127583 -2.1332283  -0.19503224 -0.6777948  -1.5273043\n",
      "  0.03394089 -0.71532243 -1.3434771  -0.02504956 -0.65579724 -1.3949826\n",
      " -0.02932483 -0.79687464 -1.5149553  -0.14438558 -0.57450235 -1.4334779\n",
      " -0.06043341 -0.6340957  -1.4151486  -0.06853945 -0.6104978  -1.5130397\n",
      "  0.05368031 -0.64469916 -1.5541457  -0.04498836 -0.47884008 -1.2599386\n",
      " -0.17399153 -0.25379658 -1.9387673  -0.00960478 -0.42135677 -1.9392456\n",
      "  0.14651847 -0.38578033 -1.406557   -0.15813223 -0.24437132 -1.1950444\n",
      " -0.06751495 -0.22561944 -1.2783386  -0.02637761 -0.24673986 -1.3950686\n",
      "  0.04802829 -0.25649518 -1.2484764 ]\n",
      "data: [ 0.01094527 -0.06711075 -0.21471687  0.03002127 -0.20095831 -0.59529805\n",
      " -0.05553612 -0.39241132 -1.3510572  -0.20209165 -0.45170966 -1.6582191\n",
      " -0.37224925 -0.57127583 -2.1332283  -0.19503224 -0.6777948  -1.5273042\n",
      "  0.03394089 -0.71532243 -1.3434771  -0.02504956 -0.65579724 -1.3949826\n",
      " -0.02932483 -0.79687464 -1.5149553  -0.14438558 -0.57450235 -1.4334779\n",
      " -0.06043341 -0.6340957  -1.4151486  -0.06853945 -0.6104978  -1.5130397\n",
      "  0.05368031 -0.64469916 -1.5541457  -0.04498836 -0.47884005 -1.2599386\n",
      " -0.17399153 -0.25379658 -1.9387672  -0.00960478 -0.42135677 -1.9392456\n",
      "  0.14651847 -0.38578033 -1.406557   -0.15813223 -0.24437132 -1.1950444\n",
      " -0.06751495 -0.22561944 -1.2783386  -0.02637761 -0.24673986 -1.3950686\n",
      "  0.04802829 -0.25649518 -1.2484764   0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0219, -0.0613, -0.2551,  ...,  0.0301, -0.2501, -1.2754],\n",
      "        [ 0.0219, -0.0613, -0.2551,  ...,  0.0301, -0.2501, -1.2754],\n",
      "        [ 0.0219, -0.0613, -0.2551,  ...,  0.0301, -0.2501, -1.2754],\n",
      "        ...,\n",
      "        [-0.1741,  0.3566, -0.0968,  ..., -0.7633,  0.8426, -0.3386],\n",
      "        [-0.1269, -0.1197,  0.5934,  ..., -0.2008,  0.6599,  0.2435],\n",
      "        [-0.1269, -0.1197,  0.5934,  ..., -0.2008,  0.6599,  0.2435]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02189947 -0.06127658 -0.25513867  0.04810989 -0.17668131 -0.625779\n",
      " -0.08692297 -0.3863862  -1.4361107  -0.23517549 -0.45500842 -1.7196933\n",
      " -0.38838962 -0.54128456 -2.2206054  -0.16775462 -0.69146144 -1.5850542\n",
      " -0.0129801  -0.74607223 -1.4173913  -0.06226984 -0.67117053 -1.477549\n",
      " -0.0750802  -0.83403337 -1.5989207  -0.13213345 -0.6040245  -1.4963256\n",
      " -0.08098149 -0.6517009  -1.4602386  -0.10706785 -0.6211371  -1.5456948\n",
      "  0.03186644 -0.6409285  -1.5650704  -0.06304622 -0.5023364  -1.3368846\n",
      " -0.20019197 -0.27037507 -2.0552025  -0.03684884 -0.42646807 -2.0799062\n",
      "  0.12660179 -0.3978328  -1.4325973  -0.16377434 -0.27482504 -1.2602043\n",
      " -0.11273003 -0.24533165 -1.3493203  -0.0798477  -0.23564343 -1.4651169\n",
      "  0.03010219 -0.25010777 -1.2753757 ]\n",
      "data: [ 0.02189947 -0.06127658 -0.25513867  0.04810989 -0.17668131 -0.625779\n",
      " -0.08692297 -0.3863862  -1.4361107  -0.23517549 -0.45500842 -1.7196933\n",
      " -0.38838962 -0.54128456 -2.2206054  -0.1677546  -0.6914614  -1.5850542\n",
      " -0.0129801  -0.74607223 -1.4173913  -0.06226984 -0.6711705  -1.477549\n",
      " -0.0750802  -0.83403337 -1.5989207  -0.13213345 -0.6040245  -1.4963257\n",
      " -0.08098149 -0.6517009  -1.4602387  -0.10706785 -0.6211371  -1.5456948\n",
      "  0.03186644 -0.6409285  -1.5650704  -0.06304622 -0.5023364  -1.3368846\n",
      " -0.20019197 -0.27037507 -2.0552025  -0.03684884 -0.42646807 -2.0799062\n",
      "  0.12660179 -0.39783278 -1.4325974  -0.16377434 -0.27482504 -1.2602043\n",
      " -0.11273003 -0.24533165 -1.3493202  -0.0798477  -0.23564343 -1.4651169\n",
      "  0.03010219 -0.25010777 -1.2753757   0.14      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0541, -0.0156, -0.1979,  ...,  0.0587, -0.2091, -1.2346],\n",
      "        [ 0.0541, -0.0156, -0.1979,  ...,  0.0587, -0.2091, -1.2346],\n",
      "        [ 0.0541, -0.0156, -0.1979,  ...,  0.0587, -0.2091, -1.2346],\n",
      "        ...,\n",
      "        [-0.1979,  0.3173, -0.1350,  ..., -0.8528,  0.7587, -0.2764],\n",
      "        [-0.1473, -0.1841,  0.5238,  ..., -0.2009,  0.5647,  0.2281],\n",
      "        [-0.1473, -0.1841,  0.5238,  ..., -0.2009,  0.5647,  0.2281]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.05414837 -0.0156472  -0.19794461  0.06597181 -0.14223257 -0.5836156\n",
      " -0.05403746 -0.33166057 -1.3425493  -0.20547554 -0.3970251  -1.6308155\n",
      " -0.37600154 -0.48799473 -2.1215994  -0.13949934 -0.64204335 -1.4963517\n",
      "  0.01264706 -0.68625396 -1.3449829  -0.03533098 -0.6098498  -1.4087155\n",
      " -0.03397281 -0.76576257 -1.5213888  -0.10296327 -0.5490954  -1.4167125\n",
      " -0.04573782 -0.5938644  -1.3820686  -0.07329406 -0.5700821  -1.4781051\n",
      "  0.06657155 -0.5773135  -1.5017815  -0.03234861 -0.45721096 -1.2594092\n",
      " -0.14921495 -0.23419584 -1.9233305  -0.00457536 -0.37743014 -1.9413972\n",
      "  0.15547292 -0.35479873 -1.3735497  -0.12354496 -0.22809722 -1.1948178\n",
      " -0.07627292 -0.20582254 -1.2878091  -0.0450754  -0.19557253 -1.4054213\n",
      "  0.05873181 -0.20908839 -1.2345946 ]\n",
      "data: [ 0.05414837 -0.0156472  -0.1979446   0.06597181 -0.14223257 -0.5836156\n",
      " -0.05403746 -0.33166057 -1.3425493  -0.20547554 -0.3970251  -1.6308154\n",
      " -0.37600154 -0.48799473 -2.1215994  -0.13949934 -0.64204335 -1.4963517\n",
      "  0.01264706 -0.68625396 -1.3449829  -0.03533098 -0.6098498  -1.4087155\n",
      " -0.03397281 -0.76576257 -1.5213886  -0.10296327 -0.5490954  -1.4167125\n",
      " -0.04573782 -0.5938644  -1.3820686  -0.07329406 -0.5700821  -1.4781051\n",
      "  0.06657155 -0.5773135  -1.5017815  -0.03234861 -0.45721096 -1.2594092\n",
      " -0.14921495 -0.23419584 -1.9233305  -0.00457536 -0.37743014 -1.9413972\n",
      "  0.15547292 -0.35479873 -1.3735497  -0.12354496 -0.22809722 -1.1948178\n",
      " -0.07627292 -0.20582254 -1.2878091  -0.0450754  -0.19557253 -1.4054213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.05873181 -0.20908839 -1.2345946   0.15      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0051, -0.0628, -0.2564,  ...,  0.0293, -0.2445, -1.3060],\n",
      "        [ 0.0051, -0.0628, -0.2564,  ...,  0.0293, -0.2445, -1.3060],\n",
      "        [ 0.0051, -0.0628, -0.2564,  ...,  0.0293, -0.2445, -1.3060],\n",
      "        ...,\n",
      "        [-0.3331,  0.2143, -0.2507,  ..., -0.8559,  0.6247, -0.3997],\n",
      "        [-0.1089, -0.0304,  0.5879,  ..., -0.2219,  0.7714,  0.2500],\n",
      "        [-0.1089, -0.0304,  0.5879,  ..., -0.2219,  0.7714,  0.2500]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00506023 -0.06279383 -0.25643146  0.03036199 -0.20296209 -0.6765792\n",
      " -0.06677677 -0.3843965  -1.434891   -0.2085872  -0.44881654 -1.7238985\n",
      " -0.36979467 -0.5570652  -2.20582    -0.19443206 -0.6653071  -1.5888298\n",
      "  0.01146008 -0.693631   -1.3899674  -0.03586487 -0.62824416 -1.4462488\n",
      " -0.04364198 -0.7585251  -1.5625026  -0.1557847  -0.5632431  -1.5084697\n",
      " -0.07469182 -0.6162395  -1.4760566  -0.09246356 -0.5878334  -1.5654655\n",
      "  0.04050659 -0.6079629  -1.6094296  -0.07197946 -0.48120117 -1.3372557\n",
      " -0.17834324 -0.25132817 -1.9572805  -0.03179287 -0.40173358 -1.957892\n",
      "  0.12107401 -0.3726499  -1.4642377  -0.16803953 -0.24602222 -1.2717524\n",
      " -0.09525959 -0.22143963 -1.3442198  -0.04818922 -0.2300116  -1.4610542\n",
      "  0.02934863 -0.24445143 -1.3059582 ]\n",
      "data: [ 0.00506023 -0.06279383 -0.25643146  0.03036199 -0.2029621  -0.67657924\n",
      " -0.06677677 -0.38439646 -1.4348911  -0.20858721 -0.44881654 -1.7238984\n",
      " -0.36979467 -0.5570652  -2.20582    -0.19443206 -0.6653071  -1.5888298\n",
      "  0.01146008 -0.693631   -1.3899674  -0.03586487 -0.62824416 -1.4462488\n",
      " -0.04364199 -0.7585251  -1.5625026  -0.1557847  -0.5632431  -1.5084697\n",
      " -0.07469182 -0.6162395  -1.4760566  -0.09246356 -0.5878334  -1.5654655\n",
      "  0.04050659 -0.6079629  -1.6094296  -0.07197946 -0.48120117 -1.3372557\n",
      " -0.17834324 -0.25132817 -1.9572806  -0.03179287 -0.40173358 -1.957892\n",
      "  0.12107401 -0.3726499  -1.4642377  -0.16803953 -0.24602222 -1.2717524\n",
      " -0.09525959 -0.22143963 -1.3442198  -0.04818922 -0.2300116  -1.4610542\n",
      "  0.02934863 -0.24445143 -1.3059582   0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0315, -0.0891, -0.2349,  ...,  0.0580, -0.2756, -1.2904],\n",
      "        [ 0.0315, -0.0891, -0.2349,  ...,  0.0580, -0.2756, -1.2904],\n",
      "        [ 0.0315, -0.0891, -0.2349,  ...,  0.0580, -0.2756, -1.2904],\n",
      "        ...,\n",
      "        [-0.1353,  0.4222, -0.1802,  ..., -0.7418,  0.9308, -0.4209],\n",
      "        [-0.1475, -0.1769,  0.5658,  ..., -0.2457,  0.5927,  0.2386],\n",
      "        [-0.1475, -0.1769,  0.5658,  ..., -0.2457,  0.5927,  0.2386]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 3.15036885e-02 -8.91007632e-02 -2.34919161e-01  5.04687689e-02\n",
      " -2.30374500e-01 -6.52444243e-01 -3.08897123e-02 -4.05574590e-01\n",
      " -1.38290715e+00 -1.70401275e-01 -4.65368897e-01 -1.67898798e+00\n",
      " -3.37734282e-01 -5.78025937e-01 -2.15062761e+00 -1.65820375e-01\n",
      " -6.93669021e-01 -1.54372311e+00  4.50214893e-02 -7.19042480e-01\n",
      " -1.36946177e+00 -3.59338522e-03 -6.55713975e-01 -1.42620635e+00\n",
      "  1.59744918e-03 -7.85730302e-01 -1.53989458e+00 -1.24665976e-01\n",
      " -5.89241803e-01 -1.46331477e+00 -3.96056324e-02 -6.40202999e-01\n",
      " -1.43947363e+00 -5.09361103e-02 -6.15989625e-01 -1.53521204e+00\n",
      "  7.83861578e-02 -6.35441542e-01 -1.58207059e+00 -3.78105566e-02\n",
      " -5.05653679e-01 -1.29416800e+00 -1.42822251e-01 -2.81946033e-01\n",
      " -1.91553164e+00  4.22521681e-03 -4.30501103e-01 -1.91416907e+00\n",
      "  1.56109050e-01 -4.00125086e-01 -1.44128919e+00 -1.36615977e-01\n",
      " -2.71065772e-01 -1.23370981e+00 -5.92547804e-02 -2.50657260e-01\n",
      " -1.31510997e+00 -1.49987340e-02 -2.62629539e-01 -1.43277049e+00\n",
      "  5.79532608e-02 -2.75553048e-01 -1.29038405e+00]\n",
      "data: [ 3.15036885e-02 -8.91007632e-02 -2.34919161e-01  5.04687689e-02\n",
      " -2.30374515e-01 -6.52444243e-01 -3.08897123e-02 -4.05574620e-01\n",
      " -1.38290715e+00 -1.70401275e-01 -4.65368867e-01 -1.67898798e+00\n",
      " -3.37734312e-01 -5.78025937e-01 -2.15062761e+00 -1.65820375e-01\n",
      " -6.93669081e-01 -1.54372311e+00  4.50214893e-02 -7.19042540e-01\n",
      " -1.36946177e+00 -3.59338522e-03 -6.55713975e-01 -1.42620635e+00\n",
      "  1.59744918e-03 -7.85730302e-01 -1.53989458e+00 -1.24665976e-01\n",
      " -5.89241803e-01 -1.46331477e+00 -3.96056324e-02 -6.40202999e-01\n",
      " -1.43947363e+00 -5.09361140e-02 -6.15989625e-01 -1.53521204e+00\n",
      "  7.83861578e-02 -6.35441542e-01 -1.58207059e+00 -3.78105566e-02\n",
      " -5.05653679e-01 -1.29416800e+00 -1.42822251e-01 -2.81946033e-01\n",
      " -1.91553164e+00  4.22521681e-03 -4.30501103e-01 -1.91416895e+00\n",
      "  1.56109050e-01 -4.00125086e-01 -1.44128919e+00 -1.36615977e-01\n",
      " -2.71065772e-01 -1.23370981e+00 -5.92547804e-02 -2.50657260e-01\n",
      " -1.31510997e+00 -1.49987340e-02 -2.62629539e-01 -1.43277049e+00\n",
      "  5.79532608e-02 -2.75553048e-01 -1.29038405e+00  1.70000002e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0250, -0.0921, -0.2500,  ...,  0.0558, -0.2825, -1.2873],\n",
      "        [ 0.0250, -0.0921, -0.2500,  ...,  0.0558, -0.2825, -1.2873],\n",
      "        [ 0.0250, -0.0921, -0.2500,  ...,  0.0558, -0.2825, -1.2873],\n",
      "        ...,\n",
      "        [-0.1391,  0.4210, -0.0845,  ..., -0.6712,  0.9152, -0.3791],\n",
      "        [-0.1665, -0.1134,  0.5936,  ..., -0.2489,  0.6619,  0.2269],\n",
      "        [-0.1665, -0.1134,  0.5936,  ..., -0.2489,  0.6619,  0.2269]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02501298 -0.09209833 -0.25003892  0.04870381 -0.22328718 -0.6417163\n",
      " -0.04922245 -0.42081553 -1.4203281  -0.19411662 -0.48564935 -1.7195902\n",
      " -0.3569495  -0.5969962  -2.2022378  -0.17429467 -0.7068172  -1.5835297\n",
      "  0.03784777 -0.74885774 -1.391578   -0.01841803 -0.6852052  -1.44573\n",
      " -0.03025007 -0.82902277 -1.5666964  -0.12870672 -0.607333   -1.4904487\n",
      " -0.05370744 -0.6639211  -1.4655144  -0.0689263  -0.6378251  -1.5570493\n",
      "  0.05537648 -0.6668131  -1.5945079  -0.03889536 -0.51321423 -1.3184898\n",
      " -0.16640362 -0.28462926 -1.995441   -0.0068582  -0.4473461  -2.0002716\n",
      "  0.14814566 -0.41349334 -1.4479816  -0.14731826 -0.2794538  -1.2488525\n",
      " -0.06672136 -0.25693864 -1.3319952  -0.0248016  -0.27077255 -1.4461203\n",
      "  0.05581414 -0.28249013 -1.2873073 ]\n",
      "data: [ 0.02501298 -0.09209833 -0.25003892  0.04870381 -0.22328718 -0.6417163\n",
      " -0.04922245 -0.42081556 -1.420328   -0.19411664 -0.48564935 -1.7195902\n",
      " -0.3569495  -0.5969962  -2.2022378  -0.17429467 -0.70681727 -1.5835297\n",
      "  0.03784777 -0.74885774 -1.391578   -0.01841803 -0.6852052  -1.44573\n",
      " -0.03025007 -0.82902277 -1.5666965  -0.12870672 -0.607333   -1.4904487\n",
      " -0.05370744 -0.6639211  -1.4655144  -0.0689263  -0.6378251  -1.5570493\n",
      "  0.05537648 -0.6668131  -1.5945079  -0.03889536 -0.51321423 -1.3184898\n",
      " -0.16640362 -0.28462926 -1.995441   -0.0068582  -0.4473461  -2.0002716\n",
      "  0.14814566 -0.41349334 -1.4479816  -0.14731826 -0.2794538  -1.2488525\n",
      " -0.06672136 -0.25693864 -1.3319952  -0.0248016  -0.27077255 -1.4461203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.05581414 -0.28249013 -1.2873073   0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0195, -0.0585, -0.2393,  ...,  0.0580, -0.2501, -1.2801],\n",
      "        [ 0.0195, -0.0585, -0.2393,  ...,  0.0580, -0.2501, -1.2801],\n",
      "        [ 0.0195, -0.0585, -0.2393,  ...,  0.0580, -0.2501, -1.2801],\n",
      "        ...,\n",
      "        [-0.1485,  0.3698, -0.1241,  ..., -0.7755,  0.8537, -0.3701],\n",
      "        [-0.1325, -0.1380,  0.5730,  ..., -0.2058,  0.6095,  0.2272],\n",
      "        [-0.1325, -0.1380,  0.5730,  ..., -0.2058,  0.6095,  0.2272]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.9516844e-02 -5.8486514e-02 -2.3927672e-01  3.3905033e-02\n",
      " -2.0017624e-01 -6.4282250e-01 -4.5195453e-02 -3.8349405e-01\n",
      " -1.3795881e+00 -1.8880574e-01 -4.4336367e-01 -1.6860222e+00\n",
      " -3.6627966e-01 -5.6641513e-01 -2.1499109e+00 -1.8866643e-01\n",
      " -6.6556859e-01 -1.5453104e+00  4.4708684e-02 -6.9562680e-01\n",
      " -1.3481992e+00 -9.5226169e-03 -6.3701862e-01 -1.4008446e+00\n",
      " -9.7849891e-03 -7.7081573e-01 -1.5184028e+00 -1.3935362e-01\n",
      " -5.5785650e-01 -1.4559004e+00 -5.0360695e-02 -6.1716634e-01\n",
      " -1.4346591e+00 -5.6169838e-02 -5.9579569e-01 -1.5342216e+00\n",
      "  7.1539074e-02 -6.2350917e-01 -1.5840739e+00 -4.0981986e-02\n",
      " -4.7119424e-01 -1.2812092e+00 -1.5805732e-01 -2.4849015e-01\n",
      " -1.9308603e+00  2.9630214e-04 -4.0898687e-01 -1.9257247e+00\n",
      "  1.5709168e-01 -3.7538016e-01 -1.4335668e+00 -1.4779301e-01\n",
      " -2.3412874e-01 -1.2198458e+00 -5.8999851e-02 -2.1734345e-01\n",
      " -1.3015382e+00 -1.2225181e-02 -2.3885897e-01 -1.4190445e+00\n",
      "  5.8038451e-02 -2.5010854e-01 -1.2800605e+00]\n",
      "data: [ 1.9516844e-02 -5.8486514e-02 -2.3927671e-01  3.3905033e-02\n",
      " -2.0017624e-01 -6.4282250e-01 -4.5195449e-02 -3.8349402e-01\n",
      " -1.3795881e+00 -1.8880576e-01 -4.4336364e-01 -1.6860222e+00\n",
      " -3.6627969e-01 -5.6641513e-01 -2.1499109e+00 -1.8866643e-01\n",
      " -6.6556859e-01 -1.5453104e+00  4.4708684e-02 -6.9562685e-01\n",
      " -1.3481994e+00 -9.5226169e-03 -6.3701862e-01 -1.4008446e+00\n",
      " -9.7849891e-03 -7.7081573e-01 -1.5184028e+00 -1.3935362e-01\n",
      " -5.5785650e-01 -1.4559004e+00 -5.0360695e-02 -6.1716634e-01\n",
      " -1.4346591e+00 -5.6169838e-02 -5.9579569e-01 -1.5342216e+00\n",
      "  7.1539074e-02 -6.2350917e-01 -1.5840739e+00 -4.0981986e-02\n",
      " -4.7119424e-01 -1.2812092e+00 -1.5805732e-01 -2.4849015e-01\n",
      " -1.9308603e+00  2.9630214e-04 -4.0898687e-01 -1.9257247e+00\n",
      "  1.5709168e-01 -3.7538016e-01 -1.4335667e+00 -1.4779301e-01\n",
      " -2.3412874e-01 -1.2198458e+00 -5.8999851e-02 -2.1734345e-01\n",
      " -1.3015382e+00 -1.2225181e-02 -2.3885897e-01 -1.4190445e+00\n",
      "  5.8038451e-02 -2.5010854e-01 -1.2800605e+00  1.9000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0131, -0.0799, -0.2481,  ...,  0.0375, -0.2685, -1.2967],\n",
      "        [ 0.0131, -0.0799, -0.2481,  ...,  0.0375, -0.2685, -1.2967],\n",
      "        [ 0.0131, -0.0799, -0.2481,  ...,  0.0375, -0.2685, -1.2967],\n",
      "        ...,\n",
      "        [-0.1520,  0.4206, -0.1380,  ..., -0.6893,  0.9022, -0.3945],\n",
      "        [-0.1639, -0.1292,  0.5822,  ..., -0.2476,  0.6531,  0.2266],\n",
      "        [-0.1639, -0.1292,  0.5822,  ..., -0.2476,  0.6531,  0.2266]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01314016 -0.07985759 -0.24814682  0.03345513 -0.2140282  -0.65522623\n",
      " -0.0653763  -0.40406632 -1.4204868  -0.20840988 -0.46879762 -1.714893\n",
      " -0.3723631  -0.5762938  -2.1953611  -0.18530674 -0.6921148  -1.5780379\n",
      "  0.01644127 -0.7291476  -1.3874134  -0.03415717 -0.66314167 -1.4443085\n",
      " -0.04056495 -0.8036899  -1.5627538  -0.1438126  -0.59176844 -1.4917016\n",
      " -0.06938388 -0.644762   -1.4639827  -0.08552683 -0.61941946 -1.5560473\n",
      "  0.04574573 -0.6406318  -1.5960176  -0.05976192 -0.50360817 -1.322846\n",
      " -0.1767734  -0.27609634 -1.9753815  -0.02451174 -0.42996532 -1.9804072\n",
      "  0.13193737 -0.39967406 -1.4525784  -0.16083424 -0.26936254 -1.2549489\n",
      " -0.08837306 -0.2464716  -1.3383911  -0.04534717 -0.25492892 -1.4538357\n",
      "  0.03754508 -0.2684813  -1.2966789 ]\n",
      "data: [ 0.01314016 -0.07985759 -0.24814682  0.03345513 -0.21402818 -0.65522623\n",
      " -0.0653763  -0.40406632 -1.4204868  -0.20840988 -0.4687976  -1.714893\n",
      " -0.3723631  -0.5762938  -2.1953611  -0.18530674 -0.6921148  -1.5780379\n",
      "  0.01644127 -0.7291477  -1.3874134  -0.03415717 -0.6631416  -1.4443085\n",
      " -0.04056496 -0.8036899  -1.5627538  -0.1438126  -0.59176844 -1.4917016\n",
      " -0.06938388 -0.644762   -1.4639827  -0.08552683 -0.61941946 -1.5560473\n",
      "  0.04574573 -0.6406318  -1.5960176  -0.05976192 -0.50360817 -1.322846\n",
      " -0.1767734  -0.27609634 -1.9753815  -0.02451174 -0.42996532 -1.9804072\n",
      "  0.13193737 -0.39967406 -1.4525784  -0.16083424 -0.26936254 -1.2549489\n",
      " -0.08837307 -0.2464716  -1.3383911  -0.04534717 -0.25492892 -1.4538357\n",
      "  0.03754508 -0.2684813  -1.2966789   0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[ 0.0089, -0.0459, -0.2337,  ...,  0.0430, -0.2400, -1.2618],\n",
      "        [ 0.0089, -0.0459, -0.2337,  ...,  0.0430, -0.2400, -1.2618],\n",
      "        [ 0.0089, -0.0459, -0.2337,  ...,  0.0430, -0.2400, -1.2618],\n",
      "        ...,\n",
      "        [-0.1759,  0.3557, -0.1630,  ..., -0.8251,  0.8373, -0.3927],\n",
      "        [-0.1455, -0.1836,  0.5519,  ..., -0.2346,  0.5735,  0.2112],\n",
      "        [-0.1455, -0.1836,  0.5519,  ..., -0.2346,  0.5735,  0.2112]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00894869 -0.04587682 -0.23366809  0.02389829 -0.1795135  -0.628245\n",
      " -0.06951524 -0.36608714 -1.3741342  -0.21259858 -0.42663604 -1.6730828\n",
      " -0.38361698 -0.53891945 -2.1442144  -0.19271153 -0.657529   -1.5326704\n",
      "  0.0147745  -0.6918895  -1.3511978  -0.03547101 -0.62752867 -1.4072188\n",
      " -0.0334864  -0.7696123  -1.5244404  -0.14781374 -0.556036   -1.4455374\n",
      " -0.06847709 -0.610306   -1.4211198  -0.07812587 -0.5872984  -1.5169729\n",
      "  0.05621339 -0.6103599  -1.5589436  -0.05806904 -0.46756223 -1.2769513\n",
      " -0.17659523 -0.24375057 -1.9389793  -0.0173815  -0.40067926 -1.9420608\n",
      "  0.14303592 -0.36953565 -1.4149678  -0.16043955 -0.23496449 -1.212461\n",
      " -0.08351837 -0.21552175 -1.296584   -0.04062982 -0.22677237 -1.414382\n",
      "  0.04299822 -0.23996426 -1.2617805 ]\n",
      "data: [-1.98 -5.33  4.01 -1.92 -5.09  3.99 -1.91 -4.75  4.19 -1.91 -4.5   4.52\n",
      "  0.    0.    0.   -1.82 -4.76  4.71  0.    0.    0.   -1.14 -3.32  0.18\n",
      " -1.17 -3.31  0.13 -1.87 -4.76  4.71  0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.   -1.88 -4.78  4.48  0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.   -1.92 -4.59  3.95 -1.94 -4.39  3.8  -1.94 -4.26  3.51\n",
      " -1.9  -4.11  2.98  0.  ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[-0.2921,  0.4660, -0.2072,  ..., -0.4810,  0.2325, -0.9156],\n",
      "        [-0.2921,  0.4660, -0.2072,  ..., -0.4810,  0.2325, -0.9156],\n",
      "        [-0.2921,  0.4660, -0.2072,  ..., -0.4810,  0.2325, -0.9156],\n",
      "        ...,\n",
      "        [ 1.2016, -1.2246,  0.4724,  ...,  1.1677, -0.7821,  0.5216],\n",
      "        [ 0.4105, -0.2338,  0.4834,  ...,  0.7591, -0.4759,  2.4948],\n",
      "        [ 0.4105, -0.2338,  0.4834,  ...,  0.7591, -0.4759,  2.4948]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.29212904  0.4660052  -0.20720646 -0.34433857  0.31746322 -0.8800446\n",
      " -0.450908    0.24428444 -1.0834868  -0.5217372   0.12205142 -1.1040297\n",
      " -0.55413187  0.06747058 -1.2451975  -0.4610701   0.13767898 -1.2891954\n",
      " -0.40434408  0.07122374 -0.9008828  -0.44462508 -0.0453676  -0.9377189\n",
      " -0.5133273  -0.08602378 -1.024397   -0.47992706  0.20923743 -1.3237064\n",
      " -0.5478147   0.08339605 -1.3065295  -0.58825517  0.00282258 -1.2993191\n",
      " -0.5024523  -0.10591957 -1.2587899  -0.5399085   0.23493621 -1.1937548\n",
      " -0.5697341   0.24918166 -1.1408807  -0.5796976   0.1630086  -1.1601272\n",
      " -0.4728566   0.0334883  -1.0637553  -0.5326833   0.3907708  -1.0456784\n",
      " -0.574821    0.35346192 -1.0150907  -0.57710534  0.34814742 -1.0521877\n",
      " -0.48097777  0.23253523 -0.91555166]\n",
      "init: [-0.29212904  0.4660052  -0.20720646 -0.34433857  0.31746322 -0.8800446\n",
      " -0.450908    0.24428444 -1.0834868  -0.5217372   0.12205142 -1.1040297\n",
      " -0.55413187  0.06747058 -1.2451975  -0.4610701   0.13767898 -1.2891954\n",
      " -0.40434408  0.07122374 -0.9008828  -0.44462508 -0.0453676  -0.9377189\n",
      " -0.5133273  -0.08602378 -1.024397   -0.47992706  0.20923743 -1.3237064\n",
      " -0.5478147   0.08339605 -1.3065295  -0.58825517  0.00282258 -1.2993191\n",
      " -0.5024523  -0.10591957 -1.2587899  -0.5399085   0.23493621 -1.1937548\n",
      " -0.5697341   0.24918166 -1.1408807  -0.5796976   0.1630086  -1.1601272\n",
      " -0.4728566   0.0334883  -1.0637553  -0.5326833   0.3907708  -1.0456784\n",
      " -0.574821    0.35346192 -1.0150907  -0.57710534  0.34814742 -1.0521877\n",
      " -0.48097777  0.23253523 -0.91555166]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [-0.29212904  0.4660052  -0.20720646 -0.34433857  0.31746322 -0.8800446\n",
      " -0.450908    0.24428444 -1.0834868  -0.5217372   0.12205142 -1.1040297\n",
      " -0.55413187  0.06747058 -1.2451975  -0.4610701   0.13767898 -1.2891954\n",
      " -0.4043441   0.07122374 -0.9008828  -0.44462508 -0.0453676  -0.937719\n",
      " -0.5133273  -0.08602378 -1.024397   -0.47992706  0.20923743 -1.3237064\n",
      " -0.5478147   0.08339605 -1.3065295  -0.58825517  0.00282258 -1.2993191\n",
      " -0.5024523  -0.10591957 -1.2587899  -0.5399085   0.2349362  -1.1937548\n",
      " -0.5697341   0.24918166 -1.1408807  -0.5796976   0.1630086  -1.1601272\n",
      " -0.4728566   0.0334883  -1.0637553  -0.5326833   0.3907708  -1.0456784\n",
      " -0.574821    0.35346192 -1.0150907  -0.57710534  0.34814742 -1.0521877\n",
      " -0.48097777  0.23253523 -0.91555166  0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 9.7386e-04, -4.3663e-01, -9.8857e-02,  ...,  3.7400e-02,\n",
      "         -5.7827e-01, -1.1869e+00],\n",
      "        [ 9.7386e-04, -4.3663e-01, -9.8857e-02,  ...,  3.7400e-02,\n",
      "         -5.7827e-01, -1.1869e+00],\n",
      "        [ 9.7386e-04, -4.3663e-01, -9.8857e-02,  ...,  3.7400e-02,\n",
      "         -5.7827e-01, -1.1869e+00],\n",
      "        ...,\n",
      "        [ 2.3057e-01,  5.2673e-01,  4.0879e-01,  ..., -7.0917e-01,\n",
      "          1.0132e+00,  5.8632e-01],\n",
      "        [-3.4645e-01,  3.2095e-01,  3.4304e-01,  ..., -7.8287e-01,\n",
      "          1.1496e+00, -5.9010e-02],\n",
      "        [-3.4645e-01,  3.2095e-01,  3.4304e-01,  ..., -7.8287e-01,\n",
      "          1.1496e+00, -5.9010e-02]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 9.7386166e-04 -4.3663490e-01 -9.8857164e-02  3.8108062e-02\n",
      " -5.8396596e-01 -5.9078133e-01 -7.4708089e-03 -7.0337605e-01\n",
      " -1.2332680e+00 -1.2828223e-01 -7.3020577e-01 -1.5009624e+00\n",
      " -2.4353826e-01 -8.4159100e-01 -1.9958079e+00 -1.9583112e-01\n",
      " -9.7863472e-01 -1.3751414e+00  1.5181422e-02 -9.4975233e-01\n",
      " -1.3032800e+00 -2.2420719e-02 -8.6301321e-01 -1.3572654e+00\n",
      " -3.2822564e-03 -9.4953549e-01 -1.4521624e+00 -1.6866411e-01\n",
      " -8.8332772e-01 -1.3266691e+00 -4.6269998e-02 -9.0146303e-01\n",
      " -1.3210789e+00 -5.2043989e-02 -8.3805108e-01 -1.3825552e+00\n",
      "  5.0434574e-02 -8.6060560e-01 -1.4334346e+00 -5.7996549e-02\n",
      " -8.1391054e-01 -1.1838710e+00 -1.1118737e-01 -5.6507266e-01\n",
      " -1.6174147e+00  1.1509806e-02 -6.9962835e-01 -1.5947932e+00\n",
      "  1.1454117e-01 -6.4263499e-01 -1.3540426e+00 -1.4750098e-01\n",
      " -6.0347235e-01 -1.1309699e+00 -4.6279967e-02 -5.5976748e-01\n",
      " -1.1895829e+00 -1.0944009e-03 -5.7517356e-01 -1.3129352e+00\n",
      "  3.7399925e-02 -5.7826841e-01 -1.1868750e+00]\n",
      "data: [ 9.73861665e-04 -4.36634898e-01 -9.88571644e-02  3.81080620e-02\n",
      " -5.83965957e-01 -5.90781331e-01 -7.47080939e-03 -7.03376055e-01\n",
      " -1.23326802e+00 -1.28282234e-01 -7.30205774e-01 -1.50096238e+00\n",
      " -2.43538260e-01 -8.41591060e-01 -1.99580801e+00 -1.95831120e-01\n",
      " -9.78634715e-01 -1.37514150e+00  1.51814222e-02 -9.49752331e-01\n",
      " -1.30328000e+00 -2.24207193e-02 -8.63013208e-01 -1.35726535e+00\n",
      " -3.28225642e-03 -9.49535549e-01 -1.45216227e+00 -1.68664113e-01\n",
      " -8.83327723e-01 -1.32666922e+00 -4.62699980e-02 -9.01463032e-01\n",
      " -1.32107890e+00 -5.20439893e-02 -8.38051081e-01 -1.38255525e+00\n",
      "  5.04345745e-02 -8.60605597e-01 -1.43343461e+00 -5.79965487e-02\n",
      " -8.13910544e-01 -1.18387103e+00 -1.11187369e-01 -5.65072656e-01\n",
      " -1.61741471e+00  1.15098059e-02 -6.99628353e-01 -1.59479320e+00\n",
      "  1.14541166e-01 -6.42634988e-01 -1.35404265e+00 -1.47500977e-01\n",
      " -6.03472352e-01 -1.13096988e+00 -4.62799631e-02 -5.59767485e-01\n",
      " -1.18958294e+00 -1.09440088e-03 -5.75173557e-01 -1.31293523e+00\n",
      "  3.73999253e-02 -5.78268409e-01 -1.18687499e+00  1.99999996e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0798, -0.1347, -0.2220,  ...,  0.0738, -0.3043, -1.2731],\n",
      "        [ 0.0798, -0.1347, -0.2220,  ...,  0.0738, -0.3043, -1.2731],\n",
      "        [ 0.0798, -0.1347, -0.2220,  ...,  0.0738, -0.3043, -1.2731],\n",
      "        ...,\n",
      "        [-0.2038,  0.3982, -0.0156,  ..., -0.2842,  1.0761, -0.5210],\n",
      "        [-0.0692,  0.0229,  0.6713,  ..., -0.1437,  0.5289,  0.4072],\n",
      "        [-0.0692,  0.0229,  0.6713,  ..., -0.1437,  0.5289,  0.4072]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 7.97883123e-02 -1.34696573e-01 -2.21953928e-01  9.79941934e-02\n",
      " -2.59995937e-01 -5.47201514e-01  5.29204309e-03 -4.73662138e-01\n",
      " -1.36778367e+00 -1.56299055e-01 -5.30244350e-01 -1.68605435e+00\n",
      " -3.39307815e-01 -6.49516821e-01 -2.18148732e+00 -1.48885190e-01\n",
      " -7.49159515e-01 -1.59504795e+00  1.03754468e-01 -8.00334275e-01\n",
      " -1.37623405e+00  4.11270633e-02 -7.34943092e-01 -1.41300297e+00\n",
      "  3.94840613e-02 -8.82829785e-01 -1.53915703e+00 -9.76937339e-02\n",
      " -6.37500167e-01 -1.48528993e+00 -1.46499574e-02 -7.02233195e-01\n",
      " -1.45311165e+00 -1.16579235e-02 -6.77594066e-01 -1.55410504e+00\n",
      "  1.18197806e-01 -7.18094170e-01 -1.59321415e+00  1.06383860e-02\n",
      " -5.33272147e-01 -1.31111073e+00 -1.53796285e-01 -2.96257466e-01\n",
      " -2.03796530e+00  2.73439288e-02 -4.84002858e-01 -2.03913426e+00\n",
      "  2.05184370e-01 -4.35352683e-01 -1.43861151e+00 -1.34802163e-01\n",
      " -2.85364449e-01 -1.23480093e+00 -3.68031189e-02 -2.64340281e-01\n",
      " -1.31376386e+00 -8.88235867e-04 -2.97670245e-01 -1.42728066e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7.37888366e-02 -3.04346561e-01 -1.27309752e+00]\n",
      "data: [ 7.97883123e-02 -1.34696573e-01 -2.21953928e-01  9.79941934e-02\n",
      " -2.59995937e-01 -5.47201514e-01  5.29204309e-03 -4.73662138e-01\n",
      " -1.36778367e+00 -1.56299055e-01 -5.30244350e-01 -1.68605435e+00\n",
      " -3.39307815e-01 -6.49516821e-01 -2.18148732e+00 -1.48885190e-01\n",
      " -7.49159575e-01 -1.59504795e+00  1.03754476e-01 -8.00334215e-01\n",
      " -1.37623417e+00  4.11270633e-02 -7.34943092e-01 -1.41300297e+00\n",
      "  3.94840613e-02 -8.82829845e-01 -1.53915715e+00 -9.76937264e-02\n",
      " -6.37500167e-01 -1.48528993e+00 -1.46499574e-02 -7.02233195e-01\n",
      " -1.45311153e+00 -1.16579235e-02 -6.77594066e-01 -1.55410504e+00\n",
      "  1.18197806e-01 -7.18094170e-01 -1.59321415e+00  1.06383860e-02\n",
      " -5.33272147e-01 -1.31111073e+00 -1.53796285e-01 -2.96257466e-01\n",
      " -2.03796530e+00  2.73439288e-02 -4.84002888e-01 -2.03913426e+00\n",
      "  2.05184370e-01 -4.35352683e-01 -1.43861151e+00 -1.34802163e-01\n",
      " -2.85364449e-01 -1.23480093e+00 -3.68031189e-02 -2.64340281e-01\n",
      " -1.31376386e+00 -8.88235867e-04 -2.97670245e-01 -1.42728078e+00\n",
      "  7.37888366e-02 -3.04346561e-01 -1.27309752e+00  2.99999993e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0307, -0.1647, -0.1928,  ...,  0.1127, -0.3575, -1.2395],\n",
      "        [ 0.0307, -0.1647, -0.1928,  ...,  0.1127, -0.3575, -1.2395],\n",
      "        [ 0.0307, -0.1647, -0.1928,  ...,  0.1127, -0.3575, -1.2395],\n",
      "        ...,\n",
      "        [-0.0619,  0.4299, -0.0393,  ..., -0.5613,  0.9605, -0.3868],\n",
      "        [-0.1000,  0.0146,  0.6205,  ..., -0.1953,  0.7021,  0.2778],\n",
      "        [-0.1000,  0.0146,  0.6205,  ..., -0.1953,  0.7021,  0.2778]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 3.0723665e-02 -1.6468406e-01 -1.9280654e-01  5.7588857e-02\n",
      " -3.1220186e-01 -5.6166077e-01 -2.0124763e-03 -5.0656730e-01\n",
      " -1.3426219e+00 -1.4893210e-01 -5.6986940e-01 -1.6667830e+00\n",
      " -3.3126044e-01 -7.1846068e-01 -2.1361988e+00 -1.8619326e-01\n",
      " -7.6650167e-01 -1.5456986e+00  1.2133791e-01 -7.9844999e-01\n",
      " -1.3094538e+00  5.6024306e-02 -7.5438237e-01 -1.3459777e+00\n",
      "  4.7329374e-02 -8.7643123e-01 -1.4715301e+00 -1.2119777e-01\n",
      " -6.4964342e-01 -1.4381053e+00 -4.9310625e-03 -7.2671890e-01\n",
      " -1.4249337e+00  6.7821741e-03 -7.0186043e-01 -1.5274713e+00\n",
      "  1.2522209e-01 -7.5730503e-01 -1.5926130e+00  3.2831877e-03\n",
      " -5.6034923e-01 -1.2419186e+00 -1.2708521e-01 -3.2899472e-01\n",
      " -1.9166315e+00  5.4978959e-02 -5.1576996e-01 -1.8971369e+00\n",
      "  2.1765026e-01 -4.7071740e-01 -1.4180437e+00 -1.3040659e-01\n",
      " -3.1113350e-01 -1.1759632e+00  2.5194660e-03 -2.9799429e-01\n",
      " -1.2459701e+00  6.2813260e-02 -3.4965479e-01 -1.3619046e+00\n",
      "  1.1266279e-01 -3.5749561e-01 -1.2394618e+00]\n",
      "data: [ 3.0723665e-02 -1.6468407e-01 -1.9280654e-01  5.7588860e-02\n",
      " -3.1220186e-01 -5.6166077e-01 -2.0124763e-03 -5.0656730e-01\n",
      " -1.3426219e+00 -1.4893210e-01 -5.6986940e-01 -1.6667830e+00\n",
      " -3.3126044e-01 -7.1846068e-01 -2.1361988e+00 -1.8619326e-01\n",
      " -7.6650167e-01 -1.5456986e+00  1.2133791e-01 -7.9844999e-01\n",
      " -1.3094538e+00  5.6024302e-02 -7.5438237e-01 -1.3459777e+00\n",
      "  4.7329374e-02 -8.7643123e-01 -1.4715302e+00 -1.2119777e-01\n",
      " -6.4964342e-01 -1.4381053e+00 -4.9310625e-03 -7.2671890e-01\n",
      " -1.4249337e+00  6.7821741e-03 -7.0186043e-01 -1.5274713e+00\n",
      "  1.2522209e-01 -7.5730497e-01 -1.5926129e+00  3.2831877e-03\n",
      " -5.6034923e-01 -1.2419186e+00 -1.2708521e-01 -3.2899472e-01\n",
      " -1.9166315e+00  5.4978956e-02 -5.1576996e-01 -1.8971370e+00\n",
      "  2.1765026e-01 -4.7071740e-01 -1.4180436e+00 -1.3040659e-01\n",
      " -3.1113350e-01 -1.1759632e+00  2.5194660e-03 -2.9799429e-01\n",
      " -1.2459701e+00  6.2813260e-02 -3.4965479e-01 -1.3619046e+00\n",
      "  1.1266279e-01 -3.5749561e-01 -1.2394618e+00  3.9999999e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0135, -0.1574, -0.1864,  ...,  0.0341, -0.3519, -1.1912],\n",
      "        [ 0.0135, -0.1574, -0.1864,  ...,  0.0341, -0.3519, -1.1912],\n",
      "        [ 0.0135, -0.1574, -0.1864,  ...,  0.0341, -0.3519, -1.1912],\n",
      "        ...,\n",
      "        [-0.0314,  0.5215, -0.1314,  ..., -0.3117,  1.0689, -0.5721],\n",
      "        [-0.1132, -0.0164,  0.6361,  ..., -0.1683,  0.7008,  0.2429],\n",
      "        [-0.1132, -0.0164,  0.6361,  ..., -0.1683,  0.7008,  0.2429]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01352995 -0.15738867 -0.18639877  0.03865317 -0.2725318  -0.50813234\n",
      " -0.09929391 -0.5056561  -1.3485816  -0.25831026 -0.57580864 -1.6392429\n",
      " -0.4185055  -0.67274475 -2.1424387  -0.18732159 -0.7976824  -1.5311772\n",
      " -0.01134236 -0.8680387  -1.367669   -0.06509234 -0.79260856 -1.415413\n",
      " -0.07505287 -0.9615706  -1.5354791  -0.14070475 -0.70333356 -1.4288985\n",
      " -0.08590961 -0.76142067 -1.3918691  -0.09763931 -0.7321465  -1.4727237\n",
      "  0.03751209 -0.76293015 -1.4909797  -0.05359025 -0.59374666 -1.2669722\n",
      " -0.21207671 -0.35868424 -2.0077899  -0.03215993 -0.5376499  -2.0261862\n",
      "  0.13924693 -0.49339223 -1.355885   -0.17648436 -0.36088413 -1.1879138\n",
      " -0.10759376 -0.33154792 -1.2736202  -0.07139054 -0.33963713 -1.3833134\n",
      "  0.03407436 -0.3518725  -1.1911703 ]\n",
      "data: [ 0.01352995 -0.15738867 -0.18639877  0.03865317 -0.2725318  -0.50813234\n",
      " -0.09929391 -0.5056561  -1.3485816  -0.25831026 -0.57580864 -1.6392429\n",
      " -0.4185055  -0.67274475 -2.1424387  -0.18732159 -0.7976824  -1.5311772\n",
      " -0.01134236 -0.8680387  -1.3676689  -0.06509234 -0.79260856 -1.415413\n",
      " -0.07505287 -0.96157056 -1.5354791  -0.14070475 -0.7033336  -1.4288985\n",
      " -0.08590961 -0.76142067 -1.3918691  -0.09763931 -0.7321465  -1.4727237\n",
      "  0.03751209 -0.76293015 -1.4909797  -0.05359025 -0.59374666 -1.2669722\n",
      " -0.21207671 -0.35868424 -2.0077899  -0.03215993 -0.5376499  -2.0261862\n",
      "  0.13924693 -0.49339223 -1.355885   -0.17648436 -0.36088413 -1.1879138\n",
      " -0.10759375 -0.33154792 -1.2736202  -0.07139054 -0.33963716 -1.3833134\n",
      "  0.03407436 -0.35187253 -1.1911703   0.05      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BB38>\n",
      "tensor([[-0.0026, -0.0145, -0.1866,  ...,  0.0206, -0.2151, -1.1494],\n",
      "        [-0.0026, -0.0145, -0.1866,  ...,  0.0206, -0.2151, -1.1494],\n",
      "        [-0.0026, -0.0145, -0.1866,  ...,  0.0206, -0.2151, -1.1494],\n",
      "        ...,\n",
      "        [-0.1761,  0.4020,  0.0104,  ..., -0.6759,  1.0206, -0.4213],\n",
      "        [-0.0817, -0.0882,  0.6192,  ..., -0.1951,  0.5925,  0.2597],\n",
      "        [-0.0817, -0.0882,  0.6192,  ..., -0.1951,  0.5925,  0.2597]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.0026376  -0.01447725 -0.18664922  0.01482544 -0.11646483 -0.46459156\n",
      " -0.14705624 -0.3529492  -1.3303297  -0.30784732 -0.42113572 -1.6125736\n",
      " -0.4699468  -0.5037875  -2.1224587  -0.19860546 -0.6666063  -1.5030541\n",
      " -0.05100609 -0.7392861  -1.3486032  -0.09410708 -0.65442437 -1.400634\n",
      " -0.08308066 -0.8312744  -1.5247617  -0.15809634 -0.5779412  -1.4022675\n",
      " -0.10779045 -0.6271452  -1.3570302  -0.11102898 -0.5941308  -1.439723\n",
      "  0.05475858 -0.6149916  -1.4484587  -0.08015864 -0.46702027 -1.2460272\n",
      " -0.24016874 -0.2317854  -2.0170937  -0.04686017 -0.4019618  -2.0483804\n",
      "  0.15539439 -0.36328053 -1.3175011  -0.20137946 -0.23570475 -1.161133\n",
      " -0.14564931 -0.20695804 -1.251137   -0.11417158 -0.19946153 -1.3632119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.02061749 -0.2151213  -1.14938   ]\n",
      "data: [-0.0026376  -0.01447725 -0.18664923  0.01482544 -0.11646483 -0.46459156\n",
      " -0.14705624 -0.35294923 -1.3303295  -0.30784732 -0.42113572 -1.6125735\n",
      " -0.46994677 -0.5037875  -2.1224587  -0.19860546 -0.6666063  -1.5030541\n",
      " -0.05100609 -0.7392861  -1.3486032  -0.09410708 -0.65442437 -1.400634\n",
      " -0.08308066 -0.8312744  -1.5247617  -0.15809634 -0.5779412  -1.4022675\n",
      " -0.10779045 -0.6271452  -1.3570302  -0.11102898 -0.5941308  -1.439723\n",
      "  0.05475858 -0.6149916  -1.4484587  -0.08015864 -0.46702027 -1.2460272\n",
      " -0.24016875 -0.23178539 -2.0170937  -0.04686017 -0.40196183 -2.0483804\n",
      "  0.15539439 -0.36328053 -1.3175011  -0.20137948 -0.23570475 -1.161133\n",
      " -0.14564931 -0.20695804 -1.251137   -0.11417158 -0.19946153 -1.3632119\n",
      "  0.02061749 -0.21512131 -1.14938     0.06      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B9B0>\n",
      "tensor([[-2.4072e-02, -3.5518e-02, -2.3054e-01,  ..., -7.0892e-05,\n",
      "         -1.9751e-01, -1.3291e+00],\n",
      "        [-2.4072e-02, -3.5518e-02, -2.3054e-01,  ..., -7.0892e-05,\n",
      "         -1.9751e-01, -1.3291e+00],\n",
      "        [-2.4072e-02, -3.5518e-02, -2.3054e-01,  ..., -7.0892e-05,\n",
      "         -1.9751e-01, -1.3291e+00],\n",
      "        ...,\n",
      "        [-2.3000e-01,  2.6806e-01, -8.1805e-02,  ..., -7.3480e-01,\n",
      "          7.4570e-01, -3.0403e-01],\n",
      "        [-1.7670e-01, -1.1312e-01,  5.1974e-01,  ..., -2.9209e-01,\n",
      "          6.3373e-01,  2.5591e-01],\n",
      "        [-1.7670e-01, -1.1312e-01,  5.1974e-01,  ..., -2.9209e-01,\n",
      "          6.3373e-01,  2.5591e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-2.40720473e-02 -3.55181545e-02 -2.30538160e-01 -1.24960728e-02\n",
      " -1.92104310e-01 -6.79993987e-01 -7.33837113e-02 -3.51992130e-01\n",
      " -1.37814796e+00 -2.18834132e-01 -4.06868339e-01 -1.68749583e+00\n",
      " -4.08228040e-01 -5.36454201e-01 -2.14440560e+00 -2.47221455e-01\n",
      " -6.25401914e-01 -1.54079068e+00  1.38951540e-02 -6.34803772e-01\n",
      " -1.32034659e+00 -3.27072591e-02 -5.77693343e-01 -1.37045062e+00\n",
      " -2.96228826e-02 -6.87008739e-01 -1.48669648e+00 -2.00004518e-01\n",
      " -5.07885695e-01 -1.46035051e+00 -9.19886678e-02 -5.65242290e-01\n",
      " -1.44369578e+00 -8.75352472e-02 -5.37016809e-01 -1.55211067e+00\n",
      "  5.03503382e-02 -5.60608149e-01 -1.62363219e+00 -9.69110206e-02\n",
      " -4.33155477e-01 -1.28251922e+00 -1.90904975e-01 -2.03331336e-01\n",
      " -1.85669672e+00 -4.21795845e-02 -3.50735068e-01 -1.84029830e+00\n",
      "  1.17171839e-01 -3.16739798e-01 -1.47433567e+00 -2.03503221e-01\n",
      " -1.84137493e-01 -1.22766948e+00 -1.09290555e-01 -1.62971407e-01\n",
      " -1.30934596e+00 -5.24882525e-02 -1.89849243e-01 -1.43261254e+00\n",
      " -7.08922744e-05 -1.97507933e-01 -1.32913899e+00]\n",
      "data: [-2.40720455e-02 -3.55181545e-02 -2.30538160e-01 -1.24960728e-02\n",
      " -1.92104295e-01 -6.79993987e-01 -7.33837113e-02 -3.51992100e-01\n",
      " -1.37814784e+00 -2.18834132e-01 -4.06868339e-01 -1.68749583e+00\n",
      " -4.08228040e-01 -5.36454201e-01 -2.14440560e+00 -2.47221455e-01\n",
      " -6.25401914e-01 -1.54079068e+00  1.38951540e-02 -6.34803772e-01\n",
      " -1.32034647e+00 -3.27072591e-02 -5.77693343e-01 -1.37045062e+00\n",
      " -2.96228845e-02 -6.87008739e-01 -1.48669648e+00 -2.00004518e-01\n",
      " -5.07885695e-01 -1.46035051e+00 -9.19886678e-02 -5.65242290e-01\n",
      " -1.44369578e+00 -8.75352472e-02 -5.37016809e-01 -1.55211055e+00\n",
      "  5.03503382e-02 -5.60608149e-01 -1.62363219e+00 -9.69110206e-02\n",
      " -4.33155477e-01 -1.28251922e+00 -1.90904975e-01 -2.03331336e-01\n",
      " -1.85669672e+00 -4.21795845e-02 -3.50735068e-01 -1.84029830e+00\n",
      "  1.17171839e-01 -3.16739798e-01 -1.47433567e+00 -2.03503221e-01\n",
      " -1.84137493e-01 -1.22766948e+00 -1.09290555e-01 -1.62971407e-01\n",
      " -1.30934596e+00 -5.24882525e-02 -1.89849243e-01 -1.43261266e+00\n",
      " -7.08922744e-05 -1.97507933e-01 -1.32913899e+00  7.00000003e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0258, -0.1538, -0.2758,  ...,  0.0311, -0.3281, -1.3668],\n",
      "        [ 0.0258, -0.1538, -0.2758,  ...,  0.0311, -0.3281, -1.3668],\n",
      "        [ 0.0258, -0.1538, -0.2758,  ...,  0.0311, -0.3281, -1.3668],\n",
      "        ...,\n",
      "        [-0.3733,  0.3257, -0.3785,  ..., -0.8851,  0.7898, -0.5561],\n",
      "        [-0.1452, -0.0113,  0.6723,  ..., -0.2270,  0.7622,  0.3671],\n",
      "        [-0.1452, -0.0113,  0.6723,  ..., -0.2270,  0.7622,  0.3671]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02577697 -0.15378182 -0.27577597  0.05059822 -0.29034364 -0.6979248\n",
      " -0.03204484 -0.46022692 -1.4433258  -0.17535533 -0.51869476 -1.7398922\n",
      " -0.33724308 -0.62583905 -2.2344868  -0.17803922 -0.75030357 -1.618326\n",
      "  0.03599483 -0.774225   -1.4417615  -0.01448804 -0.7123247  -1.4970899\n",
      " -0.01804179 -0.83667195 -1.612525   -0.1388172  -0.6497154  -1.5379467\n",
      " -0.05517366 -0.69906086 -1.519305   -0.06898607 -0.6693512  -1.617511\n",
      "  0.05562544 -0.6919225  -1.6657767  -0.05520279 -0.56630665 -1.3681853\n",
      " -0.15859497 -0.33659783 -1.9706888  -0.01525985 -0.48213387 -1.9718232\n",
      "  0.13033462 -0.45289052 -1.5242791  -0.1562056  -0.33131602 -1.3059571\n",
      " -0.07947725 -0.3071252  -1.3816276  -0.03668487 -0.318145   -1.499182\n",
      "  0.03109001 -0.32807982 -1.3668256 ]\n",
      "data: [ 0.02577697 -0.15378182 -0.27577597  0.05059822 -0.29034364 -0.6979248\n",
      " -0.03204484 -0.46022692 -1.4433258  -0.17535535 -0.51869476 -1.7398922\n",
      " -0.33724308 -0.62583905 -2.2344868  -0.17803922 -0.75030357 -1.618326\n",
      "  0.03599483 -0.774225   -1.4417615  -0.01448804 -0.7123247  -1.4970899\n",
      " -0.01804179 -0.836672   -1.612525   -0.1388172  -0.6497154  -1.5379468\n",
      " -0.05517366 -0.6990608  -1.519305   -0.06898607 -0.6693512  -1.617511\n",
      "  0.05562544 -0.6919224  -1.6657767  -0.05520279 -0.56630665 -1.3681853\n",
      " -0.15859497 -0.33659783 -1.9706888  -0.01525985 -0.48213387 -1.9718232\n",
      "  0.13033462 -0.45289052 -1.5242791  -0.1562056  -0.33131602 -1.3059571\n",
      " -0.07947725 -0.3071252  -1.3816276  -0.03668487 -0.318145   -1.499182\n",
      "  0.03109001 -0.32807982 -1.3668256   0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B320>\n",
      "tensor([[ 0.0547, -0.1774, -0.2551,  ...,  0.0755, -0.3485, -1.3465],\n",
      "        [ 0.0547, -0.1774, -0.2551,  ...,  0.0755, -0.3485, -1.3465],\n",
      "        [ 0.0547, -0.1774, -0.2551,  ...,  0.0755, -0.3485, -1.3465],\n",
      "        ...,\n",
      "        [-0.1004,  0.4604, -0.1229,  ..., -0.6771,  0.9667, -0.4277],\n",
      "        [-0.1602, -0.0484,  0.6275,  ..., -0.2292,  0.6516,  0.3472],\n",
      "        [-0.1602, -0.0484,  0.6275,  ..., -0.2292,  0.6516,  0.3472]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.05468012 -0.17743836 -0.25514713  0.08002298 -0.3230756  -0.6554125\n",
      "  0.02574844 -0.5135211  -1.42289    -0.12023947 -0.5703337  -1.7467151\n",
      " -0.29733962 -0.7043297  -2.2249205  -0.16353086 -0.7760938  -1.629878\n",
      "  0.12355554 -0.80602825 -1.4064565   0.05868271 -0.7601629  -1.4472318\n",
      "  0.04485452 -0.88331956 -1.5713754  -0.10876094 -0.6592874  -1.5265388\n",
      " -0.00517893 -0.72821295 -1.5121953  -0.00347633 -0.7048326  -1.618351\n",
      "  0.10345598 -0.7526781  -1.6793766   0.00346654 -0.562714   -1.3419588\n",
      " -0.13166432 -0.3363611  -2.0079744   0.03615937 -0.5131455  -1.9948766\n",
      "  0.18246779 -0.4682238  -1.5154028  -0.12788938 -0.3174228  -1.276505\n",
      " -0.01383539 -0.29994455 -1.3462415   0.03433095 -0.34412223 -1.4617093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.07547308 -0.34847414 -1.3465416 ]\n",
      "data: [ 0.05468012 -0.17743835 -0.25514713  0.08002298 -0.3230756  -0.6554125\n",
      "  0.02574844 -0.5135211  -1.4228901  -0.12023947 -0.5703337  -1.7467151\n",
      " -0.29733962 -0.7043297  -2.2249205  -0.16353087 -0.7760937  -1.629878\n",
      "  0.12355555 -0.8060282  -1.4064565   0.05868271 -0.7601629  -1.4472318\n",
      "  0.04485452 -0.88331956 -1.5713754  -0.10876094 -0.6592874  -1.5265388\n",
      " -0.00517893 -0.72821295 -1.5121952  -0.00347633 -0.7048326  -1.618351\n",
      "  0.10345598 -0.7526781  -1.6793765   0.00346654 -0.562714   -1.3419588\n",
      " -0.13166432 -0.3363611  -2.0079744   0.03615937 -0.5131455  -1.9948765\n",
      "  0.18246779 -0.4682238  -1.5154028  -0.12788938 -0.3174228  -1.276505\n",
      " -0.01383538 -0.29994455 -1.3462415   0.03433095 -0.34412223 -1.4617093\n",
      "  0.07547308 -0.34847414 -1.3465416   0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EC24940>\n",
      "tensor([[ 0.0015, -0.1673, -0.2024,  ...,  0.0568, -0.3601, -1.2318],\n",
      "        [ 0.0015, -0.1673, -0.2024,  ...,  0.0568, -0.3601, -1.2318],\n",
      "        [ 0.0015, -0.1673, -0.2024,  ...,  0.0568, -0.3601, -1.2318],\n",
      "        ...,\n",
      "        [-0.0325,  0.5492, -0.1583,  ..., -0.5304,  1.0992, -0.5430],\n",
      "        [-0.1303,  0.0149,  0.6086,  ..., -0.1807,  0.6985,  0.2620],\n",
      "        [-0.1303,  0.0149,  0.6086,  ..., -0.1807,  0.6985,  0.2620]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.4665322e-03 -1.6729844e-01 -2.0244174e-01  2.9383618e-02\n",
      " -3.0203640e-01 -5.6086636e-01 -4.8112147e-02 -5.0663257e-01\n",
      " -1.3576707e+00 -1.9819707e-01 -5.6849849e-01 -1.6771080e+00\n",
      " -3.7197328e-01 -7.0288306e-01 -2.1587431e+00 -2.1071927e-01\n",
      " -7.7710110e-01 -1.5561749e+00  5.7935283e-02 -8.2070500e-01\n",
      " -1.3480703e+00 -9.1966689e-03 -7.6699102e-01 -1.3909699e+00\n",
      " -1.9743189e-02 -9.0631372e-01 -1.5162866e+00 -1.5187423e-01\n",
      " -6.6950136e-01 -1.4469200e+00 -5.6850366e-02 -7.4003559e-01\n",
      " -1.4288454e+00 -5.6778111e-02 -7.1606052e-01 -1.5275437e+00\n",
      "  5.8217466e-02 -7.6418275e-01 -1.5728317e+00 -3.8597517e-02\n",
      " -5.7110035e-01 -1.2591339e+00 -1.8202753e-01 -3.4030598e-01\n",
      " -1.9666418e+00 -2.1768510e-03 -5.2662551e-01 -1.9594413e+00\n",
      "  1.5807630e-01 -4.8336202e-01 -1.4071641e+00 -1.6973351e-01\n",
      " -3.3102369e-01 -1.1893541e+00 -5.5873379e-02 -3.1478226e-01\n",
      " -1.2637646e+00 -8.1055611e-03 -3.5365787e-01 -1.3769319e+00\n",
      "  5.6783132e-02 -3.6010689e-01 -1.2317662e+00]\n",
      "data: [ 1.4665322e-03 -1.6729844e-01 -2.0244174e-01  2.9383618e-02\n",
      " -3.0203640e-01 -5.6086636e-01 -4.8112143e-02 -5.0663257e-01\n",
      " -1.3576705e+00 -1.9819707e-01 -5.6849849e-01 -1.6771080e+00\n",
      " -3.7197328e-01 -7.0288306e-01 -2.1587431e+00 -2.1071929e-01\n",
      " -7.7710116e-01 -1.5561749e+00  5.7935283e-02 -8.2070506e-01\n",
      " -1.3480703e+00 -9.1966689e-03 -7.6699102e-01 -1.3909699e+00\n",
      " -1.9743189e-02 -9.0631372e-01 -1.5162866e+00 -1.5187423e-01\n",
      " -6.6950136e-01 -1.4469200e+00 -5.6850366e-02 -7.4003565e-01\n",
      " -1.4288454e+00 -5.6778111e-02 -7.1606046e-01 -1.5275437e+00\n",
      "  5.8217470e-02 -7.6418275e-01 -1.5728317e+00 -3.8597517e-02\n",
      " -5.7110035e-01 -1.2591339e+00 -1.8202753e-01 -3.4030598e-01\n",
      " -1.9666419e+00 -2.1768510e-03 -5.2662551e-01 -1.9594414e+00\n",
      "  1.5807630e-01 -4.8336202e-01 -1.4071641e+00 -1.6973351e-01\n",
      " -3.3102372e-01 -1.1893541e+00 -5.5873379e-02 -3.1478226e-01\n",
      " -1.2637646e+00 -8.1055611e-03 -3.5365787e-01 -1.3769319e+00\n",
      "  5.6783132e-02 -3.6010689e-01 -1.2317662e+00  1.0000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0107, -0.0839, -0.1741,  ...,  0.0118, -0.2723, -1.1744],\n",
      "        [ 0.0107, -0.0839, -0.1741,  ...,  0.0118, -0.2723, -1.1744],\n",
      "        [ 0.0107, -0.0839, -0.1741,  ...,  0.0118, -0.2723, -1.1744],\n",
      "        ...,\n",
      "        [-0.1511,  0.4649, -0.0987,  ..., -0.4949,  1.0334, -0.4685],\n",
      "        [-0.1025, -0.0441,  0.6450,  ..., -0.1783,  0.6476,  0.3258],\n",
      "        [-0.1025, -0.0441,  0.6450,  ..., -0.1783,  0.6476,  0.3258]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01068425 -0.08385826 -0.17412217  0.03671333 -0.1816797  -0.45083442\n",
      " -0.12467207 -0.42494872 -1.3320795  -0.28563517 -0.49429277 -1.6132286\n",
      " -0.42910954 -0.5721192  -2.1431317  -0.186748   -0.73459345 -1.5189402\n",
      " -0.0443702  -0.8128174  -1.3908185  -0.09424964 -0.73019046 -1.4397835\n",
      " -0.09840254 -0.906436   -1.563307   -0.14686924 -0.6507275  -1.416661\n",
      " -0.10379419 -0.6988252  -1.3812131  -0.11481582 -0.65885043 -1.4596909\n",
      "  0.02946389 -0.6882048  -1.4650506  -0.0686793  -0.530067   -1.2672251\n",
      " -0.23344083 -0.29372382 -2.0180366  -0.04860426 -0.46451873 -2.052836\n",
      "  0.13253614 -0.4208818  -1.3461412  -0.19530928 -0.30283788 -1.1821864\n",
      " -0.13728808 -0.2684314  -1.2718092  -0.11188297 -0.2624453  -1.3807954\n",
      "  0.01176339 -0.2723493  -1.1744374 ]\n",
      "data: [ 0.01068425 -0.08385826 -0.17412215  0.03671333 -0.18167968 -0.45083442\n",
      " -0.12467207 -0.42494872 -1.3320794  -0.28563517 -0.49429277 -1.6132286\n",
      " -0.42910954 -0.5721192  -2.1431317  -0.18674798 -0.73459345 -1.5189403\n",
      " -0.0443702  -0.8128174  -1.3908185  -0.09424964 -0.73019046 -1.4397835\n",
      " -0.09840254 -0.906436   -1.563307   -0.14686924 -0.6507275  -1.416661\n",
      " -0.10379419 -0.6988251  -1.3812131  -0.11481582 -0.65885043 -1.4596908\n",
      "  0.02946389 -0.6882048  -1.4650505  -0.0686793  -0.530067   -1.2672251\n",
      " -0.23344083 -0.29372382 -2.0180366  -0.04860426 -0.46451873 -2.052836\n",
      "  0.13253614 -0.4208818  -1.3461412  -0.19530928 -0.30283788 -1.1821864\n",
      " -0.13728808 -0.2684314  -1.2718092  -0.11188297 -0.2624453  -1.3807952\n",
      "  0.01176339 -0.2723493  -1.1744374   0.11      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[-0.0250, -0.0049, -0.1889,  ...,  0.0204, -0.1890, -1.1772],\n",
      "        [-0.0250, -0.0049, -0.1889,  ...,  0.0204, -0.1890, -1.1772],\n",
      "        [-0.0250, -0.0049, -0.1889,  ...,  0.0204, -0.1890, -1.1772],\n",
      "        ...,\n",
      "        [-0.2343,  0.2588, -0.0090,  ..., -0.7576,  0.8531, -0.3949],\n",
      "        [-0.0949, -0.0926,  0.5930,  ..., -0.2534,  0.6143,  0.2667],\n",
      "        [-0.0949, -0.0926,  0.5930,  ..., -0.2534,  0.6143,  0.2667]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.02504722 -0.00485422 -0.18889587 -0.00388054 -0.12362894 -0.5224296\n",
      " -0.12915805 -0.33586937 -1.3293362  -0.28183252 -0.39675474 -1.6238022\n",
      " -0.44831172 -0.5007955  -2.1065676  -0.22924405 -0.6326569  -1.4917133\n",
      " -0.02593423 -0.68090785 -1.3070459  -0.07011542 -0.6088317  -1.3571584\n",
      " -0.06332098 -0.7609292  -1.483413   -0.18312453 -0.5342007  -1.3943264\n",
      " -0.10601859 -0.5885373  -1.3649585  -0.09793799 -0.5535815  -1.4540498\n",
      "  0.06115632 -0.5845629  -1.4885948  -0.08967075 -0.43228936 -1.2251227\n",
      " -0.23248383 -0.19428153 -1.9523525  -0.03960886 -0.3647635  -1.9655216\n",
      "  0.15373757 -0.32265192 -1.3462234  -0.21104288 -0.19543675 -1.1486793\n",
      " -0.13120219 -0.1660825  -1.2349458  -0.08621407 -0.17521542 -1.3535366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.02040605 -0.1889604  -1.177239  ]\n",
      "data: [-0.02504722 -0.00485422 -0.18889588 -0.00388054 -0.12362894 -0.5224296\n",
      " -0.12915805 -0.33586937 -1.3293363  -0.28183252 -0.39675477 -1.6238022\n",
      " -0.44831172 -0.5007955  -2.1065676  -0.22924405 -0.6326569  -1.4917133\n",
      " -0.02593423 -0.68090785 -1.3070459  -0.07011542 -0.6088317  -1.3571583\n",
      " -0.06332098 -0.7609293  -1.483413   -0.18312453 -0.5342007  -1.3943264\n",
      " -0.10601859 -0.5885373  -1.3649585  -0.09793799 -0.5535815  -1.4540498\n",
      "  0.06115632 -0.5845629  -1.4885948  -0.08967075 -0.43228936 -1.2251227\n",
      " -0.23248382 -0.19428153 -1.9523526  -0.03960886 -0.3647635  -1.9655216\n",
      "  0.15373757 -0.32265195 -1.3462234  -0.21104288 -0.19543675 -1.1486793\n",
      " -0.13120219 -0.1660825  -1.2349458  -0.08621407 -0.17521542 -1.3535367\n",
      "  0.02040605 -0.1889604  -1.177239    0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BB38>\n",
      "tensor([[-1.4117e-02, -1.0629e-01, -2.1754e-01,  ...,  1.1134e-03,\n",
      "         -2.6043e-01, -1.3411e+00],\n",
      "        [-1.4117e-02, -1.0629e-01, -2.1754e-01,  ...,  1.1134e-03,\n",
      "         -2.6043e-01, -1.3411e+00],\n",
      "        [-1.4117e-02, -1.0629e-01, -2.1754e-01,  ...,  1.1134e-03,\n",
      "         -2.6043e-01, -1.3411e+00],\n",
      "        ...,\n",
      "        [-2.4437e-01,  3.6164e-01, -1.7627e-01,  ..., -7.4369e-01,\n",
      "          8.2429e-01, -3.5355e-01],\n",
      "        [-1.5972e-01, -7.6668e-02,  5.6868e-01,  ..., -2.6058e-01,\n",
      "          6.9671e-01,  2.7271e-01],\n",
      "        [-1.5972e-01, -7.6668e-02,  5.6868e-01,  ..., -2.6058e-01,\n",
      "          6.9671e-01,  2.7271e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-1.4116932e-02 -1.0628925e-01 -2.1754164e-01  4.9256422e-03\n",
      " -2.6683432e-01 -6.8851852e-01 -4.3681771e-02 -4.1351128e-01\n",
      " -1.3777468e+00 -1.8459302e-01 -4.6680015e-01 -1.6865122e+00\n",
      " -3.6295658e-01 -5.9747958e-01 -2.1546836e+00 -2.3497109e-01\n",
      " -6.8429077e-01 -1.5439150e+00  3.2735497e-02 -6.8325520e-01\n",
      " -1.3218961e+00 -1.7511874e-02 -6.2895739e-01 -1.3752799e+00\n",
      " -1.9702606e-02 -7.2685409e-01 -1.4920585e+00 -1.9179593e-01\n",
      " -5.6842577e-01 -1.4691386e+00 -7.9849564e-02 -6.2186641e-01\n",
      " -1.4567137e+00 -8.3568588e-02 -5.9112453e-01 -1.5659597e+00\n",
      "  4.2150110e-02 -6.1451274e-01 -1.6379855e+00 -9.1077693e-02\n",
      " -4.9632579e-01 -1.2890387e+00 -1.7196536e-01 -2.6690751e-01\n",
      " -1.8243818e+00 -3.7987657e-02 -4.0604085e-01 -1.8057485e+00\n",
      "  1.0743885e-01 -3.7656260e-01 -1.4893718e+00 -1.9164215e-01\n",
      " -2.4987139e-01 -1.2378733e+00 -9.5083848e-02 -2.2864823e-01\n",
      " -1.3134031e+00 -4.0959716e-02 -2.5472298e-01 -1.4369071e+00\n",
      "  1.1134222e-03 -2.6043469e-01 -1.3410611e+00]\n",
      "data: [-1.4116932e-02 -1.0628925e-01 -2.1754164e-01  4.9256422e-03\n",
      " -2.6683432e-01 -6.8851852e-01 -4.3681771e-02 -4.1351128e-01\n",
      " -1.3777469e+00 -1.8459302e-01 -4.6680015e-01 -1.6865124e+00\n",
      " -3.6295658e-01 -5.9747958e-01 -2.1546836e+00 -2.3497109e-01\n",
      " -6.8429077e-01 -1.5439152e+00  3.2735497e-02 -6.8325514e-01\n",
      " -1.3218961e+00 -1.7511874e-02 -6.2895739e-01 -1.3752799e+00\n",
      " -1.9702606e-02 -7.2685409e-01 -1.4920585e+00 -1.9179592e-01\n",
      " -5.6842577e-01 -1.4691386e+00 -7.9849564e-02 -6.2186641e-01\n",
      " -1.4567137e+00 -8.3568595e-02 -5.9112453e-01 -1.5659596e+00\n",
      "  4.2150110e-02 -6.1451274e-01 -1.6379856e+00 -9.1077693e-02\n",
      " -4.9632579e-01 -1.2890387e+00 -1.7196538e-01 -2.6690751e-01\n",
      " -1.8243818e+00 -3.7987657e-02 -4.0604085e-01 -1.8057485e+00\n",
      "  1.0743885e-01 -3.7656257e-01 -1.4893718e+00 -1.9164215e-01\n",
      " -2.4987139e-01 -1.2378733e+00 -9.5083848e-02 -2.2864823e-01\n",
      " -1.3134031e+00 -4.0959716e-02 -2.5472298e-01 -1.4369071e+00\n",
      "  1.1134222e-03 -2.6043469e-01 -1.3410611e+00  1.3000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0599, -0.1391, -0.2896,  ...,  0.0540, -0.3150, -1.3435],\n",
      "        [ 0.0599, -0.1391, -0.2896,  ...,  0.0540, -0.3150, -1.3435],\n",
      "        [ 0.0599, -0.1391, -0.2896,  ...,  0.0540, -0.3150, -1.3435],\n",
      "        ...,\n",
      "        [-0.1677,  0.4858, -0.1312,  ..., -0.7331,  1.0188, -0.4445],\n",
      "        [-0.1839, -0.1000,  0.6370,  ..., -0.2633,  0.6632,  0.3194],\n",
      "        [-0.1839, -0.1000,  0.6370,  ..., -0.2633,  0.6632,  0.3194]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 5.9888292e-02 -1.3905683e-01 -2.8956181e-01  9.2326537e-02\n",
      " -2.5278413e-01 -6.6489142e-01 -2.8154880e-02 -4.6060902e-01\n",
      " -1.4744730e+00 -1.7547959e-01 -5.2369165e-01 -1.7642119e+00\n",
      " -3.1699812e-01 -6.1050403e-01 -2.2774720e+00 -1.3185854e-01\n",
      " -7.6304799e-01 -1.6421961e+00  4.0472373e-02 -8.1438953e-01\n",
      " -1.4828291e+00 -1.3261333e-02 -7.4287134e-01 -1.5400237e+00\n",
      " -3.2353975e-02 -8.9819556e-01 -1.6633936e+00 -9.5439881e-02\n",
      " -6.7516637e-01 -1.5506183e+00 -3.9878726e-02 -7.2138768e-01\n",
      " -1.5260372e+00 -6.3552544e-02 -6.8630701e-01 -1.6118748e+00\n",
      "  5.9464037e-02 -7.1423072e-01 -1.6353002e+00 -2.0231776e-02\n",
      " -5.6642276e-01 -1.3925121e+00 -1.6107599e-01 -3.3237723e-01\n",
      " -2.0982211e+00  3.9714575e-04 -4.9096382e-01 -2.1208396e+00\n",
      "  1.5092184e-01 -4.5477498e-01 -1.5070915e+00 -1.3004468e-01\n",
      " -3.3998781e-01 -1.3164505e+00 -6.8546370e-02 -3.0625379e-01\n",
      " -1.4020097e+00 -3.8819075e-02 -3.0455324e-01 -1.5164182e+00\n",
      "  5.3973578e-02 -3.1504059e-01 -1.3434833e+00]\n",
      "data: [ 5.9888292e-02 -1.3905683e-01 -2.8956181e-01  9.2326537e-02\n",
      " -2.5278413e-01 -6.6489142e-01 -2.8154878e-02 -4.6060902e-01\n",
      " -1.4744730e+00 -1.7547959e-01 -5.2369165e-01 -1.7642119e+00\n",
      " -3.1699812e-01 -6.1050403e-01 -2.2774720e+00 -1.3185854e-01\n",
      " -7.6304799e-01 -1.6421961e+00  4.0472373e-02 -8.1438947e-01\n",
      " -1.4828291e+00 -1.3261332e-02 -7.4287134e-01 -1.5400237e+00\n",
      " -3.2353975e-02 -8.9819556e-01 -1.6633935e+00 -9.5439881e-02\n",
      " -6.7516637e-01 -1.5506183e+00 -3.9878726e-02 -7.2138768e-01\n",
      " -1.5260373e+00 -6.3552544e-02 -6.8630701e-01 -1.6118748e+00\n",
      "  5.9464034e-02 -7.1423072e-01 -1.6353002e+00 -2.0231776e-02\n",
      " -5.6642276e-01 -1.3925121e+00 -1.6107599e-01 -3.3237725e-01\n",
      " -2.0982211e+00  3.9714575e-04 -4.9096382e-01 -2.1208396e+00\n",
      "  1.5092184e-01 -4.5477498e-01 -1.5070915e+00 -1.3004468e-01\n",
      " -3.3998784e-01 -1.3164505e+00 -6.8546370e-02 -3.0625379e-01\n",
      " -1.4020097e+00 -3.8819075e-02 -3.0455324e-01 -1.5164181e+00\n",
      "  5.3973578e-02 -3.1504059e-01 -1.3434833e+00  1.4000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0019, -0.0965, -0.1884,  ...,  0.0747, -0.2911, -1.2397],\n",
      "        [ 0.0019, -0.0965, -0.1884,  ...,  0.0747, -0.2911, -1.2397],\n",
      "        [ 0.0019, -0.0965, -0.1884,  ...,  0.0747, -0.2911, -1.2397],\n",
      "        ...,\n",
      "        [-0.1265,  0.4071, -0.0754,  ..., -0.8255,  0.9085, -0.3379],\n",
      "        [-0.1080, -0.0789,  0.5376,  ..., -0.1846,  0.6079,  0.1794],\n",
      "        [-0.1080, -0.0789,  0.5376,  ..., -0.1846,  0.6079,  0.1794]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.9021975e-03 -9.6525013e-02 -1.8835917e-01  1.6723949e-02\n",
      " -2.4685967e-01 -5.7905394e-01 -2.6626475e-02 -4.2379278e-01\n",
      " -1.3159966e+00 -1.6892001e-01 -4.7911161e-01 -1.6436403e+00\n",
      " -3.5634720e-01 -6.2900782e-01 -2.0992937e+00 -2.1772625e-01\n",
      " -6.8775249e-01 -1.5167965e+00  7.9360470e-02 -7.1078569e-01\n",
      " -1.3161132e+00  1.5090093e-02 -6.6589653e-01 -1.3575857e+00\n",
      "  2.6858285e-02 -7.8579456e-01 -1.4762073e+00 -1.5309335e-01\n",
      " -5.6927943e-01 -1.4144953e+00 -3.6454186e-02 -6.4132398e-01\n",
      " -1.4038728e+00 -2.5459737e-02 -6.2585664e-01 -1.5146294e+00\n",
      "  8.9977264e-02 -6.7143160e-01 -1.5807904e+00 -3.1017460e-02\n",
      " -4.8666853e-01 -1.2218776e+00 -1.4812438e-01 -2.6552391e-01\n",
      " -1.8648740e+00  2.0045057e-02 -4.4201273e-01 -1.8431746e+00\n",
      "  1.7757036e-01 -4.0432549e-01 -1.4081585e+00 -1.5495124e-01\n",
      " -2.4100041e-01 -1.1628274e+00 -2.6707038e-02 -2.3447157e-01\n",
      " -1.2358127e+00  2.9629275e-02 -2.8441745e-01 -1.3520322e+00\n",
      "  7.4747182e-02 -2.9105690e-01 -1.2397416e+00]\n",
      "data: [ 1.9021975e-03 -9.6525013e-02 -1.8835917e-01  1.6723949e-02\n",
      " -2.4685967e-01 -5.7905394e-01 -2.6626475e-02 -4.2379275e-01\n",
      " -1.3159966e+00 -1.6892000e-01 -4.7911158e-01 -1.6436403e+00\n",
      " -3.5634720e-01 -6.2900782e-01 -2.0992937e+00 -2.1772625e-01\n",
      " -6.8775249e-01 -1.5167965e+00  7.9360470e-02 -7.1078569e-01\n",
      " -1.3161132e+00  1.5090094e-02 -6.6589653e-01 -1.3575855e+00\n",
      "  2.6858285e-02 -7.8579450e-01 -1.4762073e+00 -1.5309335e-01\n",
      " -5.6927943e-01 -1.4144953e+00 -3.6454186e-02 -6.4132398e-01\n",
      " -1.4038728e+00 -2.5459738e-02 -6.2585664e-01 -1.5146294e+00\n",
      "  8.9977264e-02 -6.7143160e-01 -1.5807904e+00 -3.1017460e-02\n",
      " -4.8666850e-01 -1.2218776e+00 -1.4812438e-01 -2.6552391e-01\n",
      " -1.8648740e+00  2.0045057e-02 -4.4201270e-01 -1.8431746e+00\n",
      "  1.7757036e-01 -4.0432549e-01 -1.4081585e+00 -1.5495124e-01\n",
      " -2.4100040e-01 -1.1628274e+00 -2.6707038e-02 -2.3447157e-01\n",
      " -1.2358127e+00  2.9629275e-02 -2.8441745e-01 -1.3520322e+00\n",
      "  7.4747182e-02 -2.9105690e-01 -1.2397416e+00  1.5000001e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[ 0.0363, -0.0806, -0.2449,  ...,  0.0260, -0.2651, -1.2633],\n",
      "        [ 0.0363, -0.0806, -0.2449,  ...,  0.0260, -0.2651, -1.2633],\n",
      "        [ 0.0363, -0.0806, -0.2449,  ...,  0.0260, -0.2651, -1.2633],\n",
      "        ...,\n",
      "        [-0.1528,  0.4373, -0.1208,  ..., -0.5190,  0.9447, -0.4513],\n",
      "        [-0.1610, -0.0830,  0.6309,  ..., -0.2315,  0.6821,  0.2811],\n",
      "        [-0.1610, -0.0830,  0.6309,  ..., -0.2315,  0.6821,  0.2811]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03634242 -0.08055389 -0.24486837  0.06477211 -0.19333732 -0.5954089\n",
      " -0.08313329 -0.4181145  -1.433754   -0.23471758 -0.4899483  -1.7134815\n",
      " -0.3832736  -0.5688965  -2.224575   -0.15342093 -0.7224599  -1.5884947\n",
      " -0.00682851 -0.7846605  -1.4104317  -0.05585264 -0.7076571  -1.4690768\n",
      " -0.07763849 -0.87463564 -1.5939505  -0.12168831 -0.63400316 -1.4974883\n",
      " -0.07898854 -0.68031067 -1.4587874  -0.1059595  -0.6455362  -1.5378532\n",
      "  0.03336933 -0.6663355  -1.5523883  -0.05425443 -0.52360225 -1.3426491\n",
      " -0.20480126 -0.28942335 -2.0773897  -0.03811326 -0.44843167 -2.1066802\n",
      "  0.12715906 -0.4129871  -1.423699   -0.16151822 -0.2955209  -1.261665\n",
      " -0.1160142  -0.26123795 -1.349798   -0.08795456 -0.24884538 -1.4635589\n",
      "  0.02601358 -0.26505357 -1.2633438 ]\n",
      "data: [ 0.03634242 -0.0805539  -0.24486837  0.06477211 -0.19333732 -0.5954089\n",
      " -0.08313329 -0.4181145  -1.433754   -0.23471758 -0.4899483  -1.7134815\n",
      " -0.38327363 -0.5688965  -2.224575   -0.15342093 -0.72246    -1.5884948\n",
      " -0.00682851 -0.7846605  -1.4104316  -0.05585264 -0.7076571  -1.4690766\n",
      " -0.07763849 -0.87463564 -1.5939505  -0.12168832 -0.63400316 -1.4974883\n",
      " -0.07898854 -0.68031067 -1.4587874  -0.1059595  -0.6455362  -1.5378532\n",
      "  0.03336933 -0.6663355  -1.5523883  -0.05425443 -0.52360225 -1.3426491\n",
      " -0.20480126 -0.28942335 -2.0773897  -0.03811326 -0.44843167 -2.1066802\n",
      "  0.12715906 -0.4129871  -1.423699   -0.16151822 -0.2955209  -1.261665\n",
      " -0.1160142  -0.26123795 -1.349798   -0.08795456 -0.24884538 -1.4635589\n",
      "  0.02601358 -0.26505357 -1.2633438   0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0061, -0.0523, -0.1718,  ...,  0.0771, -0.2439, -1.1861],\n",
      "        [ 0.0061, -0.0523, -0.1718,  ...,  0.0771, -0.2439, -1.1861],\n",
      "        [ 0.0061, -0.0523, -0.1718,  ...,  0.0771, -0.2439, -1.1861],\n",
      "        ...,\n",
      "        [-0.1521,  0.3242, -0.1092,  ..., -0.8516,  0.8026, -0.3283],\n",
      "        [-0.1415, -0.1435,  0.5084,  ..., -0.2479,  0.5555,  0.1602],\n",
      "        [-0.1415, -0.1435,  0.5084,  ..., -0.2479,  0.5555,  0.1602]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 6.1160820e-03 -5.2255385e-02 -1.7175117e-01  2.6632827e-02\n",
      " -1.8244284e-01 -5.2711415e-01 -5.0904088e-02 -3.7207305e-01\n",
      " -1.2933398e+00 -1.9550350e-01 -4.2762071e-01 -1.6114833e+00\n",
      " -3.7600940e-01 -5.5830580e-01 -2.0768116e+00 -2.0260046e-01\n",
      " -6.5801537e-01 -1.4692428e+00  5.2302048e-02 -6.9222158e-01\n",
      " -1.2875494e+00 -7.1789324e-03 -6.3597077e-01 -1.3338552e+00\n",
      "  3.3339858e-04 -7.7684861e-01 -1.4561498e+00 -1.4313473e-01\n",
      " -5.5333585e-01 -1.3664839e+00 -4.5152158e-02 -6.1721611e-01\n",
      " -1.3542222e+00 -3.9635345e-02 -5.9382039e-01 -1.4602106e+00\n",
      "  9.1184139e-02 -6.3568968e-01 -1.5123637e+00 -3.4494303e-02\n",
      " -4.6140271e-01 -1.1832254e+00 -1.6827209e-01 -2.3080100e-01\n",
      " -1.9039347e+00  1.6795471e-02 -4.0775234e-01 -1.9007040e+00\n",
      "  1.8563135e-01 -3.7050664e-01 -1.3519014e+00 -1.5593924e-01\n",
      " -2.2237021e-01 -1.1179463e+00 -4.8367009e-02 -2.0737824e-01\n",
      " -1.2051052e+00  2.1690875e-03 -2.3675089e-01 -1.3261769e+00\n",
      "  7.7122055e-02 -2.4385640e-01 -1.1861356e+00]\n",
      "data: [ 6.1160820e-03 -5.2255381e-02 -1.7175117e-01  2.6632827e-02\n",
      " -1.8244284e-01 -5.2711415e-01 -5.0904088e-02 -3.7207305e-01\n",
      " -1.2933398e+00 -1.9550350e-01 -4.2762071e-01 -1.6114833e+00\n",
      " -3.7600940e-01 -5.5830580e-01 -2.0768116e+00 -2.0260046e-01\n",
      " -6.5801537e-01 -1.4692428e+00  5.2302048e-02 -6.9222158e-01\n",
      " -1.2875495e+00 -7.1789324e-03 -6.3597077e-01 -1.3338552e+00\n",
      "  3.3339858e-04 -7.7684861e-01 -1.4561497e+00 -1.4313473e-01\n",
      " -5.5333585e-01 -1.3664839e+00 -4.5152158e-02 -6.1721611e-01\n",
      " -1.3542221e+00 -3.9635345e-02 -5.9382039e-01 -1.4602106e+00\n",
      "  9.1184139e-02 -6.3568968e-01 -1.5123638e+00 -3.4494303e-02\n",
      " -4.6140271e-01 -1.1832254e+00 -1.6827209e-01 -2.3080102e-01\n",
      " -1.9039348e+00  1.6795471e-02 -4.0775234e-01 -1.9007040e+00\n",
      "  1.8563135e-01 -3.7050664e-01 -1.3519014e+00 -1.5593924e-01\n",
      " -2.2237021e-01 -1.1179463e+00 -4.8367009e-02 -2.0737824e-01\n",
      " -1.2051052e+00  2.1690875e-03 -2.3675089e-01 -1.3261769e+00\n",
      "  7.7122055e-02 -2.4385639e-01 -1.1861356e+00  1.7000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63E80>\n",
      "tensor([[ 0.0292, -0.0885, -0.2523,  ...,  0.0335, -0.2658, -1.3046],\n",
      "        [ 0.0292, -0.0885, -0.2523,  ...,  0.0335, -0.2658, -1.3046],\n",
      "        [ 0.0292, -0.0885, -0.2523,  ...,  0.0335, -0.2658, -1.3046],\n",
      "        ...,\n",
      "        [-0.2784,  0.2952, -0.2569,  ..., -0.7180,  0.7472, -0.4884],\n",
      "        [-0.1232, -0.0142,  0.6191,  ..., -0.2114,  0.7725,  0.2678],\n",
      "        [-0.1232, -0.0142,  0.6191,  ..., -0.2114,  0.7725,  0.2678]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02920463 -0.08846061 -0.25226432  0.05141481 -0.2252823  -0.66327953\n",
      " -0.06277768 -0.42604    -1.4504088  -0.21009396 -0.49424464 -1.7405143\n",
      " -0.37678224 -0.5958942  -2.223628   -0.17651112 -0.70477015 -1.6046387\n",
      "  0.01724681 -0.7463127  -1.3895174  -0.03102998 -0.6795564  -1.4448541\n",
      " -0.04875886 -0.8225461  -1.5646961  -0.13818437 -0.6011196  -1.5180134\n",
      " -0.07142089 -0.65621215 -1.4800673  -0.09075962 -0.6296723  -1.5683457\n",
      "  0.0447408  -0.6492218  -1.6079472  -0.05835927 -0.51060575 -1.349816\n",
      " -0.18486367 -0.2803796  -2.0144234  -0.03007823 -0.43671858 -2.021676\n",
      "  0.12731554 -0.4027593  -1.4612591  -0.15923232 -0.27373296 -1.2786535\n",
      " -0.09697072 -0.24614668 -1.3559965  -0.05235951 -0.2511168  -1.471987\n",
      "  0.03351507 -0.26580524 -1.3046184 ]\n",
      "data: [ 0.02920463 -0.08846061 -0.25226432  0.05141481 -0.22528228 -0.6632796\n",
      " -0.06277768 -0.42604    -1.4504088  -0.21009396 -0.49424466 -1.7405143\n",
      " -0.37678224 -0.5958942  -2.223628   -0.17651111 -0.70477015 -1.6046387\n",
      "  0.01724681 -0.74631274 -1.3895173  -0.03102998 -0.6795564  -1.4448541\n",
      " -0.04875886 -0.8225462  -1.5646961  -0.13818437 -0.6011196  -1.5180134\n",
      " -0.07142089 -0.65621215 -1.4800673  -0.09075962 -0.6296723  -1.5683457\n",
      "  0.0447408  -0.6492218  -1.6079472  -0.05835928 -0.51060575 -1.349816\n",
      " -0.18486366 -0.2803796  -2.0144234  -0.03007823 -0.43671858 -2.021676\n",
      "  0.12731554 -0.4027593  -1.4612591  -0.15923232 -0.27373296 -1.2786535\n",
      " -0.09697072 -0.24614668 -1.3559966  -0.05235951 -0.2511168  -1.471987\n",
      "  0.03351507 -0.26580524 -1.3046184   0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EC24D30>\n",
      "tensor([[-0.0057, -0.0406, -0.2050,  ...,  0.0381, -0.2301, -1.2473],\n",
      "        [-0.0057, -0.0406, -0.2050,  ...,  0.0381, -0.2301, -1.2473],\n",
      "        [-0.0057, -0.0406, -0.2050,  ...,  0.0381, -0.2301, -1.2473],\n",
      "        ...,\n",
      "        [-0.1839,  0.3584, -0.1936,  ..., -0.8615,  0.8209, -0.3876],\n",
      "        [-0.1485, -0.1782,  0.5604,  ..., -0.2410,  0.5494,  0.2572],\n",
      "        [-0.1485, -0.1782,  0.5604,  ..., -0.2410,  0.5494,  0.2572]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.00574155 -0.04064157 -0.20495477  0.0074045  -0.18337367 -0.6075455\n",
      " -0.06442695 -0.36307892 -1.3329538  -0.20573494 -0.42080474 -1.6403842\n",
      " -0.3802992  -0.5471077  -2.102023   -0.21422137 -0.64354336 -1.5047826\n",
      "  0.0258828  -0.67049015 -1.3180472  -0.02914667 -0.6145667  -1.3690188\n",
      " -0.02479465 -0.7458689  -1.4860171  -0.16351357 -0.5346724  -1.4163653\n",
      " -0.06906635 -0.5947459  -1.3990446  -0.07174318 -0.57322156 -1.4993758\n",
      "  0.053929   -0.6056256  -1.5508785  -0.06121986 -0.4470584  -1.2427602\n",
      " -0.17724852 -0.22528777 -1.8889731  -0.01685116 -0.38762674 -1.8824506\n",
      "  0.13882397 -0.3539789  -1.4023173  -0.17010121 -0.21021438 -1.181607\n",
      " -0.07458717 -0.19440383 -1.2618905  -0.02846988 -0.21915364 -1.380451\n",
      "  0.03809079 -0.23014332 -1.2472887 ]\n",
      "data: [-0.00574155 -0.04064157 -0.20495477  0.0074045  -0.18337367 -0.6075455\n",
      " -0.06442695 -0.36307892 -1.3329538  -0.20573494 -0.42080474 -1.6403842\n",
      " -0.3802992  -0.5471077  -2.102023   -0.21422139 -0.6435434  -1.5047826\n",
      "  0.0258828  -0.6704901  -1.3180472  -0.02914667 -0.6145667  -1.3690189\n",
      " -0.02479465 -0.7458689  -1.4860171  -0.16351357 -0.5346724  -1.4163651\n",
      " -0.06906635 -0.5947459  -1.3990446  -0.07174318 -0.57322156 -1.4993758\n",
      "  0.053929   -0.6056256  -1.5508786  -0.06121986 -0.4470584  -1.2427602\n",
      " -0.17724852 -0.22528777 -1.8889731  -0.01685116 -0.38762674 -1.8824506\n",
      "  0.13882397 -0.35397893 -1.4023174  -0.17010121 -0.21021439 -1.181607\n",
      " -0.07458717 -0.19440383 -1.2618905  -0.02846988 -0.21915363 -1.3804508\n",
      "  0.03809079 -0.23014332 -1.2472887   0.19      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0097, -0.0601, -0.2518,  ...,  0.0116, -0.2403, -1.2922],\n",
      "        [ 0.0097, -0.0601, -0.2518,  ...,  0.0116, -0.2403, -1.2922],\n",
      "        [ 0.0097, -0.0601, -0.2518,  ...,  0.0116, -0.2403, -1.2922],\n",
      "        ...,\n",
      "        [-0.3420,  0.2331, -0.3372,  ..., -0.8213,  0.6778, -0.5187],\n",
      "        [-0.1071, -0.0546,  0.6251,  ..., -0.2148,  0.7396,  0.2840],\n",
      "        [-0.1071, -0.0546,  0.6251,  ..., -0.2148,  0.7396,  0.2840]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00965337 -0.06014431 -0.25178576  0.0365099  -0.18602896 -0.6511396\n",
      " -0.08320934 -0.38038123 -1.4356712  -0.22693649 -0.44614133 -1.7191203\n",
      " -0.38137752 -0.5362582  -2.2135122  -0.18318549 -0.6753818  -1.585106\n",
      " -0.01616012 -0.71574557 -1.4107072  -0.06162827 -0.6446952  -1.4709274\n",
      " -0.07226404 -0.79257643 -1.5888387  -0.14995259 -0.5815363  -1.5029416\n",
      " -0.08936834 -0.62885743 -1.467853   -0.11475205 -0.59954256 -1.5550371\n",
      "  0.02227094 -0.6161338  -1.5870327  -0.07983735 -0.4892879  -1.3406116\n",
      " -0.20193967 -0.25893825 -2.0101824  -0.05018073 -0.40813684 -2.0262856\n",
      "  0.10482802 -0.38006425 -1.4490161  -0.17444605 -0.25961947 -1.269385\n",
      " -0.12139574 -0.23030823 -1.3487222  -0.08324679 -0.224626   -1.4660519\n",
      "  0.01164335 -0.24034831 -1.2922077 ]\n",
      "data: [ 0.00965337 -0.06014431 -0.25178576  0.0365099  -0.18602896 -0.6511396\n",
      " -0.08320934 -0.38038123 -1.4356712  -0.22693649 -0.44614133 -1.7191204\n",
      " -0.38137752 -0.5362582  -2.2135122  -0.18318549 -0.6753818  -1.585106\n",
      " -0.01616012 -0.71574557 -1.4107072  -0.06162827 -0.6446952  -1.4709275\n",
      " -0.07226404 -0.79257643 -1.5888387  -0.14995259 -0.5815363  -1.5029416\n",
      " -0.08936834 -0.62885743 -1.467853   -0.11475205 -0.59954256 -1.555037\n",
      "  0.02227094 -0.6161338  -1.5870327  -0.07983735 -0.4892879  -1.3406116\n",
      " -0.20193967 -0.25893825 -2.0101824  -0.05018073 -0.4081368  -2.0262856\n",
      "  0.10482802 -0.38006425 -1.4490161  -0.17444605 -0.25961947 -1.269385\n",
      " -0.12139574 -0.23030823 -1.3487222  -0.0832468  -0.224626   -1.4660519\n",
      "  0.01164335 -0.2403483  -1.2922076   0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[ 0.0407, -0.0223, -0.2017,  ...,  0.0538, -0.2177, -1.2388],\n",
      "        [ 0.0407, -0.0223, -0.2017,  ...,  0.0538, -0.2177, -1.2388],\n",
      "        [ 0.0407, -0.0223, -0.2017,  ...,  0.0538, -0.2177, -1.2388],\n",
      "        ...,\n",
      "        [-0.2207,  0.3271, -0.1879,  ..., -0.9021,  0.7740, -0.3254],\n",
      "        [-0.1492, -0.2213,  0.5179,  ..., -0.2099,  0.5288,  0.2294],\n",
      "        [-0.1492, -0.2213,  0.5179,  ..., -0.2099,  0.5288,  0.2294]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04068564 -0.02226892 -0.20166078  0.05100074 -0.15462005 -0.5924794\n",
      " -0.06170677 -0.33917588 -1.338419   -0.20954025 -0.40430766 -1.6251607\n",
      " -0.38158402 -0.500801   -2.1078842  -0.15386003 -0.64465886 -1.4924672\n",
      "  0.00617813 -0.68435127 -1.3400877  -0.03999756 -0.61022466 -1.4021952\n",
      " -0.03237147 -0.7599564  -1.512125   -0.11622887 -0.54788756 -1.4158998\n",
      " -0.0530078  -0.59386605 -1.3821476  -0.07610276 -0.5720557  -1.4776015\n",
      "  0.06450751 -0.5786118  -1.507026   -0.04352954 -0.46157032 -1.2578244\n",
      " -0.15380877 -0.23976858 -1.9061115  -0.00985651 -0.38215607 -1.9192252\n",
      "  0.14938527 -0.35919237 -1.3777728  -0.13265562 -0.23081216 -1.195853\n",
      " -0.08098725 -0.21055308 -1.2866325  -0.04545341 -0.20326845 -1.4044282\n",
      "  0.05384505 -0.21769258 -1.2388291 ]\n",
      "data: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "mask: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[-0.0333,  0.0448,  0.4349,  ..., -0.2319, -0.0727, -0.3665],\n",
      "        [-0.0333,  0.0448,  0.4349,  ..., -0.2319, -0.0727, -0.3665],\n",
      "        [-0.0333,  0.0448,  0.4349,  ..., -0.2319, -0.0727, -0.3665],\n",
      "        ...,\n",
      "        [ 0.3777,  0.0338, -0.4249,  ...,  0.2617,  0.7308, -0.4466],\n",
      "        [ 0.3953,  0.0267, -0.4035,  ...,  0.2826,  0.7878, -0.4917],\n",
      "        [ 0.3953,  0.0267, -0.4035,  ...,  0.2826,  0.7878, -0.4917]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.03331171  0.04475227  0.43488228 -0.08014037 -0.1283966   0.04251438\n",
      " -0.43275732 -0.30288675 -0.52919793 -0.6339379  -0.4416606  -0.64817005\n",
      " -0.92006445 -0.45257625 -1.0338042  -0.32898337 -0.5638237  -0.5347692\n",
      " -0.48484027 -0.5967127  -0.22969621 -0.4647954  -0.4992316  -0.28106982\n",
      " -0.5385193  -0.63992906 -0.29921997 -0.30783296 -0.44557652 -0.56127876\n",
      " -0.40865445 -0.4935944  -0.37488335 -0.53361404 -0.46619457 -0.43082047\n",
      " -0.28280222 -0.36111313 -0.51204956 -0.349191   -0.46142566 -0.4435553\n",
      " -0.3940547  -0.24101767 -0.6121369  -0.40089983 -0.258882   -0.64137584\n",
      " -0.26609105 -0.26819363 -0.39044648 -0.29307145 -0.20285279 -0.41877973\n",
      " -0.48265147 -0.14345443 -0.4460817  -0.39757866 -0.02279501 -0.5691981\n",
      " -0.23187025 -0.07268029 -0.3664986 ]\n",
      "init: [-0.03331171  0.04475227  0.43488228 -0.08014037 -0.1283966   0.04251438\n",
      " -0.43275732 -0.30288675 -0.52919793 -0.6339379  -0.4416606  -0.64817005\n",
      " -0.92006445 -0.45257625 -1.0338042  -0.32898337 -0.5638237  -0.5347692\n",
      " -0.48484027 -0.5967127  -0.22969621 -0.4647954  -0.4992316  -0.28106982\n",
      " -0.5385193  -0.63992906 -0.29921997 -0.30783296 -0.44557652 -0.56127876\n",
      " -0.40865445 -0.4935944  -0.37488335 -0.53361404 -0.46619457 -0.43082047\n",
      " -0.28280222 -0.36111313 -0.51204956 -0.349191   -0.46142566 -0.4435553\n",
      " -0.3940547  -0.24101767 -0.6121369  -0.40089983 -0.258882   -0.64137584\n",
      " -0.26609105 -0.26819363 -0.39044648 -0.29307145 -0.20285279 -0.41877973\n",
      " -0.48265147 -0.14345443 -0.4460817  -0.39757866 -0.02279501 -0.5691981\n",
      " -0.23187025 -0.07268029 -0.3664986 ]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [-0.03331171  0.04475227  0.43488228 -0.08014037 -0.1283966   0.04251438\n",
      " -0.4327573  -0.30288675 -0.52919793 -0.6339379  -0.4416606  -0.6481701\n",
      " -0.92006445 -0.45257625 -1.0338042  -0.3289834  -0.5638237  -0.5347692\n",
      " -0.48484027 -0.5967127  -0.22969621 -0.4647954  -0.4992316  -0.28106982\n",
      " -0.5385193  -0.63992906 -0.29921997 -0.30783296 -0.44557652 -0.56127876\n",
      " -0.40865445 -0.4935944  -0.37488335 -0.53361404 -0.46619457 -0.43082047\n",
      " -0.28280222 -0.36111313 -0.51204956 -0.349191   -0.46142566 -0.4435553\n",
      " -0.3940547  -0.24101767 -0.6121369  -0.4008998  -0.258882   -0.6413758\n",
      " -0.26609105 -0.26819363 -0.39044648 -0.29307145 -0.20285279 -0.41877973\n",
      " -0.48265147 -0.14345443 -0.4460817  -0.39757866 -0.02279501 -0.5691981\n",
      " -0.23187025 -0.07268029 -0.3664986   0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0976, -0.1282, -0.0014,  ..., -0.1768, -0.3206, -0.4777],\n",
      "        [ 0.0976, -0.1282, -0.0014,  ..., -0.1768, -0.3206, -0.4777],\n",
      "        [ 0.0976, -0.1282, -0.0014,  ..., -0.1768, -0.3206, -0.4777],\n",
      "        ...,\n",
      "        [ 0.3807, -0.3220,  0.1800,  ...,  0.0255,  0.4814, -0.7080],\n",
      "        [ 0.2470, -0.0607,  0.3909,  ..., -0.2374,  0.5988, -0.3907],\n",
      "        [ 0.2470, -0.0607,  0.3909,  ..., -0.2374,  0.5988, -0.3907]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.09764333 -0.12818111 -0.00139142  0.01448007 -0.21023431 -0.21530163\n",
      " -0.19374429 -0.3714562  -0.6253542  -0.37554568 -0.43195403 -0.8070229\n",
      " -0.6704508  -0.44929424 -1.1941503  -0.23161386 -0.6267141  -0.80595434\n",
      " -0.49900675 -0.64790744 -1.1695795  -0.50235474 -0.5776095  -1.1860143\n",
      " -0.41920716 -0.7813401  -1.1322979  -0.17645065 -0.54897135 -0.7414032\n",
      " -0.28347117 -0.59008485 -0.56041884 -0.39183152 -0.6059165  -0.66071415\n",
      " -0.27003443 -0.5561799  -0.7184459  -0.17070954 -0.496056   -0.6637727\n",
      " -0.30694145 -0.41535404 -0.9040673  -0.271919   -0.47494265 -0.9372133\n",
      " -0.24233057 -0.4594384  -0.5834764  -0.14623041 -0.35705602 -0.6308223\n",
      " -0.28953373 -0.35680002 -0.5369657  -0.25904596 -0.32209873 -0.6326524\n",
      " -0.17676057 -0.32056063 -0.47769672]\n",
      "data: [ 0.09764333 -0.12818111 -0.00139142  0.01448007 -0.21023431 -0.21530163\n",
      " -0.19374427 -0.37145624 -0.6253542  -0.37554568 -0.43195403 -0.8070229\n",
      " -0.6704508  -0.44929424 -1.1941503  -0.23161386 -0.6267141  -0.80595434\n",
      " -0.49900672 -0.64790744 -1.1695795  -0.50235474 -0.5776095  -1.1860143\n",
      " -0.41920716 -0.7813401  -1.1322979  -0.17645065 -0.54897135 -0.7414032\n",
      " -0.28347117 -0.59008485 -0.56041884 -0.39183152 -0.6059165  -0.6607141\n",
      " -0.27003443 -0.5561799  -0.7184459  -0.17070954 -0.496056   -0.66377276\n",
      " -0.30694145 -0.41535404 -0.9040673  -0.271919   -0.47494265 -0.9372133\n",
      " -0.24233057 -0.4594384  -0.5834764  -0.14623041 -0.35705602 -0.6308223\n",
      " -0.28953373 -0.3568     -0.5369657  -0.25904596 -0.32209873 -0.6326524\n",
      " -0.17676058 -0.32056063 -0.47769672  0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0900,  0.1017, -0.2073,  ...,  0.3068, -0.1375, -1.1475],\n",
      "        [ 0.0900,  0.1017, -0.2073,  ...,  0.3068, -0.1375, -1.1475],\n",
      "        [ 0.0900,  0.1017, -0.2073,  ...,  0.3068, -0.1375, -1.1475],\n",
      "        ...,\n",
      "        [ 0.1401, -0.4187,  0.1613,  ...,  0.3673,  0.7864, -0.4577],\n",
      "        [-0.1169,  0.0864,  0.2130,  ..., -0.8328,  0.7281, -0.1858],\n",
      "        [-0.1169,  0.0864,  0.2130,  ..., -0.8328,  0.7281, -0.1858]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.09004354  0.10170863 -0.2072531   0.10468787  0.00330134 -0.5347936\n",
      "  0.00726356 -0.16720459 -1.1657598  -0.10037886 -0.2120057  -1.4103525\n",
      " -0.22976235 -0.3165544  -1.8076682  -0.07890822 -0.4489165  -1.3445523\n",
      "  0.10811283 -0.4684853  -1.2729223   0.13283332 -0.36777702 -1.302366\n",
      "  0.21368803 -0.50388235 -1.3826895  -0.02680372 -0.36518514 -1.2833881\n",
      "  0.09790829 -0.41684842 -1.2526379   0.16122824 -0.3782552  -1.2983732\n",
      "  0.37268096 -0.39036024 -1.3855743   0.09173962 -0.3243102  -1.1600358\n",
      "  0.02003389 -0.08915249 -1.7330775   0.2276017  -0.2581452  -1.7140632\n",
      "  0.43774143 -0.18318337 -1.3041556  -0.00486229 -0.11566274 -1.0981929\n",
      "  0.09842834 -0.07345021 -1.1778378   0.20156622 -0.10605052 -1.2936413\n",
      "  0.30680764 -0.13745171 -1.1474593 ]\n",
      "data: [ 0.09004354  0.10170863 -0.2072531   0.10468787  0.00330134 -0.5347936\n",
      "  0.00726356 -0.16720459 -1.1657598  -0.10037886 -0.2120057  -1.4103525\n",
      " -0.22976235 -0.3165544  -1.8076682  -0.07890822 -0.44891652 -1.3445523\n",
      "  0.10811283 -0.4684853  -1.2729223   0.13283332 -0.36777702 -1.302366\n",
      "  0.21368803 -0.50388235 -1.3826895  -0.02680372 -0.36518514 -1.283388\n",
      "  0.09790829 -0.41684842 -1.2526379   0.16122824 -0.3782552  -1.2983732\n",
      "  0.37268096 -0.39036024 -1.3855743   0.09173962 -0.3243102  -1.1600358\n",
      "  0.02003389 -0.08915249 -1.7330775   0.2276017  -0.2581452  -1.7140632\n",
      "  0.43774143 -0.18318337 -1.3041556  -0.00486229 -0.11566274 -1.0981929\n",
      "  0.09842834 -0.07345021 -1.1778378   0.20156622 -0.10605052 -1.2936413\n",
      "  0.30680764 -0.13745171 -1.1474593   0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.1626, -0.2447, -0.2165,  ...,  0.1342, -0.3837, -1.3979],\n",
      "        [ 0.1626, -0.2447, -0.2165,  ...,  0.1342, -0.3837, -1.3979],\n",
      "        [ 0.1626, -0.2447, -0.2165,  ...,  0.1342, -0.3837, -1.3979],\n",
      "        ...,\n",
      "        [-0.3962,  0.3155, -0.2418,  ..., -0.9098,  0.8485, -0.5920],\n",
      "        [-0.1954,  0.1442,  0.4025,  ..., -0.1335,  0.9645,  0.0509],\n",
      "        [-0.1954,  0.1442,  0.4025,  ..., -0.1335,  0.9645,  0.0509]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.16259731 -0.24474892 -0.21654204  0.17051058 -0.42394608 -0.75639176\n",
      "  0.1134444  -0.5734697  -1.4409375  -0.03744851 -0.6310879  -1.7440678\n",
      " -0.24560687 -0.75492847 -2.2096317  -0.07778284 -0.8134382  -1.6215749\n",
      "  0.17727114 -0.8176117  -1.3409047   0.13588884 -0.75505805 -1.3899015\n",
      "  0.12326978 -0.8522508  -1.492666   -0.03816712 -0.68302584 -1.5522274\n",
      "  0.0609953  -0.7390543  -1.5093521   0.04989593 -0.7221918  -1.6149815\n",
      "  0.17674719 -0.7207309  -1.6925542   0.05065572 -0.6286533  -1.3766742\n",
      " -0.02669583 -0.39854333 -1.8704634   0.09021126 -0.5355292  -1.8423752\n",
      "  0.22470109 -0.49820426 -1.535238   -0.03708974 -0.37536836 -1.3240654\n",
      "  0.03305179 -0.35118255 -1.382289    0.09875719 -0.37684909 -1.4995192\n",
      "  0.13417494 -0.3836607  -1.3978517 ]\n",
      "data: [ 0.16259731 -0.24474892 -0.21654204  0.17051058 -0.42394608 -0.75639176\n",
      "  0.1134444  -0.5734697  -1.4409375  -0.03744851 -0.6310879  -1.7440678\n",
      " -0.24560685 -0.7549284  -2.2096317  -0.07778284 -0.8134382  -1.6215749\n",
      "  0.17727114 -0.8176117  -1.3409047   0.13588884 -0.75505805 -1.3899016\n",
      "  0.12326977 -0.8522508  -1.492666   -0.03816712 -0.68302584 -1.5522274\n",
      "  0.0609953  -0.7390543  -1.5093521   0.04989593 -0.72219175 -1.6149815\n",
      "  0.17674719 -0.7207309  -1.6925541   0.05065572 -0.6286533  -1.3766742\n",
      " -0.02669583 -0.39854333 -1.8704634   0.09021126 -0.5355292  -1.8423752\n",
      "  0.2247011  -0.49820426 -1.535238   -0.03708974 -0.37536836 -1.3240654\n",
      "  0.03305179 -0.35118255 -1.3822892   0.09875719 -0.37684909 -1.4995192\n",
      "  0.13417494 -0.3836607  -1.3978517   0.04      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0014, -0.2214, -0.1263,  ...,  0.0219, -0.4075, -1.1864],\n",
      "        [-0.0014, -0.2214, -0.1263,  ...,  0.0219, -0.4075, -1.1864],\n",
      "        [-0.0014, -0.2214, -0.1263,  ...,  0.0219, -0.4075, -1.1864],\n",
      "        ...,\n",
      "        [ 0.0067,  0.6645, -0.2338,  ..., -0.3585,  1.1325, -0.6183],\n",
      "        [-0.0874,  0.0135,  0.6353,  ..., -0.0416,  0.7029,  0.2584],\n",
      "        [-0.0874,  0.0135,  0.6353,  ..., -0.0416,  0.7029,  0.2584]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-1.3944982e-03 -2.2139496e-01 -1.2627394e-01  2.3896504e-02\n",
      " -3.5566261e-01 -4.8942316e-01 -6.1672233e-02 -5.7245290e-01\n",
      " -1.3055301e+00 -2.1586958e-01 -6.4056301e-01 -1.6239984e+00\n",
      " -3.9545536e-01 -7.6506054e-01 -2.1170881e+00 -2.1994479e-01\n",
      " -8.3480060e-01 -1.5171304e+00  3.2335058e-02 -8.9029098e-01\n",
      " -1.2990570e+00 -3.5176113e-02 -8.3683205e-01 -1.3376410e+00\n",
      " -5.8789648e-02 -9.8474634e-01 -1.4589331e+00 -1.6269988e-01\n",
      " -7.2757673e-01 -1.4053984e+00 -8.0031395e-02 -8.0164874e-01\n",
      " -1.3744018e+00 -9.1910936e-02 -7.8105390e-01 -1.4764490e+00\n",
      "  1.6207248e-02 -8.2567239e-01 -1.5186138e+00 -5.7775117e-02\n",
      " -6.2455750e-01 -1.2261112e+00 -2.0671402e-01 -4.0292698e-01\n",
      " -1.9258494e+00 -3.7350178e-02 -5.8595496e-01 -1.9243019e+00\n",
      "  1.1297764e-01 -5.4334009e-01 -1.3564241e+00 -1.8654317e-01\n",
      " -3.8413808e-01 -1.1533756e+00 -8.6353734e-02 -3.6845621e-01\n",
      " -1.2241373e+00 -4.1480303e-02 -4.0528905e-01 -1.3338790e+00\n",
      "  2.1869339e-02 -4.0752119e-01 -1.1863778e+00]\n",
      "data: [-1.3944982e-03 -2.2139496e-01 -1.2627394e-01  2.3896504e-02\n",
      " -3.5566261e-01 -4.8942316e-01 -6.1672233e-02 -5.7245290e-01\n",
      " -1.3055301e+00 -2.1586958e-01 -6.4056307e-01 -1.6239984e+00\n",
      " -3.9545536e-01 -7.6506060e-01 -2.1170881e+00 -2.1994478e-01\n",
      " -8.3480054e-01 -1.5171304e+00  3.2335058e-02 -8.9029098e-01\n",
      " -1.2990570e+00 -3.5176113e-02 -8.3683205e-01 -1.3376410e+00\n",
      " -5.8789648e-02 -9.8474634e-01 -1.4589331e+00 -1.6269988e-01\n",
      " -7.2757673e-01 -1.4053984e+00 -8.0031395e-02 -8.0164874e-01\n",
      " -1.3744018e+00 -9.1910936e-02 -7.8105390e-01 -1.4764490e+00\n",
      "  1.6207248e-02 -8.2567239e-01 -1.5186139e+00 -5.7775117e-02\n",
      " -6.2455750e-01 -1.2261112e+00 -2.0671402e-01 -4.0292698e-01\n",
      " -1.9258494e+00 -3.7350178e-02 -5.8595496e-01 -1.9243019e+00\n",
      "  1.1297764e-01 -5.4334009e-01 -1.3564241e+00 -1.8654317e-01\n",
      " -3.8413808e-01 -1.1533756e+00 -8.6353734e-02 -3.6845624e-01\n",
      " -1.2241373e+00 -4.1480303e-02 -4.0528905e-01 -1.3338790e+00\n",
      "  2.1869339e-02 -4.0752116e-01 -1.1863778e+00  5.0000001e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[-0.0126, -0.0440, -0.2498,  ..., -0.0144, -0.2194, -1.2621],\n",
      "        [-0.0126, -0.0440, -0.2498,  ..., -0.0144, -0.2194, -1.2621],\n",
      "        [-0.0126, -0.0440, -0.2498,  ..., -0.0144, -0.2194, -1.2621],\n",
      "        ...,\n",
      "        [-0.1622,  0.4425,  0.0162,  ..., -0.4609,  1.0799, -0.4565],\n",
      "        [ 0.0126,  0.0322,  0.7024,  ..., -0.0314,  0.6517,  0.3784],\n",
      "        [ 0.0126,  0.0322,  0.7024,  ..., -0.0314,  0.6517,  0.3784]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01260016 -0.04402129 -0.24975152  0.01478846 -0.15472816 -0.5266131\n",
      " -0.12502363 -0.39141747 -1.3883462  -0.28649244 -0.4564404  -1.6764512\n",
      " -0.44515777 -0.5470189  -2.1928806  -0.21939155 -0.6873365  -1.5933857\n",
      " -0.04077457 -0.75610626 -1.4431407  -0.09004906 -0.6806608  -1.4832897\n",
      " -0.08545484 -0.8435774  -1.6042371  -0.17609191 -0.5906966  -1.4917936\n",
      " -0.11457139 -0.64559436 -1.4508238  -0.11473942 -0.609194   -1.5363119\n",
      "  0.02967812 -0.6430152  -1.5548451  -0.08876392 -0.47219065 -1.336669\n",
      " -0.25466174 -0.23785785 -2.0866678  -0.06368307 -0.41475224 -2.1103518\n",
      "  0.1194841  -0.36610073 -1.4301422  -0.22323063 -0.2350219  -1.257385\n",
      " -0.15236887 -0.2039865  -1.3396013  -0.12047899 -0.21180402 -1.4516761\n",
      " -0.01440995 -0.21942571 -1.2620718 ]\n",
      "data: [-0.01260016 -0.04402129 -0.24975152  0.01478846 -0.15472816 -0.5266131\n",
      " -0.12502363 -0.39141747 -1.3883462  -0.28649244 -0.4564404  -1.6764512\n",
      " -0.44515777 -0.5470189  -2.1928806  -0.21939155 -0.6873365  -1.5933856\n",
      " -0.04077457 -0.75610626 -1.4431407  -0.09004906 -0.6806608  -1.4832898\n",
      " -0.08545484 -0.84357744 -1.6042371  -0.17609192 -0.5906966  -1.4917936\n",
      " -0.11457139 -0.64559436 -1.4508238  -0.11473942 -0.609194   -1.5363117\n",
      "  0.02967812 -0.6430152  -1.5548451  -0.08876392 -0.47219068 -1.336669\n",
      " -0.25466174 -0.23785786 -2.0866678  -0.06368307 -0.41475224 -2.1103518\n",
      "  0.1194841  -0.36610073 -1.4301422  -0.22323063 -0.23502189 -1.257385\n",
      " -0.15236887 -0.2039865  -1.3396013  -0.120479   -0.211804   -1.4516761\n",
      " -0.01440995 -0.21942572 -1.2620718   0.06      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BB38>\n",
      "tensor([[ 0.0241, -0.0234, -0.1925,  ...,  0.0487, -0.2037, -1.2475],\n",
      "        [ 0.0241, -0.0234, -0.1925,  ...,  0.0487, -0.2037, -1.2475],\n",
      "        [ 0.0241, -0.0234, -0.1925,  ...,  0.0487, -0.2037, -1.2475],\n",
      "        ...,\n",
      "        [-0.2241,  0.2757, -0.0837,  ..., -0.8886,  0.7851, -0.3009],\n",
      "        [-0.1668, -0.1511,  0.5197,  ..., -0.2715,  0.5750,  0.2545],\n",
      "        [-0.1668, -0.1511,  0.5197,  ..., -0.2715,  0.5750,  0.2545]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.4095450e-02 -2.3397317e-02 -1.9246504e-01  3.6783312e-02\n",
      " -1.6441725e-01 -6.0392940e-01 -4.2973556e-02 -3.3719155e-01\n",
      " -1.3340273e+00 -1.8918999e-01 -3.9412382e-01 -1.6379774e+00\n",
      " -3.6821616e-01 -5.1253116e-01 -2.1097999e+00 -1.8746799e-01\n",
      " -6.2799186e-01 -1.4924631e+00  4.1402489e-02 -6.5166652e-01\n",
      " -1.3033230e+00 -1.1073619e-02 -5.8972663e-01 -1.3564935e+00\n",
      " -7.5356439e-03 -7.1693379e-01 -1.4738281e+00 -1.4160079e-01\n",
      " -5.2175683e-01 -1.4072740e+00 -5.0551347e-02 -5.7420695e-01\n",
      " -1.3881953e+00 -5.4612584e-02 -5.4588443e-01 -1.4897521e+00\n",
      "  7.8031853e-02 -5.7079208e-01 -1.5400798e+00 -4.5987733e-02\n",
      " -4.3723911e-01 -1.2351930e+00 -1.5537095e-01 -2.0841861e-01\n",
      " -1.8606520e+00 -5.9393793e-04 -3.6003166e-01 -1.8570783e+00\n",
      "  1.5815663e-01 -3.2823038e-01 -1.3971918e+00 -1.5282506e-01\n",
      " -1.9761012e-01 -1.1739750e+00 -6.6620931e-02 -1.7802325e-01\n",
      " -1.2591355e+00 -2.2320703e-02 -1.9408941e-01 -1.3791182e+00\n",
      "  4.8713304e-02 -2.0370828e-01 -1.2475183e+00]\n",
      "data: [ 2.4095450e-02 -2.3397317e-02 -1.9246504e-01  3.6783312e-02\n",
      " -1.6441725e-01 -6.0392940e-01 -4.2973556e-02 -3.3719155e-01\n",
      " -1.3340273e+00 -1.8918999e-01 -3.9412385e-01 -1.6379772e+00\n",
      " -3.6821616e-01 -5.1253116e-01 -2.1097999e+00 -1.8746799e-01\n",
      " -6.2799186e-01 -1.4924631e+00  4.1402489e-02 -6.5166646e-01\n",
      " -1.3033230e+00 -1.1073619e-02 -5.8972663e-01 -1.3564935e+00\n",
      " -7.5356434e-03 -7.1693385e-01 -1.4738281e+00 -1.4160079e-01\n",
      " -5.2175683e-01 -1.4072740e+00 -5.0551347e-02 -5.7420695e-01\n",
      " -1.3881954e+00 -5.4612584e-02 -5.4588443e-01 -1.4897521e+00\n",
      "  7.8031853e-02 -5.7079208e-01 -1.5400798e+00 -4.5987736e-02\n",
      " -4.3723911e-01 -1.2351930e+00 -1.5537095e-01 -2.0841862e-01\n",
      " -1.8606520e+00 -5.9393793e-04 -3.6003166e-01 -1.8570782e+00\n",
      "  1.5815663e-01 -3.2823035e-01 -1.3971918e+00 -1.5282506e-01\n",
      " -1.9761012e-01 -1.1739750e+00 -6.6620931e-02 -1.7802325e-01\n",
      " -1.2591355e+00 -2.2320703e-02 -1.9408941e-01 -1.3791182e+00\n",
      "  4.8713304e-02 -2.0370826e-01 -1.2475183e+00  7.0000000e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0102, -0.0693, -0.2598,  ...,  0.0176, -0.2459, -1.3157],\n",
      "        [ 0.0102, -0.0693, -0.2598,  ...,  0.0176, -0.2459, -1.3157],\n",
      "        [ 0.0102, -0.0693, -0.2598,  ...,  0.0176, -0.2459, -1.3157],\n",
      "        ...,\n",
      "        [-0.3330,  0.2517, -0.2988,  ..., -0.7963,  0.7065, -0.4631],\n",
      "        [-0.1239, -0.0322,  0.6275,  ..., -0.2299,  0.7668,  0.3044],\n",
      "        [-0.1239, -0.0322,  0.6275,  ..., -0.2299,  0.7668,  0.3044]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01024572 -0.06931494 -0.2598051   0.03312368 -0.2075434  -0.68211603\n",
      " -0.07930832 -0.39508712 -1.4422097  -0.22210291 -0.460741   -1.7198243\n",
      " -0.37954766 -0.5575431  -2.203863   -0.18865076 -0.6795629  -1.5934205\n",
      " -0.01316372 -0.71378154 -1.4135439  -0.0533497  -0.6419605  -1.4709892\n",
      " -0.05412048 -0.7772885  -1.5830765  -0.15499717 -0.5786366  -1.5188525\n",
      " -0.08566172 -0.6265348  -1.4798243  -0.102837   -0.59772456 -1.5636504\n",
      "  0.03792007 -0.6093027  -1.6019843  -0.08149062 -0.4948063  -1.3575823\n",
      " -0.18831497 -0.26535553 -1.9734454  -0.04275692 -0.40987033 -1.9808154\n",
      "  0.11367745 -0.37895876 -1.4695594  -0.17289576 -0.26083225 -1.2903743\n",
      " -0.11604499 -0.23133117 -1.3662765  -0.07049152 -0.23005366 -1.482204\n",
      "  0.01759061 -0.24590851 -1.3157165 ]\n",
      "data: [ 0.01024572 -0.06931494 -0.2598051   0.03312368 -0.20754342 -0.68211603\n",
      " -0.07930832 -0.39508712 -1.4422097  -0.22210291 -0.460741   -1.7198243\n",
      " -0.37954766 -0.5575431  -2.203863   -0.18865076 -0.6795629  -1.5934205\n",
      " -0.01316372 -0.71378154 -1.413544   -0.0533497  -0.6419605  -1.4709892\n",
      " -0.05412048 -0.7772885  -1.5830765  -0.15499717 -0.5786366  -1.5188526\n",
      " -0.08566172 -0.6265348  -1.4798244  -0.102837   -0.59772456 -1.5636504\n",
      "  0.03792007 -0.6093027  -1.6019843  -0.08149062 -0.4948063  -1.3575824\n",
      " -0.18831497 -0.26535553 -1.9734454  -0.04275693 -0.40987033 -1.9808154\n",
      "  0.11367746 -0.3789588  -1.4695594  -0.17289576 -0.26083225 -1.2903743\n",
      " -0.11604499 -0.23133117 -1.3662765  -0.07049152 -0.23005368 -1.482204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.01759061 -0.24590851 -1.3157165   0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0310, -0.0370, -0.2254,  ...,  0.0422, -0.2325, -1.2599],\n",
      "        [ 0.0310, -0.0370, -0.2254,  ...,  0.0422, -0.2325, -1.2599],\n",
      "        [ 0.0310, -0.0370, -0.2254,  ...,  0.0422, -0.2325, -1.2599],\n",
      "        ...,\n",
      "        [-0.1242,  0.4261, -0.1213,  ..., -0.7403,  0.9402, -0.3746],\n",
      "        [-0.1425, -0.1996,  0.5466,  ..., -0.2242,  0.5669,  0.2386],\n",
      "        [-0.1425, -0.1996,  0.5466,  ..., -0.2242,  0.5669,  0.2386]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03098525 -0.0369584  -0.22536117  0.0457354  -0.1634521  -0.6162344\n",
      " -0.06468469 -0.34620738 -1.3712485  -0.21197489 -0.40877116 -1.6614351\n",
      " -0.37882566 -0.5032124  -2.1528764  -0.16229638 -0.65427005 -1.5283666\n",
      "  0.00432426 -0.69171864 -1.3727202  -0.04136017 -0.61794734 -1.4362378\n",
      " -0.03623128 -0.7666334  -1.550544   -0.1260556  -0.5603209  -1.4475327\n",
      " -0.06136589 -0.60525876 -1.4175541  -0.08286375 -0.58111477 -1.5134637\n",
      "  0.05832118 -0.59067565 -1.5440633  -0.0524356  -0.47312889 -1.2852862\n",
      " -0.16334678 -0.24868193 -1.9304912  -0.01802361 -0.39201474 -1.9440534\n",
      "  0.14322752 -0.36902076 -1.4075608  -0.1451025  -0.24416183 -1.2203326\n",
      " -0.09040126 -0.22229508 -1.3060975  -0.05568475 -0.21716872 -1.4232748\n",
      "  0.04217426 -0.23254047 -1.2598553 ]\n",
      "data: [ 0.03098525 -0.0369584  -0.22536117  0.0457354  -0.1634521  -0.6162344\n",
      " -0.06468469 -0.34620738 -1.3712485  -0.21197489 -0.40877116 -1.6614351\n",
      " -0.3788257  -0.5032124  -2.1528764  -0.16229638 -0.65427    -1.5283666\n",
      "  0.00432426 -0.6917187  -1.3727202  -0.04136017 -0.61794734 -1.4362378\n",
      " -0.03623128 -0.7666334  -1.550544   -0.1260556  -0.5603209  -1.4475327\n",
      " -0.06136589 -0.60525876 -1.4175541  -0.08286375 -0.58111477 -1.5134637\n",
      "  0.05832118 -0.59067565 -1.5440632  -0.0524356  -0.47312889 -1.2852863\n",
      " -0.16334678 -0.24868193 -1.9304912  -0.01802361 -0.39201474 -1.9440533\n",
      "  0.14322752 -0.36902076 -1.4075608  -0.1451025  -0.24416183 -1.2203326\n",
      " -0.09040126 -0.22229508 -1.3060975  -0.05568475 -0.21716872 -1.4232746\n",
      "  0.04217426 -0.23254047 -1.2598553   0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0199, -0.0697, -0.2487,  ...,  0.0320, -0.2531, -1.2927],\n",
      "        [ 0.0199, -0.0697, -0.2487,  ...,  0.0320, -0.2531, -1.2927],\n",
      "        [ 0.0199, -0.0697, -0.2487,  ...,  0.0320, -0.2531, -1.2927],\n",
      "        ...,\n",
      "        [-0.3097,  0.2221, -0.2705,  ..., -0.8127,  0.6871, -0.4634],\n",
      "        [-0.1198, -0.0546,  0.5971,  ..., -0.2316,  0.7330,  0.2658],\n",
      "        [-0.1198, -0.0546,  0.5971,  ..., -0.2316,  0.7330,  0.2658]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01993579 -0.06966496 -0.24868593  0.04546595 -0.20132595 -0.65480894\n",
      " -0.06169572 -0.38936648 -1.4213474  -0.20471168 -0.45474204 -1.707409\n",
      " -0.36309698 -0.5531723  -2.1952357  -0.1739611  -0.67992055 -1.5750332\n",
      "  0.01060649 -0.7160629  -1.3920755  -0.03621762 -0.6476884  -1.4501544\n",
      " -0.04519835 -0.7880746  -1.5663325  -0.13796845 -0.5832308  -1.4938437\n",
      " -0.06822199 -0.6332417  -1.4603218  -0.0903716  -0.604864   -1.5490668\n",
      "  0.04306478 -0.62273866 -1.5850796  -0.06169336 -0.4949101  -1.3288889\n",
      " -0.17586058 -0.26691678 -1.972605   -0.02801518 -0.41588277 -1.9816806\n",
      "  0.12506765 -0.38769275 -1.4466456  -0.15750927 -0.26335585 -1.261453\n",
      " -0.09531512 -0.2372543  -1.3397003  -0.05449202 -0.23855072 -1.4558673\n",
      "  0.03199758 -0.25306916 -1.2926606 ]\n",
      "data: [ 0.01993579 -0.06966496 -0.24868593  0.04546595 -0.20132595 -0.65480894\n",
      " -0.06169572 -0.3893665  -1.4213474  -0.20471169 -0.45474204 -1.707409\n",
      " -0.363097   -0.5531723  -2.1952357  -0.1739611  -0.67992055 -1.5750333\n",
      "  0.01060649 -0.7160629  -1.3920755  -0.03621762 -0.6476884  -1.4501544\n",
      " -0.04519835 -0.7880747  -1.5663323  -0.13796845 -0.5832308  -1.4938437\n",
      " -0.06822199 -0.6332417  -1.4603218  -0.0903716  -0.604864   -1.5490668\n",
      "  0.04306478 -0.62273866 -1.5850796  -0.06169336 -0.4949101  -1.3288889\n",
      " -0.17586058 -0.26691678 -1.972605   -0.02801518 -0.41588277 -1.9816806\n",
      "  0.12506765 -0.38769275 -1.4466456  -0.15750927 -0.26335585 -1.261453\n",
      " -0.09531512 -0.23725432 -1.3397003  -0.05449202 -0.23855072 -1.4558673\n",
      "  0.03199758 -0.25306916 -1.2926605   0.1       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0187, -0.0340, -0.2442,  ...,  0.0442, -0.2280, -1.2735],\n",
      "        [ 0.0187, -0.0340, -0.2442,  ...,  0.0442, -0.2280, -1.2735],\n",
      "        [ 0.0187, -0.0340, -0.2442,  ...,  0.0442, -0.2280, -1.2735],\n",
      "        ...,\n",
      "        [-0.1402,  0.3682, -0.1050,  ..., -0.7597,  0.8633, -0.3519],\n",
      "        [-0.1398, -0.1774,  0.5514,  ..., -0.2241,  0.5857,  0.2216],\n",
      "        [-0.1398, -0.1774,  0.5514,  ..., -0.2241,  0.5857,  0.2216]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0187253  -0.0340382  -0.24415536  0.03442964 -0.163959   -0.6357593\n",
      " -0.06546284 -0.34910768 -1.38576    -0.21017951 -0.41019332 -1.6806914\n",
      " -0.3784844  -0.516016   -2.160459   -0.18052876 -0.6461446  -1.5448583\n",
      "  0.01111954 -0.6821052  -1.3773452  -0.03746217 -0.61397254 -1.4355869\n",
      " -0.03325067 -0.7581028  -1.5510861  -0.13857403 -0.5482849  -1.4597867\n",
      " -0.06493092 -0.5990529  -1.4332521  -0.07838099 -0.5752411  -1.5285146\n",
      "  0.05787501 -0.59343493 -1.5657237  -0.05484162 -0.46058643 -1.2936817\n",
      " -0.17032844 -0.23605642 -1.9470209  -0.01595812 -0.3881109  -1.9539549\n",
      "  0.14444256 -0.3599206  -1.4251697  -0.1539166  -0.22981551 -1.229129\n",
      " -0.08462662 -0.20924242 -1.313206   -0.0444864  -0.21470958 -1.4300601\n",
      "  0.04417196 -0.2280462  -1.273493  ]\n",
      "data: [ 0.0187253  -0.0340382  -0.24415536  0.03442964 -0.16395898 -0.6357593\n",
      " -0.06546284 -0.34910765 -1.3857598  -0.21017951 -0.41019332 -1.6806914\n",
      " -0.37848437 -0.516016   -2.160459   -0.18052876 -0.6461446  -1.5448585\n",
      "  0.01111954 -0.6821052  -1.3773453  -0.03746217 -0.61397254 -1.4355868\n",
      " -0.03325067 -0.7581028  -1.5510861  -0.13857403 -0.5482849  -1.4597867\n",
      " -0.06493092 -0.5990529  -1.4332521  -0.07838099 -0.5752411  -1.5285145\n",
      "  0.05787501 -0.59343493 -1.5657238  -0.05484162 -0.46058643 -1.2936817\n",
      " -0.17032844 -0.23605642 -1.9470209  -0.01595812 -0.38811094 -1.9539549\n",
      "  0.14444256 -0.3599206  -1.4251697  -0.1539166  -0.22981553 -1.229129\n",
      " -0.08462663 -0.20924242 -1.3132061  -0.04448639 -0.21470958 -1.4300601\n",
      "  0.04417196 -0.2280462  -1.273493    0.11      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0132, -0.0842, -0.2445,  ...,  0.0303, -0.2682, -1.3034],\n",
      "        [ 0.0132, -0.0842, -0.2445,  ...,  0.0303, -0.2682, -1.3034],\n",
      "        [ 0.0132, -0.0842, -0.2445,  ...,  0.0303, -0.2682, -1.3034],\n",
      "        ...,\n",
      "        [-0.3820,  0.1613, -0.3620,  ..., -0.8460,  0.5785, -0.5050],\n",
      "        [-0.1389, -0.0780,  0.5941,  ..., -0.2411,  0.7120,  0.2555],\n",
      "        [-0.1389, -0.0780,  0.5941,  ..., -0.2411,  0.7120,  0.2555]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01317122 -0.08420759 -0.24447842  0.03387051 -0.22291018 -0.6670164\n",
      " -0.05781015 -0.40272167 -1.4146664  -0.19922587 -0.46573347 -1.707496\n",
      " -0.3650534  -0.57390565 -2.185775   -0.18652824 -0.6884461  -1.5699589\n",
      "  0.01727763 -0.71784186 -1.3798735  -0.03082883 -0.6531759  -1.4372903\n",
      " -0.03544701 -0.7856607  -1.5528088  -0.14727165 -0.5864631  -1.4885563\n",
      " -0.06896251 -0.63815844 -1.4606987  -0.08568815 -0.6128505  -1.5542698\n",
      "  0.04498531 -0.6306838  -1.5992135  -0.06493799 -0.5036864  -1.3195809\n",
      " -0.17197004 -0.27776727 -1.9419552  -0.02732164 -0.42539236 -1.9434358\n",
      "  0.12402959 -0.39702588 -1.4558326  -0.16129605 -0.2691484  -1.2558676\n",
      " -0.0905993  -0.24664025 -1.3354272  -0.04584904 -0.255022   -1.4517472\n",
      "  0.03030748 -0.26821536 -1.3034326 ]\n",
      "data: [ 0.01317122 -0.08420759 -0.24447842  0.03387051 -0.22291018 -0.6670164\n",
      " -0.05781015 -0.40272167 -1.4146664  -0.19922586 -0.46573344 -1.707496\n",
      " -0.36505336 -0.57390565 -2.185775   -0.18652825 -0.6884461  -1.5699589\n",
      "  0.01727763 -0.71784186 -1.3798735  -0.03082883 -0.6531759  -1.4372903\n",
      " -0.03544701 -0.7856607  -1.5528089  -0.14727165 -0.5864631  -1.4885563\n",
      " -0.06896251 -0.63815844 -1.4606987  -0.08568815 -0.6128505  -1.5542697\n",
      "  0.04498531 -0.6306838  -1.5992134  -0.06493799 -0.5036864  -1.3195808\n",
      " -0.17197004 -0.27776727 -1.9419552  -0.02732164 -0.42539233 -1.9434358\n",
      "  0.12402959 -0.39702588 -1.4558327  -0.16129607 -0.2691484  -1.2558676\n",
      " -0.0905993  -0.24664025 -1.335427   -0.04584904 -0.255022   -1.4517472\n",
      "  0.03030748 -0.26821536 -1.3034326   0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0292, -0.0712, -0.2568,  ...,  0.0470, -0.2604, -1.2756],\n",
      "        [ 0.0292, -0.0712, -0.2568,  ...,  0.0470, -0.2604, -1.2756],\n",
      "        [ 0.0292, -0.0712, -0.2568,  ...,  0.0470, -0.2604, -1.2756],\n",
      "        ...,\n",
      "        [-0.1131,  0.4028, -0.1182,  ..., -0.6925,  0.9186, -0.4084],\n",
      "        [-0.1317, -0.1494,  0.5852,  ..., -0.2366,  0.6244,  0.2316],\n",
      "        [-0.1317, -0.1494,  0.5852,  ..., -0.2366,  0.6244,  0.2316]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02916662 -0.07121755 -0.25683823  0.05573737 -0.1874336  -0.6280253\n",
      " -0.061896   -0.38714936 -1.4160516  -0.20724678 -0.45026577 -1.7057368\n",
      " -0.36000913 -0.5431663  -2.2015133  -0.15958752 -0.69123936 -1.5733212\n",
      "  0.01099057 -0.7386838  -1.4203315  -0.04005335 -0.6666436  -1.4796513\n",
      " -0.04582473 -0.8232968  -1.5993981  -0.12081635 -0.6024811  -1.483692\n",
      " -0.06065308 -0.65020525 -1.455825   -0.08193974 -0.6211251  -1.5445349\n",
      "  0.05071092 -0.64407504 -1.5690382  -0.04484559 -0.50279593 -1.321171\n",
      " -0.17687836 -0.27244315 -2.0243282  -0.01500839 -0.42969415 -2.0433455\n",
      "  0.14415224 -0.39983675 -1.4338677  -0.14805438 -0.27652055 -1.2486303\n",
      " -0.08610347 -0.24931505 -1.335945   -0.052626   -0.24709266 -1.4516914\n",
      "  0.04699627 -0.2604264  -1.275606  ]\n",
      "data: [ 0.02916662 -0.07121755 -0.25683823  0.05573737 -0.1874336  -0.6280253\n",
      " -0.061896   -0.38714936 -1.4160516  -0.20724678 -0.45026577 -1.7057366\n",
      " -0.3600091  -0.5431663  -2.2015133  -0.15958752 -0.6912393  -1.5733212\n",
      "  0.01099057 -0.7386839  -1.4203315  -0.04005335 -0.6666436  -1.4796513\n",
      " -0.04582473 -0.8232968  -1.5993981  -0.12081634 -0.6024811  -1.483692\n",
      " -0.06065308 -0.65020525 -1.4558251  -0.08193974 -0.6211251  -1.5445349\n",
      "  0.05071092 -0.64407504 -1.569038   -0.04484559 -0.50279593 -1.3211712\n",
      " -0.17687836 -0.27244315 -2.0243282  -0.01500839 -0.42969415 -2.0433455\n",
      "  0.14415224 -0.39983672 -1.4338677  -0.14805438 -0.27652055 -1.2486303\n",
      " -0.08610347 -0.24931505 -1.335945   -0.052626   -0.24709266 -1.4516914\n",
      "  0.04699627 -0.2604264  -1.275606    0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0230, -0.0372, -0.2422,  ...,  0.0576, -0.2269, -1.2875],\n",
      "        [ 0.0230, -0.0372, -0.2422,  ...,  0.0576, -0.2269, -1.2875],\n",
      "        [ 0.0230, -0.0372, -0.2422,  ...,  0.0576, -0.2269, -1.2875],\n",
      "        ...,\n",
      "        [-0.1597,  0.3064, -0.0638,  ..., -0.8163,  0.7750, -0.2602],\n",
      "        [-0.1439, -0.1477,  0.5407,  ..., -0.2249,  0.6090,  0.2045],\n",
      "        [-0.1439, -0.1477,  0.5407,  ..., -0.2249,  0.6090,  0.2045]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.3042787e-02 -3.7230767e-02 -2.4223529e-01  3.5724577e-02\n",
      " -1.8028998e-01 -6.5864050e-01 -4.0733352e-02 -3.5711950e-01\n",
      " -1.3823895e+00 -1.8318781e-01 -4.1604334e-01 -1.6870021e+00\n",
      " -3.6080936e-01 -5.3784776e-01 -2.1495292e+00 -1.8492353e-01\n",
      " -6.4026117e-01 -1.5435262e+00  4.4981636e-02 -6.6600215e-01\n",
      " -1.3499525e+00 -6.9272146e-03 -6.0652733e-01 -1.4039832e+00\n",
      " -4.6802983e-03 -7.3688364e-01 -1.5198811e+00 -1.3772333e-01\n",
      " -5.3281367e-01 -1.4575163e+00 -4.7519006e-02 -5.8990312e-01\n",
      " -1.4353443e+00 -5.4078214e-02 -5.6793535e-01 -1.5353205e+00\n",
      "  7.5322591e-02 -5.9230816e-01 -1.5865121e+00 -4.1371629e-02\n",
      " -4.4928089e-01 -1.2843589e+00 -1.5145689e-01 -2.2720829e-01\n",
      " -1.9146917e+00  1.9137785e-03 -3.8235337e-01 -1.9087580e+00\n",
      "  1.5758198e-01 -3.5089782e-01 -1.4381639e+00 -1.4449716e-01\n",
      " -2.1268624e-01 -1.2242508e+00 -5.8170266e-02 -1.9572136e-01\n",
      " -1.3048688e+00 -1.1379279e-02 -2.1538013e-01 -1.4227263e+00\n",
      "  5.7570726e-02 -2.2686397e-01 -1.2875177e+00]\n",
      "data: [ 2.3042787e-02 -3.7230767e-02 -2.4223527e-01  3.5724577e-02\n",
      " -1.8029000e-01 -6.5864050e-01 -4.0733352e-02 -3.5711947e-01\n",
      " -1.3823895e+00 -1.8318781e-01 -4.1604337e-01 -1.6870021e+00\n",
      " -3.6080936e-01 -5.3784776e-01 -2.1495292e+00 -1.8492353e-01\n",
      " -6.4026117e-01 -1.5435262e+00  4.4981636e-02 -6.6600209e-01\n",
      " -1.3499523e+00 -6.9272150e-03 -6.0652733e-01 -1.4039834e+00\n",
      " -4.6802983e-03 -7.3688364e-01 -1.5198811e+00 -1.3772333e-01\n",
      " -5.3281367e-01 -1.4575163e+00 -4.7519006e-02 -5.8990312e-01\n",
      " -1.4353443e+00 -5.4078210e-02 -5.6793535e-01 -1.5353206e+00\n",
      "  7.5322591e-02 -5.9230816e-01 -1.5865121e+00 -4.1371629e-02\n",
      " -4.4928089e-01 -1.2843589e+00 -1.5145689e-01 -2.2720829e-01\n",
      " -1.9146916e+00  1.9137785e-03 -3.8235337e-01 -1.9087580e+00\n",
      "  1.5758198e-01 -3.5089782e-01 -1.4381639e+00 -1.4449716e-01\n",
      " -2.1268624e-01 -1.2242508e+00 -5.8170266e-02 -1.9572136e-01\n",
      " -1.3048688e+00 -1.1379279e-02 -2.1538013e-01 -1.4227263e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5.7570726e-02 -2.2686395e-01 -1.2875177e+00  1.4000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0041, -0.0836, -0.2582,  ...,  0.0346, -0.2694, -1.3243],\n",
      "        [ 0.0041, -0.0836, -0.2582,  ...,  0.0346, -0.2694, -1.3243],\n",
      "        [ 0.0041, -0.0836, -0.2582,  ...,  0.0346, -0.2694, -1.3243],\n",
      "        ...,\n",
      "        [-0.1612,  0.4267, -0.1277,  ..., -0.7379,  0.9055, -0.3494],\n",
      "        [-0.1618, -0.1301,  0.5748,  ..., -0.2441,  0.6576,  0.2250],\n",
      "        [-0.1618, -0.1301,  0.5748,  ..., -0.2441,  0.6576,  0.2250]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00407988 -0.08359344 -0.2582027   0.02187051 -0.22928755 -0.6863927\n",
      " -0.05784484 -0.40370727 -1.426588   -0.1973928  -0.46529534 -1.723791\n",
      " -0.36754414 -0.5827589  -2.1953363  -0.19925562 -0.6832558  -1.5873829\n",
      "  0.02424657 -0.706555   -1.3903131  -0.02450652 -0.6442908  -1.4457728\n",
      " -0.02278657 -0.7686751  -1.5609192  -0.15684618 -0.5756391  -1.5057184\n",
      " -0.0677494  -0.6291536  -1.481269   -0.07786174 -0.60508585 -1.5768788\n",
      "  0.05266879 -0.62423277 -1.6291211  -0.06693908 -0.49808642 -1.3321203\n",
      " -0.16779985 -0.27194118 -1.9375144  -0.02313013 -0.4207144  -1.9315535\n",
      "  0.13012919 -0.39059308 -1.4804531  -0.16552384 -0.25997525 -1.2699429\n",
      " -0.08363894 -0.24044001 -1.3478446  -0.03423342 -0.2562467  -1.464148\n",
      "  0.03460834 -0.26935798 -1.3243209 ]\n",
      "data: [ 0.00407988 -0.08359344 -0.2582027   0.02187051 -0.22928755 -0.6863927\n",
      " -0.05784484 -0.40370727 -1.4265882  -0.1973928  -0.46529534 -1.723791\n",
      " -0.36754414 -0.5827589  -2.1953363  -0.19925562 -0.6832558  -1.5873829\n",
      "  0.02424657 -0.706555   -1.3903131  -0.02450652 -0.64429075 -1.4457726\n",
      " -0.02278657 -0.7686751  -1.5609192  -0.15684618 -0.5756391  -1.5057184\n",
      " -0.0677494  -0.6291536  -1.4812691  -0.07786174 -0.60508585 -1.5768788\n",
      "  0.05266879 -0.62423277 -1.6291211  -0.06693908 -0.49808642 -1.3321204\n",
      " -0.16779986 -0.27194118 -1.9375145  -0.02313013 -0.4207144  -1.9315535\n",
      "  0.13012919 -0.39059308 -1.4804531  -0.16552383 -0.25997525 -1.2699429\n",
      " -0.08363894 -0.24044001 -1.3478446  -0.03423342 -0.2562467  -1.464148\n",
      "  0.03460834 -0.26935798 -1.324321    0.15      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0241, -0.0933, -0.2459,  ...,  0.0459, -0.2781, -1.2807],\n",
      "        [ 0.0241, -0.0933, -0.2459,  ...,  0.0459, -0.2781, -1.2807],\n",
      "        [ 0.0241, -0.0933, -0.2459,  ...,  0.0459, -0.2781, -1.2807],\n",
      "        ...,\n",
      "        [-0.1527,  0.3986, -0.1902,  ..., -0.7500,  0.9068, -0.4612],\n",
      "        [-0.1692, -0.1684,  0.5791,  ..., -0.2687,  0.6039,  0.2355],\n",
      "        [-0.1692, -0.1684,  0.5791,  ..., -0.2687,  0.6039,  0.2355]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02405426 -0.09329669 -0.24587399  0.04516376 -0.22385135 -0.6413789\n",
      " -0.05228023 -0.4159141  -1.4008029  -0.19413619 -0.47682616 -1.6946249\n",
      " -0.35476357 -0.5829661  -2.1721427  -0.17270982 -0.7067873  -1.5596671\n",
      "  0.0235682  -0.74467915 -1.3943219  -0.02722746 -0.678051   -1.4503255\n",
      " -0.02631444 -0.8210188  -1.5672812  -0.13112943 -0.607279   -1.4726441\n",
      " -0.0577386  -0.6581544  -1.4470634  -0.07004002 -0.63195837 -1.5378811\n",
      "  0.05928189 -0.65534395 -1.5748246  -0.04646807 -0.5135435  -1.3071845\n",
      " -0.17021157 -0.28638527 -1.9779005  -0.01119384 -0.4428941  -1.9850924\n",
      "  0.14500926 -0.40908748 -1.4369848  -0.15102048 -0.28183347 -1.2394478\n",
      " -0.07761821 -0.2575308  -1.3241556  -0.03760019 -0.26579723 -1.4397407\n",
      "  0.04589526 -0.27813    -1.2807441 ]\n",
      "data: [ 0.02405426 -0.09329669 -0.24587399  0.04516376 -0.22385135 -0.6413789\n",
      " -0.05228023 -0.4159141  -1.400803   -0.19413619 -0.47682616 -1.6946249\n",
      " -0.35476357 -0.5829661  -2.1721427  -0.17270982 -0.7067873  -1.5596671\n",
      "  0.0235682  -0.7446792  -1.3943219  -0.02722746 -0.678051   -1.4503255\n",
      " -0.02631444 -0.8210188  -1.5672812  -0.13112943 -0.607279   -1.4726441\n",
      " -0.0577386  -0.6581544  -1.4470634  -0.07004002 -0.63195837 -1.5378811\n",
      "  0.05928188 -0.65534395 -1.5748246  -0.04646807 -0.5135435  -1.3071845\n",
      " -0.17021157 -0.28638527 -1.9779005  -0.01119384 -0.4428941  -1.9850925\n",
      "  0.14500926 -0.40908748 -1.4369847  -0.15102048 -0.28183347 -1.2394478\n",
      " -0.07761821 -0.2575308  -1.3241556  -0.03760019 -0.26579723 -1.4397407\n",
      "  0.04589526 -0.27813    -1.2807441   0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0203, -0.0423, -0.2425,  ...,  0.0457, -0.2376, -1.2608],\n",
      "        [ 0.0203, -0.0423, -0.2425,  ...,  0.0457, -0.2376, -1.2608],\n",
      "        [ 0.0203, -0.0423, -0.2425,  ...,  0.0457, -0.2376, -1.2608],\n",
      "        ...,\n",
      "        [-0.1507,  0.3545, -0.0864,  ..., -0.7675,  0.8441, -0.3535],\n",
      "        [-0.1277, -0.1458,  0.5647,  ..., -0.1990,  0.6161,  0.2121],\n",
      "        [-0.1277, -0.1458,  0.5647,  ..., -0.1990,  0.6161,  0.2121]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02032201 -0.04232518 -0.24251935  0.03750729 -0.1674389  -0.619884\n",
      " -0.07305197 -0.36381134 -1.3907509  -0.22104084 -0.42669317 -1.6868615\n",
      " -0.38773397 -0.52973783 -2.1714387  -0.17872459 -0.6626768  -1.5492554\n",
      "  0.00834455 -0.70633155 -1.3744185  -0.04324014 -0.6368795  -1.4329362\n",
      " -0.04687808 -0.78968304 -1.5523462  -0.13597015 -0.567352   -1.4596367\n",
      " -0.06841292 -0.6194267  -1.4315226  -0.08480944 -0.5943592  -1.5252087\n",
      "  0.05102829 -0.6158621  -1.5557768  -0.0518491  -0.47231787 -1.2937882\n",
      " -0.17923045 -0.24662167 -1.9799185  -0.01842423 -0.4044822  -1.9916806\n",
      "  0.1449407  -0.37449282 -1.4151249  -0.15448698 -0.24288552 -1.22539\n",
      " -0.08705758 -0.2208285  -1.3118737  -0.05002124 -0.22453347 -1.4285755\n",
      "  0.04565737 -0.23757015 -1.2608013 ]\n",
      "data: [ 0.02032201 -0.04232518 -0.24251933  0.03750729 -0.1674389  -0.619884\n",
      " -0.07305197 -0.36381134 -1.3907509  -0.22104084 -0.42669314 -1.6868615\n",
      " -0.38773397 -0.52973783 -2.1714387  -0.17872459 -0.6626769  -1.5492554\n",
      "  0.00834455 -0.70633155 -1.3744185  -0.04324014 -0.6368795  -1.4329362\n",
      " -0.04687808 -0.7896831  -1.5523462  -0.13597015 -0.567352   -1.4596367\n",
      " -0.06841292 -0.6194267  -1.4315227  -0.08480944 -0.5943592  -1.5252087\n",
      "  0.05102829 -0.6158621  -1.5557768  -0.0518491  -0.47231787 -1.2937882\n",
      " -0.17923047 -0.24662167 -1.9799185  -0.01842423 -0.4044822  -1.9916806\n",
      "  0.1449407  -0.37449282 -1.4151248  -0.15448698 -0.24288552 -1.22539\n",
      " -0.08705758 -0.22082849 -1.3118737  -0.05002124 -0.22453347 -1.4285754\n",
      "  0.04565737 -0.23757015 -1.2608013   0.17      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0097, -0.0175, -0.2367,  ...,  0.0328, -0.2104, -1.2826],\n",
      "        [ 0.0097, -0.0175, -0.2367,  ...,  0.0328, -0.2104, -1.2826],\n",
      "        [ 0.0097, -0.0175, -0.2367,  ...,  0.0328, -0.2104, -1.2826],\n",
      "        ...,\n",
      "        [-0.1950,  0.3170, -0.1135,  ..., -0.8350,  0.7675, -0.2843],\n",
      "        [-0.1441, -0.1694,  0.5389,  ..., -0.2148,  0.6050,  0.2085],\n",
      "        [-0.1441, -0.1694,  0.5389,  ..., -0.2148,  0.6050,  0.2085]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 9.6957423e-03 -1.7540956e-02 -2.3670152e-01  2.0198744e-02\n",
      " -1.5665853e-01 -6.5317059e-01 -7.7152520e-02 -3.3759966e-01\n",
      " -1.3940303e+00 -2.2170720e-01 -4.0134719e-01 -1.6876669e+00\n",
      " -3.9735940e-01 -5.1058763e-01 -2.1608167e+00 -1.9503158e-01\n",
      " -6.2774152e-01 -1.5464107e+00  1.8257424e-03 -6.5968937e-01\n",
      " -1.3583251e+00 -4.3820105e-02 -5.9263766e-01 -1.4164497e+00\n",
      " -4.0410087e-02 -7.3038417e-01 -1.5306120e+00 -1.5384853e-01\n",
      " -5.2475870e-01 -1.4649322e+00 -7.6631814e-02 -5.7720381e-01\n",
      " -1.4345090e+00 -8.9721777e-02 -5.5491596e-01 -1.5307798e+00\n",
      "  5.0859548e-02 -5.6873751e-01 -1.5745070e+00 -7.0448592e-02\n",
      " -4.4422770e-01 -1.2978053e+00 -1.7627239e-01 -2.2107893e-01\n",
      " -1.9210631e+00 -2.8854631e-02 -3.6793989e-01 -1.9232837e+00\n",
      "  1.3230395e-01 -3.4189343e-01 -1.4312024e+00 -1.6485283e-01\n",
      " -2.0893762e-01 -1.2340430e+00 -9.7116463e-02 -1.8972977e-01\n",
      " -1.3166769e+00 -5.2041925e-02 -1.9612694e-01 -1.4336727e+00\n",
      "  3.2794476e-02 -2.1040545e-01 -1.2826364e+00]\n",
      "data: [ 9.6957423e-03 -1.7540956e-02 -2.3670153e-01  2.0198744e-02\n",
      " -1.5665853e-01 -6.5317065e-01 -7.7152520e-02 -3.3759966e-01\n",
      " -1.3940303e+00 -2.2170720e-01 -4.0134719e-01 -1.6876669e+00\n",
      " -3.9735940e-01 -5.1058763e-01 -2.1608167e+00 -1.9503158e-01\n",
      " -6.2774152e-01 -1.5464107e+00  1.8257424e-03 -6.5968931e-01\n",
      " -1.3583252e+00 -4.3820105e-02 -5.9263766e-01 -1.4164498e+00\n",
      " -4.0410087e-02 -7.3038411e-01 -1.5306120e+00 -1.5384853e-01\n",
      " -5.2475870e-01 -1.4649322e+00 -7.6631814e-02 -5.7720381e-01\n",
      " -1.4345089e+00 -8.9721777e-02 -5.5491596e-01 -1.5307798e+00\n",
      "  5.0859548e-02 -5.6873751e-01 -1.5745070e+00 -7.0448592e-02\n",
      " -4.4422767e-01 -1.2978053e+00 -1.7627239e-01 -2.2107893e-01\n",
      " -1.9210631e+00 -2.8854631e-02 -3.6793986e-01 -1.9232837e+00\n",
      "  1.3230395e-01 -3.4189343e-01 -1.4312024e+00 -1.6485283e-01\n",
      " -2.0893760e-01 -1.2340430e+00 -9.7116463e-02 -1.8972977e-01\n",
      " -1.3166767e+00 -5.2041925e-02 -1.9612694e-01 -1.4336727e+00\n",
      "  3.2794476e-02 -2.1040544e-01 -1.2826364e+00  1.8000001e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0298, -0.0944, -0.2253,  ...,  0.0415, -0.2793, -1.2887],\n",
      "        [ 0.0298, -0.0944, -0.2253,  ...,  0.0415, -0.2793, -1.2887],\n",
      "        [ 0.0298, -0.0944, -0.2253,  ...,  0.0415, -0.2793, -1.2887],\n",
      "        ...,\n",
      "        [-0.3447,  0.2673, -0.3659,  ..., -0.8881,  0.7105, -0.5020],\n",
      "        [-0.1401, -0.0853,  0.6052,  ..., -0.2408,  0.7101,  0.2831],\n",
      "        [-0.1401, -0.0853,  0.6052,  ..., -0.2408,  0.7101,  0.2831]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02980468 -0.0944279  -0.22531241  0.04968468 -0.23617496 -0.65564966\n",
      " -0.04248378 -0.40791294 -1.3882446  -0.182984   -0.47026825 -1.6770884\n",
      " -0.34849173 -0.5740971  -2.1573117  -0.16581956 -0.69838583 -1.5418682\n",
      "  0.02273691 -0.72247857 -1.3683832  -0.02121063 -0.6554276  -1.4299309\n",
      " -0.01921084 -0.78598994 -1.5415591  -0.13077798 -0.59643227 -1.4676651\n",
      " -0.05378554 -0.6437021  -1.4380842  -0.07388707 -0.61944336 -1.5323057\n",
      "  0.06012168 -0.6296937  -1.5767486  -0.05434228 -0.5171677  -1.3011203\n",
      " -0.15129846 -0.2938594  -1.9017724  -0.01491269 -0.43319562 -1.9041388\n",
      "  0.134208   -0.408033   -1.4369583  -0.14240438 -0.28464544 -1.2415241\n",
      " -0.0804932  -0.26217127 -1.319212   -0.03705171 -0.26433507 -1.4374014\n",
      "  0.04149192 -0.2792822  -1.2887274 ]\n",
      "data: [ 0.02980468 -0.0944279  -0.22531241  0.04968468 -0.23617497 -0.65564966\n",
      " -0.04248378 -0.40791294 -1.3882446  -0.182984   -0.47026825 -1.6770883\n",
      " -0.34849176 -0.5740971  -2.1573117  -0.16581956 -0.69838583 -1.5418683\n",
      "  0.02273691 -0.72247857 -1.3683832  -0.02121063 -0.6554276  -1.4299309\n",
      " -0.01921084 -0.78598994 -1.5415591  -0.13077798 -0.59643227 -1.4676651\n",
      " -0.05378554 -0.6437021  -1.4380842  -0.07388707 -0.61944336 -1.5323057\n",
      "  0.06012168 -0.6296937  -1.5767486  -0.05434228 -0.5171677  -1.3011203\n",
      " -0.15129846 -0.2938594  -1.9017723  -0.01491269 -0.43319562 -1.9041388\n",
      "  0.134208   -0.408033   -1.4369583  -0.14240438 -0.28464544 -1.2415241\n",
      " -0.0804932  -0.26217127 -1.3192121  -0.03705171 -0.26433507 -1.4374014\n",
      "  0.04149192 -0.2792822  -1.2887274   0.19      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[ 0.0282, -0.0811, -0.2347,  ...,  0.0535, -0.2728, -1.2553],\n",
      "        [ 0.0282, -0.0811, -0.2347,  ...,  0.0535, -0.2728, -1.2553],\n",
      "        [ 0.0282, -0.0811, -0.2347,  ...,  0.0535, -0.2728, -1.2553],\n",
      "        ...,\n",
      "        [-0.1342,  0.4133, -0.0857,  ..., -0.6803,  0.9076, -0.3705],\n",
      "        [-0.1709, -0.1329,  0.5785,  ..., -0.2704,  0.6418,  0.2198],\n",
      "        [-0.1709, -0.1329,  0.5785,  ..., -0.2704,  0.6418,  0.2198]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02816815 -0.08113734 -0.23470102  0.05448964 -0.20259416 -0.6067131\n",
      " -0.05689751 -0.40877473 -1.4034604  -0.201745   -0.4741286  -1.6977472\n",
      " -0.3580877  -0.5759067  -2.1875956  -0.1647164  -0.7030825  -1.5625972\n",
      "  0.0276154  -0.75211453 -1.385365   -0.02708234 -0.68484086 -1.440582\n",
      " -0.03968798 -0.83827746 -1.5627589  -0.12207609 -0.6093996  -1.4680835\n",
      " -0.05621065 -0.6630323  -1.4413962  -0.0739717  -0.63447803 -1.5292794\n",
      "  0.05361292 -0.66346437 -1.5588163  -0.038385   -0.508909   -1.301694\n",
      " -0.17596874 -0.27884126 -2.012947   -0.00942268 -0.44306737 -2.0264025\n",
      "  0.14836587 -0.4087786  -1.4176841  -0.14769542 -0.279141   -1.2278215\n",
      " -0.07524806 -0.25375974 -1.3134234  -0.03800599 -0.2602498  -1.4274628\n",
      "  0.05346889 -0.27275142 -1.2552907 ]\n",
      "data: [ 0.02816815 -0.08113734 -0.23470102  0.05448963 -0.20259416 -0.6067131\n",
      " -0.05689751 -0.40877473 -1.4034604  -0.20174499 -0.4741286  -1.6977472\n",
      " -0.3580877  -0.5759067  -2.1875956  -0.1647164  -0.7030825  -1.5625972\n",
      "  0.0276154  -0.75211453 -1.385365   -0.02708234 -0.68484086 -1.4405819\n",
      " -0.03968798 -0.83827746 -1.5627589  -0.12207609 -0.6093996  -1.4680835\n",
      " -0.05621065 -0.6630323  -1.4413962  -0.0739717  -0.63447803 -1.5292794\n",
      "  0.05361292 -0.66346437 -1.5588164  -0.038385   -0.508909   -1.301694\n",
      " -0.17596874 -0.27884126 -2.012947   -0.00942268 -0.44306737 -2.0264025\n",
      "  0.14836587 -0.4087786  -1.4176841  -0.14769542 -0.279141   -1.2278215\n",
      " -0.07524806 -0.25375974 -1.3134235  -0.03800599 -0.2602498  -1.4274628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.05346889 -0.27275142 -1.2552907   0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63EF0>\n",
      "tensor([[ 0.0226, -0.0326, -0.2272,  ...,  0.0524, -0.2233, -1.2639],\n",
      "        [ 0.0226, -0.0326, -0.2272,  ...,  0.0524, -0.2233, -1.2639],\n",
      "        [ 0.0226, -0.0326, -0.2272,  ...,  0.0524, -0.2233, -1.2639],\n",
      "        ...,\n",
      "        [-0.1732,  0.3196, -0.0942,  ..., -0.8005,  0.7683, -0.2880],\n",
      "        [-0.1389, -0.1402,  0.5657,  ..., -0.2003,  0.6145,  0.2224],\n",
      "        [-0.1389, -0.1402,  0.5657,  ..., -0.2003,  0.6145,  0.2224]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02261335 -0.03259488 -0.22722827  0.0358988  -0.17118192 -0.6328558\n",
      " -0.05360056 -0.3601619  -1.3790615  -0.1990054  -0.42242756 -1.6825256\n",
      " -0.37526977 -0.53995955 -2.150021   -0.18561791 -0.64506763 -1.5363955\n",
      "  0.03333679 -0.67985415 -1.3402103  -0.02033344 -0.61870426 -1.3946754\n",
      " -0.02466972 -0.7581346  -1.5131634  -0.13847889 -0.5400909  -1.4465063\n",
      " -0.05719346 -0.5980793  -1.4215841  -0.06730608 -0.5754268  -1.5194017\n",
      "  0.06275862 -0.60101813 -1.5643357  -0.0448676  -0.4505403  -1.2748191\n",
      " -0.16581438 -0.22724172 -1.9344547  -0.0074747  -0.38606045 -1.9342352\n",
      "  0.15063585 -0.35405213 -1.4163742  -0.14974532 -0.21457717 -1.2104315\n",
      " -0.06867282 -0.19587041 -1.2937682  -0.02432555 -0.21187077 -1.4106572\n",
      "  0.05238169 -0.22331305 -1.263922  ]\n",
      "data: [-0.9  -4.48  3.51 -1.06 -4.21  3.65 -1.1  -3.72  3.6  -1.12 -3.43  3.91\n",
      " -1.22 -3.34  4.8  -0.85 -3.7   4.26 -0.91 -3.35  4.67 -1.05 -3.23  5.19\n",
      " -1.1  -3.15  5.19 -0.73 -3.74  4.1  -0.77 -3.37  4.36 -0.93 -3.32  4.67\n",
      " -1.04 -3.29  4.93 -0.71 -3.78  4.1  -0.72 -3.41  4.22 -0.95 -3.48  4.8\n",
      " -1.05 -3.62  4.98 -0.71 -3.82  3.94 -0.74 -3.58  4.16 -0.78 -3.53  4.07\n",
      " -0.94 -3.65  4.55  0.  ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B9B0>\n",
      "tensor([[-0.1028,  0.4596, -0.0144,  ..., -0.5470,  0.4185, -0.7402],\n",
      "        [-0.1028,  0.4596, -0.0144,  ..., -0.5470,  0.4185, -0.7402],\n",
      "        [-0.1028,  0.4596, -0.0144,  ..., -0.5470,  0.4185, -0.7402],\n",
      "        ...,\n",
      "        [ 0.3731, -0.9315,  0.8486,  ..., -0.6489, -1.1141,  1.0814],\n",
      "        [ 0.1835,  0.1112,  0.1959,  ...,  0.4856, -0.4742,  2.4856],\n",
      "        [ 0.1835,  0.1112,  0.1959,  ...,  0.4856, -0.4742,  2.4856]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.10283577  0.45958224 -0.01443899 -0.21573317  0.2742619  -0.4756187\n",
      " -0.23422286  0.17632902 -0.59893167 -0.2696802   0.06338316 -0.5539043\n",
      " -0.31399226 -0.00495112 -0.58080745 -0.35978866  0.23208681 -0.88288903\n",
      " -0.24287328  0.17792118 -0.34116113 -0.3370071   0.00952953 -0.30649313\n",
      " -0.46671456  0.05373028 -0.37163535 -0.3896296   0.3544802  -0.943539\n",
      " -0.4862355   0.2575344  -0.9506854  -0.53448725  0.17401013 -0.9305334\n",
      " -0.60482484  0.06061959 -0.88971686 -0.430322    0.41782525 -0.93220186\n",
      " -0.5597058   0.36826834 -0.955364   -0.59333956  0.30417228 -0.9547243\n",
      " -0.621868    0.21285953 -0.7992164  -0.4382584   0.5660572  -0.8101188\n",
      " -0.4697265   0.5068788  -0.8006058  -0.5224272   0.47836912 -0.7942493\n",
      " -0.5469624   0.41851246 -0.7401917 ]\n",
      "init: [-0.10283577  0.45958224 -0.01443899 -0.21573317  0.2742619  -0.4756187\n",
      " -0.23422286  0.17632902 -0.59893167 -0.2696802   0.06338316 -0.5539043\n",
      " -0.31399226 -0.00495112 -0.58080745 -0.35978866  0.23208681 -0.88288903\n",
      " -0.24287328  0.17792118 -0.34116113 -0.3370071   0.00952953 -0.30649313\n",
      " -0.46671456  0.05373028 -0.37163535 -0.3896296   0.3544802  -0.943539\n",
      " -0.4862355   0.2575344  -0.9506854  -0.53448725  0.17401013 -0.9305334\n",
      " -0.60482484  0.06061959 -0.88971686 -0.430322    0.41782525 -0.93220186\n",
      " -0.5597058   0.36826834 -0.955364   -0.59333956  0.30417228 -0.9547243\n",
      " -0.621868    0.21285953 -0.7992164  -0.4382584   0.5660572  -0.8101188\n",
      " -0.4697265   0.5068788  -0.8006058  -0.5224272   0.47836912 -0.7942493\n",
      " -0.5469624   0.41851246 -0.7401917 ]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [-0.10283577  0.45958224 -0.01443899 -0.21573317  0.2742619  -0.47561872\n",
      " -0.23422284  0.17632902 -0.59893167 -0.2696802   0.06338316 -0.5539043\n",
      " -0.31399226 -0.00495112 -0.58080745 -0.35978866  0.23208681 -0.88288903\n",
      " -0.24287328  0.17792118 -0.34116113 -0.3370071   0.00952953 -0.30649313\n",
      " -0.46671456  0.05373028 -0.37163535 -0.3896296   0.3544802  -0.943539\n",
      " -0.4862355   0.2575344  -0.9506853  -0.53448725  0.17401013 -0.93053347\n",
      " -0.60482484  0.06061959 -0.88971686 -0.430322    0.41782525 -0.93220186\n",
      " -0.5597058   0.36826837 -0.955364   -0.59333956  0.30417228 -0.95472425\n",
      " -0.621868    0.21285954 -0.7992164  -0.4382584   0.5660572  -0.8101188\n",
      " -0.46972647  0.5068788  -0.8006058  -0.5224272   0.47836912 -0.7942493\n",
      " -0.5469624   0.41851246 -0.7401917   0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F828>\n",
      "tensor([[ 0.0076, -0.2875, -0.0587,  ..., -0.0319, -0.3981, -1.1456],\n",
      "        [ 0.0076, -0.2875, -0.0587,  ..., -0.0319, -0.3981, -1.1456],\n",
      "        [ 0.0076, -0.2875, -0.0587,  ..., -0.0319, -0.3981, -1.1456],\n",
      "        ...,\n",
      "        [ 0.1888,  0.7782, -0.5005,  ..., -0.0537,  0.8506, -0.1289],\n",
      "        [-0.1076,  0.0353,  0.3432,  ..., -0.7491,  1.1276, -0.3081],\n",
      "        [-0.1076,  0.0353,  0.3432,  ..., -0.7491,  1.1276, -0.3081]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00759152 -0.28753513 -0.05868057 -0.00731969 -0.4617963  -0.5837444\n",
      " -0.15179098 -0.59316087 -1.1836802  -0.27990562 -0.6467612  -1.4062707\n",
      " -0.4714197  -0.6966633  -1.827345   -0.21546428 -0.84913474 -1.2666093\n",
      " -0.19693758 -0.8248403  -1.2432413  -0.1479719  -0.7183746  -1.3118436\n",
      " -0.06429277 -0.8284764  -1.3687652  -0.21178593 -0.72214025 -1.2538457\n",
      " -0.15053202 -0.7314993  -1.1812792  -0.14403164 -0.7023872  -1.2598151\n",
      "  0.09026493 -0.6295286  -1.3625863  -0.17771916 -0.6996645  -1.1342074\n",
      " -0.18123318 -0.48459664 -1.4361552  -0.08915524 -0.5449573  -1.434184\n",
      "  0.07846464 -0.503194   -1.2603033  -0.19209506 -0.46909094 -1.097672\n",
      " -0.22678305 -0.41388485 -1.1540205  -0.137369   -0.36811244 -1.2906041\n",
      " -0.03186654 -0.39813024 -1.1456053 ]\n",
      "data: [ 0.00759152 -0.28753513 -0.05868057 -0.00731969 -0.4617963  -0.5837444\n",
      " -0.15179098 -0.59316087 -1.1836802  -0.27990562 -0.6467612  -1.4062707\n",
      " -0.4714197  -0.69666326 -1.827345   -0.2154643  -0.84913474 -1.2666093\n",
      " -0.19693758 -0.8248403  -1.2432413  -0.1479719  -0.7183746  -1.3118435\n",
      " -0.06429277 -0.8284764  -1.3687652  -0.21178593 -0.72214025 -1.2538457\n",
      " -0.15053202 -0.7314993  -1.1812792  -0.14403164 -0.7023872  -1.2598151\n",
      "  0.09026493 -0.6295286  -1.3625863  -0.17771916 -0.6996645  -1.1342074\n",
      " -0.18123318 -0.48459664 -1.4361552  -0.08915524 -0.5449573  -1.434184\n",
      "  0.07846464 -0.503194   -1.2603033  -0.19209506 -0.46909097 -1.097672\n",
      " -0.22678305 -0.41388485 -1.1540205  -0.137369   -0.36811244 -1.2906041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.03186654 -0.39813024 -1.1456053   0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[ 0.0605, -0.0512, -0.2556,  ...,  0.1406, -0.2265, -1.2991],\n",
      "        [ 0.0605, -0.0512, -0.2556,  ...,  0.1406, -0.2265, -1.2991],\n",
      "        [ 0.0605, -0.0512, -0.2556,  ...,  0.1406, -0.2265, -1.2991],\n",
      "        ...,\n",
      "        [-0.1139,  0.3884,  0.1448,  ..., -0.1410,  1.1599, -0.4064],\n",
      "        [-0.0665,  0.1506,  0.4753,  ..., -0.4198,  0.7213,  0.1302],\n",
      "        [-0.0665,  0.1506,  0.4753,  ..., -0.4198,  0.7213,  0.1302]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.060461   -0.05122827 -0.25561637  0.09935042 -0.17679757 -0.5841077\n",
      "  0.02732419 -0.37624896 -1.388252   -0.12623714 -0.43073583 -1.7093762\n",
      " -0.29142278 -0.56977874 -2.1998744  -0.15964301 -0.63910973 -1.6284128\n",
      "  0.15515961 -0.6744091  -1.390478    0.09700626 -0.61602867 -1.4177716\n",
      "  0.09263735 -0.7444578  -1.5471232  -0.09610255 -0.52899045 -1.5169883\n",
      "  0.02341912 -0.60470307 -1.4972758   0.04437756 -0.569993   -1.5897511\n",
      "  0.17807019 -0.633605   -1.6520132   0.03653497 -0.43616545 -1.3260665\n",
      " -0.11348678 -0.18112053 -2.0377827   0.08763056 -0.3876006  -2.0217874\n",
      "  0.2701512  -0.33088946 -1.486338   -0.11719733 -0.18503201 -1.2499746\n",
      "  0.02311817 -0.15796259 -1.3139733   0.08296835 -0.21517591 -1.4314471\n",
      "  0.1405592  -0.22651625 -1.2991288 ]\n",
      "data: [ 0.060461   -0.05122827 -0.25561637  0.09935042 -0.17679757 -0.5841077\n",
      "  0.02732419 -0.37624896 -1.3882519  -0.12623714 -0.43073583 -1.7093762\n",
      " -0.29142278 -0.56977874 -2.1998744  -0.15964301 -0.63910973 -1.6284127\n",
      "  0.15515961 -0.6744091  -1.390478    0.09700626 -0.61602867 -1.4177716\n",
      "  0.09263735 -0.7444578  -1.5471233  -0.09610255 -0.52899045 -1.5169883\n",
      "  0.02341912 -0.60470307 -1.4972758   0.04437755 -0.569993   -1.5897511\n",
      "  0.17807019 -0.633605   -1.6520133   0.03653497 -0.43616545 -1.3260665\n",
      " -0.11348679 -0.18112053 -2.0377827   0.08763056 -0.3876006  -2.0217874\n",
      "  0.2701512  -0.33088946 -1.486338   -0.11719733 -0.18503201 -1.2499746\n",
      "  0.02311817 -0.15796259 -1.3139732   0.08296835 -0.21517591 -1.4314471\n",
      "  0.1405592  -0.22651625 -1.2991288   0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[-1.0902e-03, -1.8546e-01, -3.1403e-01,  ...,  5.0582e-02,\n",
      "         -3.5789e-01, -1.4180e+00],\n",
      "        [-1.0902e-03, -1.8546e-01, -3.1403e-01,  ...,  5.0582e-02,\n",
      "         -3.5789e-01, -1.4180e+00],\n",
      "        [-1.0902e-03, -1.8546e-01, -3.1403e-01,  ...,  5.0582e-02,\n",
      "         -3.5789e-01, -1.4180e+00],\n",
      "        ...,\n",
      "        [-1.7283e-01,  4.5432e-01, -2.5741e-02,  ..., -7.2464e-01,\n",
      "          9.8215e-01, -2.7449e-01],\n",
      "        [-1.9015e-01,  8.1027e-02,  6.3428e-01,  ..., -2.7277e-01,\n",
      "          8.0947e-01,  3.0132e-01],\n",
      "        [-1.9015e-01,  8.1027e-02,  6.3428e-01,  ..., -2.7277e-01,\n",
      "          8.0947e-01,  3.0132e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-1.09024625e-03 -1.85459018e-01 -3.14032614e-01  2.86988355e-02\n",
      " -3.44547004e-01 -7.86641717e-01  1.33864647e-02 -4.85766172e-01\n",
      " -1.47947431e+00 -1.21675178e-01 -5.33281922e-01 -1.80098486e+00\n",
      " -2.78660536e-01 -6.84767127e-01 -2.28495193e+00 -2.10882902e-01\n",
      " -7.54548311e-01 -1.65194237e+00  1.16162345e-01 -7.42946267e-01\n",
      " -1.39261711e+00  4.11025733e-02 -6.91359520e-01 -1.44695377e+00\n",
      "  9.63670015e-03 -7.76384473e-01 -1.57497203e+00 -1.62459165e-01\n",
      " -6.44770026e-01 -1.56905437e+00 -3.01665962e-02 -6.97417617e-01\n",
      " -1.57497406e+00 -4.52060699e-02 -6.55023575e-01 -1.67239201e+00\n",
      "  3.73201817e-02 -6.98808670e-01 -1.73338091e+00 -3.25417891e-02\n",
      " -5.63970923e-01 -1.38157332e+00 -1.20388329e-01 -3.27121198e-01\n",
      " -1.93077862e+00  1.03727281e-02 -4.82418090e-01 -1.89866555e+00\n",
      "  1.29391074e-01 -4.44075197e-01 -1.58596516e+00 -1.45769894e-01\n",
      " -3.28063905e-01 -1.32739556e+00 -8.06409121e-03 -3.10046196e-01\n",
      " -1.39577603e+00  3.48459929e-02 -3.55736971e-01 -1.51152384e+00\n",
      "  5.05819097e-02 -3.57890546e-01 -1.41800761e+00]\n",
      "data: [-1.09024625e-03 -1.85459018e-01 -3.14032614e-01  2.86988355e-02\n",
      " -3.44547004e-01 -7.86641717e-01  1.33864637e-02 -4.85766172e-01\n",
      " -1.47947431e+00 -1.21675178e-01 -5.33281922e-01 -1.80098486e+00\n",
      " -2.78660536e-01 -6.84767127e-01 -2.28495193e+00 -2.10882917e-01\n",
      " -7.54548311e-01 -1.65194249e+00  1.16162345e-01 -7.42946267e-01\n",
      " -1.39261699e+00  4.11025733e-02 -6.91359580e-01 -1.44695377e+00\n",
      "  9.63670015e-03 -7.76384532e-01 -1.57497203e+00 -1.62459165e-01\n",
      " -6.44770026e-01 -1.56905437e+00 -3.01665980e-02 -6.97417617e-01\n",
      " -1.57497406e+00 -4.52060699e-02 -6.55023575e-01 -1.67239201e+00\n",
      "  3.73201817e-02 -6.98808670e-01 -1.73338091e+00 -3.25417891e-02\n",
      " -5.63970923e-01 -1.38157332e+00 -1.20388329e-01 -3.27121198e-01\n",
      " -1.93077862e+00  1.03727281e-02 -4.82418090e-01 -1.89866567e+00\n",
      "  1.29391074e-01 -4.44075197e-01 -1.58596516e+00 -1.45769894e-01\n",
      " -3.28063875e-01 -1.32739568e+00 -8.06409121e-03 -3.10046196e-01\n",
      " -1.39577603e+00  3.48459929e-02 -3.55736971e-01 -1.51152384e+00\n",
      "  5.05819097e-02 -3.57890546e-01 -1.41800761e+00  3.99999991e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0206, -0.1986, -0.2194,  ...,  0.0135, -0.3717, -1.3060],\n",
      "        [ 0.0206, -0.1986, -0.2194,  ...,  0.0135, -0.3717, -1.3060],\n",
      "        [ 0.0206, -0.1986, -0.2194,  ...,  0.0135, -0.3717, -1.3060],\n",
      "        ...,\n",
      "        [ 0.0220,  0.5493, -0.2156,  ..., -0.4780,  1.0602, -0.5751],\n",
      "        [-0.1705, -0.0379,  0.6230,  ..., -0.1740,  0.6634,  0.3175],\n",
      "        [-0.1705, -0.0379,  0.6230,  ..., -0.1740,  0.6634,  0.3175]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02058862 -0.19864194 -0.21936749  0.04538504 -0.3362074  -0.604854\n",
      " -0.03221733 -0.53980345 -1.3948973  -0.18044655 -0.6005795  -1.7074203\n",
      " -0.34920523 -0.7176471  -2.2003784  -0.19234595 -0.8096068  -1.6010739\n",
      "  0.04994918 -0.852268   -1.3999876  -0.01260929 -0.7993009  -1.4453721\n",
      " -0.0293085  -0.9365064  -1.5673518  -0.14506377 -0.6993394  -1.5005053\n",
      " -0.06371187 -0.76266253 -1.4788504  -0.07348984 -0.74027944 -1.5791649\n",
      "  0.03364967 -0.77881503 -1.6239982  -0.04766282 -0.5958096  -1.3277286\n",
      " -0.19036728 -0.3738259  -2.007434   -0.02858002 -0.5452622  -2.007122\n",
      "  0.11470205 -0.50280356 -1.4710398  -0.17235316 -0.35756683 -1.2594469\n",
      " -0.08160876 -0.33741766 -1.3312557  -0.04329379 -0.36656693 -1.4435108\n",
      "  0.01350863 -0.37172592 -1.3059781 ]\n",
      "data: [ 0.02058862 -0.19864196 -0.21936749  0.04538505 -0.3362074  -0.604854\n",
      " -0.03221733 -0.53980345 -1.3948973  -0.18044655 -0.6005795  -1.7074203\n",
      " -0.3492052  -0.7176471  -2.2003784  -0.19234595 -0.8096068  -1.6010739\n",
      "  0.04994918 -0.852268   -1.3999877  -0.01260929 -0.7993009  -1.4453721\n",
      " -0.0293085  -0.93650645 -1.5673518  -0.14506377 -0.6993394  -1.5005053\n",
      " -0.06371187 -0.76266253 -1.4788504  -0.07348984 -0.74027944 -1.5791649\n",
      "  0.03364967 -0.77881503 -1.6239982  -0.04766282 -0.5958096  -1.3277286\n",
      " -0.19036728 -0.3738259  -2.007434   -0.02858002 -0.5452622  -2.007122\n",
      "  0.11470205 -0.50280356 -1.4710398  -0.17235318 -0.35756683 -1.2594469\n",
      " -0.08160875 -0.3374177  -1.3312557  -0.04329379 -0.36656693 -1.4435108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.01350863 -0.37172592 -1.3059781   0.05      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B320>\n",
      "tensor([[ 0.0341, -0.1728, -0.1948,  ...,  0.0557, -0.3526, -1.2167],\n",
      "        [ 0.0341, -0.1728, -0.1948,  ...,  0.0557, -0.3526, -1.2167],\n",
      "        [ 0.0341, -0.1728, -0.1948,  ...,  0.0557, -0.3526, -1.2167],\n",
      "        ...,\n",
      "        [-0.1157,  0.4913, -0.0930,  ..., -0.6423,  1.0823, -0.5354],\n",
      "        [-0.1144,  0.0112,  0.6341,  ..., -0.1586,  0.6691,  0.2947],\n",
      "        [-0.1144,  0.0112,  0.6341,  ..., -0.1586,  0.6691,  0.2947]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03405691 -0.17284644 -0.19476232  0.06734183 -0.28002203 -0.48148346\n",
      " -0.0468074  -0.50670373 -1.34156    -0.20673569 -0.56644803 -1.6548027\n",
      " -0.3646401  -0.6735751  -2.1793995  -0.17672873 -0.79962903 -1.5586883\n",
      "  0.04756106 -0.86004514 -1.3971183  -0.01594089 -0.7971158  -1.440241\n",
      " -0.02672914 -0.95538145 -1.5717608  -0.12425932 -0.70611185 -1.4430073\n",
      " -0.05040067 -0.76633894 -1.4274311  -0.04921228 -0.7296828  -1.5243826\n",
      "  0.07604276 -0.7800696  -1.5509075  -0.02169021 -0.58538806 -1.2696164\n",
      " -0.18906556 -0.3504172  -2.0277467   0.00707774 -0.5361476  -2.0447173\n",
      "  0.17982915 -0.48834568 -1.4015976  -0.16385311 -0.35364032 -1.1911966\n",
      " -0.0670374  -0.32745257 -1.2692808  -0.03457372 -0.34995508 -1.3827633\n",
      "  0.0557228  -0.35262442 -1.216689  ]\n",
      "data: [ 0.03405691 -0.17284644 -0.19476232  0.06734183 -0.28002203 -0.48148346\n",
      " -0.0468074  -0.50670373 -1.34156    -0.20673569 -0.56644803 -1.6548027\n",
      " -0.3646401  -0.67357516 -2.1793995  -0.17672873 -0.79962903 -1.5586884\n",
      "  0.04756106 -0.8600452  -1.3971183  -0.01594089 -0.7971158  -1.440241\n",
      " -0.02672913 -0.95538145 -1.5717607  -0.12425932 -0.70611185 -1.4430073\n",
      " -0.05040068 -0.76633894 -1.427431   -0.04921228 -0.72968274 -1.5243826\n",
      "  0.07604276 -0.7800696  -1.5509075  -0.02169021 -0.58538806 -1.2696164\n",
      " -0.18906555 -0.35041723 -2.0277467   0.00707774 -0.5361476  -2.0447173\n",
      "  0.17982917 -0.48834568 -1.4015976  -0.16385311 -0.35364032 -1.1911966\n",
      " -0.0670374  -0.32745257 -1.2692808  -0.03457372 -0.34995505 -1.3827633\n",
      "  0.0557228  -0.35262445 -1.216689    0.06      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FC18>\n",
      "tensor([[ 0.0168, -0.1201, -0.1750,  ...,  0.0480, -0.3050, -1.1828],\n",
      "        [ 0.0168, -0.1201, -0.1750,  ...,  0.0480, -0.3050, -1.1828],\n",
      "        [ 0.0168, -0.1201, -0.1750,  ...,  0.0480, -0.3050, -1.1828],\n",
      "        ...,\n",
      "        [-0.1496,  0.4370, -0.0019,  ..., -0.5576,  1.0134, -0.3852],\n",
      "        [-0.1118,  0.0336,  0.6269,  ..., -0.1930,  0.6962,  0.2998],\n",
      "        [-0.1118,  0.0336,  0.6269,  ..., -0.1930,  0.6962,  0.2998]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0167976  -0.12014036 -0.17502494  0.04907351 -0.23260932 -0.47145942\n",
      " -0.07473639 -0.46463713 -1.3356723  -0.23276198 -0.531165   -1.6380506\n",
      " -0.3859732  -0.63782513 -2.1533883  -0.19043899 -0.7554561  -1.5308617\n",
      "  0.02711678 -0.8186577  -1.3515099  -0.03553331 -0.7530173  -1.3941956\n",
      " -0.05082856 -0.90939206 -1.5249937  -0.1392021  -0.66103846 -1.419872\n",
      " -0.06747188 -0.7213133  -1.3959149  -0.06998106 -0.68182296 -1.483114\n",
      "  0.05790813 -0.7303335  -1.5072018  -0.03808344 -0.5429709  -1.2488526\n",
      " -0.20180449 -0.3046857  -1.9981236  -0.0097268  -0.4883001  -2.0141962\n",
      "  0.16442728 -0.44087213 -1.3648895  -0.17593455 -0.30755195 -1.1678964\n",
      " -0.08102894 -0.27936953 -1.2487404  -0.04589044 -0.29848307 -1.360079\n",
      "  0.04803614 -0.30502975 -1.1828055 ]\n",
      "data: [ 0.0167976  -0.12014036 -0.17502494  0.04907351 -0.23260932 -0.47145942\n",
      " -0.07473639 -0.46463716 -1.3356723  -0.23276198 -0.531165   -1.6380506\n",
      " -0.38597316 -0.63782513 -2.1533883  -0.190439   -0.7554561  -1.5308616\n",
      "  0.02711678 -0.8186577  -1.3515098  -0.03553331 -0.75301725 -1.3941956\n",
      " -0.05082856 -0.9093921  -1.5249935  -0.1392021  -0.66103846 -1.4198719\n",
      " -0.06747188 -0.7213133  -1.3959149  -0.06998106 -0.68182296 -1.483114\n",
      "  0.05790813 -0.7303335  -1.5072018  -0.03808344 -0.5429709  -1.2488526\n",
      " -0.20180449 -0.3046857  -1.9981236  -0.0097268  -0.48830014 -2.0141962\n",
      "  0.16442728 -0.4408721  -1.3648895  -0.17593457 -0.30755195 -1.1678964\n",
      " -0.08102894 -0.27936953 -1.2487404  -0.04589044 -0.29848307 -1.360079\n",
      "  0.04803614 -0.30502975 -1.1828055   0.07      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0263, -0.0946, -0.2013,  ...,  0.0148, -0.2777, -1.1869],\n",
      "        [-0.0263, -0.0946, -0.2013,  ...,  0.0148, -0.2777, -1.1869],\n",
      "        [-0.0263, -0.0946, -0.2013,  ...,  0.0148, -0.2777, -1.1869],\n",
      "        ...,\n",
      "        [-0.1506,  0.3723,  0.0075,  ..., -0.6544,  0.9600, -0.3805],\n",
      "        [-0.0792, -0.0479,  0.6253,  ..., -0.2030,  0.6750,  0.2497],\n",
      "        [-0.0792, -0.0479,  0.6253,  ..., -0.2030,  0.6750,  0.2497]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.02630716 -0.09463747 -0.20132938  0.00569242 -0.20320226 -0.49726292\n",
      " -0.12466945 -0.43088162 -1.3498225  -0.2775346  -0.4945375  -1.6466143\n",
      " -0.43068373 -0.5962981  -2.1509743  -0.22730388 -0.72679424 -1.5275302\n",
      " -0.02348302 -0.78592646 -1.3533609  -0.07734275 -0.7165222  -1.4002049\n",
      " -0.08312604 -0.8759116  -1.530855   -0.17919365 -0.6342273  -1.4206007\n",
      " -0.10961732 -0.68973804 -1.3966708  -0.10746052 -0.65116    -1.483053\n",
      "  0.03539521 -0.69271505 -1.5093544  -0.08491399 -0.5207099  -1.2513216\n",
      " -0.24494131 -0.28053877 -2.0164003  -0.04612263 -0.45984516 -2.035851\n",
      "  0.13762121 -0.41436413 -1.3667228  -0.21556236 -0.28778422 -1.1707702\n",
      " -0.12976451 -0.2574017  -1.2559929  -0.09106639 -0.26806882 -1.3711171\n",
      "  0.01476059 -0.2777077  -1.1868947 ]\n",
      "data: [-0.02630716 -0.09463747 -0.20132938  0.00569242 -0.20320226 -0.49726292\n",
      " -0.12466945 -0.43088162 -1.3498225  -0.2775346  -0.4945375  -1.6466144\n",
      " -0.43068373 -0.5962981  -2.1509743  -0.22730389 -0.7267943  -1.5275302\n",
      " -0.02348302 -0.78592646 -1.3533609  -0.07734275 -0.7165222  -1.4002049\n",
      " -0.08312604 -0.87591153 -1.530855   -0.17919365 -0.6342273  -1.4206005\n",
      " -0.10961732 -0.68973804 -1.3966708  -0.10746052 -0.65116    -1.483053\n",
      "  0.03539521 -0.69271505 -1.5093544  -0.08491399 -0.5207099  -1.2513216\n",
      " -0.24494131 -0.28053877 -2.0164003  -0.04612263 -0.45984516 -2.035851\n",
      "  0.13762121 -0.41436413 -1.3667228  -0.21556236 -0.28778422 -1.1707702\n",
      " -0.12976451 -0.2574017  -1.2559929  -0.09106639 -0.26806882 -1.3711171\n",
      "  0.01476059 -0.2777077  -1.1868947   0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F588>\n",
      "tensor([[-0.0122, -0.0195, -0.1724,  ...,  0.0101, -0.2068, -1.1632],\n",
      "        [-0.0122, -0.0195, -0.1724,  ...,  0.0101, -0.2068, -1.1632],\n",
      "        [-0.0122, -0.0195, -0.1724,  ...,  0.0101, -0.2068, -1.1632],\n",
      "        ...,\n",
      "        [-0.1941,  0.3325, -0.0229,  ..., -0.7489,  0.9045, -0.3570],\n",
      "        [-0.1131, -0.1226,  0.5862,  ..., -0.2228,  0.6012,  0.2420],\n",
      "        [-0.1131, -0.1226,  0.5862,  ..., -0.2228,  0.6012,  0.2420]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01221296 -0.01951683 -0.17237547  0.01078413 -0.12084042 -0.47560734\n",
      " -0.14078696 -0.3448194  -1.3173352  -0.29581323 -0.40883246 -1.6034589\n",
      " -0.44991168 -0.49025783 -2.1127825  -0.20737389 -0.6602268  -1.4819871\n",
      " -0.0516589  -0.72161865 -1.326645   -0.09242678 -0.6409651  -1.3823396\n",
      " -0.08916516 -0.81017137 -1.5093873  -0.1683001  -0.5742959  -1.3847604\n",
      " -0.11386181 -0.6201432  -1.353158   -0.11700919 -0.5824908  -1.4409254\n",
      "  0.04607001 -0.6052184  -1.46092    -0.09146855 -0.463995   -1.2279161\n",
      " -0.24076003 -0.22823507 -1.9759616  -0.05165398 -0.38994256 -2.007112\n",
      "  0.14219874 -0.35192385 -1.3309193  -0.20756918 -0.23559909 -1.1477194\n",
      " -0.15100862 -0.20222166 -1.2401588  -0.11655803 -0.19351341 -1.3572863\n",
      "  0.01007728 -0.20681125 -1.1632085 ]\n",
      "data: [-0.01221296 -0.01951683 -0.17237547  0.01078413 -0.12084042 -0.47560734\n",
      " -0.14078696 -0.34481943 -1.3173352  -0.29581323 -0.40883246 -1.6034589\n",
      " -0.44991168 -0.49025783 -2.1127825  -0.20737389 -0.6602268  -1.4819871\n",
      " -0.0516589  -0.72161865 -1.326645   -0.09242678 -0.6409651  -1.3823396\n",
      " -0.08916517 -0.81017137 -1.5093873  -0.1683001  -0.5742959  -1.3847604\n",
      " -0.11386181 -0.6201432  -1.353158   -0.11700919 -0.5824908  -1.4409252\n",
      "  0.04607001 -0.6052184  -1.46092    -0.09146855 -0.463995   -1.2279161\n",
      " -0.24076003 -0.22823507 -1.9759616  -0.05165398 -0.38994256 -2.007112\n",
      "  0.14219874 -0.35192385 -1.3309191  -0.20756918 -0.23559909 -1.1477194\n",
      " -0.15100862 -0.20222166 -1.2401588  -0.11655803 -0.19351341 -1.3572863\n",
      "  0.01007728 -0.20681125 -1.1632085   0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[-0.0265, -0.0443, -0.2391,  ..., -0.0049, -0.2073, -1.3413],\n",
      "        [-0.0265, -0.0443, -0.2391,  ..., -0.0049, -0.2073, -1.3413],\n",
      "        [-0.0265, -0.0443, -0.2391,  ..., -0.0049, -0.2073, -1.3413],\n",
      "        ...,\n",
      "        [-0.2354,  0.3038, -0.0719,  ..., -0.7485,  0.7761, -0.2819],\n",
      "        [-0.1701, -0.1121,  0.5261,  ..., -0.2801,  0.6466,  0.2580],\n",
      "        [-0.1701, -0.1121,  0.5261,  ..., -0.2801,  0.6466,  0.2580]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.02647715 -0.04427917 -0.23907028 -0.01347316 -0.20134161 -0.68356276\n",
      " -0.07764752 -0.35760206 -1.3852165  -0.2236856  -0.41321963 -1.6908458\n",
      " -0.4112196  -0.5399482  -2.1558254  -0.247407   -0.6335511  -1.551633\n",
      "  0.00630017 -0.64094245 -1.3345646  -0.03879696 -0.5815222  -1.38667\n",
      " -0.03396164 -0.68881536 -1.5016315  -0.20291056 -0.51709425 -1.4751363\n",
      " -0.09584155 -0.57182753 -1.4573326  -0.09452031 -0.54290986 -1.5653425\n",
      "  0.04530135 -0.5619247  -1.6347537  -0.10324716 -0.4453716  -1.297861\n",
      " -0.19123043 -0.2149047  -1.858316   -0.04792367 -0.3577793  -1.8428115\n",
      "  0.11104997 -0.32640138 -1.4866424  -0.20571083 -0.19717404 -1.2447718\n",
      " -0.11589526 -0.1761277  -1.3241389  -0.06011948 -0.198919   -1.447408\n",
      " -0.00491882 -0.20726772 -1.3412871 ]\n",
      "data: [-0.02647715 -0.04427917 -0.23907028 -0.01347316 -0.20134161 -0.68356276\n",
      " -0.07764752 -0.35760203 -1.3852165  -0.2236856  -0.41321963 -1.6908458\n",
      " -0.4112196  -0.5399482  -2.1558254  -0.247407   -0.6335511  -1.551633\n",
      "  0.00630017 -0.64094245 -1.3345646  -0.03879696 -0.5815222  -1.3866699\n",
      " -0.03396164 -0.68881536 -1.5016315  -0.20291056 -0.51709425 -1.4751363\n",
      " -0.09584155 -0.57182753 -1.4573326  -0.09452031 -0.54290986 -1.5653425\n",
      "  0.04530135 -0.5619247  -1.6347537  -0.10324716 -0.4453716  -1.297861\n",
      " -0.19123043 -0.2149047  -1.858316   -0.04792367 -0.35777932 -1.8428115\n",
      "  0.11104997 -0.32640135 -1.4866424  -0.20571083 -0.19717403 -1.2447718\n",
      " -0.11589525 -0.1761277  -1.324139   -0.06011948 -0.198919   -1.447408\n",
      " -0.00491882 -0.20726772 -1.3412871   0.1       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FB00>\n",
      "tensor([[ 0.0323, -0.1593, -0.2560,  ...,  0.0422, -0.3322, -1.3509],\n",
      "        [ 0.0323, -0.1593, -0.2560,  ...,  0.0422, -0.3322, -1.3509],\n",
      "        [ 0.0323, -0.1593, -0.2560,  ...,  0.0422, -0.3322, -1.3509],\n",
      "        ...,\n",
      "        [-0.3638,  0.3161, -0.3838,  ..., -0.8946,  0.7929, -0.5761],\n",
      "        [-0.1562, -0.0241,  0.6588,  ..., -0.2531,  0.7445,  0.3549],\n",
      "        [-0.1562, -0.0241,  0.6588,  ..., -0.2531,  0.7445,  0.3549]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 3.2281902e-02 -1.5932040e-01 -2.5604641e-01  5.7168100e-02\n",
      " -2.9721183e-01 -6.7482585e-01 -1.7562367e-02 -4.6619317e-01\n",
      " -1.4180162e+00 -1.6014907e-01 -5.2309239e-01 -1.7194613e+00\n",
      " -3.2315266e-01 -6.3492036e-01 -2.2127180e+00 -1.7250912e-01\n",
      " -7.5450814e-01 -1.5981178e+00  5.7390422e-02 -7.7576828e-01\n",
      " -1.4121785e+00  5.0859004e-03 -7.1658945e-01 -1.4659947e+00\n",
      "  6.2972307e-05 -8.3744848e-01 -1.5838314e+00 -1.3154756e-01\n",
      " -6.5180051e-01 -1.5156091e+00 -4.1641548e-02 -7.0242846e-01\n",
      " -1.5017561e+00 -5.1654272e-02 -6.7161667e-01 -1.6021274e+00\n",
      "  7.0772290e-02 -6.9818652e-01 -1.6540765e+00 -4.2363845e-02\n",
      " -5.6691790e-01 -1.3439214e+00 -1.4718030e-01 -3.3713371e-01\n",
      " -1.9489239e+00 -7.3163211e-04 -4.8504817e-01 -1.9472644e+00\n",
      "  1.4519979e-01 -4.5341691e-01 -1.5104817e+00 -1.4813118e-01\n",
      " -3.3072335e-01 -1.2821810e+00 -6.3470170e-02 -3.0736637e-01\n",
      " -1.3579447e+00 -2.0277768e-02 -3.2338572e-01 -1.4759816e+00\n",
      "  4.2225674e-02 -3.3219969e-01 -1.3508815e+00]\n",
      "data: [ 3.2281902e-02 -1.5932040e-01 -2.5604641e-01  5.7168104e-02\n",
      " -2.9721183e-01 -6.7482585e-01 -1.7562367e-02 -4.6619317e-01\n",
      " -1.4180162e+00 -1.6014905e-01 -5.2309239e-01 -1.7194613e+00\n",
      " -3.2315266e-01 -6.3492036e-01 -2.2127180e+00 -1.7250912e-01\n",
      " -7.5450814e-01 -1.5981178e+00  5.7390422e-02 -7.7576828e-01\n",
      " -1.4121785e+00  5.0859004e-03 -7.1658945e-01 -1.4659947e+00\n",
      "  6.2972307e-05 -8.3744848e-01 -1.5838314e+00 -1.3154756e-01\n",
      " -6.5180051e-01 -1.5156091e+00 -4.1641548e-02 -7.0242846e-01\n",
      " -1.5017562e+00 -5.1654272e-02 -6.7161667e-01 -1.6021274e+00\n",
      "  7.0772290e-02 -6.9818652e-01 -1.6540763e+00 -4.2363845e-02\n",
      " -5.6691790e-01 -1.3439213e+00 -1.4718030e-01 -3.3713371e-01\n",
      " -1.9489239e+00 -7.3163211e-04 -4.8504817e-01 -1.9472644e+00\n",
      "  1.4519979e-01 -4.5341691e-01 -1.5104817e+00 -1.4813118e-01\n",
      " -3.3072335e-01 -1.2821811e+00 -6.3470170e-02 -3.0736637e-01\n",
      " -1.3579448e+00 -2.0277767e-02 -3.2338569e-01 -1.4759816e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4.2225674e-02 -3.3219969e-01 -1.3508815e+00  1.1000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0353, -0.1734, -0.2360,  ...,  0.0893, -0.3600, -1.2703],\n",
      "        [ 0.0353, -0.1734, -0.2360,  ...,  0.0893, -0.3600, -1.2703],\n",
      "        [ 0.0353, -0.1734, -0.2360,  ...,  0.0893, -0.3600, -1.2703],\n",
      "        ...,\n",
      "        [-0.0679,  0.4841, -0.1292,  ..., -0.6250,  1.0129, -0.4802],\n",
      "        [-0.1654, -0.0341,  0.6249,  ..., -0.2452,  0.6606,  0.3022],\n",
      "        [-0.1654, -0.0341,  0.6249,  ..., -0.2452,  0.6606,  0.3022]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03528165 -0.17344403 -0.2359625   0.07233478 -0.29329365 -0.55820733\n",
      " -0.02182698 -0.50843817 -1.385828   -0.1731872  -0.56922877 -1.7002871\n",
      " -0.3322549  -0.6907932  -2.2006679  -0.16944154 -0.7887374  -1.5959706\n",
      "  0.08437431 -0.8408869  -1.4060671   0.01968625 -0.7844103  -1.4474926\n",
      "  0.00471692 -0.93304956 -1.5758383  -0.1114136  -0.68903834 -1.4849896\n",
      " -0.02435976 -0.7567875  -1.4724143  -0.0230199  -0.726938   -1.5678449\n",
      "  0.0946724  -0.7806461  -1.608279   -0.00292956 -0.58122563 -1.3036544\n",
      " -0.15918888 -0.3440941  -2.053091    0.03340822 -0.53541666 -2.0569718\n",
      "  0.19578724 -0.48808205 -1.4515297  -0.13963993 -0.34503382 -1.2301335\n",
      " -0.0306882  -0.32138258 -1.3079009   0.01446123 -0.35423267 -1.4226646\n",
      "  0.08927412 -0.3600458  -1.2702577 ]\n",
      "data: [ 0.03528165 -0.17344402 -0.23596248  0.07233478 -0.29329365 -0.55820733\n",
      " -0.02182698 -0.50843817 -1.3858279  -0.1731872  -0.56922877 -1.7002872\n",
      " -0.33225486 -0.6907932  -2.2006679  -0.16944152 -0.7887374  -1.5959706\n",
      "  0.08437432 -0.8408869  -1.4060673   0.01968625 -0.7844103  -1.4474927\n",
      "  0.00471692 -0.93304956 -1.5758383  -0.11141359 -0.68903834 -1.4849896\n",
      " -0.02435976 -0.7567875  -1.4724143  -0.0230199  -0.726938   -1.5678449\n",
      "  0.0946724  -0.7806461  -1.608279   -0.00292956 -0.58122563 -1.3036544\n",
      " -0.15918888 -0.3440941  -2.053091    0.03340822 -0.53541666 -2.0569718\n",
      "  0.19578724 -0.48808205 -1.4515297  -0.13963993 -0.34503382 -1.2301335\n",
      " -0.03068819 -0.3213826  -1.3079009   0.01446123 -0.35423267 -1.4226646\n",
      "  0.08927412 -0.3600458  -1.2702577   0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[ 0.0212, -0.1570, -0.1983,  ...,  0.0791, -0.3484, -1.2077],\n",
      "        [ 0.0212, -0.1570, -0.1983,  ...,  0.0791, -0.3484, -1.2077],\n",
      "        [ 0.0212, -0.1570, -0.1983,  ...,  0.0791, -0.3484, -1.2077],\n",
      "        ...,\n",
      "        [-0.0617,  0.4504, -0.0755,  ..., -0.5759,  1.0076, -0.4486],\n",
      "        [-0.0949,  0.0157,  0.6340,  ..., -0.1683,  0.6897,  0.2760],\n",
      "        [-0.0949,  0.0157,  0.6340,  ..., -0.1683,  0.6897,  0.2760]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02121846 -0.1570064  -0.19827941  0.05410865 -0.28437907 -0.51209664\n",
      " -0.0406084  -0.49883997 -1.345313   -0.19343191 -0.5621865  -1.6618816\n",
      " -0.36463016 -0.6891098  -2.1554716  -0.18780719 -0.77518964 -1.5476375\n",
      "  0.07059209 -0.82337844 -1.3447245   0.00493374 -0.7694763  -1.3867979\n",
      " -0.00669542 -0.9143131  -1.5159769  -0.12959513 -0.6700028  -1.43577\n",
      " -0.03904088 -0.739156   -1.4181229  -0.03737925 -0.71121    -1.5158329\n",
      "  0.0854644  -0.7623627  -1.557787   -0.01896315 -0.5653377  -1.2477964\n",
      " -0.17316218 -0.33178622 -1.9930304   0.01838289 -0.5211983  -1.993432\n",
      "  0.18653299 -0.4763216  -1.3897524  -0.15327768 -0.32594913 -1.1760708\n",
      " -0.04323806 -0.30762208 -1.2498283   0.00270906 -0.3405652  -1.3654996\n",
      "  0.07914429 -0.34843814 -1.2077348 ]\n",
      "data: [ 0.02121846 -0.1570064  -0.19827943  0.05410864 -0.28437907 -0.51209664\n",
      " -0.04060839 -0.49883997 -1.345313   -0.19343191 -0.5621865  -1.6618816\n",
      " -0.36463016 -0.6891098  -2.1554716  -0.18780717 -0.77518964 -1.5476375\n",
      "  0.07059209 -0.82337844 -1.3447245   0.00493374 -0.7694763  -1.3867979\n",
      " -0.00669542 -0.9143131  -1.5159769  -0.12959513 -0.6700028  -1.4357699\n",
      " -0.03904088 -0.739156   -1.4181229  -0.03737925 -0.71121    -1.5158328\n",
      "  0.0854644  -0.7623627  -1.5577868  -0.01896315 -0.5653377  -1.2477964\n",
      " -0.17316218 -0.33178625 -1.9930304   0.01838289 -0.5211983  -1.993432\n",
      "  0.18653299 -0.4763216  -1.3897524  -0.15327768 -0.32594913 -1.1760708\n",
      " -0.04323806 -0.30762208 -1.2498283   0.00270906 -0.34056517 -1.3654996\n",
      "  0.07914429 -0.34843814 -1.2077348   0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[ 0.0092, -0.1104, -0.1812,  ...,  0.0430, -0.3011, -1.1755],\n",
      "        [ 0.0092, -0.1104, -0.1812,  ...,  0.0430, -0.3011, -1.1755],\n",
      "        [ 0.0092, -0.1104, -0.1812,  ...,  0.0430, -0.3011, -1.1755],\n",
      "        ...,\n",
      "        [-0.1724,  0.4156, -0.1258,  ..., -0.5874,  0.9873, -0.5281],\n",
      "        [-0.0893, -0.0183,  0.6398,  ..., -0.1616,  0.6751,  0.2665],\n",
      "        [-0.0893, -0.0183,  0.6398,  ..., -0.1616,  0.6751,  0.2665]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00920619 -0.11040959 -0.18120907  0.04277122 -0.22130924 -0.46345684\n",
      " -0.08504365 -0.45249438 -1.3334761  -0.24113393 -0.5194492  -1.6346922\n",
      " -0.39686683 -0.6239455  -2.1505454  -0.1927304  -0.74617255 -1.5255258\n",
      "  0.01588856 -0.8078392  -1.3503425  -0.04421407 -0.74164844 -1.3960652\n",
      " -0.05786277 -0.9008874  -1.526479   -0.14358056 -0.65219426 -1.4154484\n",
      " -0.07498737 -0.71066946 -1.3926358  -0.07935505 -0.67364955 -1.4802003\n",
      "  0.05254887 -0.7175128  -1.5053918  -0.04679558 -0.5374482  -1.2434316\n",
      " -0.21095833 -0.2997893  -2.0084288  -0.01760805 -0.48211265 -2.025835\n",
      "  0.15672275 -0.43630862 -1.3574083  -0.18001188 -0.3046372  -1.1647704\n",
      " -0.09156282 -0.2778916  -1.2449939  -0.05596478 -0.2922063  -1.3578541\n",
      "  0.04302462 -0.3010909  -1.1754882 ]\n",
      "data: [ 0.00920619 -0.11040959 -0.18120907  0.04277122 -0.22130924 -0.46345684\n",
      " -0.08504365 -0.45249438 -1.3334761  -0.24113391 -0.5194492  -1.6346922\n",
      " -0.39686683 -0.6239455  -2.1505454  -0.19273038 -0.74617255 -1.5255258\n",
      "  0.01588856 -0.8078392  -1.3503425  -0.04421407 -0.74164844 -1.3960652\n",
      " -0.05786277 -0.9008874  -1.526479   -0.14358056 -0.65219426 -1.4154484\n",
      " -0.07498737 -0.71066946 -1.3926358  -0.07935505 -0.67364955 -1.4802003\n",
      "  0.05254887 -0.71751285 -1.5053918  -0.04679558 -0.5374482  -1.2434316\n",
      " -0.21095833 -0.2997893  -2.0084288  -0.01760805 -0.48211265 -2.025835\n",
      "  0.15672275 -0.43630862 -1.3574083  -0.18001188 -0.3046372  -1.1647704\n",
      " -0.09156282 -0.2778916  -1.2449939  -0.05596478 -0.2922063  -1.3578541\n",
      "  0.04302462 -0.3010909  -1.1754882   0.14      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0329, -0.0766, -0.1995,  ...,  0.0200, -0.2576, -1.1957],\n",
      "        [-0.0329, -0.0766, -0.1995,  ...,  0.0200, -0.2576, -1.1957],\n",
      "        [-0.0329, -0.0766, -0.1995,  ...,  0.0200, -0.2576, -1.1957],\n",
      "        ...,\n",
      "        [-0.1643,  0.3589, -0.0141,  ..., -0.6540,  0.9554, -0.3974],\n",
      "        [-0.0946, -0.0561,  0.6126,  ..., -0.2384,  0.6479,  0.2591],\n",
      "        [-0.0946, -0.0561,  0.6126,  ..., -0.2384,  0.6479,  0.2591]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.03291847 -0.07664266 -0.19953525 -0.00251754 -0.19424416 -0.5091144\n",
      " -0.11393487 -0.41235706 -1.3444035  -0.26436952 -0.47320548 -1.6481514\n",
      " -0.42552197 -0.58772004 -2.141229   -0.24075912 -0.6997516  -1.5260775\n",
      " -0.00451471 -0.7491297  -1.3347075  -0.05916198 -0.6865891  -1.3772871\n",
      " -0.06023099 -0.833573   -1.5081592  -0.18805556 -0.59946775 -1.4183464\n",
      " -0.10291313 -0.6591323  -1.3988049  -0.09082948 -0.6221423  -1.489409\n",
      "  0.05096409 -0.6690146  -1.5291426  -0.08433003 -0.49231693 -1.2416303\n",
      " -0.2380556  -0.25142297 -1.9882412  -0.03669168 -0.4333969  -1.9971795\n",
      "  0.14737137 -0.38597536 -1.3778822  -0.21902314 -0.25333196 -1.1639681\n",
      " -0.11793052 -0.22618376 -1.2455053  -0.07188539 -0.2482675  -1.3621953\n",
      "  0.01998162 -0.2576353  -1.1956732 ]\n",
      "data: [-0.03291847 -0.07664266 -0.19953525 -0.00251754 -0.19424416 -0.5091144\n",
      " -0.11393487 -0.41235706 -1.3444035  -0.26436952 -0.47320548 -1.6481514\n",
      " -0.42552197 -0.58772004 -2.141229   -0.24075912 -0.6997516  -1.5260776\n",
      " -0.00451471 -0.7491297  -1.3347075  -0.05916198 -0.6865891  -1.3772871\n",
      " -0.06023099 -0.833573   -1.5081592  -0.18805556 -0.59946775 -1.4183464\n",
      " -0.10291313 -0.6591323  -1.3988049  -0.09082948 -0.6221423  -1.489409\n",
      "  0.05096409 -0.6690146  -1.5291426  -0.08433004 -0.49231693 -1.2416303\n",
      " -0.23805562 -0.25142297 -1.9882413  -0.03669168 -0.4333969  -1.9971795\n",
      "  0.14737137 -0.38597533 -1.3778822  -0.21902314 -0.25333196 -1.1639681\n",
      " -0.11793052 -0.22618376 -1.2455053  -0.07188539 -0.2482675  -1.3621953\n",
      "  0.01998162 -0.2576353  -1.1956732   0.15      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F635F8>\n",
      "tensor([[-0.0100, -0.0466, -0.2143,  ..., -0.0199, -0.2168, -1.2462],\n",
      "        [-0.0100, -0.0466, -0.2143,  ..., -0.0199, -0.2168, -1.2462],\n",
      "        [-0.0100, -0.0466, -0.2143,  ..., -0.0199, -0.2168, -1.2462],\n",
      "        ...,\n",
      "        [-0.2809,  0.2417, -0.1651,  ..., -0.7172,  0.7234, -0.4467],\n",
      "        [-0.0646, -0.0535,  0.6542,  ..., -0.1620,  0.7063,  0.3082],\n",
      "        [-0.0646, -0.0535,  0.6542,  ..., -0.1620,  0.7063,  0.3082]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01002109 -0.04658733 -0.21429077  0.00945795 -0.17111917 -0.59071296\n",
      " -0.10679469 -0.37178478 -1.373664   -0.2568999  -0.4326542  -1.6718144\n",
      " -0.42743862 -0.52613306 -2.1605487  -0.21557136 -0.6689651  -1.527144\n",
      " -0.03218327 -0.7088196  -1.3406271  -0.07770534 -0.6414557  -1.3994038\n",
      " -0.08764682 -0.791536   -1.5238743  -0.1792225  -0.56969684 -1.4360394\n",
      " -0.11512566 -0.6183773  -1.4078465  -0.12803651 -0.5878093  -1.5066216\n",
      "  0.01653478 -0.6079291  -1.5452574  -0.1007706  -0.467213   -1.2717396\n",
      " -0.23582543 -0.24115092 -1.9654263  -0.07061258 -0.39260775 -1.9821033\n",
      "  0.09677228 -0.35843438 -1.4011675  -0.20688541 -0.23466627 -1.2025263\n",
      " -0.14990725 -0.20591119 -1.2864199  -0.11380653 -0.20513229 -1.4071771\n",
      " -0.01992923 -0.21676044 -1.2462152 ]\n",
      "data: [-0.01002109 -0.04658733 -0.21429077  0.00945795 -0.17111917 -0.59071296\n",
      " -0.10679469 -0.37178478 -1.3736641  -0.2568999  -0.4326542  -1.6718144\n",
      " -0.42743862 -0.52613306 -2.1605487  -0.21557136 -0.6689651  -1.527144\n",
      " -0.03218327 -0.7088196  -1.3406272  -0.07770534 -0.6414557  -1.3994038\n",
      " -0.08764682 -0.791536   -1.5238742  -0.1792225  -0.56969684 -1.4360394\n",
      " -0.11512566 -0.6183773  -1.4078463  -0.12803651 -0.5878093  -1.5066216\n",
      "  0.01653478 -0.6079291  -1.5452574  -0.1007706  -0.46721303 -1.2717396\n",
      " -0.23582545 -0.24115092 -1.9654263  -0.07061258 -0.39260778 -1.9821032\n",
      "  0.09677228 -0.35843438 -1.4011674  -0.20688541 -0.23466627 -1.2025263\n",
      " -0.14990725 -0.2059112  -1.2864199  -0.11380653 -0.20513229 -1.4071771\n",
      " -0.01992923 -0.21676044 -1.2462152   0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F080>\n",
      "tensor([[ 0.0212, -0.0505, -0.1966,  ...,  0.0223, -0.2271, -1.2627],\n",
      "        [ 0.0212, -0.0505, -0.1966,  ...,  0.0223, -0.2271, -1.2627],\n",
      "        [ 0.0212, -0.0505, -0.1966,  ...,  0.0223, -0.2271, -1.2627],\n",
      "        ...,\n",
      "        [-0.2965,  0.2887, -0.2409,  ..., -0.8180,  0.7438, -0.4318],\n",
      "        [-0.1716, -0.1602,  0.5465,  ..., -0.2462,  0.5995,  0.2456],\n",
      "        [-0.1716, -0.1602,  0.5465,  ..., -0.2462,  0.5995,  0.2456]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0211654  -0.05047559 -0.19663718  0.03375708 -0.18948393 -0.6221064\n",
      " -0.05906234 -0.3641242  -1.3494546  -0.2051312  -0.42508054 -1.6471419\n",
      " -0.38119656 -0.52996993 -2.1240613  -0.18461256 -0.6602026  -1.4982786\n",
      "  0.0088423  -0.68728304 -1.3219869  -0.0382815  -0.6216347  -1.3821883\n",
      " -0.03994044 -0.75778866 -1.4974217  -0.14644247 -0.5579792  -1.4188471\n",
      " -0.07026481 -0.60723066 -1.3945801  -0.0882373  -0.5809759  -1.4975753\n",
      "  0.04892914 -0.5958185  -1.5435283  -0.06600761 -0.47175792 -1.2538061\n",
      " -0.17231993 -0.24804536 -1.8771422  -0.02922847 -0.38903585 -1.8828504\n",
      "  0.12551506 -0.36451897 -1.4048293  -0.16053669 -0.23558243 -1.192677\n",
      " -0.0974599  -0.2131626  -1.279881   -0.05736805 -0.21597034 -1.4012647\n",
      "  0.022284   -0.22708045 -1.2626698 ]\n",
      "data: [ 0.0211654  -0.05047559 -0.1966372   0.03375708 -0.18948393 -0.6221064\n",
      " -0.05906234 -0.3641242  -1.3494546  -0.2051312  -0.42508054 -1.6471419\n",
      " -0.38119656 -0.52996993 -2.1240613  -0.18461256 -0.6602026  -1.4982786\n",
      "  0.0088423  -0.68728304 -1.3219868  -0.0382815  -0.6216347  -1.3821883\n",
      " -0.03994044 -0.7577887  -1.4974217  -0.14644247 -0.5579792  -1.4188471\n",
      " -0.07026481 -0.60723066 -1.3945801  -0.08823731 -0.5809759  -1.4975753\n",
      "  0.04892914 -0.5958185  -1.5435283  -0.06600761 -0.47175792 -1.2538061\n",
      " -0.17231993 -0.24804536 -1.8771422  -0.02922847 -0.38903582 -1.8828503\n",
      "  0.12551506 -0.36451897 -1.4048293  -0.16053669 -0.23558243 -1.192677\n",
      " -0.0974599  -0.2131626  -1.279881   -0.05736805 -0.21597034 -1.4012647\n",
      "  0.022284   -0.22708043 -1.2626698   0.17      ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0177, -0.0627, -0.2417,  ...,  0.0260, -0.2482, -1.2737],\n",
      "        [ 0.0177, -0.0627, -0.2417,  ...,  0.0260, -0.2482, -1.2737],\n",
      "        [ 0.0177, -0.0627, -0.2417,  ...,  0.0260, -0.2482, -1.2737],\n",
      "        ...,\n",
      "        [-0.3004,  0.2559, -0.2681,  ..., -0.8152,  0.7170, -0.4528],\n",
      "        [-0.1148, -0.0842,  0.6048,  ..., -0.2336,  0.7112,  0.2694],\n",
      "        [-0.1148, -0.0842,  0.6048,  ..., -0.2336,  0.7112,  0.2694]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01767841 -0.06270254 -0.24172597  0.04404687 -0.18799989 -0.6367176\n",
      " -0.07738718 -0.38413763 -1.4199529  -0.22087315 -0.4511103  -1.7013267\n",
      " -0.3752348  -0.5410601  -2.1944463  -0.17190146 -0.6800946  -1.5689623\n",
      " -0.00744689 -0.72265536 -1.3960717  -0.0517709  -0.650134   -1.4557456\n",
      " -0.06143471 -0.8000837  -1.5723823  -0.13865767 -0.5873041  -1.4872031\n",
      " -0.07763106 -0.6355318  -1.4501501  -0.10319206 -0.60618025 -1.5356202\n",
      "  0.03562517 -0.62229806 -1.5654371  -0.06828759 -0.49526614 -1.3266162\n",
      " -0.1897711  -0.26589316 -1.9969885  -0.03727631 -0.41604847 -2.0132692\n",
      "  0.1194064  -0.3879677  -1.4298156  -0.16274984 -0.26639903 -1.2547051\n",
      " -0.1098426  -0.23776166 -1.3342785  -0.07161406 -0.23196076 -1.4508628\n",
      "  0.02602027 -0.24818867 -1.2737225 ]\n",
      "data: [ 0.01767841 -0.06270254 -0.24172597  0.04404687 -0.1879999  -0.6367176\n",
      " -0.07738718 -0.38413766 -1.4199529  -0.22087315 -0.4511103  -1.7013267\n",
      " -0.37523478 -0.5410601  -2.1944463  -0.17190148 -0.6800946  -1.5689625\n",
      " -0.00744689 -0.72265536 -1.3960717  -0.0517709  -0.650134   -1.4557456\n",
      " -0.06143471 -0.8000837  -1.5723823  -0.13865767 -0.5873041  -1.4872031\n",
      " -0.07763106 -0.6355318  -1.4501501  -0.10319206 -0.60618025 -1.5356202\n",
      "  0.03562517 -0.62229806 -1.565437   -0.06828759 -0.49526614 -1.3266162\n",
      " -0.1897711  -0.26589316 -1.9969885  -0.03727631 -0.41604847 -2.0132692\n",
      "  0.1194064  -0.3879677  -1.4298156  -0.16274984 -0.26639903 -1.2547051\n",
      " -0.1098426  -0.23776168 -1.3342785  -0.07161406 -0.23196076 -1.4508628\n",
      "  0.02602027 -0.24818867 -1.2737225   0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63F28>\n",
      "tensor([[ 0.0370, -0.0206, -0.2148,  ...,  0.0534, -0.2165, -1.2428],\n",
      "        [ 0.0370, -0.0206, -0.2148,  ...,  0.0534, -0.2165, -1.2428],\n",
      "        [ 0.0370, -0.0206, -0.2148,  ...,  0.0534, -0.2165, -1.2428],\n",
      "        ...,\n",
      "        [-0.1964,  0.3326, -0.1276,  ..., -0.8665,  0.7986, -0.3113],\n",
      "        [-0.1444, -0.2043,  0.5417,  ..., -0.2163,  0.5659,  0.2174],\n",
      "        [-0.1444, -0.2043,  0.5417,  ..., -0.2163,  0.5659,  0.2174]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03700146 -0.02062795 -0.21475615  0.05044262 -0.14969347 -0.6100035\n",
      " -0.06524838 -0.33640516 -1.3596042  -0.21229129 -0.40091464 -1.6461729\n",
      " -0.37938738 -0.49581397 -2.1304321  -0.15640317 -0.6422946  -1.5085875\n",
      "  0.00543308 -0.68149215 -1.3485421  -0.03848855 -0.6074935  -1.4118013\n",
      " -0.03418195 -0.7580929  -1.5253851  -0.11987756 -0.5476826  -1.4301478\n",
      " -0.05628897 -0.59382415 -1.3959904  -0.0774654  -0.5696681  -1.4890355\n",
      "  0.06672166 -0.57893157 -1.5184754  -0.04663341 -0.45910037 -1.2704586\n",
      " -0.15824193 -0.23620325 -1.9211133  -0.01019572 -0.38019085 -1.9352747\n",
      "  0.1528647  -0.35640842 -1.3867841  -0.13678317 -0.23022555 -1.2059196\n",
      " -0.08447917 -0.20748107 -1.2934237  -0.04812729 -0.20057057 -1.4116306\n",
      "  0.05337166 -0.21650855 -1.2427509 ]\n",
      "data: [ 0.03700146 -0.02062795 -0.21475615  0.05044262 -0.14969347 -0.6100035\n",
      " -0.06524838 -0.33640516 -1.3596042  -0.21229129 -0.40091464 -1.646173\n",
      " -0.37938735 -0.49581397 -2.1304321  -0.15640317 -0.64229465 -1.5085875\n",
      "  0.00543308 -0.68149215 -1.348542   -0.03848855 -0.6074935  -1.4118013\n",
      " -0.03418195 -0.7580929  -1.5253851  -0.11987755 -0.5476826  -1.4301476\n",
      " -0.05628897 -0.59382415 -1.3959903  -0.0774654  -0.5696681  -1.4890355\n",
      "  0.06672166 -0.57893157 -1.5184753  -0.04663341 -0.45910037 -1.2704586\n",
      " -0.15824193 -0.23620325 -1.9211133  -0.01019572 -0.38019085 -1.9352746\n",
      "  0.1528647  -0.35640842 -1.3867841  -0.13678317 -0.23022555 -1.2059196\n",
      " -0.08447917 -0.20748109 -1.2934237  -0.04812729 -0.20057057 -1.4116305\n",
      "  0.05337166 -0.21650857 -1.2427509   0.19      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F358>\n",
      "tensor([[ 0.0105, -0.0675, -0.2339,  ...,  0.0333, -0.2498, -1.2820],\n",
      "        [ 0.0105, -0.0675, -0.2339,  ...,  0.0333, -0.2498, -1.2820],\n",
      "        [ 0.0105, -0.0675, -0.2339,  ...,  0.0333, -0.2498, -1.2820],\n",
      "        ...,\n",
      "        [-0.3359,  0.2206, -0.3029,  ..., -0.8750,  0.6431, -0.4498],\n",
      "        [-0.1204, -0.0530,  0.5813,  ..., -0.2389,  0.7447,  0.2423],\n",
      "        [-0.1204, -0.0530,  0.5813,  ..., -0.2389,  0.7447,  0.2423]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01054924 -0.06752459 -0.23389022  0.03627575 -0.2062505  -0.6504991\n",
      " -0.05819923 -0.38757378 -1.4080895  -0.19838628 -0.4511752  -1.6985343\n",
      " -0.35981792 -0.55913484 -2.1797564  -0.18682666 -0.6701329  -1.5623313\n",
      "  0.02002616 -0.6980088  -1.3661855  -0.02740888 -0.6337371  -1.4225543\n",
      " -0.03504371 -0.7648202  -1.5392692  -0.14868213 -0.5683532  -1.4810691\n",
      " -0.06737423 -0.62112916 -1.4508587  -0.08496358 -0.59306    -1.5414394\n",
      "  0.04710281 -0.6139333  -1.5863352  -0.06534588 -0.48520166 -1.3104539\n",
      " -0.17409346 -0.25630376 -1.9406735  -0.02565906 -0.40711054 -1.9419322\n",
      "  0.12611322 -0.3778586  -1.4403499  -0.16233356 -0.25085974 -1.244953\n",
      " -0.08943146 -0.22689655 -1.3181612  -0.04338391 -0.23554382 -1.4354422\n",
      "  0.03325351 -0.24983306 -1.2820153 ]\n",
      "data: [ 0.01054924 -0.06752459 -0.23389024  0.03627575 -0.20625049 -0.6504991\n",
      " -0.05819922 -0.38757378 -1.4080894  -0.19838628 -0.45117524 -1.6985343\n",
      " -0.35981792 -0.55913484 -2.1797564  -0.18682666 -0.6701329  -1.5623314\n",
      "  0.02002616 -0.6980088  -1.3661857  -0.02740888 -0.6337371  -1.4225544\n",
      " -0.03504371 -0.7648203  -1.5392692  -0.14868213 -0.5683532  -1.4810691\n",
      " -0.06737423 -0.62112916 -1.4508587  -0.08496358 -0.59306    -1.5414394\n",
      "  0.04710281 -0.6139333  -1.5863352  -0.06534588 -0.48520166 -1.3104539\n",
      " -0.17409346 -0.25630376 -1.9406735  -0.02565906 -0.40711057 -1.9419322\n",
      "  0.12611322 -0.3778586  -1.4403499  -0.16233356 -0.25085974 -1.244953\n",
      " -0.08943146 -0.22689655 -1.3181614  -0.04338391 -0.23554382 -1.4354422\n",
      "  0.03325351 -0.24983306 -1.2820153   0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0164, -0.0758, -0.2335,  ...,  0.0510, -0.2645, -1.2799],\n",
      "        [ 0.0164, -0.0758, -0.2335,  ...,  0.0510, -0.2645, -1.2799],\n",
      "        [ 0.0164, -0.0758, -0.2335,  ...,  0.0510, -0.2645, -1.2799],\n",
      "        ...,\n",
      "        [-0.1981,  0.3837, -0.1680,  ..., -0.8319,  0.8736, -0.3803],\n",
      "        [-0.1714, -0.1565,  0.5706,  ..., -0.2668,  0.6120,  0.2341],\n",
      "        [-0.1714, -0.1565,  0.5706,  ..., -0.2668,  0.6120,  0.2341]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01636136 -0.07580665 -0.23353331  0.0364192  -0.21386117 -0.6405394\n",
      " -0.0496557  -0.39989078 -1.3925748  -0.1888719  -0.4621846  -1.6895545\n",
      " -0.35488334 -0.5778726  -2.1601996  -0.1830242  -0.68368685 -1.5514016\n",
      "  0.03565158 -0.7159199  -1.3639722  -0.01571167 -0.6540824  -1.4173455\n",
      " -0.01633373 -0.7881709  -1.5342717  -0.13844734 -0.57967913 -1.4647703\n",
      " -0.05466431 -0.63475174 -1.4414389  -0.06379776 -0.6099297  -1.5342953\n",
      "  0.06436537 -0.63533396 -1.5808923  -0.0483206  -0.49348998 -1.294394\n",
      " -0.16427462 -0.26640832 -1.946847   -0.00719915 -0.42336422 -1.9461501\n",
      "  0.14722303 -0.39041138 -1.4365418  -0.15273471 -0.2575438  -1.2289767\n",
      " -0.069738   -0.23683672 -1.3117425  -0.02323446 -0.2520612  -1.4276004\n",
      "  0.05103339 -0.2644815  -1.2799339 ]\n",
      "data: [-5.11 -0.22  2.41 -4.95 -0.2   2.62 -4.83 -0.05  3.   -4.82  0.23  3.31\n",
      " -5.02  0.4   4.21 -4.88  0.47  2.94 -5.04  0.65  3.75 -5.06  0.65  3.75\n",
      " -4.98  0.57  3.41 -5.    0.54  2.84 -5.38  0.72  4.37 -5.18  0.65  3.68\n",
      " -4.96  0.53  2.9  -5.11  0.54  2.79 -5.64  0.71  4.59 -5.37  0.65  3.71\n",
      " -5.1   0.54  2.79 -5.3   0.44  2.87 -5.49  0.59  3.6  -5.47  0.59  3.6\n",
      " -5.45  0.56  3.6   0.  ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[ 0.0540, -0.1811,  0.1761,  ...,  0.0284, -0.4972,  0.1759],\n",
      "        [ 0.0540, -0.1811,  0.1761,  ...,  0.0284, -0.4972,  0.1759],\n",
      "        [ 0.0540, -0.1811,  0.1761,  ...,  0.0284, -0.4972,  0.1759],\n",
      "        ...,\n",
      "        [ 0.0176,  0.0090,  0.3921,  ..., -0.1019,  0.5688,  1.3812],\n",
      "        [ 0.0644,  0.2701,  0.3054,  ..., -1.1159,  0.6143,  1.9201],\n",
      "        [ 0.0644,  0.2701,  0.3054,  ..., -1.1159,  0.6143,  1.9201]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.05401364 -0.18111488  0.17605594 -0.0918     -0.24123251  0.00581007\n",
      " -0.18152748 -0.42487872 -0.07344082 -0.22125424 -0.570704   -0.03703938\n",
      " -0.24094972 -0.6847366   0.02074911 -0.24064705 -0.35547736 -0.42060414\n",
      " -0.1262252  -0.45536888  0.13687474 -0.20613864 -0.63886106  0.21006185\n",
      " -0.28478953 -0.68245435  0.15932861 -0.16692919 -0.31535345 -0.39692786\n",
      " -0.24962315 -0.49092445 -0.21490201 -0.26736602 -0.597756   -0.17059088\n",
      " -0.27776104 -0.7752935  -0.11508462 -0.11182569 -0.25034535 -0.34220788\n",
      " -0.23813367 -0.41718772 -0.2136358  -0.20852672 -0.5314485  -0.20192686\n",
      " -0.11215236 -0.633689    0.03211927 -0.10502802 -0.18951198 -0.2145505\n",
      " -0.03478566 -0.29805943 -0.03951478 -0.02582698 -0.4209762   0.01615216\n",
      "  0.02841414 -0.4971665   0.1759308 ]\n",
      "init: [ 0.05401364 -0.18111488  0.17605594 -0.0918     -0.24123251  0.00581007\n",
      " -0.18152748 -0.42487872 -0.07344082 -0.22125424 -0.570704   -0.03703938\n",
      " -0.24094972 -0.6847366   0.02074911 -0.24064705 -0.35547736 -0.42060414\n",
      " -0.1262252  -0.45536888  0.13687474 -0.20613864 -0.63886106  0.21006185\n",
      " -0.28478953 -0.68245435  0.15932861 -0.16692919 -0.31535345 -0.39692786\n",
      " -0.24962315 -0.49092445 -0.21490201 -0.26736602 -0.597756   -0.17059088\n",
      " -0.27776104 -0.7752935  -0.11508462 -0.11182569 -0.25034535 -0.34220788\n",
      " -0.23813367 -0.41718772 -0.2136358  -0.20852672 -0.5314485  -0.20192686\n",
      " -0.11215236 -0.633689    0.03211927 -0.10502802 -0.18951198 -0.2145505\n",
      " -0.03478566 -0.29805943 -0.03951478 -0.02582698 -0.4209762   0.01615216\n",
      "  0.02841414 -0.4971665   0.1759308 ]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [ 0.05401363 -0.18111488  0.17605595 -0.0918     -0.24123251  0.00581007\n",
      " -0.18152748 -0.42487872 -0.07344082 -0.22125426 -0.570704   -0.03703938\n",
      " -0.24094972 -0.6847366   0.02074911 -0.24064705 -0.35547736 -0.42060414\n",
      " -0.1262252  -0.45536888  0.13687474 -0.20613866 -0.63886106  0.21006185\n",
      " -0.28478953 -0.68245435  0.15932861 -0.16692919 -0.31535345 -0.39692786\n",
      " -0.24962315 -0.49092445 -0.21490201 -0.26736602 -0.597756   -0.17059088\n",
      " -0.27776104 -0.7752935  -0.11508462 -0.11182568 -0.25034535 -0.34220788\n",
      " -0.23813365 -0.41718772 -0.2136358  -0.2085267  -0.5314485  -0.20192686\n",
      " -0.11215236 -0.633689    0.03211927 -0.10502802 -0.18951198 -0.2145505\n",
      " -0.03478566 -0.29805943 -0.03951478 -0.02582698 -0.4209762   0.01615216\n",
      "  0.02841414 -0.4971665   0.1759308   0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F978>\n",
      "tensor([[-0.0290,  0.0030,  0.2442,  ..., -0.6143, -0.3058, -0.2517],\n",
      "        [-0.0290,  0.0030,  0.2442,  ..., -0.6143, -0.3058, -0.2517],\n",
      "        [-0.0290,  0.0030,  0.2442,  ..., -0.6143, -0.3058, -0.2517],\n",
      "        ...,\n",
      "        [ 0.7390, -0.2586,  0.2368,  ...,  0.6648,  0.6040, -0.6077],\n",
      "        [ 0.4507, -0.0786,  0.2361,  ...,  0.2891,  0.3237,  0.2466],\n",
      "        [ 0.4507, -0.0786,  0.2361,  ...,  0.2891,  0.3237,  0.2466]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.02903923  0.00304674  0.24420255 -0.09095132 -0.03781947 -0.12232557\n",
      " -0.1933571  -0.14426221 -0.27334145 -0.36428547 -0.19854699 -0.38557336\n",
      " -0.5753953  -0.26934114 -0.57693946 -0.3839842  -0.32476962 -0.5082544\n",
      " -0.6388412  -0.42461258 -0.97672534 -0.72342837 -0.44388062 -0.95214725\n",
      " -0.7275288  -0.627874   -0.8570466  -0.34574884 -0.31256536 -0.44613853\n",
      " -0.5266769  -0.47073248 -0.31422916 -0.7118219  -0.56513345 -0.38622156\n",
      " -0.78668046 -0.61065745 -0.37953016 -0.3620447  -0.29045746 -0.3904247\n",
      " -0.582532   -0.31917155 -0.5591563  -0.63807946 -0.46018022 -0.55917525\n",
      " -0.7759164  -0.5232961  -0.2666401  -0.37461972 -0.21165301 -0.34678575\n",
      " -0.52998835 -0.2776662  -0.26160267 -0.5503993  -0.33023936 -0.29737464\n",
      " -0.61426926 -0.30580312 -0.25171363]\n",
      "data: [-0.02903924  0.00304674  0.24420255 -0.09095133 -0.03781947 -0.12232557\n",
      " -0.19335708 -0.14426221 -0.27334145 -0.36428547 -0.19854698 -0.38557336\n",
      " -0.5753953  -0.26934114 -0.57693946 -0.3839842  -0.32476962 -0.5082544\n",
      " -0.6388412  -0.42461258 -0.97672534 -0.72342837 -0.44388062 -0.95214725\n",
      " -0.7275288  -0.627874   -0.8570466  -0.3457488  -0.31256536 -0.44613853\n",
      " -0.5266769  -0.4707325  -0.31422916 -0.7118219  -0.56513345 -0.38622153\n",
      " -0.78668046 -0.61065745 -0.37953013 -0.3620447  -0.29045746 -0.3904247\n",
      " -0.582532   -0.31917155 -0.5591563  -0.63807946 -0.4601802  -0.55917525\n",
      " -0.77591634 -0.5232961  -0.2666401  -0.37461972 -0.21165301 -0.34678572\n",
      " -0.52998835 -0.2776662  -0.26160267 -0.5503993  -0.3302394  -0.29737464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.61426926 -0.30580312 -0.25171363  0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[-0.0748, -0.1189, -0.0574,  ..., -0.3223, -0.2771, -0.6557],\n",
      "        [-0.0748, -0.1189, -0.0574,  ..., -0.3223, -0.2771, -0.6557],\n",
      "        [-0.0748, -0.1189, -0.0574,  ..., -0.3223, -0.2771, -0.6557],\n",
      "        ...,\n",
      "        [ 0.7293, -0.1316,  0.5657,  ...,  0.1059,  0.5611, -0.0732],\n",
      "        [ 0.3659, -0.1117,  0.5559,  ..., -0.2783,  0.5312, -0.0849],\n",
      "        [ 0.3659, -0.1117,  0.5559,  ..., -0.2783,  0.5312, -0.0849]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.07484499 -0.11889921 -0.05742908 -0.15431052 -0.20544028 -0.2734815\n",
      " -0.48125273 -0.42905998 -0.6885029  -0.6717006  -0.49511477 -0.81734455\n",
      " -0.96814835 -0.48790613 -1.12616    -0.4383262  -0.69758844 -0.8169558\n",
      " -0.7611598  -0.7206492  -1.0870963  -0.71723855 -0.6050428  -1.0974917\n",
      " -0.6687509  -0.79720813 -1.029336   -0.37688306 -0.6098869  -0.8022345\n",
      " -0.5194601  -0.63609827 -0.60746235 -0.59211123 -0.59561765 -0.65354115\n",
      " -0.40293196 -0.5020467  -0.76312315 -0.36531797 -0.5636118  -0.76320475\n",
      " -0.5130726  -0.4398809  -0.9568662  -0.45151263 -0.4767     -0.98875016\n",
      " -0.38700518 -0.36744642 -0.72664905 -0.33358642 -0.41462007 -0.7596042\n",
      " -0.532493   -0.34620315 -0.7397817  -0.44415495 -0.28077644 -0.8489352\n",
      " -0.32232663 -0.27706873 -0.6557028 ]\n",
      "data: [-0.07484499 -0.11889921 -0.05742908 -0.15431052 -0.2054403  -0.2734815\n",
      " -0.48125276 -0.42905998 -0.6885029  -0.6717006  -0.49511477 -0.8173445\n",
      " -0.96814835 -0.4879061  -1.12616    -0.43832624 -0.69758844 -0.8169558\n",
      " -0.7611597  -0.7206492  -1.0870963  -0.71723855 -0.6050428  -1.0974917\n",
      " -0.66875094 -0.7972081  -1.029336   -0.37688306 -0.6098869  -0.8022345\n",
      " -0.5194601  -0.63609827 -0.60746235 -0.59211123 -0.59561765 -0.6535412\n",
      " -0.402932   -0.5020467  -0.76312315 -0.36531794 -0.5636118  -0.76320475\n",
      " -0.5130726  -0.4398809  -0.9568662  -0.45151263 -0.4767     -0.98875016\n",
      " -0.3870052  -0.36744645 -0.72664905 -0.33358642 -0.41462004 -0.7596042\n",
      " -0.532493   -0.34620315 -0.7397816  -0.44415492 -0.28077644 -0.8489352\n",
      " -0.32232663 -0.27706873 -0.6557028   0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 1.3799e-01,  5.7962e-02, -1.6615e-01,  ...,  3.7581e-01,\n",
      "         -1.4836e-01, -1.1025e+00],\n",
      "        [ 1.3799e-01,  5.7962e-02, -1.6615e-01,  ...,  3.7581e-01,\n",
      "         -1.4836e-01, -1.1025e+00],\n",
      "        [ 1.3799e-01,  5.7962e-02, -1.6615e-01,  ...,  3.7581e-01,\n",
      "         -1.4836e-01, -1.1025e+00],\n",
      "        ...,\n",
      "        [ 1.1352e-01,  8.7945e-02,  7.6083e-01,  ..., -8.1419e-04,\n",
      "          1.0288e+00,  2.7295e-01],\n",
      "        [-1.6583e-01,  2.5111e-02,  5.0695e-01,  ..., -9.8617e-01,\n",
      "          4.3785e-01,  1.3965e-01],\n",
      "        [-1.6583e-01,  2.5111e-02,  5.0695e-01,  ..., -9.8617e-01,\n",
      "          4.3785e-01,  1.3965e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.13798922  0.05796214 -0.16614603  0.16982463 -0.06846429 -0.49118245\n",
      "  0.08713017 -0.2556251  -1.1788884  -0.03142381 -0.3015075  -1.447183\n",
      " -0.17329502 -0.44521248 -1.8567694  -0.06230548 -0.51110166 -1.3599346\n",
      "  0.21867386 -0.5262499  -1.1887994   0.1954228  -0.4553336  -1.2078568\n",
      "  0.23220955 -0.5731747  -1.3104142   0.00967227 -0.41344154 -1.2849672\n",
      "  0.15727526 -0.47966123 -1.2588419   0.21763104 -0.4270507  -1.3097281\n",
      "  0.38017195 -0.4856516  -1.3819767   0.15962583 -0.33819523 -1.1301552\n",
      "  0.05143583 -0.09774694 -1.7990295   0.29089937 -0.29556873 -1.7727735\n",
      "  0.48188624 -0.20815462 -1.2863582   0.04145192 -0.11917467 -1.0651352\n",
      "  0.19532093 -0.08327946 -1.138477    0.2910847  -0.13411462 -1.2630491\n",
      "  0.3758128  -0.14835954 -1.1024594 ]\n",
      "data: [ 0.13798922  0.05796214 -0.16614603  0.16982464 -0.06846429 -0.49118245\n",
      "  0.08713017 -0.2556251  -1.1788884  -0.03142381 -0.3015075  -1.4471831\n",
      " -0.17329502 -0.44521248 -1.8567694  -0.06230548 -0.51110166 -1.3599346\n",
      "  0.21867386 -0.5262499  -1.1887994   0.1954228  -0.4553336  -1.2078568\n",
      "  0.23220955 -0.5731747  -1.3104141   0.00967227 -0.41344154 -1.2849672\n",
      "  0.15727526 -0.47966123 -1.2588419   0.21763104 -0.4270507  -1.3097281\n",
      "  0.38017195 -0.4856516  -1.3819767   0.15962583 -0.33819523 -1.1301552\n",
      "  0.05143583 -0.09774694 -1.7990296   0.29089937 -0.29556873 -1.7727734\n",
      "  0.48188627 -0.20815462 -1.2863582   0.04145192 -0.11917467 -1.0651352\n",
      "  0.19532093 -0.08327946 -1.138477    0.2910847  -0.13411462 -1.2630491\n",
      "  0.3758128  -0.14835954 -1.1024594   0.04      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.1095, -0.1423, -0.1962,  ...,  0.1518, -0.2990, -1.2942],\n",
      "        [ 0.1095, -0.1423, -0.1962,  ...,  0.1518, -0.2990, -1.2942],\n",
      "        [ 0.1095, -0.1423, -0.1962,  ...,  0.1518, -0.2990, -1.2942],\n",
      "        ...,\n",
      "        [-0.2897,  0.3377, -0.0121,  ..., -0.8275,  0.7290, -0.3886],\n",
      "        [-0.3159,  0.1802,  0.3462,  ..., -0.3546,  1.0331, -0.0905],\n",
      "        [-0.3159,  0.1802,  0.3462,  ..., -0.3546,  1.0331, -0.0905]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.109479   -0.14229463 -0.1962444   0.13742292 -0.31140184 -0.6305066\n",
      "  0.08155867 -0.47762123 -1.3591118  -0.05530624 -0.5373087  -1.6613379\n",
      " -0.22983651 -0.67292976 -2.132369   -0.11037369 -0.7117264  -1.5503433\n",
      "  0.18182756 -0.71237266 -1.2648548   0.1328452  -0.66314375 -1.3092672\n",
      "  0.10263518 -0.75711477 -1.4253983  -0.06332073 -0.5844811  -1.4730614\n",
      "  0.0516049  -0.64715743 -1.457611    0.04676116 -0.6183878  -1.5487022\n",
      "  0.16215278 -0.64759624 -1.6321161   0.0495332  -0.5169625  -1.2908572\n",
      " -0.04732168 -0.28264976 -1.8549899   0.09674959 -0.44259977 -1.8248763\n",
      "  0.22662623 -0.39357176 -1.4640279  -0.05095427 -0.2733528  -1.2378756\n",
      "  0.05438361 -0.24806735 -1.2842965   0.12129675 -0.28569543 -1.4028554\n",
      "  0.15177554 -0.29903632 -1.2941502 ]\n",
      "data: [ 0.109479   -0.14229463 -0.19624442  0.13742292 -0.31140184 -0.6305066\n",
      "  0.08155867 -0.47762123 -1.3591118  -0.05530624 -0.5373087  -1.6613379\n",
      " -0.22983651 -0.67292976 -2.132369   -0.11037369 -0.7117264  -1.5503433\n",
      "  0.18182756 -0.71237266 -1.2648548   0.1328452  -0.66314375 -1.3092672\n",
      "  0.10263518 -0.75711477 -1.4253983  -0.06332073 -0.5844811  -1.4730613\n",
      "  0.0516049  -0.64715743 -1.457611    0.04676117 -0.6183878  -1.5487022\n",
      "  0.16215278 -0.6475962  -1.6321161   0.0495332  -0.5169625  -1.2908572\n",
      " -0.04732168 -0.28264976 -1.8549899   0.09674959 -0.4425998  -1.8248763\n",
      "  0.22662622 -0.39357176 -1.4640279  -0.05095427 -0.2733528  -1.2378756\n",
      "  0.05438361 -0.24806733 -1.2842965   0.12129675 -0.28569543 -1.4028554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.15177554 -0.29903632 -1.2941502   0.05      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0280, -0.1972, -0.2123,  ...,  0.0658, -0.3773, -1.2732],\n",
      "        [ 0.0280, -0.1972, -0.2123,  ...,  0.0658, -0.3773, -1.2732],\n",
      "        [ 0.0280, -0.1972, -0.2123,  ...,  0.0658, -0.3773, -1.2732],\n",
      "        ...,\n",
      "        [-0.0620,  0.5887, -0.1242,  ..., -0.5279,  1.0764, -0.5170],\n",
      "        [-0.1557,  0.0263,  0.5967,  ..., -0.2326,  0.7935,  0.1591],\n",
      "        [-0.1557,  0.0263,  0.5967,  ..., -0.2326,  0.7935,  0.1591]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.7995314e-02 -1.9716157e-01 -2.1227139e-01  5.5467021e-02\n",
      " -3.3715704e-01 -5.9962630e-01 -2.9929295e-02 -5.4879093e-01\n",
      " -1.4027182e+00 -1.8165946e-01 -6.1535358e-01 -1.7213720e+00\n",
      " -3.6095440e-01 -7.4219149e-01 -2.2039180e+00 -1.8935451e-01\n",
      " -8.0488449e-01 -1.6058757e+00  7.8282602e-02 -8.4982687e-01\n",
      " -1.3501639e+00  1.7939307e-02 -7.9855347e-01 -1.3918344e+00\n",
      " -1.0009967e-02 -9.3974584e-01 -1.5193969e+00 -1.3385761e-01\n",
      " -6.9227147e-01 -1.4975376e+00 -4.3638416e-02 -7.6648921e-01\n",
      " -1.4672277e+00 -4.7687493e-02 -7.4456549e-01 -1.5659051e+00\n",
      "  7.3245011e-02 -7.9018569e-01 -1.6186136e+00 -2.6106223e-02\n",
      " -5.9322190e-01 -1.3114340e+00 -1.7109412e-01 -3.6635682e-01\n",
      " -2.0084205e+00  5.0448626e-03 -5.5080295e-01 -2.0022340e+00\n",
      "  1.6481915e-01 -5.0452346e-01 -1.4471096e+00 -1.5308321e-01\n",
      " -3.5072470e-01 -1.2380781e+00 -5.0874628e-02 -3.2991201e-01\n",
      " -1.3043259e+00  1.8317327e-03 -3.6809599e-01 -1.4192866e+00\n",
      "  6.5821886e-02 -3.7729996e-01 -1.2732047e+00]\n",
      "data: [ 2.7995314e-02 -1.9716159e-01 -2.1227139e-01  5.5467021e-02\n",
      " -3.3715707e-01 -5.9962630e-01 -2.9929295e-02 -5.4879093e-01\n",
      " -1.4027182e+00 -1.8165947e-01 -6.1535358e-01 -1.7213721e+00\n",
      " -3.6095440e-01 -7.4219149e-01 -2.2039180e+00 -1.8935451e-01\n",
      " -8.0488449e-01 -1.6058757e+00  7.8282602e-02 -8.4982687e-01\n",
      " -1.3501639e+00  1.7939307e-02 -7.9855347e-01 -1.3918344e+00\n",
      " -1.0009967e-02 -9.3974584e-01 -1.5193970e+00 -1.3385761e-01\n",
      " -6.9227147e-01 -1.4975375e+00 -4.3638416e-02 -7.6648921e-01\n",
      " -1.4672276e+00 -4.7687493e-02 -7.4456549e-01 -1.5659051e+00\n",
      "  7.3245011e-02 -7.9018569e-01 -1.6186136e+00 -2.6106223e-02\n",
      " -5.9322190e-01 -1.3114340e+00 -1.7109412e-01 -3.6635682e-01\n",
      " -2.0084205e+00  5.0448626e-03 -5.5080295e-01 -2.0022340e+00\n",
      "  1.6481915e-01 -5.0452346e-01 -1.4471096e+00 -1.5308321e-01\n",
      " -3.5072473e-01 -1.2380781e+00 -5.0874628e-02 -3.2991201e-01\n",
      " -1.3043258e+00  1.8317327e-03 -3.6809599e-01 -1.4192866e+00\n",
      "  6.5821886e-02 -3.7729996e-01 -1.2732047e+00  5.9999999e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0196, -0.1509, -0.1735,  ...,  0.0557, -0.3321, -1.1945],\n",
      "        [ 0.0196, -0.1509, -0.1735,  ...,  0.0557, -0.3321, -1.1945],\n",
      "        [ 0.0196, -0.1509, -0.1735,  ...,  0.0557, -0.3321, -1.1945],\n",
      "        ...,\n",
      "        [-0.0878,  0.5275, -0.1462,  ..., -0.4237,  1.1018, -0.5882],\n",
      "        [-0.1110,  0.0217,  0.6627,  ..., -0.1752,  0.6636,  0.3281],\n",
      "        [-0.1110,  0.0217,  0.6627,  ..., -0.1752,  0.6636,  0.3281]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.9637238e-02 -1.5093312e-01 -1.7349097e-01  4.5833070e-02\n",
      " -2.7051434e-01 -4.8069066e-01 -5.6256287e-02 -4.8975518e-01\n",
      " -1.3147730e+00 -2.1402824e-01 -5.5105412e-01 -1.6289096e+00\n",
      " -3.8103187e-01 -6.6841495e-01 -2.1327775e+00 -1.9580652e-01\n",
      " -7.7512044e-01 -1.5234041e+00  4.2363837e-02 -8.2984090e-01\n",
      " -1.3541057e+00 -2.2495121e-02 -7.6938301e-01 -1.3938977e+00\n",
      " -2.5589734e-02 -9.1990131e-01 -1.5210456e+00 -1.3906604e-01\n",
      " -6.7402047e-01 -1.4111586e+00 -5.5747166e-02 -7.3713577e-01\n",
      " -1.3915805e+00 -5.1905207e-02 -7.0362407e-01 -1.4894396e+00\n",
      "  7.3039681e-02 -7.5433612e-01 -1.5233063e+00 -3.0408733e-02\n",
      " -5.6058961e-01 -1.2347754e+00 -1.8729393e-01 -3.2711166e-01\n",
      " -1.9627049e+00  2.0817518e-03 -5.1124310e-01 -1.9710088e+00\n",
      "  1.7520358e-01 -4.6442246e-01 -1.3735231e+00 -1.7049505e-01\n",
      " -3.2138717e-01 -1.1587449e+00 -6.4857826e-02 -2.9908866e-01\n",
      " -1.2393484e+00 -2.6983425e-02 -3.2794487e-01 -1.3532567e+00\n",
      "  5.5712037e-02 -3.3210528e-01 -1.1944885e+00]\n",
      "data: [ 1.9637238e-02 -1.5093312e-01 -1.7349096e-01  4.5833066e-02\n",
      " -2.7051434e-01 -4.8069066e-01 -5.6256283e-02 -4.8975518e-01\n",
      " -1.3147730e+00 -2.1402824e-01 -5.5105412e-01 -1.6289096e+00\n",
      " -3.8103187e-01 -6.6841489e-01 -2.1327775e+00 -1.9580652e-01\n",
      " -7.7512050e-01 -1.5234041e+00  4.2363837e-02 -8.2984090e-01\n",
      " -1.3541057e+00 -2.2495123e-02 -7.6938301e-01 -1.3938977e+00\n",
      " -2.5589732e-02 -9.1990125e-01 -1.5210456e+00 -1.3906604e-01\n",
      " -6.7402047e-01 -1.4111586e+00 -5.5747166e-02 -7.3713577e-01\n",
      " -1.3915805e+00 -5.1905207e-02 -7.0362401e-01 -1.4894395e+00\n",
      "  7.3039681e-02 -7.5433612e-01 -1.5233063e+00 -3.0408733e-02\n",
      " -5.6058961e-01 -1.2347754e+00 -1.8729393e-01 -3.2711166e-01\n",
      " -1.9627049e+00  2.0817518e-03 -5.1124310e-01 -1.9710088e+00\n",
      "  1.7520358e-01 -4.6442246e-01 -1.3735231e+00 -1.7049505e-01\n",
      " -3.2138717e-01 -1.1587449e+00 -6.4857826e-02 -2.9908866e-01\n",
      " -1.2393484e+00 -2.6983425e-02 -3.2794487e-01 -1.3532567e+00\n",
      "  5.5712037e-02 -3.3210528e-01 -1.1944885e+00  7.0000000e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[-0.0014, -0.0907, -0.1920,  ...,  0.0144, -0.2844, -1.1737],\n",
      "        [-0.0014, -0.0907, -0.1920,  ...,  0.0144, -0.2844, -1.1737],\n",
      "        [-0.0014, -0.0907, -0.1920,  ...,  0.0144, -0.2844, -1.1737],\n",
      "        ...,\n",
      "        [-0.1909,  0.4098, -0.0353,  ..., -0.6056,  0.9868, -0.4121],\n",
      "        [-0.0819, -0.0181,  0.6321,  ..., -0.1631,  0.7007,  0.2755],\n",
      "        [-0.0819, -0.0181,  0.6321,  ..., -0.1631,  0.7007,  0.2755]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-1.37409102e-03 -9.07245651e-02 -1.91998318e-01  3.04821469e-02\n",
      " -1.87995225e-01 -4.66912240e-01 -1.30658805e-01 -4.30673748e-01\n",
      " -1.34864891e+00 -2.89533198e-01 -5.01375616e-01 -1.63011551e+00\n",
      " -4.33793068e-01 -5.82623124e-01 -2.15497255e+00 -1.93133339e-01\n",
      " -7.40241349e-01 -1.52608168e+00 -4.19111997e-02 -8.16921830e-01\n",
      " -1.37820959e+00 -9.27349478e-02 -7.35986233e-01 -1.42852795e+00\n",
      " -1.04254201e-01 -9.11822379e-01 -1.55488920e+00 -1.52844384e-01\n",
      " -6.57918632e-01 -1.42284346e+00 -1.07691206e-01 -7.07870722e-01\n",
      " -1.38876522e+00 -1.19721077e-01 -6.67284906e-01 -1.46530116e+00\n",
      "  2.50675231e-02 -6.98380709e-01 -1.47184741e+00 -7.40964785e-02\n",
      " -5.39061129e-01 -1.26799786e+00 -2.40608841e-01 -2.99979925e-01\n",
      " -2.03992367e+00 -5.03977835e-02 -4.74142849e-01 -2.07302332e+00\n",
      "  1.31204352e-01 -4.30504560e-01 -1.34662604e+00 -1.99433640e-01\n",
      " -3.12891006e-01 -1.18338370e+00 -1.39029816e-01 -2.78525084e-01\n",
      " -1.27317441e+00 -1.10586584e-01 -2.72765964e-01 -1.38325667e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.44325122e-02 -2.84361660e-01 -1.17365777e+00]\n",
      "data: [-1.3740910e-03 -9.0724565e-02 -1.9199830e-01  3.0482147e-02\n",
      " -1.8799523e-01 -4.6691224e-01 -1.3065881e-01 -4.3067375e-01\n",
      " -1.3486488e+00 -2.8953320e-01 -5.0137562e-01 -1.6301155e+00\n",
      " -4.3379307e-01 -5.8262312e-01 -2.1549726e+00 -1.9313334e-01\n",
      " -7.4024129e-01 -1.5260817e+00 -4.1911200e-02 -8.1692183e-01\n",
      " -1.3782096e+00 -9.2734948e-02 -7.3598623e-01 -1.4285280e+00\n",
      " -1.0425420e-01 -9.1182238e-01 -1.5548892e+00 -1.5284438e-01\n",
      " -6.5791863e-01 -1.4228435e+00 -1.0769120e-01 -7.0787072e-01\n",
      " -1.3887652e+00 -1.1972108e-01 -6.6728491e-01 -1.4653012e+00\n",
      "  2.5067523e-02 -6.9838071e-01 -1.4718474e+00 -7.4096479e-02\n",
      " -5.3906113e-01 -1.2679979e+00 -2.4060884e-01 -2.9997993e-01\n",
      " -2.0399237e+00 -5.0397784e-02 -4.7414285e-01 -2.0730233e+00\n",
      "  1.3120435e-01 -4.3050456e-01 -1.3466259e+00 -1.9943362e-01\n",
      " -3.1289101e-01 -1.1833837e+00 -1.3902982e-01 -2.7852508e-01\n",
      " -1.2731744e+00 -1.1058658e-01 -2.7276596e-01 -1.3832567e+00\n",
      "  1.4432512e-02 -2.8436166e-01 -1.1736578e+00  7.9999998e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[-0.0177,  0.0158, -0.1806,  ...,  0.0128, -0.1743, -1.1572],\n",
      "        [-0.0177,  0.0158, -0.1806,  ...,  0.0128, -0.1743, -1.1572],\n",
      "        [-0.0177,  0.0158, -0.1806,  ...,  0.0128, -0.1743, -1.1572],\n",
      "        ...,\n",
      "        [-0.1488,  0.3681,  0.0713,  ..., -0.7228,  0.9692, -0.2938],\n",
      "        [-0.1019, -0.0920,  0.5721,  ..., -0.2554,  0.6080,  0.2480],\n",
      "        [-0.1019, -0.0920,  0.5721,  ..., -0.2554,  0.6080,  0.2480]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01774264  0.01576562 -0.1805524   0.00402657 -0.09398973 -0.49081472\n",
      " -0.14019424 -0.3161742  -1.33003    -0.2938937  -0.38045746 -1.6161231\n",
      " -0.45475167 -0.47057104 -2.1126082  -0.21431394 -0.62245    -1.4906863\n",
      " -0.04041545 -0.68008506 -1.3155172  -0.08304952 -0.60257703 -1.3678082\n",
      " -0.0778472  -0.7652096  -1.4944457  -0.17391394 -0.5296236  -1.3932633\n",
      " -0.1106886  -0.5795905  -1.3570124  -0.11024445 -0.54389906 -1.4417505\n",
      "  0.05240071 -0.5699005  -1.464913   -0.09131127 -0.42396992 -1.2308152\n",
      " -0.24218568 -0.18607624 -1.9829392  -0.04967804 -0.35419333 -2.0062773\n",
      "  0.14568453 -0.31443715 -1.327216   -0.21075608 -0.19063488 -1.1491556\n",
      " -0.14555739 -0.16029532 -1.2363247  -0.10761984 -0.15832247 -1.3528343\n",
      "  0.01282426 -0.17434102 -1.1571782 ]\n",
      "data: [-0.01774264  0.01576562 -0.1805524   0.00402657 -0.09398974 -0.49081472\n",
      " -0.14019424 -0.3161742  -1.33003    -0.2938937  -0.38045746 -1.6161231\n",
      " -0.45475167 -0.47057107 -2.1126082  -0.21431394 -0.62245    -1.4906863\n",
      " -0.04041545 -0.68008506 -1.3155171  -0.08304951 -0.60257703 -1.3678082\n",
      " -0.0778472  -0.76520956 -1.4944457  -0.17391394 -0.5296236  -1.3932633\n",
      " -0.1106886  -0.5795905  -1.3570123  -0.11024445 -0.54389906 -1.4417505\n",
      "  0.05240071 -0.5699005  -1.464913   -0.09131126 -0.42396992 -1.2308152\n",
      " -0.24218568 -0.18607624 -1.9829392  -0.04967804 -0.35419333 -2.0062773\n",
      "  0.14568453 -0.31443715 -1.327216   -0.21075608 -0.19063488 -1.1491556\n",
      " -0.14555739 -0.16029531 -1.2363247  -0.10761984 -0.15832247 -1.3528343\n",
      "  0.01282426 -0.17434102 -1.1571782   0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[-0.0079, -0.0723, -0.2146,  ...,  0.0141, -0.2339, -1.3404],\n",
      "        [-0.0079, -0.0723, -0.2146,  ...,  0.0141, -0.2339, -1.3404],\n",
      "        [-0.0079, -0.0723, -0.2146,  ...,  0.0141, -0.2339, -1.3404],\n",
      "        ...,\n",
      "        [-0.2747,  0.3256, -0.1686,  ..., -0.8031,  0.7734, -0.3128],\n",
      "        [-0.1782, -0.0794,  0.5119,  ..., -0.2663,  0.6804,  0.2609],\n",
      "        [-0.1782, -0.0794,  0.5119,  ..., -0.2663,  0.6804,  0.2609]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.00790667 -0.07232122 -0.21462567  0.00526823 -0.23588963 -0.6908697\n",
      " -0.04144386 -0.3764275  -1.3644722  -0.18260464 -0.42955223 -1.6690526\n",
      " -0.3643937  -0.5636552  -2.1331313  -0.23178574 -0.6500098  -1.5244741\n",
      "  0.03723025 -0.64683855 -1.2972696  -0.01310886 -0.58897454 -1.3502469\n",
      " -0.01328262 -0.68214047 -1.463388   -0.18757066 -0.5347877  -1.4549129\n",
      " -0.07302368 -0.58631086 -1.4436314  -0.07615601 -0.55411315 -1.5504153\n",
      "  0.04888649 -0.5728058  -1.6217864  -0.08383821 -0.4692755  -1.2789052\n",
      " -0.15472242 -0.23966512 -1.7850754  -0.02748658 -0.37419036 -1.7623897\n",
      "  0.11621419 -0.34489    -1.4824355  -0.1804958  -0.22294435 -1.230952\n",
      " -0.08259908 -0.20365688 -1.3117232  -0.02745657 -0.22927433 -1.4334822\n",
      "  0.01408958 -0.23389713 -1.3404074 ]\n",
      "data: [-0.00790667 -0.07232122 -0.21462566  0.00526823 -0.23588963 -0.6908697\n",
      " -0.04144386 -0.3764275  -1.3644722  -0.18260464 -0.42955223 -1.6690526\n",
      " -0.36439368 -0.5636552  -2.1331313  -0.23178573 -0.6500099  -1.5244741\n",
      "  0.03723025 -0.64683855 -1.2972696  -0.01310886 -0.58897454 -1.3502469\n",
      " -0.01328262 -0.6821405  -1.463388   -0.18757066 -0.5347877  -1.4549129\n",
      " -0.07302368 -0.58631086 -1.4436314  -0.07615601 -0.55411315 -1.5504154\n",
      "  0.04888649 -0.5728058  -1.6217864  -0.0838382  -0.4692755  -1.2789052\n",
      " -0.15472242 -0.23966512 -1.7850754  -0.02748658 -0.37419036 -1.7623897\n",
      "  0.11621419 -0.34489    -1.4824355  -0.1804958  -0.22294435 -1.230952\n",
      " -0.08259907 -0.20365688 -1.3117232  -0.02745657 -0.22927433 -1.4334822\n",
      "  0.01408958 -0.23389713 -1.3404074   0.1       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0566, -0.1597, -0.2868,  ...,  0.0649, -0.3308, -1.3649],\n",
      "        [ 0.0566, -0.1597, -0.2868,  ...,  0.0649, -0.3308, -1.3649],\n",
      "        [ 0.0566, -0.1597, -0.2868,  ...,  0.0649, -0.3308, -1.3649],\n",
      "        ...,\n",
      "        [-0.1233,  0.5396, -0.0670,  ..., -0.7327,  1.0648, -0.3446],\n",
      "        [-0.1804, -0.0689,  0.6373,  ..., -0.2768,  0.7107,  0.3130],\n",
      "        [-0.1804, -0.0689,  0.6373,  ..., -0.2768,  0.7107,  0.3130]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.05658485 -0.15970956 -0.28681386  0.08512719 -0.2899108  -0.6990487\n",
      " -0.00705724 -0.47678307 -1.46755    -0.14971809 -0.5355147  -1.7652471\n",
      " -0.3023954  -0.63838553 -2.2596767  -0.14276223 -0.7653301  -1.6389153\n",
      "  0.06528732 -0.7976259  -1.4652731   0.0145416  -0.7335119  -1.5207295\n",
      "  0.00548701 -0.868492   -1.6410308  -0.10296884 -0.66607547 -1.5516772\n",
      " -0.02579349 -0.71596384 -1.5322201  -0.03934477 -0.684721   -1.6252568\n",
      "  0.08486278 -0.7122705  -1.6692917  -0.01804241 -0.57136786 -1.3838434\n",
      " -0.13874224 -0.3393056  -2.0343688   0.01600769 -0.4939445  -2.0410004\n",
      "  0.16487743 -0.4580761  -1.5287042  -0.1253631  -0.3383615  -1.3152597\n",
      " -0.04899399 -0.30889118 -1.3934975  -0.00781906 -0.32003587 -1.5105581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.06485017 -0.33082977 -1.364923  ]\n",
      "data: [ 0.05658485 -0.15970956 -0.28681386  0.08512719 -0.2899108  -0.6990487\n",
      " -0.00705724 -0.47678307 -1.46755    -0.14971809 -0.5355147  -1.765247\n",
      " -0.3023954  -0.63838553 -2.2596767  -0.14276223 -0.7653301  -1.6389153\n",
      "  0.06528732 -0.7976259  -1.4652731   0.0145416  -0.733512   -1.5207295\n",
      "  0.00548701 -0.86849195 -1.6410308  -0.10296884 -0.66607547 -1.5516772\n",
      " -0.02579349 -0.71596384 -1.5322201  -0.03934477 -0.684721   -1.6252568\n",
      "  0.08486278 -0.7122705  -1.6692917  -0.01804241 -0.57136786 -1.3838434\n",
      " -0.13874224 -0.3393056  -2.0343688   0.01600769 -0.49394453 -2.0410004\n",
      "  0.16487743 -0.4580761  -1.5287042  -0.1253631  -0.3383615  -1.3152597\n",
      " -0.04899399 -0.30889118 -1.3934975  -0.00781906 -0.32003585 -1.5105581\n",
      "  0.06485017 -0.33082977 -1.364923    0.11      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0167, -0.1702, -0.2122,  ...,  0.0863, -0.3542, -1.3034],\n",
      "        [ 0.0167, -0.1702, -0.2122,  ...,  0.0863, -0.3542, -1.3034],\n",
      "        [ 0.0167, -0.1702, -0.2122,  ...,  0.0863, -0.3542, -1.3034],\n",
      "        ...,\n",
      "        [-0.0158,  0.4940, -0.0969,  ..., -0.6043,  1.0182, -0.4323],\n",
      "        [-0.1219, -0.0122,  0.5931,  ..., -0.1763,  0.6721,  0.2620],\n",
      "        [-0.1219, -0.0122,  0.5931,  ..., -0.1763,  0.6721,  0.2620]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.016695   -0.17015769 -0.21224982  0.03952216 -0.3218608  -0.5998831\n",
      "  0.00480693 -0.5007086  -1.3541462  -0.14276873 -0.55541575 -1.6927629\n",
      " -0.33342525 -0.7107893  -2.161995   -0.21061748 -0.75435877 -1.5820702\n",
      "  0.11854646 -0.7774924  -1.3523289   0.05088913 -0.7370156  -1.3880241\n",
      "  0.04807872 -0.85145164 -1.5101978  -0.14154461 -0.6325755  -1.4728237\n",
      " -0.01700423 -0.7111069  -1.4684222  -0.00271601 -0.6935084  -1.5847163\n",
      "  0.10568413 -0.7469373  -1.6606318  -0.0112099  -0.54929316 -1.2727088\n",
      " -0.13243794 -0.32281217 -1.9094434   0.03821179 -0.5074017  -1.882058\n",
      "  0.191248   -0.4631556  -1.4783065  -0.1462394  -0.29890192 -1.2144446\n",
      " -0.00671229 -0.29006094 -1.2817116   0.05495466 -0.35200155 -1.3979725\n",
      "  0.08632625 -0.35420823 -1.3033586 ]\n",
      "data: [ 0.016695   -0.17015769 -0.21224982  0.03952216 -0.32186082 -0.5998831\n",
      "  0.00480693 -0.5007086  -1.3541462  -0.14276873 -0.55541575 -1.6927629\n",
      " -0.33342525 -0.7107893  -2.161995   -0.21061748 -0.75435877 -1.5820701\n",
      "  0.11854646 -0.77749234 -1.3523289   0.05088913 -0.7370156  -1.3880241\n",
      "  0.04807872 -0.85145164 -1.5101978  -0.14154461 -0.6325755  -1.4728237\n",
      " -0.01700423 -0.7111069  -1.4684223  -0.00271601 -0.6935084  -1.5847163\n",
      "  0.10568413 -0.7469373  -1.6606317  -0.0112099  -0.54929316 -1.2727088\n",
      " -0.13243794 -0.32281217 -1.9094434   0.03821179 -0.5074017  -1.8820579\n",
      "  0.191248   -0.4631556  -1.4783065  -0.1462394  -0.29890192 -1.2144446\n",
      " -0.00671229 -0.29006094 -1.2817116   0.05495466 -0.35200155 -1.3979725\n",
      "  0.08632625 -0.35420823 -1.3033586   0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0142, -0.1452, -0.1641,  ...,  0.0359, -0.3398, -1.1609],\n",
      "        [ 0.0142, -0.1452, -0.1641,  ...,  0.0359, -0.3398, -1.1609],\n",
      "        [ 0.0142, -0.1452, -0.1641,  ...,  0.0359, -0.3398, -1.1609],\n",
      "        ...,\n",
      "        [-0.0689,  0.5164, -0.1481,  ..., -0.3310,  1.0575, -0.5594],\n",
      "        [-0.1649, -0.0297,  0.6243,  ..., -0.2459,  0.6657,  0.2717],\n",
      "        [-0.1649, -0.0297,  0.6243,  ..., -0.2459,  0.6657,  0.2717]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.014239   -0.14522049 -0.1641298   0.04517077 -0.2523353  -0.46284536\n",
      " -0.09877077 -0.49130836 -1.3233502  -0.2556421  -0.56103235 -1.6110204\n",
      " -0.40224785 -0.6535382  -2.1249576  -0.1799075  -0.7909422  -1.5072836\n",
      " -0.00730699 -0.86441946 -1.3523729  -0.06357447 -0.78893423 -1.4003667\n",
      " -0.077029   -0.96077776 -1.5250678  -0.13516945 -0.7017807  -1.4038535\n",
      " -0.08283025 -0.7571964  -1.3732048  -0.09507883 -0.72207105 -1.4500357\n",
      "  0.03761553 -0.7593976  -1.4620785  -0.04860619 -0.5844257  -1.2449526\n",
      " -0.21551445 -0.34564108 -2.0128875  -0.02834221 -0.52766764 -2.0374641\n",
      "  0.14335403 -0.48214433 -1.3327054  -0.17650205 -0.3546966  -1.1621509\n",
      " -0.10527413 -0.3226971  -1.2502657  -0.07459981 -0.327435   -1.3602448\n",
      "  0.03590642 -0.3397568  -1.1608859 ]\n",
      "data: [ 0.014239   -0.14522049 -0.1641298   0.04517077 -0.2523353  -0.46284536\n",
      " -0.09877077 -0.49130836 -1.3233502  -0.2556421  -0.56103235 -1.6110206\n",
      " -0.40224785 -0.6535382  -2.1249576  -0.1799075  -0.79094225 -1.5072837\n",
      " -0.00730699 -0.86441946 -1.3523729  -0.06357447 -0.78893423 -1.4003667\n",
      " -0.077029   -0.96077776 -1.5250678  -0.13516945 -0.7017807  -1.4038537\n",
      " -0.08283025 -0.7571964  -1.3732048  -0.09507883 -0.72207105 -1.4500357\n",
      "  0.03761553 -0.7593977  -1.4620785  -0.04860619 -0.5844257  -1.2449526\n",
      " -0.21551445 -0.34564105 -2.0128875  -0.02834221 -0.52766764 -2.0374641\n",
      "  0.14335403 -0.48214433 -1.3327054  -0.17650205 -0.35469663 -1.1621509\n",
      " -0.10527413 -0.3226971  -1.2502657  -0.07459981 -0.327435   -1.3602448\n",
      "  0.03590642 -0.3397568  -1.1608859   0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0501,  0.0163, -0.2188,  ..., -0.0175, -0.1762, -1.1719],\n",
      "        [-0.0501,  0.0163, -0.2188,  ..., -0.0175, -0.1762, -1.1719],\n",
      "        [-0.0501,  0.0163, -0.2188,  ..., -0.0175, -0.1762, -1.1719],\n",
      "        ...,\n",
      "        [-0.1627,  0.3520,  0.0392,  ..., -0.5491,  0.9619, -0.3782],\n",
      "        [-0.0653, -0.0829,  0.6403,  ..., -0.2032,  0.5826,  0.3161],\n",
      "        [-0.0653, -0.0829,  0.6403,  ..., -0.2032,  0.5826,  0.3161]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.05007889  0.0163286  -0.21880431 -0.02552724 -0.09047522 -0.48482436\n",
      " -0.17111301 -0.32481977 -1.3499894  -0.32819772 -0.38918883 -1.6396778\n",
      " -0.48809165 -0.48554465 -2.1448932  -0.25215685 -0.6267853  -1.5276167\n",
      " -0.06660965 -0.6907779  -1.354737   -0.11639027 -0.61492467 -1.4013963\n",
      " -0.11244817 -0.78010917 -1.5297987  -0.20741901 -0.53235376 -1.4226158\n",
      " -0.14403467 -0.58542824 -1.3889759  -0.13980524 -0.5486773  -1.4707258\n",
      "  0.01490228 -0.5826049  -1.4895391  -0.11597999 -0.4199395  -1.258735\n",
      " -0.2834115  -0.17937735 -2.0420537  -0.08002547 -0.36003017 -2.0642738\n",
      "  0.11477832 -0.31356534 -1.3493395  -0.24671714 -0.18668358 -1.1766169\n",
      " -0.17073324 -0.157922   -1.2594857  -0.13605718 -0.16217522 -1.3732884\n",
      " -0.01752193 -0.17620684 -1.1719341 ]\n",
      "data: [-0.05007889  0.0163286  -0.21880431 -0.02552723 -0.09047522 -0.48482436\n",
      " -0.17111301 -0.32481974 -1.3499894  -0.32819772 -0.38918886 -1.6396778\n",
      " -0.48809165 -0.48554465 -2.1448932  -0.25215685 -0.6267853  -1.5276167\n",
      " -0.06660965 -0.6907779  -1.354737   -0.11639027 -0.61492467 -1.4013963\n",
      " -0.11244817 -0.78010917 -1.5297987  -0.20741901 -0.53235376 -1.4226158\n",
      " -0.14403467 -0.58542824 -1.3889759  -0.13980524 -0.5486773  -1.4707257\n",
      "  0.01490228 -0.5826049  -1.4895391  -0.11598    -0.4199395  -1.258735\n",
      " -0.2834115  -0.17937735 -2.0420537  -0.08002547 -0.36003017 -2.0642738\n",
      "  0.11477832 -0.31356534 -1.3493395  -0.24671715 -0.18668358 -1.1766169\n",
      " -0.17073324 -0.157922   -1.2594857  -0.13605718 -0.16217522 -1.3732884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.01752193 -0.17620684 -1.1719341   0.14      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[ 0.0039, -0.0774, -0.1726,  ...,  0.0309, -0.2323, -1.2891],\n",
      "        [ 0.0039, -0.0774, -0.1726,  ...,  0.0309, -0.2323, -1.2891],\n",
      "        [ 0.0039, -0.0774, -0.1726,  ...,  0.0309, -0.2323, -1.2891],\n",
      "        ...,\n",
      "        [-0.2979,  0.3129, -0.2454,  ..., -0.8156,  0.8092, -0.4566],\n",
      "        [-0.2233, -0.1166,  0.4792,  ..., -0.3393,  0.5984,  0.2462],\n",
      "        [-0.2233, -0.1166,  0.4792,  ..., -0.3393,  0.5984,  0.2462]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 3.93541623e-03 -7.73751736e-02 -1.72561526e-01  2.33278163e-02\n",
      " -2.34513581e-01 -6.39930844e-01 -8.24620575e-03 -3.68144721e-01\n",
      " -1.30337524e+00 -1.45144820e-01 -4.12357569e-01 -1.61269236e+00\n",
      " -3.15742016e-01 -5.50714016e-01 -2.07895565e+00 -2.19495073e-01\n",
      " -6.45602584e-01 -1.46209216e+00  7.61819482e-02 -6.33429527e-01\n",
      " -1.23245800e+00  2.11156011e-02 -5.79047441e-01 -1.28315830e+00\n",
      "  1.46643445e-02 -6.63388610e-01 -1.40246165e+00 -1.74490109e-01\n",
      " -5.34073710e-01 -1.38984394e+00 -4.86436188e-02 -5.82727790e-01\n",
      " -1.39432371e+00 -4.54289988e-02 -5.40910125e-01 -1.49908555e+00\n",
      "  6.94249272e-02 -5.72407365e-01 -1.57290661e+00 -5.90341017e-02\n",
      " -4.61865634e-01 -1.21430981e+00 -1.34930208e-01 -2.27548420e-01\n",
      " -1.72953773e+00  7.78429210e-04 -3.67133349e-01 -1.70397449e+00\n",
      "  1.38537511e-01 -3.31427425e-01 -1.43833447e+00 -1.65323749e-01\n",
      " -2.19777063e-01 -1.16619921e+00 -5.03342003e-02 -1.97698176e-01\n",
      " -1.24689054e+00  8.62717628e-04 -2.30477780e-01 -1.36998534e+00\n",
      "  3.09444591e-02 -2.32287928e-01 -1.28913951e+00]\n",
      "data: [ 3.93541623e-03 -7.73751736e-02 -1.72561526e-01  2.33278163e-02\n",
      " -2.34513581e-01 -6.39930844e-01 -8.24620575e-03 -3.68144721e-01\n",
      " -1.30337524e+00 -1.45144820e-01 -4.12357569e-01 -1.61269236e+00\n",
      " -3.15742016e-01 -5.50714016e-01 -2.07895565e+00 -2.19495073e-01\n",
      " -6.45602584e-01 -1.46209216e+00  7.61819482e-02 -6.33429527e-01\n",
      " -1.23245800e+00  2.11156011e-02 -5.79047441e-01 -1.28315830e+00\n",
      "  1.46643445e-02 -6.63388610e-01 -1.40246165e+00 -1.74490109e-01\n",
      " -5.34073710e-01 -1.38984394e+00 -4.86436188e-02 -5.82727790e-01\n",
      " -1.39432371e+00 -4.54290025e-02 -5.40910125e-01 -1.49908555e+00\n",
      "  6.94249272e-02 -5.72407365e-01 -1.57290661e+00 -5.90340979e-02\n",
      " -4.61865604e-01 -1.21430981e+00 -1.34930208e-01 -2.27548420e-01\n",
      " -1.72953761e+00  7.78429210e-04 -3.67133319e-01 -1.70397449e+00\n",
      "  1.38537511e-01 -3.31427425e-01 -1.43833447e+00 -1.65323749e-01\n",
      " -2.19777063e-01 -1.16619921e+00 -5.03342003e-02 -1.97698176e-01\n",
      " -1.24689054e+00  8.62717628e-04 -2.30477765e-01 -1.36998534e+00\n",
      "  3.09444591e-02 -2.32287928e-01 -1.28913951e+00  1.50000006e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0698, -0.1418, -0.2997,  ...,  0.0826, -0.3037, -1.3919],\n",
      "        [ 0.0698, -0.1418, -0.2997,  ...,  0.0826, -0.3037, -1.3919],\n",
      "        [ 0.0698, -0.1418, -0.2997,  ...,  0.0826, -0.3037, -1.3919],\n",
      "        ...,\n",
      "        [-0.2170,  0.4032, -0.2094,  ..., -0.7431,  0.9157, -0.5060],\n",
      "        [-0.1522,  0.0162,  0.6560,  ..., -0.2642,  0.7949,  0.2833],\n",
      "        [-0.1522,  0.0162,  0.6560,  ..., -0.2642,  0.7949,  0.2833]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 6.98153526e-02 -1.41814619e-01 -2.99745649e-01  9.93376672e-02\n",
      " -2.92257845e-01 -7.40878582e-01  3.01429927e-02 -4.77151185e-01\n",
      " -1.50187945e+00 -1.10621631e-01 -5.35953641e-01 -1.80681300e+00\n",
      " -2.78321683e-01 -6.59499526e-01 -2.28143883e+00 -1.44718543e-01\n",
      " -7.31759548e-01 -1.68381691e+00  1.17377549e-01 -7.54236221e-01\n",
      " -1.45388174e+00  6.68722093e-02 -7.02336788e-01 -1.49920130e+00\n",
      "  5.29274791e-02 -8.18265915e-01 -1.62022495e+00 -1.00588113e-01\n",
      " -6.14998937e-01 -1.59252763e+00 -1.92909688e-03 -6.78277254e-01\n",
      " -1.56816435e+00 -2.31728703e-03 -6.50977731e-01 -1.66129589e+00\n",
      "  1.19236261e-01 -6.87298059e-01 -1.72506714e+00 -7.03014433e-04\n",
      " -5.28992295e-01 -1.41151714e+00 -1.20569244e-01 -2.97607720e-01\n",
      " -2.03468156e+00  3.92946303e-02 -4.63778734e-01 -2.02173948e+00\n",
      "  1.86937466e-01 -4.19750661e-01 -1.56303215e+00 -1.17171153e-01\n",
      " -2.85484999e-01 -1.34343934e+00 -2.04838663e-02 -2.59553403e-01\n",
      " -1.40413761e+00  3.48124802e-02 -2.92504430e-01 -1.52052426e+00\n",
      "  8.26009065e-02 -3.03662002e-01 -1.39187241e+00]\n",
      "data: [ 6.9815353e-02 -1.4181462e-01 -2.9974565e-01  9.9337667e-02\n",
      " -2.9225785e-01 -7.4087858e-01  3.0142995e-02 -4.7715119e-01\n",
      " -1.5018795e+00 -1.1062163e-01 -5.3595364e-01 -1.8068130e+00\n",
      " -2.7832168e-01 -6.5949953e-01 -2.2814388e+00 -1.4471854e-01\n",
      " -7.3175955e-01 -1.6838168e+00  1.1737755e-01 -7.5423622e-01\n",
      " -1.4538817e+00  6.6872209e-02 -7.0233679e-01 -1.4992013e+00\n",
      "  5.2927479e-02 -8.1826591e-01 -1.6202250e+00 -1.0058811e-01\n",
      " -6.1499894e-01 -1.5925276e+00 -1.9290969e-03 -6.7827725e-01\n",
      " -1.5681643e+00 -2.3172870e-03 -6.5097773e-01 -1.6612959e+00\n",
      "  1.1923626e-01 -6.8729806e-01 -1.7250671e+00 -7.0301443e-04\n",
      " -5.2899230e-01 -1.4115171e+00 -1.2056925e-01 -2.9760772e-01\n",
      " -2.0346816e+00  3.9294630e-02 -4.6377873e-01 -2.0217395e+00\n",
      "  1.8693747e-01 -4.1975066e-01 -1.5630323e+00 -1.1717115e-01\n",
      " -2.8548500e-01 -1.3434393e+00 -2.0483866e-02 -2.5955340e-01\n",
      " -1.4041376e+00  3.4812480e-02 -2.9250443e-01 -1.5205243e+00\n",
      "  8.2600906e-02 -3.0366200e-01 -1.3918724e+00  1.6000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0087, -0.1716, -0.2283,  ...,  0.0461, -0.3513, -1.3365],\n",
      "        [ 0.0087, -0.1716, -0.2283,  ...,  0.0461, -0.3513, -1.3365],\n",
      "        [ 0.0087, -0.1716, -0.2283,  ...,  0.0461, -0.3513, -1.3365],\n",
      "        ...,\n",
      "        [-0.0671,  0.4811, -0.1406,  ..., -0.6702,  0.9699, -0.4068],\n",
      "        [-0.1266, -0.0032,  0.5582,  ..., -0.1447,  0.7255,  0.2395],\n",
      "        [-0.1266, -0.0032,  0.5582,  ..., -0.1447,  0.7255,  0.2395]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 8.6711245e-03 -1.7158379e-01 -2.2831441e-01  1.9202691e-02\n",
      " -3.4288198e-01 -6.9481671e-01 -4.2090565e-04 -5.0409842e-01\n",
      " -1.3937075e+00 -1.3858138e-01 -5.6053001e-01 -1.7207727e+00\n",
      " -3.2698548e-01 -7.1580642e-01 -2.1721156e+00 -2.1641378e-01\n",
      " -7.5195187e-01 -1.5859277e+00  9.6933156e-02 -7.5900513e-01\n",
      " -1.3452635e+00  3.0524403e-02 -7.1641451e-01 -1.3905771e+00\n",
      "  2.5784418e-02 -8.1499857e-01 -1.5078859e+00 -1.6127424e-01\n",
      " -6.2451488e-01 -1.4942033e+00 -3.7743263e-02 -6.9324601e-01\n",
      " -1.4827123e+00 -3.8025826e-02 -6.7500895e-01 -1.5923288e+00\n",
      "  6.1753094e-02 -7.1234691e-01 -1.6655726e+00 -3.8738720e-02\n",
      " -5.4875761e-01 -1.3042572e+00 -1.3612756e-01 -3.3151755e-01\n",
      " -1.8618302e+00  1.9214973e-03 -4.9223948e-01 -1.8283710e+00\n",
      "  1.3807927e-01 -4.5491457e-01 -1.4972317e+00 -1.5505847e-01\n",
      " -3.0053699e-01 -1.2487292e+00 -2.8253302e-02 -2.9336363e-01\n",
      " -1.3150482e+00  2.5817603e-02 -3.4645191e-01 -1.4283650e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4.6087764e-02 -3.5129166e-01 -1.3365154e+00]\n",
      "data: [ 8.6711245e-03 -1.7158379e-01 -2.2831441e-01  1.9202691e-02\n",
      " -3.4288198e-01 -6.9481677e-01 -4.2090565e-04 -5.0409842e-01\n",
      " -1.3937076e+00 -1.3858138e-01 -5.6053001e-01 -1.7207727e+00\n",
      " -3.2698548e-01 -7.1580642e-01 -2.1721156e+00 -2.1641378e-01\n",
      " -7.5195193e-01 -1.5859277e+00  9.6933156e-02 -7.5900513e-01\n",
      " -1.3452635e+00  3.0524401e-02 -7.1641451e-01 -1.3905771e+00\n",
      "  2.5784418e-02 -8.1499857e-01 -1.5078859e+00 -1.6127424e-01\n",
      " -6.2451488e-01 -1.4942033e+00 -3.7743263e-02 -6.9324601e-01\n",
      " -1.4827123e+00 -3.8025826e-02 -6.7500895e-01 -1.5923288e+00\n",
      "  6.1753090e-02 -7.1234685e-01 -1.6655726e+00 -3.8738720e-02\n",
      " -5.4875761e-01 -1.3042572e+00 -1.3612756e-01 -3.3151758e-01\n",
      " -1.8618302e+00  1.9214973e-03 -4.9223945e-01 -1.8283709e+00\n",
      "  1.3807927e-01 -4.5491454e-01 -1.4972317e+00 -1.5505847e-01\n",
      " -3.0053699e-01 -1.2487292e+00 -2.8253302e-02 -2.9336363e-01\n",
      " -1.3150482e+00  2.5817605e-02 -3.4645191e-01 -1.4283650e+00\n",
      "  4.6087764e-02 -3.5129166e-01 -1.3365155e+00  1.7000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F898>\n",
      "tensor([[ 0.0100, -0.1648, -0.2103,  ...,  0.0425, -0.3535, -1.2378],\n",
      "        [ 0.0100, -0.1648, -0.2103,  ...,  0.0425, -0.3535, -1.2378],\n",
      "        [ 0.0100, -0.1648, -0.2103,  ...,  0.0425, -0.3535, -1.2378],\n",
      "        ...,\n",
      "        [-0.0480,  0.5492, -0.2125,  ..., -0.5055,  1.0772, -0.5822],\n",
      "        [-0.1767, -0.0366,  0.6515,  ..., -0.2522,  0.6470,  0.3328],\n",
      "        [-0.1767, -0.0366,  0.6515,  ..., -0.2522,  0.6470,  0.3328]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00996872 -0.16477033 -0.21034203  0.04677256 -0.27504092 -0.5151293\n",
      " -0.07163724 -0.5052553  -1.3660069  -0.22583148 -0.56948245 -1.6653548\n",
      " -0.3761958  -0.6738645  -2.1777527  -0.1893738  -0.79440916 -1.5731701\n",
      "  0.02239938 -0.8616735  -1.4133289  -0.03800632 -0.7955291  -1.4533488\n",
      " -0.05152738 -0.9579656  -1.5766451  -0.13673684 -0.7013165  -1.4646864\n",
      " -0.06764277 -0.76446605 -1.44181    -0.07236785 -0.7319716  -1.52695\n",
      "  0.04812139 -0.7807348  -1.5527935  -0.03969239 -0.5869267  -1.2985437\n",
      " -0.20567751 -0.3485399  -2.0640795  -0.01320536 -0.53927946 -2.0793529\n",
      "  0.14873435 -0.4899728  -1.4150686  -0.17573032 -0.35406142 -1.218934\n",
      " -0.08492075 -0.32525477 -1.3008286  -0.04664622 -0.34661198 -1.4120501\n",
      "  0.04252543 -0.35345685 -1.2378479 ]\n",
      "data: [ 0.00996872 -0.16477033 -0.21034202  0.04677255 -0.27504092 -0.5151293\n",
      " -0.07163724 -0.5052553  -1.3660067  -0.22583146 -0.56948245 -1.665355\n",
      " -0.3761958  -0.67386454 -2.1777527  -0.18937379 -0.79440916 -1.5731701\n",
      "  0.02239938 -0.86167353 -1.4133289  -0.03800632 -0.7955291  -1.4533486\n",
      " -0.05152738 -0.9579656  -1.5766453  -0.13673684 -0.7013165  -1.4646864\n",
      " -0.06764277 -0.76446605 -1.44181    -0.07236785 -0.73197156 -1.5269501\n",
      "  0.0481214  -0.7807348  -1.5527936  -0.03969239 -0.5869267  -1.2985437\n",
      " -0.20567751 -0.3485399  -2.0640795  -0.01320536 -0.53927946 -2.0793529\n",
      "  0.14873435 -0.4899728  -1.4150686  -0.17573032 -0.35406142 -1.218934\n",
      " -0.08492075 -0.3252548  -1.3008286  -0.04664622 -0.34661198 -1.4120501\n",
      "  0.04252543 -0.35345685 -1.2378479   0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[-0.0380, -0.0788, -0.1693,  ...,  0.0253, -0.2575, -1.1779],\n",
      "        [-0.0380, -0.0788, -0.1693,  ...,  0.0253, -0.2575, -1.1779],\n",
      "        [-0.0380, -0.0788, -0.1693,  ...,  0.0253, -0.2575, -1.1779],\n",
      "        ...,\n",
      "        [-0.1504,  0.4193, -0.0310,  ..., -0.6926,  1.0295, -0.4553],\n",
      "        [-0.0971, -0.0215,  0.6233,  ..., -0.2270,  0.6055,  0.2941],\n",
      "        [-0.0971, -0.0215,  0.6233,  ..., -0.2270,  0.6055,  0.2941]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.03803326 -0.07876956 -0.1693174  -0.01491102 -0.2201962  -0.4865995\n",
      " -0.08698524 -0.4212984  -1.2945142  -0.23725908 -0.47754532 -1.6165315\n",
      " -0.421553   -0.6174991  -2.093854   -0.26381505 -0.6859262  -1.504694\n",
      "  0.03475206 -0.7152035  -1.2833021  -0.0233514  -0.66967094 -1.3178632\n",
      " -0.01225767 -0.7908679  -1.4473242  -0.20250693 -0.56463146 -1.3943664\n",
      " -0.08579921 -0.6359341  -1.3768265  -0.05931064 -0.60760486 -1.481816\n",
      "  0.07770261 -0.6622579  -1.5458264  -0.07828093 -0.46701664 -1.2004427\n",
      " -0.22141008 -0.23562306 -1.9029796  -0.02206242 -0.42194322 -1.8902352\n",
      "  0.1610133  -0.3730944  -1.367469   -0.21919736 -0.21618451 -1.1318277\n",
      " -0.09005025 -0.20125641 -1.1918355  -0.03434826 -0.24833249 -1.310204\n",
      "  0.02525053 -0.25753796 -1.1778914 ]\n",
      "data: [-0.03803326 -0.07876956 -0.1693174  -0.01491102 -0.2201962  -0.4865995\n",
      " -0.08698524 -0.4212984  -1.2945142  -0.23725909 -0.47754532 -1.6165315\n",
      " -0.42155302 -0.6174991  -2.093854   -0.26381505 -0.6859262  -1.5046939\n",
      "  0.03475206 -0.7152035  -1.283302   -0.0233514  -0.66967094 -1.3178631\n",
      " -0.01225767 -0.7908679  -1.4473243  -0.20250693 -0.56463146 -1.3943665\n",
      " -0.08579921 -0.6359341  -1.3768265  -0.05931064 -0.60760486 -1.481816\n",
      "  0.07770261 -0.6622579  -1.5458264  -0.07828093 -0.46701664 -1.2004427\n",
      " -0.22141008 -0.23562306 -1.9029796  -0.02206242 -0.42194322 -1.8902352\n",
      "  0.1610133  -0.3730944  -1.3674691  -0.21919736 -0.21618453 -1.1318277\n",
      " -0.09005025 -0.20125641 -1.1918355  -0.03434826 -0.24833249 -1.310204\n",
      "  0.02525053 -0.25753796 -1.1778914   0.19      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[-0.0157, -0.0631, -0.2361,  ...,  0.0068, -0.2349, -1.2715],\n",
      "        [-0.0157, -0.0631, -0.2361,  ...,  0.0068, -0.2349, -1.2715],\n",
      "        [-0.0157, -0.0631, -0.2361,  ...,  0.0068, -0.2349, -1.2715],\n",
      "        ...,\n",
      "        [-0.2058,  0.4181, -0.1192,  ..., -0.7039,  0.9517, -0.4149],\n",
      "        [-0.1447, -0.1157,  0.6344,  ..., -0.2456,  0.6314,  0.2952],\n",
      "        [-0.1447, -0.1157,  0.6344,  ..., -0.2456,  0.6314,  0.2952]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01571459 -0.06308077 -0.23610875  0.01435518 -0.18610647 -0.610188\n",
      " -0.09396998 -0.38768935 -1.403243   -0.24258724 -0.44888553 -1.7040099\n",
      " -0.4062845  -0.55559915 -2.1932628  -0.22153781 -0.6793295  -1.5644355\n",
      " -0.0092708  -0.72217417 -1.3722363  -0.06425314 -0.65779215 -1.424912\n",
      " -0.07791229 -0.80417085 -1.5511748  -0.17614946 -0.5826057  -1.4681414\n",
      " -0.10411809 -0.63601303 -1.4485761  -0.11115993 -0.60243565 -1.542129\n",
      "  0.02153143 -0.6357733  -1.5804687  -0.08815243 -0.48142275 -1.2951999\n",
      " -0.22762462 -0.243278   -2.009598   -0.05032498 -0.40892547 -2.0207713\n",
      "  0.11389889 -0.37006694 -1.4351591  -0.20339127 -0.24645418 -1.2235566\n",
      " -0.1245864  -0.21687394 -1.3123404  -0.08218311 -0.22612551 -1.4315901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00682759 -0.23491424 -1.2715305 ]\n",
      "data: [-0.01571459 -0.06308077 -0.23610874  0.01435518 -0.18610647 -0.610188\n",
      " -0.09396997 -0.38768935 -1.403243   -0.24258724 -0.44888553 -1.7040099\n",
      " -0.4062845  -0.55559915 -2.1932628  -0.22153781 -0.6793295  -1.5644355\n",
      " -0.0092708  -0.72217417 -1.3722364  -0.06425314 -0.65779215 -1.424912\n",
      " -0.07791229 -0.80417085 -1.5511748  -0.17614946 -0.5826057  -1.4681414\n",
      " -0.10411809 -0.63601303 -1.4485761  -0.11115993 -0.60243565 -1.542129\n",
      "  0.02153143 -0.6357733  -1.5804687  -0.08815243 -0.48142278 -1.2951999\n",
      " -0.22762462 -0.24327798 -2.009598   -0.05032497 -0.40892547 -2.0207713\n",
      "  0.11389889 -0.37006694 -1.4351592  -0.20339127 -0.24645418 -1.2235566\n",
      " -0.1245864  -0.21687394 -1.3123404  -0.0821831  -0.22612551 -1.4315901\n",
      "  0.00682759 -0.23491424 -1.2715305   0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BB38>\n",
      "tensor([[-6.6722e-04, -4.4202e-02, -2.1757e-01,  ...,  1.2792e-02,\n",
      "         -2.1901e-01, -1.2840e+00],\n",
      "        [-6.6722e-04, -4.4202e-02, -2.1757e-01,  ...,  1.2792e-02,\n",
      "         -2.1901e-01, -1.2840e+00],\n",
      "        [-6.6722e-04, -4.4202e-02, -2.1757e-01,  ...,  1.2792e-02,\n",
      "         -2.1901e-01, -1.2840e+00],\n",
      "        ...,\n",
      "        [-3.7765e-01,  1.2254e-01, -3.6129e-01,  ..., -8.8285e-01,\n",
      "          5.4950e-01, -5.8282e-01],\n",
      "        [-1.1752e-01, -1.3762e-01,  5.9446e-01,  ..., -2.0888e-01,\n",
      "          6.2127e-01,  2.6441e-01],\n",
      "        [-1.1752e-01, -1.3762e-01,  5.9446e-01,  ..., -2.0888e-01,\n",
      "          6.2127e-01,  2.6441e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-6.67224638e-04 -4.42016870e-02 -2.17568979e-01  6.59275427e-03\n",
      " -1.94470420e-01 -6.60000682e-01 -6.41993135e-02 -3.65374684e-01\n",
      " -1.36033976e+00 -2.06145048e-01 -4.22678441e-01 -1.66724062e+00\n",
      " -3.90391290e-01 -5.41896462e-01 -2.12381887e+00 -2.14834079e-01\n",
      " -6.46726012e-01 -1.51255238e+00  1.29356533e-02 -6.64639115e-01\n",
      " -1.31520307e+00 -3.41467559e-02 -6.06428146e-01 -1.37104058e+00\n",
      " -3.20826843e-02 -7.31666446e-01 -1.48659348e+00 -1.71893671e-01\n",
      " -5.34406066e-01 -1.43065596e+00 -7.97806382e-02 -5.88620543e-01\n",
      " -1.40887737e+00 -8.54912624e-02 -5.64617515e-01 -1.51490855e+00\n",
      "  4.87799793e-02 -5.84628224e-01 -1.57411301e+00 -7.78418407e-02\n",
      " -4.49782968e-01 -1.26106083e+00 -1.80272758e-01 -2.32432663e-01\n",
      " -1.85993588e+00 -3.40942815e-02 -3.76669407e-01 -1.85363615e+00\n",
      "  1.20794326e-01 -3.45029861e-01 -1.42860293e+00 -1.77501217e-01\n",
      " -2.10754901e-01 -1.20330036e+00 -9.78436172e-02 -1.91730067e-01\n",
      " -1.28470206e+00 -5.12822568e-02 -2.09043711e-01 -1.40631759e+00\n",
      "  1.27917603e-02 -2.19006911e-01 -1.28396022e+00]\n",
      "data: [-4.26 -2.88  5.1  -4.28 -2.62  5.08 -4.29 -2.21  5.36 -4.28 -1.94  5.57\n",
      " -4.3  -1.78  5.92 -4.1  -2.23  5.54 -4.09 -1.86  5.75 -4.25 -1.79  5.99\n",
      " -4.34 -1.75  5.98 -4.12 -2.26  5.54 -4.11 -1.86  5.75 -4.3  -1.78  5.92\n",
      "  0.    0.    0.   -4.11 -2.27  5.31 -4.2  -1.93  5.77 -4.28 -1.81  5.59\n",
      "  0.    0.    0.   -4.25 -2.21  5.36 -4.28 -1.97  5.57 -4.55 -2.    6.33\n",
      " -4.51 -1.93  6.01  0.  ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[-2.2371e-02, -2.7968e-03, -6.6571e-02,  ..., -1.6999e-01,\n",
      "         -2.1121e-01, -6.3131e-01],\n",
      "        [-2.2371e-02, -2.7968e-03, -6.6571e-02,  ..., -1.6999e-01,\n",
      "         -2.1121e-01, -6.3131e-01],\n",
      "        [-2.2371e-02, -2.7968e-03, -6.6571e-02,  ..., -1.6999e-01,\n",
      "         -2.1121e-01, -6.3131e-01],\n",
      "        ...,\n",
      "        [ 9.8467e-01, -1.0751e+00,  4.0975e-01,  ..., -8.2348e-02,\n",
      "         -9.2293e-01,  7.8803e-01],\n",
      "        [ 3.3716e-01,  3.6978e-01,  1.1654e+00,  ...,  3.0336e-01,\n",
      "          2.1495e-01,  3.4814e+00],\n",
      "        [ 3.3716e-01,  3.6978e-01,  1.1654e+00,  ...,  3.0336e-01,\n",
      "          2.1495e-01,  3.4814e+00]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.02237065 -0.00279676 -0.06657142 -0.11321448 -0.07381529 -0.47453448\n",
      " -0.11189262 -0.17991982 -0.62229097 -0.08655821 -0.29859704 -0.5872375\n",
      " -0.03874383 -0.38656265 -0.65106785 -0.17514881 -0.1974276  -0.95165265\n",
      "  0.00675306 -0.24887682 -0.32016522 -0.079492   -0.3879227  -0.2986232\n",
      " -0.19886255 -0.39279932 -0.39110455 -0.18086085 -0.15545858 -0.9860443\n",
      " -0.23368996 -0.26540095 -0.9322033  -0.29992715 -0.33014244 -0.888059\n",
      " -0.3359848  -0.46372986 -0.82499087 -0.18958196 -0.11068141 -0.9658649\n",
      " -0.29126003 -0.1564606  -1.0357013  -0.29832348 -0.23484625 -1.0463264\n",
      " -0.2545338  -0.3523649  -0.74425685 -0.2069675  -0.0129867  -0.8102555\n",
      " -0.15764853 -0.0877188  -0.7818799  -0.20147638 -0.14029315 -0.75178814\n",
      " -0.16999355 -0.21120888 -0.63130665]\n",
      "init: [-0.02237065 -0.00279676 -0.06657142 -0.11321448 -0.07381529 -0.47453448\n",
      " -0.11189262 -0.17991982 -0.62229097 -0.08655821 -0.29859704 -0.5872375\n",
      " -0.03874383 -0.38656265 -0.65106785 -0.17514881 -0.1974276  -0.95165265\n",
      "  0.00675306 -0.24887682 -0.32016522 -0.079492   -0.3879227  -0.2986232\n",
      " -0.19886255 -0.39279932 -0.39110455 -0.18086085 -0.15545858 -0.9860443\n",
      " -0.23368996 -0.26540095 -0.9322033  -0.29992715 -0.33014244 -0.888059\n",
      " -0.3359848  -0.46372986 -0.82499087 -0.18958196 -0.11068141 -0.9658649\n",
      " -0.29126003 -0.1564606  -1.0357013  -0.29832348 -0.23484625 -1.0463264\n",
      " -0.2545338  -0.3523649  -0.74425685 -0.2069675  -0.0129867  -0.8102555\n",
      " -0.15764853 -0.0877188  -0.7818799  -0.20147638 -0.14029315 -0.75178814\n",
      " -0.16999355 -0.21120888 -0.63130665]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [-0.02237065 -0.00279676 -0.06657142 -0.11321447 -0.07381529 -0.47453448\n",
      " -0.11189261 -0.17991981 -0.62229097 -0.08655821 -0.29859704 -0.5872375\n",
      " -0.03874383 -0.38656265 -0.6510679  -0.17514881 -0.1974276  -0.9516527\n",
      "  0.00675306 -0.24887682 -0.32016522 -0.079492   -0.3879227  -0.2986232\n",
      " -0.19886255 -0.3927993  -0.39110455 -0.18086085 -0.15545858 -0.9860443\n",
      " -0.23368996 -0.26540095 -0.9322033  -0.29992715 -0.33014244 -0.888059\n",
      " -0.3359848  -0.46372986 -0.82499087 -0.18958196 -0.11068142 -0.9658649\n",
      " -0.29126003 -0.1564606  -1.0357013  -0.29832348 -0.23484625 -1.0463264\n",
      " -0.2545338  -0.3523649  -0.7442568  -0.2069675  -0.0129867  -0.8102555\n",
      " -0.15764853 -0.0877188  -0.7818799  -0.20147638 -0.14029315 -0.7517882\n",
      " -0.16999355 -0.21120888 -0.63130665  0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EC24BA8>\n",
      "tensor([[ 0.1319, -0.2336,  0.2936,  ...,  0.2676, -0.3780, -0.7740],\n",
      "        [ 0.1319, -0.2336,  0.2936,  ...,  0.2676, -0.3780, -0.7740],\n",
      "        [ 0.1319, -0.2336,  0.2936,  ...,  0.2676, -0.3780, -0.7740],\n",
      "        ...,\n",
      "        [-0.0010,  0.0281, -0.5317,  ..., -0.7699,  0.5029, -0.8235],\n",
      "        [-0.2136,  0.1739,  0.0607,  ..., -0.5496,  0.8697, -0.1786],\n",
      "        [-0.2136,  0.1739,  0.0607,  ..., -0.5496,  0.8697, -0.1786]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.3185479e-01 -2.3358521e-01  2.9363060e-01  1.6609821e-01\n",
      " -3.7333101e-01  1.4158189e-03  8.0055155e-02 -5.4264224e-01\n",
      " -7.5543904e-01 -7.7169552e-02 -5.8496696e-01 -1.0629519e+00\n",
      " -2.5305679e-01 -7.1664500e-01 -1.5491462e+00 -9.1884077e-02\n",
      " -8.1906319e-01 -9.5627165e-01  2.1901673e-01 -8.1956208e-01\n",
      " -7.1562862e-01  1.7305483e-01 -7.4843562e-01 -7.4552417e-01\n",
      "  1.5678778e-01 -8.5330272e-01 -8.6724007e-01 -2.2470593e-02\n",
      " -7.0655763e-01 -8.7483811e-01  1.1787626e-01 -7.5790751e-01\n",
      " -8.8304222e-01  1.4803882e-01 -6.9453537e-01 -9.7604394e-01\n",
      "  2.9307604e-01 -7.4636400e-01 -1.0612043e+00  1.2721205e-01\n",
      " -6.2412655e-01 -6.9977403e-01  1.9813165e-02 -3.5627860e-01\n",
      " -1.3255931e+00  2.1291158e-01 -5.3484201e-01 -1.3022044e+00\n",
      "  3.8139176e-01 -4.5821956e-01 -9.3909419e-01 -4.4067502e-03\n",
      " -3.7703714e-01 -6.5344024e-01  1.3281307e-01 -3.3494616e-01\n",
      " -7.4244893e-01  2.0749098e-01 -3.7541470e-01 -8.7950706e-01\n",
      "  2.6762170e-01 -3.7798560e-01 -7.7396691e-01]\n",
      "data: [ 1.3185479e-01 -2.3358521e-01  2.9363060e-01  1.6609821e-01\n",
      " -3.7333098e-01  1.4158189e-03  8.0055147e-02 -5.4264224e-01\n",
      " -7.5543904e-01 -7.7169552e-02 -5.8496696e-01 -1.0629519e+00\n",
      " -2.5305679e-01 -7.1664500e-01 -1.5491462e+00 -9.1884077e-02\n",
      " -8.1906319e-01 -9.5627165e-01  2.1901673e-01 -8.1956208e-01\n",
      " -7.1562868e-01  1.7305483e-01 -7.4843562e-01 -7.4552417e-01\n",
      "  1.5678778e-01 -8.5330272e-01 -8.6724007e-01 -2.2470593e-02\n",
      " -7.0655763e-01 -8.7483811e-01  1.1787626e-01 -7.5790751e-01\n",
      " -8.8304222e-01  1.4803882e-01 -6.9453537e-01 -9.7604394e-01\n",
      "  2.9307604e-01 -7.4636400e-01 -1.0612043e+00  1.2721205e-01\n",
      " -6.2412655e-01 -6.9977403e-01  1.9813165e-02 -3.5627860e-01\n",
      " -1.3255931e+00  2.1291156e-01 -5.3484201e-01 -1.3022045e+00\n",
      "  3.8139176e-01 -4.5821956e-01 -9.3909419e-01 -4.4067502e-03\n",
      " -3.7703714e-01 -6.5344024e-01  1.3281307e-01 -3.3494613e-01\n",
      " -7.4244899e-01  2.0749098e-01 -3.7541470e-01 -8.7950706e-01\n",
      "  2.6762170e-01 -3.7798560e-01 -7.7396691e-01  2.0000000e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B320>\n",
      "tensor([[ 0.0110, -0.0530, -0.0177,  ..., -0.1044, -0.2958, -0.9575],\n",
      "        [ 0.0110, -0.0530, -0.0177,  ..., -0.1044, -0.2958, -0.9575],\n",
      "        [ 0.0110, -0.0530, -0.0177,  ..., -0.1044, -0.2958, -0.9575],\n",
      "        ...,\n",
      "        [-0.3236,  0.0813,  0.4479,  ..., -0.3793,  0.8105, -0.2149],\n",
      "        [-0.1584,  0.2471,  0.4383,  ...,  0.1497,  0.6645,  0.1837],\n",
      "        [-0.1584,  0.2471,  0.4383,  ...,  0.1497,  0.6645,  0.1837]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01098992 -0.05296104 -0.01769522 -0.05973843 -0.18045539 -0.37435034\n",
      " -0.21337128 -0.3867334  -1.090114   -0.40133876 -0.45412776 -1.4118278\n",
      " -0.6603498  -0.5413095  -1.8940352  -0.24032158 -0.66782784 -1.3031027\n",
      " -0.27136952 -0.7636961  -1.3358155  -0.32649016 -0.642887   -1.4310651\n",
      " -0.2654671  -0.89854157 -1.4942465  -0.20080246 -0.5612978  -1.1986996\n",
      " -0.24737021 -0.61174107 -1.1345518  -0.3337186  -0.6816404  -1.2689635\n",
      " -0.19709775 -0.5944996  -1.2513813  -0.1610536  -0.5075186  -1.0511767\n",
      " -0.30150828 -0.32690793 -1.7235867  -0.22791347 -0.47251335 -1.748757\n",
      " -0.08281595 -0.48312345 -1.0555454  -0.20182253 -0.30300897 -0.99751705\n",
      " -0.2551713  -0.3194704  -1.0767167  -0.2508629  -0.28348973 -1.1729625\n",
      " -0.10439801 -0.29579967 -0.9574566 ]\n",
      "data: [ 0.01098992 -0.05296104 -0.01769522 -0.05973843 -0.18045539 -0.37435037\n",
      " -0.21337128 -0.3867334  -1.090114   -0.40133876 -0.45412776 -1.4118278\n",
      " -0.6603498  -0.5413095  -1.8940352  -0.24032158 -0.66782784 -1.3031027\n",
      " -0.27136952 -0.7636961  -1.3358155  -0.32649016 -0.64288694 -1.4310651\n",
      " -0.2654671  -0.89854157 -1.4942465  -0.20080246 -0.5612978  -1.1986996\n",
      " -0.2473702  -0.61174107 -1.1345518  -0.3337186  -0.6816404  -1.2689635\n",
      " -0.19709773 -0.5944996  -1.2513813  -0.1610536  -0.5075186  -1.0511767\n",
      " -0.30150828 -0.32690793 -1.7235867  -0.22791347 -0.47251335 -1.748757\n",
      " -0.08281595 -0.48312342 -1.0555454  -0.20182253 -0.30300897 -0.997517\n",
      " -0.2551713  -0.3194704  -1.0767167  -0.2508629  -0.28348973 -1.1729625\n",
      " -0.10439801 -0.29579967 -0.9574566   0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EC246D8>\n",
      "tensor([[ 0.0541,  0.1145, -0.2289,  ...,  0.1788, -0.0986, -1.2330],\n",
      "        [ 0.0541,  0.1145, -0.2289,  ...,  0.1788, -0.0986, -1.2330],\n",
      "        [ 0.0541,  0.1145, -0.2289,  ...,  0.1788, -0.0986, -1.2330],\n",
      "        ...,\n",
      "        [-0.0997,  0.3820,  0.1988,  ..., -0.2774,  1.0857, -0.1712],\n",
      "        [-0.1093, -0.1148,  0.4718,  ..., -0.4364,  0.4522,  0.2235],\n",
      "        [-0.1093, -0.1148,  0.4718,  ..., -0.4364,  0.4522,  0.2235]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.05405778  0.11445393 -0.22888441  0.08972684 -0.02385548 -0.5626631\n",
      "  0.01650044 -0.2006527  -1.3285736  -0.12308813 -0.2605967  -1.6232247\n",
      " -0.28873137 -0.40509742 -2.0817006  -0.14857584 -0.48101622 -1.515594\n",
      "  0.16275382 -0.49729365 -1.2603706   0.12305803 -0.43914807 -1.2916727\n",
      "  0.14241567 -0.54223806 -1.4156764  -0.09139786 -0.36861193 -1.4273843\n",
      "  0.04274321 -0.43603402 -1.4071162   0.08159079 -0.39760196 -1.4850569\n",
      "  0.24286029 -0.44716305 -1.5633862   0.03436451 -0.30350274 -1.2364572\n",
      " -0.07431216 -0.04923926 -1.8708162   0.12061977 -0.23289399 -1.843494\n",
      "  0.31768638 -0.18160145 -1.4092717  -0.10055637 -0.04870808 -1.173099\n",
      "  0.03706317 -0.02579798 -1.2453977   0.11309446 -0.07350029 -1.3648521\n",
      "  0.1788114  -0.09863551 -1.2329843 ]\n",
      "data: [ 0.05405778  0.11445393 -0.22888441  0.08972684 -0.02385548 -0.5626631\n",
      "  0.01650044 -0.20065269 -1.3285736  -0.12308813 -0.2605967  -1.6232247\n",
      " -0.28873137 -0.40509742 -2.0817006  -0.14857584 -0.48101625 -1.515594\n",
      "  0.16275384 -0.49729365 -1.2603706   0.12305804 -0.43914807 -1.2916727\n",
      "  0.14241567 -0.54223806 -1.4156765  -0.09139786 -0.36861193 -1.4273841\n",
      "  0.04274322 -0.43603402 -1.4071163   0.08159079 -0.39760196 -1.4850569\n",
      "  0.24286027 -0.44716305 -1.5633862   0.03436451 -0.30350274 -1.2364572\n",
      " -0.07431216 -0.04923926 -1.8708162   0.12061977 -0.23289399 -1.843494\n",
      "  0.31768638 -0.18160145 -1.4092717  -0.10055637 -0.04870808 -1.173099\n",
      "  0.03706317 -0.02579798 -1.2453977   0.11309446 -0.07350029 -1.3648522\n",
      "  0.1788114  -0.09863551 -1.2329843   0.04      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.1012, -0.2105, -0.2029,  ...,  0.1316, -0.3686, -1.3101],\n",
      "        [ 0.1012, -0.2105, -0.2029,  ...,  0.1316, -0.3686, -1.3101],\n",
      "        [ 0.1012, -0.2105, -0.2029,  ...,  0.1316, -0.3686, -1.3101],\n",
      "        ...,\n",
      "        [-0.4452,  0.1724, -0.4220,  ..., -1.0456,  0.5770, -0.6319],\n",
      "        [-0.1330,  0.1889,  0.5158,  ..., -0.1868,  1.0229,  0.1188],\n",
      "        [-0.1330,  0.1889,  0.5158,  ..., -0.1868,  1.0229,  0.1188]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.1011823  -0.2105326  -0.20288162  0.12169483 -0.38047227 -0.7169988\n",
      "  0.08074813 -0.5244553  -1.401      -0.05148032 -0.5758801  -1.6974348\n",
      " -0.20904218 -0.7116128  -2.1704116  -0.11650102 -0.7750554  -1.5560291\n",
      "  0.16232835 -0.7636336  -1.3023349   0.10550471 -0.70380884 -1.3565291\n",
      "  0.08462726 -0.78928536 -1.4729296  -0.07829079 -0.65948987 -1.4884099\n",
      "  0.04128806 -0.7072596  -1.4702708   0.02591906 -0.6670602  -1.5545263\n",
      "  0.12827136 -0.6934539  -1.6144667   0.03517664 -0.58893436 -1.3148317\n",
      " -0.03881319 -0.35624644 -1.8074647   0.08259846 -0.49909472 -1.7784314\n",
      "  0.20545597 -0.4590053  -1.4763361  -0.05870491 -0.35413274 -1.2555368\n",
      "  0.05069251 -0.3297166  -1.3120447   0.10068293 -0.3604175  -1.4282333\n",
      "  0.1316072  -0.36863118 -1.3100946 ]\n",
      "data: [ 0.1011823  -0.2105326  -0.20288162  0.12169483 -0.38047227 -0.7169988\n",
      "  0.08074813 -0.5244553  -1.401      -0.05148032 -0.5758801  -1.6974349\n",
      " -0.20904216 -0.7116129  -2.1704116  -0.11650102 -0.7750554  -1.5560291\n",
      "  0.16232833 -0.76363355 -1.3023349   0.10550471 -0.70380884 -1.3565291\n",
      "  0.08462726 -0.78928536 -1.4729295  -0.07829079 -0.65948987 -1.4884099\n",
      "  0.04128806 -0.7072596  -1.4702706   0.02591906 -0.66706014 -1.5545263\n",
      "  0.12827136 -0.6934539  -1.6144667   0.03517664 -0.58893436 -1.3148317\n",
      " -0.03881319 -0.35624644 -1.8074647   0.08259847 -0.49909472 -1.7784314\n",
      "  0.20545597 -0.45900527 -1.476336   -0.05870491 -0.35413274 -1.2555368\n",
      "  0.05069251 -0.3297166  -1.3120446   0.10068293 -0.3604175  -1.4282334\n",
      "  0.1316072  -0.36863118 -1.3100946   0.05      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[ 0.0085, -0.2035, -0.1850,  ...,  0.0347, -0.3911, -1.2270],\n",
      "        [ 0.0085, -0.2035, -0.1850,  ...,  0.0347, -0.3911, -1.2270],\n",
      "        [ 0.0085, -0.2035, -0.1850,  ...,  0.0347, -0.3911, -1.2270],\n",
      "        ...,\n",
      "        [-0.0114,  0.5752, -0.2271,  ..., -0.4963,  1.0836, -0.6394],\n",
      "        [-0.1415, -0.0014,  0.5976,  ..., -0.1454,  0.7210,  0.1764],\n",
      "        [-0.1415, -0.0014,  0.5976,  ..., -0.1454,  0.7210,  0.1764]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00851746 -0.20347203 -0.18500005  0.04188546 -0.33181322 -0.5522039\n",
      " -0.04946913 -0.5493716  -1.3695388  -0.19977635 -0.6132933  -1.6804565\n",
      " -0.36994624 -0.7333626  -2.1698952  -0.20257181 -0.8110385  -1.5728503\n",
      "  0.04220369 -0.86571485 -1.3637425  -0.01818616 -0.80976355 -1.4030923\n",
      " -0.03927331 -0.9592599  -1.5235413  -0.14813802 -0.7062655  -1.4622352\n",
      " -0.06756836 -0.77986175 -1.4292486  -0.07536671 -0.75985986 -1.5218513\n",
      "  0.03725929 -0.8044265  -1.5648712  -0.04668047 -0.60580766 -1.2833415\n",
      " -0.20150867 -0.37834382 -2.0085163  -0.02213944 -0.56850755 -2.006928\n",
      "  0.12801072 -0.52208394 -1.4011278  -0.17456397 -0.36976844 -1.2089807\n",
      " -0.07903055 -0.3488085  -1.2732487  -0.02988017 -0.3844478  -1.3831941\n",
      "  0.03469512 -0.39105695 -1.2269661 ]\n",
      "data: [ 0.00851746 -0.20347205 -0.18500003  0.04188546 -0.33181322 -0.5522039\n",
      " -0.04946913 -0.5493716  -1.3695388  -0.19977635 -0.6132933  -1.6804565\n",
      " -0.36994624 -0.73336256 -2.1698952  -0.20257181 -0.8110385  -1.5728503\n",
      "  0.04220369 -0.86571485 -1.3637425  -0.01818616 -0.80976355 -1.4030921\n",
      " -0.03927331 -0.9592599  -1.5235412  -0.14813802 -0.7062655  -1.4622352\n",
      " -0.06756836 -0.77986175 -1.4292485  -0.07536671 -0.75985986 -1.5218513\n",
      "  0.03725929 -0.8044265  -1.5648712  -0.04668047 -0.60580766 -1.2833415\n",
      " -0.20150867 -0.37834382 -2.0085163  -0.02213944 -0.56850755 -2.006928\n",
      "  0.12801072 -0.52208394 -1.4011278  -0.17456397 -0.36976844 -1.2089807\n",
      " -0.07903055 -0.34880847 -1.2732487  -0.02988017 -0.3844478  -1.3831941\n",
      "  0.03469512 -0.39105693 -1.2269661   0.06      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[-0.0133, -0.0789, -0.1686,  ...,  0.0095, -0.2562, -1.1675],\n",
      "        [-0.0133, -0.0789, -0.1686,  ...,  0.0095, -0.2562, -1.1675],\n",
      "        [-0.0133, -0.0789, -0.1686,  ...,  0.0095, -0.2562, -1.1675],\n",
      "        ...,\n",
      "        [-0.1474,  0.4768, -0.1128,  ..., -0.6669,  1.1013, -0.5563],\n",
      "        [-0.0530,  0.0139,  0.6697,  ..., -0.1243,  0.6744,  0.2946],\n",
      "        [-0.0530,  0.0139,  0.6697,  ..., -0.1243,  0.6744,  0.2946]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01331154 -0.07893009 -0.16862066  0.01556388 -0.19230951 -0.45309907\n",
      " -0.10741436 -0.42183828 -1.3099117  -0.26315004 -0.48489383 -1.6073279\n",
      " -0.42407024 -0.58769107 -2.1144376  -0.22016199 -0.7101675  -1.510602\n",
      " -0.01585384 -0.7712625  -1.3574088  -0.06928726 -0.7043823  -1.397776\n",
      " -0.0624145  -0.86074865 -1.5216216  -0.17063859 -0.6106961  -1.4027861\n",
      " -0.09814753 -0.6698836  -1.370655   -0.09385107 -0.637043   -1.461365\n",
      "  0.0454721  -0.67797935 -1.4898152  -0.07625439 -0.4965462  -1.2355895\n",
      " -0.23989521 -0.26212475 -1.9974127  -0.04305458 -0.44318482 -2.0146847\n",
      "  0.13794355 -0.39744398 -1.3462735  -0.21084704 -0.25843227 -1.1563547\n",
      " -0.12413426 -0.23187876 -1.2332073  -0.08579859 -0.24876155 -1.3454959\n",
      "  0.0095351  -0.25624532 -1.1675465 ]\n",
      "data: [-0.01331154 -0.07893009 -0.16862066  0.01556388 -0.19230951 -0.45309907\n",
      " -0.10741436 -0.4218383  -1.3099118  -0.26315004 -0.48489383 -1.6073279\n",
      " -0.42407024 -0.58769107 -2.1144376  -0.22016199 -0.7101675  -1.510602\n",
      " -0.01585384 -0.7712625  -1.3574088  -0.06928726 -0.7043823  -1.397776\n",
      " -0.0624145  -0.86074865 -1.5216216  -0.1706386  -0.6106961  -1.4027861\n",
      " -0.09814753 -0.66988355 -1.370655   -0.09385107 -0.637043   -1.4613651\n",
      "  0.0454721  -0.67797935 -1.4898152  -0.07625439 -0.4965462  -1.2355895\n",
      " -0.23989521 -0.26212475 -1.9974127  -0.04305458 -0.44318482 -2.0146847\n",
      "  0.13794355 -0.39744395 -1.3462735  -0.21084704 -0.25843227 -1.1563547\n",
      " -0.12413426 -0.23187876 -1.2332073  -0.08579859 -0.24876156 -1.3454959\n",
      "  0.0095351  -0.25624532 -1.1675465   0.07      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B320>\n",
      "tensor([[-0.0022, -0.0614, -0.2362,  ...,  0.0134, -0.2352, -1.2574],\n",
      "        [-0.0022, -0.0614, -0.2362,  ...,  0.0134, -0.2352, -1.2574],\n",
      "        [-0.0022, -0.0614, -0.2362,  ...,  0.0134, -0.2352, -1.2574],\n",
      "        ...,\n",
      "        [-0.2078,  0.3295,  0.0181,  ..., -0.7059,  0.8883, -0.2855],\n",
      "        [-0.0954, -0.0557,  0.6550,  ..., -0.2390,  0.6758,  0.3848],\n",
      "        [-0.0954, -0.0557,  0.6550,  ..., -0.2390,  0.6758,  0.3848]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.00220863 -0.06138002 -0.23619492  0.02652932 -0.17419416 -0.6041552\n",
      " -0.10023997 -0.3798648  -1.3938079  -0.2520657  -0.43978775 -1.6841334\n",
      " -0.40373862 -0.5317093  -2.1772926  -0.19963902 -0.68620783 -1.54731\n",
      " -0.01788443 -0.73563814 -1.3732606  -0.06823452 -0.6615192  -1.4296956\n",
      " -0.08058216 -0.81667334 -1.5556331  -0.15967195 -0.5982487  -1.4563777\n",
      " -0.09777259 -0.64558136 -1.4314958  -0.10854638 -0.6068877  -1.5178138\n",
      "  0.03180347 -0.63607377 -1.5415467  -0.07773175 -0.49014676 -1.2945825\n",
      " -0.21893086 -0.25153238 -2.01059    -0.04315652 -0.4135638  -2.0314143\n",
      "  0.12812632 -0.37487847 -1.4150162  -0.19128281 -0.26096052 -1.2198073\n",
      " -0.12533672 -0.22552277 -1.3144674  -0.09104612 -0.22417396 -1.433119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.01338743 -0.23522668 -1.2573509 ]\n",
      "data: [-0.00220863 -0.06138002 -0.23619491  0.02652932 -0.17419416 -0.6041552\n",
      " -0.10023997 -0.3798648  -1.3938079  -0.2520657  -0.43978775 -1.6841334\n",
      " -0.40373862 -0.5317093  -2.1772926  -0.19963902 -0.68620783 -1.54731\n",
      " -0.01788443 -0.73563814 -1.3732606  -0.06823452 -0.6615192  -1.4296956\n",
      " -0.08058216 -0.81667334 -1.5556331  -0.15967195 -0.5982487  -1.4563777\n",
      " -0.09777259 -0.64558136 -1.4314958  -0.10854638 -0.6068877  -1.5178139\n",
      "  0.03180347 -0.63607377 -1.5415466  -0.07773175 -0.49014676 -1.2945825\n",
      " -0.21893086 -0.25153238 -2.01059    -0.04315652 -0.41356382 -2.0314143\n",
      "  0.12812632 -0.37487847 -1.4150162  -0.19128281 -0.26096052 -1.2198073\n",
      " -0.12533672 -0.22552277 -1.3144674  -0.09104612 -0.22417396 -1.433119\n",
      "  0.01338743 -0.23522668 -1.2573509   0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0423, -0.0428, -0.1858,  ...,  0.0244, -0.2338, -1.2208],\n",
      "        [ 0.0423, -0.0428, -0.1858,  ...,  0.0244, -0.2338, -1.2208],\n",
      "        [ 0.0423, -0.0428, -0.1858,  ...,  0.0244, -0.2338, -1.2208],\n",
      "        ...,\n",
      "        [-0.3419,  0.1922, -0.2850,  ..., -0.8425,  0.6132, -0.4485],\n",
      "        [-0.1115, -0.0750,  0.5877,  ..., -0.1805,  0.6883,  0.3060],\n",
      "        [-0.1115, -0.0750,  0.5877,  ..., -0.1805,  0.6883,  0.3060]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04231596 -0.04280547 -0.18578696  0.05496174 -0.16632329 -0.5782182\n",
      " -0.07443914 -0.3595969  -1.3443468  -0.22582506 -0.42620862 -1.6262486\n",
      " -0.39394033 -0.5082164  -2.1217089  -0.15148844 -0.6714921  -1.4874333\n",
      " -0.01954226 -0.7198675  -1.3448858  -0.06453453 -0.6403795  -1.4090434\n",
      " -0.06737088 -0.80072904 -1.5191875  -0.12008066 -0.58145523 -1.4087934\n",
      " -0.07227232 -0.624537   -1.3692645  -0.10578609 -0.5993543  -1.462052\n",
      "  0.0345249  -0.60276586 -1.4823412  -0.05749898 -0.48897886 -1.2575234\n",
      " -0.17655836 -0.2661152  -1.9174615  -0.0361928  -0.40610152 -1.9399087\n",
      "  0.11875175 -0.38435763 -1.3580124  -0.14553717 -0.2618699  -1.1902902\n",
      " -0.11078155 -0.23703307 -1.2811239  -0.08217679 -0.22042868 -1.3976603\n",
      "  0.02435184 -0.23381096 -1.2208208 ]\n",
      "data: [ 0.04231596 -0.04280547 -0.18578698  0.05496174 -0.16632327 -0.5782182\n",
      " -0.07443914 -0.3595969  -1.3443468  -0.22582506 -0.42620862 -1.6262486\n",
      " -0.39394033 -0.5082164  -2.1217089  -0.15148844 -0.6714921  -1.4874333\n",
      " -0.01954226 -0.7198675  -1.3448858  -0.06453453 -0.6403795  -1.4090434\n",
      " -0.06737088 -0.80072904 -1.5191875  -0.12008066 -0.58145523 -1.4087934\n",
      " -0.07227232 -0.624537   -1.3692645  -0.10578609 -0.5993543  -1.462052\n",
      "  0.0345249  -0.60276586 -1.4823412  -0.05749898 -0.4889789  -1.2575234\n",
      " -0.17655836 -0.2661152  -1.9174615  -0.0361928  -0.40610152 -1.9399087\n",
      "  0.11875174 -0.38435763 -1.3580124  -0.14553717 -0.2618699  -1.1902902\n",
      " -0.11078156 -0.23703307 -1.2811238  -0.08217679 -0.22042868 -1.3976603\n",
      "  0.02435184 -0.23381096 -1.2208208   0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0361, -0.0298, -0.2591,  ...,  0.0138, -0.2246, -1.2885],\n",
      "        [ 0.0361, -0.0298, -0.2591,  ...,  0.0138, -0.2246, -1.2885],\n",
      "        [ 0.0361, -0.0298, -0.2591,  ...,  0.0138, -0.2246, -1.2885],\n",
      "        ...,\n",
      "        [-0.2581,  0.2831, -0.1705,  ..., -0.7906,  0.7181, -0.3466],\n",
      "        [-0.1163, -0.1135,  0.5831,  ..., -0.2096,  0.6938,  0.2868],\n",
      "        [-0.1163, -0.1135,  0.5831,  ..., -0.2096,  0.6938,  0.2868]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03610354 -0.02981331 -0.25910473  0.05324658 -0.14631188 -0.6460519\n",
      " -0.1060201  -0.34998718 -1.4488375  -0.2586912  -0.42345646 -1.7143412\n",
      " -0.417043   -0.48658234 -2.2227468  -0.14633691 -0.66861993 -1.5824022\n",
      " -0.05017427 -0.7253212  -1.4347858  -0.08436783 -0.63583523 -1.5020344\n",
      " -0.0899838  -0.8038229  -1.6129074  -0.12405302 -0.58489853 -1.5083334\n",
      " -0.08834905 -0.62355644 -1.4546502  -0.12754983 -0.593178   -1.5373929\n",
      "  0.03083288 -0.5879097  -1.549366   -0.07587338 -0.49305624 -1.362953\n",
      " -0.19282112 -0.26699644 -2.0217223  -0.05436187 -0.40021825 -2.0546668\n",
      "  0.11275923 -0.3794458  -1.4310277  -0.15775019 -0.26743293 -1.286757\n",
      " -0.1426104  -0.23577318 -1.376396   -0.1135039  -0.20514773 -1.4920442\n",
      "  0.01381693 -0.22464229 -1.2884908 ]\n",
      "data: [ 0.03610354 -0.02981331 -0.25910473  0.05324658 -0.14631188 -0.6460519\n",
      " -0.1060201  -0.34998718 -1.4488376  -0.2586912  -0.42345646 -1.7143412\n",
      " -0.417043   -0.48658234 -2.2227468  -0.14633691 -0.66861993 -1.5824022\n",
      " -0.05017427 -0.7253212  -1.4347857  -0.08436784 -0.63583523 -1.5020344\n",
      " -0.0899838  -0.8038229  -1.6129074  -0.12405302 -0.58489853 -1.5083334\n",
      " -0.08834906 -0.62355644 -1.4546502  -0.12754983 -0.593178   -1.5373929\n",
      "  0.03083288 -0.5879097  -1.549366   -0.07587338 -0.4930562  -1.3629528\n",
      " -0.19282112 -0.26699644 -2.0217223  -0.05436187 -0.40021825 -2.0546668\n",
      "  0.11275923 -0.3794458  -1.4310277  -0.15775019 -0.26743293 -1.286757\n",
      " -0.1426104  -0.23577318 -1.3763958  -0.1135039  -0.20514773 -1.4920442\n",
      "  0.01381693 -0.22464229 -1.2884908   0.1       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0506, -0.0236, -0.1728,  ...,  0.0629, -0.2172, -1.2097],\n",
      "        [ 0.0506, -0.0236, -0.1728,  ...,  0.0629, -0.2172, -1.2097],\n",
      "        [ 0.0506, -0.0236, -0.1728,  ...,  0.0629, -0.2172, -1.2097],\n",
      "        ...,\n",
      "        [-0.3265,  0.1537, -0.3320,  ..., -0.8972,  0.5378, -0.4514],\n",
      "        [-0.1514, -0.1327,  0.5078,  ..., -0.2484,  0.6360,  0.2285],\n",
      "        [-0.1514, -0.1327,  0.5078,  ..., -0.2484,  0.6360,  0.2285]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 5.06456383e-02 -2.36223843e-02 -1.72811151e-01  6.64028525e-02\n",
      " -1.60242006e-01 -5.73241472e-01 -3.81935984e-02 -3.39601576e-01\n",
      " -1.31569839e+00 -1.83621764e-01 -4.04998839e-01 -1.60128021e+00\n",
      " -3.54977071e-01 -5.05942822e-01 -2.08054519e+00 -1.42511040e-01\n",
      " -6.34725928e-01 -1.47096682e+00  2.79720128e-02 -6.69995308e-01\n",
      " -1.31563759e+00 -1.80998147e-02 -6.00308776e-01 -1.37625527e+00\n",
      " -1.28194243e-02 -7.42137909e-01 -1.48424315e+00 -1.05246335e-01\n",
      " -5.35175443e-01 -1.39466858e+00 -3.76949310e-02 -5.84513783e-01\n",
      " -1.36131477e+00 -6.11647069e-02 -5.64672589e-01 -1.45479989e+00\n",
      "  7.43155479e-02 -5.72924972e-01 -1.48979282e+00 -3.20451930e-02\n",
      " -4.54913765e-01 -1.23092461e+00 -1.38457030e-01 -2.32166529e-01\n",
      " -1.86253500e+00  1.59652531e-03 -3.76472741e-01 -1.86937737e+00\n",
      "  1.53475091e-01 -3.54353458e-01 -1.35111475e+00 -1.20705217e-01\n",
      " -2.23140016e-01 -1.17095590e+00 -6.52783513e-02 -2.03654751e-01\n",
      " -1.25280499e+00 -2.55673230e-02 -2.01597720e-01 -1.36876893e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6.29375726e-02 -2.17190519e-01 -1.20973444e+00]\n",
      "data: [ 5.06456383e-02 -2.36223843e-02 -1.72811151e-01  6.64028525e-02\n",
      " -1.60242006e-01 -5.73241472e-01 -3.81935984e-02 -3.39601606e-01\n",
      " -1.31569839e+00 -1.83621764e-01 -4.04998869e-01 -1.60128021e+00\n",
      " -3.54977071e-01 -5.05942822e-01 -2.08054519e+00 -1.42511040e-01\n",
      " -6.34725928e-01 -1.47096682e+00  2.79720109e-02 -6.69995248e-01\n",
      " -1.31563747e+00 -1.80998147e-02 -6.00308776e-01 -1.37625539e+00\n",
      " -1.28194233e-02 -7.42137909e-01 -1.48424315e+00 -1.05246335e-01\n",
      " -5.35175443e-01 -1.39466858e+00 -3.76949310e-02 -5.84513783e-01\n",
      " -1.36131465e+00 -6.11647069e-02 -5.64672589e-01 -1.45480001e+00\n",
      "  7.43155479e-02 -5.72924972e-01 -1.48979282e+00 -3.20451930e-02\n",
      " -4.54913735e-01 -1.23092461e+00 -1.38457030e-01 -2.32166514e-01\n",
      " -1.86253500e+00  1.59652531e-03 -3.76472741e-01 -1.86937749e+00\n",
      "  1.53475091e-01 -3.54353458e-01 -1.35111475e+00 -1.20705217e-01\n",
      " -2.23140016e-01 -1.17095590e+00 -6.52783513e-02 -2.03654751e-01\n",
      " -1.25280499e+00 -2.55673211e-02 -2.01597735e-01 -1.36876893e+00\n",
      "  6.29375726e-02 -2.17190519e-01 -1.20973444e+00  1.09999999e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0323, -0.0884, -0.2704,  ...,  0.0688, -0.2696, -1.3284],\n",
      "        [ 0.0323, -0.0884, -0.2704,  ...,  0.0688, -0.2696, -1.3284],\n",
      "        [ 0.0323, -0.0884, -0.2704,  ...,  0.0688, -0.2696, -1.3284],\n",
      "        ...,\n",
      "        [-0.3051,  0.2608, -0.2580,  ..., -0.7774,  0.6829, -0.4341],\n",
      "        [-0.1240, -0.0252,  0.5892,  ..., -0.2369,  0.7703,  0.2543],\n",
      "        [-0.1240, -0.0252,  0.5892,  ..., -0.2369,  0.7703,  0.2543]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03227999 -0.08836854 -0.27038482  0.05347748 -0.23911272 -0.69833744\n",
      " -0.03953443 -0.4228815  -1.4508016  -0.18228626 -0.48951402 -1.7411005\n",
      " -0.35277137 -0.60747737 -2.2098086  -0.1754809  -0.69139504 -1.606281\n",
      "  0.05079594 -0.71859556 -1.377826    0.00466911 -0.65578055 -1.4294205\n",
      " -0.00405072 -0.7795935  -1.5450122  -0.13249487 -0.5810745  -1.5262516\n",
      " -0.04333871 -0.6396022  -1.4920394  -0.05304999 -0.61256063 -1.5807068\n",
      "  0.08314475 -0.6336742  -1.633349   -0.0408048  -0.5037372  -1.3520699\n",
      " -0.14422849 -0.27392855 -1.9560938   0.00476843 -0.42779258 -1.9484386\n",
      "  0.16172925 -0.3934998  -1.4853368  -0.1393373  -0.26226193 -1.2882559\n",
      " -0.05871633 -0.23877974 -1.3608975  -0.00323927 -0.2550875  -1.4776666\n",
      "  0.06884761 -0.26964808 -1.3284073 ]\n",
      "data: [ 0.03227999 -0.08836853 -0.27038482  0.05347748 -0.23911272 -0.6983374\n",
      " -0.03953443 -0.4228815  -1.4508015  -0.18228626 -0.489514   -1.7411007\n",
      " -0.35277137 -0.60747737 -2.2098086  -0.1754809  -0.69139504 -1.6062809\n",
      "  0.05079594 -0.71859556 -1.377826    0.00466911 -0.65578055 -1.4294205\n",
      " -0.00405072 -0.7795935  -1.5450122  -0.13249487 -0.5810745  -1.5262516\n",
      " -0.04333871 -0.6396022  -1.4920394  -0.05304999 -0.61256063 -1.5807068\n",
      "  0.08314475 -0.6336742  -1.633349   -0.04080481 -0.5037372  -1.3520699\n",
      " -0.14422849 -0.27392855 -1.9560938   0.00476843 -0.42779258 -1.9484388\n",
      "  0.16172925 -0.3934998  -1.4853368  -0.1393373  -0.26226193 -1.2882559\n",
      " -0.05871633 -0.23877974 -1.3608975  -0.00323927 -0.2550875  -1.4776666\n",
      "  0.06884761 -0.26964808 -1.3284073   0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0234, -0.1290, -0.2563,  ...,  0.0693, -0.3125, -1.3228],\n",
      "        [ 0.0234, -0.1290, -0.2563,  ...,  0.0693, -0.3125, -1.3228],\n",
      "        [ 0.0234, -0.1290, -0.2563,  ...,  0.0693, -0.3125, -1.3228],\n",
      "        ...,\n",
      "        [-0.1278,  0.4439, -0.1893,  ..., -0.7179,  0.9441, -0.4529],\n",
      "        [-0.1581, -0.1075,  0.6038,  ..., -0.2440,  0.6501,  0.2737],\n",
      "        [-0.1581, -0.1075,  0.6038,  ..., -0.2440,  0.6501,  0.2737]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02343937 -0.12902538 -0.25629616  0.04172685 -0.2805808  -0.67622805\n",
      " -0.01638745 -0.45607162 -1.4031987  -0.15708144 -0.51438063 -1.7134364\n",
      " -0.33273953 -0.6489805  -2.1743724  -0.1878229  -0.7250496  -1.5825262\n",
      "  0.07502924 -0.7465558  -1.382998    0.01828031 -0.69300485 -1.4309411\n",
      "  0.02193799 -0.8109418  -1.5469426  -0.13568482 -0.61044836 -1.4933281\n",
      " -0.03171934 -0.6722965  -1.4764175  -0.03067173 -0.64960766 -1.5765007\n",
      "  0.08821493 -0.68252265 -1.6361077  -0.02860274 -0.5281538  -1.3123393\n",
      " -0.13698961 -0.30310923 -1.9257824   0.01782201 -0.46483523 -1.9099638\n",
      "  0.16883363 -0.42723468 -1.4821801  -0.14125186 -0.28578985 -1.2532926\n",
      " -0.03517273 -0.2695591  -1.3289632   0.01747558 -0.30357116 -1.4446088\n",
      "  0.06926899 -0.3125248  -1.3227924 ]\n",
      "data: [ 0.02343937 -0.12902538 -0.25629616  0.04172685 -0.2805808  -0.67622805\n",
      " -0.01638745 -0.45607162 -1.4031987  -0.15708144 -0.51438063 -1.7134365\n",
      " -0.33273953 -0.6489805  -2.1743724  -0.1878229  -0.7250496  -1.5825262\n",
      "  0.07502924 -0.7465558  -1.382998    0.01828031 -0.69300485 -1.4309411\n",
      "  0.02193799 -0.8109419  -1.5469426  -0.13568482 -0.61044836 -1.4933281\n",
      " -0.03171934 -0.6722965  -1.4764175  -0.03067173 -0.6496077  -1.5765007\n",
      "  0.08821493 -0.68252265 -1.6361077  -0.02860274 -0.5281538  -1.3123393\n",
      " -0.13698961 -0.30310923 -1.9257824   0.01782201 -0.46483526 -1.9099638\n",
      "  0.16883364 -0.42723468 -1.4821801  -0.14125186 -0.28578985 -1.2532926\n",
      " -0.03517273 -0.2695591  -1.3289632   0.01747558 -0.30357116 -1.4446088\n",
      "  0.06926899 -0.3125248  -1.3227924   0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0243, -0.1289, -0.2333,  ...,  0.0504, -0.3139, -1.2635],\n",
      "        [ 0.0243, -0.1289, -0.2333,  ...,  0.0504, -0.3139, -1.2635],\n",
      "        [ 0.0243, -0.1289, -0.2333,  ...,  0.0504, -0.3139, -1.2635],\n",
      "        ...,\n",
      "        [-0.1106,  0.4747, -0.1662,  ..., -0.6168,  0.9607, -0.4914],\n",
      "        [-0.1482, -0.0795,  0.6213,  ..., -0.2288,  0.6586,  0.2792],\n",
      "        [-0.1482, -0.0795,  0.6213,  ..., -0.2288,  0.6586,  0.2792]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02427689 -0.12890105 -0.23330016  0.05041591 -0.25575197 -0.5997515\n",
      " -0.05499956 -0.46425495 -1.3920327  -0.2034794  -0.5278292  -1.689834\n",
      " -0.36082354 -0.63644856 -2.1787312  -0.17630404 -0.7503684  -1.568154\n",
      "  0.0312674  -0.800055   -1.3894624  -0.02745548 -0.7352603  -1.4405901\n",
      " -0.0392812  -0.8852812  -1.5623384  -0.12951793 -0.6517201  -1.4727159\n",
      " -0.05840421 -0.709054   -1.4481707  -0.07123144 -0.68086743 -1.5366472\n",
      "  0.05030645 -0.71570456 -1.5663023  -0.03719088 -0.54729474 -1.3047266\n",
      " -0.17826569 -0.31751803 -2.0090346  -0.0095171  -0.48833188 -2.018293\n",
      "  0.14717185 -0.44888955 -1.4269783  -0.15332676 -0.31485617 -1.2327458\n",
      " -0.07152645 -0.28947747 -1.3165748  -0.03418654 -0.30379087 -1.4302938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.05043546 -0.3138901  -1.2634795 ]\n",
      "data: [ 0.02427689 -0.12890105 -0.23330016  0.05041592 -0.25575197 -0.5997515\n",
      " -0.05499956 -0.46425495 -1.3920327  -0.20347938 -0.5278292  -1.689834\n",
      " -0.36082354 -0.63644856 -2.1787312  -0.17630404 -0.7503684  -1.568154\n",
      "  0.0312674  -0.800055   -1.3894622  -0.02745548 -0.7352603  -1.4405903\n",
      " -0.0392812  -0.8852812  -1.5623384  -0.12951793 -0.6517201  -1.4727159\n",
      " -0.05840421 -0.70905393 -1.4481707  -0.07123144 -0.68086743 -1.5366472\n",
      "  0.05030645 -0.71570456 -1.5663023  -0.03719088 -0.54729474 -1.3047266\n",
      " -0.17826569 -0.31751803 -2.0090346  -0.0095171  -0.48833188 -2.018293\n",
      "  0.14717185 -0.44888955 -1.4269783  -0.15332676 -0.31485617 -1.2327458\n",
      " -0.07152645 -0.28947747 -1.3165748  -0.03418654 -0.30379087 -1.4302937\n",
      "  0.05043546 -0.3138901  -1.2634795   0.14      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B320>\n",
      "tensor([[ 0.0047, -0.0582, -0.1682,  ...,  0.0550, -0.2652, -1.1383],\n",
      "        [ 0.0047, -0.0582, -0.1682,  ...,  0.0550, -0.2652, -1.1383],\n",
      "        [ 0.0047, -0.0582, -0.1682,  ...,  0.0550, -0.2652, -1.1383],\n",
      "        ...,\n",
      "        [-0.1300,  0.3811, -0.0782,  ..., -0.7473,  0.8879, -0.3621],\n",
      "        [-0.1147, -0.0984,  0.5744,  ..., -0.2114,  0.6161,  0.2342],\n",
      "        [-0.1147, -0.0984,  0.5744,  ..., -0.2114,  0.6161,  0.2342]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00467074 -0.05824932 -0.16823548  0.03244312 -0.15940401 -0.4577542\n",
      " -0.10889004 -0.38489923 -1.2973005  -0.26304132 -0.44937786 -1.5887655\n",
      " -0.41555896 -0.544113   -2.0940435  -0.18546492 -0.6953165  -1.4727848\n",
      " -0.01183288 -0.7622187  -1.3227125  -0.06573984 -0.6875198  -1.3753427\n",
      " -0.07038848 -0.8619718  -1.5002952  -0.13693927 -0.611469   -1.3705748\n",
      " -0.07957628 -0.6663232  -1.3453807  -0.088897   -0.63551855 -1.4297014\n",
      "  0.05241352 -0.67059875 -1.4438608  -0.04987139 -0.5010489  -1.2075385\n",
      " -0.2084237  -0.2660105  -1.9895569  -0.01577709 -0.4458991  -2.014711\n",
      "  0.16259822 -0.4077248  -1.3079463  -0.16917169 -0.27696854 -1.1294652\n",
      " -0.09728935 -0.25038603 -1.2205652  -0.06363641 -0.25217724 -1.3351808\n",
      "  0.05504156 -0.26521784 -1.1382703 ]\n",
      "data: [ 0.00467074 -0.05824932 -0.16823548  0.03244312 -0.15940401 -0.45775422\n",
      " -0.10889003 -0.38489923 -1.2973005  -0.26304132 -0.44937786 -1.5887656\n",
      " -0.41555896 -0.544113   -2.0940435  -0.18546492 -0.6953165  -1.4727848\n",
      " -0.01183288 -0.7622187  -1.3227125  -0.06573984 -0.6875198  -1.3753427\n",
      " -0.07038848 -0.8619718  -1.5002952  -0.13693927 -0.611469   -1.3705748\n",
      " -0.07957628 -0.6663232  -1.3453807  -0.088897   -0.63551855 -1.4297013\n",
      "  0.05241352 -0.67059875 -1.4438608  -0.04987139 -0.5010489  -1.2075385\n",
      " -0.2084237  -0.2660105  -1.9895569  -0.01577709 -0.4458991  -2.014711\n",
      "  0.16259822 -0.4077248  -1.3079463  -0.16917169 -0.27696854 -1.1294652\n",
      " -0.09728935 -0.25038603 -1.2205652  -0.06363641 -0.25217724 -1.3351808\n",
      "  0.05504156 -0.26521784 -1.1382703   0.15      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0496,  0.0045, -0.2231,  ..., -0.0126, -0.1837, -1.2162],\n",
      "        [-0.0496,  0.0045, -0.2231,  ..., -0.0126, -0.1837, -1.2162],\n",
      "        [-0.0496,  0.0045, -0.2231,  ..., -0.0126, -0.1837, -1.2162],\n",
      "        ...,\n",
      "        [-0.2457,  0.2513, -0.0744,  ..., -0.7079,  0.7748, -0.4215],\n",
      "        [-0.1491, -0.1435,  0.5753,  ..., -0.2854,  0.6031,  0.2287],\n",
      "        [-0.1491, -0.1435,  0.5753,  ..., -0.2854,  0.6031,  0.2287]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.0495871   0.00448659 -0.22309656 -0.02267651 -0.09959212 -0.54806334\n",
      " -0.16150579 -0.31235093 -1.3680685  -0.31676978 -0.37405652 -1.6627808\n",
      " -0.4723761  -0.4645929  -2.1670713  -0.24290851 -0.6272291  -1.5287712\n",
      " -0.07081962 -0.6822207  -1.3692124  -0.11812639 -0.6034342  -1.4284458\n",
      " -0.12118003 -0.7711762  -1.5569642  -0.20011598 -0.54212487 -1.4307525\n",
      " -0.13968012 -0.59062207 -1.4061675  -0.148787   -0.5550474  -1.4977047\n",
      "  0.00589196 -0.58195555 -1.5198276  -0.11757011 -0.4351055  -1.2646568\n",
      " -0.26311842 -0.19478905 -2.0165138  -0.07793228 -0.3611014  -2.0422518\n",
      "  0.10904071 -0.32695755 -1.3820479  -0.23209807 -0.20657802 -1.1873648\n",
      " -0.16737187 -0.17426519 -1.2818189  -0.13163155 -0.17064185 -1.4013839\n",
      " -0.01258951 -0.18368833 -1.2162416 ]\n",
      "data: [-0.0495871   0.00448659 -0.22309656 -0.02267651 -0.09959212 -0.54806334\n",
      " -0.16150579 -0.31235093 -1.3680683  -0.31676978 -0.37405652 -1.6627808\n",
      " -0.4723761  -0.4645929  -2.1670713  -0.24290852 -0.6272291  -1.5287712\n",
      " -0.07081962 -0.6822207  -1.3692124  -0.11812639 -0.6034342  -1.4284457\n",
      " -0.12118003 -0.7711762  -1.5569642  -0.20011598 -0.54212487 -1.4307525\n",
      " -0.13968012 -0.59062207 -1.4061675  -0.148787   -0.5550474  -1.4977047\n",
      "  0.00589196 -0.58195555 -1.5198276  -0.11757012 -0.4351055  -1.2646568\n",
      " -0.26311842 -0.19478905 -2.0165138  -0.07793228 -0.3611014  -2.0422518\n",
      "  0.10904071 -0.32695755 -1.3820479  -0.23209806 -0.20657803 -1.1873648\n",
      " -0.16737187 -0.17426519 -1.2818189  -0.13163155 -0.17064185 -1.4013839\n",
      " -0.01258951 -0.18368834 -1.2162416   0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE3F7CB748>\n",
      "tensor([[-0.0043, -0.0683, -0.1819,  ...,  0.0162, -0.2300, -1.2941],\n",
      "        [-0.0043, -0.0683, -0.1819,  ...,  0.0162, -0.2300, -1.2941],\n",
      "        [-0.0043, -0.0683, -0.1819,  ...,  0.0162, -0.2300, -1.2941],\n",
      "        ...,\n",
      "        [-0.3047,  0.3145, -0.2465,  ..., -0.8749,  0.7802, -0.4090],\n",
      "        [-0.2059, -0.1405,  0.4908,  ..., -0.3015,  0.6035,  0.2136],\n",
      "        [-0.2059, -0.1405,  0.4908,  ..., -0.3015,  0.6035,  0.2136]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.00425075 -0.06827411 -0.18191223  0.01145569 -0.22958902 -0.66002285\n",
      " -0.02131804 -0.36148655 -1.3116678  -0.15681928 -0.40838563 -1.6188737\n",
      " -0.33411425 -0.5442049  -2.0772622  -0.22373898 -0.6377865  -1.4655137\n",
      "  0.05476469 -0.6263805  -1.2459987   0.00360407 -0.5712447  -1.2999877\n",
      "  0.00219002 -0.6597017  -1.413767   -0.18125483 -0.5241825  -1.396422\n",
      " -0.06105165 -0.5737306  -1.3939627  -0.06379698 -0.53962886 -1.5008007\n",
      "  0.05417895 -0.56198907 -1.5752044  -0.07360434 -0.45737398 -1.2215886\n",
      " -0.14400879 -0.2298096  -1.7272241  -0.01725886 -0.36438298 -1.7017258\n",
      "  0.11812644 -0.33374548 -1.4363018  -0.17099471 -0.21588233 -1.1763806\n",
      " -0.0680842  -0.19705112 -1.2551256  -0.01609603 -0.22569506 -1.377861\n",
      "  0.01620423 -0.23000765 -1.2940712 ]\n",
      "data: [-0.00425075 -0.06827411 -0.18191223  0.01145569 -0.22958903 -0.6600229\n",
      " -0.02131804 -0.36148655 -1.3116678  -0.15681928 -0.40838563 -1.6188737\n",
      " -0.33411425 -0.5442049  -2.0772622  -0.22373897 -0.6377865  -1.4655137\n",
      "  0.05476469 -0.6263805  -1.2459987   0.00360407 -0.5712447  -1.2999877\n",
      "  0.00219002 -0.6597017  -1.413767   -0.18125482 -0.5241825  -1.3964219\n",
      " -0.06105165 -0.5737306  -1.3939627  -0.06379698 -0.53962886 -1.5008007\n",
      "  0.05417895 -0.56198907 -1.5752044  -0.07360434 -0.45737398 -1.2215886\n",
      " -0.14400879 -0.22980958 -1.7272241  -0.01725886 -0.36438298 -1.7017257\n",
      "  0.11812644 -0.3337455  -1.4363018  -0.17099471 -0.21588235 -1.1763806\n",
      " -0.0680842  -0.19705112 -1.2551256  -0.01609603 -0.22569506 -1.377861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.01620423 -0.23000765 -1.2940712   0.17      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0642, -0.1468, -0.2848,  ...,  0.0758, -0.3092, -1.3775],\n",
      "        [ 0.0642, -0.1468, -0.2848,  ...,  0.0758, -0.3092, -1.3775],\n",
      "        [ 0.0642, -0.1468, -0.2848,  ...,  0.0758, -0.3092, -1.3775],\n",
      "        ...,\n",
      "        [-0.1901,  0.4387, -0.2080,  ..., -0.7441,  0.9434, -0.4829],\n",
      "        [-0.2027, -0.0488,  0.6123,  ..., -0.3025,  0.7328,  0.2529],\n",
      "        [-0.2027, -0.0488,  0.6123,  ..., -0.3025,  0.7328,  0.2529]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.06416836 -0.14681393 -0.2848436   0.09127432 -0.29505175 -0.73736286\n",
      "  0.01738735 -0.4784925  -1.4887955  -0.12270817 -0.5379342  -1.7915292\n",
      " -0.28731698 -0.6572372  -2.2672317  -0.14705543 -0.7418604  -1.6585703\n",
      "  0.09903643 -0.76503634 -1.4423561   0.04919234 -0.70946527 -1.4918876\n",
      "  0.0363692  -0.8302052  -1.6126494  -0.10511819 -0.629302   -1.5702682\n",
      " -0.01137659 -0.6885148  -1.5466177  -0.016298   -0.6593617  -1.639828\n",
      "  0.10754271 -0.692413   -1.6987777  -0.00995976 -0.5412791  -1.3938017\n",
      " -0.12659587 -0.3097164  -2.0181835   0.03058949 -0.4703537  -2.0102777\n",
      "  0.17867847 -0.42991552 -1.5448072  -0.12137131 -0.30003905 -1.3246636\n",
      " -0.03117459 -0.27262348 -1.3920441   0.02078082 -0.2983066  -1.5099084\n",
      "  0.0758188  -0.30920547 -1.3774786 ]\n",
      "data: [ 0.06416836 -0.14681393 -0.2848436   0.09127432 -0.29505175 -0.7373628\n",
      "  0.01738735 -0.4784925  -1.4887955  -0.12270817 -0.5379342  -1.7915292\n",
      " -0.28731698 -0.6572372  -2.2672317  -0.14705543 -0.74186033 -1.6585703\n",
      "  0.09903643 -0.76503634 -1.4423561   0.04919234 -0.70946527 -1.4918876\n",
      "  0.0363692  -0.8302052  -1.6126494  -0.10511819 -0.629302   -1.5702682\n",
      " -0.01137659 -0.6885149  -1.5466177  -0.016298   -0.6593617  -1.6398281\n",
      "  0.10754271 -0.692413   -1.6987777  -0.00995976 -0.5412791  -1.3938017\n",
      " -0.12659587 -0.3097164  -2.0181835   0.03058949 -0.4703537  -2.0102777\n",
      "  0.17867847 -0.42991552 -1.5448071  -0.12137131 -0.30003905 -1.3246636\n",
      " -0.03117459 -0.27262348 -1.3920441   0.02078082 -0.2983066  -1.5099084\n",
      "  0.0758188  -0.30920547 -1.3774786   0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B320>\n",
      "tensor([[ 0.0074, -0.1640, -0.2135,  ...,  0.0549, -0.3425, -1.3143],\n",
      "        [ 0.0074, -0.1640, -0.2135,  ...,  0.0549, -0.3425, -1.3143],\n",
      "        [ 0.0074, -0.1640, -0.2135,  ...,  0.0549, -0.3425, -1.3143],\n",
      "        ...,\n",
      "        [-0.0643,  0.5208, -0.1636,  ..., -0.6733,  1.0123, -0.4360],\n",
      "        [-0.1427, -0.0194,  0.5736,  ..., -0.1851,  0.7073,  0.2552],\n",
      "        [-0.1427, -0.0194,  0.5736,  ..., -0.1851,  0.7073,  0.2552]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00735428 -0.16402072 -0.2135495   0.02024836 -0.33183777 -0.6705135\n",
      " -0.00380145 -0.4965831  -1.3726444  -0.14436716 -0.5525738  -1.7020805\n",
      " -0.3341369  -0.7082846  -2.1510863  -0.2185978  -0.74541354 -1.5682912\n",
      "  0.09527654 -0.7560682  -1.3349245   0.02991764 -0.7134906  -1.3787405\n",
      "  0.02863005 -0.8166816  -1.4965312  -0.159919   -0.61898875 -1.4733269\n",
      " -0.03655154 -0.69028354 -1.4616647  -0.03200354 -0.6726837  -1.5727983\n",
      "  0.07299506 -0.71318054 -1.6467178  -0.03631201 -0.5412426  -1.2802684\n",
      " -0.13809314 -0.32197282 -1.8548965   0.00865433 -0.48780444 -1.8230631\n",
      "  0.15189725 -0.44902244 -1.475992   -0.15593603 -0.2919721  -1.2242451\n",
      " -0.02730737 -0.2833207  -1.2926154   0.02984691 -0.3377968  -1.4077077\n",
      "  0.05489318 -0.34251636 -1.3142579 ]\n",
      "data: [ 0.00735428 -0.16402072 -0.2135495   0.02024836 -0.33183777 -0.6705135\n",
      " -0.00380145 -0.4965831  -1.3726443  -0.14436716 -0.5525738  -1.7020805\n",
      " -0.33413687 -0.7082846  -2.1510863  -0.2185978  -0.74541354 -1.5682912\n",
      "  0.09527655 -0.7560683  -1.3349245   0.02991764 -0.7134906  -1.3787405\n",
      "  0.02863005 -0.8166816  -1.4965312  -0.159919   -0.61898875 -1.4733269\n",
      " -0.03655154 -0.69028354 -1.4616647  -0.03200354 -0.6726837  -1.5727983\n",
      "  0.07299506 -0.71318054 -1.6467178  -0.03631201 -0.5412426  -1.2802684\n",
      " -0.13809314 -0.32197282 -1.8548965   0.00865433 -0.48780444 -1.8230633\n",
      "  0.15189725 -0.44902244 -1.475992   -0.15593603 -0.2919721  -1.2242451\n",
      " -0.02730737 -0.2833207  -1.2926154   0.02984691 -0.3377968  -1.4077077\n",
      "  0.05489318 -0.34251636 -1.3142579   0.19      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63F28>\n",
      "tensor([[ 0.0091, -0.1527, -0.1946,  ...,  0.0351, -0.3425, -1.2168],\n",
      "        [ 0.0091, -0.1527, -0.1946,  ...,  0.0351, -0.3425, -1.2168],\n",
      "        [ 0.0091, -0.1527, -0.1946,  ...,  0.0351, -0.3425, -1.2168],\n",
      "        ...,\n",
      "        [-0.0696,  0.5315, -0.2011,  ..., -0.5020,  1.0436, -0.5612],\n",
      "        [-0.1828, -0.0412,  0.6403,  ..., -0.2532,  0.6519,  0.3182],\n",
      "        [-0.1828, -0.0412,  0.6403,  ..., -0.2532,  0.6519,  0.3182]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00911995 -0.15265527 -0.19460428  0.04620134 -0.2589829  -0.4942161\n",
      " -0.08183834 -0.4938789  -1.3516958  -0.2366756  -0.55946666 -1.6452239\n",
      " -0.38301307 -0.65735066 -2.1606715  -0.18772797 -0.7862226  -1.554711\n",
      "  0.00710195 -0.8584204  -1.4066525  -0.05062753 -0.78851783 -1.4474618\n",
      " -0.06375277 -0.95524824 -1.5689924  -0.13744152 -0.696272   -1.4473598\n",
      " -0.07556804 -0.75743365 -1.4219145  -0.08227291 -0.7238511  -1.5034374\n",
      "  0.04056521 -0.76916516 -1.5247978  -0.04537239 -0.58067584 -1.2860215\n",
      " -0.21247019 -0.34233636 -2.0511494  -0.02126995 -0.530928   -2.070496\n",
      "  0.14108916 -0.48149422 -1.392725   -0.17953865 -0.34996146 -1.205181\n",
      " -0.09655085 -0.31890988 -1.2884816  -0.05979422 -0.335254   -1.3980908\n",
      "  0.03514617 -0.3424698  -1.2168479 ]\n",
      "data: [ 0.00911995 -0.15265527 -0.19460428  0.04620134 -0.2589829  -0.4942161\n",
      " -0.08183834 -0.4938789  -1.3516957  -0.2366756  -0.55946666 -1.6452239\n",
      " -0.38301307 -0.6573507  -2.1606715  -0.18772797 -0.78622264 -1.554711\n",
      "  0.00710195 -0.85842043 -1.4066526  -0.05062753 -0.78851783 -1.4474618\n",
      " -0.06375277 -0.95524824 -1.5689923  -0.13744152 -0.6962721  -1.4473598\n",
      " -0.07556804 -0.75743365 -1.4219146  -0.08227291 -0.7238511  -1.5034374\n",
      "  0.04056521 -0.7691652  -1.5247978  -0.04537239 -0.58067584 -1.2860215\n",
      " -0.21247019 -0.34233636 -2.0511494  -0.02126995 -0.530928   -2.070496\n",
      "  0.14108916 -0.48149422 -1.3927249  -0.17953865 -0.34996146 -1.205181\n",
      " -0.09655085 -0.31890988 -1.2884816  -0.05979422 -0.335254   -1.3980908\n",
      "  0.03514617 -0.3424698  -1.2168479   0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[-0.0320, -0.0462, -0.1655,  ...,  0.0282, -0.2286, -1.1556],\n",
      "        [-0.0320, -0.0462, -0.1655,  ...,  0.0282, -0.2286, -1.1556],\n",
      "        [-0.0320, -0.0462, -0.1655,  ...,  0.0282, -0.2286, -1.1556],\n",
      "        ...,\n",
      "        [-0.1615,  0.3749, -0.0236,  ..., -0.6656,  0.9769, -0.4341],\n",
      "        [-0.0846, -0.0464,  0.6165,  ..., -0.2230,  0.5829,  0.3009],\n",
      "        [-0.0846, -0.0464,  0.6165,  ..., -0.2230,  0.5829,  0.3009]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.03195643 -0.04616985 -0.16553353 -0.00548091 -0.17830686 -0.4614609\n",
      " -0.09514644 -0.3881455  -1.2892185  -0.2458411  -0.44586146 -1.6016953\n",
      " -0.4198748  -0.57749254 -2.0865743  -0.25223494 -0.6599276  -1.4932947\n",
      "  0.02622269 -0.69749695 -1.2794704  -0.0310818  -0.646985   -1.3151624\n",
      " -0.02310181 -0.77594507 -1.4458158  -0.19407053 -0.5453484  -1.3839324\n",
      " -0.08833589 -0.6134152  -1.365938   -0.06423844 -0.58178353 -1.4625653\n",
      "  0.07515085 -0.6357409  -1.5161486  -0.07562169 -0.44411254 -1.1961092\n",
      " -0.22688557 -0.2086216  -1.9229709  -0.02241375 -0.39702415 -1.9176915\n",
      "  0.16285397 -0.34739614 -1.3461851  -0.21655343 -0.19781044 -1.1239699\n",
      " -0.09551556 -0.17932959 -1.1878587  -0.0440678  -0.21788917 -1.3047996\n",
      "  0.02817776 -0.2286346  -1.1556356 ]\n",
      "data: [-3.16 -2.93  2.66 -3.11 -2.72  2.77 -2.95 -2.38  2.85  0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.   -2.34 -1.12 -0.85 -2.4  -1.02 -1.03\n",
      " -2.37 -0.99 -1.03 -2.47 -1.34 -1.13 -2.43 -1.12 -0.98 -2.41 -0.96 -1.18\n",
      " -2.41 -0.96 -1.18  0.    0.    0.   -2.47 -1.2  -1.37 -2.54 -1.02 -1.35\n",
      " -2.54 -0.99 -1.33  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.  ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 8.8766e-03,  7.7521e-04, -2.3262e-01,  ..., -3.0538e-01,\n",
      "         -3.4998e-01, -5.1276e-01],\n",
      "        [ 8.8766e-03,  7.7521e-04, -2.3262e-01,  ..., -3.0538e-01,\n",
      "         -3.4998e-01, -5.1276e-01],\n",
      "        [ 8.8766e-03,  7.7521e-04, -2.3262e-01,  ..., -3.0538e-01,\n",
      "         -3.4998e-01, -5.1276e-01],\n",
      "        ...,\n",
      "        [ 5.1506e-01, -4.6867e-01,  1.1016e+00,  ...,  3.6564e-01,\n",
      "          4.9817e-01, -9.1111e-01],\n",
      "        [ 5.9471e-02, -6.3189e-02,  3.3095e-01,  ..., -1.3849e+00,\n",
      "          6.3809e-01,  5.9951e-01],\n",
      "        [ 5.9471e-02, -6.3189e-02,  3.3095e-01,  ..., -1.3849e+00,\n",
      "          6.3809e-01,  5.9951e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 8.8765966e-03  7.7521172e-04 -2.3261684e-01 -9.0008870e-02\n",
      " -3.5260800e-02 -6.7060184e-01 -1.9911118e-01 -9.0095580e-02\n",
      " -7.6295483e-01 -2.9467058e-01 -1.4779471e-01 -7.5236523e-01\n",
      " -3.7677985e-01 -1.6892728e-01 -8.1193662e-01 -2.1125537e-01\n",
      " -2.5987664e-01 -8.5720074e-01 -2.9001796e-01 -3.1656870e-01\n",
      " -7.8852761e-01 -3.2256591e-01 -4.0920687e-01 -7.6753235e-01\n",
      " -3.7342548e-01 -4.4756553e-01 -7.7898383e-01 -2.1634714e-01\n",
      " -2.6326215e-01 -8.4559286e-01 -3.1559068e-01 -3.5860035e-01\n",
      " -8.0662584e-01 -3.3433944e-01 -3.9453217e-01 -7.6993024e-01\n",
      " -3.1774259e-01 -5.0905466e-01 -7.3932731e-01 -2.3580471e-01\n",
      " -2.3593092e-01 -8.0604839e-01 -3.4425545e-01 -3.0589899e-01\n",
      " -7.0810783e-01 -3.2735094e-01 -3.8163996e-01 -7.1091843e-01\n",
      " -3.2069468e-01 -4.3256408e-01 -6.4201987e-01 -2.5176859e-01\n",
      " -1.9215618e-01 -6.7616713e-01 -3.1743598e-01 -2.4791208e-01\n",
      " -5.9753096e-01 -3.3176816e-01 -2.8917691e-01 -6.0351539e-01\n",
      " -3.0537799e-01 -3.4998184e-01 -5.1275754e-01]\n",
      "init: [ 8.8765966e-03  7.7521172e-04 -2.3261684e-01 -9.0008870e-02\n",
      " -3.5260800e-02 -6.7060184e-01 -1.9911118e-01 -9.0095580e-02\n",
      " -7.6295483e-01 -2.9467058e-01 -1.4779471e-01 -7.5236523e-01\n",
      " -3.7677985e-01 -1.6892728e-01 -8.1193662e-01 -2.1125537e-01\n",
      " -2.5987664e-01 -8.5720074e-01 -2.9001796e-01 -3.1656870e-01\n",
      " -7.8852761e-01 -3.2256591e-01 -4.0920687e-01 -7.6753235e-01\n",
      " -3.7342548e-01 -4.4756553e-01 -7.7898383e-01 -2.1634714e-01\n",
      " -2.6326215e-01 -8.4559286e-01 -3.1559068e-01 -3.5860035e-01\n",
      " -8.0662584e-01 -3.3433944e-01 -3.9453217e-01 -7.6993024e-01\n",
      " -3.1774259e-01 -5.0905466e-01 -7.3932731e-01 -2.3580471e-01\n",
      " -2.3593092e-01 -8.0604839e-01 -3.4425545e-01 -3.0589899e-01\n",
      " -7.0810783e-01 -3.2735094e-01 -3.8163996e-01 -7.1091843e-01\n",
      " -3.2069468e-01 -4.3256408e-01 -6.4201987e-01 -2.5176859e-01\n",
      " -1.9215618e-01 -6.7616713e-01 -3.1743598e-01 -2.4791208e-01\n",
      " -5.9753096e-01 -3.3176816e-01 -2.8917691e-01 -6.0351539e-01\n",
      " -3.0537799e-01 -3.4998184e-01 -5.1275754e-01]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [ 8.8765966e-03  7.7521172e-04 -2.3261684e-01 -9.0008870e-02\n",
      " -3.5260800e-02 -6.7060179e-01 -1.9911118e-01 -9.0095580e-02\n",
      " -7.6295489e-01 -2.9467058e-01 -1.4779471e-01 -7.5236529e-01\n",
      " -3.7677985e-01 -1.6892728e-01 -8.1193662e-01 -2.1125537e-01\n",
      " -2.5987664e-01 -8.5720080e-01 -2.9001796e-01 -3.1656870e-01\n",
      " -7.8852761e-01 -3.2256591e-01 -4.0920684e-01 -7.6753235e-01\n",
      " -3.7342548e-01 -4.4756553e-01 -7.7898383e-01 -2.1634714e-01\n",
      " -2.6326215e-01 -8.4559286e-01 -3.1559068e-01 -3.5860035e-01\n",
      " -8.0662584e-01 -3.3433944e-01 -3.9453217e-01 -7.6993024e-01\n",
      " -3.1774259e-01 -5.0905466e-01 -7.3932731e-01 -2.3580471e-01\n",
      " -2.3593092e-01 -8.0604845e-01 -3.4425545e-01 -3.0589899e-01\n",
      " -7.0810783e-01 -3.2735097e-01 -3.8163993e-01 -7.1091843e-01\n",
      " -3.2069468e-01 -4.3256408e-01 -6.4201987e-01 -2.5176859e-01\n",
      " -1.9215618e-01 -6.7616713e-01 -3.1743598e-01 -2.4791208e-01\n",
      " -5.9753096e-01 -3.3176816e-01 -2.8917691e-01 -6.0351539e-01\n",
      " -3.0537799e-01 -3.4998184e-01 -5.1275754e-01  9.9999998e-03]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BB38>\n",
      "tensor([[ 0.2565, -0.1653,  0.0619,  ...,  0.3460, -0.3228, -0.9771],\n",
      "        [ 0.2565, -0.1653,  0.0619,  ...,  0.3460, -0.3228, -0.9771],\n",
      "        [ 0.2565, -0.1653,  0.0619,  ...,  0.3460, -0.3228, -0.9771],\n",
      "        ...,\n",
      "        [-0.2043, -0.0798, -0.1112,  ..., -1.2513,  0.7190, -0.4925],\n",
      "        [-0.4337,  0.3037, -0.0345,  ..., -0.9720,  1.0205, -0.2868],\n",
      "        [-0.4337,  0.3037, -0.0345,  ..., -0.9720,  1.0205, -0.2868]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.25653934 -0.16527198  0.06187012  0.28650266 -0.31047314 -0.33754987\n",
      "  0.23528197 -0.46471494 -1.053416    0.09572317 -0.5028829  -1.3683327\n",
      " -0.06291848 -0.64231503 -1.8531039   0.03117532 -0.726853   -1.2478509\n",
      "  0.33241624 -0.71730125 -1.0593773   0.2803405  -0.6629752  -1.0964617\n",
      "  0.2854924  -0.7714131  -1.2177808   0.09075134 -0.6089933  -1.1583282\n",
      "  0.22459769 -0.66388535 -1.1534357   0.24657148 -0.6233009  -1.2400773\n",
      "  0.3710913  -0.6864811  -1.3209887   0.2284773  -0.5289115  -0.97290796\n",
      "  0.11266309 -0.27025694 -1.5996144   0.3003994  -0.459152   -1.5728395\n",
      "  0.44843358 -0.39967397 -1.1645628   0.10238601 -0.28966057 -0.9093513\n",
      "  0.24283816 -0.25737637 -0.9548083   0.30494884 -0.3049412  -1.0884054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.34596658 -0.32275409 -0.9770704 ]\n",
      "data: [ 0.25653934 -0.16527198  0.06187012  0.28650266 -0.31047314 -0.33754987\n",
      "  0.23528199 -0.4647149  -1.053416    0.09572317 -0.5028829  -1.3683326\n",
      " -0.06291848 -0.6423151  -1.853104    0.03117532 -0.726853   -1.2478509\n",
      "  0.33241624 -0.71730125 -1.0593773   0.2803405  -0.66297513 -1.0964617\n",
      "  0.2854924  -0.7714131  -1.2177808   0.09075134 -0.6089933  -1.1583282\n",
      "  0.2245977  -0.66388535 -1.1534357   0.24657148 -0.6233009  -1.2400773\n",
      "  0.3710913  -0.6864811  -1.3209887   0.2284773  -0.5289115  -0.97290796\n",
      "  0.11266309 -0.27025694 -1.5996144   0.3003994  -0.45915204 -1.5728395\n",
      "  0.44843358 -0.39967397 -1.1645628   0.10238602 -0.28966057 -0.9093513\n",
      "  0.24283816 -0.25737637 -0.9548083   0.30494884 -0.3049412  -1.0884054\n",
      "  0.34596658 -0.32275409 -0.9770704   0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0858, -0.0379, -0.1032,  ..., -0.0047, -0.2544, -1.2068],\n",
      "        [ 0.0858, -0.0379, -0.1032,  ..., -0.0047, -0.2544, -1.2068],\n",
      "        [ 0.0858, -0.0379, -0.1032,  ..., -0.0047, -0.2544, -1.2068],\n",
      "        ...,\n",
      "        [-0.3288,  0.2455, -0.0844,  ..., -0.8282,  0.8416, -0.6565],\n",
      "        [-0.1093,  0.0893,  0.3410,  ...,  0.3546,  0.8067,  0.0037],\n",
      "        [-0.1093,  0.0893,  0.3410,  ...,  0.3546,  0.8067,  0.0037]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.08579506 -0.0379421  -0.1032365   0.02253027 -0.22140418 -0.61245143\n",
      " -0.07017726 -0.41160282 -1.3064108  -0.23742421 -0.4898873  -1.6096717\n",
      " -0.4944898  -0.601745   -2.0641756  -0.18030061 -0.6453427  -1.5076917\n",
      " -0.08497573 -0.71022236 -1.403039   -0.12487441 -0.624002   -1.4606444\n",
      " -0.06842096 -0.79532075 -1.526402   -0.14321701 -0.5114523  -1.4217496\n",
      " -0.10977936 -0.5732943  -1.3357794  -0.14579345 -0.61462283 -1.453882\n",
      " -0.011227   -0.5606911  -1.4829737  -0.08263461 -0.4637096  -1.2776452\n",
      " -0.17403881 -0.29198587 -1.785383   -0.08775978 -0.42329374 -1.775744\n",
      "  0.05542279 -0.4111142  -1.3202158  -0.14013897 -0.22652973 -1.2139158\n",
      " -0.13122518 -0.24074309 -1.2728609  -0.08975354 -0.24573481 -1.3690485\n",
      " -0.00474979 -0.25439793 -1.2068065 ]\n",
      "data: [ 0.08579506 -0.0379421  -0.1032365   0.02253027 -0.22140417 -0.61245143\n",
      " -0.07017726 -0.41160282 -1.3064108  -0.2374242  -0.48988733 -1.6096718\n",
      " -0.4944898  -0.601745   -2.0641756  -0.18030062 -0.6453427  -1.5076919\n",
      " -0.08497574 -0.7102224  -1.403039   -0.12487441 -0.624002   -1.4606444\n",
      " -0.06842096 -0.79532075 -1.526402   -0.14321701 -0.5114523  -1.4217496\n",
      " -0.10977936 -0.5732943  -1.3357794  -0.14579345 -0.61462283 -1.453882\n",
      " -0.011227   -0.5606911  -1.4829736  -0.08263461 -0.4637096  -1.2776452\n",
      " -0.17403881 -0.29198587 -1.785383   -0.08775978 -0.4232937  -1.775744\n",
      "  0.05542279 -0.4111142  -1.3202157  -0.14013897 -0.22652973 -1.2139158\n",
      " -0.13122518 -0.24074309 -1.2728609  -0.08975354 -0.24573481 -1.3690485\n",
      " -0.00474979 -0.25439793 -1.2068065   0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0518, -0.0347, -0.2597,  ...,  0.0969, -0.2282, -1.3006],\n",
      "        [ 0.0518, -0.0347, -0.2597,  ...,  0.0969, -0.2282, -1.3006],\n",
      "        [ 0.0518, -0.0347, -0.2597,  ...,  0.0969, -0.2282, -1.3006],\n",
      "        ...,\n",
      "        [-0.2225,  0.3641, -0.0336,  ..., -0.9048,  0.8922, -0.2522],\n",
      "        [-0.1117, -0.1334,  0.5945,  ..., -0.2216,  0.6309,  0.3238],\n",
      "        [-0.1117, -0.1334,  0.5945,  ..., -0.2216,  0.6309,  0.3238]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0517824  -0.03472922 -0.25971124  0.0681355  -0.16965756 -0.6638105\n",
      " -0.03307278 -0.34102085 -1.4007678  -0.17917459 -0.40053084 -1.6898875\n",
      " -0.3462881  -0.5074003  -2.1687233  -0.14591628 -0.6400659  -1.5621727\n",
      "  0.04537889 -0.66618    -1.4019201   0.00408043 -0.59203553 -1.4619579\n",
      "  0.02245484 -0.7269622  -1.5743434  -0.10501273 -0.5409882  -1.4862742\n",
      " -0.02098165 -0.588884   -1.4559152  -0.029376   -0.56238806 -1.5495522\n",
      "  0.12112708 -0.5748155  -1.5904188  -0.01998592 -0.46438614 -1.3164742\n",
      " -0.11711022 -0.23264915 -1.9317942   0.033484   -0.3797005  -1.9341836\n",
      "  0.20495218 -0.35373524 -1.4526155  -0.11419681 -0.22992721 -1.2543633\n",
      " -0.04306123 -0.20703566 -1.3368251   0.00421278 -0.211473   -1.4565957\n",
      "  0.09688578 -0.22815453 -1.30057   ]\n",
      "data: [ 0.0517824  -0.03472922 -0.25971124  0.0681355  -0.16965756 -0.6638105\n",
      " -0.03307278 -0.34102085 -1.4007678  -0.1791746  -0.40053084 -1.6898875\n",
      " -0.3462881  -0.5074003  -2.1687233  -0.14591628 -0.6400659  -1.5621727\n",
      "  0.04537889 -0.66618    -1.40192     0.00408043 -0.59203553 -1.461958\n",
      "  0.02245484 -0.7269622  -1.5743434  -0.10501273 -0.5409882  -1.4862742\n",
      " -0.02098165 -0.588884   -1.4559152  -0.029376   -0.56238806 -1.5495522\n",
      "  0.12112708 -0.5748155  -1.5904188  -0.01998592 -0.46438614 -1.3164742\n",
      " -0.11711022 -0.23264915 -1.9317942   0.033484   -0.3797005  -1.9341836\n",
      "  0.20495218 -0.35373524 -1.4526155  -0.11419681 -0.22992721 -1.2543633\n",
      " -0.04306123 -0.20703566 -1.3368251   0.00421278 -0.211473   -1.4565957\n",
      "  0.09688578 -0.22815453 -1.30057     0.04      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0052, -0.1234, -0.2770,  ...,  0.0478, -0.2990, -1.3706],\n",
      "        [ 0.0052, -0.1234, -0.2770,  ...,  0.0478, -0.2990, -1.3706],\n",
      "        [ 0.0052, -0.1234, -0.2770,  ...,  0.0478, -0.2990, -1.3706],\n",
      "        ...,\n",
      "        [-0.1338,  0.4304, -0.0416,  ..., -0.7269,  0.9185, -0.2566],\n",
      "        [-0.1942, -0.0689,  0.5782,  ..., -0.2751,  0.7127,  0.2486],\n",
      "        [-0.1942, -0.0689,  0.5782,  ..., -0.2751,  0.7127,  0.2486]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 5.2226596e-03 -1.2336556e-01 -2.7701223e-01  2.3266774e-02\n",
      " -2.8366584e-01 -7.2994715e-01 -2.2571579e-02 -4.4067159e-01\n",
      " -1.4347417e+00 -1.6054907e-01 -4.9550840e-01 -1.7436517e+00\n",
      " -3.3475685e-01 -6.3250101e-01 -2.2059233e+00 -2.0769742e-01\n",
      " -7.0679826e-01 -1.6084456e+00  6.7041606e-02 -7.1222383e-01\n",
      " -1.3911881e+00  1.3133481e-02 -6.5720153e-01 -1.4423772e+00\n",
      "  1.6149834e-02 -7.5815743e-01 -1.5578367e+00 -1.5990102e-01\n",
      " -5.8975106e-01 -1.5281191e+00 -4.5289598e-02 -6.4640552e-01\n",
      " -1.5131313e+00 -4.6079606e-02 -6.1962521e-01 -1.6143306e+00\n",
      "  7.2571233e-02 -6.4591026e-01 -1.6808692e+00 -5.1306196e-02\n",
      " -5.1691782e-01 -1.3459438e+00 -1.3848725e-01 -2.9052988e-01\n",
      " -1.8985372e+00  3.9944798e-04 -4.3995509e-01 -1.8755912e+00\n",
      "  1.4631200e-01 -4.0470213e-01 -1.5287153e+00 -1.5658112e-01\n",
      " -2.7348310e-01 -1.2916934e+00 -4.8708677e-02 -2.5655031e-01\n",
      " -1.3632152e+00  6.2177777e-03 -2.9062167e-01 -1.4800853e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4.7794603e-02 -2.9896283e-01 -1.3705552e+00]\n",
      "data: [ 5.2226596e-03 -1.2336555e-01 -2.7701223e-01  2.3266774e-02\n",
      " -2.8366584e-01 -7.2994715e-01 -2.2571579e-02 -4.4067156e-01\n",
      " -1.4347416e+00 -1.6054907e-01 -4.9550837e-01 -1.7436517e+00\n",
      " -3.3475685e-01 -6.3250101e-01 -2.2059233e+00 -2.0769744e-01\n",
      " -7.0679826e-01 -1.6084456e+00  6.7041606e-02 -7.1222383e-01\n",
      " -1.3911881e+00  1.3133480e-02 -6.5720153e-01 -1.4423772e+00\n",
      "  1.6149834e-02 -7.5815743e-01 -1.5578367e+00 -1.5990102e-01\n",
      " -5.8975106e-01 -1.5281191e+00 -4.5289598e-02 -6.4640546e-01\n",
      " -1.5131313e+00 -4.6079606e-02 -6.1962521e-01 -1.6143306e+00\n",
      "  7.2571233e-02 -6.4591026e-01 -1.6808693e+00 -5.1306196e-02\n",
      " -5.1691782e-01 -1.3459438e+00 -1.3848725e-01 -2.9052988e-01\n",
      " -1.8985372e+00  3.9944798e-04 -4.3995512e-01 -1.8755912e+00\n",
      "  1.4631200e-01 -4.0470210e-01 -1.5287153e+00 -1.5658112e-01\n",
      " -2.7348310e-01 -1.2916934e+00 -4.8708677e-02 -2.5655031e-01\n",
      " -1.3632152e+00  6.2177777e-03 -2.9062167e-01 -1.4800853e+00\n",
      "  4.7794603e-02 -2.9896283e-01 -1.3705552e+00  5.0000001e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0433, -0.2041, -0.2625,  ...,  0.0676, -0.3788, -1.3515],\n",
      "        [ 0.0433, -0.2041, -0.2625,  ...,  0.0676, -0.3788, -1.3515],\n",
      "        [ 0.0433, -0.2041, -0.2625,  ...,  0.0676, -0.3788, -1.3515],\n",
      "        ...,\n",
      "        [-0.1157,  0.5064, -0.1786,  ..., -0.6651,  0.9915, -0.4793],\n",
      "        [-0.1999, -0.0512,  0.6390,  ..., -0.2682,  0.6716,  0.3377],\n",
      "        [-0.1999, -0.0512,  0.6390,  ..., -0.2682,  0.6716,  0.3377]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04329524 -0.20413402 -0.26245952  0.07103048 -0.3417235  -0.65823394\n",
      "  0.00380342 -0.53469515 -1.43301    -0.14162475 -0.5929396  -1.7503157\n",
      " -0.3085353  -0.71895933 -2.2363605  -0.16851342 -0.8063271  -1.6350511\n",
      "  0.09764639 -0.8413929  -1.4260145   0.03432182 -0.7906076  -1.4703777\n",
      "  0.01951165 -0.9212488  -1.5948771  -0.11573466 -0.69711447 -1.534194\n",
      " -0.02146324 -0.7621429  -1.5213295  -0.02417239 -0.73686445 -1.623239\n",
      "  0.08553038 -0.78239036 -1.6768271  -0.01026887 -0.5992169  -1.3541965\n",
      " -0.14507529 -0.36993143 -2.0294406   0.02258748 -0.54452527 -2.0237203\n",
      "  0.17015085 -0.50222266 -1.5204716  -0.137065   -0.35838526 -1.2864399\n",
      " -0.03107586 -0.3376043  -1.3619076   0.01466004 -0.37310705 -1.4774283\n",
      "  0.06764819 -0.3788001  -1.3515046 ]\n",
      "data: [ 0.04329524 -0.20413403 -0.26245952  0.07103048 -0.34172353 -0.65823394\n",
      "  0.00380342 -0.53469515 -1.43301    -0.14162475 -0.5929396  -1.7503157\n",
      " -0.3085353  -0.71895933 -2.2363605  -0.16851342 -0.8063271  -1.6350511\n",
      "  0.09764639 -0.8413929  -1.4260145   0.03432182 -0.79060763 -1.4703777\n",
      "  0.01951165 -0.9212488  -1.5948771  -0.11573467 -0.69711447 -1.534194\n",
      " -0.02146324 -0.7621429  -1.5213295  -0.02417239 -0.73686445 -1.623239\n",
      "  0.08553038 -0.78239036 -1.6768271  -0.01026887 -0.5992169  -1.3541964\n",
      " -0.14507529 -0.3699314  -2.0294406   0.02258748 -0.54452527 -2.0237203\n",
      "  0.17015085 -0.50222266 -1.5204715  -0.137065   -0.35838526 -1.2864398\n",
      " -0.03107586 -0.33760434 -1.3619076   0.01466004 -0.37310705 -1.4774283\n",
      "  0.06764819 -0.3788001  -1.3515046   0.06      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0054, -0.1985, -0.1939,  ...,  0.0404, -0.3788, -1.2585],\n",
      "        [ 0.0054, -0.1985, -0.1939,  ...,  0.0404, -0.3788, -1.2585],\n",
      "        [ 0.0054, -0.1985, -0.1939,  ...,  0.0404, -0.3788, -1.2585],\n",
      "        ...,\n",
      "        [ 0.0202,  0.5715, -0.1782,  ..., -0.4463,  1.1368, -0.5949],\n",
      "        [-0.1106,  0.0464,  0.6118,  ..., -0.1301,  0.7031,  0.2968],\n",
      "        [-0.1106,  0.0464,  0.6118,  ..., -0.1301,  0.7031,  0.2968]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00543465 -0.19846447 -0.1938572   0.03333358 -0.33578634 -0.5502198\n",
      " -0.03337895 -0.53841454 -1.3533912  -0.18620448 -0.59737694 -1.6824579\n",
      " -0.36540234 -0.7326577  -2.173997   -0.21519852 -0.8046272  -1.5740511\n",
      "  0.072368   -0.84345555 -1.3558116   0.00452331 -0.7952374  -1.3950486\n",
      " -0.00891861 -0.92805004 -1.5228865  -0.15623489 -0.6913254  -1.4614627\n",
      " -0.05452806 -0.76359165 -1.4472442  -0.05066656 -0.73878133 -1.5544212\n",
      "  0.06152321 -0.79111266 -1.609205   -0.03892808 -0.58986324 -1.271714\n",
      " -0.18587214 -0.36016718 -1.9717777  -0.00586314 -0.54685044 -1.9622333\n",
      "  0.15205386 -0.50046504 -1.437259   -0.17801651 -0.34538233 -1.2030077\n",
      " -0.05903332 -0.329181   -1.2710631  -0.01186089 -0.37502062 -1.3858705\n",
      "  0.04042812 -0.37876135 -1.2585213 ]\n",
      "data: [ 0.00543465 -0.19846447 -0.1938572   0.03333358 -0.33578637 -0.5502198\n",
      " -0.03337895 -0.53841454 -1.3533912  -0.18620448 -0.59737694 -1.6824579\n",
      " -0.36540234 -0.7326577  -2.173997   -0.21519852 -0.8046272  -1.5740513\n",
      "  0.072368   -0.84345555 -1.3558116   0.00452331 -0.7952374  -1.3950486\n",
      " -0.00891861 -0.9280501  -1.5228865  -0.15623489 -0.6913254  -1.4614627\n",
      " -0.05452805 -0.7635916  -1.4472442  -0.05066656 -0.73878133 -1.5544212\n",
      "  0.06152321 -0.79111266 -1.609205   -0.03892808 -0.58986324 -1.271714\n",
      " -0.18587214 -0.36016715 -1.9717777  -0.00586314 -0.54685044 -1.9622333\n",
      "  0.15205386 -0.50046504 -1.437259   -0.17801651 -0.34538233 -1.2030077\n",
      " -0.05903332 -0.329181   -1.2710631  -0.01186089 -0.37502062 -1.3858705\n",
      "  0.04042812 -0.37876138 -1.2585213   0.07      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0478, -0.1555, -0.1780,  ...,  0.0383, -0.3342, -1.2024],\n",
      "        [ 0.0478, -0.1555, -0.1780,  ...,  0.0383, -0.3342, -1.2024],\n",
      "        [ 0.0478, -0.1555, -0.1780,  ...,  0.0383, -0.3342, -1.2024],\n",
      "        ...,\n",
      "        [-0.0826,  0.5301, -0.0904,  ..., -0.2568,  1.1351, -0.5496],\n",
      "        [-0.1291,  0.0340,  0.6380,  ..., -0.1836,  0.6904,  0.3219],\n",
      "        [-0.1291,  0.0340,  0.6380,  ..., -0.1836,  0.6904,  0.3219]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04781825 -0.15545261 -0.17802133  0.08191451 -0.2548343  -0.45621318\n",
      " -0.05794116 -0.496289   -1.3388393  -0.22046    -0.5617608  -1.6356962\n",
      " -0.36602318 -0.65115    -2.1740131  -0.15690072 -0.79809177 -1.5441828\n",
      "  0.02460244 -0.8720472  -1.3965042  -0.03508194 -0.79824317 -1.4408033\n",
      " -0.05332944 -0.9676118  -1.5690668  -0.11260685 -0.7107934  -1.4333568\n",
      " -0.06029251 -0.76436245 -1.4085374  -0.07038117 -0.72355425 -1.4931633\n",
      "  0.05544688 -0.765241   -1.5070021  -0.02381397 -0.585212   -1.2762544\n",
      " -0.19953614 -0.34526387 -2.0436082  -0.01033825 -0.52663255 -2.071302\n",
      "  0.1573712  -0.47782192 -1.3783937  -0.16288245 -0.35556772 -1.1939559\n",
      " -0.08819717 -0.3216725  -1.2777927  -0.06320298 -0.3297057  -1.3870676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.03829669 -0.3341728  -1.2023733 ]\n",
      "data: [ 0.04781825 -0.15545261 -0.17802134  0.08191451 -0.2548343  -0.45621318\n",
      " -0.05794116 -0.496289   -1.3388393  -0.22046    -0.5617608  -1.635696\n",
      " -0.36602318 -0.65115    -2.1740131  -0.15690072 -0.7980917  -1.5441828\n",
      "  0.02460244 -0.8720472  -1.3965042  -0.03508194 -0.79824317 -1.4408032\n",
      " -0.05332944 -0.9676118  -1.5690668  -0.11260685 -0.7107934  -1.4333568\n",
      " -0.06029251 -0.7643625  -1.4085374  -0.07038117 -0.72355425 -1.4931633\n",
      "  0.05544688 -0.765241   -1.5070021  -0.02381397 -0.585212   -1.2762544\n",
      " -0.19953614 -0.34526387 -2.0436082  -0.01033825 -0.52663255 -2.071302\n",
      "  0.1573712  -0.47782192 -1.3783937  -0.16288245 -0.35556775 -1.1939559\n",
      " -0.08819717 -0.32167253 -1.2777927  -0.06320298 -0.3297057  -1.3870676\n",
      "  0.03829669 -0.3341728  -1.2023733   0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B9B0>\n",
      "tensor([[-0.0224, -0.0785, -0.2056,  ...,  0.0359, -0.2609, -1.1964],\n",
      "        [-0.0224, -0.0785, -0.2056,  ...,  0.0359, -0.2609, -1.1964],\n",
      "        [-0.0224, -0.0785, -0.2056,  ...,  0.0359, -0.2609, -1.1964],\n",
      "        ...,\n",
      "        [-0.1489,  0.3956,  0.0445,  ..., -0.5832,  1.0048, -0.4153],\n",
      "        [-0.0818, -0.0158,  0.6127,  ..., -0.2063,  0.6407,  0.2541],\n",
      "        [-0.0818, -0.0158,  0.6127,  ..., -0.2063,  0.6407,  0.2541]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.02240093 -0.07845861 -0.20556557  0.0040775  -0.20517334 -0.51009905\n",
      " -0.09383052 -0.41861352 -1.337134   -0.24742793 -0.47813356 -1.6503026\n",
      " -0.4168078  -0.6049646  -2.1409616  -0.24022976 -0.69776046 -1.531985\n",
      "  0.02420233 -0.74021804 -1.3208232  -0.0354341  -0.6835954  -1.3612257\n",
      " -0.03611077 -0.82082653 -1.4940212  -0.18322252 -0.58990467 -1.4218538\n",
      " -0.08608832 -0.6546953  -1.4042122  -0.07057127 -0.6196805  -1.4997841\n",
      "  0.06721278 -0.6709335  -1.5448834  -0.0671292  -0.48371908 -1.2371918\n",
      " -0.21889366 -0.24640906 -1.9653771  -0.01976117 -0.43181047 -1.9655777\n",
      "  0.16510531 -0.38377658 -1.3825457  -0.20570382 -0.24086425 -1.1633123\n",
      " -0.09068494 -0.21903622 -1.2356626  -0.04416263 -0.2517159  -1.3521781\n",
      "  0.03590789 -0.26093072 -1.1964047 ]\n",
      "data: [-0.02240093 -0.07845861 -0.20556557  0.0040775  -0.20517334 -0.51009905\n",
      " -0.09383052 -0.41861352 -1.3371339  -0.24742793 -0.47813356 -1.6503025\n",
      " -0.41680777 -0.6049646  -2.1409616  -0.24022976 -0.69776046 -1.531985\n",
      "  0.02420233 -0.74021804 -1.3208232  -0.0354341  -0.6835954  -1.3612257\n",
      " -0.03611077 -0.8208266  -1.4940212  -0.18322252 -0.58990467 -1.4218538\n",
      " -0.08608832 -0.6546953  -1.4042122  -0.07057127 -0.6196805  -1.4997841\n",
      "  0.06721278 -0.6709335  -1.5448834  -0.0671292  -0.48371905 -1.2371918\n",
      " -0.21889366 -0.24640906 -1.9653771  -0.01976117 -0.43181047 -1.9655777\n",
      "  0.1651053  -0.38377658 -1.3825458  -0.20570382 -0.24086423 -1.1633123\n",
      " -0.09068494 -0.21903622 -1.2356626  -0.04416263 -0.2517159  -1.3521781\n",
      "  0.03590789 -0.26093072 -1.1964047   0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[-3.0083e-04, -7.9370e-02, -2.5237e-01,  ...,  2.0854e-02,\n",
      "         -2.5452e-01, -1.2785e+00],\n",
      "        [-3.0083e-04, -7.9370e-02, -2.5237e-01,  ...,  2.0854e-02,\n",
      "         -2.5452e-01, -1.2785e+00],\n",
      "        [-3.0083e-04, -7.9370e-02, -2.5237e-01,  ...,  2.0854e-02,\n",
      "         -2.5452e-01, -1.2785e+00],\n",
      "        ...,\n",
      "        [-1.7687e-01,  3.7146e-01, -1.0098e-01,  ..., -7.0901e-01,\n",
      "          8.9767e-01, -3.8903e-01],\n",
      "        [-1.0585e-01, -6.9382e-02,  6.4233e-01,  ..., -2.1256e-01,\n",
      "          6.7798e-01,  3.0364e-01],\n",
      "        [-1.0585e-01, -6.9382e-02,  6.4233e-01,  ..., -2.1256e-01,\n",
      "          6.7798e-01,  3.0364e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-3.0083489e-04 -7.9370350e-02 -2.5237262e-01  2.7866337e-02\n",
      " -1.9955632e-01 -6.1706209e-01 -8.6227380e-02 -4.0411940e-01\n",
      " -1.4128153e+00 -2.3549436e-01 -4.6537632e-01 -1.7127342e+00\n",
      " -4.0016556e-01 -5.6780368e-01 -2.2021780e+00 -2.0278423e-01\n",
      " -7.0048714e-01 -1.5723052e+00 -1.5202165e-03 -7.4599493e-01\n",
      " -1.3877978e+00 -5.5353358e-02 -6.8010443e-01 -1.4416175e+00\n",
      " -6.7739323e-02 -8.3247769e-01 -1.5674727e+00 -1.5847319e-01\n",
      " -6.0539645e-01 -1.4761767e+00 -8.9913301e-02 -6.5797353e-01\n",
      " -1.4541090e+00 -9.9103458e-02 -6.2522811e-01 -1.5482121e+00\n",
      "  3.6486790e-02 -6.5720034e-01 -1.5827010e+00 -7.2960295e-02\n",
      " -5.0147212e-01 -1.3063793e+00 -2.1605866e-01 -2.6578373e-01\n",
      " -2.0365362e+00 -3.6815993e-02 -4.3154901e-01 -2.0514965e+00\n",
      "  1.2933522e-01 -3.9366704e-01 -1.4396887e+00 -1.8715683e-01\n",
      " -2.6859456e-01 -1.2342858e+00 -1.1371626e-01 -2.3962495e-01\n",
      " -1.3244030e+00 -7.4204102e-02 -2.4512678e-01 -1.4446588e+00\n",
      "  2.0854451e-02 -2.5452352e-01 -1.2784548e+00]\n",
      "data: [-3.0083489e-04 -7.9370350e-02 -2.5237262e-01  2.7866337e-02\n",
      " -1.9955631e-01 -6.1706209e-01 -8.6227380e-02 -4.0411940e-01\n",
      " -1.4128155e+00 -2.3549436e-01 -4.6537632e-01 -1.7127342e+00\n",
      " -4.0016556e-01 -5.6780368e-01 -2.2021780e+00 -2.0278424e-01\n",
      " -7.0048714e-01 -1.5723052e+00 -1.5202165e-03 -7.4599493e-01\n",
      " -1.3877978e+00 -5.5353358e-02 -6.8010443e-01 -1.4416175e+00\n",
      " -6.7739323e-02 -8.3247775e-01 -1.5674727e+00 -1.5847319e-01\n",
      " -6.0539645e-01 -1.4761767e+00 -8.9913301e-02 -6.5797353e-01\n",
      " -1.4541088e+00 -9.9103458e-02 -6.2522811e-01 -1.5482119e+00\n",
      "  3.6486790e-02 -6.5720034e-01 -1.5827010e+00 -7.2960295e-02\n",
      " -5.0147212e-01 -1.3063794e+00 -2.1605866e-01 -2.6578373e-01\n",
      " -2.0365362e+00 -3.6815993e-02 -4.3154898e-01 -2.0514965e+00\n",
      "  1.2933522e-01 -3.9366704e-01 -1.4396887e+00 -1.8715683e-01\n",
      " -2.6859456e-01 -1.2342858e+00 -1.1371626e-01 -2.3962493e-01\n",
      " -1.3244030e+00 -7.4204102e-02 -2.4512678e-01 -1.4446588e+00\n",
      "  2.0854451e-02 -2.5452352e-01 -1.2784548e+00  1.0000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[ 0.0227, -0.0221, -0.2236,  ...,  0.0344, -0.2105, -1.2537],\n",
      "        [ 0.0227, -0.0221, -0.2236,  ...,  0.0344, -0.2105, -1.2537],\n",
      "        [ 0.0227, -0.0221, -0.2236,  ...,  0.0344, -0.2105, -1.2537],\n",
      "        ...,\n",
      "        [-0.2117,  0.3361, -0.0996,  ..., -0.8561,  0.8434, -0.3474],\n",
      "        [-0.1336, -0.1671,  0.5832,  ..., -0.2096,  0.5897,  0.2487],\n",
      "        [-0.1336, -0.1671,  0.5832,  ..., -0.2096,  0.5897,  0.2487]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0227052  -0.02213115 -0.22364108  0.03557546 -0.14768156 -0.610139\n",
      " -0.07837511 -0.334044   -1.3636583  -0.22915122 -0.39576513 -1.6587358\n",
      " -0.39974695 -0.49093136 -2.148356   -0.17582405 -0.64328635 -1.5182365\n",
      " -0.00622922 -0.6812049  -1.3567997  -0.05386344 -0.6084055  -1.4206665\n",
      " -0.05310149 -0.76022446 -1.5390117  -0.13805377 -0.54959214 -1.4350603\n",
      " -0.07324591 -0.5948036  -1.4072423  -0.09290378 -0.5673003  -1.5063304\n",
      "  0.05095135 -0.5807631  -1.5355055  -0.06075952 -0.45509276 -1.2725084\n",
      " -0.17763884 -0.2312074  -1.932658   -0.02564389 -0.3759931  -1.9488738\n",
      "  0.14092165 -0.35092548 -1.4003686  -0.15661623 -0.22636475 -1.2069842\n",
      " -0.10034156 -0.20300928 -1.2971009  -0.06772235 -0.19728884 -1.417517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.03441143 -0.21054359 -1.2536815 ]\n",
      "data: [ 0.0227052  -0.02213115 -0.2236411   0.03557546 -0.14768156 -0.610139\n",
      " -0.07837511 -0.334044   -1.3636583  -0.2291512  -0.39576513 -1.6587358\n",
      " -0.39974698 -0.49093136 -2.148356   -0.17582405 -0.64328635 -1.5182365\n",
      " -0.00622922 -0.6812049  -1.3567997  -0.05386344 -0.6084055  -1.4206665\n",
      " -0.05310149 -0.76022446 -1.5390117  -0.13805377 -0.54959214 -1.4350603\n",
      " -0.07324591 -0.5948036  -1.4072423  -0.09290378 -0.5673003  -1.5063304\n",
      "  0.05095135 -0.5807631  -1.5355055  -0.06075952 -0.4550928  -1.2725084\n",
      " -0.17763883 -0.23120742 -1.932658   -0.02564389 -0.37599313 -1.9488738\n",
      "  0.14092165 -0.35092548 -1.4003685  -0.15661623 -0.22636475 -1.2069842\n",
      " -0.10034156 -0.20300928 -1.2971008  -0.06772235 -0.19728884 -1.417517\n",
      "  0.03441143 -0.21054359 -1.2536815   0.11      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[ 0.0457, -0.0816, -0.2287,  ...,  0.0377, -0.2685, -1.2861],\n",
      "        [ 0.0457, -0.0816, -0.2287,  ...,  0.0377, -0.2685, -1.2861],\n",
      "        [ 0.0457, -0.0816, -0.2287,  ...,  0.0377, -0.2685, -1.2861],\n",
      "        ...,\n",
      "        [-0.3148,  0.2689, -0.2740,  ..., -0.8180,  0.6870, -0.3890],\n",
      "        [-0.1528, -0.0798,  0.5705,  ..., -0.2318,  0.7034,  0.2887],\n",
      "        [-0.1528, -0.0798,  0.5705,  ..., -0.2318,  0.7034,  0.2887]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04570087 -0.08157682 -0.22867218  0.06753543 -0.21519436 -0.634231\n",
      " -0.05154284 -0.40204805 -1.4034021  -0.19844316 -0.4711608  -1.6813285\n",
      " -0.36077273 -0.5605397  -2.1786253  -0.14619784 -0.7005291  -1.5555444\n",
      "  0.00570412 -0.74090314 -1.3948574  -0.03900748 -0.66676664 -1.4560431\n",
      " -0.04348808 -0.8118392  -1.5650953  -0.1148228  -0.6053295  -1.4816667\n",
      " -0.0565511  -0.65083385 -1.4406798  -0.0883964  -0.62525296 -1.5296398\n",
      "  0.04650927 -0.6309968  -1.5584545  -0.05071526 -0.5205169  -1.3237808\n",
      " -0.15892196 -0.29498    -1.9535364  -0.02335307 -0.43443498 -1.9677202\n",
      "  0.12474595 -0.41171816 -1.4294299  -0.13696863 -0.2894086  -1.259626\n",
      " -0.09307252 -0.26442158 -1.3409057  -0.0563602  -0.25400662 -1.4567031\n",
      "  0.037739   -0.2685492  -1.2861392 ]\n",
      "data: [ 0.04570086 -0.08157682 -0.22867218  0.06753543 -0.21519436 -0.634231\n",
      " -0.05154284 -0.40204802 -1.4034021  -0.19844316 -0.4711608  -1.6813285\n",
      " -0.36077273 -0.5605397  -2.1786253  -0.14619784 -0.7005291  -1.5555444\n",
      "  0.00570412 -0.74090314 -1.3948575  -0.03900748 -0.66676664 -1.4560431\n",
      " -0.04348808 -0.8118392  -1.5650954  -0.1148228  -0.6053295  -1.4816667\n",
      " -0.0565511  -0.65083385 -1.4406798  -0.0883964  -0.62525296 -1.5296398\n",
      "  0.04650927 -0.6309968  -1.5584546  -0.05071526 -0.5205169  -1.3237808\n",
      " -0.15892196 -0.29498    -1.9535364  -0.02335307 -0.43443498 -1.9677202\n",
      "  0.12474595 -0.4117182  -1.4294299  -0.13696863 -0.2894086  -1.259626\n",
      " -0.09307252 -0.26442158 -1.3409057  -0.0563602  -0.25400662 -1.4567031\n",
      "  0.037739   -0.2685492  -1.2861392   0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[ 0.0366, -0.0839, -0.2525,  ...,  0.0681, -0.2729, -1.2691],\n",
      "        [ 0.0366, -0.0839, -0.2525,  ...,  0.0681, -0.2729, -1.2691],\n",
      "        [ 0.0366, -0.0839, -0.2525,  ...,  0.0681, -0.2729, -1.2691],\n",
      "        ...,\n",
      "        [-0.1166,  0.3779, -0.0460,  ..., -0.7588,  0.8863, -0.3271],\n",
      "        [-0.1276, -0.1184,  0.5732,  ..., -0.2263,  0.6559,  0.2101],\n",
      "        [-0.1276, -0.1184,  0.5732,  ..., -0.2263,  0.6559,  0.2101]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0366109  -0.0838832  -0.2524715   0.06312925 -0.20383996 -0.6256118\n",
      " -0.04785972 -0.4038563  -1.4106498  -0.19439988 -0.46665716 -1.7064965\n",
      " -0.35078317 -0.56885105 -2.1966422  -0.15760227 -0.70176923 -1.5701617\n",
      "  0.03485738 -0.7470886  -1.4005774  -0.01925415 -0.67889714 -1.4572918\n",
      " -0.02790208 -0.83142966 -1.5798508  -0.11426979 -0.61022055 -1.4770639\n",
      " -0.04552507 -0.6624412  -1.4516026  -0.06147103 -0.6322037  -1.5418756\n",
      "  0.06984863 -0.6616083  -1.5704089  -0.02911771 -0.5098438  -1.3088913\n",
      " -0.1620043  -0.2789909  -2.0107834   0.00523597 -0.4415963  -2.0246208\n",
      "  0.16725679 -0.40903968 -1.430419   -0.13746497 -0.2813068  -1.2368455\n",
      " -0.06346937 -0.2553979  -1.3229616  -0.02649717 -0.26101726 -1.4394169\n",
      "  0.0681319  -0.27289683 -1.2690762 ]\n",
      "data: [ 0.0366109  -0.0838832  -0.2524715   0.06312925 -0.20383996 -0.6256118\n",
      " -0.04785972 -0.4038563  -1.4106498  -0.19439988 -0.4666572  -1.7064965\n",
      " -0.35078317 -0.56885105 -2.1966422  -0.15760227 -0.70176923 -1.5701617\n",
      "  0.03485738 -0.7470886  -1.4005774  -0.01925415 -0.67889714 -1.4572918\n",
      " -0.02790208 -0.83142966 -1.5798508  -0.11426979 -0.61022055 -1.4770639\n",
      " -0.04552507 -0.6624412  -1.4516026  -0.06147103 -0.6322037  -1.5418756\n",
      "  0.06984863 -0.6616083  -1.5704089  -0.02911771 -0.5098438  -1.3088913\n",
      " -0.16200429 -0.2789909  -2.0107834   0.00523597 -0.4415963  -2.0246208\n",
      "  0.16725679 -0.40903968 -1.430419   -0.13746497 -0.2813068  -1.2368455\n",
      " -0.06346937 -0.2553979  -1.3229616  -0.02649717 -0.26101726 -1.4394168\n",
      "  0.0681319  -0.27289683 -1.2690762   0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0231, -0.0583, -0.2458,  ...,  0.0623, -0.2488, -1.2929],\n",
      "        [ 0.0231, -0.0583, -0.2458,  ...,  0.0623, -0.2488, -1.2929],\n",
      "        [ 0.0231, -0.0583, -0.2458,  ...,  0.0623, -0.2488, -1.2929],\n",
      "        ...,\n",
      "        [-0.1330,  0.3452, -0.0617,  ..., -0.7471,  0.8205, -0.2949],\n",
      "        [-0.1345, -0.1173,  0.5644,  ..., -0.2053,  0.6359,  0.2210],\n",
      "        [-0.1345, -0.1173,  0.5644,  ..., -0.2053,  0.6359,  0.2210]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02306871 -0.058311   -0.24579594  0.03634458 -0.20305799 -0.658018\n",
      " -0.03859257 -0.38265723 -1.3868449  -0.18258265 -0.44240996 -1.6946497\n",
      " -0.3623004  -0.5678203  -2.1569345  -0.18683976 -0.6626055  -1.5532176\n",
      "  0.05158553 -0.68971133 -1.3520536  -0.00251307 -0.6315628  -1.4047885\n",
      " -0.00283766 -0.76186144 -1.5217586  -0.13731363 -0.5534928  -1.4648311\n",
      " -0.04506353 -0.6132684  -1.443536   -0.05073419 -0.59182405 -1.5444257\n",
      "  0.07677441 -0.6186546  -1.5965769  -0.03726858 -0.46900517 -1.2889085\n",
      " -0.14985144 -0.24672931 -1.9238074   0.00528098 -0.40549025 -1.9160299\n",
      "  0.16143024 -0.37238494 -1.4451702  -0.14328974 -0.23093522 -1.2289252\n",
      " -0.05264495 -0.21470292 -1.3093991  -0.00466273 -0.23800683 -1.4269648\n",
      "  0.06228004 -0.24882777 -1.2928827 ]\n",
      "data: [ 0.02306871 -0.058311   -0.24579594  0.03634458 -0.20305799 -0.65801793\n",
      " -0.03859257 -0.38265723 -1.386845   -0.18258265 -0.44240996 -1.6946497\n",
      " -0.36230043 -0.5678203  -2.1569345  -0.18683976 -0.6626055  -1.5532176\n",
      "  0.05158553 -0.68971133 -1.3520536  -0.00251307 -0.6315628  -1.4047885\n",
      " -0.00283766 -0.76186144 -1.5217586  -0.13731363 -0.5534928  -1.4648311\n",
      " -0.04506353 -0.6132684  -1.443536   -0.05073419 -0.59182405 -1.5444256\n",
      "  0.07677441 -0.6186546  -1.596577   -0.03726858 -0.46900517 -1.2889085\n",
      " -0.14985144 -0.24672931 -1.9238074   0.00528098 -0.40549028 -1.9160299\n",
      "  0.16143024 -0.37238494 -1.4451702  -0.14328974 -0.23093522 -1.2289252\n",
      " -0.05264495 -0.2147029  -1.3093991  -0.00466273 -0.23800682 -1.4269648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.06228004 -0.24882776 -1.2928827   0.14      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0131, -0.0892, -0.2556,  ...,  0.0404, -0.2774, -1.3114],\n",
      "        [ 0.0131, -0.0892, -0.2556,  ...,  0.0404, -0.2774, -1.3114],\n",
      "        [ 0.0131, -0.0892, -0.2556,  ...,  0.0404, -0.2774, -1.3114],\n",
      "        ...,\n",
      "        [-0.1523,  0.4304, -0.1317,  ..., -0.7003,  0.9102, -0.3815],\n",
      "        [-0.1621, -0.1277,  0.5896,  ..., -0.2419,  0.6527,  0.2384],\n",
      "        [-0.1621, -0.1277,  0.5896,  ..., -0.2419,  0.6527,  0.2384]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01306144 -0.08921674 -0.25556132  0.03226295 -0.2280296  -0.66875523\n",
      " -0.05849055 -0.41376126 -1.4263914  -0.20072196 -0.4775865  -1.722878\n",
      " -0.36738047 -0.5899949  -2.1999133  -0.18791088 -0.6978381  -1.5870357\n",
      "  0.02479163 -0.7309816  -1.3921599  -0.02651271 -0.6669155  -1.4477034\n",
      " -0.03085955 -0.8016648  -1.5650921  -0.14501375 -0.59432685 -1.5013599\n",
      " -0.06488781 -0.6483854  -1.4751258  -0.0785848  -0.62382746 -1.5685809\n",
      "  0.05038288 -0.6454575  -1.6128304  -0.05741421 -0.5092038  -1.3304441\n",
      " -0.16994113 -0.28248847 -1.9674077  -0.02014339 -0.43587053 -1.9678342\n",
      "  0.13440625 -0.40484416 -1.4674847  -0.1590248  -0.27306306 -1.2645965\n",
      " -0.08125143 -0.25185645 -1.3464067  -0.03602999 -0.26454595 -1.4615862\n",
      "  0.04038706 -0.27744246 -1.3113766 ]\n",
      "data: [ 0.01306144 -0.08921674 -0.25556132  0.03226295 -0.2280296  -0.6687553\n",
      " -0.05849055 -0.41376126 -1.4263912  -0.20072196 -0.4775865  -1.722878\n",
      " -0.3673805  -0.5899949  -2.1999133  -0.18791088 -0.6978381  -1.5870357\n",
      "  0.02479163 -0.7309816  -1.3921599  -0.02651271 -0.66691554 -1.4477034\n",
      " -0.03085955 -0.8016648  -1.5650922  -0.14501375 -0.59432685 -1.5013598\n",
      " -0.06488781 -0.6483854  -1.4751258  -0.0785848  -0.62382746 -1.568581\n",
      "  0.05038288 -0.6454575  -1.6128304  -0.05741421 -0.5092038  -1.330444\n",
      " -0.16994113 -0.28248847 -1.9674077  -0.02014339 -0.43587053 -1.9678341\n",
      "  0.13440625 -0.40484416 -1.4674847  -0.1590248  -0.27306306 -1.2645965\n",
      " -0.08125143 -0.25185645 -1.3464067  -0.03602999 -0.26454595 -1.4615864\n",
      "  0.04038706 -0.27744246 -1.3113767   0.15      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0239, -0.0819, -0.2537,  ...,  0.0507, -0.2689, -1.2834],\n",
      "        [ 0.0239, -0.0819, -0.2537,  ...,  0.0507, -0.2689, -1.2834],\n",
      "        [ 0.0239, -0.0819, -0.2537,  ...,  0.0507, -0.2689, -1.2834],\n",
      "        ...,\n",
      "        [-0.1178,  0.4086, -0.1522,  ..., -0.6969,  0.9265, -0.4435],\n",
      "        [-0.1357, -0.1446,  0.5902,  ..., -0.2441,  0.6178,  0.2354],\n",
      "        [-0.1357, -0.1446,  0.5902,  ..., -0.2441,  0.6178,  0.2354]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02389957 -0.0819366  -0.25372833  0.04925447 -0.20801815 -0.638772\n",
      " -0.04771054 -0.40066522 -1.4068053  -0.19044545 -0.4612441  -1.7045913\n",
      " -0.34967965 -0.5676692  -2.1872113  -0.17121282 -0.693752   -1.5694277\n",
      "  0.03138796 -0.73288894 -1.4017303  -0.02249282 -0.668179   -1.4571269\n",
      " -0.02720394 -0.81330466 -1.5766854  -0.12780187 -0.59724116 -1.4784329\n",
      " -0.05373489 -0.64985275 -1.456147   -0.06762026 -0.622625   -1.5485554\n",
      "  0.05855689 -0.65118766 -1.5847964  -0.04114443 -0.5012427  -1.3095565\n",
      " -0.16880086 -0.27290738 -1.9930387  -0.00694171 -0.43342787 -2.0012023\n",
      "  0.14805657 -0.3999688  -1.4425967  -0.14880642 -0.2707532  -1.2411442\n",
      " -0.07148021 -0.24686624 -1.3253899  -0.03249488 -0.25706196 -1.4416714\n",
      "  0.05070193 -0.268863   -1.2834227 ]\n",
      "data: [ 0.02389957 -0.0819366  -0.25372833  0.04925447 -0.20801815 -0.638772\n",
      " -0.04771054 -0.4006652  -1.4068053  -0.19044547 -0.46124414 -1.7045913\n",
      " -0.34967965 -0.5676692  -2.1872113  -0.17121282 -0.693752   -1.5694278\n",
      "  0.03138796 -0.73288894 -1.4017303  -0.02249282 -0.6681789  -1.457127\n",
      " -0.02720394 -0.81330466 -1.5766854  -0.12780187 -0.59724116 -1.4784329\n",
      " -0.05373489 -0.64985275 -1.456147   -0.06762026 -0.622625   -1.5485553\n",
      "  0.05855689 -0.65118766 -1.5847964  -0.04114443 -0.5012427  -1.3095565\n",
      " -0.16880088 -0.27290738 -1.9930387  -0.00694171 -0.4334279  -2.0012023\n",
      "  0.14805657 -0.3999688  -1.4425968  -0.14880642 -0.2707532  -1.2411442\n",
      " -0.07148021 -0.24686624 -1.3253899  -0.03249488 -0.25706196 -1.4416715\n",
      "  0.05070193 -0.268863   -1.2834227   0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0186, -0.0474, -0.2469,  ...,  0.0551, -0.2396, -1.2876],\n",
      "        [ 0.0186, -0.0474, -0.2469,  ...,  0.0551, -0.2396, -1.2876],\n",
      "        [ 0.0186, -0.0474, -0.2469,  ...,  0.0551, -0.2396, -1.2876],\n",
      "        ...,\n",
      "        [-0.1552,  0.3435, -0.0910,  ..., -0.7960,  0.8242, -0.3240],\n",
      "        [-0.1350, -0.1444,  0.5594,  ..., -0.2080,  0.6132,  0.2147],\n",
      "        [-0.1350, -0.1444,  0.5594,  ..., -0.2080,  0.6132,  0.2147]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01862139 -0.04736958 -0.2469066   0.03215976 -0.18782996 -0.6529748\n",
      " -0.05091162 -0.36965317 -1.3888106  -0.194742   -0.42987698 -1.6922698\n",
      " -0.3707925  -0.5496845  -2.159053   -0.18823531 -0.65467787 -1.551435\n",
      "  0.03560835 -0.68481314 -1.359879   -0.01682337 -0.6234058  -1.4142914\n",
      " -0.01526428 -0.7583151  -1.5307782  -0.1407102  -0.54884434 -1.4641688\n",
      " -0.05436791 -0.60581315 -1.4412043  -0.06214964 -0.58396745 -1.5399787\n",
      "  0.0681762  -0.6080431  -1.5874944  -0.04558896 -0.4636429  -1.2915108\n",
      " -0.15905505 -0.24058062 -1.933289   -0.00381411 -0.3975021  -1.9300051\n",
      "  0.15382901 -0.3658878  -1.4398067  -0.14910623 -0.22771183 -1.2299905\n",
      " -0.06495021 -0.21028744 -1.312221   -0.01901677 -0.22793937 -1.4295578\n",
      "  0.05511964 -0.23958339 -1.2875767 ]\n",
      "data: [ 0.01862139 -0.04736958 -0.24690658  0.03215976 -0.18782996 -0.6529748\n",
      " -0.05091162 -0.36965317 -1.3888106  -0.194742   -0.42987698 -1.6922698\n",
      " -0.3707925  -0.5496845  -2.159053   -0.18823533 -0.65467787 -1.551435\n",
      "  0.03560835 -0.68481314 -1.359879   -0.01682337 -0.6234058  -1.4142914\n",
      " -0.01526428 -0.75831515 -1.5307782  -0.1407102  -0.54884434 -1.4641689\n",
      " -0.05436791 -0.60581315 -1.4412044  -0.06214963 -0.58396745 -1.5399787\n",
      "  0.0681762  -0.6080431  -1.5874944  -0.04558896 -0.4636429  -1.2915108\n",
      " -0.15905505 -0.24058062 -1.933289   -0.00381411 -0.3975021  -1.9300051\n",
      "  0.15382901 -0.3658878  -1.4398067  -0.14910623 -0.22771183 -1.2299905\n",
      " -0.06495021 -0.21028744 -1.312221   -0.01901677 -0.22793938 -1.4295578\n",
      "  0.05511964 -0.2395834  -1.2875766   0.17      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0087, -0.0796, -0.2508,  ...,  0.0356, -0.2672, -1.3079],\n",
      "        [ 0.0087, -0.0796, -0.2508,  ...,  0.0356, -0.2672, -1.3079],\n",
      "        [ 0.0087, -0.0796, -0.2508,  ...,  0.0356, -0.2672, -1.3079],\n",
      "        ...,\n",
      "        [-0.1623,  0.4165, -0.1407,  ..., -0.7212,  0.8974, -0.3776],\n",
      "        [-0.1648, -0.1360,  0.5743,  ..., -0.2519,  0.6455,  0.2241],\n",
      "        [-0.1648, -0.1360,  0.5743,  ..., -0.2519,  0.6455,  0.2241]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00866021 -0.07963304 -0.25084373  0.0274888  -0.21872798 -0.668907\n",
      " -0.06064876 -0.40095097 -1.4201121  -0.20152389 -0.46363968 -1.7167447\n",
      " -0.3687237  -0.5760913  -2.1915941  -0.1918847  -0.6857121  -1.5784144\n",
      "  0.0212951  -0.7161568  -1.3855641  -0.02874167 -0.6524096  -1.4416401\n",
      " -0.0311783  -0.7855972  -1.5586152  -0.14966907 -0.582071   -1.4937797\n",
      " -0.06810069 -0.6353719  -1.4684463  -0.08102825 -0.61092496 -1.5627711\n",
      "  0.04912634 -0.63177073 -1.6091027  -0.06263243 -0.49861932 -1.322835\n",
      " -0.17261572 -0.2721411  -1.9551902  -0.02354099 -0.42382854 -1.9549644\n",
      "  0.130844   -0.3935426  -1.463304   -0.16309005 -0.26264554 -1.2576821\n",
      " -0.08562587 -0.24159837 -1.339442   -0.03980222 -0.254058   -1.4553969\n",
      "  0.03558231 -0.26719782 -1.3079202 ]\n",
      "data: [ 0.00866021 -0.07963304 -0.25084373  0.0274888  -0.21872798 -0.668907\n",
      " -0.06064876 -0.40095097 -1.4201121  -0.20152387 -0.46363968 -1.7167447\n",
      " -0.3687237  -0.5760913  -2.1915941  -0.1918847  -0.6857121  -1.5784144\n",
      "  0.0212951  -0.7161568  -1.3855641  -0.02874167 -0.6524096  -1.4416401\n",
      " -0.0311783  -0.7855972  -1.5586152  -0.14966907 -0.582071   -1.4937797\n",
      " -0.06810069 -0.6353719  -1.4684463  -0.08102825 -0.61092496 -1.5627712\n",
      "  0.04912634 -0.63177073 -1.6091027  -0.06263243 -0.49861932 -1.322835\n",
      " -0.17261572 -0.2721411  -1.9551902  -0.02354099 -0.42382854 -1.9549644\n",
      "  0.130844   -0.3935426  -1.463304   -0.16309005 -0.26264554 -1.2576821\n",
      " -0.08562586 -0.24159835 -1.339442   -0.03980222 -0.254058   -1.4553969\n",
      "  0.03558231 -0.26719782 -1.3079202   0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[ 0.0157, -0.0884, -0.2488,  ...,  0.0481, -0.2758, -1.2809],\n",
      "        [ 0.0157, -0.0884, -0.2488,  ...,  0.0481, -0.2758, -1.2809],\n",
      "        [ 0.0157, -0.0884, -0.2488,  ...,  0.0481, -0.2758, -1.2809],\n",
      "        ...,\n",
      "        [-0.1233,  0.3970, -0.1657,  ..., -0.7113,  0.9054, -0.4368],\n",
      "        [-0.1447, -0.1626,  0.5724,  ..., -0.2583,  0.6041,  0.2194],\n",
      "        [-0.1447, -0.1626,  0.5724,  ..., -0.2583,  0.6041,  0.2194]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01565049 -0.08840943 -0.24882078  0.03881737 -0.2197536  -0.6423788\n",
      " -0.05313284 -0.4095633  -1.3998382  -0.19370238 -0.47009066 -1.6973335\n",
      " -0.35597128 -0.5807245  -2.172038   -0.18072878 -0.698176   -1.5601467\n",
      "  0.02861246 -0.73364294 -1.3856161  -0.02345239 -0.67033494 -1.4402721\n",
      " -0.02526256 -0.81137764 -1.5586308  -0.13676174 -0.59805393 -1.4712715\n",
      " -0.0579998  -0.65173817 -1.4486294  -0.06874707 -0.6258596  -1.5409696\n",
      "  0.05923612 -0.6534864  -1.5820004  -0.04806466 -0.5056778  -1.301833\n",
      " -0.1713272  -0.27852252 -1.9751074  -0.00985499 -0.43833175 -1.9793541\n",
      "  0.14563595 -0.40422437 -1.4388739  -0.154238   -0.27352446 -1.2350404\n",
      " -0.07441902 -0.2507955  -1.3185734  -0.0319517  -0.26329017 -1.4354665\n",
      "  0.04810753 -0.2757852  -1.2808844 ]\n",
      "data: [ 0.01565049 -0.08840943 -0.24882078  0.03881737 -0.2197536  -0.64237887\n",
      " -0.05313284 -0.4095633  -1.3998382  -0.1937024  -0.4700907  -1.6973336\n",
      " -0.35597125 -0.5807245  -2.172038   -0.18072878 -0.698176   -1.5601467\n",
      "  0.02861247 -0.73364294 -1.385616   -0.02345239 -0.67033494 -1.4402721\n",
      " -0.02526256 -0.81137764 -1.5586308  -0.13676174 -0.59805393 -1.4712715\n",
      " -0.0579998  -0.6517381  -1.4486295  -0.06874707 -0.6258596  -1.5409695\n",
      "  0.05923612 -0.65348643 -1.5820004  -0.04806466 -0.5056778  -1.301833\n",
      " -0.1713272  -0.27852252 -1.9751074  -0.00985499 -0.43833175 -1.9793541\n",
      "  0.14563595 -0.40422437 -1.4388739  -0.154238   -0.27352446 -1.2350404\n",
      " -0.07441902 -0.2507955  -1.3185734  -0.0319517  -0.26329017 -1.4354664\n",
      "  0.04810753 -0.2757852  -1.2808844   0.19      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[ 0.0262, -0.0719, -0.2504,  ...,  0.0543, -0.2619, -1.2735],\n",
      "        [ 0.0262, -0.0719, -0.2504,  ...,  0.0543, -0.2619, -1.2735],\n",
      "        [ 0.0262, -0.0719, -0.2504,  ...,  0.0543, -0.2619, -1.2735],\n",
      "        ...,\n",
      "        [-0.1488,  0.3685, -0.1191,  ..., -0.7789,  0.8664, -0.3820],\n",
      "        [-0.1308, -0.1280,  0.5814,  ..., -0.2185,  0.6411,  0.2156],\n",
      "        [-0.1308, -0.1280,  0.5814,  ..., -0.2185,  0.6411,  0.2156]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02618609 -0.0718894  -0.25038207  0.0498399  -0.19689885 -0.62996787\n",
      " -0.05672058 -0.39453232 -1.4079318  -0.2017671  -0.45729634 -1.7038543\n",
      " -0.36245883 -0.561671   -2.1887474  -0.1695978  -0.68947995 -1.5666568\n",
      "  0.02460727 -0.7323432  -1.39428    -0.02850939 -0.66535354 -1.4509304\n",
      " -0.03450555 -0.81533194 -1.5714383  -0.1265092  -0.59406364 -1.4755664\n",
      " -0.05645888 -0.6466981  -1.4496002  -0.0720493  -0.61958873 -1.5411127\n",
      "  0.05876072 -0.6461464  -1.5735934  -0.04168689 -0.4971312  -1.3076706\n",
      " -0.17161305 -0.26860848 -2.001585   -0.00784267 -0.42942274 -2.0125797\n",
      "  0.15160257 -0.39720467 -1.4321389  -0.14761664 -0.2669545  -1.2379389\n",
      " -0.0749477  -0.24297506 -1.3236129  -0.03639652 -0.24946713 -1.4401889\n",
      "  0.05432136 -0.2618507  -1.2734876 ]\n",
      "data: [ 0.02618609 -0.0718894  -0.25038207  0.0498399  -0.19689885 -0.62996787\n",
      " -0.05672058 -0.39453232 -1.4079318  -0.2017671  -0.45729634 -1.7038543\n",
      " -0.36245883 -0.561671   -2.1887474  -0.1695978  -0.68948    -1.5666568\n",
      "  0.02460727 -0.7323432  -1.39428    -0.02850939 -0.66535354 -1.4509304\n",
      " -0.03450555 -0.81533194 -1.5714383  -0.1265092  -0.59406364 -1.4755664\n",
      " -0.05645888 -0.6466982  -1.4496002  -0.0720493  -0.61958873 -1.5411127\n",
      "  0.05876072 -0.6461464  -1.5735935  -0.04168688 -0.4971312  -1.3076706\n",
      " -0.17161304 -0.26860848 -2.001585   -0.00784267 -0.42942274 -2.0125797\n",
      "  0.15160257 -0.39720467 -1.4321389  -0.14761664 -0.2669545  -1.2379389\n",
      " -0.0749477  -0.24297506 -1.3236129  -0.03639652 -0.24946712 -1.4401889\n",
      "  0.05432136 -0.2618507  -1.2734876   0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F9E8>\n",
      "tensor([[ 0.0150, -0.0390, -0.2423,  ...,  0.0529, -0.2311, -1.2824],\n",
      "        [ 0.0150, -0.0390, -0.2423,  ...,  0.0529, -0.2311, -1.2824],\n",
      "        [ 0.0150, -0.0390, -0.2423,  ...,  0.0529, -0.2311, -1.2824],\n",
      "        ...,\n",
      "        [-0.1702,  0.3345, -0.1124,  ..., -0.8146,  0.8012, -0.3203],\n",
      "        [-0.1403, -0.1450,  0.5520,  ..., -0.2140,  0.6143,  0.2066],\n",
      "        [-0.1403, -0.1450,  0.5520,  ..., -0.2140,  0.6143,  0.2066]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01498981 -0.0389964  -0.24228404  0.02859202 -0.17943622 -0.6505176\n",
      " -0.05444761 -0.360452   -1.3854585  -0.19795354 -0.42076594 -1.6891277\n",
      " -0.373949   -0.54098654 -2.1552439  -0.19208516 -0.6456346  -1.5458566\n",
      "  0.03279623 -0.67498153 -1.3526632  -0.01946224 -0.6141258  -1.4073437\n",
      " -0.01838566 -0.74861866 -1.524459   -0.14450373 -0.54001766 -1.4586015\n",
      " -0.05757417 -0.5971565  -1.4362093  -0.06511912 -0.5749578  -1.5352043\n",
      "  0.06610192 -0.5996313  -1.583543   -0.04930442 -0.45520812 -1.2852707\n",
      " -0.16212055 -0.23177688 -1.9268696  -0.00636835 -0.38847947 -1.9235458\n",
      "  0.15188895 -0.35752726 -1.4349601  -0.15245521 -0.21914467 -1.22355\n",
      " -0.0678363  -0.20165877 -1.3058531  -0.02138251 -0.2192069  -1.4237076\n",
      "  0.05293977 -0.23109904 -1.2823699 ]\n",
      "data: [ -5.18   9.54 -12.66  -5.13   9.71 -12.29  -5.01   9.92 -12.09  -5.01\n",
      "  10.13 -11.97   0.     0.     0.    -5.16  10.3  -12.1    0.     0.\n",
      "   0.    -5.14  10.39 -12.02  -5.12  10.19 -12.17  -5.25  10.19 -12.21\n",
      "  -7.58  13.23  -4.67  -5.24  10.28 -12.18  -5.23  10.16 -12.19  -5.39\n",
      "  10.18 -12.19  -7.79  13.15  -4.53  -5.4   10.22 -12.16  -5.36  10.06\n",
      " -12.25  -5.49  10.08 -12.24  -5.49  10.14 -12.3   -5.49  10.1  -12.27\n",
      "  -5.46  10.02 -12.28   0.  ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[ 0.1501, -0.4984, -0.3885,  ...,  0.1845, -0.7372, -0.0455],\n",
      "        [ 0.1501, -0.4984, -0.3885,  ...,  0.1845, -0.7372, -0.0455],\n",
      "        [ 0.1501, -0.4984, -0.3885,  ...,  0.1845, -0.7372, -0.0455],\n",
      "        ...,\n",
      "        [ 0.9415,  0.7092,  1.0447,  ..., -0.1724,  1.4020,  0.4430],\n",
      "        [ 0.9228,  0.1725, -0.1145,  ...,  1.0942,  0.7803, -1.7086],\n",
      "        [ 0.9228,  0.1725, -0.1145,  ...,  1.0942,  0.7803, -1.7086]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.15011042 -0.49842834 -0.38848162  0.10079224 -0.5601156  -0.31477654\n",
      "  0.02743319 -0.6283959  -0.11229432 -0.03843342 -0.7377856  -0.00553533\n",
      " -0.06438521 -0.8098905   0.05492687 -0.01147498 -0.698673   -0.2616793\n",
      "  0.0770711  -0.7375614   0.22401541  0.05733632 -0.8439441   0.30808944\n",
      "  0.01244649 -0.8128095   0.31711316  0.04677667 -0.6672174  -0.30070028\n",
      "  0.00997868 -0.7627634  -0.14254132  0.03206141 -0.8112807  -0.07310754\n",
      "  0.06255344 -0.91209865 -0.05988824  0.07249876 -0.6423298  -0.27595925\n",
      "  0.01950306 -0.6904502  -0.15142378  0.06177486 -0.75696075 -0.11240092\n",
      "  0.11949377 -0.8138436  -0.04128498  0.0972127  -0.54899174 -0.2553609\n",
      "  0.12855159 -0.58955324 -0.10478064  0.17006187 -0.6593671  -0.07681209\n",
      "  0.1845204  -0.7371862  -0.04551378]\n",
      "init: [ 0.15011042 -0.49842834 -0.38848162  0.10079224 -0.5601156  -0.31477654\n",
      "  0.02743319 -0.6283959  -0.11229432 -0.03843342 -0.7377856  -0.00553533\n",
      " -0.06438521 -0.8098905   0.05492687 -0.01147498 -0.698673   -0.2616793\n",
      "  0.0770711  -0.7375614   0.22401541  0.05733632 -0.8439441   0.30808944\n",
      "  0.01244649 -0.8128095   0.31711316  0.04677667 -0.6672174  -0.30070028\n",
      "  0.00997868 -0.7627634  -0.14254132  0.03206141 -0.8112807  -0.07310754\n",
      "  0.06255344 -0.91209865 -0.05988824  0.07249876 -0.6423298  -0.27595925\n",
      "  0.01950306 -0.6904502  -0.15142378  0.06177486 -0.75696075 -0.11240092\n",
      "  0.11949377 -0.8138436  -0.04128498  0.0972127  -0.54899174 -0.2553609\n",
      "  0.12855159 -0.58955324 -0.10478064  0.17006187 -0.6593671  -0.07681209\n",
      "  0.1845204  -0.7371862  -0.04551378]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [ 0.15011042 -0.49842834 -0.3884816   0.10079224 -0.5601156  -0.31477654\n",
      "  0.02743319 -0.6283959  -0.11229431 -0.03843342 -0.7377856  -0.00553533\n",
      " -0.06438521 -0.8098905   0.05492687 -0.01147498 -0.698673   -0.2616793\n",
      "  0.0770711  -0.7375614   0.22401541  0.05733632 -0.8439441   0.30808944\n",
      "  0.01244649 -0.8128095   0.31711316  0.04677667 -0.66721743 -0.30070028\n",
      "  0.00997868 -0.7627634  -0.14254132  0.03206141 -0.8112807  -0.07310754\n",
      "  0.06255344 -0.91209865 -0.05988824  0.07249876 -0.6423298  -0.27595925\n",
      "  0.01950306 -0.6904502  -0.15142378  0.06177486 -0.75696075 -0.11240092\n",
      "  0.11949377 -0.8138436  -0.04128498  0.0972127  -0.54899174 -0.2553609\n",
      "  0.12855159 -0.58955324 -0.10478064  0.17006187 -0.6593671  -0.07681209\n",
      "  0.1845204  -0.7371862  -0.04551378  0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[-0.1186,  0.1468,  0.0673,  ..., -0.0203, -0.1890, -0.4958],\n",
      "        [-0.1186,  0.1468,  0.0673,  ..., -0.0203, -0.1890, -0.4958],\n",
      "        [-0.1186,  0.1468,  0.0673,  ..., -0.0203, -0.1890, -0.4958],\n",
      "        ...,\n",
      "        [ 0.1750,  0.0475,  0.0117,  ..., -0.1443,  0.7345, -0.4342],\n",
      "        [ 0.3455, -0.2853,  0.0617,  ...,  0.7724,  0.0147,  0.2080],\n",
      "        [ 0.3455, -0.2853,  0.0617,  ...,  0.7724,  0.0147,  0.2080]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.11856715  0.14679766  0.06725986 -0.22518727  0.02428654 -0.23407279\n",
      " -0.40322646 -0.09891073 -0.76158327 -0.56388664 -0.1748755  -0.9997993\n",
      " -0.8115647  -0.2536615  -1.3564947  -0.3314559  -0.42601946 -0.8593856\n",
      " -0.39366353 -0.4843394  -0.9968594  -0.36238256 -0.38218695 -1.0807067\n",
      " -0.14616123 -0.5799919  -1.1269181  -0.29522467 -0.32627904 -0.79154927\n",
      " -0.2786789  -0.37424928 -0.73675764 -0.24029312 -0.4320092  -0.84295\n",
      "  0.07026695 -0.3608279  -0.8719764  -0.26611087 -0.34359238 -0.62404287\n",
      " -0.26819962 -0.176949   -0.9442099  -0.15970588 -0.27160233 -0.9583295\n",
      "  0.13870594 -0.32055965 -0.6471585  -0.28163034 -0.12493107 -0.5477392\n",
      " -0.30523202 -0.1502567  -0.5893648  -0.24520828 -0.10925762 -0.6912393\n",
      " -0.02031758 -0.18903777 -0.49583042]\n",
      "data: [-0.11856715  0.14679766  0.06725986 -0.22518726  0.02428654 -0.23407277\n",
      " -0.40322646 -0.09891072 -0.76158327 -0.56388664 -0.17487548 -0.9997994\n",
      " -0.8115647  -0.2536615  -1.3564945  -0.3314559  -0.4260195  -0.8593856\n",
      " -0.39366353 -0.48433936 -0.9968594  -0.36238253 -0.38218698 -1.0807067\n",
      " -0.14616123 -0.5799919  -1.1269181  -0.29522467 -0.32627904 -0.7915493\n",
      " -0.2786789  -0.37424928 -0.73675764 -0.24029312 -0.4320092  -0.84295\n",
      "  0.07026695 -0.3608279  -0.8719764  -0.26611087 -0.34359238 -0.62404287\n",
      " -0.26819962 -0.17694898 -0.9442099  -0.15970588 -0.27160233 -0.95832944\n",
      "  0.13870594 -0.32055965 -0.6471585  -0.28163034 -0.12493107 -0.5477392\n",
      " -0.30523202 -0.1502567  -0.5893648  -0.24520828 -0.10925761 -0.6912393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.02031758 -0.18903776 -0.49583042  0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.2124, -0.1992, -0.0553,  ...,  0.2485, -0.3526, -1.2062],\n",
      "        [ 0.2124, -0.1992, -0.0553,  ...,  0.2485, -0.3526, -1.2062],\n",
      "        [ 0.2124, -0.1992, -0.0553,  ...,  0.2485, -0.3526, -1.2062],\n",
      "        ...,\n",
      "        [-0.0987,  0.1928,  0.4868,  ..., -0.2323,  0.8479,  0.2273],\n",
      "        [-0.6467,  0.3779,  0.2728,  ..., -1.2975,  1.0934,  0.0208],\n",
      "        [-0.6467,  0.3779,  0.2728,  ..., -1.2975,  1.0934,  0.0208]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.21235022 -0.19923162 -0.055316    0.2388141  -0.3227366  -0.48527202\n",
      "  0.17966762 -0.44764346 -1.1500429   0.04126929 -0.47612095 -1.4335662\n",
      " -0.08646607 -0.579447   -1.9501979   0.00491565 -0.76461554 -1.3206859\n",
      "  0.25311267 -0.74586105 -1.136657    0.21480964 -0.64817977 -1.1914643\n",
      "  0.20582157 -0.7340281  -1.3060157   0.03592217 -0.68201673 -1.2677416\n",
      "  0.15745541 -0.6955464  -1.2836413   0.16096917 -0.6162243  -1.3615501\n",
      "  0.2843461  -0.62975645 -1.4168878   0.15629518 -0.60826933 -1.1322379\n",
      "  0.09986378 -0.35048205 -1.5746211   0.2254906  -0.47266117 -1.5594893\n",
      "  0.36270338 -0.4111109  -1.3552362   0.05049156 -0.39041388 -1.0837948\n",
      "  0.15382774 -0.34260425 -1.1824926   0.19471791 -0.3558956  -1.3038455\n",
      "  0.2484645  -0.3525933  -1.2062072 ]\n",
      "data: [ 0.21235022 -0.19923162 -0.055316    0.2388141  -0.3227366  -0.48527202\n",
      "  0.17966762 -0.44764346 -1.1500429   0.04126929 -0.47612095 -1.4335663\n",
      " -0.08646607 -0.579447   -1.9501979   0.00491565 -0.76461554 -1.3206859\n",
      "  0.25311267 -0.74586105 -1.136657    0.21480964 -0.64817977 -1.1914643\n",
      "  0.20582157 -0.7340281  -1.3060157   0.03592217 -0.68201673 -1.2677416\n",
      "  0.15745541 -0.6955464  -1.2836413   0.16096917 -0.6162243  -1.3615501\n",
      "  0.2843461  -0.62975645 -1.4168878   0.15629518 -0.60826933 -1.1322379\n",
      "  0.09986379 -0.35048208 -1.5746211   0.22549061 -0.47266117 -1.5594893\n",
      "  0.3627034  -0.4111109  -1.3552362   0.05049156 -0.39041388 -1.0837948\n",
      "  0.15382774 -0.34260425 -1.1824926   0.19471793 -0.3558956  -1.3038455\n",
      "  0.2484645  -0.3525933  -1.2062072   0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0316, -0.1459, -0.1685,  ...,  0.0344, -0.3277, -1.2186],\n",
      "        [ 0.0316, -0.1459, -0.1685,  ...,  0.0344, -0.3277, -1.2186],\n",
      "        [ 0.0316, -0.1459, -0.1685,  ...,  0.0344, -0.3277, -1.2186],\n",
      "        ...,\n",
      "        [-0.1678,  0.3985, -0.2209,  ..., -0.4675,  0.8946, -0.7394],\n",
      "        [-0.2204,  0.0284,  0.4881,  ..., -0.1618,  0.8059, -0.0451],\n",
      "        [-0.2204,  0.0284,  0.4881,  ..., -0.1618,  0.8059, -0.0451]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 3.1556580e-02 -1.4594047e-01 -1.6848859e-01  3.6773037e-02\n",
      " -2.9903001e-01 -5.5063748e-01 -7.7040367e-02 -5.1685601e-01\n",
      " -1.3572819e+00 -2.3873317e-01 -5.9041780e-01 -1.6565279e+00\n",
      " -4.3287858e-01 -7.1094716e-01 -2.1459727e+00 -2.0883912e-01\n",
      " -7.5633347e-01 -1.5700412e+00  2.1149516e-03 -8.1092858e-01\n",
      " -1.3377504e+00 -5.2159518e-02 -7.4286115e-01 -1.3787837e+00\n",
      " -6.2102541e-02 -8.9174879e-01 -1.4882501e+00 -1.5929168e-01\n",
      " -6.3619936e-01 -1.4734594e+00 -8.9387089e-02 -7.0729101e-01\n",
      " -1.4160774e+00 -1.0480210e-01 -6.9515729e-01 -1.5061255e+00\n",
      "  2.6134565e-02 -7.1282053e-01 -1.5424386e+00 -6.0760297e-02\n",
      " -5.5178750e-01 -1.3031934e+00 -1.9670367e-01 -3.3003438e-01\n",
      " -1.9382017e+00 -4.3464363e-02 -5.0600106e-01 -1.9321847e+00\n",
      "  1.1711034e-01 -4.6367732e-01 -1.3806018e+00 -1.6961971e-01\n",
      " -3.0932385e-01 -1.2308422e+00 -9.5564261e-02 -2.9338223e-01\n",
      " -1.2859069e+00 -4.7028244e-02 -3.1688029e-01 -1.3948172e+00\n",
      "  3.4411684e-02 -3.2767951e-01 -1.2186011e+00]\n",
      "data: [ 3.1556580e-02 -1.4594047e-01 -1.6848859e-01  3.6773037e-02\n",
      " -2.9903001e-01 -5.5063748e-01 -7.7040367e-02 -5.1685601e-01\n",
      " -1.3572819e+00 -2.3873317e-01 -5.9041780e-01 -1.6565279e+00\n",
      " -4.3287858e-01 -7.1094722e-01 -2.1459727e+00 -2.0883912e-01\n",
      " -7.5633347e-01 -1.5700412e+00  2.1149516e-03 -8.1092858e-01\n",
      " -1.3377504e+00 -5.2159518e-02 -7.4286115e-01 -1.3787837e+00\n",
      " -6.2102541e-02 -8.9174879e-01 -1.4882501e+00 -1.5929168e-01\n",
      " -6.3619936e-01 -1.4734594e+00 -8.9387089e-02 -7.0729101e-01\n",
      " -1.4160774e+00 -1.0480210e-01 -6.9515729e-01 -1.5061255e+00\n",
      "  2.6134565e-02 -7.1282053e-01 -1.5424386e+00 -6.0760297e-02\n",
      " -5.5178750e-01 -1.3031936e+00 -1.9670369e-01 -3.3003438e-01\n",
      " -1.9382015e+00 -4.3464366e-02 -5.0600106e-01 -1.9321847e+00\n",
      "  1.1711034e-01 -4.6367732e-01 -1.3806018e+00 -1.6961971e-01\n",
      " -3.0932385e-01 -1.2308422e+00 -9.5564261e-02 -2.9338223e-01\n",
      " -1.2859070e+00 -4.7028247e-02 -3.1688029e-01 -1.3948172e+00\n",
      "  3.4411684e-02 -3.2767951e-01 -1.2186011e+00  3.9999999e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0117, -0.0686, -0.1553,  ...,  0.0568, -0.2716, -1.1177],\n",
      "        [ 0.0117, -0.0686, -0.1553,  ...,  0.0568, -0.2716, -1.1177],\n",
      "        [ 0.0117, -0.0686, -0.1553,  ...,  0.0568, -0.2716, -1.1177],\n",
      "        ...,\n",
      "        [-0.1961,  0.4115, -0.0885,  ..., -0.7143,  1.0140, -0.4341],\n",
      "        [-0.0892, -0.0445,  0.6485,  ..., -0.1937,  0.6326,  0.3372],\n",
      "        [-0.0892, -0.0445,  0.6485,  ..., -0.1937,  0.6326,  0.3372]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01174215 -0.06855387 -0.15530655  0.04191713 -0.15917195 -0.4190836\n",
      " -0.11379759 -0.39284    -1.2896487  -0.2686301  -0.4578343  -1.5718112\n",
      " -0.40952465 -0.5438051  -2.0884314  -0.17806008 -0.71059203 -1.4684259\n",
      " -0.0159944  -0.7838404  -1.3353952  -0.06687503 -0.70463777 -1.3838823\n",
      " -0.06303655 -0.8796389  -1.5113347  -0.13285989 -0.6320518  -1.3649328\n",
      " -0.0786178  -0.6824701  -1.3377929  -0.07998382 -0.64241385 -1.4148662\n",
      "  0.07088843 -0.6811341  -1.4217157  -0.04858602 -0.516539   -1.2074051\n",
      " -0.21292868 -0.27519503 -1.9936101  -0.01079237 -0.45484832 -2.0262876\n",
      "  0.18123296 -0.4137462  -1.2959895  -0.17679559 -0.29156905 -1.1206616\n",
      " -0.10390636 -0.2604703  -1.2146211  -0.07362747 -0.2578906  -1.3272933\n",
      "  0.05683643 -0.27156478 -1.1176858 ]\n",
      "data: [ 0.01174215 -0.06855387 -0.15530655  0.04191713 -0.15917195 -0.4190836\n",
      " -0.11379759 -0.39284    -1.2896485  -0.2686301  -0.45783433 -1.5718112\n",
      " -0.40952465 -0.5438051  -2.0884314  -0.1780601  -0.71059203 -1.4684259\n",
      " -0.0159944  -0.7838404  -1.3353952  -0.06687503 -0.70463777 -1.3838823\n",
      " -0.06303655 -0.8796389  -1.5113347  -0.13285989 -0.6320518  -1.3649327\n",
      " -0.0786178  -0.6824701  -1.3377929  -0.07998382 -0.64241385 -1.4148662\n",
      "  0.07088843 -0.6811341  -1.4217157  -0.04858602 -0.516539   -1.2074051\n",
      " -0.21292868 -0.27519503 -1.99361    -0.01079237 -0.45484832 -2.0262876\n",
      "  0.18123297 -0.41374624 -1.2959895  -0.17679557 -0.29156905 -1.1206616\n",
      " -0.10390636 -0.2604703  -1.2146211  -0.07362747 -0.2578906  -1.3272933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.05683643 -0.27156478 -1.1176858   0.05      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-4.2666e-02, -1.7392e-03, -2.4590e-01,  ..., -8.6974e-03,\n",
      "         -1.8679e-01, -1.2423e+00],\n",
      "        [-4.2666e-02, -1.7392e-03, -2.4590e-01,  ..., -8.6974e-03,\n",
      "         -1.8679e-01, -1.2423e+00],\n",
      "        [-4.2666e-02, -1.7392e-03, -2.4590e-01,  ..., -8.6974e-03,\n",
      "         -1.8679e-01, -1.2423e+00],\n",
      "        ...,\n",
      "        [-2.0950e-01,  2.8209e-01,  1.2043e-03,  ..., -6.6862e-01,\n",
      "          8.1310e-01, -3.4805e-01],\n",
      "        [-1.4217e-01, -9.6481e-02,  5.6704e-01,  ..., -2.7312e-01,\n",
      "          6.4004e-01,  2.3552e-01],\n",
      "        [-1.4217e-01, -9.6481e-02,  5.6704e-01,  ..., -2.7312e-01,\n",
      "          6.4004e-01,  2.3552e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-4.26657461e-02 -1.73917226e-03 -2.45898679e-01 -1.66098587e-02\n",
      " -1.07902810e-01 -5.73545575e-01 -1.55073911e-01 -3.20625395e-01\n",
      " -1.38919508e+00 -3.11991453e-01 -3.82259667e-01 -1.68388140e+00\n",
      " -4.69752133e-01 -4.73675162e-01 -2.18778062e+00 -2.37520739e-01\n",
      " -6.34800911e-01 -1.55100155e+00 -6.39822632e-02 -6.89862251e-01\n",
      " -1.38659298e+00 -1.13173038e-01 -6.10588908e-01 -1.44550645e+00\n",
      " -1.18404776e-01 -7.77751923e-01 -1.57382321e+00 -1.94783643e-01\n",
      " -5.48907638e-01 -1.45423520e+00 -1.34272754e-01 -5.97126365e-01\n",
      " -1.42885101e+00 -1.44622326e-01 -5.60705304e-01 -1.52011895e+00\n",
      "  7.93951750e-03 -5.87492108e-01 -1.53968310e+00 -1.11273147e-01\n",
      " -4.40233648e-01 -1.28922439e+00 -2.58100450e-01 -1.99578702e-01\n",
      " -2.04244161e+00 -7.33884797e-02 -3.66238326e-01 -2.06787658e+00\n",
      "  1.12427816e-01 -3.31116229e-01 -1.40517938e+00 -2.26304710e-01\n",
      " -2.11225614e-01 -1.21235561e+00 -1.61509618e-01 -1.78722993e-01\n",
      " -1.30842173e+00 -1.27539068e-01 -1.74776733e-01 -1.42820883e+00\n",
      " -8.69742781e-03 -1.86792955e-01 -1.24227250e+00]\n",
      "data: [-4.26657423e-02 -1.73917238e-03 -2.45898679e-01 -1.66098587e-02\n",
      " -1.07902810e-01 -5.73545575e-01 -1.55073911e-01 -3.20625395e-01\n",
      " -1.38919508e+00 -3.11991453e-01 -3.82259667e-01 -1.68388140e+00\n",
      " -4.69752133e-01 -4.73675162e-01 -2.18778062e+00 -2.37520739e-01\n",
      " -6.34800911e-01 -1.55100155e+00 -6.39822632e-02 -6.89862192e-01\n",
      " -1.38659298e+00 -1.13173038e-01 -6.10588908e-01 -1.44550645e+00\n",
      " -1.18404776e-01 -7.77751923e-01 -1.57382321e+00 -1.94783643e-01\n",
      " -5.48907638e-01 -1.45423520e+00 -1.34272754e-01 -5.97126365e-01\n",
      " -1.42885101e+00 -1.44622326e-01 -5.60705304e-01 -1.52011907e+00\n",
      "  7.93951750e-03 -5.87492108e-01 -1.53968310e+00 -1.11273147e-01\n",
      " -4.40233648e-01 -1.28922439e+00 -2.58100450e-01 -1.99578702e-01\n",
      " -2.04244161e+00 -7.33884797e-02 -3.66238326e-01 -2.06787658e+00\n",
      "  1.12427816e-01 -3.31116229e-01 -1.40517950e+00 -2.26304710e-01\n",
      " -2.11225599e-01 -1.21235561e+00 -1.61509603e-01 -1.78722993e-01\n",
      " -1.30842173e+00 -1.27539068e-01 -1.74776733e-01 -1.42820883e+00\n",
      " -8.69742781e-03 -1.86792940e-01 -1.24227250e+00  5.99999987e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0312, -0.0765, -0.1678,  ...,  0.0289, -0.2385, -1.2911],\n",
      "        [ 0.0312, -0.0765, -0.1678,  ...,  0.0289, -0.2385, -1.2911],\n",
      "        [ 0.0312, -0.0765, -0.1678,  ...,  0.0289, -0.2385, -1.2911],\n",
      "        ...,\n",
      "        [-0.3091,  0.2881, -0.2450,  ..., -0.8751,  0.7628, -0.3990],\n",
      "        [-0.2236, -0.1328,  0.4800,  ..., -0.3071,  0.6078,  0.2362],\n",
      "        [-0.2236, -0.1328,  0.4800,  ..., -0.3071,  0.6078,  0.2362]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 3.11994068e-02 -7.65322596e-02 -1.67797998e-01  4.16086800e-02\n",
      " -2.43273407e-01 -6.56704903e-01  2.13281065e-03 -3.80884945e-01\n",
      " -1.31450284e+00 -1.33517325e-01 -4.32792664e-01 -1.61552405e+00\n",
      " -3.19118887e-01 -5.62369704e-01 -2.06703758e+00 -1.90366060e-01\n",
      " -6.51465297e-01 -1.46605468e+00  7.03264773e-02 -6.45359755e-01\n",
      " -1.25125444e+00  2.60749906e-02 -5.91371059e-01 -1.30282009e+00\n",
      "  3.05773616e-02 -6.80458069e-01 -1.41066742e+00 -1.51592374e-01\n",
      " -5.32379746e-01 -1.39870167e+00 -3.86364534e-02 -5.83899617e-01\n",
      " -1.38458490e+00 -4.04859036e-02 -5.55373311e-01 -1.49093068e+00\n",
      "  8.41780752e-02 -5.69831967e-01 -1.56919539e+00 -5.42447194e-02\n",
      " -4.69678402e-01 -1.22766626e+00 -1.24220476e-01 -2.48293728e-01\n",
      " -1.72005117e+00 -1.69068575e-03 -3.77609104e-01 -1.69544256e+00\n",
      "  1.34566635e-01 -3.47558111e-01 -1.42814994e+00 -1.48338050e-01\n",
      " -2.24036351e-01 -1.18144596e+00 -5.88592887e-02 -2.06365287e-01\n",
      " -1.25631058e+00 -3.80094349e-03 -2.31829017e-01 -1.37684035e+00\n",
      "  2.88520381e-02 -2.38513187e-01 -1.29111528e+00]\n",
      "data: [ 3.11994068e-02 -7.65322596e-02 -1.67797998e-01  4.16086800e-02\n",
      " -2.43273407e-01 -6.56704843e-01  2.13281065e-03 -3.80884945e-01\n",
      " -1.31450284e+00 -1.33517325e-01 -4.32792664e-01 -1.61552393e+00\n",
      " -3.19118887e-01 -5.62369704e-01 -2.06703758e+00 -1.90366060e-01\n",
      " -6.51465297e-01 -1.46605468e+00  7.03264773e-02 -6.45359755e-01\n",
      " -1.25125444e+00  2.60749906e-02 -5.91371059e-01 -1.30282009e+00\n",
      "  3.05773616e-02 -6.80458069e-01 -1.41066742e+00 -1.51592374e-01\n",
      " -5.32379746e-01 -1.39870167e+00 -3.86364534e-02 -5.83899617e-01\n",
      " -1.38458490e+00 -4.04859036e-02 -5.55373311e-01 -1.49093068e+00\n",
      "  8.41780752e-02 -5.69831967e-01 -1.56919539e+00 -5.42447194e-02\n",
      " -4.69678432e-01 -1.22766626e+00 -1.24220476e-01 -2.48293728e-01\n",
      " -1.72005117e+00 -1.69068575e-03 -3.77609104e-01 -1.69544256e+00\n",
      "  1.34566635e-01 -3.47558111e-01 -1.42814982e+00 -1.48338050e-01\n",
      " -2.24036351e-01 -1.18144596e+00 -5.88592924e-02 -2.06365287e-01\n",
      " -1.25631058e+00 -3.80094349e-03 -2.31829017e-01 -1.37684035e+00\n",
      "  2.88520381e-02 -2.38513187e-01 -1.29111528e+00  7.00000003e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63E80>\n",
      "tensor([[ 0.0655, -0.1150, -0.3038,  ...,  0.0818, -0.2821, -1.3646],\n",
      "        [ 0.0655, -0.1150, -0.3038,  ...,  0.0818, -0.2821, -1.3646],\n",
      "        [ 0.0655, -0.1150, -0.3038,  ...,  0.0818, -0.2821, -1.3646],\n",
      "        ...,\n",
      "        [-0.1599,  0.4704, -0.0788,  ..., -0.7288,  0.9982, -0.4008],\n",
      "        [-0.1892, -0.0458,  0.6120,  ..., -0.2845,  0.7302,  0.2492],\n",
      "        [-0.1892, -0.0458,  0.6120,  ..., -0.2845,  0.7302,  0.2492]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.06546668 -0.11498398 -0.30381307  0.10278231 -0.24316955 -0.6963588\n",
      "  0.00725235 -0.4380828  -1.4960053  -0.13716939 -0.49699146 -1.7948709\n",
      " -0.2878753  -0.60425955 -2.2944996  -0.13730446 -0.7160206  -1.6758473\n",
      "  0.09081741 -0.75063175 -1.4806063   0.03828792 -0.6899804  -1.5305324\n",
      "  0.02319845 -0.8228215  -1.6558044  -0.09510043 -0.61523414 -1.5813286\n",
      " -0.01242242 -0.67121136 -1.5601075  -0.02040786 -0.63741887 -1.649436\n",
      "  0.10472298 -0.67492735 -1.6943688  -0.0038524  -0.5184866  -1.4054193\n",
      " -0.13602734 -0.28012228 -2.081515    0.03235457 -0.44778842 -2.0856903\n",
      "  0.18652576 -0.40755612 -1.541528   -0.12085802 -0.28303108 -1.3318784\n",
      " -0.03400563 -0.25232232 -1.4002273   0.01103594 -0.270841   -1.5166531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.08183178 -0.2821222  -1.3646116 ]\n",
      "data: [ 0.06546668 -0.11498398 -0.30381307  0.10278231 -0.24316956 -0.6963588\n",
      "  0.00725235 -0.4380828  -1.4960053  -0.13716939 -0.49699146 -1.7948709\n",
      " -0.2878753  -0.60425955 -2.2944996  -0.13730446 -0.7160206  -1.6758473\n",
      "  0.09081741 -0.7506317  -1.4806064   0.03828792 -0.6899804  -1.5305324\n",
      "  0.02319845 -0.8228215  -1.6558044  -0.09510043 -0.61523414 -1.5813286\n",
      " -0.01242242 -0.6712114  -1.5601075  -0.02040786 -0.63741887 -1.649436\n",
      "  0.10472298 -0.67492735 -1.6943688  -0.0038524  -0.5184866  -1.4054193\n",
      " -0.13602734 -0.28012228 -2.081515    0.03235457 -0.44778842 -2.0856903\n",
      "  0.18652576 -0.40755612 -1.541528   -0.12085802 -0.28303108 -1.3318783\n",
      " -0.03400563 -0.25232232 -1.4002273   0.01103594 -0.270841   -1.5166532\n",
      "  0.08183178 -0.2821222  -1.3646116   0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[-0.0076, -0.1253, -0.2703,  ...,  0.0413, -0.3049, -1.3560],\n",
      "        [-0.0076, -0.1253, -0.2703,  ...,  0.0413, -0.3049, -1.3560],\n",
      "        [-0.0076, -0.1253, -0.2703,  ...,  0.0413, -0.3049, -1.3560],\n",
      "        ...,\n",
      "        [-0.0383,  0.4675, -0.0529,  ..., -0.6411,  0.9584, -0.2865],\n",
      "        [-0.0937, -0.0265,  0.5787,  ..., -0.1544,  0.6818,  0.2680],\n",
      "        [-0.0937, -0.0265,  0.5787,  ..., -0.1544,  0.6818,  0.2680]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.00755997 -0.12531357 -0.2703319   0.009091   -0.28835285 -0.70969695\n",
      " -0.00806255 -0.44171542 -1.4062178  -0.14451706 -0.49109393 -1.7353258\n",
      " -0.32442594 -0.64586174 -2.1963584  -0.22759615 -0.6991198  -1.6007388\n",
      "  0.09144472 -0.69898564 -1.3636259   0.01988102 -0.6538825  -1.4121685\n",
      "  0.01062983 -0.75125176 -1.5327023  -0.17223042 -0.5781017  -1.5102243\n",
      " -0.04627637 -0.64076257 -1.5096977  -0.05053729 -0.61721206 -1.618291\n",
      "  0.042014   -0.65692866 -1.68609    -0.04454117 -0.49985588 -1.3201082\n",
      " -0.14444341 -0.27715856 -1.8983668  -0.00391072 -0.4400983  -1.8661464\n",
      "  0.12657075 -0.40155315 -1.5200504  -0.16014224 -0.2591216  -1.2684239\n",
      " -0.02812514 -0.2509845  -1.3351114   0.01966299 -0.30124784 -1.450704\n",
      "  0.04132146 -0.3049353  -1.3559726 ]\n",
      "data: [-0.00755997 -0.12531357 -0.2703319   0.009091   -0.28835285 -0.70969695\n",
      " -0.00806255 -0.44171542 -1.4062178  -0.14451706 -0.49109393 -1.7353258\n",
      " -0.32442594 -0.64586174 -2.1963584  -0.22759615 -0.6991198  -1.6007389\n",
      "  0.09144471 -0.6989857  -1.363626    0.01988102 -0.6538825  -1.4121686\n",
      "  0.01062983 -0.75125176 -1.5327023  -0.17223042 -0.5781017  -1.5102243\n",
      " -0.04627637 -0.64076257 -1.5096977  -0.05053729 -0.61721206 -1.618291\n",
      "  0.042014   -0.65692866 -1.68609    -0.04454117 -0.49985588 -1.3201082\n",
      " -0.14444341 -0.27715856 -1.8983668  -0.00391072 -0.44009826 -1.8661464\n",
      "  0.12657075 -0.40155315 -1.5200504  -0.16014224 -0.2591216  -1.2684239\n",
      " -0.02812514 -0.2509845  -1.3351114   0.01966299 -0.30124784 -1.4507041\n",
      "  0.04132146 -0.3049353  -1.3559726   0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BB38>\n",
      "tensor([[ 0.0435, -0.1908, -0.2566,  ...,  0.0600, -0.3662, -1.3366],\n",
      "        [ 0.0435, -0.1908, -0.2566,  ...,  0.0600, -0.3662, -1.3366],\n",
      "        [ 0.0435, -0.1908, -0.2566,  ...,  0.0600, -0.3662, -1.3366],\n",
      "        ...,\n",
      "        [-0.1254,  0.5027, -0.1805,  ..., -0.6531,  0.9954, -0.4980],\n",
      "        [-0.1944, -0.0565,  0.6419,  ..., -0.2567,  0.6695,  0.3282],\n",
      "        [-0.1944, -0.0565,  0.6419,  ..., -0.2567,  0.6695,  0.3282]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 4.35033329e-02 -1.90793887e-01 -2.56612539e-01  7.16632903e-02\n",
      " -3.24056804e-01 -6.50462747e-01 -4.33474779e-03 -5.21879911e-01\n",
      " -1.43173599e+00 -1.49254411e-01 -5.80406070e-01 -1.74455190e+00\n",
      " -3.12719196e-01 -7.00015783e-01 -2.23211145e+00 -1.65224224e-01\n",
      " -7.97505856e-01 -1.62586522e+00  8.36509392e-02 -8.36772084e-01\n",
      " -1.42833209e+00  2.19672993e-02 -7.82432437e-01 -1.47441483e+00\n",
      "  7.13627785e-03 -9.19332027e-01 -1.59814143e+00 -1.15295090e-01\n",
      " -6.91387057e-01 -1.52536607e+00 -2.89357230e-02 -7.53804088e-01\n",
      " -1.50998878e+00 -3.46753150e-02 -7.28009582e-01 -1.60843277e+00\n",
      "  7.63888136e-02 -7.70775914e-01 -1.65673876e+00 -1.52012557e-02\n",
      " -5.90998709e-01 -1.34982371e+00 -1.54614031e-01 -3.61255646e-01\n",
      " -2.03950548e+00  1.42027885e-02 -5.35268426e-01 -2.03854799e+00\n",
      "  1.61348283e-01 -4.92754549e-01 -1.50475168e+00 -1.40051395e-01\n",
      " -3.53044629e-01 -1.27977467e+00 -4.24384549e-02 -3.30169618e-01\n",
      " -1.35727096e+00  5.98125160e-04 -3.59891236e-01 -1.47226262e+00\n",
      "  6.00387752e-02 -3.66225183e-01 -1.33658338e+00]\n",
      "data: [ 4.3503333e-02 -1.9079390e-01 -2.5661254e-01  7.1663290e-02\n",
      " -3.2405680e-01 -6.5046275e-01 -4.3347478e-03 -5.2187991e-01\n",
      " -1.4317360e+00 -1.4925441e-01 -5.8040607e-01 -1.7445519e+00\n",
      " -3.1271920e-01 -7.0001578e-01 -2.2321115e+00 -1.6522422e-01\n",
      " -7.9750586e-01 -1.6258652e+00  8.3650939e-02 -8.3677208e-01\n",
      " -1.4283321e+00  2.1967299e-02 -7.8243238e-01 -1.4744148e+00\n",
      "  7.1362783e-03 -9.1933203e-01 -1.5981414e+00 -1.1529508e-01\n",
      " -6.9138700e-01 -1.5253661e+00 -2.8935723e-02 -7.5380409e-01\n",
      " -1.5099887e+00 -3.4675315e-02 -7.2800958e-01 -1.6084328e+00\n",
      "  7.6388814e-02 -7.7077591e-01 -1.6567388e+00 -1.5201257e-02\n",
      " -5.9099871e-01 -1.3498237e+00 -1.5461403e-01 -3.6125565e-01\n",
      " -2.0395055e+00  1.4202788e-02 -5.3526843e-01 -2.0385480e+00\n",
      "  1.6134828e-01 -4.9275455e-01 -1.5047517e+00 -1.4005139e-01\n",
      " -3.5304463e-01 -1.2797747e+00 -4.2438455e-02 -3.3016959e-01\n",
      " -1.3572710e+00  5.9812516e-04 -3.5989124e-01 -1.4722626e+00\n",
      "  6.0038775e-02 -3.6622515e-01 -1.3365834e+00  1.0000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[ 0.0152, -0.1664, -0.2065,  ...,  0.0693, -0.3551, -1.2394],\n",
      "        [ 0.0152, -0.1664, -0.2065,  ...,  0.0693, -0.3551, -1.2394],\n",
      "        [ 0.0152, -0.1664, -0.2065,  ...,  0.0693, -0.3551, -1.2394],\n",
      "        ...,\n",
      "        [-0.0352,  0.5114, -0.1329,  ..., -0.5487,  1.0811, -0.5324],\n",
      "        [-0.0876,  0.0118,  0.6148,  ..., -0.1490,  0.6730,  0.2750],\n",
      "        [-0.0876,  0.0118,  0.6148,  ..., -0.1490,  0.6730,  0.2750]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.5235809e-02 -1.6644520e-01 -2.0649603e-01  4.4739898e-02\n",
      " -3.0019993e-01 -5.4402000e-01 -3.0535527e-02 -5.0499344e-01\n",
      " -1.3551202e+00 -1.8141119e-01 -5.6531221e-01 -1.6797731e+00\n",
      " -3.5691997e-01 -6.9980705e-01 -2.1683927e+00 -1.9904479e-01\n",
      " -7.7618027e-01 -1.5644221e+00  7.8493342e-02 -8.1728280e-01\n",
      " -1.3569460e+00  9.6478909e-03 -7.6739204e-01 -1.3978775e+00\n",
      " -8.6903572e-04 -9.0483594e-01 -1.5261219e+00 -1.3899273e-01\n",
      " -6.6674948e-01 -1.4521859e+00 -4.0165730e-02 -7.3733580e-01\n",
      " -1.4389062e+00 -3.7425667e-02 -7.1173346e-01 -1.5421319e+00\n",
      "  7.7321842e-02 -7.6483822e-01 -1.5911121e+00 -2.2687800e-02\n",
      " -5.6506222e-01 -1.2616541e+00 -1.7002803e-01 -3.3466354e-01\n",
      " -1.9779239e+00  1.3744369e-02 -5.2244329e-01 -1.9715357e+00\n",
      "  1.7512241e-01 -4.7767350e-01 -1.4200771e+00 -1.5862145e-01\n",
      " -3.2355869e-01 -1.1922851e+00 -3.9931908e-02 -3.0837312e-01\n",
      " -1.2648423e+00  6.4883679e-03 -3.4929764e-01 -1.3805354e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6.9282271e-02 -3.5508329e-01 -1.2394376e+00]\n",
      "data: [ 1.5235809e-02 -1.6644520e-01 -2.0649603e-01  4.4739898e-02\n",
      " -3.0019993e-01 -5.4402000e-01 -3.0535527e-02 -5.0499344e-01\n",
      " -1.3551202e+00 -1.8141119e-01 -5.6531221e-01 -1.6797731e+00\n",
      " -3.5691997e-01 -6.9980705e-01 -2.1683927e+00 -1.9904479e-01\n",
      " -7.7618027e-01 -1.5644221e+00  7.8493342e-02 -8.1728280e-01\n",
      " -1.3569460e+00  9.6478909e-03 -7.6739204e-01 -1.3978775e+00\n",
      " -8.6903572e-04 -9.0483594e-01 -1.5261219e+00 -1.3899273e-01\n",
      " -6.6674948e-01 -1.4521859e+00 -4.0165730e-02 -7.3733580e-01\n",
      " -1.4389062e+00 -3.7425667e-02 -7.1173346e-01 -1.5421319e+00\n",
      "  7.7321842e-02 -7.6483828e-01 -1.5911120e+00 -2.2687800e-02\n",
      " -5.6506222e-01 -1.2616541e+00 -1.7002803e-01 -3.3466354e-01\n",
      " -1.9779239e+00  1.3744368e-02 -5.2244329e-01 -1.9715357e+00\n",
      "  1.7512241e-01 -4.7767350e-01 -1.4200771e+00 -1.5862145e-01\n",
      " -3.2355869e-01 -1.1922851e+00 -3.9931908e-02 -3.0837312e-01\n",
      " -1.2648423e+00  6.4883679e-03 -3.4929764e-01 -1.3805355e+00\n",
      "  6.9282271e-02 -3.5508329e-01 -1.2394376e+00  1.1000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63EB8>\n",
      "tensor([[ 0.0165, -0.1070, -0.1724,  ...,  0.0395, -0.2961, -1.1676],\n",
      "        [ 0.0165, -0.1070, -0.1724,  ...,  0.0395, -0.2961, -1.1676],\n",
      "        [ 0.0165, -0.1070, -0.1724,  ...,  0.0395, -0.2961, -1.1676],\n",
      "        ...,\n",
      "        [-0.1246,  0.4546, -0.0918,  ..., -0.4409,  1.0126, -0.4865],\n",
      "        [-0.1023, -0.0290,  0.6449,  ..., -0.1836,  0.6545,  0.3019],\n",
      "        [-0.1023, -0.0290,  0.6449,  ..., -0.1836,  0.6545,  0.3019]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.65093727e-02 -1.07035235e-01 -1.72392473e-01  4.73191775e-02\n",
      " -2.13898405e-01 -4.54586565e-01 -9.26960781e-02 -4.50875342e-01\n",
      " -1.32664752e+00 -2.50685662e-01 -5.19104600e-01 -1.62020004e+00\n",
      " -3.99610072e-01 -6.14626646e-01 -2.13980103e+00 -1.83615625e-01\n",
      " -7.49246895e-01 -1.51641583e+00  1.80976093e-03 -8.17752361e-01\n",
      " -1.35741961e+00 -5.60066253e-02 -7.45715201e-01 -1.40399742e+00\n",
      " -6.78091943e-02 -9.11714792e-01 -1.53217983e+00 -1.37273416e-01\n",
      " -6.58588290e-01 -1.40945959e+00 -7.82177448e-02 -7.13784158e-01\n",
      " -1.38174748e+00 -8.60644132e-02 -6.75500333e-01 -1.46442688e+00\n",
      "  4.81721908e-02 -7.16045558e-01 -1.48113263e+00 -4.58912626e-02\n",
      " -5.40043831e-01 -1.24615836e+00 -2.11756229e-01 -3.02114010e-01\n",
      " -2.00723386e+00 -2.19610855e-02 -4.82012212e-01 -2.03080177e+00\n",
      "  1.53778940e-01 -4.36542213e-01 -1.34553671e+00 -1.77590102e-01\n",
      " -3.08834225e-01 -1.16462576e+00 -9.87019837e-02 -2.78570652e-01\n",
      " -1.24859560e+00 -6.76481426e-02 -2.86349535e-01 -1.35976851e+00\n",
      "  3.95378694e-02 -2.96075255e-01 -1.16764319e+00]\n",
      "data: [ 1.65093727e-02 -1.07035235e-01 -1.72392458e-01  4.73191775e-02\n",
      " -2.13898405e-01 -4.54586565e-01 -9.26960781e-02 -4.50875372e-01\n",
      " -1.32664752e+00 -2.50685662e-01 -5.19104600e-01 -1.62020004e+00\n",
      " -3.99610072e-01 -6.14626646e-01 -2.13980103e+00 -1.83615625e-01\n",
      " -7.49246895e-01 -1.51641583e+00  1.80976093e-03 -8.17752361e-01\n",
      " -1.35741961e+00 -5.60066253e-02 -7.45715201e-01 -1.40399754e+00\n",
      " -6.78091943e-02 -9.11714792e-01 -1.53217983e+00 -1.37273416e-01\n",
      " -6.58588231e-01 -1.40945959e+00 -7.82177448e-02 -7.13784158e-01\n",
      " -1.38174748e+00 -8.60644132e-02 -6.75500333e-01 -1.46442688e+00\n",
      "  4.81721908e-02 -7.16045558e-01 -1.48113263e+00 -4.58912626e-02\n",
      " -5.40043831e-01 -1.24615836e+00 -2.11756229e-01 -3.02114010e-01\n",
      " -2.00723386e+00 -2.19610855e-02 -4.82012212e-01 -2.03080177e+00\n",
      "  1.53778940e-01 -4.36542213e-01 -1.34553671e+00 -1.77590102e-01\n",
      " -3.08834225e-01 -1.16462576e+00 -9.87019837e-02 -2.78570652e-01\n",
      " -1.24859560e+00 -6.76481426e-02 -2.86349535e-01 -1.35976851e+00\n",
      "  3.95378694e-02 -2.96075255e-01 -1.16764319e+00  1.19999997e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BB38>\n",
      "tensor([[-0.0482, -0.0218, -0.2074,  ...,  0.0029, -0.2096, -1.1828],\n",
      "        [-0.0482, -0.0218, -0.2074,  ...,  0.0029, -0.2096, -1.1828],\n",
      "        [-0.0482, -0.0218, -0.2074,  ...,  0.0029, -0.2096, -1.1828],\n",
      "        ...,\n",
      "        [-0.1724,  0.3375,  0.0217,  ..., -0.6419,  0.9176, -0.3596],\n",
      "        [-0.0982, -0.0836,  0.5880,  ..., -0.2317,  0.6133,  0.2527],\n",
      "        [-0.0982, -0.0836,  0.5880,  ..., -0.2317,  0.6133,  0.2527]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.04816314 -0.02179962 -0.2073713  -0.0228404  -0.13246174 -0.50693274\n",
      " -0.1518175  -0.35342765 -1.3421276  -0.3053825  -0.41482428 -1.6393433\n",
      " -0.46539903 -0.5203273  -2.1346924  -0.25282717 -0.6532998  -1.5125501\n",
      " -0.04459475 -0.7081727  -1.3333552  -0.09569831 -0.6373086  -1.381233\n",
      " -0.09363155 -0.7941244  -1.511395   -0.20309225 -0.55874974 -1.4079821\n",
      " -0.12924957 -0.6135582  -1.3863466  -0.1208026  -0.57616735 -1.4739349\n",
      "  0.03067198 -0.61485445 -1.5038712  -0.10579505 -0.45099837 -1.237632\n",
      " -0.2603377  -0.20909014 -1.995192   -0.05944382 -0.38710526 -2.011543\n",
      "  0.13211666 -0.34280562 -1.360043   -0.23446372 -0.21607678 -1.1586622\n",
      " -0.14706251 -0.18710834 -1.2467139  -0.10553345 -0.19786294 -1.363353\n",
      "  0.00286939 -0.2096477  -1.1828227 ]\n",
      "data: [-0.04816314 -0.02179962 -0.2073713  -0.0228404  -0.13246174 -0.50693274\n",
      " -0.1518175  -0.35342765 -1.3421276  -0.3053825  -0.4148243  -1.6393433\n",
      " -0.46539903 -0.5203273  -2.1346924  -0.25282717 -0.6532998  -1.51255\n",
      " -0.04459475 -0.7081727  -1.3333553  -0.09569831 -0.6373086  -1.3812329\n",
      " -0.09363155 -0.7941244  -1.511395   -0.20309225 -0.55874974 -1.4079822\n",
      " -0.12924957 -0.6135582  -1.3863466  -0.1208026  -0.57616735 -1.4739349\n",
      "  0.03067198 -0.61485445 -1.5038712  -0.10579505 -0.4509984  -1.237632\n",
      " -0.2603377  -0.20909014 -1.995192   -0.05944382 -0.38710526 -2.011543\n",
      "  0.13211666 -0.34280562 -1.360043   -0.23446374 -0.21607678 -1.1586622\n",
      " -0.14706251 -0.18710834 -1.2467139  -0.10553345 -0.19786292 -1.363353\n",
      "  0.00286939 -0.2096477  -1.1828227   0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[-0.0146, -0.0819, -0.1982,  ..., -0.0029, -0.2397, -1.3138],\n",
      "        [-0.0146, -0.0819, -0.1982,  ..., -0.0029, -0.2397, -1.3138],\n",
      "        [-0.0146, -0.0819, -0.1982,  ..., -0.0029, -0.2397, -1.3138],\n",
      "        ...,\n",
      "        [-0.2632,  0.3078, -0.1764,  ..., -0.7532,  0.7876, -0.3882],\n",
      "        [-0.1799, -0.1230,  0.5423,  ..., -0.2775,  0.6258,  0.2573],\n",
      "        [-0.1799, -0.1230,  0.5423,  ..., -0.2775,  0.6258,  0.2573]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-1.45899765e-02 -8.19381177e-02 -1.98193699e-01 -6.92602247e-04\n",
      " -2.40073562e-01 -6.62375391e-01 -5.05674854e-02 -3.91505837e-01\n",
      " -1.34681034e+00 -1.92511976e-01 -4.43890959e-01 -1.65915298e+00\n",
      " -3.81346166e-01 -5.74406385e-01 -2.11673856e+00 -2.38766342e-01\n",
      " -6.65491462e-01 -1.50893617e+00  2.88071185e-02 -6.68588161e-01\n",
      " -1.28616834e+00 -1.83635950e-02 -6.15795135e-01 -1.33779311e+00\n",
      " -1.73751712e-02 -7.18973756e-01 -1.45446467e+00 -1.93549454e-01\n",
      " -5.47867179e-01 -1.43021798e+00 -8.41310918e-02 -6.03685975e-01\n",
      " -1.41952229e+00 -8.06363821e-02 -5.76231241e-01 -1.53197932e+00\n",
      "  5.14928848e-02 -5.99272132e-01 -1.60886431e+00 -9.31008533e-02\n",
      " -4.74570632e-01 -1.25151491e+00 -1.81904659e-01 -2.47922897e-01\n",
      " -1.81059194e+00 -3.87657061e-02 -3.89766276e-01 -1.79281259e+00\n",
      "  1.12530440e-01 -3.57577533e-01 -1.45764136e+00 -1.96796790e-01\n",
      " -2.26743072e-01 -1.20030856e+00 -1.03229418e-01 -2.06466883e-01\n",
      " -1.28124833e+00 -4.70414460e-02 -2.33597636e-01 -1.40569115e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -2.87459791e-03 -2.39719614e-01 -1.31380105e+00]\n",
      "data: [-1.45899765e-02 -8.19381177e-02 -1.98193699e-01 -6.92602247e-04\n",
      " -2.40073562e-01 -6.62375391e-01 -5.05674854e-02 -3.91505837e-01\n",
      " -1.34681034e+00 -1.92511976e-01 -4.43890959e-01 -1.65915298e+00\n",
      " -3.81346166e-01 -5.74406385e-01 -2.11673856e+00 -2.38766342e-01\n",
      " -6.65491462e-01 -1.50893617e+00  2.88071185e-02 -6.68588161e-01\n",
      " -1.28616834e+00 -1.83635950e-02 -6.15795135e-01 -1.33779311e+00\n",
      " -1.73751712e-02 -7.18973756e-01 -1.45446467e+00 -1.93549454e-01\n",
      " -5.47867179e-01 -1.43021810e+00 -8.41310918e-02 -6.03685975e-01\n",
      " -1.41952229e+00 -8.06363896e-02 -5.76231241e-01 -1.53197932e+00\n",
      "  5.14928848e-02 -5.99272132e-01 -1.60886431e+00 -9.31008533e-02\n",
      " -4.74570632e-01 -1.25151491e+00 -1.81904659e-01 -2.47922897e-01\n",
      " -1.81059194e+00 -3.87657061e-02 -3.89766276e-01 -1.79281271e+00\n",
      "  1.12530440e-01 -3.57577503e-01 -1.45764124e+00 -1.96796805e-01\n",
      " -2.26743072e-01 -1.20030856e+00 -1.03229418e-01 -2.06466883e-01\n",
      " -1.28124833e+00 -4.70414460e-02 -2.33597636e-01 -1.40569127e+00\n",
      " -2.87459791e-03 -2.39719614e-01 -1.31380117e+00  1.40000001e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0396, -0.1417, -0.2676,  ...,  0.0387, -0.3173, -1.3228],\n",
      "        [ 0.0396, -0.1417, -0.2676,  ...,  0.0387, -0.3173, -1.3228],\n",
      "        [ 0.0396, -0.1417, -0.2676,  ...,  0.0387, -0.3173, -1.3228],\n",
      "        ...,\n",
      "        [-0.2229,  0.4597, -0.1597,  ..., -0.7784,  0.9868, -0.4799],\n",
      "        [-0.1329, -0.0163,  0.6903,  ..., -0.2288,  0.7648,  0.3385],\n",
      "        [-0.1329, -0.0163,  0.6903,  ..., -0.2288,  0.7648,  0.3385]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03961344 -0.14167991 -0.26759464  0.07063653 -0.25900698 -0.6478001\n",
      " -0.0455507  -0.4557998  -1.4399999  -0.19467886 -0.518994   -1.7337723\n",
      " -0.3444252  -0.60897267 -2.2457643  -0.15453056 -0.7587272  -1.6106062\n",
      "  0.02328297 -0.8030784  -1.4434884  -0.03020714 -0.73468816 -1.5034572\n",
      " -0.04940262 -0.88622403 -1.6270552  -0.1175901  -0.6698388  -1.5217685\n",
      " -0.05804252 -0.7169578  -1.4997818  -0.08290258 -0.68372667 -1.5923218\n",
      "  0.04428293 -0.70987546 -1.6200515  -0.04242068 -0.5662559  -1.3578038\n",
      " -0.17387167 -0.3341304  -2.044808   -0.01692499 -0.48810232 -2.0652108\n",
      "  0.13558155 -0.457386   -1.4836226  -0.14693758 -0.33922184 -1.2861544\n",
      " -0.08568653 -0.30817187 -1.3695915  -0.05437109 -0.30583033 -1.4873075\n",
      "  0.03871151 -0.31727427 -1.3227668 ]\n",
      "data: [ 0.03961344 -0.14167991 -0.26759464  0.07063653 -0.25900698 -0.6478001\n",
      " -0.04555069 -0.4557998  -1.44       -0.19467886 -0.518994   -1.7337723\n",
      " -0.3444252  -0.60897267 -2.2457643  -0.15453056 -0.7587272  -1.6106062\n",
      "  0.02328298 -0.8030784  -1.4434884  -0.03020714 -0.73468816 -1.5034572\n",
      " -0.04940262 -0.88622403 -1.6270552  -0.1175901  -0.6698388  -1.5217685\n",
      " -0.05804252 -0.7169578  -1.4997818  -0.08290258 -0.68372667 -1.5923218\n",
      "  0.04428293 -0.70987546 -1.6200516  -0.04242068 -0.5662559  -1.3578038\n",
      " -0.17387167 -0.3341304  -2.044808   -0.01692499 -0.48810232 -2.0652108\n",
      "  0.13558155 -0.457386   -1.4836226  -0.14693758 -0.33922184 -1.2861543\n",
      " -0.08568653 -0.30817187 -1.3695915  -0.05437109 -0.30583033 -1.4873075\n",
      "  0.03871151 -0.31727427 -1.3227668   0.15      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0132, -0.0812, -0.1919,  ...,  0.0842, -0.2817, -1.1950],\n",
      "        [ 0.0132, -0.0812, -0.1919,  ...,  0.0842, -0.2817, -1.1950],\n",
      "        [ 0.0132, -0.0812, -0.1919,  ...,  0.0842, -0.2817, -1.1950],\n",
      "        ...,\n",
      "        [-0.1393,  0.3980, -0.0867,  ..., -0.8104,  0.9134, -0.3708],\n",
      "        [-0.1284, -0.1013,  0.5660,  ..., -0.2306,  0.5752,  0.2230],\n",
      "        [-0.1284, -0.1013,  0.5660,  ..., -0.2306,  0.5752,  0.2230]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01315248 -0.08121764 -0.19194737  0.04029853 -0.20589449 -0.5196885\n",
      " -0.04565675 -0.4070153  -1.3165398  -0.1918777  -0.46578255 -1.6296818\n",
      " -0.3588831  -0.5932627  -2.1115384  -0.19010304 -0.69308436 -1.5077069\n",
      "  0.06058419 -0.7365037  -1.3298655  -0.00366163 -0.6811825  -1.3746972\n",
      " -0.00266008 -0.82589674 -1.4992568  -0.13067444 -0.5921018  -1.4020522\n",
      " -0.03855221 -0.65756047 -1.3892026  -0.03666729 -0.6332059  -1.4871545\n",
      "  0.08501951 -0.6816573  -1.5285239  -0.02160274 -0.49310744 -1.21942\n",
      " -0.16469607 -0.2627068  -1.9527915   0.02177212 -0.44691283 -1.9530802\n",
      "  0.18663916 -0.40798482 -1.3697579  -0.14790457 -0.25771058 -1.150662\n",
      " -0.03778933 -0.242365   -1.2317367   0.0072339  -0.27273372 -1.347966\n",
      "  0.08418373 -0.28166288 -1.1950419 ]\n",
      "data: [ 0.01315248 -0.08121764 -0.19194737  0.04029853 -0.20589449 -0.5196885\n",
      " -0.04565675 -0.4070153  -1.3165398  -0.1918777  -0.46578255 -1.6296818\n",
      " -0.35888308 -0.5932627  -2.1115384  -0.19010304 -0.69308436 -1.5077069\n",
      "  0.06058419 -0.7365038  -1.3298655  -0.00366163 -0.6811825  -1.3746972\n",
      " -0.00266008 -0.82589674 -1.4992568  -0.13067444 -0.5921018  -1.4020522\n",
      " -0.03855221 -0.6575605  -1.3892026  -0.03666729 -0.6332059  -1.4871545\n",
      "  0.08501951 -0.6816573  -1.5285239  -0.02160274 -0.49310744 -1.21942\n",
      " -0.16469607 -0.2627068  -1.9527915   0.02177212 -0.44691285 -1.9530802\n",
      "  0.18663916 -0.40798482 -1.3697579  -0.14790457 -0.25771058 -1.150662\n",
      " -0.03778933 -0.242365   -1.2317367   0.0072339  -0.27273372 -1.347966\n",
      "  0.08418373 -0.28166288 -1.1950419   0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 8.5224e-04, -7.8399e-02, -1.9320e-01,  ...,  4.0403e-02,\n",
      "         -2.7621e-01, -1.1826e+00],\n",
      "        [ 8.5224e-04, -7.8399e-02, -1.9320e-01,  ...,  4.0403e-02,\n",
      "         -2.7621e-01, -1.1826e+00],\n",
      "        [ 8.5224e-04, -7.8399e-02, -1.9320e-01,  ...,  4.0403e-02,\n",
      "         -2.7621e-01, -1.1826e+00],\n",
      "        ...,\n",
      "        [-1.8277e-01,  3.6679e-01, -1.2091e-01,  ..., -7.2061e-01,\n",
      "          8.7814e-01, -4.0790e-01],\n",
      "        [-1.3722e-01, -5.4070e-02,  5.8343e-01,  ..., -2.2816e-01,\n",
      "          7.0533e-01,  2.0072e-01],\n",
      "        [-1.3722e-01, -5.4070e-02,  5.8343e-01,  ..., -2.2816e-01,\n",
      "          7.0533e-01,  2.0072e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 8.5223932e-04 -7.8399010e-02 -1.9320168e-01  3.6879908e-02\n",
      " -1.7653500e-01 -5.0008857e-01 -1.1148516e-01 -4.0650409e-01\n",
      " -1.3577313e+00 -2.6347265e-01 -4.7477412e-01 -1.6454487e+00\n",
      " -4.0738407e-01 -5.6166428e-01 -2.1590123e+00 -1.8375359e-01\n",
      " -7.1683651e-01 -1.5239248e+00 -2.1448120e-02 -7.8565133e-01\n",
      " -1.3721242e+00 -7.3621646e-02 -7.0900983e-01 -1.4266205e+00\n",
      " -8.7982193e-02 -8.8519847e-01 -1.5535216e+00 -1.3972874e-01\n",
      " -6.3637620e-01 -1.4215271e+00 -8.9248650e-02 -6.8844700e-01\n",
      " -1.3934653e+00 -1.0541472e-01 -6.5337270e-01 -1.4745390e+00\n",
      "  3.5065338e-02 -6.8701100e-01 -1.4892888e+00 -6.1380066e-02\n",
      " -5.2423489e-01 -1.2591884e+00 -2.2168925e-01 -2.8321370e-01\n",
      " -2.0500894e+00 -3.0836962e-02 -4.5961726e-01 -2.0799489e+00\n",
      "  1.4321223e-01 -4.2153502e-01 -1.3546476e+00 -1.7865212e-01\n",
      " -2.9967213e-01 -1.1769586e+00 -1.1424990e-01 -2.6668382e-01\n",
      " -1.2690487e+00 -7.9283625e-02 -2.6309127e-01 -1.3835750e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4.0402837e-02 -2.7621102e-01 -1.1826165e+00]\n",
      "data: [ 8.5223926e-04 -7.8399010e-02 -1.9320168e-01  3.6879908e-02\n",
      " -1.7653500e-01 -5.0008857e-01 -1.1148515e-01 -4.0650409e-01\n",
      " -1.3577313e+00 -2.6347265e-01 -4.7477412e-01 -1.6454486e+00\n",
      " -4.0738407e-01 -5.6166428e-01 -2.1590123e+00 -1.8375358e-01\n",
      " -7.1683657e-01 -1.5239248e+00 -2.1448120e-02 -7.8565133e-01\n",
      " -1.3721242e+00 -7.3621646e-02 -7.0900989e-01 -1.4266205e+00\n",
      " -8.7982200e-02 -8.8519841e-01 -1.5535216e+00 -1.3972874e-01\n",
      " -6.3637620e-01 -1.4215271e+00 -8.9248650e-02 -6.8844694e-01\n",
      " -1.3934653e+00 -1.0541472e-01 -6.5337270e-01 -1.4745390e+00\n",
      "  3.5065338e-02 -6.8701100e-01 -1.4892888e+00 -6.1380066e-02\n",
      " -5.2423489e-01 -1.2591884e+00 -2.2168927e-01 -2.8321370e-01\n",
      " -2.0500894e+00 -3.0836962e-02 -4.5961726e-01 -2.0799489e+00\n",
      "  1.4321223e-01 -4.2153504e-01 -1.3546476e+00 -1.7865211e-01\n",
      " -2.9967213e-01 -1.1769586e+00 -1.1424990e-01 -2.6668382e-01\n",
      " -1.2690487e+00 -7.9283625e-02 -2.6309127e-01 -1.3835750e+00\n",
      "  4.0402837e-02 -2.7621102e-01 -1.1826165e+00  1.7000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[-0.0197,  0.0135, -0.1869,  ...,  0.0252, -0.1740, -1.1828],\n",
      "        [-0.0197,  0.0135, -0.1869,  ...,  0.0252, -0.1740, -1.1828],\n",
      "        [-0.0197,  0.0135, -0.1869,  ...,  0.0252, -0.1740, -1.1828],\n",
      "        ...,\n",
      "        [-0.1804,  0.2990, -0.0203,  ..., -0.7587,  0.8506, -0.3621],\n",
      "        [-0.1235, -0.1510,  0.5574,  ..., -0.2460,  0.5683,  0.2086],\n",
      "        [-0.1235, -0.1510,  0.5574,  ..., -0.2460,  0.5683,  0.2086]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-1.97181888e-02  1.34532396e-02 -1.86891735e-01  1.24700740e-03\n",
      " -1.04115382e-01 -5.11500239e-01 -1.23163290e-01 -3.16214889e-01\n",
      " -1.32735085e+00 -2.76359230e-01 -3.78287882e-01 -1.62636709e+00\n",
      " -4.44514483e-01 -4.82384026e-01 -2.11736655e+00 -2.23870993e-01\n",
      " -6.15915358e-01 -1.49511373e+00 -2.12603807e-02 -6.64759934e-01\n",
      " -1.31334519e+00 -6.84422255e-02 -5.94784737e-01 -1.36502230e+00\n",
      " -6.45759404e-02 -7.49602973e-01 -1.49255288e+00 -1.76485345e-01\n",
      " -5.18425882e-01 -1.39548671e+00 -1.01313189e-01 -5.72820485e-01\n",
      " -1.37006664e+00 -9.71903130e-02 -5.39695024e-01 -1.46404386e+00\n",
      "  5.81914634e-02 -5.71029782e-01 -1.49910414e+00 -8.39058384e-02\n",
      " -4.15894389e-01 -1.22457957e+00 -2.27079615e-01 -1.79943800e-01\n",
      " -1.95825291e+00 -3.64166647e-02 -3.49255443e-01 -1.97321141e+00\n",
      "  1.53153569e-01 -3.10163617e-01 -1.35252333e+00 -2.03864872e-01\n",
      " -1.79986760e-01 -1.14958167e+00 -1.24493316e-01 -1.53269961e-01\n",
      " -1.23662198e+00 -8.12588930e-02 -1.61399275e-01 -1.35600102e+00\n",
      "  2.51779184e-02 -1.74044117e-01 -1.18277335e+00]\n",
      "data: [-1.97181888e-02  1.34532396e-02 -1.86891735e-01  1.24700740e-03\n",
      " -1.04115382e-01 -5.11500239e-01 -1.23163290e-01 -3.16214889e-01\n",
      " -1.32735097e+00 -2.76359230e-01 -3.78287882e-01 -1.62636709e+00\n",
      " -4.44514453e-01 -4.82384026e-01 -2.11736655e+00 -2.23871008e-01\n",
      " -6.15915358e-01 -1.49511373e+00 -2.12603807e-02 -6.64759874e-01\n",
      " -1.31334519e+00 -6.84422255e-02 -5.94784737e-01 -1.36502230e+00\n",
      " -6.45759404e-02 -7.49602973e-01 -1.49255300e+00 -1.76485345e-01\n",
      " -5.18425882e-01 -1.39548671e+00 -1.01313189e-01 -5.72820485e-01\n",
      " -1.37006664e+00 -9.71903130e-02 -5.39695024e-01 -1.46404386e+00\n",
      "  5.81914634e-02 -5.71029782e-01 -1.49910414e+00 -8.39058384e-02\n",
      " -4.15894389e-01 -1.22457957e+00 -2.27079615e-01 -1.79943815e-01\n",
      " -1.95825291e+00 -3.64166647e-02 -3.49255443e-01 -1.97321141e+00\n",
      "  1.53153569e-01 -3.10163617e-01 -1.35252333e+00 -2.03864872e-01\n",
      " -1.79986760e-01 -1.14958167e+00 -1.24493316e-01 -1.53269961e-01\n",
      " -1.23662198e+00 -8.12588856e-02 -1.61399275e-01 -1.35600102e+00\n",
      "  2.51779184e-02 -1.74044117e-01 -1.18277335e+00  1.80000007e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[ 1.2829e-03, -1.3294e-01, -2.1069e-01,  ...,  2.9892e-02,\n",
      "         -2.8742e-01, -1.3381e+00],\n",
      "        [ 1.2829e-03, -1.3294e-01, -2.1069e-01,  ...,  2.9892e-02,\n",
      "         -2.8742e-01, -1.3381e+00],\n",
      "        [ 1.2829e-03, -1.3294e-01, -2.1069e-01,  ...,  2.9892e-02,\n",
      "         -2.8742e-01, -1.3381e+00],\n",
      "        ...,\n",
      "        [-2.5032e-01,  3.6200e-01, -1.9690e-01,  ..., -7.4014e-01,\n",
      "          7.8549e-01, -3.5198e-01],\n",
      "        [-1.7741e-01, -8.3254e-02,  5.2805e-01,  ..., -2.6470e-01,\n",
      "          6.8291e-01,  2.2540e-01],\n",
      "        [-1.7741e-01, -8.3254e-02,  5.2805e-01,  ..., -2.6470e-01,\n",
      "          6.8291e-01,  2.2540e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.2829043e-03 -1.3294348e-01 -2.1068799e-01  1.6536672e-02\n",
      " -3.0102080e-01 -6.9516468e-01 -2.1230519e-02 -4.4273826e-01\n",
      " -1.3630860e+00 -1.6029474e-01 -4.9360102e-01 -1.6738399e+00\n",
      " -3.4115446e-01 -6.3448483e-01 -2.1316009e+00 -2.2438352e-01\n",
      " -7.0813394e-01 -1.5216587e+00  6.4589605e-02 -6.9967598e-01\n",
      " -1.2748746e+00  1.1334240e-02 -6.4505929e-01 -1.3271581e+00\n",
      "  3.4293383e-03 -7.3442352e-01 -1.4445649e+00 -1.7913209e-01\n",
      " -5.8976829e-01 -1.4502238e+00 -5.6489773e-02 -6.4290625e-01\n",
      " -1.4416200e+00 -5.7853207e-02 -6.0762918e-01 -1.5488291e+00\n",
      "  6.2204063e-02 -6.3231480e-01 -1.6233438e+00 -6.6937976e-02\n",
      " -5.1932418e-01 -1.2718875e+00 -1.4100999e-01 -2.9067746e-01\n",
      " -1.7833563e+00 -9.7936913e-03 -4.2923588e-01 -1.7566668e+00\n",
      "  1.3166581e-01 -3.9459568e-01 -1.4828963e+00 -1.6790545e-01\n",
      " -2.7371228e-01 -1.2245429e+00 -6.0623646e-02 -2.5358951e-01\n",
      " -1.3040155e+00 -4.9864203e-03 -2.8512239e-01 -1.4279411e+00\n",
      "  2.9891960e-02 -2.8742325e-01 -1.3380738e+00]\n",
      "data: [ 1.2829043e-03 -1.3294348e-01 -2.1068799e-01  1.6536672e-02\n",
      " -3.0102080e-01 -6.9516462e-01 -2.1230519e-02 -4.4273826e-01\n",
      " -1.3630860e+00 -1.6029474e-01 -4.9360102e-01 -1.6738399e+00\n",
      " -3.4115446e-01 -6.3448483e-01 -2.1316009e+00 -2.2438353e-01\n",
      " -7.0813394e-01 -1.5216587e+00  6.4589605e-02 -6.9967598e-01\n",
      " -1.2748746e+00  1.1334240e-02 -6.4505929e-01 -1.3271581e+00\n",
      "  3.4293383e-03 -7.3442352e-01 -1.4445649e+00 -1.7913207e-01\n",
      " -5.8976829e-01 -1.4502238e+00 -5.6489773e-02 -6.4290625e-01\n",
      " -1.4416200e+00 -5.7853207e-02 -6.0762918e-01 -1.5488291e+00\n",
      "  6.2204067e-02 -6.3231480e-01 -1.6233438e+00 -6.6937976e-02\n",
      " -5.1932418e-01 -1.2718875e+00 -1.4100999e-01 -2.9067746e-01\n",
      " -1.7833563e+00 -9.7936913e-03 -4.2923588e-01 -1.7566667e+00\n",
      "  1.3166581e-01 -3.9459568e-01 -1.4828963e+00 -1.6790545e-01\n",
      " -2.7371228e-01 -1.2245429e+00 -6.0623646e-02 -2.5358951e-01\n",
      " -1.3040155e+00 -4.9864203e-03 -2.8512239e-01 -1.4279411e+00\n",
      "  2.9891960e-02 -2.8742325e-01 -1.3380738e+00  1.9000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0422, -0.1444, -0.2736,  ...,  0.0638, -0.3182, -1.3356],\n",
      "        [ 0.0422, -0.1444, -0.2736,  ...,  0.0638, -0.3182, -1.3356],\n",
      "        [ 0.0422, -0.1444, -0.2736,  ...,  0.0638, -0.3182, -1.3356],\n",
      "        ...,\n",
      "        [-0.1383,  0.5005, -0.1485,  ..., -0.6849,  1.0352, -0.5008],\n",
      "        [-0.1990, -0.0693,  0.6428,  ..., -0.3057,  0.6771,  0.2816],\n",
      "        [-0.1990, -0.0693,  0.6428,  ..., -0.3057,  0.6771,  0.2816]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04218609 -0.14441042 -0.27355197  0.07454577 -0.27236432 -0.65258443\n",
      " -0.01590193 -0.47786817 -1.4521102  -0.16181186 -0.53901064 -1.7574829\n",
      " -0.31774026 -0.65102625 -2.253364   -0.16292511 -0.7556467  -1.6413183\n",
      "  0.07382531 -0.7992718  -1.4440234   0.0150269  -0.7415458  -1.4889755\n",
      " -0.0037184  -0.88245845 -1.6139505  -0.1143337  -0.65350235 -1.5407908\n",
      " -0.03194349 -0.7143899  -1.5201077  -0.03917176 -0.6832266  -1.6121508\n",
      "  0.07707128 -0.7277843  -1.655567   -0.01647487 -0.5488543  -1.368468\n",
      " -0.15923454 -0.31571895 -2.0674634   0.0140106  -0.4906502  -2.0718057\n",
      "  0.16517965 -0.4464669  -1.508409   -0.14093111 -0.3121518  -1.2940348\n",
      " -0.04668091 -0.2847489  -1.3689501  -0.00398026 -0.309957   -1.4838266\n",
      "  0.06383391 -0.31817335 -1.3356178 ]\n",
      "data: [ 0.04218609 -0.14441042 -0.27355197  0.07454577 -0.27236432 -0.65258443\n",
      " -0.01590193 -0.47786817 -1.4521102  -0.16181187 -0.53901064 -1.7574829\n",
      " -0.31774026 -0.65102625 -2.253364   -0.16292511 -0.75564665 -1.6413183\n",
      "  0.07382531 -0.7992718  -1.4440235   0.0150269  -0.7415458  -1.4889755\n",
      " -0.0037184  -0.88245845 -1.6139505  -0.1143337  -0.65350235 -1.5407909\n",
      " -0.03194349 -0.71439    -1.5201077  -0.03917176 -0.68322664 -1.6121507\n",
      "  0.07707128 -0.7277843  -1.655567   -0.01647487 -0.5488543  -1.368468\n",
      " -0.15923454 -0.31571895 -2.0674634   0.0140106  -0.4906502  -2.0718057\n",
      "  0.16517965 -0.4464669  -1.508409   -0.14093111 -0.3121518  -1.2940348\n",
      " -0.04668091 -0.2847489  -1.3689502  -0.00398026 -0.309957   -1.4838266\n",
      "  0.06383391 -0.31817335 -1.3356178   0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F208>\n",
      "tensor([[-0.0061, -0.1097, -0.2057,  ...,  0.0734, -0.3060, -1.2508],\n",
      "        [-0.0061, -0.1097, -0.2057,  ...,  0.0734, -0.3060, -1.2508],\n",
      "        [-0.0061, -0.1097, -0.2057,  ...,  0.0734, -0.3060, -1.2508],\n",
      "        ...,\n",
      "        [-0.1132,  0.4721, -0.1400,  ..., -0.7650,  0.9895, -0.4209],\n",
      "        [-0.1273, -0.0541,  0.5891,  ..., -0.2075,  0.6363,  0.2230],\n",
      "        [-0.1273, -0.0541,  0.5891,  ..., -0.2075,  0.6363,  0.2230]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.00605021 -0.10968094 -0.20574751  0.01544496 -0.2557404  -0.5837827\n",
      " -0.03246776 -0.43599045 -1.3406085  -0.17678374 -0.49225786 -1.6689837\n",
      " -0.36280912 -0.64262843 -2.132554   -0.22440386 -0.7009398  -1.5416709\n",
      "  0.08027011 -0.7262405  -1.32963     0.0154499  -0.6806866  -1.3698306\n",
      "  0.02081069 -0.80092347 -1.4915838  -0.15876119 -0.5849569  -1.435209\n",
      " -0.04120638 -0.65854573 -1.426724   -0.02886239 -0.63983107 -1.5357238\n",
      "  0.08802997 -0.6886368  -1.6024752  -0.03516955 -0.5028051  -1.238115\n",
      " -0.15620506 -0.2751658  -1.8944892   0.0179093  -0.45653835 -1.872629\n",
      "  0.17790353 -0.41718033 -1.4247476  -0.16343036 -0.25634795 -1.1772077\n",
      " -0.0318694  -0.24793243 -1.249069    0.0270271  -0.2993979  -1.3649449\n",
      "  0.07337331 -0.30596602 -1.250823  ]\n",
      "data: [ 4.990e+00  7.000e-01 -7.940e+00  5.070e+00  5.100e-01 -7.210e+00\n",
      "  5.130e+00  3.800e-01 -6.700e+00  5.590e+00  0.000e+00 -2.430e+00\n",
      "  5.410e+00  0.000e+00 -2.180e+00  5.100e+00  3.500e-01 -6.700e+00\n",
      "  5.690e+00 -9.000e-02 -2.570e+00  5.530e+00 -1.000e-02 -2.230e+00\n",
      "  5.420e+00  2.000e-02 -2.010e+00  5.750e+00  2.200e-01 -2.410e+00\n",
      "  5.580e+00  8.000e-02 -2.050e+00  5.530e+00  1.600e-01 -1.660e+00\n",
      "  7.870e+00 -1.010e+00  1.311e+01  5.730e+00  2.400e-01 -1.940e+00\n",
      "  7.880e+00 -5.600e-01  1.228e+01  5.550e+00  2.100e-01 -1.660e+00\n",
      "  7.820e+00 -1.050e+00  1.298e+01  5.830e+00  5.400e-01 -1.460e+00\n",
      "  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00\n",
      "  7.880e+00 -5.600e-01  1.228e+01  0.000e+00]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[-0.1070,  0.0335, -0.2282,  ..., -0.6499, -0.1895, -1.0337],\n",
      "        [-0.1070,  0.0335, -0.2282,  ..., -0.6499, -0.1895, -1.0337],\n",
      "        [-0.1070,  0.0335, -0.2282,  ..., -0.6499, -0.1895, -1.0337],\n",
      "        ...,\n",
      "        [ 0.7558,  0.3770,  0.3194,  ...,  0.7572,  0.4594,  1.4537],\n",
      "        [ 0.7780, -0.0845,  0.0029,  ...,  1.4096,  0.4201, -0.5211],\n",
      "        [ 0.7780, -0.0845,  0.0029,  ...,  1.4096,  0.4201, -0.5211]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.10695712  0.03345665 -0.22819631 -0.32735723 -0.13462637 -0.7280887\n",
      " -0.3693644  -0.21939017 -0.9233306  -0.51104903 -0.33141372 -0.98685217\n",
      " -0.6116402  -0.38894945 -1.1375821  -0.5169359  -0.24898851 -1.2827344\n",
      " -0.49922743 -0.31723747 -1.0560925  -0.6071109  -0.4657171  -1.0546918\n",
      " -0.6859132  -0.43486145 -1.1231503  -0.54057384 -0.1560747  -1.2853764\n",
      " -0.6412467  -0.2558036  -1.3148772  -0.6810209  -0.33235934 -1.3416147\n",
      " -0.7391912  -0.42926198 -1.2880805  -0.50793576 -0.07685468 -1.254671\n",
      " -0.6023536  -0.2035326  -0.97150767 -0.6957198  -0.23280558 -0.9626942\n",
      " -0.6824906  -0.32326478 -1.1567602  -0.5148235   0.03249151 -1.1298449\n",
      " -0.5267403  -0.05914073 -1.061424   -0.6134176  -0.12518632 -1.0343738\n",
      " -0.649928   -0.18948953 -1.0336742 ]\n",
      "init: [-0.10695712  0.03345665 -0.22819631 -0.32735723 -0.13462637 -0.7280887\n",
      " -0.3693644  -0.21939017 -0.9233306  -0.51104903 -0.33141372 -0.98685217\n",
      " -0.6116402  -0.38894945 -1.1375821  -0.5169359  -0.24898851 -1.2827344\n",
      " -0.49922743 -0.31723747 -1.0560925  -0.6071109  -0.4657171  -1.0546918\n",
      " -0.6859132  -0.43486145 -1.1231503  -0.54057384 -0.1560747  -1.2853764\n",
      " -0.6412467  -0.2558036  -1.3148772  -0.6810209  -0.33235934 -1.3416147\n",
      " -0.7391912  -0.42926198 -1.2880805  -0.50793576 -0.07685468 -1.254671\n",
      " -0.6023536  -0.2035326  -0.97150767 -0.6957198  -0.23280558 -0.9626942\n",
      " -0.6824906  -0.32326478 -1.1567602  -0.5148235   0.03249151 -1.1298449\n",
      " -0.5267403  -0.05914073 -1.061424   -0.6134176  -0.12518632 -1.0343738\n",
      " -0.649928   -0.18948953 -1.0336742 ]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [-0.10695712  0.03345665 -0.22819632 -0.3273572  -0.13462637 -0.7280887\n",
      " -0.36936438 -0.21939017 -0.9233306  -0.51104903 -0.33141372 -0.98685217\n",
      " -0.6116402  -0.38894948 -1.1375821  -0.5169359  -0.24898851 -1.2827344\n",
      " -0.49922743 -0.31723747 -1.0560925  -0.6071109  -0.46571714 -1.0546918\n",
      " -0.68591326 -0.43486145 -1.1231503  -0.54057384 -0.1560747  -1.2853764\n",
      " -0.6412466  -0.2558036  -1.3148772  -0.6810209  -0.33235934 -1.3416147\n",
      " -0.73919123 -0.42926198 -1.2880805  -0.50793576 -0.07685468 -1.254671\n",
      " -0.6023536  -0.2035326  -0.97150767 -0.6957198  -0.23280558 -0.9626942\n",
      " -0.6824906  -0.32326478 -1.1567602  -0.5148235   0.03249151 -1.1298449\n",
      " -0.5267403  -0.05914073 -1.061424   -0.6134176  -0.12518632 -1.0343738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.649928   -0.18948954 -1.0336742   0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63668>\n",
      "tensor([[ 0.0233, -0.2528, -0.0385,  ...,  0.4231, -0.3868, -1.1501],\n",
      "        [ 0.0233, -0.2528, -0.0385,  ...,  0.4231, -0.3868, -1.1501],\n",
      "        [ 0.0233, -0.2528, -0.0385,  ...,  0.4231, -0.3868, -1.1501],\n",
      "        ...,\n",
      "        [ 0.0656,  0.5390,  0.1152,  ..., -0.6761,  1.3183,  0.0949],\n",
      "        [-0.1411,  0.2685,  0.2919,  ..., -1.0776,  0.4609,  0.3565],\n",
      "        [-0.1411,  0.2685,  0.2919,  ..., -1.0776,  0.4609,  0.3565]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02332719 -0.25276494 -0.03849489  0.12804966 -0.3140055  -0.43381086\n",
      "  0.05913451 -0.35457724 -1.1638945  -0.03756477 -0.32492778 -1.460992\n",
      " -0.14720976 -0.41226056 -1.9325199  -0.16446725 -0.64649826 -1.3489339\n",
      "  0.09896666 -0.6037252  -1.3158002   0.07822752 -0.50316435 -1.3936878\n",
      "  0.10452905 -0.57806087 -1.4963995  -0.08307856 -0.6492764  -1.2742153\n",
      "  0.10507001 -0.6924625  -1.3574914   0.1382848  -0.59939843 -1.5199082\n",
      "  0.29878086 -0.601087   -1.5779762   0.0437619  -0.62256426 -1.0556659\n",
      "  0.09610638 -0.4200282  -1.5532088   0.30048966 -0.5137223  -1.562293\n",
      "  0.47070217 -0.45763233 -1.430359    0.02758172 -0.49269375 -1.0051409\n",
      "  0.16373427 -0.46045756 -1.1080816   0.30015308 -0.4640935  -1.261928\n",
      "  0.42306015 -0.38682508 -1.1501276 ]\n",
      "data: [ 0.02332719 -0.25276494 -0.03849489  0.12804966 -0.3140055  -0.43381083\n",
      "  0.05913451 -0.35457724 -1.1638945  -0.03756477 -0.32492778 -1.460992\n",
      " -0.14720976 -0.41226056 -1.9325198  -0.16446725 -0.64649826 -1.3489338\n",
      "  0.09896666 -0.6037252  -1.3158002   0.07822752 -0.50316435 -1.3936878\n",
      "  0.10452905 -0.57806087 -1.4963995  -0.08307856 -0.6492764  -1.2742153\n",
      "  0.10507001 -0.69246256 -1.3574913   0.1382848  -0.59939843 -1.5199082\n",
      "  0.29878086 -0.601087   -1.5779762   0.0437619  -0.62256426 -1.0556659\n",
      "  0.09610638 -0.42002824 -1.5532088   0.30048966 -0.5137223  -1.562293\n",
      "  0.47070217 -0.45763233 -1.430359    0.02758172 -0.49269375 -1.0051409\n",
      "  0.16373426 -0.46045756 -1.1080816   0.30015308 -0.4640935  -1.261928\n",
      "  0.42306015 -0.3868251  -1.1501276   0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.1333, -0.2534, -0.2495,  ...,  0.1454, -0.4250, -1.2666],\n",
      "        [ 0.1333, -0.2534, -0.2495,  ...,  0.1454, -0.4250, -1.2666],\n",
      "        [ 0.1333, -0.2534, -0.2495,  ...,  0.1454, -0.4250, -1.2666],\n",
      "        ...,\n",
      "        [-0.3474,  0.3257,  0.0286,  ..., -0.5161,  0.9316, -0.4933],\n",
      "        [-0.2991,  0.2229,  0.4657,  ..., -0.3892,  0.9659, -0.0417],\n",
      "        [-0.2991,  0.2229,  0.4657,  ..., -0.3892,  0.9659, -0.0417]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.13327299 -0.25335512 -0.2494569   0.1584035  -0.40231007 -0.6445124\n",
      "  0.06196142 -0.6163373  -1.427304   -0.08514643 -0.6804963  -1.7183535\n",
      " -0.2494329  -0.8070649  -2.1854005  -0.09563969 -0.8486279  -1.6218958\n",
      "  0.15455505 -0.8896291  -1.3727858   0.10227653 -0.8290677  -1.4071364\n",
      "  0.08292727 -0.9596789  -1.5226922  -0.04873712 -0.7266846  -1.5274615\n",
      "  0.03499748 -0.7980399  -1.4830608   0.03423404 -0.7745472  -1.5496976\n",
      "  0.15541208 -0.813938   -1.599613    0.06182302 -0.6393316  -1.3551826\n",
      " -0.08859241 -0.39909196 -2.0134876   0.08298466 -0.5933067  -1.9965136\n",
      "  0.23420605 -0.5342871  -1.4401252  -0.06270829 -0.39700007 -1.2802248\n",
      "  0.03357433 -0.367483   -1.3257122   0.08715016 -0.40485236 -1.4344666\n",
      "  0.14537701 -0.42502904 -1.2666371 ]\n",
      "data: [ 0.13327299 -0.25335512 -0.2494569   0.1584035  -0.40231007 -0.6445124\n",
      "  0.06196142 -0.6163373  -1.427304   -0.08514643 -0.6804963  -1.7183536\n",
      " -0.2494329  -0.8070649  -2.1854005  -0.09563968 -0.8486279  -1.6218958\n",
      "  0.15455505 -0.8896291  -1.3727858   0.10227653 -0.8290677  -1.4071364\n",
      "  0.08292727 -0.9596789  -1.5226922  -0.04873712 -0.7266846  -1.5274615\n",
      "  0.03499748 -0.7980399  -1.483061    0.03423404 -0.7745472  -1.5496975\n",
      "  0.15541208 -0.81393796 -1.5996128   0.06182302 -0.6393316  -1.3551826\n",
      " -0.08859242 -0.39909196 -2.0134876   0.08298466 -0.5933067  -1.9965137\n",
      "  0.23420605 -0.5342871  -1.4401252  -0.06270829 -0.39700007 -1.2802248\n",
      "  0.03357433 -0.367483   -1.3257123   0.08715016 -0.40485236 -1.4344666\n",
      "  0.14537701 -0.42502904 -1.2666371   0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B9B0>\n",
      "tensor([[-0.0041, -0.1893, -0.1588,  ...,  0.0088, -0.3689, -1.2147],\n",
      "        [-0.0041, -0.1893, -0.1588,  ...,  0.0088, -0.3689, -1.2147],\n",
      "        [-0.0041, -0.1893, -0.1588,  ...,  0.0088, -0.3689, -1.2147],\n",
      "        ...,\n",
      "        [ 0.0361,  0.6278, -0.1413,  ..., -0.2359,  1.1479, -0.6035],\n",
      "        [-0.0171,  0.0523,  0.6067,  ...,  0.0488,  0.7372,  0.2188],\n",
      "        [-0.0171,  0.0523,  0.6067,  ...,  0.0488,  0.7372,  0.2188]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.00410488 -0.18931243 -0.15883626  0.00651836 -0.33782184 -0.51177204\n",
      " -0.07053707 -0.5375688  -1.3137074  -0.22527352 -0.6024259  -1.6350274\n",
      " -0.42601803 -0.72866154 -2.1158652  -0.228212   -0.80058825 -1.5237377\n",
      "  0.02296764 -0.8373052  -1.312839   -0.03521769 -0.78160083 -1.3558834\n",
      " -0.03101714 -0.91354084 -1.4743855  -0.17729077 -0.6796074  -1.4194171\n",
      " -0.08287532 -0.7457671  -1.3866727  -0.08588917 -0.7274871  -1.5004919\n",
      "  0.04426569 -0.7541864  -1.5549362  -0.07303667 -0.58888996 -1.2360344\n",
      " -0.20331049 -0.37219688 -1.8898594  -0.04450409 -0.5364687  -1.8821034\n",
      "  0.12330382 -0.49836835 -1.381124   -0.19607627 -0.34001467 -1.1707602\n",
      " -0.10094409 -0.3305583  -1.239007   -0.05473372 -0.3634454  -1.3522425\n",
      "  0.00877923 -0.36889696 -1.2146544 ]\n",
      "data: [-0.00410488 -0.18931241 -0.15883626  0.00651836 -0.33782184 -0.51177204\n",
      " -0.07053707 -0.5375688  -1.3137072  -0.22527352 -0.6024259  -1.6350274\n",
      " -0.42601803 -0.7286615  -2.1158652  -0.228212   -0.80058825 -1.5237377\n",
      "  0.02296764 -0.83730525 -1.312839   -0.03521769 -0.7816008  -1.3558834\n",
      " -0.03101714 -0.9135408  -1.4743855  -0.17729077 -0.6796074  -1.4194171\n",
      " -0.08287532 -0.7457671  -1.3866726  -0.08588917 -0.7274871  -1.5004917\n",
      "  0.04426569 -0.7541864  -1.5549362  -0.07303667 -0.58888996 -1.2360344\n",
      " -0.20331049 -0.37219688 -1.8898594  -0.04450409 -0.5364687  -1.8821034\n",
      "  0.12330382 -0.49836835 -1.381124   -0.19607627 -0.34001464 -1.1707602\n",
      " -0.10094409 -0.33055833 -1.239007   -0.05473372 -0.3634454  -1.3522425\n",
      "  0.00877923 -0.36889693 -1.2146544   0.04      ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0418, -0.1358, -0.1699,  ...,  0.0425, -0.3156, -1.1843],\n",
      "        [ 0.0418, -0.1358, -0.1699,  ...,  0.0425, -0.3156, -1.1843],\n",
      "        [ 0.0418, -0.1358, -0.1699,  ...,  0.0425, -0.3156, -1.1843],\n",
      "        ...,\n",
      "        [-0.1439,  0.5228, -0.0830,  ..., -0.2349,  1.2091, -0.5436],\n",
      "        [-0.0803,  0.0543,  0.6811,  ..., -0.2083,  0.6852,  0.3763],\n",
      "        [-0.0803,  0.0543,  0.6811,  ..., -0.2083,  0.6852,  0.3763]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04175557 -0.13582475 -0.16993968  0.07791734 -0.22792746 -0.4357096\n",
      " -0.0791604  -0.47217786 -1.3224478  -0.24304686 -0.53890836 -1.6059378\n",
      " -0.38266987 -0.6189294  -2.1454778  -0.15862708 -0.78237057 -1.5249152\n",
      "  0.00619884 -0.86188316 -1.3841597  -0.04502894 -0.78160083 -1.4249381\n",
      " -0.05522878 -0.95464504 -1.5508169  -0.11548482 -0.7005329  -1.4193454\n",
      " -0.0654164  -0.75245905 -1.3859802  -0.07013253 -0.7072656  -1.4631561\n",
      "  0.07122356 -0.7481935  -1.4722418  -0.03182092 -0.57573557 -1.269203\n",
      " -0.20603882 -0.33044103 -2.040835   -0.00900794 -0.51204395 -2.0743628\n",
      "  0.17200173 -0.46282533 -1.3574823  -0.17034142 -0.3447832  -1.1829643\n",
      " -0.10136531 -0.30595273 -1.270995   -0.0736184  -0.307789   -1.3814882\n",
      "  0.0425114  -0.31555843 -1.1842848 ]\n",
      "data: [ 0.04175557 -0.13582475 -0.1699397   0.07791734 -0.22792746 -0.4357096\n",
      " -0.0791604  -0.47217786 -1.3224478  -0.24304685 -0.53890836 -1.6059378\n",
      " -0.38266987 -0.6189294  -2.1454778  -0.15862708 -0.7823706  -1.5249152\n",
      "  0.00619884 -0.86188316 -1.3841597  -0.04502894 -0.7816008  -1.4249381\n",
      " -0.05522878 -0.954645   -1.550817   -0.11548482 -0.7005329  -1.4193454\n",
      " -0.0654164  -0.75245905 -1.3859802  -0.07013253 -0.7072656  -1.4631561\n",
      "  0.07122356 -0.7481935  -1.4722419  -0.03182092 -0.57573557 -1.269203\n",
      " -0.20603882 -0.33044103 -2.040835   -0.00900794 -0.51204395 -2.0743628\n",
      "  0.17200175 -0.46282533 -1.3574823  -0.17034142 -0.3447832  -1.1829643\n",
      " -0.10136531 -0.30595273 -1.270995   -0.0736184  -0.307789   -1.3814882\n",
      "  0.04251141 -0.31555843 -1.1842848   0.05      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[-0.0312, -0.0480, -0.1977,  ...,  0.0167, -0.2335, -1.1759],\n",
      "        [-0.0312, -0.0480, -0.1977,  ...,  0.0167, -0.2335, -1.1759],\n",
      "        [-0.0312, -0.0480, -0.1977,  ...,  0.0167, -0.2335, -1.1759],\n",
      "        ...,\n",
      "        [-0.1502,  0.3583,  0.0717,  ..., -0.6179,  0.9455, -0.3476],\n",
      "        [-0.0897, -0.0458,  0.6001,  ..., -0.2193,  0.6383,  0.2536],\n",
      "        [-0.0897, -0.0458,  0.6001,  ..., -0.2193,  0.6383,  0.2536]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.03120036 -0.04801105 -0.1977014  -0.00441914 -0.16562799 -0.48987132\n",
      " -0.12398373 -0.38874638 -1.3338994  -0.2795514  -0.45091596 -1.6369567\n",
      " -0.4448085  -0.5645944  -2.135097   -0.24231333 -0.6778841  -1.5179836\n",
      " -0.01195115 -0.7308099  -1.3218805  -0.06847316 -0.66602975 -1.365087\n",
      " -0.07146779 -0.81603706 -1.4962491  -0.18998888 -0.57727486 -1.4096055\n",
      " -0.10851602 -0.6371622  -1.3867333  -0.09906916 -0.60011417 -1.4761575\n",
      "  0.0438496  -0.64473623 -1.5091813  -0.0848896  -0.46764383 -1.2340746\n",
      " -0.24380557 -0.22783512 -1.9886484  -0.04216769 -0.4113621  -1.9989208\n",
      "  0.14447561 -0.3637923  -1.3576801  -0.21973294 -0.22956534 -1.1564256\n",
      " -0.12175952 -0.2039012  -1.2352216  -0.08000067 -0.22367236 -1.3506112\n",
      "  0.01670561 -0.23354264 -1.1759074 ]\n",
      "data: [-0.03120036 -0.04801105 -0.1977014  -0.00441914 -0.165628   -0.48987132\n",
      " -0.12398373 -0.38874638 -1.3338994  -0.2795514  -0.45091593 -1.6369567\n",
      " -0.4448085  -0.5645944  -2.135097   -0.24231333 -0.67788404 -1.5179836\n",
      " -0.01195115 -0.7308099  -1.3218805  -0.06847316 -0.66602975 -1.365087\n",
      " -0.07146779 -0.81603706 -1.4962491  -0.18998888 -0.57727486 -1.4096055\n",
      " -0.10851602 -0.6371622  -1.3867333  -0.09906916 -0.60011417 -1.4761575\n",
      "  0.0438496  -0.64473623 -1.5091813  -0.08488961 -0.46764383 -1.2340746\n",
      " -0.24380559 -0.22783512 -1.9886484  -0.04216769 -0.4113621  -1.9989208\n",
      "  0.14447561 -0.3637923  -1.3576801  -0.21973294 -0.22956534 -1.1564256\n",
      " -0.12175952 -0.2039012  -1.2352216  -0.08000067 -0.22367235 -1.3506112\n",
      "  0.01670561 -0.23354264 -1.1759074   0.06      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[ 4.4218e-03, -9.0808e-02, -2.3997e-01,  ...,  3.9541e-04,\n",
      "         -2.5243e-01, -1.3002e+00],\n",
      "        [ 4.4218e-03, -9.0808e-02, -2.3997e-01,  ...,  3.9541e-04,\n",
      "         -2.5243e-01, -1.3002e+00],\n",
      "        [ 4.4218e-03, -9.0808e-02, -2.3997e-01,  ...,  3.9541e-04,\n",
      "         -2.5243e-01, -1.3002e+00],\n",
      "        ...,\n",
      "        [-2.5323e-01,  3.0464e-01, -1.4628e-01,  ..., -6.8726e-01,\n",
      "          7.9997e-01, -4.0614e-01],\n",
      "        [-1.5166e-01, -9.3790e-02,  6.0132e-01,  ..., -2.6315e-01,\n",
      "          6.6764e-01,  2.7418e-01],\n",
      "        [-1.5166e-01, -9.3790e-02,  6.0132e-01,  ..., -2.6315e-01,\n",
      "          6.6764e-01,  2.7418e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 4.42183483e-03 -9.08079967e-02 -2.39967465e-01  2.99372561e-02\n",
      " -2.20873639e-01 -6.51082575e-01 -6.99452832e-02 -4.06399697e-01\n",
      " -1.40593147e+00 -2.16797337e-01 -4.64804739e-01 -1.70610607e+00\n",
      " -3.84304553e-01 -5.65046430e-01 -2.19021249e+00 -2.00310826e-01\n",
      " -7.01640904e-01 -1.55799925e+00  3.83262336e-03 -7.31450677e-01\n",
      " -1.36210847e+00 -4.34389561e-02 -6.68680727e-01 -1.42063141e+00\n",
      " -5.55308685e-02 -8.06859732e-01 -1.54527700e+00 -1.63021073e-01\n",
      " -6.01818919e-01 -1.47174585e+00 -8.85614082e-02 -6.51190639e-01\n",
      " -1.44905734e+00 -1.00526541e-01 -6.18953049e-01 -1.54984307e+00\n",
      "  3.82903069e-02 -6.43311501e-01 -1.59549141e+00 -8.28850046e-02\n",
      " -5.03875613e-01 -1.30247116e+00 -2.07182691e-01 -2.73348123e-01\n",
      " -1.97511196e+00 -4.55418751e-02 -4.23038721e-01 -1.98604298e+00\n",
      "  1.15304396e-01 -3.91295969e-01 -1.45228434e+00 -1.87689126e-01\n",
      " -2.68231094e-01 -1.23660910e+00 -1.22025996e-01 -2.38128632e-01\n",
      " -1.32144332e+00 -8.17752033e-02 -2.41919592e-01 -1.44486642e+00\n",
      "  3.95409763e-04 -2.52432823e-01 -1.30017769e+00]\n",
      "data: [ 4.42183483e-03 -9.08080041e-02 -2.39967465e-01  2.99372561e-02\n",
      " -2.20873639e-01 -6.51082635e-01 -6.99452832e-02 -4.06399697e-01\n",
      " -1.40593135e+00 -2.16797337e-01 -4.64804739e-01 -1.70610607e+00\n",
      " -3.84304553e-01 -5.65046430e-01 -2.19021249e+00 -2.00310826e-01\n",
      " -7.01640904e-01 -1.55799925e+00  3.83262336e-03 -7.31450677e-01\n",
      " -1.36210847e+00 -4.34389561e-02 -6.68680727e-01 -1.42063141e+00\n",
      " -5.55308685e-02 -8.06859732e-01 -1.54527700e+00 -1.63021073e-01\n",
      " -6.01818919e-01 -1.47174597e+00 -8.85614082e-02 -6.51190639e-01\n",
      " -1.44905734e+00 -1.00526541e-01 -6.18953049e-01 -1.54984319e+00\n",
      "  3.82903069e-02 -6.43311441e-01 -1.59549129e+00 -8.28850046e-02\n",
      " -5.03875613e-01 -1.30247116e+00 -2.07182691e-01 -2.73348123e-01\n",
      " -1.97511196e+00 -4.55418713e-02 -4.23038721e-01 -1.98604298e+00\n",
      "  1.15304396e-01 -3.91295969e-01 -1.45228434e+00 -1.87689126e-01\n",
      " -2.68231094e-01 -1.23660910e+00 -1.22025996e-01 -2.38128617e-01\n",
      " -1.32144332e+00 -8.17752108e-02 -2.41919592e-01 -1.44486654e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3.95409763e-04 -2.52432823e-01 -1.30017781e+00  7.00000003e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0275, -0.0289, -0.2226,  ...,  0.0298, -0.2189, -1.2546],\n",
      "        [ 0.0275, -0.0289, -0.2226,  ...,  0.0298, -0.2189, -1.2546],\n",
      "        [ 0.0275, -0.0289, -0.2226,  ...,  0.0298, -0.2189, -1.2546],\n",
      "        ...,\n",
      "        [-0.1812,  0.4000, -0.0979,  ..., -0.7638,  0.9112, -0.3849],\n",
      "        [-0.1271, -0.1756,  0.6082,  ..., -0.1993,  0.5882,  0.2819],\n",
      "        [-0.1271, -0.1756,  0.6082,  ..., -0.1993,  0.5882,  0.2819]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02751968 -0.02886344 -0.22258227  0.03999272 -0.14762302 -0.6048707\n",
      " -0.08564919 -0.33968887 -1.371816   -0.23859799 -0.40397215 -1.6628733\n",
      " -0.40317535 -0.4901197  -2.1641235  -0.16869198 -0.6549715  -1.5274836\n",
      " -0.01823659 -0.7002082  -1.3743373  -0.06551115 -0.62285906 -1.4399197\n",
      " -0.0684497  -0.78253835 -1.5583886  -0.13343766 -0.5668278  -1.4439583\n",
      " -0.07830027 -0.6099731  -1.4130347  -0.10459591 -0.5810286  -1.5101609\n",
      "  0.04015036 -0.5921049  -1.5313721  -0.06199945 -0.46904492 -1.2866634\n",
      " -0.18140997 -0.2445746  -1.949978   -0.032828   -0.3871607  -1.9732454\n",
      "  0.13412845 -0.36459184 -1.4016612  -0.15620014 -0.2428031  -1.2169118\n",
      " -0.10840486 -0.21730223 -1.3082991  -0.08043575 -0.20538428 -1.426797\n",
      "  0.02976409 -0.2188807  -1.2546158 ]\n",
      "data: [ 0.02751968 -0.02886344 -0.22258227  0.03999272 -0.14762302 -0.6048707\n",
      " -0.08564919 -0.33968887 -1.3718162  -0.23859799 -0.40397218 -1.6628733\n",
      " -0.40317535 -0.4901197  -2.1641235  -0.16869198 -0.6549715  -1.5274835\n",
      " -0.01823659 -0.7002082  -1.3743373  -0.06551115 -0.62285906 -1.4399197\n",
      " -0.0684497  -0.78253835 -1.5583885  -0.13343766 -0.5668278  -1.4439583\n",
      " -0.07830027 -0.6099731  -1.4130347  -0.10459592 -0.5810286  -1.5101609\n",
      "  0.04015036 -0.5921049  -1.5313721  -0.06199945 -0.46904492 -1.2866634\n",
      " -0.18140997 -0.2445746  -1.949978   -0.032828   -0.3871607  -1.9732454\n",
      "  0.13412845 -0.36459184 -1.4016613  -0.15620014 -0.2428031  -1.2169118\n",
      " -0.10840485 -0.21730223 -1.3082991  -0.08043575 -0.2053843  -1.426797\n",
      "  0.02976408 -0.2188807  -1.2546158   0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0471, -0.0397, -0.2135,  ...,  0.0326, -0.2338, -1.2653],\n",
      "        [ 0.0471, -0.0397, -0.2135,  ...,  0.0326, -0.2338, -1.2653],\n",
      "        [ 0.0471, -0.0397, -0.2135,  ...,  0.0326, -0.2338, -1.2653],\n",
      "        ...,\n",
      "        [-0.3057,  0.2313, -0.2575,  ..., -0.8069,  0.6250, -0.3527],\n",
      "        [-0.1214, -0.0933,  0.5584,  ..., -0.1864,  0.6841,  0.2931],\n",
      "        [-0.1214, -0.0933,  0.5584,  ..., -0.1864,  0.6841,  0.2931]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04709836 -0.03969218 -0.21353804  0.0583301  -0.17396772 -0.6136582\n",
      " -0.07154372 -0.3616214  -1.3779243  -0.22307464 -0.43238842 -1.6526083\n",
      " -0.39747295 -0.51622593 -2.1478248  -0.14782861 -0.66584074 -1.5264242\n",
      " -0.01540951 -0.7097156  -1.3700835  -0.0539997  -0.6298268  -1.4328418\n",
      " -0.05209068 -0.7803242  -1.5378864  -0.1184156  -0.57007754 -1.455396\n",
      " -0.06551436 -0.6141231  -1.409281   -0.09708989 -0.59066176 -1.5003126\n",
      "  0.05043549 -0.58613276 -1.5271672  -0.05838982 -0.4890513  -1.3031491\n",
      " -0.16170487 -0.26829934 -1.9170502  -0.03054918 -0.40112743 -1.9336785\n",
      "  0.12587819 -0.38013038 -1.4014325  -0.13957557 -0.25780886 -1.2394196\n",
      " -0.10811425 -0.234774   -1.3244101  -0.07209567 -0.21799977 -1.4403591\n",
      "  0.03256419 -0.23380993 -1.2653475 ]\n",
      "data: [ 0.04709835 -0.03969218 -0.21353804  0.0583301  -0.17396772 -0.6136582\n",
      " -0.07154372 -0.3616214  -1.3779243  -0.22307464 -0.43238842 -1.6526084\n",
      " -0.39747295 -0.51622593 -2.1478248  -0.14782861 -0.66584074 -1.526424\n",
      " -0.01540951 -0.7097156  -1.3700835  -0.0539997  -0.6298268  -1.4328418\n",
      " -0.05209068 -0.7803242  -1.5378864  -0.1184156  -0.57007754 -1.4553962\n",
      " -0.06551436 -0.6141231  -1.409281   -0.09708989 -0.59066176 -1.5003124\n",
      "  0.05043549 -0.58613276 -1.5271672  -0.05838982 -0.4890513  -1.3031491\n",
      " -0.16170487 -0.26829934 -1.9170501  -0.03054918 -0.40112743 -1.9336784\n",
      "  0.12587819 -0.38013038 -1.4014325  -0.13957557 -0.25780886 -1.2394196\n",
      " -0.10811425 -0.234774   -1.3244101  -0.07209567 -0.21799976 -1.4403592\n",
      "  0.03256419 -0.23380993 -1.2653475   0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0214, -0.0627, -0.2447,  ...,  0.0375, -0.2498, -1.2723],\n",
      "        [ 0.0214, -0.0627, -0.2447,  ...,  0.0375, -0.2498, -1.2723],\n",
      "        [ 0.0214, -0.0627, -0.2447,  ...,  0.0375, -0.2498, -1.2723],\n",
      "        ...,\n",
      "        [-0.2621,  0.2323, -0.2334,  ..., -0.7746,  0.7014, -0.4419],\n",
      "        [-0.0839, -0.0682,  0.5971,  ..., -0.2079,  0.7208,  0.2648],\n",
      "        [-0.0839, -0.0682,  0.5971,  ..., -0.2079,  0.7208,  0.2648]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.1392282e-02 -6.2734902e-02 -2.4473564e-01  4.7804985e-02\n",
      " -1.8609291e-01 -6.3589835e-01 -7.2874412e-02 -3.8066477e-01\n",
      " -1.4156622e+00 -2.1875358e-01 -4.4732195e-01 -1.6987303e+00\n",
      " -3.7284115e-01 -5.3970975e-01 -2.1927948e+00 -1.6946521e-01\n",
      " -6.7783320e-01 -1.5682318e+00  8.3440542e-04 -7.2123533e-01\n",
      " -1.3933703e+00 -4.5733899e-02 -6.4922994e-01 -1.4526359e+00\n",
      " -5.5939920e-02 -7.9898202e-01 -1.5704929e+00 -1.3353086e-01\n",
      " -5.8694184e-01 -1.4851408e+00 -7.0789903e-02 -6.3636142e-01\n",
      " -1.4496281e+00 -9.4945282e-02 -6.0652924e-01 -1.5358164e+00\n",
      "  4.3104336e-02 -6.2558913e-01 -1.5634764e+00 -5.9914939e-02\n",
      " -4.9440175e-01 -1.3221741e+00 -1.8014415e-01 -2.6439989e-01\n",
      " -1.9868435e+00 -2.7154095e-02 -4.1623425e-01 -2.0025079e+00\n",
      "  1.3207893e-01 -3.8940114e-01 -1.4278593e+00 -1.5640220e-01\n",
      " -2.6566672e-01 -1.2507211e+00 -9.8681331e-02 -2.3767482e-01\n",
      " -1.3314902e+00 -6.0834825e-02 -2.3415814e-01 -1.4474896e+00\n",
      "  3.7509777e-02 -2.4981523e-01 -1.2723323e+00]\n",
      "data: [ 2.1392280e-02 -6.2734902e-02 -2.4473564e-01  4.7804985e-02\n",
      " -1.8609291e-01 -6.3589835e-01 -7.2874412e-02 -3.8066474e-01\n",
      " -1.4156623e+00 -2.1875359e-01 -4.4732198e-01 -1.6987303e+00\n",
      " -3.7284115e-01 -5.3970975e-01 -2.1927948e+00 -1.6946521e-01\n",
      " -6.7783320e-01 -1.5682318e+00  8.3440542e-04 -7.2123533e-01\n",
      " -1.3933702e+00 -4.5733899e-02 -6.4922994e-01 -1.4526360e+00\n",
      " -5.5939924e-02 -7.9898202e-01 -1.5704929e+00 -1.3353086e-01\n",
      " -5.8694184e-01 -1.4851408e+00 -7.0789903e-02 -6.3636142e-01\n",
      " -1.4496281e+00 -9.4945282e-02 -6.0652924e-01 -1.5358166e+00\n",
      "  4.3104336e-02 -6.2558913e-01 -1.5634764e+00 -5.9914935e-02\n",
      " -4.9440175e-01 -1.3221741e+00 -1.8014413e-01 -2.6439989e-01\n",
      " -1.9868435e+00 -2.7154095e-02 -4.1623425e-01 -2.0025079e+00\n",
      "  1.3207893e-01 -3.8940114e-01 -1.4278593e+00 -1.5640220e-01\n",
      " -2.6566672e-01 -1.2507211e+00 -9.8681338e-02 -2.3767480e-01\n",
      " -1.3314902e+00 -6.0834829e-02 -2.3415813e-01 -1.4474896e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3.7509777e-02 -2.4981521e-01 -1.2723323e+00  1.0000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0239, -0.0309, -0.2423,  ...,  0.0470, -0.2265, -1.2697],\n",
      "        [ 0.0239, -0.0309, -0.2423,  ...,  0.0470, -0.2265, -1.2697],\n",
      "        [ 0.0239, -0.0309, -0.2423,  ...,  0.0470, -0.2265, -1.2697],\n",
      "        ...,\n",
      "        [-0.1618,  0.3414, -0.0864,  ..., -0.8119,  0.8265, -0.3006],\n",
      "        [-0.1402, -0.1724,  0.5473,  ..., -0.2200,  0.5951,  0.2175],\n",
      "        [-0.1402, -0.1724,  0.5473,  ..., -0.2200,  0.5951,  0.2175]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0238638  -0.03093706 -0.24232203  0.03912248 -0.15894568 -0.63401246\n",
      " -0.06981223 -0.34575635 -1.3869567  -0.2157969  -0.40867752 -1.677617\n",
      " -0.3834005  -0.5091764  -2.1599023  -0.17266615 -0.6470421  -1.5410893\n",
      "  0.00515004 -0.6856585  -1.3757408  -0.04077494 -0.6145577  -1.4359113\n",
      " -0.03683317 -0.76258624 -1.5508367  -0.13283697 -0.5515826  -1.4583331\n",
      " -0.06427866 -0.6007314  -1.4280654  -0.08060451 -0.57664704 -1.5219295\n",
      "  0.06062499 -0.5910936  -1.5554928  -0.05425035 -0.46389276 -1.2949182\n",
      " -0.16864166 -0.2392902  -1.9502212  -0.01551652 -0.38852966 -1.9609313\n",
      "  0.14752202 -0.36250877 -1.4184637  -0.1496282  -0.2340382  -1.229653\n",
      " -0.08820647 -0.21220893 -1.3156503  -0.0489525  -0.21194643 -1.4329611\n",
      "  0.04698052 -0.22650382 -1.2697383 ]\n",
      "data: [ 0.0238638  -0.03093706 -0.24232203  0.03912248 -0.15894568 -0.63401246\n",
      " -0.06981223 -0.34575635 -1.3869567  -0.2157969  -0.40867752 -1.6776168\n",
      " -0.3834005  -0.5091764  -2.1599023  -0.17266615 -0.6470421  -1.5410893\n",
      "  0.00515004 -0.6856585  -1.3757408  -0.04077494 -0.6145577  -1.4359113\n",
      " -0.03683317 -0.76258624 -1.5508367  -0.13283697 -0.5515826  -1.4583331\n",
      " -0.06427866 -0.6007314  -1.4280655  -0.08060451 -0.57664704 -1.5219295\n",
      "  0.06062499 -0.5910936  -1.5554928  -0.05425035 -0.46389276 -1.2949182\n",
      " -0.16864166 -0.2392902  -1.9502213  -0.01551652 -0.38852966 -1.9609313\n",
      "  0.14752202 -0.36250877 -1.4184637  -0.1496282  -0.2340382  -1.229653\n",
      " -0.08820647 -0.21220893 -1.3156503  -0.0489525  -0.21194643 -1.4329611\n",
      "  0.04698052 -0.2265038  -1.2697383   0.11      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0141, -0.0817, -0.2418,  ...,  0.0304, -0.2658, -1.2977],\n",
      "        [ 0.0141, -0.0817, -0.2418,  ...,  0.0304, -0.2658, -1.2977],\n",
      "        [ 0.0141, -0.0817, -0.2418,  ...,  0.0304, -0.2658, -1.2977],\n",
      "        ...,\n",
      "        [-0.3565,  0.1824, -0.3352,  ..., -0.8445,  0.6089, -0.4857],\n",
      "        [-0.1289, -0.0715,  0.5924,  ..., -0.2349,  0.7214,  0.2549],\n",
      "        [-0.1289, -0.0715,  0.5924,  ..., -0.2349,  0.7214,  0.2549]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01405067 -0.081738   -0.24184586  0.03476316 -0.22031124 -0.6646235\n",
      " -0.05888142 -0.40034324 -1.4124372  -0.2007083  -0.46367773 -1.7043519\n",
      " -0.3663044  -0.57090795 -2.1832786  -0.18554705 -0.6856853  -1.5673032\n",
      "  0.01503064 -0.71530795 -1.3779967  -0.03253485 -0.65009356 -1.4359717\n",
      " -0.03722659 -0.7833986  -1.551228   -0.1468564  -0.5840068  -1.4863043\n",
      " -0.06967244 -0.63560224 -1.4568787  -0.08741347 -0.6105591  -1.5499377\n",
      "  0.04414754 -0.6275686  -1.5937796  -0.06537792 -0.5013779  -1.3174019\n",
      " -0.17210558 -0.27570552 -1.9383509  -0.02815463 -0.42305884 -1.9403095\n",
      "  0.12353339 -0.39531222 -1.4500258  -0.160618   -0.26741898 -1.2535944\n",
      " -0.09163781 -0.24474168 -1.331825   -0.04717033 -0.25214353 -1.4481125\n",
      "  0.03037528 -0.26580435 -1.2977257 ]\n",
      "data: [ 0.01405067 -0.081738   -0.24184586  0.03476316 -0.22031124 -0.6646235\n",
      " -0.05888142 -0.40034324 -1.4124371  -0.2007083  -0.46367776 -1.7043519\n",
      " -0.3663044  -0.57090795 -2.1832786  -0.18554705 -0.6856853  -1.5673032\n",
      "  0.01503064 -0.71530795 -1.3779967  -0.03253485 -0.65009356 -1.4359717\n",
      " -0.03722659 -0.78339857 -1.551228   -0.1468564  -0.5840068  -1.4863043\n",
      " -0.06967244 -0.63560224 -1.4568787  -0.08741347 -0.6105591  -1.5499377\n",
      "  0.04414754 -0.6275686  -1.5937796  -0.06537792 -0.5013779  -1.3174019\n",
      " -0.17210558 -0.27570552 -1.938351   -0.02815463 -0.42305887 -1.9403094\n",
      "  0.12353339 -0.39531222 -1.4500258  -0.160618   -0.26741898 -1.2535944\n",
      " -0.09163781 -0.24474166 -1.3318249  -0.04717033 -0.25214353 -1.4481125\n",
      "  0.03037528 -0.26580435 -1.2977257   0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0292, -0.0683, -0.2562,  ...,  0.0458, -0.2577, -1.2747],\n",
      "        [ 0.0292, -0.0683, -0.2562,  ...,  0.0458, -0.2577, -1.2747],\n",
      "        [ 0.0292, -0.0683, -0.2562,  ...,  0.0458, -0.2577, -1.2747],\n",
      "        ...,\n",
      "        [-0.1133,  0.4026, -0.1135,  ..., -0.6931,  0.9172, -0.4015],\n",
      "        [-0.1304, -0.1499,  0.5839,  ..., -0.2346,  0.6259,  0.2319],\n",
      "        [-0.1304, -0.1499,  0.5839,  ..., -0.2346,  0.6259,  0.2319]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0292435  -0.06826396 -0.2562253   0.05564853 -0.18372439 -0.6272136\n",
      " -0.06455807 -0.38376775 -1.4166403  -0.21027313 -0.447337   -1.7051811\n",
      " -0.362526   -0.5385062  -2.2024062  -0.15882184 -0.689279   -1.5728331\n",
      "  0.00749452 -0.737369   -1.4208908  -0.04296686 -0.6643573  -1.4809241\n",
      " -0.04878584 -0.82213277 -1.6006336  -0.12081337 -0.6013237  -1.4838209\n",
      " -0.0622806  -0.64831984 -1.4550028  -0.0846598  -0.6190538  -1.5434043\n",
      "  0.04924294 -0.64085895 -1.5666399  -0.04639695 -0.50156677 -1.3220806\n",
      " -0.17811382 -0.27106547 -2.0254972  -0.01690348 -0.4272905  -2.0457702\n",
      "  0.14294414 -0.39820677 -1.4324071  -0.14854074 -0.27563757 -1.2491822\n",
      " -0.08888455 -0.24805424 -1.3369117  -0.05599619 -0.24402246 -1.4527292\n",
      "  0.04576557 -0.25768757 -1.2746718 ]\n",
      "data: [ 0.0292435  -0.06826396 -0.2562253   0.05564853 -0.18372439 -0.6272136\n",
      " -0.06455807 -0.38376772 -1.4166403  -0.21027313 -0.447337   -1.7051811\n",
      " -0.36252603 -0.5385062  -2.2024062  -0.15882184 -0.689279   -1.5728331\n",
      "  0.00749452 -0.737369   -1.4208908  -0.04296686 -0.6643573  -1.4809241\n",
      " -0.04878584 -0.8221328  -1.6006335  -0.12081337 -0.6013237  -1.4838209\n",
      " -0.0622806  -0.64831984 -1.4550028  -0.08465979 -0.6190538  -1.5434043\n",
      "  0.04924294 -0.6408589  -1.5666399  -0.04639695 -0.50156677 -1.3220807\n",
      " -0.17811382 -0.27106547 -2.0254972  -0.01690348 -0.4272905  -2.0457702\n",
      "  0.14294414 -0.3982068  -1.432407   -0.14854074 -0.27563757 -1.2491822\n",
      " -0.08888455 -0.24805424 -1.3369117  -0.05599619 -0.24402246 -1.4527292\n",
      "  0.04576557 -0.25768757 -1.2746718   0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0227, -0.0344, -0.2415,  ...,  0.0568, -0.2242, -1.2858],\n",
      "        [ 0.0227, -0.0344, -0.2415,  ...,  0.0568, -0.2242, -1.2858],\n",
      "        [ 0.0227, -0.0344, -0.2415,  ...,  0.0568, -0.2242, -1.2858],\n",
      "        ...,\n",
      "        [-0.1621,  0.3030, -0.0649,  ..., -0.8211,  0.7703, -0.2565],\n",
      "        [-0.1458, -0.1505,  0.5371,  ..., -0.2282,  0.6074,  0.2013],\n",
      "        [-0.1458, -0.1505,  0.5371,  ..., -0.2282,  0.6074,  0.2013]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.2728879e-02 -3.4435533e-02 -2.4145265e-01  3.5467576e-02\n",
      " -1.7697723e-01 -6.5794015e-01 -4.1905880e-02 -3.5368720e-01\n",
      " -1.3816953e+00 -1.8422195e-01 -4.1265589e-01 -1.6856058e+00\n",
      " -3.6134762e-01 -5.3366876e-01 -2.1484990e+00 -1.8476126e-01\n",
      " -6.3747966e-01 -1.5418649e+00  4.3145128e-02 -6.6332078e-01\n",
      " -1.3495691e+00 -8.3668903e-03 -6.0349524e-01 -1.4038813e+00\n",
      " -5.9117451e-03 -7.3421180e-01 -1.5196586e+00 -1.3796431e-01\n",
      " -5.3052497e-01 -1.4561734e+00 -4.8425257e-02 -5.8720994e-01\n",
      " -1.4337361e+00 -5.5295855e-02 -5.6511617e-01 -1.5333936e+00\n",
      "  7.4610971e-02 -5.8906090e-01 -1.5841391e+00 -4.2382151e-02\n",
      " -4.4709617e-01 -1.2834466e+00 -1.5220007e-01 -2.2497058e-01\n",
      " -1.9136021e+00  9.9728256e-04 -3.7962621e-01 -1.9081817e+00\n",
      "  1.5676853e-01 -3.4850743e-01 -1.4362416e+00 -1.4495519e-01\n",
      " -2.1085593e-01 -1.2232001e+00 -5.9589081e-02 -1.9370577e-01\n",
      " -1.3038552e+00 -1.3003267e-02 -2.1255024e-01 -1.4217341e+00\n",
      "  5.6774631e-02 -2.2421934e-01 -1.2857516e+00]\n",
      "data: [ 2.2728879e-02 -3.4435533e-02 -2.4145265e-01  3.5467576e-02\n",
      " -1.7697723e-01 -6.5794015e-01 -4.1905880e-02 -3.5368720e-01\n",
      " -1.3816953e+00 -1.8422195e-01 -4.1265592e-01 -1.6856058e+00\n",
      " -3.6134762e-01 -5.3366876e-01 -2.1484990e+00 -1.8476126e-01\n",
      " -6.3747966e-01 -1.5418649e+00  4.3145128e-02 -6.6332078e-01\n",
      " -1.3495691e+00 -8.3668903e-03 -6.0349524e-01 -1.4038814e+00\n",
      " -5.9117447e-03 -7.3421180e-01 -1.5196586e+00 -1.3796431e-01\n",
      " -5.3052497e-01 -1.4561734e+00 -4.8425253e-02 -5.8720994e-01\n",
      " -1.4337361e+00 -5.5295855e-02 -5.6511617e-01 -1.5333935e+00\n",
      "  7.4610971e-02 -5.8906090e-01 -1.5841391e+00 -4.2382151e-02\n",
      " -4.4709617e-01 -1.2834466e+00 -1.5220007e-01 -2.2497059e-01\n",
      " -1.9136021e+00  9.9728256e-04 -3.7962618e-01 -1.9081817e+00\n",
      "  1.5676853e-01 -3.4850743e-01 -1.4362416e+00 -1.4495519e-01\n",
      " -2.1085592e-01 -1.2232001e+00 -5.9589081e-02 -1.9370577e-01\n",
      " -1.3038552e+00 -1.3003267e-02 -2.1255024e-01 -1.4217342e+00\n",
      "  5.6774631e-02 -2.2421934e-01 -1.2857517e+00  1.4000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0030, -0.0827, -0.2580,  ...,  0.0338, -0.2683, -1.3244],\n",
      "        [ 0.0030, -0.0827, -0.2580,  ...,  0.0338, -0.2683, -1.3244],\n",
      "        [ 0.0030, -0.0827, -0.2580,  ...,  0.0338, -0.2683, -1.3244],\n",
      "        ...,\n",
      "        [-0.1623,  0.4254, -0.1262,  ..., -0.7421,  0.9039, -0.3444],\n",
      "        [-0.1622, -0.1302,  0.5730,  ..., -0.2453,  0.6584,  0.2237],\n",
      "        [-0.1622, -0.1302,  0.5730,  ..., -0.2453,  0.6584,  0.2237]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00301177 -0.08268975 -0.2579527   0.02080414 -0.22892177 -0.68694794\n",
      " -0.05812575 -0.40221214 -1.4257829  -0.19736727 -0.46357358 -1.7228076\n",
      " -0.36767077 -0.58133125 -2.1941009  -0.20039445 -0.68139315 -1.5866504\n",
      "  0.02365094 -0.703675   -1.3898404  -0.02470651 -0.6415044  -1.4453473\n",
      " -0.02226326 -0.76489526 -1.5602152  -0.15817854 -0.5734678  -1.5054855\n",
      " -0.06830639 -0.6268329  -1.4811099  -0.07813167 -0.60277456 -1.576788\n",
      "  0.05271517 -0.6215572  -1.6297054  -0.06820825 -0.49673152 -1.3316822\n",
      " -0.16790074 -0.27061242 -1.9340532  -0.02370419 -0.41888577 -1.9275563\n",
      "  0.12944542 -0.38889652 -1.4806814  -0.16635157 -0.25857693 -1.2698903\n",
      " -0.08429237 -0.23917624 -1.3471293  -0.03451516 -0.25509214 -1.463547\n",
      "  0.03379098 -0.26831335 -1.3244078 ]\n",
      "data: [ 0.00301177 -0.08268974 -0.2579527   0.02080414 -0.22892177 -0.68694794\n",
      " -0.05812575 -0.40221214 -1.4257829  -0.19736727 -0.46357358 -1.7228076\n",
      " -0.36767077 -0.58133125 -2.1941009  -0.20039445 -0.68139315 -1.5866504\n",
      "  0.02365094 -0.70367503 -1.3898404  -0.02470651 -0.64150447 -1.4453473\n",
      " -0.02226326 -0.76489526 -1.5602154  -0.15817854 -0.5734678  -1.5054855\n",
      " -0.06830639 -0.6268329  -1.48111    -0.07813167 -0.60277456 -1.5767881\n",
      "  0.05271517 -0.6215572  -1.6297055  -0.06820825 -0.49673152 -1.3316821\n",
      " -0.16790074 -0.27061242 -1.9340532  -0.02370419 -0.41888577 -1.9275563\n",
      "  0.12944542 -0.38889652 -1.4806814  -0.16635157 -0.25857693 -1.2698903\n",
      " -0.08429237 -0.23917623 -1.3471293  -0.03451516 -0.25509214 -1.4635471\n",
      "  0.03379098 -0.26831335 -1.3244078   0.15      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0237, -0.0930, -0.2468,  ...,  0.0452, -0.2775, -1.2831],\n",
      "        [ 0.0237, -0.0930, -0.2468,  ...,  0.0452, -0.2775, -1.2831],\n",
      "        [ 0.0237, -0.0930, -0.2468,  ...,  0.0452, -0.2775, -1.2831],\n",
      "        ...,\n",
      "        [-0.1537,  0.4002, -0.1900,  ..., -0.7512,  0.9091, -0.4615],\n",
      "        [-0.1693, -0.1687,  0.5784,  ..., -0.2689,  0.6041,  0.2350],\n",
      "        [-0.1693, -0.1687,  0.5784,  ..., -0.2689,  0.6041,  0.2350]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02373355 -0.09304289 -0.24677339  0.04496157 -0.22357734 -0.64299494\n",
      " -0.05221949 -0.41502738 -1.4024789  -0.19406903 -0.47578645 -1.6963965\n",
      " -0.3545304  -0.58178174 -2.174543   -0.17309003 -0.70609725 -1.5615706\n",
      "  0.02347508 -0.74357235 -1.3959932  -0.02722362 -0.6768755  -1.4521141\n",
      " -0.02627463 -0.8194258  -1.5691587  -0.13163021 -0.6066332  -1.4746687\n",
      " -0.05802958 -0.6572877  -1.4493302  -0.0703578  -0.63095725 -1.540355\n",
      "  0.05905737 -0.65419567 -1.5775802  -0.04706716 -0.51318836 -1.3090583\n",
      " -0.17021154 -0.28580266 -1.9781327  -0.01164202 -0.4419191  -1.9852788\n",
      "  0.14452685 -0.4082745  -1.4395851  -0.1515084  -0.28138012 -1.2413476\n",
      " -0.07809791 -0.2569893  -1.32596    -0.03802535 -0.26520687 -1.4416137\n",
      "  0.04524281 -0.27753115 -1.283142  ]\n",
      "data: [ 0.02373355 -0.09304289 -0.24677339  0.04496157 -0.22357732 -0.64299494\n",
      " -0.05221949 -0.41502738 -1.4024789  -0.19406903 -0.47578645 -1.6963965\n",
      " -0.35453042 -0.58178174 -2.174543   -0.17309003 -0.70609725 -1.5615706\n",
      "  0.02347508 -0.7435724  -1.3959932  -0.02722361 -0.6768755  -1.4521141\n",
      " -0.02627463 -0.8194258  -1.5691587  -0.13163021 -0.6066332  -1.4746687\n",
      " -0.05802958 -0.6572878  -1.4493301  -0.0703578  -0.63095725 -1.540355\n",
      "  0.05905737 -0.6541956  -1.5775802  -0.04706715 -0.51318836 -1.3090584\n",
      " -0.17021154 -0.28580266 -1.9781327  -0.01164202 -0.4419191  -1.9852787\n",
      "  0.14452685 -0.4082745  -1.4395851  -0.1515084  -0.28138012 -1.2413476\n",
      " -0.07809791 -0.2569893  -1.32596    -0.03802535 -0.26520687 -1.4416137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.04524281 -0.27753115 -1.283142    0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0202, -0.0428, -0.2428,  ...,  0.0467, -0.2376, -1.2630],\n",
      "        [ 0.0202, -0.0428, -0.2428,  ...,  0.0467, -0.2376, -1.2630],\n",
      "        [ 0.0202, -0.0428, -0.2428,  ...,  0.0467, -0.2376, -1.2630],\n",
      "        ...,\n",
      "        [-0.1511,  0.3555, -0.0889,  ..., -0.7689,  0.8455, -0.3547],\n",
      "        [-0.1288, -0.1472,  0.5641,  ..., -0.2013,  0.6140,  0.2126],\n",
      "        [-0.1288, -0.1472,  0.5641,  ..., -0.2013,  0.6140,  0.2126]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02019228 -0.04277489 -0.24275105  0.03716334 -0.16916205 -0.62257725\n",
      " -0.07060383 -0.3640619  -1.3900006  -0.21815836 -0.42654172 -1.6869228\n",
      " -0.38556272 -0.531198   -2.1698554  -0.17956588 -0.66172576 -1.5490582\n",
      "  0.01122697 -0.7040379  -1.3730419  -0.04052994 -0.63539076 -1.4311464\n",
      " -0.04362262 -0.78646815 -1.550343   -0.1363106  -0.56549525 -1.459578\n",
      " -0.06689739 -0.6179882  -1.432195   -0.08236119 -0.5931394  -1.5263836\n",
      "  0.05281722 -0.61507845 -1.5585434  -0.05104025 -0.471264   -1.2930353\n",
      " -0.17723507 -0.24574116 -1.9753094  -0.01677906 -0.40361458 -1.9856722\n",
      "  0.14602163 -0.3733844  -1.4172423  -0.15392727 -0.24128874 -1.2252719\n",
      " -0.08468667 -0.2196204  -1.3114004  -0.04687721 -0.22472754 -1.428191\n",
      "  0.04669012 -0.23758869 -1.2629838 ]\n",
      "data: [ 0.02019228 -0.04277489 -0.24275105  0.03716334 -0.16916205 -0.62257725\n",
      " -0.07060383 -0.3640619  -1.3900006  -0.21815836 -0.42654172 -1.6869228\n",
      " -0.38556272 -0.531198   -2.1698554  -0.17956586 -0.66172576 -1.5490582\n",
      "  0.01122697 -0.7040379  -1.3730419  -0.04052994 -0.63539076 -1.4311464\n",
      " -0.04362262 -0.78646815 -1.550343   -0.1363106  -0.56549525 -1.459578\n",
      " -0.06689739 -0.6179882  -1.432195   -0.08236119 -0.5931394  -1.5263836\n",
      "  0.05281721 -0.61507845 -1.5585434  -0.05104025 -0.471264   -1.2930353\n",
      " -0.17723507 -0.24574116 -1.9753095  -0.01677906 -0.40361458 -1.9856724\n",
      "  0.14602163 -0.3733844  -1.4172423  -0.15392727 -0.24128874 -1.2252719\n",
      " -0.08468667 -0.2196204  -1.3114004  -0.04687721 -0.22472754 -1.428191\n",
      "  0.04669012 -0.23758869 -1.2629838   0.17      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0093, -0.0192, -0.2377,  ...,  0.0328, -0.2122, -1.2846],\n",
      "        [ 0.0093, -0.0192, -0.2377,  ...,  0.0328, -0.2122, -1.2846],\n",
      "        [ 0.0093, -0.0192, -0.2377,  ...,  0.0328, -0.2122, -1.2846],\n",
      "        ...,\n",
      "        [-0.1936,  0.3227, -0.1152,  ..., -0.8308,  0.7761, -0.2918],\n",
      "        [-0.1430, -0.1691,  0.5405,  ..., -0.2129,  0.6058,  0.2098],\n",
      "        [-0.1430, -0.1691,  0.5405,  ..., -0.2129,  0.6058,  0.2098]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00928621 -0.01920857 -0.23772818  0.01956337 -0.15904869 -0.6548717\n",
      " -0.07677667 -0.33936954 -1.3950641  -0.22127128 -0.40305784 -1.6890491\n",
      " -0.39732265 -0.5129807  -2.1619744  -0.19583629 -0.6288817  -1.5481505\n",
      "  0.00258844 -0.6602255  -1.3587403  -0.04320879 -0.59342456 -1.416819\n",
      " -0.03967418 -0.7303786  -1.530963   -0.15452744 -0.5253917  -1.4667717\n",
      " -0.07658036 -0.57796955 -1.4365426  -0.08949334 -0.5558691  -1.5330348\n",
      "  0.05083033 -0.5696417  -1.5772951  -0.07061616 -0.4453826  -1.2992059\n",
      " -0.17573851 -0.22235253 -1.9199605  -0.02888759 -0.36910567 -1.9215189\n",
      "  0.13210061 -0.3430561  -1.43339    -0.16500027 -0.20984398 -1.2357014\n",
      " -0.09659541 -0.19093972 -1.3179374  -0.05129281 -0.197874   -1.434884\n",
      "  0.03277459 -0.21218194 -1.2846292 ]\n",
      "data: [ 0.00928621 -0.01920857 -0.23772818  0.01956337 -0.15904869 -0.6548717\n",
      " -0.07677667 -0.33936954 -1.3950641  -0.22127129 -0.40305787 -1.6890491\n",
      " -0.39732265 -0.5129807  -2.1619744  -0.19583629 -0.6288817  -1.5481505\n",
      "  0.00258844 -0.6602255  -1.3587403  -0.04320879 -0.59342456 -1.416819\n",
      " -0.03967418 -0.7303786  -1.530963   -0.15452744 -0.5253917  -1.4667717\n",
      " -0.07658036 -0.57796955 -1.4365426  -0.08949334 -0.5558691  -1.5330348\n",
      "  0.05083033 -0.5696417  -1.5772951  -0.07061616 -0.44538262 -1.2992059\n",
      " -0.17573851 -0.22235255 -1.9199605  -0.02888759 -0.3691057  -1.9215188\n",
      "  0.13210061 -0.3430561  -1.43339    -0.16500026 -0.20984398 -1.2357014\n",
      " -0.0965954  -0.19093972 -1.3179374  -0.05129281 -0.197874   -1.4348838\n",
      "  0.03277459 -0.21218196 -1.2846292   0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0295, -0.0945, -0.2256,  ...,  0.0405, -0.2796, -1.2881],\n",
      "        [ 0.0295, -0.0945, -0.2256,  ...,  0.0405, -0.2796, -1.2881],\n",
      "        [ 0.0295, -0.0945, -0.2256,  ...,  0.0405, -0.2796, -1.2881],\n",
      "        ...,\n",
      "        [-0.3370,  0.2709, -0.3637,  ..., -0.8788,  0.7226, -0.5099],\n",
      "        [-0.1401, -0.0879,  0.6051,  ..., -0.2403,  0.7060,  0.2835],\n",
      "        [-0.1401, -0.0879,  0.6051,  ..., -0.2403,  0.7060,  0.2835]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02947903 -0.09449033 -0.22562076  0.0494662  -0.23549654 -0.65321016\n",
      " -0.04418155 -0.40826556 -1.3880646  -0.18497194 -0.47085175 -1.6765215\n",
      " -0.3501453  -0.57372755 -2.1577816  -0.16563886 -0.6995197  -1.5421674\n",
      "  0.02106267 -0.72445995 -1.3696043  -0.02279525 -0.657014   -1.4312449\n",
      " -0.02097727 -0.78848106 -1.5430133  -0.1308574  -0.5979456  -1.4678268\n",
      " -0.05482372 -0.64495265 -1.4381151  -0.07517344 -0.6204807  -1.5321007\n",
      "  0.05921961 -0.630571   -1.5757165  -0.0549294  -0.5180179  -1.3017633\n",
      " -0.15279463 -0.29466188 -1.9048996  -0.01601275 -0.43404132 -1.9080775\n",
      "  0.13356791 -0.40873802 -1.4364016  -0.14319922 -0.28572083 -1.2418501\n",
      " -0.08212921 -0.26302388 -1.3198838  -0.03922741 -0.26450065 -1.4380026\n",
      "  0.0404722  -0.2795503  -1.2880957 ]\n",
      "data: [ 0.02947903 -0.09449033 -0.22562076  0.0494662  -0.23549654 -0.65321016\n",
      " -0.04418155 -0.40826556 -1.3880646  -0.18497194 -0.47085175 -1.6765217\n",
      " -0.3501453  -0.57372755 -2.1577816  -0.16563886 -0.69951975 -1.5421673\n",
      "  0.02106267 -0.7244599  -1.3696043  -0.02279525 -0.657014   -1.4312449\n",
      " -0.02097727 -0.78848106 -1.5430133  -0.1308574  -0.5979456  -1.4678268\n",
      " -0.05482372 -0.6449526  -1.4381151  -0.07517344 -0.6204807  -1.5321007\n",
      "  0.05921961 -0.630571   -1.5757165  -0.0549294  -0.5180179  -1.3017633\n",
      " -0.15279463 -0.29466188 -1.9048996  -0.01601275 -0.43404132 -1.9080776\n",
      "  0.13356791 -0.40873802 -1.4364017  -0.14319922 -0.28572083 -1.2418501\n",
      " -0.08212921 -0.26302388 -1.3198838  -0.03922741 -0.26450065 -1.4380026\n",
      "  0.0404722  -0.2795503  -1.2880957   0.19      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0285, -0.0803, -0.2340,  ...,  0.0527, -0.2720, -1.2526],\n",
      "        [ 0.0285, -0.0803, -0.2340,  ...,  0.0527, -0.2720, -1.2526],\n",
      "        [ 0.0285, -0.0803, -0.2340,  ...,  0.0527, -0.2720, -1.2526],\n",
      "        ...,\n",
      "        [-0.1326,  0.4101, -0.0849,  ..., -0.6781,  0.9048, -0.3702],\n",
      "        [-0.1697, -0.1335,  0.5778,  ..., -0.2695,  0.6408,  0.2197],\n",
      "        [-0.1697, -0.1335,  0.5778,  ..., -0.2695,  0.6408,  0.2197]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02847145 -0.08030284 -0.23400176  0.05498813 -0.20074275 -0.6039785\n",
      " -0.05825195 -0.4080009  -1.4027426  -0.20327812 -0.47348276 -1.6963608\n",
      " -0.35907036 -0.57407355 -2.1870222  -0.16387652 -0.70325196 -1.5611544\n",
      "  0.02587382 -0.75316155 -1.3851788  -0.02858418 -0.68538463 -1.4405713\n",
      " -0.0414078  -0.8399539  -1.5628772  -0.12165201 -0.6102208  -1.466548\n",
      " -0.05699994 -0.6634978  -1.4394267  -0.07510778 -0.63463485 -1.5268743\n",
      "  0.05300647 -0.6634426  -1.5553713  -0.03874546 -0.50898767 -1.3008404\n",
      " -0.17738284 -0.2788393  -2.0152836  -0.01021594 -0.4430807  -2.0297492\n",
      "  0.14800236 -0.40876338 -1.4149699  -0.14806302 -0.27966565 -1.2265413\n",
      " -0.07684343 -0.25393113 -1.3124378  -0.04017337 -0.25945124 -1.4264517\n",
      "  0.05271142 -0.27202243 -1.2525954 ]\n",
      "data: [ 0.02847145 -0.08030284 -0.23400176  0.05498813 -0.20074277 -0.6039785\n",
      " -0.05825195 -0.40800086 -1.4027426  -0.20327812 -0.47348273 -1.6963608\n",
      " -0.35907036 -0.57407355 -2.1870222  -0.16387652 -0.70325196 -1.5611544\n",
      "  0.02587382 -0.75316155 -1.3851788  -0.02858418 -0.6853846  -1.4405713\n",
      " -0.0414078  -0.8399539  -1.5628772  -0.12165201 -0.6102208  -1.466548\n",
      " -0.05699994 -0.66349775 -1.4394268  -0.07510778 -0.63463485 -1.5268742\n",
      "  0.05300647 -0.6634426  -1.5553713  -0.03874546 -0.50898767 -1.3008405\n",
      " -0.17738286 -0.2788393  -2.0152836  -0.01021594 -0.44308072 -2.0297492\n",
      "  0.14800236 -0.40876338 -1.4149699  -0.14806302 -0.27966565 -1.2265413\n",
      " -0.07684343 -0.25393113 -1.3124378  -0.04017337 -0.25945124 -1.4264517\n",
      "  0.05271142 -0.27202243 -1.2525954   0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0224, -0.0294, -0.2245,  ...,  0.0506, -0.2199, -1.2611],\n",
      "        [ 0.0224, -0.0294, -0.2245,  ...,  0.0506, -0.2199, -1.2611],\n",
      "        [ 0.0224, -0.0294, -0.2245,  ...,  0.0506, -0.2199, -1.2611],\n",
      "        ...,\n",
      "        [-0.1752,  0.3138, -0.0921,  ..., -0.8016,  0.7585, -0.2801],\n",
      "        [-0.1391, -0.1422,  0.5642,  ..., -0.1991,  0.6125,  0.2231],\n",
      "        [-0.1391, -0.1422,  0.5642,  ..., -0.1991,  0.6125,  0.2231]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02235977 -0.02943329 -0.22449256  0.03543291 -0.1676367  -0.63029695\n",
      " -0.05529554 -0.35741526 -1.3777707  -0.20092773 -0.41997123 -1.6808313\n",
      " -0.37707824 -0.53669703 -2.148804   -0.18592001 -0.64263296 -1.5342613\n",
      "  0.03113262 -0.6780659  -1.3385181  -0.02243443 -0.6165737  -1.3931004\n",
      " -0.02722833 -0.75665426 -1.5116166  -0.13910289 -0.5379542  -1.4443015\n",
      " -0.05878784 -0.59574175 -1.4188774  -0.06939655 -0.5728545  -1.5164746\n",
      "  0.06088826 -0.59815407 -1.5608163  -0.04609021 -0.44795874 -1.2731712\n",
      " -0.16757281 -0.22467497 -1.9336927  -0.00931098 -0.383199   -1.9341011\n",
      "  0.14888237 -0.35125306 -1.4133735  -0.15085094 -0.21210827 -1.2083666\n",
      " -0.07077003 -0.193139   -1.2919248  -0.02678904 -0.20849164 -1.4086734\n",
      "  0.05059134 -0.2198879  -1.2610894 ]\n",
      "data: [-4.53 -0.46 -0.99 -4.27 -0.06 -0.69  0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.   -3.82  0.82 -4.09  0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.   -3.68  1.25 -4.04 -3.71  1.32 -4.09\n",
      " -3.78  1.43 -4.27  0.    0.    0.   -3.63  1.04 -4.01 -3.69  1.35 -4.08\n",
      " -3.75  1.45 -4.15 -4.84 -0.06 -0.01 -4.76  0.14 -0.28 -4.74  0.28 -0.83\n",
      "  0.    0.    0.    0.  ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[-0.0616, -0.0989, -0.3574,  ...,  0.0308, -0.3425, -0.6167],\n",
      "        [-0.0616, -0.0989, -0.3574,  ...,  0.0308, -0.3425, -0.6167],\n",
      "        [-0.0616, -0.0989, -0.3574,  ...,  0.0308, -0.3425, -0.6167],\n",
      "        ...,\n",
      "        [ 0.5100,  0.4480,  0.0639,  ...,  0.2533,  0.8246, -0.7671],\n",
      "        [ 0.4547, -0.2717,  1.1917,  ..., -1.0919,  0.3483,  0.4608],\n",
      "        [ 0.4547, -0.2717,  1.1917,  ..., -1.0919,  0.3483,  0.4608]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.06159512 -0.09888814 -0.3573879  -0.14766493 -0.18241678 -0.67857355\n",
      " -0.17417017 -0.26297915 -0.89150494 -0.20749469 -0.3308816  -0.9291102\n",
      " -0.20983192 -0.3942481  -1.0895681  -0.22721528 -0.355773   -1.0514485\n",
      " -0.08823545 -0.36254534 -0.65349936 -0.1156304  -0.40354416 -0.6623882\n",
      " -0.10940352 -0.4071207  -0.743747   -0.21565776 -0.3231642  -1.0387394\n",
      " -0.18061316 -0.34741795 -0.9775894  -0.14346008 -0.35464376 -0.95585185\n",
      " -0.08546731 -0.42304897 -0.89687306 -0.1574499  -0.27153972 -0.97456473\n",
      " -0.10960367 -0.30154997 -0.7116641  -0.09800826 -0.32457992 -0.69676304\n",
      "  0.03570297 -0.36801982 -0.81507385 -0.15547906 -0.19662386 -0.8594278\n",
      " -0.06648405 -0.24405976 -0.7866912  -0.06333552 -0.29356343 -0.7742376\n",
      "  0.03076672 -0.34251368 -0.61673343]\n",
      "init: [-0.06159512 -0.09888814 -0.3573879  -0.14766493 -0.18241678 -0.67857355\n",
      " -0.17417017 -0.26297915 -0.89150494 -0.20749469 -0.3308816  -0.9291102\n",
      " -0.20983192 -0.3942481  -1.0895681  -0.22721528 -0.355773   -1.0514485\n",
      " -0.08823545 -0.36254534 -0.65349936 -0.1156304  -0.40354416 -0.6623882\n",
      " -0.10940352 -0.4071207  -0.743747   -0.21565776 -0.3231642  -1.0387394\n",
      " -0.18061316 -0.34741795 -0.9775894  -0.14346008 -0.35464376 -0.95585185\n",
      " -0.08546731 -0.42304897 -0.89687306 -0.1574499  -0.27153972 -0.97456473\n",
      " -0.10960367 -0.30154997 -0.7116641  -0.09800826 -0.32457992 -0.69676304\n",
      "  0.03570297 -0.36801982 -0.81507385 -0.15547906 -0.19662386 -0.8594278\n",
      " -0.06648405 -0.24405976 -0.7866912  -0.06333552 -0.29356343 -0.7742376\n",
      "  0.03076672 -0.34251368 -0.61673343]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [-0.06159512 -0.09888814 -0.3573879  -0.14766493 -0.18241678 -0.67857355\n",
      " -0.17417017 -0.26297915 -0.891505   -0.20749469 -0.33088157 -0.9291103\n",
      " -0.20983192 -0.3942481  -1.0895681  -0.22721528 -0.355773   -1.0514485\n",
      " -0.08823545 -0.36254537 -0.65349936 -0.11563041 -0.40354416 -0.6623882\n",
      " -0.10940352 -0.4071207  -0.743747   -0.21565776 -0.32316417 -1.0387394\n",
      " -0.18061316 -0.34741795 -0.9775894  -0.14346008 -0.35464373 -0.9558518\n",
      " -0.08546731 -0.42304897 -0.8968731  -0.1574499  -0.27153972 -0.97456473\n",
      " -0.10960367 -0.30154997 -0.711664   -0.09800826 -0.32457992 -0.696763\n",
      "  0.03570297 -0.36801982 -0.81507385 -0.15547906 -0.19662386 -0.8594278\n",
      " -0.06648405 -0.24405976 -0.7866912  -0.06333552 -0.29356343 -0.7742376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.03076672 -0.34251368 -0.61673343  0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[ 0.2892, -0.1116, -0.0274,  ...,  0.3475, -0.2799, -1.1951],\n",
      "        [ 0.2892, -0.1116, -0.0274,  ...,  0.3475, -0.2799, -1.1951],\n",
      "        [ 0.2892, -0.1116, -0.0274,  ...,  0.3475, -0.2799, -1.1951],\n",
      "        ...,\n",
      "        [-0.3509,  0.3386,  0.2062,  ..., -0.2344,  1.0064,  0.0143],\n",
      "        [-0.3723,  0.1065,  0.0543,  ..., -0.8547,  0.7977, -0.0714],\n",
      "        [-0.3723,  0.1065,  0.0543,  ..., -0.8547,  0.7977, -0.0714]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.2892052  -0.11159389 -0.02741515  0.33861566 -0.23916528 -0.50993496\n",
      "  0.2948746  -0.3436696  -1.1940434   0.15625882 -0.3730706  -1.4777098\n",
      "  0.05073822 -0.48649526 -2.0213895   0.09556359 -0.66309094 -1.379338\n",
      "  0.39751607 -0.6333294  -1.122509    0.3460033  -0.5440927  -1.1751587\n",
      "  0.32102394 -0.61515456 -1.3030899   0.12420428 -0.5839757  -1.3278599\n",
      "  0.26980007 -0.6057713  -1.328527    0.26500875 -0.52260417 -1.3958173\n",
      "  0.3780082  -0.56310046 -1.4418764   0.25084707 -0.5163857  -1.1678164\n",
      "  0.19998464 -0.2390842  -1.6019726   0.32512933 -0.3806346  -1.5779197\n",
      "  0.46238378 -0.32977885 -1.3653932   0.1331511  -0.29079264 -1.1048086\n",
      "  0.2648838  -0.24446303 -1.1782615   0.3037019  -0.27116925 -1.302675\n",
      "  0.34754008 -0.2798958  -1.1950808 ]\n",
      "data: [ 0.2892052  -0.11159389 -0.02741515  0.33861566 -0.23916526 -0.50993496\n",
      "  0.2948746  -0.3436696  -1.1940434   0.15625882 -0.3730706  -1.4777098\n",
      "  0.05073822 -0.48649526 -2.0213895   0.09556359 -0.66309094 -1.379338\n",
      "  0.39751607 -0.6333294  -1.122509    0.3460033  -0.5440927  -1.1751587\n",
      "  0.32102394 -0.61515456 -1.3030899   0.12420427 -0.5839757  -1.3278598\n",
      "  0.26980007 -0.6057713  -1.328527    0.26500875 -0.52260417 -1.3958173\n",
      "  0.3780082  -0.56310046 -1.4418764   0.25084707 -0.5163857  -1.1678164\n",
      "  0.19998464 -0.2390842  -1.6019727   0.32512933 -0.3806346  -1.5779197\n",
      "  0.46238378 -0.32977885 -1.3653932   0.1331511  -0.29079264 -1.1048086\n",
      "  0.2648838  -0.24446303 -1.1782615   0.3037019  -0.27116925 -1.302675\n",
      "  0.34754008 -0.2798958  -1.1950808   0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0991, -0.0931, -0.1294,  ...,  0.1359, -0.2614, -1.2076],\n",
      "        [ 0.0991, -0.0931, -0.1294,  ...,  0.1359, -0.2614, -1.2076],\n",
      "        [ 0.0991, -0.0931, -0.1294,  ...,  0.1359, -0.2614, -1.2076],\n",
      "        ...,\n",
      "        [-0.2792,  0.3122, -0.0283,  ..., -0.7693,  0.8389, -0.5401],\n",
      "        [-0.3182,  0.0620,  0.3594,  ..., -0.2562,  0.8672, -0.1510],\n",
      "        [-0.3182,  0.0620,  0.3594,  ..., -0.2562,  0.8672, -0.1510]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0990836  -0.09314179 -0.12941873  0.12400255 -0.26048994 -0.55957353\n",
      "  0.06785074 -0.4430298  -1.321447   -0.07196943 -0.50558496 -1.6328049\n",
      " -0.25644803 -0.64935726 -2.1117072  -0.13507846 -0.667788   -1.5244257\n",
      "  0.170044   -0.67908037 -1.2202975   0.11573125 -0.63365394 -1.2582569\n",
      "  0.08787798 -0.7367581  -1.3792622  -0.08584931 -0.5402435  -1.4321455\n",
      "  0.0299793  -0.61069494 -1.4023988   0.03100913 -0.584784   -1.4946207\n",
      "  0.14663748 -0.6225173  -1.5688828   0.03208333 -0.46531    -1.2451272\n",
      " -0.0794217  -0.23936233 -1.8278072   0.07844911 -0.41103595 -1.7982236\n",
      "  0.21951726 -0.36025232 -1.3901112  -0.07997917 -0.22264296 -1.181436\n",
      "  0.03468497 -0.20562966 -1.2185676   0.09845467 -0.25143403 -1.3346069\n",
      "  0.13587597 -0.26144475 -1.2076298 ]\n",
      "data: [ 0.0990836  -0.09314179 -0.12941873  0.12400255 -0.26048994 -0.55957353\n",
      "  0.06785074 -0.4430298  -1.321447   -0.07196943 -0.50558496 -1.6328049\n",
      " -0.25644803 -0.6493572  -2.1117072  -0.13507846 -0.667788   -1.5244259\n",
      "  0.170044   -0.67908037 -1.2202975   0.11573126 -0.63365394 -1.2582569\n",
      "  0.08787798 -0.7367581  -1.3792622  -0.08584931 -0.5402435  -1.4321456\n",
      "  0.0299793  -0.61069494 -1.4023988   0.03100913 -0.584784   -1.4946207\n",
      "  0.14663748 -0.6225173  -1.5688827   0.03208333 -0.46531    -1.2451272\n",
      " -0.0794217  -0.23936233 -1.8278072   0.07844911 -0.41103595 -1.7982236\n",
      "  0.21951728 -0.3602523  -1.3901112  -0.07997917 -0.22264296 -1.181436\n",
      "  0.03468497 -0.20562965 -1.2185676   0.09845467 -0.25143403 -1.3346069\n",
      "  0.13587597 -0.26144475 -1.2076298   0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0246, -0.0876, -0.2159,  ...,  0.0647, -0.2677, -1.2753],\n",
      "        [ 0.0246, -0.0876, -0.2159,  ...,  0.0647, -0.2677, -1.2753],\n",
      "        [ 0.0246, -0.0876, -0.2159,  ...,  0.0647, -0.2677, -1.2753],\n",
      "        ...,\n",
      "        [-0.1028,  0.5222, -0.0966,  ..., -0.6027,  1.0443, -0.4941],\n",
      "        [-0.1544,  0.0124,  0.5803,  ..., -0.2409,  0.7955,  0.1463],\n",
      "        [-0.1544,  0.0124,  0.5803,  ..., -0.2409,  0.7955,  0.1463]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.4595644e-02 -8.7649614e-02 -2.1590614e-01  4.9370226e-02\n",
      " -2.2423454e-01 -5.9941554e-01 -4.7251999e-02 -4.3276685e-01\n",
      " -1.4084921e+00 -1.9889624e-01 -4.9900988e-01 -1.7208235e+00\n",
      " -3.7183896e-01 -6.1948007e-01 -2.2092423e+00 -1.9038644e-01\n",
      " -6.9741499e-01 -1.6050162e+00  6.1796576e-02 -7.3986822e-01\n",
      " -1.3613328e+00  6.8969429e-03 -6.8233395e-01 -1.4078052e+00\n",
      " -1.3778344e-02 -8.2231849e-01 -1.5369936e+00 -1.3912226e-01\n",
      " -5.8733827e-01 -1.5010624e+00 -5.1831655e-02 -6.5472591e-01\n",
      " -1.4750342e+00 -5.3289592e-02 -6.2817681e-01 -1.5705584e+00\n",
      "  8.0164537e-02 -6.6740036e-01 -1.6212204e+00 -3.5210364e-02\n",
      " -4.9174011e-01 -1.3172528e+00 -1.7352998e-01 -2.5882936e-01\n",
      " -2.0017567e+00  1.8806830e-03 -4.3626267e-01 -1.9994822e+00\n",
      "  1.7168242e-01 -3.9205313e-01 -1.4527310e+00 -1.5875620e-01\n",
      " -2.4994309e-01 -1.2417182e+00 -6.2314749e-02 -2.2567256e-01\n",
      " -1.3114629e+00 -1.0491908e-02 -2.5523207e-01 -1.4271759e+00\n",
      "  6.4735301e-02 -2.6772910e-01 -1.2753187e+00]\n",
      "data: [ 2.4595644e-02 -8.7649614e-02 -2.1590614e-01  4.9370226e-02\n",
      " -2.2423454e-01 -5.9941554e-01 -4.7251996e-02 -4.3276682e-01\n",
      " -1.4084921e+00 -1.9889623e-01 -4.9900991e-01 -1.7208235e+00\n",
      " -3.7183896e-01 -6.1948007e-01 -2.2092423e+00 -1.9038644e-01\n",
      " -6.9741499e-01 -1.6050162e+00  6.1796576e-02 -7.3986822e-01\n",
      " -1.3613327e+00  6.8969429e-03 -6.8233401e-01 -1.4078052e+00\n",
      " -1.3778343e-02 -8.2231849e-01 -1.5369935e+00 -1.3912226e-01\n",
      " -5.8733827e-01 -1.5010623e+00 -5.1831655e-02 -6.5472585e-01\n",
      " -1.4750342e+00 -5.3289596e-02 -6.2817681e-01 -1.5705584e+00\n",
      "  8.0164537e-02 -6.6740036e-01 -1.6212204e+00 -3.5210364e-02\n",
      " -4.9174011e-01 -1.3172528e+00 -1.7352998e-01 -2.5882936e-01\n",
      " -2.0017567e+00  1.8806830e-03 -4.3626267e-01 -1.9994822e+00\n",
      "  1.7168242e-01 -3.9205316e-01 -1.4527310e+00 -1.5875620e-01\n",
      " -2.4994308e-01 -1.2417182e+00 -6.2314749e-02 -2.2567254e-01\n",
      " -1.3114629e+00 -1.0491908e-02 -2.5523207e-01 -1.4271759e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6.4735301e-02 -2.6772910e-01 -1.2753187e+00  3.9999999e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0243, -0.1195, -0.2455,  ...,  0.0630, -0.2966, -1.3201],\n",
      "        [ 0.0243, -0.1195, -0.2455,  ...,  0.0630, -0.2966, -1.3201],\n",
      "        [ 0.0243, -0.1195, -0.2455,  ...,  0.0630, -0.2966, -1.3201],\n",
      "        ...,\n",
      "        [-0.1069,  0.4229, -0.1196,  ..., -0.6190,  0.9267, -0.4073],\n",
      "        [-0.1204, -0.0885,  0.6407,  ..., -0.2091,  0.6557,  0.3153],\n",
      "        [-0.1204, -0.0885,  0.6407,  ..., -0.2091,  0.6557,  0.3153]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02428309 -0.11954894 -0.24548194  0.03990952 -0.2724902  -0.6756314\n",
      " -0.02216232 -0.45206437 -1.400195   -0.16421367 -0.5122546  -1.7101653\n",
      " -0.34176058 -0.644566   -2.168634   -0.19119185 -0.71943474 -1.573407\n",
      "  0.07108244 -0.7424136  -1.3610795   0.01575805 -0.68934155 -1.4079131\n",
      "  0.01256885 -0.8080539  -1.5257204  -0.13991244 -0.6040507  -1.4842148\n",
      " -0.03723163 -0.66655755 -1.4658813  -0.03576914 -0.64043045 -1.5658762\n",
      "  0.0862408  -0.6747672  -1.6269851  -0.03258388 -0.51800406 -1.3064071\n",
      " -0.14247288 -0.29373097 -1.9142742   0.01304565 -0.45359907 -1.900081\n",
      "  0.16608733 -0.41395122 -1.4770432  -0.14636952 -0.27400756 -1.2450683\n",
      " -0.0424509  -0.25512287 -1.3232636   0.01015969 -0.28821456 -1.4401362\n",
      "  0.06304202 -0.29660445 -1.3201377 ]\n",
      "data: [ 0.02428309 -0.11954894 -0.24548192  0.03990952 -0.2724902  -0.6756314\n",
      " -0.02216232 -0.45206437 -1.400195   -0.16421367 -0.5122546  -1.7101653\n",
      " -0.34176055 -0.64456594 -2.168634   -0.19119185 -0.71943474 -1.5734069\n",
      "  0.07108244 -0.7424136  -1.3610795   0.01575805 -0.6893416  -1.4079131\n",
      "  0.01256885 -0.8080539  -1.5257204  -0.13991244 -0.6040507  -1.4842148\n",
      " -0.03723163 -0.66655755 -1.4658813  -0.03576914 -0.64043045 -1.5658764\n",
      "  0.0862408  -0.67476726 -1.6269851  -0.03258388 -0.51800406 -1.3064072\n",
      " -0.14247288 -0.29373097 -1.9142743   0.01304565 -0.45359907 -1.900081\n",
      "  0.16608733 -0.41395122 -1.4770432  -0.14636952 -0.27400756 -1.2450683\n",
      " -0.0424509  -0.25512287 -1.3232636   0.01015969 -0.28821456 -1.4401363\n",
      "  0.06304202 -0.29660445 -1.3201377   0.05      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0610, -0.1881, -0.2800,  ...,  0.0731, -0.3645, -1.3512],\n",
      "        [ 0.0610, -0.1881, -0.2800,  ...,  0.0731, -0.3645, -1.3512],\n",
      "        [ 0.0610, -0.1881, -0.2800,  ...,  0.0731, -0.3645, -1.3512],\n",
      "        ...,\n",
      "        [-0.0803,  0.4768, -0.1248,  ..., -0.6099,  0.9725, -0.4584],\n",
      "        [-0.1445, -0.0454,  0.6598,  ..., -0.1949,  0.6979,  0.3127],\n",
      "        [-0.1445, -0.0454,  0.6598,  ..., -0.1949,  0.6979,  0.3127]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0610242  -0.18809211 -0.27998686  0.0884272  -0.3227576  -0.6722292\n",
      "  0.00327726 -0.5266839  -1.4626255  -0.14412719 -0.58906525 -1.7718278\n",
      " -0.3093778  -0.70590043 -2.2612972  -0.14879082 -0.7997464  -1.6507785\n",
      "  0.09208198 -0.8426266  -1.4410006   0.0313105  -0.7861967  -1.4873751\n",
      "  0.0102001  -0.9250101  -1.610809   -0.10034478 -0.6936878  -1.5505732\n",
      " -0.01854564 -0.75655806 -1.5283685  -0.02851769 -0.7297543  -1.6239767\n",
      "  0.08429462 -0.7690097  -1.6689287  -0.00229212 -0.5925791  -1.3766435\n",
      " -0.14244    -0.36394832 -2.0621588   0.02350897 -0.53630555 -2.062357\n",
      "  0.17098993 -0.49364004 -1.5177222  -0.12440309 -0.35472023 -1.3059919\n",
      " -0.03261502 -0.33110076 -1.3810996   0.01014023 -0.35780498 -1.494496\n",
      "  0.07314367 -0.36447144 -1.3511688 ]\n",
      "data: [ 0.0610242  -0.18809211 -0.27998686  0.0884272  -0.3227576  -0.6722292\n",
      "  0.00327726 -0.5266839  -1.4626254  -0.14412719 -0.58906525 -1.7718278\n",
      " -0.3093778  -0.70590043 -2.2612972  -0.14879082 -0.7997464  -1.6507785\n",
      "  0.09208198 -0.8426266  -1.4410005   0.0313105  -0.78619677 -1.4873751\n",
      "  0.0102001  -0.9250101  -1.610809   -0.10034477 -0.6936878  -1.5505732\n",
      " -0.01854564 -0.75655806 -1.5283685  -0.0285177  -0.7297543  -1.6239767\n",
      "  0.08429462 -0.7690097  -1.6689286  -0.00229212 -0.5925791  -1.3766435\n",
      " -0.14244    -0.36394832 -2.0621588   0.02350897 -0.53630555 -2.062357\n",
      "  0.17098993 -0.49364004 -1.5177224  -0.12440309 -0.35472023 -1.3059918\n",
      " -0.03261502 -0.33110076 -1.3810996   0.01014023 -0.35780498 -1.494496\n",
      "  0.07314367 -0.36447144 -1.3511689   0.06      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[-1.0588e-02, -1.4278e-01, -1.8799e-01,  ...,  4.6696e-02,\n",
      "         -3.3009e-01, -1.2345e+00],\n",
      "        [-1.0588e-02, -1.4278e-01, -1.8799e-01,  ...,  4.6696e-02,\n",
      "         -3.3009e-01, -1.2345e+00],\n",
      "        [-1.0588e-02, -1.4278e-01, -1.8799e-01,  ...,  4.6696e-02,\n",
      "         -3.3009e-01, -1.2345e+00],\n",
      "        ...,\n",
      "        [-2.6975e-02,  5.3857e-01, -1.3604e-01,  ..., -5.3487e-01,\n",
      "          1.0936e+00, -5.3815e-01],\n",
      "        [-7.5178e-02,  1.1375e-03,  6.0047e-01,  ..., -1.0785e-01,\n",
      "          6.6040e-01,  2.6148e-01],\n",
      "        [-7.5178e-02,  1.1375e-03,  6.0047e-01,  ..., -1.0785e-01,\n",
      "          6.6040e-01,  2.6148e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01058777 -0.14277557 -0.18798932  0.00965619 -0.28521892 -0.54969966\n",
      " -0.05334686 -0.47655338 -1.3244838  -0.20493993 -0.53367054 -1.6535815\n",
      " -0.39097893 -0.67456055 -2.1289983  -0.23278095 -0.7434703  -1.5354764\n",
      "  0.0526277  -0.77587056 -1.3285698  -0.01327248 -0.72639644 -1.3711553\n",
      " -0.01366428 -0.8560504  -1.495071   -0.17026901 -0.6285124  -1.4275339\n",
      " -0.06437545 -0.6997583  -1.4153764  -0.05796877 -0.6795293  -1.5254374\n",
      "  0.06028742 -0.7256707  -1.5825651  -0.05019306 -0.5356957  -1.2346733\n",
      " -0.18240781 -0.30996883 -1.9073956  -0.00870608 -0.4911001  -1.8936838\n",
      "  0.15414326 -0.44954833 -1.4079942  -0.17993738 -0.29148215 -1.1718132\n",
      " -0.05977298 -0.27967516 -1.2439901  -0.00894105 -0.32461643 -1.3602705\n",
      "  0.0466963  -0.33008593 -1.2345012 ]\n",
      "data: [-0.01058777 -0.14277557 -0.18798932  0.00965619 -0.28521892 -0.54969966\n",
      " -0.05334686 -0.47655338 -1.3244838  -0.20493993 -0.53367054 -1.6535815\n",
      " -0.39097893 -0.67456055 -2.1289983  -0.23278095 -0.7434703  -1.5354763\n",
      "  0.0526277  -0.77587056 -1.3285698  -0.01327248 -0.7263964  -1.3711553\n",
      " -0.01366428 -0.8560503  -1.495071   -0.17026901 -0.6285124  -1.4275339\n",
      " -0.06437545 -0.6997583  -1.4153764  -0.05796877 -0.67952937 -1.5254374\n",
      "  0.06028742 -0.7256707  -1.582565   -0.05019306 -0.5356957  -1.2346733\n",
      " -0.18240781 -0.30996883 -1.9073956  -0.00870608 -0.49110013 -1.8936838\n",
      "  0.15414326 -0.44954833 -1.407994   -0.17993738 -0.29148215 -1.1718132\n",
      " -0.05977298 -0.27967516 -1.2439901  -0.00894105 -0.32461643 -1.3602705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.04669629 -0.33008593 -1.2345012   0.07      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BB38>\n",
      "tensor([[ 0.0102, -0.0890, -0.1745,  ...,  0.0292, -0.2859, -1.1470],\n",
      "        [ 0.0102, -0.0890, -0.1745,  ...,  0.0292, -0.2859, -1.1470],\n",
      "        [ 0.0102, -0.0890, -0.1745,  ...,  0.0292, -0.2859, -1.1470],\n",
      "        ...,\n",
      "        [-0.1502,  0.4302, -0.0958,  ..., -0.3828,  1.0288, -0.5192],\n",
      "        [-0.0911, -0.0694,  0.6329,  ..., -0.2184,  0.6463,  0.2692],\n",
      "        [-0.0911, -0.0694,  0.6329,  ..., -0.2184,  0.6463,  0.2692]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01020548 -0.08899603 -0.17448173  0.04284561 -0.18452308 -0.4422792\n",
      " -0.11944649 -0.4257366  -1.3232718  -0.27532575 -0.49587703 -1.6038108\n",
      " -0.41768613 -0.57529056 -2.126519   -0.17739171 -0.73899066 -1.4984901\n",
      " -0.02975395 -0.81374776 -1.3538704  -0.07923384 -0.7334266  -1.4047964\n",
      " -0.08820219 -0.9120207  -1.5317428  -0.13830058 -0.65664303 -1.396625\n",
      " -0.09383081 -0.70535827 -1.3632185  -0.10614808 -0.6660391  -1.438674\n",
      "  0.0416771  -0.6984756  -1.4468226  -0.0613156  -0.5386749  -1.2421343\n",
      " -0.23005739 -0.29807603 -2.028931   -0.03719887 -0.4739975  -2.0633757\n",
      "  0.14546034 -0.4311972  -1.3200438  -0.18581872 -0.31281704 -1.157182\n",
      " -0.12701198 -0.27852133 -1.2473352  -0.09925075 -0.27050698 -1.3601727\n",
      "  0.02919466 -0.28586328 -1.1469564 ]\n",
      "data: [ 0.01020548 -0.08899603 -0.17448173  0.04284561 -0.18452306 -0.44227922\n",
      " -0.11944649 -0.4257366  -1.3232718  -0.27532575 -0.49587703 -1.6038108\n",
      " -0.4176861  -0.57529056 -2.126519   -0.17739171 -0.7389906  -1.4984901\n",
      " -0.02975395 -0.81374776 -1.3538704  -0.07923384 -0.7334266  -1.4047962\n",
      " -0.08820219 -0.91202074 -1.5317428  -0.13830058 -0.6566431  -1.396625\n",
      " -0.0938308  -0.70535827 -1.3632185  -0.10614808 -0.6660391  -1.438674\n",
      "  0.0416771  -0.6984756  -1.4468226  -0.0613156  -0.5386749  -1.2421343\n",
      " -0.23005739 -0.29807603 -2.028931   -0.03719887 -0.4739975  -2.0633757\n",
      "  0.14546034 -0.4311972  -1.3200438  -0.18581872 -0.31281704 -1.157182\n",
      " -0.12701198 -0.27852133 -1.2473352  -0.09925075 -0.27050698 -1.3601727\n",
      "  0.02919466 -0.28586328 -1.1469564   0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[-0.0425,  0.0082, -0.2159,  ..., -0.0048, -0.1770, -1.1976],\n",
      "        [-0.0425,  0.0082, -0.2159,  ..., -0.0048, -0.1770, -1.1976],\n",
      "        [-0.0425,  0.0082, -0.2159,  ..., -0.0048, -0.1770, -1.1976],\n",
      "        ...,\n",
      "        [-0.1304,  0.3661,  0.1172,  ..., -0.6541,  0.9515, -0.2600],\n",
      "        [-0.0725, -0.0687,  0.5986,  ..., -0.2261,  0.6476,  0.2675],\n",
      "        [-0.0725, -0.0687,  0.5986,  ..., -0.2261,  0.6476,  0.2675]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.04254099  0.00817353 -0.21592948 -0.02015235 -0.10115206 -0.536059\n",
      " -0.16061422 -0.32004815 -1.3597233  -0.31758484 -0.3820755  -1.6518495\n",
      " -0.47889867 -0.47604698 -2.1475694  -0.24254376 -0.62623006 -1.5224819\n",
      " -0.06341258 -0.68262464 -1.3538148  -0.10850455 -0.6036809  -1.4075768\n",
      " -0.10495126 -0.7676115  -1.5346196  -0.19877376 -0.53507674 -1.4237239\n",
      " -0.13361621 -0.58577764 -1.3915386  -0.1336798  -0.5491936  -1.4794235\n",
      "  0.02656446 -0.576899   -1.5021238  -0.1113487  -0.42754978 -1.2586844\n",
      " -0.26024538 -0.18777855 -2.0046935  -0.06858686 -0.35759008 -2.0268164\n",
      "  0.12657595 -0.3175578  -1.365453   -0.23153806 -0.19502984 -1.1791518\n",
      " -0.16215652 -0.16298264 -1.2695501  -0.12383194 -0.16372453 -1.3874145\n",
      " -0.00484588 -0.1769605  -1.1976197 ]\n",
      "data: [-0.04254098  0.00817353 -0.21592946 -0.02015235 -0.10115205 -0.536059\n",
      " -0.16061422 -0.32004815 -1.3597233  -0.31758484 -0.3820755  -1.6518495\n",
      " -0.47889864 -0.47604698 -2.1475694  -0.24254376 -0.62623006 -1.522482\n",
      " -0.06341258 -0.68262464 -1.3538148  -0.10850456 -0.6036809  -1.4075768\n",
      " -0.10495127 -0.76761156 -1.5346196  -0.19877377 -0.53507674 -1.4237239\n",
      " -0.13361621 -0.58577764 -1.3915387  -0.1336798  -0.5491936  -1.4794235\n",
      "  0.02656446 -0.576899   -1.5021238  -0.1113487  -0.42754978 -1.2586844\n",
      " -0.26024538 -0.18777855 -2.0046935  -0.06858686 -0.35759008 -2.0268164\n",
      "  0.12657595 -0.3175578  -1.365453   -0.23153804 -0.19502982 -1.1791518\n",
      " -0.16215652 -0.16298264 -1.2695501  -0.12383194 -0.16372451 -1.3874145\n",
      " -0.00484588 -0.17696051 -1.1976197   0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B9B0>\n",
      "tensor([[-0.0039, -0.0861, -0.1984,  ...,  0.0090, -0.2433, -1.3269],\n",
      "        [-0.0039, -0.0861, -0.1984,  ...,  0.0090, -0.2433, -1.3269],\n",
      "        [-0.0039, -0.0861, -0.1984,  ...,  0.0090, -0.2433, -1.3269],\n",
      "        ...,\n",
      "        [-0.2789,  0.3238, -0.1976,  ..., -0.8100,  0.7879, -0.3633],\n",
      "        [-0.1926, -0.1087,  0.5036,  ..., -0.2819,  0.6379,  0.2458],\n",
      "        [-0.1926, -0.1087,  0.5036,  ..., -0.2819,  0.6379,  0.2458]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-3.9314665e-03 -8.6066231e-02 -1.9840765e-01  1.0187391e-02\n",
      " -2.4983004e-01 -6.8162209e-01 -2.7394466e-02 -3.8574666e-01\n",
      " -1.3421468e+00 -1.6523568e-01 -4.3579304e-01 -1.6496226e+00\n",
      " -3.4727138e-01 -5.6987488e-01 -2.1088181e+00 -2.2757548e-01\n",
      " -6.5904897e-01 -1.4997323e+00  4.7193632e-02 -6.5080243e-01\n",
      " -1.2763767e+00 -1.4150143e-03 -5.9682953e-01 -1.3290987e+00\n",
      " -1.2650490e-03 -6.8603295e-01 -1.4425930e+00 -1.8506899e-01\n",
      " -5.4265130e-01 -1.4298711e+00 -6.7418337e-02 -5.9401035e-01\n",
      " -1.4230188e+00 -6.8122126e-02 -5.6167811e-01 -1.5324823e+00\n",
      "  5.5468008e-02 -5.8204293e-01 -1.6100479e+00 -8.1399344e-02\n",
      " -4.7623277e-01 -1.2542114e+00 -1.5232871e-01 -2.4954785e-01\n",
      " -1.7582494e+00 -2.4549097e-02 -3.8231218e-01 -1.7343078e+00\n",
      "  1.1546677e-01 -3.5215390e-01 -1.4683981e+00 -1.7889538e-01\n",
      " -2.3065148e-01 -1.2078363e+00 -8.0190152e-02 -2.1127658e-01\n",
      " -1.2865533e+00 -2.5229558e-02 -2.3893744e-01 -1.4097779e+00\n",
      "  8.9619458e-03 -2.4330273e-01 -1.3269126e+00]\n",
      "data: [-3.9314665e-03 -8.6066224e-02 -1.9840765e-01  1.0187391e-02\n",
      " -2.4983004e-01 -6.8162209e-01 -2.7394466e-02 -3.8574666e-01\n",
      " -1.3421468e+00 -1.6523570e-01 -4.3579304e-01 -1.6496224e+00\n",
      " -3.4727138e-01 -5.6987488e-01 -2.1088181e+00 -2.2757548e-01\n",
      " -6.5904897e-01 -1.4997323e+00  4.7193632e-02 -6.5080243e-01\n",
      " -1.2763767e+00 -1.4150143e-03 -5.9682953e-01 -1.3290987e+00\n",
      " -1.2650490e-03 -6.8603295e-01 -1.4425930e+00 -1.8506899e-01\n",
      " -5.4265130e-01 -1.4298711e+00 -6.7418337e-02 -5.9401035e-01\n",
      " -1.4230188e+00 -6.8122126e-02 -5.6167811e-01 -1.5324823e+00\n",
      "  5.5468008e-02 -5.8204293e-01 -1.6100479e+00 -8.1399344e-02\n",
      " -4.7623277e-01 -1.2542114e+00 -1.5232871e-01 -2.4954787e-01\n",
      " -1.7582494e+00 -2.4549099e-02 -3.8231218e-01 -1.7343078e+00\n",
      "  1.1546677e-01 -3.5215390e-01 -1.4683981e+00 -1.7889538e-01\n",
      " -2.3065147e-01 -1.2078363e+00 -8.0190152e-02 -2.1127658e-01\n",
      " -1.2865531e+00 -2.5229558e-02 -2.3893744e-01 -1.4097779e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8.9619458e-03 -2.4330273e-01 -1.3269126e+00  1.0000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0414, -0.1406, -0.2970,  ...,  0.0524, -0.3103, -1.3601],\n",
      "        [ 0.0414, -0.1406, -0.2970,  ...,  0.0524, -0.3103, -1.3601],\n",
      "        [ 0.0414, -0.1406, -0.2970,  ...,  0.0524, -0.3103, -1.3601],\n",
      "        ...,\n",
      "        [-0.1042,  0.5352, -0.0094,  ..., -0.6975,  1.0745, -0.3261],\n",
      "        [-0.1662, -0.0392,  0.6563,  ..., -0.2748,  0.7425,  0.3060],\n",
      "        [-0.1662, -0.0392,  0.6563,  ..., -0.2748,  0.7425,  0.3060]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 4.14253585e-02 -1.40624598e-01 -2.96994686e-01  7.38958716e-02\n",
      " -2.66126901e-01 -6.95631802e-01 -2.72081494e-02 -4.62107509e-01\n",
      " -1.48364639e+00 -1.71550885e-01 -5.22535205e-01 -1.78028774e+00\n",
      " -3.19743872e-01 -6.23710871e-01 -2.27878070e+00 -1.58568695e-01\n",
      " -7.47373104e-01 -1.65606236e+00  4.87852395e-02 -7.85620213e-01\n",
      " -1.47490573e+00 -3.77534330e-03 -7.21654534e-01 -1.52878094e+00\n",
      " -1.97874531e-02 -8.61985922e-01 -1.65219522e+00 -1.17605925e-01\n",
      " -6.50354207e-01 -1.56452179e+00 -4.42406535e-02 -7.02839851e-01\n",
      " -1.54264808e+00 -5.90998605e-02 -6.70221925e-01 -1.63235831e+00\n",
      "  6.47605658e-02 -7.02940524e-01 -1.67213106e+00 -3.16054747e-02\n",
      " -5.51005483e-01 -1.39542365e+00 -1.61677167e-01 -3.16533059e-01\n",
      " -2.06766105e+00 -6.45622611e-04 -4.77949679e-01 -2.07719111e+00\n",
      "  1.50485933e-01 -4.40693438e-01 -1.52885342e+00 -1.42413065e-01\n",
      " -3.18911701e-01 -1.32284069e+00 -6.50543272e-02 -2.87480712e-01\n",
      " -1.39868259e+00 -2.44659334e-02 -2.99039215e-01 -1.51496983e+00\n",
      "  5.24304062e-02 -3.10259104e-01 -1.36009002e+00]\n",
      "data: [ 4.14253585e-02 -1.40624598e-01 -2.96994686e-01  7.38958716e-02\n",
      " -2.66126901e-01 -6.95631802e-01 -2.72081494e-02 -4.62107509e-01\n",
      " -1.48364639e+00 -1.71550885e-01 -5.22535205e-01 -1.78028774e+00\n",
      " -3.19743872e-01 -6.23710871e-01 -2.27878070e+00 -1.58568695e-01\n",
      " -7.47373104e-01 -1.65606236e+00  4.87852395e-02 -7.85620213e-01\n",
      " -1.47490573e+00 -3.77534330e-03 -7.21654534e-01 -1.52878094e+00\n",
      " -1.97874531e-02 -8.61985922e-01 -1.65219533e+00 -1.17605925e-01\n",
      " -6.50354207e-01 -1.56452179e+00 -4.42406572e-02 -7.02839792e-01\n",
      " -1.54264796e+00 -5.90998605e-02 -6.70221925e-01 -1.63235819e+00\n",
      "  6.47605658e-02 -7.02940524e-01 -1.67213106e+00 -3.16054747e-02\n",
      " -5.51005483e-01 -1.39542353e+00 -1.61677167e-01 -3.16533059e-01\n",
      " -2.06766105e+00 -6.45622611e-04 -4.77949679e-01 -2.07719111e+00\n",
      "  1.50485933e-01 -4.40693438e-01 -1.52885342e+00 -1.42413065e-01\n",
      " -3.18911701e-01 -1.32284069e+00 -6.50543272e-02 -2.87480712e-01\n",
      " -1.39868259e+00 -2.44659334e-02 -2.99039215e-01 -1.51496983e+00\n",
      "  5.24304062e-02 -3.10259104e-01 -1.36009002e+00  1.09999999e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63828>\n",
      "tensor([[ 0.0102, -0.1145, -0.2258,  ...,  0.0478, -0.2931, -1.3161],\n",
      "        [ 0.0102, -0.1145, -0.2258,  ...,  0.0478, -0.2931, -1.3161],\n",
      "        [ 0.0102, -0.1145, -0.2258,  ...,  0.0478, -0.2931, -1.3161],\n",
      "        ...,\n",
      "        [-0.0794,  0.5017, -0.1160,  ..., -0.6693,  1.0016, -0.3883],\n",
      "        [-0.1045, -0.0615,  0.5688,  ..., -0.1789,  0.6474,  0.2537],\n",
      "        [-0.1045, -0.0615,  0.5688,  ..., -0.1789,  0.6474,  0.2537]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01018016 -0.11450277 -0.22584413  0.02155941 -0.27464256 -0.67332107\n",
      " -0.00358649 -0.43742058 -1.377435   -0.14427666 -0.4896078  -1.7102168\n",
      " -0.33634198 -0.6404085  -2.1619358  -0.21621694 -0.69447386 -1.5714881\n",
      "  0.09091055 -0.70549726 -1.3485742   0.02536862 -0.6626544  -1.3939137\n",
      "  0.02740481 -0.7708397  -1.5128651  -0.15789497 -0.5708535  -1.4732196\n",
      " -0.03951471 -0.6395047  -1.4637716  -0.03514241 -0.6239768  -1.5788312\n",
      "  0.0710746  -0.6635473  -1.6515992  -0.03771158 -0.49180084 -1.280417\n",
      " -0.14521345 -0.2725275  -1.8754551   0.00439011 -0.4381483  -1.8477159\n",
      "  0.14868958 -0.40175816 -1.4768887  -0.15768072 -0.24450487 -1.2238371\n",
      " -0.03354894 -0.23676848 -1.2935264   0.01969415 -0.28806862 -1.4095697\n",
      "  0.0477918  -0.29308414 -1.3161416 ]\n",
      "data: [ 0.01018016 -0.11450277 -0.22584413  0.02155941 -0.27464256 -0.67332107\n",
      " -0.00358649 -0.43742058 -1.377435   -0.14427666 -0.4896078  -1.7102169\n",
      " -0.33634198 -0.64040846 -2.1619358  -0.21621695 -0.69447386 -1.5714881\n",
      "  0.09091055 -0.70549726 -1.3485742   0.02536862 -0.6626544  -1.3939137\n",
      "  0.02740481 -0.7708397  -1.512865   -0.15789497 -0.5708535  -1.4732196\n",
      " -0.03951471 -0.6395047  -1.4637715  -0.03514241 -0.6239768  -1.5788312\n",
      "  0.0710746  -0.6635473  -1.6515992  -0.03771158 -0.49180084 -1.280417\n",
      " -0.14521345 -0.2725275  -1.8754551   0.00439011 -0.43814832 -1.8477159\n",
      "  0.14868958 -0.40175816 -1.4768888  -0.15768072 -0.24450487 -1.2238371\n",
      " -0.03354894 -0.2367685  -1.2935264   0.01969415 -0.28806862 -1.4095697\n",
      "  0.0477918  -0.29308414 -1.3161416   0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0359, -0.1146, -0.2504,  ...,  0.0521, -0.3010, -1.2967],\n",
      "        [ 0.0359, -0.1146, -0.2504,  ...,  0.0521, -0.3010, -1.2967],\n",
      "        [ 0.0359, -0.1146, -0.2504,  ...,  0.0521, -0.3010, -1.2967],\n",
      "        ...,\n",
      "        [-0.1612,  0.4631, -0.1471,  ..., -0.6781,  0.9676, -0.4664],\n",
      "        [-0.1802, -0.1149,  0.6332,  ..., -0.2529,  0.6502,  0.2766],\n",
      "        [-0.1802, -0.1149,  0.6332,  ..., -0.2529,  0.6502,  0.2766]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03585218 -0.11458728 -0.25039652  0.05579716 -0.2486906  -0.64890766\n",
      " -0.04463922 -0.45155644 -1.4276011  -0.18919799 -0.51681215 -1.7225263\n",
      " -0.35141748 -0.6251986  -2.2021892  -0.16654734 -0.734077   -1.5912087\n",
      "  0.03742208 -0.7792678  -1.4024708  -0.01718561 -0.7138295  -1.4550059\n",
      " -0.02651339 -0.85799325 -1.5735109  -0.12309854 -0.6314515  -1.499954\n",
      " -0.05237073 -0.68669903 -1.4710281  -0.06606036 -0.6610311  -1.5589628\n",
      "  0.05748755 -0.68714833 -1.5950084  -0.03534272 -0.53552663 -1.3339837\n",
      " -0.16567965 -0.3084756  -2.0045364  -0.0076405  -0.4699648  -2.0099168\n",
      "  0.14601985 -0.43207756 -1.455404   -0.14461286 -0.3007447  -1.2626941\n",
      " -0.06863384 -0.27657515 -1.3464813  -0.02795851 -0.289276   -1.4587066\n",
      "  0.05213434 -0.30100125 -1.2967    ]\n",
      "data: [ 0.03585218 -0.11458728 -0.25039652  0.05579716 -0.2486906  -0.6489076\n",
      " -0.04463922 -0.45155644 -1.4276012  -0.18919797 -0.51681215 -1.7225262\n",
      " -0.35141745 -0.6251986  -2.2021892  -0.16654734 -0.734077   -1.5912087\n",
      "  0.03742208 -0.7792678  -1.4024708  -0.01718561 -0.7138295  -1.455006\n",
      " -0.02651339 -0.85799325 -1.5735109  -0.12309854 -0.6314515  -1.4999539\n",
      " -0.05237073 -0.6866991  -1.4710281  -0.06606036 -0.6610311  -1.5589628\n",
      "  0.05748754 -0.68714833 -1.5950084  -0.03534272 -0.53552663 -1.3339837\n",
      " -0.16567965 -0.3084756  -2.0045364  -0.0076405  -0.4699648  -2.0099168\n",
      "  0.14601985 -0.43207756 -1.455404   -0.14461286 -0.3007447  -1.2626941\n",
      " -0.06863384 -0.27657515 -1.3464813  -0.02795851 -0.289276   -1.4587066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.05213434 -0.30100125 -1.2967      0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0012, -0.0651, -0.1802,  ...,  0.0688, -0.2714, -1.1702],\n",
      "        [ 0.0012, -0.0651, -0.1802,  ...,  0.0688, -0.2714, -1.1702],\n",
      "        [ 0.0012, -0.0651, -0.1802,  ...,  0.0688, -0.2714, -1.1702],\n",
      "        ...,\n",
      "        [-0.1216,  0.4051, -0.1098,  ..., -0.7534,  0.9040, -0.3865],\n",
      "        [-0.1292, -0.1142,  0.5663,  ..., -0.2283,  0.5973,  0.2157],\n",
      "        [-0.1292, -0.1142,  0.5663,  ..., -0.2283,  0.5973,  0.2157]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.2120875e-03 -6.5107390e-02 -1.8018021e-01  2.7200203e-02\n",
      " -1.7871039e-01 -5.0032353e-01 -8.3583899e-02 -3.8758451e-01\n",
      " -1.3032666e+00 -2.3214810e-01 -4.4878006e-01 -1.6046503e+00\n",
      " -3.9068037e-01 -5.6091702e-01 -2.0932143e+00 -1.9361559e-01\n",
      " -6.8718809e-01 -1.4823297e+00  1.8203929e-02 -7.4071062e-01\n",
      " -1.3205131e+00 -3.9762825e-02 -6.7453879e-01 -1.3703523e+00\n",
      " -4.0572926e-02 -8.3347660e-01 -1.4936062e+00 -1.3925782e-01\n",
      " -5.9589475e-01 -1.3809764e+00 -6.3174963e-02 -6.5562928e-01\n",
      " -1.3638532e+00 -6.7120895e-02 -6.2830800e-01 -1.4545351e+00\n",
      "  6.4730823e-02 -6.6877002e-01 -1.4834069e+00 -4.0796764e-02\n",
      " -4.9411637e-01 -1.2093936e+00 -1.8547241e-01 -2.6148170e-01\n",
      " -1.9536487e+00  6.7478418e-04 -4.4153154e-01 -1.9650139e+00\n",
      "  1.7135738e-01 -4.0405053e-01 -1.3393919e+00 -1.6085251e-01\n",
      " -2.6516163e-01 -1.1370610e+00 -6.9515198e-02 -2.4403551e-01\n",
      " -1.2261345e+00 -2.8815448e-02 -2.6008862e-01 -1.3417487e+00\n",
      "  6.8771549e-02 -2.7141064e-01 -1.1701620e+00]\n",
      "data: [ 1.2120875e-03 -6.5107390e-02 -1.8018021e-01  2.7200203e-02\n",
      " -1.7871039e-01 -5.0032353e-01 -8.3583899e-02 -3.8758451e-01\n",
      " -1.3032666e+00 -2.3214810e-01 -4.4878006e-01 -1.6046503e+00\n",
      " -3.9068040e-01 -5.6091702e-01 -2.0932143e+00 -1.9361559e-01\n",
      " -6.8718809e-01 -1.4823297e+00  1.8203929e-02 -7.4071062e-01\n",
      " -1.3205131e+00 -3.9762825e-02 -6.7453879e-01 -1.3703523e+00\n",
      " -4.0572926e-02 -8.3347666e-01 -1.4936062e+00 -1.3925782e-01\n",
      " -5.9589475e-01 -1.3809764e+00 -6.3174963e-02 -6.5562928e-01\n",
      " -1.3638531e+00 -6.7120895e-02 -6.2830800e-01 -1.4545350e+00\n",
      "  6.4730823e-02 -6.6877002e-01 -1.4834068e+00 -4.0796768e-02\n",
      " -4.9411637e-01 -1.2093936e+00 -1.8547241e-01 -2.6148170e-01\n",
      " -1.9536487e+00  6.7478418e-04 -4.4153154e-01 -1.9650139e+00\n",
      "  1.7135738e-01 -4.0405053e-01 -1.3393919e+00 -1.6085251e-01\n",
      " -2.6516163e-01 -1.1370610e+00 -6.9515198e-02 -2.4403551e-01\n",
      " -1.2261345e+00 -2.8815448e-02 -2.6008862e-01 -1.3417487e+00\n",
      "  6.8771549e-02 -2.7141064e-01 -1.1701620e+00  1.4000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63320>\n",
      "tensor([[-0.0431, -0.0528, -0.2322,  ..., -0.0179, -0.2386, -1.2123],\n",
      "        [-0.0431, -0.0528, -0.2322,  ..., -0.0179, -0.2386, -1.2123],\n",
      "        [-0.0431, -0.0528, -0.2322,  ..., -0.0179, -0.2386, -1.2123],\n",
      "        ...,\n",
      "        [-0.2145,  0.3132, -0.0915,  ..., -0.7543,  0.8365, -0.4280],\n",
      "        [-0.0612,  0.0032,  0.6137,  ..., -0.1926,  0.7757,  0.2133],\n",
      "        [-0.0612,  0.0032,  0.6137,  ..., -0.1926,  0.7757,  0.2133]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.04308465 -0.05283199 -0.2321727  -0.01228864 -0.14744265 -0.53927934\n",
      " -0.16337009 -0.37287802 -1.3905406  -0.31595957 -0.4365527  -1.6820469\n",
      " -0.46102792 -0.5170747  -2.195004   -0.23094875 -0.6882174  -1.5486326\n",
      " -0.08048265 -0.75157404 -1.4058967  -0.13023274 -0.6720617  -1.4660606\n",
      " -0.13990411 -0.8509743  -1.5964487  -0.19099851 -0.6082201  -1.4461234\n",
      " -0.1438956  -0.65443254 -1.4197104  -0.16132379 -0.61814666 -1.5072742\n",
      " -0.01239499 -0.6472844  -1.5214581  -0.11535276 -0.4929601  -1.2846894\n",
      " -0.27493367 -0.2536667  -2.0733728  -0.08698681 -0.42228988 -2.1084664\n",
      "  0.09443572 -0.38759795 -1.3840342  -0.23013206 -0.27004737 -1.2014964\n",
      " -0.1732585  -0.23554525 -1.2952724  -0.14372943 -0.22542879 -1.4132984\n",
      " -0.01793402 -0.23855713 -1.2122817 ]\n",
      "data: [-0.04308464 -0.05283199 -0.2321727  -0.01228864 -0.14744265 -0.53927934\n",
      " -0.16337009 -0.372878   -1.3905406  -0.31595957 -0.4365527  -1.6820468\n",
      " -0.46102792 -0.5170747  -2.195004   -0.23094875 -0.6882174  -1.5486326\n",
      " -0.08048265 -0.75157404 -1.4058967  -0.13023274 -0.6720617  -1.4660606\n",
      " -0.13990411 -0.8509743  -1.5964487  -0.19099851 -0.6082201  -1.4461234\n",
      " -0.1438956  -0.65443254 -1.4197104  -0.16132377 -0.61814666 -1.5072742\n",
      " -0.01239499 -0.6472844  -1.5214581  -0.11535276 -0.4929601  -1.2846894\n",
      " -0.27493367 -0.2536667  -2.0733728  -0.08698681 -0.42228988 -2.1084664\n",
      "  0.09443572 -0.38759795 -1.3840342  -0.23013206 -0.27004737 -1.2014964\n",
      " -0.1732585  -0.23554525 -1.2952724  -0.14372943 -0.22542879 -1.4132984\n",
      " -0.01793402 -0.23855713 -1.2122817   0.15      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0284, -0.0396, -0.1535,  ...,  0.0389, -0.2070, -1.2405],\n",
      "        [ 0.0284, -0.0396, -0.1535,  ...,  0.0389, -0.2070, -1.2405],\n",
      "        [ 0.0284, -0.0396, -0.1535,  ...,  0.0389, -0.2070, -1.2405],\n",
      "        ...,\n",
      "        [-0.2890,  0.2329, -0.1851,  ..., -0.8816,  0.7855, -0.4534],\n",
      "        [-0.2590, -0.1993,  0.4942,  ..., -0.3976,  0.4961,  0.2565],\n",
      "        [-0.2590, -0.1993,  0.4942,  ..., -0.3976,  0.4961,  0.2565]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02838794 -0.03959948 -0.15346265  0.03867505 -0.19471963 -0.6160178\n",
      " -0.01559848 -0.35643265 -1.3117578  -0.15324241 -0.40971974 -1.6187416\n",
      " -0.34227538 -0.5374837  -2.0619984  -0.19263716 -0.62849474 -1.4642965\n",
      "  0.0699255  -0.63826287 -1.2413698   0.02543512 -0.5869585  -1.288564\n",
      "  0.03266927 -0.69524205 -1.4048136  -0.14849076 -0.50924027 -1.3815719\n",
      " -0.04169725 -0.5677651  -1.3611517  -0.03206307 -0.54310393 -1.4658369\n",
      "  0.10438032 -0.56988215 -1.5407611  -0.04969736 -0.43413746 -1.2058471\n",
      " -0.15182889 -0.20958778 -1.7986449   0.00345768 -0.35910738 -1.781967\n",
      "  0.16089858 -0.32308397 -1.3879693  -0.15872745 -0.18592165 -1.1461092\n",
      " -0.06533594 -0.16687076 -1.22416    -0.00886899 -0.19583356 -1.3459101\n",
      "  0.03888827 -0.2069744  -1.240461  ]\n",
      "data: [ 0.02838794 -0.03959948 -0.15346265  0.03867505 -0.19471961 -0.6160178\n",
      " -0.01559848 -0.35643265 -1.3117578  -0.15324241 -0.40971974 -1.6187416\n",
      " -0.34227538 -0.5374837  -2.0619984  -0.19263716 -0.62849474 -1.4642965\n",
      "  0.0699255  -0.63826287 -1.2413698   0.02543512 -0.5869585  -1.288564\n",
      "  0.03266927 -0.6952421  -1.4048136  -0.14849076 -0.50924027 -1.381572\n",
      " -0.04169725 -0.5677651  -1.3611517  -0.03206307 -0.54310393 -1.465837\n",
      "  0.10438032 -0.56988215 -1.5407611  -0.04969736 -0.43413746 -1.2058471\n",
      " -0.15182889 -0.20958778 -1.7986449   0.00345768 -0.35910738 -1.781967\n",
      "  0.1608986  -0.32308397 -1.3879693  -0.15872745 -0.18592165 -1.1461092\n",
      " -0.06533594 -0.16687077 -1.22416    -0.00886899 -0.19583356 -1.3459101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.03888827 -0.20697442 -1.240461    0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0333, -0.0833, -0.2571,  ...,  0.0596, -0.2597, -1.3140],\n",
      "        [ 0.0333, -0.0833, -0.2571,  ...,  0.0596, -0.2597, -1.3140],\n",
      "        [ 0.0333, -0.0833, -0.2571,  ...,  0.0596, -0.2597, -1.3140],\n",
      "        ...,\n",
      "        [-0.2899,  0.3133, -0.3249,  ..., -0.7669,  0.7758, -0.5344],\n",
      "        [-0.1440, -0.0476,  0.6232,  ..., -0.2418,  0.7526,  0.2750],\n",
      "        [-0.1440, -0.0476,  0.6232,  ..., -0.2418,  0.7526,  0.2750]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03327632 -0.08331247 -0.2570792   0.05451242 -0.23200141 -0.68493503\n",
      " -0.04788357 -0.4208268  -1.4405352  -0.19036058 -0.4879638  -1.7239097\n",
      " -0.3555509  -0.59894264 -2.1947656  -0.17345536 -0.68964326 -1.5954658\n",
      "  0.03384507 -0.7204422  -1.3826919  -0.00816055 -0.65432453 -1.4353169\n",
      " -0.01268272 -0.78159475 -1.5491431  -0.13396992 -0.58030784 -1.5180324\n",
      " -0.05234642 -0.6358838  -1.4805713  -0.0616912  -0.6082432  -1.5648882\n",
      "  0.07853463 -0.6255652  -1.6132063  -0.04837259 -0.500211   -1.349386\n",
      " -0.1540985  -0.27056566 -1.9554042  -0.00400154 -0.42218393 -1.9525083\n",
      "  0.15500669 -0.3864595  -1.4712846  -0.1446833  -0.2606434  -1.2834705\n",
      " -0.07286972 -0.2335379  -1.3559332  -0.0189769  -0.24406427 -1.4719516\n",
      "  0.05960736 -0.25971603 -1.313985  ]\n",
      "data: [ 0.03327632 -0.08331247 -0.2570792   0.05451242 -0.2320014  -0.684935\n",
      " -0.04788357 -0.4208268  -1.4405351  -0.19036059 -0.4879638  -1.7239097\n",
      " -0.3555509  -0.59894264 -2.1947656  -0.17345536 -0.68964326 -1.5954659\n",
      "  0.03384507 -0.7204422  -1.3826919  -0.00816055 -0.6543245  -1.4353169\n",
      " -0.01268272 -0.78159475 -1.5491431  -0.13396992 -0.58030784 -1.5180324\n",
      " -0.05234642 -0.6358838  -1.4805713  -0.0616912  -0.6082432  -1.5648884\n",
      "  0.07853463 -0.6255652  -1.6132064  -0.04837259 -0.500211   -1.349386\n",
      " -0.1540985  -0.27056566 -1.9554042  -0.00400154 -0.4221839  -1.9525084\n",
      "  0.15500669 -0.3864595  -1.4712846  -0.1446833  -0.2606434  -1.2834705\n",
      " -0.07286972 -0.2335379  -1.3559332  -0.0189769  -0.24406427 -1.4719516\n",
      "  0.05960736 -0.25971603 -1.313985    0.17      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0096, -0.1300, -0.2542,  ...,  0.0669, -0.3129, -1.3247],\n",
      "        [ 0.0096, -0.1300, -0.2542,  ...,  0.0669, -0.3129, -1.3247],\n",
      "        [ 0.0096, -0.1300, -0.2542,  ...,  0.0669, -0.3129, -1.3247],\n",
      "        ...,\n",
      "        [-0.1015,  0.4466, -0.1733,  ..., -0.7057,  0.9485, -0.4317],\n",
      "        [-0.1471, -0.1223,  0.5795,  ..., -0.2590,  0.6327,  0.2407],\n",
      "        [-0.1471, -0.1223,  0.5795,  ..., -0.2590,  0.6327,  0.2407]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0095737  -0.13001633 -0.25424653  0.02854564 -0.28469336 -0.67840993\n",
      " -0.01754753 -0.45331013 -1.3981342  -0.155659   -0.50964165 -1.7146044\n",
      " -0.33329913 -0.6509417  -2.1727793  -0.20295236 -0.719056   -1.5798253\n",
      "  0.08107537 -0.7330023  -1.3684607   0.02271181 -0.68388414 -1.4150152\n",
      "  0.02500127 -0.7951765  -1.533363   -0.14846346 -0.6020274  -1.4891549\n",
      " -0.0339805  -0.6656047  -1.4776646  -0.02980893 -0.641791   -1.5811479\n",
      "  0.08726306 -0.67984724 -1.6482782  -0.03450143 -0.5220144  -1.3031662\n",
      " -0.13880752 -0.29661435 -1.9079859   0.01692039 -0.45966247 -1.8870803\n",
      "  0.16693082 -0.42159715 -1.4878403  -0.14946023 -0.27810222 -1.2451909\n",
      " -0.03249063 -0.26386622 -1.3183644   0.0227448  -0.30412805 -1.4361551\n",
      "  0.06693346 -0.31287754 -1.3246748 ]\n",
      "data: [ 0.0095737  -0.13001633 -0.25424653  0.02854564 -0.28469336 -0.67840993\n",
      " -0.01754753 -0.45331013 -1.3981341  -0.155659   -0.50964165 -1.7146044\n",
      " -0.33329913 -0.65094167 -2.1727793  -0.20295234 -0.719056   -1.5798253\n",
      "  0.08107537 -0.7330023  -1.3684607   0.02271181 -0.68388414 -1.4150152\n",
      "  0.02500127 -0.79517657 -1.533363   -0.14846346 -0.6020274  -1.4891549\n",
      " -0.0339805  -0.6656047  -1.4776646  -0.02980893 -0.641791   -1.5811479\n",
      "  0.08726306 -0.67984724 -1.6482782  -0.03450143 -0.5220144  -1.3031662\n",
      " -0.13880752 -0.29661435 -1.907986    0.01692039 -0.45966247 -1.8870804\n",
      "  0.16693082 -0.42159712 -1.4878403  -0.14946023 -0.27810222 -1.2451909\n",
      " -0.03249063 -0.26386622 -1.3183644   0.0227448  -0.30412805 -1.4361551\n",
      "  0.06693346 -0.31287754 -1.3246748   0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0174, -0.1269, -0.2224,  ...,  0.0383, -0.3133, -1.2474],\n",
      "        [ 0.0174, -0.1269, -0.2224,  ...,  0.0383, -0.3133, -1.2474],\n",
      "        [ 0.0174, -0.1269, -0.2224,  ...,  0.0383, -0.3133, -1.2474],\n",
      "        ...,\n",
      "        [-0.1402,  0.4726, -0.1689,  ..., -0.6279,  0.9620, -0.4961],\n",
      "        [-0.1921, -0.0840,  0.6188,  ..., -0.2744,  0.6549,  0.2715],\n",
      "        [-0.1921, -0.0840,  0.6188,  ..., -0.2744,  0.6549,  0.2715]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01743386 -0.12691255 -0.22237746  0.04662374 -0.24637155 -0.5756698\n",
      " -0.06771434 -0.4604289  -1.3839593  -0.21615057 -0.5247371  -1.6789417\n",
      " -0.36717746 -0.62616104 -2.177099   -0.17831564 -0.7531507  -1.5596666\n",
      "  0.01598884 -0.8075343  -1.3896208  -0.0424825  -0.7404181  -1.4420636\n",
      " -0.05703259 -0.8968752  -1.5654285  -0.13388008 -0.6593696  -1.4630725\n",
      " -0.06968743 -0.7142292  -1.4382982  -0.08596753 -0.68405414 -1.5245948\n",
      "  0.03596552 -0.7190502  -1.5486686  -0.04625415 -0.5504589  -1.2985325\n",
      " -0.19359608 -0.31939736 -2.0240257  -0.02194847 -0.4905532  -2.0396292\n",
      "  0.13487212 -0.4514162  -1.4128244  -0.16272075 -0.3211735  -1.2237537\n",
      " -0.08656558 -0.2937323  -1.3090715  -0.05308051 -0.3027881  -1.4225714\n",
      "  0.03826993 -0.3132894  -1.2473762 ]\n",
      "data: [ 0.01743386 -0.12691255 -0.22237748  0.04662374 -0.24637155 -0.5756698\n",
      " -0.06771434 -0.4604289  -1.3839593  -0.21615057 -0.5247371  -1.6789416\n",
      " -0.36717746 -0.62616104 -2.177099   -0.17831564 -0.7531507  -1.5596666\n",
      "  0.01598884 -0.8075343  -1.3896208  -0.0424825  -0.7404181  -1.4420636\n",
      " -0.05703259 -0.8968752  -1.5654285  -0.13388008 -0.6593696  -1.4630725\n",
      " -0.06968743 -0.7142292  -1.4382982  -0.08596752 -0.68405414 -1.5245948\n",
      "  0.03596552 -0.7190502  -1.5486686  -0.04625415 -0.5504589  -1.2985324\n",
      " -0.19359608 -0.31939736 -2.0240257  -0.02194847 -0.4905532  -2.0396292\n",
      "  0.13487212 -0.4514162  -1.4128244  -0.16272075 -0.3211735  -1.2237537\n",
      " -0.08656558 -0.2937323  -1.3090715  -0.05308051 -0.3027881  -1.4225714\n",
      "  0.03826993 -0.3132894  -1.2473762   0.19      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[-0.0123, -0.0619, -0.1719,  ...,  0.0447, -0.2596, -1.1417],\n",
      "        [-0.0123, -0.0619, -0.1719,  ...,  0.0447, -0.2596, -1.1417],\n",
      "        [-0.0123, -0.0619, -0.1719,  ...,  0.0447, -0.2596, -1.1417],\n",
      "        ...,\n",
      "        [-0.1304,  0.3445, -0.0361,  ..., -0.7475,  0.8687, -0.3625],\n",
      "        [-0.1041, -0.1214,  0.5814,  ..., -0.2155,  0.5980,  0.1953],\n",
      "        [-0.1041, -0.1214,  0.5814,  ..., -0.2155,  0.5980,  0.1953]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01228445 -0.06194561 -0.17185745  0.01556756 -0.17647576 -0.47698742\n",
      " -0.0999682  -0.39397407 -1.2994998  -0.24898525 -0.45489353 -1.6026719\n",
      " -0.415196   -0.5672028  -2.0866544  -0.21274354 -0.6861132  -1.4736865\n",
      "  0.00345613 -0.739951   -1.2952476  -0.05175993 -0.67615616 -1.3430502\n",
      " -0.05244038 -0.8348446  -1.469022   -0.15948457 -0.5894767  -1.3672025\n",
      " -0.08455235 -0.6506659  -1.3450694  -0.08245505 -0.6240998  -1.4368474\n",
      "  0.05608754 -0.66366464 -1.4706607  -0.06224573 -0.48565596 -1.1918187\n",
      " -0.21840905 -0.2524147  -1.9659851  -0.02082345 -0.4357236  -1.9772894\n",
      "  0.15627791 -0.3939336  -1.3153803  -0.18590814 -0.25394118 -1.1186447\n",
      " -0.09730819 -0.23192829 -1.2016461  -0.05338147 -0.24831998 -1.3179901\n",
      "  0.04470699 -0.25961214 -1.141707  ]\n",
      "data: [-0.01228445 -0.06194561 -0.17185745  0.01556756 -0.17647575 -0.47698742\n",
      " -0.0999682  -0.39397407 -1.2994999  -0.24898525 -0.45489353 -1.6026719\n",
      " -0.415196   -0.5672028  -2.0866544  -0.21274354 -0.6861132  -1.4736866\n",
      "  0.00345613 -0.739951   -1.2952476  -0.05175993 -0.67615616 -1.3430502\n",
      " -0.05244038 -0.8348446  -1.469022   -0.15948457 -0.5894767  -1.3672024\n",
      " -0.08455235 -0.6506659  -1.3450694  -0.08245505 -0.6240998  -1.4368473\n",
      "  0.05608754 -0.66366464 -1.4706607  -0.06224574 -0.48565596 -1.1918187\n",
      " -0.21840905 -0.2524147  -1.9659851  -0.02082345 -0.4357236  -1.9772894\n",
      "  0.15627791 -0.3939336  -1.3153805  -0.18590814 -0.25394118 -1.1186447\n",
      " -0.09730819 -0.23192829 -1.2016461  -0.05338147 -0.24831998 -1.3179901\n",
      "  0.04470699 -0.25961214 -1.141707    0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0479, -0.0484, -0.2082,  ..., -0.0063, -0.2285, -1.2108],\n",
      "        [-0.0479, -0.0484, -0.2082,  ..., -0.0063, -0.2285, -1.2108],\n",
      "        [-0.0479, -0.0484, -0.2082,  ..., -0.0063, -0.2285, -1.2108],\n",
      "        ...,\n",
      "        [-0.2318,  0.3041, -0.1163,  ..., -0.7078,  0.8427, -0.4607],\n",
      "        [-0.1497, -0.1280,  0.5977,  ..., -0.2967,  0.6235,  0.2289],\n",
      "        [-0.1497, -0.1280,  0.5977,  ..., -0.2967,  0.6235,  0.2289]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.04794021 -0.04837726 -0.20823601 -0.01612841 -0.15443897 -0.5364765\n",
      " -0.14283249 -0.36441216 -1.3567575  -0.2949692  -0.42372575 -1.6573435\n",
      " -0.44802147 -0.5205911  -2.159737   -0.24377246 -0.6716604  -1.5235026\n",
      " -0.05095841 -0.7214394  -1.3605235  -0.10089654 -0.6487329  -1.4168558\n",
      " -0.10505985 -0.80977005 -1.547728   -0.19829193 -0.5838133  -1.4221607\n",
      " -0.12984025 -0.63455015 -1.4031503  -0.13433114 -0.5980675  -1.4971522\n",
      "  0.0144069  -0.6325806  -1.5268798  -0.11030897 -0.47596014 -1.2505438\n",
      " -0.25666982 -0.2345539  -2.0013323  -0.06786846 -0.40437305 -2.0229888\n",
      "  0.11551414 -0.3676653  -1.3827096  -0.2299171  -0.24570593 -1.1739513\n",
      " -0.15371357 -0.21331228 -1.2649683  -0.11480531 -0.21726197 -1.3856541\n",
      " -0.00625307 -0.22845216 -1.2108232 ]\n",
      "data: [-3.32 -3.2   0.8  -3.27 -3.    1.49 -3.27 -2.68  2.06 -3.21 -2.33  1.86\n",
      "  0.    0.    0.   -3.16 -2.8   2.28 -3.13 -2.6   2.51  0.    0.    0.\n",
      "  0.    0.    0.   -3.26 -2.74  2.01 -3.21 -2.42  1.99  0.    0.    0.\n",
      "  0.    0.    0.   -3.3  -2.72  1.77 -3.27 -2.52  1.79 -3.39 -2.3   1.91\n",
      " -3.39 -2.3   1.91 -3.42 -2.6   1.53 -3.4  -2.6   1.68 -3.47 -2.48  1.94\n",
      " -3.47 -2.41  1.94  0.  ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.4088, -0.1583, -0.2330,  ...,  0.1695, -0.1975, -0.7195],\n",
      "        [ 0.4088, -0.1583, -0.2330,  ...,  0.1695, -0.1975, -0.7195],\n",
      "        [ 0.4088, -0.1583, -0.2330,  ...,  0.1695, -0.1975, -0.7195],\n",
      "        ...,\n",
      "        [-0.0420, -0.9453, -0.0266,  ...,  0.1668, -1.0402, -0.5223],\n",
      "        [-0.4433,  0.1242,  0.4401,  ..., -0.7988, -0.2520,  2.1505],\n",
      "        [-0.4433,  0.1242,  0.4401,  ..., -0.7988, -0.2520,  2.1505]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.4088333  -0.15834327 -0.23295991  0.3063401  -0.29365736 -0.44305533\n",
      "  0.20301007 -0.46337968 -0.74097097  0.18553706 -0.59409994 -0.6578311\n",
      "  0.16394499 -0.62284875 -0.6478258   0.18782832 -0.3962135  -0.9911042\n",
      "  0.32729733 -0.45791912 -0.28041708  0.28639325 -0.5955285  -0.21514356\n",
      "  0.16378057 -0.5373255  -0.29758033  0.17226009 -0.28499758 -1.0302024\n",
      "  0.10317844 -0.3621807  -0.97788453  0.11877751 -0.39080498 -0.9229968\n",
      "  0.15028396 -0.49019864 -0.9141351   0.15432903 -0.2216268  -1.0264452\n",
      "  0.03210863 -0.25710818 -1.0430012   0.06188649 -0.29885918 -1.0511461\n",
      "  0.14883327 -0.33475202 -0.83145183  0.1275599  -0.06910606 -0.8853378\n",
      "  0.12707943 -0.0994907  -0.86484104  0.12821501 -0.12909248 -0.8414034\n",
      "  0.16951236 -0.19750583 -0.71949315]\n",
      "init: [ 0.4088333  -0.15834327 -0.23295991  0.3063401  -0.29365736 -0.44305533\n",
      "  0.20301007 -0.46337968 -0.74097097  0.18553706 -0.59409994 -0.6578311\n",
      "  0.16394499 -0.62284875 -0.6478258   0.18782832 -0.3962135  -0.9911042\n",
      "  0.32729733 -0.45791912 -0.28041708  0.28639325 -0.5955285  -0.21514356\n",
      "  0.16378057 -0.5373255  -0.29758033  0.17226009 -0.28499758 -1.0302024\n",
      "  0.10317844 -0.3621807  -0.97788453  0.11877751 -0.39080498 -0.9229968\n",
      "  0.15028396 -0.49019864 -0.9141351   0.15432903 -0.2216268  -1.0264452\n",
      "  0.03210863 -0.25710818 -1.0430012   0.06188649 -0.29885918 -1.0511461\n",
      "  0.14883327 -0.33475202 -0.83145183  0.1275599  -0.06910606 -0.8853378\n",
      "  0.12707943 -0.0994907  -0.86484104  0.12821501 -0.12909248 -0.8414034\n",
      "  0.16951236 -0.19750583 -0.71949315]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [ 0.40883332 -0.15834327 -0.23295993  0.3063401  -0.29365736 -0.44305533\n",
      "  0.20301007 -0.46337968 -0.74097097  0.18553706 -0.59409994 -0.657831\n",
      "  0.16394499 -0.62284875 -0.6478258   0.18782832 -0.3962135  -0.9911042\n",
      "  0.32729733 -0.45791912 -0.28041708  0.28639325 -0.5955285  -0.21514356\n",
      "  0.16378057 -0.5373255  -0.29758033  0.17226009 -0.28499758 -1.0302024\n",
      "  0.10317844 -0.3621807  -0.97788453  0.11877751 -0.39080498 -0.9229968\n",
      "  0.15028396 -0.49019864 -0.91413516  0.15432903 -0.2216268  -1.0264452\n",
      "  0.03210863 -0.25710818 -1.0430012   0.06188649 -0.29885918 -1.0511461\n",
      "  0.14883327 -0.334752   -0.8314518   0.1275599  -0.06910606 -0.8853378\n",
      "  0.12707943 -0.0994907  -0.8648411   0.12821501 -0.12909248 -0.8414034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.16951236 -0.19750583 -0.71949315  0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.1246, -0.0202,  0.1891,  ..., -0.1077, -0.2313, -0.9579],\n",
      "        [ 0.1246, -0.0202,  0.1891,  ..., -0.1077, -0.2313, -0.9579],\n",
      "        [ 0.1246, -0.0202,  0.1891,  ..., -0.1077, -0.2313, -0.9579],\n",
      "        ...,\n",
      "        [ 0.1558,  0.5862, -0.2994,  ..., -0.0019,  1.3589, -0.7980],\n",
      "        [-0.0936, -0.0108,  0.2504,  ...,  0.5251,  0.5991, -0.0303],\n",
      "        [-0.0936, -0.0108,  0.2504,  ...,  0.5251,  0.5991, -0.0303]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.12459634 -0.02022119  0.18911009  0.00219895 -0.20046148 -0.40985185\n",
      " -0.09251741 -0.3574744  -0.99984735 -0.27393943 -0.4180681  -1.3127542\n",
      " -0.56239563 -0.48290765 -1.7738683  -0.16803244 -0.62240905 -1.1823354\n",
      " -0.23317441 -0.6879033  -1.2784121  -0.25777566 -0.5644957  -1.359515\n",
      " -0.15013477 -0.7699283  -1.3857694  -0.15162843 -0.4951952  -1.1070912\n",
      " -0.16796926 -0.5264542  -1.0048087  -0.2429569  -0.5938804  -1.1544011\n",
      " -0.10852307 -0.47172564 -1.1666267  -0.1275315  -0.45777953 -1.0084219\n",
      " -0.19094169 -0.32248855 -1.4063251  -0.17659137 -0.40101618 -1.4153821\n",
      " -0.06365263 -0.40796047 -1.0296135  -0.13772151 -0.24200684 -0.95235926\n",
      " -0.21119192 -0.2635303  -1.0116596  -0.19995189 -0.23202227 -1.1058004\n",
      " -0.10769591 -0.2312537  -0.9579025 ]\n",
      "data: [ 0.12459633 -0.02022119  0.18911009  0.00219895 -0.20046148 -0.40985185\n",
      " -0.09251741 -0.35747442 -0.99984735 -0.27393943 -0.4180681  -1.3127542\n",
      " -0.56239563 -0.48290765 -1.7738682  -0.16803244 -0.62240905 -1.1823354\n",
      " -0.23317441 -0.6879033  -1.2784121  -0.25777566 -0.5644957  -1.359515\n",
      " -0.15013477 -0.7699283  -1.3857694  -0.15162843 -0.4951952  -1.1070912\n",
      " -0.16796927 -0.5264542  -1.0048087  -0.2429569  -0.5938804  -1.1544011\n",
      " -0.10852307 -0.47172564 -1.1666267  -0.1275315  -0.45777953 -1.0084219\n",
      " -0.19094169 -0.32248855 -1.4063251  -0.17659135 -0.40101615 -1.415382\n",
      " -0.06365263 -0.40796047 -1.0296135  -0.13772151 -0.24200684 -0.95235926\n",
      " -0.21119192 -0.2635303  -1.0116596  -0.1999519  -0.23202227 -1.1058004\n",
      " -0.10769591 -0.2312537  -0.95790255  0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0704,  0.0809, -0.2381,  ...,  0.2039, -0.1075, -1.2545],\n",
      "        [ 0.0704,  0.0809, -0.2381,  ...,  0.2039, -0.1075, -1.2545],\n",
      "        [ 0.0704,  0.0809, -0.2381,  ...,  0.2039, -0.1075, -1.2545],\n",
      "        ...,\n",
      "        [-0.0914,  0.4736,  0.2470,  ..., -0.3183,  1.1706, -0.1457],\n",
      "        [-0.0305,  0.0666,  0.5570,  ..., -0.4111,  0.6987,  0.3084],\n",
      "        [-0.0305,  0.0666,  0.5570,  ..., -0.4111,  0.6987,  0.3084]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.07041749  0.08087856 -0.2380596   0.11188129 -0.04651107 -0.593524\n",
      "  0.0369784  -0.2173428  -1.3077521  -0.09982549 -0.26689008 -1.5877218\n",
      " -0.23249993 -0.40049228 -2.0551298  -0.13112476 -0.49900344 -1.4932907\n",
      "  0.15305701 -0.512602   -1.2970088   0.11287431 -0.43640766 -1.3269511\n",
      "  0.12549986 -0.5429841  -1.4402632  -0.07419175 -0.40281966 -1.4181497\n",
      "  0.0570392  -0.45725307 -1.4015865   0.08560558 -0.4004372  -1.4635857\n",
      "  0.22698016 -0.4520199  -1.5254251   0.05999518 -0.3268057  -1.253471\n",
      " -0.0375306  -0.06565163 -1.8323177   0.14496449 -0.24551678 -1.8091065\n",
      "  0.31887746 -0.18162647 -1.4236158  -0.06899811 -0.08874243 -1.1920954\n",
      "  0.07010144 -0.04948705 -1.2716212   0.13883573 -0.09286425 -1.3900852\n",
      "  0.20385292 -0.10746641 -1.2544596 ]\n",
      "data: [ 0.07041749  0.08087856 -0.2380596   0.11188129 -0.04651107 -0.593524\n",
      "  0.0369784  -0.2173428  -1.3077521  -0.09982549 -0.26689008 -1.5877218\n",
      " -0.23249993 -0.40049228 -2.0551298  -0.13112476 -0.49900344 -1.4932907\n",
      "  0.15305701 -0.512602   -1.2970089   0.11287431 -0.43640766 -1.3269511\n",
      "  0.12549986 -0.5429841  -1.4402633  -0.07419175 -0.40281966 -1.4181497\n",
      "  0.0570392  -0.45725307 -1.4015867   0.08560558 -0.4004372  -1.4635856\n",
      "  0.22698016 -0.45201987 -1.5254251   0.05999519 -0.3268057  -1.253471\n",
      " -0.0375306  -0.06565163 -1.8323177   0.14496449 -0.24551678 -1.8091065\n",
      "  0.31887746 -0.18162647 -1.4236159  -0.06899811 -0.08874243 -1.1920954\n",
      "  0.07010144 -0.04948706 -1.2716212   0.13883573 -0.09286425 -1.3900851\n",
      "  0.20385292 -0.10746641 -1.2544596   0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0815, -0.1447, -0.2480,  ...,  0.0991, -0.2912, -1.3839],\n",
      "        [ 0.0815, -0.1447, -0.2480,  ...,  0.0991, -0.2912, -1.3839],\n",
      "        [ 0.0815, -0.1447, -0.2480,  ...,  0.0991, -0.2912, -1.3839],\n",
      "        ...,\n",
      "        [-0.3572,  0.1870, -0.4105,  ..., -0.9574,  0.4673, -0.5629],\n",
      "        [-0.1467,  0.1141,  0.5210,  ..., -0.2650,  1.0116,  0.1232],\n",
      "        [-0.1467,  0.1141,  0.5210,  ..., -0.2650,  1.0116,  0.1232]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 8.1490040e-02 -1.4469561e-01 -2.4801569e-01  9.7671077e-02\n",
      " -3.2587498e-01 -7.3710960e-01  3.4836978e-02 -4.8695534e-01\n",
      " -1.4552214e+00 -1.0790475e-01 -5.5327630e-01 -1.7530010e+00\n",
      " -2.9128781e-01 -6.8300343e-01 -2.2284744e+00 -1.4273360e-01\n",
      " -7.2343862e-01 -1.6394835e+00  1.1370386e-01 -7.2670400e-01\n",
      " -1.3960643e+00  7.1625382e-02 -6.7446172e-01 -1.4442430e+00\n",
      "  6.6801518e-02 -7.7152991e-01 -1.5544841e+00 -1.0129985e-01\n",
      " -5.9193695e-01 -1.5680943e+00  9.7890347e-03 -6.5342808e-01\n",
      " -1.5326242e+00  2.1582246e-03 -6.2992060e-01 -1.6324604e+00\n",
      "  1.3540067e-01 -6.4930642e-01 -1.7092044e+00 -4.8131272e-03\n",
      " -5.2590454e-01 -1.3871017e+00 -8.3646759e-02 -2.9849574e-01\n",
      " -1.9020498e+00  4.7233984e-02 -4.4234380e-01 -1.8794484e+00\n",
      "  1.9150309e-01 -4.0957573e-01 -1.5460777e+00 -9.7276866e-02\n",
      " -2.7254611e-01 -1.3277469e+00 -7.5811297e-03 -2.5002128e-01\n",
      " -1.3753564e+00  5.7192832e-02 -2.7747089e-01 -1.4969025e+00\n",
      "  9.9099003e-02 -2.9115921e-01 -1.3839355e+00]\n",
      "data: [ 8.1490040e-02 -1.4469561e-01 -2.4801569e-01  9.7671077e-02\n",
      " -3.2587498e-01 -7.3710960e-01  3.4836978e-02 -4.8695534e-01\n",
      " -1.4552214e+00 -1.0790475e-01 -5.5327630e-01 -1.7530010e+00\n",
      " -2.9128781e-01 -6.8300337e-01 -2.2284744e+00 -1.4273360e-01\n",
      " -7.2343862e-01 -1.6394835e+00  1.1370386e-01 -7.2670400e-01\n",
      " -1.3960643e+00  7.1625382e-02 -6.7446172e-01 -1.4442430e+00\n",
      "  6.6801518e-02 -7.7152991e-01 -1.5544841e+00 -1.0129985e-01\n",
      " -5.9193695e-01 -1.5680941e+00  9.7890347e-03 -6.5342802e-01\n",
      " -1.5326242e+00  2.1582246e-03 -6.2992060e-01 -1.6324604e+00\n",
      "  1.3540067e-01 -6.4930642e-01 -1.7092044e+00 -4.8131272e-03\n",
      " -5.2590454e-01 -1.3871017e+00 -8.3646752e-02 -2.9849574e-01\n",
      " -1.9020497e+00  4.7233984e-02 -4.4234380e-01 -1.8794484e+00\n",
      "  1.9150309e-01 -4.0957573e-01 -1.5460777e+00 -9.7276866e-02\n",
      " -2.7254611e-01 -1.3277469e+00 -7.5811297e-03 -2.5002128e-01\n",
      " -1.3753564e+00  5.7192832e-02 -2.7747089e-01 -1.4969025e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9.9099010e-02 -2.9115921e-01 -1.3839355e+00  3.9999999e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0222, -0.2359, -0.2448,  ...,  0.0694, -0.4098, -1.3656],\n",
      "        [ 0.0222, -0.2359, -0.2448,  ...,  0.0694, -0.4098, -1.3656],\n",
      "        [ 0.0222, -0.2359, -0.2448,  ...,  0.0694, -0.4098, -1.3656],\n",
      "        ...,\n",
      "        [-0.0243,  0.5930, -0.1938,  ..., -0.5726,  1.0935, -0.5326],\n",
      "        [-0.1775,  0.0390,  0.6295,  ..., -0.2157,  0.7608,  0.3092],\n",
      "        [-0.1775,  0.0390,  0.6295,  ..., -0.2157,  0.7608,  0.3092]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02224021 -0.23587255 -0.24475221  0.04636989 -0.399424   -0.675328\n",
      "  0.01784981 -0.5748842  -1.4199216  -0.12703967 -0.63311076 -1.7538813\n",
      " -0.31588894 -0.78924835 -2.2239537  -0.2074758  -0.81755304 -1.6417564\n",
      "  0.12900269 -0.8336973  -1.3777368   0.06259245 -0.79707575 -1.4141947\n",
      "  0.0475277  -0.9002117  -1.537868   -0.14554203 -0.6903106  -1.5388694\n",
      " -0.01850837 -0.7688205  -1.5284493  -0.00915147 -0.7486557  -1.6406653\n",
      "  0.09509239 -0.8005065  -1.720394   -0.01859925 -0.60844505 -1.340028\n",
      " -0.13369338 -0.38309604 -1.9448339   0.02731766 -0.5612649  -1.9133857\n",
      "  0.17174195 -0.5170268  -1.5393829  -0.14974284 -0.35544795 -1.2805564\n",
      " -0.01343761 -0.34435582 -1.3394808   0.04846537 -0.4061913  -1.455362\n",
      "  0.06935381 -0.40977478 -1.3655636 ]\n",
      "data: [ 0.02224021 -0.23587255 -0.24475221  0.04636989 -0.399424   -0.675328\n",
      "  0.01784981 -0.5748842  -1.4199215  -0.12703967 -0.63311076 -1.7538813\n",
      " -0.31588894 -0.78924835 -2.2239537  -0.2074758  -0.81755304 -1.6417564\n",
      "  0.12900269 -0.8336974  -1.3777368   0.06259245 -0.79707575 -1.4141946\n",
      "  0.0475277  -0.9002117  -1.537868   -0.14554203 -0.6903106  -1.5388694\n",
      " -0.01850837 -0.7688205  -1.5284493  -0.00915147 -0.7486557  -1.6406653\n",
      "  0.09509239 -0.8005064  -1.720394   -0.01859925 -0.60844505 -1.340028\n",
      " -0.13369338 -0.38309604 -1.9448339   0.02731766 -0.5612649  -1.9133857\n",
      "  0.17174195 -0.5170268  -1.5393829  -0.14974284 -0.35544795 -1.2805564\n",
      " -0.01343761 -0.34435582 -1.3394808   0.04846537 -0.4061913  -1.455362\n",
      "  0.06935381 -0.40977478 -1.3655636   0.05      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[-0.0016, -0.1895, -0.1666,  ...,  0.0084, -0.3731, -1.2160],\n",
      "        [-0.0016, -0.1895, -0.1666,  ...,  0.0084, -0.3731, -1.2160],\n",
      "        [-0.0016, -0.1895, -0.1666,  ...,  0.0084, -0.3731, -1.2160],\n",
      "        ...,\n",
      "        [-0.0053,  0.6191, -0.1638,  ..., -0.4361,  1.1763, -0.5834],\n",
      "        [-0.1070,  0.0663,  0.6271,  ..., -0.1046,  0.7249,  0.2976],\n",
      "        [-0.1070,  0.0663,  0.6271,  ..., -0.1046,  0.7249,  0.2976]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-1.5811427e-03 -1.8947846e-01 -1.6658936e-01  2.6433300e-02\n",
      " -3.1167352e-01 -5.0431633e-01 -6.7277797e-02 -5.3203094e-01\n",
      " -1.3322266e+00 -2.2501417e-01 -5.9326470e-01 -1.6492481e+00\n",
      " -3.9731663e-01 -7.1046841e-01 -2.1540942e+00 -2.1791556e-01\n",
      " -8.0903351e-01 -1.5491844e+00  2.2833571e-02 -8.6786699e-01\n",
      " -1.3612345e+00 -4.2823553e-02 -8.0807745e-01 -1.4008718e+00\n",
      " -5.6958891e-02 -9.6170604e-01 -1.5246001e+00 -1.6378783e-01\n",
      " -7.0656776e-01 -1.4352237e+00 -8.5688978e-02 -7.7453983e-01\n",
      " -1.4095147e+00 -9.0033390e-02 -7.4912786e-01 -1.5086807e+00\n",
      "  2.3441613e-02 -7.9497969e-01 -1.5427483e+00 -5.9939615e-02\n",
      " -5.9621692e-01 -1.2601584e+00 -2.2096112e-01 -3.6709589e-01\n",
      " -1.9896573e+00 -3.9421007e-02 -5.5469388e-01 -1.9944111e+00\n",
      "  1.1914486e-01 -5.0771463e-01 -1.3887913e+00 -1.9851248e-01\n",
      " -3.5881504e-01 -1.1848056e+00 -1.0117480e-01 -3.3832186e-01\n",
      " -1.2595689e+00 -6.3315198e-02 -3.7107915e-01 -1.3698535e+00\n",
      "  8.4193423e-03 -3.7305146e-01 -1.2160137e+00]\n",
      "data: [-1.5811427e-03 -1.8947846e-01 -1.6658935e-01  2.6433300e-02\n",
      " -3.1167352e-01 -5.0431633e-01 -6.7277797e-02 -5.3203094e-01\n",
      " -1.3322265e+00 -2.2501417e-01 -5.9326470e-01 -1.6492480e+00\n",
      " -3.9731663e-01 -7.1046847e-01 -2.1540942e+00 -2.1791558e-01\n",
      " -8.0903351e-01 -1.5491844e+00  2.2833571e-02 -8.6786699e-01\n",
      " -1.3612345e+00 -4.2823553e-02 -8.0807745e-01 -1.4008718e+00\n",
      " -5.6958891e-02 -9.6170598e-01 -1.5246003e+00 -1.6378783e-01\n",
      " -7.0656776e-01 -1.4352237e+00 -8.5688978e-02 -7.7453977e-01\n",
      " -1.4095147e+00 -9.0033390e-02 -7.4912786e-01 -1.5086807e+00\n",
      "  2.3441613e-02 -7.9497969e-01 -1.5427482e+00 -5.9939612e-02\n",
      " -5.9621692e-01 -1.2601584e+00 -2.2096114e-01 -3.6709586e-01\n",
      " -1.9896573e+00 -3.9421007e-02 -5.5469388e-01 -1.9944111e+00\n",
      "  1.1914486e-01 -5.0771463e-01 -1.3887913e+00 -1.9851248e-01\n",
      " -3.5881504e-01 -1.1848056e+00 -1.0117480e-01 -3.3832186e-01\n",
      " -1.2595689e+00 -6.3315198e-02 -3.7107915e-01 -1.3698535e+00\n",
      "  8.4193423e-03 -3.7305146e-01 -1.2160137e+00  5.9999999e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F634E0>\n",
      "tensor([[-0.0082, -0.1021, -0.1936,  ...,  0.0122, -0.2759, -1.2059],\n",
      "        [-0.0082, -0.1021, -0.1936,  ...,  0.0122, -0.2759, -1.2059],\n",
      "        [-0.0082, -0.1021, -0.1936,  ...,  0.0122, -0.2759, -1.2059],\n",
      "        ...,\n",
      "        [-0.1442,  0.4655, -0.0344,  ..., -0.5545,  1.1048, -0.4750],\n",
      "        [-0.0656,  0.0376,  0.6581,  ..., -0.1687,  0.6723,  0.3472],\n",
      "        [-0.0656,  0.0376,  0.6581,  ..., -0.1687,  0.6723,  0.3472]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.00817808 -0.10214648 -0.19356342  0.03047847 -0.20705017 -0.4625692\n",
      " -0.09190357 -0.43893415 -1.3379813  -0.24893592 -0.49923784 -1.6386385\n",
      " -0.3996595  -0.6007548  -2.1622756  -0.2134206  -0.73221123 -1.5511564\n",
      "  0.00767335 -0.7940197  -1.3848163  -0.0485487  -0.72777903 -1.4221785\n",
      " -0.05337411 -0.8832163  -1.5522873  -0.16405626 -0.6369278  -1.4392858\n",
      " -0.08840653 -0.6961128  -1.4160334  -0.08142987 -0.65590256 -1.5042512\n",
      "  0.05338275 -0.70681375 -1.5335057  -0.06498799 -0.5176654  -1.2715157\n",
      " -0.23867369 -0.27338696 -2.0550845  -0.03247432 -0.46303725 -2.073337\n",
      "  0.14659664 -0.41158634 -1.391758   -0.21096364 -0.2802243  -1.1894741\n",
      " -0.11597876 -0.24871466 -1.2653806  -0.0794901  -0.26940912 -1.3787377\n",
      "  0.01224449 -0.27593762 -1.2058969 ]\n",
      "data: [-0.00817808 -0.10214648 -0.19356342  0.03047847 -0.20705017 -0.4625692\n",
      " -0.09190357 -0.43893415 -1.3379815  -0.24893592 -0.49923784 -1.6386385\n",
      " -0.3996595  -0.6007548  -2.1622756  -0.2134206  -0.73221123 -1.5511565\n",
      "  0.00767335 -0.7940197  -1.3848163  -0.0485487  -0.72777903 -1.4221785\n",
      " -0.05337411 -0.8832163  -1.5522873  -0.16405626 -0.6369278  -1.4392858\n",
      " -0.08840653 -0.6961128  -1.4160333  -0.08142987 -0.65590256 -1.5042512\n",
      "  0.05338275 -0.70681375 -1.5335057  -0.06498799 -0.5176654  -1.2715157\n",
      " -0.23867369 -0.27338696 -2.0550845  -0.03247432 -0.46303725 -2.073337\n",
      "  0.14659664 -0.41158634 -1.391758   -0.21096364 -0.2802243  -1.1894741\n",
      " -0.11597876 -0.24871466 -1.2653806  -0.0794901  -0.26940912 -1.3787377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.01224449 -0.27593762 -1.2058969   0.07      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[-0.0140, -0.0252, -0.1743,  ...,  0.0416, -0.2139, -1.1670],\n",
      "        [-0.0140, -0.0252, -0.1743,  ...,  0.0416, -0.2139, -1.1670],\n",
      "        [-0.0140, -0.0252, -0.1743,  ...,  0.0416, -0.2139, -1.1670],\n",
      "        ...,\n",
      "        [-0.1873,  0.3072, -0.0232,  ..., -0.7099,  0.8836, -0.3548],\n",
      "        [-0.1268, -0.0850,  0.5642,  ..., -0.2554,  0.6033,  0.2579],\n",
      "        [-0.1268, -0.0850,  0.5642,  ..., -0.2554,  0.6033,  0.2579]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01396478 -0.02522582 -0.1743472   0.0105522  -0.14016993 -0.48927602\n",
      " -0.10364405 -0.35341766 -1.3043811  -0.25441006 -0.4125968  -1.606802\n",
      " -0.4169071  -0.52563506 -2.0957925  -0.22231254 -0.64920753 -1.4785793\n",
      "  0.00404297 -0.69857824 -1.2928195  -0.05026372 -0.6334051  -1.3387425\n",
      " -0.05110985 -0.78348684 -1.4679341  -0.16925146 -0.5527444  -1.3745255\n",
      " -0.08861816 -0.60976547 -1.3594441  -0.07784118 -0.57366765 -1.4495385\n",
      "  0.06456681 -0.6162484  -1.4864514  -0.06657548 -0.44780385 -1.2025044\n",
      " -0.2168178  -0.20860589 -1.945015   -0.0178864  -0.38721728 -1.9553356\n",
      "  0.16468057 -0.34116924 -1.3419383  -0.1954241  -0.2133939  -1.1275856\n",
      " -0.09939852 -0.18688864 -1.2157271  -0.05542658 -0.2041131  -1.3331223\n",
      "  0.04159295 -0.21391766 -1.1669915 ]\n",
      "data: [-0.01396478 -0.02522582 -0.1743472   0.0105522  -0.14016993 -0.48927602\n",
      " -0.10364404 -0.35341766 -1.3043811  -0.25441006 -0.4125968  -1.6068021\n",
      " -0.41690713 -0.52563506 -2.0957925  -0.22231254 -0.64920753 -1.4785793\n",
      "  0.00404297 -0.69857824 -1.2928195  -0.05026372 -0.6334051  -1.3387425\n",
      " -0.05110985 -0.78348684 -1.4679341  -0.16925146 -0.5527444  -1.3745255\n",
      " -0.08861817 -0.60976547 -1.3594441  -0.07784118 -0.57366765 -1.4495385\n",
      "  0.06456681 -0.6162484  -1.4864514  -0.06657548 -0.44780385 -1.2025044\n",
      " -0.2168178  -0.20860589 -1.945015   -0.0178864  -0.38721728 -1.9553357\n",
      "  0.16468057 -0.34116924 -1.3419384  -0.1954241  -0.2133939  -1.1275856\n",
      " -0.09939852 -0.18688864 -1.2157271  -0.05542658 -0.2041131  -1.3331223\n",
      "  0.04159294 -0.21391766 -1.1669915   0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[-0.0237, -0.0494, -0.2633,  ..., -0.0175, -0.2189, -1.3363],\n",
      "        [-0.0237, -0.0494, -0.2633,  ..., -0.0175, -0.2189, -1.3363],\n",
      "        [-0.0237, -0.0494, -0.2633,  ..., -0.0175, -0.2189, -1.3363],\n",
      "        ...,\n",
      "        [-0.2644,  0.3332, -0.1444,  ..., -0.7390,  0.7933, -0.3316],\n",
      "        [-0.1473, -0.0837,  0.6078,  ..., -0.2626,  0.6978,  0.3188],\n",
      "        [-0.1473, -0.0837,  0.6078,  ..., -0.2626,  0.6978,  0.3188]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-2.3688208e-02 -4.9367152e-02 -2.6334220e-01 -4.8511848e-04\n",
      " -1.9290404e-01 -7.0484644e-01 -9.3534790e-02 -3.6142206e-01\n",
      " -1.4303361e+00 -2.3984851e-01 -4.2042154e-01 -1.7222708e+00\n",
      " -4.1198125e-01 -5.2655768e-01 -2.2010558e+00 -2.2897351e-01\n",
      " -6.5024108e-01 -1.5839393e+00 -3.0038744e-02 -6.7323208e-01\n",
      " -1.3967865e+00 -7.5738817e-02 -6.0514337e-01 -1.4563630e+00\n",
      " -7.5721867e-02 -7.3325241e-01 -1.5683444e+00 -1.9117180e-01\n",
      " -5.4655164e-01 -1.5094808e+00 -1.1300826e-01 -5.9452361e-01\n",
      " -1.4791946e+00 -1.2941277e-01 -5.6887847e-01 -1.5760806e+00\n",
      "  5.8837086e-03 -5.8000410e-01 -1.6218044e+00 -1.1345508e-01\n",
      " -4.6755517e-01 -1.3382422e+00 -2.1366730e-01 -2.3529039e-01\n",
      " -1.9472837e+00 -7.1494363e-02 -3.7863958e-01 -1.9479171e+00\n",
      "  8.0125511e-02 -3.5099334e-01 -1.4809339e+00 -2.0451625e-01\n",
      " -2.3002766e-01 -1.2802100e+00 -1.4164972e-01 -2.0356287e-01\n",
      " -1.3598886e+00 -9.5035702e-02 -2.0679094e-01 -1.4808266e+00\n",
      " -1.7543890e-02 -2.1892588e-01 -1.3362913e+00]\n",
      "data: [-2.3688208e-02 -4.9367152e-02 -2.6334220e-01 -4.8511848e-04\n",
      " -1.9290404e-01 -7.0484644e-01 -9.3534797e-02 -3.6142203e-01\n",
      " -1.4303361e+00 -2.3984852e-01 -4.2042151e-01 -1.7222708e+00\n",
      " -4.1198123e-01 -5.2655768e-01 -2.2010558e+00 -2.2897351e-01\n",
      " -6.5024108e-01 -1.5839393e+00 -3.0038742e-02 -6.7323214e-01\n",
      " -1.3967865e+00 -7.5738817e-02 -6.0514337e-01 -1.4563630e+00\n",
      " -7.5721867e-02 -7.3325241e-01 -1.5683445e+00 -1.9117180e-01\n",
      " -5.4655164e-01 -1.5094810e+00 -1.1300826e-01 -5.9452361e-01\n",
      " -1.4791946e+00 -1.2941277e-01 -5.6887847e-01 -1.5760807e+00\n",
      "  5.8837086e-03 -5.8000410e-01 -1.6218044e+00 -1.1345508e-01\n",
      " -4.6755517e-01 -1.3382422e+00 -2.1366730e-01 -2.3529039e-01\n",
      " -1.9472837e+00 -7.1494363e-02 -3.7863958e-01 -1.9479172e+00\n",
      "  8.0125511e-02 -3.5099334e-01 -1.4809338e+00 -2.0451623e-01\n",
      " -2.3002766e-01 -1.2802100e+00 -1.4164972e-01 -2.0356287e-01\n",
      " -1.3598886e+00 -9.5035702e-02 -2.0679094e-01 -1.4808266e+00\n",
      " -1.7543890e-02 -2.1892588e-01 -1.3362913e+00  9.0000004e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63438>\n",
      "tensor([[ 0.0641, -0.1227, -0.2174,  ...,  0.0646, -0.3021, -1.2988],\n",
      "        [ 0.0641, -0.1227, -0.2174,  ...,  0.0646, -0.3021, -1.2988],\n",
      "        [ 0.0641, -0.1227, -0.2174,  ...,  0.0646, -0.3021, -1.2988],\n",
      "        ...,\n",
      "        [-0.2914,  0.2523, -0.3705,  ..., -0.8481,  0.7207, -0.5158],\n",
      "        [-0.1517, -0.0934,  0.5571,  ..., -0.2366,  0.6565,  0.3008],\n",
      "        [-0.1517, -0.0934,  0.5571,  ..., -0.2366,  0.6565,  0.3008]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.06413683 -0.12269788 -0.21738727  0.09069285 -0.2533096  -0.615709\n",
      "  0.00364892 -0.427685   -1.3750222  -0.14098433 -0.4869313  -1.6734829\n",
      " -0.3019487  -0.5912289  -2.1754525  -0.13501796 -0.7229125  -1.5533395\n",
      "  0.07075848 -0.75248474 -1.3829944   0.01586201 -0.6899018  -1.4399316\n",
      "  0.00674761 -0.82260936 -1.5561337  -0.09542019 -0.62573016 -1.4698699\n",
      " -0.01942503 -0.6750016  -1.4535122  -0.04101955 -0.6480965  -1.5532892\n",
      "  0.07737216 -0.6703931  -1.5957246  -0.01430532 -0.53931403 -1.3011799\n",
      " -0.12635607 -0.31015536 -1.9339943   0.01620221 -0.4588775  -1.9392638\n",
      "  0.156317   -0.4322217  -1.4528913  -0.11551087 -0.30725783 -1.240226\n",
      " -0.04323738 -0.2850654  -1.3188848  -0.00595326 -0.29285777 -1.435772\n",
      "  0.06458569 -0.302118   -1.29883   ]\n",
      "data: [ 0.06413683 -0.12269787 -0.21738727  0.09069285 -0.2533096  -0.615709\n",
      "  0.00364892 -0.42768496 -1.3750222  -0.14098433 -0.4869313  -1.673483\n",
      " -0.3019487  -0.5912289  -2.1754525  -0.13501796 -0.72291255 -1.5533395\n",
      "  0.07075848 -0.75248474 -1.3829944   0.01586201 -0.6899018  -1.4399316\n",
      "  0.00674761 -0.8226093  -1.5561337  -0.09542019 -0.62573016 -1.4698699\n",
      " -0.01942503 -0.6750016  -1.4535123  -0.04101955 -0.64809644 -1.5532892\n",
      "  0.07737216 -0.67039317 -1.5957246  -0.01430532 -0.53931403 -1.3011798\n",
      " -0.12635607 -0.31015536 -1.9339943   0.01620221 -0.45887747 -1.9392638\n",
      "  0.156317   -0.4322217  -1.4528913  -0.11551087 -0.30725783 -1.240226\n",
      " -0.04323738 -0.2850654  -1.3188848  -0.00595326 -0.29285777 -1.435772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.06458569 -0.302118   -1.2988299   0.1       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[ 0.0312, -0.1329, -0.2032,  ...,  0.0982, -0.3318, -1.2273],\n",
      "        [ 0.0312, -0.1329, -0.2032,  ...,  0.0982, -0.3318, -1.2273],\n",
      "        [ 0.0312, -0.1329, -0.2032,  ...,  0.0982, -0.3318, -1.2273],\n",
      "        ...,\n",
      "        [-0.1134,  0.4451, -0.0455,  ..., -0.6443,  0.9724, -0.3958],\n",
      "        [-0.1649, -0.0550,  0.5830,  ..., -0.2558,  0.6831,  0.1883],\n",
      "        [-0.1649, -0.0550,  0.5830,  ..., -0.2558,  0.6831,  0.1883]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03123678 -0.13285375 -0.20315067  0.05984717 -0.26300412 -0.55737925\n",
      " -0.02667706 -0.46915314 -1.3576937  -0.17268789 -0.5336963  -1.6689419\n",
      " -0.34121987 -0.6606175  -2.1474698  -0.17155811 -0.74553263 -1.5442116\n",
      "  0.08213406 -0.7913329  -1.3427614   0.02151792 -0.7351886  -1.3861415\n",
      "  0.01220448 -0.87715834 -1.5095615  -0.1138593  -0.6418627  -1.4381689\n",
      " -0.0223249  -0.710067   -1.4189217  -0.02211232 -0.6846243  -1.513533\n",
      "  0.10005993 -0.72955394 -1.5609298  -0.00664964 -0.5465671  -1.2553037\n",
      " -0.1451869  -0.31543446 -1.9629658   0.0350382  -0.4970773  -1.9594404\n",
      "  0.19730231 -0.45461243 -1.4009455  -0.1324628  -0.30791742 -1.1846832\n",
      " -0.02503444 -0.28936076 -1.2633564   0.02649509 -0.322548   -1.3765013\n",
      "  0.0981631  -0.3318206  -1.2272526 ]\n",
      "data: [ 0.03123678 -0.13285375 -0.20315067  0.05984717 -0.26300412 -0.55737925\n",
      " -0.02667706 -0.46915314 -1.3576937  -0.17268789 -0.5336963  -1.6689419\n",
      " -0.34121987 -0.6606175  -2.1474698  -0.17155811 -0.74553263 -1.5442116\n",
      "  0.08213405 -0.79133296 -1.3427614   0.02151792 -0.7351886  -1.3861415\n",
      "  0.01220448 -0.87715834 -1.5095614  -0.1138593  -0.6418627  -1.438169\n",
      " -0.0223249  -0.710067   -1.4189217  -0.02211232 -0.6846243  -1.513533\n",
      "  0.10005994 -0.72955394 -1.5609298  -0.00664964 -0.5465671  -1.2553037\n",
      " -0.1451869  -0.31543446 -1.9629658   0.0350382  -0.4970773  -1.9594404\n",
      "  0.1973023  -0.45461243 -1.4009455  -0.1324628  -0.30791742 -1.1846832\n",
      " -0.02503444 -0.28936076 -1.2633564   0.02649509 -0.322548   -1.3765013\n",
      "  0.0981631  -0.3318206  -1.2272526   0.11      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[ 0.0242, -0.1194, -0.1874,  ...,  0.0666, -0.3217, -1.1733],\n",
      "        [ 0.0242, -0.1194, -0.1874,  ...,  0.0666, -0.3217, -1.1733],\n",
      "        [ 0.0242, -0.1194, -0.1874,  ...,  0.0666, -0.3217, -1.1733],\n",
      "        ...,\n",
      "        [-0.0865,  0.4492, -0.1217,  ..., -0.4422,  0.9944, -0.5175],\n",
      "        [-0.1014, -0.0331,  0.6132,  ..., -0.1912,  0.6923,  0.2277],\n",
      "        [-0.1014, -0.0331,  0.6132,  ..., -0.1912,  0.6923,  0.2277]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.42487453e-02 -1.19445123e-01 -1.87442809e-01  6.00603409e-02\n",
      " -2.27471039e-01 -4.83773172e-01 -7.29450062e-02 -4.57951218e-01\n",
      " -1.34045005e+00 -2.26540327e-01 -5.27255535e-01 -1.63559127e+00\n",
      " -3.80304962e-01 -6.27967834e-01 -2.14368463e+00 -1.66525126e-01\n",
      " -7.56270230e-01 -1.52141643e+00  2.73801237e-02 -8.22422504e-01\n",
      " -1.34769058e+00 -3.07783037e-02 -7.53522456e-01 -1.39595938e+00\n",
      " -4.82499227e-02 -9.21198249e-01 -1.52276039e+00 -1.18127376e-01\n",
      " -6.66808844e-01 -1.41511893e+00 -5.66622093e-02 -7.26372361e-01\n",
      " -1.38818789e+00 -6.86728060e-02 -6.94194973e-01 -1.47055507e+00\n",
      "  6.27729446e-02 -7.34996676e-01 -1.49202037e+00 -2.83196643e-02\n",
      " -5.56078136e-01 -1.24570251e+00 -1.92470223e-01 -3.17329049e-01\n",
      " -2.02968073e+00 -1.05107576e-03 -5.02308071e-01 -2.04878855e+00\n",
      "  1.68467999e-01 -4.59875703e-01 -1.34722972e+00 -1.54155821e-01\n",
      " -3.26233447e-01 -1.16684532e+00 -7.48168081e-02 -2.98801601e-01\n",
      " -1.25129652e+00 -3.78608406e-02 -3.08662176e-01 -1.36402440e+00\n",
      "  6.66077808e-02 -3.21688116e-01 -1.17330647e+00]\n",
      "data: [ 2.42487453e-02 -1.19445123e-01 -1.87442824e-01  6.00603372e-02\n",
      " -2.27471054e-01 -4.83773142e-01 -7.29450062e-02 -4.57951188e-01\n",
      " -1.34044993e+00 -2.26540342e-01 -5.27255535e-01 -1.63559127e+00\n",
      " -3.80304933e-01 -6.27967834e-01 -2.14368463e+00 -1.66525111e-01\n",
      " -7.56270230e-01 -1.52141643e+00  2.73801237e-02 -8.22422504e-01\n",
      " -1.34769058e+00 -3.07783037e-02 -7.53522515e-01 -1.39595938e+00\n",
      " -4.82499227e-02 -9.21198249e-01 -1.52276027e+00 -1.18127376e-01\n",
      " -6.66808844e-01 -1.41511881e+00 -5.66622131e-02 -7.26372361e-01\n",
      " -1.38818789e+00 -6.86728060e-02 -6.94194973e-01 -1.47055507e+00\n",
      "  6.27729446e-02 -7.34996617e-01 -1.49202037e+00 -2.83196643e-02\n",
      " -5.56078136e-01 -1.24570251e+00 -1.92470223e-01 -3.17329049e-01\n",
      " -2.02968073e+00 -1.05107576e-03 -5.02308071e-01 -2.04878855e+00\n",
      "  1.68467999e-01 -4.59875703e-01 -1.34722972e+00 -1.54155821e-01\n",
      " -3.26233447e-01 -1.16684532e+00 -7.48168081e-02 -2.98801601e-01\n",
      " -1.25129652e+00 -3.78608406e-02 -3.08662176e-01 -1.36402440e+00\n",
      "  6.66077808e-02 -3.21688116e-01 -1.17330647e+00  1.19999997e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0377, -0.0399, -0.1947,  ...,  0.0139, -0.2268, -1.1799],\n",
      "        [-0.0377, -0.0399, -0.1947,  ...,  0.0139, -0.2268, -1.1799],\n",
      "        [-0.0377, -0.0399, -0.1947,  ...,  0.0139, -0.2268, -1.1799],\n",
      "        ...,\n",
      "        [-0.1658,  0.3407, -0.0054,  ..., -0.7021,  0.9106, -0.4055],\n",
      "        [-0.0928, -0.0743,  0.6025,  ..., -0.2099,  0.6287,  0.2339],\n",
      "        [-0.0928, -0.0743,  0.6025,  ..., -0.2099,  0.6287,  0.2339]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.03774831 -0.03992422 -0.19473897 -0.01243975 -0.15870084 -0.4949648\n",
      " -0.12735745 -0.37710163 -1.3297752  -0.28171152 -0.43866843 -1.6375688\n",
      " -0.45143998 -0.55375177 -2.132227   -0.24856867 -0.66650164 -1.5130336\n",
      " -0.01886049 -0.71668226 -1.321993   -0.07531387 -0.6535468  -1.3678502\n",
      " -0.07726026 -0.80539876 -1.4983389  -0.19494838 -0.5655671  -1.4043918\n",
      " -0.11311267 -0.6261503  -1.3839012  -0.10599165 -0.5929922  -1.4791896\n",
      "  0.03668973 -0.63570625 -1.5161865  -0.09091795 -0.45850444 -1.2262201\n",
      " -0.24591611 -0.22186124 -1.980862   -0.0471673  -0.40311453 -1.9906731\n",
      "  0.13725306 -0.35888594 -1.3593925  -0.22135963 -0.22125784 -1.1511607\n",
      " -0.12512152 -0.19778231 -1.2314931  -0.0816659  -0.21746245 -1.348914\n",
      "  0.01385603 -0.22680221 -1.1798531 ]\n",
      "data: [-0.03774831 -0.03992422 -0.19473895 -0.01243975 -0.15870084 -0.49496478\n",
      " -0.12735745 -0.37710163 -1.3297752  -0.28171152 -0.43866843 -1.6375688\n",
      " -0.45143998 -0.55375177 -2.132227   -0.24856867 -0.66650164 -1.5130336\n",
      " -0.01886049 -0.71668226 -1.321993   -0.07531387 -0.6535468  -1.3678502\n",
      " -0.07726026 -0.80539876 -1.4983389  -0.19494838 -0.5655671  -1.4043918\n",
      " -0.11311267 -0.6261503  -1.3839012  -0.10599165 -0.5929922  -1.4791896\n",
      "  0.03668973 -0.63570625 -1.5161865  -0.09091795 -0.45850444 -1.2262201\n",
      " -0.24591611 -0.22186124 -1.980862   -0.0471673  -0.4031145  -1.9906731\n",
      "  0.13725306 -0.35888594 -1.3593925  -0.22135964 -0.22125784 -1.1511607\n",
      " -0.12512152 -0.19778231 -1.2314931  -0.0816659  -0.21746245 -1.348914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.01385603 -0.22680221 -1.1798531   0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[-0.0381, -0.0426, -0.2282,  ..., -0.0233, -0.2039, -1.3155],\n",
      "        [-0.0381, -0.0426, -0.2282,  ..., -0.0233, -0.2039, -1.3155],\n",
      "        [-0.0381, -0.0426, -0.2282,  ..., -0.0233, -0.2039, -1.3155],\n",
      "        ...,\n",
      "        [-0.2625,  0.2877, -0.1418,  ..., -0.7217,  0.7794, -0.3984],\n",
      "        [-0.1617, -0.1545,  0.5967,  ..., -0.2707,  0.6069,  0.2728],\n",
      "        [-0.1617, -0.1545,  0.5967,  ..., -0.2707,  0.6069,  0.2728]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.03810981 -0.04264897 -0.22820584 -0.02190181 -0.19071093 -0.67937016\n",
      " -0.0893152  -0.35502964 -1.3788745  -0.23496106 -0.4089102  -1.6915686\n",
      " -0.42217666 -0.5315005  -2.1519618  -0.25779396 -0.6365591  -1.5365748\n",
      " -0.00957195 -0.6505094  -1.321084   -0.05601606 -0.59472054 -1.3759925\n",
      " -0.05743404 -0.7143286  -1.4960885  -0.21222156 -0.5245661  -1.452388\n",
      " -0.11507596 -0.5806158  -1.4374485  -0.11338002 -0.55453604 -1.5484655\n",
      "  0.02540271 -0.57862675 -1.6157024  -0.11733846 -0.44212615 -1.2732351\n",
      " -0.22021596 -0.21473317 -1.8813736  -0.06540657 -0.36253792 -1.8731925\n",
      "  0.0950584  -0.3302967  -1.4619906  -0.221667   -0.19817558 -1.216789\n",
      " -0.13713618 -0.17464781 -1.3002193  -0.08387627 -0.19556005 -1.4254322\n",
      " -0.02325371 -0.20387158 -1.3154631 ]\n",
      "data: [-0.03810981 -0.04264897 -0.22820586 -0.02190181 -0.19071093 -0.67937016\n",
      " -0.0893152  -0.35502964 -1.3788745  -0.23496108 -0.4089102  -1.6915686\n",
      " -0.42217666 -0.5315005  -2.1519618  -0.25779396 -0.6365591  -1.5365748\n",
      " -0.00957195 -0.6505094  -1.321084   -0.05601606 -0.59472054 -1.3759925\n",
      " -0.05743404 -0.7143286  -1.4960885  -0.21222156 -0.5245661  -1.452388\n",
      " -0.11507596 -0.5806158  -1.4374484  -0.11338002 -0.55453604 -1.5484654\n",
      "  0.02540271 -0.57862675 -1.6157024  -0.11733846 -0.44212615 -1.2732351\n",
      " -0.22021598 -0.21473317 -1.8813736  -0.06540657 -0.36253792 -1.8731925\n",
      "  0.0950584  -0.3302967  -1.4619907  -0.221667   -0.19817558 -1.216789\n",
      " -0.13713618 -0.17464781 -1.3002193  -0.08387627 -0.19556005 -1.4254321\n",
      " -0.02325371 -0.20387158 -1.3154631   0.14      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0299, -0.1439, -0.2442,  ...,  0.0376, -0.3150, -1.3483],\n",
      "        [ 0.0299, -0.1439, -0.2442,  ...,  0.0376, -0.3150, -1.3483],\n",
      "        [ 0.0299, -0.1439, -0.2442,  ...,  0.0376, -0.3150, -1.3483],\n",
      "        ...,\n",
      "        [-0.2653,  0.3906, -0.3020,  ..., -0.8213,  0.8987, -0.5086],\n",
      "        [-0.1946, -0.0846,  0.6085,  ..., -0.2939,  0.6730,  0.3198],\n",
      "        [-0.1946, -0.0846,  0.6085,  ..., -0.2939,  0.6730,  0.3198]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0298538  -0.14391011 -0.24423781  0.05697441 -0.28549737 -0.681025\n",
      " -0.0060932  -0.44251475 -1.4089224  -0.1460389  -0.4979305  -1.7133508\n",
      " -0.31055194 -0.6124377  -2.2051325  -0.17444907 -0.7304043  -1.5854133\n",
      "  0.06447209 -0.74331456 -1.398322    0.01097786 -0.68769073 -1.4531193\n",
      "  0.00466792 -0.80137426 -1.5702822  -0.13436328 -0.6270794  -1.5048027\n",
      " -0.03881597 -0.6774734  -1.4940504  -0.05171961 -0.6468235  -1.5980643\n",
      "  0.06644784 -0.674135   -1.6555318  -0.04524665 -0.54692304 -1.3288882\n",
      " -0.14116882 -0.3175038  -1.911627   -0.00223222 -0.46137166 -1.9061028\n",
      "  0.13680981 -0.4335003  -1.5068749  -0.14788775 -0.30984366 -1.2699134\n",
      " -0.0604154  -0.288244   -1.3428102  -0.01638269 -0.30619794 -1.4625696\n",
      "  0.03764743 -0.31502444 -1.3483033 ]\n",
      "data: [ 0.0298538  -0.14391011 -0.24423781  0.05697441 -0.28549737 -0.681025\n",
      " -0.0060932  -0.44251478 -1.4089224  -0.1460389  -0.4979305  -1.7133508\n",
      " -0.31055194 -0.6124377  -2.2051325  -0.17444906 -0.73040426 -1.5854133\n",
      "  0.06447209 -0.74331456 -1.398322    0.01097786 -0.68769073 -1.4531192\n",
      "  0.00466792 -0.80137426 -1.5702823  -0.13436328 -0.6270794  -1.5048027\n",
      " -0.03881597 -0.6774734  -1.4940505  -0.05171961 -0.6468235  -1.5980643\n",
      "  0.06644784 -0.674135   -1.6555318  -0.04524665 -0.54692304 -1.3288883\n",
      " -0.14116882 -0.3175038  -1.911627   -0.00223222 -0.46137166 -1.9061028\n",
      "  0.13680981 -0.4335003  -1.5068748  -0.14788775 -0.30984366 -1.2699134\n",
      " -0.0604154  -0.288244   -1.3428102  -0.01638269 -0.30619794 -1.4625696\n",
      "  0.03764743 -0.31502444 -1.3483033   0.15      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0435, -0.1766, -0.2422,  ...,  0.0788, -0.3595, -1.2904],\n",
      "        [ 0.0435, -0.1766, -0.2422,  ...,  0.0788, -0.3595, -1.2904],\n",
      "        [ 0.0435, -0.1766, -0.2422,  ...,  0.0788, -0.3595, -1.2904],\n",
      "        ...,\n",
      "        [-0.1186,  0.4849, -0.1236,  ..., -0.6752,  0.9911, -0.4452],\n",
      "        [-0.2041, -0.0457,  0.6276,  ..., -0.2737,  0.6681,  0.3047],\n",
      "        [-0.2041, -0.0457,  0.6276,  ..., -0.2737,  0.6681,  0.3047]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 4.3527272e-02 -1.7663789e-01 -2.4223381e-01  7.8749418e-02\n",
      " -2.9833889e-01 -5.8831215e-01 -1.4840521e-02 -5.1140106e-01\n",
      " -1.4035920e+00 -1.6345707e-01 -5.7329476e-01 -1.7139957e+00\n",
      " -3.1928372e-01 -6.8913555e-01 -2.2135279e+00 -1.5821391e-01\n",
      " -7.9360735e-01 -1.6034276e+00  8.3309934e-02 -8.4446192e-01\n",
      " -1.4105822e+00  1.9380555e-02 -7.8732693e-01 -1.4550551e+00\n",
      " -1.0527223e-03 -9.3588340e-01 -1.5824435e+00 -1.0538261e-01\n",
      " -6.9473433e-01 -1.4973481e+00 -2.4149761e-02 -7.5900555e-01\n",
      " -1.4816030e+00 -3.0742593e-02 -7.2911966e-01 -1.5755992e+00\n",
      "  8.2889125e-02 -7.7825689e-01 -1.6139568e+00 -3.8393810e-03\n",
      " -5.8567905e-01 -1.3223630e+00 -1.5737309e-01 -3.5167763e-01\n",
      " -2.0619133e+00  2.5752649e-02 -5.3551483e-01 -2.0683584e+00\n",
      "  1.8008700e-01 -4.9072614e-01 -1.4646356e+00 -1.3446394e-01\n",
      " -3.5108179e-01 -1.2488126e+00 -3.5026699e-02 -3.2604980e-01\n",
      " -1.3281660e+00  5.9310198e-03 -3.5323590e-01 -1.4425862e+00\n",
      "  7.8834482e-02 -3.5949987e-01 -1.2903644e+00]\n",
      "data: [ 4.3527268e-02 -1.7663787e-01 -2.4223381e-01  7.8749418e-02\n",
      " -2.9833889e-01 -5.8831215e-01 -1.4840521e-02 -5.1140106e-01\n",
      " -1.4035919e+00 -1.6345707e-01 -5.7329476e-01 -1.7139957e+00\n",
      " -3.1928372e-01 -6.8913561e-01 -2.2135279e+00 -1.5821391e-01\n",
      " -7.9360735e-01 -1.6034275e+00  8.3309934e-02 -8.4446192e-01\n",
      " -1.4105821e+00  1.9380555e-02 -7.8732699e-01 -1.4550551e+00\n",
      " -1.0527223e-03 -9.3588340e-01 -1.5824436e+00 -1.0538261e-01\n",
      " -6.9473433e-01 -1.4973481e+00 -2.4149761e-02 -7.5900561e-01\n",
      " -1.4816031e+00 -3.0742593e-02 -7.2911966e-01 -1.5755992e+00\n",
      "  8.2889125e-02 -7.7825689e-01 -1.6139568e+00 -3.8393810e-03\n",
      " -5.8567905e-01 -1.3223630e+00 -1.5737309e-01 -3.5167763e-01\n",
      " -2.0619133e+00  2.5752649e-02 -5.3551483e-01 -2.0683584e+00\n",
      "  1.8008700e-01 -4.9072611e-01 -1.4646356e+00 -1.3446394e-01\n",
      " -3.5108176e-01 -1.2488126e+00 -3.5026699e-02 -3.2604980e-01\n",
      " -1.3281660e+00  5.9310198e-03 -3.5323590e-01 -1.4425862e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7.8834482e-02 -3.5949984e-01 -1.2903644e+00  1.6000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0045, -0.1169, -0.1969,  ...,  0.0653, -0.3105, -1.1976],\n",
      "        [ 0.0045, -0.1169, -0.1969,  ...,  0.0653, -0.3105, -1.1976],\n",
      "        [ 0.0045, -0.1169, -0.1969,  ...,  0.0653, -0.3105, -1.1976],\n",
      "        ...,\n",
      "        [-0.0905,  0.4559, -0.0857,  ..., -0.6646,  1.0018, -0.4470],\n",
      "        [-0.0910, -0.0094,  0.6229,  ..., -0.1389,  0.6632,  0.2583],\n",
      "        [-0.0910, -0.0094,  0.6229,  ..., -0.1389,  0.6632,  0.2583]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00453762 -0.11690919 -0.19685921  0.03183507 -0.24406844 -0.5109719\n",
      " -0.06206992 -0.45168757 -1.327222   -0.21487331 -0.51192623 -1.644766\n",
      " -0.3887117  -0.6381991  -2.1340082  -0.20579992 -0.732488   -1.5253258\n",
      "  0.04543698 -0.7761092  -1.3352877  -0.01711321 -0.71998495 -1.3813444\n",
      " -0.02075115 -0.86435884 -1.5090121  -0.14774935 -0.6276047  -1.4161204\n",
      " -0.05688647 -0.6941904  -1.4013921  -0.05450008 -0.6682055  -1.5026393\n",
      "  0.07378301 -0.71346414 -1.5457709  -0.03703917 -0.5259472  -1.2290218\n",
      " -0.18417957 -0.2956252  -1.9613945   0.00332676 -0.4794832  -1.9618422\n",
      "  0.17471029 -0.43787044 -1.3769917  -0.1653788  -0.28870362 -1.1608686\n",
      " -0.05895473 -0.27179134 -1.235601   -0.0134432  -0.30199605 -1.3523761\n",
      "  0.06529357 -0.3104623  -1.1976458 ]\n",
      "data: [ 0.00453762 -0.11690919 -0.19685921  0.03183507 -0.24406844 -0.5109719\n",
      " -0.06206992 -0.45168757 -1.327222   -0.21487331 -0.51192623 -1.644766\n",
      " -0.3887117  -0.6381991  -2.1340082  -0.20579992 -0.7324879  -1.5253258\n",
      "  0.04543698 -0.7761092  -1.3352876  -0.01711321 -0.71998495 -1.3813444\n",
      " -0.02075115 -0.86435884 -1.5090121  -0.14774935 -0.6276047  -1.4161204\n",
      " -0.05688647 -0.6941904  -1.4013921  -0.05450008 -0.6682055  -1.5026393\n",
      "  0.07378301 -0.71346414 -1.5457709  -0.03703917 -0.5259472  -1.2290218\n",
      " -0.18417957 -0.2956252  -1.9613945   0.00332676 -0.4794832  -1.9618422\n",
      "  0.17471029 -0.43787044 -1.3769917  -0.1653788  -0.28870362 -1.1608686\n",
      " -0.05895473 -0.27179134 -1.235601   -0.0134432  -0.30199605 -1.3523761\n",
      "  0.06529357 -0.3104623  -1.1976458   0.17      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[-0.0191, -0.0958, -0.1833,  ...,  0.0272, -0.2807, -1.1756],\n",
      "        [-0.0191, -0.0958, -0.1833,  ...,  0.0272, -0.2807, -1.1756],\n",
      "        [-0.0191, -0.0958, -0.1833,  ...,  0.0272, -0.2807, -1.1756],\n",
      "        ...,\n",
      "        [-0.1580,  0.3940, -0.0843,  ..., -0.6693,  0.9638, -0.4703],\n",
      "        [-0.0893, -0.0634,  0.6407,  ..., -0.2067,  0.6751,  0.2184],\n",
      "        [-0.0893, -0.0634,  0.6407,  ..., -0.2067,  0.6751,  0.2184]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01908859 -0.09576681 -0.18327466  0.01463665 -0.20642507 -0.47797406\n",
      " -0.10660106 -0.43074018 -1.3304957  -0.2574301  -0.4939143  -1.6346601\n",
      " -0.41504422 -0.60016537 -2.1381733  -0.21972865 -0.7232349  -1.5141382\n",
      " -0.00497851 -0.7784967  -1.3375278  -0.05994688 -0.7137678  -1.3846178\n",
      " -0.06683493 -0.8724524  -1.5158446  -0.16929643 -0.62798125 -1.4043255\n",
      " -0.09562368 -0.686371   -1.3843553  -0.09415799 -0.6520131  -1.4766809\n",
      "  0.04569124 -0.69540936 -1.5110888  -0.07311351 -0.5171721  -1.229406\n",
      " -0.23259816 -0.27903807 -2.001381   -0.03404428 -0.46018744 -2.0177526\n",
      "  0.14547625 -0.41601384 -1.3574774  -0.20321156 -0.28349227 -1.1516134\n",
      " -0.11373684 -0.25605837 -1.2339513  -0.071877   -0.27112883 -1.350922\n",
      "  0.02715219 -0.28074154 -1.1755843 ]\n",
      "data: [-0.01908859 -0.09576681 -0.18327466  0.01463665 -0.20642507 -0.47797406\n",
      " -0.10660106 -0.43074018 -1.3304957  -0.2574301  -0.4939143  -1.6346602\n",
      " -0.41504422 -0.60016537 -2.1381733  -0.21972865 -0.7232349  -1.5141382\n",
      " -0.00497851 -0.7784967  -1.3375278  -0.05994688 -0.7137678  -1.3846178\n",
      " -0.06683493 -0.8724524  -1.5158446  -0.16929644 -0.62798125 -1.4043256\n",
      " -0.09562369 -0.686371   -1.3843553  -0.09415798 -0.65201306 -1.4766809\n",
      "  0.04569124 -0.6954094  -1.5110888  -0.07311351 -0.5171721  -1.229406\n",
      " -0.23259816 -0.27903807 -2.001381   -0.03404428 -0.46018746 -2.0177526\n",
      "  0.14547625 -0.41601384 -1.3574774  -0.20321156 -0.28349227 -1.1516134\n",
      " -0.11373684 -0.25605837 -1.2339513  -0.071877   -0.27112883 -1.350922\n",
      "  0.02715219 -0.28074154 -1.1755843   0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[-0.0223, -0.0243, -0.1814,  ...,  0.0165, -0.2117, -1.1751],\n",
      "        [-0.0223, -0.0243, -0.1814,  ...,  0.0165, -0.2117, -1.1751],\n",
      "        [-0.0223, -0.0243, -0.1814,  ...,  0.0165, -0.2117, -1.1751],\n",
      "        ...,\n",
      "        [-0.1907,  0.3503, -0.0403,  ..., -0.6738,  0.9280, -0.3971],\n",
      "        [-0.1104, -0.1130,  0.5938,  ..., -0.2262,  0.5992,  0.2545],\n",
      "        [-0.1104, -0.1130,  0.5938,  ..., -0.2262,  0.5992,  0.2545]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.02229249 -0.02434896 -0.18138547  0.003474   -0.13070127 -0.48659384\n",
      " -0.13142473 -0.34968823 -1.3197763  -0.2859124  -0.41122276 -1.6157851\n",
      " -0.4438397  -0.50697035 -2.1198404  -0.22216564 -0.6584527  -1.4908347\n",
      " -0.03284077 -0.7143272  -1.320652   -0.07976954 -0.63985103 -1.3732433\n",
      " -0.07888806 -0.8018737  -1.5028756  -0.17656037 -0.5682273  -1.3893116\n",
      " -0.11001571 -0.6189529  -1.3667314  -0.1072772  -0.5820998  -1.4576557\n",
      "  0.04789962 -0.6138466  -1.4856191  -0.08803452 -0.45976543 -1.2232642\n",
      " -0.23775166 -0.22065787 -1.9727726  -0.04404341 -0.39059097 -1.9950998\n",
      "  0.14672104 -0.34991193 -1.3467534  -0.21088898 -0.22787979 -1.1459143\n",
      " -0.13655017 -0.19702269 -1.2374864  -0.09774604 -0.20010072 -1.3556039\n",
      "  0.01649756 -0.21172288 -1.1750991 ]\n",
      "data: [-0.02229249 -0.02434896 -0.18138547  0.003474   -0.13070127 -0.48659384\n",
      " -0.13142473 -0.34968823 -1.3197763  -0.2859124  -0.41122276 -1.6157851\n",
      " -0.44383967 -0.50697035 -2.1198404  -0.22216564 -0.6584527  -1.4908347\n",
      " -0.03284077 -0.7143272  -1.320652   -0.07976954 -0.63985103 -1.3732435\n",
      " -0.07888806 -0.8018737  -1.5028756  -0.17656036 -0.5682273  -1.3893116\n",
      " -0.11001571 -0.6189529  -1.3667314  -0.1072772  -0.5820998  -1.4576557\n",
      "  0.04789962 -0.6138466  -1.4856191  -0.08803452 -0.45976543 -1.2232642\n",
      " -0.23775166 -0.22065787 -1.9727725  -0.04404341 -0.39059097 -1.9950998\n",
      "  0.14672104 -0.34991193 -1.3467534  -0.21088898 -0.22787979 -1.1459143\n",
      " -0.13655017 -0.19702269 -1.2374864  -0.09774604 -0.20010072 -1.3556039\n",
      "  0.01649756 -0.2117229  -1.1750991   0.19      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[-0.0324, -0.0511, -0.2121,  ..., -0.0075, -0.2103, -1.3204],\n",
      "        [-0.0324, -0.0511, -0.2121,  ..., -0.0075, -0.2103, -1.3204],\n",
      "        [-0.0324, -0.0511, -0.2121,  ..., -0.0075, -0.2103, -1.3204],\n",
      "        ...,\n",
      "        [-0.2453,  0.2999, -0.1419,  ..., -0.7399,  0.7729, -0.3650],\n",
      "        [-0.1689, -0.1265,  0.5411,  ..., -0.2820,  0.6341,  0.2439],\n",
      "        [-0.1689, -0.1265,  0.5411,  ..., -0.2820,  0.6341,  0.2439]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.03238913 -0.05113777 -0.21213908 -0.01859513 -0.21085131 -0.6748495\n",
      " -0.06938725 -0.36372507 -1.3603823  -0.21319593 -0.41675895 -1.6749524\n",
      " -0.40294188 -0.55104953 -2.1317499  -0.25798243 -0.6346263  -1.526272\n",
      "  0.01640601 -0.6378731  -1.296207   -0.03198266 -0.5852513  -1.3477582\n",
      " -0.03132626 -0.68922913 -1.4659141  -0.20999779 -0.5157631  -1.4460683\n",
      " -0.09763333 -0.5738407  -1.4344736  -0.09261505 -0.5467834  -1.5466366\n",
      "  0.0412699  -0.5723762  -1.6229818  -0.1051329  -0.4421885  -1.2633519\n",
      " -0.19445677 -0.21383719 -1.8253759  -0.04814624 -0.35989034 -1.8059391\n",
      "  0.1075     -0.32709122 -1.4677373  -0.2101362  -0.1934319  -1.21125\n",
      " -0.11156136 -0.17323186 -1.2900516  -0.0535388  -0.20318706 -1.4148936\n",
      " -0.00754917 -0.21030158 -1.3204253 ]\n",
      "data: [-0.03238913 -0.05113777 -0.21213908 -0.01859513 -0.21085131 -0.67484957\n",
      " -0.06938725 -0.36372507 -1.3603824  -0.21319593 -0.41675895 -1.6749524\n",
      " -0.40294188 -0.55104953 -2.1317499  -0.25798243 -0.6346263  -1.5262722\n",
      "  0.01640601 -0.6378731  -1.296207   -0.03198266 -0.5852513  -1.3477582\n",
      " -0.03132626 -0.68922913 -1.4659141  -0.20999779 -0.5157631  -1.4460683\n",
      " -0.09763333 -0.5738407  -1.4344735  -0.09261504 -0.5467834  -1.5466367\n",
      "  0.0412699  -0.5723762  -1.6229817  -0.10513291 -0.4421885  -1.2633519\n",
      " -0.19445677 -0.21383719 -1.825376   -0.04814624 -0.35989034 -1.8059391\n",
      "  0.1075     -0.32709122 -1.4677373  -0.2101362  -0.1934319  -1.21125\n",
      " -0.11156136 -0.17323186 -1.2900516  -0.0535388  -0.20318706 -1.4148936\n",
      " -0.00754917 -0.21030158 -1.3204253   0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FA90>\n",
      "tensor([[ 0.0164, -0.1369, -0.2563,  ...,  0.0189, -0.3045, -1.3541],\n",
      "        [ 0.0164, -0.1369, -0.2563,  ...,  0.0189, -0.3045, -1.3541],\n",
      "        [ 0.0164, -0.1369, -0.2563,  ...,  0.0189, -0.3045, -1.3541],\n",
      "        ...,\n",
      "        [-0.2665,  0.4464, -0.3108,  ..., -0.8218,  0.9516, -0.5557],\n",
      "        [-0.1835, -0.0508,  0.6460,  ..., -0.2694,  0.7203,  0.3197],\n",
      "        [-0.1835, -0.0508,  0.6460,  ..., -0.2694,  0.7203,  0.3197]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01644298 -0.1368838  -0.2562804   0.04181166 -0.280289   -0.6913363\n",
      " -0.03232475 -0.44970137 -1.4306872  -0.1731234  -0.5085337  -1.7284698\n",
      " -0.33511522 -0.61911404 -2.2193117  -0.18724266 -0.7324282  -1.6048625\n",
      "  0.0351654  -0.75202453 -1.4277562  -0.01564588 -0.6932374  -1.4818894\n",
      " -0.02021458 -0.81189024 -1.5972384  -0.14897977 -0.6268275  -1.5247351\n",
      " -0.06022799 -0.6767452  -1.5071702  -0.07300251 -0.6456907  -1.6045094\n",
      "  0.04784749 -0.67071533 -1.6572596  -0.06271068 -0.541787   -1.3542098\n",
      " -0.1656697  -0.31273064 -1.9495099  -0.02312613 -0.45814797 -1.9472139\n",
      "  0.11813469 -0.42596927 -1.5142043  -0.16541745 -0.30464178 -1.2912889\n",
      " -0.08404382 -0.27972028 -1.3633522  -0.04042459 -0.29448685 -1.4810777\n",
      "  0.01889513 -0.30453455 -1.3540697 ]\n"
     ]
    }
   ],
   "source": [
    "#recallset = Mydatasets2(datas = data_recall, img_array = img_recall, data_masks = mask_recall, transform = trans)\n",
    "\n",
    "def recall_sequence(data, mask, img, imask):\n",
    "    data = data.astype('float32')/100\n",
    "    mask = mask.astype('float32')\n",
    "    img = img.astype('float32')\n",
    "    imask = imask.astype('float32')\n",
    "    \n",
    "    #data = np.array(data.astype(np.float32))\n",
    "    #mask = np.array(mask.astype(np.float32))\n",
    "    #img = trans(np.array(img.astype(np.float32)))\n",
    "    \n",
    "    print(\"data:\",data)\n",
    "    print(\"mask:\",mask)\n",
    "    print(\"img:\",img)\n",
    "    print(\"imask: \",imask)\n",
    "    #init_l_points = np.array(init_l_points.astype(np.float32))\n",
    "    #print(init_l_points)\n",
    "    recallset = Mydatasets2(datas = data, img_array = img, data_masks = mask, img_masks = imask, transform = trans)\n",
    "    print(\"recall_set:\",recallset)\n",
    "    recallloader = torch.utils.data.DataLoader(recallset, batch_size = 25, shuffle = False, num_workers = 0)\n",
    "    \n",
    "    #net.eval()\n",
    "    for (inputs, imgs, masks, imasks) in recallloader:\n",
    "    #tmp = recallloader.__iter__()\n",
    "    #inputs, imgs, masks = tmp.next()\n",
    "        inputs, imgs, masks, imasks = inputs.to(device), imgs.to(device), masks.to(device), imasks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        handloc, pose_h, posedesc = net(input_img, inputs, input_mask, img_mask)\n",
    "        #手首位置基準座標→物体位置基準座標\n",
    "        xd = torch.zeros_like(pose_h).to(device)\n",
    "        yd = torch.zeros_like(pose_h).to(device)\n",
    "        zd = torch.zeros_like(pose_h).to(device)\n",
    "        for bsize in range(pose_h.size()[0]):\n",
    "            xval = handloc[bsize][0].item()\n",
    "            yval = handloc[bsize][1].item()\n",
    "            zval = handloc[bsize][2].item()\n",
    "            for i in range(int(pose_h.size()[1] / 3)):\n",
    "                xd[bsize][i*3+0] = xval\n",
    "                yd[bsize][i*3+1] = yval\n",
    "                zd[bsize][i*3+2] = zval\n",
    "        recall_out = (pose_h + xd + yd + zd).to(device)\n",
    "        print(recall_out)\n",
    "        break\n",
    "    recall_out_np = recall_out.to('cpu').detach().numpy().copy()\n",
    "    print(recall_out_np[0])\n",
    "    return recall_out_np[0]\n",
    "\n",
    "mask_static = np.ones(data_recall.shape[1])\n",
    "\n",
    "for r in range(len(data_recall)):\n",
    "    with open(PATH + \"\\\\recalls\\\\{:0=4}\".format(r) + \"\\\\recall_0.csv\" , 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        record = data_recall[r]\n",
    "        writer.writerow(record.tolist())\n",
    "    initial = recall_sequence(data_recall[r], mask_recall[r], img_recall[r], imgmask_recall[r])\n",
    "    print(\"init:\",initial)\n",
    "    print(\"type:\",type(initial))\n",
    "    \n",
    "    for t in range(20):\n",
    "        initial = (initial*100).tolist()\n",
    "        initial.append(t+1)\n",
    "        with open(PATH + \"\\\\recalls\\\\{:0=4}\".format(r) + \"\\\\recall_\" + \"{:0=2}\".format(t+1) + \".csv\", 'w') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(initial)\n",
    "        initial = recall_sequence( np.array(initial), mask_static, img_recall[r], imgmask_recall[r])\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydatasets3(torch.utils.data.Dataset):\n",
    "    def __init__(self, datas, img_array, data_masks, img_masks, transform = None):\n",
    "        self.transform = transform\n",
    "        #self.transform2 = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "        self.data = datas\n",
    "        self.img_array = img_array\n",
    "        self.masks = data_masks\n",
    "        self.img_masks = img_masks\n",
    "\n",
    "        self.datanum = datas.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.datanum\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #batch_set = []\n",
    "        \n",
    "        i_data = self.data[idx]\n",
    "        i_img = self.img_array[idx]\n",
    "        i_mask = self.masks[idx]\n",
    "        i_imask = self.img_masks[idx]\n",
    "        \n",
    "        #print(out_label)\n",
    "        #print(type(i_label))\n",
    "        out_data = np.array(i_data.astype(np.float32))\n",
    "        out_img = np.array(i_img.astype(np.float32))\n",
    "        out_mask = np.array(i_mask.astype(np.float32))\n",
    "        out_imask = np.array(i_imask.astype(np.float32))\n",
    "        #out_label.append(i_label.astype(np.float32))\n",
    "        #print(type(out_label))\n",
    "\n",
    "        if self.transform:\n",
    "            #out_data = self.transform(i_data)\n",
    "            out_img = self.transform(out_img)\n",
    "            out_imask = self.transform(out_imask)\n",
    "            #out_label = self.transform2(out_label)\n",
    "        \n",
    "        #batch_set.append(out_data)\n",
    "        #batch_set.append(out_label)\n",
    "        #batch_set.append(out_img)\n",
    "        #batch_set.append(out_mask)\n",
    "        #batch_set.append(out_lmask)\n",
    "\n",
    "        return out_data, out_img, out_mask, out_imask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 64)\n",
      "(600, 36, 36)\n",
      "(600, 64)\n",
      "(600, 36, 36)\n",
      "train_test\n"
     ]
    }
   ],
   "source": [
    "data_check = []\n",
    "img_check = []\n",
    "mask_check = []\n",
    "imgmask_check = []\n",
    "for i in range(len(img_skeleton_sets_train)):\n",
    "    data_check.append(img_skeleton_sets_train[i][0])\n",
    "    img_check.append(img_skeleton_sets_train[i][1])\n",
    "    mask_check.append(img_skeleton_sets_train[i][2])\n",
    "    imgmask_check.append(img_skeleton_sets_train[i][3])\n",
    "    \n",
    "data_check = np.array(data_check).astype('float32')/100\n",
    "img_check = np.array(img_check).astype('float32')/1000\n",
    "mask_check = np.array(mask_check).astype('float32')\n",
    "imgmask_check = np.array(imgmask_check).astype('float32')\n",
    "print(data_check.shape)\n",
    "print(img_check.shape)\n",
    "print(mask_check.shape)\n",
    "print(imgmask_check.shape)\n",
    "\n",
    "checkset = Mydatasets3(datas = data_check, img_array = img_check, data_masks = mask_check, img_masks = imgmask_check, transform = trans)\n",
    "\n",
    "checkloader = torch.utils.data.DataLoader(checkset, batch_size = BATCH_SIZE,\n",
    "                        shuffle = False, num_workers = 0)\n",
    "\n",
    "print(\"train_test\")\n",
    "#train dataを使ってテストをする(パラメータ更新がないようになっている)\n",
    "num = 0\n",
    "net.eval()\n",
    "for (inputs, input_img, input_mask, input_imask) in checkloader:\n",
    "    inputs, input_img, input_mask, input_imask = \\\n",
    "    inputs.to(device), input_img.to(device), input_mask.to(device), input_imask.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(input_img, inputs, input_mask, input_imask)\n",
    "    out_np = (outputs.to('cpu').detach().numpy().copy()) * 100\n",
    "    for b in range(BATCH_SIZE):\n",
    "        with open(PATH + \"\\\\checks\\\\check_\" + str((num * BATCH_SIZE) + b) + \".csv\" , 'w') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(out_np[b].tolist())\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), PATH + \"\\\\model8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.pool = nn.AvgPool2d(2, stride=2)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1,16,3)\n",
    "        self.conv2 = nn.Conv2d(16,32,3)\n",
    "        self.bn2d1 = nn.BatchNorm2d(16)\n",
    "        self.bn2d2 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.fcm = Ignore(32 * 7 * 7 + 64, 32 * 7 * 7 + 64)\n",
    "        self.bnm = nn.BatchNorm1d(32 * 7 * 7 + 64)\n",
    "        #fully connect for hand Location(x,y,z)\n",
    "        self.fcL1 = nn.Linear(32 * 7 * 7 + 64, 300)\n",
    "        self.fcL2 = nn.Linear(300, 30)\n",
    "        self.fcL3 = nn.Linear(30, 3)        \n",
    "        self.bnL1 = nn.BatchNorm1d(300)\n",
    "        self.bnL2 = nn.BatchNorm1d(30)\n",
    "        #fully connect for hand Pose Descriptor(8 properties)\n",
    "        self.fcPD1 = nn.Linear(32 * 7 * 7 + 64, 300)\n",
    "        self.fcPD2 = nn.Linear(300, 60)\n",
    "        self.fcPD3 = nn.Linear(60, 8)\n",
    "        self.bnPD1 = nn.BatchNorm1d(300)\n",
    "        self.bnPD2 = nn.BatchNorm1d(60)\n",
    "\n",
    "    def forward(self, x, y, m, im):\n",
    "        #print(\"original: \",x[0][0:2],\"\\n\",x[1][0:2], x.size())\n",
    "        #print(\"original mask: \",im[0][0:2],\"\\n\",im[1][0:2], im.size())\n",
    "        \n",
    "        #Conv2d 1\n",
    "        x = self.conv1(x)\n",
    "        im = self.conv1(im)\n",
    "        #print(\"conv1: \",x[0:2][0:2], x.size())\n",
    "        #print(\"conv1 mask: \",im[0:2][0:2], im.size())\n",
    "        im_conv1 = im.clone().detach().to(torch.device(\"cuda:0\"))\n",
    "        for c in range(im.size()[1]):\n",
    "            mode, ind = torch.mode(torch.reshape(im[0][c].clone().detach(), (-1, im.size()[2] * im.size()[3])))\n",
    "            im_conv1[:,c] = torch.sub(im_conv1[:,c], mode.item())\n",
    "        #print(\"conv1 mask fix: \",im_conv1[0:2][0:2], im_conv1.size())       \n",
    "        \n",
    "        #ReLU→BatchNorm2d 1\n",
    "        x = self.bn2d1(self.relu(x))\n",
    "        #print(\"relu1: \", x[0:2][0:2], x.size())\n",
    "        #x = self.bn2d1(self.tanh(x))\n",
    "        #print(\"tanh1: \", x[0:2][0:2], x.size())\n",
    "        \n",
    "        #AvgPool2d\n",
    "        x = self.pool(x)\n",
    "        im = self.pool(im_conv1)\n",
    "        #print(\"pool1: \", x[0:2][0:2], x.size())\n",
    "        #print(\"pool1 mask: \",im[0:2][0:2], im.size())\n",
    "        \n",
    "        #Conv2d 2\n",
    "        x = self.conv2(x)\n",
    "        im = self.conv2(im)\n",
    "        #print(\"conv2: \",x[0:2][0:2], x.size())\n",
    "        #print(\"conv2 mask: \",im[0:2][0:2], im.size())\n",
    "        im_conv2 = im.clone().detach().to(torch.device(\"cuda:0\"))\n",
    "        for c in range(im.size()[1]):\n",
    "            mode, ind = torch.mode(torch.reshape(im[0][c].clone().detach(), (-1, im.size()[2] * im.size()[3])))\n",
    "            im_conv2[:,c] = torch.sub(im_conv2[:,c], mode.item())\n",
    "        #print(\"conv2 mask fix: \",im_conv2[0:2][0:2], im_conv2.size())\n",
    "        \n",
    "        #ReLU→BatchNorm2d 2\n",
    "        x = self.bn2d2(self.relu(x))\n",
    "        #print(\"relu2: \", x[0:2][0:2], x.size())\n",
    "        #x = self.bn2d2(self.tanh(x))\n",
    "        #print(\"tanh2: \", x[0:2][0:2], x.size())\n",
    "        \n",
    "        #AvgPool2d\n",
    "        x = self.pool(x)\n",
    "        im = self.pool(im_conv2)\n",
    "        #print(\"pool2: \", x[0:2][0:2], x.size())\n",
    "        #print(\"pool2 mask: \",im[0:2][0:2], im.size())\n",
    "        \n",
    "        #1次元ベクトル化\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        im = im.view(im.size()[0], -1)\n",
    "        #print(\"view: \", x[0:2], x.size())\n",
    "        #print(\"view mask: \",im[0:2], im.size())\n",
    "        \n",
    "        #マスク再構築(0→1, 0以外→0)\n",
    "        im = torch.logical_not(torch.logical_and(im, torch.tensor([True]).to(torch.device(\"cuda:0\")))).float()\n",
    "        #print(\"mask_img: \", im[0:2], im.size())\n",
    "        \n",
    "        #骨格データと結合\n",
    "        x = torch.cat([x, y], axis = -1)\n",
    "        m = torch.cat([im, m], axis = -1)\n",
    "        #print(\"cat: \", x[0:2], x.size())\n",
    "        #print(\"cat mask: \", m[0:2], m.size())\n",
    "        \n",
    "        #MaskedLinear\n",
    "        x = self.fcm(x, m)\n",
    "        #print(\"masked: \", x[0], x.size())\n",
    "        x = self.bnm(self.relu(x))\n",
    "        #x = self.bnm(self.tanh(x))\n",
    "        xL = self.fcL1(x)\n",
    "        xPD = self.fcPD1(x)\n",
    "        #print(\"fc1: \",x[0])\n",
    "        xL = self.bnL1(self.relu(xL))\n",
    "        xPD = self.bnPD1(self.relu(xPD))\n",
    "        #x = self.bn1(self.tanh(x))\n",
    "        xL = self.fcL2(xL)\n",
    "        xPD = self.fcPD2(xPD)\n",
    "        #print(\"fc2: \",x[0])\n",
    "        xL = self.bnL2(self.relu(xL))\n",
    "        xPD = self.bnPD2(self.relu(xPD))\n",
    "        #x = self.bn2(self.tanh(x))\n",
    "        xL = self.fcL3(xL)\n",
    "        xPD = self.fcPD3(xPD)\n",
    "        return xL, xPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

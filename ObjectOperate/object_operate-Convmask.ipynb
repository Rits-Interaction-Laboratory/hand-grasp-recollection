{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fin loading\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt    #グラフ出力用module\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "import glob\n",
    "import os\n",
    "import csv\n",
    "\n",
    "PATH = os.getcwd()\n",
    "image_size=36\n",
    "\n",
    "#seanセットフォルダ一覧取得\n",
    "datadir = PATH + \"\\\\dataset_h\"\n",
    "traindir = datadir + \"\\\\train\"\n",
    "testdir = datadir + \"\\\\test\"\n",
    "train_seanset = glob.glob(traindir + \"\\\\*\")\n",
    "test_seanset = glob.glob(testdir + \"\\\\*\")\n",
    "\n",
    "train_sean_seqs = []\n",
    "test_sean_seqs = []\n",
    "for sean in train_seanset:\n",
    "    #sean_imgcfile = glob.glob(sean + \"\\\\object*.png\")[0]\n",
    "    sean_imgdfile = glob.glob(sean + \"\\\\objectd*.png\")[0]\n",
    "    s_datafiles = glob.glob(sean + \"\\\\data\\\\*.csv\")\n",
    "    s_labelfiles = glob.glob(sean + \"\\\\label\\\\*.csv\")\n",
    "    for t in range(len(s_datafiles)):\n",
    "        pair = []\n",
    "        pair.append(s_datafiles[t])\n",
    "        pair.append(s_labelfiles[t])\n",
    "        pair.append(sean_imgdfile)\n",
    "        train_sean_seqs.append(pair) #dataとlabelと画像名をセットで登録\n",
    "for sean in test_seanset:\n",
    "    #sean_imgcfile = glob.glob(sean + \"\\\\object*.png\")[0]\n",
    "    sean_imgdfile = glob.glob(sean + \"\\\\objectd*.png\")[0]\n",
    "    s_datafiles = glob.glob(sean + \"\\\\data\\\\*.csv\")\n",
    "    s_labelfiles = glob.glob(sean + \"\\\\label\\\\*.csv\")\n",
    "    for t in range(len(s_datafiles)):\n",
    "        pair = []\n",
    "        pair.append(s_datafiles[t])\n",
    "        pair.append(s_labelfiles[t])\n",
    "        pair.append(sean_imgdfile)\n",
    "        test_sean_seqs.append(pair) #dataとlabelと画像名をセットで登録\n",
    "\n",
    "img_skeleton_sets_train = []\n",
    "img_skeleton_sets_test = []\n",
    "\n",
    "def make_datasets(sean_seqs):\n",
    "    img_skeleton_sets = []\n",
    "    for i in range(len(sean_seqs)):\n",
    "        #画像読み込み・リサイズ・配列に変換\n",
    "        image = Image.open(sean_seqs[i][2])\n",
    "        image = image.resize((image_size, image_size))\n",
    "        img_array = np.asarray(image)\n",
    "        #画像マスク作成(元画像の画素値が外れ値(0～500)の部分を1にする、他は0)\n",
    "        img_mask_array = np.zeros((image_size, image_size), np.uint8)\n",
    "        for h in range(img_array.shape[0]):\n",
    "            for w in range(img_array.shape[1]):\n",
    "                if 0 <= img_array[h,w] < 500:\n",
    "                    img_mask_array[h,w] = 1\n",
    "        data_points = []\n",
    "        data_masks = []\n",
    "        data_masks2 = []\n",
    "        label_points = []\n",
    "        label_masks = []\n",
    "        invdata_cnt = 0\n",
    "        invlabel_cnt = 0\n",
    "        #学習用骨格データ読み込み\n",
    "        with open(sean_seqs[i][0]) as f:\n",
    "            reader = csv.reader(f)\n",
    "            num = 0\n",
    "            for row in reader:\n",
    "                if num == 0:\n",
    "                    elem = 1\n",
    "                    for point in row:\n",
    "                        if float(point) == -10000 or float(point) == 0:\n",
    "                            invdata_cnt += 1\n",
    "                            data_points.append(float(0))\n",
    "                            data_masks.append(0)\n",
    "                            if elem != 64:\n",
    "                                data_masks2.append(0)\n",
    "                        else:\n",
    "                            data_points.append(float(point))\n",
    "                            data_masks.append(1)\n",
    "                            if elem != 64:\n",
    "                                data_masks2.append(1)\n",
    "                        elem += 1\n",
    "                    data_points = np.asarray(data_points)\n",
    "                    data_masks = np.asarray(data_masks)\n",
    "                    data_masks2 = np.array(data_masks2)\n",
    "                    num += 1\n",
    "        #ラベル用骨格データ読み込み\n",
    "        with open(sean_seqs[i][1]) as f:\n",
    "            reader = csv.reader(f)\n",
    "            num = 0\n",
    "            for row in reader:\n",
    "                if num == 0:\n",
    "                    for point in row:\n",
    "                        if float(point) == -10000 or float(point) == 0:\n",
    "                            invlabel_cnt += 1\n",
    "                            label_points.append(float(0))\n",
    "                            label_masks.append(0)\n",
    "                        else:\n",
    "                            label_points.append(float(point))\n",
    "                            label_masks.append(1)\n",
    "                    label_points = np.asarray(label_points)\n",
    "                    label_masks = np.asarray(label_masks)\n",
    "                    num += 1\n",
    "        #画像・学習用・ラベル用スケルトンデータをパッケージング\n",
    "        if invdata_cnt >= 1 or invlabel_cnt >= 1:\n",
    "            continue\n",
    "        img_skeleton_pack = []\n",
    "        img_skeleton_pack.append(img_array)\n",
    "        img_skeleton_pack.append(img_mask_array)\n",
    "        img_skeleton_pack.append(data_points)\n",
    "        img_skeleton_pack.append(data_masks)\n",
    "        img_skeleton_pack.append(data_masks2)\n",
    "        img_skeleton_pack.append(label_points)\n",
    "        img_skeleton_pack.append(label_masks)\n",
    "        #パッケージをデータセットに登録\n",
    "        img_skeleton_sets.append(img_skeleton_pack)\n",
    "    return img_skeleton_sets\n",
    "\n",
    "img_skeleton_sets_train = np.array(make_datasets(train_sean_seqs))\n",
    "img_skeleton_sets_test = np.array(make_datasets(test_sean_seqs))\n",
    "print(\"fin loading\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(270, 7) img_skeleton_sets_train shape\n",
      "(36, 7) img_skeleton_sets_test  shape\n"
     ]
    }
   ],
   "source": [
    "#print(\"[0]image     \", img_skeleton_sets_train[0][0].shape, \"\\n\", img_skeleton_sets_train[0][0]) #画像\n",
    "#print(\"[1]image-mask\", img_skeleton_sets_train[0][1].shape, \"\\n\", img_skeleton_sets_train[0][1]) #画像マスク\n",
    "#print(\"[2]input     \", img_skeleton_sets_train[0][2].shape, \"\\n\", img_skeleton_sets_train[0][2]) #骨格(入力)\n",
    "#print(\"[3]input-mask\", img_skeleton_sets_train[0][3].shape, \"\\n\", img_skeleton_sets_train[0][3]) #骨格マスク(入力)\n",
    "#print(\"[4]label     \", img_skeleton_sets_train[0][4].shape, \"\\n\", img_skeleton_sets_train[0][4]) #骨格(ラベル)\n",
    "#print(\"[5]label-mask\", img_skeleton_sets_train[0][5].shape, \"\\n\", img_skeleton_sets_train[0][5]) #骨格マスク(ラベル)\n",
    "\n",
    "print(type(img_skeleton_sets_train))\n",
    "print(img_skeleton_sets_train.shape, \"img_skeleton_sets_train shape\")\n",
    "print(img_skeleton_sets_test.shape, \"img_skeleton_sets_test  shape\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# 数合わせ用\n",
    "img_skeleton_sets_train, govage = train_test_split(\n",
    "    img_skeleton_sets_train,\n",
    "    shuffle = False,\n",
    "    train_size = 270\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "img_skeleton_sets_test, govage = train_test_split(\n",
    "    img_skeleton_sets_test,\n",
    "    shuffle = False,\n",
    "    train_size = 36\n",
    ")\n",
    "#print(img_skeleton_sets_train.shape, img_skeleton_sets_test.shape, govage.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-709.824     -3.05917  215.      -686.776     -1.88933  219.\n",
      " -668.719     18.1747   246.      -671.82      38.0006   260.578\n",
      " -682.365     50.307    271.314   -694.682     51.6632   246.\n",
      " -710.251     66.53     343.      -708.44      68.4203   359.018\n",
      " -708.855     59.8439   372.571   -719.396     51.7795   277.\n",
      " -724.463     70.2023   339.      -712.818     66.6119   343.\n",
      " -704.887     62.713    351.      -730.87      52.5227   274.\n",
      " -736.722     65.1119   338.      -738.357     68.6287   355.879\n",
      " -709.872     56.0759   310.      -735.735     49.9692   274.\n",
      " -727.124     60.2585   277.      -714.243     58.0638   279.958\n",
      " -706.288     52.4367   267.         1.     ]\n",
      "[[3435 3435 3442 ... 3446 3446 3449]\n",
      " [3435 3435 3426 ... 3425 3425 3426]\n",
      " [3426 3426 3425 ... 3414 3414 3411]\n",
      " ...\n",
      " [3023 3023 3010 ... 2917 2917 2943]\n",
      " [3023 3023 3010 ... 2917 2917 2943]\n",
      " [3009 3009 2998 ... 2922 2922 2949]]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n",
      "[-709.401     -5.60336  214.      -687.087     -2.00882  220.\n",
      " -665.617     18.3058   244.      -669.72      38.7328   257.385\n",
      " -693.427     50.4301   273.177   -695.217     48.742    248.\n",
      " -704.813     71.0193   325.      -697.981     70.7466   339.692\n",
      " -690.205     70.5085   353.      -720.659     51.3769   281.\n",
      " -721.432     73.9282   329.      -705.2       73.7225   326.\n",
      " -702.912     62.4407   310.87    -735.344     51.1156   288.\n",
      " -730.093     66.2593   325.      -718.639     65.4632   329.\n",
      " -697.513     62.9241   326.164   -737.743     48.4609   288.\n",
      " -731.79      63.5343   299.      -728.871     57.3302   310.485\n",
      " -726.742     52.8046   318.862  ]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "data_train = []\n",
    "img_train = []\n",
    "mask_train = []\n",
    "mask_train2 = []\n",
    "imask_train = []\n",
    "data_test = []\n",
    "img_test = []\n",
    "mask_test = []\n",
    "mask_test2 = []\n",
    "imask_test = []\n",
    "label_train = []\n",
    "lmask_train = []\n",
    "label_test = []\n",
    "lmask_test = []\n",
    "for i in range(len(img_skeleton_sets_train)):\n",
    "    data_train.append(img_skeleton_sets_train[i][2])\n",
    "    img_train.append(img_skeleton_sets_train[i][0])\n",
    "    mask_train.append(img_skeleton_sets_train[i][3])\n",
    "    mask_train2.append(img_skeleton_sets_train[i][4])\n",
    "    imask_train.append(img_skeleton_sets_train[i][1])\n",
    "    label_train.append(img_skeleton_sets_train[i][5])\n",
    "    lmask_train.append(img_skeleton_sets_train[i][6])\n",
    "for i in range(len(img_skeleton_sets_test)):\n",
    "    data_test.append(img_skeleton_sets_test[i][2])\n",
    "    img_test.append(img_skeleton_sets_test[i][0])\n",
    "    mask_test.append(img_skeleton_sets_test[i][3])\n",
    "    mask_test2.append(img_skeleton_sets_train[i][4])\n",
    "    imask_test.append(img_skeleton_sets_test[i][1])\n",
    "    label_test.append(img_skeleton_sets_test[i][5])\n",
    "    lmask_test.append(img_skeleton_sets_test[i][6])\n",
    "    \n",
    "print(data_train[0])\n",
    "print(img_train[0])\n",
    "print(mask_train[0])\n",
    "print(mask_train2[0])\n",
    "print(imask_train[0])\n",
    "print(label_train[0])\n",
    "print(lmask_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_trainF = np.array(data_train).astype('float32')/100\n",
    "data_testF = np.array(data_test).astype('float32')/100\n",
    "img_trainF = np.array(img_train).astype('float32')/10000\n",
    "img_testF = np.array(img_test).astype('float32')/10000\n",
    "mask_trainF = np.array(mask_train).astype('float32')\n",
    "mask_testF = np.array(mask_test).astype('float32')\n",
    "mask_train2F = np.array(mask_train2).astype('float32')\n",
    "mask_test2F = np.array(mask_test2).astype('float32')\n",
    "imask_trainF = np.array(imask_train).astype('float32')\n",
    "imask_testF = np.array(imask_test).astype('float32')\n",
    "label_trainF = np.array(label_train).astype('float32')/100\n",
    "label_testF = np.array(label_test).astype('float32')/100\n",
    "lmask_trainF = np.array(lmask_train).astype('float32')\n",
    "lmask_testF = np.array(lmask_test).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data        train  (270, 64)\n",
      "data        test   (36, 64)\n",
      "image       train  (270, 36, 36)\n",
      "image       test   (36, 36, 36)\n",
      "data-mask   train  (270, 64)\n",
      "data-mask   test   (36, 64)\n",
      "data-mask2  train  (270, 63)\n",
      "data-mask2  test   (36, 63)\n",
      "image-mask  train  (270, 36, 36)\n",
      "image-mask  test   (36, 36, 36)\n",
      "label       train  (270, 63)\n",
      "label       test   (36, 63)\n",
      "label-mask  train  (270, 63)\n",
      "label-mask  test   (36, 63)\n"
     ]
    }
   ],
   "source": [
    "print(\"data        train \",data_trainF.shape)\n",
    "print(\"data        test  \",data_testF.shape)\n",
    "print(\"image       train \",img_trainF.shape)\n",
    "print(\"image       test  \",img_testF.shape)\n",
    "print(\"data-mask   train \",mask_trainF.shape)\n",
    "print(\"data-mask   test  \",mask_testF.shape)\n",
    "print(\"data-mask2  train \",mask_train2F.shape)\n",
    "print(\"data-mask2  test  \",mask_test2F.shape)\n",
    "print(\"image-mask  train \",imask_trainF.shape)\n",
    "print(\"image-mask  test  \",imask_testF.shape)\n",
    "print(\"label       train \",label_trainF.shape)\n",
    "print(\"label       test  \",label_testF.shape)\n",
    "print(\"label-mask  train \",lmask_trainF.shape)\n",
    "print(\"label-mask  test  \",lmask_testF.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = torchvision.transforms.Compose(\n",
    "    [torchvision.transforms.ToTensor()]#,torchvision.transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydatasets(torch.utils.data.Dataset):\n",
    "    def __init__(self, datas, labels, img_array, data_masks, data_masks2, label_masks, img_masks, transform = None):\n",
    "        self.transform = transform\n",
    "        #self.transform2 = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "        self.data = datas\n",
    "        self.label = labels\n",
    "        self.img_array = img_array\n",
    "        self.masks = data_masks\n",
    "        self.masks2 = data_masks2\n",
    "        self.lmasks = label_masks\n",
    "        self.imasks = img_masks\n",
    "\n",
    "        self.datanum = datas.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.datanum\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #batch_set = []\n",
    "        \n",
    "        i_data = self.data[idx]\n",
    "        i_label = self.label[idx]\n",
    "        i_img = self.img_array[idx]\n",
    "        i_mask = self.masks[idx]\n",
    "        i_mask2 = self.masks2[idx]\n",
    "        i_lmask = self.lmasks[idx]\n",
    "        i_imask = self.imasks[idx]\n",
    "        \n",
    "        #print(out_label)\n",
    "        #print(type(i_label))\n",
    "        out_label = np.array(i_label.astype(np.float32))\n",
    "        out_data = np.array(i_data.astype(np.float32))\n",
    "        out_img = np.array(i_img.astype(np.float32))\n",
    "        out_mask = np.array(i_mask.astype(np.float32))\n",
    "        out_mask2 = np.array(i_mask2.astype(np.float32))\n",
    "        out_lmask = np.array(i_lmask.astype(np.float32))\n",
    "        out_imask = np.array(i_imask.astype(np.float32))\n",
    "        #out_label.append(i_label.astype(np.float32))\n",
    "        #print(type(out_label))\n",
    "\n",
    "        if self.transform:\n",
    "            #out_data = self.transform(i_data)\n",
    "            out_img = self.transform(out_img)\n",
    "            out_imask = self.transform(out_imask)\n",
    "            #out_label = self.transform2(out_label)\n",
    "        \n",
    "        #batch_set.append(out_data)\n",
    "        #batch_set.append(out_label)\n",
    "        #batch_set.append(out_img)\n",
    "        #batch_set.append(out_mask)\n",
    "        #batch_set.append(out_lmask)\n",
    "\n",
    "        return out_data, out_label, out_img, out_mask, out_mask2, out_lmask, out_imask\n",
    "        #return batch_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = Mydatasets(datas = data_trainF, labels = label_trainF, img_array = img_trainF, data_masks = mask_trainF, data_masks2 = mask_train2F, label_masks = lmask_trainF, img_masks = imask_trainF, transform = trans)\n",
    "testset = Mydatasets(datas = data_testF, labels = label_testF, img_array = img_testF, data_masks = mask_testF, data_masks2 = mask_test2F, label_masks = lmask_testF, img_masks = imask_testF, transform = trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 18\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size = BATCH_SIZE,\n",
    "                        shuffle = True, num_workers = 0)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size = BATCH_SIZE,\n",
    "                        shuffle = False, num_workers = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ignore(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, activation = lambda x: x):\n",
    "        '''\n",
    "        引数:\n",
    "            input_dim: 入力次元\n",
    "            output_dim: 出力次元\n",
    "            activation: 活性化関数\n",
    "        パラメータ:\n",
    "            W: 重み\n",
    "            b: バイアス\n",
    "        '''\n",
    "        super().__init__()\n",
    "        self.W = nn.Parameter(torch.Tensor(np.random.normal(size = (output_dim, input_dim))))\n",
    "        self.b = nn.Parameter(torch.Tensor(np.zeros(output_dim)))\n",
    "        self.activation = activation\n",
    "    def forward(self, x, mask):\n",
    "        \n",
    "        out = torch.empty_like(x).to(torch.device(\"cuda:0\"))\n",
    "        masked_x = torch.mul(x, mask)\n",
    "        \n",
    "        try:\n",
    "            m_size = torch.Tensor(mask.size()[1]).to(torch.device(\"cuda:0\"))\n",
    "            m_sum = torch.sum(mask, 1).to(torch.device(\"cuda:0\"))\n",
    "            rate = (m_size.size()[0] / m_sum).to(torch.device(\"cuda:0\"))\n",
    "            for b in range(out.size()[0]):\n",
    "                out[b] = torch.add(torch.mul(rate[b], torch.sum(torch.mul(masked_x[b], self.W), 1)), self.b)\n",
    "        except IndexError:\n",
    "            m_size = torch.Tensor(mask.size()).to(torch.device(\"cuda:0\"))\n",
    "            m_sum = torch.sum(mask).to(torch.device(\"cuda:0\"))\n",
    "            rate = (m_size.size()[0] / m_sum).to(torch.device(\"cuda:0\"))\n",
    "            out = torch.add(torch.mul(rate, torch.sum(torch.mul(masked_x, self.W))), self.b)\n",
    "        \n",
    "        return self.activation(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HandGraspRecolletion(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(HandGraspRecolletion, self).__init__()\n",
    "        #CNN\n",
    "        self.pool = nn.AvgPool2d(2, stride=2)\n",
    "        self.conv1 = nn.Conv2d(1,16,3)\n",
    "        self.conv2 = nn.Conv2d(16,32,3)\n",
    "        self.bn2d1 = nn.BatchNorm2d(16)\n",
    "        self.bn2d2 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.fcm = Ignore(32 * 7 * 7 + 64, 32 * 7 * 7 + 64)\n",
    "        self.bnm = nn.BatchNorm1d(32 * 7 * 7 + 64)\n",
    "        #fully connect for hand Location(x,y,z)\n",
    "        self.fcL1 = nn.Linear(32 * 7 * 7 + 64, 300)\n",
    "        self.fcL2 = nn.Linear(300, 30)\n",
    "        self.fcL3 = nn.Linear(30, 3)        \n",
    "        self.bnL1 = nn.BatchNorm1d(300)\n",
    "        self.bnL2 = nn.BatchNorm1d(30)\n",
    "        #fully connect for hand Pose Descriptor(8 properties)\n",
    "        self.fcPD1 = nn.Linear(32 * 7 * 7 + 64, 300)\n",
    "        self.fcPD2 = nn.Linear(300, 60)\n",
    "        self.fcPD3 = nn.Linear(60, 8)\n",
    "        self.bnPD1 = nn.BatchNorm1d(300)\n",
    "        self.bnPD2 = nn.BatchNorm1d(60)\n",
    "        \n",
    "        #Autoencoder\n",
    "        self.mask = Ignore(84, 84)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dense_enc1 = nn.Linear(84, 40)\n",
    "        self.bn1 = nn.BatchNorm1d(40)\n",
    "        self.dense_enc2 = nn.Linear(40, 18)\n",
    "        self.bn2 = nn.BatchNorm1d(18)\n",
    "        self.dense_enc3 = nn.Linear(18,8)\n",
    "    \n",
    "        self.dense_dec1 = nn.Linear(8,16)\n",
    "        self.bn4 = nn.BatchNorm1d(16)\n",
    "        self.dense_dec2 = nn.Linear(16, 32)\n",
    "        self.bn5 = nn.BatchNorm1d(32)\n",
    "        self.drop1 = nn.Dropout(p=0.2)\n",
    "        self.dense_dec3 = nn.Linear(32, 63)\n",
    "\n",
    "    def cnn_part(self, x, y, m, im):\n",
    "        #Conv2d 1\n",
    "        x = self.conv1(x)\n",
    "        im = self.conv1(im)\n",
    "        im_conv1 = im.clone().detach().to(torch.device(\"cuda:0\"))\n",
    "        for c in range(im.size()[1]):\n",
    "            mode, ind = torch.mode(torch.reshape(im[0][c].clone().detach(), (-1, im.size()[2] * im.size()[3])))\n",
    "            im_conv1[:,c] = torch.sub(im_conv1[:,c], mode.item())\n",
    "        #ReLU→BatchNorm2d 1\n",
    "        x = self.bn2d1(self.relu(x))\n",
    "        #AvgPool2d\n",
    "        x = self.pool(x)\n",
    "        im = self.pool(im_conv1)\n",
    "        #Conv2d 2\n",
    "        x = self.conv2(x)\n",
    "        im = self.conv2(im)\n",
    "        im_conv2 = im.clone().detach().to(torch.device(\"cuda:0\"))\n",
    "        for c in range(im.size()[1]):\n",
    "            mode, ind = torch.mode(torch.reshape(im[0][c].clone().detach(), (-1, im.size()[2] * im.size()[3])))\n",
    "            im_conv2[:,c] = torch.sub(im_conv2[:,c], mode.item())\n",
    "        #ReLU→BatchNorm2d 2\n",
    "        x = self.bn2d2(self.relu(x))\n",
    "        #AvgPool2d\n",
    "        x = self.pool(x)\n",
    "        im = self.pool(im_conv2)\n",
    "        #1次元ベクトル化\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        im = im.view(im.size()[0], -1)\n",
    "        #マスク再構築(0→1, 0以外→0)\n",
    "        im = torch.logical_not(torch.logical_and(im, torch.tensor([True]).to(torch.device(\"cuda:0\")))).float()\n",
    "        #骨格データと結合\n",
    "        x = torch.cat([x, y], axis = -1)\n",
    "        m = torch.cat([im, m], axis = -1)\n",
    "        #MaskedLinear\n",
    "        x = self.fcm(x, m)\n",
    "        x = self.bnm(self.relu(x))\n",
    "        xL = self.fcL1(x)\n",
    "        xPD = self.fcPD1(x)\n",
    "        xL = self.bnL1(self.relu(xL))\n",
    "        xPD = self.bnPD1(self.relu(xPD))\n",
    "        xL = self.fcL2(xL)\n",
    "        xPD = self.fcPD2(xPD)\n",
    "        xL = self.bnL2(self.relu(xL))\n",
    "        xPD = self.bnPD2(self.relu(xPD))\n",
    "        xL = self.fcL3(xL)\n",
    "        xPD = self.fcPD3(xPD)\n",
    "        return xL, xPD\n",
    "        \n",
    "    def encoder(self, x):\n",
    "        #x = torch.div(x, 100.)\n",
    "        #x = self.mask(x, m)\n",
    "        x = self.dense_enc1(x)\n",
    "        x = self.bn1(self.relu(x))\n",
    "        x = self.dense_enc2(x)\n",
    "        x = self.bn2(self.relu(x))\n",
    "        x = self.dense_enc3(x)\n",
    "        return x\n",
    "\n",
    "    def decoder(self, x):\n",
    "        x = self.dense_dec1(x)\n",
    "        x = self.bn4(self.relu(x))\n",
    "        x = self.dense_dec2(x)\n",
    "        x = self.bn5(self.relu(x))\n",
    "        #x = self.drop1(x)\n",
    "        x = self.dense_dec3(x)\n",
    "        #x = self.mask(x, m)\n",
    "        #x = torch.mul(x, 100.)\n",
    "        return x\n",
    "    \n",
    "    def forward(self, x, y, m, im):\n",
    "        xLoc, xPD = self.cnn_part(x, y, m, im)\n",
    "        xPose = self.decoder(xPD)\n",
    "        return xLoc, xPose, xPD\n",
    "    #    if x != None and z == None:\n",
    "    #        z = self.encoder(x)\n",
    "    #        x = self.decoder(z)\n",
    "    #    elif x == None and z != None:\n",
    "    #        print(\"decoder only\")\n",
    "    #        x = self.decoder(z)\n",
    "    #    return x, z\n",
    "\n",
    "    #def forward(self, x=None, z=None):\n",
    "    #    if x != None and z == None:\n",
    "    #        z = self.encoder(x)\n",
    "    #        x = self.decoder(z)\n",
    "    #    elif x == None and z != None:\n",
    "    #        print(\"decoder only\")\n",
    "    #        x = self.decoder(z)\n",
    "    #    return x, z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MaskMSELoss(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(MaskMSELoss, self).__init__()\n",
    "        #self.margin = margin\n",
    "\n",
    "    def forward(self, inputs, labels, imasks2, lmasks):\n",
    "        ##m_size = lmasks.size()[1]     #print(\"m_size:\",m_size)\n",
    "        #3m_sum = torch.sum(lmasks, 1)  #print(\"m_sum:\",m_sum)\n",
    "        \n",
    "        #無効値をマスクがけして減った要素分の比率をlossにかけて増幅する\n",
    "        #rate = (m_size / m_sum).reshape(BATCH_SIZE,-1) #print(\"rate:\",rate)\n",
    "        #for i in range(rate.size()[0]):\n",
    "        #    #print(rate[i].item())\n",
    "        #    if np.isinf(rate[i].item()):\n",
    "        #        rate[i] = 0. #print(\"inf!\")\n",
    "        ##print(\"rate+:\", rate)\n",
    "        \n",
    "        #imask = torch.\n",
    "        \n",
    "        masked_in = torch.mul(torch.mul(inputs, imasks2), lmasks)\n",
    "        masked_lb = torch.mul(torch.mul(labels, imasks2), lmasks)\n",
    "        \n",
    "        #loss = torch.sub(masked_in, masked_lb)\n",
    "        #print(\"sub:\",loss)\n",
    "        #loss = torch.pow(loss, 2)\n",
    "        #print(\"pow:\",loss)\n",
    "        #loss = torch.sum(loss, 1)\n",
    "        #print(\"sum:\",loss)\n",
    "        #loss = torch.div(loss, m_sum)\n",
    "        #print(\"div:\",loss)\n",
    "        #loss = torch.mul(rate, loss)\n",
    "        #print(\"gain2:\",loss)\n",
    "        #loss = torch.mean(loss)\n",
    "        #print(\"mean:\",loss)\n",
    "        \n",
    "        loss = torch.sub(masked_in, masked_lb)\n",
    "        loss = torch.pow(loss, 2)\n",
    "        #loss = torch.mul(loss, rate)\n",
    "        loss = torch.mean(loss, 1)\n",
    "        loss = torch.mean(loss)\n",
    "        \n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.01\n",
    "#WEIGHT_DECAY = 0.0001\n",
    "#MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 0.\n",
    "MOMENTUM = 0.\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "device_cpu = torch.device('cpu')\n",
    "#net = Net().to(device)\n",
    "#ae = Autoencoder()\n",
    "net = HandGraspRecolletion().to(device)\n",
    "net.load_state_dict(torch.load(PATH + \"\\\\hand_AE_model\"))\n",
    "for p in net.parameters(): # freeze all model parameters\n",
    "    p.requires_grad = False\n",
    "for p in net.conv1.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.conv2.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.bn2d1.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.bn2d2.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.fcm.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.bnm.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.fcL1.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.fcL2.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.fcL3.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.bnL1.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.bnL2.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.fcPD1.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.fcPD2.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.fcPD3.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.bnPD1.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.bnPD2.parameters():\n",
    "    p.requires_grad = True    \n",
    "criterion = MaskMSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "train_loss_value=[]      #trainingのlossを保持するlist\n",
    "test_loss_value=[]       #testのlossを保持するlist\n",
    "\n",
    "train_input_value = []\n",
    "train_output_value = []\n",
    "train_desc_value = []\n",
    "train_handloc_value = []\n",
    "test_input_value = []\n",
    "test_output_value = []\n",
    "test_desc_value = []\n",
    "test_handloc_value = []\n",
    "\n",
    "train_size = data_trainF.shape[0]\n",
    "test_size = data_testF.shape[0]\n",
    "\n",
    "max_train_loss_value = 0.\n",
    "max_test_loss_value = 0.\n",
    "min_test_loss_value = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "keys = [\"conv1.weight\",\"conv1.bias\",\"conv2.weight\",\"conv2.bias\",\"bn2d1.weight\",\"bn2d1.bias\",\"bn2d2.weight\",\\\n",
    "        \"bn2d2.bias\",\"fcm.W\",\"fcm.b\",\"bnm.weight\",\"bnm.bias\",\"fcL1.weight\",\"fcL1.bias\",\"fcL2.weight\",\\\n",
    "        \"fcL2.bias\",\"fcL3.weight\",\"fcL3.bias\",\"bnL1.weight\",\"bnL1.bias\",\"bnL2.weight\",\"bnL2.bias\",\\\n",
    "        \"fcPD1.weight\",\"fcPD1.bias\",\"fcPD2.weight\",\"fcPD2.bias\",\"fcPD3.weight\",\"fcPD3.bias\",\"bnPD1.weight\",\\\n",
    "        \"bnPD1.bias\",\"bnPD2.weight\",\"bnPD2.bias\",\"mask.W\",\"mask.b\",\"dense_enc1.weight\",\"dense_enc1.bias\",\\\n",
    "        \"bn1.weight\",\"bn1.bias\",\"dense_enc2.weight\",\"dense_enc2.bias\",\"bn2.weight\",\"bn2.bias\",\\\n",
    "        \"dense_enc3.weight\",\"dense_enc3.bias\",\"dense_dec1.weight\",\"dense_dec1.bias\",\"bn4.weight\",\"bn4.bias\",\\\n",
    "        \"dense_dec2.weight\",\"dense_dec2.bias\",\"bn5.weight\",\"bn5.bias\",\"dense_dec3.weight\",\"dense_dec3.bias\"]\n",
    "#for k, p in zip(keys, net.parameters()):\n",
    "#    print(k, \"\\n\", p, \"\\n\")\n",
    "#for k, p in zip(keys, net.parameters()):\n",
    "#    print(k, \"requires_grad = \", p.requires_grad)\n",
    "\n",
    "#途中から保存したモデルを読み込んで学習再開する用\n",
    "LEARNING_RATE = 0.05\n",
    "#WEIGHT_DECAY = 0.0001\n",
    "#MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 0.\n",
    "MOMENTUM = 0.\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "device_cpu = torch.device('cpu')\n",
    "#net = Net().to(device)\n",
    "#ae = Autoencoder()\n",
    "net = HandGraspRecolletion().to(device)\n",
    "net.load_state_dict(torch.load(PATH + \"\\\\test11\\\\model_train\\\\model_epoch3300_trainloss_62853.38125\"))\n",
    "for p in net.parameters(): # freeze all model parameters\n",
    "    p.requires_grad = False\n",
    "for p in net.conv1.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.conv2.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.bn2d1.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.bn2d2.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.fcm.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.bnm.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.fcL1.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.fcL2.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.fcL3.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.bnL1.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.bnL2.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.fcPD1.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.fcPD2.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.fcPD3.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.bnPD1.parameters():\n",
    "    p.requires_grad = True\n",
    "for p in net.bnPD2.parameters():\n",
    "    p.requires_grad = True    \n",
    "criterion = MaskMSELoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "\n",
    "train_loss_value=[]      #trainingのlossを保持するlist\n",
    "test_loss_value=[]       #testのlossを保持するlist\n",
    "\n",
    "train_input_value = []\n",
    "train_output_value = []\n",
    "train_desc_value = []\n",
    "train_handloc_value = []\n",
    "test_input_value = []\n",
    "test_output_value = []\n",
    "test_desc_value = []\n",
    "test_handloc_value = []\n",
    "\n",
    "train_size = data_trainF.shape[0]\n",
    "test_size = data_testF.shape[0]\n",
    "\n",
    "max_train_loss_value = 0.\n",
    "max_test_loss_value = 0.\n",
    "min_test_loss_value = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#出力値保存\n",
    "def outcsv(n_epoch, train_input_value, train_output_value, train_desc_value, train_handloc_value,\\\n",
    "           test_input_value, test_output_value, test_desc_value, test_handloc_value):\n",
    "    with open(PATH + \"\\\\outputs\\\\network_outs_\" + str(n_epoch) + \".csv\", mode='w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([\"train_test\",\" \"])\n",
    "        #for i in range(len(train_input_value)):                      #epoch数 loop 1000\n",
    "        writer.writerow([\"epoch:\" + str(n_epoch),\" \"])\n",
    "        for j in range(len(train_input_value[0])):               #batch size数 loop 10\n",
    "            writer.writerow([\"batch:\" + str(j+1),\" \"])\n",
    "            input_x = []\n",
    "            input_y = []\n",
    "            input_z = []\n",
    "            output_x = []\n",
    "            output_y = []\n",
    "            output_z = []\n",
    "            descriptor = []\n",
    "            handlocation = []\n",
    "            for k in range(int(len(train_input_value[0][j])/3)): #data size / 2 loop (x, y分離) 21(42)\n",
    "                input_x.append(train_input_value[0][j][k*3+0].item())\n",
    "                input_y.append(train_input_value[0][j][k*3+1].item())\n",
    "                input_z.append(train_input_value[0][j][k*3+2].item())\n",
    "                output_x.append(train_output_value[0][j][k*3+0].item())\n",
    "                output_y.append(train_output_value[0][j][k*3+1].item())\n",
    "                output_z.append(train_output_value[0][j][k*3+2].item())\n",
    "            for l in range(len(train_desc_value[0][j])):\n",
    "                descriptor.append(train_desc_value[0][j][l].item())\n",
    "            for l in range(len(train_handloc_value[0][j])):\n",
    "                handlocation.append(train_handloc_value[0][j][l].item())\n",
    "            writer.writerow(input_x)\n",
    "            writer.writerow(input_y)\n",
    "            writer.writerow(input_z)\n",
    "            writer.writerow(output_x)\n",
    "            writer.writerow(output_y)\n",
    "            writer.writerow(output_z)\n",
    "            writer.writerow(descriptor)\n",
    "            writer.writerow(handlocation)\n",
    "        writer.writerow([\"test_test\",\" \"])\n",
    "        #for i in range(len(test_input_value)):                      #epoch数 loop 1000\n",
    "        writer.writerow([\"epoch:\" + str(n_epoch),\" \"])\n",
    "        for j in range(len(test_input_value[0])):               #batch size数 loop 10\n",
    "            writer.writerow([\"batch:\" + str(j+1),\" \"])\n",
    "            input_x = []\n",
    "            input_y = []\n",
    "            input_z = []\n",
    "            output_x = []\n",
    "            output_y = []\n",
    "            output_z = []\n",
    "            descriptor = []\n",
    "            handlocation = []\n",
    "            for k in range(int(len(test_input_value[0][j])/3)): #data size / 2 loop (x, y分離) 21(42)\n",
    "                input_x.append(test_input_value[0][j][k*3+0].item())\n",
    "                input_y.append(test_input_value[0][j][k*3+1].item())\n",
    "                input_z.append(test_input_value[0][j][k*3+2].item())\n",
    "                output_x.append(test_output_value[0][j][k*3+0].item())\n",
    "                output_y.append(test_output_value[0][j][k*3+1].item())\n",
    "                output_z.append(test_output_value[0][j][k*3+2].item())\n",
    "            for l in range(len(test_desc_value[0][j])):\n",
    "                descriptor.append(test_desc_value[0][j][l].item())\n",
    "            for l in range(len(test_handloc_value[0][j])):\n",
    "                handlocation.append(test_handloc_value[0][j][l].item())\n",
    "            writer.writerow(input_x)\n",
    "            writer.writerow(input_y)\n",
    "            writer.writerow(input_z)\n",
    "            writer.writerow(output_x)\n",
    "            writer.writerow(output_y)\n",
    "            writer.writerow(output_z)\n",
    "            writer.writerow(descriptor)\n",
    "            writer.writerow(handlocation)\n",
    "        print(\"fin save.\")\n",
    "    return\n",
    "\n",
    "def saveloss(train, test):\n",
    "    with open(PATH + \"\\\\outputs\\\\loss_values.csv\", mode='a', newline='') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1\n",
      "test_train\n",
      "train mean loss=62653.93854166667\n",
      "test_test\n",
      "test mean loss=87312.72265625\n",
      "fin save.\n",
      "epoch 2\n",
      "test_train\n",
      "train mean loss=62772.45559895833\n",
      "test_test\n",
      "test mean loss=87295.7109375\n",
      "fin save.\n",
      "epoch 3\n",
      "test_train\n",
      "train mean loss=63125.53919270833\n",
      "test_test\n",
      "test mean loss=87253.3359375\n",
      "fin save.\n",
      "epoch 4\n",
      "test_train\n",
      "train mean loss=62732.83059895833\n",
      "test_test\n",
      "test mean loss=87371.91796875\n",
      "fin save.\n",
      "epoch 5\n",
      "test_train\n",
      "train mean loss=62758.337239583336\n",
      "test_test\n",
      "test mean loss=87212.546875\n",
      "fin save.\n",
      "epoch 6\n",
      "test_train\n",
      "train mean loss=61654.69869791667\n",
      "test_test\n",
      "test mean loss=87179.65625\n",
      "fin save.\n",
      "epoch 7\n",
      "test_train\n",
      "train mean loss=61633.67330729167\n",
      "test_test\n",
      "test mean loss=87103.515625\n",
      "fin save.\n",
      "epoch 8\n",
      "test_train\n",
      "train mean loss=62524.50638020833\n",
      "test_test\n",
      "test mean loss=86210.296875\n",
      "fin save.\n",
      "epoch 9\n",
      "test_train\n",
      "train mean loss=62516.930338541664\n",
      "test_test\n",
      "test mean loss=86227.46484375\n",
      "fin save.\n",
      "epoch 10\n",
      "test_train\n",
      "train mean loss=62491.15703125\n",
      "test_test\n",
      "test mean loss=86334.2421875\n",
      "fin save.\n",
      "epoch 11\n",
      "test_train\n",
      "train mean loss=62660.7296875\n",
      "test_test\n",
      "test mean loss=86400.70703125\n",
      "fin save.\n",
      "epoch 12\n",
      "test_train\n",
      "train mean loss=61645.53111979167\n",
      "test_test\n",
      "test mean loss=86189.2421875\n",
      "fin save.\n",
      "epoch 13\n",
      "test_train\n",
      "train mean loss=62416.49361979167\n",
      "test_test\n",
      "test mean loss=86222.13671875\n",
      "fin save.\n",
      "epoch 14\n",
      "test_train\n",
      "train mean loss=61588.992578125\n",
      "test_test\n",
      "test mean loss=86318.84765625\n",
      "fin save.\n",
      "epoch 15\n",
      "test_train\n",
      "train mean loss=62073.51744791667\n",
      "test_test\n",
      "test mean loss=85868.46875\n",
      "fin save.\n",
      "epoch 16\n",
      "test_train\n",
      "train mean loss=62052.38776041667\n",
      "test_test\n",
      "test mean loss=86140.01953125\n",
      "fin save.\n",
      "epoch 17\n",
      "test_train\n",
      "train mean loss=61670.20546875\n",
      "test_test\n",
      "test mean loss=86309.3515625\n",
      "fin save.\n",
      "epoch 18\n",
      "test_train\n",
      "train mean loss=62454.92239583333\n",
      "test_test\n",
      "test mean loss=85953.4765625\n",
      "fin save.\n",
      "epoch 19\n",
      "test_train\n",
      "train mean loss=62448.675130208336\n",
      "test_test\n",
      "test mean loss=86516.16796875\n",
      "fin save.\n",
      "epoch 20\n",
      "test_train\n",
      "train mean loss=63014.2546875\n",
      "test_test\n",
      "test mean loss=86652.7265625\n",
      "fin save.\n",
      "epoch 21\n",
      "test_train\n",
      "train mean loss=62781.182942708336\n",
      "test_test\n",
      "test mean loss=86045.48828125\n",
      "fin save.\n",
      "epoch 22\n",
      "test_train\n",
      "train mean loss=62634.65026041667\n",
      "test_test\n",
      "test mean loss=86154.22265625\n",
      "fin save.\n",
      "epoch 23\n",
      "test_train\n",
      "train mean loss=62108.16419270833\n",
      "test_test\n",
      "test mean loss=86212.03515625\n",
      "fin save.\n",
      "epoch 24\n",
      "test_train\n",
      "train mean loss=62167.64791666667\n",
      "test_test\n",
      "test mean loss=86148.21484375\n",
      "fin save.\n",
      "epoch 25\n",
      "test_train\n",
      "train mean loss=62258.47890625\n",
      "test_test\n",
      "test mean loss=86032.7890625\n",
      "fin save.\n",
      "epoch 26\n",
      "test_train\n",
      "train mean loss=62503.81796875\n",
      "test_test\n",
      "test mean loss=86215.4375\n",
      "fin save.\n",
      "epoch 27\n",
      "test_train\n",
      "train mean loss=62296.9203125\n",
      "test_test\n",
      "test mean loss=86576.7265625\n",
      "fin save.\n",
      "epoch 28\n",
      "test_train\n",
      "train mean loss=62782.735546875\n",
      "test_test\n",
      "test mean loss=86589.33984375\n",
      "fin save.\n",
      "epoch 29\n",
      "test_train\n",
      "train mean loss=61792.16510416667\n",
      "test_test\n",
      "test mean loss=86549.81640625\n",
      "fin save.\n",
      "epoch 30\n",
      "test_train\n",
      "train mean loss=62491.88776041667\n",
      "test_test\n",
      "test mean loss=86507.6484375\n",
      "fin save.\n",
      "epoch 31\n",
      "test_train\n",
      "train mean loss=62148.3765625\n",
      "test_test\n",
      "test mean loss=86874.0234375\n",
      "fin save.\n",
      "epoch 32\n",
      "test_train\n",
      "train mean loss=62887.44609375\n",
      "test_test\n",
      "test mean loss=86797.8515625\n",
      "fin save.\n",
      "epoch 33\n",
      "test_train\n",
      "train mean loss=63102.6078125\n",
      "test_test\n",
      "test mean loss=86801.23046875\n",
      "fin save.\n",
      "epoch 34\n",
      "test_train\n",
      "train mean loss=62852.92473958333\n",
      "test_test\n",
      "test mean loss=86413.4140625\n",
      "fin save.\n",
      "epoch 35\n",
      "test_train\n",
      "train mean loss=61058.726822916666\n",
      "test_test\n",
      "test mean loss=86678.69921875\n",
      "fin save.\n",
      "epoch 36\n",
      "test_train\n",
      "train mean loss=62607.41354166667\n",
      "test_test\n",
      "test mean loss=86592.38671875\n",
      "fin save.\n",
      "epoch 37\n",
      "test_train\n",
      "train mean loss=62775.07421875\n",
      "test_test\n",
      "test mean loss=86564.53125\n",
      "fin save.\n",
      "epoch 38\n",
      "test_train\n",
      "train mean loss=62144.31822916667\n",
      "test_test\n",
      "test mean loss=86318.47265625\n",
      "fin save.\n",
      "epoch 39\n",
      "test_train\n",
      "train mean loss=62035.21302083333\n",
      "test_test\n",
      "test mean loss=86502.60546875\n",
      "fin save.\n",
      "epoch 40\n",
      "test_train\n",
      "train mean loss=63657.053125\n",
      "test_test\n",
      "test mean loss=86108.4375\n",
      "fin save.\n",
      "epoch 41\n",
      "test_train\n",
      "train mean loss=63135.108203125\n",
      "test_test\n",
      "test mean loss=86315.5625\n",
      "fin save.\n",
      "epoch 42\n",
      "test_train\n",
      "train mean loss=63003.83307291667\n",
      "test_test\n",
      "test mean loss=86706.7578125\n",
      "fin save.\n",
      "epoch 43\n",
      "test_train\n",
      "train mean loss=62730.42083333333\n",
      "test_test\n",
      "test mean loss=86308.15625\n",
      "fin save.\n",
      "epoch 44\n",
      "test_train\n",
      "train mean loss=62499.31979166667\n",
      "test_test\n",
      "test mean loss=86053.68359375\n",
      "fin save.\n",
      "epoch 45\n",
      "test_train\n",
      "train mean loss=61627.5359375\n",
      "test_test\n",
      "test mean loss=86592.3203125\n",
      "fin save.\n",
      "epoch 46\n",
      "test_train\n",
      "train mean loss=62892.105729166666\n",
      "test_test\n",
      "test mean loss=85606.38671875\n",
      "fin save.\n",
      "epoch 47\n",
      "test_train\n",
      "train mean loss=62849.72161458333\n",
      "test_test\n",
      "test mean loss=85883.109375\n",
      "fin save.\n",
      "epoch 48\n",
      "test_train\n",
      "train mean loss=62186.204296875\n",
      "test_test\n",
      "test mean loss=85790.8203125\n",
      "fin save.\n",
      "epoch 49\n",
      "test_train\n",
      "train mean loss=62513.777734375\n",
      "test_test\n",
      "test mean loss=85745.73828125\n",
      "fin save.\n",
      "epoch 50\n",
      "test_train\n",
      "train mean loss=61433.20546875\n",
      "test_test\n",
      "test mean loss=86023.98046875\n",
      "fin save.\n",
      "epoch 51\n",
      "test_train\n",
      "train mean loss=62861.20859375\n",
      "test_test\n",
      "test mean loss=86014.76171875\n",
      "fin save.\n",
      "epoch 52\n",
      "test_train\n",
      "train mean loss=61411.81067708333\n",
      "test_test\n",
      "test mean loss=86207.41796875\n",
      "fin save.\n",
      "epoch 53\n",
      "test_train\n",
      "train mean loss=61480.6640625\n",
      "test_test\n",
      "test mean loss=85992.23046875\n",
      "fin save.\n",
      "epoch 54\n",
      "test_train\n",
      "train mean loss=62440.81015625\n",
      "test_test\n",
      "test mean loss=85808.56640625\n",
      "fin save.\n",
      "epoch 55\n",
      "test_train\n",
      "train mean loss=62410.20911458333\n",
      "test_test\n",
      "test mean loss=86004.33203125\n",
      "fin save.\n",
      "epoch 56\n",
      "test_train\n",
      "train mean loss=61685.67083333333\n",
      "test_test\n",
      "test mean loss=86112.640625\n",
      "fin save.\n",
      "epoch 57\n",
      "test_train\n",
      "train mean loss=60793.18359375\n",
      "test_test\n",
      "test mean loss=86206.90234375\n",
      "fin save.\n",
      "epoch 58\n",
      "test_train\n",
      "train mean loss=61827.198958333334\n",
      "test_test\n",
      "test mean loss=86080.703125\n",
      "fin save.\n",
      "epoch 59\n",
      "test_train\n",
      "train mean loss=62131.11627604167\n",
      "test_test\n",
      "test mean loss=86351.125\n",
      "fin save.\n",
      "epoch 60\n",
      "test_train\n",
      "train mean loss=62774.76875\n",
      "test_test\n",
      "test mean loss=86116.359375\n",
      "fin save.\n",
      "epoch 61\n",
      "test_train\n",
      "train mean loss=62669.46796875\n",
      "test_test\n",
      "test mean loss=86368.73828125\n",
      "fin save.\n",
      "epoch 62\n",
      "test_train\n",
      "train mean loss=61924.499739583334\n",
      "test_test\n",
      "test mean loss=86127.4765625\n",
      "fin save.\n",
      "epoch 63\n",
      "test_train\n",
      "train mean loss=62090.7296875\n",
      "test_test\n",
      "test mean loss=86008.625\n",
      "fin save.\n",
      "epoch 64\n",
      "test_train\n",
      "train mean loss=62460.45130208333\n",
      "test_test\n",
      "test mean loss=85812.6328125\n",
      "fin save.\n",
      "epoch 65\n",
      "test_train\n",
      "train mean loss=62278.720052083336\n",
      "test_test\n",
      "test mean loss=85928.19921875\n",
      "fin save.\n",
      "epoch 66\n",
      "test_train\n",
      "train mean loss=61560.12604166667\n",
      "test_test\n",
      "test mean loss=85827.80859375\n",
      "fin save.\n",
      "epoch 67\n",
      "test_train\n",
      "train mean loss=63366.879166666666\n",
      "test_test\n",
      "test mean loss=85924.1484375\n",
      "fin save.\n",
      "epoch 68\n",
      "test_train\n",
      "train mean loss=61710.8484375\n",
      "test_test\n",
      "test mean loss=85970.09375\n",
      "fin save.\n",
      "epoch 69\n",
      "test_train\n",
      "train mean loss=62658.905989583334\n",
      "test_test\n",
      "test mean loss=86045.2578125\n",
      "fin save.\n",
      "epoch 70\n",
      "test_train\n",
      "train mean loss=62132.27877604167\n",
      "test_test\n",
      "test mean loss=86164.4140625\n",
      "fin save.\n",
      "epoch 71\n",
      "test_train\n",
      "train mean loss=62277.967447916664\n",
      "test_test\n",
      "test mean loss=86312.01953125\n",
      "fin save.\n",
      "epoch 72\n",
      "test_train\n",
      "train mean loss=62080.624348958336\n",
      "test_test\n",
      "test mean loss=86108.51953125\n",
      "fin save.\n",
      "epoch 73\n",
      "test_train\n",
      "train mean loss=62645.63385416667\n",
      "test_test\n",
      "test mean loss=86087.51953125\n",
      "fin save.\n",
      "epoch 74\n",
      "test_train\n",
      "train mean loss=62774.136067708336\n",
      "test_test\n",
      "test mean loss=86058.4296875\n",
      "fin save.\n",
      "epoch 75\n",
      "test_train\n",
      "train mean loss=62580.928385416664\n",
      "test_test\n",
      "test mean loss=86035.82421875\n",
      "fin save.\n",
      "epoch 76\n",
      "test_train\n",
      "train mean loss=62014.25442708333\n",
      "test_test\n",
      "test mean loss=86223.8828125\n",
      "fin save.\n",
      "epoch 77\n",
      "test_train\n",
      "train mean loss=62696.846354166664\n",
      "test_test\n",
      "test mean loss=86211.72265625\n",
      "fin save.\n",
      "epoch 78\n",
      "test_train\n",
      "train mean loss=61918.41848958333\n",
      "test_test\n",
      "test mean loss=86160.54296875\n",
      "fin save.\n",
      "epoch 79\n",
      "test_train\n",
      "train mean loss=62339.194661458336\n",
      "test_test\n",
      "test mean loss=86069.5234375\n",
      "fin save.\n",
      "epoch 80\n",
      "test_train\n",
      "train mean loss=63377.73828125\n",
      "test_test\n",
      "test mean loss=86040.69140625\n",
      "fin save.\n",
      "epoch 81\n",
      "test_train\n",
      "train mean loss=62888.672135416666\n",
      "test_test\n",
      "test mean loss=86136.5859375\n",
      "fin save.\n",
      "epoch 82\n",
      "test_train\n",
      "train mean loss=62124.4296875\n",
      "test_test\n",
      "test mean loss=86013.30078125\n",
      "fin save.\n",
      "epoch 83\n",
      "test_train\n",
      "train mean loss=62195.150390625\n",
      "test_test\n",
      "test mean loss=85881.97265625\n",
      "fin save.\n",
      "epoch 84\n",
      "test_train\n",
      "train mean loss=62907.18697916667\n",
      "test_test\n",
      "test mean loss=85975.484375\n",
      "fin save.\n",
      "epoch 85\n",
      "test_train\n",
      "train mean loss=62150.99375\n",
      "test_test\n",
      "test mean loss=85920.4453125\n",
      "fin save.\n",
      "epoch 86\n",
      "test_train\n",
      "train mean loss=62422.91484375\n",
      "test_test\n",
      "test mean loss=85584.9140625\n",
      "fin save.\n",
      "epoch 87\n",
      "test_train\n",
      "train mean loss=61323.9421875\n",
      "test_test\n",
      "test mean loss=85668.375\n",
      "fin save.\n",
      "epoch 88\n",
      "test_train\n",
      "train mean loss=62366.160546875\n",
      "test_test\n",
      "test mean loss=85777.41796875\n",
      "fin save.\n",
      "epoch 89\n",
      "test_train\n",
      "train mean loss=62812.57630208333\n",
      "test_test\n",
      "test mean loss=85757.19140625\n",
      "fin save.\n",
      "epoch 90\n",
      "test_train\n",
      "train mean loss=62022.18736979167\n",
      "test_test\n",
      "test mean loss=86018.4609375\n",
      "fin save.\n",
      "epoch 91\n",
      "test_train\n",
      "train mean loss=62872.03203125\n",
      "test_test\n",
      "test mean loss=85926.109375\n",
      "fin save.\n",
      "epoch 92\n",
      "test_train\n",
      "train mean loss=61694.84609375\n",
      "test_test\n",
      "test mean loss=86272.7421875\n",
      "fin save.\n",
      "epoch 93\n",
      "test_train\n",
      "train mean loss=61492.29973958333\n",
      "test_test\n",
      "test mean loss=86104.3046875\n",
      "fin save.\n",
      "epoch 94\n",
      "test_train\n",
      "train mean loss=62017.61614583333\n",
      "test_test\n",
      "test mean loss=86093.02734375\n",
      "fin save.\n",
      "epoch 95\n",
      "test_train\n",
      "train mean loss=62199.89453125\n",
      "test_test\n",
      "test mean loss=86225.4921875\n",
      "fin save.\n",
      "epoch 96\n",
      "test_train\n",
      "train mean loss=62094.868880208334\n",
      "test_test\n",
      "test mean loss=86351.0390625\n",
      "fin save.\n",
      "epoch 97\n",
      "test_train\n",
      "train mean loss=61782.88229166667\n",
      "test_test\n",
      "test mean loss=86248.328125\n",
      "fin save.\n",
      "epoch 98\n",
      "test_train\n",
      "train mean loss=63170.552083333336\n",
      "test_test\n",
      "test mean loss=85976.81640625\n",
      "fin save.\n",
      "epoch 99\n",
      "test_train\n",
      "train mean loss=62570.98619791667\n",
      "test_test\n",
      "test mean loss=86116.04296875\n",
      "fin save.\n",
      "epoch 100\n",
      "test_train\n",
      "train mean loss=61788.502213541666\n",
      "test_test\n",
      "test mean loss=86083.21875\n",
      "fin save.\n",
      "epoch 101\n",
      "test_train\n",
      "train mean loss=62263.0390625\n",
      "test_test\n",
      "test mean loss=85978.19140625\n",
      "fin save.\n",
      "epoch 102\n",
      "test_train\n",
      "train mean loss=62670.5296875\n",
      "test_test\n",
      "test mean loss=86026.390625\n",
      "fin save.\n",
      "epoch 103\n",
      "test_train\n",
      "train mean loss=62160.99127604167\n",
      "test_test\n",
      "test mean loss=86041.03515625\n",
      "fin save.\n",
      "epoch 104\n",
      "test_train\n",
      "train mean loss=61941.841145833336\n",
      "test_test\n",
      "test mean loss=85726.609375\n",
      "fin save.\n",
      "epoch 105\n",
      "test_train\n",
      "train mean loss=62014.98203125\n",
      "test_test\n",
      "test mean loss=85939.1015625\n",
      "fin save.\n",
      "epoch 106\n",
      "test_train\n",
      "train mean loss=62435.091015625\n",
      "test_test\n",
      "test mean loss=86039.51953125\n",
      "fin save.\n",
      "epoch 107\n",
      "test_train\n",
      "train mean loss=62357.797526041664\n",
      "test_test\n",
      "test mean loss=86142.04296875\n",
      "fin save.\n",
      "epoch 108\n",
      "test_train\n",
      "train mean loss=62699.25677083333\n",
      "test_test\n",
      "test mean loss=86246.67578125\n",
      "fin save.\n",
      "epoch 109\n",
      "test_train\n",
      "train mean loss=62485.17473958333\n",
      "test_test\n",
      "test mean loss=86120.36328125\n",
      "fin save.\n",
      "epoch 110\n",
      "test_train\n",
      "train mean loss=63434.817708333336\n",
      "test_test\n",
      "test mean loss=86054.8203125\n",
      "fin save.\n",
      "epoch 111\n",
      "test_train\n",
      "train mean loss=62983.53502604167\n",
      "test_test\n",
      "test mean loss=86065.90625\n",
      "fin save.\n",
      "epoch 112\n",
      "test_train\n",
      "train mean loss=62385.615885416664\n",
      "test_test\n",
      "test mean loss=86022.79296875\n",
      "fin save.\n",
      "epoch 113\n",
      "test_train\n",
      "train mean loss=62223.97161458333\n",
      "test_test\n",
      "test mean loss=86016.33984375\n",
      "fin save.\n",
      "epoch 114\n",
      "test_train\n",
      "train mean loss=62565.957291666666\n",
      "test_test\n",
      "test mean loss=86145.84375\n",
      "fin save.\n",
      "epoch 115\n",
      "test_train\n",
      "train mean loss=62112.467447916664\n",
      "test_test\n",
      "test mean loss=85730.09375\n",
      "fin save.\n",
      "epoch 116\n",
      "test_train\n",
      "train mean loss=61314.313802083336\n",
      "test_test\n",
      "test mean loss=85963.78515625\n",
      "fin save.\n",
      "epoch 117\n",
      "test_train\n",
      "train mean loss=61496.435546875\n",
      "test_test\n",
      "test mean loss=86193.03125\n",
      "fin save.\n",
      "epoch 118\n",
      "test_train\n",
      "train mean loss=61803.60338541667\n",
      "test_test\n",
      "test mean loss=86135.33984375\n",
      "fin save.\n",
      "epoch 119\n",
      "test_train\n",
      "train mean loss=62335.215625\n",
      "test_test\n",
      "test mean loss=85952.1015625\n",
      "fin save.\n",
      "epoch 120\n",
      "test_train\n",
      "train mean loss=61823.0515625\n",
      "test_test\n",
      "test mean loss=86073.15625\n",
      "fin save.\n",
      "epoch 121\n",
      "test_train\n",
      "train mean loss=62088.947916666664\n",
      "test_test\n",
      "test mean loss=86142.9921875\n",
      "fin save.\n",
      "epoch 122\n",
      "test_train\n",
      "train mean loss=61699.278645833336\n",
      "test_test\n",
      "test mean loss=86183.91796875\n",
      "fin save.\n",
      "epoch 123\n",
      "test_train\n",
      "train mean loss=62202.98046875\n",
      "test_test\n",
      "test mean loss=86409.109375\n",
      "fin save.\n",
      "epoch 124\n",
      "test_train\n",
      "train mean loss=61891.90078125\n",
      "test_test\n",
      "test mean loss=86232.1640625\n",
      "fin save.\n",
      "epoch 125\n",
      "test_train\n",
      "train mean loss=61669.74322916667\n",
      "test_test\n",
      "test mean loss=85984.125\n",
      "fin save.\n",
      "epoch 126\n",
      "test_train\n",
      "train mean loss=61463.183333333334\n",
      "test_test\n",
      "test mean loss=85883.40234375\n",
      "fin save.\n",
      "epoch 127\n",
      "test_train\n",
      "train mean loss=61716.397265625\n",
      "test_test\n",
      "test mean loss=86078.5390625\n",
      "fin save.\n",
      "epoch 128\n",
      "test_train\n",
      "train mean loss=62569.85260416667\n",
      "test_test\n",
      "test mean loss=86428.7890625\n",
      "fin save.\n",
      "epoch 129\n",
      "test_train\n",
      "train mean loss=61834.054427083334\n",
      "test_test\n",
      "test mean loss=86552.75\n",
      "fin save.\n",
      "epoch 130\n",
      "test_train\n",
      "train mean loss=61836.220052083336\n",
      "test_test\n",
      "test mean loss=86072.54296875\n",
      "fin save.\n",
      "epoch 131\n",
      "test_train\n",
      "train mean loss=62529.52682291667\n",
      "test_test\n",
      "test mean loss=86182.6640625\n",
      "fin save.\n",
      "epoch 132\n",
      "test_train\n",
      "train mean loss=62354.11223958333\n",
      "test_test\n",
      "test mean loss=86322.7578125\n",
      "fin save.\n",
      "epoch 133\n",
      "test_train\n",
      "train mean loss=62711.546614583334\n",
      "test_test\n",
      "test mean loss=86424.92578125\n",
      "fin save.\n",
      "epoch 134\n",
      "test_train\n",
      "train mean loss=63432.24947916667\n",
      "test_test\n",
      "test mean loss=86136.5\n",
      "fin save.\n",
      "epoch 135\n",
      "test_train\n",
      "train mean loss=62301.395703125\n",
      "test_test\n",
      "test mean loss=86190.99609375\n",
      "fin save.\n",
      "epoch 136\n",
      "test_train\n",
      "train mean loss=62092.63880208333\n",
      "test_test\n",
      "test mean loss=85990.703125\n",
      "fin save.\n",
      "epoch 137\n",
      "test_train\n",
      "train mean loss=61336.99401041667\n",
      "test_test\n",
      "test mean loss=86067.81640625\n",
      "fin save.\n",
      "epoch 138\n",
      "test_train\n",
      "train mean loss=62077.48255208333\n",
      "test_test\n",
      "test mean loss=86133.38671875\n",
      "fin save.\n",
      "epoch 139\n",
      "test_train\n",
      "train mean loss=61916.206770833334\n",
      "test_test\n",
      "test mean loss=86200.97265625\n",
      "fin save.\n",
      "epoch 140\n",
      "test_train\n",
      "train mean loss=62176.800130208336\n",
      "test_test\n",
      "test mean loss=86300.5859375\n",
      "fin save.\n",
      "epoch 141\n",
      "test_train\n",
      "train mean loss=62644.861979166664\n",
      "test_test\n",
      "test mean loss=86232.75390625\n",
      "fin save.\n",
      "epoch 142\n",
      "test_train\n",
      "train mean loss=61829.94479166667\n",
      "test_test\n",
      "test mean loss=86333.921875\n",
      "fin save.\n",
      "epoch 143\n",
      "test_train\n",
      "train mean loss=63136.957291666666\n",
      "test_test\n",
      "test mean loss=86463.41796875\n",
      "fin save.\n",
      "epoch 144\n",
      "test_train\n",
      "train mean loss=62449.93984375\n",
      "test_test\n",
      "test mean loss=86479.39453125\n",
      "fin save.\n",
      "epoch 145\n",
      "test_train\n",
      "train mean loss=63167.563802083336\n",
      "test_test\n",
      "test mean loss=86384.6953125\n",
      "fin save.\n",
      "epoch 146\n",
      "test_train\n",
      "train mean loss=62016.24817708333\n",
      "test_test\n",
      "test mean loss=86434.36328125\n",
      "fin save.\n",
      "epoch 147\n",
      "test_train\n",
      "train mean loss=62349.0359375\n",
      "test_test\n",
      "test mean loss=86835.83203125\n",
      "fin save.\n",
      "epoch 148\n",
      "test_train\n",
      "train mean loss=61403.31432291667\n",
      "test_test\n",
      "test mean loss=86823.09765625\n",
      "fin save.\n",
      "epoch 149\n",
      "test_train\n",
      "train mean loss=62400.161848958334\n",
      "test_test\n",
      "test mean loss=86869.02734375\n",
      "fin save.\n",
      "epoch 150\n",
      "test_train\n",
      "train mean loss=62513.68177083333\n",
      "test_test\n",
      "test mean loss=86776.578125\n",
      "fin save.\n",
      "epoch 151\n",
      "test_train\n",
      "train mean loss=62730.374739583334\n",
      "test_test\n",
      "test mean loss=86883.41015625\n",
      "fin save.\n",
      "epoch 152\n",
      "test_train\n",
      "train mean loss=61478.454296875\n",
      "test_test\n",
      "test mean loss=86891.70703125\n",
      "fin save.\n",
      "epoch 153\n",
      "test_train\n",
      "train mean loss=62582.313802083336\n",
      "test_test\n",
      "test mean loss=86887.60546875\n",
      "fin save.\n",
      "epoch 154\n",
      "test_train\n",
      "train mean loss=62595.755859375\n",
      "test_test\n",
      "test mean loss=86774.60546875\n",
      "fin save.\n",
      "epoch 155\n",
      "test_train\n",
      "train mean loss=62123.994791666664\n",
      "test_test\n",
      "test mean loss=86806.40625\n",
      "fin save.\n",
      "epoch 156\n",
      "test_train\n",
      "train mean loss=61831.25286458333\n",
      "test_test\n",
      "test mean loss=86889.3828125\n",
      "fin save.\n",
      "epoch 157\n",
      "test_train\n",
      "train mean loss=62212.137890625\n",
      "test_test\n",
      "test mean loss=86905.953125\n",
      "fin save.\n",
      "epoch 158\n",
      "test_train\n",
      "train mean loss=62556.452864583334\n",
      "test_test\n",
      "test mean loss=86768.06640625\n",
      "fin save.\n",
      "epoch 159\n",
      "test_train\n",
      "train mean loss=62587.79088541667\n",
      "test_test\n",
      "test mean loss=86889.1953125\n",
      "fin save.\n",
      "epoch 160\n",
      "test_train\n",
      "train mean loss=63773.890364583334\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=86769.99609375\n",
      "fin save.\n",
      "epoch 161\n",
      "test_train\n",
      "train mean loss=63584.09622395833\n",
      "test_test\n",
      "test mean loss=86992.3203125\n",
      "fin save.\n",
      "epoch 162\n",
      "test_train\n",
      "train mean loss=62026.828515625\n",
      "test_test\n",
      "test mean loss=87148.82421875\n",
      "fin save.\n",
      "epoch 163\n",
      "test_train\n",
      "train mean loss=63425.391796875\n",
      "test_test\n",
      "test mean loss=87139.421875\n",
      "fin save.\n",
      "epoch 164\n",
      "test_train\n",
      "train mean loss=62089.873828125\n",
      "test_test\n",
      "test mean loss=87102.44140625\n",
      "fin save.\n",
      "epoch 165\n",
      "test_train\n",
      "train mean loss=63062.55872395833\n",
      "test_test\n",
      "test mean loss=87065.62109375\n",
      "fin save.\n",
      "epoch 166\n",
      "test_train\n",
      "train mean loss=62196.74401041667\n",
      "test_test\n",
      "test mean loss=86658.1640625\n",
      "fin save.\n",
      "epoch 167\n",
      "test_train\n",
      "train mean loss=62660.96171875\n",
      "test_test\n",
      "test mean loss=86772.25390625\n",
      "fin save.\n",
      "epoch 168\n",
      "test_train\n",
      "train mean loss=62493.18932291667\n",
      "test_test\n",
      "test mean loss=86885.4921875\n",
      "fin save.\n",
      "epoch 169\n",
      "test_train\n",
      "train mean loss=62113.34427083333\n",
      "test_test\n",
      "test mean loss=86545.75\n",
      "fin save.\n",
      "epoch 170\n",
      "test_train\n",
      "train mean loss=61710.86223958333\n",
      "test_test\n",
      "test mean loss=86598.64453125\n",
      "fin save.\n",
      "epoch 171\n",
      "test_train\n",
      "train mean loss=62815.654947916664\n",
      "test_test\n",
      "test mean loss=86558.5703125\n",
      "fin save.\n",
      "epoch 172\n",
      "test_train\n",
      "train mean loss=62277.4515625\n",
      "test_test\n",
      "test mean loss=86620.0\n",
      "fin save.\n",
      "epoch 173\n",
      "test_train\n",
      "train mean loss=62808.284375\n",
      "test_test\n",
      "test mean loss=86801.49609375\n",
      "fin save.\n",
      "epoch 174\n",
      "test_train\n",
      "train mean loss=62563.50377604167\n",
      "test_test\n",
      "test mean loss=86732.18359375\n",
      "fin save.\n",
      "epoch 175\n",
      "test_train\n",
      "train mean loss=62885.58111979167\n",
      "test_test\n",
      "test mean loss=86794.3203125\n",
      "fin save.\n",
      "epoch 176\n",
      "test_train\n",
      "train mean loss=61539.60651041667\n",
      "test_test\n",
      "test mean loss=86618.50390625\n",
      "fin save.\n",
      "epoch 177\n",
      "test_train\n",
      "train mean loss=62504.27161458333\n",
      "test_test\n",
      "test mean loss=86556.28515625\n",
      "fin save.\n",
      "epoch 178\n",
      "test_train\n",
      "train mean loss=62657.06692708333\n",
      "test_test\n",
      "test mean loss=86606.96484375\n",
      "fin save.\n",
      "epoch 179\n",
      "test_train\n",
      "train mean loss=62347.434895833336\n",
      "test_test\n",
      "test mean loss=86698.8046875\n",
      "fin save.\n",
      "epoch 180\n",
      "test_train\n",
      "train mean loss=62547.47734375\n",
      "test_test\n",
      "test mean loss=86326.83984375\n",
      "fin save.\n",
      "epoch 181\n",
      "test_train\n",
      "train mean loss=62210.639453125\n",
      "test_test\n",
      "test mean loss=86236.43359375\n",
      "fin save.\n",
      "epoch 182\n",
      "test_train\n",
      "train mean loss=62200.44739583333\n",
      "test_test\n",
      "test mean loss=86680.7265625\n",
      "fin save.\n",
      "epoch 183\n",
      "test_train\n",
      "train mean loss=63212.910807291664\n",
      "test_test\n",
      "test mean loss=86519.23828125\n",
      "fin save.\n",
      "epoch 184\n",
      "test_train\n",
      "train mean loss=63375.93802083333\n",
      "test_test\n",
      "test mean loss=86646.203125\n",
      "fin save.\n",
      "epoch 185\n",
      "test_train\n",
      "train mean loss=62492.54583333333\n",
      "test_test\n",
      "test mean loss=86236.03515625\n",
      "fin save.\n",
      "epoch 186\n",
      "test_train\n",
      "train mean loss=62092.5265625\n",
      "test_test\n",
      "test mean loss=86033.2734375\n",
      "fin save.\n",
      "epoch 187\n",
      "test_train\n",
      "train mean loss=62198.251302083336\n",
      "test_test\n",
      "test mean loss=86261.7421875\n",
      "fin save.\n",
      "epoch 188\n",
      "test_train\n",
      "train mean loss=62736.247395833336\n",
      "test_test\n",
      "test mean loss=86320.92578125\n",
      "fin save.\n",
      "epoch 189\n",
      "test_train\n",
      "train mean loss=62220.55859375\n",
      "test_test\n",
      "test mean loss=86359.41796875\n",
      "fin save.\n",
      "epoch 190\n",
      "test_train\n",
      "train mean loss=62076.87447916667\n",
      "test_test\n",
      "test mean loss=86470.8984375\n",
      "fin save.\n",
      "epoch 191\n",
      "test_train\n",
      "train mean loss=62615.784895833334\n",
      "test_test\n",
      "test mean loss=86098.63671875\n",
      "fin save.\n",
      "epoch 192\n",
      "test_train\n",
      "train mean loss=62747.53203125\n",
      "test_test\n",
      "test mean loss=86082.20703125\n",
      "fin save.\n",
      "epoch 193\n",
      "test_train\n",
      "train mean loss=61819.92760416667\n",
      "test_test\n",
      "test mean loss=86266.59765625\n",
      "fin save.\n",
      "epoch 194\n",
      "test_train\n",
      "train mean loss=62279.47421875\n",
      "test_test\n",
      "test mean loss=86339.109375\n",
      "fin save.\n",
      "epoch 195\n",
      "test_train\n",
      "train mean loss=62638.06979166667\n",
      "test_test\n",
      "test mean loss=86243.12890625\n",
      "fin save.\n",
      "epoch 196\n",
      "test_train\n",
      "train mean loss=62630.25234375\n",
      "test_test\n",
      "test mean loss=86331.9296875\n",
      "fin save.\n",
      "epoch 197\n",
      "test_train\n",
      "train mean loss=62377.09583333333\n",
      "test_test\n",
      "test mean loss=86686.77734375\n",
      "fin save.\n",
      "epoch 198\n",
      "test_train\n",
      "train mean loss=62854.20703125\n",
      "test_test\n",
      "test mean loss=86752.21875\n",
      "fin save.\n",
      "epoch 199\n",
      "test_train\n",
      "train mean loss=62054.79505208333\n",
      "test_test\n",
      "test mean loss=86717.04296875\n",
      "fin save.\n",
      "epoch 200\n",
      "test_train\n",
      "train mean loss=62789.108072916664\n",
      "test_test\n",
      "test mean loss=86792.93359375\n",
      "fin save.\n",
      "epoch 201\n",
      "test_train\n",
      "train mean loss=61741.31171875\n",
      "test_test\n",
      "test mean loss=86649.12890625\n",
      "fin save.\n",
      "epoch 202\n",
      "test_train\n",
      "train mean loss=61988.13203125\n",
      "test_test\n",
      "test mean loss=86579.67578125\n",
      "fin save.\n",
      "epoch 203\n",
      "test_train\n",
      "train mean loss=63067.5828125\n",
      "test_test\n",
      "test mean loss=86281.359375\n",
      "fin save.\n",
      "epoch 204\n",
      "test_train\n",
      "train mean loss=62521.537760416664\n",
      "test_test\n",
      "test mean loss=86566.19140625\n",
      "fin save.\n",
      "epoch 205\n",
      "test_train\n",
      "train mean loss=63222.71666666667\n",
      "test_test\n",
      "test mean loss=86543.234375\n",
      "fin save.\n",
      "epoch 206\n",
      "test_train\n",
      "train mean loss=62075.79348958333\n",
      "test_test\n",
      "test mean loss=86215.98046875\n",
      "fin save.\n",
      "epoch 207\n",
      "test_train\n",
      "train mean loss=62172.746354166666\n",
      "test_test\n",
      "test mean loss=86534.85546875\n",
      "fin save.\n",
      "epoch 208\n",
      "test_train\n",
      "train mean loss=63845.06848958333\n",
      "test_test\n",
      "test mean loss=86594.83203125\n",
      "fin save.\n",
      "epoch 209\n",
      "test_train\n",
      "train mean loss=62810.07317708333\n",
      "test_test\n",
      "test mean loss=86661.87890625\n",
      "fin save.\n",
      "epoch 210\n",
      "test_train\n",
      "train mean loss=63095.483072916664\n",
      "test_test\n",
      "test mean loss=86761.1953125\n",
      "fin save.\n",
      "epoch 211\n",
      "test_train\n",
      "train mean loss=62856.82526041667\n",
      "test_test\n",
      "test mean loss=86710.95703125\n",
      "fin save.\n",
      "epoch 212\n",
      "test_train\n",
      "train mean loss=63253.07734375\n",
      "test_test\n",
      "test mean loss=86694.0078125\n",
      "fin save.\n",
      "epoch 213\n",
      "test_train\n",
      "train mean loss=62465.58216145833\n",
      "test_test\n",
      "test mean loss=86736.4609375\n",
      "fin save.\n",
      "epoch 214\n",
      "test_train\n",
      "train mean loss=61091.517317708334\n",
      "test_test\n",
      "test mean loss=86732.2890625\n",
      "fin save.\n",
      "epoch 215\n",
      "test_train\n",
      "train mean loss=63486.92291666667\n",
      "test_test\n",
      "test mean loss=86832.51953125\n",
      "fin save.\n",
      "epoch 216\n",
      "test_train\n",
      "train mean loss=62507.823958333334\n",
      "test_test\n",
      "test mean loss=86885.1796875\n",
      "fin save.\n",
      "epoch 217\n",
      "test_train\n",
      "train mean loss=61859.19817708333\n",
      "test_test\n",
      "test mean loss=86857.45703125\n",
      "fin save.\n",
      "epoch 218\n",
      "test_train\n",
      "train mean loss=62200.60494791667\n",
      "test_test\n",
      "test mean loss=86947.9296875\n",
      "fin save.\n",
      "epoch 219\n",
      "test_train\n",
      "train mean loss=62705.63125\n",
      "test_test\n",
      "test mean loss=86798.07421875\n",
      "fin save.\n",
      "epoch 220\n",
      "test_train\n",
      "train mean loss=63305.718098958336\n",
      "test_test\n",
      "test mean loss=86618.23828125\n",
      "fin save.\n",
      "epoch 221\n",
      "test_train\n",
      "train mean loss=62884.74114583333\n",
      "test_test\n",
      "test mean loss=86153.9140625\n",
      "fin save.\n",
      "epoch 222\n",
      "test_train\n",
      "train mean loss=62018.371875\n",
      "test_test\n",
      "test mean loss=86286.89453125\n",
      "fin save.\n",
      "epoch 223\n",
      "test_train\n",
      "train mean loss=62757.526953125\n",
      "test_test\n",
      "test mean loss=86431.41015625\n",
      "fin save.\n",
      "epoch 224\n",
      "test_train\n",
      "train mean loss=62247.12552083333\n",
      "test_test\n",
      "test mean loss=86469.69921875\n",
      "fin save.\n",
      "epoch 225\n",
      "test_train\n",
      "train mean loss=62134.99296875\n",
      "test_test\n",
      "test mean loss=86387.12109375\n",
      "fin save.\n",
      "epoch 226\n",
      "test_train\n",
      "train mean loss=61912.63203125\n",
      "test_test\n",
      "test mean loss=86566.203125\n",
      "fin save.\n",
      "epoch 227\n",
      "test_train\n",
      "train mean loss=61920.52890625\n",
      "test_test\n",
      "test mean loss=86167.58203125\n",
      "fin save.\n",
      "epoch 228\n",
      "test_train\n",
      "train mean loss=62310.49140625\n",
      "test_test\n",
      "test mean loss=86229.3125\n",
      "fin save.\n",
      "epoch 229\n",
      "test_train\n",
      "train mean loss=62193.58828125\n",
      "test_test\n",
      "test mean loss=86608.61328125\n",
      "fin save.\n",
      "epoch 230\n",
      "test_train\n",
      "train mean loss=62291.207291666666\n",
      "test_test\n",
      "test mean loss=86326.84765625\n",
      "fin save.\n",
      "epoch 231\n",
      "test_train\n",
      "train mean loss=62897.79296875\n",
      "test_test\n",
      "test mean loss=86514.37109375\n",
      "fin save.\n",
      "epoch 232\n",
      "test_train\n",
      "train mean loss=63405.507552083334\n",
      "test_test\n",
      "test mean loss=86455.0078125\n",
      "fin save.\n",
      "epoch 233\n",
      "test_train\n",
      "train mean loss=62031.014322916664\n",
      "test_test\n",
      "test mean loss=86488.296875\n",
      "fin save.\n",
      "epoch 234\n",
      "test_train\n",
      "train mean loss=62087.64348958333\n",
      "test_test\n",
      "test mean loss=86303.24609375\n",
      "fin save.\n",
      "epoch 235\n",
      "test_train\n",
      "train mean loss=63149.01666666667\n",
      "test_test\n",
      "test mean loss=86327.5\n",
      "fin save.\n",
      "epoch 236\n",
      "test_train\n",
      "train mean loss=63188.571614583336\n",
      "test_test\n",
      "test mean loss=86378.203125\n",
      "fin save.\n",
      "epoch 237\n",
      "test_train\n",
      "train mean loss=62033.5265625\n",
      "test_test\n",
      "test mean loss=86632.58984375\n",
      "fin save.\n",
      "epoch 238\n",
      "test_train\n",
      "train mean loss=62806.25286458333\n",
      "test_test\n",
      "test mean loss=86241.05859375\n",
      "fin save.\n",
      "epoch 239\n",
      "test_train\n",
      "train mean loss=62577.272135416664\n",
      "test_test\n",
      "test mean loss=86827.6640625\n",
      "fin save.\n",
      "epoch 240\n",
      "test_train\n",
      "train mean loss=62368.978515625\n",
      "test_test\n",
      "test mean loss=86614.62109375\n",
      "fin save.\n",
      "epoch 241\n",
      "test_train\n",
      "train mean loss=62502.95859375\n",
      "test_test\n",
      "test mean loss=86485.47265625\n",
      "fin save.\n",
      "epoch 242\n",
      "test_train\n",
      "train mean loss=62407.20208333333\n",
      "test_test\n",
      "test mean loss=86517.37109375\n",
      "fin save.\n",
      "epoch 243\n",
      "test_train\n",
      "train mean loss=63209.739973958334\n",
      "test_test\n",
      "test mean loss=86376.0\n",
      "fin save.\n",
      "epoch 244\n",
      "test_train\n",
      "train mean loss=63607.58203125\n",
      "test_test\n",
      "test mean loss=86519.5\n",
      "fin save.\n",
      "epoch 245\n",
      "test_train\n",
      "train mean loss=61584.28606770833\n",
      "test_test\n",
      "test mean loss=86566.1015625\n",
      "fin save.\n",
      "epoch 246\n",
      "test_train\n",
      "train mean loss=62078.118880208334\n",
      "test_test\n",
      "test mean loss=86457.55078125\n",
      "fin save.\n",
      "epoch 247\n",
      "test_train\n",
      "train mean loss=62039.12890625\n",
      "test_test\n",
      "test mean loss=86670.96875\n",
      "fin save.\n",
      "epoch 248\n",
      "test_train\n",
      "train mean loss=62724.99791666667\n",
      "test_test\n",
      "test mean loss=86608.01953125\n",
      "fin save.\n",
      "epoch 249\n",
      "test_train\n",
      "train mean loss=63088.655078125\n",
      "test_test\n",
      "test mean loss=86689.9375\n",
      "fin save.\n",
      "epoch 250\n",
      "test_train\n",
      "train mean loss=62639.656640625\n",
      "test_test\n",
      "test mean loss=86693.05078125\n",
      "fin save.\n",
      "epoch 251\n",
      "test_train\n",
      "train mean loss=62789.731770833336\n",
      "test_test\n",
      "test mean loss=86218.96484375\n",
      "fin save.\n",
      "epoch 252\n",
      "test_train\n",
      "train mean loss=62560.85625\n",
      "test_test\n",
      "test mean loss=86347.05859375\n",
      "fin save.\n",
      "epoch 253\n",
      "test_train\n",
      "train mean loss=62424.36875\n",
      "test_test\n",
      "test mean loss=86191.19921875\n",
      "fin save.\n",
      "epoch 254\n",
      "test_train\n",
      "train mean loss=63309.912760416664\n",
      "test_test\n",
      "test mean loss=86165.44921875\n",
      "fin save.\n",
      "epoch 255\n",
      "test_train\n",
      "train mean loss=61865.84973958333\n",
      "test_test\n",
      "test mean loss=86175.6796875\n",
      "fin save.\n",
      "epoch 256\n",
      "test_train\n",
      "train mean loss=62153.249739583334\n",
      "test_test\n",
      "test mean loss=86279.4375\n",
      "fin save.\n",
      "epoch 257\n",
      "test_train\n",
      "train mean loss=62230.26510416667\n",
      "test_test\n",
      "test mean loss=86327.94140625\n",
      "fin save.\n",
      "epoch 258\n",
      "test_train\n",
      "train mean loss=62923.480729166666\n",
      "test_test\n",
      "test mean loss=86080.6171875\n",
      "fin save.\n",
      "epoch 259\n",
      "test_train\n",
      "train mean loss=62237.06588541667\n",
      "test_test\n",
      "test mean loss=86349.1875\n",
      "fin save.\n",
      "epoch 260\n",
      "test_train\n",
      "train mean loss=62493.654947916664\n",
      "test_test\n",
      "test mean loss=86317.453125\n",
      "fin save.\n",
      "epoch 261\n",
      "test_train\n",
      "train mean loss=63583.577864583334\n",
      "test_test\n",
      "test mean loss=86612.09765625\n",
      "fin save.\n",
      "epoch 262\n",
      "test_train\n",
      "train mean loss=62466.037890625\n",
      "test_test\n",
      "test mean loss=86497.9453125\n",
      "fin save.\n",
      "epoch 263\n",
      "test_train\n",
      "train mean loss=62023.47513020833\n",
      "test_test\n",
      "test mean loss=86518.49609375\n",
      "fin save.\n",
      "epoch 264\n",
      "test_train\n",
      "train mean loss=62153.93697916667\n",
      "test_test\n",
      "test mean loss=86810.16796875\n",
      "fin save.\n",
      "epoch 265\n",
      "test_train\n",
      "train mean loss=62796.14153645833\n",
      "test_test\n",
      "test mean loss=86202.52734375\n",
      "fin save.\n",
      "epoch 266\n",
      "test_train\n",
      "train mean loss=63540.64348958333\n",
      "test_test\n",
      "test mean loss=86242.53515625\n",
      "fin save.\n",
      "epoch 267\n",
      "test_train\n",
      "train mean loss=62399.65807291667\n",
      "test_test\n",
      "test mean loss=86434.95703125\n",
      "fin save.\n",
      "epoch 268\n",
      "test_train\n",
      "train mean loss=62187.649088541664\n",
      "test_test\n",
      "test mean loss=86480.796875\n",
      "fin save.\n",
      "epoch 269\n",
      "test_train\n",
      "train mean loss=63051.16510416667\n",
      "test_test\n",
      "test mean loss=86359.29296875\n",
      "fin save.\n",
      "epoch 270\n",
      "test_train\n",
      "train mean loss=62165.866015625\n",
      "test_test\n",
      "test mean loss=86396.609375\n",
      "fin save.\n",
      "epoch 271\n",
      "test_train\n",
      "train mean loss=61829.28828125\n",
      "test_test\n",
      "test mean loss=86389.01171875\n",
      "fin save.\n",
      "epoch 272\n",
      "test_train\n",
      "train mean loss=63269.191145833334\n",
      "test_test\n",
      "test mean loss=86301.58984375\n",
      "fin save.\n",
      "epoch 273\n",
      "test_train\n",
      "train mean loss=62307.51510416667\n",
      "test_test\n",
      "test mean loss=86066.9296875\n",
      "fin save.\n",
      "epoch 274\n",
      "test_train\n",
      "train mean loss=62488.25677083333\n",
      "test_test\n",
      "test mean loss=86909.33984375\n",
      "fin save.\n",
      "epoch 275\n",
      "test_train\n",
      "train mean loss=62815.800390625\n",
      "test_test\n",
      "test mean loss=86611.78515625\n",
      "fin save.\n",
      "epoch 276\n",
      "test_train\n",
      "train mean loss=63097.79973958333\n",
      "test_test\n",
      "test mean loss=86915.65234375\n",
      "fin save.\n",
      "epoch 277\n",
      "test_train\n",
      "train mean loss=63227.269791666666\n",
      "test_test\n",
      "test mean loss=86741.3828125\n",
      "fin save.\n",
      "epoch 278\n",
      "test_train\n",
      "train mean loss=62772.77734375\n",
      "test_test\n",
      "test mean loss=87043.921875\n",
      "fin save.\n",
      "epoch 279\n",
      "test_train\n",
      "train mean loss=62320.867447916666\n",
      "test_test\n",
      "test mean loss=86914.33203125\n",
      "fin save.\n",
      "epoch 280\n",
      "test_train\n",
      "train mean loss=62259.702734375\n",
      "test_test\n",
      "test mean loss=86634.04296875\n",
      "fin save.\n",
      "epoch 281\n",
      "test_train\n",
      "train mean loss=63151.35390625\n",
      "test_test\n",
      "test mean loss=86875.00390625\n",
      "fin save.\n",
      "epoch 282\n",
      "test_train\n",
      "train mean loss=62580.910416666666\n",
      "test_test\n",
      "test mean loss=87924.85546875\n",
      "fin save.\n",
      "epoch 283\n",
      "test_train\n",
      "train mean loss=61717.215625\n",
      "test_test\n",
      "test mean loss=87952.95703125\n",
      "fin save.\n",
      "epoch 284\n",
      "test_train\n",
      "train mean loss=62099.700520833336\n",
      "test_test\n",
      "test mean loss=87880.94140625\n",
      "fin save.\n",
      "epoch 285\n",
      "test_train\n",
      "train mean loss=62826.710677083334\n",
      "test_test\n",
      "test mean loss=87987.29296875\n",
      "fin save.\n",
      "epoch 286\n",
      "test_train\n",
      "train mean loss=62561.80234375\n",
      "test_test\n",
      "test mean loss=87997.59765625\n",
      "fin save.\n",
      "epoch 287\n",
      "test_train\n",
      "train mean loss=62579.01458333333\n",
      "test_test\n",
      "test mean loss=88144.66796875\n",
      "fin save.\n",
      "epoch 288\n",
      "test_train\n",
      "train mean loss=63165.855208333334\n",
      "test_test\n",
      "test mean loss=87866.1953125\n",
      "fin save.\n",
      "epoch 289\n",
      "test_train\n",
      "train mean loss=62332.789713541664\n",
      "test_test\n",
      "test mean loss=87821.33984375\n",
      "fin save.\n",
      "epoch 290\n",
      "test_train\n",
      "train mean loss=63201.675\n",
      "test_test\n",
      "test mean loss=87648.97265625\n",
      "fin save.\n",
      "epoch 291\n",
      "test_train\n",
      "train mean loss=62439.21432291667\n",
      "test_test\n",
      "test mean loss=87810.01953125\n",
      "fin save.\n",
      "epoch 292\n",
      "test_train\n",
      "train mean loss=62900.052083333336\n",
      "test_test\n",
      "test mean loss=87575.00390625\n",
      "fin save.\n",
      "epoch 293\n",
      "test_train\n",
      "train mean loss=61439.54791666667\n",
      "test_test\n",
      "test mean loss=87678.08203125\n",
      "fin save.\n",
      "epoch 294\n",
      "test_train\n",
      "train mean loss=62420.39140625\n",
      "test_test\n",
      "test mean loss=87761.6328125\n",
      "fin save.\n",
      "epoch 295\n",
      "test_train\n",
      "train mean loss=62995.183854166666\n",
      "test_test\n",
      "test mean loss=87854.9609375\n",
      "fin save.\n",
      "epoch 296\n",
      "test_train\n",
      "train mean loss=63340.4921875\n",
      "test_test\n",
      "test mean loss=87770.22265625\n",
      "fin save.\n",
      "epoch 297\n",
      "test_train\n",
      "train mean loss=63766.569010416664\n",
      "test_test\n",
      "test mean loss=87848.91015625\n",
      "fin save.\n",
      "epoch 298\n",
      "test_train\n",
      "train mean loss=63075.99661458333\n",
      "test_test\n",
      "test mean loss=87815.4453125\n",
      "fin save.\n",
      "epoch 299\n",
      "test_train\n",
      "train mean loss=62808.2484375\n",
      "test_test\n",
      "test mean loss=87756.0\n",
      "fin save.\n",
      "epoch 300\n",
      "test_train\n",
      "train mean loss=62227.63828125\n",
      "test_test\n",
      "test mean loss=87707.0390625\n",
      "fin save.\n",
      "epoch 301\n",
      "test_train\n",
      "train mean loss=63048.85859375\n",
      "test_test\n",
      "test mean loss=87711.671875\n",
      "fin save.\n",
      "epoch 302\n",
      "test_train\n",
      "train mean loss=62595.533854166664\n",
      "test_test\n",
      "test mean loss=87862.859375\n",
      "fin save.\n",
      "epoch 303\n",
      "test_train\n",
      "train mean loss=62316.298177083336\n",
      "test_test\n",
      "test mean loss=88047.21875\n",
      "fin save.\n",
      "epoch 304\n",
      "test_train\n",
      "train mean loss=62368.20546875\n",
      "test_test\n",
      "test mean loss=87997.0546875\n",
      "fin save.\n",
      "epoch 305\n",
      "test_train\n",
      "train mean loss=63361.240494791666\n",
      "test_test\n",
      "test mean loss=87945.5\n",
      "fin save.\n",
      "epoch 306\n",
      "test_train\n",
      "train mean loss=62838.754166666666\n",
      "test_test\n",
      "test mean loss=87895.80078125\n",
      "fin save.\n",
      "epoch 307\n",
      "test_train\n",
      "train mean loss=62202.101302083334\n",
      "test_test\n",
      "test mean loss=88037.4921875\n",
      "fin save.\n",
      "epoch 308\n",
      "test_train\n",
      "train mean loss=62585.80755208333\n",
      "test_test\n",
      "test mean loss=88258.53125\n",
      "fin save.\n",
      "epoch 309\n",
      "test_train\n",
      "train mean loss=62120.29895833333\n",
      "test_test\n",
      "test mean loss=88269.140625\n",
      "fin save.\n",
      "epoch 310\n",
      "test_train\n",
      "train mean loss=62879.57825520833\n",
      "test_test\n",
      "test mean loss=88199.16796875\n",
      "fin save.\n",
      "epoch 311\n",
      "test_train\n",
      "train mean loss=61546.00182291667\n",
      "test_test\n",
      "test mean loss=87931.09765625\n",
      "fin save.\n",
      "epoch 312\n",
      "test_train\n",
      "train mean loss=63010.5796875\n",
      "test_test\n",
      "test mean loss=87861.453125\n",
      "fin save.\n",
      "epoch 313\n",
      "test_train\n",
      "train mean loss=63154.453515625\n",
      "test_test\n",
      "test mean loss=87819.12109375\n",
      "fin save.\n",
      "epoch 314\n",
      "test_train\n",
      "train mean loss=61697.44322916667\n",
      "test_test\n",
      "test mean loss=87983.30859375\n",
      "fin save.\n",
      "epoch 315\n",
      "test_train\n",
      "train mean loss=62034.40286458333\n",
      "test_test\n",
      "test mean loss=87919.29296875\n",
      "fin save.\n",
      "epoch 316\n",
      "test_train\n",
      "train mean loss=62352.14791666667\n",
      "test_test\n",
      "test mean loss=87974.78515625\n",
      "fin save.\n",
      "epoch 317\n",
      "test_train\n",
      "train mean loss=62109.68567708333\n",
      "test_test\n",
      "test mean loss=87841.7265625\n",
      "fin save.\n",
      "epoch 318\n",
      "test_train\n",
      "train mean loss=62216.97994791667\n",
      "test_test\n",
      "test mean loss=87831.12890625\n",
      "fin save.\n",
      "epoch 319\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=62781.836197916666\n",
      "test_test\n",
      "test mean loss=87837.734375\n",
      "fin save.\n",
      "epoch 320\n",
      "test_train\n",
      "train mean loss=63238.98203125\n",
      "test_test\n",
      "test mean loss=87446.875\n",
      "fin save.\n",
      "epoch 321\n",
      "test_train\n",
      "train mean loss=62138.34140625\n",
      "test_test\n",
      "test mean loss=87800.859375\n",
      "fin save.\n",
      "epoch 322\n",
      "test_train\n",
      "train mean loss=62361.41588541667\n",
      "test_test\n",
      "test mean loss=87663.98828125\n",
      "fin save.\n",
      "epoch 323\n",
      "test_train\n",
      "train mean loss=62185.765885416666\n",
      "test_test\n",
      "test mean loss=87875.29296875\n",
      "fin save.\n",
      "epoch 324\n",
      "test_train\n",
      "train mean loss=63787.280078125\n",
      "test_test\n",
      "test mean loss=87714.01171875\n",
      "fin save.\n",
      "epoch 325\n",
      "test_train\n",
      "train mean loss=61708.0046875\n",
      "test_test\n",
      "test mean loss=87866.625\n",
      "fin save.\n",
      "epoch 326\n",
      "test_train\n",
      "train mean loss=62725.76940104167\n",
      "test_test\n",
      "test mean loss=87901.34765625\n",
      "fin save.\n",
      "epoch 327\n",
      "test_train\n",
      "train mean loss=62581.86341145833\n",
      "test_test\n",
      "test mean loss=88015.24609375\n",
      "fin save.\n",
      "epoch 328\n",
      "test_train\n",
      "train mean loss=62062.11145833333\n",
      "test_test\n",
      "test mean loss=88242.859375\n",
      "fin save.\n",
      "epoch 329\n",
      "test_train\n",
      "train mean loss=62415.98723958333\n",
      "test_test\n",
      "test mean loss=88249.8671875\n",
      "fin save.\n",
      "epoch 330\n",
      "test_train\n",
      "train mean loss=62749.579427083336\n",
      "test_test\n",
      "test mean loss=88207.49609375\n",
      "fin save.\n",
      "epoch 331\n",
      "test_train\n",
      "train mean loss=62296.019791666666\n",
      "test_test\n",
      "test mean loss=88145.9296875\n",
      "fin save.\n",
      "epoch 332\n",
      "test_train\n",
      "train mean loss=62683.03802083333\n",
      "test_test\n",
      "test mean loss=88272.73046875\n",
      "fin save.\n",
      "epoch 333\n",
      "test_train\n",
      "train mean loss=63042.543229166666\n",
      "test_test\n",
      "test mean loss=88282.4453125\n",
      "fin save.\n",
      "epoch 334\n",
      "test_train\n",
      "train mean loss=62119.006510416664\n",
      "test_test\n",
      "test mean loss=88167.86328125\n",
      "fin save.\n",
      "epoch 335\n",
      "test_train\n",
      "train mean loss=63053.691666666666\n",
      "test_test\n",
      "test mean loss=88126.05859375\n",
      "fin save.\n",
      "epoch 336\n",
      "test_train\n",
      "train mean loss=62713.420572916664\n",
      "test_test\n",
      "test mean loss=88206.60546875\n",
      "fin save.\n",
      "epoch 337\n",
      "test_train\n",
      "train mean loss=63457.74609375\n",
      "test_test\n",
      "test mean loss=87972.8984375\n",
      "fin save.\n",
      "epoch 338\n",
      "test_train\n",
      "train mean loss=62560.08190104167\n",
      "test_test\n",
      "test mean loss=87737.82421875\n",
      "fin save.\n",
      "epoch 339\n",
      "test_train\n",
      "train mean loss=62763.64401041667\n",
      "test_test\n",
      "test mean loss=87946.5078125\n",
      "fin save.\n",
      "epoch 340\n",
      "test_train\n",
      "train mean loss=62231.949479166666\n",
      "test_test\n",
      "test mean loss=87741.08984375\n",
      "fin save.\n",
      "epoch 341\n",
      "test_train\n",
      "train mean loss=62489.527604166666\n",
      "test_test\n",
      "test mean loss=87924.640625\n",
      "fin save.\n",
      "epoch 342\n",
      "test_train\n",
      "train mean loss=62862.865494791666\n",
      "test_test\n",
      "test mean loss=88026.55859375\n",
      "fin save.\n",
      "epoch 343\n",
      "test_train\n",
      "train mean loss=61628.601302083334\n",
      "test_test\n",
      "test mean loss=88022.03125\n",
      "fin save.\n",
      "epoch 344\n",
      "test_train\n",
      "train mean loss=61586.52421875\n",
      "test_test\n",
      "test mean loss=87896.4609375\n",
      "fin save.\n",
      "epoch 345\n",
      "test_train\n",
      "train mean loss=62619.22213541667\n",
      "test_test\n",
      "test mean loss=88029.79296875\n",
      "fin save.\n",
      "epoch 346\n",
      "test_train\n",
      "train mean loss=62606.77526041667\n",
      "test_test\n",
      "test mean loss=87882.94921875\n",
      "fin save.\n",
      "epoch 347\n",
      "test_train\n",
      "train mean loss=62463.520833333336\n",
      "test_test\n",
      "test mean loss=87955.0078125\n",
      "fin save.\n",
      "epoch 348\n",
      "test_train\n",
      "train mean loss=62175.76458333333\n",
      "test_test\n",
      "test mean loss=87990.83984375\n",
      "fin save.\n",
      "epoch 349\n",
      "test_train\n",
      "train mean loss=62082.106770833336\n",
      "test_test\n",
      "test mean loss=87974.2421875\n",
      "fin save.\n",
      "epoch 350\n",
      "test_train\n",
      "train mean loss=61658.339583333334\n",
      "test_test\n",
      "test mean loss=88016.875\n",
      "fin save.\n",
      "epoch 351\n",
      "test_train\n",
      "train mean loss=62629.503645833334\n",
      "test_test\n",
      "test mean loss=88113.7578125\n",
      "fin save.\n",
      "epoch 352\n",
      "test_train\n",
      "train mean loss=62193.01328125\n",
      "test_test\n",
      "test mean loss=88095.125\n",
      "fin save.\n",
      "epoch 353\n",
      "test_train\n",
      "train mean loss=62437.81927083333\n",
      "test_test\n",
      "test mean loss=88055.8203125\n",
      "fin save.\n",
      "epoch 354\n",
      "test_train\n",
      "train mean loss=61810.884765625\n",
      "test_test\n",
      "test mean loss=87817.80859375\n",
      "fin save.\n",
      "epoch 355\n",
      "test_train\n",
      "train mean loss=62644.17096354167\n",
      "test_test\n",
      "test mean loss=87980.57421875\n",
      "fin save.\n",
      "epoch 356\n",
      "test_train\n",
      "train mean loss=61686.584765625\n",
      "test_test\n",
      "test mean loss=87950.08984375\n",
      "fin save.\n",
      "epoch 357\n",
      "test_train\n",
      "train mean loss=62605.31484375\n",
      "test_test\n",
      "test mean loss=87691.89453125\n",
      "fin save.\n",
      "epoch 358\n",
      "test_train\n",
      "train mean loss=62953.42760416667\n",
      "test_test\n",
      "test mean loss=88007.73046875\n",
      "fin save.\n",
      "epoch 359\n",
      "test_train\n",
      "train mean loss=62905.75442708333\n",
      "test_test\n",
      "test mean loss=87740.62890625\n",
      "fin save.\n",
      "epoch 360\n",
      "test_train\n",
      "train mean loss=62939.14114583333\n",
      "test_test\n",
      "test mean loss=87865.296875\n",
      "fin save.\n",
      "epoch 361\n",
      "test_train\n",
      "train mean loss=62879.5875\n",
      "test_test\n",
      "test mean loss=87982.8125\n",
      "fin save.\n",
      "epoch 362\n",
      "test_train\n",
      "train mean loss=62571.744140625\n",
      "test_test\n",
      "test mean loss=87860.76171875\n",
      "fin save.\n",
      "epoch 363\n",
      "test_train\n",
      "train mean loss=62575.557291666664\n",
      "test_test\n",
      "test mean loss=87827.79296875\n",
      "fin save.\n",
      "epoch 364\n",
      "test_train\n",
      "train mean loss=62181.576822916664\n",
      "test_test\n",
      "test mean loss=87865.0078125\n",
      "fin save.\n",
      "epoch 365\n",
      "test_train\n",
      "train mean loss=63376.1828125\n",
      "test_test\n",
      "test mean loss=87849.1484375\n",
      "fin save.\n",
      "epoch 366\n",
      "test_train\n",
      "train mean loss=62423.416666666664\n",
      "test_test\n",
      "test mean loss=87829.02734375\n",
      "fin save.\n",
      "epoch 367\n",
      "test_train\n",
      "train mean loss=62942.004166666666\n",
      "test_test\n",
      "test mean loss=87999.05859375\n",
      "fin save.\n",
      "epoch 368\n",
      "test_train\n",
      "train mean loss=62928.303125\n",
      "test_test\n",
      "test mean loss=87818.21875\n",
      "fin save.\n",
      "epoch 369\n",
      "test_train\n",
      "train mean loss=62447.048177083336\n",
      "test_test\n",
      "test mean loss=87767.81640625\n",
      "fin save.\n",
      "epoch 370\n",
      "test_train\n",
      "train mean loss=62797.823958333334\n",
      "test_test\n",
      "test mean loss=87836.2109375\n",
      "fin save.\n",
      "epoch 371\n",
      "test_train\n",
      "train mean loss=62734.96015625\n",
      "test_test\n",
      "test mean loss=87884.98828125\n",
      "fin save.\n",
      "epoch 372\n",
      "test_train\n",
      "train mean loss=62427.820703125\n",
      "test_test\n",
      "test mean loss=87920.89453125\n",
      "fin save.\n",
      "epoch 373\n",
      "test_train\n",
      "train mean loss=62624.91614583333\n",
      "test_test\n",
      "test mean loss=87905.16015625\n",
      "fin save.\n",
      "epoch 374\n",
      "test_train\n",
      "train mean loss=62727.022135416664\n",
      "test_test\n",
      "test mean loss=87920.92578125\n",
      "fin save.\n",
      "epoch 375\n",
      "test_train\n",
      "train mean loss=62667.338541666664\n",
      "test_test\n",
      "test mean loss=87912.51171875\n",
      "fin save.\n",
      "epoch 376\n",
      "test_train\n",
      "train mean loss=62679.690755208336\n",
      "test_test\n",
      "test mean loss=88011.75\n",
      "fin save.\n",
      "epoch 377\n",
      "test_train\n",
      "train mean loss=62461.77578125\n",
      "test_test\n",
      "test mean loss=87864.3828125\n",
      "fin save.\n",
      "epoch 378\n",
      "test_train\n",
      "train mean loss=62463.920572916664\n",
      "test_test\n",
      "test mean loss=88552.50390625\n",
      "fin save.\n",
      "epoch 379\n",
      "test_train\n",
      "train mean loss=62203.578125\n",
      "test_test\n",
      "test mean loss=88253.24609375\n",
      "fin save.\n",
      "epoch 380\n",
      "test_train\n",
      "train mean loss=61630.84270833333\n",
      "test_test\n",
      "test mean loss=88500.3984375\n",
      "fin save.\n",
      "epoch 381\n",
      "test_train\n",
      "train mean loss=62207.45807291667\n",
      "test_test\n",
      "test mean loss=88342.30859375\n",
      "fin save.\n",
      "epoch 382\n",
      "test_train\n",
      "train mean loss=62718.6859375\n",
      "test_test\n",
      "test mean loss=88369.34375\n",
      "fin save.\n",
      "epoch 383\n",
      "test_train\n",
      "train mean loss=62295.03177083333\n",
      "test_test\n",
      "test mean loss=88122.96875\n",
      "fin save.\n",
      "epoch 384\n",
      "test_train\n",
      "train mean loss=61870.99114583333\n",
      "test_test\n",
      "test mean loss=88269.7421875\n",
      "fin save.\n",
      "epoch 385\n",
      "test_train\n",
      "train mean loss=62645.68255208333\n",
      "test_test\n",
      "test mean loss=88280.75390625\n",
      "fin save.\n",
      "epoch 386\n",
      "test_train\n",
      "train mean loss=62794.309375\n",
      "test_test\n",
      "test mean loss=88124.22265625\n",
      "fin save.\n",
      "epoch 387\n",
      "test_train\n",
      "train mean loss=62240.55677083333\n",
      "test_test\n",
      "test mean loss=88272.99609375\n",
      "fin save.\n",
      "epoch 388\n",
      "test_train\n",
      "train mean loss=62703.12421875\n",
      "test_test\n",
      "test mean loss=88024.7265625\n",
      "fin save.\n",
      "epoch 389\n",
      "test_train\n",
      "train mean loss=62537.497395833336\n",
      "test_test\n",
      "test mean loss=88042.171875\n",
      "fin save.\n",
      "epoch 390\n",
      "test_train\n",
      "train mean loss=61993.202864583334\n",
      "test_test\n",
      "test mean loss=87970.90625\n",
      "fin save.\n",
      "epoch 391\n",
      "test_train\n",
      "train mean loss=61671.04635416667\n",
      "test_test\n",
      "test mean loss=88052.171875\n",
      "fin save.\n",
      "epoch 392\n",
      "test_train\n",
      "train mean loss=63438.400390625\n",
      "test_test\n",
      "test mean loss=88170.53515625\n",
      "fin save.\n",
      "epoch 393\n",
      "test_train\n",
      "train mean loss=62675.63489583333\n",
      "test_test\n",
      "test mean loss=88264.19921875\n",
      "fin save.\n",
      "epoch 394\n",
      "test_train\n",
      "train mean loss=62911.845963541666\n",
      "test_test\n",
      "test mean loss=88108.7890625\n",
      "fin save.\n",
      "epoch 395\n",
      "test_train\n",
      "train mean loss=62489.178385416664\n",
      "test_test\n",
      "test mean loss=87722.41015625\n",
      "fin save.\n",
      "epoch 396\n",
      "test_train\n",
      "train mean loss=62779.426041666666\n",
      "test_test\n",
      "test mean loss=87917.71875\n",
      "fin save.\n",
      "epoch 397\n",
      "test_train\n",
      "train mean loss=61820.835677083334\n",
      "test_test\n",
      "test mean loss=87458.84375\n",
      "fin save.\n",
      "epoch 398\n",
      "test_train\n",
      "train mean loss=62589.2734375\n",
      "test_test\n",
      "test mean loss=87652.05078125\n",
      "fin save.\n",
      "epoch 399\n",
      "test_train\n",
      "train mean loss=61528.437760416666\n",
      "test_test\n",
      "test mean loss=87170.11328125\n",
      "fin save.\n",
      "epoch 400\n",
      "test_train\n",
      "train mean loss=62788.40963541667\n",
      "test_test\n",
      "test mean loss=87092.22265625\n",
      "fin save.\n",
      "epoch 401\n",
      "test_train\n",
      "train mean loss=62275.56536458333\n",
      "test_test\n",
      "test mean loss=87181.95703125\n",
      "fin save.\n",
      "epoch 402\n",
      "test_train\n",
      "train mean loss=62000.941145833334\n",
      "test_test\n",
      "test mean loss=87639.50390625\n",
      "fin save.\n",
      "epoch 403\n",
      "test_train\n",
      "train mean loss=61402.98880208333\n",
      "test_test\n",
      "test mean loss=87685.30859375\n",
      "fin save.\n",
      "epoch 404\n",
      "test_train\n",
      "train mean loss=62423.52486979167\n",
      "test_test\n",
      "test mean loss=87605.59765625\n",
      "fin save.\n",
      "epoch 405\n",
      "test_train\n",
      "train mean loss=63434.198828125\n",
      "test_test\n",
      "test mean loss=87579.703125\n",
      "fin save.\n",
      "epoch 406\n",
      "test_train\n",
      "train mean loss=62522.64609375\n",
      "test_test\n",
      "test mean loss=87660.01953125\n",
      "fin save.\n",
      "epoch 407\n",
      "test_train\n",
      "train mean loss=62612.570052083334\n",
      "test_test\n",
      "test mean loss=87523.98828125\n",
      "fin save.\n",
      "epoch 408\n",
      "test_train\n",
      "train mean loss=61134.1265625\n",
      "test_test\n",
      "test mean loss=87555.98046875\n",
      "fin save.\n",
      "epoch 409\n",
      "test_train\n",
      "train mean loss=62365.12317708333\n",
      "test_test\n",
      "test mean loss=87606.578125\n",
      "fin save.\n",
      "epoch 410\n",
      "test_train\n",
      "train mean loss=62205.80364583333\n",
      "test_test\n",
      "test mean loss=87816.96484375\n",
      "fin save.\n",
      "epoch 411\n",
      "test_train\n",
      "train mean loss=61318.819010416664\n",
      "test_test\n",
      "test mean loss=87879.6328125\n",
      "fin save.\n",
      "epoch 412\n",
      "test_train\n",
      "train mean loss=61855.006510416664\n",
      "test_test\n",
      "test mean loss=87956.69140625\n",
      "fin save.\n",
      "epoch 413\n",
      "test_train\n",
      "train mean loss=62651.00104166667\n",
      "test_test\n",
      "test mean loss=87961.5703125\n",
      "fin save.\n",
      "epoch 414\n",
      "test_train\n",
      "train mean loss=62586.11510416667\n",
      "test_test\n",
      "test mean loss=87844.01953125\n",
      "fin save.\n",
      "epoch 415\n",
      "test_train\n",
      "train mean loss=63204.475260416664\n",
      "test_test\n",
      "test mean loss=87868.640625\n",
      "fin save.\n",
      "epoch 416\n",
      "test_train\n",
      "train mean loss=61466.3390625\n",
      "test_test\n",
      "test mean loss=87816.82421875\n",
      "fin save.\n",
      "epoch 417\n",
      "test_train\n",
      "train mean loss=61721.11770833333\n",
      "test_test\n",
      "test mean loss=87784.5078125\n",
      "fin save.\n",
      "epoch 418\n",
      "test_train\n",
      "train mean loss=61988.332291666666\n",
      "test_test\n",
      "test mean loss=87496.77734375\n",
      "fin save.\n",
      "epoch 419\n",
      "test_train\n",
      "train mean loss=62969.41875\n",
      "test_test\n",
      "test mean loss=87547.75390625\n",
      "fin save.\n",
      "epoch 420\n",
      "test_train\n",
      "train mean loss=62192.340625\n",
      "test_test\n",
      "test mean loss=87462.328125\n",
      "fin save.\n",
      "epoch 421\n",
      "test_train\n",
      "train mean loss=61832.11861979167\n",
      "test_test\n",
      "test mean loss=87521.5625\n",
      "fin save.\n",
      "epoch 422\n",
      "test_train\n",
      "train mean loss=62646.33932291667\n",
      "test_test\n",
      "test mean loss=87561.2109375\n",
      "fin save.\n",
      "epoch 423\n",
      "test_train\n",
      "train mean loss=62746.88567708333\n",
      "test_test\n",
      "test mean loss=88005.5546875\n",
      "fin save.\n",
      "epoch 424\n",
      "test_train\n",
      "train mean loss=63058.163802083334\n",
      "test_test\n",
      "test mean loss=87703.76171875\n",
      "fin save.\n",
      "epoch 425\n",
      "test_train\n",
      "train mean loss=63156.007161458336\n",
      "test_test\n",
      "test mean loss=87934.72265625\n",
      "fin save.\n",
      "epoch 426\n",
      "test_train\n",
      "train mean loss=61991.995703125\n",
      "test_test\n",
      "test mean loss=87992.66796875\n",
      "fin save.\n",
      "epoch 427\n",
      "test_train\n",
      "train mean loss=61553.840625\n",
      "test_test\n",
      "test mean loss=87907.0859375\n",
      "fin save.\n",
      "epoch 428\n",
      "test_train\n",
      "train mean loss=62028.33385416667\n",
      "test_test\n",
      "test mean loss=88004.91015625\n",
      "fin save.\n",
      "epoch 429\n",
      "test_train\n",
      "train mean loss=62387.50703125\n",
      "test_test\n",
      "test mean loss=88098.55859375\n",
      "fin save.\n",
      "epoch 430\n",
      "test_train\n",
      "train mean loss=61752.459635416664\n",
      "test_test\n",
      "test mean loss=88145.80078125\n",
      "fin save.\n",
      "epoch 431\n",
      "test_train\n",
      "train mean loss=62907.26640625\n",
      "test_test\n",
      "test mean loss=87908.5\n",
      "fin save.\n",
      "epoch 432\n",
      "test_train\n",
      "train mean loss=62190.40182291667\n",
      "test_test\n",
      "test mean loss=87605.03515625\n",
      "fin save.\n",
      "epoch 433\n",
      "test_train\n",
      "train mean loss=62368.718098958336\n",
      "test_test\n",
      "test mean loss=86785.15625\n",
      "fin save.\n",
      "epoch 434\n",
      "test_train\n",
      "train mean loss=62120.93411458333\n",
      "test_test\n",
      "test mean loss=86978.97265625\n",
      "fin save.\n",
      "epoch 435\n",
      "test_train\n",
      "train mean loss=61965.3421875\n",
      "test_test\n",
      "test mean loss=87247.91015625\n",
      "fin save.\n",
      "epoch 436\n",
      "test_train\n",
      "train mean loss=62119.31458333333\n",
      "test_test\n",
      "test mean loss=87118.0234375\n",
      "fin save.\n",
      "epoch 437\n",
      "test_train\n",
      "train mean loss=62606.941145833334\n",
      "test_test\n",
      "test mean loss=86902.82421875\n",
      "fin save.\n",
      "epoch 438\n",
      "test_train\n",
      "train mean loss=62641.737109375\n",
      "test_test\n",
      "test mean loss=87092.828125\n",
      "fin save.\n",
      "epoch 439\n",
      "test_train\n",
      "train mean loss=61564.23776041667\n",
      "test_test\n",
      "test mean loss=87181.4765625\n",
      "fin save.\n",
      "epoch 440\n",
      "test_train\n",
      "train mean loss=62824.26848958333\n",
      "test_test\n",
      "test mean loss=87182.99609375\n",
      "fin save.\n",
      "epoch 441\n",
      "test_train\n",
      "train mean loss=61845.887890625\n",
      "test_test\n",
      "test mean loss=87210.015625\n",
      "fin save.\n",
      "epoch 442\n",
      "test_train\n",
      "train mean loss=62740.6796875\n",
      "test_test\n",
      "test mean loss=87249.828125\n",
      "fin save.\n",
      "epoch 443\n",
      "test_train\n",
      "train mean loss=62788.25625\n",
      "test_test\n",
      "test mean loss=87529.19140625\n",
      "fin save.\n",
      "epoch 444\n",
      "test_train\n",
      "train mean loss=62963.554427083334\n",
      "test_test\n",
      "test mean loss=87308.45703125\n",
      "fin save.\n",
      "epoch 445\n",
      "test_train\n",
      "train mean loss=62329.9375\n",
      "test_test\n",
      "test mean loss=87257.703125\n",
      "fin save.\n",
      "epoch 446\n",
      "test_train\n",
      "train mean loss=62372.003645833334\n",
      "test_test\n",
      "test mean loss=87313.12890625\n",
      "fin save.\n",
      "epoch 447\n",
      "test_train\n",
      "train mean loss=62395.634375\n",
      "test_test\n",
      "test mean loss=87312.8046875\n",
      "fin save.\n",
      "epoch 448\n",
      "test_train\n",
      "train mean loss=63518.8875\n",
      "test_test\n",
      "test mean loss=87351.53515625\n",
      "fin save.\n",
      "epoch 449\n",
      "test_train\n",
      "train mean loss=62335.01875\n",
      "test_test\n",
      "test mean loss=87360.51171875\n",
      "fin save.\n",
      "epoch 450\n",
      "test_train\n",
      "train mean loss=63339.452864583334\n",
      "test_test\n",
      "test mean loss=87126.01953125\n",
      "fin save.\n",
      "epoch 451\n",
      "test_train\n",
      "train mean loss=63030.24075520833\n",
      "test_test\n",
      "test mean loss=87098.91015625\n",
      "fin save.\n",
      "epoch 452\n",
      "test_train\n",
      "train mean loss=63070.52265625\n",
      "test_test\n",
      "test mean loss=87562.76953125\n",
      "fin save.\n",
      "epoch 453\n",
      "test_train\n",
      "train mean loss=62615.735026041664\n",
      "test_test\n",
      "test mean loss=87768.1484375\n",
      "fin save.\n",
      "epoch 454\n",
      "test_train\n",
      "train mean loss=62765.9765625\n",
      "test_test\n",
      "test mean loss=87644.1328125\n",
      "fin save.\n",
      "epoch 455\n",
      "test_train\n",
      "train mean loss=62374.29205729167\n",
      "test_test\n",
      "test mean loss=87655.41015625\n",
      "fin save.\n",
      "epoch 456\n",
      "test_train\n",
      "train mean loss=62451.38033854167\n",
      "test_test\n",
      "test mean loss=87600.1171875\n",
      "fin save.\n",
      "epoch 457\n",
      "test_train\n",
      "train mean loss=63093.25768229167\n",
      "test_test\n",
      "test mean loss=87232.34765625\n",
      "fin save.\n",
      "epoch 458\n",
      "test_train\n",
      "train mean loss=63169.755208333336\n",
      "test_test\n",
      "test mean loss=87103.15625\n",
      "fin save.\n",
      "epoch 459\n",
      "test_train\n",
      "train mean loss=62293.17005208333\n",
      "test_test\n",
      "test mean loss=86971.4609375\n",
      "fin save.\n",
      "epoch 460\n",
      "test_train\n",
      "train mean loss=62608.56354166667\n",
      "test_test\n",
      "test mean loss=87094.0625\n",
      "fin save.\n",
      "epoch 461\n",
      "test_train\n",
      "train mean loss=62595.88359375\n",
      "test_test\n",
      "test mean loss=87298.140625\n",
      "fin save.\n",
      "epoch 462\n",
      "test_train\n",
      "train mean loss=61651.22578125\n",
      "test_test\n",
      "test mean loss=87332.27734375\n",
      "fin save.\n",
      "epoch 463\n",
      "test_train\n",
      "train mean loss=62574.760546875\n",
      "test_test\n",
      "test mean loss=87391.79296875\n",
      "fin save.\n",
      "epoch 464\n",
      "test_train\n",
      "train mean loss=63107.403125\n",
      "test_test\n",
      "test mean loss=87288.58203125\n",
      "fin save.\n",
      "epoch 465\n",
      "test_train\n",
      "train mean loss=61456.36901041667\n",
      "test_test\n",
      "test mean loss=87102.953125\n",
      "fin save.\n",
      "epoch 466\n",
      "test_train\n",
      "train mean loss=62754.21471354167\n",
      "test_test\n",
      "test mean loss=87263.84765625\n",
      "fin save.\n",
      "epoch 467\n",
      "test_train\n",
      "train mean loss=61850.04973958333\n",
      "test_test\n",
      "test mean loss=87201.6328125\n",
      "fin save.\n",
      "epoch 468\n",
      "test_train\n",
      "train mean loss=61862.46770833333\n",
      "test_test\n",
      "test mean loss=87044.09375\n",
      "fin save.\n",
      "epoch 469\n",
      "test_train\n",
      "train mean loss=62142.037760416664\n",
      "test_test\n",
      "test mean loss=87238.41796875\n",
      "fin save.\n",
      "epoch 470\n",
      "test_train\n",
      "train mean loss=61487.613020833334\n",
      "test_test\n",
      "test mean loss=87097.81640625\n",
      "fin save.\n",
      "epoch 471\n",
      "test_train\n",
      "train mean loss=62042.355729166666\n",
      "test_test\n",
      "test mean loss=86819.0625\n",
      "fin save.\n",
      "epoch 472\n",
      "test_train\n",
      "train mean loss=62803.88723958333\n",
      "test_test\n",
      "test mean loss=86761.40625\n",
      "fin save.\n",
      "epoch 473\n",
      "test_train\n",
      "train mean loss=63408.92239583333\n",
      "test_test\n",
      "test mean loss=87094.125\n",
      "fin save.\n",
      "epoch 474\n",
      "test_train\n",
      "train mean loss=62323.33125\n",
      "test_test\n",
      "test mean loss=86942.23828125\n",
      "fin save.\n",
      "epoch 475\n",
      "test_train\n",
      "train mean loss=62305.016927083336\n",
      "test_test\n",
      "test mean loss=86999.2734375\n",
      "fin save.\n",
      "epoch 476\n",
      "test_train\n",
      "train mean loss=61672.62890625\n",
      "test_test\n",
      "test mean loss=86851.4296875\n",
      "fin save.\n",
      "epoch 477\n",
      "test_train\n",
      "train mean loss=62254.59778645833\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=87144.16015625\n",
      "fin save.\n",
      "epoch 478\n",
      "test_train\n",
      "train mean loss=63142.534375\n",
      "test_test\n",
      "test mean loss=86775.3046875\n",
      "fin save.\n",
      "epoch 479\n",
      "test_train\n",
      "train mean loss=62179.074479166666\n",
      "test_test\n",
      "test mean loss=86835.28125\n",
      "fin save.\n",
      "epoch 480\n",
      "test_train\n",
      "train mean loss=62216.38828125\n",
      "test_test\n",
      "test mean loss=86802.19140625\n",
      "fin save.\n",
      "epoch 481\n",
      "test_train\n",
      "train mean loss=62519.41692708333\n",
      "test_test\n",
      "test mean loss=86868.84765625\n",
      "fin save.\n",
      "epoch 482\n",
      "test_train\n",
      "train mean loss=61915.55234375\n",
      "test_test\n",
      "test mean loss=86838.80859375\n",
      "fin save.\n",
      "epoch 483\n",
      "test_train\n",
      "train mean loss=62542.61315104167\n",
      "test_test\n",
      "test mean loss=86909.43359375\n",
      "fin save.\n",
      "epoch 484\n",
      "test_train\n",
      "train mean loss=62329.20065104167\n",
      "test_test\n",
      "test mean loss=86957.28515625\n",
      "fin save.\n",
      "epoch 485\n",
      "test_train\n",
      "train mean loss=62267.87994791667\n",
      "test_test\n",
      "test mean loss=87010.484375\n",
      "fin save.\n",
      "epoch 486\n",
      "test_train\n",
      "train mean loss=62303.35390625\n",
      "test_test\n",
      "test mean loss=86907.31640625\n",
      "fin save.\n",
      "epoch 487\n",
      "test_train\n",
      "train mean loss=62347.29114583333\n",
      "test_test\n",
      "test mean loss=86711.2109375\n",
      "fin save.\n",
      "epoch 488\n",
      "test_train\n",
      "train mean loss=62469.52838541667\n",
      "test_test\n",
      "test mean loss=86982.58203125\n",
      "fin save.\n",
      "epoch 489\n",
      "test_train\n",
      "train mean loss=62310.11041666667\n",
      "test_test\n",
      "test mean loss=86867.1328125\n",
      "fin save.\n",
      "epoch 490\n",
      "test_train\n",
      "train mean loss=62917.84166666667\n",
      "test_test\n",
      "test mean loss=86914.64453125\n",
      "fin save.\n",
      "epoch 491\n",
      "test_train\n",
      "train mean loss=63570.755208333336\n",
      "test_test\n",
      "test mean loss=87029.61328125\n",
      "fin save.\n",
      "epoch 492\n",
      "test_train\n",
      "train mean loss=62846.415364583336\n",
      "test_test\n",
      "test mean loss=86983.80859375\n",
      "fin save.\n",
      "epoch 493\n",
      "test_train\n",
      "train mean loss=62373.284895833334\n",
      "test_test\n",
      "test mean loss=86934.8046875\n",
      "fin save.\n",
      "epoch 494\n",
      "test_train\n",
      "train mean loss=62328.281901041664\n",
      "test_test\n",
      "test mean loss=86870.99609375\n",
      "fin save.\n",
      "epoch 495\n",
      "test_train\n",
      "train mean loss=61862.68502604167\n",
      "test_test\n",
      "test mean loss=86789.03515625\n",
      "fin save.\n",
      "epoch 496\n",
      "test_train\n",
      "train mean loss=62763.370833333334\n",
      "test_test\n",
      "test mean loss=86905.6328125\n",
      "fin save.\n",
      "epoch 497\n",
      "test_train\n",
      "train mean loss=62181.426432291664\n",
      "test_test\n",
      "test mean loss=86774.296875\n",
      "fin save.\n",
      "epoch 498\n",
      "test_train\n",
      "train mean loss=63048.76223958333\n",
      "test_test\n",
      "test mean loss=86923.2421875\n",
      "fin save.\n",
      "epoch 499\n",
      "test_train\n",
      "train mean loss=62653.690625\n",
      "test_test\n",
      "test mean loss=86783.02734375\n",
      "fin save.\n",
      "epoch 500\n",
      "test_train\n",
      "train mean loss=62258.712239583336\n",
      "test_test\n",
      "test mean loss=86649.21875\n",
      "fin save.\n",
      "epoch 501\n",
      "test_train\n",
      "train mean loss=62526.98151041667\n",
      "test_test\n",
      "test mean loss=86426.296875\n",
      "fin save.\n",
      "epoch 502\n",
      "test_train\n",
      "train mean loss=62213.46302083333\n",
      "test_test\n",
      "test mean loss=87834.609375\n",
      "fin save.\n",
      "epoch 503\n",
      "test_train\n",
      "train mean loss=61829.07604166667\n",
      "test_test\n",
      "test mean loss=87474.140625\n",
      "fin save.\n",
      "epoch 504\n",
      "test_train\n",
      "train mean loss=62588.57994791667\n",
      "test_test\n",
      "test mean loss=87567.703125\n",
      "fin save.\n",
      "epoch 505\n",
      "test_train\n",
      "train mean loss=62710.86432291667\n",
      "test_test\n",
      "test mean loss=87654.19140625\n",
      "fin save.\n",
      "epoch 506\n",
      "test_train\n",
      "train mean loss=61734.99140625\n",
      "test_test\n",
      "test mean loss=87407.01171875\n",
      "fin save.\n",
      "epoch 507\n",
      "test_train\n",
      "train mean loss=62877.015625\n",
      "test_test\n",
      "test mean loss=87491.2578125\n",
      "fin save.\n",
      "epoch 508\n",
      "test_train\n",
      "train mean loss=61764.675520833334\n",
      "test_test\n",
      "test mean loss=87894.74609375\n",
      "fin save.\n",
      "epoch 509\n",
      "test_train\n",
      "train mean loss=62538.53033854167\n",
      "test_test\n",
      "test mean loss=87980.83203125\n",
      "fin save.\n",
      "epoch 510\n",
      "test_train\n",
      "train mean loss=62526.25078125\n",
      "test_test\n",
      "test mean loss=87851.5\n",
      "fin save.\n",
      "epoch 511\n",
      "test_train\n",
      "train mean loss=61858.72890625\n",
      "test_test\n",
      "test mean loss=87751.4765625\n",
      "fin save.\n",
      "epoch 512\n",
      "test_train\n",
      "train mean loss=62266.38333333333\n",
      "test_test\n",
      "test mean loss=87831.22265625\n",
      "fin save.\n",
      "epoch 513\n",
      "test_train\n",
      "train mean loss=62536.136458333334\n",
      "test_test\n",
      "test mean loss=88022.13671875\n",
      "fin save.\n",
      "epoch 514\n",
      "test_train\n",
      "train mean loss=62947.92486979167\n",
      "test_test\n",
      "test mean loss=88250.3125\n",
      "fin save.\n",
      "epoch 515\n",
      "test_train\n",
      "train mean loss=62004.367838541664\n",
      "test_test\n",
      "test mean loss=88350.32421875\n",
      "fin save.\n",
      "epoch 516\n",
      "test_train\n",
      "train mean loss=62863.56171875\n",
      "test_test\n",
      "test mean loss=88287.99609375\n",
      "fin save.\n",
      "epoch 517\n",
      "test_train\n",
      "train mean loss=62308.226302083334\n",
      "test_test\n",
      "test mean loss=88412.03125\n",
      "fin save.\n",
      "epoch 518\n",
      "test_train\n",
      "train mean loss=62471.21640625\n",
      "test_test\n",
      "test mean loss=88300.31640625\n",
      "fin save.\n",
      "epoch 519\n",
      "test_train\n",
      "train mean loss=63121.397135416664\n",
      "test_test\n",
      "test mean loss=88335.984375\n",
      "fin save.\n",
      "epoch 520\n",
      "test_train\n",
      "train mean loss=62031.686848958336\n",
      "test_test\n",
      "test mean loss=88610.7578125\n",
      "fin save.\n",
      "epoch 521\n",
      "test_train\n",
      "train mean loss=61459.49322916667\n",
      "test_test\n",
      "test mean loss=88783.3125\n",
      "fin save.\n",
      "epoch 522\n",
      "test_train\n",
      "train mean loss=62760.591796875\n",
      "test_test\n",
      "test mean loss=88666.8046875\n",
      "fin save.\n",
      "epoch 523\n",
      "test_train\n",
      "train mean loss=61702.972265625\n",
      "test_test\n",
      "test mean loss=88710.66015625\n",
      "fin save.\n",
      "epoch 524\n",
      "test_train\n",
      "train mean loss=61576.76510416667\n",
      "test_test\n",
      "test mean loss=89040.046875\n",
      "fin save.\n",
      "epoch 525\n",
      "test_train\n",
      "train mean loss=62484.51953125\n",
      "test_test\n",
      "test mean loss=88745.421875\n",
      "fin save.\n",
      "epoch 526\n",
      "test_train\n",
      "train mean loss=62448.048046875\n",
      "test_test\n",
      "test mean loss=88731.77734375\n",
      "fin save.\n",
      "epoch 527\n",
      "test_train\n",
      "train mean loss=63153.46640625\n",
      "test_test\n",
      "test mean loss=88847.84765625\n",
      "fin save.\n",
      "epoch 528\n",
      "test_train\n",
      "train mean loss=62049.567057291664\n",
      "test_test\n",
      "test mean loss=89060.3046875\n",
      "fin save.\n",
      "epoch 529\n",
      "test_train\n",
      "train mean loss=62502.44427083333\n",
      "test_test\n",
      "test mean loss=88713.390625\n",
      "fin save.\n",
      "epoch 530\n",
      "test_train\n",
      "train mean loss=61683.77942708333\n",
      "test_test\n",
      "test mean loss=88567.515625\n",
      "fin save.\n",
      "epoch 531\n",
      "test_train\n",
      "train mean loss=62242.94375\n",
      "test_test\n",
      "test mean loss=88575.921875\n",
      "fin save.\n",
      "epoch 532\n",
      "test_train\n",
      "train mean loss=62886.25677083333\n",
      "test_test\n",
      "test mean loss=88611.69921875\n",
      "fin save.\n",
      "epoch 533\n",
      "test_train\n",
      "train mean loss=62002.336328125\n",
      "test_test\n",
      "test mean loss=88808.5546875\n",
      "fin save.\n",
      "epoch 534\n",
      "test_train\n",
      "train mean loss=61693.022135416664\n",
      "test_test\n",
      "test mean loss=88929.34765625\n",
      "fin save.\n",
      "epoch 535\n",
      "test_train\n",
      "train mean loss=61862.59088541667\n",
      "test_test\n",
      "test mean loss=88926.10546875\n",
      "fin save.\n",
      "epoch 536\n",
      "test_train\n",
      "train mean loss=62183.90416666667\n",
      "test_test\n",
      "test mean loss=88764.21484375\n",
      "fin save.\n",
      "epoch 537\n",
      "test_train\n",
      "train mean loss=62312.19583333333\n",
      "test_test\n",
      "test mean loss=88402.94140625\n",
      "fin save.\n",
      "epoch 538\n",
      "test_train\n",
      "train mean loss=61511.560546875\n",
      "test_test\n",
      "test mean loss=88481.109375\n",
      "fin save.\n",
      "epoch 539\n",
      "test_train\n",
      "train mean loss=63127.79388020833\n",
      "test_test\n",
      "test mean loss=88430.046875\n",
      "fin save.\n",
      "epoch 540\n",
      "test_train\n",
      "train mean loss=62905.19479166667\n",
      "test_test\n",
      "test mean loss=88247.13671875\n",
      "fin save.\n",
      "epoch 541\n",
      "test_train\n",
      "train mean loss=62190.14244791667\n",
      "test_test\n",
      "test mean loss=88283.140625\n",
      "fin save.\n",
      "epoch 542\n",
      "test_train\n",
      "train mean loss=61837.394270833334\n",
      "test_test\n",
      "test mean loss=87728.96484375\n",
      "fin save.\n",
      "epoch 543\n",
      "test_train\n",
      "train mean loss=61048.3890625\n",
      "test_test\n",
      "test mean loss=87653.25390625\n",
      "fin save.\n",
      "epoch 544\n",
      "test_train\n",
      "train mean loss=62005.29869791667\n",
      "test_test\n",
      "test mean loss=87569.33984375\n",
      "fin save.\n",
      "epoch 545\n",
      "test_train\n",
      "train mean loss=62295.87057291667\n",
      "test_test\n",
      "test mean loss=87619.3359375\n",
      "fin save.\n",
      "epoch 546\n",
      "test_train\n",
      "train mean loss=62854.88463541667\n",
      "test_test\n",
      "test mean loss=87692.9296875\n",
      "fin save.\n",
      "epoch 547\n",
      "test_train\n",
      "train mean loss=61854.35703125\n",
      "test_test\n",
      "test mean loss=87657.70703125\n",
      "fin save.\n",
      "epoch 548\n",
      "test_train\n",
      "train mean loss=62148.0171875\n",
      "test_test\n",
      "test mean loss=87791.484375\n",
      "fin save.\n",
      "epoch 549\n",
      "test_train\n",
      "train mean loss=62744.57630208333\n",
      "test_test\n",
      "test mean loss=87960.09375\n",
      "fin save.\n",
      "epoch 550\n",
      "test_train\n",
      "train mean loss=60758.01953125\n",
      "test_test\n",
      "test mean loss=87873.03515625\n",
      "fin save.\n",
      "epoch 551\n",
      "test_train\n",
      "train mean loss=62247.356770833336\n",
      "test_test\n",
      "test mean loss=87861.04296875\n",
      "fin save.\n",
      "epoch 552\n",
      "test_train\n",
      "train mean loss=62907.51901041667\n",
      "test_test\n",
      "test mean loss=87896.609375\n",
      "fin save.\n",
      "epoch 553\n",
      "test_train\n",
      "train mean loss=62451.78411458333\n",
      "test_test\n",
      "test mean loss=87517.3203125\n",
      "fin save.\n",
      "epoch 554\n",
      "test_train\n",
      "train mean loss=61721.531510416666\n",
      "test_test\n",
      "test mean loss=87707.83203125\n",
      "fin save.\n",
      "epoch 555\n",
      "test_train\n",
      "train mean loss=61062.71692708333\n",
      "test_test\n",
      "test mean loss=87899.76171875\n",
      "fin save.\n",
      "epoch 556\n",
      "test_train\n",
      "train mean loss=61565.68645833333\n",
      "test_test\n",
      "test mean loss=86933.16796875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fin save.\n",
      "epoch 557\n",
      "test_train\n",
      "train mean loss=62213.791666666664\n",
      "test_test\n",
      "test mean loss=87077.68359375\n",
      "fin save.\n",
      "epoch 558\n",
      "test_train\n",
      "train mean loss=60936.66223958333\n",
      "test_test\n",
      "test mean loss=87050.10546875\n",
      "fin save.\n",
      "epoch 559\n",
      "test_train\n",
      "train mean loss=62595.62161458333\n",
      "test_test\n",
      "test mean loss=87277.75\n",
      "fin save.\n",
      "epoch 560\n",
      "test_train\n",
      "train mean loss=61221.25104166667\n",
      "test_test\n",
      "test mean loss=87061.6953125\n",
      "fin save.\n",
      "epoch 561\n",
      "test_train\n",
      "train mean loss=62423.979166666664\n",
      "test_test\n",
      "test mean loss=86795.97265625\n",
      "fin save.\n",
      "epoch 562\n",
      "test_train\n",
      "train mean loss=62738.24114583333\n",
      "test_test\n",
      "test mean loss=86566.0\n",
      "fin save.\n",
      "epoch 563\n",
      "test_train\n",
      "train mean loss=62108.80716145833\n",
      "test_test\n",
      "test mean loss=86841.21484375\n",
      "fin save.\n",
      "epoch 564\n",
      "test_train\n",
      "train mean loss=62302.55130208333\n",
      "test_test\n",
      "test mean loss=86858.29296875\n",
      "fin save.\n",
      "epoch 565\n",
      "test_train\n",
      "train mean loss=62038.11328125\n",
      "test_test\n",
      "test mean loss=86393.93359375\n",
      "fin save.\n",
      "epoch 566\n",
      "test_train\n",
      "train mean loss=62015.68567708333\n",
      "test_test\n",
      "test mean loss=86780.0234375\n",
      "fin save.\n",
      "epoch 567\n",
      "test_train\n",
      "train mean loss=62450.665234375\n",
      "test_test\n",
      "test mean loss=86890.0\n",
      "fin save.\n",
      "epoch 568\n",
      "test_train\n",
      "train mean loss=61833.103255208334\n",
      "test_test\n",
      "test mean loss=86919.49609375\n",
      "fin save.\n",
      "epoch 569\n",
      "test_train\n",
      "train mean loss=63477.62942708333\n",
      "test_test\n",
      "test mean loss=86819.91796875\n",
      "fin save.\n",
      "epoch 570\n",
      "test_train\n",
      "train mean loss=61686.279296875\n",
      "test_test\n",
      "test mean loss=86643.5\n",
      "fin save.\n",
      "epoch 571\n",
      "test_train\n",
      "train mean loss=62446.02838541667\n",
      "test_test\n",
      "test mean loss=86646.8046875\n",
      "fin save.\n",
      "epoch 572\n",
      "test_train\n",
      "train mean loss=62756.92877604167\n",
      "test_test\n",
      "test mean loss=86528.8359375\n",
      "fin save.\n",
      "epoch 573\n",
      "test_train\n",
      "train mean loss=62706.143229166664\n",
      "test_test\n",
      "test mean loss=86487.9140625\n",
      "fin save.\n",
      "epoch 574\n",
      "test_train\n",
      "train mean loss=62665.95026041667\n",
      "test_test\n",
      "test mean loss=86897.84375\n",
      "fin save.\n",
      "epoch 575\n",
      "test_train\n",
      "train mean loss=61923.46627604167\n",
      "test_test\n",
      "test mean loss=86864.48046875\n",
      "fin save.\n",
      "epoch 576\n",
      "test_train\n",
      "train mean loss=62584.88984375\n",
      "test_test\n",
      "test mean loss=86741.71875\n",
      "fin save.\n",
      "epoch 577\n",
      "test_train\n",
      "train mean loss=62741.671875\n",
      "test_test\n",
      "test mean loss=86684.7109375\n",
      "fin save.\n",
      "epoch 578\n",
      "test_train\n",
      "train mean loss=61545.28020833333\n",
      "test_test\n",
      "test mean loss=86527.5078125\n",
      "fin save.\n",
      "epoch 579\n",
      "test_train\n",
      "train mean loss=62552.42877604167\n",
      "test_test\n",
      "test mean loss=86515.34375\n",
      "fin save.\n",
      "epoch 580\n",
      "test_train\n",
      "train mean loss=62333.64049479167\n",
      "test_test\n",
      "test mean loss=86454.07421875\n",
      "fin save.\n",
      "epoch 581\n",
      "test_train\n",
      "train mean loss=62028.7890625\n",
      "test_test\n",
      "test mean loss=86913.4140625\n",
      "fin save.\n",
      "epoch 582\n",
      "test_train\n",
      "train mean loss=62602.29296875\n",
      "test_test\n",
      "test mean loss=87022.35546875\n",
      "fin save.\n",
      "epoch 583\n",
      "test_train\n",
      "train mean loss=61644.640625\n",
      "test_test\n",
      "test mean loss=87038.68359375\n",
      "fin save.\n",
      "epoch 584\n",
      "test_train\n",
      "train mean loss=62128.37213541667\n",
      "test_test\n",
      "test mean loss=87051.05078125\n",
      "fin save.\n",
      "epoch 585\n",
      "test_train\n",
      "train mean loss=62580.86640625\n",
      "test_test\n",
      "test mean loss=86603.87890625\n",
      "fin save.\n",
      "epoch 586\n",
      "test_train\n",
      "train mean loss=62302.0828125\n",
      "test_test\n",
      "test mean loss=86454.4765625\n",
      "fin save.\n",
      "epoch 587\n",
      "test_train\n",
      "train mean loss=61536.321484375\n",
      "test_test\n",
      "test mean loss=86787.65625\n",
      "fin save.\n",
      "epoch 588\n",
      "test_train\n",
      "train mean loss=61548.13138020833\n",
      "test_test\n",
      "test mean loss=86691.4609375\n",
      "fin save.\n",
      "epoch 589\n",
      "test_train\n",
      "train mean loss=61309.80572916667\n",
      "test_test\n",
      "test mean loss=86649.7421875\n",
      "fin save.\n",
      "epoch 590\n",
      "test_train\n",
      "train mean loss=61653.48190104167\n",
      "test_test\n",
      "test mean loss=86687.27734375\n",
      "fin save.\n",
      "epoch 591\n",
      "test_train\n",
      "train mean loss=63094.66744791667\n",
      "test_test\n",
      "test mean loss=86693.76953125\n",
      "fin save.\n",
      "epoch 592\n",
      "test_train\n",
      "train mean loss=62000.68828125\n",
      "test_test\n",
      "test mean loss=86756.6484375\n",
      "fin save.\n",
      "epoch 593\n",
      "test_train\n",
      "train mean loss=62496.161458333336\n",
      "test_test\n",
      "test mean loss=86616.1875\n",
      "fin save.\n",
      "epoch 594\n",
      "test_train\n",
      "train mean loss=61523.34322916667\n",
      "test_test\n",
      "test mean loss=86893.0\n",
      "fin save.\n",
      "epoch 595\n",
      "test_train\n",
      "train mean loss=63180.4859375\n",
      "test_test\n",
      "test mean loss=86640.9609375\n",
      "fin save.\n",
      "epoch 596\n",
      "test_train\n",
      "train mean loss=61882.75533854167\n",
      "test_test\n",
      "test mean loss=86690.921875\n",
      "fin save.\n",
      "epoch 597\n",
      "test_train\n",
      "train mean loss=62751.58111979167\n",
      "test_test\n",
      "test mean loss=87142.1328125\n",
      "fin save.\n",
      "epoch 598\n",
      "test_train\n",
      "train mean loss=61466.572916666664\n",
      "test_test\n",
      "test mean loss=86714.2734375\n",
      "fin save.\n",
      "epoch 599\n",
      "test_train\n",
      "train mean loss=62466.93932291667\n",
      "test_test\n",
      "test mean loss=86598.67578125\n",
      "fin save.\n",
      "epoch 600\n",
      "test_train\n",
      "train mean loss=61225.678515625\n",
      "test_test\n",
      "test mean loss=86012.00390625\n",
      "fin save.\n",
      "epoch 601\n",
      "test_train\n",
      "train mean loss=62357.54153645833\n",
      "test_test\n",
      "test mean loss=86251.54296875\n",
      "fin save.\n",
      "epoch 602\n",
      "test_train\n",
      "train mean loss=62316.58046875\n",
      "test_test\n",
      "test mean loss=86198.58203125\n",
      "fin save.\n",
      "epoch 603\n",
      "test_train\n",
      "train mean loss=61831.497786458334\n",
      "test_test\n",
      "test mean loss=87009.484375\n",
      "fin save.\n",
      "epoch 604\n",
      "test_train\n",
      "train mean loss=62557.51354166667\n",
      "test_test\n",
      "test mean loss=87002.83203125\n",
      "fin save.\n",
      "epoch 605\n",
      "test_train\n",
      "train mean loss=61648.81484375\n",
      "test_test\n",
      "test mean loss=87006.8203125\n",
      "fin save.\n",
      "epoch 606\n",
      "test_train\n",
      "train mean loss=61675.238541666666\n",
      "test_test\n",
      "test mean loss=86808.21484375\n",
      "fin save.\n",
      "epoch 607\n",
      "test_train\n",
      "train mean loss=62094.39309895833\n",
      "test_test\n",
      "test mean loss=87366.08984375\n",
      "fin save.\n",
      "epoch 608\n",
      "test_train\n",
      "train mean loss=61335.745442708336\n",
      "test_test\n",
      "test mean loss=87106.1015625\n",
      "fin save.\n",
      "epoch 609\n",
      "test_train\n",
      "train mean loss=62235.419921875\n",
      "test_test\n",
      "test mean loss=87068.5390625\n",
      "fin save.\n",
      "epoch 610\n",
      "test_train\n",
      "train mean loss=62486.33489583333\n",
      "test_test\n",
      "test mean loss=87046.5859375\n",
      "fin save.\n",
      "epoch 611\n",
      "test_train\n",
      "train mean loss=61857.26354166667\n",
      "test_test\n",
      "test mean loss=87060.48828125\n",
      "fin save.\n",
      "epoch 612\n",
      "test_train\n",
      "train mean loss=62785.392317708334\n",
      "test_test\n",
      "test mean loss=87200.625\n",
      "fin save.\n",
      "epoch 613\n",
      "test_train\n",
      "train mean loss=62149.962890625\n",
      "test_test\n",
      "test mean loss=87691.390625\n",
      "fin save.\n",
      "epoch 614\n",
      "test_train\n",
      "train mean loss=62448.20260416667\n",
      "test_test\n",
      "test mean loss=87114.03125\n",
      "fin save.\n",
      "epoch 615\n",
      "test_train\n",
      "train mean loss=62641.398177083334\n",
      "test_test\n",
      "test mean loss=87357.609375\n",
      "fin save.\n",
      "epoch 616\n",
      "test_train\n",
      "train mean loss=62601.353125\n",
      "test_test\n",
      "test mean loss=87570.37109375\n",
      "fin save.\n",
      "epoch 617\n",
      "test_train\n",
      "train mean loss=62119.398697916666\n",
      "test_test\n",
      "test mean loss=87436.046875\n",
      "fin save.\n",
      "epoch 618\n",
      "test_train\n",
      "train mean loss=62405.103776041666\n",
      "test_test\n",
      "test mean loss=87445.01953125\n",
      "fin save.\n",
      "epoch 619\n",
      "test_train\n",
      "train mean loss=62166.79895833333\n",
      "test_test\n",
      "test mean loss=87290.38671875\n",
      "fin save.\n",
      "epoch 620\n",
      "test_train\n",
      "train mean loss=63246.770833333336\n",
      "test_test\n",
      "test mean loss=87088.96484375\n",
      "fin save.\n",
      "epoch 621\n",
      "test_train\n",
      "train mean loss=61125.57708333333\n",
      "test_test\n",
      "test mean loss=87541.46875\n",
      "fin save.\n",
      "epoch 622\n",
      "test_train\n",
      "train mean loss=62673.92890625\n",
      "test_test\n",
      "test mean loss=87216.0625\n",
      "fin save.\n",
      "epoch 623\n",
      "test_train\n",
      "train mean loss=61479.35546875\n",
      "test_test\n",
      "test mean loss=87202.51953125\n",
      "fin save.\n",
      "epoch 624\n",
      "test_train\n",
      "train mean loss=62433.54830729167\n",
      "test_test\n",
      "test mean loss=87064.625\n",
      "fin save.\n",
      "epoch 625\n",
      "test_train\n",
      "train mean loss=62280.485677083336\n",
      "test_test\n",
      "test mean loss=86970.72265625\n",
      "fin save.\n",
      "epoch 626\n",
      "test_train\n",
      "train mean loss=62739.28958333333\n",
      "test_test\n",
      "test mean loss=86973.5234375\n",
      "fin save.\n",
      "epoch 627\n",
      "test_train\n",
      "train mean loss=61423.520833333336\n",
      "test_test\n",
      "test mean loss=87042.98046875\n",
      "fin save.\n",
      "epoch 628\n",
      "test_train\n",
      "train mean loss=62392.15625\n",
      "test_test\n",
      "test mean loss=87112.75\n",
      "fin save.\n",
      "epoch 629\n",
      "test_train\n",
      "train mean loss=62630.88177083333\n",
      "test_test\n",
      "test mean loss=87155.28515625\n",
      "fin save.\n",
      "epoch 630\n",
      "test_train\n",
      "train mean loss=62107.846354166664\n",
      "test_test\n",
      "test mean loss=87362.23046875\n",
      "fin save.\n",
      "epoch 631\n",
      "test_train\n",
      "train mean loss=62688.509375\n",
      "test_test\n",
      "test mean loss=87259.77734375\n",
      "fin save.\n",
      "epoch 632\n",
      "test_train\n",
      "train mean loss=62245.62994791667\n",
      "test_test\n",
      "test mean loss=87343.94921875\n",
      "fin save.\n",
      "epoch 633\n",
      "test_train\n",
      "train mean loss=62355.659765625\n",
      "test_test\n",
      "test mean loss=87353.3671875\n",
      "fin save.\n",
      "epoch 634\n",
      "test_train\n",
      "train mean loss=61761.582682291664\n",
      "test_test\n",
      "test mean loss=87323.33984375\n",
      "fin save.\n",
      "epoch 635\n",
      "test_train\n",
      "train mean loss=61988.54479166667\n",
      "test_test\n",
      "test mean loss=87342.15625\n",
      "fin save.\n",
      "epoch 636\n",
      "test_train\n",
      "train mean loss=61477.58046875\n",
      "test_test\n",
      "test mean loss=87315.421875\n",
      "fin save.\n",
      "epoch 637\n",
      "test_train\n",
      "train mean loss=62401.82265625\n",
      "test_test\n",
      "test mean loss=87252.234375\n",
      "fin save.\n",
      "epoch 638\n",
      "test_train\n",
      "train mean loss=63248.51184895833\n",
      "test_test\n",
      "test mean loss=87265.53125\n",
      "fin save.\n",
      "epoch 639\n",
      "test_train\n",
      "train mean loss=61392.4265625\n",
      "test_test\n",
      "test mean loss=87350.2578125\n",
      "fin save.\n",
      "epoch 640\n",
      "test_train\n",
      "train mean loss=62807.72447916667\n",
      "test_test\n",
      "test mean loss=87309.703125\n",
      "fin save.\n",
      "epoch 641\n",
      "test_train\n",
      "train mean loss=62227.95859375\n",
      "test_test\n",
      "test mean loss=87180.02734375\n",
      "fin save.\n",
      "epoch 642\n",
      "test_train\n",
      "train mean loss=62082.79739583333\n",
      "test_test\n",
      "test mean loss=87209.56640625\n",
      "fin save.\n",
      "epoch 643\n",
      "test_train\n",
      "train mean loss=61613.58580729167\n",
      "test_test\n",
      "test mean loss=86999.9609375\n",
      "fin save.\n",
      "epoch 644\n",
      "test_train\n",
      "train mean loss=61648.864583333336\n",
      "test_test\n",
      "test mean loss=86903.42578125\n",
      "fin save.\n",
      "epoch 645\n",
      "test_train\n",
      "train mean loss=62346.683854166666\n",
      "test_test\n",
      "test mean loss=87003.4375\n",
      "fin save.\n",
      "epoch 646\n",
      "test_train\n",
      "train mean loss=62132.16796875\n",
      "test_test\n",
      "test mean loss=86950.078125\n",
      "fin save.\n",
      "epoch 647\n",
      "test_train\n",
      "train mean loss=61968.958333333336\n",
      "test_test\n",
      "test mean loss=87039.765625\n",
      "fin save.\n",
      "epoch 648\n",
      "test_train\n",
      "train mean loss=63165.10260416667\n",
      "test_test\n",
      "test mean loss=86873.26171875\n",
      "fin save.\n",
      "epoch 649\n",
      "test_train\n",
      "train mean loss=61747.14765625\n",
      "test_test\n",
      "test mean loss=87257.02734375\n",
      "fin save.\n",
      "epoch 650\n",
      "test_train\n",
      "train mean loss=62671.575520833336\n",
      "test_test\n",
      "test mean loss=87081.1328125\n",
      "fin save.\n",
      "epoch 651\n",
      "test_train\n",
      "train mean loss=61444.631510416664\n",
      "test_test\n",
      "test mean loss=87073.6796875\n",
      "fin save.\n",
      "epoch 652\n",
      "test_train\n",
      "train mean loss=62275.3453125\n",
      "test_test\n",
      "test mean loss=86965.390625\n",
      "fin save.\n",
      "epoch 653\n",
      "test_train\n",
      "train mean loss=62464.461197916666\n",
      "test_test\n",
      "test mean loss=86937.7578125\n",
      "fin save.\n",
      "epoch 654\n",
      "test_train\n",
      "train mean loss=62633.243359375\n",
      "test_test\n",
      "test mean loss=87083.45703125\n",
      "fin save.\n",
      "epoch 655\n",
      "test_train\n",
      "train mean loss=62650.03177083333\n",
      "test_test\n",
      "test mean loss=87177.28515625\n",
      "fin save.\n",
      "epoch 656\n",
      "test_train\n",
      "train mean loss=62317.93932291667\n",
      "test_test\n",
      "test mean loss=86986.92578125\n",
      "fin save.\n",
      "epoch 657\n",
      "test_train\n",
      "train mean loss=62402.225\n",
      "test_test\n",
      "test mean loss=86845.390625\n",
      "fin save.\n",
      "epoch 658\n",
      "test_train\n",
      "train mean loss=61152.12291666667\n",
      "test_test\n",
      "test mean loss=86823.6484375\n",
      "fin save.\n",
      "epoch 659\n",
      "test_train\n",
      "train mean loss=61798.44036458333\n",
      "test_test\n",
      "test mean loss=86836.46875\n",
      "fin save.\n",
      "epoch 660\n",
      "test_train\n",
      "train mean loss=62436.24375\n",
      "test_test\n",
      "test mean loss=86824.3046875\n",
      "fin save.\n",
      "epoch 661\n",
      "test_train\n",
      "train mean loss=61900.888671875\n",
      "test_test\n",
      "test mean loss=86872.9765625\n",
      "fin save.\n",
      "epoch 662\n",
      "test_train\n",
      "train mean loss=62317.84192708333\n",
      "test_test\n",
      "test mean loss=86891.1875\n",
      "fin save.\n",
      "epoch 663\n",
      "test_train\n",
      "train mean loss=63426.570572916666\n",
      "test_test\n",
      "test mean loss=86917.8828125\n",
      "fin save.\n",
      "epoch 664\n",
      "test_train\n",
      "train mean loss=62571.27421875\n",
      "test_test\n",
      "test mean loss=86791.16015625\n",
      "fin save.\n",
      "epoch 665\n",
      "test_train\n",
      "train mean loss=63058.83515625\n",
      "test_test\n",
      "test mean loss=86718.54296875\n",
      "fin save.\n",
      "epoch 666\n",
      "test_train\n",
      "train mean loss=62834.62604166667\n",
      "test_test\n",
      "test mean loss=86841.2734375\n",
      "fin save.\n",
      "epoch 667\n",
      "test_train\n",
      "train mean loss=62279.066796875\n",
      "test_test\n",
      "test mean loss=86853.046875\n",
      "fin save.\n",
      "epoch 668\n",
      "test_train\n",
      "train mean loss=62108.83645833333\n",
      "test_test\n",
      "test mean loss=86501.76171875\n",
      "fin save.\n",
      "epoch 669\n",
      "test_train\n",
      "train mean loss=62255.87682291667\n",
      "test_test\n",
      "test mean loss=86594.54296875\n",
      "fin save.\n",
      "epoch 670\n",
      "test_train\n",
      "train mean loss=62753.09166666667\n",
      "test_test\n",
      "test mean loss=86890.3671875\n",
      "fin save.\n",
      "epoch 671\n",
      "test_train\n",
      "train mean loss=62368.502734375\n",
      "test_test\n",
      "test mean loss=86914.03515625\n",
      "fin save.\n",
      "epoch 672\n",
      "test_train\n",
      "train mean loss=61505.656510416666\n",
      "test_test\n",
      "test mean loss=86950.578125\n",
      "fin save.\n",
      "epoch 673\n",
      "test_train\n",
      "train mean loss=62904.19713541667\n",
      "test_test\n",
      "test mean loss=87138.2109375\n",
      "fin save.\n",
      "epoch 674\n",
      "test_train\n",
      "train mean loss=63066.26744791667\n",
      "test_test\n",
      "test mean loss=87082.57421875\n",
      "fin save.\n",
      "epoch 675\n",
      "test_train\n",
      "train mean loss=62215.23359375\n",
      "test_test\n",
      "test mean loss=87145.56640625\n",
      "fin save.\n",
      "epoch 676\n",
      "test_train\n",
      "train mean loss=62581.11966145833\n",
      "test_test\n",
      "test mean loss=87082.88671875\n",
      "fin save.\n",
      "epoch 677\n",
      "test_train\n",
      "train mean loss=61397.771875\n",
      "test_test\n",
      "test mean loss=86042.7890625\n",
      "fin save.\n",
      "epoch 678\n",
      "test_train\n",
      "train mean loss=62644.464583333334\n",
      "test_test\n",
      "test mean loss=86135.79296875\n",
      "fin save.\n",
      "epoch 679\n",
      "test_train\n",
      "train mean loss=61573.16953125\n",
      "test_test\n",
      "test mean loss=85994.28125\n",
      "fin save.\n",
      "epoch 680\n",
      "test_train\n",
      "train mean loss=62345.75885416667\n",
      "test_test\n",
      "test mean loss=86131.37890625\n",
      "fin save.\n",
      "epoch 681\n",
      "test_train\n",
      "train mean loss=62860.864583333336\n",
      "test_test\n",
      "test mean loss=85890.84375\n",
      "fin save.\n",
      "epoch 682\n",
      "test_train\n",
      "train mean loss=61482.18802083333\n",
      "test_test\n",
      "test mean loss=85991.546875\n",
      "fin save.\n",
      "epoch 683\n",
      "test_train\n",
      "train mean loss=62172.3953125\n",
      "test_test\n",
      "test mean loss=86175.78515625\n",
      "fin save.\n",
      "epoch 684\n",
      "test_train\n",
      "train mean loss=62923.305989583336\n",
      "test_test\n",
      "test mean loss=86309.56640625\n",
      "fin save.\n",
      "epoch 685\n",
      "test_train\n",
      "train mean loss=62876.025390625\n",
      "test_test\n",
      "test mean loss=86175.60546875\n",
      "fin save.\n",
      "epoch 686\n",
      "test_train\n",
      "train mean loss=63134.28424479167\n",
      "test_test\n",
      "test mean loss=86057.63671875\n",
      "fin save.\n",
      "epoch 687\n",
      "test_train\n",
      "train mean loss=62607.14453125\n",
      "test_test\n",
      "test mean loss=85856.66796875\n",
      "fin save.\n",
      "epoch 688\n",
      "test_train\n",
      "train mean loss=63168.972916666666\n",
      "test_test\n",
      "test mean loss=85937.15234375\n",
      "fin save.\n",
      "epoch 689\n",
      "test_train\n",
      "train mean loss=62218.76953125\n",
      "test_test\n",
      "test mean loss=86196.90234375\n",
      "fin save.\n",
      "epoch 690\n",
      "test_train\n",
      "train mean loss=62910.730729166666\n",
      "test_test\n",
      "test mean loss=85978.6640625\n",
      "fin save.\n",
      "epoch 691\n",
      "test_train\n",
      "train mean loss=62809.398046875\n",
      "test_test\n",
      "test mean loss=85867.47265625\n",
      "fin save.\n",
      "epoch 692\n",
      "test_train\n",
      "train mean loss=62533.09479166667\n",
      "test_test\n",
      "test mean loss=85941.58203125\n",
      "fin save.\n",
      "epoch 693\n",
      "test_train\n",
      "train mean loss=63509.547135416666\n",
      "test_test\n",
      "test mean loss=86130.7421875\n",
      "fin save.\n",
      "epoch 694\n",
      "test_train\n",
      "train mean loss=62569.750651041664\n",
      "test_test\n",
      "test mean loss=86020.0546875\n",
      "fin save.\n",
      "epoch 695\n",
      "test_train\n",
      "train mean loss=63579.561197916664\n",
      "test_test\n",
      "test mean loss=85888.86328125\n",
      "fin save.\n",
      "epoch 696\n",
      "test_train\n",
      "train mean loss=62254.640625\n",
      "test_test\n",
      "test mean loss=86054.078125\n",
      "fin save.\n",
      "epoch 697\n",
      "test_train\n",
      "train mean loss=62514.53333333333\n",
      "test_test\n",
      "test mean loss=86031.82421875\n",
      "fin save.\n",
      "epoch 698\n",
      "test_train\n",
      "train mean loss=62186.655989583334\n",
      "test_test\n",
      "test mean loss=86118.0234375\n",
      "fin save.\n",
      "epoch 699\n",
      "test_train\n",
      "train mean loss=62797.03411458333\n",
      "test_test\n",
      "test mean loss=86196.4609375\n",
      "fin save.\n",
      "epoch 700\n",
      "test_train\n",
      "train mean loss=62210.259765625\n",
      "test_test\n",
      "test mean loss=86080.50390625\n",
      "fin save.\n",
      "epoch 701\n",
      "test_train\n",
      "train mean loss=62555.60755208333\n",
      "test_test\n",
      "test mean loss=86129.9453125\n",
      "fin save.\n",
      "epoch 702\n",
      "test_train\n",
      "train mean loss=62132.87578125\n",
      "test_test\n",
      "test mean loss=85882.5\n",
      "fin save.\n",
      "epoch 703\n",
      "test_train\n",
      "train mean loss=62258.672135416666\n",
      "test_test\n",
      "test mean loss=85892.90234375\n",
      "fin save.\n",
      "epoch 704\n",
      "test_train\n",
      "train mean loss=62881.90078125\n",
      "test_test\n",
      "test mean loss=85887.8515625\n",
      "fin save.\n",
      "epoch 705\n",
      "test_train\n",
      "train mean loss=62599.41119791667\n",
      "test_test\n",
      "test mean loss=86039.66015625\n",
      "fin save.\n",
      "epoch 706\n",
      "test_train\n",
      "train mean loss=62553.53463541667\n",
      "test_test\n",
      "test mean loss=86096.7890625\n",
      "fin save.\n",
      "epoch 707\n",
      "test_train\n",
      "train mean loss=61730.161458333336\n",
      "test_test\n",
      "test mean loss=85781.41015625\n",
      "fin save.\n",
      "epoch 708\n",
      "test_train\n",
      "train mean loss=62194.73619791667\n",
      "test_test\n",
      "test mean loss=85717.56640625\n",
      "fin save.\n",
      "epoch 709\n",
      "test_train\n",
      "train mean loss=62278.09036458333\n",
      "test_test\n",
      "test mean loss=85841.8046875\n",
      "fin save.\n",
      "epoch 710\n",
      "test_train\n",
      "train mean loss=62756.847916666666\n",
      "test_test\n",
      "test mean loss=85942.90625\n",
      "fin save.\n",
      "epoch 711\n",
      "test_train\n",
      "train mean loss=61824.40703125\n",
      "test_test\n",
      "test mean loss=86118.6328125\n",
      "fin save.\n",
      "epoch 712\n",
      "test_train\n",
      "train mean loss=62808.25546875\n",
      "test_test\n",
      "test mean loss=86766.703125\n",
      "fin save.\n",
      "epoch 713\n",
      "test_train\n",
      "train mean loss=62899.38958333333\n",
      "test_test\n",
      "test mean loss=86726.17578125\n",
      "fin save.\n",
      "epoch 714\n",
      "test_train\n",
      "train mean loss=62212.84973958333\n",
      "test_test\n",
      "test mean loss=86472.78515625\n",
      "fin save.\n",
      "epoch 715\n",
      "test_train\n",
      "train mean loss=61489.60338541667\n",
      "test_test\n",
      "test mean loss=86577.45703125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fin save.\n",
      "epoch 716\n",
      "test_train\n",
      "train mean loss=62617.334375\n",
      "test_test\n",
      "test mean loss=86557.00390625\n",
      "fin save.\n",
      "epoch 717\n",
      "test_train\n",
      "train mean loss=62968.32864583333\n",
      "test_test\n",
      "test mean loss=86507.0703125\n",
      "fin save.\n",
      "epoch 718\n",
      "test_train\n",
      "train mean loss=61714.89401041667\n",
      "test_test\n",
      "test mean loss=86534.04296875\n",
      "fin save.\n",
      "epoch 719\n",
      "test_train\n",
      "train mean loss=62533.371354166666\n",
      "test_test\n",
      "test mean loss=86449.95703125\n",
      "fin save.\n",
      "epoch 720\n",
      "test_train\n",
      "train mean loss=62659.11901041667\n",
      "test_test\n",
      "test mean loss=86342.24609375\n",
      "fin save.\n",
      "epoch 721\n",
      "test_train\n",
      "train mean loss=62691.66106770833\n",
      "test_test\n",
      "test mean loss=86672.74609375\n",
      "fin save.\n",
      "epoch 722\n",
      "test_train\n",
      "train mean loss=62282.14375\n",
      "test_test\n",
      "test mean loss=86561.86328125\n",
      "fin save.\n",
      "epoch 723\n",
      "test_train\n",
      "train mean loss=62190.640364583334\n",
      "test_test\n",
      "test mean loss=86422.18359375\n",
      "fin save.\n",
      "epoch 724\n",
      "test_train\n",
      "train mean loss=62485.95703125\n",
      "test_test\n",
      "test mean loss=86153.2109375\n",
      "fin save.\n",
      "epoch 725\n",
      "test_train\n",
      "train mean loss=62696.4375\n",
      "test_test\n",
      "test mean loss=86272.80078125\n",
      "fin save.\n",
      "epoch 726\n",
      "test_train\n",
      "train mean loss=63309.99375\n",
      "test_test\n",
      "test mean loss=86218.890625\n",
      "fin save.\n",
      "epoch 727\n",
      "test_train\n",
      "train mean loss=63483.14401041667\n",
      "test_test\n",
      "test mean loss=86355.33984375\n",
      "fin save.\n",
      "epoch 728\n",
      "test_train\n",
      "train mean loss=63964.996744791664\n",
      "test_test\n",
      "test mean loss=86421.0625\n",
      "fin save.\n",
      "epoch 729\n",
      "test_train\n",
      "train mean loss=62864.987109375\n",
      "test_test\n",
      "test mean loss=86766.9765625\n",
      "fin save.\n",
      "epoch 730\n",
      "test_train\n",
      "train mean loss=62436.613020833334\n",
      "test_test\n",
      "test mean loss=86590.640625\n",
      "fin save.\n",
      "epoch 731\n",
      "test_train\n",
      "train mean loss=62637.22864583333\n",
      "test_test\n",
      "test mean loss=86539.6953125\n",
      "fin save.\n",
      "epoch 732\n",
      "test_train\n",
      "train mean loss=62824.91106770833\n",
      "test_test\n",
      "test mean loss=86431.62109375\n",
      "fin save.\n",
      "epoch 733\n",
      "test_train\n",
      "train mean loss=63210.61471354167\n",
      "test_test\n",
      "test mean loss=86445.66796875\n",
      "fin save.\n",
      "epoch 734\n",
      "test_train\n",
      "train mean loss=63021.80286458333\n",
      "test_test\n",
      "test mean loss=86364.9140625\n",
      "fin save.\n",
      "epoch 735\n",
      "test_train\n",
      "train mean loss=62334.40677083333\n",
      "test_test\n",
      "test mean loss=86443.64453125\n",
      "fin save.\n",
      "epoch 736\n",
      "test_train\n",
      "train mean loss=62453.459244791666\n",
      "test_test\n",
      "test mean loss=86498.0546875\n",
      "fin save.\n",
      "epoch 737\n",
      "test_train\n",
      "train mean loss=62688.51015625\n",
      "test_test\n",
      "test mean loss=86359.66796875\n",
      "fin save.\n",
      "epoch 738\n",
      "test_train\n",
      "train mean loss=62128.869791666664\n",
      "test_test\n",
      "test mean loss=86527.859375\n",
      "fin save.\n",
      "epoch 739\n",
      "test_train\n",
      "train mean loss=63012.40638020833\n",
      "test_test\n",
      "test mean loss=86183.23828125\n",
      "fin save.\n",
      "epoch 740\n",
      "test_train\n",
      "train mean loss=62738.794270833336\n",
      "test_test\n",
      "test mean loss=86457.59765625\n",
      "fin save.\n",
      "epoch 741\n",
      "test_train\n",
      "train mean loss=62445.29921875\n",
      "test_test\n",
      "test mean loss=86508.0703125\n",
      "fin save.\n",
      "epoch 742\n",
      "test_train\n",
      "train mean loss=61975.20364583333\n",
      "test_test\n",
      "test mean loss=86298.12109375\n",
      "fin save.\n",
      "epoch 743\n",
      "test_train\n",
      "train mean loss=63140.17877604167\n",
      "test_test\n",
      "test mean loss=86269.92578125\n",
      "fin save.\n",
      "epoch 744\n",
      "test_train\n",
      "train mean loss=62339.06588541667\n",
      "test_test\n",
      "test mean loss=86454.3515625\n",
      "fin save.\n",
      "epoch 745\n",
      "test_train\n",
      "train mean loss=62030.0984375\n",
      "test_test\n",
      "test mean loss=86551.6953125\n",
      "fin save.\n",
      "epoch 746\n",
      "test_train\n",
      "train mean loss=62882.23932291667\n",
      "test_test\n",
      "test mean loss=86272.20703125\n",
      "fin save.\n",
      "epoch 747\n",
      "test_train\n",
      "train mean loss=62413.66510416667\n",
      "test_test\n",
      "test mean loss=86144.3515625\n",
      "fin save.\n",
      "epoch 748\n",
      "test_train\n",
      "train mean loss=63210.83307291667\n",
      "test_test\n",
      "test mean loss=86359.78515625\n",
      "fin save.\n",
      "epoch 749\n",
      "test_train\n",
      "train mean loss=62634.655078125\n",
      "test_test\n",
      "test mean loss=86470.20703125\n",
      "fin save.\n",
      "epoch 750\n",
      "test_train\n",
      "train mean loss=62285.615885416664\n",
      "test_test\n",
      "test mean loss=86414.99609375\n",
      "fin save.\n",
      "epoch 751\n",
      "test_train\n",
      "train mean loss=62295.74895833333\n",
      "test_test\n",
      "test mean loss=86249.64453125\n",
      "fin save.\n",
      "epoch 752\n",
      "test_train\n",
      "train mean loss=62631.42526041667\n",
      "test_test\n",
      "test mean loss=86417.65625\n",
      "fin save.\n",
      "epoch 753\n",
      "test_train\n",
      "train mean loss=62393.96197916667\n",
      "test_test\n",
      "test mean loss=86545.76953125\n",
      "fin save.\n",
      "epoch 754\n",
      "test_train\n",
      "train mean loss=62650.975260416664\n",
      "test_test\n",
      "test mean loss=86462.734375\n",
      "fin save.\n",
      "epoch 755\n",
      "test_train\n",
      "train mean loss=63309.876302083336\n",
      "test_test\n",
      "test mean loss=86621.12890625\n",
      "fin save.\n",
      "epoch 756\n",
      "test_train\n",
      "train mean loss=61762.57916666667\n",
      "test_test\n",
      "test mean loss=86560.45703125\n",
      "fin save.\n",
      "epoch 757\n",
      "test_train\n",
      "train mean loss=63304.597395833334\n",
      "test_test\n",
      "test mean loss=86583.5078125\n",
      "fin save.\n",
      "epoch 758\n",
      "test_train\n",
      "train mean loss=63203.4046875\n",
      "test_test\n",
      "test mean loss=86523.96484375\n",
      "fin save.\n",
      "epoch 759\n",
      "test_train\n",
      "train mean loss=61602.94583333333\n",
      "test_test\n",
      "test mean loss=86380.79296875\n",
      "fin save.\n",
      "epoch 760\n",
      "test_train\n",
      "train mean loss=62057.179427083334\n",
      "test_test\n",
      "test mean loss=86687.171875\n",
      "fin save.\n",
      "epoch 761\n",
      "test_train\n",
      "train mean loss=63069.287760416664\n",
      "test_test\n",
      "test mean loss=87137.8046875\n",
      "fin save.\n",
      "epoch 762\n",
      "test_train\n",
      "train mean loss=62153.92890625\n",
      "test_test\n",
      "test mean loss=86989.171875\n",
      "fin save.\n",
      "epoch 763\n",
      "test_train\n",
      "train mean loss=62297.176041666666\n",
      "test_test\n",
      "test mean loss=86904.98828125\n",
      "fin save.\n",
      "epoch 764\n",
      "test_train\n",
      "train mean loss=62217.415364583336\n",
      "test_test\n",
      "test mean loss=87067.625\n",
      "fin save.\n",
      "epoch 765\n",
      "test_train\n",
      "train mean loss=62944.70989583333\n",
      "test_test\n",
      "test mean loss=87254.83984375\n",
      "fin save.\n",
      "epoch 766\n",
      "test_train\n",
      "train mean loss=62202.84817708333\n",
      "test_test\n",
      "test mean loss=87090.66015625\n",
      "fin save.\n",
      "epoch 767\n",
      "test_train\n",
      "train mean loss=62800.86614583333\n",
      "test_test\n",
      "test mean loss=86835.87890625\n",
      "fin save.\n",
      "epoch 768\n",
      "test_train\n",
      "train mean loss=61370.455729166664\n",
      "test_test\n",
      "test mean loss=87267.48046875\n",
      "fin save.\n",
      "epoch 769\n",
      "test_train\n",
      "train mean loss=61946.877604166664\n",
      "test_test\n",
      "test mean loss=87361.8359375\n",
      "fin save.\n",
      "epoch 770\n",
      "test_train\n",
      "train mean loss=62954.93463541667\n",
      "test_test\n",
      "test mean loss=87250.34765625\n",
      "fin save.\n",
      "epoch 771\n",
      "test_train\n",
      "train mean loss=63223.29921875\n",
      "test_test\n",
      "test mean loss=87307.6875\n",
      "fin save.\n",
      "epoch 772\n",
      "test_train\n",
      "train mean loss=61716.64830729167\n",
      "test_test\n",
      "test mean loss=87204.16796875\n",
      "fin save.\n",
      "epoch 773\n",
      "test_train\n",
      "train mean loss=62696.77161458333\n",
      "test_test\n",
      "test mean loss=87221.25\n",
      "fin save.\n",
      "epoch 774\n",
      "test_train\n",
      "train mean loss=61695.5046875\n",
      "test_test\n",
      "test mean loss=87094.62890625\n",
      "fin save.\n",
      "epoch 775\n",
      "test_train\n",
      "train mean loss=62178.8703125\n",
      "test_test\n",
      "test mean loss=87144.578125\n",
      "fin save.\n",
      "epoch 776\n",
      "test_train\n",
      "train mean loss=63310.605729166666\n",
      "test_test\n",
      "test mean loss=87279.3359375\n",
      "fin save.\n",
      "epoch 777\n",
      "test_train\n",
      "train mean loss=62158.34270833333\n",
      "test_test\n",
      "test mean loss=87235.9375\n",
      "fin save.\n",
      "epoch 778\n",
      "test_train\n",
      "train mean loss=62709.95078125\n",
      "test_test\n",
      "test mean loss=87049.33984375\n",
      "fin save.\n",
      "epoch 779\n",
      "test_train\n",
      "train mean loss=61518.46497395833\n",
      "test_test\n",
      "test mean loss=86992.41796875\n",
      "fin save.\n",
      "epoch 780\n",
      "test_train\n",
      "train mean loss=62284.32083333333\n",
      "test_test\n",
      "test mean loss=87177.58203125\n",
      "fin save.\n",
      "epoch 781\n",
      "test_train\n",
      "train mean loss=63013.78072916667\n",
      "test_test\n",
      "test mean loss=87131.3515625\n",
      "fin save.\n",
      "epoch 782\n",
      "test_train\n",
      "train mean loss=62784.4453125\n",
      "test_test\n",
      "test mean loss=87190.15234375\n",
      "fin save.\n",
      "epoch 783\n",
      "test_train\n",
      "train mean loss=61881.07109375\n",
      "test_test\n",
      "test mean loss=87059.2265625\n",
      "fin save.\n",
      "epoch 784\n",
      "test_train\n",
      "train mean loss=62260.130208333336\n",
      "test_test\n",
      "test mean loss=86921.89453125\n",
      "fin save.\n",
      "epoch 785\n",
      "test_train\n",
      "train mean loss=61498.85104166667\n",
      "test_test\n",
      "test mean loss=87390.64453125\n",
      "fin save.\n",
      "epoch 786\n",
      "test_train\n",
      "train mean loss=63000.365625\n",
      "test_test\n",
      "test mean loss=87504.39453125\n",
      "fin save.\n",
      "epoch 787\n",
      "test_train\n",
      "train mean loss=62026.90182291667\n",
      "test_test\n",
      "test mean loss=87523.44140625\n",
      "fin save.\n",
      "epoch 788\n",
      "test_train\n",
      "train mean loss=63108.226171875\n",
      "test_test\n",
      "test mean loss=87544.0703125\n",
      "fin save.\n",
      "epoch 789\n",
      "test_train\n",
      "train mean loss=63168.958333333336\n",
      "test_test\n",
      "test mean loss=87380.0703125\n",
      "fin save.\n",
      "epoch 790\n",
      "test_train\n",
      "train mean loss=61614.82473958333\n",
      "test_test\n",
      "test mean loss=87577.6171875\n",
      "fin save.\n",
      "epoch 791\n",
      "test_train\n",
      "train mean loss=63138.25598958333\n",
      "test_test\n",
      "test mean loss=87532.1171875\n",
      "fin save.\n",
      "epoch 792\n",
      "test_train\n",
      "train mean loss=62347.804947916666\n",
      "test_test\n",
      "test mean loss=87580.5234375\n",
      "fin save.\n",
      "epoch 793\n",
      "test_train\n",
      "train mean loss=62251.23125\n",
      "test_test\n",
      "test mean loss=87639.73046875\n",
      "fin save.\n",
      "epoch 794\n",
      "test_train\n",
      "train mean loss=62258.2390625\n",
      "test_test\n",
      "test mean loss=87609.4609375\n",
      "fin save.\n",
      "epoch 795\n",
      "test_train\n",
      "train mean loss=62155.58216145833\n",
      "test_test\n",
      "test mean loss=87858.703125\n",
      "fin save.\n",
      "epoch 796\n",
      "test_train\n",
      "train mean loss=63137.44296875\n",
      "test_test\n",
      "test mean loss=87542.92578125\n",
      "fin save.\n",
      "epoch 797\n",
      "test_train\n",
      "train mean loss=62394.48489583333\n",
      "test_test\n",
      "test mean loss=87538.4375\n",
      "fin save.\n",
      "epoch 798\n",
      "test_train\n",
      "train mean loss=61625.11041666667\n",
      "test_test\n",
      "test mean loss=87748.015625\n",
      "fin save.\n",
      "epoch 799\n",
      "test_train\n",
      "train mean loss=62520.77421875\n",
      "test_test\n",
      "test mean loss=87740.484375\n",
      "fin save.\n",
      "epoch 800\n",
      "test_train\n",
      "train mean loss=62306.52630208333\n",
      "test_test\n",
      "test mean loss=87667.30859375\n",
      "fin save.\n",
      "epoch 801\n",
      "test_train\n",
      "train mean loss=61742.740625\n",
      "test_test\n",
      "test mean loss=87773.36328125\n",
      "fin save.\n",
      "epoch 802\n",
      "test_train\n",
      "train mean loss=61662.812890625\n",
      "test_test\n",
      "test mean loss=87690.8828125\n",
      "fin save.\n",
      "epoch 803\n",
      "test_train\n",
      "train mean loss=62495.666796875\n",
      "test_test\n",
      "test mean loss=87634.6796875\n",
      "fin save.\n",
      "epoch 804\n",
      "test_train\n",
      "train mean loss=63134.315104166664\n",
      "test_test\n",
      "test mean loss=87970.2421875\n",
      "fin save.\n",
      "epoch 805\n",
      "test_train\n",
      "train mean loss=61985.30859375\n",
      "test_test\n",
      "test mean loss=87710.87890625\n",
      "fin save.\n",
      "epoch 806\n",
      "test_train\n",
      "train mean loss=61742.58411458333\n",
      "test_test\n",
      "test mean loss=87676.1953125\n",
      "fin save.\n",
      "epoch 807\n",
      "test_train\n",
      "train mean loss=62557.902604166666\n",
      "test_test\n",
      "test mean loss=87829.171875\n",
      "fin save.\n",
      "epoch 808\n",
      "test_train\n",
      "train mean loss=61817.153645833336\n",
      "test_test\n",
      "test mean loss=87583.28125\n",
      "fin save.\n",
      "epoch 809\n",
      "test_train\n",
      "train mean loss=63136.629557291664\n",
      "test_test\n",
      "test mean loss=87793.2578125\n",
      "fin save.\n",
      "epoch 810\n",
      "test_train\n",
      "train mean loss=62468.8625\n",
      "test_test\n",
      "test mean loss=87587.5703125\n",
      "fin save.\n",
      "epoch 811\n",
      "test_train\n",
      "train mean loss=62190.790364583336\n",
      "test_test\n",
      "test mean loss=87628.390625\n",
      "fin save.\n",
      "epoch 812\n",
      "test_train\n",
      "train mean loss=62381.172526041664\n",
      "test_test\n",
      "test mean loss=87218.16015625\n",
      "fin save.\n",
      "epoch 813\n",
      "test_train\n",
      "train mean loss=62082.60625\n",
      "test_test\n",
      "test mean loss=87031.7265625\n",
      "fin save.\n",
      "epoch 814\n",
      "test_train\n",
      "train mean loss=63568.9890625\n",
      "test_test\n",
      "test mean loss=87246.46484375\n",
      "fin save.\n",
      "epoch 815\n",
      "test_train\n",
      "train mean loss=62180.44778645833\n",
      "test_test\n",
      "test mean loss=87187.2734375\n",
      "fin save.\n",
      "epoch 816\n",
      "test_train\n",
      "train mean loss=62711.2984375\n",
      "test_test\n",
      "test mean loss=87590.24609375\n",
      "fin save.\n",
      "epoch 817\n",
      "test_train\n",
      "train mean loss=62337.379557291664\n",
      "test_test\n",
      "test mean loss=87368.8828125\n",
      "fin save.\n",
      "epoch 818\n",
      "test_train\n",
      "train mean loss=62006.76940104167\n",
      "test_test\n",
      "test mean loss=87358.76171875\n",
      "fin save.\n",
      "epoch 819\n",
      "test_train\n",
      "train mean loss=62013.44609375\n",
      "test_test\n",
      "test mean loss=87214.62109375\n",
      "fin save.\n",
      "epoch 820\n",
      "test_train\n",
      "train mean loss=62152.68203125\n",
      "test_test\n",
      "test mean loss=87107.89453125\n",
      "fin save.\n",
      "epoch 821\n",
      "test_train\n",
      "train mean loss=63319.89166666667\n",
      "test_test\n",
      "test mean loss=87181.7265625\n",
      "fin save.\n",
      "epoch 822\n",
      "test_train\n",
      "train mean loss=62304.48880208333\n",
      "test_test\n",
      "test mean loss=87293.83984375\n",
      "fin save.\n",
      "epoch 823\n",
      "test_train\n",
      "train mean loss=63194.578515625\n",
      "test_test\n",
      "test mean loss=87485.31640625\n",
      "fin save.\n",
      "epoch 824\n",
      "test_train\n",
      "train mean loss=61564.48541666667\n",
      "test_test\n",
      "test mean loss=87493.45703125\n",
      "fin save.\n",
      "epoch 825\n",
      "test_train\n",
      "train mean loss=62255.167708333334\n",
      "test_test\n",
      "test mean loss=87286.8671875\n",
      "fin save.\n",
      "epoch 826\n",
      "test_train\n",
      "train mean loss=62177.791666666664\n",
      "test_test\n",
      "test mean loss=87293.67578125\n",
      "fin save.\n",
      "epoch 827\n",
      "test_train\n",
      "train mean loss=62598.32578125\n",
      "test_test\n",
      "test mean loss=87422.4453125\n",
      "fin save.\n",
      "epoch 828\n",
      "test_train\n",
      "train mean loss=62046.29296875\n",
      "test_test\n",
      "test mean loss=87292.24609375\n",
      "fin save.\n",
      "epoch 829\n",
      "test_train\n",
      "train mean loss=64036.276953125\n",
      "test_test\n",
      "test mean loss=87375.28515625\n",
      "fin save.\n",
      "epoch 830\n",
      "test_train\n",
      "train mean loss=62124.794270833336\n",
      "test_test\n",
      "test mean loss=87494.6015625\n",
      "fin save.\n",
      "epoch 831\n",
      "test_train\n",
      "train mean loss=63030.37395833333\n",
      "test_test\n",
      "test mean loss=87446.91796875\n",
      "fin save.\n",
      "epoch 832\n",
      "test_train\n",
      "train mean loss=62814.890885416666\n",
      "test_test\n",
      "test mean loss=87514.37890625\n",
      "fin save.\n",
      "epoch 833\n",
      "test_train\n",
      "train mean loss=62273.73815104167\n",
      "test_test\n",
      "test mean loss=87644.76953125\n",
      "fin save.\n",
      "epoch 834\n",
      "test_train\n",
      "train mean loss=63607.01354166667\n",
      "test_test\n",
      "test mean loss=87535.015625\n",
      "fin save.\n",
      "epoch 835\n",
      "test_train\n",
      "train mean loss=63295.5296875\n",
      "test_test\n",
      "test mean loss=87587.765625\n",
      "fin save.\n",
      "epoch 836\n",
      "test_train\n",
      "train mean loss=62617.91640625\n",
      "test_test\n",
      "test mean loss=87538.171875\n",
      "fin save.\n",
      "epoch 837\n",
      "test_train\n",
      "train mean loss=62762.22317708333\n",
      "test_test\n",
      "test mean loss=87484.42578125\n",
      "fin save.\n",
      "epoch 838\n",
      "test_train\n",
      "train mean loss=62457.46184895833\n",
      "test_test\n",
      "test mean loss=87453.3984375\n",
      "fin save.\n",
      "epoch 839\n",
      "test_train\n",
      "train mean loss=62963.74609375\n",
      "test_test\n",
      "test mean loss=87475.1171875\n",
      "fin save.\n",
      "epoch 840\n",
      "test_train\n",
      "train mean loss=62501.80026041667\n",
      "test_test\n",
      "test mean loss=87507.5703125\n",
      "fin save.\n",
      "epoch 841\n",
      "test_train\n",
      "train mean loss=62556.740885416664\n",
      "test_test\n",
      "test mean loss=87766.72265625\n",
      "fin save.\n",
      "epoch 842\n",
      "test_train\n",
      "train mean loss=62840.0140625\n",
      "test_test\n",
      "test mean loss=87841.9296875\n",
      "fin save.\n",
      "epoch 843\n",
      "test_train\n",
      "train mean loss=62331.53046875\n",
      "test_test\n",
      "test mean loss=87666.09765625\n",
      "fin save.\n",
      "epoch 844\n",
      "test_train\n",
      "train mean loss=62872.686848958336\n",
      "test_test\n",
      "test mean loss=87859.32421875\n",
      "fin save.\n",
      "epoch 845\n",
      "test_train\n",
      "train mean loss=62798.85338541667\n",
      "test_test\n",
      "test mean loss=87782.375\n",
      "fin save.\n",
      "epoch 846\n",
      "test_train\n",
      "train mean loss=63437.98489583333\n",
      "test_test\n",
      "test mean loss=87477.6015625\n",
      "fin save.\n",
      "epoch 847\n",
      "test_train\n",
      "train mean loss=62373.1703125\n",
      "test_test\n",
      "test mean loss=87634.62890625\n",
      "fin save.\n",
      "epoch 848\n",
      "test_train\n",
      "train mean loss=61796.36927083333\n",
      "test_test\n",
      "test mean loss=87523.69140625\n",
      "fin save.\n",
      "epoch 849\n",
      "test_train\n",
      "train mean loss=62701.43658854167\n",
      "test_test\n",
      "test mean loss=87741.1015625\n",
      "fin save.\n",
      "epoch 850\n",
      "test_train\n",
      "train mean loss=64312.51015625\n",
      "test_test\n",
      "test mean loss=87492.0625\n",
      "fin save.\n",
      "epoch 851\n",
      "test_train\n",
      "train mean loss=63520.109375\n",
      "test_test\n",
      "test mean loss=87695.69921875\n",
      "fin save.\n",
      "epoch 852\n",
      "test_train\n",
      "train mean loss=62020.30520833333\n",
      "test_test\n",
      "test mean loss=87574.10546875\n",
      "fin save.\n",
      "epoch 853\n",
      "test_train\n",
      "train mean loss=62505.77552083333\n",
      "test_test\n",
      "test mean loss=87241.51953125\n",
      "fin save.\n",
      "epoch 854\n",
      "test_train\n",
      "train mean loss=62198.303125\n",
      "test_test\n",
      "test mean loss=87176.7421875\n",
      "fin save.\n",
      "epoch 855\n",
      "test_train\n",
      "train mean loss=62581.31458333333\n",
      "test_test\n",
      "test mean loss=87030.9140625\n",
      "fin save.\n",
      "epoch 856\n",
      "test_train\n",
      "train mean loss=63335.81145833333\n",
      "test_test\n",
      "test mean loss=87249.6640625\n",
      "fin save.\n",
      "epoch 857\n",
      "test_train\n",
      "train mean loss=63437.467447916664\n",
      "test_test\n",
      "test mean loss=87521.9140625\n",
      "fin save.\n",
      "epoch 858\n",
      "test_train\n",
      "train mean loss=62624.25729166667\n",
      "test_test\n",
      "test mean loss=87437.8125\n",
      "fin save.\n",
      "epoch 859\n",
      "test_train\n",
      "train mean loss=62831.43268229167\n",
      "test_test\n",
      "test mean loss=87514.03125\n",
      "fin save.\n",
      "epoch 860\n",
      "test_train\n",
      "train mean loss=62972.21328125\n",
      "test_test\n",
      "test mean loss=87521.3125\n",
      "fin save.\n",
      "epoch 861\n",
      "test_train\n",
      "train mean loss=61438.712109375\n",
      "test_test\n",
      "test mean loss=87393.24609375\n",
      "fin save.\n",
      "epoch 862\n",
      "test_train\n",
      "train mean loss=62040.526041666664\n",
      "test_test\n",
      "test mean loss=87213.22265625\n",
      "fin save.\n",
      "epoch 863\n",
      "test_train\n",
      "train mean loss=62876.00286458333\n",
      "test_test\n",
      "test mean loss=87629.91796875\n",
      "fin save.\n",
      "epoch 864\n",
      "test_train\n",
      "train mean loss=62935.97864583333\n",
      "test_test\n",
      "test mean loss=87565.765625\n",
      "fin save.\n",
      "epoch 865\n",
      "test_train\n",
      "train mean loss=62788.578125\n",
      "test_test\n",
      "test mean loss=87567.2890625\n",
      "fin save.\n",
      "epoch 866\n",
      "test_train\n",
      "train mean loss=63163.47760416667\n",
      "test_test\n",
      "test mean loss=87591.7734375\n",
      "fin save.\n",
      "epoch 867\n",
      "test_train\n",
      "train mean loss=63288.98255208333\n",
      "test_test\n",
      "test mean loss=87315.0703125\n",
      "fin save.\n",
      "epoch 868\n",
      "test_train\n",
      "train mean loss=61732.11822916667\n",
      "test_test\n",
      "test mean loss=87531.515625\n",
      "fin save.\n",
      "epoch 869\n",
      "test_train\n",
      "train mean loss=62557.36028645833\n",
      "test_test\n",
      "test mean loss=87721.71875\n",
      "fin save.\n",
      "epoch 870\n",
      "test_train\n",
      "train mean loss=63639.13072916667\n",
      "test_test\n",
      "test mean loss=87389.16796875\n",
      "fin save.\n",
      "epoch 871\n",
      "test_train\n",
      "train mean loss=62196.20364583333\n",
      "test_test\n",
      "test mean loss=87358.1015625\n",
      "fin save.\n",
      "epoch 872\n",
      "test_train\n",
      "train mean loss=62596.74296875\n",
      "test_test\n",
      "test mean loss=87318.8203125\n",
      "fin save.\n",
      "epoch 873\n",
      "test_train\n",
      "train mean loss=63000.759765625\n",
      "test_test\n",
      "test mean loss=87051.26171875\n",
      "fin save.\n",
      "epoch 874\n",
      "test_train\n",
      "train mean loss=62169.084244791666\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=87140.79296875\n",
      "fin save.\n",
      "epoch 875\n",
      "test_train\n",
      "train mean loss=61977.99765625\n",
      "test_test\n",
      "test mean loss=87242.0234375\n",
      "fin save.\n",
      "epoch 876\n",
      "test_train\n",
      "train mean loss=62552.75481770833\n",
      "test_test\n",
      "test mean loss=86915.421875\n",
      "fin save.\n",
      "epoch 877\n",
      "test_train\n",
      "train mean loss=62653.940104166664\n",
      "test_test\n",
      "test mean loss=87117.05859375\n",
      "fin save.\n",
      "epoch 878\n",
      "test_train\n",
      "train mean loss=62563.9859375\n",
      "test_test\n",
      "test mean loss=86837.40625\n",
      "fin save.\n",
      "epoch 879\n",
      "test_train\n",
      "train mean loss=62976.241927083334\n",
      "test_test\n",
      "test mean loss=86887.15234375\n",
      "fin save.\n",
      "epoch 880\n",
      "test_train\n",
      "train mean loss=61753.94388020833\n",
      "test_test\n",
      "test mean loss=86823.2578125\n",
      "fin save.\n",
      "epoch 881\n",
      "test_train\n",
      "train mean loss=63398.4375\n",
      "test_test\n",
      "test mean loss=87024.4453125\n",
      "fin save.\n",
      "epoch 882\n",
      "test_train\n",
      "train mean loss=62277.09088541667\n",
      "test_test\n",
      "test mean loss=86996.29296875\n",
      "fin save.\n",
      "epoch 883\n",
      "test_train\n",
      "train mean loss=62219.7421875\n",
      "test_test\n",
      "test mean loss=86998.95703125\n",
      "fin save.\n",
      "epoch 884\n",
      "test_train\n",
      "train mean loss=62231.22057291667\n",
      "test_test\n",
      "test mean loss=87085.15625\n",
      "fin save.\n",
      "epoch 885\n",
      "test_train\n",
      "train mean loss=62431.8734375\n",
      "test_test\n",
      "test mean loss=87662.7109375\n",
      "fin save.\n",
      "epoch 886\n",
      "test_train\n",
      "train mean loss=61807.27916666667\n",
      "test_test\n",
      "test mean loss=87555.41796875\n",
      "fin save.\n",
      "epoch 887\n",
      "test_train\n",
      "train mean loss=62074.68802083333\n",
      "test_test\n",
      "test mean loss=87691.515625\n",
      "fin save.\n",
      "epoch 888\n",
      "test_train\n",
      "train mean loss=62918.015625\n",
      "test_test\n",
      "test mean loss=87729.88671875\n",
      "fin save.\n",
      "epoch 889\n",
      "test_train\n",
      "train mean loss=62662.586197916666\n",
      "test_test\n",
      "test mean loss=87754.9453125\n",
      "fin save.\n",
      "epoch 890\n",
      "test_train\n",
      "train mean loss=61906.33255208333\n",
      "test_test\n",
      "test mean loss=87452.77734375\n",
      "fin save.\n",
      "epoch 891\n",
      "test_train\n",
      "train mean loss=62655.120833333334\n",
      "test_test\n",
      "test mean loss=87286.8984375\n",
      "fin save.\n",
      "epoch 892\n",
      "test_train\n",
      "train mean loss=62069.678385416664\n",
      "test_test\n",
      "test mean loss=87275.59375\n",
      "fin save.\n",
      "epoch 893\n",
      "test_train\n",
      "train mean loss=62385.54609375\n",
      "test_test\n",
      "test mean loss=87044.59375\n",
      "fin save.\n",
      "epoch 894\n",
      "test_train\n",
      "train mean loss=62356.72018229167\n",
      "test_test\n",
      "test mean loss=87222.46875\n",
      "fin save.\n",
      "epoch 895\n",
      "test_train\n",
      "train mean loss=61708.1046875\n",
      "test_test\n",
      "test mean loss=86964.66796875\n",
      "fin save.\n",
      "epoch 896\n",
      "test_train\n",
      "train mean loss=62691.08125\n",
      "test_test\n",
      "test mean loss=86952.87109375\n",
      "fin save.\n",
      "epoch 897\n",
      "test_train\n",
      "train mean loss=62427.65247395833\n",
      "test_test\n",
      "test mean loss=86971.1953125\n",
      "fin save.\n",
      "epoch 898\n",
      "test_train\n",
      "train mean loss=62149.981640625\n",
      "test_test\n",
      "test mean loss=87036.9375\n",
      "fin save.\n",
      "epoch 899\n",
      "test_train\n",
      "train mean loss=62371.847395833334\n",
      "test_test\n",
      "test mean loss=87040.20703125\n",
      "fin save.\n",
      "epoch 900\n",
      "test_train\n",
      "train mean loss=62048.96927083333\n",
      "test_test\n",
      "test mean loss=87224.2734375\n",
      "fin save.\n",
      "epoch 901\n",
      "test_train\n",
      "train mean loss=62106.54505208333\n",
      "test_test\n",
      "test mean loss=87453.390625\n",
      "fin save.\n",
      "epoch 902\n",
      "test_train\n",
      "train mean loss=62496.54609375\n",
      "test_test\n",
      "test mean loss=87404.85546875\n",
      "fin save.\n",
      "epoch 903\n",
      "test_train\n",
      "train mean loss=62285.9421875\n",
      "test_test\n",
      "test mean loss=87464.9921875\n",
      "fin save.\n",
      "epoch 904\n",
      "test_train\n",
      "train mean loss=62279.369140625\n",
      "test_test\n",
      "test mean loss=87595.5078125\n",
      "fin save.\n",
      "epoch 905\n",
      "test_train\n",
      "train mean loss=62765.43020833333\n",
      "test_test\n",
      "test mean loss=87494.9375\n",
      "fin save.\n",
      "epoch 906\n",
      "test_train\n",
      "train mean loss=62738.039322916666\n",
      "test_test\n",
      "test mean loss=87576.06640625\n",
      "fin save.\n",
      "epoch 907\n",
      "test_train\n",
      "train mean loss=63187.88828125\n",
      "test_test\n",
      "test mean loss=87188.32421875\n",
      "fin save.\n",
      "epoch 908\n",
      "test_train\n",
      "train mean loss=62395.102213541664\n",
      "test_test\n",
      "test mean loss=87364.2265625\n",
      "fin save.\n",
      "epoch 909\n",
      "test_train\n",
      "train mean loss=62409.2515625\n",
      "test_test\n",
      "test mean loss=87489.09765625\n",
      "fin save.\n",
      "epoch 910\n",
      "test_train\n",
      "train mean loss=61980.76940104167\n",
      "test_test\n",
      "test mean loss=87322.13671875\n",
      "fin save.\n",
      "epoch 911\n",
      "test_train\n",
      "train mean loss=61903.86536458333\n",
      "test_test\n",
      "test mean loss=87368.34765625\n",
      "fin save.\n",
      "epoch 912\n",
      "test_train\n",
      "train mean loss=62451.36614583333\n",
      "test_test\n",
      "test mean loss=87246.73046875\n",
      "fin save.\n",
      "epoch 913\n",
      "test_train\n",
      "train mean loss=63176.700911458334\n",
      "test_test\n",
      "test mean loss=87452.7421875\n",
      "fin save.\n",
      "epoch 914\n",
      "test_train\n",
      "train mean loss=61570.38919270833\n",
      "test_test\n",
      "test mean loss=87372.1953125\n",
      "fin save.\n",
      "epoch 915\n",
      "test_train\n",
      "train mean loss=62349.47421875\n",
      "test_test\n",
      "test mean loss=87658.1484375\n",
      "fin save.\n",
      "epoch 916\n",
      "test_train\n",
      "train mean loss=62428.96328125\n",
      "test_test\n",
      "test mean loss=87413.6953125\n",
      "fin save.\n",
      "epoch 917\n",
      "test_train\n",
      "train mean loss=63575.71692708333\n",
      "test_test\n",
      "test mean loss=87215.8125\n",
      "fin save.\n",
      "epoch 918\n",
      "test_train\n",
      "train mean loss=62495.23723958333\n",
      "test_test\n",
      "test mean loss=87405.49609375\n",
      "fin save.\n",
      "epoch 919\n",
      "test_train\n",
      "train mean loss=62426.769921875\n",
      "test_test\n",
      "test mean loss=87652.2890625\n",
      "fin save.\n",
      "epoch 920\n",
      "test_train\n",
      "train mean loss=61950.640234375\n",
      "test_test\n",
      "test mean loss=87714.42578125\n",
      "fin save.\n",
      "epoch 921\n",
      "test_train\n",
      "train mean loss=61407.29609375\n",
      "test_test\n",
      "test mean loss=87667.5625\n",
      "fin save.\n",
      "epoch 922\n",
      "test_train\n",
      "train mean loss=62881.539322916666\n",
      "test_test\n",
      "test mean loss=87878.96875\n",
      "fin save.\n",
      "epoch 923\n",
      "test_train\n",
      "train mean loss=62302.733072916664\n",
      "test_test\n",
      "test mean loss=87943.41796875\n",
      "fin save.\n",
      "epoch 924\n",
      "test_train\n",
      "train mean loss=61681.13854166667\n",
      "test_test\n",
      "test mean loss=87816.921875\n",
      "fin save.\n",
      "epoch 925\n",
      "test_train\n",
      "train mean loss=62164.975260416664\n",
      "test_test\n",
      "test mean loss=87899.22265625\n",
      "fin save.\n",
      "epoch 926\n",
      "test_train\n",
      "train mean loss=62151.86731770833\n",
      "test_test\n",
      "test mean loss=87806.30078125\n",
      "fin save.\n",
      "epoch 927\n",
      "test_train\n",
      "train mean loss=62490.25390625\n",
      "test_test\n",
      "test mean loss=87684.7578125\n",
      "fin save.\n",
      "epoch 928\n",
      "test_train\n",
      "train mean loss=62047.8515625\n",
      "test_test\n",
      "test mean loss=87838.5390625\n",
      "fin save.\n",
      "epoch 929\n",
      "test_train\n",
      "train mean loss=61537.4734375\n",
      "test_test\n",
      "test mean loss=87656.43359375\n",
      "fin save.\n",
      "epoch 930\n",
      "test_train\n",
      "train mean loss=61994.64661458333\n",
      "test_test\n",
      "test mean loss=87738.078125\n",
      "fin save.\n",
      "epoch 931\n",
      "test_train\n",
      "train mean loss=62889.0796875\n",
      "test_test\n",
      "test mean loss=87622.73046875\n",
      "fin save.\n",
      "epoch 932\n",
      "test_train\n",
      "train mean loss=63375.405989583334\n",
      "test_test\n",
      "test mean loss=87760.640625\n",
      "fin save.\n",
      "epoch 933\n",
      "test_train\n",
      "train mean loss=62525.68984375\n",
      "test_test\n",
      "test mean loss=87816.0390625\n",
      "fin save.\n",
      "epoch 934\n",
      "test_train\n",
      "train mean loss=62004.238020833334\n",
      "test_test\n",
      "test mean loss=87821.3984375\n",
      "fin save.\n",
      "epoch 935\n",
      "test_train\n",
      "train mean loss=62844.81927083333\n",
      "test_test\n",
      "test mean loss=87495.16015625\n",
      "fin save.\n",
      "epoch 936\n",
      "test_train\n",
      "train mean loss=63173.356770833336\n",
      "test_test\n",
      "test mean loss=87537.26171875\n",
      "fin save.\n",
      "epoch 937\n",
      "test_train\n",
      "train mean loss=62348.132552083334\n",
      "test_test\n",
      "test mean loss=87285.671875\n",
      "fin save.\n",
      "epoch 938\n",
      "test_train\n",
      "train mean loss=62541.153515625\n",
      "test_test\n",
      "test mean loss=87475.171875\n",
      "fin save.\n",
      "epoch 939\n",
      "test_train\n",
      "train mean loss=62136.995833333334\n",
      "test_test\n",
      "test mean loss=87392.84375\n",
      "fin save.\n",
      "epoch 940\n",
      "test_train\n",
      "train mean loss=62645.093359375\n",
      "test_test\n",
      "test mean loss=87536.72265625\n",
      "fin save.\n",
      "epoch 941\n",
      "test_train\n",
      "train mean loss=62290.691666666666\n",
      "test_test\n",
      "test mean loss=87554.5546875\n",
      "fin save.\n",
      "epoch 942\n",
      "test_train\n",
      "train mean loss=62851.19622395833\n",
      "test_test\n",
      "test mean loss=87389.2890625\n",
      "fin save.\n",
      "epoch 943\n",
      "test_train\n",
      "train mean loss=62413.848307291664\n",
      "test_test\n",
      "test mean loss=87418.69921875\n",
      "fin save.\n",
      "epoch 944\n",
      "test_train\n",
      "train mean loss=62379.0140625\n",
      "test_test\n",
      "test mean loss=87372.79296875\n",
      "fin save.\n",
      "epoch 945\n",
      "test_train\n",
      "train mean loss=62345.92083333333\n",
      "test_test\n",
      "test mean loss=87392.5390625\n",
      "fin save.\n",
      "epoch 946\n",
      "test_train\n",
      "train mean loss=61905.772135416664\n",
      "test_test\n",
      "test mean loss=87428.86328125\n",
      "fin save.\n",
      "epoch 947\n",
      "test_train\n",
      "train mean loss=62295.60260416667\n",
      "test_test\n",
      "test mean loss=87547.5625\n",
      "fin save.\n",
      "epoch 948\n",
      "test_train\n",
      "train mean loss=62331.8921875\n",
      "test_test\n",
      "test mean loss=87682.08203125\n",
      "fin save.\n",
      "epoch 949\n",
      "test_train\n",
      "train mean loss=61939.574479166666\n",
      "test_test\n",
      "test mean loss=87607.8515625\n",
      "fin save.\n",
      "epoch 950\n",
      "test_train\n",
      "train mean loss=63072.084765625\n",
      "test_test\n",
      "test mean loss=87504.640625\n",
      "fin save.\n",
      "epoch 951\n",
      "test_train\n",
      "train mean loss=62660.882552083334\n",
      "test_test\n",
      "test mean loss=87474.73046875\n",
      "fin save.\n",
      "epoch 952\n",
      "test_train\n",
      "train mean loss=62671.57604166667\n",
      "test_test\n",
      "test mean loss=87410.015625\n",
      "fin save.\n",
      "epoch 953\n",
      "test_train\n",
      "train mean loss=62247.579427083336\n",
      "test_test\n",
      "test mean loss=87302.8828125\n",
      "fin save.\n",
      "epoch 954\n",
      "test_train\n",
      "train mean loss=61740.25338541667\n",
      "test_test\n",
      "test mean loss=87466.88671875\n",
      "fin save.\n",
      "epoch 955\n",
      "test_train\n",
      "train mean loss=62523.89505208333\n",
      "test_test\n",
      "test mean loss=87514.23828125\n",
      "fin save.\n",
      "epoch 956\n",
      "test_train\n",
      "train mean loss=62123.21822916667\n",
      "test_test\n",
      "test mean loss=87632.34375\n",
      "fin save.\n",
      "epoch 957\n",
      "test_train\n",
      "train mean loss=62717.92578125\n",
      "test_test\n",
      "test mean loss=87517.5234375\n",
      "fin save.\n",
      "epoch 958\n",
      "test_train\n",
      "train mean loss=62275.9375\n",
      "test_test\n",
      "test mean loss=87643.640625\n",
      "fin save.\n",
      "epoch 959\n",
      "test_train\n",
      "train mean loss=62017.37994791667\n",
      "test_test\n",
      "test mean loss=87405.32421875\n",
      "fin save.\n",
      "epoch 960\n",
      "test_train\n",
      "train mean loss=62856.71979166667\n",
      "test_test\n",
      "test mean loss=87516.078125\n",
      "fin save.\n",
      "epoch 961\n",
      "test_train\n",
      "train mean loss=62788.71471354167\n",
      "test_test\n",
      "test mean loss=87469.6171875\n",
      "fin save.\n",
      "epoch 962\n",
      "test_train\n",
      "train mean loss=63266.769791666666\n",
      "test_test\n",
      "test mean loss=87635.3046875\n",
      "fin save.\n",
      "epoch 963\n",
      "test_train\n",
      "train mean loss=63273.23203125\n",
      "test_test\n",
      "test mean loss=87455.6484375\n",
      "fin save.\n",
      "epoch 964\n",
      "test_train\n",
      "train mean loss=62898.75390625\n",
      "test_test\n",
      "test mean loss=87451.85546875\n",
      "fin save.\n",
      "epoch 965\n",
      "test_train\n",
      "train mean loss=62291.85260416667\n",
      "test_test\n",
      "test mean loss=87472.2578125\n",
      "fin save.\n",
      "epoch 966\n",
      "test_train\n",
      "train mean loss=63057.61927083333\n",
      "test_test\n",
      "test mean loss=87291.109375\n",
      "fin save.\n",
      "epoch 967\n",
      "test_train\n",
      "train mean loss=62211.526171875\n",
      "test_test\n",
      "test mean loss=87477.48828125\n",
      "fin save.\n",
      "epoch 968\n",
      "test_train\n",
      "train mean loss=62601.882552083334\n",
      "test_test\n",
      "test mean loss=87549.0703125\n",
      "fin save.\n",
      "epoch 969\n",
      "test_train\n",
      "train mean loss=62472.24375\n",
      "test_test\n",
      "test mean loss=87332.39453125\n",
      "fin save.\n",
      "epoch 970\n",
      "test_train\n",
      "train mean loss=62369.122395833336\n",
      "test_test\n",
      "test mean loss=87443.25\n",
      "fin save.\n",
      "epoch 971\n",
      "test_train\n",
      "train mean loss=62274.38828125\n",
      "test_test\n",
      "test mean loss=87458.7890625\n",
      "fin save.\n",
      "epoch 972\n",
      "test_train\n",
      "train mean loss=62082.10755208333\n",
      "test_test\n",
      "test mean loss=87281.328125\n",
      "fin save.\n",
      "epoch 973\n",
      "test_train\n",
      "train mean loss=61472.767578125\n",
      "test_test\n",
      "test mean loss=87328.50390625\n",
      "fin save.\n",
      "epoch 974\n",
      "test_train\n",
      "train mean loss=62306.79973958333\n",
      "test_test\n",
      "test mean loss=87262.234375\n",
      "fin save.\n",
      "epoch 975\n",
      "test_train\n",
      "train mean loss=62782.22109375\n",
      "test_test\n",
      "test mean loss=86983.0\n",
      "fin save.\n",
      "epoch 976\n",
      "test_train\n",
      "train mean loss=62097.41614583333\n",
      "test_test\n",
      "test mean loss=87241.28515625\n",
      "fin save.\n",
      "epoch 977\n",
      "test_train\n",
      "train mean loss=62355.09453125\n",
      "test_test\n",
      "test mean loss=87375.3515625\n",
      "fin save.\n",
      "epoch 978\n",
      "test_train\n",
      "train mean loss=62449.305989583336\n",
      "test_test\n",
      "test mean loss=87375.82421875\n",
      "fin save.\n",
      "epoch 979\n",
      "test_train\n",
      "train mean loss=63299.13046875\n",
      "test_test\n",
      "test mean loss=87225.30859375\n",
      "fin save.\n",
      "epoch 980\n",
      "test_train\n",
      "train mean loss=62779.308333333334\n",
      "test_test\n",
      "test mean loss=87441.8515625\n",
      "fin save.\n",
      "epoch 981\n",
      "test_train\n",
      "train mean loss=62857.81458333333\n",
      "test_test\n",
      "test mean loss=87067.28515625\n",
      "fin save.\n",
      "epoch 982\n",
      "test_train\n",
      "train mean loss=62021.383072916666\n",
      "test_test\n",
      "test mean loss=87285.87890625\n",
      "fin save.\n",
      "epoch 983\n",
      "test_train\n",
      "train mean loss=63243.525\n",
      "test_test\n",
      "test mean loss=87031.53125\n",
      "fin save.\n",
      "epoch 984\n",
      "test_train\n",
      "train mean loss=62352.60403645833\n",
      "test_test\n",
      "test mean loss=87129.7734375\n",
      "fin save.\n",
      "epoch 985\n",
      "test_train\n",
      "train mean loss=61968.10338541667\n",
      "test_test\n",
      "test mean loss=87067.2578125\n",
      "fin save.\n",
      "epoch 986\n",
      "test_train\n",
      "train mean loss=62659.51848958333\n",
      "test_test\n",
      "test mean loss=87105.9140625\n",
      "fin save.\n",
      "epoch 987\n",
      "test_train\n",
      "train mean loss=61947.066666666666\n",
      "test_test\n",
      "test mean loss=87062.39453125\n",
      "fin save.\n",
      "epoch 988\n",
      "test_train\n",
      "train mean loss=62009.48385416667\n",
      "test_test\n",
      "test mean loss=87173.9921875\n",
      "fin save.\n",
      "epoch 989\n",
      "test_train\n",
      "train mean loss=62699.91067708333\n",
      "test_test\n",
      "test mean loss=87272.02734375\n",
      "fin save.\n",
      "epoch 990\n",
      "test_train\n",
      "train mean loss=61787.840625\n",
      "test_test\n",
      "test mean loss=87122.60546875\n",
      "fin save.\n",
      "epoch 991\n",
      "test_train\n",
      "train mean loss=62405.81692708333\n",
      "test_test\n",
      "test mean loss=87132.45703125\n",
      "fin save.\n",
      "epoch 992\n",
      "test_train\n",
      "train mean loss=62499.4921875\n",
      "test_test\n",
      "test mean loss=87039.59375\n",
      "fin save.\n",
      "epoch 993\n",
      "test_train\n",
      "train mean loss=61519.06236979167\n",
      "test_test\n",
      "test mean loss=86972.875\n",
      "fin save.\n",
      "epoch 994\n",
      "test_train\n",
      "train mean loss=62314.5640625\n",
      "test_test\n",
      "test mean loss=86958.90234375\n",
      "fin save.\n",
      "epoch 995\n",
      "test_train\n",
      "train mean loss=61757.819010416664\n",
      "test_test\n",
      "test mean loss=86939.97265625\n",
      "fin save.\n",
      "epoch 996\n",
      "test_train\n",
      "train mean loss=61691.169661458334\n",
      "test_test\n",
      "test mean loss=87243.26171875\n",
      "fin save.\n",
      "epoch 997\n",
      "test_train\n",
      "train mean loss=62475.20169270833\n",
      "test_test\n",
      "test mean loss=87034.44921875\n",
      "fin save.\n",
      "epoch 998\n",
      "test_train\n",
      "train mean loss=63809.79244791667\n",
      "test_test\n",
      "test mean loss=87170.625\n",
      "fin save.\n",
      "epoch 999\n",
      "test_train\n",
      "train mean loss=61935.773046875\n",
      "test_test\n",
      "test mean loss=87079.91015625\n",
      "fin save.\n",
      "epoch 1000\n",
      "test_train\n",
      "train mean loss=61412.56263020833\n",
      "test_test\n",
      "test mean loss=87341.63671875\n",
      "fin save.\n",
      "epoch 1001\n",
      "test_train\n",
      "train mean loss=61907.541666666664\n",
      "test_test\n",
      "test mean loss=87445.703125\n",
      "fin save.\n",
      "epoch 1002\n",
      "test_train\n",
      "train mean loss=61226.162109375\n",
      "test_test\n",
      "test mean loss=87419.6640625\n",
      "fin save.\n",
      "epoch 1003\n",
      "test_train\n",
      "train mean loss=62019.00286458333\n",
      "test_test\n",
      "test mean loss=87396.015625\n",
      "fin save.\n",
      "epoch 1004\n",
      "test_train\n",
      "train mean loss=62733.84427083333\n",
      "test_test\n",
      "test mean loss=87428.7421875\n",
      "fin save.\n",
      "epoch 1005\n",
      "test_train\n",
      "train mean loss=62404.74309895833\n",
      "test_test\n",
      "test mean loss=87092.8125\n",
      "fin save.\n",
      "epoch 1006\n",
      "test_train\n",
      "train mean loss=61526.30260416667\n",
      "test_test\n",
      "test mean loss=87223.50390625\n",
      "fin save.\n",
      "epoch 1007\n",
      "test_train\n",
      "train mean loss=62931.36640625\n",
      "test_test\n",
      "test mean loss=87112.13671875\n",
      "fin save.\n",
      "epoch 1008\n",
      "test_train\n",
      "train mean loss=62008.01510416667\n",
      "test_test\n",
      "test mean loss=87279.0390625\n",
      "fin save.\n",
      "epoch 1009\n",
      "test_train\n",
      "train mean loss=61569.682291666664\n",
      "test_test\n",
      "test mean loss=87099.3828125\n",
      "fin save.\n",
      "epoch 1010\n",
      "test_train\n",
      "train mean loss=61544.77447916667\n",
      "test_test\n",
      "test mean loss=87116.4375\n",
      "fin save.\n",
      "epoch 1011\n",
      "test_train\n",
      "train mean loss=62300.158203125\n",
      "test_test\n",
      "test mean loss=87128.0390625\n",
      "fin save.\n",
      "epoch 1012\n",
      "test_train\n",
      "train mean loss=62732.794270833336\n",
      "test_test\n",
      "test mean loss=87101.92578125\n",
      "fin save.\n",
      "epoch 1013\n",
      "test_train\n",
      "train mean loss=62474.948958333334\n",
      "test_test\n",
      "test mean loss=87578.46484375\n",
      "fin save.\n",
      "epoch 1014\n",
      "test_train\n",
      "train mean loss=62939.34075520833\n",
      "test_test\n",
      "test mean loss=87523.60546875\n",
      "fin save.\n",
      "epoch 1015\n",
      "test_train\n",
      "train mean loss=62325.23671875\n",
      "test_test\n",
      "test mean loss=87360.4921875\n",
      "fin save.\n",
      "epoch 1016\n",
      "test_train\n",
      "train mean loss=62550.41588541667\n",
      "test_test\n",
      "test mean loss=87505.1953125\n",
      "fin save.\n",
      "epoch 1017\n",
      "test_train\n",
      "train mean loss=62508.43645833333\n",
      "test_test\n",
      "test mean loss=87419.7109375\n",
      "fin save.\n",
      "epoch 1018\n",
      "test_train\n",
      "train mean loss=62608.59375\n",
      "test_test\n",
      "test mean loss=87240.37890625\n",
      "fin save.\n",
      "epoch 1019\n",
      "test_train\n",
      "train mean loss=62125.11028645833\n",
      "test_test\n",
      "test mean loss=87025.875\n",
      "fin save.\n",
      "epoch 1020\n",
      "test_train\n",
      "train mean loss=62101.59921875\n",
      "test_test\n",
      "test mean loss=86893.1015625\n",
      "fin save.\n",
      "epoch 1021\n",
      "test_train\n",
      "train mean loss=61913.75286458333\n",
      "test_test\n",
      "test mean loss=87022.9453125\n",
      "fin save.\n",
      "epoch 1022\n",
      "test_train\n",
      "train mean loss=62782.14830729167\n",
      "test_test\n",
      "test mean loss=87020.62890625\n",
      "fin save.\n",
      "epoch 1023\n",
      "test_train\n",
      "train mean loss=62102.2609375\n",
      "test_test\n",
      "test mean loss=87198.84375\n",
      "fin save.\n",
      "epoch 1024\n",
      "test_train\n",
      "train mean loss=62111.40481770833\n",
      "test_test\n",
      "test mean loss=87312.5703125\n",
      "fin save.\n",
      "epoch 1025\n",
      "test_train\n",
      "train mean loss=62156.33541666667\n",
      "test_test\n",
      "test mean loss=87204.87109375\n",
      "fin save.\n",
      "epoch 1026\n",
      "test_train\n",
      "train mean loss=61889.216145833336\n",
      "test_test\n",
      "test mean loss=87150.05078125\n",
      "fin save.\n",
      "epoch 1027\n",
      "test_train\n",
      "train mean loss=62055.828385416666\n",
      "test_test\n",
      "test mean loss=87209.30859375\n",
      "fin save.\n",
      "epoch 1028\n",
      "test_train\n",
      "train mean loss=62523.059244791664\n",
      "test_test\n",
      "test mean loss=87179.1328125\n",
      "fin save.\n",
      "epoch 1029\n",
      "test_train\n",
      "train mean loss=62045.032552083336\n",
      "test_test\n",
      "test mean loss=87219.28515625\n",
      "fin save.\n",
      "epoch 1030\n",
      "test_train\n",
      "train mean loss=62847.95703125\n",
      "test_test\n",
      "test mean loss=87074.5234375\n",
      "fin save.\n",
      "epoch 1031\n",
      "test_train\n",
      "train mean loss=62894.40703125\n",
      "test_test\n",
      "test mean loss=87059.7890625\n",
      "fin save.\n",
      "epoch 1032\n",
      "test_train\n",
      "train mean loss=61768.458333333336\n",
      "test_test\n",
      "test mean loss=86906.88671875\n",
      "fin save.\n",
      "epoch 1033\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=61225.92578125\n",
      "test_test\n",
      "test mean loss=86911.16015625\n",
      "fin save.\n",
      "epoch 1034\n",
      "test_train\n",
      "train mean loss=62414.36822916667\n",
      "test_test\n",
      "test mean loss=87247.80859375\n",
      "fin save.\n",
      "epoch 1035\n",
      "test_train\n",
      "train mean loss=63087.63125\n",
      "test_test\n",
      "test mean loss=87322.1953125\n",
      "fin save.\n",
      "epoch 1036\n",
      "test_train\n",
      "train mean loss=62563.344010416666\n",
      "test_test\n",
      "test mean loss=87432.31640625\n",
      "fin save.\n",
      "epoch 1037\n",
      "test_train\n",
      "train mean loss=62103.535416666666\n",
      "test_test\n",
      "test mean loss=87103.5859375\n",
      "fin save.\n",
      "epoch 1038\n",
      "test_train\n",
      "train mean loss=62131.18059895833\n",
      "test_test\n",
      "test mean loss=87139.0390625\n",
      "fin save.\n",
      "epoch 1039\n",
      "test_train\n",
      "train mean loss=62326.81744791667\n",
      "test_test\n",
      "test mean loss=87323.53125\n",
      "fin save.\n",
      "epoch 1040\n",
      "test_train\n",
      "train mean loss=62124.8734375\n",
      "test_test\n",
      "test mean loss=87341.87109375\n",
      "fin save.\n",
      "epoch 1041\n",
      "test_train\n",
      "train mean loss=62074.17890625\n",
      "test_test\n",
      "test mean loss=87214.21484375\n",
      "fin save.\n",
      "epoch 1042\n",
      "test_train\n",
      "train mean loss=61514.459635416664\n",
      "test_test\n",
      "test mean loss=87187.75\n",
      "fin save.\n",
      "epoch 1043\n",
      "test_train\n",
      "train mean loss=62464.90390625\n",
      "test_test\n",
      "test mean loss=87269.4453125\n",
      "fin save.\n",
      "epoch 1044\n",
      "test_train\n",
      "train mean loss=61191.05091145833\n",
      "test_test\n",
      "test mean loss=87189.28515625\n",
      "fin save.\n",
      "epoch 1045\n",
      "test_train\n",
      "train mean loss=61502.55416666667\n",
      "test_test\n",
      "test mean loss=87375.1875\n",
      "fin save.\n",
      "epoch 1046\n",
      "test_train\n",
      "train mean loss=61685.06783854167\n",
      "test_test\n",
      "test mean loss=87215.17578125\n",
      "fin save.\n",
      "epoch 1047\n",
      "test_train\n",
      "train mean loss=61947.99791666667\n",
      "test_test\n",
      "test mean loss=87200.4375\n",
      "fin save.\n",
      "epoch 1048\n",
      "test_train\n",
      "train mean loss=62361.36119791667\n",
      "test_test\n",
      "test mean loss=87213.62890625\n",
      "fin save.\n",
      "epoch 1049\n",
      "test_train\n",
      "train mean loss=63070.050390625\n",
      "test_test\n",
      "test mean loss=87372.78125\n",
      "fin save.\n",
      "epoch 1050\n",
      "test_train\n",
      "train mean loss=63354.171223958336\n",
      "test_test\n",
      "test mean loss=87335.1875\n",
      "fin save.\n",
      "epoch 1051\n",
      "test_train\n",
      "train mean loss=61294.59661458333\n",
      "test_test\n",
      "test mean loss=87179.171875\n",
      "fin save.\n",
      "epoch 1052\n",
      "test_train\n",
      "train mean loss=61876.46692708333\n",
      "test_test\n",
      "test mean loss=87189.73828125\n",
      "fin save.\n",
      "epoch 1053\n",
      "test_train\n",
      "train mean loss=62435.444010416664\n",
      "test_test\n",
      "test mean loss=87155.5546875\n",
      "fin save.\n",
      "epoch 1054\n",
      "test_train\n",
      "train mean loss=61398.228125\n",
      "test_test\n",
      "test mean loss=87246.36328125\n",
      "fin save.\n",
      "epoch 1055\n",
      "test_train\n",
      "train mean loss=61995.90390625\n",
      "test_test\n",
      "test mean loss=87085.47265625\n",
      "fin save.\n",
      "epoch 1056\n",
      "test_train\n",
      "train mean loss=62435.54453125\n",
      "test_test\n",
      "test mean loss=87178.41796875\n",
      "fin save.\n",
      "epoch 1057\n",
      "test_train\n",
      "train mean loss=62051.153125\n",
      "test_test\n",
      "test mean loss=87100.42578125\n",
      "fin save.\n",
      "epoch 1058\n",
      "test_train\n",
      "train mean loss=61743.479817708336\n",
      "test_test\n",
      "test mean loss=87456.4375\n",
      "fin save.\n",
      "epoch 1059\n",
      "test_train\n",
      "train mean loss=62044.09166666667\n",
      "test_test\n",
      "test mean loss=87473.48046875\n",
      "fin save.\n",
      "epoch 1060\n",
      "test_train\n",
      "train mean loss=63212.77578125\n",
      "test_test\n",
      "test mean loss=87312.30078125\n",
      "fin save.\n",
      "epoch 1061\n",
      "test_train\n",
      "train mean loss=61965.197526041666\n",
      "test_test\n",
      "test mean loss=87571.3203125\n",
      "fin save.\n",
      "epoch 1062\n",
      "test_train\n",
      "train mean loss=62434.695572916666\n",
      "test_test\n",
      "test mean loss=87223.59375\n",
      "fin save.\n",
      "epoch 1063\n",
      "test_train\n",
      "train mean loss=62157.053125\n",
      "test_test\n",
      "test mean loss=87355.9453125\n",
      "fin save.\n",
      "epoch 1064\n",
      "test_train\n",
      "train mean loss=63020.0984375\n",
      "test_test\n",
      "test mean loss=87293.28125\n",
      "fin save.\n",
      "epoch 1065\n",
      "test_train\n",
      "train mean loss=61981.80963541667\n",
      "test_test\n",
      "test mean loss=87259.03125\n",
      "fin save.\n",
      "epoch 1066\n",
      "test_train\n",
      "train mean loss=62269.339192708336\n",
      "test_test\n",
      "test mean loss=87350.22265625\n",
      "fin save.\n",
      "epoch 1067\n",
      "test_train\n",
      "train mean loss=62978.05677083333\n",
      "test_test\n",
      "test mean loss=87245.375\n",
      "fin save.\n",
      "epoch 1068\n",
      "test_train\n",
      "train mean loss=62993.30703125\n",
      "test_test\n",
      "test mean loss=87252.89453125\n",
      "fin save.\n",
      "epoch 1069\n",
      "test_train\n",
      "train mean loss=62127.8796875\n",
      "test_test\n",
      "test mean loss=87383.66015625\n",
      "fin save.\n",
      "epoch 1070\n",
      "test_train\n",
      "train mean loss=62199.418229166666\n",
      "test_test\n",
      "test mean loss=87245.7109375\n",
      "fin save.\n",
      "epoch 1071\n",
      "test_train\n",
      "train mean loss=62503.594140625\n",
      "test_test\n",
      "test mean loss=87422.52734375\n",
      "fin save.\n",
      "epoch 1072\n",
      "test_train\n",
      "train mean loss=62443.797135416666\n",
      "test_test\n",
      "test mean loss=87566.06640625\n",
      "fin save.\n",
      "epoch 1073\n",
      "test_train\n",
      "train mean loss=62615.026041666664\n",
      "test_test\n",
      "test mean loss=87455.09765625\n",
      "fin save.\n",
      "epoch 1074\n",
      "test_train\n",
      "train mean loss=62679.096354166664\n",
      "test_test\n",
      "test mean loss=87512.0\n",
      "fin save.\n",
      "epoch 1075\n",
      "test_train\n",
      "train mean loss=61682.320703125\n",
      "test_test\n",
      "test mean loss=87231.0390625\n",
      "fin save.\n",
      "epoch 1076\n",
      "test_train\n",
      "train mean loss=62821.1984375\n",
      "test_test\n",
      "test mean loss=87471.171875\n",
      "fin save.\n",
      "epoch 1077\n",
      "test_train\n",
      "train mean loss=62269.27526041667\n",
      "test_test\n",
      "test mean loss=87348.11328125\n",
      "fin save.\n",
      "epoch 1078\n",
      "test_train\n",
      "train mean loss=62292.980208333334\n",
      "test_test\n",
      "test mean loss=87374.1328125\n",
      "fin save.\n",
      "epoch 1079\n",
      "test_train\n",
      "train mean loss=61934.916666666664\n",
      "test_test\n",
      "test mean loss=87406.26171875\n",
      "fin save.\n",
      "epoch 1080\n",
      "test_train\n",
      "train mean loss=62470.15703125\n",
      "test_test\n",
      "test mean loss=87414.5625\n",
      "fin save.\n",
      "epoch 1081\n",
      "test_train\n",
      "train mean loss=63068.772135416664\n",
      "test_test\n",
      "test mean loss=87356.37109375\n",
      "fin save.\n",
      "epoch 1082\n",
      "test_train\n",
      "train mean loss=63278.58203125\n",
      "test_test\n",
      "test mean loss=87540.046875\n",
      "fin save.\n",
      "epoch 1083\n",
      "test_train\n",
      "train mean loss=61649.918619791664\n",
      "test_test\n",
      "test mean loss=87432.87109375\n",
      "fin save.\n",
      "epoch 1084\n",
      "test_train\n",
      "train mean loss=62700.69192708333\n",
      "test_test\n",
      "test mean loss=87440.13671875\n",
      "fin save.\n",
      "epoch 1085\n",
      "test_train\n",
      "train mean loss=62601.199479166666\n",
      "test_test\n",
      "test mean loss=87538.49609375\n",
      "fin save.\n",
      "epoch 1086\n",
      "test_train\n",
      "train mean loss=61167.346484375\n",
      "test_test\n",
      "test mean loss=87569.76953125\n",
      "fin save.\n",
      "epoch 1087\n",
      "test_train\n",
      "train mean loss=62440.514973958336\n",
      "test_test\n",
      "test mean loss=87212.671875\n",
      "fin save.\n",
      "epoch 1088\n",
      "test_train\n",
      "train mean loss=63051.29140625\n",
      "test_test\n",
      "test mean loss=87262.54296875\n",
      "fin save.\n",
      "epoch 1089\n",
      "test_train\n",
      "train mean loss=62468.85364583333\n",
      "test_test\n",
      "test mean loss=87330.2265625\n",
      "fin save.\n",
      "epoch 1090\n",
      "test_train\n",
      "train mean loss=62531.46666666667\n",
      "test_test\n",
      "test mean loss=87422.1328125\n",
      "fin save.\n",
      "epoch 1091\n",
      "test_train\n",
      "train mean loss=63432.45234375\n",
      "test_test\n",
      "test mean loss=87563.40234375\n",
      "fin save.\n",
      "epoch 1092\n",
      "test_train\n",
      "train mean loss=62506.32369791667\n",
      "test_test\n",
      "test mean loss=87576.125\n",
      "fin save.\n",
      "epoch 1093\n",
      "test_train\n",
      "train mean loss=62655.81549479167\n",
      "test_test\n",
      "test mean loss=87644.3125\n",
      "fin save.\n",
      "epoch 1094\n",
      "test_train\n",
      "train mean loss=62575.154947916664\n",
      "test_test\n",
      "test mean loss=87426.1328125\n",
      "fin save.\n",
      "epoch 1095\n",
      "test_train\n",
      "train mean loss=62819.95416666667\n",
      "test_test\n",
      "test mean loss=87315.51171875\n",
      "fin save.\n",
      "epoch 1096\n",
      "test_train\n",
      "train mean loss=62053.287109375\n",
      "test_test\n",
      "test mean loss=87288.9375\n",
      "fin save.\n",
      "epoch 1097\n",
      "test_train\n",
      "train mean loss=63454.933854166666\n",
      "test_test\n",
      "test mean loss=87161.67578125\n",
      "fin save.\n",
      "epoch 1098\n",
      "test_train\n",
      "train mean loss=62034.50078125\n",
      "test_test\n",
      "test mean loss=87137.328125\n",
      "fin save.\n",
      "epoch 1099\n",
      "test_train\n",
      "train mean loss=62632.80182291667\n",
      "test_test\n",
      "test mean loss=87183.703125\n",
      "fin save.\n",
      "epoch 1100\n",
      "test_train\n",
      "train mean loss=62172.240234375\n",
      "test_test\n",
      "test mean loss=87250.92578125\n",
      "fin save.\n",
      "epoch 1101\n",
      "test_train\n",
      "train mean loss=61837.43997395833\n",
      "test_test\n",
      "test mean loss=87228.08203125\n",
      "fin save.\n",
      "epoch 1102\n",
      "test_train\n",
      "train mean loss=62373.038802083334\n",
      "test_test\n",
      "test mean loss=87035.49609375\n",
      "fin save.\n",
      "epoch 1103\n",
      "test_train\n",
      "train mean loss=62439.405989583334\n",
      "test_test\n",
      "test mean loss=87186.671875\n",
      "fin save.\n",
      "epoch 1104\n",
      "test_train\n",
      "train mean loss=62575.115625\n",
      "test_test\n",
      "test mean loss=87037.05859375\n",
      "fin save.\n",
      "epoch 1105\n",
      "test_train\n",
      "train mean loss=62534.1453125\n",
      "test_test\n",
      "test mean loss=87335.171875\n",
      "fin save.\n",
      "epoch 1106\n",
      "test_train\n",
      "train mean loss=62015.309375\n",
      "test_test\n",
      "test mean loss=87205.4375\n",
      "fin save.\n",
      "epoch 1107\n",
      "test_train\n",
      "train mean loss=61937.27057291667\n",
      "test_test\n",
      "test mean loss=86932.6640625\n",
      "fin save.\n",
      "epoch 1108\n",
      "test_train\n",
      "train mean loss=62211.01575520833\n",
      "test_test\n",
      "test mean loss=86766.6875\n",
      "fin save.\n",
      "epoch 1109\n",
      "test_train\n",
      "train mean loss=62063.12942708333\n",
      "test_test\n",
      "test mean loss=86764.5859375\n",
      "fin save.\n",
      "epoch 1110\n",
      "test_train\n",
      "train mean loss=62569.886458333334\n",
      "test_test\n",
      "test mean loss=86796.58203125\n",
      "fin save.\n",
      "epoch 1111\n",
      "test_train\n",
      "train mean loss=61280.531510416666\n",
      "test_test\n",
      "test mean loss=86808.08984375\n",
      "fin save.\n",
      "epoch 1112\n",
      "test_train\n",
      "train mean loss=62421.20169270833\n",
      "test_test\n",
      "test mean loss=86828.1171875\n",
      "fin save.\n",
      "epoch 1113\n",
      "test_train\n",
      "train mean loss=62943.77239583333\n",
      "test_test\n",
      "test mean loss=86791.5234375\n",
      "fin save.\n",
      "epoch 1114\n",
      "test_train\n",
      "train mean loss=62468.191666666666\n",
      "test_test\n",
      "test mean loss=86650.3046875\n",
      "fin save.\n",
      "epoch 1115\n",
      "test_train\n",
      "train mean loss=62645.42005208333\n",
      "test_test\n",
      "test mean loss=86773.1953125\n",
      "fin save.\n",
      "epoch 1116\n",
      "test_train\n",
      "train mean loss=62860.48190104167\n",
      "test_test\n",
      "test mean loss=86798.58984375\n",
      "fin save.\n",
      "epoch 1117\n",
      "test_train\n",
      "train mean loss=61818.71145833333\n",
      "test_test\n",
      "test mean loss=86834.61328125\n",
      "fin save.\n",
      "epoch 1118\n",
      "test_train\n",
      "train mean loss=61839.605729166666\n",
      "test_test\n",
      "test mean loss=86833.03515625\n",
      "fin save.\n",
      "epoch 1119\n",
      "test_train\n",
      "train mean loss=63819.260416666664\n",
      "test_test\n",
      "test mean loss=86835.44140625\n",
      "fin save.\n",
      "epoch 1120\n",
      "test_train\n",
      "train mean loss=62045.22213541667\n",
      "test_test\n",
      "test mean loss=86748.0625\n",
      "fin save.\n",
      "epoch 1121\n",
      "test_train\n",
      "train mean loss=61312.21770833333\n",
      "test_test\n",
      "test mean loss=86866.5625\n",
      "fin save.\n",
      "epoch 1122\n",
      "test_train\n",
      "train mean loss=61997.45078125\n",
      "test_test\n",
      "test mean loss=86945.4140625\n",
      "fin save.\n",
      "epoch 1123\n",
      "test_train\n",
      "train mean loss=62712.68567708333\n",
      "test_test\n",
      "test mean loss=86892.109375\n",
      "fin save.\n",
      "epoch 1124\n",
      "test_train\n",
      "train mean loss=62286.733072916664\n",
      "test_test\n",
      "test mean loss=86726.078125\n",
      "fin save.\n",
      "epoch 1125\n",
      "test_train\n",
      "train mean loss=61912.75208333333\n",
      "test_test\n",
      "test mean loss=86945.5546875\n",
      "fin save.\n",
      "epoch 1126\n",
      "test_train\n",
      "train mean loss=62213.40338541667\n",
      "test_test\n",
      "test mean loss=87223.39453125\n",
      "fin save.\n",
      "epoch 1127\n",
      "test_train\n",
      "train mean loss=61673.360677083336\n",
      "test_test\n",
      "test mean loss=87390.0703125\n",
      "fin save.\n",
      "epoch 1128\n",
      "test_train\n",
      "train mean loss=63055.28177083333\n",
      "test_test\n",
      "test mean loss=87287.26171875\n",
      "fin save.\n",
      "epoch 1129\n",
      "test_train\n",
      "train mean loss=61939.939453125\n",
      "test_test\n",
      "test mean loss=87382.71875\n",
      "fin save.\n",
      "epoch 1130\n",
      "test_train\n",
      "train mean loss=62688.948958333334\n",
      "test_test\n",
      "test mean loss=87329.96484375\n",
      "fin save.\n",
      "epoch 1131\n",
      "test_train\n",
      "train mean loss=61927.73984375\n",
      "test_test\n",
      "test mean loss=87449.35546875\n",
      "fin save.\n",
      "epoch 1132\n",
      "test_train\n",
      "train mean loss=62769.226822916666\n",
      "test_test\n",
      "test mean loss=87548.76171875\n",
      "fin save.\n",
      "epoch 1133\n",
      "test_train\n",
      "train mean loss=62334.83385416667\n",
      "test_test\n",
      "test mean loss=87333.91796875\n",
      "fin save.\n",
      "epoch 1134\n",
      "test_train\n",
      "train mean loss=62604.71171875\n",
      "test_test\n",
      "test mean loss=87516.734375\n",
      "fin save.\n",
      "epoch 1135\n",
      "test_train\n",
      "train mean loss=61592.66848958333\n",
      "test_test\n",
      "test mean loss=87400.75390625\n",
      "fin save.\n",
      "epoch 1136\n",
      "test_train\n",
      "train mean loss=62883.886979166666\n",
      "test_test\n",
      "test mean loss=87461.5546875\n",
      "fin save.\n",
      "epoch 1137\n",
      "test_train\n",
      "train mean loss=62905.064713541666\n",
      "test_test\n",
      "test mean loss=87607.14453125\n",
      "fin save.\n",
      "epoch 1138\n",
      "test_train\n",
      "train mean loss=61919.67721354167\n",
      "test_test\n",
      "test mean loss=87804.20703125\n",
      "fin save.\n",
      "epoch 1139\n",
      "test_train\n",
      "train mean loss=61988.21796875\n",
      "test_test\n",
      "test mean loss=87472.66015625\n",
      "fin save.\n",
      "epoch 1140\n",
      "test_train\n",
      "train mean loss=62354.26458333333\n",
      "test_test\n",
      "test mean loss=87212.8828125\n",
      "fin save.\n",
      "epoch 1141\n",
      "test_train\n",
      "train mean loss=61472.63515625\n",
      "test_test\n",
      "test mean loss=87242.46875\n",
      "fin save.\n",
      "epoch 1142\n",
      "test_train\n",
      "train mean loss=62545.464583333334\n",
      "test_test\n",
      "test mean loss=87081.12109375\n",
      "fin save.\n",
      "epoch 1143\n",
      "test_train\n",
      "train mean loss=62731.366796875\n",
      "test_test\n",
      "test mean loss=87275.08984375\n",
      "fin save.\n",
      "epoch 1144\n",
      "test_train\n",
      "train mean loss=62255.9359375\n",
      "test_test\n",
      "test mean loss=87077.125\n",
      "fin save.\n",
      "epoch 1145\n",
      "test_train\n",
      "train mean loss=62975.04739583333\n",
      "test_test\n",
      "test mean loss=87104.0703125\n",
      "fin save.\n",
      "epoch 1146\n",
      "test_train\n",
      "train mean loss=62662.95390625\n",
      "test_test\n",
      "test mean loss=86940.4765625\n",
      "fin save.\n",
      "epoch 1147\n",
      "test_train\n",
      "train mean loss=63379.27291666667\n",
      "test_test\n",
      "test mean loss=87138.046875\n",
      "fin save.\n",
      "epoch 1148\n",
      "test_train\n",
      "train mean loss=62482.36471354167\n",
      "test_test\n",
      "test mean loss=87032.359375\n",
      "fin save.\n",
      "epoch 1149\n",
      "test_train\n",
      "train mean loss=62203.30625\n",
      "test_test\n",
      "test mean loss=87157.96484375\n",
      "fin save.\n",
      "epoch 1150\n",
      "test_train\n",
      "train mean loss=63117.43515625\n",
      "test_test\n",
      "test mean loss=87041.68359375\n",
      "fin save.\n",
      "epoch 1151\n",
      "test_train\n",
      "train mean loss=61962.94921875\n",
      "test_test\n",
      "test mean loss=87208.4140625\n",
      "fin save.\n",
      "epoch 1152\n",
      "test_train\n",
      "train mean loss=61960.14739583333\n",
      "test_test\n",
      "test mean loss=87401.99609375\n",
      "fin save.\n",
      "epoch 1153\n",
      "test_train\n",
      "train mean loss=61834.83489583333\n",
      "test_test\n",
      "test mean loss=87512.00390625\n",
      "fin save.\n",
      "epoch 1154\n",
      "test_train\n",
      "train mean loss=62525.948958333334\n",
      "test_test\n",
      "test mean loss=87195.83984375\n",
      "fin save.\n",
      "epoch 1155\n",
      "test_train\n",
      "train mean loss=61883.7484375\n",
      "test_test\n",
      "test mean loss=87275.4140625\n",
      "fin save.\n",
      "epoch 1156\n",
      "test_train\n",
      "train mean loss=60523.75885416667\n",
      "test_test\n",
      "test mean loss=87321.75\n",
      "fin save.\n",
      "epoch 1157\n",
      "test_train\n",
      "train mean loss=62237.47955729167\n",
      "test_test\n",
      "test mean loss=87280.44140625\n",
      "fin save.\n",
      "epoch 1158\n",
      "test_train\n",
      "train mean loss=63339.367447916666\n",
      "test_test\n",
      "test mean loss=87071.16796875\n",
      "fin save.\n",
      "epoch 1159\n",
      "test_train\n",
      "train mean loss=62528.254166666666\n",
      "test_test\n",
      "test mean loss=87216.68359375\n",
      "fin save.\n",
      "epoch 1160\n",
      "test_train\n",
      "train mean loss=62275.372786458334\n",
      "test_test\n",
      "test mean loss=87154.93359375\n",
      "fin save.\n",
      "epoch 1161\n",
      "test_train\n",
      "train mean loss=62064.304427083334\n",
      "test_test\n",
      "test mean loss=87138.05859375\n",
      "fin save.\n",
      "epoch 1162\n",
      "test_train\n",
      "train mean loss=62427.75885416667\n",
      "test_test\n",
      "test mean loss=87347.26171875\n",
      "fin save.\n",
      "epoch 1163\n",
      "test_train\n",
      "train mean loss=63167.3765625\n",
      "test_test\n",
      "test mean loss=87317.6796875\n",
      "fin save.\n",
      "epoch 1164\n",
      "test_train\n",
      "train mean loss=63078.48151041667\n",
      "test_test\n",
      "test mean loss=86781.328125\n",
      "fin save.\n",
      "epoch 1165\n",
      "test_train\n",
      "train mean loss=63210.273697916666\n",
      "test_test\n",
      "test mean loss=86464.55859375\n",
      "fin save.\n",
      "epoch 1166\n",
      "test_train\n",
      "train mean loss=63028.10651041667\n",
      "test_test\n",
      "test mean loss=86704.8671875\n",
      "fin save.\n",
      "epoch 1167\n",
      "test_train\n",
      "train mean loss=61952.03671875\n",
      "test_test\n",
      "test mean loss=86795.59375\n",
      "fin save.\n",
      "epoch 1168\n",
      "test_train\n",
      "train mean loss=62747.579427083336\n",
      "test_test\n",
      "test mean loss=86701.09765625\n",
      "fin save.\n",
      "epoch 1169\n",
      "test_train\n",
      "train mean loss=61997.239583333336\n",
      "test_test\n",
      "test mean loss=86542.171875\n",
      "fin save.\n",
      "epoch 1170\n",
      "test_train\n",
      "train mean loss=62873.243359375\n",
      "test_test\n",
      "test mean loss=86580.953125\n",
      "fin save.\n",
      "epoch 1171\n",
      "test_train\n",
      "train mean loss=62225.61953125\n",
      "test_test\n",
      "test mean loss=86493.7578125\n",
      "fin save.\n",
      "epoch 1172\n",
      "test_train\n",
      "train mean loss=62342.724869791666\n",
      "test_test\n",
      "test mean loss=86534.7265625\n",
      "fin save.\n",
      "epoch 1173\n",
      "test_train\n",
      "train mean loss=62307.80416666667\n",
      "test_test\n",
      "test mean loss=86698.55078125\n",
      "fin save.\n",
      "epoch 1174\n",
      "test_train\n",
      "train mean loss=62748.0265625\n",
      "test_test\n",
      "test mean loss=86629.28515625\n",
      "fin save.\n",
      "epoch 1175\n",
      "test_train\n",
      "train mean loss=62277.76354166667\n",
      "test_test\n",
      "test mean loss=86467.09765625\n",
      "fin save.\n",
      "epoch 1176\n",
      "test_train\n",
      "train mean loss=63070.284505208336\n",
      "test_test\n",
      "test mean loss=86465.48828125\n",
      "fin save.\n",
      "epoch 1177\n",
      "test_train\n",
      "train mean loss=63201.07213541667\n",
      "test_test\n",
      "test mean loss=86653.6953125\n",
      "fin save.\n",
      "epoch 1178\n",
      "test_train\n",
      "train mean loss=61537.9859375\n",
      "test_test\n",
      "test mean loss=86575.27734375\n",
      "fin save.\n",
      "epoch 1179\n",
      "test_train\n",
      "train mean loss=62546.81536458333\n",
      "test_test\n",
      "test mean loss=86509.35546875\n",
      "fin save.\n",
      "epoch 1180\n",
      "test_train\n",
      "train mean loss=61482.45520833333\n",
      "test_test\n",
      "test mean loss=86695.90234375\n",
      "fin save.\n",
      "epoch 1181\n",
      "test_train\n",
      "train mean loss=62264.44244791667\n",
      "test_test\n",
      "test mean loss=86503.4765625\n",
      "fin save.\n",
      "epoch 1182\n",
      "test_train\n",
      "train mean loss=62330.247395833336\n",
      "test_test\n",
      "test mean loss=86606.41015625\n",
      "fin save.\n",
      "epoch 1183\n",
      "test_train\n",
      "train mean loss=62254.68177083333\n",
      "test_test\n",
      "test mean loss=86530.9296875\n",
      "fin save.\n",
      "epoch 1184\n",
      "test_train\n",
      "train mean loss=62734.4375\n",
      "test_test\n",
      "test mean loss=86567.27734375\n",
      "fin save.\n",
      "epoch 1185\n",
      "test_train\n",
      "train mean loss=62340.79791666667\n",
      "test_test\n",
      "test mean loss=86793.94921875\n",
      "fin save.\n",
      "epoch 1186\n",
      "test_train\n",
      "train mean loss=62380.791666666664\n",
      "test_test\n",
      "test mean loss=86442.8203125\n",
      "fin save.\n",
      "epoch 1187\n",
      "test_train\n",
      "train mean loss=62792.44765625\n",
      "test_test\n",
      "test mean loss=86454.2421875\n",
      "fin save.\n",
      "epoch 1188\n",
      "test_train\n",
      "train mean loss=61896.219010416666\n",
      "test_test\n",
      "test mean loss=86551.6328125\n",
      "fin save.\n",
      "epoch 1189\n",
      "test_train\n",
      "train mean loss=62296.554947916666\n",
      "test_test\n",
      "test mean loss=86573.8125\n",
      "fin save.\n",
      "epoch 1190\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=62957.282942708334\n",
      "test_test\n",
      "test mean loss=86379.94140625\n",
      "fin save.\n",
      "epoch 1191\n",
      "test_train\n",
      "train mean loss=62079.41328125\n",
      "test_test\n",
      "test mean loss=86615.4296875\n",
      "fin save.\n",
      "epoch 1192\n",
      "test_train\n",
      "train mean loss=63136.7078125\n",
      "test_test\n",
      "test mean loss=86560.37890625\n",
      "fin save.\n",
      "epoch 1193\n",
      "test_train\n",
      "train mean loss=62162.18359375\n",
      "test_test\n",
      "test mean loss=86626.75390625\n",
      "fin save.\n",
      "epoch 1194\n",
      "test_train\n",
      "train mean loss=61830.10625\n",
      "test_test\n",
      "test mean loss=86569.71484375\n",
      "fin save.\n",
      "epoch 1195\n",
      "test_train\n",
      "train mean loss=62902.28229166667\n",
      "test_test\n",
      "test mean loss=86713.86328125\n",
      "fin save.\n",
      "epoch 1196\n",
      "test_train\n",
      "train mean loss=62470.48203125\n",
      "test_test\n",
      "test mean loss=86675.44140625\n",
      "fin save.\n",
      "epoch 1197\n",
      "test_train\n",
      "train mean loss=62842.092447916664\n",
      "test_test\n",
      "test mean loss=86666.890625\n",
      "fin save.\n",
      "epoch 1198\n",
      "test_train\n",
      "train mean loss=61989.150651041666\n",
      "test_test\n",
      "test mean loss=86799.078125\n",
      "fin save.\n",
      "epoch 1199\n",
      "test_train\n",
      "train mean loss=62776.75598958333\n",
      "test_test\n",
      "test mean loss=87255.87109375\n",
      "fin save.\n",
      "epoch 1200\n",
      "test_train\n",
      "train mean loss=62420.46484375\n",
      "test_test\n",
      "test mean loss=87312.17578125\n",
      "fin save.\n",
      "epoch 1201\n",
      "test_train\n",
      "train mean loss=63023.96875\n",
      "test_test\n",
      "test mean loss=87381.828125\n",
      "fin save.\n",
      "epoch 1202\n",
      "test_train\n",
      "train mean loss=62067.709375\n",
      "test_test\n",
      "test mean loss=87419.28125\n",
      "fin save.\n",
      "epoch 1203\n",
      "test_train\n",
      "train mean loss=62731.59270833333\n",
      "test_test\n",
      "test mean loss=87039.8671875\n",
      "fin save.\n",
      "epoch 1204\n",
      "test_train\n",
      "train mean loss=62480.988541666666\n",
      "test_test\n",
      "test mean loss=87137.6875\n",
      "fin save.\n",
      "epoch 1205\n",
      "test_train\n",
      "train mean loss=62135.62682291667\n",
      "test_test\n",
      "test mean loss=86869.78515625\n",
      "fin save.\n",
      "epoch 1206\n",
      "test_train\n",
      "train mean loss=62794.32721354167\n",
      "test_test\n",
      "test mean loss=86630.72265625\n",
      "fin save.\n",
      "epoch 1207\n",
      "test_train\n",
      "train mean loss=63086.81341145833\n",
      "test_test\n",
      "test mean loss=86693.82421875\n",
      "fin save.\n",
      "epoch 1208\n",
      "test_train\n",
      "train mean loss=62030.399088541664\n",
      "test_test\n",
      "test mean loss=86972.78125\n",
      "fin save.\n",
      "epoch 1209\n",
      "test_train\n",
      "train mean loss=61843.84075520833\n",
      "test_test\n",
      "test mean loss=87032.2890625\n",
      "fin save.\n",
      "epoch 1210\n",
      "test_train\n",
      "train mean loss=62726.612890625\n",
      "test_test\n",
      "test mean loss=86891.3515625\n",
      "fin save.\n",
      "epoch 1211\n",
      "test_train\n",
      "train mean loss=62391.07578125\n",
      "test_test\n",
      "test mean loss=87383.01171875\n",
      "fin save.\n",
      "epoch 1212\n",
      "test_train\n",
      "train mean loss=62993.613541666666\n",
      "test_test\n",
      "test mean loss=87044.0\n",
      "fin save.\n",
      "epoch 1213\n",
      "test_train\n",
      "train mean loss=61568.81692708333\n",
      "test_test\n",
      "test mean loss=87108.15234375\n",
      "fin save.\n",
      "epoch 1214\n",
      "test_train\n",
      "train mean loss=62406.83645833333\n",
      "test_test\n",
      "test mean loss=87228.08203125\n",
      "fin save.\n",
      "epoch 1215\n",
      "test_train\n",
      "train mean loss=61826.580859375\n",
      "test_test\n",
      "test mean loss=87329.55859375\n",
      "fin save.\n",
      "epoch 1216\n",
      "test_train\n",
      "train mean loss=62002.2625\n",
      "test_test\n",
      "test mean loss=87248.73046875\n",
      "fin save.\n",
      "epoch 1217\n",
      "test_train\n",
      "train mean loss=62408.886458333334\n",
      "test_test\n",
      "test mean loss=87250.41015625\n",
      "fin save.\n",
      "epoch 1218\n",
      "test_train\n",
      "train mean loss=62208.66744791667\n",
      "test_test\n",
      "test mean loss=87098.55078125\n",
      "fin save.\n",
      "epoch 1219\n",
      "test_train\n",
      "train mean loss=61784.251302083336\n",
      "test_test\n",
      "test mean loss=86866.77734375\n",
      "fin save.\n",
      "epoch 1220\n",
      "test_train\n",
      "train mean loss=62511.771875\n",
      "test_test\n",
      "test mean loss=87080.9765625\n",
      "fin save.\n",
      "epoch 1221\n",
      "test_train\n",
      "train mean loss=62607.56744791667\n",
      "test_test\n",
      "test mean loss=87067.23046875\n",
      "fin save.\n",
      "epoch 1222\n",
      "test_train\n",
      "train mean loss=62614.226822916666\n",
      "test_test\n",
      "test mean loss=87095.2109375\n",
      "fin save.\n",
      "epoch 1223\n",
      "test_train\n",
      "train mean loss=62270.88958333333\n",
      "test_test\n",
      "test mean loss=87028.02734375\n",
      "fin save.\n",
      "epoch 1224\n",
      "test_train\n",
      "train mean loss=62495.17421875\n",
      "test_test\n",
      "test mean loss=86940.10546875\n",
      "fin save.\n",
      "epoch 1225\n",
      "test_train\n",
      "train mean loss=61543.71796875\n",
      "test_test\n",
      "test mean loss=86732.1484375\n",
      "fin save.\n",
      "epoch 1226\n",
      "test_train\n",
      "train mean loss=62620.29296875\n",
      "test_test\n",
      "test mean loss=86877.0078125\n",
      "fin save.\n",
      "epoch 1227\n",
      "test_train\n",
      "train mean loss=62768.575520833336\n",
      "test_test\n",
      "test mean loss=87172.09765625\n",
      "fin save.\n",
      "epoch 1228\n",
      "test_train\n",
      "train mean loss=62620.26484375\n",
      "test_test\n",
      "test mean loss=86762.55078125\n",
      "fin save.\n",
      "epoch 1229\n",
      "test_train\n",
      "train mean loss=62248.87786458333\n",
      "test_test\n",
      "test mean loss=86726.43359375\n",
      "fin save.\n",
      "epoch 1230\n",
      "test_train\n",
      "train mean loss=62680.08541666667\n",
      "test_test\n",
      "test mean loss=86702.88671875\n",
      "fin save.\n",
      "epoch 1231\n",
      "test_train\n",
      "train mean loss=61940.5015625\n",
      "test_test\n",
      "test mean loss=86690.46875\n",
      "fin save.\n",
      "epoch 1232\n",
      "test_train\n",
      "train mean loss=62925.68854166667\n",
      "test_test\n",
      "test mean loss=86514.53125\n",
      "fin save.\n",
      "epoch 1233\n",
      "test_train\n",
      "train mean loss=61479.89921875\n",
      "test_test\n",
      "test mean loss=86625.2578125\n",
      "fin save.\n",
      "epoch 1234\n",
      "test_train\n",
      "train mean loss=62459.24713541667\n",
      "test_test\n",
      "test mean loss=86832.796875\n",
      "fin save.\n",
      "epoch 1235\n",
      "test_train\n",
      "train mean loss=61813.944140625\n",
      "test_test\n",
      "test mean loss=86874.7890625\n",
      "fin save.\n",
      "epoch 1236\n",
      "test_train\n",
      "train mean loss=62123.1875\n",
      "test_test\n",
      "test mean loss=86794.87890625\n",
      "fin save.\n",
      "epoch 1237\n",
      "test_train\n",
      "train mean loss=62292.52682291667\n",
      "test_test\n",
      "test mean loss=86661.046875\n",
      "fin save.\n",
      "epoch 1238\n",
      "test_train\n",
      "train mean loss=63332.654947916664\n",
      "test_test\n",
      "test mean loss=86797.8828125\n",
      "fin save.\n",
      "epoch 1239\n",
      "test_train\n",
      "train mean loss=62111.96015625\n",
      "test_test\n",
      "test mean loss=86620.09375\n",
      "fin save.\n",
      "epoch 1240\n",
      "test_train\n",
      "train mean loss=63219.01171875\n",
      "test_test\n",
      "test mean loss=86769.79296875\n",
      "fin save.\n",
      "epoch 1241\n",
      "test_train\n",
      "train mean loss=61804.80390625\n",
      "test_test\n",
      "test mean loss=86859.82421875\n",
      "fin save.\n",
      "epoch 1242\n",
      "test_train\n",
      "train mean loss=63287.80260416667\n",
      "test_test\n",
      "test mean loss=86887.9453125\n",
      "fin save.\n",
      "epoch 1243\n",
      "test_train\n",
      "train mean loss=62103.419270833336\n",
      "test_test\n",
      "test mean loss=86868.8203125\n",
      "fin save.\n",
      "epoch 1244\n",
      "test_train\n",
      "train mean loss=62338.90729166667\n",
      "test_test\n",
      "test mean loss=86884.76171875\n",
      "fin save.\n",
      "epoch 1245\n",
      "test_train\n",
      "train mean loss=62383.7203125\n",
      "test_test\n",
      "test mean loss=86807.76171875\n",
      "fin save.\n",
      "epoch 1246\n",
      "test_train\n",
      "train mean loss=63017.753645833334\n",
      "test_test\n",
      "test mean loss=86717.703125\n",
      "fin save.\n",
      "epoch 1247\n",
      "test_train\n",
      "train mean loss=62444.856770833336\n",
      "test_test\n",
      "test mean loss=86967.46484375\n",
      "fin save.\n",
      "epoch 1248\n",
      "test_train\n",
      "train mean loss=62697.197005208334\n",
      "test_test\n",
      "test mean loss=86896.3125\n",
      "fin save.\n",
      "epoch 1249\n",
      "test_train\n",
      "train mean loss=62058.47708333333\n",
      "test_test\n",
      "test mean loss=86971.07421875\n",
      "fin save.\n",
      "epoch 1250\n",
      "test_train\n",
      "train mean loss=61779.3484375\n",
      "test_test\n",
      "test mean loss=87035.796875\n",
      "fin save.\n",
      "epoch 1251\n",
      "test_train\n",
      "train mean loss=61718.52109375\n",
      "test_test\n",
      "test mean loss=86971.4375\n",
      "fin save.\n",
      "epoch 1252\n",
      "test_train\n",
      "train mean loss=62758.86510416667\n",
      "test_test\n",
      "test mean loss=86897.69140625\n",
      "fin save.\n",
      "epoch 1253\n",
      "test_train\n",
      "train mean loss=62784.263671875\n",
      "test_test\n",
      "test mean loss=87042.09765625\n",
      "fin save.\n",
      "epoch 1254\n",
      "test_train\n",
      "train mean loss=62195.155989583334\n",
      "test_test\n",
      "test mean loss=87211.95703125\n",
      "fin save.\n",
      "epoch 1255\n",
      "test_train\n",
      "train mean loss=61983.366015625\n",
      "test_test\n",
      "test mean loss=87092.140625\n",
      "fin save.\n",
      "epoch 1256\n",
      "test_train\n",
      "train mean loss=62579.08046875\n",
      "test_test\n",
      "test mean loss=87144.28515625\n",
      "fin save.\n",
      "epoch 1257\n",
      "test_train\n",
      "train mean loss=62709.97734375\n",
      "test_test\n",
      "test mean loss=87006.24609375\n",
      "fin save.\n",
      "epoch 1258\n",
      "test_train\n",
      "train mean loss=62565.65729166667\n",
      "test_test\n",
      "test mean loss=87149.4453125\n",
      "fin save.\n",
      "epoch 1259\n",
      "test_train\n",
      "train mean loss=62496.24505208333\n",
      "test_test\n",
      "test mean loss=87060.3984375\n",
      "fin save.\n",
      "epoch 1260\n",
      "test_train\n",
      "train mean loss=61934.86276041667\n",
      "test_test\n",
      "test mean loss=86957.375\n",
      "fin save.\n",
      "epoch 1261\n",
      "test_train\n",
      "train mean loss=62322.07760416667\n",
      "test_test\n",
      "test mean loss=87023.1171875\n",
      "fin save.\n",
      "epoch 1262\n",
      "test_train\n",
      "train mean loss=62968.0546875\n",
      "test_test\n",
      "test mean loss=86960.4140625\n",
      "fin save.\n",
      "epoch 1263\n",
      "test_train\n",
      "train mean loss=62662.78411458333\n",
      "test_test\n",
      "test mean loss=87016.08984375\n",
      "fin save.\n",
      "epoch 1264\n",
      "test_train\n",
      "train mean loss=61382.20989583333\n",
      "test_test\n",
      "test mean loss=86908.625\n",
      "fin save.\n",
      "epoch 1265\n",
      "test_train\n",
      "train mean loss=62885.76901041667\n",
      "test_test\n",
      "test mean loss=87042.984375\n",
      "fin save.\n",
      "epoch 1266\n",
      "test_train\n",
      "train mean loss=62840.034505208336\n",
      "test_test\n",
      "test mean loss=87163.12109375\n",
      "fin save.\n",
      "epoch 1267\n",
      "test_train\n",
      "train mean loss=61653.310286458334\n",
      "test_test\n",
      "test mean loss=86912.0625\n",
      "fin save.\n",
      "epoch 1268\n",
      "test_train\n",
      "train mean loss=62529.78958333333\n",
      "test_test\n",
      "test mean loss=86939.89453125\n",
      "fin save.\n",
      "epoch 1269\n",
      "test_train\n",
      "train mean loss=62267.21640625\n",
      "test_test\n",
      "test mean loss=87081.54296875\n",
      "fin save.\n",
      "epoch 1270\n",
      "test_train\n",
      "train mean loss=61790.427473958334\n",
      "test_test\n",
      "test mean loss=86984.38671875\n",
      "fin save.\n",
      "epoch 1271\n",
      "test_train\n",
      "train mean loss=62151.907552083336\n",
      "test_test\n",
      "test mean loss=86963.35546875\n",
      "fin save.\n",
      "epoch 1272\n",
      "test_train\n",
      "train mean loss=62453.225260416664\n",
      "test_test\n",
      "test mean loss=86778.265625\n",
      "fin save.\n",
      "epoch 1273\n",
      "test_train\n",
      "train mean loss=62096.76848958333\n",
      "test_test\n",
      "test mean loss=86710.19140625\n",
      "fin save.\n",
      "epoch 1274\n",
      "test_train\n",
      "train mean loss=62748.594921875\n",
      "test_test\n",
      "test mean loss=86851.92578125\n",
      "fin save.\n",
      "epoch 1275\n",
      "test_train\n",
      "train mean loss=62967.010416666664\n",
      "test_test\n",
      "test mean loss=86652.54296875\n",
      "fin save.\n",
      "epoch 1276\n",
      "test_train\n",
      "train mean loss=61367.1515625\n",
      "test_test\n",
      "test mean loss=86712.72265625\n",
      "fin save.\n",
      "epoch 1277\n",
      "test_train\n",
      "train mean loss=62377.32473958333\n",
      "test_test\n",
      "test mean loss=86928.2578125\n",
      "fin save.\n",
      "epoch 1278\n",
      "test_train\n",
      "train mean loss=61904.726822916666\n",
      "test_test\n",
      "test mean loss=86770.5078125\n",
      "fin save.\n",
      "epoch 1279\n",
      "test_train\n",
      "train mean loss=61816.68359375\n",
      "test_test\n",
      "test mean loss=86890.66015625\n",
      "fin save.\n",
      "epoch 1280\n",
      "test_train\n",
      "train mean loss=62748.47994791667\n",
      "test_test\n",
      "test mean loss=86918.609375\n",
      "fin save.\n",
      "epoch 1281\n",
      "test_train\n",
      "train mean loss=62426.627604166664\n",
      "test_test\n",
      "test mean loss=86833.2265625\n",
      "fin save.\n",
      "epoch 1282\n",
      "test_train\n",
      "train mean loss=61550.3234375\n",
      "test_test\n",
      "test mean loss=86860.140625\n",
      "fin save.\n",
      "epoch 1283\n",
      "test_train\n",
      "train mean loss=62122.55065104167\n",
      "test_test\n",
      "test mean loss=86849.56640625\n",
      "fin save.\n",
      "epoch 1284\n",
      "test_train\n",
      "train mean loss=62869.087890625\n",
      "test_test\n",
      "test mean loss=86842.30859375\n",
      "fin save.\n",
      "epoch 1285\n",
      "test_train\n",
      "train mean loss=62451.72057291667\n",
      "test_test\n",
      "test mean loss=86923.2734375\n",
      "fin save.\n",
      "epoch 1286\n",
      "test_train\n",
      "train mean loss=62890.88984375\n",
      "test_test\n",
      "test mean loss=86811.7421875\n",
      "fin save.\n",
      "epoch 1287\n",
      "test_train\n",
      "train mean loss=61886.6921875\n",
      "test_test\n",
      "test mean loss=86838.11328125\n",
      "fin save.\n",
      "epoch 1288\n",
      "test_train\n",
      "train mean loss=62947.511458333334\n",
      "test_test\n",
      "test mean loss=87051.01953125\n",
      "fin save.\n",
      "epoch 1289\n",
      "test_train\n",
      "train mean loss=62464.775\n",
      "test_test\n",
      "test mean loss=87137.55078125\n",
      "fin save.\n",
      "epoch 1290\n",
      "test_train\n",
      "train mean loss=62799.88528645833\n",
      "test_test\n",
      "test mean loss=86782.36328125\n",
      "fin save.\n",
      "epoch 1291\n",
      "test_train\n",
      "train mean loss=62157.66002604167\n",
      "test_test\n",
      "test mean loss=87046.98828125\n",
      "fin save.\n",
      "epoch 1292\n",
      "test_train\n",
      "train mean loss=62738.72265625\n",
      "test_test\n",
      "test mean loss=87003.359375\n",
      "fin save.\n",
      "epoch 1293\n",
      "test_train\n",
      "train mean loss=62196.745833333334\n",
      "test_test\n",
      "test mean loss=86623.21875\n",
      "fin save.\n",
      "epoch 1294\n",
      "test_train\n",
      "train mean loss=61504.178385416664\n",
      "test_test\n",
      "test mean loss=86619.796875\n",
      "fin save.\n",
      "epoch 1295\n",
      "test_train\n",
      "train mean loss=62885.3140625\n",
      "test_test\n",
      "test mean loss=86980.61328125\n",
      "fin save.\n",
      "epoch 1296\n",
      "test_train\n",
      "train mean loss=62662.408854166664\n",
      "test_test\n",
      "test mean loss=86993.34375\n",
      "fin save.\n",
      "epoch 1297\n",
      "test_train\n",
      "train mean loss=62180.480208333334\n",
      "test_test\n",
      "test mean loss=86847.74609375\n",
      "fin save.\n",
      "epoch 1298\n",
      "test_train\n",
      "train mean loss=62805.616927083334\n",
      "test_test\n",
      "test mean loss=86922.2109375\n",
      "fin save.\n",
      "epoch 1299\n",
      "test_train\n",
      "train mean loss=62791.613541666666\n",
      "test_test\n",
      "test mean loss=86969.0234375\n",
      "fin save.\n",
      "epoch 1300\n",
      "test_train\n",
      "train mean loss=62300.1828125\n",
      "test_test\n",
      "test mean loss=86766.95703125\n",
      "fin save.\n",
      "epoch 1301\n",
      "test_train\n",
      "train mean loss=62636.382161458336\n",
      "test_test\n",
      "test mean loss=86882.515625\n",
      "fin save.\n",
      "epoch 1302\n",
      "test_train\n",
      "train mean loss=61784.756119791666\n",
      "test_test\n",
      "test mean loss=86550.77734375\n",
      "fin save.\n",
      "epoch 1303\n",
      "test_train\n",
      "train mean loss=61970.419661458334\n",
      "test_test\n",
      "test mean loss=87107.3359375\n",
      "fin save.\n",
      "epoch 1304\n",
      "test_train\n",
      "train mean loss=61440.311197916664\n",
      "test_test\n",
      "test mean loss=87056.171875\n",
      "fin save.\n",
      "epoch 1305\n",
      "test_train\n",
      "train mean loss=61512.24375\n",
      "test_test\n",
      "test mean loss=87040.09375\n",
      "fin save.\n",
      "epoch 1306\n",
      "test_train\n",
      "train mean loss=63071.36875\n",
      "test_test\n",
      "test mean loss=86863.99609375\n",
      "fin save.\n",
      "epoch 1307\n",
      "test_train\n",
      "train mean loss=61458.74114583333\n",
      "test_test\n",
      "test mean loss=87102.9296875\n",
      "fin save.\n",
      "epoch 1308\n",
      "test_train\n",
      "train mean loss=62431.636458333334\n",
      "test_test\n",
      "test mean loss=87165.64453125\n",
      "fin save.\n",
      "epoch 1309\n",
      "test_train\n",
      "train mean loss=62061.30234375\n",
      "test_test\n",
      "test mean loss=87022.97265625\n",
      "fin save.\n",
      "epoch 1310\n",
      "test_train\n",
      "train mean loss=62032.873307291666\n",
      "test_test\n",
      "test mean loss=87267.80078125\n",
      "fin save.\n",
      "epoch 1311\n",
      "test_train\n",
      "train mean loss=61673.386979166666\n",
      "test_test\n",
      "test mean loss=86945.6015625\n",
      "fin save.\n",
      "epoch 1312\n",
      "test_train\n",
      "train mean loss=63196.39114583333\n",
      "test_test\n",
      "test mean loss=86969.34765625\n",
      "fin save.\n",
      "epoch 1313\n",
      "test_train\n",
      "train mean loss=61409.310807291666\n",
      "test_test\n",
      "test mean loss=86478.37109375\n",
      "fin save.\n",
      "epoch 1314\n",
      "test_train\n",
      "train mean loss=60795.35559895833\n",
      "test_test\n",
      "test mean loss=86541.203125\n",
      "fin save.\n",
      "epoch 1315\n",
      "test_train\n",
      "train mean loss=61460.621354166666\n",
      "test_test\n",
      "test mean loss=86602.296875\n",
      "fin save.\n",
      "epoch 1316\n",
      "test_train\n",
      "train mean loss=61695.155078125\n",
      "test_test\n",
      "test mean loss=86431.9453125\n",
      "fin save.\n",
      "epoch 1317\n",
      "test_train\n",
      "train mean loss=61925.249348958336\n",
      "test_test\n",
      "test mean loss=86375.453125\n",
      "fin save.\n",
      "epoch 1318\n",
      "test_train\n",
      "train mean loss=61571.179427083334\n",
      "test_test\n",
      "test mean loss=86367.16015625\n",
      "fin save.\n",
      "epoch 1319\n",
      "test_train\n",
      "train mean loss=62043.31158854167\n",
      "test_test\n",
      "test mean loss=86377.171875\n",
      "fin save.\n",
      "epoch 1320\n",
      "test_train\n",
      "train mean loss=61773.145833333336\n",
      "test_test\n",
      "test mean loss=86400.046875\n",
      "fin save.\n",
      "epoch 1321\n",
      "test_train\n",
      "train mean loss=62128.86328125\n",
      "test_test\n",
      "test mean loss=86441.34765625\n",
      "fin save.\n",
      "epoch 1322\n",
      "test_train\n",
      "train mean loss=63501.52630208333\n",
      "test_test\n",
      "test mean loss=86657.421875\n",
      "fin save.\n",
      "epoch 1323\n",
      "test_train\n",
      "train mean loss=62236.068098958334\n",
      "test_test\n",
      "test mean loss=86276.23828125\n",
      "fin save.\n",
      "epoch 1324\n",
      "test_train\n",
      "train mean loss=62607.925390625\n",
      "test_test\n",
      "test mean loss=86429.73828125\n",
      "fin save.\n",
      "epoch 1325\n",
      "test_train\n",
      "train mean loss=61655.528645833336\n",
      "test_test\n",
      "test mean loss=86447.09375\n",
      "fin save.\n",
      "epoch 1326\n",
      "test_train\n",
      "train mean loss=61850.05703125\n",
      "test_test\n",
      "test mean loss=86739.4609375\n",
      "fin save.\n",
      "epoch 1327\n",
      "test_train\n",
      "train mean loss=61763.06731770833\n",
      "test_test\n",
      "test mean loss=86604.38671875\n",
      "fin save.\n",
      "epoch 1328\n",
      "test_train\n",
      "train mean loss=61702.404947916664\n",
      "test_test\n",
      "test mean loss=86696.01953125\n",
      "fin save.\n",
      "epoch 1329\n",
      "test_train\n",
      "train mean loss=63661.91744791667\n",
      "test_test\n",
      "test mean loss=86519.90234375\n",
      "fin save.\n",
      "epoch 1330\n",
      "test_train\n",
      "train mean loss=62649.5140625\n",
      "test_test\n",
      "test mean loss=86417.921875\n",
      "fin save.\n",
      "epoch 1331\n",
      "test_train\n",
      "train mean loss=61833.715625\n",
      "test_test\n",
      "test mean loss=86489.97265625\n",
      "fin save.\n",
      "epoch 1332\n",
      "test_train\n",
      "train mean loss=62284.684375\n",
      "test_test\n",
      "test mean loss=86640.1015625\n",
      "fin save.\n",
      "epoch 1333\n",
      "test_train\n",
      "train mean loss=61772.53229166667\n",
      "test_test\n",
      "test mean loss=86691.9296875\n",
      "fin save.\n",
      "epoch 1334\n",
      "test_train\n",
      "train mean loss=62499.589583333334\n",
      "test_test\n",
      "test mean loss=86753.57421875\n",
      "fin save.\n",
      "epoch 1335\n",
      "test_train\n",
      "train mean loss=62630.71666666667\n",
      "test_test\n",
      "test mean loss=86686.42578125\n",
      "fin save.\n",
      "epoch 1336\n",
      "test_train\n",
      "train mean loss=62059.576953125\n",
      "test_test\n",
      "test mean loss=86696.15234375\n",
      "fin save.\n",
      "epoch 1337\n",
      "test_train\n",
      "train mean loss=61180.003515625\n",
      "test_test\n",
      "test mean loss=86618.0703125\n",
      "fin save.\n",
      "epoch 1338\n",
      "test_train\n",
      "train mean loss=62674.159895833334\n",
      "test_test\n",
      "test mean loss=86567.4921875\n",
      "fin save.\n",
      "epoch 1339\n",
      "test_train\n",
      "train mean loss=62284.79296875\n",
      "test_test\n",
      "test mean loss=86565.109375\n",
      "fin save.\n",
      "epoch 1340\n",
      "test_train\n",
      "train mean loss=62137.960546875\n",
      "test_test\n",
      "test mean loss=86658.92578125\n",
      "fin save.\n",
      "epoch 1341\n",
      "test_train\n",
      "train mean loss=61796.516927083336\n",
      "test_test\n",
      "test mean loss=86752.33984375\n",
      "fin save.\n",
      "epoch 1342\n",
      "test_train\n",
      "train mean loss=62720.18932291667\n",
      "test_test\n",
      "test mean loss=86738.234375\n",
      "fin save.\n",
      "epoch 1343\n",
      "test_train\n",
      "train mean loss=62383.17877604167\n",
      "test_test\n",
      "test mean loss=86693.046875\n",
      "fin save.\n",
      "epoch 1344\n",
      "test_train\n",
      "train mean loss=62506.83802083333\n",
      "test_test\n",
      "test mean loss=86895.69140625\n",
      "fin save.\n",
      "epoch 1345\n",
      "test_train\n",
      "train mean loss=62130.00703125\n",
      "test_test\n",
      "test mean loss=86856.3984375\n",
      "fin save.\n",
      "epoch 1346\n",
      "test_train\n",
      "train mean loss=61789.570052083334\n",
      "test_test\n",
      "test mean loss=86800.74609375\n",
      "fin save.\n",
      "epoch 1347\n",
      "test_train\n",
      "train mean loss=61418.240885416664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_test\n",
      "test mean loss=86781.19921875\n",
      "fin save.\n",
      "epoch 1348\n",
      "test_train\n",
      "train mean loss=61766.78463541667\n",
      "test_test\n",
      "test mean loss=86424.61328125\n",
      "fin save.\n",
      "epoch 1349\n",
      "test_train\n",
      "train mean loss=61786.04765625\n",
      "test_test\n",
      "test mean loss=86853.48046875\n",
      "fin save.\n",
      "epoch 1350\n",
      "test_train\n",
      "train mean loss=62504.29791666667\n",
      "test_test\n",
      "test mean loss=86707.98046875\n",
      "fin save.\n",
      "epoch 1351\n",
      "test_train\n",
      "train mean loss=62310.11380208333\n",
      "test_test\n",
      "test mean loss=86535.97265625\n",
      "fin save.\n",
      "epoch 1352\n",
      "test_train\n",
      "train mean loss=62374.86015625\n",
      "test_test\n",
      "test mean loss=86629.2421875\n",
      "fin save.\n",
      "epoch 1353\n",
      "test_train\n",
      "train mean loss=60660.782552083336\n",
      "test_test\n",
      "test mean loss=86607.63671875\n",
      "fin save.\n",
      "epoch 1354\n",
      "test_train\n",
      "train mean loss=62112.7375\n",
      "test_test\n",
      "test mean loss=86656.15625\n",
      "fin save.\n",
      "epoch 1355\n",
      "test_train\n",
      "train mean loss=63085.76419270833\n",
      "test_test\n",
      "test mean loss=86727.71484375\n",
      "fin save.\n",
      "epoch 1356\n",
      "test_train\n",
      "train mean loss=61093.83151041667\n",
      "test_test\n",
      "test mean loss=86719.6328125\n",
      "fin save.\n",
      "epoch 1357\n",
      "test_train\n",
      "train mean loss=63437.640625\n",
      "test_test\n",
      "test mean loss=86738.07421875\n",
      "fin save.\n",
      "epoch 1358\n",
      "test_train\n",
      "train mean loss=62766.227864583336\n",
      "test_test\n",
      "test mean loss=86719.609375\n",
      "fin save.\n",
      "epoch 1359\n",
      "test_train\n",
      "train mean loss=62335.516276041664\n",
      "test_test\n",
      "test mean loss=86679.9765625\n",
      "fin save.\n",
      "epoch 1360\n",
      "test_train\n",
      "train mean loss=61609.847916666666\n",
      "test_test\n",
      "test mean loss=86680.39453125\n",
      "fin save.\n",
      "epoch 1361\n",
      "test_train\n",
      "train mean loss=62292.784895833334\n",
      "test_test\n",
      "test mean loss=86932.55078125\n",
      "fin save.\n",
      "epoch 1362\n",
      "test_train\n",
      "train mean loss=62309.8390625\n",
      "test_test\n",
      "test mean loss=86943.49609375\n",
      "fin save.\n",
      "epoch 1363\n",
      "test_train\n",
      "train mean loss=62108.01875\n",
      "test_test\n",
      "test mean loss=86871.10546875\n",
      "fin save.\n",
      "epoch 1364\n",
      "test_train\n",
      "train mean loss=62798.766927083336\n",
      "test_test\n",
      "test mean loss=86623.80859375\n",
      "fin save.\n",
      "epoch 1365\n",
      "test_train\n",
      "train mean loss=61957.84661458333\n",
      "test_test\n",
      "test mean loss=86637.03515625\n",
      "fin save.\n",
      "epoch 1366\n",
      "test_train\n",
      "train mean loss=62716.04765625\n",
      "test_test\n",
      "test mean loss=86721.89453125\n",
      "fin save.\n",
      "epoch 1367\n",
      "test_train\n",
      "train mean loss=62883.367447916666\n",
      "test_test\n",
      "test mean loss=86739.6328125\n",
      "fin save.\n",
      "epoch 1368\n",
      "test_train\n",
      "train mean loss=62725.26119791667\n",
      "test_test\n",
      "test mean loss=86604.3828125\n",
      "fin save.\n",
      "epoch 1369\n",
      "test_train\n",
      "train mean loss=62314.80286458333\n",
      "test_test\n",
      "test mean loss=86784.8125\n",
      "fin save.\n",
      "epoch 1370\n",
      "test_train\n",
      "train mean loss=63617.95989583333\n",
      "test_test\n",
      "test mean loss=86642.8046875\n",
      "fin save.\n",
      "epoch 1371\n",
      "test_train\n",
      "train mean loss=62671.549479166664\n",
      "test_test\n",
      "test mean loss=86619.8203125\n",
      "fin save.\n",
      "epoch 1372\n",
      "test_train\n",
      "train mean loss=62865.95911458333\n",
      "test_test\n",
      "test mean loss=86609.7265625\n",
      "fin save.\n",
      "epoch 1373\n",
      "test_train\n",
      "train mean loss=61532.98098958333\n",
      "test_test\n",
      "test mean loss=86642.9609375\n",
      "fin save.\n",
      "epoch 1374\n",
      "test_train\n",
      "train mean loss=61636.6671875\n",
      "test_test\n",
      "test mean loss=86781.5703125\n",
      "fin save.\n",
      "epoch 1375\n",
      "test_train\n",
      "train mean loss=62902.18411458333\n",
      "test_test\n",
      "test mean loss=86785.0234375\n",
      "fin save.\n",
      "epoch 1376\n",
      "test_train\n",
      "train mean loss=62512.707421875\n",
      "test_test\n",
      "test mean loss=86689.609375\n",
      "fin save.\n",
      "epoch 1377\n",
      "test_train\n",
      "train mean loss=61943.96783854167\n",
      "test_test\n",
      "test mean loss=86778.0546875\n",
      "fin save.\n",
      "epoch 1378\n",
      "test_train\n",
      "train mean loss=62611.09231770833\n",
      "test_test\n",
      "test mean loss=86770.9765625\n",
      "fin save.\n",
      "epoch 1379\n",
      "test_train\n",
      "train mean loss=63425.99817708333\n",
      "test_test\n",
      "test mean loss=86630.875\n",
      "fin save.\n",
      "epoch 1380\n",
      "test_train\n",
      "train mean loss=62236.105729166666\n",
      "test_test\n",
      "test mean loss=86704.96484375\n",
      "fin save.\n",
      "epoch 1381\n",
      "test_train\n",
      "train mean loss=63030.6296875\n",
      "test_test\n",
      "test mean loss=86661.7109375\n",
      "fin save.\n",
      "epoch 1382\n",
      "test_train\n",
      "train mean loss=62812.3984375\n",
      "test_test\n",
      "test mean loss=86721.1796875\n",
      "fin save.\n",
      "epoch 1383\n",
      "test_train\n",
      "train mean loss=62113.416276041666\n",
      "test_test\n",
      "test mean loss=86771.3984375\n",
      "fin save.\n",
      "epoch 1384\n",
      "test_train\n",
      "train mean loss=61876.225260416664\n",
      "test_test\n",
      "test mean loss=86548.1484375\n",
      "fin save.\n",
      "epoch 1385\n",
      "test_train\n",
      "train mean loss=61810.036458333336\n",
      "test_test\n",
      "test mean loss=86611.265625\n",
      "fin save.\n",
      "epoch 1386\n",
      "test_train\n",
      "train mean loss=62208.41510416667\n",
      "test_test\n",
      "test mean loss=86768.5390625\n",
      "fin save.\n",
      "epoch 1387\n",
      "test_train\n",
      "train mean loss=63328.17434895833\n",
      "test_test\n",
      "test mean loss=86701.109375\n",
      "fin save.\n",
      "epoch 1388\n",
      "test_train\n",
      "train mean loss=61994.92109375\n",
      "test_test\n",
      "test mean loss=86731.12890625\n",
      "fin save.\n",
      "epoch 1389\n",
      "test_train\n",
      "train mean loss=61329.48046875\n",
      "test_test\n",
      "test mean loss=86705.03125\n",
      "fin save.\n",
      "epoch 1390\n",
      "test_train\n",
      "train mean loss=62840.2921875\n",
      "test_test\n",
      "test mean loss=86802.94140625\n",
      "fin save.\n",
      "epoch 1391\n",
      "test_train\n",
      "train mean loss=62267.333333333336\n",
      "test_test\n",
      "test mean loss=86851.55859375\n",
      "fin save.\n",
      "epoch 1392\n",
      "test_train\n",
      "train mean loss=60799.6609375\n",
      "test_test\n",
      "test mean loss=87026.74609375\n",
      "fin save.\n",
      "epoch 1393\n",
      "test_train\n",
      "train mean loss=61700.75494791667\n",
      "test_test\n",
      "test mean loss=86960.69921875\n",
      "fin save.\n",
      "epoch 1394\n",
      "test_train\n",
      "train mean loss=62088.08776041667\n",
      "test_test\n",
      "test mean loss=86868.87890625\n",
      "fin save.\n",
      "epoch 1395\n",
      "test_train\n",
      "train mean loss=62234.55625\n",
      "test_test\n",
      "test mean loss=86987.5390625\n",
      "fin save.\n",
      "epoch 1396\n",
      "test_train\n",
      "train mean loss=62488.666666666664\n",
      "test_test\n",
      "test mean loss=86768.765625\n",
      "fin save.\n",
      "epoch 1397\n",
      "test_train\n",
      "train mean loss=61742.62161458333\n",
      "test_test\n",
      "test mean loss=86757.078125\n",
      "fin save.\n",
      "epoch 1398\n",
      "test_train\n",
      "train mean loss=62758.434375\n",
      "test_test\n",
      "test mean loss=86960.83203125\n",
      "fin save.\n",
      "epoch 1399\n",
      "test_train\n",
      "train mean loss=62255.138020833336\n",
      "test_test\n",
      "test mean loss=86915.859375\n",
      "fin save.\n",
      "epoch 1400\n",
      "test_train\n",
      "train mean loss=62883.56796875\n",
      "test_test\n",
      "test mean loss=86978.2421875\n",
      "fin save.\n",
      "epoch 1401\n",
      "test_train\n",
      "train mean loss=62281.084244791666\n",
      "test_test\n",
      "test mean loss=86855.49609375\n",
      "fin save.\n",
      "epoch 1402\n",
      "test_train\n",
      "train mean loss=61732.0125\n",
      "test_test\n",
      "test mean loss=86861.55859375\n",
      "fin save.\n",
      "epoch 1403\n",
      "test_train\n",
      "train mean loss=62825.41549479167\n",
      "test_test\n",
      "test mean loss=86963.6171875\n",
      "fin save.\n",
      "epoch 1404\n",
      "test_train\n",
      "train mean loss=61630.48541666667\n",
      "test_test\n",
      "test mean loss=87134.2109375\n",
      "fin save.\n",
      "epoch 1405\n",
      "test_train\n",
      "train mean loss=62594.55286458333\n",
      "test_test\n",
      "test mean loss=87227.27734375\n",
      "fin save.\n",
      "epoch 1406\n",
      "test_train\n",
      "train mean loss=63183.91588541667\n",
      "test_test\n",
      "test mean loss=87204.76953125\n",
      "fin save.\n",
      "epoch 1407\n",
      "test_train\n",
      "train mean loss=62181.726822916666\n",
      "test_test\n",
      "test mean loss=87264.30859375\n",
      "fin save.\n",
      "epoch 1408\n",
      "test_train\n",
      "train mean loss=62176.77265625\n",
      "test_test\n",
      "test mean loss=87353.7265625\n",
      "fin save.\n",
      "epoch 1409\n",
      "test_train\n",
      "train mean loss=62005.65143229167\n",
      "test_test\n",
      "test mean loss=87195.35546875\n",
      "fin save.\n",
      "epoch 1410\n",
      "test_train\n",
      "train mean loss=61804.54140625\n",
      "test_test\n",
      "test mean loss=86941.54296875\n",
      "fin save.\n",
      "epoch 1411\n",
      "test_train\n",
      "train mean loss=61784.72161458333\n",
      "test_test\n",
      "test mean loss=86844.87109375\n",
      "fin save.\n",
      "epoch 1412\n",
      "test_train\n",
      "train mean loss=62942.24166666667\n",
      "test_test\n",
      "test mean loss=86879.7421875\n",
      "fin save.\n",
      "epoch 1413\n",
      "test_train\n",
      "train mean loss=62185.116796875\n",
      "test_test\n",
      "test mean loss=86797.32421875\n",
      "fin save.\n",
      "epoch 1414\n",
      "test_train\n",
      "train mean loss=62523.537760416664\n",
      "test_test\n",
      "test mean loss=87161.890625\n",
      "fin save.\n",
      "epoch 1415\n",
      "test_train\n",
      "train mean loss=61994.048177083336\n",
      "test_test\n",
      "test mean loss=86978.8515625\n",
      "fin save.\n",
      "epoch 1416\n",
      "test_train\n",
      "train mean loss=63114.5859375\n",
      "test_test\n",
      "test mean loss=86970.4140625\n",
      "fin save.\n",
      "epoch 1417\n",
      "test_train\n",
      "train mean loss=62676.37005208333\n",
      "test_test\n",
      "test mean loss=86774.58984375\n",
      "fin save.\n",
      "epoch 1418\n",
      "test_train\n",
      "train mean loss=62288.90572916667\n",
      "test_test\n",
      "test mean loss=87058.22265625\n",
      "fin save.\n",
      "epoch 1419\n",
      "test_train\n",
      "train mean loss=62947.26575520833\n",
      "test_test\n",
      "test mean loss=87321.515625\n",
      "fin save.\n",
      "epoch 1420\n",
      "test_train\n",
      "train mean loss=61584.165625\n",
      "test_test\n",
      "test mean loss=87297.01953125\n",
      "fin save.\n",
      "epoch 1421\n",
      "test_train\n",
      "train mean loss=62591.5265625\n",
      "test_test\n",
      "test mean loss=87338.6171875\n",
      "fin save.\n",
      "epoch 1422\n",
      "test_train\n",
      "train mean loss=63397.35390625\n",
      "test_test\n",
      "test mean loss=87549.59375\n",
      "fin save.\n",
      "epoch 1423\n",
      "test_train\n",
      "train mean loss=62966.90963541667\n",
      "test_test\n",
      "test mean loss=87415.984375\n",
      "fin save.\n",
      "epoch 1424\n",
      "test_train\n",
      "train mean loss=61951.19348958333\n",
      "test_test\n",
      "test mean loss=87332.953125\n",
      "fin save.\n",
      "epoch 1425\n",
      "test_train\n",
      "train mean loss=63458.687239583334\n",
      "test_test\n",
      "test mean loss=87258.3046875\n",
      "fin save.\n",
      "epoch 1426\n",
      "test_train\n",
      "train mean loss=61701.45260416667\n",
      "test_test\n",
      "test mean loss=87172.9140625\n",
      "fin save.\n",
      "epoch 1427\n",
      "test_train\n",
      "train mean loss=61998.26471354167\n",
      "test_test\n",
      "test mean loss=87158.26171875\n",
      "fin save.\n",
      "epoch 1428\n",
      "test_train\n",
      "train mean loss=61213.97213541667\n",
      "test_test\n",
      "test mean loss=87141.25\n",
      "fin save.\n",
      "epoch 1429\n",
      "test_train\n",
      "train mean loss=62061.004166666666\n",
      "test_test\n",
      "test mean loss=87321.96484375\n",
      "fin save.\n",
      "epoch 1430\n",
      "test_train\n",
      "train mean loss=62848.819010416664\n",
      "test_test\n",
      "test mean loss=86900.1875\n",
      "fin save.\n",
      "epoch 1431\n",
      "test_train\n",
      "train mean loss=63079.778125\n",
      "test_test\n",
      "test mean loss=87137.5\n",
      "fin save.\n",
      "epoch 1432\n",
      "test_train\n",
      "train mean loss=62826.05390625\n",
      "test_test\n",
      "test mean loss=87320.2578125\n",
      "fin save.\n",
      "epoch 1433\n",
      "test_train\n",
      "train mean loss=62934.24296875\n",
      "test_test\n",
      "test mean loss=87201.1875\n",
      "fin save.\n",
      "epoch 1434\n",
      "test_train\n",
      "train mean loss=62898.252604166664\n",
      "test_test\n",
      "test mean loss=87380.01171875\n",
      "fin save.\n",
      "epoch 1435\n",
      "test_train\n",
      "train mean loss=62055.23489583333\n",
      "test_test\n",
      "test mean loss=87376.90625\n",
      "fin save.\n",
      "epoch 1436\n",
      "test_train\n",
      "train mean loss=61040.37838541667\n",
      "test_test\n",
      "test mean loss=86817.9453125\n",
      "fin save.\n",
      "epoch 1437\n",
      "test_train\n",
      "train mean loss=63052.842447916664\n",
      "test_test\n",
      "test mean loss=86995.19921875\n",
      "fin save.\n",
      "epoch 1438\n",
      "test_train\n",
      "train mean loss=62477.55078125\n",
      "test_test\n",
      "test mean loss=87077.68359375\n",
      "fin save.\n",
      "epoch 1439\n",
      "test_train\n",
      "train mean loss=62260.217447916664\n",
      "test_test\n",
      "test mean loss=87042.6015625\n",
      "fin save.\n",
      "epoch 1440\n",
      "test_train\n",
      "train mean loss=62120.536328125\n",
      "test_test\n",
      "test mean loss=86743.92578125\n",
      "fin save.\n",
      "epoch 1441\n",
      "test_train\n",
      "train mean loss=62972.77005208333\n",
      "test_test\n",
      "test mean loss=86812.7578125\n",
      "fin save.\n",
      "epoch 1442\n",
      "test_train\n",
      "train mean loss=61347.673828125\n",
      "test_test\n",
      "test mean loss=86723.6171875\n",
      "fin save.\n",
      "epoch 1443\n",
      "test_train\n",
      "train mean loss=61736.46796875\n",
      "test_test\n",
      "test mean loss=86651.11328125\n",
      "fin save.\n",
      "epoch 1444\n",
      "test_train\n",
      "train mean loss=63377.63958333333\n",
      "test_test\n",
      "test mean loss=86803.9921875\n",
      "fin save.\n",
      "epoch 1445\n",
      "test_train\n",
      "train mean loss=62226.77643229167\n",
      "test_test\n",
      "test mean loss=86839.1484375\n",
      "fin save.\n",
      "epoch 1446\n",
      "test_train\n",
      "train mean loss=62109.42682291667\n",
      "test_test\n",
      "test mean loss=87110.98828125\n",
      "fin save.\n",
      "epoch 1447\n",
      "test_train\n",
      "train mean loss=62477.630078125\n",
      "test_test\n",
      "test mean loss=87082.26953125\n",
      "fin save.\n",
      "epoch 1448\n",
      "test_train\n",
      "train mean loss=62476.45625\n",
      "test_test\n",
      "test mean loss=87058.515625\n",
      "fin save.\n",
      "epoch 1449\n",
      "test_train\n",
      "train mean loss=62380.54453125\n",
      "test_test\n",
      "test mean loss=87301.6015625\n",
      "fin save.\n",
      "epoch 1450\n",
      "test_train\n",
      "train mean loss=62784.55859375\n",
      "test_test\n",
      "test mean loss=87029.7578125\n",
      "fin save.\n",
      "epoch 1451\n",
      "test_train\n",
      "train mean loss=62075.027083333334\n",
      "test_test\n",
      "test mean loss=87339.10546875\n",
      "fin save.\n",
      "epoch 1452\n",
      "test_train\n",
      "train mean loss=63202.20911458333\n",
      "test_test\n",
      "test mean loss=87241.7421875\n",
      "fin save.\n",
      "epoch 1453\n",
      "test_train\n",
      "train mean loss=62617.40377604167\n",
      "test_test\n",
      "test mean loss=87412.02734375\n",
      "fin save.\n",
      "epoch 1454\n",
      "test_train\n",
      "train mean loss=62763.721875\n",
      "test_test\n",
      "test mean loss=86561.484375\n",
      "fin save.\n",
      "epoch 1455\n",
      "test_train\n",
      "train mean loss=62696.03723958333\n",
      "test_test\n",
      "test mean loss=86566.63671875\n",
      "fin save.\n",
      "epoch 1456\n",
      "test_train\n",
      "train mean loss=62406.365494791666\n",
      "test_test\n",
      "test mean loss=86670.77734375\n",
      "fin save.\n",
      "epoch 1457\n",
      "test_train\n",
      "train mean loss=61545.95625\n",
      "test_test\n",
      "test mean loss=86475.3828125\n",
      "fin save.\n",
      "epoch 1458\n",
      "test_train\n",
      "train mean loss=61647.412760416664\n",
      "test_test\n",
      "test mean loss=86789.98046875\n",
      "fin save.\n",
      "epoch 1459\n",
      "test_train\n",
      "train mean loss=62430.595963541666\n",
      "test_test\n",
      "test mean loss=86820.421875\n",
      "fin save.\n",
      "epoch 1460\n",
      "test_train\n",
      "train mean loss=61688.56145833333\n",
      "test_test\n",
      "test mean loss=86869.8046875\n",
      "fin save.\n",
      "epoch 1461\n",
      "test_train\n",
      "train mean loss=63288.4171875\n",
      "test_test\n",
      "test mean loss=87197.04296875\n",
      "fin save.\n",
      "epoch 1462\n",
      "test_train\n",
      "train mean loss=61817.79973958333\n",
      "test_test\n",
      "test mean loss=86660.140625\n",
      "fin save.\n",
      "epoch 1463\n",
      "test_train\n",
      "train mean loss=62650.27252604167\n",
      "test_test\n",
      "test mean loss=86748.8984375\n",
      "fin save.\n",
      "epoch 1464\n",
      "test_train\n",
      "train mean loss=62141.16197916667\n",
      "test_test\n",
      "test mean loss=86726.01953125\n",
      "fin save.\n",
      "epoch 1465\n",
      "test_train\n",
      "train mean loss=61689.32083333333\n",
      "test_test\n",
      "test mean loss=86730.0859375\n",
      "fin save.\n",
      "epoch 1466\n",
      "test_train\n",
      "train mean loss=62187.595442708334\n",
      "test_test\n",
      "test mean loss=86763.29296875\n",
      "fin save.\n",
      "epoch 1467\n",
      "test_train\n",
      "train mean loss=61987.14270833333\n",
      "test_test\n",
      "test mean loss=86937.14453125\n",
      "fin save.\n",
      "epoch 1468\n",
      "test_train\n",
      "train mean loss=62699.32955729167\n",
      "test_test\n",
      "test mean loss=86813.796875\n",
      "fin save.\n",
      "epoch 1469\n",
      "test_train\n",
      "train mean loss=63110.212109375\n",
      "test_test\n",
      "test mean loss=86821.84765625\n",
      "fin save.\n",
      "epoch 1470\n",
      "test_train\n",
      "train mean loss=62299.903515625\n",
      "test_test\n",
      "test mean loss=86772.21484375\n",
      "fin save.\n",
      "epoch 1471\n",
      "test_train\n",
      "train mean loss=62388.83346354167\n",
      "test_test\n",
      "test mean loss=86810.46875\n",
      "fin save.\n",
      "epoch 1472\n",
      "test_train\n",
      "train mean loss=61784.773697916666\n",
      "test_test\n",
      "test mean loss=86869.4140625\n",
      "fin save.\n",
      "epoch 1473\n",
      "test_train\n",
      "train mean loss=62149.46041666667\n",
      "test_test\n",
      "test mean loss=86794.56640625\n",
      "fin save.\n",
      "epoch 1474\n",
      "test_train\n",
      "train mean loss=62442.2140625\n",
      "test_test\n",
      "test mean loss=86961.50390625\n",
      "fin save.\n",
      "epoch 1475\n",
      "test_train\n",
      "train mean loss=61320.9390625\n",
      "test_test\n",
      "test mean loss=86965.4296875\n",
      "fin save.\n",
      "epoch 1476\n",
      "test_train\n",
      "train mean loss=62775.67955729167\n",
      "test_test\n",
      "test mean loss=86928.23828125\n",
      "fin save.\n",
      "epoch 1477\n",
      "test_train\n",
      "train mean loss=62187.76510416667\n",
      "test_test\n",
      "test mean loss=87133.56640625\n",
      "fin save.\n",
      "epoch 1478\n",
      "test_train\n",
      "train mean loss=62393.45\n",
      "test_test\n",
      "test mean loss=87114.94140625\n",
      "fin save.\n",
      "epoch 1479\n",
      "test_train\n",
      "train mean loss=62187.045572916664\n",
      "test_test\n",
      "test mean loss=87036.5625\n",
      "fin save.\n",
      "epoch 1480\n",
      "test_train\n",
      "train mean loss=61735.313151041664\n",
      "test_test\n",
      "test mean loss=86854.390625\n",
      "fin save.\n",
      "epoch 1481\n",
      "test_train\n",
      "train mean loss=62924.10598958333\n",
      "test_test\n",
      "test mean loss=86814.69921875\n",
      "fin save.\n",
      "epoch 1482\n",
      "test_train\n",
      "train mean loss=61029.16744791667\n",
      "test_test\n",
      "test mean loss=86915.80859375\n",
      "fin save.\n",
      "epoch 1483\n",
      "test_train\n",
      "train mean loss=62493.51770833333\n",
      "test_test\n",
      "test mean loss=87039.4453125\n",
      "fin save.\n",
      "epoch 1484\n",
      "test_train\n",
      "train mean loss=62165.92630208333\n",
      "test_test\n",
      "test mean loss=86787.75390625\n",
      "fin save.\n",
      "epoch 1485\n",
      "test_train\n",
      "train mean loss=62026.720703125\n",
      "test_test\n",
      "test mean loss=86828.9609375\n",
      "fin save.\n",
      "epoch 1486\n",
      "test_train\n",
      "train mean loss=62169.991796875\n",
      "test_test\n",
      "test mean loss=86867.796875\n",
      "fin save.\n",
      "epoch 1487\n",
      "test_train\n",
      "train mean loss=61592.059895833336\n",
      "test_test\n",
      "test mean loss=86750.16015625\n",
      "fin save.\n",
      "epoch 1488\n",
      "test_train\n",
      "train mean loss=62118.747395833336\n",
      "test_test\n",
      "test mean loss=86810.375\n",
      "fin save.\n",
      "epoch 1489\n",
      "test_train\n",
      "train mean loss=61375.92682291667\n",
      "test_test\n",
      "test mean loss=86861.14453125\n",
      "fin save.\n",
      "epoch 1490\n",
      "test_train\n",
      "train mean loss=62100.19127604167\n",
      "test_test\n",
      "test mean loss=86759.015625\n",
      "fin save.\n",
      "epoch 1491\n",
      "test_train\n",
      "train mean loss=62588.473828125\n",
      "test_test\n",
      "test mean loss=87007.37890625\n",
      "fin save.\n",
      "epoch 1492\n",
      "test_train\n",
      "train mean loss=62750.65911458333\n",
      "test_test\n",
      "test mean loss=87114.94140625\n",
      "fin save.\n",
      "epoch 1493\n",
      "test_train\n",
      "train mean loss=62533.340494791664\n",
      "test_test\n",
      "test mean loss=87103.109375\n",
      "fin save.\n",
      "epoch 1494\n",
      "test_train\n",
      "train mean loss=61177.93125\n",
      "test_test\n",
      "test mean loss=87053.734375\n",
      "fin save.\n",
      "epoch 1495\n",
      "test_train\n",
      "train mean loss=63011.75208333333\n",
      "test_test\n",
      "test mean loss=87030.4140625\n",
      "fin save.\n",
      "epoch 1496\n",
      "test_train\n",
      "train mean loss=61696.33203125\n",
      "test_test\n",
      "test mean loss=87164.81640625\n",
      "fin save.\n",
      "epoch 1497\n",
      "test_train\n",
      "train mean loss=62394.26796875\n",
      "test_test\n",
      "test mean loss=87259.0078125\n",
      "fin save.\n",
      "epoch 1498\n",
      "test_train\n",
      "train mean loss=61964.83151041667\n",
      "test_test\n",
      "test mean loss=86908.81640625\n",
      "fin save.\n",
      "epoch 1499\n",
      "test_train\n",
      "train mean loss=60882.981770833336\n",
      "test_test\n",
      "test mean loss=87117.9453125\n",
      "fin save.\n",
      "epoch 1500\n",
      "test_train\n",
      "train mean loss=63348.64166666667\n",
      "test_test\n",
      "test mean loss=86908.12109375\n",
      "fin save.\n",
      "epoch 1501\n",
      "test_train\n",
      "train mean loss=62087.11770833333\n",
      "test_test\n",
      "test mean loss=86990.125\n",
      "fin save.\n",
      "epoch 1502\n",
      "test_train\n",
      "train mean loss=63052.42421875\n",
      "test_test\n",
      "test mean loss=86966.45703125\n",
      "fin save.\n",
      "epoch 1503\n",
      "test_train\n",
      "train mean loss=63256.48255208333\n",
      "test_test\n",
      "test mean loss=87053.6015625\n",
      "fin save.\n",
      "epoch 1504\n",
      "test_train\n",
      "train mean loss=62002.39309895833\n",
      "test_test\n",
      "test mean loss=87005.57421875\n",
      "fin save.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1505\n",
      "test_train\n",
      "train mean loss=61951.38776041667\n",
      "test_test\n",
      "test mean loss=86966.33203125\n",
      "fin save.\n",
      "epoch 1506\n",
      "test_train\n",
      "train mean loss=61761.59557291667\n",
      "test_test\n",
      "test mean loss=86939.05859375\n",
      "fin save.\n",
      "epoch 1507\n",
      "test_train\n",
      "train mean loss=62844.495833333334\n",
      "test_test\n",
      "test mean loss=87009.08203125\n",
      "fin save.\n",
      "epoch 1508\n",
      "test_train\n",
      "train mean loss=62744.136458333334\n",
      "test_test\n",
      "test mean loss=87025.08984375\n",
      "fin save.\n",
      "epoch 1509\n",
      "test_train\n",
      "train mean loss=62920.31744791667\n",
      "test_test\n",
      "test mean loss=86822.22265625\n",
      "fin save.\n",
      "epoch 1510\n",
      "test_train\n",
      "train mean loss=61838.18515625\n",
      "test_test\n",
      "test mean loss=86773.46484375\n",
      "fin save.\n",
      "epoch 1511\n",
      "test_train\n",
      "train mean loss=62700.882421875\n",
      "test_test\n",
      "test mean loss=87101.60546875\n",
      "fin save.\n",
      "epoch 1512\n",
      "test_train\n",
      "train mean loss=62407.04700520833\n",
      "test_test\n",
      "test mean loss=86996.515625\n",
      "fin save.\n",
      "epoch 1513\n",
      "test_train\n",
      "train mean loss=61999.49205729167\n",
      "test_test\n",
      "test mean loss=86812.2265625\n",
      "fin save.\n",
      "epoch 1514\n",
      "test_train\n",
      "train mean loss=62770.445963541664\n",
      "test_test\n",
      "test mean loss=87038.51171875\n",
      "fin save.\n",
      "epoch 1515\n",
      "test_train\n",
      "train mean loss=62443.8375\n",
      "test_test\n",
      "test mean loss=87023.03515625\n",
      "fin save.\n",
      "epoch 1516\n",
      "test_train\n",
      "train mean loss=62532.41067708333\n",
      "test_test\n",
      "test mean loss=86979.84375\n",
      "fin save.\n",
      "epoch 1517\n",
      "test_train\n",
      "train mean loss=62333.97708333333\n",
      "test_test\n",
      "test mean loss=87008.25390625\n",
      "fin save.\n",
      "epoch 1518\n",
      "test_train\n",
      "train mean loss=61949.605859375\n",
      "test_test\n",
      "test mean loss=87134.9765625\n",
      "fin save.\n",
      "epoch 1519\n",
      "test_train\n",
      "train mean loss=62722.71197916667\n",
      "test_test\n",
      "test mean loss=87093.05078125\n",
      "fin save.\n",
      "epoch 1520\n",
      "test_train\n",
      "train mean loss=63088.86223958333\n",
      "test_test\n",
      "test mean loss=87281.22265625\n",
      "fin save.\n",
      "epoch 1521\n",
      "test_train\n",
      "train mean loss=60854.92473958333\n",
      "test_test\n",
      "test mean loss=87374.55859375\n",
      "fin save.\n",
      "epoch 1522\n",
      "test_train\n",
      "train mean loss=62394.973958333336\n",
      "test_test\n",
      "test mean loss=87429.4140625\n",
      "fin save.\n",
      "epoch 1523\n",
      "test_train\n",
      "train mean loss=62728.45859375\n",
      "test_test\n",
      "test mean loss=87494.55859375\n",
      "fin save.\n",
      "epoch 1524\n",
      "test_train\n",
      "train mean loss=62684.35390625\n",
      "test_test\n",
      "test mean loss=87467.12109375\n",
      "fin save.\n",
      "epoch 1525\n",
      "test_train\n",
      "train mean loss=61912.144921875\n",
      "test_test\n",
      "test mean loss=87349.27734375\n",
      "fin save.\n",
      "epoch 1526\n",
      "test_train\n",
      "train mean loss=62445.06744791667\n",
      "test_test\n",
      "test mean loss=87590.95703125\n",
      "fin save.\n",
      "epoch 1527\n",
      "test_train\n",
      "train mean loss=62842.103255208334\n",
      "test_test\n",
      "test mean loss=87438.04296875\n",
      "fin save.\n",
      "epoch 1528\n",
      "test_train\n",
      "train mean loss=63107.25572916667\n",
      "test_test\n",
      "test mean loss=87321.5390625\n",
      "fin save.\n",
      "epoch 1529\n",
      "test_train\n",
      "train mean loss=62470.402083333334\n",
      "test_test\n",
      "test mean loss=87321.48046875\n",
      "fin save.\n",
      "epoch 1530\n",
      "test_train\n",
      "train mean loss=61894.10260416667\n",
      "test_test\n",
      "test mean loss=87228.73828125\n",
      "fin save.\n",
      "epoch 1531\n",
      "test_train\n",
      "train mean loss=62131.838541666664\n",
      "test_test\n",
      "test mean loss=87393.484375\n",
      "fin save.\n",
      "epoch 1532\n",
      "test_train\n",
      "train mean loss=62424.156510416666\n",
      "test_test\n",
      "test mean loss=87537.40625\n",
      "fin save.\n",
      "epoch 1533\n",
      "test_train\n",
      "train mean loss=62989.25833333333\n",
      "test_test\n",
      "test mean loss=87508.4296875\n",
      "fin save.\n",
      "epoch 1534\n",
      "test_train\n",
      "train mean loss=62221.479166666664\n",
      "test_test\n",
      "test mean loss=87339.640625\n",
      "fin save.\n",
      "epoch 1535\n",
      "test_train\n",
      "train mean loss=61635.6734375\n",
      "test_test\n",
      "test mean loss=87505.171875\n",
      "fin save.\n",
      "epoch 1536\n",
      "test_train\n",
      "train mean loss=62806.51744791667\n",
      "test_test\n",
      "test mean loss=87357.33984375\n",
      "fin save.\n",
      "epoch 1537\n",
      "test_train\n",
      "train mean loss=62220.91549479167\n",
      "test_test\n",
      "test mean loss=87534.9140625\n",
      "fin save.\n",
      "epoch 1538\n",
      "test_train\n",
      "train mean loss=62711.444661458336\n",
      "test_test\n",
      "test mean loss=87628.6875\n",
      "fin save.\n",
      "epoch 1539\n",
      "test_train\n",
      "train mean loss=63133.26276041667\n",
      "test_test\n",
      "test mean loss=87751.23828125\n",
      "fin save.\n",
      "epoch 1540\n",
      "test_train\n",
      "train mean loss=61859.046614583334\n",
      "test_test\n",
      "test mean loss=87676.02734375\n",
      "fin save.\n",
      "epoch 1541\n",
      "test_train\n",
      "train mean loss=62556.743489583336\n",
      "test_test\n",
      "test mean loss=87653.88671875\n",
      "fin save.\n",
      "epoch 1542\n",
      "test_train\n",
      "train mean loss=62415.60651041667\n",
      "test_test\n",
      "test mean loss=87814.0\n",
      "fin save.\n",
      "epoch 1543\n",
      "test_train\n",
      "train mean loss=61328.37057291667\n",
      "test_test\n",
      "test mean loss=87437.88671875\n",
      "fin save.\n",
      "epoch 1544\n",
      "test_train\n",
      "train mean loss=62611.535416666666\n",
      "test_test\n",
      "test mean loss=87622.96484375\n",
      "fin save.\n",
      "epoch 1545\n",
      "test_train\n",
      "train mean loss=62459.87786458333\n",
      "test_test\n",
      "test mean loss=87892.10546875\n",
      "fin save.\n",
      "epoch 1546\n",
      "test_train\n",
      "train mean loss=61955.89114583333\n",
      "test_test\n",
      "test mean loss=87628.81640625\n",
      "fin save.\n",
      "epoch 1547\n",
      "test_train\n",
      "train mean loss=62357.42278645833\n",
      "test_test\n",
      "test mean loss=87516.8203125\n",
      "fin save.\n",
      "epoch 1548\n",
      "test_train\n",
      "train mean loss=62913.18255208333\n",
      "test_test\n",
      "test mean loss=87665.12890625\n",
      "fin save.\n",
      "epoch 1549\n",
      "test_train\n",
      "train mean loss=62746.855208333334\n",
      "test_test\n",
      "test mean loss=87701.171875\n",
      "fin save.\n",
      "epoch 1550\n",
      "test_train\n",
      "train mean loss=62714.62838541667\n",
      "test_test\n",
      "test mean loss=87344.71875\n",
      "fin save.\n",
      "epoch 1551\n",
      "test_train\n",
      "train mean loss=61896.95208333333\n",
      "test_test\n",
      "test mean loss=87482.32421875\n",
      "fin save.\n",
      "epoch 1552\n",
      "test_train\n",
      "train mean loss=62682.950520833336\n",
      "test_test\n",
      "test mean loss=87717.19921875\n",
      "fin save.\n",
      "epoch 1553\n",
      "test_train\n",
      "train mean loss=62772.9578125\n",
      "test_test\n",
      "test mean loss=87642.73828125\n",
      "fin save.\n",
      "epoch 1554\n",
      "test_train\n",
      "train mean loss=62128.20859375\n",
      "test_test\n",
      "test mean loss=87364.33984375\n",
      "fin save.\n",
      "epoch 1555\n",
      "test_train\n",
      "train mean loss=62483.778645833336\n",
      "test_test\n",
      "test mean loss=87584.66796875\n",
      "fin save.\n",
      "epoch 1556\n",
      "test_train\n",
      "train mean loss=62461.93255208333\n",
      "test_test\n",
      "test mean loss=87381.12109375\n",
      "fin save.\n",
      "epoch 1557\n",
      "test_train\n",
      "train mean loss=61652.95989583333\n",
      "test_test\n",
      "test mean loss=87425.265625\n",
      "fin save.\n",
      "epoch 1558\n",
      "test_train\n",
      "train mean loss=62378.57213541667\n",
      "test_test\n",
      "test mean loss=87548.45703125\n",
      "fin save.\n",
      "epoch 1559\n",
      "test_train\n",
      "train mean loss=62774.68828125\n",
      "test_test\n",
      "test mean loss=87517.140625\n",
      "fin save.\n",
      "epoch 1560\n",
      "test_train\n",
      "train mean loss=62028.604817708336\n",
      "test_test\n",
      "test mean loss=87332.484375\n",
      "fin save.\n",
      "epoch 1561\n",
      "test_train\n",
      "train mean loss=62200.373307291666\n",
      "test_test\n",
      "test mean loss=87377.05859375\n",
      "fin save.\n",
      "epoch 1562\n",
      "test_train\n",
      "train mean loss=62696.4734375\n",
      "test_test\n",
      "test mean loss=87290.17578125\n",
      "fin save.\n",
      "epoch 1563\n",
      "test_train\n",
      "train mean loss=62059.944921875\n",
      "test_test\n",
      "test mean loss=87335.49609375\n",
      "fin save.\n",
      "epoch 1564\n",
      "test_train\n",
      "train mean loss=62910.83098958333\n",
      "test_test\n",
      "test mean loss=87038.1875\n",
      "fin save.\n",
      "epoch 1565\n",
      "test_train\n",
      "train mean loss=61766.42265625\n",
      "test_test\n",
      "test mean loss=86480.95703125\n",
      "fin save.\n",
      "epoch 1566\n",
      "test_train\n",
      "train mean loss=62084.721875\n",
      "test_test\n",
      "test mean loss=86567.89453125\n",
      "fin save.\n",
      "epoch 1567\n",
      "test_train\n",
      "train mean loss=62841.571614583336\n",
      "test_test\n",
      "test mean loss=86787.578125\n",
      "fin save.\n",
      "epoch 1568\n",
      "test_train\n",
      "train mean loss=62605.78815104167\n",
      "test_test\n",
      "test mean loss=86495.2734375\n",
      "fin save.\n",
      "epoch 1569\n",
      "test_train\n",
      "train mean loss=62208.90130208333\n",
      "test_test\n",
      "test mean loss=86730.23046875\n",
      "fin save.\n",
      "epoch 1570\n",
      "test_train\n",
      "train mean loss=62274.19869791667\n",
      "test_test\n",
      "test mean loss=86728.94921875\n",
      "fin save.\n",
      "epoch 1571\n",
      "test_train\n",
      "train mean loss=61434.24140625\n",
      "test_test\n",
      "test mean loss=87231.41796875\n",
      "fin save.\n",
      "epoch 1572\n",
      "test_train\n",
      "train mean loss=62854.160807291664\n",
      "test_test\n",
      "test mean loss=87019.26953125\n",
      "fin save.\n",
      "epoch 1573\n",
      "test_train\n",
      "train mean loss=63267.73125\n",
      "test_test\n",
      "test mean loss=86930.96484375\n",
      "fin save.\n",
      "epoch 1574\n",
      "test_train\n",
      "train mean loss=61992.47161458333\n",
      "test_test\n",
      "test mean loss=86909.69140625\n",
      "fin save.\n",
      "epoch 1575\n",
      "test_train\n",
      "train mean loss=61727.42005208333\n",
      "test_test\n",
      "test mean loss=86960.4609375\n",
      "fin save.\n",
      "epoch 1576\n",
      "test_train\n",
      "train mean loss=62833.90390625\n",
      "test_test\n",
      "test mean loss=86729.53125\n",
      "fin save.\n",
      "epoch 1577\n",
      "test_train\n",
      "train mean loss=62189.21145833333\n",
      "test_test\n",
      "test mean loss=87361.82421875\n",
      "fin save.\n",
      "epoch 1578\n",
      "test_train\n",
      "train mean loss=62435.1875\n",
      "test_test\n",
      "test mean loss=87025.52734375\n",
      "fin save.\n",
      "epoch 1579\n",
      "test_train\n",
      "train mean loss=62070.025\n",
      "test_test\n",
      "test mean loss=87152.7578125\n",
      "fin save.\n",
      "epoch 1580\n",
      "test_train\n",
      "train mean loss=62829.88489583333\n",
      "test_test\n",
      "test mean loss=87196.45703125\n",
      "fin save.\n",
      "epoch 1581\n",
      "test_train\n",
      "train mean loss=62046.326822916664\n",
      "test_test\n",
      "test mean loss=87308.74609375\n",
      "fin save.\n",
      "epoch 1582\n",
      "test_train\n",
      "train mean loss=62135.234375\n",
      "test_test\n",
      "test mean loss=87835.18359375\n",
      "fin save.\n",
      "epoch 1583\n",
      "test_train\n",
      "train mean loss=62707.751302083336\n",
      "test_test\n",
      "test mean loss=87723.8046875\n",
      "fin save.\n",
      "epoch 1584\n",
      "test_train\n",
      "train mean loss=63635.77630208333\n",
      "test_test\n",
      "test mean loss=87640.95703125\n",
      "fin save.\n",
      "epoch 1585\n",
      "test_train\n",
      "train mean loss=62633.810546875\n",
      "test_test\n",
      "test mean loss=87628.6796875\n",
      "fin save.\n",
      "epoch 1586\n",
      "test_train\n",
      "train mean loss=62566.310807291666\n",
      "test_test\n",
      "test mean loss=87910.875\n",
      "fin save.\n",
      "epoch 1587\n",
      "test_train\n",
      "train mean loss=62298.85989583333\n",
      "test_test\n",
      "test mean loss=87848.60546875\n",
      "fin save.\n",
      "epoch 1588\n",
      "test_train\n",
      "train mean loss=62462.43346354167\n",
      "test_test\n",
      "test mean loss=87757.8203125\n",
      "fin save.\n",
      "epoch 1589\n",
      "test_train\n",
      "train mean loss=61549.4078125\n",
      "test_test\n",
      "test mean loss=87719.8125\n",
      "fin save.\n",
      "epoch 1590\n",
      "test_train\n",
      "train mean loss=62421.51223958333\n",
      "test_test\n",
      "test mean loss=88090.42578125\n",
      "fin save.\n",
      "epoch 1591\n",
      "test_train\n",
      "train mean loss=62961.02005208333\n",
      "test_test\n",
      "test mean loss=88089.17578125\n",
      "fin save.\n",
      "epoch 1592\n",
      "test_train\n",
      "train mean loss=62439.85833333333\n",
      "test_test\n",
      "test mean loss=87878.03515625\n",
      "fin save.\n",
      "epoch 1593\n",
      "test_train\n",
      "train mean loss=61958.513411458334\n",
      "test_test\n",
      "test mean loss=87647.03515625\n",
      "fin save.\n",
      "epoch 1594\n",
      "test_train\n",
      "train mean loss=61255.928385416664\n",
      "test_test\n",
      "test mean loss=87402.9921875\n",
      "fin save.\n",
      "epoch 1595\n",
      "test_train\n",
      "train mean loss=61822.047265625\n",
      "test_test\n",
      "test mean loss=87306.9921875\n",
      "fin save.\n",
      "epoch 1596\n",
      "test_train\n",
      "train mean loss=62126.86875\n",
      "test_test\n",
      "test mean loss=87359.3359375\n",
      "fin save.\n",
      "epoch 1597\n",
      "test_train\n",
      "train mean loss=62505.72994791667\n",
      "test_test\n",
      "test mean loss=87175.8828125\n",
      "fin save.\n",
      "epoch 1598\n",
      "test_train\n",
      "train mean loss=61670.79609375\n",
      "test_test\n",
      "test mean loss=86760.953125\n",
      "fin save.\n",
      "epoch 1599\n",
      "test_train\n",
      "train mean loss=63153.41158854167\n",
      "test_test\n",
      "test mean loss=87129.33984375\n",
      "fin save.\n",
      "epoch 1600\n",
      "test_train\n",
      "train mean loss=62078.190625\n",
      "test_test\n",
      "test mean loss=87134.52734375\n",
      "fin save.\n",
      "epoch 1601\n",
      "test_train\n",
      "train mean loss=62316.914453125\n",
      "test_test\n",
      "test mean loss=87230.96484375\n",
      "fin save.\n",
      "epoch 1602\n",
      "test_train\n",
      "train mean loss=62433.043229166666\n",
      "test_test\n",
      "test mean loss=87006.02734375\n",
      "fin save.\n",
      "epoch 1603\n",
      "test_train\n",
      "train mean loss=62677.905859375\n",
      "test_test\n",
      "test mean loss=87445.3359375\n",
      "fin save.\n",
      "epoch 1604\n",
      "test_train\n",
      "train mean loss=62638.53723958333\n",
      "test_test\n",
      "test mean loss=87379.0\n",
      "fin save.\n",
      "epoch 1605\n",
      "test_train\n",
      "train mean loss=61851.686197916664\n",
      "test_test\n",
      "test mean loss=87332.43359375\n",
      "fin save.\n",
      "epoch 1606\n",
      "test_train\n",
      "train mean loss=62776.352864583336\n",
      "test_test\n",
      "test mean loss=87413.62890625\n",
      "fin save.\n",
      "epoch 1607\n",
      "test_train\n",
      "train mean loss=61436.826953125\n",
      "test_test\n",
      "test mean loss=87380.546875\n",
      "fin save.\n",
      "epoch 1608\n",
      "test_train\n",
      "train mean loss=62344.93515625\n",
      "test_test\n",
      "test mean loss=87315.43359375\n",
      "fin save.\n",
      "epoch 1609\n",
      "test_train\n",
      "train mean loss=62020.773697916666\n",
      "test_test\n",
      "test mean loss=87269.90625\n",
      "fin save.\n",
      "epoch 1610\n",
      "test_train\n",
      "train mean loss=62186.484375\n",
      "test_test\n",
      "test mean loss=86298.8359375\n",
      "fin save.\n",
      "epoch 1611\n",
      "test_train\n",
      "train mean loss=61563.7078125\n",
      "test_test\n",
      "test mean loss=86231.9375\n",
      "fin save.\n",
      "epoch 1612\n",
      "test_train\n",
      "train mean loss=61678.14348958333\n",
      "test_test\n",
      "test mean loss=86446.2890625\n",
      "fin save.\n",
      "epoch 1613\n",
      "test_train\n",
      "train mean loss=62675.70221354167\n",
      "test_test\n",
      "test mean loss=86566.80859375\n",
      "fin save.\n",
      "epoch 1614\n",
      "test_train\n",
      "train mean loss=62704.163671875\n",
      "test_test\n",
      "test mean loss=86459.11328125\n",
      "fin save.\n",
      "epoch 1615\n",
      "test_train\n",
      "train mean loss=61847.96770833333\n",
      "test_test\n",
      "test mean loss=86486.671875\n",
      "fin save.\n",
      "epoch 1616\n",
      "test_train\n",
      "train mean loss=62405.53216145833\n",
      "test_test\n",
      "test mean loss=86496.64453125\n",
      "fin save.\n",
      "epoch 1617\n",
      "test_train\n",
      "train mean loss=62501.14596354167\n",
      "test_test\n",
      "test mean loss=86335.8203125\n",
      "fin save.\n",
      "epoch 1618\n",
      "test_train\n",
      "train mean loss=61484.60078125\n",
      "test_test\n",
      "test mean loss=86517.12890625\n",
      "fin save.\n",
      "epoch 1619\n",
      "test_train\n",
      "train mean loss=63463.74205729167\n",
      "test_test\n",
      "test mean loss=86518.04296875\n",
      "fin save.\n",
      "epoch 1620\n",
      "test_train\n",
      "train mean loss=63089.654947916664\n",
      "test_test\n",
      "test mean loss=86561.8671875\n",
      "fin save.\n",
      "epoch 1621\n",
      "test_train\n",
      "train mean loss=62349.166666666664\n",
      "test_test\n",
      "test mean loss=86475.7578125\n",
      "fin save.\n",
      "epoch 1622\n",
      "test_train\n",
      "train mean loss=62488.10598958333\n",
      "test_test\n",
      "test mean loss=86477.234375\n",
      "fin save.\n",
      "epoch 1623\n",
      "test_train\n",
      "train mean loss=62649.542708333334\n",
      "test_test\n",
      "test mean loss=86514.41015625\n",
      "fin save.\n",
      "epoch 1624\n",
      "test_train\n",
      "train mean loss=62468.81145833333\n",
      "test_test\n",
      "test mean loss=86594.14453125\n",
      "fin save.\n",
      "epoch 1625\n",
      "test_train\n",
      "train mean loss=61994.18984375\n",
      "test_test\n",
      "test mean loss=86458.0078125\n",
      "fin save.\n",
      "epoch 1626\n",
      "test_train\n",
      "train mean loss=62812.375\n",
      "test_test\n",
      "test mean loss=86377.99609375\n",
      "fin save.\n",
      "epoch 1627\n",
      "test_train\n",
      "train mean loss=62729.65338541667\n",
      "test_test\n",
      "test mean loss=86370.62890625\n",
      "fin save.\n",
      "epoch 1628\n",
      "test_train\n",
      "train mean loss=62130.82421875\n",
      "test_test\n",
      "test mean loss=86426.5625\n",
      "fin save.\n",
      "epoch 1629\n",
      "test_train\n",
      "train mean loss=62294.3015625\n",
      "test_test\n",
      "test mean loss=86413.2578125\n",
      "fin save.\n",
      "epoch 1630\n",
      "test_train\n",
      "train mean loss=63050.85\n",
      "test_test\n",
      "test mean loss=86607.05078125\n",
      "fin save.\n",
      "epoch 1631\n",
      "test_train\n",
      "train mean loss=62244.015885416666\n",
      "test_test\n",
      "test mean loss=86812.52734375\n",
      "fin save.\n",
      "epoch 1632\n",
      "test_train\n",
      "train mean loss=63901.80677083333\n",
      "test_test\n",
      "test mean loss=86265.703125\n",
      "fin save.\n",
      "epoch 1633\n",
      "test_train\n",
      "train mean loss=63949.025\n",
      "test_test\n",
      "test mean loss=86023.70703125\n",
      "fin save.\n",
      "epoch 1634\n",
      "test_train\n",
      "train mean loss=62340.35651041667\n",
      "test_test\n",
      "test mean loss=86620.3671875\n",
      "fin save.\n",
      "epoch 1635\n",
      "test_train\n",
      "train mean loss=62746.39635416667\n",
      "test_test\n",
      "test mean loss=86826.3671875\n",
      "fin save.\n",
      "epoch 1636\n",
      "test_train\n",
      "train mean loss=63354.4515625\n",
      "test_test\n",
      "test mean loss=86851.703125\n",
      "fin save.\n",
      "epoch 1637\n",
      "test_train\n",
      "train mean loss=62614.051041666666\n",
      "test_test\n",
      "test mean loss=86695.94921875\n",
      "fin save.\n",
      "epoch 1638\n",
      "test_train\n",
      "train mean loss=62676.212239583336\n",
      "test_test\n",
      "test mean loss=86983.8046875\n",
      "fin save.\n",
      "epoch 1639\n",
      "test_train\n",
      "train mean loss=62227.58828125\n",
      "test_test\n",
      "test mean loss=86796.67578125\n",
      "fin save.\n",
      "epoch 1640\n",
      "test_train\n",
      "train mean loss=61796.363671875\n",
      "test_test\n",
      "test mean loss=87135.359375\n",
      "fin save.\n",
      "epoch 1641\n",
      "test_train\n",
      "train mean loss=62352.840625\n",
      "test_test\n",
      "test mean loss=87070.41015625\n",
      "fin save.\n",
      "epoch 1642\n",
      "test_train\n",
      "train mean loss=62903.77838541667\n",
      "test_test\n",
      "test mean loss=86919.9765625\n",
      "fin save.\n",
      "epoch 1643\n",
      "test_train\n",
      "train mean loss=63622.53671875\n",
      "test_test\n",
      "test mean loss=87059.39453125\n",
      "fin save.\n",
      "epoch 1644\n",
      "test_train\n",
      "train mean loss=63051.835677083334\n",
      "test_test\n",
      "test mean loss=86959.16796875\n",
      "fin save.\n",
      "epoch 1645\n",
      "test_train\n",
      "train mean loss=62625.58098958333\n",
      "test_test\n",
      "test mean loss=87315.55859375\n",
      "fin save.\n",
      "epoch 1646\n",
      "test_train\n",
      "train mean loss=62279.8203125\n",
      "test_test\n",
      "test mean loss=87085.56640625\n",
      "fin save.\n",
      "epoch 1647\n",
      "test_train\n",
      "train mean loss=63219.087890625\n",
      "test_test\n",
      "test mean loss=87014.41796875\n",
      "fin save.\n",
      "epoch 1648\n",
      "test_train\n",
      "train mean loss=62414.45026041667\n",
      "test_test\n",
      "test mean loss=86960.1640625\n",
      "fin save.\n",
      "epoch 1649\n",
      "test_train\n",
      "train mean loss=62263.994921875\n",
      "test_test\n",
      "test mean loss=86982.87109375\n",
      "fin save.\n",
      "epoch 1650\n",
      "test_train\n",
      "train mean loss=62317.902604166666\n",
      "test_test\n",
      "test mean loss=86942.13671875\n",
      "fin save.\n",
      "epoch 1651\n",
      "test_train\n",
      "train mean loss=62378.128125\n",
      "test_test\n",
      "test mean loss=86938.984375\n",
      "fin save.\n",
      "epoch 1652\n",
      "test_train\n",
      "train mean loss=62707.205729166664\n",
      "test_test\n",
      "test mean loss=86950.05078125\n",
      "fin save.\n",
      "epoch 1653\n",
      "test_train\n",
      "train mean loss=62855.63424479167\n",
      "test_test\n",
      "test mean loss=86996.6484375\n",
      "fin save.\n",
      "epoch 1654\n",
      "test_train\n",
      "train mean loss=63326.12265625\n",
      "test_test\n",
      "test mean loss=87012.453125\n",
      "fin save.\n",
      "epoch 1655\n",
      "test_train\n",
      "train mean loss=61782.34388020833\n",
      "test_test\n",
      "test mean loss=87126.41015625\n",
      "fin save.\n",
      "epoch 1656\n",
      "test_train\n",
      "train mean loss=62925.81067708333\n",
      "test_test\n",
      "test mean loss=87052.515625\n",
      "fin save.\n",
      "epoch 1657\n",
      "test_train\n",
      "train mean loss=63085.0890625\n",
      "test_test\n",
      "test mean loss=87037.12890625\n",
      "fin save.\n",
      "epoch 1658\n",
      "test_train\n",
      "train mean loss=62280.27434895833\n",
      "test_test\n",
      "test mean loss=87221.3671875\n",
      "fin save.\n",
      "epoch 1659\n",
      "test_train\n",
      "train mean loss=62505.094010416666\n",
      "test_test\n",
      "test mean loss=87445.77734375\n",
      "fin save.\n",
      "epoch 1660\n",
      "test_train\n",
      "train mean loss=62004.390234375\n",
      "test_test\n",
      "test mean loss=87530.0625\n",
      "fin save.\n",
      "epoch 1661\n",
      "test_train\n",
      "train mean loss=62969.206770833334\n",
      "test_test\n",
      "test mean loss=87042.04296875\n",
      "fin save.\n",
      "epoch 1662\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_train\n",
      "train mean loss=62170.2546875\n",
      "test_test\n",
      "test mean loss=87346.53125\n",
      "fin save.\n",
      "epoch 1663\n",
      "test_train\n",
      "train mean loss=63388.908854166664\n",
      "test_test\n",
      "test mean loss=87216.9765625\n",
      "fin save.\n",
      "epoch 1664\n",
      "test_train\n",
      "train mean loss=62256.29114583333\n",
      "test_test\n",
      "test mean loss=87323.3671875\n",
      "fin save.\n",
      "epoch 1665\n",
      "test_train\n",
      "train mean loss=62898.227734375\n",
      "test_test\n",
      "test mean loss=87376.98828125\n",
      "fin save.\n",
      "epoch 1666\n",
      "test_train\n",
      "train mean loss=62879.790625\n",
      "test_test\n",
      "test mean loss=87046.1328125\n",
      "fin save.\n",
      "epoch 1667\n",
      "test_train\n",
      "train mean loss=63071.05963541667\n",
      "test_test\n",
      "test mean loss=87266.10546875\n",
      "fin save.\n",
      "epoch 1668\n",
      "test_train\n",
      "train mean loss=63347.511458333334\n",
      "test_test\n",
      "test mean loss=87298.34375\n",
      "fin save.\n",
      "epoch 1669\n",
      "test_train\n",
      "train mean loss=62518.5765625\n",
      "test_test\n",
      "test mean loss=87257.8828125\n",
      "fin save.\n",
      "epoch 1670\n",
      "test_train\n",
      "train mean loss=62132.636067708336\n",
      "test_test\n",
      "test mean loss=87131.7109375\n",
      "fin save.\n",
      "epoch 1671\n",
      "test_train\n",
      "train mean loss=63022.34661458333\n",
      "test_test\n",
      "test mean loss=86852.1484375\n",
      "fin save.\n",
      "epoch 1672\n",
      "test_train\n",
      "train mean loss=63769.53697916667\n",
      "test_test\n",
      "test mean loss=86882.54296875\n",
      "fin save.\n",
      "epoch 1673\n",
      "test_train\n",
      "train mean loss=63036.702734375\n",
      "test_test\n",
      "test mean loss=86868.23046875\n",
      "fin save.\n",
      "epoch 1674\n",
      "test_train\n",
      "train mean loss=62674.3234375\n",
      "test_test\n",
      "test mean loss=86742.0703125\n",
      "fin save.\n",
      "epoch 1675\n",
      "test_train\n",
      "train mean loss=61971.238020833334\n",
      "test_test\n",
      "test mean loss=86699.9765625\n",
      "fin save.\n",
      "epoch 1676\n",
      "test_train\n",
      "train mean loss=63393.360026041664\n",
      "test_test\n",
      "test mean loss=86739.4140625\n",
      "fin save.\n",
      "epoch 1677\n",
      "test_train\n",
      "train mean loss=62509.144921875\n",
      "test_test\n",
      "test mean loss=87219.5625\n",
      "fin save.\n",
      "epoch 1678\n",
      "test_train\n",
      "train mean loss=62967.65182291667\n",
      "test_test\n",
      "test mean loss=87060.87109375\n",
      "fin save.\n",
      "epoch 1679\n",
      "test_train\n",
      "train mean loss=62221.476822916666\n",
      "test_test\n",
      "test mean loss=87126.4453125\n",
      "fin save.\n",
      "epoch 1680\n",
      "test_train\n",
      "train mean loss=62592.6859375\n",
      "test_test\n",
      "test mean loss=87109.62890625\n",
      "fin save.\n",
      "epoch 1681\n",
      "test_train\n",
      "train mean loss=62922.54088541667\n",
      "test_test\n",
      "test mean loss=87087.546875\n",
      "fin save.\n",
      "epoch 1682\n",
      "test_train\n",
      "train mean loss=62451.20390625\n",
      "test_test\n",
      "test mean loss=86937.359375\n",
      "fin save.\n",
      "epoch 1683\n",
      "test_train\n",
      "train mean loss=62562.942578125\n",
      "test_test\n",
      "test mean loss=87016.828125\n",
      "fin save.\n",
      "epoch 1684\n",
      "test_train\n",
      "train mean loss=62204.311197916664\n",
      "test_test\n",
      "test mean loss=87110.8984375\n",
      "fin save.\n",
      "epoch 1685\n",
      "test_train\n",
      "train mean loss=63508.67734375\n",
      "test_test\n",
      "test mean loss=87256.79296875\n",
      "fin save.\n",
      "epoch 1686\n",
      "test_train\n",
      "train mean loss=62730.64361979167\n",
      "test_test\n",
      "test mean loss=87143.15625\n",
      "fin save.\n",
      "epoch 1687\n",
      "test_train\n",
      "train mean loss=62662.11627604167\n",
      "test_test\n",
      "test mean loss=87204.33203125\n",
      "fin save.\n",
      "epoch 1688\n",
      "test_train\n",
      "train mean loss=63142.06341145833\n",
      "test_test\n",
      "test mean loss=87143.703125\n",
      "fin save.\n",
      "epoch 1689\n",
      "test_train\n",
      "train mean loss=62991.48359375\n",
      "test_test\n",
      "test mean loss=87192.359375\n",
      "fin save.\n",
      "epoch 1690\n",
      "test_train\n",
      "train mean loss=63280.8546875\n",
      "test_test\n",
      "test mean loss=87220.94921875\n",
      "fin save.\n",
      "epoch 1691\n",
      "test_train\n",
      "train mean loss=62533.6359375\n",
      "test_test\n",
      "test mean loss=87017.22265625\n",
      "fin save.\n",
      "epoch 1692\n",
      "test_train\n",
      "train mean loss=62320.73046875\n",
      "test_test\n",
      "test mean loss=87036.32421875\n",
      "fin save.\n",
      "epoch 1693\n",
      "test_train\n",
      "train mean loss=61718.16653645833\n",
      "test_test\n",
      "test mean loss=87199.65625\n",
      "fin save.\n",
      "epoch 1694\n",
      "test_train\n",
      "train mean loss=62707.52447916667\n",
      "test_test\n",
      "test mean loss=86681.578125\n",
      "fin save.\n",
      "epoch 1695\n",
      "test_train\n",
      "train mean loss=62260.613671875\n",
      "test_test\n",
      "test mean loss=86867.91796875\n",
      "fin save.\n",
      "epoch 1696\n",
      "test_train\n",
      "train mean loss=62785.07213541667\n",
      "test_test\n",
      "test mean loss=86858.5\n",
      "fin save.\n",
      "epoch 1697\n",
      "test_train\n",
      "train mean loss=61965.99010416667\n",
      "test_test\n",
      "test mean loss=86834.6953125\n",
      "fin save.\n",
      "epoch 1698\n",
      "test_train\n",
      "train mean loss=62891.031901041664\n",
      "test_test\n",
      "test mean loss=86984.1328125\n",
      "fin save.\n",
      "epoch 1699\n",
      "test_train\n",
      "train mean loss=62333.067708333336\n",
      "test_test\n",
      "test mean loss=86806.37109375\n",
      "fin save.\n",
      "epoch 1700\n",
      "test_train\n",
      "train mean loss=61439.696614583336\n",
      "test_test\n",
      "test mean loss=86779.5\n",
      "fin save.\n",
      "epoch 1701\n",
      "test_train\n",
      "train mean loss=62295.23828125\n",
      "test_test\n",
      "test mean loss=86776.15234375\n",
      "fin save.\n",
      "epoch 1702\n",
      "test_train\n",
      "train mean loss=62493.49609375\n",
      "test_test\n",
      "test mean loss=86846.75390625\n",
      "fin save.\n",
      "epoch 1703\n",
      "test_train\n",
      "train mean loss=63692.429947916666\n",
      "test_test\n",
      "test mean loss=86923.38671875\n",
      "fin save.\n",
      "epoch 1704\n",
      "test_train\n",
      "train mean loss=62065.19518229167\n",
      "test_test\n",
      "test mean loss=87060.37890625\n",
      "fin save.\n",
      "epoch 1705\n",
      "test_train\n",
      "train mean loss=63789.00859375\n",
      "test_test\n",
      "test mean loss=87131.05078125\n",
      "fin save.\n",
      "epoch 1706\n",
      "test_train\n",
      "train mean loss=62128.45390625\n",
      "test_test\n",
      "test mean loss=86899.3125\n",
      "fin save.\n",
      "epoch 1707\n",
      "test_train\n",
      "train mean loss=62106.81927083333\n",
      "test_test\n",
      "test mean loss=86955.69140625\n",
      "fin save.\n",
      "epoch 1708\n",
      "test_train\n",
      "train mean loss=62758.594010416666\n",
      "test_test\n",
      "test mean loss=87056.01171875\n",
      "fin save.\n",
      "epoch 1709\n",
      "test_train\n",
      "train mean loss=62430.12447916667\n",
      "test_test\n",
      "test mean loss=86981.48046875\n",
      "fin save.\n",
      "epoch 1710\n",
      "test_train\n",
      "train mean loss=61696.7484375\n",
      "test_test\n",
      "test mean loss=87139.67578125\n",
      "fin save.\n",
      "epoch 1711\n",
      "test_train\n",
      "train mean loss=63115.806640625\n",
      "test_test\n",
      "test mean loss=87130.13671875\n",
      "fin save.\n",
      "epoch 1712\n",
      "test_train\n",
      "train mean loss=62646.65377604167\n",
      "test_test\n",
      "test mean loss=86913.55078125\n",
      "fin save.\n",
      "epoch 1713\n",
      "test_train\n",
      "train mean loss=62303.271484375\n",
      "test_test\n",
      "test mean loss=86990.90234375\n",
      "fin save.\n",
      "epoch 1714\n",
      "test_train\n",
      "train mean loss=62361.94674479167\n",
      "test_test\n",
      "test mean loss=86267.72265625\n",
      "fin save.\n",
      "epoch 1715\n",
      "test_train\n",
      "train mean loss=61922.12890625\n",
      "test_test\n",
      "test mean loss=86312.84375\n",
      "fin save.\n",
      "epoch 1716\n",
      "test_train\n",
      "train mean loss=62872.23619791667\n",
      "test_test\n",
      "test mean loss=86301.94140625\n",
      "fin save.\n",
      "epoch 1717\n",
      "test_train\n",
      "train mean loss=62319.738020833334\n",
      "test_test\n",
      "test mean loss=86232.16015625\n",
      "fin save.\n",
      "epoch 1718\n",
      "test_train\n",
      "train mean loss=62763.8859375\n",
      "test_test\n",
      "test mean loss=86068.859375\n",
      "fin save.\n",
      "epoch 1719\n",
      "test_train\n",
      "train mean loss=62583.7953125\n",
      "test_test\n",
      "test mean loss=86319.11328125\n",
      "fin save.\n",
      "epoch 1720\n",
      "test_train\n",
      "train mean loss=62443.733072916664\n",
      "test_test\n",
      "test mean loss=86064.01953125\n",
      "fin save.\n",
      "epoch 1721\n",
      "test_train\n",
      "train mean loss=62314.70364583333\n",
      "test_test\n",
      "test mean loss=86063.7109375\n",
      "fin save.\n",
      "epoch 1722\n",
      "test_train\n",
      "train mean loss=62144.03138020833\n",
      "test_test\n",
      "test mean loss=86073.16015625\n",
      "fin save.\n",
      "epoch 1723\n",
      "test_train\n",
      "train mean loss=62804.84557291667\n",
      "test_test\n",
      "test mean loss=86100.26171875\n",
      "fin save.\n",
      "epoch 1724\n",
      "test_train\n",
      "train mean loss=63562.93125\n",
      "test_test\n",
      "test mean loss=86074.15625\n",
      "fin save.\n",
      "epoch 1725\n",
      "test_train\n",
      "train mean loss=62171.084375\n",
      "test_test\n",
      "test mean loss=86047.4296875\n",
      "fin save.\n",
      "epoch 1726\n",
      "test_train\n",
      "train mean loss=62206.13177083333\n",
      "test_test\n",
      "test mean loss=86229.8515625\n",
      "fin save.\n",
      "epoch 1727\n",
      "test_train\n",
      "train mean loss=62288.13098958333\n",
      "test_test\n",
      "test mean loss=86178.76171875\n",
      "fin save.\n",
      "epoch 1728\n",
      "test_train\n",
      "train mean loss=63114.178125\n",
      "test_test\n",
      "test mean loss=86190.16796875\n",
      "fin save.\n",
      "epoch 1729\n",
      "test_train\n",
      "train mean loss=62198.856770833336\n",
      "test_test\n",
      "test mean loss=86211.20703125\n",
      "fin save.\n",
      "epoch 1730\n",
      "test_train\n",
      "train mean loss=62684.50703125\n",
      "test_test\n",
      "test mean loss=86350.16015625\n",
      "fin save.\n",
      "epoch 1731\n",
      "test_train\n",
      "train mean loss=62893.78984375\n",
      "test_test\n",
      "test mean loss=86265.28515625\n",
      "fin save.\n",
      "epoch 1732\n",
      "test_train\n",
      "train mean loss=62240.01796875\n",
      "test_test\n",
      "test mean loss=86553.6015625\n",
      "fin save.\n",
      "epoch 1733\n",
      "test_train\n",
      "train mean loss=62635.823958333334\n",
      "test_test\n",
      "test mean loss=86614.34375\n",
      "fin save.\n",
      "epoch 1734\n",
      "test_train\n",
      "train mean loss=63499.3890625\n",
      "test_test\n",
      "test mean loss=86441.6953125\n",
      "fin save.\n",
      "epoch 1735\n",
      "test_train\n",
      "train mean loss=62236.04375\n",
      "test_test\n",
      "test mean loss=86424.78125\n",
      "fin save.\n",
      "epoch 1736\n",
      "test_train\n",
      "train mean loss=61229.570572916666\n",
      "test_test\n",
      "test mean loss=86564.87890625\n",
      "fin save.\n",
      "epoch 1737\n",
      "test_train\n",
      "train mean loss=62298.37005208333\n",
      "test_test\n",
      "test mean loss=86531.6328125\n",
      "fin save.\n",
      "epoch 1738\n",
      "test_train\n",
      "train mean loss=63110.57083333333\n",
      "test_test\n",
      "test mean loss=86651.30859375\n",
      "fin save.\n",
      "epoch 1739\n",
      "test_train\n",
      "train mean loss=62496.94427083333\n",
      "test_test\n",
      "test mean loss=86597.8984375\n",
      "fin save.\n",
      "epoch 1740\n",
      "test_train\n",
      "train mean loss=62547.584375\n",
      "test_test\n",
      "test mean loss=86668.640625\n",
      "fin save.\n",
      "epoch 1741\n",
      "test_train\n",
      "train mean loss=63295.863541666666\n",
      "test_test\n",
      "test mean loss=86747.48828125\n",
      "fin save.\n",
      "epoch 1742\n",
      "test_train\n",
      "train mean loss=62714.18697916667\n",
      "test_test\n",
      "test mean loss=86834.8984375\n",
      "fin save.\n",
      "epoch 1743\n",
      "test_train\n",
      "train mean loss=62081.39947916667\n",
      "test_test\n",
      "test mean loss=86397.6015625\n",
      "fin save.\n",
      "epoch 1744\n",
      "test_train\n",
      "train mean loss=62891.133072916666\n",
      "test_test\n",
      "test mean loss=86446.96875\n",
      "fin save.\n",
      "epoch 1745\n",
      "test_train\n",
      "train mean loss=62755.8\n",
      "test_test\n",
      "test mean loss=86309.30078125\n",
      "fin save.\n",
      "epoch 1746\n",
      "test_train\n",
      "train mean loss=63356.71822916667\n",
      "test_test\n",
      "test mean loss=86666.0390625\n",
      "fin save.\n",
      "epoch 1747\n",
      "test_train\n",
      "train mean loss=62791.06458333333\n",
      "test_test\n",
      "test mean loss=86753.40234375\n",
      "fin save.\n",
      "epoch 1748\n",
      "test_train\n",
      "train mean loss=62638.98203125\n",
      "test_test\n",
      "test mean loss=85741.19921875\n",
      "fin save.\n",
      "epoch 1749\n",
      "test_train\n",
      "train mean loss=61187.26015625\n",
      "test_test\n",
      "test mean loss=85891.921875\n",
      "fin save.\n",
      "epoch 1750\n",
      "test_train\n",
      "train mean loss=61392.563802083336\n",
      "test_test\n",
      "test mean loss=85668.953125\n",
      "fin save.\n",
      "epoch 1751\n",
      "test_train\n",
      "train mean loss=61624.97369791667\n",
      "test_test\n",
      "test mean loss=85782.04296875\n",
      "fin save.\n",
      "epoch 1752\n",
      "test_train\n",
      "train mean loss=61200.75\n",
      "test_test\n",
      "test mean loss=85865.96484375\n",
      "fin save.\n",
      "epoch 1753\n",
      "test_train\n",
      "train mean loss=62697.69140625\n",
      "test_test\n",
      "test mean loss=86029.765625\n",
      "fin save.\n",
      "epoch 1754\n",
      "test_train\n",
      "train mean loss=62401.494140625\n",
      "test_test\n",
      "test mean loss=86012.5\n",
      "fin save.\n",
      "epoch 1755\n",
      "test_train\n",
      "train mean loss=63161.37395833333\n",
      "test_test\n",
      "test mean loss=86011.9609375\n",
      "fin save.\n",
      "epoch 1756\n",
      "test_train\n",
      "train mean loss=62438.28697916667\n",
      "test_test\n",
      "test mean loss=85988.96875\n",
      "fin save.\n",
      "epoch 1757\n",
      "test_train\n",
      "train mean loss=61445.45807291667\n",
      "test_test\n",
      "test mean loss=86024.1953125\n",
      "fin save.\n",
      "epoch 1758\n",
      "test_train\n",
      "train mean loss=62625.661458333336\n",
      "test_test\n",
      "test mean loss=86118.015625\n",
      "fin save.\n",
      "epoch 1759\n",
      "test_train\n",
      "train mean loss=62665.894270833334\n",
      "test_test\n",
      "test mean loss=86121.75\n",
      "fin save.\n",
      "epoch 1760\n",
      "test_train\n",
      "train mean loss=62126.41744791667\n",
      "test_test\n",
      "test mean loss=85986.265625\n",
      "fin save.\n",
      "epoch 1761\n",
      "test_train\n",
      "train mean loss=63051.58450520833\n",
      "test_test\n",
      "test mean loss=86074.73828125\n",
      "fin save.\n",
      "epoch 1762\n",
      "test_train\n",
      "train mean loss=61944.93177083333\n",
      "test_test\n",
      "test mean loss=86348.63671875\n",
      "fin save.\n",
      "epoch 1763\n",
      "test_train\n",
      "train mean loss=63185.17682291667\n",
      "test_test\n",
      "test mean loss=86053.1796875\n",
      "fin save.\n",
      "epoch 1764\n",
      "test_train\n",
      "train mean loss=62709.916666666664\n",
      "test_test\n",
      "test mean loss=85962.63671875\n",
      "fin save.\n",
      "epoch 1765\n",
      "test_train\n",
      "train mean loss=61528.638020833336\n",
      "test_test\n",
      "test mean loss=86131.1015625\n",
      "fin save.\n",
      "epoch 1766\n",
      "test_train\n",
      "train mean loss=62638.49947916667\n",
      "test_test\n",
      "test mean loss=86624.53125\n",
      "fin save.\n",
      "epoch 1767\n",
      "test_train\n",
      "train mean loss=62450.836197916666\n",
      "test_test\n",
      "test mean loss=86369.33203125\n",
      "fin save.\n",
      "epoch 1768\n",
      "test_train\n",
      "train mean loss=62656.859375\n",
      "test_test\n",
      "test mean loss=86417.21875\n",
      "fin save.\n",
      "epoch 1769\n",
      "test_train\n",
      "train mean loss=62279.585677083334\n",
      "test_test\n",
      "test mean loss=86278.0546875\n",
      "fin save.\n",
      "epoch 1770\n",
      "test_train\n",
      "train mean loss=61474.91015625\n",
      "test_test\n",
      "test mean loss=86384.87109375\n",
      "fin save.\n",
      "epoch 1771\n",
      "test_train\n",
      "train mean loss=61634.45911458333\n",
      "test_test\n",
      "test mean loss=86421.05078125\n",
      "fin save.\n",
      "epoch 1772\n",
      "test_train\n",
      "train mean loss=61475.748697916664\n",
      "test_test\n",
      "test mean loss=86377.26953125\n",
      "fin save.\n",
      "epoch 1773\n",
      "test_train\n",
      "train mean loss=63109.35833333333\n",
      "test_test\n",
      "test mean loss=86061.04296875\n",
      "fin save.\n",
      "epoch 1774\n",
      "test_train\n",
      "train mean loss=62024.54895833333\n",
      "test_test\n",
      "test mean loss=86146.6640625\n",
      "fin save.\n",
      "epoch 1775\n",
      "test_train\n",
      "train mean loss=61489.765364583334\n",
      "test_test\n",
      "test mean loss=86561.625\n",
      "fin save.\n",
      "epoch 1776\n",
      "test_train\n",
      "train mean loss=62687.53567708333\n",
      "test_test\n",
      "test mean loss=86217.1640625\n",
      "fin save.\n",
      "epoch 1777\n",
      "test_train\n",
      "train mean loss=61661.719010416666\n",
      "test_test\n",
      "test mean loss=86242.140625\n",
      "fin save.\n",
      "epoch 1778\n",
      "test_train\n",
      "train mean loss=62202.595052083336\n",
      "test_test\n",
      "test mean loss=86375.34375\n",
      "fin save.\n",
      "epoch 1779\n",
      "test_train\n",
      "train mean loss=62166.19088541667\n",
      "test_test\n",
      "test mean loss=86179.7265625\n",
      "fin save.\n",
      "epoch 1780\n",
      "test_train\n",
      "train mean loss=62534.7984375\n",
      "test_test\n",
      "test mean loss=86294.97265625\n",
      "fin save.\n",
      "epoch 1781\n",
      "test_train\n",
      "train mean loss=63208.001302083336\n",
      "test_test\n",
      "test mean loss=86477.203125\n",
      "fin save.\n",
      "epoch 1782\n",
      "test_train\n",
      "train mean loss=61695.70546875\n",
      "test_test\n",
      "test mean loss=86304.5390625\n",
      "fin save.\n",
      "epoch 1783\n",
      "test_train\n",
      "train mean loss=61671.85494791667\n",
      "test_test\n",
      "test mean loss=86039.140625\n",
      "fin save.\n",
      "epoch 1784\n",
      "test_train\n",
      "train mean loss=61954.303385416664\n",
      "test_test\n",
      "test mean loss=86186.4296875\n",
      "fin save.\n",
      "epoch 1785\n",
      "test_train\n",
      "train mean loss=61883.43020833333\n",
      "test_test\n",
      "test mean loss=86332.98046875\n",
      "fin save.\n",
      "epoch 1786\n",
      "test_train\n",
      "train mean loss=61832.24895833333\n",
      "test_test\n",
      "test mean loss=86584.49609375\n",
      "fin save.\n",
      "epoch 1787\n",
      "test_train\n",
      "train mean loss=61770.81197916667\n",
      "test_test\n",
      "test mean loss=86380.09765625\n",
      "fin save.\n",
      "epoch 1788\n",
      "test_train\n",
      "train mean loss=62446.53697916667\n",
      "test_test\n",
      "test mean loss=86315.87109375\n",
      "fin save.\n",
      "epoch 1789\n",
      "test_train\n",
      "train mean loss=61772.81432291667\n",
      "test_test\n",
      "test mean loss=86527.65234375\n",
      "fin save.\n",
      "epoch 1790\n",
      "test_train\n",
      "train mean loss=62771.04778645833\n",
      "test_test\n",
      "test mean loss=86357.109375\n",
      "fin save.\n",
      "epoch 1791\n",
      "test_train\n",
      "train mean loss=61350.02057291667\n",
      "test_test\n",
      "test mean loss=86246.125\n",
      "fin save.\n",
      "epoch 1792\n",
      "test_train\n",
      "train mean loss=61218.94192708333\n",
      "test_test\n",
      "test mean loss=86169.67578125\n",
      "fin save.\n",
      "epoch 1793\n",
      "test_train\n",
      "train mean loss=62097.64856770833\n",
      "test_test\n",
      "test mean loss=86254.3515625\n",
      "fin save.\n",
      "epoch 1794\n",
      "test_train\n",
      "train mean loss=61911.39440104167\n",
      "test_test\n",
      "test mean loss=86101.3203125\n",
      "fin save.\n",
      "epoch 1795\n",
      "test_train\n",
      "train mean loss=60891.0125\n",
      "test_test\n",
      "test mean loss=86184.29296875\n",
      "fin save.\n",
      "epoch 1796\n",
      "test_train\n",
      "train mean loss=63147.662760416664\n",
      "test_test\n",
      "test mean loss=86286.1015625\n",
      "fin save.\n",
      "epoch 1797\n",
      "test_train\n",
      "train mean loss=62018.3921875\n",
      "test_test\n",
      "test mean loss=86152.08984375\n",
      "fin save.\n",
      "epoch 1798\n",
      "test_train\n",
      "train mean loss=62359.905989583334\n",
      "test_test\n",
      "test mean loss=86126.140625\n",
      "fin save.\n",
      "epoch 1799\n",
      "test_train\n",
      "train mean loss=61407.20130208333\n",
      "test_test\n",
      "test mean loss=85822.765625\n",
      "fin save.\n",
      "epoch 1800\n",
      "test_train\n",
      "train mean loss=62155.708984375\n",
      "test_test\n",
      "test mean loss=85672.96875\n",
      "fin save.\n",
      "epoch 1801\n",
      "test_train\n",
      "train mean loss=61569.5109375\n",
      "test_test\n",
      "test mean loss=85687.59375\n",
      "fin save.\n",
      "epoch 1802\n",
      "test_train\n",
      "train mean loss=62492.9953125\n",
      "test_test\n",
      "test mean loss=85907.73828125\n",
      "fin save.\n",
      "epoch 1803\n",
      "test_train\n",
      "train mean loss=61271.16796875\n",
      "test_test\n",
      "test mean loss=85760.2265625\n",
      "fin save.\n",
      "epoch 1804\n",
      "test_train\n",
      "train mean loss=61874.60794270833\n",
      "test_test\n",
      "test mean loss=85945.51171875\n",
      "fin save.\n",
      "epoch 1805\n",
      "test_train\n",
      "train mean loss=62825.25390625\n",
      "test_test\n",
      "test mean loss=85884.3203125\n",
      "fin save.\n",
      "epoch 1806\n",
      "test_train\n",
      "train mean loss=62343.141927083336\n",
      "test_test\n",
      "test mean loss=85725.1640625\n",
      "fin save.\n",
      "epoch 1807\n",
      "test_train\n",
      "train mean loss=61743.5734375\n",
      "test_test\n",
      "test mean loss=85649.4453125\n",
      "fin save.\n",
      "epoch 1808\n",
      "test_train\n",
      "train mean loss=63421.294661458334\n",
      "test_test\n",
      "test mean loss=85500.2265625\n",
      "fin save.\n",
      "epoch 1809\n",
      "test_train\n",
      "train mean loss=61623.083984375\n",
      "test_test\n",
      "test mean loss=86652.125\n",
      "fin save.\n",
      "epoch 1810\n",
      "test_train\n",
      "train mean loss=61686.785416666666\n",
      "test_test\n",
      "test mean loss=86740.88671875\n",
      "fin save.\n",
      "epoch 1811\n",
      "test_train\n",
      "train mean loss=62783.841536458334\n",
      "test_test\n",
      "test mean loss=86727.94140625\n",
      "fin save.\n",
      "epoch 1812\n",
      "test_train\n",
      "train mean loss=61829.749739583334\n",
      "test_test\n",
      "test mean loss=86502.5625\n",
      "fin save.\n",
      "epoch 1813\n",
      "test_train\n",
      "train mean loss=62583.587239583336\n",
      "test_test\n",
      "test mean loss=86486.83984375\n",
      "fin save.\n",
      "epoch 1814\n",
      "test_train\n",
      "train mean loss=61797.8880859375\n",
      "test_test\n",
      "test mean loss=86371.125\n",
      "fin save.\n",
      "epoch 1815\n",
      "test_train\n",
      "train mean loss=61807.702473958336\n",
      "test_test\n",
      "test mean loss=86747.9609375\n",
      "fin save.\n",
      "epoch 1816\n",
      "test_train\n",
      "train mean loss=62003.1578125\n",
      "test_test\n",
      "test mean loss=86404.72265625\n",
      "fin save.\n",
      "epoch 1817\n",
      "test_train\n",
      "train mean loss=61130.94427083333\n",
      "test_test\n",
      "test mean loss=86377.97265625\n",
      "fin save.\n",
      "epoch 1818\n",
      "test_train\n",
      "train mean loss=62893.52890625\n",
      "test_test\n",
      "test mean loss=86168.234375\n",
      "fin save.\n",
      "epoch 1819\n",
      "test_train\n",
      "train mean loss=62647.11627604167\n",
      "test_test\n",
      "test mean loss=86123.48828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fin save.\n",
      "epoch 1820\n",
      "test_train\n",
      "train mean loss=61860.24036458333\n",
      "test_test\n",
      "test mean loss=86347.67578125\n",
      "fin save.\n",
      "epoch 1821\n",
      "test_train\n",
      "train mean loss=62493.67200520833\n",
      "test_test\n",
      "test mean loss=85539.890625\n",
      "fin save.\n",
      "epoch 1822\n",
      "test_train\n",
      "train mean loss=61865.072526041666\n",
      "test_test\n",
      "test mean loss=85827.45703125\n",
      "fin save.\n",
      "epoch 1823\n",
      "test_train\n",
      "train mean loss=62347.165364583336\n",
      "test_test\n",
      "test mean loss=85700.70703125\n",
      "fin save.\n",
      "epoch 1824\n",
      "test_train\n",
      "train mean loss=61620.02252604167\n",
      "test_test\n",
      "test mean loss=85777.421875\n",
      "fin save.\n",
      "epoch 1825\n",
      "test_train\n",
      "train mean loss=61445.365625\n",
      "test_test\n",
      "test mean loss=85863.48828125\n",
      "fin save.\n",
      "epoch 1826\n",
      "test_train\n",
      "train mean loss=61860.51666666667\n",
      "test_test\n",
      "test mean loss=85874.99609375\n",
      "fin save.\n",
      "epoch 1827\n",
      "test_train\n",
      "train mean loss=62440.38619791667\n",
      "test_test\n",
      "test mean loss=85865.23046875\n",
      "fin save.\n",
      "epoch 1828\n",
      "test_train\n",
      "train mean loss=62762.81692708333\n",
      "test_test\n",
      "test mean loss=85875.05859375\n",
      "fin save.\n",
      "epoch 1829\n",
      "test_train\n",
      "train mean loss=62377.15234375\n",
      "test_test\n",
      "test mean loss=85758.65625\n",
      "fin save.\n",
      "epoch 1830\n",
      "test_train\n",
      "train mean loss=62027.24609375\n",
      "test_test\n",
      "test mean loss=85862.515625\n",
      "fin save.\n",
      "epoch 1831\n",
      "test_train\n",
      "train mean loss=61901.26380208333\n",
      "test_test\n",
      "test mean loss=85679.515625\n",
      "fin save.\n",
      "epoch 1832\n",
      "test_train\n",
      "train mean loss=61491.66510416667\n",
      "test_test\n",
      "test mean loss=85711.85546875\n",
      "fin save.\n",
      "epoch 1833\n",
      "test_train\n",
      "train mean loss=62675.9265625\n",
      "test_test\n",
      "test mean loss=85902.10546875\n",
      "fin save.\n",
      "epoch 1834\n",
      "test_train\n",
      "train mean loss=61813.46041666667\n",
      "test_test\n",
      "test mean loss=85911.578125\n",
      "fin save.\n",
      "epoch 1835\n",
      "test_train\n",
      "train mean loss=63187.88424479167\n",
      "test_test\n",
      "test mean loss=85884.10546875\n",
      "fin save.\n",
      "epoch 1836\n",
      "test_train\n",
      "train mean loss=63051.903645833336\n",
      "test_test\n",
      "test mean loss=85886.7421875\n",
      "fin save.\n",
      "epoch 1837\n",
      "test_train\n",
      "train mean loss=62282.47747395833\n",
      "test_test\n",
      "test mean loss=85998.578125\n",
      "fin save.\n",
      "epoch 1838\n",
      "test_train\n",
      "train mean loss=62627.271875\n",
      "test_test\n",
      "test mean loss=86170.75\n",
      "fin save.\n",
      "epoch 1839\n",
      "test_train\n",
      "train mean loss=62914.12421875\n",
      "test_test\n",
      "test mean loss=86111.1484375\n",
      "fin save.\n",
      "epoch 1840\n",
      "test_train\n",
      "train mean loss=62082.15625\n",
      "test_test\n",
      "test mean loss=86010.48046875\n",
      "fin save.\n",
      "epoch 1841\n",
      "test_train\n",
      "train mean loss=62868.667708333334\n",
      "test_test\n",
      "test mean loss=85806.49609375\n",
      "fin save.\n",
      "epoch 1842\n",
      "test_train\n",
      "train mean loss=62524.89947916667\n",
      "test_test\n",
      "test mean loss=86430.0078125\n",
      "fin save.\n",
      "epoch 1843\n",
      "test_train\n",
      "train mean loss=61740.73203125\n",
      "test_test\n",
      "test mean loss=86473.89453125\n",
      "fin save.\n",
      "epoch 1844\n",
      "test_train\n",
      "train mean loss=62204.61627604167\n",
      "test_test\n",
      "test mean loss=86579.8046875\n",
      "fin save.\n",
      "epoch 1845\n",
      "test_train\n",
      "train mean loss=62249.59453125\n",
      "test_test\n",
      "test mean loss=86279.79296875\n",
      "fin save.\n",
      "epoch 1846\n",
      "test_train\n",
      "train mean loss=62476.22669270833\n",
      "test_test\n",
      "test mean loss=86340.56640625\n",
      "fin save.\n",
      "epoch 1847\n",
      "test_train\n",
      "train mean loss=62808.22317708333\n",
      "test_test\n",
      "test mean loss=86469.48828125\n",
      "fin save.\n",
      "epoch 1848\n",
      "test_train\n",
      "train mean loss=62903.378645833334\n",
      "test_test\n",
      "test mean loss=86186.04296875\n",
      "fin save.\n",
      "epoch 1849\n",
      "test_train\n",
      "train mean loss=61847.583333333336\n",
      "test_test\n",
      "test mean loss=86336.46484375\n",
      "fin save.\n",
      "epoch 1850\n",
      "test_train\n",
      "train mean loss=62191.88515625\n",
      "test_test\n",
      "test mean loss=86355.640625\n",
      "fin save.\n",
      "epoch 1851\n",
      "test_train\n",
      "train mean loss=61938.803125\n",
      "test_test\n",
      "test mean loss=86369.05078125\n",
      "fin save.\n",
      "epoch 1852\n",
      "test_train\n",
      "train mean loss=61803.07317708333\n",
      "test_test\n",
      "test mean loss=86499.546875\n",
      "fin save.\n",
      "epoch 1853\n",
      "test_train\n",
      "train mean loss=62796.98333333333\n",
      "test_test\n",
      "test mean loss=86087.8671875\n",
      "fin save.\n",
      "epoch 1854\n",
      "test_train\n",
      "train mean loss=62468.94036458333\n",
      "test_test\n",
      "test mean loss=86314.13671875\n",
      "fin save.\n",
      "epoch 1855\n",
      "test_train\n",
      "train mean loss=62315.065104166664\n",
      "test_test\n",
      "test mean loss=85935.58984375\n",
      "fin save.\n",
      "epoch 1856\n",
      "test_train\n",
      "train mean loss=62568.360677083336\n",
      "test_test\n",
      "test mean loss=86612.48046875\n",
      "fin save.\n",
      "epoch 1857\n",
      "test_train\n",
      "train mean loss=62219.84036458333\n",
      "test_test\n",
      "test mean loss=86383.02734375\n",
      "fin save.\n",
      "epoch 1858\n",
      "test_train\n",
      "train mean loss=63069.08385416667\n",
      "test_test\n",
      "test mean loss=86563.51953125\n",
      "fin save.\n",
      "epoch 1859\n",
      "test_train\n",
      "train mean loss=61677.75208333333\n",
      "test_test\n",
      "test mean loss=85868.125\n",
      "fin save.\n",
      "epoch 1860\n",
      "test_train\n",
      "train mean loss=61818.210677083334\n",
      "test_test\n",
      "test mean loss=85809.12109375\n",
      "fin save.\n",
      "epoch 1861\n",
      "test_train\n",
      "train mean loss=62427.76848958333\n",
      "test_test\n",
      "test mean loss=85926.82421875\n",
      "fin save.\n",
      "epoch 1862\n",
      "test_train\n",
      "train mean loss=62939.79986979167\n",
      "test_test\n",
      "test mean loss=85775.30859375\n",
      "fin save.\n",
      "epoch 1863\n",
      "test_train\n",
      "train mean loss=62554.788802083334\n",
      "test_test\n",
      "test mean loss=86150.03125\n",
      "fin save.\n",
      "epoch 1864\n",
      "test_train\n",
      "train mean loss=62080.9453125\n",
      "test_test\n",
      "test mean loss=86248.84375\n",
      "fin save.\n",
      "epoch 1865\n",
      "test_train\n",
      "train mean loss=62192.00494791667\n",
      "test_test\n",
      "test mean loss=86305.91015625\n",
      "fin save.\n",
      "epoch 1866\n",
      "test_train\n",
      "train mean loss=62134.75833333333\n",
      "test_test\n",
      "test mean loss=86478.74609375\n",
      "fin save.\n",
      "epoch 1867\n",
      "test_train\n",
      "train mean loss=62511.351302083334\n",
      "test_test\n",
      "test mean loss=86333.55859375\n",
      "fin save.\n",
      "epoch 1868\n",
      "test_train\n",
      "train mean loss=63202.86901041667\n",
      "test_test\n",
      "test mean loss=86266.1796875\n",
      "fin save.\n",
      "epoch 1869\n",
      "test_train\n",
      "train mean loss=62383.4921875\n",
      "test_test\n",
      "test mean loss=86161.3984375\n",
      "fin save.\n",
      "epoch 1870\n",
      "test_train\n",
      "train mean loss=62780.54296875\n",
      "test_test\n",
      "test mean loss=85886.6484375\n",
      "fin save.\n",
      "epoch 1871\n",
      "test_train\n",
      "train mean loss=61591.328125\n",
      "test_test\n",
      "test mean loss=86859.6328125\n",
      "fin save.\n",
      "epoch 1872\n",
      "test_train\n",
      "train mean loss=61916.70208333333\n",
      "test_test\n",
      "test mean loss=86689.66015625\n",
      "fin save.\n",
      "epoch 1873\n",
      "test_train\n",
      "train mean loss=62377.00598958333\n",
      "test_test\n",
      "test mean loss=86537.6484375\n",
      "fin save.\n",
      "epoch 1874\n",
      "test_train\n",
      "train mean loss=62373.82734375\n",
      "test_test\n",
      "test mean loss=86441.2734375\n",
      "fin save.\n",
      "epoch 1875\n",
      "test_train\n",
      "train mean loss=62146.67578125\n",
      "test_test\n",
      "test mean loss=86307.55078125\n",
      "fin save.\n",
      "epoch 1876\n",
      "test_train\n",
      "train mean loss=62764.29010416667\n",
      "test_test\n",
      "test mean loss=85972.7109375\n",
      "fin save.\n",
      "epoch 1877\n",
      "test_train\n",
      "train mean loss=62007.257552083334\n",
      "test_test\n",
      "test mean loss=86616.05859375\n",
      "fin save.\n",
      "epoch 1878\n",
      "test_train\n",
      "train mean loss=62684.230859375\n",
      "test_test\n",
      "test mean loss=86467.79296875\n",
      "fin save.\n",
      "epoch 1879\n",
      "test_train\n",
      "train mean loss=64300.091796875\n",
      "test_test\n",
      "test mean loss=87826.1015625\n",
      "fin save.\n",
      "epoch 1880\n",
      "test_train\n",
      "train mean loss=62345.738020833334\n",
      "test_test\n",
      "test mean loss=87867.1953125\n",
      "fin save.\n",
      "epoch 1881\n",
      "test_train\n",
      "train mean loss=63080.37005208333\n",
      "test_test\n",
      "test mean loss=87815.60546875\n",
      "fin save.\n",
      "epoch 1882\n",
      "test_train\n",
      "train mean loss=62054.16875\n",
      "test_test\n",
      "test mean loss=87966.2265625\n",
      "fin save.\n",
      "epoch 1883\n",
      "test_train\n",
      "train mean loss=62709.716145833336\n",
      "test_test\n",
      "test mean loss=88122.97265625\n",
      "fin save.\n",
      "epoch 1884\n",
      "test_train\n",
      "train mean loss=62166.42109375\n",
      "test_test\n",
      "test mean loss=88013.74609375\n",
      "fin save.\n",
      "epoch 1885\n",
      "test_train\n",
      "train mean loss=61636.164322916666\n",
      "test_test\n",
      "test mean loss=87796.1015625\n",
      "fin save.\n",
      "epoch 1886\n",
      "test_train\n",
      "train mean loss=62194.60533854167\n",
      "test_test\n",
      "test mean loss=87860.19140625\n",
      "fin save.\n",
      "epoch 1887\n",
      "test_train\n",
      "train mean loss=61861.805338541664\n",
      "test_test\n",
      "test mean loss=87990.38671875\n",
      "fin save.\n",
      "epoch 1888\n",
      "test_train\n",
      "train mean loss=63207.54140625\n",
      "test_test\n",
      "test mean loss=88232.61328125\n",
      "fin save.\n",
      "epoch 1889\n",
      "test_train\n",
      "train mean loss=62471.890885416666\n",
      "test_test\n",
      "test mean loss=88086.39453125\n",
      "fin save.\n",
      "epoch 1890\n",
      "test_train\n",
      "train mean loss=61567.28723958333\n",
      "test_test\n",
      "test mean loss=87992.3828125\n",
      "fin save.\n",
      "epoch 1891\n",
      "test_train\n",
      "train mean loss=62201.338671875\n",
      "test_test\n",
      "test mean loss=87911.953125\n",
      "fin save.\n",
      "epoch 1892\n",
      "test_train\n",
      "train mean loss=62208.94453125\n",
      "test_test\n",
      "test mean loss=87763.94140625\n",
      "fin save.\n",
      "epoch 1893\n",
      "test_train\n",
      "train mean loss=63027.6328125\n",
      "test_test\n",
      "test mean loss=87933.5390625\n",
      "fin save.\n",
      "epoch 1894\n",
      "test_train\n",
      "train mean loss=62343.16744791667\n",
      "test_test\n",
      "test mean loss=88065.37109375\n",
      "fin save.\n",
      "epoch 1895\n",
      "test_train\n",
      "train mean loss=62080.993489583336\n",
      "test_test\n",
      "test mean loss=88134.796875\n",
      "fin save.\n",
      "epoch 1896\n",
      "test_train\n",
      "train mean loss=62081.0546875\n",
      "test_test\n",
      "test mean loss=88275.3671875\n",
      "fin save.\n",
      "epoch 1897\n",
      "test_train\n",
      "train mean loss=63075.68645833333\n",
      "test_test\n",
      "test mean loss=88097.45703125\n",
      "fin save.\n",
      "epoch 1898\n",
      "test_train\n",
      "train mean loss=62074.754166666666\n",
      "test_test\n",
      "test mean loss=87868.23046875\n",
      "fin save.\n",
      "epoch 1899\n",
      "test_train\n",
      "train mean loss=62816.04192708333\n",
      "test_test\n",
      "test mean loss=87985.34765625\n",
      "fin save.\n",
      "epoch 1900\n",
      "test_train\n",
      "train mean loss=62319.003125\n",
      "test_test\n",
      "test mean loss=87874.671875\n",
      "fin save.\n",
      "epoch 1901\n",
      "test_train\n",
      "train mean loss=62800.92135416667\n",
      "test_test\n",
      "test mean loss=88108.1171875\n",
      "fin save.\n",
      "epoch 1902\n",
      "test_train\n",
      "train mean loss=63001.632552083334\n",
      "test_test\n",
      "test mean loss=87879.80859375\n",
      "fin save.\n",
      "epoch 1903\n",
      "test_train\n",
      "train mean loss=62623.988020833334\n",
      "test_test\n",
      "test mean loss=87910.0546875\n",
      "fin save.\n",
      "epoch 1904\n",
      "test_train\n",
      "train mean loss=62822.95703125\n",
      "test_test\n",
      "test mean loss=87750.95703125\n",
      "fin save.\n",
      "epoch 1905\n",
      "test_train\n",
      "train mean loss=62100.64791666667\n",
      "test_test\n",
      "test mean loss=87953.30859375\n",
      "fin save.\n",
      "epoch 1906\n",
      "test_train\n",
      "train mean loss=62844.54140625\n",
      "test_test\n",
      "test mean loss=87768.9453125\n",
      "fin save.\n",
      "epoch 1907\n",
      "test_train\n",
      "train mean loss=62491.9328125\n",
      "test_test\n",
      "test mean loss=87913.1015625\n",
      "fin save.\n",
      "epoch 1908\n",
      "test_train\n",
      "train mean loss=62256.096354166664\n",
      "test_test\n",
      "test mean loss=88059.75\n",
      "fin save.\n",
      "epoch 1909\n",
      "test_train\n",
      "train mean loss=62486.13098958333\n",
      "test_test\n",
      "test mean loss=87980.3359375\n",
      "fin save.\n",
      "epoch 1910\n",
      "test_train\n",
      "train mean loss=61252.377213541666\n",
      "test_test\n",
      "test mean loss=88046.30078125\n",
      "fin save.\n",
      "epoch 1911\n",
      "test_train\n",
      "train mean loss=62314.285416666666\n",
      "test_test\n",
      "test mean loss=87961.0625\n",
      "fin save.\n",
      "epoch 1912\n",
      "test_train\n",
      "train mean loss=62641.890625\n",
      "test_test\n",
      "test mean loss=88119.703125\n",
      "fin save.\n",
      "epoch 1913\n",
      "test_train\n",
      "train mean loss=62524.053125\n",
      "test_test\n",
      "test mean loss=88115.98046875\n",
      "fin save.\n",
      "epoch 1914\n",
      "test_train\n",
      "train mean loss=62213.87786458333\n",
      "test_test\n",
      "test mean loss=88380.31640625\n",
      "fin save.\n",
      "epoch 1915\n",
      "test_train\n",
      "train mean loss=63054.658463541666\n",
      "test_test\n",
      "test mean loss=88329.4453125\n",
      "fin save.\n",
      "epoch 1916\n",
      "test_train\n",
      "train mean loss=63159.445052083334\n",
      "test_test\n",
      "test mean loss=87967.8359375\n",
      "fin save.\n",
      "epoch 1917\n",
      "test_train\n",
      "train mean loss=61968.080729166664\n",
      "test_test\n",
      "test mean loss=87900.45703125\n",
      "fin save.\n",
      "epoch 1918\n",
      "test_train\n",
      "train mean loss=62588.62317708333\n",
      "test_test\n",
      "test mean loss=87934.16796875\n",
      "fin save.\n",
      "epoch 1919\n",
      "test_train\n",
      "train mean loss=61851.113541666666\n",
      "test_test\n",
      "test mean loss=88151.51171875\n",
      "fin save.\n",
      "epoch 1920\n",
      "test_train\n",
      "train mean loss=63315.720052083336\n",
      "test_test\n",
      "test mean loss=88006.55859375\n",
      "fin save.\n",
      "epoch 1921\n",
      "test_train\n",
      "train mean loss=62389.08020833333\n",
      "test_test\n",
      "test mean loss=87777.1328125\n",
      "fin save.\n",
      "epoch 1922\n",
      "test_train\n",
      "train mean loss=61726.026041666664\n",
      "test_test\n",
      "test mean loss=87896.19140625\n",
      "fin save.\n",
      "epoch 1923\n",
      "test_train\n",
      "train mean loss=62998.58125\n",
      "test_test\n",
      "test mean loss=87871.078125\n",
      "fin save.\n",
      "epoch 1924\n",
      "test_train\n",
      "train mean loss=63010.72265625\n",
      "test_test\n",
      "test mean loss=87880.87890625\n",
      "fin save.\n",
      "epoch 1925\n",
      "test_train\n",
      "train mean loss=63347.41549479167\n",
      "test_test\n",
      "test mean loss=87685.41796875\n",
      "fin save.\n",
      "epoch 1926\n",
      "test_train\n",
      "train mean loss=61953.780078125\n",
      "test_test\n",
      "test mean loss=87923.6875\n",
      "fin save.\n",
      "epoch 1927\n",
      "test_train\n",
      "train mean loss=62887.04479166667\n",
      "test_test\n",
      "test mean loss=87869.28515625\n",
      "fin save.\n",
      "epoch 1928\n",
      "test_train\n",
      "train mean loss=62555.74140625\n",
      "test_test\n",
      "test mean loss=87954.296875\n",
      "fin save.\n",
      "epoch 1929\n",
      "test_train\n",
      "train mean loss=62636.69674479167\n",
      "test_test\n",
      "test mean loss=88112.01171875\n",
      "fin save.\n",
      "epoch 1930\n",
      "test_train\n",
      "train mean loss=62835.17239583333\n",
      "test_test\n",
      "test mean loss=88089.28515625\n",
      "fin save.\n",
      "epoch 1931\n",
      "test_train\n",
      "train mean loss=63063.933854166666\n",
      "test_test\n",
      "test mean loss=87880.06640625\n",
      "fin save.\n",
      "epoch 1932\n",
      "test_train\n",
      "train mean loss=62555.78229166667\n",
      "test_test\n",
      "test mean loss=87841.40625\n",
      "fin save.\n",
      "epoch 1933\n",
      "test_train\n",
      "train mean loss=61777.73489583333\n",
      "test_test\n",
      "test mean loss=87715.28515625\n",
      "fin save.\n",
      "epoch 1934\n",
      "test_train\n",
      "train mean loss=61824.4421875\n",
      "test_test\n",
      "test mean loss=87752.71484375\n",
      "fin save.\n",
      "epoch 1935\n",
      "test_train\n",
      "train mean loss=62070.94140625\n",
      "test_test\n",
      "test mean loss=87500.47265625\n",
      "fin save.\n",
      "epoch 1936\n",
      "test_train\n",
      "train mean loss=63104.35442708333\n",
      "test_test\n",
      "test mean loss=87572.0\n",
      "fin save.\n",
      "epoch 1937\n",
      "test_train\n",
      "train mean loss=61700.297265625\n",
      "test_test\n",
      "test mean loss=87412.625\n",
      "fin save.\n",
      "epoch 1938\n",
      "test_train\n",
      "train mean loss=64164.93046875\n",
      "test_test\n",
      "test mean loss=87528.359375\n",
      "fin save.\n",
      "epoch 1939\n",
      "test_train\n",
      "train mean loss=62818.07916666667\n",
      "test_test\n",
      "test mean loss=87344.40625\n",
      "fin save.\n",
      "epoch 1940\n",
      "test_train\n",
      "train mean loss=62517.85924479167\n",
      "test_test\n",
      "test mean loss=87266.359375\n",
      "fin save.\n",
      "epoch 1941\n",
      "test_train\n",
      "train mean loss=62353.043229166666\n",
      "test_test\n",
      "test mean loss=87304.98046875\n",
      "fin save.\n",
      "epoch 1942\n",
      "test_train\n",
      "train mean loss=62151.57109375\n",
      "test_test\n",
      "test mean loss=87290.140625\n",
      "fin save.\n",
      "epoch 1943\n",
      "test_train\n",
      "train mean loss=61967.26614583333\n",
      "test_test\n",
      "test mean loss=87354.375\n",
      "fin save.\n",
      "epoch 1944\n",
      "test_train\n",
      "train mean loss=60851.49921875\n",
      "test_test\n",
      "test mean loss=87326.69921875\n",
      "fin save.\n",
      "epoch 1945\n",
      "test_train\n",
      "train mean loss=63057.98255208333\n",
      "test_test\n",
      "test mean loss=87299.14453125\n",
      "fin save.\n",
      "epoch 1946\n",
      "test_train\n",
      "train mean loss=62572.86510416667\n",
      "test_test\n",
      "test mean loss=87404.125\n",
      "fin save.\n",
      "epoch 1947\n",
      "test_train\n",
      "train mean loss=62149.554296875\n",
      "test_test\n",
      "test mean loss=87491.39453125\n",
      "fin save.\n",
      "epoch 1948\n",
      "test_train\n",
      "train mean loss=62480.06484375\n",
      "test_test\n",
      "test mean loss=87688.8828125\n",
      "fin save.\n",
      "epoch 1949\n",
      "test_train\n",
      "train mean loss=62661.844010416666\n",
      "test_test\n",
      "test mean loss=87614.0\n",
      "fin save.\n",
      "epoch 1950\n",
      "test_train\n",
      "train mean loss=63028.83776041667\n",
      "test_test\n",
      "test mean loss=87468.77734375\n",
      "fin save.\n",
      "epoch 1951\n",
      "test_train\n",
      "train mean loss=62033.81145833333\n",
      "test_test\n",
      "test mean loss=87443.484375\n",
      "fin save.\n",
      "epoch 1952\n",
      "test_train\n",
      "train mean loss=62530.538802083334\n",
      "test_test\n",
      "test mean loss=87395.33984375\n",
      "fin save.\n",
      "epoch 1953\n",
      "test_train\n",
      "train mean loss=62813.54635416667\n",
      "test_test\n",
      "test mean loss=87465.859375\n",
      "fin save.\n",
      "epoch 1954\n",
      "test_train\n",
      "train mean loss=62447.364583333336\n",
      "test_test\n",
      "test mean loss=87389.84765625\n",
      "fin save.\n",
      "epoch 1955\n",
      "test_train\n",
      "train mean loss=62465.66158854167\n",
      "test_test\n",
      "test mean loss=87622.10546875\n",
      "fin save.\n",
      "epoch 1956\n",
      "test_train\n",
      "train mean loss=62174.04986979167\n",
      "test_test\n",
      "test mean loss=87738.42578125\n",
      "fin save.\n",
      "epoch 1957\n",
      "test_train\n",
      "train mean loss=62101.29192708333\n",
      "test_test\n",
      "test mean loss=87599.7734375\n",
      "fin save.\n",
      "epoch 1958\n",
      "test_train\n",
      "train mean loss=62693.92083333333\n",
      "test_test\n",
      "test mean loss=87431.87890625\n",
      "fin save.\n",
      "epoch 1959\n",
      "test_train\n",
      "train mean loss=61593.623828125\n",
      "test_test\n",
      "test mean loss=87785.47265625\n",
      "fin save.\n",
      "epoch 1960\n",
      "test_train\n",
      "train mean loss=62253.42421875\n",
      "test_test\n",
      "test mean loss=87678.30078125\n",
      "fin save.\n",
      "epoch 1961\n",
      "test_train\n",
      "train mean loss=62916.8203125\n",
      "test_test\n",
      "test mean loss=87632.95703125\n",
      "fin save.\n",
      "epoch 1962\n",
      "test_train\n",
      "train mean loss=61729.013020833336\n",
      "test_test\n",
      "test mean loss=87683.83984375\n",
      "fin save.\n",
      "epoch 1963\n",
      "test_train\n",
      "train mean loss=62179.929427083334\n",
      "test_test\n",
      "test mean loss=87723.96484375\n",
      "fin save.\n",
      "epoch 1964\n",
      "test_train\n",
      "train mean loss=62404.36770833333\n",
      "test_test\n",
      "test mean loss=87674.91015625\n",
      "fin save.\n",
      "epoch 1965\n",
      "test_train\n",
      "train mean loss=62172.625651041664\n",
      "test_test\n",
      "test mean loss=87682.98828125\n",
      "fin save.\n",
      "epoch 1966\n",
      "test_train\n",
      "train mean loss=62028.75\n",
      "test_test\n",
      "test mean loss=87913.1796875\n",
      "fin save.\n",
      "epoch 1967\n",
      "test_train\n",
      "train mean loss=62393.96822916667\n",
      "test_test\n",
      "test mean loss=87861.765625\n",
      "fin save.\n",
      "epoch 1968\n",
      "test_train\n",
      "train mean loss=61959.44375\n",
      "test_test\n",
      "test mean loss=87190.02734375\n",
      "fin save.\n",
      "epoch 1969\n",
      "test_train\n",
      "train mean loss=62532.385416666664\n",
      "test_test\n",
      "test mean loss=87186.23828125\n",
      "fin save.\n",
      "epoch 1970\n",
      "test_train\n",
      "train mean loss=61796.63776041667\n",
      "test_test\n",
      "test mean loss=87245.921875\n",
      "fin save.\n",
      "epoch 1971\n",
      "test_train\n",
      "train mean loss=62162.05859375\n",
      "test_test\n",
      "test mean loss=87723.04296875\n",
      "fin save.\n",
      "epoch 1972\n",
      "test_train\n",
      "train mean loss=63255.94817708333\n",
      "test_test\n",
      "test mean loss=87043.49609375\n",
      "fin save.\n",
      "epoch 1973\n",
      "test_train\n",
      "train mean loss=62289.85234375\n",
      "test_test\n",
      "test mean loss=87337.27734375\n",
      "fin save.\n",
      "epoch 1974\n",
      "test_train\n",
      "train mean loss=62862.40052083333\n",
      "test_test\n",
      "test mean loss=87156.92578125\n",
      "fin save.\n",
      "epoch 1975\n",
      "test_train\n",
      "train mean loss=63484.02890625\n",
      "test_test\n",
      "test mean loss=87247.12890625\n",
      "fin save.\n",
      "epoch 1976\n",
      "test_train\n",
      "train mean loss=62071.945572916666\n",
      "test_test\n",
      "test mean loss=86940.078125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fin save.\n",
      "epoch 1977\n",
      "test_train\n",
      "train mean loss=62317.255078125\n",
      "test_test\n",
      "test mean loss=87027.53125\n",
      "fin save.\n",
      "epoch 1978\n",
      "test_train\n",
      "train mean loss=62886.06744791667\n",
      "test_test\n",
      "test mean loss=87106.20703125\n",
      "fin save.\n",
      "epoch 1979\n",
      "test_train\n",
      "train mean loss=62115.16171875\n",
      "test_test\n",
      "test mean loss=87119.70703125\n",
      "fin save.\n",
      "epoch 1980\n",
      "test_train\n",
      "train mean loss=62031.07421875\n",
      "test_test\n",
      "test mean loss=86921.3359375\n",
      "fin save.\n",
      "epoch 1981\n",
      "test_train\n",
      "train mean loss=62283.79296875\n",
      "test_test\n",
      "test mean loss=86976.82421875\n",
      "fin save.\n",
      "epoch 1982\n",
      "test_train\n",
      "train mean loss=61967.560286458334\n",
      "test_test\n",
      "test mean loss=87158.703125\n",
      "fin save.\n",
      "epoch 1983\n",
      "test_train\n",
      "train mean loss=62638.12486979167\n",
      "test_test\n",
      "test mean loss=87191.16796875\n",
      "fin save.\n",
      "epoch 1984\n",
      "test_train\n",
      "train mean loss=62643.23359375\n",
      "test_test\n",
      "test mean loss=87078.6875\n",
      "fin save.\n",
      "epoch 1985\n",
      "test_train\n",
      "train mean loss=63129.783854166664\n",
      "test_test\n",
      "test mean loss=87031.01953125\n",
      "fin save.\n",
      "epoch 1986\n",
      "test_train\n",
      "train mean loss=62630.343359375\n",
      "test_test\n",
      "test mean loss=87129.71484375\n",
      "fin save.\n",
      "epoch 1987\n",
      "test_train\n",
      "train mean loss=61773.151041666664\n",
      "test_test\n",
      "test mean loss=87332.8984375\n",
      "fin save.\n",
      "epoch 1988\n",
      "test_train\n",
      "train mean loss=61371.102864583336\n",
      "test_test\n",
      "test mean loss=87102.41796875\n",
      "fin save.\n",
      "epoch 1989\n",
      "test_train\n",
      "train mean loss=62435.2375\n",
      "test_test\n",
      "test mean loss=87209.48046875\n",
      "fin save.\n",
      "epoch 1990\n",
      "test_train\n",
      "train mean loss=62973.49791666667\n",
      "test_test\n",
      "test mean loss=87113.62890625\n",
      "fin save.\n",
      "epoch 1991\n",
      "test_train\n",
      "train mean loss=62915.35950520833\n",
      "test_test\n",
      "test mean loss=87342.41796875\n",
      "fin save.\n",
      "epoch 1992\n",
      "test_train\n",
      "train mean loss=61840.99140625\n",
      "test_test\n",
      "test mean loss=87190.6640625\n",
      "fin save.\n",
      "epoch 1993\n",
      "test_train\n",
      "train mean loss=62545.72760416667\n",
      "test_test\n",
      "test mean loss=86776.23828125\n",
      "fin save.\n",
      "epoch 1994\n",
      "test_train\n",
      "train mean loss=62694.06536458333\n",
      "test_test\n",
      "test mean loss=86803.80078125\n",
      "fin save.\n",
      "epoch 1995\n",
      "test_train\n",
      "train mean loss=63616.49453125\n",
      "test_test\n",
      "test mean loss=86782.94921875\n",
      "fin save.\n",
      "epoch 1996\n",
      "test_train\n",
      "train mean loss=62722.303125\n",
      "test_test\n",
      "test mean loss=86771.51953125\n",
      "fin save.\n",
      "epoch 1997\n",
      "test_train\n",
      "train mean loss=62742.64010416667\n",
      "test_test\n",
      "test mean loss=86539.7734375\n",
      "fin save.\n",
      "epoch 1998\n",
      "test_train\n",
      "train mean loss=62588.17890625\n",
      "test_test\n",
      "test mean loss=86595.9921875\n",
      "fin save.\n",
      "epoch 1999\n",
      "test_train\n",
      "train mean loss=62634.61276041667\n",
      "test_test\n",
      "test mean loss=86640.6640625\n",
      "fin save.\n",
      "epoch 2000\n",
      "test_train\n",
      "train mean loss=61991.51875\n",
      "test_test\n",
      "test mean loss=88098.5390625\n",
      "fin save.\n",
      "epoch 2001\n",
      "test_train\n",
      "train mean loss=62417.959635416664\n",
      "test_test\n",
      "test mean loss=88085.61328125\n",
      "fin save.\n",
      "epoch 2002\n",
      "test_train\n",
      "train mean loss=61534.306380208334\n",
      "test_test\n",
      "test mean loss=88058.0078125\n",
      "fin save.\n",
      "epoch 2003\n",
      "test_train\n",
      "train mean loss=62635.120833333334\n",
      "test_test\n",
      "test mean loss=88089.5546875\n",
      "fin save.\n",
      "epoch 2004\n",
      "test_train\n",
      "train mean loss=62907.20390625\n",
      "test_test\n",
      "test mean loss=88055.1015625\n",
      "fin save.\n",
      "epoch 2005\n",
      "test_train\n",
      "train mean loss=64170.82955729167\n",
      "test_test\n",
      "test mean loss=88106.69921875\n",
      "fin save.\n",
      "epoch 2006\n",
      "test_train\n",
      "train mean loss=61930.91067708333\n",
      "test_test\n",
      "test mean loss=88156.2265625\n",
      "fin save.\n",
      "epoch 2007\n",
      "test_train\n",
      "train mean loss=63428.710677083334\n",
      "test_test\n",
      "test mean loss=88122.21875\n",
      "fin save.\n",
      "epoch 2008\n",
      "test_train\n",
      "train mean loss=63051.30416666667\n",
      "test_test\n",
      "test mean loss=88109.953125\n",
      "fin save.\n",
      "epoch 2009\n",
      "test_train\n",
      "train mean loss=61892.92369791667\n",
      "test_test\n",
      "test mean loss=88087.9140625\n",
      "fin save.\n",
      "epoch 2010\n",
      "test_train\n",
      "train mean loss=62016.69348958333\n",
      "test_test\n",
      "test mean loss=87892.1796875\n",
      "fin save.\n",
      "epoch 2011\n",
      "test_train\n",
      "train mean loss=63135.904947916664\n",
      "test_test\n",
      "test mean loss=87724.875\n",
      "fin save.\n",
      "epoch 2012\n",
      "test_train\n",
      "train mean loss=63051.519921875\n",
      "test_test\n",
      "test mean loss=87678.078125\n",
      "fin save.\n",
      "epoch 2013\n",
      "test_train\n",
      "train mean loss=61948.874739583334\n",
      "test_test\n",
      "test mean loss=87697.6875\n",
      "fin save.\n",
      "epoch 2014\n",
      "test_train\n",
      "train mean loss=63053.523697916666\n",
      "test_test\n",
      "test mean loss=87975.171875\n",
      "fin save.\n",
      "epoch 2015\n",
      "test_train\n",
      "train mean loss=62702.98645833333\n",
      "test_test\n",
      "test mean loss=87771.37109375\n",
      "fin save.\n",
      "epoch 2016\n",
      "test_train\n",
      "train mean loss=62223.855208333334\n",
      "test_test\n",
      "test mean loss=87827.6171875\n",
      "fin save.\n",
      "epoch 2017\n",
      "test_train\n",
      "train mean loss=62733.65052083333\n",
      "test_test\n",
      "test mean loss=87651.8671875\n",
      "fin save.\n",
      "epoch 2018\n",
      "test_train\n",
      "train mean loss=62457.51158854167\n",
      "test_test\n",
      "test mean loss=87878.44921875\n",
      "fin save.\n",
      "epoch 2019\n",
      "test_train\n",
      "train mean loss=62133.22109375\n",
      "test_test\n",
      "test mean loss=87740.24609375\n",
      "fin save.\n",
      "epoch 2020\n",
      "test_train\n",
      "train mean loss=62779.304947916666\n",
      "test_test\n",
      "test mean loss=87663.84765625\n",
      "fin save.\n",
      "epoch 2021\n",
      "test_train\n",
      "train mean loss=62303.48229166667\n",
      "test_test\n",
      "test mean loss=87747.3671875\n",
      "fin save.\n",
      "epoch 2022\n",
      "test_train\n",
      "train mean loss=61710.92578125\n",
      "test_test\n",
      "test mean loss=87633.75390625\n",
      "fin save.\n",
      "epoch 2023\n",
      "test_train\n",
      "train mean loss=62799.20455729167\n",
      "test_test\n",
      "test mean loss=87699.4453125\n",
      "fin save.\n",
      "epoch 2024\n",
      "test_train\n",
      "train mean loss=62164.55520833333\n",
      "test_test\n",
      "test mean loss=87753.73828125\n",
      "fin save.\n",
      "epoch 2025\n",
      "test_train\n",
      "train mean loss=62336.0875\n",
      "test_test\n",
      "test mean loss=87712.08984375\n",
      "fin save.\n",
      "epoch 2026\n",
      "test_train\n",
      "train mean loss=61979.282552083336\n",
      "test_test\n",
      "test mean loss=87610.16796875\n",
      "fin save.\n",
      "epoch 2027\n",
      "test_train\n",
      "train mean loss=62730.98033854167\n",
      "test_test\n",
      "test mean loss=87469.125\n",
      "fin save.\n",
      "epoch 2028\n",
      "test_train\n",
      "train mean loss=63246.764322916664\n",
      "test_test\n",
      "test mean loss=87555.96484375\n",
      "fin save.\n",
      "epoch 2029\n",
      "test_train\n",
      "train mean loss=62970.666796875\n",
      "test_test\n",
      "test mean loss=87685.85546875\n",
      "fin save.\n",
      "epoch 2030\n",
      "test_train\n",
      "train mean loss=62743.60625\n",
      "test_test\n",
      "test mean loss=87890.7578125\n",
      "fin save.\n",
      "epoch 2031\n",
      "test_train\n",
      "train mean loss=61690.079427083336\n",
      "test_test\n",
      "test mean loss=87822.09765625\n",
      "fin save.\n",
      "epoch 2032\n",
      "test_train\n",
      "train mean loss=62315.15807291667\n",
      "test_test\n",
      "test mean loss=87793.12890625\n",
      "fin save.\n",
      "epoch 2033\n",
      "test_train\n",
      "train mean loss=61582.37122395833\n",
      "test_test\n",
      "test mean loss=87799.8046875\n",
      "fin save.\n",
      "epoch 2034\n",
      "test_train\n",
      "train mean loss=62649.18046875\n",
      "test_test\n",
      "test mean loss=88227.91015625\n",
      "fin save.\n",
      "epoch 2035\n",
      "test_train\n",
      "train mean loss=62738.038671875\n",
      "test_test\n",
      "test mean loss=88265.84375\n",
      "fin save.\n",
      "epoch 2036\n",
      "test_train\n",
      "train mean loss=62646.00338541667\n",
      "test_test\n",
      "test mean loss=88175.79296875\n",
      "fin save.\n",
      "epoch 2037\n",
      "test_train\n",
      "train mean loss=62582.95104166667\n",
      "test_test\n",
      "test mean loss=88014.82421875\n",
      "fin save.\n",
      "epoch 2038\n",
      "test_train\n",
      "train mean loss=62376.925\n",
      "test_test\n",
      "test mean loss=88089.50390625\n",
      "fin save.\n",
      "epoch 2039\n",
      "test_train\n",
      "train mean loss=63041.53567708333\n",
      "test_test\n",
      "test mean loss=88176.5390625\n",
      "fin save.\n",
      "epoch 2040\n",
      "test_train\n",
      "train mean loss=62578.490625\n",
      "test_test\n",
      "test mean loss=88039.02734375\n",
      "fin save.\n",
      "epoch 2041\n",
      "test_train\n",
      "train mean loss=62853.407421875\n",
      "test_test\n",
      "test mean loss=87814.44140625\n",
      "fin save.\n",
      "epoch 2042\n",
      "test_train\n",
      "train mean loss=62165.626171875\n",
      "test_test\n",
      "test mean loss=87904.44921875\n",
      "fin save.\n",
      "epoch 2043\n",
      "test_train\n",
      "train mean loss=62752.61028645833\n",
      "test_test\n",
      "test mean loss=87940.17578125\n",
      "fin save.\n",
      "epoch 2044\n",
      "test_train\n",
      "train mean loss=63596.75390625\n",
      "test_test\n",
      "test mean loss=87969.29296875\n",
      "fin save.\n",
      "epoch 2045\n",
      "test_train\n",
      "train mean loss=61936.105729166666\n",
      "test_test\n",
      "test mean loss=88211.44140625\n",
      "fin save.\n",
      "epoch 2046\n",
      "test_train\n",
      "train mean loss=61738.675\n",
      "test_test\n",
      "test mean loss=88111.1328125\n",
      "fin save.\n",
      "epoch 2047\n",
      "test_train\n",
      "train mean loss=62271.36536458333\n",
      "test_test\n",
      "test mean loss=88137.9375\n",
      "fin save.\n",
      "epoch 2048\n",
      "test_train\n",
      "train mean loss=62637.35625\n",
      "test_test\n",
      "test mean loss=88257.6015625\n",
      "fin save.\n",
      "epoch 2049\n",
      "test_train\n",
      "train mean loss=63089.407421875\n",
      "test_test\n",
      "test mean loss=88089.91015625\n",
      "fin save.\n",
      "epoch 2050\n",
      "test_train\n",
      "train mean loss=62089.347395833334\n",
      "test_test\n",
      "test mean loss=88237.390625\n",
      "fin save.\n",
      "epoch 2051\n",
      "test_train\n",
      "train mean loss=61929.20078125\n",
      "test_test\n",
      "test mean loss=88130.9765625\n",
      "fin save.\n",
      "epoch 2052\n",
      "test_train\n",
      "train mean loss=62484.126302083336\n",
      "test_test\n",
      "test mean loss=88041.39453125\n",
      "fin save.\n",
      "epoch 2053\n",
      "test_train\n",
      "train mean loss=62146.803515625\n",
      "test_test\n",
      "test mean loss=88065.0859375\n",
      "fin save.\n",
      "epoch 2054\n",
      "test_train\n",
      "train mean loss=64106.60104166667\n",
      "test_test\n",
      "test mean loss=88051.8515625\n",
      "fin save.\n",
      "epoch 2055\n",
      "test_train\n",
      "train mean loss=63494.61666666667\n",
      "test_test\n",
      "test mean loss=87973.47265625\n",
      "fin save.\n",
      "epoch 2056\n",
      "test_train\n",
      "train mean loss=62611.039322916666\n",
      "test_test\n",
      "test mean loss=87786.3203125\n",
      "fin save.\n",
      "epoch 2057\n",
      "test_train\n",
      "train mean loss=62564.7390625\n",
      "test_test\n",
      "test mean loss=87837.84375\n",
      "fin save.\n",
      "epoch 2058\n",
      "test_train\n",
      "train mean loss=61877.13125\n",
      "test_test\n",
      "test mean loss=87486.25390625\n",
      "fin save.\n",
      "epoch 2059\n",
      "test_train\n",
      "train mean loss=62219.97890625\n",
      "test_test\n",
      "test mean loss=87445.8515625\n",
      "fin save.\n",
      "epoch 2060\n",
      "test_train\n",
      "train mean loss=63101.463671875\n",
      "test_test\n",
      "test mean loss=87466.9296875\n",
      "fin save.\n",
      "epoch 2061\n",
      "test_train\n",
      "train mean loss=62056.64700520833\n",
      "test_test\n",
      "test mean loss=87418.04296875\n",
      "fin save.\n",
      "epoch 2062\n",
      "test_train\n",
      "train mean loss=62823.40234375\n",
      "test_test\n",
      "test mean loss=87167.1640625\n",
      "fin save.\n",
      "epoch 2063\n",
      "test_train\n",
      "train mean loss=61905.8984375\n",
      "test_test\n",
      "test mean loss=87081.6171875\n",
      "fin save.\n",
      "epoch 2064\n",
      "test_train\n",
      "train mean loss=62562.048177083336\n",
      "test_test\n",
      "test mean loss=87246.1953125\n",
      "fin save.\n",
      "epoch 2065\n",
      "test_train\n",
      "train mean loss=63481.21015625\n",
      "test_test\n",
      "test mean loss=87610.90625\n",
      "fin save.\n",
      "epoch 2066\n",
      "test_train\n",
      "train mean loss=62210.08307291667\n",
      "test_test\n",
      "test mean loss=87641.265625\n",
      "fin save.\n",
      "epoch 2067\n",
      "test_train\n",
      "train mean loss=62332.95755208333\n",
      "test_test\n",
      "test mean loss=87352.5\n",
      "fin save.\n",
      "epoch 2068\n",
      "test_train\n",
      "train mean loss=63431.62291666667\n",
      "test_test\n",
      "test mean loss=87469.6328125\n",
      "fin save.\n",
      "epoch 2069\n",
      "test_train\n",
      "train mean loss=62768.69635416667\n",
      "test_test\n",
      "test mean loss=87574.98828125\n",
      "fin save.\n",
      "epoch 2070\n",
      "test_train\n",
      "train mean loss=62341.00924479167\n",
      "test_test\n",
      "test mean loss=87508.8984375\n",
      "fin save.\n",
      "epoch 2071\n",
      "test_train\n",
      "train mean loss=62578.831770833334\n",
      "test_test\n",
      "test mean loss=87459.75\n",
      "fin save.\n",
      "epoch 2072\n",
      "test_train\n",
      "train mean loss=62610.98919270833\n",
      "test_test\n",
      "test mean loss=87231.7890625\n",
      "fin save.\n",
      "epoch 2073\n",
      "test_train\n",
      "train mean loss=63302.01953125\n",
      "test_test\n",
      "test mean loss=87406.8984375\n",
      "fin save.\n",
      "epoch 2074\n",
      "test_train\n",
      "train mean loss=63149.663411458336\n",
      "test_test\n",
      "test mean loss=87292.98046875\n",
      "fin save.\n",
      "epoch 2075\n",
      "test_train\n",
      "train mean loss=63447.97447916667\n",
      "test_test\n",
      "test mean loss=87214.0859375\n",
      "fin save.\n",
      "epoch 2076\n",
      "test_train\n",
      "train mean loss=62606.414322916666\n",
      "test_test\n",
      "test mean loss=87313.05859375\n",
      "fin save.\n",
      "epoch 2077\n",
      "test_train\n",
      "train mean loss=63748.024739583336\n",
      "test_test\n",
      "test mean loss=87375.13671875\n",
      "fin save.\n",
      "epoch 2078\n",
      "test_train\n",
      "train mean loss=62989.87018229167\n",
      "test_test\n",
      "test mean loss=87360.87109375\n",
      "fin save.\n",
      "epoch 2079\n",
      "test_train\n",
      "train mean loss=62749.214192708336\n",
      "test_test\n",
      "test mean loss=87257.83203125\n",
      "fin save.\n",
      "epoch 2080\n",
      "test_train\n",
      "train mean loss=62063.56875\n",
      "test_test\n",
      "test mean loss=87061.125\n",
      "fin save.\n",
      "epoch 2081\n",
      "test_train\n",
      "train mean loss=62031.84322916667\n",
      "test_test\n",
      "test mean loss=87316.05078125\n",
      "fin save.\n",
      "epoch 2082\n",
      "test_train\n",
      "train mean loss=61883.51640625\n",
      "test_test\n",
      "test mean loss=87266.6484375\n",
      "fin save.\n",
      "epoch 2083\n",
      "test_train\n",
      "train mean loss=62337.153645833336\n",
      "test_test\n",
      "test mean loss=87275.28515625\n",
      "fin save.\n",
      "epoch 2084\n",
      "test_train\n",
      "train mean loss=62270.56484375\n",
      "test_test\n",
      "test mean loss=87493.00390625\n",
      "fin save.\n",
      "epoch 2085\n",
      "test_train\n",
      "train mean loss=63033.261458333334\n",
      "test_test\n",
      "test mean loss=87410.65234375\n",
      "fin save.\n",
      "epoch 2086\n",
      "test_train\n",
      "train mean loss=62644.1734375\n",
      "test_test\n",
      "test mean loss=87081.31640625\n",
      "fin save.\n",
      "epoch 2087\n",
      "test_train\n",
      "train mean loss=63759.709765625\n",
      "test_test\n",
      "test mean loss=87376.10546875\n",
      "fin save.\n",
      "epoch 2088\n",
      "test_train\n",
      "train mean loss=62561.90729166667\n",
      "test_test\n",
      "test mean loss=87180.43359375\n",
      "fin save.\n",
      "epoch 2089\n",
      "test_train\n",
      "train mean loss=62531.466015625\n",
      "test_test\n",
      "test mean loss=87253.03515625\n",
      "fin save.\n",
      "epoch 2090\n",
      "test_train\n",
      "train mean loss=63086.024609375\n",
      "test_test\n",
      "test mean loss=87252.93359375\n",
      "fin save.\n",
      "epoch 2091\n",
      "test_train\n",
      "train mean loss=62076.09296875\n",
      "test_test\n",
      "test mean loss=87275.09375\n",
      "fin save.\n",
      "epoch 2092\n",
      "test_train\n",
      "train mean loss=62332.71484375\n",
      "test_test\n",
      "test mean loss=87229.55078125\n",
      "fin save.\n",
      "epoch 2093\n",
      "test_train\n",
      "train mean loss=62601.341145833336\n",
      "test_test\n",
      "test mean loss=87061.546875\n",
      "fin save.\n",
      "epoch 2094\n",
      "test_train\n",
      "train mean loss=62730.35442708333\n",
      "test_test\n",
      "test mean loss=87035.34375\n",
      "fin save.\n",
      "epoch 2095\n",
      "test_train\n",
      "train mean loss=61892.040625\n",
      "test_test\n",
      "test mean loss=87214.33203125\n",
      "fin save.\n",
      "epoch 2096\n",
      "test_train\n",
      "train mean loss=62148.20598958333\n",
      "test_test\n",
      "test mean loss=86963.9921875\n",
      "fin save.\n",
      "epoch 2097\n",
      "test_train\n",
      "train mean loss=63044.11809895833\n",
      "test_test\n",
      "test mean loss=87017.22265625\n",
      "fin save.\n",
      "epoch 2098\n",
      "test_train\n",
      "train mean loss=63090.57734375\n",
      "test_test\n",
      "test mean loss=87199.73046875\n",
      "fin save.\n",
      "epoch 2099\n",
      "test_train\n",
      "train mean loss=61746.57317708333\n",
      "test_test\n",
      "test mean loss=87251.1484375\n",
      "fin save.\n",
      "epoch 2100\n",
      "test_train\n",
      "train mean loss=62683.85104166667\n",
      "test_test\n",
      "test mean loss=87476.7578125\n",
      "fin save.\n",
      "epoch 2101\n",
      "test_train\n",
      "train mean loss=62217.57630208333\n",
      "test_test\n",
      "test mean loss=87184.55859375\n",
      "fin save.\n",
      "epoch 2102\n",
      "test_train\n",
      "train mean loss=61647.57708333333\n",
      "test_test\n",
      "test mean loss=87189.1171875\n",
      "fin save.\n",
      "epoch 2103\n",
      "test_train\n",
      "train mean loss=62649.579427083336\n",
      "test_test\n",
      "test mean loss=87313.55859375\n",
      "fin save.\n",
      "epoch 2104\n",
      "test_train\n",
      "train mean loss=62967.877604166664\n",
      "test_test\n",
      "test mean loss=87286.40625\n",
      "fin save.\n",
      "epoch 2105\n",
      "test_train\n",
      "train mean loss=62996.0140625\n",
      "test_test\n",
      "test mean loss=87229.875\n",
      "fin save.\n",
      "epoch 2106\n",
      "test_train\n",
      "train mean loss=62485.459244791666\n",
      "test_test\n",
      "test mean loss=87240.94140625\n",
      "fin save.\n",
      "epoch 2107\n",
      "test_train\n",
      "train mean loss=62593.31328125\n",
      "test_test\n",
      "test mean loss=87372.14453125\n",
      "fin save.\n",
      "epoch 2108\n",
      "test_train\n",
      "train mean loss=62322.22421875\n",
      "test_test\n",
      "test mean loss=87433.87890625\n",
      "fin save.\n",
      "epoch 2109\n",
      "test_train\n",
      "train mean loss=62115.571484375\n",
      "test_test\n",
      "test mean loss=87800.46484375\n",
      "fin save.\n",
      "epoch 2110\n",
      "test_train\n",
      "train mean loss=62331.5890625\n",
      "test_test\n",
      "test mean loss=87682.828125\n",
      "fin save.\n",
      "epoch 2111\n",
      "test_train\n",
      "train mean loss=61870.03567708333\n",
      "test_test\n",
      "test mean loss=87853.359375\n",
      "fin save.\n",
      "epoch 2112\n",
      "test_train\n",
      "train mean loss=62707.62057291667\n",
      "test_test\n",
      "test mean loss=87755.453125\n",
      "fin save.\n",
      "epoch 2113\n",
      "test_train\n",
      "train mean loss=62730.450911458334\n",
      "test_test\n",
      "test mean loss=88020.6328125\n",
      "fin save.\n",
      "epoch 2114\n",
      "test_train\n",
      "train mean loss=61274.740885416664\n",
      "test_test\n",
      "test mean loss=86917.515625\n",
      "fin save.\n",
      "epoch 2115\n",
      "test_train\n",
      "train mean loss=62380.015625\n",
      "test_test\n",
      "test mean loss=87499.0390625\n",
      "fin save.\n",
      "epoch 2116\n",
      "test_train\n",
      "train mean loss=61883.669140625\n",
      "test_test\n",
      "test mean loss=87241.28125\n",
      "fin save.\n",
      "epoch 2117\n",
      "test_train\n",
      "train mean loss=61579.89140625\n",
      "test_test\n",
      "test mean loss=87488.234375\n",
      "fin save.\n",
      "epoch 2118\n",
      "test_train\n",
      "train mean loss=61469.363671875\n",
      "test_test\n",
      "test mean loss=87289.65234375\n",
      "fin save.\n",
      "epoch 2119\n",
      "test_train\n",
      "train mean loss=62566.95807291667\n",
      "test_test\n",
      "test mean loss=87428.69140625\n",
      "fin save.\n",
      "epoch 2120\n",
      "test_train\n",
      "train mean loss=62451.12213541667\n",
      "test_test\n",
      "test mean loss=87274.10546875\n",
      "fin save.\n",
      "epoch 2121\n",
      "test_train\n",
      "train mean loss=62394.54596354167\n",
      "test_test\n",
      "test mean loss=87469.0703125\n",
      "fin save.\n",
      "epoch 2122\n",
      "test_train\n",
      "train mean loss=62337.66015625\n",
      "test_test\n",
      "test mean loss=87310.953125\n",
      "fin save.\n",
      "epoch 2123\n",
      "test_train\n",
      "train mean loss=63496.54986979167\n",
      "test_test\n",
      "test mean loss=87330.953125\n",
      "fin save.\n",
      "epoch 2124\n",
      "test_train\n",
      "train mean loss=61715.52161458333\n",
      "test_test\n",
      "test mean loss=87361.1640625\n",
      "fin save.\n",
      "epoch 2125\n",
      "test_train\n",
      "train mean loss=63261.823958333334\n",
      "test_test\n",
      "test mean loss=87429.17578125\n",
      "fin save.\n",
      "epoch 2126\n",
      "test_train\n",
      "train mean loss=60888.54192708333\n",
      "test_test\n",
      "test mean loss=87544.05859375\n",
      "fin save.\n",
      "epoch 2127\n",
      "test_train\n",
      "train mean loss=62520.51328125\n",
      "test_test\n",
      "test mean loss=87448.0\n",
      "fin save.\n",
      "epoch 2128\n",
      "test_train\n",
      "train mean loss=61851.826171875\n",
      "test_test\n",
      "test mean loss=87618.48046875\n",
      "fin save.\n",
      "epoch 2129\n",
      "test_train\n",
      "train mean loss=62530.16158854167\n",
      "test_test\n",
      "test mean loss=87613.1796875\n",
      "fin save.\n",
      "epoch 2130\n",
      "test_train\n",
      "train mean loss=61824.24609375\n",
      "test_test\n",
      "test mean loss=87634.7734375\n",
      "fin save.\n",
      "epoch 2131\n",
      "test_train\n",
      "train mean loss=62729.63359375\n",
      "test_test\n",
      "test mean loss=87688.5703125\n",
      "fin save.\n",
      "epoch 2132\n",
      "test_train\n",
      "train mean loss=63010.85260416667\n",
      "test_test\n",
      "test mean loss=87649.22265625\n",
      "fin save.\n",
      "epoch 2133\n",
      "test_train\n",
      "train mean loss=62419.133072916666\n",
      "test_test\n",
      "test mean loss=87695.625\n",
      "fin save.\n",
      "epoch 2134\n",
      "test_train\n",
      "train mean loss=62430.882552083334\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=87737.08984375\n",
      "fin save.\n",
      "epoch 2135\n",
      "test_train\n",
      "train mean loss=62116.660416666666\n",
      "test_test\n",
      "test mean loss=87679.828125\n",
      "fin save.\n",
      "epoch 2136\n",
      "test_train\n",
      "train mean loss=61778.3578125\n",
      "test_test\n",
      "test mean loss=87752.2890625\n",
      "fin save.\n",
      "epoch 2137\n",
      "test_train\n",
      "train mean loss=62292.63177083333\n",
      "test_test\n",
      "test mean loss=87855.10546875\n",
      "fin save.\n",
      "epoch 2138\n",
      "test_train\n",
      "train mean loss=62783.03828125\n",
      "test_test\n",
      "test mean loss=87732.328125\n",
      "fin save.\n",
      "epoch 2139\n",
      "test_train\n",
      "train mean loss=62388.699869791664\n",
      "test_test\n",
      "test mean loss=87752.52734375\n",
      "fin save.\n",
      "epoch 2140\n",
      "test_train\n",
      "train mean loss=62412.065104166664\n",
      "test_test\n",
      "test mean loss=87590.63671875\n",
      "fin save.\n",
      "epoch 2141\n",
      "test_train\n",
      "train mean loss=61902.72421875\n",
      "test_test\n",
      "test mean loss=87590.36328125\n",
      "fin save.\n",
      "epoch 2142\n",
      "test_train\n",
      "train mean loss=61657.06458333333\n",
      "test_test\n",
      "test mean loss=87531.90625\n",
      "fin save.\n",
      "epoch 2143\n",
      "test_train\n",
      "train mean loss=62454.936848958336\n",
      "test_test\n",
      "test mean loss=87623.66015625\n",
      "fin save.\n",
      "epoch 2144\n",
      "test_train\n",
      "train mean loss=61167.05416666667\n",
      "test_test\n",
      "test mean loss=87527.671875\n",
      "fin save.\n",
      "epoch 2145\n",
      "test_train\n",
      "train mean loss=63272.05130208333\n",
      "test_test\n",
      "test mean loss=87542.828125\n",
      "fin save.\n",
      "epoch 2146\n",
      "test_train\n",
      "train mean loss=61101.963541666664\n",
      "test_test\n",
      "test mean loss=88540.8359375\n",
      "fin save.\n",
      "epoch 2147\n",
      "test_train\n",
      "train mean loss=62571.91223958333\n",
      "test_test\n",
      "test mean loss=88706.8828125\n",
      "fin save.\n",
      "epoch 2148\n",
      "test_train\n",
      "train mean loss=62828.99296875\n",
      "test_test\n",
      "test mean loss=88548.6015625\n",
      "fin save.\n",
      "epoch 2149\n",
      "test_train\n",
      "train mean loss=62484.302083333336\n",
      "test_test\n",
      "test mean loss=88524.2265625\n",
      "fin save.\n",
      "epoch 2150\n",
      "test_train\n",
      "train mean loss=62533.519791666666\n",
      "test_test\n",
      "test mean loss=88303.0234375\n",
      "fin save.\n",
      "epoch 2151\n",
      "test_train\n",
      "train mean loss=62213.24505208333\n",
      "test_test\n",
      "test mean loss=88649.015625\n",
      "fin save.\n",
      "epoch 2152\n",
      "test_train\n",
      "train mean loss=62726.29192708333\n",
      "test_test\n",
      "test mean loss=88594.4296875\n",
      "fin save.\n",
      "epoch 2153\n",
      "test_train\n",
      "train mean loss=63202.763411458334\n",
      "test_test\n",
      "test mean loss=88672.90625\n",
      "fin save.\n",
      "epoch 2154\n",
      "test_train\n",
      "train mean loss=62049.8859375\n",
      "test_test\n",
      "test mean loss=88702.95703125\n",
      "fin save.\n",
      "epoch 2155\n",
      "test_train\n",
      "train mean loss=61679.126302083336\n",
      "test_test\n",
      "test mean loss=88789.1015625\n",
      "fin save.\n",
      "epoch 2156\n",
      "test_train\n",
      "train mean loss=61593.28046875\n",
      "test_test\n",
      "test mean loss=88851.9375\n",
      "fin save.\n",
      "epoch 2157\n",
      "test_train\n",
      "train mean loss=61956.87552083333\n",
      "test_test\n",
      "test mean loss=88847.58984375\n",
      "fin save.\n",
      "epoch 2158\n",
      "test_train\n",
      "train mean loss=61975.30911458333\n",
      "test_test\n",
      "test mean loss=88749.34765625\n",
      "fin save.\n",
      "epoch 2159\n",
      "test_train\n",
      "train mean loss=63142.80807291667\n",
      "test_test\n",
      "test mean loss=88488.87109375\n",
      "fin save.\n",
      "epoch 2160\n",
      "test_train\n",
      "train mean loss=62175.75924479167\n",
      "test_test\n",
      "test mean loss=88624.0703125\n",
      "fin save.\n",
      "epoch 2161\n",
      "test_train\n",
      "train mean loss=62199.79348958333\n",
      "test_test\n",
      "test mean loss=88717.49609375\n",
      "fin save.\n",
      "epoch 2162\n",
      "test_train\n",
      "train mean loss=61857.89505208333\n",
      "test_test\n",
      "test mean loss=88585.91796875\n",
      "fin save.\n",
      "epoch 2163\n",
      "test_train\n",
      "train mean loss=61173.28177083333\n",
      "test_test\n",
      "test mean loss=88535.55859375\n",
      "fin save.\n",
      "epoch 2164\n",
      "test_train\n",
      "train mean loss=62319.24791666667\n",
      "test_test\n",
      "test mean loss=88594.078125\n",
      "fin save.\n",
      "epoch 2165\n",
      "test_train\n",
      "train mean loss=63354.520833333336\n",
      "test_test\n",
      "test mean loss=88694.06640625\n",
      "fin save.\n",
      "epoch 2166\n",
      "test_train\n",
      "train mean loss=62611.0390625\n",
      "test_test\n",
      "test mean loss=88657.87890625\n",
      "fin save.\n",
      "epoch 2167\n",
      "test_train\n",
      "train mean loss=62521.47708333333\n",
      "test_test\n",
      "test mean loss=88727.87109375\n",
      "fin save.\n",
      "epoch 2168\n",
      "test_train\n",
      "train mean loss=62768.7640625\n",
      "test_test\n",
      "test mean loss=88683.48828125\n",
      "fin save.\n",
      "epoch 2169\n",
      "test_train\n",
      "train mean loss=62714.853515625\n",
      "test_test\n",
      "test mean loss=88071.23828125\n",
      "fin save.\n",
      "epoch 2170\n",
      "test_train\n",
      "train mean loss=62413.259375\n",
      "test_test\n",
      "test mean loss=88141.20703125\n",
      "fin save.\n",
      "epoch 2171\n",
      "test_train\n",
      "train mean loss=62252.373046875\n",
      "test_test\n",
      "test mean loss=88250.68359375\n",
      "fin save.\n",
      "epoch 2172\n",
      "test_train\n",
      "train mean loss=61345.162369791666\n",
      "test_test\n",
      "test mean loss=88377.7265625\n",
      "fin save.\n",
      "epoch 2173\n",
      "test_train\n",
      "train mean loss=63276.289453125\n",
      "test_test\n",
      "test mean loss=88331.1015625\n",
      "fin save.\n",
      "epoch 2174\n",
      "test_train\n",
      "train mean loss=62754.30859375\n",
      "test_test\n",
      "test mean loss=88378.2734375\n",
      "fin save.\n",
      "epoch 2175\n",
      "test_train\n",
      "train mean loss=62050.880859375\n",
      "test_test\n",
      "test mean loss=88410.796875\n",
      "fin save.\n",
      "epoch 2176\n",
      "test_train\n",
      "train mean loss=62412.99713541667\n",
      "test_test\n",
      "test mean loss=88516.21484375\n",
      "fin save.\n",
      "epoch 2177\n",
      "test_train\n",
      "train mean loss=62501.71796875\n",
      "test_test\n",
      "test mean loss=88575.546875\n",
      "fin save.\n",
      "epoch 2178\n",
      "test_train\n",
      "train mean loss=62251.113541666666\n",
      "test_test\n",
      "test mean loss=88572.0390625\n",
      "fin save.\n",
      "epoch 2179\n",
      "test_train\n",
      "train mean loss=62573.09270833333\n",
      "test_test\n",
      "test mean loss=88516.74609375\n",
      "fin save.\n",
      "epoch 2180\n",
      "test_train\n",
      "train mean loss=62630.20989583333\n",
      "test_test\n",
      "test mean loss=88400.03125\n",
      "fin save.\n",
      "epoch 2181\n",
      "test_train\n",
      "train mean loss=62155.67526041667\n",
      "test_test\n",
      "test mean loss=88375.90234375\n",
      "fin save.\n",
      "epoch 2182\n",
      "test_train\n",
      "train mean loss=62463.820572916666\n",
      "test_test\n",
      "test mean loss=88426.71484375\n",
      "fin save.\n",
      "epoch 2183\n",
      "test_train\n",
      "train mean loss=61904.190104166664\n",
      "test_test\n",
      "test mean loss=88462.12890625\n",
      "fin save.\n",
      "epoch 2184\n",
      "test_train\n",
      "train mean loss=62844.378645833334\n",
      "test_test\n",
      "test mean loss=88625.18359375\n",
      "fin save.\n",
      "epoch 2185\n",
      "test_train\n",
      "train mean loss=62550.309375\n",
      "test_test\n",
      "test mean loss=88525.2421875\n",
      "fin save.\n",
      "epoch 2186\n",
      "test_train\n",
      "train mean loss=62325.721875\n",
      "test_test\n",
      "test mean loss=88276.41015625\n",
      "fin save.\n",
      "epoch 2187\n",
      "test_train\n",
      "train mean loss=62764.80703125\n",
      "test_test\n",
      "test mean loss=88346.7265625\n",
      "fin save.\n",
      "epoch 2188\n",
      "test_train\n",
      "train mean loss=62698.09817708333\n",
      "test_test\n",
      "test mean loss=88324.1484375\n",
      "fin save.\n",
      "epoch 2189\n",
      "test_train\n",
      "train mean loss=61982.37122395833\n",
      "test_test\n",
      "test mean loss=88395.30859375\n",
      "fin save.\n",
      "epoch 2190\n",
      "test_train\n",
      "train mean loss=63025.639322916664\n",
      "test_test\n",
      "test mean loss=88172.23828125\n",
      "fin save.\n",
      "epoch 2191\n",
      "test_train\n",
      "train mean loss=62330.60260416667\n",
      "test_test\n",
      "test mean loss=88263.11328125\n",
      "fin save.\n",
      "epoch 2192\n",
      "test_train\n",
      "train mean loss=62404.0828125\n",
      "test_test\n",
      "test mean loss=87768.4296875\n",
      "fin save.\n",
      "epoch 2193\n",
      "test_train\n",
      "train mean loss=61374.73255208333\n",
      "test_test\n",
      "test mean loss=87781.72265625\n",
      "fin save.\n",
      "epoch 2194\n",
      "test_train\n",
      "train mean loss=61524.49166666667\n",
      "test_test\n",
      "test mean loss=87979.84375\n",
      "fin save.\n",
      "epoch 2195\n",
      "test_train\n",
      "train mean loss=63046.60338541667\n",
      "test_test\n",
      "test mean loss=87869.89453125\n",
      "fin save.\n",
      "epoch 2196\n",
      "test_train\n",
      "train mean loss=62651.7921875\n",
      "test_test\n",
      "test mean loss=87811.1875\n",
      "fin save.\n",
      "epoch 2197\n",
      "test_train\n",
      "train mean loss=62896.85\n",
      "test_test\n",
      "test mean loss=88229.64453125\n",
      "fin save.\n",
      "epoch 2198\n",
      "test_train\n",
      "train mean loss=63209.56145833333\n",
      "test_test\n",
      "test mean loss=88577.3515625\n",
      "fin save.\n",
      "epoch 2199\n",
      "test_train\n",
      "train mean loss=62484.13919270833\n",
      "test_test\n",
      "test mean loss=88633.34765625\n",
      "fin save.\n",
      "epoch 2200\n",
      "test_train\n",
      "train mean loss=61669.56848958333\n",
      "test_test\n",
      "test mean loss=88608.85546875\n",
      "fin save.\n",
      "epoch 2201\n",
      "test_train\n",
      "train mean loss=62370.84817708333\n",
      "test_test\n",
      "test mean loss=88514.84765625\n",
      "fin save.\n",
      "epoch 2202\n",
      "test_train\n",
      "train mean loss=62268.81536458333\n",
      "test_test\n",
      "test mean loss=88678.30078125\n",
      "fin save.\n",
      "epoch 2203\n",
      "test_train\n",
      "train mean loss=63479.490494791666\n",
      "test_test\n",
      "test mean loss=88376.87890625\n",
      "fin save.\n",
      "epoch 2204\n",
      "test_train\n",
      "train mean loss=62996.18020833333\n",
      "test_test\n",
      "test mean loss=87830.16796875\n",
      "fin save.\n",
      "epoch 2205\n",
      "test_train\n",
      "train mean loss=62289.46536458333\n",
      "test_test\n",
      "test mean loss=87902.7265625\n",
      "fin save.\n",
      "epoch 2206\n",
      "test_train\n",
      "train mean loss=62104.56692708333\n",
      "test_test\n",
      "test mean loss=87846.3359375\n",
      "fin save.\n",
      "epoch 2207\n",
      "test_train\n",
      "train mean loss=62706.87421875\n",
      "test_test\n",
      "test mean loss=87420.03515625\n",
      "fin save.\n",
      "epoch 2208\n",
      "test_train\n",
      "train mean loss=62628.54440104167\n",
      "test_test\n",
      "test mean loss=87571.52734375\n",
      "fin save.\n",
      "epoch 2209\n",
      "test_train\n",
      "train mean loss=62836.98932291667\n",
      "test_test\n",
      "test mean loss=87506.890625\n",
      "fin save.\n",
      "epoch 2210\n",
      "test_train\n",
      "train mean loss=62424.325\n",
      "test_test\n",
      "test mean loss=87434.3515625\n",
      "fin save.\n",
      "epoch 2211\n",
      "test_train\n",
      "train mean loss=62223.74895833333\n",
      "test_test\n",
      "test mean loss=87378.57421875\n",
      "fin save.\n",
      "epoch 2212\n",
      "test_train\n",
      "train mean loss=62655.35755208333\n",
      "test_test\n",
      "test mean loss=87966.12890625\n",
      "fin save.\n",
      "epoch 2213\n",
      "test_train\n",
      "train mean loss=62624.829296875\n",
      "test_test\n",
      "test mean loss=87841.828125\n",
      "fin save.\n",
      "epoch 2214\n",
      "test_train\n",
      "train mean loss=62399.06484375\n",
      "test_test\n",
      "test mean loss=87972.859375\n",
      "fin save.\n",
      "epoch 2215\n",
      "test_train\n",
      "train mean loss=62940.73776041667\n",
      "test_test\n",
      "test mean loss=87544.64453125\n",
      "fin save.\n",
      "epoch 2216\n",
      "test_train\n",
      "train mean loss=63571.02005208333\n",
      "test_test\n",
      "test mean loss=87240.390625\n",
      "fin save.\n",
      "epoch 2217\n",
      "test_train\n",
      "train mean loss=63016.87708333333\n",
      "test_test\n",
      "test mean loss=87564.11328125\n",
      "fin save.\n",
      "epoch 2218\n",
      "test_train\n",
      "train mean loss=63284.998828125\n",
      "test_test\n",
      "test mean loss=87775.25\n",
      "fin save.\n",
      "epoch 2219\n",
      "test_train\n",
      "train mean loss=62841.94088541667\n",
      "test_test\n",
      "test mean loss=87786.546875\n",
      "fin save.\n",
      "epoch 2220\n",
      "test_train\n",
      "train mean loss=62887.24427083333\n",
      "test_test\n",
      "test mean loss=88083.9921875\n",
      "fin save.\n",
      "epoch 2221\n",
      "test_train\n",
      "train mean loss=63037.89140625\n",
      "test_test\n",
      "test mean loss=88038.140625\n",
      "fin save.\n",
      "epoch 2222\n",
      "test_train\n",
      "train mean loss=62492.31041666667\n",
      "test_test\n",
      "test mean loss=88159.2265625\n",
      "fin save.\n",
      "epoch 2223\n",
      "test_train\n",
      "train mean loss=62631.11901041667\n",
      "test_test\n",
      "test mean loss=87856.81640625\n",
      "fin save.\n",
      "epoch 2224\n",
      "test_train\n",
      "train mean loss=63008.87942708333\n",
      "test_test\n",
      "test mean loss=89064.2578125\n",
      "fin save.\n",
      "epoch 2225\n",
      "test_train\n",
      "train mean loss=63698.28177083333\n",
      "test_test\n",
      "test mean loss=89063.140625\n",
      "fin save.\n",
      "epoch 2226\n",
      "test_train\n",
      "train mean loss=62112.729166666664\n",
      "test_test\n",
      "test mean loss=89150.21484375\n",
      "fin save.\n",
      "epoch 2227\n",
      "test_train\n",
      "train mean loss=63216.03072916667\n",
      "test_test\n",
      "test mean loss=89172.765625\n",
      "fin save.\n",
      "epoch 2228\n",
      "test_train\n",
      "train mean loss=63495.07239583333\n",
      "test_test\n",
      "test mean loss=88363.84375\n",
      "fin save.\n",
      "epoch 2229\n",
      "test_train\n",
      "train mean loss=63130.58489583333\n",
      "test_test\n",
      "test mean loss=88195.3671875\n",
      "fin save.\n",
      "epoch 2230\n",
      "test_train\n",
      "train mean loss=62931.576953125\n",
      "test_test\n",
      "test mean loss=87935.21484375\n",
      "fin save.\n",
      "epoch 2231\n",
      "test_train\n",
      "train mean loss=62886.22760416667\n",
      "test_test\n",
      "test mean loss=87925.12109375\n",
      "fin save.\n",
      "epoch 2232\n",
      "test_train\n",
      "train mean loss=62615.62734375\n",
      "test_test\n",
      "test mean loss=87693.7734375\n",
      "fin save.\n",
      "epoch 2233\n",
      "test_train\n",
      "train mean loss=62948.007552083334\n",
      "test_test\n",
      "test mean loss=87619.8515625\n",
      "fin save.\n",
      "epoch 2234\n",
      "test_train\n",
      "train mean loss=62579.026041666664\n",
      "test_test\n",
      "test mean loss=88052.09765625\n",
      "fin save.\n",
      "epoch 2235\n",
      "test_train\n",
      "train mean loss=63059.35651041667\n",
      "test_test\n",
      "test mean loss=87825.45703125\n",
      "fin save.\n",
      "epoch 2236\n",
      "test_train\n",
      "train mean loss=64667.798177083336\n",
      "test_test\n",
      "test mean loss=87657.78515625\n",
      "fin save.\n",
      "epoch 2237\n",
      "test_train\n",
      "train mean loss=62376.812239583334\n",
      "test_test\n",
      "test mean loss=87667.11328125\n",
      "fin save.\n",
      "epoch 2238\n",
      "test_train\n",
      "train mean loss=64065.27890625\n",
      "test_test\n",
      "test mean loss=87474.1796875\n",
      "fin save.\n",
      "epoch 2239\n",
      "test_train\n",
      "train mean loss=62797.46276041667\n",
      "test_test\n",
      "test mean loss=88076.578125\n",
      "fin save.\n",
      "epoch 2240\n",
      "test_train\n",
      "train mean loss=62625.17890625\n",
      "test_test\n",
      "test mean loss=88212.734375\n",
      "fin save.\n",
      "epoch 2241\n",
      "test_train\n",
      "train mean loss=63891.55\n",
      "test_test\n",
      "test mean loss=88011.66015625\n",
      "fin save.\n",
      "epoch 2242\n",
      "test_train\n",
      "train mean loss=62756.00625\n",
      "test_test\n",
      "test mean loss=87994.5078125\n",
      "fin save.\n",
      "epoch 2243\n",
      "test_train\n",
      "train mean loss=62985.100260416664\n",
      "test_test\n",
      "test mean loss=87752.96484375\n",
      "fin save.\n",
      "epoch 2244\n",
      "test_train\n",
      "train mean loss=63120.28307291667\n",
      "test_test\n",
      "test mean loss=87614.49609375\n",
      "fin save.\n",
      "epoch 2245\n",
      "test_train\n",
      "train mean loss=62447.5328125\n",
      "test_test\n",
      "test mean loss=88088.10546875\n",
      "fin save.\n",
      "epoch 2246\n",
      "test_train\n",
      "train mean loss=62988.06536458333\n",
      "test_test\n",
      "test mean loss=88103.4296875\n",
      "fin save.\n",
      "epoch 2247\n",
      "test_train\n",
      "train mean loss=63124.421875\n",
      "test_test\n",
      "test mean loss=87911.77734375\n",
      "fin save.\n",
      "epoch 2248\n",
      "test_train\n",
      "train mean loss=63297.59765625\n",
      "test_test\n",
      "test mean loss=87935.984375\n",
      "fin save.\n",
      "epoch 2249\n",
      "test_train\n",
      "train mean loss=63691.309895833336\n",
      "test_test\n",
      "test mean loss=87816.3515625\n",
      "fin save.\n",
      "epoch 2250\n",
      "test_train\n",
      "train mean loss=63186.63619791667\n",
      "test_test\n",
      "test mean loss=88045.0859375\n",
      "fin save.\n",
      "epoch 2251\n",
      "test_train\n",
      "train mean loss=63058.73932291667\n",
      "test_test\n",
      "test mean loss=88085.5859375\n",
      "fin save.\n",
      "epoch 2252\n",
      "test_train\n",
      "train mean loss=63933.45911458333\n",
      "test_test\n",
      "test mean loss=87990.48046875\n",
      "fin save.\n",
      "epoch 2253\n",
      "test_train\n",
      "train mean loss=63370.48880208333\n",
      "test_test\n",
      "test mean loss=88025.953125\n",
      "fin save.\n",
      "epoch 2254\n",
      "test_train\n",
      "train mean loss=63194.58671875\n",
      "test_test\n",
      "test mean loss=87982.92578125\n",
      "fin save.\n",
      "epoch 2255\n",
      "test_train\n",
      "train mean loss=62569.92916666667\n",
      "test_test\n",
      "test mean loss=87837.93359375\n",
      "fin save.\n",
      "epoch 2256\n",
      "test_train\n",
      "train mean loss=63974.360546875\n",
      "test_test\n",
      "test mean loss=88077.84375\n",
      "fin save.\n",
      "epoch 2257\n",
      "test_train\n",
      "train mean loss=63227.93203125\n",
      "test_test\n",
      "test mean loss=88100.84375\n",
      "fin save.\n",
      "epoch 2258\n",
      "test_train\n",
      "train mean loss=63616.63958333333\n",
      "test_test\n",
      "test mean loss=87916.91015625\n",
      "fin save.\n",
      "epoch 2259\n",
      "test_train\n",
      "train mean loss=62833.390885416666\n",
      "test_test\n",
      "test mean loss=87156.8671875\n",
      "fin save.\n",
      "epoch 2260\n",
      "test_train\n",
      "train mean loss=63279.263671875\n",
      "test_test\n",
      "test mean loss=87204.46875\n",
      "fin save.\n",
      "epoch 2261\n",
      "test_train\n",
      "train mean loss=63174.30807291667\n",
      "test_test\n",
      "test mean loss=87488.37109375\n",
      "fin save.\n",
      "epoch 2262\n",
      "test_train\n",
      "train mean loss=63719.871875\n",
      "test_test\n",
      "test mean loss=87373.20703125\n",
      "fin save.\n",
      "epoch 2263\n",
      "test_train\n",
      "train mean loss=62998.05651041667\n",
      "test_test\n",
      "test mean loss=87407.625\n",
      "fin save.\n",
      "epoch 2264\n",
      "test_train\n",
      "train mean loss=62905.555859375\n",
      "test_test\n",
      "test mean loss=87416.921875\n",
      "fin save.\n",
      "epoch 2265\n",
      "test_train\n",
      "train mean loss=62859.94817708333\n",
      "test_test\n",
      "test mean loss=87024.81640625\n",
      "fin save.\n",
      "epoch 2266\n",
      "test_train\n",
      "train mean loss=62245.66510416667\n",
      "test_test\n",
      "test mean loss=87511.625\n",
      "fin save.\n",
      "epoch 2267\n",
      "test_train\n",
      "train mean loss=63181.370833333334\n",
      "test_test\n",
      "test mean loss=87461.25390625\n",
      "fin save.\n",
      "epoch 2268\n",
      "test_train\n",
      "train mean loss=62725.87890625\n",
      "test_test\n",
      "test mean loss=86870.77734375\n",
      "fin save.\n",
      "epoch 2269\n",
      "test_train\n",
      "train mean loss=63520.26796875\n",
      "test_test\n",
      "test mean loss=86709.27734375\n",
      "fin save.\n",
      "epoch 2270\n",
      "test_train\n",
      "train mean loss=62617.821875\n",
      "test_test\n",
      "test mean loss=86688.32421875\n",
      "fin save.\n",
      "epoch 2271\n",
      "test_train\n",
      "train mean loss=61965.75963541667\n",
      "test_test\n",
      "test mean loss=87229.07421875\n",
      "fin save.\n",
      "epoch 2272\n",
      "test_train\n",
      "train mean loss=62785.57239583333\n",
      "test_test\n",
      "test mean loss=87418.015625\n",
      "fin save.\n",
      "epoch 2273\n",
      "test_train\n",
      "train mean loss=63568.42473958333\n",
      "test_test\n",
      "test mean loss=87166.27734375\n",
      "fin save.\n",
      "epoch 2274\n",
      "test_train\n",
      "train mean loss=64041.898046875\n",
      "test_test\n",
      "test mean loss=87288.12109375\n",
      "fin save.\n",
      "epoch 2275\n",
      "test_train\n",
      "train mean loss=63186.108072916664\n",
      "test_test\n",
      "test mean loss=87335.83203125\n",
      "fin save.\n",
      "epoch 2276\n",
      "test_train\n",
      "train mean loss=63417.43151041667\n",
      "test_test\n",
      "test mean loss=87332.0390625\n",
      "fin save.\n",
      "epoch 2277\n",
      "test_train\n",
      "train mean loss=63027.887369791664\n",
      "test_test\n",
      "test mean loss=87248.14453125\n",
      "fin save.\n",
      "epoch 2278\n",
      "test_train\n",
      "train mean loss=63233.005598958334\n",
      "test_test\n",
      "test mean loss=87400.41015625\n",
      "fin save.\n",
      "epoch 2279\n",
      "test_train\n",
      "train mean loss=62529.594010416666\n",
      "test_test\n",
      "test mean loss=87281.36328125\n",
      "fin save.\n",
      "epoch 2280\n",
      "test_train\n",
      "train mean loss=63377.364583333336\n",
      "test_test\n",
      "test mean loss=87488.24609375\n",
      "fin save.\n",
      "epoch 2281\n",
      "test_train\n",
      "train mean loss=63205.718489583334\n",
      "test_test\n",
      "test mean loss=88272.015625\n",
      "fin save.\n",
      "epoch 2282\n",
      "test_train\n",
      "train mean loss=63397.59661458333\n",
      "test_test\n",
      "test mean loss=87990.5078125\n",
      "fin save.\n",
      "epoch 2283\n",
      "test_train\n",
      "train mean loss=62917.47734375\n",
      "test_test\n",
      "test mean loss=87854.59765625\n",
      "fin save.\n",
      "epoch 2284\n",
      "test_train\n",
      "train mean loss=62707.031510416666\n",
      "test_test\n",
      "test mean loss=87975.3984375\n",
      "fin save.\n",
      "epoch 2285\n",
      "test_train\n",
      "train mean loss=63162.326822916664\n",
      "test_test\n",
      "test mean loss=87648.8515625\n",
      "fin save.\n",
      "epoch 2286\n",
      "test_train\n",
      "train mean loss=62922.52630208333\n",
      "test_test\n",
      "test mean loss=87405.5703125\n",
      "fin save.\n",
      "epoch 2287\n",
      "test_train\n",
      "train mean loss=63473.041666666664\n",
      "test_test\n",
      "test mean loss=87340.8203125\n",
      "fin save.\n",
      "epoch 2288\n",
      "test_train\n",
      "train mean loss=62663.36484375\n",
      "test_test\n",
      "test mean loss=87286.16796875\n",
      "fin save.\n",
      "epoch 2289\n",
      "test_train\n",
      "train mean loss=63920.9765625\n",
      "test_test\n",
      "test mean loss=87380.35546875\n",
      "fin save.\n",
      "epoch 2290\n",
      "test_train\n",
      "train mean loss=62345.0640625\n",
      "test_test\n",
      "test mean loss=87453.4296875\n",
      "fin save.\n",
      "epoch 2291\n",
      "test_train\n",
      "train mean loss=63508.82083333333\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=87220.3203125\n",
      "fin save.\n",
      "epoch 2292\n",
      "test_train\n",
      "train mean loss=62765.61627604167\n",
      "test_test\n",
      "test mean loss=87639.7265625\n",
      "fin save.\n",
      "epoch 2293\n",
      "test_train\n",
      "train mean loss=62577.1296875\n",
      "test_test\n",
      "test mean loss=87898.58984375\n",
      "fin save.\n",
      "epoch 2294\n",
      "test_train\n",
      "train mean loss=63350.52734375\n",
      "test_test\n",
      "test mean loss=87615.65625\n",
      "fin save.\n",
      "epoch 2295\n",
      "test_train\n",
      "train mean loss=62799.79674479167\n",
      "test_test\n",
      "test mean loss=87652.59375\n",
      "fin save.\n",
      "epoch 2296\n",
      "test_train\n",
      "train mean loss=64091.50052083333\n",
      "test_test\n",
      "test mean loss=87658.265625\n",
      "fin save.\n",
      "epoch 2297\n",
      "test_train\n",
      "train mean loss=62967.93020833333\n",
      "test_test\n",
      "test mean loss=87162.62109375\n",
      "fin save.\n",
      "epoch 2298\n",
      "test_train\n",
      "train mean loss=64006.76328125\n",
      "test_test\n",
      "test mean loss=86950.3671875\n",
      "fin save.\n",
      "epoch 2299\n",
      "test_train\n",
      "train mean loss=62643.52916666667\n",
      "test_test\n",
      "test mean loss=87215.66796875\n",
      "fin save.\n",
      "epoch 2300\n",
      "test_train\n",
      "train mean loss=62965.05182291667\n",
      "test_test\n",
      "test mean loss=87087.7578125\n",
      "fin save.\n",
      "epoch 2301\n",
      "test_train\n",
      "train mean loss=63068.165625\n",
      "test_test\n",
      "test mean loss=87036.2734375\n",
      "fin save.\n",
      "epoch 2302\n",
      "test_train\n",
      "train mean loss=62847.75390625\n",
      "test_test\n",
      "test mean loss=87389.03125\n",
      "fin save.\n",
      "epoch 2303\n",
      "test_train\n",
      "train mean loss=61994.875260416666\n",
      "test_test\n",
      "test mean loss=87035.671875\n",
      "fin save.\n",
      "epoch 2304\n",
      "test_train\n",
      "train mean loss=62609.03671875\n",
      "test_test\n",
      "test mean loss=87502.62890625\n",
      "fin save.\n",
      "epoch 2305\n",
      "test_train\n",
      "train mean loss=63829.41197916667\n",
      "test_test\n",
      "test mean loss=87481.9140625\n",
      "fin save.\n",
      "epoch 2306\n",
      "test_train\n",
      "train mean loss=64299.18671875\n",
      "test_test\n",
      "test mean loss=87383.390625\n",
      "fin save.\n",
      "epoch 2307\n",
      "test_train\n",
      "train mean loss=63720.562760416666\n",
      "test_test\n",
      "test mean loss=87360.0078125\n",
      "fin save.\n",
      "epoch 2308\n",
      "test_train\n",
      "train mean loss=63420.09375\n",
      "test_test\n",
      "test mean loss=87191.1015625\n",
      "fin save.\n",
      "epoch 2309\n",
      "test_train\n",
      "train mean loss=62552.972395833334\n",
      "test_test\n",
      "test mean loss=87237.97265625\n",
      "fin save.\n",
      "epoch 2310\n",
      "test_train\n",
      "train mean loss=63153.419661458334\n",
      "test_test\n",
      "test mean loss=87301.99609375\n",
      "fin save.\n",
      "epoch 2311\n",
      "test_train\n",
      "train mean loss=62904.851822916666\n",
      "test_test\n",
      "test mean loss=87095.44140625\n",
      "fin save.\n",
      "epoch 2312\n",
      "test_train\n",
      "train mean loss=63510.52161458333\n",
      "test_test\n",
      "test mean loss=87070.08984375\n",
      "fin save.\n",
      "epoch 2313\n",
      "test_train\n",
      "train mean loss=64141.85338541667\n",
      "test_test\n",
      "test mean loss=87578.77734375\n",
      "fin save.\n",
      "epoch 2314\n",
      "test_train\n",
      "train mean loss=63747.408463541666\n",
      "test_test\n",
      "test mean loss=87670.9453125\n",
      "fin save.\n",
      "epoch 2315\n",
      "test_train\n",
      "train mean loss=63400.41640625\n",
      "test_test\n",
      "test mean loss=87487.6328125\n",
      "fin save.\n",
      "epoch 2316\n",
      "test_train\n",
      "train mean loss=63185.823958333334\n",
      "test_test\n",
      "test mean loss=87229.9375\n",
      "fin save.\n",
      "epoch 2317\n",
      "test_train\n",
      "train mean loss=63168.748697916664\n",
      "test_test\n",
      "test mean loss=87519.97265625\n",
      "fin save.\n",
      "epoch 2318\n",
      "test_train\n",
      "train mean loss=63513.374739583334\n",
      "test_test\n",
      "test mean loss=87533.19921875\n",
      "fin save.\n",
      "epoch 2319\n",
      "test_train\n",
      "train mean loss=63595.43151041667\n",
      "test_test\n",
      "test mean loss=87698.38671875\n",
      "fin save.\n",
      "epoch 2320\n",
      "test_train\n",
      "train mean loss=62953.48828125\n",
      "test_test\n",
      "test mean loss=87430.140625\n",
      "fin save.\n",
      "epoch 2321\n",
      "test_train\n",
      "train mean loss=63396.07044270833\n",
      "test_test\n",
      "test mean loss=87593.90234375\n",
      "fin save.\n",
      "epoch 2322\n",
      "test_train\n",
      "train mean loss=63403.8625\n",
      "test_test\n",
      "test mean loss=86953.18359375\n",
      "fin save.\n",
      "epoch 2323\n",
      "test_train\n",
      "train mean loss=62912.84557291667\n",
      "test_test\n",
      "test mean loss=87025.296875\n",
      "fin save.\n",
      "epoch 2324\n",
      "test_train\n",
      "train mean loss=62930.30703125\n",
      "test_test\n",
      "test mean loss=87045.11328125\n",
      "fin save.\n",
      "epoch 2325\n",
      "test_train\n",
      "train mean loss=63074.00338541667\n",
      "test_test\n",
      "test mean loss=86958.765625\n",
      "fin save.\n",
      "epoch 2326\n",
      "test_train\n",
      "train mean loss=63376.2296875\n",
      "test_test\n",
      "test mean loss=86932.96875\n",
      "fin save.\n",
      "epoch 2327\n",
      "test_train\n",
      "train mean loss=62785.412760416664\n",
      "test_test\n",
      "test mean loss=87072.46875\n",
      "fin save.\n",
      "epoch 2328\n",
      "test_train\n",
      "train mean loss=62489.527604166666\n",
      "test_test\n",
      "test mean loss=87028.7421875\n",
      "fin save.\n",
      "epoch 2329\n",
      "test_train\n",
      "train mean loss=62829.76966145833\n",
      "test_test\n",
      "test mean loss=87130.53125\n",
      "fin save.\n",
      "epoch 2330\n",
      "test_train\n",
      "train mean loss=63147.761458333334\n",
      "test_test\n",
      "test mean loss=87195.5234375\n",
      "fin save.\n",
      "epoch 2331\n",
      "test_train\n",
      "train mean loss=63483.04778645833\n",
      "test_test\n",
      "test mean loss=86953.49609375\n",
      "fin save.\n",
      "epoch 2332\n",
      "test_train\n",
      "train mean loss=62464.22421875\n",
      "test_test\n",
      "test mean loss=87107.328125\n",
      "fin save.\n",
      "epoch 2333\n",
      "test_train\n",
      "train mean loss=64608.86796875\n",
      "test_test\n",
      "test mean loss=87233.66796875\n",
      "fin save.\n",
      "epoch 2334\n",
      "test_train\n",
      "train mean loss=62522.22552083333\n",
      "test_test\n",
      "test mean loss=87318.29296875\n",
      "fin save.\n",
      "epoch 2335\n",
      "test_train\n",
      "train mean loss=62402.58450520833\n",
      "test_test\n",
      "test mean loss=87222.0\n",
      "fin save.\n",
      "epoch 2336\n",
      "test_train\n",
      "train mean loss=62265.9046875\n",
      "test_test\n",
      "test mean loss=87280.203125\n",
      "fin save.\n",
      "epoch 2337\n",
      "test_train\n",
      "train mean loss=62989.54244791667\n",
      "test_test\n",
      "test mean loss=87273.51171875\n",
      "fin save.\n",
      "epoch 2338\n",
      "test_train\n",
      "train mean loss=63006.28958333333\n",
      "test_test\n",
      "test mean loss=87153.578125\n",
      "fin save.\n",
      "epoch 2339\n",
      "test_train\n",
      "train mean loss=63915.85533854167\n",
      "test_test\n",
      "test mean loss=86957.10546875\n",
      "fin save.\n",
      "epoch 2340\n",
      "test_train\n",
      "train mean loss=64116.83125\n",
      "test_test\n",
      "test mean loss=87015.53125\n",
      "fin save.\n",
      "epoch 2341\n",
      "test_train\n",
      "train mean loss=63322.889322916664\n",
      "test_test\n",
      "test mean loss=87164.38671875\n",
      "fin save.\n",
      "epoch 2342\n",
      "test_train\n",
      "train mean loss=64079.63763020833\n",
      "test_test\n",
      "test mean loss=87430.25390625\n",
      "fin save.\n",
      "epoch 2343\n",
      "test_train\n",
      "train mean loss=63790.42630208333\n",
      "test_test\n",
      "test mean loss=86760.36328125\n",
      "fin save.\n",
      "epoch 2344\n",
      "test_train\n",
      "train mean loss=62850.208984375\n",
      "test_test\n",
      "test mean loss=87053.4453125\n",
      "fin save.\n",
      "epoch 2345\n",
      "test_train\n",
      "train mean loss=63364.847395833334\n",
      "test_test\n",
      "test mean loss=86993.16015625\n",
      "fin save.\n",
      "epoch 2346\n",
      "test_train\n",
      "train mean loss=62913.187890625\n",
      "test_test\n",
      "test mean loss=86878.7578125\n",
      "fin save.\n",
      "epoch 2347\n",
      "test_train\n",
      "train mean loss=62910.649739583336\n",
      "test_test\n",
      "test mean loss=86852.00390625\n",
      "fin save.\n",
      "epoch 2348\n",
      "test_train\n",
      "train mean loss=63218.55807291667\n",
      "test_test\n",
      "test mean loss=87002.2265625\n",
      "fin save.\n",
      "epoch 2349\n",
      "test_train\n",
      "train mean loss=64052.697005208334\n",
      "test_test\n",
      "test mean loss=86829.13671875\n",
      "fin save.\n",
      "epoch 2350\n",
      "test_train\n",
      "train mean loss=63630.590494791664\n",
      "test_test\n",
      "test mean loss=86986.85546875\n",
      "fin save.\n",
      "epoch 2351\n",
      "test_train\n",
      "train mean loss=63775.89153645833\n",
      "test_test\n",
      "test mean loss=86944.91015625\n",
      "fin save.\n",
      "epoch 2352\n",
      "test_train\n",
      "train mean loss=63357.02630208333\n",
      "test_test\n",
      "test mean loss=86937.90234375\n",
      "fin save.\n",
      "epoch 2353\n",
      "test_train\n",
      "train mean loss=64343.08828125\n",
      "test_test\n",
      "test mean loss=86853.1875\n",
      "fin save.\n",
      "epoch 2354\n",
      "test_train\n",
      "train mean loss=63417.110677083336\n",
      "test_test\n",
      "test mean loss=87027.8828125\n",
      "fin save.\n",
      "epoch 2355\n",
      "test_train\n",
      "train mean loss=63870.600260416664\n",
      "test_test\n",
      "test mean loss=87013.14453125\n",
      "fin save.\n",
      "epoch 2356\n",
      "test_train\n",
      "train mean loss=63721.58697916667\n",
      "test_test\n",
      "test mean loss=86960.34375\n",
      "fin save.\n",
      "epoch 2357\n",
      "test_train\n",
      "train mean loss=62355.82890625\n",
      "test_test\n",
      "test mean loss=86835.04296875\n",
      "fin save.\n",
      "epoch 2358\n",
      "test_train\n",
      "train mean loss=62417.139322916664\n",
      "test_test\n",
      "test mean loss=86866.60546875\n",
      "fin save.\n",
      "epoch 2359\n",
      "test_train\n",
      "train mean loss=63387.483203125\n",
      "test_test\n",
      "test mean loss=86849.09375\n",
      "fin save.\n",
      "epoch 2360\n",
      "test_train\n",
      "train mean loss=64046.037760416664\n",
      "test_test\n",
      "test mean loss=86881.9140625\n",
      "fin save.\n",
      "epoch 2361\n",
      "test_train\n",
      "train mean loss=63005.468489583334\n",
      "test_test\n",
      "test mean loss=86944.26171875\n",
      "fin save.\n",
      "epoch 2362\n",
      "test_train\n",
      "train mean loss=64275.823046875\n",
      "test_test\n",
      "test mean loss=87113.73046875\n",
      "fin save.\n",
      "epoch 2363\n",
      "test_train\n",
      "train mean loss=63454.5203125\n",
      "test_test\n",
      "test mean loss=87174.6171875\n",
      "fin save.\n",
      "epoch 2364\n",
      "test_train\n",
      "train mean loss=63536.8984375\n",
      "test_test\n",
      "test mean loss=87991.62890625\n",
      "fin save.\n",
      "epoch 2365\n",
      "test_train\n",
      "train mean loss=63167.43216145833\n",
      "test_test\n",
      "test mean loss=87766.67578125\n",
      "fin save.\n",
      "epoch 2366\n",
      "test_train\n",
      "train mean loss=63578.34765625\n",
      "test_test\n",
      "test mean loss=88022.99609375\n",
      "fin save.\n",
      "epoch 2367\n",
      "test_train\n",
      "train mean loss=62718.6765625\n",
      "test_test\n",
      "test mean loss=87949.10546875\n",
      "fin save.\n",
      "epoch 2368\n",
      "test_train\n",
      "train mean loss=63301.79479166667\n",
      "test_test\n",
      "test mean loss=87925.61328125\n",
      "fin save.\n",
      "epoch 2369\n",
      "test_train\n",
      "train mean loss=62906.53723958333\n",
      "test_test\n",
      "test mean loss=88495.55859375\n",
      "fin save.\n",
      "epoch 2370\n",
      "test_train\n",
      "train mean loss=64136.674088541666\n",
      "test_test\n",
      "test mean loss=88271.69140625\n",
      "fin save.\n",
      "epoch 2371\n",
      "test_train\n",
      "train mean loss=64439.09322916667\n",
      "test_test\n",
      "test mean loss=88160.9453125\n",
      "fin save.\n",
      "epoch 2372\n",
      "test_train\n",
      "train mean loss=63202.479166666664\n",
      "test_test\n",
      "test mean loss=87649.33203125\n",
      "fin save.\n",
      "epoch 2373\n",
      "test_train\n",
      "train mean loss=63015.274739583336\n",
      "test_test\n",
      "test mean loss=87592.02734375\n",
      "fin save.\n",
      "epoch 2374\n",
      "test_train\n",
      "train mean loss=63226.64947916667\n",
      "test_test\n",
      "test mean loss=87513.0859375\n",
      "fin save.\n",
      "epoch 2375\n",
      "test_train\n",
      "train mean loss=62398.42786458333\n",
      "test_test\n",
      "test mean loss=87690.73828125\n",
      "fin save.\n",
      "epoch 2376\n",
      "test_train\n",
      "train mean loss=62770.20169270833\n",
      "test_test\n",
      "test mean loss=87546.8671875\n",
      "fin save.\n",
      "epoch 2377\n",
      "test_train\n",
      "train mean loss=62582.910807291664\n",
      "test_test\n",
      "test mean loss=87368.90625\n",
      "fin save.\n",
      "epoch 2378\n",
      "test_train\n",
      "train mean loss=63686.43359375\n",
      "test_test\n",
      "test mean loss=87434.81640625\n",
      "fin save.\n",
      "epoch 2379\n",
      "test_train\n",
      "train mean loss=63329.965494791664\n",
      "test_test\n",
      "test mean loss=87438.73046875\n",
      "fin save.\n",
      "epoch 2380\n",
      "test_train\n",
      "train mean loss=62603.828125\n",
      "test_test\n",
      "test mean loss=87631.55078125\n",
      "fin save.\n",
      "epoch 2381\n",
      "test_train\n",
      "train mean loss=63178.994791666664\n",
      "test_test\n",
      "test mean loss=87580.71875\n",
      "fin save.\n",
      "epoch 2382\n",
      "test_train\n",
      "train mean loss=63416.297135416666\n",
      "test_test\n",
      "test mean loss=87721.58984375\n",
      "fin save.\n",
      "epoch 2383\n",
      "test_train\n",
      "train mean loss=63191.278645833336\n",
      "test_test\n",
      "test mean loss=87590.15234375\n",
      "fin save.\n",
      "epoch 2384\n",
      "test_train\n",
      "train mean loss=62818.268229166664\n",
      "test_test\n",
      "test mean loss=87570.09765625\n",
      "fin save.\n",
      "epoch 2385\n",
      "test_train\n",
      "train mean loss=62389.726822916666\n",
      "test_test\n",
      "test mean loss=87538.421875\n",
      "fin save.\n",
      "epoch 2386\n",
      "test_train\n",
      "train mean loss=63705.677083333336\n",
      "test_test\n",
      "test mean loss=87768.58203125\n",
      "fin save.\n",
      "epoch 2387\n",
      "test_train\n",
      "train mean loss=62592.11770833333\n",
      "test_test\n",
      "test mean loss=87670.78515625\n",
      "fin save.\n",
      "epoch 2388\n",
      "test_train\n",
      "train mean loss=63585.932291666664\n",
      "test_test\n",
      "test mean loss=87682.36328125\n",
      "fin save.\n",
      "epoch 2389\n",
      "test_train\n",
      "train mean loss=63386.19348958333\n",
      "test_test\n",
      "test mean loss=87626.26171875\n",
      "fin save.\n",
      "epoch 2390\n",
      "test_train\n",
      "train mean loss=63219.209375\n",
      "test_test\n",
      "test mean loss=87600.4453125\n",
      "fin save.\n",
      "epoch 2391\n",
      "test_train\n",
      "train mean loss=63550.74505208333\n",
      "test_test\n",
      "test mean loss=87843.0625\n",
      "fin save.\n",
      "epoch 2392\n",
      "test_train\n",
      "train mean loss=63568.53216145833\n",
      "test_test\n",
      "test mean loss=87784.55859375\n",
      "fin save.\n",
      "epoch 2393\n",
      "test_train\n",
      "train mean loss=62901.52591145833\n",
      "test_test\n",
      "test mean loss=87947.17578125\n",
      "fin save.\n",
      "epoch 2394\n",
      "test_train\n",
      "train mean loss=63141.98046875\n",
      "test_test\n",
      "test mean loss=87095.66015625\n",
      "fin save.\n",
      "epoch 2395\n",
      "test_train\n",
      "train mean loss=62641.22734375\n",
      "test_test\n",
      "test mean loss=86983.50390625\n",
      "fin save.\n",
      "epoch 2396\n",
      "test_train\n",
      "train mean loss=62991.88489583333\n",
      "test_test\n",
      "test mean loss=87030.95703125\n",
      "fin save.\n",
      "epoch 2397\n",
      "test_train\n",
      "train mean loss=63750.74817708333\n",
      "test_test\n",
      "test mean loss=87169.3828125\n",
      "fin save.\n",
      "epoch 2398\n",
      "test_train\n",
      "train mean loss=63198.61276041667\n",
      "test_test\n",
      "test mean loss=86990.66796875\n",
      "fin save.\n",
      "epoch 2399\n",
      "test_train\n",
      "train mean loss=63862.965234375\n",
      "test_test\n",
      "test mean loss=87112.87890625\n",
      "fin save.\n",
      "epoch 2400\n",
      "test_train\n",
      "train mean loss=63326.27421875\n",
      "test_test\n",
      "test mean loss=87258.04296875\n",
      "fin save.\n",
      "epoch 2401\n",
      "test_train\n",
      "train mean loss=62895.52421875\n",
      "test_test\n",
      "test mean loss=87051.36328125\n",
      "fin save.\n",
      "epoch 2402\n",
      "test_train\n",
      "train mean loss=62863.606770833336\n",
      "test_test\n",
      "test mean loss=87221.78125\n",
      "fin save.\n",
      "epoch 2403\n",
      "test_train\n",
      "train mean loss=62951.768229166664\n",
      "test_test\n",
      "test mean loss=87293.24609375\n",
      "fin save.\n",
      "epoch 2404\n",
      "test_train\n",
      "train mean loss=62193.319921875\n",
      "test_test\n",
      "test mean loss=87320.328125\n",
      "fin save.\n",
      "epoch 2405\n",
      "test_train\n",
      "train mean loss=63025.20885416667\n",
      "test_test\n",
      "test mean loss=86821.1484375\n",
      "fin save.\n",
      "epoch 2406\n",
      "test_train\n",
      "train mean loss=64357.61276041667\n",
      "test_test\n",
      "test mean loss=86894.08203125\n",
      "fin save.\n",
      "epoch 2407\n",
      "test_train\n",
      "train mean loss=62124.70364583333\n",
      "test_test\n",
      "test mean loss=86767.94140625\n",
      "fin save.\n",
      "epoch 2408\n",
      "test_train\n",
      "train mean loss=62338.58515625\n",
      "test_test\n",
      "test mean loss=87127.390625\n",
      "fin save.\n",
      "epoch 2409\n",
      "test_train\n",
      "train mean loss=63379.18671875\n",
      "test_test\n",
      "test mean loss=86786.20703125\n",
      "fin save.\n",
      "epoch 2410\n",
      "test_train\n",
      "train mean loss=62951.801432291664\n",
      "test_test\n",
      "test mean loss=87302.9453125\n",
      "fin save.\n",
      "epoch 2411\n",
      "test_train\n",
      "train mean loss=63054.303385416664\n",
      "test_test\n",
      "test mean loss=87181.65625\n",
      "fin save.\n",
      "epoch 2412\n",
      "test_train\n",
      "train mean loss=63028.31744791667\n",
      "test_test\n",
      "test mean loss=87073.109375\n",
      "fin save.\n",
      "epoch 2413\n",
      "test_train\n",
      "train mean loss=62895.25494791667\n",
      "test_test\n",
      "test mean loss=86857.40625\n",
      "fin save.\n",
      "epoch 2414\n",
      "test_train\n",
      "train mean loss=62900.608203125\n",
      "test_test\n",
      "test mean loss=86944.7734375\n",
      "fin save.\n",
      "epoch 2415\n",
      "test_train\n",
      "train mean loss=62749.312239583334\n",
      "test_test\n",
      "test mean loss=87028.67578125\n",
      "fin save.\n",
      "epoch 2416\n",
      "test_train\n",
      "train mean loss=63782.859635416666\n",
      "test_test\n",
      "test mean loss=86831.87890625\n",
      "fin save.\n",
      "epoch 2417\n",
      "test_train\n",
      "train mean loss=62593.46875\n",
      "test_test\n",
      "test mean loss=86925.94140625\n",
      "fin save.\n",
      "epoch 2418\n",
      "test_train\n",
      "train mean loss=63782.597005208336\n",
      "test_test\n",
      "test mean loss=86858.625\n",
      "fin save.\n",
      "epoch 2419\n",
      "test_train\n",
      "train mean loss=63195.8859375\n",
      "test_test\n",
      "test mean loss=86715.04296875\n",
      "fin save.\n",
      "epoch 2420\n",
      "test_train\n",
      "train mean loss=63161.017578125\n",
      "test_test\n",
      "test mean loss=86788.66015625\n",
      "fin save.\n",
      "epoch 2421\n",
      "test_train\n",
      "train mean loss=62985.90729166667\n",
      "test_test\n",
      "test mean loss=86639.6171875\n",
      "fin save.\n",
      "epoch 2422\n",
      "test_train\n",
      "train mean loss=62580.86484375\n",
      "test_test\n",
      "test mean loss=86685.46484375\n",
      "fin save.\n",
      "epoch 2423\n",
      "test_train\n",
      "train mean loss=63202.61028645833\n",
      "test_test\n",
      "test mean loss=86748.01171875\n",
      "fin save.\n",
      "epoch 2424\n",
      "test_train\n",
      "train mean loss=62960.1046875\n",
      "test_test\n",
      "test mean loss=86650.42578125\n",
      "fin save.\n",
      "epoch 2425\n",
      "test_train\n",
      "train mean loss=61867.342447916664\n",
      "test_test\n",
      "test mean loss=86715.265625\n",
      "fin save.\n",
      "epoch 2426\n",
      "test_train\n",
      "train mean loss=63482.155989583334\n",
      "test_test\n",
      "test mean loss=86692.4921875\n",
      "fin save.\n",
      "epoch 2427\n",
      "test_train\n",
      "train mean loss=63868.42734375\n",
      "test_test\n",
      "test mean loss=86910.90234375\n",
      "fin save.\n",
      "epoch 2428\n",
      "test_train\n",
      "train mean loss=61886.68177083333\n",
      "test_test\n",
      "test mean loss=86934.3515625\n",
      "fin save.\n",
      "epoch 2429\n",
      "test_train\n",
      "train mean loss=63060.05911458333\n",
      "test_test\n",
      "test mean loss=86793.765625\n",
      "fin save.\n",
      "epoch 2430\n",
      "test_train\n",
      "train mean loss=62679.43463541667\n",
      "test_test\n",
      "test mean loss=86936.51171875\n",
      "fin save.\n",
      "epoch 2431\n",
      "test_train\n",
      "train mean loss=62790.53046875\n",
      "test_test\n",
      "test mean loss=86769.07421875\n",
      "fin save.\n",
      "epoch 2432\n",
      "test_train\n",
      "train mean loss=63044.765234375\n",
      "test_test\n",
      "test mean loss=86839.21875\n",
      "fin save.\n",
      "epoch 2433\n",
      "test_train\n",
      "train mean loss=62987.33802083333\n",
      "test_test\n",
      "test mean loss=86864.625\n",
      "fin save.\n",
      "epoch 2434\n",
      "test_train\n",
      "train mean loss=63292.969401041664\n",
      "test_test\n",
      "test mean loss=86610.8125\n",
      "fin save.\n",
      "epoch 2435\n",
      "test_train\n",
      "train mean loss=63214.38658854167\n",
      "test_test\n",
      "test mean loss=86797.1484375\n",
      "fin save.\n",
      "epoch 2436\n",
      "test_train\n",
      "train mean loss=63239.25208333333\n",
      "test_test\n",
      "test mean loss=87106.96484375\n",
      "fin save.\n",
      "epoch 2437\n",
      "test_train\n",
      "train mean loss=62851.120833333334\n",
      "test_test\n",
      "test mean loss=87231.9453125\n",
      "fin save.\n",
      "epoch 2438\n",
      "test_train\n",
      "train mean loss=63151.0515625\n",
      "test_test\n",
      "test mean loss=87381.40625\n",
      "fin save.\n",
      "epoch 2439\n",
      "test_train\n",
      "train mean loss=63175.9546875\n",
      "test_test\n",
      "test mean loss=87142.23046875\n",
      "fin save.\n",
      "epoch 2440\n",
      "test_train\n",
      "train mean loss=64044.82369791667\n",
      "test_test\n",
      "test mean loss=87334.1484375\n",
      "fin save.\n",
      "epoch 2441\n",
      "test_train\n",
      "train mean loss=63179.88072916667\n",
      "test_test\n",
      "test mean loss=87183.3828125\n",
      "fin save.\n",
      "epoch 2442\n",
      "test_train\n",
      "train mean loss=62995.55026041667\n",
      "test_test\n",
      "test mean loss=87167.87109375\n",
      "fin save.\n",
      "epoch 2443\n",
      "test_train\n",
      "train mean loss=63044.096354166664\n",
      "test_test\n",
      "test mean loss=87201.49609375\n",
      "fin save.\n",
      "epoch 2444\n",
      "test_train\n",
      "train mean loss=62672.52734375\n",
      "test_test\n",
      "test mean loss=87705.40625\n",
      "fin save.\n",
      "epoch 2445\n",
      "test_train\n",
      "train mean loss=63104.52734375\n",
      "test_test\n",
      "test mean loss=87671.09375\n",
      "fin save.\n",
      "epoch 2446\n",
      "test_train\n",
      "train mean loss=63257.708723958334\n",
      "test_test\n",
      "test mean loss=87728.64453125\n",
      "fin save.\n",
      "epoch 2447\n",
      "test_train\n",
      "train mean loss=62701.22083333333\n",
      "test_test\n",
      "test mean loss=87839.25390625\n",
      "fin save.\n",
      "epoch 2448\n",
      "test_train\n",
      "train mean loss=63228.21822916667\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=87589.359375\n",
      "fin save.\n",
      "epoch 2449\n",
      "test_train\n",
      "train mean loss=63090.44049479167\n",
      "test_test\n",
      "test mean loss=87748.94921875\n",
      "fin save.\n",
      "epoch 2450\n",
      "test_train\n",
      "train mean loss=62535.15026041667\n",
      "test_test\n",
      "test mean loss=87673.7578125\n",
      "fin save.\n",
      "epoch 2451\n",
      "test_train\n",
      "train mean loss=63490.531901041664\n",
      "test_test\n",
      "test mean loss=87922.9296875\n",
      "fin save.\n",
      "epoch 2452\n",
      "test_train\n",
      "train mean loss=62605.85625\n",
      "test_test\n",
      "test mean loss=87904.125\n",
      "fin save.\n",
      "epoch 2453\n",
      "test_train\n",
      "train mean loss=63116.11822916667\n",
      "test_test\n",
      "test mean loss=87780.9921875\n",
      "fin save.\n",
      "epoch 2454\n",
      "test_train\n",
      "train mean loss=63434.195052083334\n",
      "test_test\n",
      "test mean loss=88587.5703125\n",
      "fin save.\n",
      "epoch 2455\n",
      "test_train\n",
      "train mean loss=63004.769270833334\n",
      "test_test\n",
      "test mean loss=88357.29296875\n",
      "fin save.\n",
      "epoch 2456\n",
      "test_train\n",
      "train mean loss=62240.19140625\n",
      "test_test\n",
      "test mean loss=88430.24609375\n",
      "fin save.\n",
      "epoch 2457\n",
      "test_train\n",
      "train mean loss=62764.168229166666\n",
      "test_test\n",
      "test mean loss=88486.61328125\n",
      "fin save.\n",
      "epoch 2458\n",
      "test_train\n",
      "train mean loss=63072.65963541667\n",
      "test_test\n",
      "test mean loss=88327.36328125\n",
      "fin save.\n",
      "epoch 2459\n",
      "test_train\n",
      "train mean loss=63051.6734375\n",
      "test_test\n",
      "test mean loss=88391.57421875\n",
      "fin save.\n",
      "epoch 2460\n",
      "test_train\n",
      "train mean loss=63458.88515625\n",
      "test_test\n",
      "test mean loss=88066.3359375\n",
      "fin save.\n",
      "epoch 2461\n",
      "test_train\n",
      "train mean loss=63362.85755208333\n",
      "test_test\n",
      "test mean loss=88325.40234375\n",
      "fin save.\n",
      "epoch 2462\n",
      "test_train\n",
      "train mean loss=62692.319010416664\n",
      "test_test\n",
      "test mean loss=88093.2421875\n",
      "fin save.\n",
      "epoch 2463\n",
      "test_train\n",
      "train mean loss=62573.81432291667\n",
      "test_test\n",
      "test mean loss=88344.28125\n",
      "fin save.\n",
      "epoch 2464\n",
      "test_train\n",
      "train mean loss=62345.83411458333\n",
      "test_test\n",
      "test mean loss=88759.26953125\n",
      "fin save.\n",
      "epoch 2465\n",
      "test_train\n",
      "train mean loss=63054.62421875\n",
      "test_test\n",
      "test mean loss=88366.17578125\n",
      "fin save.\n",
      "epoch 2466\n",
      "test_train\n",
      "train mean loss=62537.82408854167\n",
      "test_test\n",
      "test mean loss=88378.5234375\n",
      "fin save.\n",
      "epoch 2467\n",
      "test_train\n",
      "train mean loss=61600.073958333334\n",
      "test_test\n",
      "test mean loss=88397.48828125\n",
      "fin save.\n",
      "epoch 2468\n",
      "test_train\n",
      "train mean loss=63262.91588541667\n",
      "test_test\n",
      "test mean loss=88484.03515625\n",
      "fin save.\n",
      "epoch 2469\n",
      "test_train\n",
      "train mean loss=62803.57890625\n",
      "test_test\n",
      "test mean loss=88414.16796875\n",
      "fin save.\n",
      "epoch 2470\n",
      "test_train\n",
      "train mean loss=62789.43515625\n",
      "test_test\n",
      "test mean loss=88395.078125\n",
      "fin save.\n",
      "epoch 2471\n",
      "test_train\n",
      "train mean loss=61883.51015625\n",
      "test_test\n",
      "test mean loss=88398.99609375\n",
      "fin save.\n",
      "epoch 2472\n",
      "test_train\n",
      "train mean loss=62486.77682291667\n",
      "test_test\n",
      "test mean loss=88418.79296875\n",
      "fin save.\n",
      "epoch 2473\n",
      "test_train\n",
      "train mean loss=63188.0375\n",
      "test_test\n",
      "test mean loss=88405.14453125\n",
      "fin save.\n",
      "epoch 2474\n",
      "test_train\n",
      "train mean loss=63581.01549479167\n",
      "test_test\n",
      "test mean loss=88314.81640625\n",
      "fin save.\n",
      "epoch 2475\n",
      "test_train\n",
      "train mean loss=62931.83307291667\n",
      "test_test\n",
      "test mean loss=88498.875\n",
      "fin save.\n",
      "epoch 2476\n",
      "test_train\n",
      "train mean loss=63364.597395833334\n",
      "test_test\n",
      "test mean loss=88324.81640625\n",
      "fin save.\n",
      "epoch 2477\n",
      "test_train\n",
      "train mean loss=62508.93802083333\n",
      "test_test\n",
      "test mean loss=88491.66796875\n",
      "fin save.\n",
      "epoch 2478\n",
      "test_train\n",
      "train mean loss=63582.83515625\n",
      "test_test\n",
      "test mean loss=88591.2734375\n",
      "fin save.\n",
      "epoch 2479\n",
      "test_train\n",
      "train mean loss=62775.966145833336\n",
      "test_test\n",
      "test mean loss=88508.75\n",
      "fin save.\n",
      "epoch 2480\n",
      "test_train\n",
      "train mean loss=63382.128125\n",
      "test_test\n",
      "test mean loss=88463.46484375\n",
      "fin save.\n",
      "epoch 2481\n",
      "test_train\n",
      "train mean loss=63926.769791666666\n",
      "test_test\n",
      "test mean loss=88572.609375\n",
      "fin save.\n",
      "epoch 2482\n",
      "test_train\n",
      "train mean loss=62789.51171875\n",
      "test_test\n",
      "test mean loss=88263.84375\n",
      "fin save.\n",
      "epoch 2483\n",
      "test_train\n",
      "train mean loss=62835.175390625\n",
      "test_test\n",
      "test mean loss=88429.50390625\n",
      "fin save.\n",
      "epoch 2484\n",
      "test_train\n",
      "train mean loss=63258.126302083336\n",
      "test_test\n",
      "test mean loss=88230.69140625\n",
      "fin save.\n",
      "epoch 2485\n",
      "test_train\n",
      "train mean loss=63196.61276041667\n",
      "test_test\n",
      "test mean loss=88159.22265625\n",
      "fin save.\n",
      "epoch 2486\n",
      "test_train\n",
      "train mean loss=63478.09283854167\n",
      "test_test\n",
      "test mean loss=88226.5390625\n",
      "fin save.\n",
      "epoch 2487\n",
      "test_train\n",
      "train mean loss=63044.683333333334\n",
      "test_test\n",
      "test mean loss=88584.546875\n",
      "fin save.\n",
      "epoch 2488\n",
      "test_train\n",
      "train mean loss=63732.950520833336\n",
      "test_test\n",
      "test mean loss=88532.6796875\n",
      "fin save.\n",
      "epoch 2489\n",
      "test_train\n",
      "train mean loss=62860.11223958333\n",
      "test_test\n",
      "test mean loss=88544.8984375\n",
      "fin save.\n",
      "epoch 2490\n",
      "test_train\n",
      "train mean loss=62955.36822916667\n",
      "test_test\n",
      "test mean loss=88446.09375\n",
      "fin save.\n",
      "epoch 2491\n",
      "test_train\n",
      "train mean loss=62134.96276041667\n",
      "test_test\n",
      "test mean loss=87848.83203125\n",
      "fin save.\n",
      "epoch 2492\n",
      "test_train\n",
      "train mean loss=62950.9296875\n",
      "test_test\n",
      "test mean loss=87891.15234375\n",
      "fin save.\n",
      "epoch 2493\n",
      "test_train\n",
      "train mean loss=63541.44192708333\n",
      "test_test\n",
      "test mean loss=87922.91796875\n",
      "fin save.\n",
      "epoch 2494\n",
      "test_train\n",
      "train mean loss=63003.81692708333\n",
      "test_test\n",
      "test mean loss=87823.26953125\n",
      "fin save.\n",
      "epoch 2495\n",
      "test_train\n",
      "train mean loss=62100.37447916667\n",
      "test_test\n",
      "test mean loss=87938.7265625\n",
      "fin save.\n",
      "epoch 2496\n",
      "test_train\n",
      "train mean loss=62507.058984375\n",
      "test_test\n",
      "test mean loss=87944.171875\n",
      "fin save.\n",
      "epoch 2497\n",
      "test_train\n",
      "train mean loss=63364.5453125\n",
      "test_test\n",
      "test mean loss=87779.79296875\n",
      "fin save.\n",
      "epoch 2498\n",
      "test_train\n",
      "train mean loss=63537.985677083336\n",
      "test_test\n",
      "test mean loss=87878.11328125\n",
      "fin save.\n",
      "epoch 2499\n",
      "test_train\n",
      "train mean loss=63439.38177083333\n",
      "test_test\n",
      "test mean loss=87919.46484375\n",
      "fin save.\n",
      "epoch 2500\n",
      "test_train\n",
      "train mean loss=62498.2109375\n",
      "test_test\n",
      "test mean loss=87930.72265625\n",
      "fin save.\n",
      "epoch 2501\n",
      "test_train\n",
      "train mean loss=62776.032552083336\n",
      "test_test\n",
      "test mean loss=87883.6953125\n",
      "fin save.\n",
      "epoch 2502\n",
      "test_train\n",
      "train mean loss=62818.395833333336\n",
      "test_test\n",
      "test mean loss=88098.828125\n",
      "fin save.\n",
      "epoch 2503\n",
      "test_train\n",
      "train mean loss=61751.73450520833\n",
      "test_test\n",
      "test mean loss=87989.890625\n",
      "fin save.\n",
      "epoch 2504\n",
      "test_train\n",
      "train mean loss=63184.064192708334\n",
      "test_test\n",
      "test mean loss=88087.69140625\n",
      "fin save.\n",
      "epoch 2505\n",
      "test_train\n",
      "train mean loss=62263.228125\n",
      "test_test\n",
      "test mean loss=88031.05859375\n",
      "fin save.\n",
      "epoch 2506\n",
      "test_train\n",
      "train mean loss=62600.055989583336\n",
      "test_test\n",
      "test mean loss=87930.20703125\n",
      "fin save.\n",
      "epoch 2507\n",
      "test_train\n",
      "train mean loss=63330.27578125\n",
      "test_test\n",
      "test mean loss=87834.05859375\n",
      "fin save.\n",
      "epoch 2508\n",
      "test_train\n",
      "train mean loss=63072.498697916664\n",
      "test_test\n",
      "test mean loss=87942.22265625\n",
      "fin save.\n",
      "epoch 2509\n",
      "test_train\n",
      "train mean loss=63149.05078125\n",
      "test_test\n",
      "test mean loss=87935.1953125\n",
      "fin save.\n",
      "epoch 2510\n",
      "test_train\n",
      "train mean loss=63013.672135416666\n",
      "test_test\n",
      "test mean loss=88116.21875\n",
      "fin save.\n",
      "epoch 2511\n",
      "test_train\n",
      "train mean loss=62397.03997395833\n",
      "test_test\n",
      "test mean loss=87888.3515625\n",
      "fin save.\n",
      "epoch 2512\n",
      "test_train\n",
      "train mean loss=63471.589453125\n",
      "test_test\n",
      "test mean loss=88001.58984375\n",
      "fin save.\n",
      "epoch 2513\n",
      "test_train\n",
      "train mean loss=61938.226822916666\n",
      "test_test\n",
      "test mean loss=88163.59765625\n",
      "fin save.\n",
      "epoch 2514\n",
      "test_train\n",
      "train mean loss=62214.03177083333\n",
      "test_test\n",
      "test mean loss=88049.63671875\n",
      "fin save.\n",
      "epoch 2515\n",
      "test_train\n",
      "train mean loss=63154.483723958336\n",
      "test_test\n",
      "test mean loss=88069.28515625\n",
      "fin save.\n",
      "epoch 2516\n",
      "test_train\n",
      "train mean loss=63009.3046875\n",
      "test_test\n",
      "test mean loss=87968.33984375\n",
      "fin save.\n",
      "epoch 2517\n",
      "test_train\n",
      "train mean loss=62720.331770833334\n",
      "test_test\n",
      "test mean loss=88133.23828125\n",
      "fin save.\n",
      "epoch 2518\n",
      "test_train\n",
      "train mean loss=62985.20911458333\n",
      "test_test\n",
      "test mean loss=88100.58984375\n",
      "fin save.\n",
      "epoch 2519\n",
      "test_train\n",
      "train mean loss=63039.88463541667\n",
      "test_test\n",
      "test mean loss=88197.046875\n",
      "fin save.\n",
      "epoch 2520\n",
      "test_train\n",
      "train mean loss=62374.475\n",
      "test_test\n",
      "test mean loss=88073.890625\n",
      "fin save.\n",
      "epoch 2521\n",
      "test_train\n",
      "train mean loss=62877.93984375\n",
      "test_test\n",
      "test mean loss=88099.42578125\n",
      "fin save.\n",
      "epoch 2522\n",
      "test_train\n",
      "train mean loss=62801.101302083334\n",
      "test_test\n",
      "test mean loss=88012.71875\n",
      "fin save.\n",
      "epoch 2523\n",
      "test_train\n",
      "train mean loss=62524.096875\n",
      "test_test\n",
      "test mean loss=88023.7890625\n",
      "fin save.\n",
      "epoch 2524\n",
      "test_train\n",
      "train mean loss=62896.701432291666\n",
      "test_test\n",
      "test mean loss=88142.01171875\n",
      "fin save.\n",
      "epoch 2525\n",
      "test_train\n",
      "train mean loss=62657.095442708334\n",
      "test_test\n",
      "test mean loss=88221.640625\n",
      "fin save.\n",
      "epoch 2526\n",
      "test_train\n",
      "train mean loss=62563.73489583333\n",
      "test_test\n",
      "test mean loss=88203.08203125\n",
      "fin save.\n",
      "epoch 2527\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=62579.40182291667\n",
      "test_test\n",
      "test mean loss=88122.78515625\n",
      "fin save.\n",
      "epoch 2528\n",
      "test_train\n",
      "train mean loss=63344.796614583334\n",
      "test_test\n",
      "test mean loss=88203.0703125\n",
      "fin save.\n",
      "epoch 2529\n",
      "test_train\n",
      "train mean loss=63710.822916666664\n",
      "test_test\n",
      "test mean loss=88363.38671875\n",
      "fin save.\n",
      "epoch 2530\n",
      "test_train\n",
      "train mean loss=62766.53411458333\n",
      "test_test\n",
      "test mean loss=88954.53125\n",
      "fin save.\n",
      "epoch 2531\n",
      "test_train\n",
      "train mean loss=63808.1921875\n",
      "test_test\n",
      "test mean loss=89056.7734375\n",
      "fin save.\n",
      "epoch 2532\n",
      "test_train\n",
      "train mean loss=63735.698958333334\n",
      "test_test\n",
      "test mean loss=88904.296875\n",
      "fin save.\n",
      "epoch 2533\n",
      "test_train\n",
      "train mean loss=62486.176041666666\n",
      "test_test\n",
      "test mean loss=88850.9921875\n",
      "fin save.\n",
      "epoch 2534\n",
      "test_train\n",
      "train mean loss=63555.975\n",
      "test_test\n",
      "test mean loss=88882.12109375\n",
      "fin save.\n",
      "epoch 2535\n",
      "test_train\n",
      "train mean loss=62288.26171875\n",
      "test_test\n",
      "test mean loss=88890.6953125\n",
      "fin save.\n",
      "epoch 2536\n",
      "test_train\n",
      "train mean loss=62165.853125\n",
      "test_test\n",
      "test mean loss=89164.09765625\n",
      "fin save.\n",
      "epoch 2537\n",
      "test_train\n",
      "train mean loss=62501.36484375\n",
      "test_test\n",
      "test mean loss=89009.33203125\n",
      "fin save.\n",
      "epoch 2538\n",
      "test_train\n",
      "train mean loss=63075.264322916664\n",
      "test_test\n",
      "test mean loss=89139.92578125\n",
      "fin save.\n",
      "epoch 2539\n",
      "test_train\n",
      "train mean loss=62366.805078125\n",
      "test_test\n",
      "test mean loss=89343.6796875\n",
      "fin save.\n",
      "epoch 2540\n",
      "test_train\n",
      "train mean loss=62677.79348958333\n",
      "test_test\n",
      "test mean loss=89312.53125\n",
      "fin save.\n",
      "epoch 2541\n",
      "test_train\n",
      "train mean loss=62225.52447916667\n",
      "test_test\n",
      "test mean loss=89322.05859375\n",
      "fin save.\n",
      "epoch 2542\n",
      "test_train\n",
      "train mean loss=63295.326171875\n",
      "test_test\n",
      "test mean loss=89411.7265625\n",
      "fin save.\n",
      "epoch 2543\n",
      "test_train\n",
      "train mean loss=62120.8828125\n",
      "test_test\n",
      "test mean loss=89193.6875\n",
      "fin save.\n",
      "epoch 2544\n",
      "test_train\n",
      "train mean loss=62569.0859375\n",
      "test_test\n",
      "test mean loss=89135.03125\n",
      "fin save.\n",
      "epoch 2545\n",
      "test_train\n",
      "train mean loss=63052.098958333336\n",
      "test_test\n",
      "test mean loss=89054.18359375\n",
      "fin save.\n",
      "epoch 2546\n",
      "test_train\n",
      "train mean loss=62547.85690104167\n",
      "test_test\n",
      "test mean loss=89066.53515625\n",
      "fin save.\n",
      "epoch 2547\n",
      "test_train\n",
      "train mean loss=63209.621744791664\n",
      "test_test\n",
      "test mean loss=89110.21484375\n",
      "fin save.\n",
      "epoch 2548\n",
      "test_train\n",
      "train mean loss=62764.5078125\n",
      "test_test\n",
      "test mean loss=89152.8125\n",
      "fin save.\n",
      "epoch 2549\n",
      "test_train\n",
      "train mean loss=63035.68463541667\n",
      "test_test\n",
      "test mean loss=89130.1328125\n",
      "fin save.\n",
      "epoch 2550\n",
      "test_train\n",
      "train mean loss=63094.902083333334\n",
      "test_test\n",
      "test mean loss=89387.62890625\n",
      "fin save.\n",
      "epoch 2551\n",
      "test_train\n",
      "train mean loss=63310.81236979167\n",
      "test_test\n",
      "test mean loss=89325.265625\n",
      "fin save.\n",
      "epoch 2552\n",
      "test_train\n",
      "train mean loss=62811.66588541667\n",
      "test_test\n",
      "test mean loss=89247.3359375\n",
      "fin save.\n",
      "epoch 2553\n",
      "test_train\n",
      "train mean loss=63187.770833333336\n",
      "test_test\n",
      "test mean loss=89116.6953125\n",
      "fin save.\n",
      "epoch 2554\n",
      "test_train\n",
      "train mean loss=62845.492447916666\n",
      "test_test\n",
      "test mean loss=88798.140625\n",
      "fin save.\n",
      "epoch 2555\n",
      "test_train\n",
      "train mean loss=63058.0484375\n",
      "test_test\n",
      "test mean loss=88648.9375\n",
      "fin save.\n",
      "epoch 2556\n",
      "test_train\n",
      "train mean loss=62251.69244791667\n",
      "test_test\n",
      "test mean loss=88964.8359375\n",
      "fin save.\n",
      "epoch 2557\n",
      "test_train\n",
      "train mean loss=64001.069010416664\n",
      "test_test\n",
      "test mean loss=88743.53515625\n",
      "fin save.\n",
      "epoch 2558\n",
      "test_train\n",
      "train mean loss=62910.4890625\n",
      "test_test\n",
      "test mean loss=88735.50390625\n",
      "fin save.\n",
      "epoch 2559\n",
      "test_train\n",
      "train mean loss=62410.02421875\n",
      "test_test\n",
      "test mean loss=88722.22265625\n",
      "fin save.\n",
      "epoch 2560\n",
      "test_train\n",
      "train mean loss=62385.060807291666\n",
      "test_test\n",
      "test mean loss=88755.73828125\n",
      "fin save.\n",
      "epoch 2561\n",
      "test_train\n",
      "train mean loss=62408.563802083336\n",
      "test_test\n",
      "test mean loss=88639.27734375\n",
      "fin save.\n",
      "epoch 2562\n",
      "test_train\n",
      "train mean loss=63352.437760416666\n",
      "test_test\n",
      "test mean loss=88917.97265625\n",
      "fin save.\n",
      "epoch 2563\n",
      "test_train\n",
      "train mean loss=62900.986979166664\n",
      "test_test\n",
      "test mean loss=88739.1015625\n",
      "fin save.\n",
      "epoch 2564\n",
      "test_train\n",
      "train mean loss=63155.53567708333\n",
      "test_test\n",
      "test mean loss=88737.83984375\n",
      "fin save.\n",
      "epoch 2565\n",
      "test_train\n",
      "train mean loss=62747.93307291667\n",
      "test_test\n",
      "test mean loss=88643.3671875\n",
      "fin save.\n",
      "epoch 2566\n",
      "test_train\n",
      "train mean loss=62429.433333333334\n",
      "test_test\n",
      "test mean loss=88704.6796875\n",
      "fin save.\n",
      "epoch 2567\n",
      "test_train\n",
      "train mean loss=63391.29635416667\n",
      "test_test\n",
      "test mean loss=88635.765625\n",
      "fin save.\n",
      "epoch 2568\n",
      "test_train\n",
      "train mean loss=62415.755208333336\n",
      "test_test\n",
      "test mean loss=88619.79296875\n",
      "fin save.\n",
      "epoch 2569\n",
      "test_train\n",
      "train mean loss=63212.922135416666\n",
      "test_test\n",
      "test mean loss=88714.3828125\n",
      "fin save.\n",
      "epoch 2570\n",
      "test_train\n",
      "train mean loss=62819.40807291667\n",
      "test_test\n",
      "test mean loss=88724.171875\n",
      "fin save.\n",
      "epoch 2571\n",
      "test_train\n",
      "train mean loss=62582.736588541666\n",
      "test_test\n",
      "test mean loss=88677.6640625\n",
      "fin save.\n",
      "epoch 2572\n",
      "test_train\n",
      "train mean loss=62013.18450520833\n",
      "test_test\n",
      "test mean loss=88886.4140625\n",
      "fin save.\n",
      "epoch 2573\n",
      "test_train\n",
      "train mean loss=62808.7125\n",
      "test_test\n",
      "test mean loss=88743.41796875\n",
      "fin save.\n",
      "epoch 2574\n",
      "test_train\n",
      "train mean loss=62542.805989583336\n",
      "test_test\n",
      "test mean loss=88723.4921875\n",
      "fin save.\n",
      "epoch 2575\n",
      "test_train\n",
      "train mean loss=62750.17434895833\n",
      "test_test\n",
      "test mean loss=88731.1015625\n",
      "fin save.\n",
      "epoch 2576\n",
      "test_train\n",
      "train mean loss=62641.1953125\n",
      "test_test\n",
      "test mean loss=88714.640625\n",
      "fin save.\n",
      "epoch 2577\n",
      "test_train\n",
      "train mean loss=62779.55911458333\n",
      "test_test\n",
      "test mean loss=88842.83984375\n",
      "fin save.\n",
      "epoch 2578\n",
      "test_train\n",
      "train mean loss=61752.975260416664\n",
      "test_test\n",
      "test mean loss=88531.90625\n",
      "fin save.\n",
      "epoch 2579\n",
      "test_train\n",
      "train mean loss=62724.24166666667\n",
      "test_test\n",
      "test mean loss=88736.25\n",
      "fin save.\n",
      "epoch 2580\n",
      "test_train\n",
      "train mean loss=62488.2328125\n",
      "test_test\n",
      "test mean loss=88450.3125\n",
      "fin save.\n",
      "epoch 2581\n",
      "test_train\n",
      "train mean loss=63236.09661458333\n",
      "test_test\n",
      "test mean loss=88602.515625\n",
      "fin save.\n",
      "epoch 2582\n",
      "test_train\n",
      "train mean loss=62610.89140625\n",
      "test_test\n",
      "test mean loss=88578.53125\n",
      "fin save.\n",
      "epoch 2583\n",
      "test_train\n",
      "train mean loss=61537.17473958333\n",
      "test_test\n",
      "test mean loss=88564.3359375\n",
      "fin save.\n",
      "epoch 2584\n",
      "test_train\n",
      "train mean loss=61480.74609375\n",
      "test_test\n",
      "test mean loss=88658.70703125\n",
      "fin save.\n",
      "epoch 2585\n",
      "test_train\n",
      "train mean loss=63185.670703125\n",
      "test_test\n",
      "test mean loss=89011.234375\n",
      "fin save.\n",
      "epoch 2586\n",
      "test_train\n",
      "train mean loss=63132.460546875\n",
      "test_test\n",
      "test mean loss=88878.0\n",
      "fin save.\n",
      "epoch 2587\n",
      "test_train\n",
      "train mean loss=62960.00885416667\n",
      "test_test\n",
      "test mean loss=88902.94921875\n",
      "fin save.\n",
      "epoch 2588\n",
      "test_train\n",
      "train mean loss=63337.01953125\n",
      "test_test\n",
      "test mean loss=89023.47265625\n",
      "fin save.\n",
      "epoch 2589\n",
      "test_train\n",
      "train mean loss=64340.10403645833\n",
      "test_test\n",
      "test mean loss=89063.26171875\n",
      "fin save.\n",
      "epoch 2590\n",
      "test_train\n",
      "train mean loss=63614.55364583333\n",
      "test_test\n",
      "test mean loss=89099.75\n",
      "fin save.\n",
      "epoch 2591\n",
      "test_train\n",
      "train mean loss=62286.124739583334\n",
      "test_test\n",
      "test mean loss=88979.34375\n",
      "fin save.\n",
      "epoch 2592\n",
      "test_train\n",
      "train mean loss=63335.977213541664\n",
      "test_test\n",
      "test mean loss=88948.359375\n",
      "fin save.\n",
      "epoch 2593\n",
      "test_train\n",
      "train mean loss=62784.043229166666\n",
      "test_test\n",
      "test mean loss=89153.296875\n",
      "fin save.\n",
      "epoch 2594\n",
      "test_train\n",
      "train mean loss=63272.679036458336\n",
      "test_test\n",
      "test mean loss=89021.95703125\n",
      "fin save.\n",
      "epoch 2595\n",
      "test_train\n",
      "train mean loss=63362.43515625\n",
      "test_test\n",
      "test mean loss=88955.03515625\n",
      "fin save.\n",
      "epoch 2596\n",
      "test_train\n",
      "train mean loss=62335.7390625\n",
      "test_test\n",
      "test mean loss=89146.71875\n",
      "fin save.\n",
      "epoch 2597\n",
      "test_train\n",
      "train mean loss=62194.61223958333\n",
      "test_test\n",
      "test mean loss=88941.6875\n",
      "fin save.\n",
      "epoch 2598\n",
      "test_train\n",
      "train mean loss=62840.39609375\n",
      "test_test\n",
      "test mean loss=88860.859375\n",
      "fin save.\n",
      "epoch 2599\n",
      "test_train\n",
      "train mean loss=63060.54921875\n",
      "test_test\n",
      "test mean loss=88958.50390625\n",
      "fin save.\n",
      "epoch 2600\n",
      "test_train\n",
      "train mean loss=62636.85104166667\n",
      "test_test\n",
      "test mean loss=89094.5859375\n",
      "fin save.\n",
      "epoch 2601\n",
      "test_train\n",
      "train mean loss=62190.50234375\n",
      "test_test\n",
      "test mean loss=88845.53515625\n",
      "fin save.\n",
      "epoch 2602\n",
      "test_train\n",
      "train mean loss=62029.29088541667\n",
      "test_test\n",
      "test mean loss=88940.90234375\n",
      "fin save.\n",
      "epoch 2603\n",
      "test_train\n",
      "train mean loss=62741.76666666667\n",
      "test_test\n",
      "test mean loss=89095.57421875\n",
      "fin save.\n",
      "epoch 2604\n",
      "test_train\n",
      "train mean loss=61657.90416666667\n",
      "test_test\n",
      "test mean loss=89312.2421875\n",
      "fin save.\n",
      "epoch 2605\n",
      "test_train\n",
      "train mean loss=61854.78854166667\n",
      "test_test\n",
      "test mean loss=89394.9765625\n",
      "fin save.\n",
      "epoch 2606\n",
      "test_train\n",
      "train mean loss=62069.01171875\n",
      "test_test\n",
      "test mean loss=89213.37109375\n",
      "fin save.\n",
      "epoch 2607\n",
      "test_train\n",
      "train mean loss=61534.27682291667\n",
      "test_test\n",
      "test mean loss=87974.58203125\n",
      "fin save.\n",
      "epoch 2608\n",
      "test_train\n",
      "train mean loss=61187.32916666667\n",
      "test_test\n",
      "test mean loss=87987.8125\n",
      "fin save.\n",
      "epoch 2609\n",
      "test_train\n",
      "train mean loss=61583.248697916664\n",
      "test_test\n",
      "test mean loss=87987.8203125\n",
      "fin save.\n",
      "epoch 2610\n",
      "test_train\n",
      "train mean loss=62033.03046875\n",
      "test_test\n",
      "test mean loss=87847.828125\n",
      "fin save.\n",
      "epoch 2611\n",
      "test_train\n",
      "train mean loss=61292.30416666667\n",
      "test_test\n",
      "test mean loss=88019.375\n",
      "fin save.\n",
      "epoch 2612\n",
      "test_train\n",
      "train mean loss=61898.65377604167\n",
      "test_test\n",
      "test mean loss=88154.27734375\n",
      "fin save.\n",
      "epoch 2613\n",
      "test_train\n",
      "train mean loss=61893.06041666667\n",
      "test_test\n",
      "test mean loss=88241.75\n",
      "fin save.\n",
      "epoch 2614\n",
      "test_train\n",
      "train mean loss=60530.019270833334\n",
      "test_test\n",
      "test mean loss=88544.890625\n",
      "fin save.\n",
      "epoch 2615\n",
      "test_train\n",
      "train mean loss=61499.405989583334\n",
      "test_test\n",
      "test mean loss=88404.51171875\n",
      "fin save.\n",
      "epoch 2616\n",
      "test_train\n",
      "train mean loss=61385.537760416664\n",
      "test_test\n",
      "test mean loss=88246.1875\n",
      "fin save.\n",
      "epoch 2617\n",
      "test_train\n",
      "train mean loss=61607.20208333333\n",
      "test_test\n",
      "test mean loss=88606.23046875\n",
      "fin save.\n",
      "epoch 2618\n",
      "test_train\n",
      "train mean loss=61513.767317708334\n",
      "test_test\n",
      "test mean loss=88231.53125\n",
      "fin save.\n",
      "epoch 2619\n",
      "test_train\n",
      "train mean loss=61397.311197916664\n",
      "test_test\n",
      "test mean loss=88376.328125\n",
      "fin save.\n",
      "epoch 2620\n",
      "test_train\n",
      "train mean loss=61585.169270833336\n",
      "test_test\n",
      "test mean loss=88675.10546875\n",
      "fin save.\n",
      "epoch 2621\n",
      "test_train\n",
      "train mean loss=61180.66067708333\n",
      "test_test\n",
      "test mean loss=88879.90234375\n",
      "fin save.\n",
      "epoch 2622\n",
      "test_train\n",
      "train mean loss=62192.119791666664\n",
      "test_test\n",
      "test mean loss=88872.546875\n",
      "fin save.\n",
      "epoch 2623\n",
      "test_train\n",
      "train mean loss=61614.838151041666\n",
      "test_test\n",
      "test mean loss=88768.76953125\n",
      "fin save.\n",
      "epoch 2624\n",
      "test_train\n",
      "train mean loss=62081.880208333336\n",
      "test_test\n",
      "test mean loss=88768.47265625\n",
      "fin save.\n",
      "epoch 2625\n",
      "test_train\n",
      "train mean loss=61410.24765625\n",
      "test_test\n",
      "test mean loss=88596.14453125\n",
      "fin save.\n",
      "epoch 2626\n",
      "test_train\n",
      "train mean loss=61331.52005208333\n",
      "test_test\n",
      "test mean loss=88439.1875\n",
      "fin save.\n",
      "epoch 2627\n",
      "test_train\n",
      "train mean loss=60535.679427083334\n",
      "test_test\n",
      "test mean loss=88445.515625\n",
      "fin save.\n",
      "epoch 2628\n",
      "test_train\n",
      "train mean loss=61521.878125\n",
      "test_test\n",
      "test mean loss=88563.73828125\n",
      "fin save.\n",
      "epoch 2629\n",
      "test_train\n",
      "train mean loss=61928.36276041667\n",
      "test_test\n",
      "test mean loss=89075.59375\n",
      "fin save.\n",
      "epoch 2630\n",
      "test_train\n",
      "train mean loss=61695.406640625\n",
      "test_test\n",
      "test mean loss=89356.87109375\n",
      "fin save.\n",
      "epoch 2631\n",
      "test_train\n",
      "train mean loss=60933.055989583336\n",
      "test_test\n",
      "test mean loss=89566.20703125\n",
      "fin save.\n",
      "epoch 2632\n",
      "test_train\n",
      "train mean loss=60877.52734375\n",
      "test_test\n",
      "test mean loss=89556.44921875\n",
      "fin save.\n",
      "epoch 2633\n",
      "test_train\n",
      "train mean loss=62035.2671875\n",
      "test_test\n",
      "test mean loss=89386.6015625\n",
      "fin save.\n",
      "epoch 2634\n",
      "test_train\n",
      "train mean loss=62639.359375\n",
      "test_test\n",
      "test mean loss=89300.1953125\n",
      "fin save.\n",
      "epoch 2635\n",
      "test_train\n",
      "train mean loss=62372.49322916667\n",
      "test_test\n",
      "test mean loss=89408.78515625\n",
      "fin save.\n",
      "epoch 2636\n",
      "test_train\n",
      "train mean loss=61989.039322916666\n",
      "test_test\n",
      "test mean loss=89234.59765625\n",
      "fin save.\n",
      "epoch 2637\n",
      "test_train\n",
      "train mean loss=61973.60625\n",
      "test_test\n",
      "test mean loss=89118.39453125\n",
      "fin save.\n",
      "epoch 2638\n",
      "test_train\n",
      "train mean loss=61421.133072916666\n",
      "test_test\n",
      "test mean loss=89284.95703125\n",
      "fin save.\n",
      "epoch 2639\n",
      "test_train\n",
      "train mean loss=60966.57630208333\n",
      "test_test\n",
      "test mean loss=89148.109375\n",
      "fin save.\n",
      "epoch 2640\n",
      "test_train\n",
      "train mean loss=61559.76380208333\n",
      "test_test\n",
      "test mean loss=89062.3984375\n",
      "fin save.\n",
      "epoch 2641\n",
      "test_train\n",
      "train mean loss=62419.358072916664\n",
      "test_test\n",
      "test mean loss=88797.3671875\n",
      "fin save.\n",
      "epoch 2642\n",
      "test_train\n",
      "train mean loss=61359.329427083336\n",
      "test_test\n",
      "test mean loss=88840.77734375\n",
      "fin save.\n",
      "epoch 2643\n",
      "test_train\n",
      "train mean loss=60884.121744791664\n",
      "test_test\n",
      "test mean loss=88944.44921875\n",
      "fin save.\n",
      "epoch 2644\n",
      "test_train\n",
      "train mean loss=61491.779947916664\n",
      "test_test\n",
      "test mean loss=88923.328125\n",
      "fin save.\n",
      "epoch 2645\n",
      "test_train\n",
      "train mean loss=61742.032552083336\n",
      "test_test\n",
      "test mean loss=88699.2734375\n",
      "fin save.\n",
      "epoch 2646\n",
      "test_train\n",
      "train mean loss=61486.47903645833\n",
      "test_test\n",
      "test mean loss=88887.2109375\n",
      "fin save.\n",
      "epoch 2647\n",
      "test_train\n",
      "train mean loss=61498.111979166664\n",
      "test_test\n",
      "test mean loss=88928.67578125\n",
      "fin save.\n",
      "epoch 2648\n",
      "test_train\n",
      "train mean loss=61999.18020833333\n",
      "test_test\n",
      "test mean loss=88968.14453125\n",
      "fin save.\n",
      "epoch 2649\n",
      "test_train\n",
      "train mean loss=61645.65234375\n",
      "test_test\n",
      "test mean loss=88713.90234375\n",
      "fin save.\n",
      "epoch 2650\n",
      "test_train\n",
      "train mean loss=62058.516927083336\n",
      "test_test\n",
      "test mean loss=88993.72265625\n",
      "fin save.\n",
      "epoch 2651\n",
      "test_train\n",
      "train mean loss=62070.403645833336\n",
      "test_test\n",
      "test mean loss=88958.5078125\n",
      "fin save.\n",
      "epoch 2652\n",
      "test_train\n",
      "train mean loss=61685.54895833333\n",
      "test_test\n",
      "test mean loss=88898.84765625\n",
      "fin save.\n",
      "epoch 2653\n",
      "test_train\n",
      "train mean loss=63569.08671875\n",
      "test_test\n",
      "test mean loss=88905.078125\n",
      "fin save.\n",
      "epoch 2654\n",
      "test_train\n",
      "train mean loss=62300.48098958333\n",
      "test_test\n",
      "test mean loss=88767.390625\n",
      "fin save.\n",
      "epoch 2655\n",
      "test_train\n",
      "train mean loss=62831.766796875\n",
      "test_test\n",
      "test mean loss=88804.35546875\n",
      "fin save.\n",
      "epoch 2656\n",
      "test_train\n",
      "train mean loss=62284.43411458333\n",
      "test_test\n",
      "test mean loss=88759.7578125\n",
      "fin save.\n",
      "epoch 2657\n",
      "test_train\n",
      "train mean loss=62486.891927083336\n",
      "test_test\n",
      "test mean loss=88771.3203125\n",
      "fin save.\n",
      "epoch 2658\n",
      "test_train\n",
      "train mean loss=61741.41171875\n",
      "test_test\n",
      "test mean loss=88883.03515625\n",
      "fin save.\n",
      "epoch 2659\n",
      "test_train\n",
      "train mean loss=62407.67760416667\n",
      "test_test\n",
      "test mean loss=88896.671875\n",
      "fin save.\n",
      "epoch 2660\n",
      "test_train\n",
      "train mean loss=61849.8265625\n",
      "test_test\n",
      "test mean loss=88949.54296875\n",
      "fin save.\n",
      "epoch 2661\n",
      "test_train\n",
      "train mean loss=62213.76744791667\n",
      "test_test\n",
      "test mean loss=88576.89453125\n",
      "fin save.\n",
      "epoch 2662\n",
      "test_train\n",
      "train mean loss=62844.359375\n",
      "test_test\n",
      "test mean loss=88479.59375\n",
      "fin save.\n",
      "epoch 2663\n",
      "test_train\n",
      "train mean loss=62221.2515625\n",
      "test_test\n",
      "test mean loss=88480.78515625\n",
      "fin save.\n",
      "epoch 2664\n",
      "test_train\n",
      "train mean loss=62282.86145833333\n",
      "test_test\n",
      "test mean loss=88474.96484375\n",
      "fin save.\n",
      "epoch 2665\n",
      "test_train\n",
      "train mean loss=63118.760416666664\n",
      "test_test\n",
      "test mean loss=88574.9375\n",
      "fin save.\n",
      "epoch 2666\n",
      "test_train\n",
      "train mean loss=62784.48776041667\n",
      "test_test\n",
      "test mean loss=88615.44140625\n",
      "fin save.\n",
      "epoch 2667\n",
      "test_train\n",
      "train mean loss=61615.65078125\n",
      "test_test\n",
      "test mean loss=88661.10546875\n",
      "fin save.\n",
      "epoch 2668\n",
      "test_train\n",
      "train mean loss=62417.48489583333\n",
      "test_test\n",
      "test mean loss=88771.98046875\n",
      "fin save.\n",
      "epoch 2669\n",
      "test_train\n",
      "train mean loss=61693.527734375\n",
      "test_test\n",
      "test mean loss=89237.23046875\n",
      "fin save.\n",
      "epoch 2670\n",
      "test_train\n",
      "train mean loss=62421.055859375\n",
      "test_test\n",
      "test mean loss=89258.41015625\n",
      "fin save.\n",
      "epoch 2671\n",
      "test_train\n",
      "train mean loss=62737.15859375\n",
      "test_test\n",
      "test mean loss=89129.9453125\n",
      "fin save.\n",
      "epoch 2672\n",
      "test_train\n",
      "train mean loss=61933.22473958333\n",
      "test_test\n",
      "test mean loss=89131.59375\n",
      "fin save.\n",
      "epoch 2673\n",
      "test_train\n",
      "train mean loss=61827.00442708333\n",
      "test_test\n",
      "test mean loss=88741.46484375\n",
      "fin save.\n",
      "epoch 2674\n",
      "test_train\n",
      "train mean loss=62042.803385416664\n",
      "test_test\n",
      "test mean loss=88601.87890625\n",
      "fin save.\n",
      "epoch 2675\n",
      "test_train\n",
      "train mean loss=62624.215104166666\n",
      "test_test\n",
      "test mean loss=88649.1875\n",
      "fin save.\n",
      "epoch 2676\n",
      "test_train\n",
      "train mean loss=61718.71692708333\n",
      "test_test\n",
      "test mean loss=89142.203125\n",
      "fin save.\n",
      "epoch 2677\n",
      "test_train\n",
      "train mean loss=62109.332421875\n",
      "test_test\n",
      "test mean loss=89043.01953125\n",
      "fin save.\n",
      "epoch 2678\n",
      "test_train\n",
      "train mean loss=62204.07369791667\n",
      "test_test\n",
      "test mean loss=88337.7890625\n",
      "fin save.\n",
      "epoch 2679\n",
      "test_train\n",
      "train mean loss=62405.30286458333\n",
      "test_test\n",
      "test mean loss=88634.04296875\n",
      "fin save.\n",
      "epoch 2680\n",
      "test_train\n",
      "train mean loss=61899.66848958333\n",
      "test_test\n",
      "test mean loss=89217.2265625\n",
      "fin save.\n",
      "epoch 2681\n",
      "test_train\n",
      "train mean loss=61977.05807291667\n",
      "test_test\n",
      "test mean loss=89156.19140625\n",
      "fin save.\n",
      "epoch 2682\n",
      "test_train\n",
      "train mean loss=62448.543359375\n",
      "test_test\n",
      "test mean loss=89220.9296875\n",
      "fin save.\n",
      "epoch 2683\n",
      "test_train\n",
      "train mean loss=62273.05234375\n",
      "test_test\n",
      "test mean loss=88957.33984375\n",
      "fin save.\n",
      "epoch 2684\n",
      "test_train\n",
      "train mean loss=61810.756510416664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_test\n",
      "test mean loss=88957.27734375\n",
      "fin save.\n",
      "epoch 2685\n",
      "test_train\n",
      "train mean loss=61637.77161458333\n",
      "test_test\n",
      "test mean loss=88700.8046875\n",
      "fin save.\n",
      "epoch 2686\n",
      "test_train\n",
      "train mean loss=62029.28723958333\n",
      "test_test\n",
      "test mean loss=88851.09375\n",
      "fin save.\n",
      "epoch 2687\n",
      "test_train\n",
      "train mean loss=63272.99817708333\n",
      "test_test\n",
      "test mean loss=88765.5703125\n",
      "fin save.\n",
      "epoch 2688\n",
      "test_train\n",
      "train mean loss=62305.299609375\n",
      "test_test\n",
      "test mean loss=88824.96875\n",
      "fin save.\n",
      "epoch 2689\n",
      "test_train\n",
      "train mean loss=62768.809895833336\n",
      "test_test\n",
      "test mean loss=88568.4453125\n",
      "fin save.\n",
      "epoch 2690\n",
      "test_train\n",
      "train mean loss=62276.740625\n",
      "test_test\n",
      "test mean loss=88454.44921875\n",
      "fin save.\n",
      "epoch 2691\n",
      "test_train\n",
      "train mean loss=62966.43697916667\n",
      "test_test\n",
      "test mean loss=88828.90234375\n",
      "fin save.\n",
      "epoch 2692\n",
      "test_train\n",
      "train mean loss=61618.640885416666\n",
      "test_test\n",
      "test mean loss=89026.51171875\n",
      "fin save.\n",
      "epoch 2693\n",
      "test_train\n",
      "train mean loss=62970.16809895833\n",
      "test_test\n",
      "test mean loss=88925.25390625\n",
      "fin save.\n",
      "epoch 2694\n",
      "test_train\n",
      "train mean loss=62469.091536458334\n",
      "test_test\n",
      "test mean loss=89094.2109375\n",
      "fin save.\n",
      "epoch 2695\n",
      "test_train\n",
      "train mean loss=61804.577473958336\n",
      "test_test\n",
      "test mean loss=88989.77734375\n",
      "fin save.\n",
      "epoch 2696\n",
      "test_train\n",
      "train mean loss=62116.90325520833\n",
      "test_test\n",
      "test mean loss=88952.21484375\n",
      "fin save.\n",
      "epoch 2697\n",
      "test_train\n",
      "train mean loss=62482.475\n",
      "test_test\n",
      "test mean loss=88924.0390625\n",
      "fin save.\n",
      "epoch 2698\n",
      "test_train\n",
      "train mean loss=61434.72447916667\n",
      "test_test\n",
      "test mean loss=89099.984375\n",
      "fin save.\n",
      "epoch 2699\n",
      "test_train\n",
      "train mean loss=62964.561848958336\n",
      "test_test\n",
      "test mean loss=88634.5\n",
      "fin save.\n",
      "epoch 2700\n",
      "test_train\n",
      "train mean loss=62983.1671875\n",
      "test_test\n",
      "test mean loss=88620.38671875\n",
      "fin save.\n",
      "epoch 2701\n",
      "test_train\n",
      "train mean loss=62256.879166666666\n",
      "test_test\n",
      "test mean loss=88704.05859375\n",
      "fin save.\n",
      "epoch 2702\n",
      "test_train\n",
      "train mean loss=61881.354817708336\n",
      "test_test\n",
      "test mean loss=88652.76953125\n",
      "fin save.\n",
      "epoch 2703\n",
      "test_train\n",
      "train mean loss=62565.4625\n",
      "test_test\n",
      "test mean loss=88874.34375\n",
      "fin save.\n",
      "epoch 2704\n",
      "test_train\n",
      "train mean loss=61621.34192708333\n",
      "test_test\n",
      "test mean loss=88926.9921875\n",
      "fin save.\n",
      "epoch 2705\n",
      "test_train\n",
      "train mean loss=62849.250260416666\n",
      "test_test\n",
      "test mean loss=88754.84375\n",
      "fin save.\n",
      "epoch 2706\n",
      "test_train\n",
      "train mean loss=62427.885416666664\n",
      "test_test\n",
      "test mean loss=89520.16015625\n",
      "fin save.\n",
      "epoch 2707\n",
      "test_train\n",
      "train mean loss=62245.56354166667\n",
      "test_test\n",
      "test mean loss=88756.890625\n",
      "fin save.\n",
      "epoch 2708\n",
      "test_train\n",
      "train mean loss=62255.86171875\n",
      "test_test\n",
      "test mean loss=89528.91796875\n",
      "fin save.\n",
      "epoch 2709\n",
      "test_train\n",
      "train mean loss=63122.895833333336\n",
      "test_test\n",
      "test mean loss=88950.234375\n",
      "fin save.\n",
      "epoch 2710\n",
      "test_train\n",
      "train mean loss=62260.76354166667\n",
      "test_test\n",
      "test mean loss=89071.62890625\n",
      "fin save.\n",
      "epoch 2711\n",
      "test_train\n",
      "train mean loss=62570.973046875\n",
      "test_test\n",
      "test mean loss=88902.65234375\n",
      "fin save.\n",
      "epoch 2712\n",
      "test_train\n",
      "train mean loss=61514.4703125\n",
      "test_test\n",
      "test mean loss=88825.390625\n",
      "fin save.\n",
      "epoch 2713\n",
      "test_train\n",
      "train mean loss=61707.38984375\n",
      "test_test\n",
      "test mean loss=88760.41796875\n",
      "fin save.\n",
      "epoch 2714\n",
      "test_train\n",
      "train mean loss=63160.78333333333\n",
      "test_test\n",
      "test mean loss=88973.75390625\n",
      "fin save.\n",
      "epoch 2715\n",
      "test_train\n",
      "train mean loss=62035.951171875\n",
      "test_test\n",
      "test mean loss=89005.75390625\n",
      "fin save.\n",
      "epoch 2716\n",
      "test_train\n",
      "train mean loss=62350.868359375\n",
      "test_test\n",
      "test mean loss=88805.05859375\n",
      "fin save.\n",
      "epoch 2717\n",
      "test_train\n",
      "train mean loss=62898.95651041667\n",
      "test_test\n",
      "test mean loss=88663.75\n",
      "fin save.\n",
      "epoch 2718\n",
      "test_train\n",
      "train mean loss=62289.2984375\n",
      "test_test\n",
      "test mean loss=88794.140625\n",
      "fin save.\n",
      "epoch 2719\n",
      "test_train\n",
      "train mean loss=62072.283854166664\n",
      "test_test\n",
      "test mean loss=88863.75390625\n",
      "fin save.\n",
      "epoch 2720\n",
      "test_train\n",
      "train mean loss=61448.29869791667\n",
      "test_test\n",
      "test mean loss=88719.02734375\n",
      "fin save.\n",
      "epoch 2721\n",
      "test_train\n",
      "train mean loss=62261.080338541666\n",
      "test_test\n",
      "test mean loss=89283.86328125\n",
      "fin save.\n",
      "epoch 2722\n",
      "test_train\n",
      "train mean loss=62255.43463541667\n",
      "test_test\n",
      "test mean loss=89361.0234375\n",
      "fin save.\n",
      "epoch 2723\n",
      "test_train\n",
      "train mean loss=61578.12734375\n",
      "test_test\n",
      "test mean loss=88961.03515625\n",
      "fin save.\n",
      "epoch 2724\n",
      "test_train\n",
      "train mean loss=61872.03984375\n",
      "test_test\n",
      "test mean loss=88651.5234375\n",
      "fin save.\n",
      "epoch 2725\n",
      "test_train\n",
      "train mean loss=62316.717447916664\n",
      "test_test\n",
      "test mean loss=88732.67578125\n",
      "fin save.\n",
      "epoch 2726\n",
      "test_train\n",
      "train mean loss=63061.66848958333\n",
      "test_test\n",
      "test mean loss=88565.55078125\n",
      "fin save.\n",
      "epoch 2727\n",
      "test_train\n",
      "train mean loss=61745.094010416666\n",
      "test_test\n",
      "test mean loss=88987.83203125\n",
      "fin save.\n",
      "epoch 2728\n",
      "test_train\n",
      "train mean loss=62104.19322916667\n",
      "test_test\n",
      "test mean loss=88783.6328125\n",
      "fin save.\n",
      "epoch 2729\n",
      "test_train\n",
      "train mean loss=62058.41744791667\n",
      "test_test\n",
      "test mean loss=88923.08984375\n",
      "fin save.\n",
      "epoch 2730\n",
      "test_train\n",
      "train mean loss=62214.21145833333\n",
      "test_test\n",
      "test mean loss=88899.6015625\n",
      "fin save.\n",
      "epoch 2731\n",
      "test_train\n",
      "train mean loss=62218.6984375\n",
      "test_test\n",
      "test mean loss=88506.546875\n",
      "fin save.\n",
      "epoch 2732\n",
      "test_train\n",
      "train mean loss=62236.67265625\n",
      "test_test\n",
      "test mean loss=88609.86328125\n",
      "fin save.\n",
      "epoch 2733\n",
      "test_train\n",
      "train mean loss=62141.58450520833\n",
      "test_test\n",
      "test mean loss=88638.54296875\n",
      "fin save.\n",
      "epoch 2734\n",
      "test_train\n",
      "train mean loss=62158.46783854167\n",
      "test_test\n",
      "test mean loss=88757.84375\n",
      "fin save.\n",
      "epoch 2735\n",
      "test_train\n",
      "train mean loss=62090.474869791666\n",
      "test_test\n",
      "test mean loss=88764.08203125\n",
      "fin save.\n",
      "epoch 2736\n",
      "test_train\n",
      "train mean loss=62884.50247395833\n",
      "test_test\n",
      "test mean loss=88826.421875\n",
      "fin save.\n",
      "epoch 2737\n",
      "test_train\n",
      "train mean loss=61618.36119791667\n",
      "test_test\n",
      "test mean loss=88306.76953125\n",
      "fin save.\n",
      "epoch 2738\n",
      "test_train\n",
      "train mean loss=62567.636979166666\n",
      "test_test\n",
      "test mean loss=88281.484375\n",
      "fin save.\n",
      "epoch 2739\n",
      "test_train\n",
      "train mean loss=62253.509114583336\n",
      "test_test\n",
      "test mean loss=88190.67578125\n",
      "fin save.\n",
      "epoch 2740\n",
      "test_train\n",
      "train mean loss=62419.640625\n",
      "test_test\n",
      "test mean loss=88143.25\n",
      "fin save.\n",
      "epoch 2741\n",
      "test_train\n",
      "train mean loss=62609.329427083336\n",
      "test_test\n",
      "test mean loss=88373.02734375\n",
      "fin save.\n",
      "epoch 2742\n",
      "test_train\n",
      "train mean loss=62655.925520833334\n",
      "test_test\n",
      "test mean loss=88653.01953125\n",
      "fin save.\n",
      "epoch 2743\n",
      "test_train\n",
      "train mean loss=62374.43984375\n",
      "test_test\n",
      "test mean loss=88475.15234375\n",
      "fin save.\n",
      "epoch 2744\n",
      "test_train\n",
      "train mean loss=62304.64765625\n",
      "test_test\n",
      "test mean loss=88828.296875\n",
      "fin save.\n",
      "epoch 2745\n",
      "test_train\n",
      "train mean loss=62823.894921875\n",
      "test_test\n",
      "test mean loss=88772.55859375\n",
      "fin save.\n",
      "epoch 2746\n",
      "test_train\n",
      "train mean loss=62228.52552083333\n",
      "test_test\n",
      "test mean loss=88844.92578125\n",
      "fin save.\n",
      "epoch 2747\n",
      "test_train\n",
      "train mean loss=62408.973307291664\n",
      "test_test\n",
      "test mean loss=88885.80859375\n",
      "fin save.\n",
      "epoch 2748\n",
      "test_train\n",
      "train mean loss=61874.66354166667\n",
      "test_test\n",
      "test mean loss=88793.6015625\n",
      "fin save.\n",
      "epoch 2749\n",
      "test_train\n",
      "train mean loss=62545.89557291667\n",
      "test_test\n",
      "test mean loss=89072.9453125\n",
      "fin save.\n",
      "epoch 2750\n",
      "test_train\n",
      "train mean loss=62311.9796875\n",
      "test_test\n",
      "test mean loss=88983.375\n",
      "fin save.\n",
      "epoch 2751\n",
      "test_train\n",
      "train mean loss=62120.12708333333\n",
      "test_test\n",
      "test mean loss=88866.2578125\n",
      "fin save.\n",
      "epoch 2752\n",
      "test_train\n",
      "train mean loss=61813.372395833336\n",
      "test_test\n",
      "test mean loss=88963.6953125\n",
      "fin save.\n",
      "epoch 2753\n",
      "test_train\n",
      "train mean loss=62379.58385416667\n",
      "test_test\n",
      "test mean loss=89038.90625\n",
      "fin save.\n",
      "epoch 2754\n",
      "test_train\n",
      "train mean loss=62234.125651041664\n",
      "test_test\n",
      "test mean loss=88837.58203125\n",
      "fin save.\n",
      "epoch 2755\n",
      "test_train\n",
      "train mean loss=62056.34518229167\n",
      "test_test\n",
      "test mean loss=88967.37109375\n",
      "fin save.\n",
      "epoch 2756\n",
      "test_train\n",
      "train mean loss=62290.137890625\n",
      "test_test\n",
      "test mean loss=88884.375\n",
      "fin save.\n",
      "epoch 2757\n",
      "test_train\n",
      "train mean loss=61466.5234375\n",
      "test_test\n",
      "test mean loss=88794.12109375\n",
      "fin save.\n",
      "epoch 2758\n",
      "test_train\n",
      "train mean loss=62778.573567708336\n",
      "test_test\n",
      "test mean loss=89023.4921875\n",
      "fin save.\n",
      "epoch 2759\n",
      "test_train\n",
      "train mean loss=63040.82421875\n",
      "test_test\n",
      "test mean loss=89088.38671875\n",
      "fin save.\n",
      "epoch 2760\n",
      "test_train\n",
      "train mean loss=62803.65520833333\n",
      "test_test\n",
      "test mean loss=88851.4453125\n",
      "fin save.\n",
      "epoch 2761\n",
      "test_train\n",
      "train mean loss=62110.558854166666\n",
      "test_test\n",
      "test mean loss=89058.49609375\n",
      "fin save.\n",
      "epoch 2762\n",
      "test_train\n",
      "train mean loss=63315.37421875\n",
      "test_test\n",
      "test mean loss=88922.71875\n",
      "fin save.\n",
      "epoch 2763\n",
      "test_train\n",
      "train mean loss=62038.65338541667\n",
      "test_test\n",
      "test mean loss=88978.36328125\n",
      "fin save.\n",
      "epoch 2764\n",
      "test_train\n",
      "train mean loss=62712.95807291667\n",
      "test_test\n",
      "test mean loss=88996.734375\n",
      "fin save.\n",
      "epoch 2765\n",
      "test_train\n",
      "train mean loss=63085.438671875\n",
      "test_test\n",
      "test mean loss=89152.2265625\n",
      "fin save.\n",
      "epoch 2766\n",
      "test_train\n",
      "train mean loss=62956.541276041666\n",
      "test_test\n",
      "test mean loss=89116.53515625\n",
      "fin save.\n",
      "epoch 2767\n",
      "test_train\n",
      "train mean loss=62422.8234375\n",
      "test_test\n",
      "test mean loss=89113.87109375\n",
      "fin save.\n",
      "epoch 2768\n",
      "test_train\n",
      "train mean loss=62933.464583333334\n",
      "test_test\n",
      "test mean loss=89004.98046875\n",
      "fin save.\n",
      "epoch 2769\n",
      "test_train\n",
      "train mean loss=61528.50872395833\n",
      "test_test\n",
      "test mean loss=89002.48828125\n",
      "fin save.\n",
      "epoch 2770\n",
      "test_train\n",
      "train mean loss=61965.42786458333\n",
      "test_test\n",
      "test mean loss=89046.73046875\n",
      "fin save.\n",
      "epoch 2771\n",
      "test_train\n",
      "train mean loss=62991.63958333333\n",
      "test_test\n",
      "test mean loss=88848.0234375\n",
      "fin save.\n",
      "epoch 2772\n",
      "test_train\n",
      "train mean loss=63315.05260416667\n",
      "test_test\n",
      "test mean loss=89046.953125\n",
      "fin save.\n",
      "epoch 2773\n",
      "test_train\n",
      "train mean loss=62254.699479166666\n",
      "test_test\n",
      "test mean loss=89078.66796875\n",
      "fin save.\n",
      "epoch 2774\n",
      "test_train\n",
      "train mean loss=62511.629166666666\n",
      "test_test\n",
      "test mean loss=88892.1484375\n",
      "fin save.\n",
      "epoch 2775\n",
      "test_train\n",
      "train mean loss=62156.58932291667\n",
      "test_test\n",
      "test mean loss=88928.08984375\n",
      "fin save.\n",
      "epoch 2776\n",
      "test_train\n",
      "train mean loss=62604.657552083336\n",
      "test_test\n",
      "test mean loss=88911.35546875\n",
      "fin save.\n",
      "epoch 2777\n",
      "test_train\n",
      "train mean loss=61894.009375\n",
      "test_test\n",
      "test mean loss=88671.10546875\n",
      "fin save.\n",
      "epoch 2778\n",
      "test_train\n",
      "train mean loss=62319.563151041664\n",
      "test_test\n",
      "test mean loss=88679.609375\n",
      "fin save.\n",
      "epoch 2779\n",
      "test_train\n",
      "train mean loss=63391.15026041667\n",
      "test_test\n",
      "test mean loss=88642.9609375\n",
      "fin save.\n",
      "epoch 2780\n",
      "test_train\n",
      "train mean loss=62194.84947916667\n",
      "test_test\n",
      "test mean loss=88729.9453125\n",
      "fin save.\n",
      "epoch 2781\n",
      "test_train\n",
      "train mean loss=62801.619140625\n",
      "test_test\n",
      "test mean loss=88967.5078125\n",
      "fin save.\n",
      "epoch 2782\n",
      "test_train\n",
      "train mean loss=62841.500651041664\n",
      "test_test\n",
      "test mean loss=88862.15234375\n",
      "fin save.\n",
      "epoch 2783\n",
      "test_train\n",
      "train mean loss=61699.44713541667\n",
      "test_test\n",
      "test mean loss=88800.0\n",
      "fin save.\n",
      "epoch 2784\n",
      "test_train\n",
      "train mean loss=62136.11770833333\n",
      "test_test\n",
      "test mean loss=89230.03515625\n",
      "fin save.\n",
      "epoch 2785\n",
      "test_train\n",
      "train mean loss=61746.467578125\n",
      "test_test\n",
      "test mean loss=89324.16015625\n",
      "fin save.\n",
      "epoch 2786\n",
      "test_train\n",
      "train mean loss=61972.35729166667\n",
      "test_test\n",
      "test mean loss=89244.125\n",
      "fin save.\n",
      "epoch 2787\n",
      "test_train\n",
      "train mean loss=62919.92786458333\n",
      "test_test\n",
      "test mean loss=89516.08203125\n",
      "fin save.\n",
      "epoch 2788\n",
      "test_train\n",
      "train mean loss=63178.27291666667\n",
      "test_test\n",
      "test mean loss=89658.140625\n",
      "fin save.\n",
      "epoch 2789\n",
      "test_train\n",
      "train mean loss=62396.80364583333\n",
      "test_test\n",
      "test mean loss=89331.4453125\n",
      "fin save.\n",
      "epoch 2790\n",
      "test_train\n",
      "train mean loss=62118.71875\n",
      "test_test\n",
      "test mean loss=89358.0234375\n",
      "fin save.\n",
      "epoch 2791\n",
      "test_train\n",
      "train mean loss=62627.28046875\n",
      "test_test\n",
      "test mean loss=89505.51953125\n",
      "fin save.\n",
      "epoch 2792\n",
      "test_train\n",
      "train mean loss=62237.570052083334\n",
      "test_test\n",
      "test mean loss=89435.5078125\n",
      "fin save.\n",
      "epoch 2793\n",
      "test_train\n",
      "train mean loss=61165.4484375\n",
      "test_test\n",
      "test mean loss=89298.6953125\n",
      "fin save.\n",
      "epoch 2794\n",
      "test_train\n",
      "train mean loss=62779.65768229167\n",
      "test_test\n",
      "test mean loss=89402.40234375\n",
      "fin save.\n",
      "epoch 2795\n",
      "test_train\n",
      "train mean loss=63017.85104166667\n",
      "test_test\n",
      "test mean loss=89232.3515625\n",
      "fin save.\n",
      "epoch 2796\n",
      "test_train\n",
      "train mean loss=62053.31341145833\n",
      "test_test\n",
      "test mean loss=89126.84375\n",
      "fin save.\n",
      "epoch 2797\n",
      "test_train\n",
      "train mean loss=62291.304947916666\n",
      "test_test\n",
      "test mean loss=89032.23828125\n",
      "fin save.\n",
      "epoch 2798\n",
      "test_train\n",
      "train mean loss=62212.153125\n",
      "test_test\n",
      "test mean loss=89045.02734375\n",
      "fin save.\n",
      "epoch 2799\n",
      "test_train\n",
      "train mean loss=62248.88671875\n",
      "test_test\n",
      "test mean loss=89053.59765625\n",
      "fin save.\n",
      "epoch 2800\n",
      "test_train\n",
      "train mean loss=62112.97369791667\n",
      "test_test\n",
      "test mean loss=89055.2578125\n",
      "fin save.\n",
      "epoch 2801\n",
      "test_train\n",
      "train mean loss=62844.838541666664\n",
      "test_test\n",
      "test mean loss=88803.3828125\n",
      "fin save.\n",
      "epoch 2802\n",
      "test_train\n",
      "train mean loss=62955.90325520833\n",
      "test_test\n",
      "test mean loss=88661.5625\n",
      "fin save.\n",
      "epoch 2803\n",
      "test_train\n",
      "train mean loss=63011.24817708333\n",
      "test_test\n",
      "test mean loss=88827.796875\n",
      "fin save.\n",
      "epoch 2804\n",
      "test_train\n",
      "train mean loss=62070.60234375\n",
      "test_test\n",
      "test mean loss=88851.8828125\n",
      "fin save.\n",
      "epoch 2805\n",
      "test_train\n",
      "train mean loss=62324.8640625\n",
      "test_test\n",
      "test mean loss=88820.8515625\n",
      "fin save.\n",
      "epoch 2806\n",
      "test_train\n",
      "train mean loss=63059.21432291667\n",
      "test_test\n",
      "test mean loss=88891.3828125\n",
      "fin save.\n",
      "epoch 2807\n",
      "test_train\n",
      "train mean loss=62311.29049479167\n",
      "test_test\n",
      "test mean loss=88894.5234375\n",
      "fin save.\n",
      "epoch 2808\n",
      "test_train\n",
      "train mean loss=62006.78958333333\n",
      "test_test\n",
      "test mean loss=88671.93359375\n",
      "fin save.\n",
      "epoch 2809\n",
      "test_train\n",
      "train mean loss=63198.90091145833\n",
      "test_test\n",
      "test mean loss=88706.1015625\n",
      "fin save.\n",
      "epoch 2810\n",
      "test_train\n",
      "train mean loss=61846.929947916666\n",
      "test_test\n",
      "test mean loss=88264.08203125\n",
      "fin save.\n",
      "epoch 2811\n",
      "test_train\n",
      "train mean loss=62779.33125\n",
      "test_test\n",
      "test mean loss=88430.80859375\n",
      "fin save.\n",
      "epoch 2812\n",
      "test_train\n",
      "train mean loss=62214.195052083334\n",
      "test_test\n",
      "test mean loss=88614.0390625\n",
      "fin save.\n",
      "epoch 2813\n",
      "test_train\n",
      "train mean loss=62662.30546875\n",
      "test_test\n",
      "test mean loss=88443.42578125\n",
      "fin save.\n",
      "epoch 2814\n",
      "test_train\n",
      "train mean loss=62578.5125\n",
      "test_test\n",
      "test mean loss=88381.36328125\n",
      "fin save.\n",
      "epoch 2815\n",
      "test_train\n",
      "train mean loss=63011.20546875\n",
      "test_test\n",
      "test mean loss=88503.07421875\n",
      "fin save.\n",
      "epoch 2816\n",
      "test_train\n",
      "train mean loss=62899.64635416667\n",
      "test_test\n",
      "test mean loss=88612.35546875\n",
      "fin save.\n",
      "epoch 2817\n",
      "test_train\n",
      "train mean loss=62454.51276041667\n",
      "test_test\n",
      "test mean loss=88526.7890625\n",
      "fin save.\n",
      "epoch 2818\n",
      "test_train\n",
      "train mean loss=62790.656510416666\n",
      "test_test\n",
      "test mean loss=88414.296875\n",
      "fin save.\n",
      "epoch 2819\n",
      "test_train\n",
      "train mean loss=63320.105729166666\n",
      "test_test\n",
      "test mean loss=88705.1953125\n",
      "fin save.\n",
      "epoch 2820\n",
      "test_train\n",
      "train mean loss=61864.49453125\n",
      "test_test\n",
      "test mean loss=88770.44140625\n",
      "fin save.\n",
      "epoch 2821\n",
      "test_train\n",
      "train mean loss=62310.254166666666\n",
      "test_test\n",
      "test mean loss=88719.14453125\n",
      "fin save.\n",
      "epoch 2822\n",
      "test_train\n",
      "train mean loss=62740.889322916664\n",
      "test_test\n",
      "test mean loss=88627.4453125\n",
      "fin save.\n",
      "epoch 2823\n",
      "test_train\n",
      "train mean loss=62493.26875\n",
      "test_test\n",
      "test mean loss=88641.4609375\n",
      "fin save.\n",
      "epoch 2824\n",
      "test_train\n",
      "train mean loss=62764.19635416667\n",
      "test_test\n",
      "test mean loss=88793.26953125\n",
      "fin save.\n",
      "epoch 2825\n",
      "test_train\n",
      "train mean loss=61892.00794270833\n",
      "test_test\n",
      "test mean loss=88853.84375\n",
      "fin save.\n",
      "epoch 2826\n",
      "test_train\n",
      "train mean loss=63005.47369791667\n",
      "test_test\n",
      "test mean loss=88680.10546875\n",
      "fin save.\n",
      "epoch 2827\n",
      "test_train\n",
      "train mean loss=63544.15091145833\n",
      "test_test\n",
      "test mean loss=88734.93359375\n",
      "fin save.\n",
      "epoch 2828\n",
      "test_train\n",
      "train mean loss=61974.69908854167\n",
      "test_test\n",
      "test mean loss=88456.34375\n",
      "fin save.\n",
      "epoch 2829\n",
      "test_train\n",
      "train mean loss=62991.93984375\n",
      "test_test\n",
      "test mean loss=88884.7578125\n",
      "fin save.\n",
      "epoch 2830\n",
      "test_train\n",
      "train mean loss=62694.24921875\n",
      "test_test\n",
      "test mean loss=88938.765625\n",
      "fin save.\n",
      "epoch 2831\n",
      "test_train\n",
      "train mean loss=62394.50104166667\n",
      "test_test\n",
      "test mean loss=88727.62890625\n",
      "fin save.\n",
      "epoch 2832\n",
      "test_train\n",
      "train mean loss=63287.06927083333\n",
      "test_test\n",
      "test mean loss=88791.38671875\n",
      "fin save.\n",
      "epoch 2833\n",
      "test_train\n",
      "train mean loss=62549.10703125\n",
      "test_test\n",
      "test mean loss=88702.15625\n",
      "fin save.\n",
      "epoch 2834\n",
      "test_train\n",
      "train mean loss=63118.6984375\n",
      "test_test\n",
      "test mean loss=88426.40234375\n",
      "fin save.\n",
      "epoch 2835\n",
      "test_train\n",
      "train mean loss=62526.280859375\n",
      "test_test\n",
      "test mean loss=88677.15625\n",
      "fin save.\n",
      "epoch 2836\n",
      "test_train\n",
      "train mean loss=63487.734765625\n",
      "test_test\n",
      "test mean loss=88529.69921875\n",
      "fin save.\n",
      "epoch 2837\n",
      "test_train\n",
      "train mean loss=63103.563671875\n",
      "test_test\n",
      "test mean loss=88494.1640625\n",
      "fin save.\n",
      "epoch 2838\n",
      "test_train\n",
      "train mean loss=62762.841145833336\n",
      "test_test\n",
      "test mean loss=88828.62890625\n",
      "fin save.\n",
      "epoch 2839\n",
      "test_train\n",
      "train mean loss=62587.81783854167\n",
      "test_test\n",
      "test mean loss=88661.1796875\n",
      "fin save.\n",
      "epoch 2840\n",
      "test_train\n",
      "train mean loss=62201.791276041666\n",
      "test_test\n",
      "test mean loss=88530.91796875\n",
      "fin save.\n",
      "epoch 2841\n",
      "test_train\n",
      "train mean loss=62378.48645833333\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=88842.6328125\n",
      "fin save.\n",
      "epoch 2842\n",
      "test_train\n",
      "train mean loss=61711.17473958333\n",
      "test_test\n",
      "test mean loss=88771.546875\n",
      "fin save.\n",
      "epoch 2843\n",
      "test_train\n",
      "train mean loss=61671.027604166666\n",
      "test_test\n",
      "test mean loss=88589.01171875\n",
      "fin save.\n",
      "epoch 2844\n",
      "test_train\n",
      "train mean loss=62023.40390625\n",
      "test_test\n",
      "test mean loss=88475.703125\n",
      "fin save.\n",
      "epoch 2845\n",
      "test_train\n",
      "train mean loss=61502.53567708333\n",
      "test_test\n",
      "test mean loss=88291.89453125\n",
      "fin save.\n",
      "epoch 2846\n",
      "test_train\n",
      "train mean loss=63243.83828125\n",
      "test_test\n",
      "test mean loss=88338.0234375\n",
      "fin save.\n",
      "epoch 2847\n",
      "test_train\n",
      "train mean loss=62452.068619791666\n",
      "test_test\n",
      "test mean loss=88254.1953125\n",
      "fin save.\n",
      "epoch 2848\n",
      "test_train\n",
      "train mean loss=62933.794140625\n",
      "test_test\n",
      "test mean loss=88056.91796875\n",
      "fin save.\n",
      "epoch 2849\n",
      "test_train\n",
      "train mean loss=62280.83932291667\n",
      "test_test\n",
      "test mean loss=88143.3515625\n",
      "fin save.\n",
      "epoch 2850\n",
      "test_train\n",
      "train mean loss=61506.52447916667\n",
      "test_test\n",
      "test mean loss=88253.515625\n",
      "fin save.\n",
      "epoch 2851\n",
      "test_train\n",
      "train mean loss=62248.798177083336\n",
      "test_test\n",
      "test mean loss=88295.8125\n",
      "fin save.\n",
      "epoch 2852\n",
      "test_train\n",
      "train mean loss=62489.68359375\n",
      "test_test\n",
      "test mean loss=88179.20703125\n",
      "fin save.\n",
      "epoch 2853\n",
      "test_train\n",
      "train mean loss=62966.09921875\n",
      "test_test\n",
      "test mean loss=88151.5\n",
      "fin save.\n",
      "epoch 2854\n",
      "test_train\n",
      "train mean loss=61797.978515625\n",
      "test_test\n",
      "test mean loss=88158.796875\n",
      "fin save.\n",
      "epoch 2855\n",
      "test_train\n",
      "train mean loss=62599.06171875\n",
      "test_test\n",
      "test mean loss=88231.8046875\n",
      "fin save.\n",
      "epoch 2856\n",
      "test_train\n",
      "train mean loss=63479.93984375\n",
      "test_test\n",
      "test mean loss=88137.8515625\n",
      "fin save.\n",
      "epoch 2857\n",
      "test_train\n",
      "train mean loss=62465.19322916667\n",
      "test_test\n",
      "test mean loss=88292.52734375\n",
      "fin save.\n",
      "epoch 2858\n",
      "test_train\n",
      "train mean loss=64401.962239583336\n",
      "test_test\n",
      "test mean loss=88097.55078125\n",
      "fin save.\n",
      "epoch 2859\n",
      "test_train\n",
      "train mean loss=62229.39361979167\n",
      "test_test\n",
      "test mean loss=88178.58984375\n",
      "fin save.\n",
      "epoch 2860\n",
      "test_train\n",
      "train mean loss=62117.613020833334\n",
      "test_test\n",
      "test mean loss=88063.34375\n",
      "fin save.\n",
      "epoch 2861\n",
      "test_train\n",
      "train mean loss=62919.8390625\n",
      "test_test\n",
      "test mean loss=88238.05859375\n",
      "fin save.\n",
      "epoch 2862\n",
      "test_train\n",
      "train mean loss=62889.309895833336\n",
      "test_test\n",
      "test mean loss=88299.59375\n",
      "fin save.\n",
      "epoch 2863\n",
      "test_train\n",
      "train mean loss=61926.570572916666\n",
      "test_test\n",
      "test mean loss=88309.6640625\n",
      "fin save.\n",
      "epoch 2864\n",
      "test_train\n",
      "train mean loss=61103.65911458333\n",
      "test_test\n",
      "test mean loss=88284.45703125\n",
      "fin save.\n",
      "epoch 2865\n",
      "test_train\n",
      "train mean loss=62505.7765625\n",
      "test_test\n",
      "test mean loss=88227.4375\n",
      "fin save.\n",
      "epoch 2866\n",
      "test_train\n",
      "train mean loss=62452.74557291667\n",
      "test_test\n",
      "test mean loss=88253.10546875\n",
      "fin save.\n",
      "epoch 2867\n",
      "test_train\n",
      "train mean loss=62692.90520833333\n",
      "test_test\n",
      "test mean loss=88196.78515625\n",
      "fin save.\n",
      "epoch 2868\n",
      "test_train\n",
      "train mean loss=62473.965625\n",
      "test_test\n",
      "test mean loss=88269.09765625\n",
      "fin save.\n",
      "epoch 2869\n",
      "test_train\n",
      "train mean loss=61678.97161458333\n",
      "test_test\n",
      "test mean loss=88259.9375\n",
      "fin save.\n",
      "epoch 2870\n",
      "test_train\n",
      "train mean loss=61709.753125\n",
      "test_test\n",
      "test mean loss=88180.87890625\n",
      "fin save.\n",
      "epoch 2871\n",
      "test_train\n",
      "train mean loss=62358.674479166664\n",
      "test_test\n",
      "test mean loss=88366.55078125\n",
      "fin save.\n",
      "epoch 2872\n",
      "test_train\n",
      "train mean loss=61999.430989583336\n",
      "test_test\n",
      "test mean loss=88451.1796875\n",
      "fin save.\n",
      "epoch 2873\n",
      "test_train\n",
      "train mean loss=62248.92955729167\n",
      "test_test\n",
      "test mean loss=88248.06640625\n",
      "fin save.\n",
      "epoch 2874\n",
      "test_train\n",
      "train mean loss=62755.970052083336\n",
      "test_test\n",
      "test mean loss=88367.3984375\n",
      "fin save.\n",
      "epoch 2875\n",
      "test_train\n",
      "train mean loss=63257.801041666666\n",
      "test_test\n",
      "test mean loss=88415.015625\n",
      "fin save.\n",
      "epoch 2876\n",
      "test_train\n",
      "train mean loss=63060.24036458333\n",
      "test_test\n",
      "test mean loss=88286.25390625\n",
      "fin save.\n",
      "epoch 2877\n",
      "test_train\n",
      "train mean loss=61850.30572916667\n",
      "test_test\n",
      "test mean loss=88243.4609375\n",
      "fin save.\n",
      "epoch 2878\n",
      "test_train\n",
      "train mean loss=62931.11015625\n",
      "test_test\n",
      "test mean loss=88156.91015625\n",
      "fin save.\n",
      "epoch 2879\n",
      "test_train\n",
      "train mean loss=62130.48619791667\n",
      "test_test\n",
      "test mean loss=88280.62109375\n",
      "fin save.\n",
      "epoch 2880\n",
      "test_train\n",
      "train mean loss=63307.90416666667\n",
      "test_test\n",
      "test mean loss=87954.265625\n",
      "fin save.\n",
      "epoch 2881\n",
      "test_train\n",
      "train mean loss=62616.25442708333\n",
      "test_test\n",
      "test mean loss=88103.140625\n",
      "fin save.\n",
      "epoch 2882\n",
      "test_train\n",
      "train mean loss=62261.16484375\n",
      "test_test\n",
      "test mean loss=87989.16796875\n",
      "fin save.\n",
      "epoch 2883\n",
      "test_train\n",
      "train mean loss=62237.62291666667\n",
      "test_test\n",
      "test mean loss=88225.171875\n",
      "fin save.\n",
      "epoch 2884\n",
      "test_train\n",
      "train mean loss=62674.11822916667\n",
      "test_test\n",
      "test mean loss=88067.3828125\n",
      "fin save.\n",
      "epoch 2885\n",
      "test_train\n",
      "train mean loss=62803.73815104167\n",
      "test_test\n",
      "test mean loss=88080.83984375\n",
      "fin save.\n",
      "epoch 2886\n",
      "test_train\n",
      "train mean loss=62843.698958333334\n",
      "test_test\n",
      "test mean loss=88907.54296875\n",
      "fin save.\n",
      "epoch 2887\n",
      "test_train\n",
      "train mean loss=63125.14921875\n",
      "test_test\n",
      "test mean loss=88866.5546875\n",
      "fin save.\n",
      "epoch 2888\n",
      "test_train\n",
      "train mean loss=62179.442708333336\n",
      "test_test\n",
      "test mean loss=89805.4765625\n",
      "fin save.\n",
      "epoch 2889\n",
      "test_train\n",
      "train mean loss=62241.659375\n",
      "test_test\n",
      "test mean loss=89876.86328125\n",
      "fin save.\n",
      "epoch 2890\n",
      "test_train\n",
      "train mean loss=62786.84713541667\n",
      "test_test\n",
      "test mean loss=89875.01953125\n",
      "fin save.\n",
      "epoch 2891\n",
      "test_train\n",
      "train mean loss=62205.350390625\n",
      "test_test\n",
      "test mean loss=89996.81640625\n",
      "fin save.\n",
      "epoch 2892\n",
      "test_train\n",
      "train mean loss=61898.347395833334\n",
      "test_test\n",
      "test mean loss=89765.41015625\n",
      "fin save.\n",
      "epoch 2893\n",
      "test_train\n",
      "train mean loss=62757.89635416667\n",
      "test_test\n",
      "test mean loss=89696.0546875\n",
      "fin save.\n",
      "epoch 2894\n",
      "test_train\n",
      "train mean loss=62568.92760416667\n",
      "test_test\n",
      "test mean loss=89633.640625\n",
      "fin save.\n",
      "epoch 2895\n",
      "test_train\n",
      "train mean loss=61611.336197916666\n",
      "test_test\n",
      "test mean loss=89694.203125\n",
      "fin save.\n",
      "epoch 2896\n",
      "test_train\n",
      "train mean loss=62464.87265625\n",
      "test_test\n",
      "test mean loss=89642.07421875\n",
      "fin save.\n",
      "epoch 2897\n",
      "test_train\n",
      "train mean loss=61961.79348958333\n",
      "test_test\n",
      "test mean loss=90764.35546875\n",
      "fin save.\n",
      "epoch 2898\n",
      "test_train\n",
      "train mean loss=62499.4359375\n",
      "test_test\n",
      "test mean loss=90720.66796875\n",
      "fin save.\n",
      "epoch 2899\n",
      "test_train\n",
      "train mean loss=61258.78411458333\n",
      "test_test\n",
      "test mean loss=90307.5\n",
      "fin save.\n",
      "epoch 2900\n",
      "test_train\n",
      "train mean loss=62483.61041666667\n",
      "test_test\n",
      "test mean loss=90321.984375\n",
      "fin save.\n",
      "epoch 2901\n",
      "test_train\n",
      "train mean loss=61926.341145833336\n",
      "test_test\n",
      "test mean loss=90089.69921875\n",
      "fin save.\n",
      "epoch 2902\n",
      "test_train\n",
      "train mean loss=62485.39739583333\n",
      "test_test\n",
      "test mean loss=90079.2734375\n",
      "fin save.\n",
      "epoch 2903\n",
      "test_train\n",
      "train mean loss=62500.921875\n",
      "test_test\n",
      "test mean loss=90050.0078125\n",
      "fin save.\n",
      "epoch 2904\n",
      "test_train\n",
      "train mean loss=61850.14661458333\n",
      "test_test\n",
      "test mean loss=90093.21875\n",
      "fin save.\n",
      "epoch 2905\n",
      "test_train\n",
      "train mean loss=62246.488671875\n",
      "test_test\n",
      "test mean loss=90409.4609375\n",
      "fin save.\n",
      "epoch 2906\n",
      "test_train\n",
      "train mean loss=62170.78333333333\n",
      "test_test\n",
      "test mean loss=90511.890625\n",
      "fin save.\n",
      "epoch 2907\n",
      "test_train\n",
      "train mean loss=62045.57916666667\n",
      "test_test\n",
      "test mean loss=89982.9375\n",
      "fin save.\n",
      "epoch 2908\n",
      "test_train\n",
      "train mean loss=62262.37604166667\n",
      "test_test\n",
      "test mean loss=90007.7265625\n",
      "fin save.\n",
      "epoch 2909\n",
      "test_train\n",
      "train mean loss=63173.773046875\n",
      "test_test\n",
      "test mean loss=89792.25390625\n",
      "fin save.\n",
      "epoch 2910\n",
      "test_train\n",
      "train mean loss=62556.683333333334\n",
      "test_test\n",
      "test mean loss=89602.734375\n",
      "fin save.\n",
      "epoch 2911\n",
      "test_train\n",
      "train mean loss=62262.86705729167\n",
      "test_test\n",
      "test mean loss=89333.25390625\n",
      "fin save.\n",
      "epoch 2912\n",
      "test_train\n",
      "train mean loss=62863.676171875\n",
      "test_test\n",
      "test mean loss=89794.3828125\n",
      "fin save.\n",
      "epoch 2913\n",
      "test_train\n",
      "train mean loss=62333.854166666664\n",
      "test_test\n",
      "test mean loss=89882.703125\n",
      "fin save.\n",
      "epoch 2914\n",
      "test_train\n",
      "train mean loss=62039.34140625\n",
      "test_test\n",
      "test mean loss=89800.72265625\n",
      "fin save.\n",
      "epoch 2915\n",
      "test_train\n",
      "train mean loss=61341.00208333333\n",
      "test_test\n",
      "test mean loss=89895.7578125\n",
      "fin save.\n",
      "epoch 2916\n",
      "test_train\n",
      "train mean loss=61955.15416666667\n",
      "test_test\n",
      "test mean loss=89895.67578125\n",
      "fin save.\n",
      "epoch 2917\n",
      "test_train\n",
      "train mean loss=62243.372395833336\n",
      "test_test\n",
      "test mean loss=89645.35546875\n",
      "fin save.\n",
      "epoch 2918\n",
      "test_train\n",
      "train mean loss=60873.399088541664\n",
      "test_test\n",
      "test mean loss=89484.1640625\n",
      "fin save.\n",
      "epoch 2919\n",
      "test_train\n",
      "train mean loss=62483.65572916667\n",
      "test_test\n",
      "test mean loss=89454.7890625\n",
      "fin save.\n",
      "epoch 2920\n",
      "test_train\n",
      "train mean loss=62616.4125\n",
      "test_test\n",
      "test mean loss=89758.87890625\n",
      "fin save.\n",
      "epoch 2921\n",
      "test_train\n",
      "train mean loss=61433.72421875\n",
      "test_test\n",
      "test mean loss=89509.8359375\n",
      "fin save.\n",
      "epoch 2922\n",
      "test_train\n",
      "train mean loss=61895.462890625\n",
      "test_test\n",
      "test mean loss=89366.9140625\n",
      "fin save.\n",
      "epoch 2923\n",
      "test_train\n",
      "train mean loss=61713.937239583334\n",
      "test_test\n",
      "test mean loss=89357.6875\n",
      "fin save.\n",
      "epoch 2924\n",
      "test_train\n",
      "train mean loss=61851.30325520833\n",
      "test_test\n",
      "test mean loss=89187.6328125\n",
      "fin save.\n",
      "epoch 2925\n",
      "test_train\n",
      "train mean loss=62062.57083333333\n",
      "test_test\n",
      "test mean loss=89467.4375\n",
      "fin save.\n",
      "epoch 2926\n",
      "test_train\n",
      "train mean loss=61516.204427083336\n",
      "test_test\n",
      "test mean loss=89554.375\n",
      "fin save.\n",
      "epoch 2927\n",
      "test_train\n",
      "train mean loss=63035.23190104167\n",
      "test_test\n",
      "test mean loss=89477.46484375\n",
      "fin save.\n",
      "epoch 2928\n",
      "test_train\n",
      "train mean loss=62395.302994791666\n",
      "test_test\n",
      "test mean loss=89474.36328125\n",
      "fin save.\n",
      "epoch 2929\n",
      "test_train\n",
      "train mean loss=63151.167578125\n",
      "test_test\n",
      "test mean loss=89524.81640625\n",
      "fin save.\n",
      "epoch 2930\n",
      "test_train\n",
      "train mean loss=63035.32122395833\n",
      "test_test\n",
      "test mean loss=89542.98828125\n",
      "fin save.\n",
      "epoch 2931\n",
      "test_train\n",
      "train mean loss=62364.19192708333\n",
      "test_test\n",
      "test mean loss=89400.515625\n",
      "fin save.\n",
      "epoch 2932\n",
      "test_train\n",
      "train mean loss=62426.35260416667\n",
      "test_test\n",
      "test mean loss=89430.8203125\n",
      "fin save.\n",
      "epoch 2933\n",
      "test_train\n",
      "train mean loss=62027.84661458333\n",
      "test_test\n",
      "test mean loss=89611.6796875\n",
      "fin save.\n",
      "epoch 2934\n",
      "test_train\n",
      "train mean loss=61960.41979166667\n",
      "test_test\n",
      "test mean loss=89662.5390625\n",
      "fin save.\n",
      "epoch 2935\n",
      "test_train\n",
      "train mean loss=62018.871354166666\n",
      "test_test\n",
      "test mean loss=89657.8125\n",
      "fin save.\n",
      "epoch 2936\n",
      "test_train\n",
      "train mean loss=61455.56796875\n",
      "test_test\n",
      "test mean loss=89528.2578125\n",
      "fin save.\n",
      "epoch 2937\n",
      "test_train\n",
      "train mean loss=61744.147135416664\n",
      "test_test\n",
      "test mean loss=89668.828125\n",
      "fin save.\n",
      "epoch 2938\n",
      "test_train\n",
      "train mean loss=61408.71770833333\n",
      "test_test\n",
      "test mean loss=89492.375\n",
      "fin save.\n",
      "epoch 2939\n",
      "test_train\n",
      "train mean loss=61743.25\n",
      "test_test\n",
      "test mean loss=89392.98828125\n",
      "fin save.\n",
      "epoch 2940\n",
      "test_train\n",
      "train mean loss=62106.33059895833\n",
      "test_test\n",
      "test mean loss=89176.69921875\n",
      "fin save.\n",
      "epoch 2941\n",
      "test_train\n",
      "train mean loss=62891.18515625\n",
      "test_test\n",
      "test mean loss=89104.8359375\n",
      "fin save.\n",
      "epoch 2942\n",
      "test_train\n",
      "train mean loss=61894.127604166664\n",
      "test_test\n",
      "test mean loss=89339.6953125\n",
      "fin save.\n",
      "epoch 2943\n",
      "test_train\n",
      "train mean loss=63226.62395833333\n",
      "test_test\n",
      "test mean loss=89410.78125\n",
      "fin save.\n",
      "epoch 2944\n",
      "test_train\n",
      "train mean loss=62268.56497395833\n",
      "test_test\n",
      "test mean loss=89121.98046875\n",
      "fin save.\n",
      "epoch 2945\n",
      "test_train\n",
      "train mean loss=62616.63294270833\n",
      "test_test\n",
      "test mean loss=88978.74609375\n",
      "fin save.\n",
      "epoch 2946\n",
      "test_train\n",
      "train mean loss=63286.98151041667\n",
      "test_test\n",
      "test mean loss=89475.3046875\n",
      "fin save.\n",
      "epoch 2947\n",
      "test_train\n",
      "train mean loss=63308.33645833333\n",
      "test_test\n",
      "test mean loss=89355.72265625\n",
      "fin save.\n",
      "epoch 2948\n",
      "test_train\n",
      "train mean loss=62037.437239583334\n",
      "test_test\n",
      "test mean loss=89317.17578125\n",
      "fin save.\n",
      "epoch 2949\n",
      "test_train\n",
      "train mean loss=62154.02135416667\n",
      "test_test\n",
      "test mean loss=89177.9296875\n",
      "fin save.\n",
      "epoch 2950\n",
      "test_train\n",
      "train mean loss=61198.30807291667\n",
      "test_test\n",
      "test mean loss=89215.5078125\n",
      "fin save.\n",
      "epoch 2951\n",
      "test_train\n",
      "train mean loss=61979.81015625\n",
      "test_test\n",
      "test mean loss=89212.46484375\n",
      "fin save.\n",
      "epoch 2952\n",
      "test_train\n",
      "train mean loss=62458.59036458333\n",
      "test_test\n",
      "test mean loss=88988.98828125\n",
      "fin save.\n",
      "epoch 2953\n",
      "test_train\n",
      "train mean loss=61099.3375\n",
      "test_test\n",
      "test mean loss=88953.31640625\n",
      "fin save.\n",
      "epoch 2954\n",
      "test_train\n",
      "train mean loss=61736.43125\n",
      "test_test\n",
      "test mean loss=88862.484375\n",
      "fin save.\n",
      "epoch 2955\n",
      "test_train\n",
      "train mean loss=63212.16783854167\n",
      "test_test\n",
      "test mean loss=88991.30859375\n",
      "fin save.\n",
      "epoch 2956\n",
      "test_train\n",
      "train mean loss=62250.31536458333\n",
      "test_test\n",
      "test mean loss=89000.9453125\n",
      "fin save.\n",
      "epoch 2957\n",
      "test_train\n",
      "train mean loss=61523.21106770833\n",
      "test_test\n",
      "test mean loss=89005.44921875\n",
      "fin save.\n",
      "epoch 2958\n",
      "test_train\n",
      "train mean loss=62288.83359375\n",
      "test_test\n",
      "test mean loss=88896.8203125\n",
      "fin save.\n",
      "epoch 2959\n",
      "test_train\n",
      "train mean loss=63158.713541666664\n",
      "test_test\n",
      "test mean loss=89109.9375\n",
      "fin save.\n",
      "epoch 2960\n",
      "test_train\n",
      "train mean loss=62336.81822916667\n",
      "test_test\n",
      "test mean loss=89133.26953125\n",
      "fin save.\n",
      "epoch 2961\n",
      "test_train\n",
      "train mean loss=62156.594401041664\n",
      "test_test\n",
      "test mean loss=88847.328125\n",
      "fin save.\n",
      "epoch 2962\n",
      "test_train\n",
      "train mean loss=62176.75182291667\n",
      "test_test\n",
      "test mean loss=88708.4296875\n",
      "fin save.\n",
      "epoch 2963\n",
      "test_train\n",
      "train mean loss=62907.07239583333\n",
      "test_test\n",
      "test mean loss=88709.2890625\n",
      "fin save.\n",
      "epoch 2964\n",
      "test_train\n",
      "train mean loss=62122.422135416666\n",
      "test_test\n",
      "test mean loss=88862.90234375\n",
      "fin save.\n",
      "epoch 2965\n",
      "test_train\n",
      "train mean loss=63194.584375\n",
      "test_test\n",
      "test mean loss=89077.609375\n",
      "fin save.\n",
      "epoch 2966\n",
      "test_train\n",
      "train mean loss=61402.717578125\n",
      "test_test\n",
      "test mean loss=88912.54296875\n",
      "fin save.\n",
      "epoch 2967\n",
      "test_train\n",
      "train mean loss=61250.48125\n",
      "test_test\n",
      "test mean loss=89106.859375\n",
      "fin save.\n",
      "epoch 2968\n",
      "test_train\n",
      "train mean loss=61349.05572916667\n",
      "test_test\n",
      "test mean loss=89100.99609375\n",
      "fin save.\n",
      "epoch 2969\n",
      "test_train\n",
      "train mean loss=61826.62786458333\n",
      "test_test\n",
      "test mean loss=88890.31640625\n",
      "fin save.\n",
      "epoch 2970\n",
      "test_train\n",
      "train mean loss=61270.65729166667\n",
      "test_test\n",
      "test mean loss=88662.6953125\n",
      "fin save.\n",
      "epoch 2971\n",
      "test_train\n",
      "train mean loss=61847.9875\n",
      "test_test\n",
      "test mean loss=87816.015625\n",
      "fin save.\n",
      "epoch 2972\n",
      "test_train\n",
      "train mean loss=61957.04010416667\n",
      "test_test\n",
      "test mean loss=87803.09765625\n",
      "fin save.\n",
      "epoch 2973\n",
      "test_train\n",
      "train mean loss=62161.73515625\n",
      "test_test\n",
      "test mean loss=87895.53515625\n",
      "fin save.\n",
      "epoch 2974\n",
      "test_train\n",
      "train mean loss=61140.578385416666\n",
      "test_test\n",
      "test mean loss=87885.73828125\n",
      "fin save.\n",
      "epoch 2975\n",
      "test_train\n",
      "train mean loss=61912.15286458333\n",
      "test_test\n",
      "test mean loss=87953.640625\n",
      "fin save.\n",
      "epoch 2976\n",
      "test_train\n",
      "train mean loss=61832.98046875\n",
      "test_test\n",
      "test mean loss=87992.4453125\n",
      "fin save.\n",
      "epoch 2977\n",
      "test_train\n",
      "train mean loss=62791.335677083334\n",
      "test_test\n",
      "test mean loss=88181.0546875\n",
      "fin save.\n",
      "epoch 2978\n",
      "test_train\n",
      "train mean loss=61953.429947916666\n",
      "test_test\n",
      "test mean loss=88294.16015625\n",
      "fin save.\n",
      "epoch 2979\n",
      "test_train\n",
      "train mean loss=61228.33489583333\n",
      "test_test\n",
      "test mean loss=88022.3515625\n",
      "fin save.\n",
      "epoch 2980\n",
      "test_train\n",
      "train mean loss=61417.526171875\n",
      "test_test\n",
      "test mean loss=88293.9765625\n",
      "fin save.\n",
      "epoch 2981\n",
      "test_train\n",
      "train mean loss=61859.754166666666\n",
      "test_test\n",
      "test mean loss=88050.90234375\n",
      "fin save.\n",
      "epoch 2982\n",
      "test_train\n",
      "train mean loss=61896.81015625\n",
      "test_test\n",
      "test mean loss=88157.52734375\n",
      "fin save.\n",
      "epoch 2983\n",
      "test_train\n",
      "train mean loss=61358.71979166667\n",
      "test_test\n",
      "test mean loss=88118.25\n",
      "fin save.\n",
      "epoch 2984\n",
      "test_train\n",
      "train mean loss=61222.69973958333\n",
      "test_test\n",
      "test mean loss=88174.984375\n",
      "fin save.\n",
      "epoch 2985\n",
      "test_train\n",
      "train mean loss=62081.75729166667\n",
      "test_test\n",
      "test mean loss=88041.17578125\n",
      "fin save.\n",
      "epoch 2986\n",
      "test_train\n",
      "train mean loss=60654.980729166666\n",
      "test_test\n",
      "test mean loss=88660.4453125\n",
      "fin save.\n",
      "epoch 2987\n",
      "test_train\n",
      "train mean loss=61871.06354166667\n",
      "test_test\n",
      "test mean loss=88564.90234375\n",
      "fin save.\n",
      "epoch 2988\n",
      "test_train\n",
      "train mean loss=62064.24270833333\n",
      "test_test\n",
      "test mean loss=88579.46484375\n",
      "fin save.\n",
      "epoch 2989\n",
      "test_train\n",
      "train mean loss=62448.531510416666\n",
      "test_test\n",
      "test mean loss=87913.61328125\n",
      "fin save.\n",
      "epoch 2990\n",
      "test_train\n",
      "train mean loss=61792.90572916667\n",
      "test_test\n",
      "test mean loss=88072.328125\n",
      "fin save.\n",
      "epoch 2991\n",
      "test_train\n",
      "train mean loss=61587.210677083334\n",
      "test_test\n",
      "test mean loss=88039.91015625\n",
      "fin save.\n",
      "epoch 2992\n",
      "test_train\n",
      "train mean loss=62399.102213541664\n",
      "test_test\n",
      "test mean loss=87889.9609375\n",
      "fin save.\n",
      "epoch 2993\n",
      "test_train\n",
      "train mean loss=61753.8734375\n",
      "test_test\n",
      "test mean loss=87991.76953125\n",
      "fin save.\n",
      "epoch 2994\n",
      "test_train\n",
      "train mean loss=62912.109375\n",
      "test_test\n",
      "test mean loss=87591.30859375\n",
      "fin save.\n",
      "epoch 2995\n",
      "test_train\n",
      "train mean loss=62111.981770833336\n",
      "test_test\n",
      "test mean loss=87681.5078125\n",
      "fin save.\n",
      "epoch 2996\n",
      "test_train\n",
      "train mean loss=62601.540625\n",
      "test_test\n",
      "test mean loss=87344.12890625\n",
      "fin save.\n",
      "epoch 2997\n",
      "test_train\n",
      "train mean loss=62701.35729166667\n",
      "test_test\n",
      "test mean loss=87859.51953125\n",
      "fin save.\n",
      "epoch 2998\n",
      "test_train\n",
      "train mean loss=61530.57213541667\n",
      "test_test\n",
      "test mean loss=87326.79296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fin save.\n",
      "epoch 2999\n",
      "test_train\n",
      "train mean loss=60537.94609375\n",
      "test_test\n",
      "test mean loss=87821.6015625\n",
      "fin save.\n",
      "epoch 3000\n",
      "test_train\n",
      "train mean loss=62246.533984375\n",
      "test_test\n",
      "test mean loss=87566.265625\n",
      "fin save.\n",
      "epoch 3001\n",
      "test_train\n",
      "train mean loss=61146.92369791667\n",
      "test_test\n",
      "test mean loss=88113.47265625\n",
      "fin save.\n",
      "epoch 3002\n",
      "test_train\n",
      "train mean loss=61539.8015625\n",
      "test_test\n",
      "test mean loss=88139.203125\n",
      "fin save.\n",
      "epoch 3003\n",
      "test_train\n",
      "train mean loss=61756.959635416664\n",
      "test_test\n",
      "test mean loss=88000.6953125\n",
      "fin save.\n",
      "epoch 3004\n",
      "test_train\n",
      "train mean loss=61707.91692708333\n",
      "test_test\n",
      "test mean loss=87761.8828125\n",
      "fin save.\n",
      "epoch 3005\n",
      "test_train\n",
      "train mean loss=61871.805078125\n",
      "test_test\n",
      "test mean loss=88057.4453125\n",
      "fin save.\n",
      "epoch 3006\n",
      "test_train\n",
      "train mean loss=61742.137890625\n",
      "test_test\n",
      "test mean loss=87774.47265625\n",
      "fin save.\n",
      "epoch 3007\n",
      "test_train\n",
      "train mean loss=61696.41197916667\n",
      "test_test\n",
      "test mean loss=87794.328125\n",
      "fin save.\n",
      "epoch 3008\n",
      "test_train\n",
      "train mean loss=62145.183984375\n",
      "test_test\n",
      "test mean loss=87957.234375\n",
      "fin save.\n",
      "epoch 3009\n",
      "test_train\n",
      "train mean loss=61964.572916666664\n",
      "test_test\n",
      "test mean loss=87732.375\n",
      "fin save.\n",
      "epoch 3010\n",
      "test_train\n",
      "train mean loss=63279.487109375\n",
      "test_test\n",
      "test mean loss=88067.1484375\n",
      "fin save.\n",
      "epoch 3011\n",
      "test_train\n",
      "train mean loss=61981.07903645833\n",
      "test_test\n",
      "test mean loss=88266.41015625\n",
      "fin save.\n",
      "epoch 3012\n",
      "test_train\n",
      "train mean loss=62497.733984375\n",
      "test_test\n",
      "test mean loss=88359.3828125\n",
      "fin save.\n",
      "epoch 3013\n",
      "test_train\n",
      "train mean loss=61959.35989583333\n",
      "test_test\n",
      "test mean loss=88379.33203125\n",
      "fin save.\n",
      "epoch 3014\n",
      "test_train\n",
      "train mean loss=62309.73619791667\n",
      "test_test\n",
      "test mean loss=88316.83984375\n",
      "fin save.\n",
      "epoch 3015\n",
      "test_train\n",
      "train mean loss=62998.64010416667\n",
      "test_test\n",
      "test mean loss=88318.0234375\n",
      "fin save.\n",
      "epoch 3016\n",
      "test_train\n",
      "train mean loss=61649.97278645833\n",
      "test_test\n",
      "test mean loss=88333.8046875\n",
      "fin save.\n",
      "epoch 3017\n",
      "test_train\n",
      "train mean loss=61800.519791666666\n",
      "test_test\n",
      "test mean loss=88304.39453125\n",
      "fin save.\n",
      "epoch 3018\n",
      "test_train\n",
      "train mean loss=61767.906510416666\n",
      "test_test\n",
      "test mean loss=88454.84765625\n",
      "fin save.\n",
      "epoch 3019\n",
      "test_train\n",
      "train mean loss=62156.557291666664\n",
      "test_test\n",
      "test mean loss=88188.8671875\n",
      "fin save.\n",
      "epoch 3020\n",
      "test_train\n",
      "train mean loss=62160.43372395833\n",
      "test_test\n",
      "test mean loss=88495.2109375\n",
      "fin save.\n",
      "epoch 3021\n",
      "test_train\n",
      "train mean loss=61962.37838541667\n",
      "test_test\n",
      "test mean loss=88551.83203125\n",
      "fin save.\n",
      "epoch 3022\n",
      "test_train\n",
      "train mean loss=62186.421614583334\n",
      "test_test\n",
      "test mean loss=88170.91015625\n",
      "fin save.\n",
      "epoch 3023\n",
      "test_train\n",
      "train mean loss=61866.7390625\n",
      "test_test\n",
      "test mean loss=88073.2109375\n",
      "fin save.\n",
      "epoch 3024\n",
      "test_train\n",
      "train mean loss=61789.857161458334\n",
      "test_test\n",
      "test mean loss=88550.7890625\n",
      "fin save.\n",
      "epoch 3025\n",
      "test_train\n",
      "train mean loss=61337.79114583333\n",
      "test_test\n",
      "test mean loss=88403.6328125\n",
      "fin save.\n",
      "epoch 3026\n",
      "test_train\n",
      "train mean loss=62508.984114583334\n",
      "test_test\n",
      "test mean loss=88162.6015625\n",
      "fin save.\n",
      "epoch 3027\n",
      "test_train\n",
      "train mean loss=61489.402083333334\n",
      "test_test\n",
      "test mean loss=88392.82421875\n",
      "fin save.\n",
      "epoch 3028\n",
      "test_train\n",
      "train mean loss=61582.341145833336\n",
      "test_test\n",
      "test mean loss=88312.63671875\n",
      "fin save.\n",
      "epoch 3029\n",
      "test_train\n",
      "train mean loss=62516.67526041667\n",
      "test_test\n",
      "test mean loss=88368.46484375\n",
      "fin save.\n",
      "epoch 3030\n",
      "test_train\n",
      "train mean loss=60803.799479166664\n",
      "test_test\n",
      "test mean loss=88613.0625\n",
      "fin save.\n",
      "epoch 3031\n",
      "test_train\n",
      "train mean loss=61264.981640625\n",
      "test_test\n",
      "test mean loss=88590.359375\n",
      "fin save.\n",
      "epoch 3032\n",
      "test_train\n",
      "train mean loss=61856.782552083336\n",
      "test_test\n",
      "test mean loss=88361.94140625\n",
      "fin save.\n",
      "epoch 3033\n",
      "test_train\n",
      "train mean loss=61199.668229166666\n",
      "test_test\n",
      "test mean loss=88375.29296875\n",
      "fin save.\n",
      "epoch 3034\n",
      "test_train\n",
      "train mean loss=61793.514322916664\n",
      "test_test\n",
      "test mean loss=88617.6328125\n",
      "fin save.\n",
      "epoch 3035\n",
      "test_train\n",
      "train mean loss=61576.28463541667\n",
      "test_test\n",
      "test mean loss=88440.9140625\n",
      "fin save.\n",
      "epoch 3036\n",
      "test_train\n",
      "train mean loss=62153.588151041666\n",
      "test_test\n",
      "test mean loss=88311.51953125\n",
      "fin save.\n",
      "epoch 3037\n",
      "test_train\n",
      "train mean loss=61656.81197916667\n",
      "test_test\n",
      "test mean loss=88333.34765625\n",
      "fin save.\n",
      "epoch 3038\n",
      "test_train\n",
      "train mean loss=61393.961588541664\n",
      "test_test\n",
      "test mean loss=88162.73046875\n",
      "fin save.\n",
      "epoch 3039\n",
      "test_train\n",
      "train mean loss=62263.21692708333\n",
      "test_test\n",
      "test mean loss=88345.34765625\n",
      "fin save.\n",
      "epoch 3040\n",
      "test_train\n",
      "train mean loss=62100.00078125\n",
      "test_test\n",
      "test mean loss=88309.43359375\n",
      "fin save.\n",
      "epoch 3041\n",
      "test_train\n",
      "train mean loss=61843.6984375\n",
      "test_test\n",
      "test mean loss=88293.3125\n",
      "fin save.\n",
      "epoch 3042\n",
      "test_train\n",
      "train mean loss=61801.62421875\n",
      "test_test\n",
      "test mean loss=87900.1484375\n",
      "fin save.\n",
      "epoch 3043\n",
      "test_train\n",
      "train mean loss=61669.5203125\n",
      "test_test\n",
      "test mean loss=88015.41796875\n",
      "fin save.\n",
      "epoch 3044\n",
      "test_train\n",
      "train mean loss=62415.739583333336\n",
      "test_test\n",
      "test mean loss=88472.51953125\n",
      "fin save.\n",
      "epoch 3045\n",
      "test_train\n",
      "train mean loss=61785.303125\n",
      "test_test\n",
      "test mean loss=88107.63671875\n",
      "fin save.\n",
      "epoch 3046\n",
      "test_train\n",
      "train mean loss=62090.22421875\n",
      "test_test\n",
      "test mean loss=88163.82421875\n",
      "fin save.\n",
      "epoch 3047\n",
      "test_train\n",
      "train mean loss=61983.36419270833\n",
      "test_test\n",
      "test mean loss=88050.359375\n",
      "fin save.\n",
      "epoch 3048\n",
      "test_train\n",
      "train mean loss=62437.405598958336\n",
      "test_test\n",
      "test mean loss=88168.57421875\n",
      "fin save.\n",
      "epoch 3049\n",
      "test_train\n",
      "train mean loss=61775.707291666666\n",
      "test_test\n",
      "test mean loss=88212.5390625\n",
      "fin save.\n",
      "epoch 3050\n",
      "test_train\n",
      "train mean loss=61070.54375\n",
      "test_test\n",
      "test mean loss=88311.9609375\n",
      "fin save.\n",
      "epoch 3051\n",
      "test_train\n",
      "train mean loss=61819.40182291667\n",
      "test_test\n",
      "test mean loss=88161.734375\n",
      "fin save.\n",
      "epoch 3052\n",
      "test_train\n",
      "train mean loss=61313.0015625\n",
      "test_test\n",
      "test mean loss=88149.58984375\n",
      "fin save.\n",
      "epoch 3053\n",
      "test_train\n",
      "train mean loss=62908.53411458333\n",
      "test_test\n",
      "test mean loss=88053.4140625\n",
      "fin save.\n",
      "epoch 3054\n",
      "test_train\n",
      "train mean loss=61679.38880208333\n",
      "test_test\n",
      "test mean loss=88143.8125\n",
      "fin save.\n",
      "epoch 3055\n",
      "test_train\n",
      "train mean loss=62390.33359375\n",
      "test_test\n",
      "test mean loss=88009.7421875\n",
      "fin save.\n",
      "epoch 3056\n",
      "test_train\n",
      "train mean loss=61431.922135416666\n",
      "test_test\n",
      "test mean loss=88223.0078125\n",
      "fin save.\n",
      "epoch 3057\n",
      "test_train\n",
      "train mean loss=61117.97838541667\n",
      "test_test\n",
      "test mean loss=88426.8828125\n",
      "fin save.\n",
      "epoch 3058\n",
      "test_train\n",
      "train mean loss=61300.625260416666\n",
      "test_test\n",
      "test mean loss=88520.7109375\n",
      "fin save.\n",
      "epoch 3059\n",
      "test_train\n",
      "train mean loss=62161.394140625\n",
      "test_test\n",
      "test mean loss=88112.9453125\n",
      "fin save.\n",
      "epoch 3060\n",
      "test_train\n",
      "train mean loss=62523.73776041667\n",
      "test_test\n",
      "test mean loss=88210.84375\n",
      "fin save.\n",
      "epoch 3061\n",
      "test_train\n",
      "train mean loss=61750.746875\n",
      "test_test\n",
      "test mean loss=88336.015625\n",
      "fin save.\n",
      "epoch 3062\n",
      "test_train\n",
      "train mean loss=61194.21666666667\n",
      "test_test\n",
      "test mean loss=88345.375\n",
      "fin save.\n",
      "epoch 3063\n",
      "test_train\n",
      "train mean loss=61297.51354166667\n",
      "test_test\n",
      "test mean loss=88466.71875\n",
      "fin save.\n",
      "epoch 3064\n",
      "test_train\n",
      "train mean loss=62239.531510416666\n",
      "test_test\n",
      "test mean loss=88457.265625\n",
      "fin save.\n",
      "epoch 3065\n",
      "test_train\n",
      "train mean loss=62547.54765625\n",
      "test_test\n",
      "test mean loss=88491.140625\n",
      "fin save.\n",
      "epoch 3066\n",
      "test_train\n",
      "train mean loss=62531.91796875\n",
      "test_test\n",
      "test mean loss=88516.9375\n",
      "fin save.\n",
      "epoch 3067\n",
      "test_train\n",
      "train mean loss=61961.48294270833\n",
      "test_test\n",
      "test mean loss=88350.23046875\n",
      "fin save.\n",
      "epoch 3068\n",
      "test_train\n",
      "train mean loss=61403.277083333334\n",
      "test_test\n",
      "test mean loss=88620.5546875\n",
      "fin save.\n",
      "epoch 3069\n",
      "test_train\n",
      "train mean loss=62312.99947916667\n",
      "test_test\n",
      "test mean loss=88781.07421875\n",
      "fin save.\n",
      "epoch 3070\n",
      "test_train\n",
      "train mean loss=61471.790625\n",
      "test_test\n",
      "test mean loss=88482.9375\n",
      "fin save.\n",
      "epoch 3071\n",
      "test_train\n",
      "train mean loss=61954.252604166664\n",
      "test_test\n",
      "test mean loss=88331.078125\n",
      "fin save.\n",
      "epoch 3072\n",
      "test_train\n",
      "train mean loss=62501.9703125\n",
      "test_test\n",
      "test mean loss=88264.71484375\n",
      "fin save.\n",
      "epoch 3073\n",
      "test_train\n",
      "train mean loss=63229.56354166667\n",
      "test_test\n",
      "test mean loss=88343.75\n",
      "fin save.\n",
      "epoch 3074\n",
      "test_train\n",
      "train mean loss=62165.68359375\n",
      "test_test\n",
      "test mean loss=88289.62109375\n",
      "fin save.\n",
      "epoch 3075\n",
      "test_train\n",
      "train mean loss=62271.44739583333\n",
      "test_test\n",
      "test mean loss=88242.8046875\n",
      "fin save.\n",
      "epoch 3076\n",
      "test_train\n",
      "train mean loss=61465.498697916664\n",
      "test_test\n",
      "test mean loss=88259.22265625\n",
      "fin save.\n",
      "epoch 3077\n",
      "test_train\n",
      "train mean loss=62644.14609375\n",
      "test_test\n",
      "test mean loss=88351.48828125\n",
      "fin save.\n",
      "epoch 3078\n",
      "test_train\n",
      "train mean loss=61873.7171875\n",
      "test_test\n",
      "test mean loss=88365.82421875\n",
      "fin save.\n",
      "epoch 3079\n",
      "test_train\n",
      "train mean loss=61825.0625\n",
      "test_test\n",
      "test mean loss=88311.41796875\n",
      "fin save.\n",
      "epoch 3080\n",
      "test_train\n",
      "train mean loss=62052.07721354167\n",
      "test_test\n",
      "test mean loss=88234.421875\n",
      "fin save.\n",
      "epoch 3081\n",
      "test_train\n",
      "train mean loss=62652.9515625\n",
      "test_test\n",
      "test mean loss=88552.08984375\n",
      "fin save.\n",
      "epoch 3082\n",
      "test_train\n",
      "train mean loss=62414.990885416664\n",
      "test_test\n",
      "test mean loss=88492.68359375\n",
      "fin save.\n",
      "epoch 3083\n",
      "test_train\n",
      "train mean loss=62395.437760416666\n",
      "test_test\n",
      "test mean loss=88544.578125\n",
      "fin save.\n",
      "epoch 3084\n",
      "test_train\n",
      "train mean loss=62204.101171875\n",
      "test_test\n",
      "test mean loss=88346.546875\n",
      "fin save.\n",
      "epoch 3085\n",
      "test_train\n",
      "train mean loss=61956.1109375\n",
      "test_test\n",
      "test mean loss=88379.06640625\n",
      "fin save.\n",
      "epoch 3086\n",
      "test_train\n",
      "train mean loss=61748.43020833333\n",
      "test_test\n",
      "test mean loss=88273.13671875\n",
      "fin save.\n",
      "epoch 3087\n",
      "test_train\n",
      "train mean loss=62679.22122395833\n",
      "test_test\n",
      "test mean loss=88241.765625\n",
      "fin save.\n",
      "epoch 3088\n",
      "test_train\n",
      "train mean loss=62306.83489583333\n",
      "test_test\n",
      "test mean loss=88504.83203125\n",
      "fin save.\n",
      "epoch 3089\n",
      "test_train\n",
      "train mean loss=62105.696614583336\n",
      "test_test\n",
      "test mean loss=88667.78515625\n",
      "fin save.\n",
      "epoch 3090\n",
      "test_train\n",
      "train mean loss=62058.928385416664\n",
      "test_test\n",
      "test mean loss=88552.3359375\n",
      "fin save.\n",
      "epoch 3091\n",
      "test_train\n",
      "train mean loss=61498.42760416667\n",
      "test_test\n",
      "test mean loss=88433.859375\n",
      "fin save.\n",
      "epoch 3092\n",
      "test_train\n",
      "train mean loss=62333.8953125\n",
      "test_test\n",
      "test mean loss=88542.5390625\n",
      "fin save.\n",
      "epoch 3093\n",
      "test_train\n",
      "train mean loss=62508.31875\n",
      "test_test\n",
      "test mean loss=88686.96484375\n",
      "fin save.\n",
      "epoch 3094\n",
      "test_train\n",
      "train mean loss=61962.693359375\n",
      "test_test\n",
      "test mean loss=89066.66015625\n",
      "fin save.\n",
      "epoch 3095\n",
      "test_train\n",
      "train mean loss=61811.50234375\n",
      "test_test\n",
      "test mean loss=88793.96484375\n",
      "fin save.\n",
      "epoch 3096\n",
      "test_train\n",
      "train mean loss=61700.42981770833\n",
      "test_test\n",
      "test mean loss=88577.09765625\n",
      "fin save.\n",
      "epoch 3097\n",
      "test_train\n",
      "train mean loss=62636.5453125\n",
      "test_test\n",
      "test mean loss=88571.046875\n",
      "fin save.\n",
      "epoch 3098\n",
      "test_train\n",
      "train mean loss=62100.041666666664\n",
      "test_test\n",
      "test mean loss=88509.375\n",
      "fin save.\n",
      "epoch 3099\n",
      "test_train\n",
      "train mean loss=63023.91809895833\n",
      "test_test\n",
      "test mean loss=88604.8125\n",
      "fin save.\n",
      "epoch 3100\n",
      "test_train\n",
      "train mean loss=62297.299088541666\n",
      "test_test\n",
      "test mean loss=88585.7578125\n",
      "fin save.\n",
      "epoch 3101\n",
      "test_train\n",
      "train mean loss=61939.455729166664\n",
      "test_test\n",
      "test mean loss=88543.04296875\n",
      "fin save.\n",
      "epoch 3102\n",
      "test_train\n",
      "train mean loss=62284.132552083334\n",
      "test_test\n",
      "test mean loss=88513.515625\n",
      "fin save.\n",
      "epoch 3103\n",
      "test_train\n",
      "train mean loss=62222.15390625\n",
      "test_test\n",
      "test mean loss=88346.8828125\n",
      "fin save.\n",
      "epoch 3104\n",
      "test_train\n",
      "train mean loss=61599.25989583333\n",
      "test_test\n",
      "test mean loss=88488.0234375\n",
      "fin save.\n",
      "epoch 3105\n",
      "test_train\n",
      "train mean loss=62294.31354166667\n",
      "test_test\n",
      "test mean loss=88417.59765625\n",
      "fin save.\n",
      "epoch 3106\n",
      "test_train\n",
      "train mean loss=62819.572916666664\n",
      "test_test\n",
      "test mean loss=88411.5078125\n",
      "fin save.\n",
      "epoch 3107\n",
      "test_train\n",
      "train mean loss=61924.41197916667\n",
      "test_test\n",
      "test mean loss=88233.25\n",
      "fin save.\n",
      "epoch 3108\n",
      "test_train\n",
      "train mean loss=62495.53606770833\n",
      "test_test\n",
      "test mean loss=88307.03125\n",
      "fin save.\n",
      "epoch 3109\n",
      "test_train\n",
      "train mean loss=62903.558854166666\n",
      "test_test\n",
      "test mean loss=88524.01953125\n",
      "fin save.\n",
      "epoch 3110\n",
      "test_train\n",
      "train mean loss=62825.39765625\n",
      "test_test\n",
      "test mean loss=88257.94140625\n",
      "fin save.\n",
      "epoch 3111\n",
      "test_train\n",
      "train mean loss=62082.257421875\n",
      "test_test\n",
      "test mean loss=88161.08984375\n",
      "fin save.\n",
      "epoch 3112\n",
      "test_train\n",
      "train mean loss=61810.069010416664\n",
      "test_test\n",
      "test mean loss=88246.84375\n",
      "fin save.\n",
      "epoch 3113\n",
      "test_train\n",
      "train mean loss=62096.41979166667\n",
      "test_test\n",
      "test mean loss=88345.4609375\n",
      "fin save.\n",
      "epoch 3114\n",
      "test_train\n",
      "train mean loss=62104.033854166664\n",
      "test_test\n",
      "test mean loss=88298.16796875\n",
      "fin save.\n",
      "epoch 3115\n",
      "test_train\n",
      "train mean loss=62225.864583333336\n",
      "test_test\n",
      "test mean loss=88397.75390625\n",
      "fin save.\n",
      "epoch 3116\n",
      "test_train\n",
      "train mean loss=62706.950520833336\n",
      "test_test\n",
      "test mean loss=88095.04296875\n",
      "fin save.\n",
      "epoch 3117\n",
      "test_train\n",
      "train mean loss=62400.854296875\n",
      "test_test\n",
      "test mean loss=88252.33203125\n",
      "fin save.\n",
      "epoch 3118\n",
      "test_train\n",
      "train mean loss=61345.823958333334\n",
      "test_test\n",
      "test mean loss=88239.04296875\n",
      "fin save.\n",
      "epoch 3119\n",
      "test_train\n",
      "train mean loss=62192.97161458333\n",
      "test_test\n",
      "test mean loss=88930.66796875\n",
      "fin save.\n",
      "epoch 3120\n",
      "test_train\n",
      "train mean loss=61218.13489583333\n",
      "test_test\n",
      "test mean loss=88965.1640625\n",
      "fin save.\n",
      "epoch 3121\n",
      "test_train\n",
      "train mean loss=61492.140885416666\n",
      "test_test\n",
      "test mean loss=89077.9453125\n",
      "fin save.\n",
      "epoch 3122\n",
      "test_train\n",
      "train mean loss=63133.513671875\n",
      "test_test\n",
      "test mean loss=89119.59765625\n",
      "fin save.\n",
      "epoch 3123\n",
      "test_train\n",
      "train mean loss=62425.075911458334\n",
      "test_test\n",
      "test mean loss=89005.35546875\n",
      "fin save.\n",
      "epoch 3124\n",
      "test_train\n",
      "train mean loss=63040.480208333334\n",
      "test_test\n",
      "test mean loss=89487.5\n",
      "fin save.\n",
      "epoch 3125\n",
      "test_train\n",
      "train mean loss=60888.1640625\n",
      "test_test\n",
      "test mean loss=89032.859375\n",
      "fin save.\n",
      "epoch 3126\n",
      "test_train\n",
      "train mean loss=62132.829427083336\n",
      "test_test\n",
      "test mean loss=88949.0\n",
      "fin save.\n",
      "epoch 3127\n",
      "test_train\n",
      "train mean loss=62083.139453125\n",
      "test_test\n",
      "test mean loss=88922.4140625\n",
      "fin save.\n",
      "epoch 3128\n",
      "test_train\n",
      "train mean loss=62452.97578125\n",
      "test_test\n",
      "test mean loss=88835.30078125\n",
      "fin save.\n",
      "epoch 3129\n",
      "test_train\n",
      "train mean loss=61716.124739583334\n",
      "test_test\n",
      "test mean loss=88962.890625\n",
      "fin save.\n",
      "epoch 3130\n",
      "test_train\n",
      "train mean loss=62509.63098958333\n",
      "test_test\n",
      "test mean loss=89267.3046875\n",
      "fin save.\n",
      "epoch 3131\n",
      "test_train\n",
      "train mean loss=62238.70234375\n",
      "test_test\n",
      "test mean loss=88206.58984375\n",
      "fin save.\n",
      "epoch 3132\n",
      "test_train\n",
      "train mean loss=61601.33385416667\n",
      "test_test\n",
      "test mean loss=88175.7109375\n",
      "fin save.\n",
      "epoch 3133\n",
      "test_train\n",
      "train mean loss=60186.468489583334\n",
      "test_test\n",
      "test mean loss=88214.625\n",
      "fin save.\n",
      "epoch 3134\n",
      "test_train\n",
      "train mean loss=61418.146223958334\n",
      "test_test\n",
      "test mean loss=88055.20703125\n",
      "fin save.\n",
      "epoch 3135\n",
      "test_train\n",
      "train mean loss=61707.669270833336\n",
      "test_test\n",
      "test mean loss=88427.04296875\n",
      "fin save.\n",
      "epoch 3136\n",
      "test_train\n",
      "train mean loss=62369.08489583333\n",
      "test_test\n",
      "test mean loss=88649.90234375\n",
      "fin save.\n",
      "epoch 3137\n",
      "test_train\n",
      "train mean loss=63002.89270833333\n",
      "test_test\n",
      "test mean loss=88737.23828125\n",
      "fin save.\n",
      "epoch 3138\n",
      "test_train\n",
      "train mean loss=61708.546484375\n",
      "test_test\n",
      "test mean loss=88837.421875\n",
      "fin save.\n",
      "epoch 3139\n",
      "test_train\n",
      "train mean loss=60966.87786458333\n",
      "test_test\n",
      "test mean loss=88835.50390625\n",
      "fin save.\n",
      "epoch 3140\n",
      "test_train\n",
      "train mean loss=62028.51901041667\n",
      "test_test\n",
      "test mean loss=88921.45703125\n",
      "fin save.\n",
      "epoch 3141\n",
      "test_train\n",
      "train mean loss=62846.746354166666\n",
      "test_test\n",
      "test mean loss=88454.83984375\n",
      "fin save.\n",
      "epoch 3142\n",
      "test_train\n",
      "train mean loss=61913.616927083334\n",
      "test_test\n",
      "test mean loss=88218.76953125\n",
      "fin save.\n",
      "epoch 3143\n",
      "test_train\n",
      "train mean loss=61903.26328125\n",
      "test_test\n",
      "test mean loss=88443.48046875\n",
      "fin save.\n",
      "epoch 3144\n",
      "test_train\n",
      "train mean loss=62136.59557291667\n",
      "test_test\n",
      "test mean loss=88342.1796875\n",
      "fin save.\n",
      "epoch 3145\n",
      "test_train\n",
      "train mean loss=62211.72864583333\n",
      "test_test\n",
      "test mean loss=88381.67578125\n",
      "fin save.\n",
      "epoch 3146\n",
      "test_train\n",
      "train mean loss=61784.70208333333\n",
      "test_test\n",
      "test mean loss=88296.2734375\n",
      "fin save.\n",
      "epoch 3147\n",
      "test_train\n",
      "train mean loss=61806.767578125\n",
      "test_test\n",
      "test mean loss=88236.47265625\n",
      "fin save.\n",
      "epoch 3148\n",
      "test_train\n",
      "train mean loss=62062.661458333336\n",
      "test_test\n",
      "test mean loss=88260.23046875\n",
      "fin save.\n",
      "epoch 3149\n",
      "test_train\n",
      "train mean loss=62525.53177083333\n",
      "test_test\n",
      "test mean loss=88306.75390625\n",
      "fin save.\n",
      "epoch 3150\n",
      "test_train\n",
      "train mean loss=61355.802473958334\n",
      "test_test\n",
      "test mean loss=88360.796875\n",
      "fin save.\n",
      "epoch 3151\n",
      "test_train\n",
      "train mean loss=62319.61666666667\n",
      "test_test\n",
      "test mean loss=88234.33984375\n",
      "fin save.\n",
      "epoch 3152\n",
      "test_train\n",
      "train mean loss=61664.9515625\n",
      "test_test\n",
      "test mean loss=88092.91015625\n",
      "fin save.\n",
      "epoch 3153\n",
      "test_train\n",
      "train mean loss=63061.816145833334\n",
      "test_test\n",
      "test mean loss=88292.04296875\n",
      "fin save.\n",
      "epoch 3154\n",
      "test_train\n",
      "train mean loss=62094.97760416667\n",
      "test_test\n",
      "test mean loss=88369.03125\n",
      "fin save.\n",
      "epoch 3155\n",
      "test_train\n",
      "train mean loss=61916.1703125\n",
      "test_test\n",
      "test mean loss=88371.7890625\n",
      "fin save.\n",
      "epoch 3156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_train\n",
      "train mean loss=61008.226822916666\n",
      "test_test\n",
      "test mean loss=88303.875\n",
      "fin save.\n",
      "epoch 3157\n",
      "test_train\n",
      "train mean loss=62347.980208333334\n",
      "test_test\n",
      "test mean loss=88144.82421875\n",
      "fin save.\n",
      "epoch 3158\n",
      "test_train\n",
      "train mean loss=61615.32890625\n",
      "test_test\n",
      "test mean loss=88153.44140625\n",
      "fin save.\n",
      "epoch 3159\n",
      "test_train\n",
      "train mean loss=61601.594010416666\n",
      "test_test\n",
      "test mean loss=88414.33203125\n",
      "fin save.\n",
      "epoch 3160\n",
      "test_train\n",
      "train mean loss=62548.126692708334\n",
      "test_test\n",
      "test mean loss=88288.19140625\n",
      "fin save.\n",
      "epoch 3161\n",
      "test_train\n",
      "train mean loss=62121.0234375\n",
      "test_test\n",
      "test mean loss=88077.04296875\n",
      "fin save.\n",
      "epoch 3162\n",
      "test_train\n",
      "train mean loss=63445.03372395833\n",
      "test_test\n",
      "test mean loss=88030.140625\n",
      "fin save.\n",
      "epoch 3163\n",
      "test_train\n",
      "train mean loss=61807.88671875\n",
      "test_test\n",
      "test mean loss=88306.31640625\n",
      "fin save.\n",
      "epoch 3164\n",
      "test_train\n",
      "train mean loss=61918.708333333336\n",
      "test_test\n",
      "test mean loss=88407.24609375\n",
      "fin save.\n",
      "epoch 3165\n",
      "test_train\n",
      "train mean loss=62674.839453125\n",
      "test_test\n",
      "test mean loss=87953.734375\n",
      "fin save.\n",
      "epoch 3166\n",
      "test_train\n",
      "train mean loss=62374.29609375\n",
      "test_test\n",
      "test mean loss=87969.71875\n",
      "fin save.\n",
      "epoch 3167\n",
      "test_train\n",
      "train mean loss=61773.66067708333\n",
      "test_test\n",
      "test mean loss=88139.37890625\n",
      "fin save.\n",
      "epoch 3168\n",
      "test_train\n",
      "train mean loss=61387.94479166667\n",
      "test_test\n",
      "test mean loss=88214.24609375\n",
      "fin save.\n",
      "epoch 3169\n",
      "test_train\n",
      "train mean loss=61852.753515625\n",
      "test_test\n",
      "test mean loss=88153.62890625\n",
      "fin save.\n",
      "epoch 3170\n",
      "test_train\n",
      "train mean loss=62177.53463541667\n",
      "test_test\n",
      "test mean loss=88033.52734375\n",
      "fin save.\n",
      "epoch 3171\n",
      "test_train\n",
      "train mean loss=62553.17890625\n",
      "test_test\n",
      "test mean loss=88105.10546875\n",
      "fin save.\n",
      "epoch 3172\n",
      "test_train\n",
      "train mean loss=61331.81692708333\n",
      "test_test\n",
      "test mean loss=88098.09375\n",
      "fin save.\n",
      "epoch 3173\n",
      "test_train\n",
      "train mean loss=61824.61484375\n",
      "test_test\n",
      "test mean loss=87968.17578125\n",
      "fin save.\n",
      "epoch 3174\n",
      "test_train\n",
      "train mean loss=61454.961197916666\n",
      "test_test\n",
      "test mean loss=88047.9453125\n",
      "fin save.\n",
      "epoch 3175\n",
      "test_train\n",
      "train mean loss=62610.63098958333\n",
      "test_test\n",
      "test mean loss=87973.00390625\n",
      "fin save.\n",
      "epoch 3176\n",
      "test_train\n",
      "train mean loss=61724.69388020833\n",
      "test_test\n",
      "test mean loss=88007.8671875\n",
      "fin save.\n",
      "epoch 3177\n",
      "test_train\n",
      "train mean loss=61923.936848958336\n",
      "test_test\n",
      "test mean loss=88048.63671875\n",
      "fin save.\n",
      "epoch 3178\n",
      "test_train\n",
      "train mean loss=61376.62708333333\n",
      "test_test\n",
      "test mean loss=87857.765625\n",
      "fin save.\n",
      "epoch 3179\n",
      "test_train\n",
      "train mean loss=62327.28359375\n",
      "test_test\n",
      "test mean loss=87933.55859375\n",
      "fin save.\n",
      "epoch 3180\n",
      "test_train\n",
      "train mean loss=62116.644140625\n",
      "test_test\n",
      "test mean loss=87930.08203125\n",
      "fin save.\n",
      "epoch 3181\n",
      "test_train\n",
      "train mean loss=61360.546875\n",
      "test_test\n",
      "test mean loss=87967.41015625\n",
      "fin save.\n",
      "epoch 3182\n",
      "test_train\n",
      "train mean loss=61769.32265625\n",
      "test_test\n",
      "test mean loss=87863.72265625\n",
      "fin save.\n",
      "epoch 3183\n",
      "test_train\n",
      "train mean loss=61731.86276041667\n",
      "test_test\n",
      "test mean loss=87892.81640625\n",
      "fin save.\n",
      "epoch 3184\n",
      "test_train\n",
      "train mean loss=61292.601822916666\n",
      "test_test\n",
      "test mean loss=87895.90625\n",
      "fin save.\n",
      "epoch 3185\n",
      "test_train\n",
      "train mean loss=62790.82317708333\n",
      "test_test\n",
      "test mean loss=88132.80078125\n",
      "fin save.\n",
      "epoch 3186\n",
      "test_train\n",
      "train mean loss=62983.45807291667\n",
      "test_test\n",
      "test mean loss=88019.08203125\n",
      "fin save.\n",
      "epoch 3187\n",
      "test_train\n",
      "train mean loss=63615.655989583334\n",
      "test_test\n",
      "test mean loss=87934.015625\n",
      "fin save.\n",
      "epoch 3188\n",
      "test_train\n",
      "train mean loss=62222.94088541667\n",
      "test_test\n",
      "test mean loss=88006.6328125\n",
      "fin save.\n",
      "epoch 3189\n",
      "test_train\n",
      "train mean loss=63020.15221354167\n",
      "test_test\n",
      "test mean loss=87784.55078125\n",
      "fin save.\n",
      "epoch 3190\n",
      "test_train\n",
      "train mean loss=61760.88880208333\n",
      "test_test\n",
      "test mean loss=87782.6328125\n",
      "fin save.\n",
      "epoch 3191\n",
      "test_train\n",
      "train mean loss=62717.555989583336\n",
      "test_test\n",
      "test mean loss=88036.4609375\n",
      "fin save.\n",
      "epoch 3192\n",
      "test_train\n",
      "train mean loss=61740.53046875\n",
      "test_test\n",
      "test mean loss=88011.890625\n",
      "fin save.\n",
      "epoch 3193\n",
      "test_train\n",
      "train mean loss=62228.46497395833\n",
      "test_test\n",
      "test mean loss=87846.65234375\n",
      "fin save.\n",
      "epoch 3194\n",
      "test_train\n",
      "train mean loss=62436.721354166664\n",
      "test_test\n",
      "test mean loss=87688.78515625\n",
      "fin save.\n",
      "epoch 3195\n",
      "test_train\n",
      "train mean loss=61922.79869791667\n",
      "test_test\n",
      "test mean loss=87972.88671875\n",
      "fin save.\n",
      "epoch 3196\n",
      "test_train\n",
      "train mean loss=62506.404947916664\n",
      "test_test\n",
      "test mean loss=87844.359375\n",
      "fin save.\n",
      "epoch 3197\n",
      "test_train\n",
      "train mean loss=62923.06783854167\n",
      "test_test\n",
      "test mean loss=87962.6484375\n",
      "fin save.\n",
      "epoch 3198\n",
      "test_train\n",
      "train mean loss=62706.16458333333\n",
      "test_test\n",
      "test mean loss=87753.9765625\n",
      "fin save.\n",
      "epoch 3199\n",
      "test_train\n",
      "train mean loss=61623.546875\n",
      "test_test\n",
      "test mean loss=87889.4609375\n",
      "fin save.\n",
      "epoch 3200\n",
      "test_train\n",
      "train mean loss=61371.381510416664\n",
      "test_test\n",
      "test mean loss=88067.44140625\n",
      "fin save.\n",
      "epoch 3201\n",
      "test_train\n",
      "train mean loss=62518.157942708334\n",
      "test_test\n",
      "test mean loss=88195.54296875\n",
      "fin save.\n",
      "epoch 3202\n",
      "test_train\n",
      "train mean loss=61686.343489583334\n",
      "test_test\n",
      "test mean loss=88009.25390625\n",
      "fin save.\n",
      "epoch 3203\n",
      "test_train\n",
      "train mean loss=62699.591145833336\n",
      "test_test\n",
      "test mean loss=87843.78125\n",
      "fin save.\n",
      "epoch 3204\n",
      "test_train\n",
      "train mean loss=61794.67109375\n",
      "test_test\n",
      "test mean loss=87745.24609375\n",
      "fin save.\n",
      "epoch 3205\n",
      "test_train\n",
      "train mean loss=61790.15182291667\n",
      "test_test\n",
      "test mean loss=87666.71484375\n",
      "fin save.\n",
      "epoch 3206\n",
      "test_train\n",
      "train mean loss=61460.878255208336\n",
      "test_test\n",
      "test mean loss=87858.54296875\n",
      "fin save.\n",
      "epoch 3207\n",
      "test_train\n",
      "train mean loss=62750.19713541667\n",
      "test_test\n",
      "test mean loss=87790.53515625\n",
      "fin save.\n",
      "epoch 3208\n",
      "test_train\n",
      "train mean loss=62084.66640625\n",
      "test_test\n",
      "test mean loss=87822.2109375\n",
      "fin save.\n",
      "epoch 3209\n",
      "test_train\n",
      "train mean loss=61947.81354166667\n",
      "test_test\n",
      "test mean loss=87626.8828125\n",
      "fin save.\n",
      "epoch 3210\n",
      "test_train\n",
      "train mean loss=61351.040625\n",
      "test_test\n",
      "test mean loss=87768.4375\n",
      "fin save.\n",
      "epoch 3211\n",
      "test_train\n",
      "train mean loss=61740.68463541667\n",
      "test_test\n",
      "test mean loss=87722.66796875\n",
      "fin save.\n",
      "epoch 3212\n",
      "test_train\n",
      "train mean loss=62657.51171875\n",
      "test_test\n",
      "test mean loss=87691.43359375\n",
      "fin save.\n",
      "epoch 3213\n",
      "test_train\n",
      "train mean loss=62287.433333333334\n",
      "test_test\n",
      "test mean loss=87616.671875\n",
      "fin save.\n",
      "epoch 3214\n",
      "test_train\n",
      "train mean loss=62538.965625\n",
      "test_test\n",
      "test mean loss=87796.82421875\n",
      "fin save.\n",
      "epoch 3215\n",
      "test_train\n",
      "train mean loss=62950.68111979167\n",
      "test_test\n",
      "test mean loss=87913.1640625\n",
      "fin save.\n",
      "epoch 3216\n",
      "test_train\n",
      "train mean loss=62182.699479166666\n",
      "test_test\n",
      "test mean loss=87831.24609375\n",
      "fin save.\n",
      "epoch 3217\n",
      "test_train\n",
      "train mean loss=62111.287760416664\n",
      "test_test\n",
      "test mean loss=87915.109375\n",
      "fin save.\n",
      "epoch 3218\n",
      "test_train\n",
      "train mean loss=61295.41067708333\n",
      "test_test\n",
      "test mean loss=87953.35546875\n",
      "fin save.\n",
      "epoch 3219\n",
      "test_train\n",
      "train mean loss=61390.97890625\n",
      "test_test\n",
      "test mean loss=87938.6875\n",
      "fin save.\n",
      "epoch 3220\n",
      "test_train\n",
      "train mean loss=62480.18932291667\n",
      "test_test\n",
      "test mean loss=88062.1484375\n",
      "fin save.\n",
      "epoch 3221\n",
      "test_train\n",
      "train mean loss=62199.26744791667\n",
      "test_test\n",
      "test mean loss=87939.1953125\n",
      "fin save.\n",
      "epoch 3222\n",
      "test_train\n",
      "train mean loss=61753.152604166666\n",
      "test_test\n",
      "test mean loss=88018.05859375\n",
      "fin save.\n",
      "epoch 3223\n",
      "test_train\n",
      "train mean loss=61330.21953125\n",
      "test_test\n",
      "test mean loss=88048.9296875\n",
      "fin save.\n",
      "epoch 3224\n",
      "test_train\n",
      "train mean loss=62589.867578125\n",
      "test_test\n",
      "test mean loss=87834.6484375\n",
      "fin save.\n",
      "epoch 3225\n",
      "test_train\n",
      "train mean loss=62526.98359375\n",
      "test_test\n",
      "test mean loss=87805.7109375\n",
      "fin save.\n",
      "epoch 3226\n",
      "test_train\n",
      "train mean loss=62193.595052083336\n",
      "test_test\n",
      "test mean loss=87657.8671875\n",
      "fin save.\n",
      "epoch 3227\n",
      "test_train\n",
      "train mean loss=61902.7859375\n",
      "test_test\n",
      "test mean loss=87804.4453125\n",
      "fin save.\n",
      "epoch 3228\n",
      "test_train\n",
      "train mean loss=62063.76158854167\n",
      "test_test\n",
      "test mean loss=87924.16796875\n",
      "fin save.\n",
      "epoch 3229\n",
      "test_train\n",
      "train mean loss=62290.6640625\n",
      "test_test\n",
      "test mean loss=87696.89453125\n",
      "fin save.\n",
      "epoch 3230\n",
      "test_train\n",
      "train mean loss=63429.12994791667\n",
      "test_test\n",
      "test mean loss=87775.98046875\n",
      "fin save.\n",
      "epoch 3231\n",
      "test_train\n",
      "train mean loss=62447.447265625\n",
      "test_test\n",
      "test mean loss=87913.70703125\n",
      "fin save.\n",
      "epoch 3232\n",
      "test_train\n",
      "train mean loss=62048.45130208333\n",
      "test_test\n",
      "test mean loss=87816.484375\n",
      "fin save.\n",
      "epoch 3233\n",
      "test_train\n",
      "train mean loss=62507.9390625\n",
      "test_test\n",
      "test mean loss=87829.08203125\n",
      "fin save.\n",
      "epoch 3234\n",
      "test_train\n",
      "train mean loss=62431.878255208336\n",
      "test_test\n",
      "test mean loss=87842.03125\n",
      "fin save.\n",
      "epoch 3235\n",
      "test_train\n",
      "train mean loss=61251.31796875\n",
      "test_test\n",
      "test mean loss=87832.17578125\n",
      "fin save.\n",
      "epoch 3236\n",
      "test_train\n",
      "train mean loss=61063.981119791664\n",
      "test_test\n",
      "test mean loss=87808.46875\n",
      "fin save.\n",
      "epoch 3237\n",
      "test_train\n",
      "train mean loss=63041.871875\n",
      "test_test\n",
      "test mean loss=87942.83984375\n",
      "fin save.\n",
      "epoch 3238\n",
      "test_train\n",
      "train mean loss=62245.45234375\n",
      "test_test\n",
      "test mean loss=87731.4140625\n",
      "fin save.\n",
      "epoch 3239\n",
      "test_train\n",
      "train mean loss=62395.48151041667\n",
      "test_test\n",
      "test mean loss=87679.06640625\n",
      "fin save.\n",
      "epoch 3240\n",
      "test_train\n",
      "train mean loss=62909.65611979167\n",
      "test_test\n",
      "test mean loss=87687.890625\n",
      "fin save.\n",
      "epoch 3241\n",
      "test_train\n",
      "train mean loss=62637.837109375\n",
      "test_test\n",
      "test mean loss=87798.34375\n",
      "fin save.\n",
      "epoch 3242\n",
      "test_train\n",
      "train mean loss=62694.371875\n",
      "test_test\n",
      "test mean loss=87143.39453125\n",
      "fin save.\n",
      "epoch 3243\n",
      "test_train\n",
      "train mean loss=61531.526041666664\n",
      "test_test\n",
      "test mean loss=87413.8359375\n",
      "fin save.\n",
      "epoch 3244\n",
      "test_train\n",
      "train mean loss=62137.75885416667\n",
      "test_test\n",
      "test mean loss=87631.31640625\n",
      "fin save.\n",
      "epoch 3245\n",
      "test_train\n",
      "train mean loss=62951.165364583336\n",
      "test_test\n",
      "test mean loss=87151.36328125\n",
      "fin save.\n",
      "epoch 3246\n",
      "test_train\n",
      "train mean loss=61777.86536458333\n",
      "test_test\n",
      "test mean loss=87228.953125\n",
      "fin save.\n",
      "epoch 3247\n",
      "test_train\n",
      "train mean loss=63846.184895833336\n",
      "test_test\n",
      "test mean loss=87234.15625\n",
      "fin save.\n",
      "epoch 3248\n",
      "test_train\n",
      "train mean loss=62157.998697916664\n",
      "test_test\n",
      "test mean loss=87277.87890625\n",
      "fin save.\n",
      "epoch 3249\n",
      "test_train\n",
      "train mean loss=62264.3265625\n",
      "test_test\n",
      "test mean loss=87277.96875\n",
      "fin save.\n",
      "epoch 3250\n",
      "test_train\n",
      "train mean loss=62414.640885416666\n",
      "test_test\n",
      "test mean loss=87298.8046875\n",
      "fin save.\n",
      "epoch 3251\n",
      "test_train\n",
      "train mean loss=62756.06328125\n",
      "test_test\n",
      "test mean loss=87339.203125\n",
      "fin save.\n",
      "epoch 3252\n",
      "test_train\n",
      "train mean loss=63287.61484375\n",
      "test_test\n",
      "test mean loss=87186.23828125\n",
      "fin save.\n",
      "epoch 3253\n",
      "test_train\n",
      "train mean loss=61837.41979166667\n",
      "test_test\n",
      "test mean loss=87523.97265625\n",
      "fin save.\n",
      "epoch 3254\n",
      "test_train\n",
      "train mean loss=62281.20859375\n",
      "test_test\n",
      "test mean loss=87374.12109375\n",
      "fin save.\n",
      "epoch 3255\n",
      "test_train\n",
      "train mean loss=61459.40729166667\n",
      "test_test\n",
      "test mean loss=87229.32421875\n",
      "fin save.\n",
      "epoch 3256\n",
      "test_train\n",
      "train mean loss=62959.67174479167\n",
      "test_test\n",
      "test mean loss=87258.6328125\n",
      "fin save.\n",
      "epoch 3257\n",
      "test_train\n",
      "train mean loss=62576.12161458333\n",
      "test_test\n",
      "test mean loss=87249.32421875\n",
      "fin save.\n",
      "epoch 3258\n",
      "test_train\n",
      "train mean loss=61890.580729166664\n",
      "test_test\n",
      "test mean loss=87527.88671875\n",
      "fin save.\n",
      "epoch 3259\n",
      "test_train\n",
      "train mean loss=62350.74791666667\n",
      "test_test\n",
      "test mean loss=87506.1953125\n",
      "fin save.\n",
      "epoch 3260\n",
      "test_train\n",
      "train mean loss=62719.7328125\n",
      "test_test\n",
      "test mean loss=87500.046875\n",
      "fin save.\n",
      "epoch 3261\n",
      "test_train\n",
      "train mean loss=61727.56796875\n",
      "test_test\n",
      "test mean loss=87760.5390625\n",
      "fin save.\n",
      "epoch 3262\n",
      "test_train\n",
      "train mean loss=61709.20625\n",
      "test_test\n",
      "test mean loss=87740.1171875\n",
      "fin save.\n",
      "epoch 3263\n",
      "test_train\n",
      "train mean loss=62148.71770833333\n",
      "test_test\n",
      "test mean loss=87363.0703125\n",
      "fin save.\n",
      "epoch 3264\n",
      "test_train\n",
      "train mean loss=61744.61041666667\n",
      "test_test\n",
      "test mean loss=87123.12890625\n",
      "fin save.\n",
      "epoch 3265\n",
      "test_train\n",
      "train mean loss=62665.37265625\n",
      "test_test\n",
      "test mean loss=87129.23828125\n",
      "fin save.\n",
      "epoch 3266\n",
      "test_train\n",
      "train mean loss=61884.417317708336\n",
      "test_test\n",
      "test mean loss=86908.0\n",
      "fin save.\n",
      "epoch 3267\n",
      "test_train\n",
      "train mean loss=62870.833333333336\n",
      "test_test\n",
      "test mean loss=86929.85546875\n",
      "fin save.\n",
      "epoch 3268\n",
      "test_train\n",
      "train mean loss=62036.33984375\n",
      "test_test\n",
      "test mean loss=87009.25390625\n",
      "fin save.\n",
      "epoch 3269\n",
      "test_train\n",
      "train mean loss=61309.905989583334\n",
      "test_test\n",
      "test mean loss=87069.890625\n",
      "fin save.\n",
      "epoch 3270\n",
      "test_train\n",
      "train mean loss=62348.66888020833\n",
      "test_test\n",
      "test mean loss=87015.83203125\n",
      "fin save.\n",
      "epoch 3271\n",
      "test_train\n",
      "train mean loss=62119.34765625\n",
      "test_test\n",
      "test mean loss=87067.1328125\n",
      "fin save.\n",
      "epoch 3272\n",
      "test_train\n",
      "train mean loss=61849.880078125\n",
      "test_test\n",
      "test mean loss=87211.09765625\n",
      "fin save.\n",
      "epoch 3273\n",
      "test_train\n",
      "train mean loss=62761.58645833333\n",
      "test_test\n",
      "test mean loss=87170.48828125\n",
      "fin save.\n",
      "epoch 3274\n",
      "test_train\n",
      "train mean loss=62160.622265625\n",
      "test_test\n",
      "test mean loss=87450.37109375\n",
      "fin save.\n",
      "epoch 3275\n",
      "test_train\n",
      "train mean loss=62314.63776041667\n",
      "test_test\n",
      "test mean loss=87248.203125\n",
      "fin save.\n",
      "epoch 3276\n",
      "test_train\n",
      "train mean loss=62259.20260416667\n",
      "test_test\n",
      "test mean loss=87416.15625\n",
      "fin save.\n",
      "epoch 3277\n",
      "test_train\n",
      "train mean loss=62722.70403645833\n",
      "test_test\n",
      "test mean loss=87207.25390625\n",
      "fin save.\n",
      "epoch 3278\n",
      "test_train\n",
      "train mean loss=62266.02395833333\n",
      "test_test\n",
      "test mean loss=87524.4296875\n",
      "fin save.\n",
      "epoch 3279\n",
      "test_train\n",
      "train mean loss=61938.1875\n",
      "test_test\n",
      "test mean loss=87462.91796875\n",
      "fin save.\n",
      "epoch 3280\n",
      "test_train\n",
      "train mean loss=61511.735677083336\n",
      "test_test\n",
      "test mean loss=87332.88671875\n",
      "fin save.\n",
      "epoch 3281\n",
      "test_train\n",
      "train mean loss=62128.20520833333\n",
      "test_test\n",
      "test mean loss=87269.00390625\n",
      "fin save.\n",
      "epoch 3282\n",
      "test_train\n",
      "train mean loss=61849.600390625\n",
      "test_test\n",
      "test mean loss=87519.203125\n",
      "fin save.\n",
      "epoch 3283\n",
      "test_train\n",
      "train mean loss=62288.305338541664\n",
      "test_test\n",
      "test mean loss=87866.515625\n",
      "fin save.\n",
      "epoch 3284\n",
      "test_train\n",
      "train mean loss=62766.761067708336\n",
      "test_test\n",
      "test mean loss=87544.125\n",
      "fin save.\n",
      "epoch 3285\n",
      "test_train\n",
      "train mean loss=63004.562760416666\n",
      "test_test\n",
      "test mean loss=87356.20703125\n",
      "fin save.\n",
      "epoch 3286\n",
      "test_train\n",
      "train mean loss=62215.969010416666\n",
      "test_test\n",
      "test mean loss=87477.1015625\n",
      "fin save.\n",
      "epoch 3287\n",
      "test_train\n",
      "train mean loss=62325.07604166667\n",
      "test_test\n",
      "test mean loss=87474.66796875\n",
      "fin save.\n",
      "epoch 3288\n",
      "test_train\n",
      "train mean loss=62254.6234375\n",
      "test_test\n",
      "test mean loss=87890.14453125\n",
      "fin save.\n",
      "epoch 3289\n",
      "test_train\n",
      "train mean loss=62550.684375\n",
      "test_test\n",
      "test mean loss=87886.6875\n",
      "fin save.\n",
      "epoch 3290\n",
      "test_train\n",
      "train mean loss=62494.43255208333\n",
      "test_test\n",
      "test mean loss=87980.19921875\n",
      "fin save.\n",
      "epoch 3291\n",
      "test_train\n",
      "train mean loss=62342.791666666664\n",
      "test_test\n",
      "test mean loss=87984.90234375\n",
      "fin save.\n",
      "epoch 3292\n",
      "test_train\n",
      "train mean loss=62307.740234375\n",
      "test_test\n",
      "test mean loss=87894.921875\n",
      "fin save.\n",
      "epoch 3293\n",
      "test_train\n",
      "train mean loss=61782.35494791667\n",
      "test_test\n",
      "test mean loss=88026.73828125\n",
      "fin save.\n",
      "epoch 3294\n",
      "test_train\n",
      "train mean loss=61704.373697916664\n",
      "test_test\n",
      "test mean loss=87764.12890625\n",
      "fin save.\n",
      "epoch 3295\n",
      "test_train\n",
      "train mean loss=61885.67526041667\n",
      "test_test\n",
      "test mean loss=87555.24609375\n",
      "fin save.\n",
      "epoch 3296\n",
      "test_train\n",
      "train mean loss=61799.081770833334\n",
      "test_test\n",
      "test mean loss=87852.03125\n",
      "fin save.\n",
      "epoch 3297\n",
      "test_train\n",
      "train mean loss=61658.39375\n",
      "test_test\n",
      "test mean loss=87512.0234375\n",
      "fin save.\n",
      "epoch 3298\n",
      "test_train\n",
      "train mean loss=62367.21041666667\n",
      "test_test\n",
      "test mean loss=87701.734375\n",
      "fin save.\n",
      "epoch 3299\n",
      "test_train\n",
      "train mean loss=60919.06171875\n",
      "test_test\n",
      "test mean loss=87877.1953125\n",
      "fin save.\n",
      "epoch 3300\n",
      "test_train\n",
      "train mean loss=62790.397135416664\n",
      "test_test\n",
      "test mean loss=87670.609375\n",
      "fin save.\n",
      "epoch 3301\n",
      "test_train\n",
      "train mean loss=62464.57213541667\n",
      "test_test\n",
      "test mean loss=87926.09765625\n",
      "fin save.\n",
      "epoch 3302\n",
      "test_train\n",
      "train mean loss=63215.93958333333\n",
      "test_test\n",
      "test mean loss=87844.984375\n",
      "fin save.\n",
      "epoch 3303\n",
      "test_train\n",
      "train mean loss=61654.159375\n",
      "test_test\n",
      "test mean loss=87649.0078125\n",
      "fin save.\n",
      "epoch 3304\n",
      "test_train\n",
      "train mean loss=62353.371875\n",
      "test_test\n",
      "test mean loss=87650.52734375\n",
      "fin save.\n",
      "epoch 3305\n",
      "test_train\n",
      "train mean loss=62941.973958333336\n",
      "test_test\n",
      "test mean loss=87698.20703125\n",
      "fin save.\n",
      "epoch 3306\n",
      "test_train\n",
      "train mean loss=62674.09817708333\n",
      "test_test\n",
      "test mean loss=87600.54296875\n",
      "fin save.\n",
      "epoch 3307\n",
      "test_train\n",
      "train mean loss=61992.53619791667\n",
      "test_test\n",
      "test mean loss=87738.625\n",
      "fin save.\n",
      "epoch 3308\n",
      "test_train\n",
      "train mean loss=61988.09036458333\n",
      "test_test\n",
      "test mean loss=87688.359375\n",
      "fin save.\n",
      "epoch 3309\n",
      "test_train\n",
      "train mean loss=62739.52239583333\n",
      "test_test\n",
      "test mean loss=87495.10546875\n",
      "fin save.\n",
      "epoch 3310\n",
      "test_train\n",
      "train mean loss=62019.485677083336\n",
      "test_test\n",
      "test mean loss=87875.18359375\n",
      "fin save.\n",
      "epoch 3311\n",
      "test_train\n",
      "train mean loss=62580.532942708334\n",
      "test_test\n",
      "test mean loss=87655.26171875\n",
      "fin save.\n",
      "epoch 3312\n",
      "test_train\n",
      "train mean loss=62224.97552083333\n",
      "test_test\n",
      "test mean loss=87605.29296875\n",
      "fin save.\n",
      "epoch 3313\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=63066.30286458333\n",
      "test_test\n",
      "test mean loss=87604.0625\n",
      "fin save.\n",
      "epoch 3314\n",
      "test_train\n",
      "train mean loss=62564.68697916667\n",
      "test_test\n",
      "test mean loss=87356.31640625\n",
      "fin save.\n",
      "epoch 3315\n",
      "test_train\n",
      "train mean loss=61905.9671875\n",
      "test_test\n",
      "test mean loss=86880.82421875\n",
      "fin save.\n",
      "epoch 3316\n",
      "test_train\n",
      "train mean loss=62638.67526041667\n",
      "test_test\n",
      "test mean loss=87141.828125\n",
      "fin save.\n",
      "epoch 3317\n",
      "test_train\n",
      "train mean loss=63181.23880208333\n",
      "test_test\n",
      "test mean loss=87255.12890625\n",
      "fin save.\n",
      "epoch 3318\n",
      "test_train\n",
      "train mean loss=62681.39739583333\n",
      "test_test\n",
      "test mean loss=87227.7421875\n",
      "fin save.\n",
      "epoch 3319\n",
      "test_train\n",
      "train mean loss=62931.61796875\n",
      "test_test\n",
      "test mean loss=87241.98828125\n",
      "fin save.\n",
      "epoch 3320\n",
      "test_train\n",
      "train mean loss=63112.959375\n",
      "test_test\n",
      "test mean loss=87248.28515625\n",
      "fin save.\n",
      "epoch 3321\n",
      "test_train\n",
      "train mean loss=61842.74010416667\n",
      "test_test\n",
      "test mean loss=87479.765625\n",
      "fin save.\n",
      "epoch 3322\n",
      "test_train\n",
      "train mean loss=62714.19140625\n",
      "test_test\n",
      "test mean loss=87327.46484375\n",
      "fin save.\n",
      "epoch 3323\n",
      "test_train\n",
      "train mean loss=62798.060286458334\n",
      "test_test\n",
      "test mean loss=87359.3203125\n",
      "fin save.\n",
      "epoch 3324\n",
      "test_train\n",
      "train mean loss=62603.903645833336\n",
      "test_test\n",
      "test mean loss=87312.30078125\n",
      "fin save.\n",
      "epoch 3325\n",
      "test_train\n",
      "train mean loss=61618.434895833336\n",
      "test_test\n",
      "test mean loss=87098.82421875\n",
      "fin save.\n",
      "epoch 3326\n",
      "test_train\n",
      "train mean loss=62447.27109375\n",
      "test_test\n",
      "test mean loss=87238.0\n",
      "fin save.\n",
      "epoch 3327\n",
      "test_train\n",
      "train mean loss=62206.226822916666\n",
      "test_test\n",
      "test mean loss=87049.9765625\n",
      "fin save.\n",
      "epoch 3328\n",
      "test_train\n",
      "train mean loss=62232.662760416664\n",
      "test_test\n",
      "test mean loss=87150.58203125\n",
      "fin save.\n",
      "epoch 3329\n",
      "test_train\n",
      "train mean loss=62405.91002604167\n",
      "test_test\n",
      "test mean loss=87055.79296875\n",
      "fin save.\n",
      "epoch 3330\n",
      "test_train\n",
      "train mean loss=63427.57526041667\n",
      "test_test\n",
      "test mean loss=87321.859375\n",
      "fin save.\n",
      "epoch 3331\n",
      "test_train\n",
      "train mean loss=62037.459635416664\n",
      "test_test\n",
      "test mean loss=87290.8515625\n",
      "fin save.\n",
      "epoch 3332\n",
      "test_train\n",
      "train mean loss=62747.435807291666\n",
      "test_test\n",
      "test mean loss=87288.51953125\n",
      "fin save.\n",
      "epoch 3333\n",
      "test_train\n",
      "train mean loss=62953.266927083336\n",
      "test_test\n",
      "test mean loss=87312.38671875\n",
      "fin save.\n",
      "epoch 3334\n",
      "test_train\n",
      "train mean loss=62376.74322916667\n",
      "test_test\n",
      "test mean loss=87198.76171875\n",
      "fin save.\n",
      "epoch 3335\n",
      "test_train\n",
      "train mean loss=61410.5703125\n",
      "test_test\n",
      "test mean loss=87311.328125\n",
      "fin save.\n",
      "epoch 3336\n",
      "test_train\n",
      "train mean loss=62298.64921875\n",
      "test_test\n",
      "test mean loss=87445.4765625\n",
      "fin save.\n",
      "epoch 3337\n",
      "test_train\n",
      "train mean loss=62368.64765625\n",
      "test_test\n",
      "test mean loss=87404.21484375\n",
      "fin save.\n",
      "epoch 3338\n",
      "test_train\n",
      "train mean loss=62012.16458333333\n",
      "test_test\n",
      "test mean loss=87224.5\n",
      "fin save.\n",
      "epoch 3339\n",
      "test_train\n",
      "train mean loss=61711.85703125\n",
      "test_test\n",
      "test mean loss=87535.98828125\n",
      "fin save.\n",
      "epoch 3340\n",
      "test_train\n",
      "train mean loss=62749.45416666667\n",
      "test_test\n",
      "test mean loss=87434.953125\n",
      "fin save.\n",
      "epoch 3341\n",
      "test_train\n",
      "train mean loss=62035.21015625\n",
      "test_test\n",
      "test mean loss=87377.63671875\n",
      "fin save.\n",
      "epoch 3342\n",
      "test_train\n",
      "train mean loss=61678.145833333336\n",
      "test_test\n",
      "test mean loss=87453.82421875\n",
      "fin save.\n",
      "epoch 3343\n",
      "test_train\n",
      "train mean loss=62385.591145833336\n",
      "test_test\n",
      "test mean loss=87459.984375\n",
      "fin save.\n",
      "epoch 3344\n",
      "test_train\n",
      "train mean loss=60969.761458333334\n",
      "test_test\n",
      "test mean loss=87400.0234375\n",
      "fin save.\n",
      "epoch 3345\n",
      "test_train\n",
      "train mean loss=61608.39921875\n",
      "test_test\n",
      "test mean loss=87704.578125\n",
      "fin save.\n",
      "epoch 3346\n",
      "test_train\n",
      "train mean loss=63111.70989583333\n",
      "test_test\n",
      "test mean loss=87699.62890625\n",
      "fin save.\n",
      "epoch 3347\n",
      "test_train\n",
      "train mean loss=62261.430989583336\n",
      "test_test\n",
      "test mean loss=87704.58984375\n",
      "fin save.\n",
      "epoch 3348\n",
      "test_train\n",
      "train mean loss=62891.1\n",
      "test_test\n",
      "test mean loss=87639.2421875\n",
      "fin save.\n",
      "epoch 3349\n",
      "test_train\n",
      "train mean loss=62374.666666666664\n",
      "test_test\n",
      "test mean loss=87556.171875\n",
      "fin save.\n",
      "epoch 3350\n",
      "test_train\n",
      "train mean loss=62145.86614583333\n",
      "test_test\n",
      "test mean loss=87645.5390625\n",
      "fin save.\n",
      "epoch 3351\n",
      "test_train\n",
      "train mean loss=62596.31041666667\n",
      "test_test\n",
      "test mean loss=87762.80078125\n",
      "fin save.\n",
      "epoch 3352\n",
      "test_train\n",
      "train mean loss=61865.79505208333\n",
      "test_test\n",
      "test mean loss=87631.5859375\n",
      "fin save.\n",
      "epoch 3353\n",
      "test_train\n",
      "train mean loss=62570.86953125\n",
      "test_test\n",
      "test mean loss=87513.1796875\n",
      "fin save.\n",
      "epoch 3354\n",
      "test_train\n",
      "train mean loss=61704.48138020833\n",
      "test_test\n",
      "test mean loss=87611.4921875\n",
      "fin save.\n",
      "epoch 3355\n",
      "test_train\n",
      "train mean loss=62353.31354166667\n",
      "test_test\n",
      "test mean loss=87738.37890625\n",
      "fin save.\n",
      "epoch 3356\n",
      "test_train\n",
      "train mean loss=61529.148697916666\n",
      "test_test\n",
      "test mean loss=88168.73046875\n",
      "fin save.\n",
      "epoch 3357\n",
      "test_train\n",
      "train mean loss=61782.32708333333\n",
      "test_test\n",
      "test mean loss=87897.7890625\n",
      "fin save.\n",
      "epoch 3358\n",
      "test_train\n",
      "train mean loss=61601.30611979167\n",
      "test_test\n",
      "test mean loss=87801.10546875\n",
      "fin save.\n",
      "epoch 3359\n",
      "test_train\n",
      "train mean loss=62348.12552083333\n",
      "test_test\n",
      "test mean loss=88019.9296875\n",
      "fin save.\n",
      "epoch 3360\n",
      "test_train\n",
      "train mean loss=61843.580729166664\n",
      "test_test\n",
      "test mean loss=87772.10546875\n",
      "fin save.\n",
      "epoch 3361\n",
      "test_train\n",
      "train mean loss=61868.43203125\n",
      "test_test\n",
      "test mean loss=87696.35546875\n",
      "fin save.\n",
      "epoch 3362\n",
      "test_train\n",
      "train mean loss=62537.63723958333\n",
      "test_test\n",
      "test mean loss=87724.578125\n",
      "fin save.\n",
      "epoch 3363\n",
      "test_train\n",
      "train mean loss=61814.26770833333\n",
      "test_test\n",
      "test mean loss=88022.1640625\n",
      "fin save.\n",
      "epoch 3364\n",
      "test_train\n",
      "train mean loss=62301.47890625\n",
      "test_test\n",
      "test mean loss=87896.9765625\n",
      "fin save.\n",
      "epoch 3365\n",
      "test_train\n",
      "train mean loss=61972.420703125\n",
      "test_test\n",
      "test mean loss=87946.70703125\n",
      "fin save.\n",
      "epoch 3366\n",
      "test_train\n",
      "train mean loss=62521.13854166667\n",
      "test_test\n",
      "test mean loss=87863.484375\n",
      "fin save.\n",
      "epoch 3367\n",
      "test_train\n",
      "train mean loss=62735.739583333336\n",
      "test_test\n",
      "test mean loss=87954.58984375\n",
      "fin save.\n",
      "epoch 3368\n",
      "test_train\n",
      "train mean loss=61772.86276041667\n",
      "test_test\n",
      "test mean loss=88045.1953125\n",
      "fin save.\n",
      "epoch 3369\n",
      "test_train\n",
      "train mean loss=62419.532552083336\n",
      "test_test\n",
      "test mean loss=88100.7265625\n",
      "fin save.\n",
      "epoch 3370\n",
      "test_train\n",
      "train mean loss=61923.6375\n",
      "test_test\n",
      "test mean loss=87925.16796875\n",
      "fin save.\n",
      "epoch 3371\n",
      "test_train\n",
      "train mean loss=61349.71979166667\n",
      "test_test\n",
      "test mean loss=87946.17578125\n",
      "fin save.\n",
      "epoch 3372\n",
      "test_train\n",
      "train mean loss=61707.47369791667\n",
      "test_test\n",
      "test mean loss=87939.98828125\n",
      "fin save.\n",
      "epoch 3373\n",
      "test_train\n",
      "train mean loss=61887.867447916666\n",
      "test_test\n",
      "test mean loss=85865.20703125\n",
      "fin save.\n",
      "epoch 3374\n",
      "test_train\n",
      "train mean loss=61432.2375\n",
      "test_test\n",
      "test mean loss=85806.88671875\n",
      "fin save.\n",
      "epoch 3375\n",
      "test_train\n",
      "train mean loss=62023.799479166664\n",
      "test_test\n",
      "test mean loss=85900.09375\n",
      "fin save.\n",
      "epoch 3376\n",
      "test_train\n",
      "train mean loss=61661.540625\n",
      "test_test\n",
      "test mean loss=85833.3046875\n",
      "fin save.\n",
      "epoch 3377\n",
      "test_train\n",
      "train mean loss=62138.60989583333\n",
      "test_test\n",
      "test mean loss=86003.5703125\n",
      "fin save.\n",
      "epoch 3378\n",
      "test_train\n",
      "train mean loss=62849.33111979167\n",
      "test_test\n",
      "test mean loss=86543.91015625\n",
      "fin save.\n",
      "epoch 3379\n",
      "test_train\n",
      "train mean loss=61925.28177083333\n",
      "test_test\n",
      "test mean loss=86630.78515625\n",
      "fin save.\n",
      "epoch 3380\n",
      "test_train\n",
      "train mean loss=61653.123697916664\n",
      "test_test\n",
      "test mean loss=86672.8515625\n",
      "fin save.\n",
      "epoch 3381\n",
      "test_train\n",
      "train mean loss=62216.40520833333\n",
      "test_test\n",
      "test mean loss=86491.8046875\n",
      "fin save.\n",
      "epoch 3382\n",
      "test_train\n",
      "train mean loss=63099.0515625\n",
      "test_test\n",
      "test mean loss=86724.16796875\n",
      "fin save.\n",
      "epoch 3383\n",
      "test_train\n",
      "train mean loss=61587.36927083333\n",
      "test_test\n",
      "test mean loss=86795.03515625\n",
      "fin save.\n",
      "epoch 3384\n",
      "test_train\n",
      "train mean loss=61849.196614583336\n",
      "test_test\n",
      "test mean loss=86657.08984375\n",
      "fin save.\n",
      "epoch 3385\n",
      "test_train\n",
      "train mean loss=61840.06328125\n",
      "test_test\n",
      "test mean loss=86879.51171875\n",
      "fin save.\n",
      "epoch 3386\n",
      "test_train\n",
      "train mean loss=61412.42578125\n",
      "test_test\n",
      "test mean loss=86904.68359375\n",
      "fin save.\n",
      "epoch 3387\n",
      "test_train\n",
      "train mean loss=62120.070052083334\n",
      "test_test\n",
      "test mean loss=87009.4296875\n",
      "fin save.\n",
      "epoch 3388\n",
      "test_train\n",
      "train mean loss=62153.537890625\n",
      "test_test\n",
      "test mean loss=86987.99609375\n",
      "fin save.\n",
      "epoch 3389\n",
      "test_train\n",
      "train mean loss=62517.329427083336\n",
      "test_test\n",
      "test mean loss=86887.48828125\n",
      "fin save.\n",
      "epoch 3390\n",
      "test_train\n",
      "train mean loss=62193.328125\n",
      "test_test\n",
      "test mean loss=86854.81640625\n",
      "fin save.\n",
      "epoch 3391\n",
      "test_train\n",
      "train mean loss=61280.50677083333\n",
      "test_test\n",
      "test mean loss=86926.578125\n",
      "fin save.\n",
      "epoch 3392\n",
      "test_train\n",
      "train mean loss=62841.865885416664\n",
      "test_test\n",
      "test mean loss=87024.8359375\n",
      "fin save.\n",
      "epoch 3393\n",
      "test_train\n",
      "train mean loss=62336.53203125\n",
      "test_test\n",
      "test mean loss=87023.57421875\n",
      "fin save.\n",
      "epoch 3394\n",
      "test_train\n",
      "train mean loss=62520.719401041664\n",
      "test_test\n",
      "test mean loss=87844.51171875\n",
      "fin save.\n",
      "epoch 3395\n",
      "test_train\n",
      "train mean loss=61726.56692708333\n",
      "test_test\n",
      "test mean loss=88070.9140625\n",
      "fin save.\n",
      "epoch 3396\n",
      "test_train\n",
      "train mean loss=62663.210677083334\n",
      "test_test\n",
      "test mean loss=88060.2578125\n",
      "fin save.\n",
      "epoch 3397\n",
      "test_train\n",
      "train mean loss=62758.81627604167\n",
      "test_test\n",
      "test mean loss=88168.41796875\n",
      "fin save.\n",
      "epoch 3398\n",
      "test_train\n",
      "train mean loss=62062.74505208333\n",
      "test_test\n",
      "test mean loss=88028.7265625\n",
      "fin save.\n",
      "epoch 3399\n",
      "test_train\n",
      "train mean loss=63040.358723958336\n",
      "test_test\n",
      "test mean loss=88022.06640625\n",
      "fin save.\n",
      "epoch 3400\n",
      "test_train\n",
      "train mean loss=62904.523177083334\n",
      "test_test\n",
      "test mean loss=87818.5703125\n",
      "fin save.\n",
      "epoch 3401\n",
      "test_train\n",
      "train mean loss=62528.65611979167\n",
      "test_test\n",
      "test mean loss=87954.65625\n",
      "fin save.\n",
      "epoch 3402\n",
      "test_train\n",
      "train mean loss=62791.89947916667\n",
      "test_test\n",
      "test mean loss=87920.6015625\n",
      "fin save.\n",
      "epoch 3403\n",
      "test_train\n",
      "train mean loss=61938.849869791666\n",
      "test_test\n",
      "test mean loss=87966.703125\n",
      "fin save.\n",
      "epoch 3404\n",
      "test_train\n",
      "train mean loss=62964.729166666664\n",
      "test_test\n",
      "test mean loss=87869.25\n",
      "fin save.\n",
      "epoch 3405\n",
      "test_train\n",
      "train mean loss=62958.12578125\n",
      "test_test\n",
      "test mean loss=87899.078125\n",
      "fin save.\n",
      "epoch 3406\n",
      "test_train\n",
      "train mean loss=62316.778645833336\n",
      "test_test\n",
      "test mean loss=87926.90625\n",
      "fin save.\n",
      "epoch 3407\n",
      "test_train\n",
      "train mean loss=62134.79791666667\n",
      "test_test\n",
      "test mean loss=88056.3828125\n",
      "fin save.\n",
      "epoch 3408\n",
      "test_train\n",
      "train mean loss=62500.370833333334\n",
      "test_test\n",
      "test mean loss=88249.6953125\n",
      "fin save.\n",
      "epoch 3409\n",
      "test_train\n",
      "train mean loss=61781.19348958333\n",
      "test_test\n",
      "test mean loss=88659.703125\n",
      "fin save.\n",
      "epoch 3410\n",
      "test_train\n",
      "train mean loss=62038.29934895833\n",
      "test_test\n",
      "test mean loss=87935.0859375\n",
      "fin save.\n",
      "epoch 3411\n",
      "test_train\n",
      "train mean loss=61935.51458333333\n",
      "test_test\n",
      "test mean loss=87706.09375\n",
      "fin save.\n",
      "epoch 3412\n",
      "test_train\n",
      "train mean loss=62091.335677083334\n",
      "test_test\n",
      "test mean loss=87902.109375\n",
      "fin save.\n",
      "epoch 3413\n",
      "test_train\n",
      "train mean loss=61839.45\n",
      "test_test\n",
      "test mean loss=88179.80859375\n",
      "fin save.\n",
      "epoch 3414\n",
      "test_train\n",
      "train mean loss=62647.709375\n",
      "test_test\n",
      "test mean loss=88280.71875\n",
      "fin save.\n",
      "epoch 3415\n",
      "test_train\n",
      "train mean loss=62166.089583333334\n",
      "test_test\n",
      "test mean loss=88481.265625\n",
      "fin save.\n",
      "epoch 3416\n",
      "test_train\n",
      "train mean loss=62287.38229166667\n",
      "test_test\n",
      "test mean loss=88169.12890625\n",
      "fin save.\n",
      "epoch 3417\n",
      "test_train\n",
      "train mean loss=61988.16015625\n",
      "test_test\n",
      "test mean loss=88369.04296875\n",
      "fin save.\n",
      "epoch 3418\n",
      "test_train\n",
      "train mean loss=61913.48359375\n",
      "test_test\n",
      "test mean loss=88342.0\n",
      "fin save.\n",
      "epoch 3419\n",
      "test_train\n",
      "train mean loss=61906.48046875\n",
      "test_test\n",
      "test mean loss=88491.8515625\n",
      "fin save.\n",
      "epoch 3420\n",
      "test_train\n",
      "train mean loss=62156.204427083336\n",
      "test_test\n",
      "test mean loss=88421.109375\n",
      "fin save.\n",
      "epoch 3421\n",
      "test_train\n",
      "train mean loss=63095.43307291667\n",
      "test_test\n",
      "test mean loss=88511.51171875\n",
      "fin save.\n",
      "epoch 3422\n",
      "test_train\n",
      "train mean loss=62379.8234375\n",
      "test_test\n",
      "test mean loss=88578.9921875\n",
      "fin save.\n",
      "epoch 3423\n",
      "test_train\n",
      "train mean loss=61939.27291666667\n",
      "test_test\n",
      "test mean loss=88643.58203125\n",
      "fin save.\n",
      "epoch 3424\n",
      "test_train\n",
      "train mean loss=62301.249348958336\n",
      "test_test\n",
      "test mean loss=88574.234375\n",
      "fin save.\n",
      "epoch 3425\n",
      "test_train\n",
      "train mean loss=62307.61640625\n",
      "test_test\n",
      "test mean loss=88493.046875\n",
      "fin save.\n",
      "epoch 3426\n",
      "test_train\n",
      "train mean loss=61881.30260416667\n",
      "test_test\n",
      "test mean loss=88505.56640625\n",
      "fin save.\n",
      "epoch 3427\n",
      "test_train\n",
      "train mean loss=62894.65677083333\n",
      "test_test\n",
      "test mean loss=88545.3671875\n",
      "fin save.\n",
      "epoch 3428\n",
      "test_train\n",
      "train mean loss=63113.926953125\n",
      "test_test\n",
      "test mean loss=88728.33203125\n",
      "fin save.\n",
      "epoch 3429\n",
      "test_train\n",
      "train mean loss=62123.58411458333\n",
      "test_test\n",
      "test mean loss=88508.09765625\n",
      "fin save.\n",
      "epoch 3430\n",
      "test_train\n",
      "train mean loss=62610.43645833333\n",
      "test_test\n",
      "test mean loss=88580.05078125\n",
      "fin save.\n",
      "epoch 3431\n",
      "test_train\n",
      "train mean loss=62204.10755208333\n",
      "test_test\n",
      "test mean loss=88653.72265625\n",
      "fin save.\n",
      "epoch 3432\n",
      "test_train\n",
      "train mean loss=62895.98984375\n",
      "test_test\n",
      "test mean loss=88567.02734375\n",
      "fin save.\n",
      "epoch 3433\n",
      "test_train\n",
      "train mean loss=62557.458984375\n",
      "test_test\n",
      "test mean loss=88745.3515625\n",
      "fin save.\n",
      "epoch 3434\n",
      "test_train\n",
      "train mean loss=62327.09557291667\n",
      "test_test\n",
      "test mean loss=88728.12890625\n",
      "fin save.\n",
      "epoch 3435\n",
      "test_train\n",
      "train mean loss=62301.91588541667\n",
      "test_test\n",
      "test mean loss=88848.625\n",
      "fin save.\n",
      "epoch 3436\n",
      "test_train\n",
      "train mean loss=62406.509375\n",
      "test_test\n",
      "test mean loss=88351.58984375\n",
      "fin save.\n",
      "epoch 3437\n",
      "test_train\n",
      "train mean loss=61821.01614583333\n",
      "test_test\n",
      "test mean loss=88908.19140625\n",
      "fin save.\n",
      "epoch 3438\n",
      "test_train\n",
      "train mean loss=62770.327473958336\n",
      "test_test\n",
      "test mean loss=89258.23046875\n",
      "fin save.\n",
      "epoch 3439\n",
      "test_train\n",
      "train mean loss=62366.10260416667\n",
      "test_test\n",
      "test mean loss=89221.19140625\n",
      "fin save.\n",
      "epoch 3440\n",
      "test_train\n",
      "train mean loss=62771.32044270833\n",
      "test_test\n",
      "test mean loss=88958.76953125\n",
      "fin save.\n",
      "epoch 3441\n",
      "test_train\n",
      "train mean loss=62638.5484375\n",
      "test_test\n",
      "test mean loss=89064.41015625\n",
      "fin save.\n",
      "epoch 3442\n",
      "test_train\n",
      "train mean loss=62297.82916666667\n",
      "test_test\n",
      "test mean loss=89206.6796875\n",
      "fin save.\n",
      "epoch 3443\n",
      "test_train\n",
      "train mean loss=62115.188802083336\n",
      "test_test\n",
      "test mean loss=89253.55859375\n",
      "fin save.\n",
      "epoch 3444\n",
      "test_train\n",
      "train mean loss=62058.622395833336\n",
      "test_test\n",
      "test mean loss=89214.9296875\n",
      "fin save.\n",
      "epoch 3445\n",
      "test_train\n",
      "train mean loss=61811.2578125\n",
      "test_test\n",
      "test mean loss=89321.00390625\n",
      "fin save.\n",
      "epoch 3446\n",
      "test_train\n",
      "train mean loss=62740.68111979167\n",
      "test_test\n",
      "test mean loss=88881.31640625\n",
      "fin save.\n",
      "epoch 3447\n",
      "test_train\n",
      "train mean loss=62730.679036458336\n",
      "test_test\n",
      "test mean loss=88934.1328125\n",
      "fin save.\n",
      "epoch 3448\n",
      "test_train\n",
      "train mean loss=62605.65\n",
      "test_test\n",
      "test mean loss=88957.60546875\n",
      "fin save.\n",
      "epoch 3449\n",
      "test_train\n",
      "train mean loss=62901.670182291666\n",
      "test_test\n",
      "test mean loss=89279.3671875\n",
      "fin save.\n",
      "epoch 3450\n",
      "test_train\n",
      "train mean loss=63835.79791666667\n",
      "test_test\n",
      "test mean loss=89171.48828125\n",
      "fin save.\n",
      "epoch 3451\n",
      "test_train\n",
      "train mean loss=61782.40546875\n",
      "test_test\n",
      "test mean loss=89244.53125\n",
      "fin save.\n",
      "epoch 3452\n",
      "test_train\n",
      "train mean loss=61892.726302083334\n",
      "test_test\n",
      "test mean loss=89169.73046875\n",
      "fin save.\n",
      "epoch 3453\n",
      "test_train\n",
      "train mean loss=62540.26953125\n",
      "test_test\n",
      "test mean loss=89012.8984375\n",
      "fin save.\n",
      "epoch 3454\n",
      "test_train\n",
      "train mean loss=63153.875\n",
      "test_test\n",
      "test mean loss=89132.328125\n",
      "fin save.\n",
      "epoch 3455\n",
      "test_train\n",
      "train mean loss=62882.811197916664\n",
      "test_test\n",
      "test mean loss=87959.953125\n",
      "fin save.\n",
      "epoch 3456\n",
      "test_train\n",
      "train mean loss=62082.65416666667\n",
      "test_test\n",
      "test mean loss=87768.23046875\n",
      "fin save.\n",
      "epoch 3457\n",
      "test_train\n",
      "train mean loss=62309.885416666664\n",
      "test_test\n",
      "test mean loss=88046.49609375\n",
      "fin save.\n",
      "epoch 3458\n",
      "test_train\n",
      "train mean loss=61921.972395833334\n",
      "test_test\n",
      "test mean loss=88253.16796875\n",
      "fin save.\n",
      "epoch 3459\n",
      "test_train\n",
      "train mean loss=62564.31692708333\n",
      "test_test\n",
      "test mean loss=88087.4453125\n",
      "fin save.\n",
      "epoch 3460\n",
      "test_train\n",
      "train mean loss=62084.84270833333\n",
      "test_test\n",
      "test mean loss=88017.21484375\n",
      "fin save.\n",
      "epoch 3461\n",
      "test_train\n",
      "train mean loss=62928.984635416666\n",
      "test_test\n",
      "test mean loss=88168.796875\n",
      "fin save.\n",
      "epoch 3462\n",
      "test_train\n",
      "train mean loss=63169.5671875\n",
      "test_test\n",
      "test mean loss=88134.19140625\n",
      "fin save.\n",
      "epoch 3463\n",
      "test_train\n",
      "train mean loss=62682.035416666666\n",
      "test_test\n",
      "test mean loss=88039.94921875\n",
      "fin save.\n",
      "epoch 3464\n",
      "test_train\n",
      "train mean loss=62330.680989583336\n",
      "test_test\n",
      "test mean loss=87858.046875\n",
      "fin save.\n",
      "epoch 3465\n",
      "test_train\n",
      "train mean loss=61894.134505208334\n",
      "test_test\n",
      "test mean loss=87975.64453125\n",
      "fin save.\n",
      "epoch 3466\n",
      "test_train\n",
      "train mean loss=61980.52447916667\n",
      "test_test\n",
      "test mean loss=87931.42578125\n",
      "fin save.\n",
      "epoch 3467\n",
      "test_train\n",
      "train mean loss=62047.40234375\n",
      "test_test\n",
      "test mean loss=87617.4453125\n",
      "fin save.\n",
      "epoch 3468\n",
      "test_train\n",
      "train mean loss=62510.2\n",
      "test_test\n",
      "test mean loss=87587.62109375\n",
      "fin save.\n",
      "epoch 3469\n",
      "test_train\n",
      "train mean loss=62568.71328125\n",
      "test_test\n",
      "test mean loss=87898.921875\n",
      "fin save.\n",
      "epoch 3470\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=62397.152604166666\n",
      "test_test\n",
      "test mean loss=87616.48046875\n",
      "fin save.\n",
      "epoch 3471\n",
      "test_train\n",
      "train mean loss=62705.48880208333\n",
      "test_test\n",
      "test mean loss=87956.7109375\n",
      "fin save.\n",
      "epoch 3472\n",
      "test_train\n",
      "train mean loss=61746.33359375\n",
      "test_test\n",
      "test mean loss=87636.09375\n",
      "fin save.\n",
      "epoch 3473\n",
      "test_train\n",
      "train mean loss=62918.801041666666\n",
      "test_test\n",
      "test mean loss=88006.71484375\n",
      "fin save.\n",
      "epoch 3474\n",
      "test_train\n",
      "train mean loss=62732.32369791667\n",
      "test_test\n",
      "test mean loss=87610.73828125\n",
      "fin save.\n",
      "epoch 3475\n",
      "test_train\n",
      "train mean loss=62901.32083333333\n",
      "test_test\n",
      "test mean loss=88068.109375\n",
      "fin save.\n",
      "epoch 3476\n",
      "test_train\n",
      "train mean loss=62909.530989583334\n",
      "test_test\n",
      "test mean loss=87629.77734375\n",
      "fin save.\n",
      "epoch 3477\n",
      "test_train\n",
      "train mean loss=62074.22278645833\n",
      "test_test\n",
      "test mean loss=87709.13671875\n",
      "fin save.\n",
      "epoch 3478\n",
      "test_train\n",
      "train mean loss=63076.60885416667\n",
      "test_test\n",
      "test mean loss=87863.21484375\n",
      "fin save.\n",
      "epoch 3479\n",
      "test_train\n",
      "train mean loss=61849.38984375\n",
      "test_test\n",
      "test mean loss=87939.51171875\n",
      "fin save.\n",
      "epoch 3480\n",
      "test_train\n",
      "train mean loss=61241.270833333336\n",
      "test_test\n",
      "test mean loss=87795.7890625\n",
      "fin save.\n",
      "epoch 3481\n",
      "test_train\n",
      "train mean loss=61822.489583333336\n",
      "test_test\n",
      "test mean loss=87764.15625\n",
      "fin save.\n",
      "epoch 3482\n",
      "test_train\n",
      "train mean loss=62484.696614583336\n",
      "test_test\n",
      "test mean loss=87923.98046875\n",
      "fin save.\n",
      "epoch 3483\n",
      "test_train\n",
      "train mean loss=62201.14947916667\n",
      "test_test\n",
      "test mean loss=87760.23828125\n",
      "fin save.\n",
      "epoch 3484\n",
      "test_train\n",
      "train mean loss=62030.422135416666\n",
      "test_test\n",
      "test mean loss=87638.90625\n",
      "fin save.\n",
      "epoch 3485\n",
      "test_train\n",
      "train mean loss=62110.12708333333\n",
      "test_test\n",
      "test mean loss=87702.7890625\n",
      "fin save.\n",
      "epoch 3486\n",
      "test_train\n",
      "train mean loss=61790.976302083334\n",
      "test_test\n",
      "test mean loss=87862.4140625\n",
      "fin save.\n",
      "epoch 3487\n",
      "test_train\n",
      "train mean loss=62757.36640625\n",
      "test_test\n",
      "test mean loss=88115.15625\n",
      "fin save.\n",
      "epoch 3488\n",
      "test_train\n",
      "train mean loss=62841.53463541667\n",
      "test_test\n",
      "test mean loss=87278.96484375\n",
      "fin save.\n",
      "epoch 3489\n",
      "test_train\n",
      "train mean loss=62404.70651041667\n",
      "test_test\n",
      "test mean loss=87337.74609375\n",
      "fin save.\n",
      "epoch 3490\n",
      "test_train\n",
      "train mean loss=63094.82317708333\n",
      "test_test\n",
      "test mean loss=87490.98828125\n",
      "fin save.\n",
      "epoch 3491\n",
      "test_train\n",
      "train mean loss=63492.52135416667\n",
      "test_test\n",
      "test mean loss=87572.7421875\n",
      "fin save.\n",
      "epoch 3492\n",
      "test_train\n",
      "train mean loss=61086.13828125\n",
      "test_test\n",
      "test mean loss=87533.86328125\n",
      "fin save.\n",
      "epoch 3493\n",
      "test_train\n",
      "train mean loss=63257.97109375\n",
      "test_test\n",
      "test mean loss=87452.08984375\n",
      "fin save.\n",
      "epoch 3494\n",
      "test_train\n",
      "train mean loss=62016.972265625\n",
      "test_test\n",
      "test mean loss=87329.61328125\n",
      "fin save.\n",
      "epoch 3495\n",
      "test_train\n",
      "train mean loss=63750.95703125\n",
      "test_test\n",
      "test mean loss=87823.33203125\n",
      "fin save.\n",
      "epoch 3496\n",
      "test_train\n",
      "train mean loss=62402.246744791664\n",
      "test_test\n",
      "test mean loss=87447.39453125\n",
      "fin save.\n",
      "epoch 3497\n",
      "test_train\n",
      "train mean loss=62567.57174479167\n",
      "test_test\n",
      "test mean loss=87594.74609375\n",
      "fin save.\n",
      "epoch 3498\n",
      "test_train\n",
      "train mean loss=62530.55859375\n",
      "test_test\n",
      "test mean loss=87481.48828125\n",
      "fin save.\n",
      "epoch 3499\n",
      "test_train\n",
      "train mean loss=62735.476822916666\n",
      "test_test\n",
      "test mean loss=87203.2265625\n",
      "fin save.\n",
      "epoch 3500\n",
      "test_train\n",
      "train mean loss=63119.49817708333\n",
      "test_test\n",
      "test mean loss=87354.33203125\n",
      "fin save.\n",
      "epoch 3501\n",
      "test_train\n",
      "train mean loss=62831.55286458333\n",
      "test_test\n",
      "test mean loss=87894.28125\n",
      "fin save.\n",
      "epoch 3502\n",
      "test_train\n",
      "train mean loss=62885.32734375\n",
      "test_test\n",
      "test mean loss=87799.24609375\n",
      "fin save.\n",
      "epoch 3503\n",
      "test_train\n",
      "train mean loss=62487.91940104167\n",
      "test_test\n",
      "test mean loss=87831.9765625\n",
      "fin save.\n",
      "epoch 3504\n",
      "test_train\n",
      "train mean loss=63036.882161458336\n",
      "test_test\n",
      "test mean loss=87950.43359375\n",
      "fin save.\n",
      "epoch 3505\n",
      "test_train\n",
      "train mean loss=61754.849348958334\n",
      "test_test\n",
      "test mean loss=88005.4375\n",
      "fin save.\n",
      "epoch 3506\n",
      "test_train\n",
      "train mean loss=62199.55520833333\n",
      "test_test\n",
      "test mean loss=87921.4375\n",
      "fin save.\n",
      "epoch 3507\n",
      "test_train\n",
      "train mean loss=63208.39609375\n",
      "test_test\n",
      "test mean loss=87831.96484375\n",
      "fin save.\n",
      "epoch 3508\n",
      "test_train\n",
      "train mean loss=63443.863020833334\n",
      "test_test\n",
      "test mean loss=87641.890625\n",
      "fin save.\n",
      "epoch 3509\n",
      "test_train\n",
      "train mean loss=62443.808333333334\n",
      "test_test\n",
      "test mean loss=87770.6171875\n",
      "fin save.\n",
      "epoch 3510\n",
      "test_train\n",
      "train mean loss=61824.52916666667\n",
      "test_test\n",
      "test mean loss=87643.26171875\n",
      "fin save.\n",
      "epoch 3511\n",
      "test_train\n",
      "train mean loss=62017.54205729167\n",
      "test_test\n",
      "test mean loss=87638.4375\n",
      "fin save.\n",
      "epoch 3512\n",
      "test_train\n",
      "train mean loss=61847.91002604167\n",
      "test_test\n",
      "test mean loss=87570.65234375\n",
      "fin save.\n",
      "epoch 3513\n",
      "test_train\n",
      "train mean loss=62227.72473958333\n",
      "test_test\n",
      "test mean loss=87565.25390625\n",
      "fin save.\n",
      "epoch 3514\n",
      "test_train\n",
      "train mean loss=62832.13515625\n",
      "test_test\n",
      "test mean loss=87646.5\n",
      "fin save.\n",
      "epoch 3515\n",
      "test_train\n",
      "train mean loss=62519.684375\n",
      "test_test\n",
      "test mean loss=87648.4140625\n",
      "fin save.\n",
      "epoch 3516\n",
      "test_train\n",
      "train mean loss=62932.413802083334\n",
      "test_test\n",
      "test mean loss=87534.125\n",
      "fin save.\n",
      "epoch 3517\n",
      "test_train\n",
      "train mean loss=61946.160416666666\n",
      "test_test\n",
      "test mean loss=87572.6015625\n",
      "fin save.\n",
      "epoch 3518\n",
      "test_train\n",
      "train mean loss=62106.144270833334\n",
      "test_test\n",
      "test mean loss=87554.26953125\n",
      "fin save.\n",
      "epoch 3519\n",
      "test_train\n",
      "train mean loss=62321.86041666667\n",
      "test_test\n",
      "test mean loss=87406.13671875\n",
      "fin save.\n",
      "epoch 3520\n",
      "test_train\n",
      "train mean loss=62359.77643229167\n",
      "test_test\n",
      "test mean loss=87605.890625\n",
      "fin save.\n",
      "epoch 3521\n",
      "test_train\n",
      "train mean loss=62564.774739583336\n",
      "test_test\n",
      "test mean loss=87542.765625\n",
      "fin save.\n",
      "epoch 3522\n",
      "test_train\n",
      "train mean loss=62177.51380208333\n",
      "test_test\n",
      "test mean loss=87434.3515625\n",
      "fin save.\n",
      "epoch 3523\n",
      "test_train\n",
      "train mean loss=62714.052473958334\n",
      "test_test\n",
      "test mean loss=87449.91796875\n",
      "fin save.\n",
      "epoch 3524\n",
      "test_train\n",
      "train mean loss=63124.06692708333\n",
      "test_test\n",
      "test mean loss=87467.3046875\n",
      "fin save.\n",
      "epoch 3525\n",
      "test_train\n",
      "train mean loss=62394.45130208333\n",
      "test_test\n",
      "test mean loss=87242.0546875\n",
      "fin save.\n",
      "epoch 3526\n",
      "test_train\n",
      "train mean loss=62573.01471354167\n",
      "test_test\n",
      "test mean loss=87294.01953125\n",
      "fin save.\n",
      "epoch 3527\n",
      "test_train\n",
      "train mean loss=62879.855859375\n",
      "test_test\n",
      "test mean loss=87256.875\n",
      "fin save.\n",
      "epoch 3528\n",
      "test_train\n",
      "train mean loss=62281.80390625\n",
      "test_test\n",
      "test mean loss=87378.1484375\n",
      "fin save.\n",
      "epoch 3529\n",
      "test_train\n",
      "train mean loss=62729.930078125\n",
      "test_test\n",
      "test mean loss=87396.84765625\n",
      "fin save.\n",
      "epoch 3530\n",
      "test_train\n",
      "train mean loss=63231.91979166667\n",
      "test_test\n",
      "test mean loss=87574.87109375\n",
      "fin save.\n",
      "epoch 3531\n",
      "test_train\n",
      "train mean loss=62547.66302083333\n",
      "test_test\n",
      "test mean loss=87438.203125\n",
      "fin save.\n",
      "epoch 3532\n",
      "test_train\n",
      "train mean loss=63223.02786458333\n",
      "test_test\n",
      "test mean loss=87672.42578125\n",
      "fin save.\n",
      "epoch 3533\n",
      "test_train\n",
      "train mean loss=63308.70260416667\n",
      "test_test\n",
      "test mean loss=87564.37109375\n",
      "fin save.\n",
      "epoch 3534\n",
      "test_train\n",
      "train mean loss=62102.603125\n",
      "test_test\n",
      "test mean loss=87512.6875\n",
      "fin save.\n",
      "epoch 3535\n",
      "test_train\n",
      "train mean loss=62756.16484375\n",
      "test_test\n",
      "test mean loss=87614.9140625\n",
      "fin save.\n",
      "epoch 3536\n",
      "test_train\n",
      "train mean loss=63116.21588541667\n",
      "test_test\n",
      "test mean loss=87530.7734375\n",
      "fin save.\n",
      "epoch 3537\n",
      "test_train\n",
      "train mean loss=63684.46276041667\n",
      "test_test\n",
      "test mean loss=87695.14453125\n",
      "fin save.\n",
      "epoch 3538\n",
      "test_train\n",
      "train mean loss=62590.01223958333\n",
      "test_test\n",
      "test mean loss=87563.01171875\n",
      "fin save.\n",
      "epoch 3539\n",
      "test_train\n",
      "train mean loss=62669.59765625\n",
      "test_test\n",
      "test mean loss=87668.4296875\n",
      "fin save.\n",
      "epoch 3540\n",
      "test_train\n",
      "train mean loss=62457.56484375\n",
      "test_test\n",
      "test mean loss=87678.32421875\n",
      "fin save.\n",
      "epoch 3541\n",
      "test_train\n",
      "train mean loss=62266.20859375\n",
      "test_test\n",
      "test mean loss=87474.6640625\n",
      "fin save.\n",
      "epoch 3542\n",
      "test_train\n",
      "train mean loss=63324.61705729167\n",
      "test_test\n",
      "test mean loss=87452.46875\n",
      "fin save.\n",
      "epoch 3543\n",
      "test_train\n",
      "train mean loss=62732.165234375\n",
      "test_test\n",
      "test mean loss=87539.28515625\n",
      "fin save.\n",
      "epoch 3544\n",
      "test_train\n",
      "train mean loss=63386.92864583333\n",
      "test_test\n",
      "test mean loss=87639.5390625\n",
      "fin save.\n",
      "epoch 3545\n",
      "test_train\n",
      "train mean loss=62743.507552083334\n",
      "test_test\n",
      "test mean loss=87661.64453125\n",
      "fin save.\n",
      "epoch 3546\n",
      "test_train\n",
      "train mean loss=62912.779947916664\n",
      "test_test\n",
      "test mean loss=87521.66015625\n",
      "fin save.\n",
      "epoch 3547\n",
      "test_train\n",
      "train mean loss=62804.273697916666\n",
      "test_test\n",
      "test mean loss=87624.734375\n",
      "fin save.\n",
      "epoch 3548\n",
      "test_train\n",
      "train mean loss=62289.18567708333\n",
      "test_test\n",
      "test mean loss=87683.37890625\n",
      "fin save.\n",
      "epoch 3549\n",
      "test_train\n",
      "train mean loss=62808.451822916664\n",
      "test_test\n",
      "test mean loss=87672.76953125\n",
      "fin save.\n",
      "epoch 3550\n",
      "test_train\n",
      "train mean loss=63327.364583333336\n",
      "test_test\n",
      "test mean loss=87835.2265625\n",
      "fin save.\n",
      "epoch 3551\n",
      "test_train\n",
      "train mean loss=62384.79153645833\n",
      "test_test\n",
      "test mean loss=87640.4765625\n",
      "fin save.\n",
      "epoch 3552\n",
      "test_train\n",
      "train mean loss=62373.871875\n",
      "test_test\n",
      "test mean loss=87576.58203125\n",
      "fin save.\n",
      "epoch 3553\n",
      "test_train\n",
      "train mean loss=63273.187239583334\n",
      "test_test\n",
      "test mean loss=87690.46875\n",
      "fin save.\n",
      "epoch 3554\n",
      "test_train\n",
      "train mean loss=62166.37109375\n",
      "test_test\n",
      "test mean loss=87375.16796875\n",
      "fin save.\n",
      "epoch 3555\n",
      "test_train\n",
      "train mean loss=62659.09713541667\n",
      "test_test\n",
      "test mean loss=87670.21484375\n",
      "fin save.\n",
      "epoch 3556\n",
      "test_train\n",
      "train mean loss=61979.02942708333\n",
      "test_test\n",
      "test mean loss=87686.21875\n",
      "fin save.\n",
      "epoch 3557\n",
      "test_train\n",
      "train mean loss=62481.49947916667\n",
      "test_test\n",
      "test mean loss=87842.85546875\n",
      "fin save.\n",
      "epoch 3558\n",
      "test_train\n",
      "train mean loss=62518.421223958336\n",
      "test_test\n",
      "test mean loss=87807.8671875\n",
      "fin save.\n",
      "epoch 3559\n",
      "test_train\n",
      "train mean loss=62800.743489583336\n",
      "test_test\n",
      "test mean loss=87537.8828125\n",
      "fin save.\n",
      "epoch 3560\n",
      "test_train\n",
      "train mean loss=62596.635546875\n",
      "test_test\n",
      "test mean loss=87543.01171875\n",
      "fin save.\n",
      "epoch 3561\n",
      "test_train\n",
      "train mean loss=62554.15963541667\n",
      "test_test\n",
      "test mean loss=87513.32421875\n",
      "fin save.\n",
      "epoch 3562\n",
      "test_train\n",
      "train mean loss=62720.578125\n",
      "test_test\n",
      "test mean loss=87673.9453125\n",
      "fin save.\n",
      "epoch 3563\n",
      "test_train\n",
      "train mean loss=63010.633463541664\n",
      "test_test\n",
      "test mean loss=87766.30859375\n",
      "fin save.\n",
      "epoch 3564\n",
      "test_train\n",
      "train mean loss=62193.41067708333\n",
      "test_test\n",
      "test mean loss=87784.5234375\n",
      "fin save.\n",
      "epoch 3565\n",
      "test_train\n",
      "train mean loss=60845.15625\n",
      "test_test\n",
      "test mean loss=87497.33984375\n",
      "fin save.\n",
      "epoch 3566\n",
      "test_train\n",
      "train mean loss=63092.190234375\n",
      "test_test\n",
      "test mean loss=87682.0078125\n",
      "fin save.\n",
      "epoch 3567\n",
      "test_train\n",
      "train mean loss=62557.66067708333\n",
      "test_test\n",
      "test mean loss=87566.53515625\n",
      "fin save.\n",
      "epoch 3568\n",
      "test_train\n",
      "train mean loss=62615.8703125\n",
      "test_test\n",
      "test mean loss=87205.5390625\n",
      "fin save.\n",
      "epoch 3569\n",
      "test_train\n",
      "train mean loss=62724.860677083336\n",
      "test_test\n",
      "test mean loss=87314.0078125\n",
      "fin save.\n",
      "epoch 3570\n",
      "test_train\n",
      "train mean loss=61970.4828125\n",
      "test_test\n",
      "test mean loss=87318.8125\n",
      "fin save.\n",
      "epoch 3571\n",
      "test_train\n",
      "train mean loss=63313.7390625\n",
      "test_test\n",
      "test mean loss=87549.28125\n",
      "fin save.\n",
      "epoch 3572\n",
      "test_train\n",
      "train mean loss=63337.27786458333\n",
      "test_test\n",
      "test mean loss=87579.16015625\n",
      "fin save.\n",
      "epoch 3573\n",
      "test_train\n",
      "train mean loss=62271.00833333333\n",
      "test_test\n",
      "test mean loss=87638.3203125\n",
      "fin save.\n",
      "epoch 3574\n",
      "test_train\n",
      "train mean loss=62680.03697916667\n",
      "test_test\n",
      "test mean loss=87576.04296875\n",
      "fin save.\n",
      "epoch 3575\n",
      "test_train\n",
      "train mean loss=62756.75494791667\n",
      "test_test\n",
      "test mean loss=88723.87109375\n",
      "fin save.\n",
      "epoch 3576\n",
      "test_train\n",
      "train mean loss=62523.48098958333\n",
      "test_test\n",
      "test mean loss=88782.3203125\n",
      "fin save.\n",
      "epoch 3577\n",
      "test_train\n",
      "train mean loss=61488.53984375\n",
      "test_test\n",
      "test mean loss=88666.46875\n",
      "fin save.\n",
      "epoch 3578\n",
      "test_train\n",
      "train mean loss=61938.39661458333\n",
      "test_test\n",
      "test mean loss=88613.08984375\n",
      "fin save.\n",
      "epoch 3579\n",
      "test_train\n",
      "train mean loss=62670.02161458333\n",
      "test_test\n",
      "test mean loss=88541.8125\n",
      "fin save.\n",
      "epoch 3580\n",
      "test_train\n",
      "train mean loss=62823.69921875\n",
      "test_test\n",
      "test mean loss=88823.3125\n",
      "fin save.\n",
      "epoch 3581\n",
      "test_train\n",
      "train mean loss=62092.34583333333\n",
      "test_test\n",
      "test mean loss=88729.94921875\n",
      "fin save.\n",
      "epoch 3582\n",
      "test_train\n",
      "train mean loss=61902.98151041667\n",
      "test_test\n",
      "test mean loss=89152.08984375\n",
      "fin save.\n",
      "epoch 3583\n",
      "test_train\n",
      "train mean loss=62195.34661458333\n",
      "test_test\n",
      "test mean loss=88862.3828125\n",
      "fin save.\n",
      "epoch 3584\n",
      "test_train\n",
      "train mean loss=63131.25442708333\n",
      "test_test\n",
      "test mean loss=87906.38671875\n",
      "fin save.\n",
      "epoch 3585\n",
      "test_train\n",
      "train mean loss=61959.86614583333\n",
      "test_test\n",
      "test mean loss=87981.859375\n",
      "fin save.\n",
      "epoch 3586\n",
      "test_train\n",
      "train mean loss=62208.46380208333\n",
      "test_test\n",
      "test mean loss=87961.671875\n",
      "fin save.\n",
      "epoch 3587\n",
      "test_train\n",
      "train mean loss=61355.641927083336\n",
      "test_test\n",
      "test mean loss=87922.79296875\n",
      "fin save.\n",
      "epoch 3588\n",
      "test_train\n",
      "train mean loss=62299.3453125\n",
      "test_test\n",
      "test mean loss=88088.2578125\n",
      "fin save.\n",
      "epoch 3589\n",
      "test_train\n",
      "train mean loss=63015.84947916667\n",
      "test_test\n",
      "test mean loss=88129.15234375\n",
      "fin save.\n",
      "epoch 3590\n",
      "test_train\n",
      "train mean loss=62572.162369791666\n",
      "test_test\n",
      "test mean loss=87845.484375\n",
      "fin save.\n",
      "epoch 3591\n",
      "test_train\n",
      "train mean loss=62388.03177083333\n",
      "test_test\n",
      "test mean loss=88097.875\n",
      "fin save.\n",
      "epoch 3592\n",
      "test_train\n",
      "train mean loss=63193.445052083334\n",
      "test_test\n",
      "test mean loss=87760.7578125\n",
      "fin save.\n",
      "epoch 3593\n",
      "test_train\n",
      "train mean loss=62369.659765625\n",
      "test_test\n",
      "test mean loss=87765.921875\n",
      "fin save.\n",
      "epoch 3594\n",
      "test_train\n",
      "train mean loss=62142.24752604167\n",
      "test_test\n",
      "test mean loss=87776.703125\n",
      "fin save.\n",
      "epoch 3595\n",
      "test_train\n",
      "train mean loss=61614.265885416666\n",
      "test_test\n",
      "test mean loss=87695.62109375\n",
      "fin save.\n",
      "epoch 3596\n",
      "test_train\n",
      "train mean loss=62148.744140625\n",
      "test_test\n",
      "test mean loss=87914.5859375\n",
      "fin save.\n",
      "epoch 3597\n",
      "test_train\n",
      "train mean loss=62220.030598958336\n",
      "test_test\n",
      "test mean loss=88369.09375\n",
      "fin save.\n",
      "epoch 3598\n",
      "test_train\n",
      "train mean loss=62400.371354166666\n",
      "test_test\n",
      "test mean loss=88268.2734375\n",
      "fin save.\n",
      "epoch 3599\n",
      "test_train\n",
      "train mean loss=62599.317708333336\n",
      "test_test\n",
      "test mean loss=88242.375\n",
      "fin save.\n",
      "epoch 3600\n",
      "test_train\n",
      "train mean loss=62908.657421875\n",
      "test_test\n",
      "test mean loss=88206.73828125\n",
      "fin save.\n",
      "epoch 3601\n",
      "test_train\n",
      "train mean loss=62763.9828125\n",
      "test_test\n",
      "test mean loss=88368.68359375\n",
      "fin save.\n",
      "epoch 3602\n",
      "test_train\n",
      "train mean loss=61994.976822916666\n",
      "test_test\n",
      "test mean loss=88345.19140625\n",
      "fin save.\n",
      "epoch 3603\n",
      "test_train\n",
      "train mean loss=62131.78125\n",
      "test_test\n",
      "test mean loss=88156.9609375\n",
      "fin save.\n",
      "epoch 3604\n",
      "test_train\n",
      "train mean loss=61828.98294270833\n",
      "test_test\n",
      "test mean loss=88206.91015625\n",
      "fin save.\n",
      "epoch 3605\n",
      "test_train\n",
      "train mean loss=63279.06067708333\n",
      "test_test\n",
      "test mean loss=88062.16796875\n",
      "fin save.\n",
      "epoch 3606\n",
      "test_train\n",
      "train mean loss=62343.970052083336\n",
      "test_test\n",
      "test mean loss=88110.171875\n",
      "fin save.\n",
      "epoch 3607\n",
      "test_train\n",
      "train mean loss=62707.3765625\n",
      "test_test\n",
      "test mean loss=87942.1171875\n",
      "fin save.\n",
      "epoch 3608\n",
      "test_train\n",
      "train mean loss=62534.95546875\n",
      "test_test\n",
      "test mean loss=87726.70703125\n",
      "fin save.\n",
      "epoch 3609\n",
      "test_train\n",
      "train mean loss=63297.29765625\n",
      "test_test\n",
      "test mean loss=87757.36328125\n",
      "fin save.\n",
      "epoch 3610\n",
      "test_train\n",
      "train mean loss=62828.657421875\n",
      "test_test\n",
      "test mean loss=87829.52734375\n",
      "fin save.\n",
      "epoch 3611\n",
      "test_train\n",
      "train mean loss=62703.29739583333\n",
      "test_test\n",
      "test mean loss=88024.921875\n",
      "fin save.\n",
      "epoch 3612\n",
      "test_train\n",
      "train mean loss=62017.529947916664\n",
      "test_test\n",
      "test mean loss=87908.765625\n",
      "fin save.\n",
      "epoch 3613\n",
      "test_train\n",
      "train mean loss=61876.890234375\n",
      "test_test\n",
      "test mean loss=87797.14453125\n",
      "fin save.\n",
      "epoch 3614\n",
      "test_train\n",
      "train mean loss=62042.85729166667\n",
      "test_test\n",
      "test mean loss=87964.3359375\n",
      "fin save.\n",
      "epoch 3615\n",
      "test_train\n",
      "train mean loss=61317.433854166666\n",
      "test_test\n",
      "test mean loss=88149.1640625\n",
      "fin save.\n",
      "epoch 3616\n",
      "test_train\n",
      "train mean loss=62565.845052083336\n",
      "test_test\n",
      "test mean loss=87928.55078125\n",
      "fin save.\n",
      "epoch 3617\n",
      "test_train\n",
      "train mean loss=62338.464453125\n",
      "test_test\n",
      "test mean loss=88028.2265625\n",
      "fin save.\n",
      "epoch 3618\n",
      "test_train\n",
      "train mean loss=61659.04895833333\n",
      "test_test\n",
      "test mean loss=87967.08984375\n",
      "fin save.\n",
      "epoch 3619\n",
      "test_train\n",
      "train mean loss=62139.536458333336\n",
      "test_test\n",
      "test mean loss=87650.765625\n",
      "fin save.\n",
      "epoch 3620\n",
      "test_train\n",
      "train mean loss=62338.09479166667\n",
      "test_test\n",
      "test mean loss=87857.75390625\n",
      "fin save.\n",
      "epoch 3621\n",
      "test_train\n",
      "train mean loss=62213.656510416666\n",
      "test_test\n",
      "test mean loss=88085.94140625\n",
      "fin save.\n",
      "epoch 3622\n",
      "test_train\n",
      "train mean loss=61890.47552083333\n",
      "test_test\n",
      "test mean loss=87853.35546875\n",
      "fin save.\n",
      "epoch 3623\n",
      "test_train\n",
      "train mean loss=60775.254166666666\n",
      "test_test\n",
      "test mean loss=88211.4296875\n",
      "fin save.\n",
      "epoch 3624\n",
      "test_train\n",
      "train mean loss=62170.57994791667\n",
      "test_test\n",
      "test mean loss=88254.18359375\n",
      "fin save.\n",
      "epoch 3625\n",
      "test_train\n",
      "train mean loss=62781.16953125\n",
      "test_test\n",
      "test mean loss=88350.84765625\n",
      "fin save.\n",
      "epoch 3626\n",
      "test_train\n",
      "train mean loss=61666.43203125\n",
      "test_test\n",
      "test mean loss=88210.93359375\n",
      "fin save.\n",
      "epoch 3627\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=61932.52630208333\n",
      "test_test\n",
      "test mean loss=88236.03515625\n",
      "fin save.\n",
      "epoch 3628\n",
      "test_train\n",
      "train mean loss=61995.47369791667\n",
      "test_test\n",
      "test mean loss=88282.55859375\n",
      "fin save.\n",
      "epoch 3629\n",
      "test_train\n",
      "train mean loss=62502.19739583333\n",
      "test_test\n",
      "test mean loss=88203.40234375\n",
      "fin save.\n",
      "epoch 3630\n",
      "test_train\n",
      "train mean loss=63053.8578125\n",
      "test_test\n",
      "test mean loss=88235.43359375\n",
      "fin save.\n",
      "epoch 3631\n",
      "test_train\n",
      "train mean loss=63165.445052083334\n",
      "test_test\n",
      "test mean loss=88207.21484375\n",
      "fin save.\n",
      "epoch 3632\n",
      "test_train\n",
      "train mean loss=62337.552734375\n",
      "test_test\n",
      "test mean loss=88022.3671875\n",
      "fin save.\n",
      "epoch 3633\n",
      "test_train\n",
      "train mean loss=62293.72057291667\n",
      "test_test\n",
      "test mean loss=88171.484375\n",
      "fin save.\n",
      "epoch 3634\n",
      "test_train\n",
      "train mean loss=62006.273697916666\n",
      "test_test\n",
      "test mean loss=88138.4921875\n",
      "fin save.\n",
      "epoch 3635\n",
      "test_train\n",
      "train mean loss=61975.12786458333\n",
      "test_test\n",
      "test mean loss=88302.9375\n",
      "fin save.\n",
      "epoch 3636\n",
      "test_train\n",
      "train mean loss=62209.58151041667\n",
      "test_test\n",
      "test mean loss=88163.2734375\n",
      "fin save.\n",
      "epoch 3637\n",
      "test_train\n",
      "train mean loss=62875.805989583336\n",
      "test_test\n",
      "test mean loss=87915.765625\n",
      "fin save.\n",
      "epoch 3638\n",
      "test_train\n",
      "train mean loss=61773.09557291667\n",
      "test_test\n",
      "test mean loss=88173.05078125\n",
      "fin save.\n",
      "epoch 3639\n",
      "test_train\n",
      "train mean loss=62160.03828125\n",
      "test_test\n",
      "test mean loss=88227.1640625\n",
      "fin save.\n",
      "epoch 3640\n",
      "test_train\n",
      "train mean loss=62216.906510416666\n",
      "test_test\n",
      "test mean loss=88143.33203125\n",
      "fin save.\n",
      "epoch 3641\n",
      "test_train\n",
      "train mean loss=61685.00703125\n",
      "test_test\n",
      "test mean loss=88336.7734375\n",
      "fin save.\n",
      "epoch 3642\n",
      "test_train\n",
      "train mean loss=62459.63033854167\n",
      "test_test\n",
      "test mean loss=88030.27734375\n",
      "fin save.\n",
      "epoch 3643\n",
      "test_train\n",
      "train mean loss=61261.00677083333\n",
      "test_test\n",
      "test mean loss=88352.41796875\n",
      "fin save.\n",
      "epoch 3644\n",
      "test_train\n",
      "train mean loss=62040.73776041667\n",
      "test_test\n",
      "test mean loss=87976.94921875\n",
      "fin save.\n",
      "epoch 3645\n",
      "test_train\n",
      "train mean loss=62044.87265625\n",
      "test_test\n",
      "test mean loss=87989.38671875\n",
      "fin save.\n",
      "epoch 3646\n",
      "test_train\n",
      "train mean loss=63302.964192708336\n",
      "test_test\n",
      "test mean loss=87991.7265625\n",
      "fin save.\n",
      "epoch 3647\n",
      "test_train\n",
      "train mean loss=62384.546875\n",
      "test_test\n",
      "test mean loss=87913.0625\n",
      "fin save.\n",
      "epoch 3648\n",
      "test_train\n",
      "train mean loss=61997.04192708333\n",
      "test_test\n",
      "test mean loss=87904.1953125\n",
      "fin save.\n",
      "epoch 3649\n",
      "test_train\n",
      "train mean loss=62807.02526041667\n",
      "test_test\n",
      "test mean loss=87755.796875\n",
      "fin save.\n",
      "epoch 3650\n",
      "test_train\n",
      "train mean loss=62543.73541666667\n",
      "test_test\n",
      "test mean loss=87860.29296875\n",
      "fin save.\n",
      "epoch 3651\n",
      "test_train\n",
      "train mean loss=61917.440755208336\n",
      "test_test\n",
      "test mean loss=87846.6484375\n",
      "fin save.\n",
      "epoch 3652\n",
      "test_train\n",
      "train mean loss=63047.1984375\n",
      "test_test\n",
      "test mean loss=87745.11328125\n",
      "fin save.\n",
      "epoch 3653\n",
      "test_train\n",
      "train mean loss=62676.00677083333\n",
      "test_test\n",
      "test mean loss=88033.21875\n",
      "fin save.\n",
      "epoch 3654\n",
      "test_train\n",
      "train mean loss=62289.59192708333\n",
      "test_test\n",
      "test mean loss=87871.47265625\n",
      "fin save.\n",
      "epoch 3655\n",
      "test_train\n",
      "train mean loss=61963.9328125\n",
      "test_test\n",
      "test mean loss=87858.5078125\n",
      "fin save.\n",
      "epoch 3656\n",
      "test_train\n",
      "train mean loss=62246.97057291667\n",
      "test_test\n",
      "test mean loss=87942.41015625\n",
      "fin save.\n",
      "epoch 3657\n",
      "test_train\n",
      "train mean loss=61792.2125\n",
      "test_test\n",
      "test mean loss=87970.4453125\n",
      "fin save.\n",
      "epoch 3658\n",
      "test_train\n",
      "train mean loss=61951.585677083334\n",
      "test_test\n",
      "test mean loss=88068.60546875\n",
      "fin save.\n",
      "epoch 3659\n",
      "test_train\n",
      "train mean loss=61801.684895833336\n",
      "test_test\n",
      "test mean loss=88224.26171875\n",
      "fin save.\n",
      "epoch 3660\n",
      "test_train\n",
      "train mean loss=61977.78697916667\n",
      "test_test\n",
      "test mean loss=88140.01953125\n",
      "fin save.\n",
      "epoch 3661\n",
      "test_train\n",
      "train mean loss=62130.200390625\n",
      "test_test\n",
      "test mean loss=88317.3515625\n",
      "fin save.\n",
      "epoch 3662\n",
      "test_train\n",
      "train mean loss=63106.44192708333\n",
      "test_test\n",
      "test mean loss=88104.46484375\n",
      "fin save.\n",
      "epoch 3663\n",
      "test_train\n",
      "train mean loss=62833.26614583333\n",
      "test_test\n",
      "test mean loss=88177.2734375\n",
      "fin save.\n",
      "epoch 3664\n",
      "test_train\n",
      "train mean loss=62674.2203125\n",
      "test_test\n",
      "test mean loss=87996.109375\n",
      "fin save.\n",
      "epoch 3665\n",
      "test_train\n",
      "train mean loss=63364.334635416664\n",
      "test_test\n",
      "test mean loss=87817.90234375\n",
      "fin save.\n",
      "epoch 3666\n",
      "test_train\n",
      "train mean loss=61795.153645833336\n",
      "test_test\n",
      "test mean loss=88136.54296875\n",
      "fin save.\n",
      "epoch 3667\n",
      "test_train\n",
      "train mean loss=62834.926041666666\n",
      "test_test\n",
      "test mean loss=88177.10546875\n",
      "fin save.\n",
      "epoch 3668\n",
      "test_train\n",
      "train mean loss=62963.641927083336\n",
      "test_test\n",
      "test mean loss=88048.23046875\n",
      "fin save.\n",
      "epoch 3669\n",
      "test_train\n",
      "train mean loss=61803.03515625\n",
      "test_test\n",
      "test mean loss=87953.0703125\n",
      "fin save.\n",
      "epoch 3670\n",
      "test_train\n",
      "train mean loss=62240.996354166666\n",
      "test_test\n",
      "test mean loss=88122.77734375\n",
      "fin save.\n",
      "epoch 3671\n",
      "test_train\n",
      "train mean loss=61407.949609375\n",
      "test_test\n",
      "test mean loss=87956.46484375\n",
      "fin save.\n",
      "epoch 3672\n",
      "test_train\n",
      "train mean loss=62514.61510416667\n",
      "test_test\n",
      "test mean loss=88107.19921875\n",
      "fin save.\n",
      "epoch 3673\n",
      "test_train\n",
      "train mean loss=62384.93411458333\n",
      "test_test\n",
      "test mean loss=88237.23046875\n",
      "fin save.\n",
      "epoch 3674\n",
      "test_train\n",
      "train mean loss=63176.12447916667\n",
      "test_test\n",
      "test mean loss=88268.6875\n",
      "fin save.\n",
      "epoch 3675\n",
      "test_train\n",
      "train mean loss=62749.27434895833\n",
      "test_test\n",
      "test mean loss=88152.33984375\n",
      "fin save.\n",
      "epoch 3676\n",
      "test_train\n",
      "train mean loss=62250.94348958333\n",
      "test_test\n",
      "test mean loss=88275.6015625\n",
      "fin save.\n",
      "epoch 3677\n",
      "test_train\n",
      "train mean loss=62279.71145833333\n",
      "test_test\n",
      "test mean loss=88385.078125\n",
      "fin save.\n",
      "epoch 3678\n",
      "test_train\n",
      "train mean loss=62362.48541666667\n",
      "test_test\n",
      "test mean loss=88311.55078125\n",
      "fin save.\n",
      "epoch 3679\n",
      "test_train\n",
      "train mean loss=62039.14830729167\n",
      "test_test\n",
      "test mean loss=87958.6796875\n",
      "fin save.\n",
      "epoch 3680\n",
      "test_train\n",
      "train mean loss=62724.88294270833\n",
      "test_test\n",
      "test mean loss=88229.015625\n",
      "fin save.\n",
      "epoch 3681\n",
      "test_train\n",
      "train mean loss=61473.73489583333\n",
      "test_test\n",
      "test mean loss=88322.00390625\n",
      "fin save.\n",
      "epoch 3682\n",
      "test_train\n",
      "train mean loss=63039.308984375\n",
      "test_test\n",
      "test mean loss=88399.50390625\n",
      "fin save.\n",
      "epoch 3683\n",
      "test_train\n",
      "train mean loss=62450.8609375\n",
      "test_test\n",
      "test mean loss=88283.20703125\n",
      "fin save.\n",
      "epoch 3684\n",
      "test_train\n",
      "train mean loss=62211.638020833336\n",
      "test_test\n",
      "test mean loss=88459.734375\n",
      "fin save.\n",
      "epoch 3685\n",
      "test_train\n",
      "train mean loss=62234.52786458333\n",
      "test_test\n",
      "test mean loss=88519.265625\n",
      "fin save.\n",
      "epoch 3686\n",
      "test_train\n",
      "train mean loss=62131.947005208334\n",
      "test_test\n",
      "test mean loss=88731.2421875\n",
      "fin save.\n",
      "epoch 3687\n",
      "test_train\n",
      "train mean loss=63081.53515625\n",
      "test_test\n",
      "test mean loss=88583.86328125\n",
      "fin save.\n",
      "epoch 3688\n",
      "test_train\n",
      "train mean loss=61502.528125\n",
      "test_test\n",
      "test mean loss=88527.734375\n",
      "fin save.\n",
      "epoch 3689\n",
      "test_train\n",
      "train mean loss=62672.35638020833\n",
      "test_test\n",
      "test mean loss=89093.8046875\n",
      "fin save.\n",
      "epoch 3690\n",
      "test_train\n",
      "train mean loss=62680.835677083334\n",
      "test_test\n",
      "test mean loss=88769.859375\n",
      "fin save.\n",
      "epoch 3691\n",
      "test_train\n",
      "train mean loss=62129.916276041666\n",
      "test_test\n",
      "test mean loss=88659.046875\n",
      "fin save.\n",
      "epoch 3692\n",
      "test_train\n",
      "train mean loss=63011.83880208333\n",
      "test_test\n",
      "test mean loss=88663.3203125\n",
      "fin save.\n",
      "epoch 3693\n",
      "test_train\n",
      "train mean loss=62756.816666666666\n",
      "test_test\n",
      "test mean loss=88711.91796875\n",
      "fin save.\n",
      "epoch 3694\n",
      "test_train\n",
      "train mean loss=61299.30364583333\n",
      "test_test\n",
      "test mean loss=88496.9765625\n",
      "fin save.\n",
      "epoch 3695\n",
      "test_train\n",
      "train mean loss=62632.793229166666\n",
      "test_test\n",
      "test mean loss=88314.55078125\n",
      "fin save.\n",
      "epoch 3696\n",
      "test_train\n",
      "train mean loss=62090.460546875\n",
      "test_test\n",
      "test mean loss=88441.0625\n",
      "fin save.\n",
      "epoch 3697\n",
      "test_train\n",
      "train mean loss=61953.939192708334\n",
      "test_test\n",
      "test mean loss=88338.52734375\n",
      "fin save.\n",
      "epoch 3698\n",
      "test_train\n",
      "train mean loss=62120.58645833333\n",
      "test_test\n",
      "test mean loss=88337.4609375\n",
      "fin save.\n",
      "epoch 3699\n",
      "test_train\n",
      "train mean loss=62711.36627604167\n",
      "test_test\n",
      "test mean loss=88687.1875\n",
      "fin save.\n",
      "epoch 3700\n",
      "test_train\n",
      "train mean loss=61934.458723958334\n",
      "test_test\n",
      "test mean loss=88755.3203125\n",
      "fin save.\n",
      "epoch 3701\n",
      "test_train\n",
      "train mean loss=61723.996875\n",
      "test_test\n",
      "test mean loss=88595.53515625\n",
      "fin save.\n",
      "epoch 3702\n",
      "test_train\n",
      "train mean loss=62299.568619791666\n",
      "test_test\n",
      "test mean loss=88530.8984375\n",
      "fin save.\n",
      "epoch 3703\n",
      "test_train\n",
      "train mean loss=63106.90859375\n",
      "test_test\n",
      "test mean loss=88569.68359375\n",
      "fin save.\n",
      "epoch 3704\n",
      "test_train\n",
      "train mean loss=62415.34140625\n",
      "test_test\n",
      "test mean loss=88542.2734375\n",
      "fin save.\n",
      "epoch 3705\n",
      "test_train\n",
      "train mean loss=61928.794270833336\n",
      "test_test\n",
      "test mean loss=88665.359375\n",
      "fin save.\n",
      "epoch 3706\n",
      "test_train\n",
      "train mean loss=62947.387890625\n",
      "test_test\n",
      "test mean loss=88630.453125\n",
      "fin save.\n",
      "epoch 3707\n",
      "test_train\n",
      "train mean loss=63080.855729166666\n",
      "test_test\n",
      "test mean loss=88775.72265625\n",
      "fin save.\n",
      "epoch 3708\n",
      "test_train\n",
      "train mean loss=61769.169921875\n",
      "test_test\n",
      "test mean loss=88417.2109375\n",
      "fin save.\n",
      "epoch 3709\n",
      "test_train\n",
      "train mean loss=62548.57708333333\n",
      "test_test\n",
      "test mean loss=88508.4375\n",
      "fin save.\n",
      "epoch 3710\n",
      "test_train\n",
      "train mean loss=62344.58307291667\n",
      "test_test\n",
      "test mean loss=88546.453125\n",
      "fin save.\n",
      "epoch 3711\n",
      "test_train\n",
      "train mean loss=62682.63619791667\n",
      "test_test\n",
      "test mean loss=88515.26953125\n",
      "fin save.\n",
      "epoch 3712\n",
      "test_train\n",
      "train mean loss=63360.30416666667\n",
      "test_test\n",
      "test mean loss=88263.41015625\n",
      "fin save.\n",
      "epoch 3713\n",
      "test_train\n",
      "train mean loss=62944.61380208333\n",
      "test_test\n",
      "test mean loss=88176.06640625\n",
      "fin save.\n",
      "epoch 3714\n",
      "test_train\n",
      "train mean loss=62524.37317708333\n",
      "test_test\n",
      "test mean loss=88236.52734375\n",
      "fin save.\n",
      "epoch 3715\n",
      "test_train\n",
      "train mean loss=62375.20026041667\n",
      "test_test\n",
      "test mean loss=88194.578125\n",
      "fin save.\n",
      "epoch 3716\n",
      "test_train\n",
      "train mean loss=62489.147135416664\n",
      "test_test\n",
      "test mean loss=88221.8515625\n",
      "fin save.\n",
      "epoch 3717\n",
      "test_train\n",
      "train mean loss=63209.2421875\n",
      "test_test\n",
      "test mean loss=88100.1875\n",
      "fin save.\n",
      "epoch 3718\n",
      "test_train\n",
      "train mean loss=61829.665625\n",
      "test_test\n",
      "test mean loss=87856.1328125\n",
      "fin save.\n",
      "epoch 3719\n",
      "test_train\n",
      "train mean loss=62013.31744791667\n",
      "test_test\n",
      "test mean loss=87839.83984375\n",
      "fin save.\n",
      "epoch 3720\n",
      "test_train\n",
      "train mean loss=62465.45520833333\n",
      "test_test\n",
      "test mean loss=87967.609375\n",
      "fin save.\n",
      "epoch 3721\n",
      "test_train\n",
      "train mean loss=63047.95390625\n",
      "test_test\n",
      "test mean loss=87898.0078125\n",
      "fin save.\n",
      "epoch 3722\n",
      "test_train\n",
      "train mean loss=62806.655598958336\n",
      "test_test\n",
      "test mean loss=87897.22265625\n",
      "fin save.\n",
      "epoch 3723\n",
      "test_train\n",
      "train mean loss=61909.73229166667\n",
      "test_test\n",
      "test mean loss=87963.34765625\n",
      "fin save.\n",
      "epoch 3724\n",
      "test_train\n",
      "train mean loss=63092.65859375\n",
      "test_test\n",
      "test mean loss=88239.89453125\n",
      "fin save.\n",
      "epoch 3725\n",
      "test_train\n",
      "train mean loss=63057.04010416667\n",
      "test_test\n",
      "test mean loss=88216.76953125\n",
      "fin save.\n",
      "epoch 3726\n",
      "test_train\n",
      "train mean loss=61757.613020833334\n",
      "test_test\n",
      "test mean loss=88023.5\n",
      "fin save.\n",
      "epoch 3727\n",
      "test_train\n",
      "train mean loss=63190.943359375\n",
      "test_test\n",
      "test mean loss=88129.08984375\n",
      "fin save.\n",
      "epoch 3728\n",
      "test_train\n",
      "train mean loss=62330.23424479167\n",
      "test_test\n",
      "test mean loss=88142.58203125\n",
      "fin save.\n",
      "epoch 3729\n",
      "test_train\n",
      "train mean loss=62013.598958333336\n",
      "test_test\n",
      "test mean loss=88216.62890625\n",
      "fin save.\n",
      "epoch 3730\n",
      "test_train\n",
      "train mean loss=62830.33971354167\n",
      "test_test\n",
      "test mean loss=88123.58203125\n",
      "fin save.\n",
      "epoch 3731\n",
      "test_train\n",
      "train mean loss=62056.98346354167\n",
      "test_test\n",
      "test mean loss=88046.27734375\n",
      "fin save.\n",
      "epoch 3732\n",
      "test_train\n",
      "train mean loss=62385.8515625\n",
      "test_test\n",
      "test mean loss=87942.27734375\n",
      "fin save.\n",
      "epoch 3733\n",
      "test_train\n",
      "train mean loss=62029.84036458333\n",
      "test_test\n",
      "test mean loss=88033.67578125\n",
      "fin save.\n",
      "epoch 3734\n",
      "test_train\n",
      "train mean loss=62497.50703125\n",
      "test_test\n",
      "test mean loss=87874.1328125\n",
      "fin save.\n",
      "epoch 3735\n",
      "test_train\n",
      "train mean loss=63142.994921875\n",
      "test_test\n",
      "test mean loss=88054.54296875\n",
      "fin save.\n",
      "epoch 3736\n",
      "test_train\n",
      "train mean loss=63034.309895833336\n",
      "test_test\n",
      "test mean loss=87920.26171875\n",
      "fin save.\n",
      "epoch 3737\n",
      "test_train\n",
      "train mean loss=62032.40963541667\n",
      "test_test\n",
      "test mean loss=88013.4921875\n",
      "fin save.\n",
      "epoch 3738\n",
      "test_train\n",
      "train mean loss=63201.22708333333\n",
      "test_test\n",
      "test mean loss=88045.390625\n",
      "fin save.\n",
      "epoch 3739\n",
      "test_train\n",
      "train mean loss=62637.755859375\n",
      "test_test\n",
      "test mean loss=88136.10546875\n",
      "fin save.\n",
      "epoch 3740\n",
      "test_train\n",
      "train mean loss=64059.402994791664\n",
      "test_test\n",
      "test mean loss=87984.28125\n",
      "fin save.\n",
      "epoch 3741\n",
      "test_train\n",
      "train mean loss=62912.554296875\n",
      "test_test\n",
      "test mean loss=88023.95703125\n",
      "fin save.\n",
      "epoch 3742\n",
      "test_train\n",
      "train mean loss=62952.499739583334\n",
      "test_test\n",
      "test mean loss=87904.97265625\n",
      "fin save.\n",
      "epoch 3743\n",
      "test_train\n",
      "train mean loss=62562.3609375\n",
      "test_test\n",
      "test mean loss=87803.98046875\n",
      "fin save.\n",
      "epoch 3744\n",
      "test_train\n",
      "train mean loss=62351.226822916666\n",
      "test_test\n",
      "test mean loss=87611.5625\n",
      "fin save.\n",
      "epoch 3745\n",
      "test_train\n",
      "train mean loss=61946.09661458333\n",
      "test_test\n",
      "test mean loss=87467.06640625\n",
      "fin save.\n",
      "epoch 3746\n",
      "test_train\n",
      "train mean loss=62041.30859375\n",
      "test_test\n",
      "test mean loss=87438.34765625\n",
      "fin save.\n",
      "epoch 3747\n",
      "test_train\n",
      "train mean loss=62879.081640625\n",
      "test_test\n",
      "test mean loss=87687.71875\n",
      "fin save.\n",
      "epoch 3748\n",
      "test_train\n",
      "train mean loss=62471.8875\n",
      "test_test\n",
      "test mean loss=87755.0703125\n",
      "fin save.\n",
      "epoch 3749\n",
      "test_train\n",
      "train mean loss=62953.01744791667\n",
      "test_test\n",
      "test mean loss=88053.96484375\n",
      "fin save.\n",
      "epoch 3750\n",
      "test_train\n",
      "train mean loss=62388.88385416667\n",
      "test_test\n",
      "test mean loss=87798.51171875\n",
      "fin save.\n",
      "epoch 3751\n",
      "test_train\n",
      "train mean loss=62884.70078125\n",
      "test_test\n",
      "test mean loss=87713.3828125\n",
      "fin save.\n",
      "epoch 3752\n",
      "test_train\n",
      "train mean loss=62559.72083333333\n",
      "test_test\n",
      "test mean loss=87860.2734375\n",
      "fin save.\n",
      "epoch 3753\n",
      "test_train\n",
      "train mean loss=63540.64270833333\n",
      "test_test\n",
      "test mean loss=87868.89453125\n",
      "fin save.\n",
      "epoch 3754\n",
      "test_train\n",
      "train mean loss=64204.694010416664\n",
      "test_test\n",
      "test mean loss=88046.26171875\n",
      "fin save.\n",
      "epoch 3755\n",
      "test_train\n",
      "train mean loss=62209.699479166666\n",
      "test_test\n",
      "test mean loss=87973.63671875\n",
      "fin save.\n",
      "epoch 3756\n",
      "test_train\n",
      "train mean loss=62614.29635416667\n",
      "test_test\n",
      "test mean loss=88192.7578125\n",
      "fin save.\n",
      "epoch 3757\n",
      "test_train\n",
      "train mean loss=62518.334635416664\n",
      "test_test\n",
      "test mean loss=88297.1328125\n",
      "fin save.\n",
      "epoch 3758\n",
      "test_train\n",
      "train mean loss=62552.988020833334\n",
      "test_test\n",
      "test mean loss=88477.74609375\n",
      "fin save.\n",
      "epoch 3759\n",
      "test_train\n",
      "train mean loss=61398.15520833333\n",
      "test_test\n",
      "test mean loss=88179.92578125\n",
      "fin save.\n",
      "epoch 3760\n",
      "test_train\n",
      "train mean loss=62628.94973958333\n",
      "test_test\n",
      "test mean loss=88173.86328125\n",
      "fin save.\n",
      "epoch 3761\n",
      "test_train\n",
      "train mean loss=62778.19453125\n",
      "test_test\n",
      "test mean loss=88143.203125\n",
      "fin save.\n",
      "epoch 3762\n",
      "test_train\n",
      "train mean loss=62628.91510416667\n",
      "test_test\n",
      "test mean loss=88041.8203125\n",
      "fin save.\n",
      "epoch 3763\n",
      "test_train\n",
      "train mean loss=62853.46041666667\n",
      "test_test\n",
      "test mean loss=88108.6171875\n",
      "fin save.\n",
      "epoch 3764\n",
      "test_train\n",
      "train mean loss=62237.662760416664\n",
      "test_test\n",
      "test mean loss=87754.3125\n",
      "fin save.\n",
      "epoch 3765\n",
      "test_train\n",
      "train mean loss=62435.76067708333\n",
      "test_test\n",
      "test mean loss=87975.05078125\n",
      "fin save.\n",
      "epoch 3766\n",
      "test_train\n",
      "train mean loss=62078.74375\n",
      "test_test\n",
      "test mean loss=87822.1484375\n",
      "fin save.\n",
      "epoch 3767\n",
      "test_train\n",
      "train mean loss=62647.85846354167\n",
      "test_test\n",
      "test mean loss=88093.75\n",
      "fin save.\n",
      "epoch 3768\n",
      "test_train\n",
      "train mean loss=62073.48229166667\n",
      "test_test\n",
      "test mean loss=88030.66796875\n",
      "fin save.\n",
      "epoch 3769\n",
      "test_train\n",
      "train mean loss=62039.6046875\n",
      "test_test\n",
      "test mean loss=87952.11328125\n",
      "fin save.\n",
      "epoch 3770\n",
      "test_train\n",
      "train mean loss=61572.51809895833\n",
      "test_test\n",
      "test mean loss=87950.92578125\n",
      "fin save.\n",
      "epoch 3771\n",
      "test_train\n",
      "train mean loss=61762.992578125\n",
      "test_test\n",
      "test mean loss=87981.75\n",
      "fin save.\n",
      "epoch 3772\n",
      "test_train\n",
      "train mean loss=62834.3359375\n",
      "test_test\n",
      "test mean loss=88020.62890625\n",
      "fin save.\n",
      "epoch 3773\n",
      "test_train\n",
      "train mean loss=61675.77682291667\n",
      "test_test\n",
      "test mean loss=87881.62109375\n",
      "fin save.\n",
      "epoch 3774\n",
      "test_train\n",
      "train mean loss=62201.76848958333\n",
      "test_test\n",
      "test mean loss=88047.15625\n",
      "fin save.\n",
      "epoch 3775\n",
      "test_train\n",
      "train mean loss=62299.79479166667\n",
      "test_test\n",
      "test mean loss=88239.55078125\n",
      "fin save.\n",
      "epoch 3776\n",
      "test_train\n",
      "train mean loss=62241.73098958333\n",
      "test_test\n",
      "test mean loss=88327.06640625\n",
      "fin save.\n",
      "epoch 3777\n",
      "test_train\n",
      "train mean loss=63125.18151041667\n",
      "test_test\n",
      "test mean loss=88129.03125\n",
      "fin save.\n",
      "epoch 3778\n",
      "test_train\n",
      "train mean loss=62780.26080729167\n",
      "test_test\n",
      "test mean loss=88324.89453125\n",
      "fin save.\n",
      "epoch 3779\n",
      "test_train\n",
      "train mean loss=62500.96640625\n",
      "test_test\n",
      "test mean loss=88281.2578125\n",
      "fin save.\n",
      "epoch 3780\n",
      "test_train\n",
      "train mean loss=62256.673046875\n",
      "test_test\n",
      "test mean loss=88324.2421875\n",
      "fin save.\n",
      "epoch 3781\n",
      "test_train\n",
      "train mean loss=63053.029947916664\n",
      "test_test\n",
      "test mean loss=88273.25390625\n",
      "fin save.\n",
      "epoch 3782\n",
      "test_train\n",
      "train mean loss=62802.35833333333\n",
      "test_test\n",
      "test mean loss=88354.359375\n",
      "fin save.\n",
      "epoch 3783\n",
      "test_train\n",
      "train mean loss=62959.21640625\n",
      "test_test\n",
      "test mean loss=88386.1640625\n",
      "fin save.\n",
      "epoch 3784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_train\n",
      "train mean loss=62313.311197916664\n",
      "test_test\n",
      "test mean loss=88696.0078125\n",
      "fin save.\n",
      "epoch 3785\n",
      "test_train\n",
      "train mean loss=62075.278125\n",
      "test_test\n",
      "test mean loss=88487.375\n",
      "fin save.\n",
      "epoch 3786\n",
      "test_train\n",
      "train mean loss=62856.834635416664\n",
      "test_test\n",
      "test mean loss=88673.546875\n",
      "fin save.\n",
      "epoch 3787\n",
      "test_train\n",
      "train mean loss=63288.420572916664\n",
      "test_test\n",
      "test mean loss=88613.03515625\n",
      "fin save.\n",
      "epoch 3788\n",
      "test_train\n",
      "train mean loss=62423.29348958333\n",
      "test_test\n",
      "test mean loss=88441.4609375\n",
      "fin save.\n",
      "epoch 3789\n",
      "test_train\n",
      "train mean loss=63044.26419270833\n",
      "test_test\n",
      "test mean loss=88474.90625\n",
      "fin save.\n",
      "epoch 3790\n",
      "test_train\n",
      "train mean loss=62245.12994791667\n",
      "test_test\n",
      "test mean loss=88359.66015625\n",
      "fin save.\n",
      "epoch 3791\n",
      "test_train\n",
      "train mean loss=62090.0609375\n",
      "test_test\n",
      "test mean loss=88257.25\n",
      "fin save.\n",
      "epoch 3792\n",
      "test_train\n",
      "train mean loss=62415.10598958333\n",
      "test_test\n",
      "test mean loss=88313.578125\n",
      "fin save.\n",
      "epoch 3793\n",
      "test_train\n",
      "train mean loss=62980.56536458333\n",
      "test_test\n",
      "test mean loss=88395.52734375\n",
      "fin save.\n",
      "epoch 3794\n",
      "test_train\n",
      "train mean loss=61645.47864583333\n",
      "test_test\n",
      "test mean loss=88365.6875\n",
      "fin save.\n",
      "epoch 3795\n",
      "test_train\n",
      "train mean loss=63043.27552083333\n",
      "test_test\n",
      "test mean loss=88243.4296875\n",
      "fin save.\n",
      "epoch 3796\n",
      "test_train\n",
      "train mean loss=62740.53958333333\n",
      "test_test\n",
      "test mean loss=88522.23046875\n",
      "fin save.\n",
      "epoch 3797\n",
      "test_train\n",
      "train mean loss=62394.28723958333\n",
      "test_test\n",
      "test mean loss=88355.5546875\n",
      "fin save.\n",
      "epoch 3798\n",
      "test_train\n",
      "train mean loss=62838.26744791667\n",
      "test_test\n",
      "test mean loss=88447.7109375\n",
      "fin save.\n",
      "epoch 3799\n",
      "test_train\n",
      "train mean loss=62874.433333333334\n",
      "test_test\n",
      "test mean loss=88372.75\n",
      "fin save.\n",
      "epoch 3800\n",
      "test_train\n",
      "train mean loss=62623.6359375\n",
      "test_test\n",
      "test mean loss=88420.89453125\n",
      "fin save.\n",
      "epoch 3801\n",
      "test_train\n",
      "train mean loss=62557.4203125\n",
      "test_test\n",
      "test mean loss=87935.578125\n",
      "fin save.\n",
      "epoch 3802\n",
      "test_train\n",
      "train mean loss=62075.87317708333\n",
      "test_test\n",
      "test mean loss=87940.86328125\n",
      "fin save.\n",
      "epoch 3803\n",
      "test_train\n",
      "train mean loss=62784.234375\n",
      "test_test\n",
      "test mean loss=87930.59375\n",
      "fin save.\n",
      "epoch 3804\n",
      "test_train\n",
      "train mean loss=63013.059244791664\n",
      "test_test\n",
      "test mean loss=88359.43359375\n",
      "fin save.\n",
      "epoch 3805\n",
      "test_train\n",
      "train mean loss=62896.541666666664\n",
      "test_test\n",
      "test mean loss=88074.01953125\n",
      "fin save.\n",
      "epoch 3806\n",
      "test_train\n",
      "train mean loss=62759.96822916667\n",
      "test_test\n",
      "test mean loss=88173.38671875\n",
      "fin save.\n",
      "epoch 3807\n",
      "test_train\n",
      "train mean loss=61862.30572916667\n",
      "test_test\n",
      "test mean loss=88577.5234375\n",
      "fin save.\n",
      "epoch 3808\n",
      "test_train\n",
      "train mean loss=61883.92630208333\n",
      "test_test\n",
      "test mean loss=88704.65625\n",
      "fin save.\n",
      "epoch 3809\n",
      "test_train\n",
      "train mean loss=62837.367578125\n",
      "test_test\n",
      "test mean loss=88778.20703125\n",
      "fin save.\n",
      "epoch 3810\n",
      "test_train\n",
      "train mean loss=63492.381510416664\n",
      "test_test\n",
      "test mean loss=88687.3828125\n",
      "fin save.\n",
      "epoch 3811\n",
      "test_train\n",
      "train mean loss=61540.46276041667\n",
      "test_test\n",
      "test mean loss=88895.91015625\n",
      "fin save.\n",
      "epoch 3812\n",
      "test_train\n",
      "train mean loss=61758.03177083333\n",
      "test_test\n",
      "test mean loss=88760.34765625\n",
      "fin save.\n",
      "epoch 3813\n",
      "test_train\n",
      "train mean loss=62095.2140625\n",
      "test_test\n",
      "test mean loss=88578.375\n",
      "fin save.\n",
      "epoch 3814\n",
      "test_train\n",
      "train mean loss=61897.67239583333\n",
      "test_test\n",
      "test mean loss=88604.171875\n",
      "fin save.\n",
      "epoch 3815\n",
      "test_train\n",
      "train mean loss=62501.32864583333\n",
      "test_test\n",
      "test mean loss=88496.796875\n",
      "fin save.\n",
      "epoch 3816\n",
      "test_train\n",
      "train mean loss=61794.9875\n",
      "test_test\n",
      "test mean loss=88513.7734375\n",
      "fin save.\n",
      "epoch 3817\n",
      "test_train\n",
      "train mean loss=61464.119921875\n",
      "test_test\n",
      "test mean loss=88358.48828125\n",
      "fin save.\n",
      "epoch 3818\n",
      "test_train\n",
      "train mean loss=61849.475260416664\n",
      "test_test\n",
      "test mean loss=88407.54296875\n",
      "fin save.\n",
      "epoch 3819\n",
      "test_train\n",
      "train mean loss=62335.09817708333\n",
      "test_test\n",
      "test mean loss=88456.32421875\n",
      "fin save.\n",
      "epoch 3820\n",
      "test_train\n",
      "train mean loss=61677.926953125\n",
      "test_test\n",
      "test mean loss=88664.63671875\n",
      "fin save.\n",
      "epoch 3821\n",
      "test_train\n",
      "train mean loss=62029.111328125\n",
      "test_test\n",
      "test mean loss=88595.82421875\n",
      "fin save.\n",
      "epoch 3822\n",
      "test_train\n",
      "train mean loss=63098.673177083336\n",
      "test_test\n",
      "test mean loss=88444.96875\n",
      "fin save.\n",
      "epoch 3823\n",
      "test_train\n",
      "train mean loss=62140.20559895833\n",
      "test_test\n",
      "test mean loss=88192.38671875\n",
      "fin save.\n",
      "epoch 3824\n",
      "test_train\n",
      "train mean loss=62584.430078125\n",
      "test_test\n",
      "test mean loss=88314.6953125\n",
      "fin save.\n",
      "epoch 3825\n",
      "test_train\n",
      "train mean loss=61804.239583333336\n",
      "test_test\n",
      "test mean loss=88304.8515625\n",
      "fin save.\n",
      "epoch 3826\n",
      "test_train\n",
      "train mean loss=61247.66354166667\n",
      "test_test\n",
      "test mean loss=88298.671875\n",
      "fin save.\n",
      "epoch 3827\n",
      "test_train\n",
      "train mean loss=62592.81536458333\n",
      "test_test\n",
      "test mean loss=88334.359375\n",
      "fin save.\n",
      "epoch 3828\n",
      "test_train\n",
      "train mean loss=62200.71015625\n",
      "test_test\n",
      "test mean loss=88220.91796875\n",
      "fin save.\n",
      "epoch 3829\n",
      "test_train\n",
      "train mean loss=62980.59713541667\n",
      "test_test\n",
      "test mean loss=88381.6796875\n",
      "fin save.\n",
      "epoch 3830\n",
      "test_train\n",
      "train mean loss=62393.6828125\n",
      "test_test\n",
      "test mean loss=87985.4609375\n",
      "fin save.\n",
      "epoch 3831\n",
      "test_train\n",
      "train mean loss=61508.894791666666\n",
      "test_test\n",
      "test mean loss=88080.1484375\n",
      "fin save.\n",
      "epoch 3832\n",
      "test_train\n",
      "train mean loss=62114.08151041667\n",
      "test_test\n",
      "test mean loss=88232.75\n",
      "fin save.\n",
      "epoch 3833\n",
      "test_train\n",
      "train mean loss=62182.017838541666\n",
      "test_test\n",
      "test mean loss=88029.765625\n",
      "fin save.\n",
      "epoch 3834\n",
      "test_train\n",
      "train mean loss=61976.86901041667\n",
      "test_test\n",
      "test mean loss=88208.53515625\n",
      "fin save.\n",
      "epoch 3835\n",
      "test_train\n",
      "train mean loss=62709.50546875\n",
      "test_test\n",
      "test mean loss=88350.4453125\n",
      "fin save.\n",
      "epoch 3836\n",
      "test_train\n",
      "train mean loss=62276.94635416667\n",
      "test_test\n",
      "test mean loss=88280.39453125\n",
      "fin save.\n",
      "epoch 3837\n",
      "test_train\n",
      "train mean loss=63756.430859375\n",
      "test_test\n",
      "test mean loss=88061.09375\n",
      "fin save.\n",
      "epoch 3838\n",
      "test_train\n",
      "train mean loss=62743.52005208333\n",
      "test_test\n",
      "test mean loss=88163.83203125\n",
      "fin save.\n",
      "epoch 3839\n",
      "test_train\n",
      "train mean loss=63176.229817708336\n",
      "test_test\n",
      "test mean loss=87949.9609375\n",
      "fin save.\n",
      "epoch 3840\n",
      "test_train\n",
      "train mean loss=61698.110677083336\n",
      "test_test\n",
      "test mean loss=88067.2421875\n",
      "fin save.\n",
      "epoch 3841\n",
      "test_train\n",
      "train mean loss=62349.95364583333\n",
      "test_test\n",
      "test mean loss=88165.9453125\n",
      "fin save.\n",
      "epoch 3842\n",
      "test_train\n",
      "train mean loss=62488.573958333334\n",
      "test_test\n",
      "test mean loss=88170.1796875\n",
      "fin save.\n",
      "epoch 3843\n",
      "test_train\n",
      "train mean loss=62156.04635416667\n",
      "test_test\n",
      "test mean loss=88112.56640625\n",
      "fin save.\n",
      "epoch 3844\n",
      "test_train\n",
      "train mean loss=62356.75286458333\n",
      "test_test\n",
      "test mean loss=88066.5703125\n",
      "fin save.\n",
      "epoch 3845\n",
      "test_train\n",
      "train mean loss=62399.38098958333\n",
      "test_test\n",
      "test mean loss=88219.91015625\n",
      "fin save.\n",
      "epoch 3846\n",
      "test_train\n",
      "train mean loss=61868.93151041667\n",
      "test_test\n",
      "test mean loss=88257.81640625\n",
      "fin save.\n",
      "epoch 3847\n",
      "test_train\n",
      "train mean loss=62252.99322916667\n",
      "test_test\n",
      "test mean loss=88355.359375\n",
      "fin save.\n",
      "epoch 3848\n",
      "test_train\n",
      "train mean loss=62459.60651041667\n",
      "test_test\n",
      "test mean loss=88351.75390625\n",
      "fin save.\n",
      "epoch 3849\n",
      "test_train\n",
      "train mean loss=62233.01953125\n",
      "test_test\n",
      "test mean loss=88303.546875\n",
      "fin save.\n",
      "epoch 3850\n",
      "test_train\n",
      "train mean loss=61991.216796875\n",
      "test_test\n",
      "test mean loss=88061.80859375\n",
      "fin save.\n",
      "epoch 3851\n",
      "test_train\n",
      "train mean loss=63537.81145833333\n",
      "test_test\n",
      "test mean loss=87968.2109375\n",
      "fin save.\n",
      "epoch 3852\n",
      "test_train\n",
      "train mean loss=61726.57708333333\n",
      "test_test\n",
      "test mean loss=87822.640625\n",
      "fin save.\n",
      "epoch 3853\n",
      "test_train\n",
      "train mean loss=63174.10208333333\n",
      "test_test\n",
      "test mean loss=87788.28125\n",
      "fin save.\n",
      "epoch 3854\n",
      "test_train\n",
      "train mean loss=62069.075390625\n",
      "test_test\n",
      "test mean loss=87894.26171875\n",
      "fin save.\n",
      "epoch 3855\n",
      "test_train\n",
      "train mean loss=62668.40390625\n",
      "test_test\n",
      "test mean loss=87983.875\n",
      "fin save.\n",
      "epoch 3856\n",
      "test_train\n",
      "train mean loss=62986.85104166667\n",
      "test_test\n",
      "test mean loss=88169.8125\n",
      "fin save.\n",
      "epoch 3857\n",
      "test_train\n",
      "train mean loss=61887.4015625\n",
      "test_test\n",
      "test mean loss=88183.91015625\n",
      "fin save.\n",
      "epoch 3858\n",
      "test_train\n",
      "train mean loss=60900.57083333333\n",
      "test_test\n",
      "test mean loss=88330.046875\n",
      "fin save.\n",
      "epoch 3859\n",
      "test_train\n",
      "train mean loss=62830.39505208333\n",
      "test_test\n",
      "test mean loss=88307.9453125\n",
      "fin save.\n",
      "epoch 3860\n",
      "test_train\n",
      "train mean loss=61079.762109375\n",
      "test_test\n",
      "test mean loss=88334.4296875\n",
      "fin save.\n",
      "epoch 3861\n",
      "test_train\n",
      "train mean loss=61142.67083333333\n",
      "test_test\n",
      "test mean loss=88201.7109375\n",
      "fin save.\n",
      "epoch 3862\n",
      "test_train\n",
      "train mean loss=63111.50013020833\n",
      "test_test\n",
      "test mean loss=88150.8828125\n",
      "fin save.\n",
      "epoch 3863\n",
      "test_train\n",
      "train mean loss=62359.66848958333\n",
      "test_test\n",
      "test mean loss=88341.60546875\n",
      "fin save.\n",
      "epoch 3864\n",
      "test_train\n",
      "train mean loss=62250.9125\n",
      "test_test\n",
      "test mean loss=88388.65625\n",
      "fin save.\n",
      "epoch 3865\n",
      "test_train\n",
      "train mean loss=63276.33125\n",
      "test_test\n",
      "test mean loss=88467.1484375\n",
      "fin save.\n",
      "epoch 3866\n",
      "test_train\n",
      "train mean loss=63838.483072916664\n",
      "test_test\n",
      "test mean loss=88143.9765625\n",
      "fin save.\n",
      "epoch 3867\n",
      "test_train\n",
      "train mean loss=62767.21145833333\n",
      "test_test\n",
      "test mean loss=88412.2421875\n",
      "fin save.\n",
      "epoch 3868\n",
      "test_train\n",
      "train mean loss=62040.49231770833\n",
      "test_test\n",
      "test mean loss=88547.109375\n",
      "fin save.\n",
      "epoch 3869\n",
      "test_train\n",
      "train mean loss=61731.164322916666\n",
      "test_test\n",
      "test mean loss=88655.9609375\n",
      "fin save.\n",
      "epoch 3870\n",
      "test_train\n",
      "train mean loss=61302.18359375\n",
      "test_test\n",
      "test mean loss=88814.37109375\n",
      "fin save.\n",
      "epoch 3871\n",
      "test_train\n",
      "train mean loss=62079.56328125\n",
      "test_test\n",
      "test mean loss=88965.32421875\n",
      "fin save.\n",
      "epoch 3872\n",
      "test_train\n",
      "train mean loss=62005.59856770833\n",
      "test_test\n",
      "test mean loss=88940.80078125\n",
      "fin save.\n",
      "epoch 3873\n",
      "test_train\n",
      "train mean loss=62226.0484375\n",
      "test_test\n",
      "test mean loss=88647.94921875\n",
      "fin save.\n",
      "epoch 3874\n",
      "test_train\n",
      "train mean loss=62520.66328125\n",
      "test_test\n",
      "test mean loss=88504.58984375\n",
      "fin save.\n",
      "epoch 3875\n",
      "test_train\n",
      "train mean loss=62205.28958333333\n",
      "test_test\n",
      "test mean loss=88540.9296875\n",
      "fin save.\n",
      "epoch 3876\n",
      "test_train\n",
      "train mean loss=62401.23125\n",
      "test_test\n",
      "test mean loss=88759.60546875\n",
      "fin save.\n",
      "epoch 3877\n",
      "test_train\n",
      "train mean loss=62506.00377604167\n",
      "test_test\n",
      "test mean loss=88736.28125\n",
      "fin save.\n",
      "epoch 3878\n",
      "test_train\n",
      "train mean loss=61922.69153645833\n",
      "test_test\n",
      "test mean loss=88599.16015625\n",
      "fin save.\n",
      "epoch 3879\n",
      "test_train\n",
      "train mean loss=62458.283203125\n",
      "test_test\n",
      "test mean loss=88755.5\n",
      "fin save.\n",
      "epoch 3880\n",
      "test_train\n",
      "train mean loss=61979.70390625\n",
      "test_test\n",
      "test mean loss=88488.68359375\n",
      "fin save.\n",
      "epoch 3881\n",
      "test_train\n",
      "train mean loss=62483.80026041667\n",
      "test_test\n",
      "test mean loss=88427.87109375\n",
      "fin save.\n",
      "epoch 3882\n",
      "test_train\n",
      "train mean loss=61651.79088541667\n",
      "test_test\n",
      "test mean loss=88421.828125\n",
      "fin save.\n",
      "epoch 3883\n",
      "test_train\n",
      "train mean loss=62925.222395833334\n",
      "test_test\n",
      "test mean loss=88420.15234375\n",
      "fin save.\n",
      "epoch 3884\n",
      "test_train\n",
      "train mean loss=61853.46015625\n",
      "test_test\n",
      "test mean loss=88628.2734375\n",
      "fin save.\n",
      "epoch 3885\n",
      "test_train\n",
      "train mean loss=62068.1328125\n",
      "test_test\n",
      "test mean loss=88691.1484375\n",
      "fin save.\n",
      "epoch 3886\n",
      "test_train\n",
      "train mean loss=62738.731770833336\n",
      "test_test\n",
      "test mean loss=88569.1796875\n",
      "fin save.\n",
      "epoch 3887\n",
      "test_train\n",
      "train mean loss=62071.4\n",
      "test_test\n",
      "test mean loss=88660.38671875\n",
      "fin save.\n",
      "epoch 3888\n",
      "test_train\n",
      "train mean loss=62969.38854166667\n",
      "test_test\n",
      "test mean loss=88599.578125\n",
      "fin save.\n",
      "epoch 3889\n",
      "test_train\n",
      "train mean loss=61037.586197916666\n",
      "test_test\n",
      "test mean loss=88589.6953125\n",
      "fin save.\n",
      "epoch 3890\n",
      "test_train\n",
      "train mean loss=62795.78020833333\n",
      "test_test\n",
      "test mean loss=88709.8984375\n",
      "fin save.\n",
      "epoch 3891\n",
      "test_train\n",
      "train mean loss=62110.89244791667\n",
      "test_test\n",
      "test mean loss=88619.90234375\n",
      "fin save.\n",
      "epoch 3892\n",
      "test_train\n",
      "train mean loss=63536.678125\n",
      "test_test\n",
      "test mean loss=88633.00390625\n",
      "fin save.\n",
      "epoch 3893\n",
      "test_train\n",
      "train mean loss=61824.86328125\n",
      "test_test\n",
      "test mean loss=88524.1484375\n",
      "fin save.\n",
      "epoch 3894\n",
      "test_train\n",
      "train mean loss=62579.360677083336\n",
      "test_test\n",
      "test mean loss=88048.19921875\n",
      "fin save.\n",
      "epoch 3895\n",
      "test_train\n",
      "train mean loss=61954.64166666667\n",
      "test_test\n",
      "test mean loss=88424.953125\n",
      "fin save.\n",
      "epoch 3896\n",
      "test_train\n",
      "train mean loss=62827.90182291667\n",
      "test_test\n",
      "test mean loss=88542.8828125\n",
      "fin save.\n",
      "epoch 3897\n",
      "test_train\n",
      "train mean loss=63092.13072916667\n",
      "test_test\n",
      "test mean loss=88594.109375\n",
      "fin save.\n",
      "epoch 3898\n",
      "test_train\n",
      "train mean loss=61646.21380208333\n",
      "test_test\n",
      "test mean loss=88737.34765625\n",
      "fin save.\n",
      "epoch 3899\n",
      "test_train\n",
      "train mean loss=61956.01953125\n",
      "test_test\n",
      "test mean loss=88285.30859375\n",
      "fin save.\n",
      "epoch 3900\n",
      "test_train\n",
      "train mean loss=62218.503645833334\n",
      "test_test\n",
      "test mean loss=88229.62890625\n",
      "fin save.\n",
      "epoch 3901\n",
      "test_train\n",
      "train mean loss=61680.61171875\n",
      "test_test\n",
      "test mean loss=87984.984375\n",
      "fin save.\n",
      "epoch 3902\n",
      "test_train\n",
      "train mean loss=62318.250651041664\n",
      "test_test\n",
      "test mean loss=88198.28515625\n",
      "fin save.\n",
      "epoch 3903\n",
      "test_train\n",
      "train mean loss=62991.463541666664\n",
      "test_test\n",
      "test mean loss=88274.75\n",
      "fin save.\n",
      "epoch 3904\n",
      "test_train\n",
      "train mean loss=62095.76484375\n",
      "test_test\n",
      "test mean loss=88406.59765625\n",
      "fin save.\n",
      "epoch 3905\n",
      "test_train\n",
      "train mean loss=62232.559375\n",
      "test_test\n",
      "test mean loss=88023.4453125\n",
      "fin save.\n",
      "epoch 3906\n",
      "test_train\n",
      "train mean loss=62661.21979166667\n",
      "test_test\n",
      "test mean loss=87837.3046875\n",
      "fin save.\n",
      "epoch 3907\n",
      "test_train\n",
      "train mean loss=62587.80755208333\n",
      "test_test\n",
      "test mean loss=88742.25\n",
      "fin save.\n",
      "epoch 3908\n",
      "test_train\n",
      "train mean loss=63202.344010416666\n",
      "test_test\n",
      "test mean loss=88352.4453125\n",
      "fin save.\n",
      "epoch 3909\n",
      "test_train\n",
      "train mean loss=62500.99791666667\n",
      "test_test\n",
      "test mean loss=88362.640625\n",
      "fin save.\n",
      "epoch 3910\n",
      "test_train\n",
      "train mean loss=62295.541015625\n",
      "test_test\n",
      "test mean loss=88796.3359375\n",
      "fin save.\n",
      "epoch 3911\n",
      "test_train\n",
      "train mean loss=62045.807291666664\n",
      "test_test\n",
      "test mean loss=88924.34375\n",
      "fin save.\n",
      "epoch 3912\n",
      "test_train\n",
      "train mean loss=62512.260546875\n",
      "test_test\n",
      "test mean loss=88642.2265625\n",
      "fin save.\n",
      "epoch 3913\n",
      "test_train\n",
      "train mean loss=61875.234114583334\n",
      "test_test\n",
      "test mean loss=88679.35546875\n",
      "fin save.\n",
      "epoch 3914\n",
      "test_train\n",
      "train mean loss=61733.45598958333\n",
      "test_test\n",
      "test mean loss=88788.61328125\n",
      "fin save.\n",
      "epoch 3915\n",
      "test_train\n",
      "train mean loss=62080.437760416666\n",
      "test_test\n",
      "test mean loss=88628.98828125\n",
      "fin save.\n",
      "epoch 3916\n",
      "test_train\n",
      "train mean loss=62476.79635416667\n",
      "test_test\n",
      "test mean loss=88530.08203125\n",
      "fin save.\n",
      "epoch 3917\n",
      "test_train\n",
      "train mean loss=62904.4203125\n",
      "test_test\n",
      "test mean loss=88544.7578125\n",
      "fin save.\n",
      "epoch 3918\n",
      "test_train\n",
      "train mean loss=62246.61510416667\n",
      "test_test\n",
      "test mean loss=88609.40234375\n",
      "fin save.\n",
      "epoch 3919\n",
      "test_train\n",
      "train mean loss=62620.03333333333\n",
      "test_test\n",
      "test mean loss=88569.51953125\n",
      "fin save.\n",
      "epoch 3920\n",
      "test_train\n",
      "train mean loss=62323.132552083334\n",
      "test_test\n",
      "test mean loss=88586.203125\n",
      "fin save.\n",
      "epoch 3921\n",
      "test_train\n",
      "train mean loss=62339.63984375\n",
      "test_test\n",
      "test mean loss=88275.45703125\n",
      "fin save.\n",
      "epoch 3922\n",
      "test_train\n",
      "train mean loss=62263.072916666664\n",
      "test_test\n",
      "test mean loss=88248.0703125\n",
      "fin save.\n",
      "epoch 3923\n",
      "test_train\n",
      "train mean loss=62208.173177083336\n",
      "test_test\n",
      "test mean loss=88235.421875\n",
      "fin save.\n",
      "epoch 3924\n",
      "test_train\n",
      "train mean loss=62456.99114583333\n",
      "test_test\n",
      "test mean loss=88400.0625\n",
      "fin save.\n",
      "epoch 3925\n",
      "test_train\n",
      "train mean loss=62652.37213541667\n",
      "test_test\n",
      "test mean loss=88310.8125\n",
      "fin save.\n",
      "epoch 3926\n",
      "test_train\n",
      "train mean loss=62325.7390625\n",
      "test_test\n",
      "test mean loss=88316.53125\n",
      "fin save.\n",
      "epoch 3927\n",
      "test_train\n",
      "train mean loss=62478.76263020833\n",
      "test_test\n",
      "test mean loss=88132.88671875\n",
      "fin save.\n",
      "epoch 3928\n",
      "test_train\n",
      "train mean loss=62055.40052083333\n",
      "test_test\n",
      "test mean loss=88337.828125\n",
      "fin save.\n",
      "epoch 3929\n",
      "test_train\n",
      "train mean loss=62208.59270833333\n",
      "test_test\n",
      "test mean loss=88414.65625\n",
      "fin save.\n",
      "epoch 3930\n",
      "test_train\n",
      "train mean loss=62764.91953125\n",
      "test_test\n",
      "test mean loss=88434.62109375\n",
      "fin save.\n",
      "epoch 3931\n",
      "test_train\n",
      "train mean loss=61996.16302083333\n",
      "test_test\n",
      "test mean loss=88431.90625\n",
      "fin save.\n",
      "epoch 3932\n",
      "test_train\n",
      "train mean loss=62807.5515625\n",
      "test_test\n",
      "test mean loss=88472.484375\n",
      "fin save.\n",
      "epoch 3933\n",
      "test_train\n",
      "train mean loss=62192.99947916667\n",
      "test_test\n",
      "test mean loss=88460.73828125\n",
      "fin save.\n",
      "epoch 3934\n",
      "test_train\n",
      "train mean loss=62701.8515625\n",
      "test_test\n",
      "test mean loss=88395.4140625\n",
      "fin save.\n",
      "epoch 3935\n",
      "test_train\n",
      "train mean loss=62424.4390625\n",
      "test_test\n",
      "test mean loss=88430.23046875\n",
      "fin save.\n",
      "epoch 3936\n",
      "test_train\n",
      "train mean loss=62273.21536458333\n",
      "test_test\n",
      "test mean loss=88652.9296875\n",
      "fin save.\n",
      "epoch 3937\n",
      "test_train\n",
      "train mean loss=62782.162369791666\n",
      "test_test\n",
      "test mean loss=88719.00390625\n",
      "fin save.\n",
      "epoch 3938\n",
      "test_train\n",
      "train mean loss=61687.01158854167\n",
      "test_test\n",
      "test mean loss=88624.51953125\n",
      "fin save.\n",
      "epoch 3939\n",
      "test_train\n",
      "train mean loss=61418.73580729167\n",
      "test_test\n",
      "test mean loss=88612.890625\n",
      "fin save.\n",
      "epoch 3940\n",
      "test_train\n",
      "train mean loss=61429.11119791667\n",
      "test_test\n",
      "test mean loss=88587.77734375\n",
      "fin save.\n",
      "epoch 3941\n",
      "test_train\n",
      "train mean loss=61832.44973958333\n",
      "test_test\n",
      "test mean loss=88637.828125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fin save.\n",
      "epoch 3942\n",
      "test_train\n",
      "train mean loss=62112.784375\n",
      "test_test\n",
      "test mean loss=88336.16796875\n",
      "fin save.\n",
      "epoch 3943\n",
      "test_train\n",
      "train mean loss=62117.43854166667\n",
      "test_test\n",
      "test mean loss=88316.265625\n",
      "fin save.\n",
      "epoch 3944\n",
      "test_train\n",
      "train mean loss=61773.3421875\n",
      "test_test\n",
      "test mean loss=88649.6953125\n",
      "fin save.\n",
      "epoch 3945\n",
      "test_train\n",
      "train mean loss=62526.04895833333\n",
      "test_test\n",
      "test mean loss=88660.80078125\n",
      "fin save.\n",
      "epoch 3946\n",
      "test_train\n",
      "train mean loss=62892.809375\n",
      "test_test\n",
      "test mean loss=88466.9296875\n",
      "fin save.\n",
      "epoch 3947\n",
      "test_train\n",
      "train mean loss=61840.205338541666\n",
      "test_test\n",
      "test mean loss=88784.109375\n",
      "fin save.\n",
      "epoch 3948\n",
      "test_train\n",
      "train mean loss=61754.29440104167\n",
      "test_test\n",
      "test mean loss=88507.41015625\n",
      "fin save.\n",
      "epoch 3949\n",
      "test_train\n",
      "train mean loss=62723.485677083336\n",
      "test_test\n",
      "test mean loss=88312.51171875\n",
      "fin save.\n",
      "epoch 3950\n",
      "test_train\n",
      "train mean loss=62031.14661458333\n",
      "test_test\n",
      "test mean loss=88333.09765625\n",
      "fin save.\n",
      "epoch 3951\n",
      "test_train\n",
      "train mean loss=62399.86614583333\n",
      "test_test\n",
      "test mean loss=88060.1171875\n",
      "fin save.\n",
      "epoch 3952\n",
      "test_train\n",
      "train mean loss=62171.9953125\n",
      "test_test\n",
      "test mean loss=88309.86328125\n",
      "fin save.\n",
      "epoch 3953\n",
      "test_train\n",
      "train mean loss=63182.636458333334\n",
      "test_test\n",
      "test mean loss=88482.4375\n",
      "fin save.\n",
      "epoch 3954\n",
      "test_train\n",
      "train mean loss=62302.70807291667\n",
      "test_test\n",
      "test mean loss=88409.39453125\n",
      "fin save.\n",
      "epoch 3955\n",
      "test_train\n",
      "train mean loss=62101.473958333336\n",
      "test_test\n",
      "test mean loss=88224.1328125\n",
      "fin save.\n",
      "epoch 3956\n",
      "test_train\n",
      "train mean loss=63160.571875\n",
      "test_test\n",
      "test mean loss=88335.890625\n",
      "fin save.\n",
      "epoch 3957\n",
      "test_train\n",
      "train mean loss=61877.25078125\n",
      "test_test\n",
      "test mean loss=88391.671875\n",
      "fin save.\n",
      "epoch 3958\n",
      "test_train\n",
      "train mean loss=62116.782942708334\n",
      "test_test\n",
      "test mean loss=88428.17578125\n",
      "fin save.\n",
      "epoch 3959\n",
      "test_train\n",
      "train mean loss=61796.838541666664\n",
      "test_test\n",
      "test mean loss=88289.38671875\n",
      "fin save.\n",
      "epoch 3960\n",
      "test_train\n",
      "train mean loss=61980.64166666667\n",
      "test_test\n",
      "test mean loss=88640.3515625\n",
      "fin save.\n",
      "epoch 3961\n",
      "test_train\n",
      "train mean loss=62501.153125\n",
      "test_test\n",
      "test mean loss=88300.04296875\n",
      "fin save.\n",
      "epoch 3962\n",
      "test_train\n",
      "train mean loss=62179.07473958333\n",
      "test_test\n",
      "test mean loss=88298.48828125\n",
      "fin save.\n",
      "epoch 3963\n",
      "test_train\n",
      "train mean loss=62799.01770833333\n",
      "test_test\n",
      "test mean loss=88148.96875\n",
      "fin save.\n",
      "epoch 3964\n",
      "test_train\n",
      "train mean loss=62513.377604166664\n",
      "test_test\n",
      "test mean loss=88427.5390625\n",
      "fin save.\n",
      "epoch 3965\n",
      "test_train\n",
      "train mean loss=61646.77942708333\n",
      "test_test\n",
      "test mean loss=88616.203125\n",
      "fin save.\n",
      "epoch 3966\n",
      "test_train\n",
      "train mean loss=62473.3078125\n",
      "test_test\n",
      "test mean loss=88422.2734375\n",
      "fin save.\n",
      "epoch 3967\n",
      "test_train\n",
      "train mean loss=62506.145833333336\n",
      "test_test\n",
      "test mean loss=88472.38671875\n",
      "fin save.\n",
      "epoch 3968\n",
      "test_train\n",
      "train mean loss=63122.50533854167\n",
      "test_test\n",
      "test mean loss=88467.0\n",
      "fin save.\n",
      "epoch 3969\n",
      "test_train\n",
      "train mean loss=61983.125260416666\n",
      "test_test\n",
      "test mean loss=88620.18359375\n",
      "fin save.\n",
      "epoch 3970\n",
      "test_train\n",
      "train mean loss=62117.19934895833\n",
      "test_test\n",
      "test mean loss=88695.23046875\n",
      "fin save.\n",
      "epoch 3971\n",
      "test_train\n",
      "train mean loss=63133.123046875\n",
      "test_test\n",
      "test mean loss=88693.109375\n",
      "fin save.\n",
      "epoch 3972\n",
      "test_train\n",
      "train mean loss=63266.68802083333\n",
      "test_test\n",
      "test mean loss=88449.83203125\n",
      "fin save.\n",
      "epoch 3973\n",
      "test_train\n",
      "train mean loss=61802.496875\n",
      "test_test\n",
      "test mean loss=88490.73828125\n",
      "fin save.\n",
      "epoch 3974\n",
      "test_train\n",
      "train mean loss=62487.60651041667\n",
      "test_test\n",
      "test mean loss=88447.078125\n",
      "fin save.\n",
      "epoch 3975\n",
      "test_train\n",
      "train mean loss=62141.834375\n",
      "test_test\n",
      "test mean loss=88660.76953125\n",
      "fin save.\n",
      "epoch 3976\n",
      "test_train\n",
      "train mean loss=62355.89635416667\n",
      "test_test\n",
      "test mean loss=88705.19140625\n",
      "fin save.\n",
      "epoch 3977\n",
      "test_train\n",
      "train mean loss=62788.2\n",
      "test_test\n",
      "test mean loss=88627.54296875\n",
      "fin save.\n",
      "epoch 3978\n",
      "test_train\n",
      "train mean loss=63311.07721354167\n",
      "test_test\n",
      "test mean loss=88623.6328125\n",
      "fin save.\n",
      "epoch 3979\n",
      "test_train\n",
      "train mean loss=62695.75885416667\n",
      "test_test\n",
      "test mean loss=88758.1171875\n",
      "fin save.\n",
      "epoch 3980\n",
      "test_train\n",
      "train mean loss=62948.45104166667\n",
      "test_test\n",
      "test mean loss=88676.265625\n",
      "fin save.\n",
      "epoch 3981\n",
      "test_train\n",
      "train mean loss=61973.090494791664\n",
      "test_test\n",
      "test mean loss=88465.7109375\n",
      "fin save.\n",
      "epoch 3982\n",
      "test_train\n",
      "train mean loss=62499.92890625\n",
      "test_test\n",
      "test mean loss=88588.1015625\n",
      "fin save.\n",
      "epoch 3983\n",
      "test_train\n",
      "train mean loss=61958.44153645833\n",
      "test_test\n",
      "test mean loss=88428.0\n",
      "fin save.\n",
      "epoch 3984\n",
      "test_train\n",
      "train mean loss=61858.24166666667\n",
      "test_test\n",
      "test mean loss=88355.69140625\n",
      "fin save.\n",
      "epoch 3985\n",
      "test_train\n",
      "train mean loss=62009.82760416667\n",
      "test_test\n",
      "test mean loss=88490.04296875\n",
      "fin save.\n",
      "epoch 3986\n",
      "test_train\n",
      "train mean loss=61861.95325520833\n",
      "test_test\n",
      "test mean loss=88412.328125\n",
      "fin save.\n",
      "epoch 3987\n",
      "test_train\n",
      "train mean loss=63354.98125\n",
      "test_test\n",
      "test mean loss=88442.078125\n",
      "fin save.\n",
      "epoch 3988\n",
      "test_train\n",
      "train mean loss=62039.476302083334\n",
      "test_test\n",
      "test mean loss=88231.66796875\n",
      "fin save.\n",
      "epoch 3989\n",
      "test_train\n",
      "train mean loss=62589.99375\n",
      "test_test\n",
      "test mean loss=88279.3671875\n",
      "fin save.\n",
      "epoch 3990\n",
      "test_train\n",
      "train mean loss=61892.85078125\n",
      "test_test\n",
      "test mean loss=88243.5078125\n",
      "fin save.\n",
      "epoch 3991\n",
      "test_train\n",
      "train mean loss=62754.75833333333\n",
      "test_test\n",
      "test mean loss=88040.22265625\n",
      "fin save.\n",
      "epoch 3992\n",
      "test_train\n",
      "train mean loss=63091.7203125\n",
      "test_test\n",
      "test mean loss=88095.015625\n",
      "fin save.\n",
      "epoch 3993\n",
      "test_train\n",
      "train mean loss=62575.925\n",
      "test_test\n",
      "test mean loss=88053.08984375\n",
      "fin save.\n",
      "epoch 3994\n",
      "test_train\n",
      "train mean loss=61885.164322916666\n",
      "test_test\n",
      "test mean loss=87814.421875\n",
      "fin save.\n",
      "epoch 3995\n",
      "test_train\n",
      "train mean loss=62285.036458333336\n",
      "test_test\n",
      "test mean loss=88170.03125\n",
      "fin save.\n",
      "epoch 3996\n",
      "test_train\n",
      "train mean loss=62280.42890625\n",
      "test_test\n",
      "test mean loss=88388.38671875\n",
      "fin save.\n",
      "epoch 3997\n",
      "test_train\n",
      "train mean loss=61939.93671875\n",
      "test_test\n",
      "test mean loss=88196.3515625\n",
      "fin save.\n",
      "epoch 3998\n",
      "test_train\n",
      "train mean loss=64065.4953125\n",
      "test_test\n",
      "test mean loss=88290.89453125\n",
      "fin save.\n",
      "epoch 3999\n",
      "test_train\n",
      "train mean loss=62572.33255208333\n",
      "test_test\n",
      "test mean loss=88197.30078125\n",
      "fin save.\n",
      "epoch 4000\n",
      "test_train\n",
      "train mean loss=61081.123307291666\n",
      "test_test\n",
      "test mean loss=88072.9609375\n",
      "fin save.\n",
      "epoch 4001\n",
      "test_train\n",
      "train mean loss=61865.57578125\n",
      "test_test\n",
      "test mean loss=88203.61328125\n",
      "fin save.\n",
      "epoch 4002\n",
      "test_train\n",
      "train mean loss=62063.601822916666\n",
      "test_test\n",
      "test mean loss=88216.04296875\n",
      "fin save.\n",
      "epoch 4003\n",
      "test_train\n",
      "train mean loss=62750.3828125\n",
      "test_test\n",
      "test mean loss=88147.92578125\n",
      "fin save.\n",
      "epoch 4004\n",
      "test_train\n",
      "train mean loss=64070.44244791667\n",
      "test_test\n",
      "test mean loss=89914.76953125\n",
      "fin save.\n",
      "epoch 4005\n",
      "test_train\n",
      "train mean loss=63585.52526041667\n",
      "test_test\n",
      "test mean loss=89689.23046875\n",
      "fin save.\n",
      "epoch 4006\n",
      "test_train\n",
      "train mean loss=63033.568619791666\n",
      "test_test\n",
      "test mean loss=89550.45703125\n",
      "fin save.\n",
      "epoch 4007\n",
      "test_train\n",
      "train mean loss=61616.067708333336\n",
      "test_test\n",
      "test mean loss=89468.5390625\n",
      "fin save.\n",
      "epoch 4008\n",
      "test_train\n",
      "train mean loss=62437.3796875\n",
      "test_test\n",
      "test mean loss=89115.765625\n",
      "fin save.\n",
      "epoch 4009\n",
      "test_train\n",
      "train mean loss=62680.2453125\n",
      "test_test\n",
      "test mean loss=89172.984375\n",
      "fin save.\n",
      "epoch 4010\n",
      "test_train\n",
      "train mean loss=62381.791796875\n",
      "test_test\n",
      "test mean loss=89067.5703125\n",
      "fin save.\n",
      "epoch 4011\n",
      "test_train\n",
      "train mean loss=62423.49114583333\n",
      "test_test\n",
      "test mean loss=88843.7109375\n",
      "fin save.\n",
      "epoch 4012\n",
      "test_train\n",
      "train mean loss=63342.836197916666\n",
      "test_test\n",
      "test mean loss=88832.8046875\n",
      "fin save.\n",
      "epoch 4013\n",
      "test_train\n",
      "train mean loss=62484.149739583336\n",
      "test_test\n",
      "test mean loss=88836.38671875\n",
      "fin save.\n",
      "epoch 4014\n",
      "test_train\n",
      "train mean loss=62526.67265625\n",
      "test_test\n",
      "test mean loss=88741.703125\n",
      "fin save.\n",
      "epoch 4015\n",
      "test_train\n",
      "train mean loss=62683.33984375\n",
      "test_test\n",
      "test mean loss=88350.0625\n",
      "fin save.\n",
      "epoch 4016\n",
      "test_train\n",
      "train mean loss=63360.434375\n",
      "test_test\n",
      "test mean loss=88356.921875\n",
      "fin save.\n",
      "epoch 4017\n",
      "test_train\n",
      "train mean loss=63975.186197916664\n",
      "test_test\n",
      "test mean loss=88050.43359375\n",
      "fin save.\n",
      "epoch 4018\n",
      "test_train\n",
      "train mean loss=63275.56328125\n",
      "test_test\n",
      "test mean loss=88099.04296875\n",
      "fin save.\n",
      "epoch 4019\n",
      "test_train\n",
      "train mean loss=64120.122395833336\n",
      "test_test\n",
      "test mean loss=88023.54296875\n",
      "fin save.\n",
      "epoch 4020\n",
      "test_train\n",
      "train mean loss=63514.10885416667\n",
      "test_test\n",
      "test mean loss=87761.9375\n",
      "fin save.\n",
      "epoch 4021\n",
      "test_train\n",
      "train mean loss=62096.19244791667\n",
      "test_test\n",
      "test mean loss=87833.35546875\n",
      "fin save.\n",
      "epoch 4022\n",
      "test_train\n",
      "train mean loss=63457.69479166667\n",
      "test_test\n",
      "test mean loss=88042.2890625\n",
      "fin save.\n",
      "epoch 4023\n",
      "test_train\n",
      "train mean loss=63471.722916666666\n",
      "test_test\n",
      "test mean loss=87935.125\n",
      "fin save.\n",
      "epoch 4024\n",
      "test_train\n",
      "train mean loss=64197.653125\n",
      "test_test\n",
      "test mean loss=88190.20703125\n",
      "fin save.\n",
      "epoch 4025\n",
      "test_train\n",
      "train mean loss=62049.86236979167\n",
      "test_test\n",
      "test mean loss=88195.01171875\n",
      "fin save.\n",
      "epoch 4026\n",
      "test_train\n",
      "train mean loss=62249.28958333333\n",
      "test_test\n",
      "test mean loss=87934.91015625\n",
      "fin save.\n",
      "epoch 4027\n",
      "test_train\n",
      "train mean loss=62943.945963541664\n",
      "test_test\n",
      "test mean loss=87924.9375\n",
      "fin save.\n",
      "epoch 4028\n",
      "test_train\n",
      "train mean loss=62104.46041666667\n",
      "test_test\n",
      "test mean loss=87870.9765625\n",
      "fin save.\n",
      "epoch 4029\n",
      "test_train\n",
      "train mean loss=62339.26158854167\n",
      "test_test\n",
      "test mean loss=87779.66015625\n",
      "fin save.\n",
      "epoch 4030\n",
      "test_train\n",
      "train mean loss=62425.09453125\n",
      "test_test\n",
      "test mean loss=88025.42578125\n",
      "fin save.\n",
      "epoch 4031\n",
      "test_train\n",
      "train mean loss=62257.256640625\n",
      "test_test\n",
      "test mean loss=88022.21484375\n",
      "fin save.\n",
      "epoch 4032\n",
      "test_train\n",
      "train mean loss=61717.67486979167\n",
      "test_test\n",
      "test mean loss=88047.70703125\n",
      "fin save.\n",
      "epoch 4033\n",
      "test_train\n",
      "train mean loss=62420.48046875\n",
      "test_test\n",
      "test mean loss=88087.67578125\n",
      "fin save.\n",
      "epoch 4034\n",
      "test_train\n",
      "train mean loss=62221.08984375\n",
      "test_test\n",
      "test mean loss=87696.39453125\n",
      "fin save.\n",
      "epoch 4035\n",
      "test_train\n",
      "train mean loss=62720.180989583336\n",
      "test_test\n",
      "test mean loss=87669.9765625\n",
      "fin save.\n",
      "epoch 4036\n",
      "test_train\n",
      "train mean loss=61851.47161458333\n",
      "test_test\n",
      "test mean loss=87765.88671875\n",
      "fin save.\n",
      "epoch 4037\n",
      "test_train\n",
      "train mean loss=62966.549479166664\n",
      "test_test\n",
      "test mean loss=87923.578125\n",
      "fin save.\n",
      "epoch 4038\n",
      "test_train\n",
      "train mean loss=62345.840234375\n",
      "test_test\n",
      "test mean loss=87795.91796875\n",
      "fin save.\n",
      "epoch 4039\n",
      "test_train\n",
      "train mean loss=62774.017317708334\n",
      "test_test\n",
      "test mean loss=87703.8203125\n",
      "fin save.\n",
      "epoch 4040\n",
      "test_train\n",
      "train mean loss=62092.715625\n",
      "test_test\n",
      "test mean loss=87995.21875\n",
      "fin save.\n",
      "epoch 4041\n",
      "test_train\n",
      "train mean loss=62803.73815104167\n",
      "test_test\n",
      "test mean loss=87604.890625\n",
      "fin save.\n",
      "epoch 4042\n",
      "test_train\n",
      "train mean loss=62457.01861979167\n",
      "test_test\n",
      "test mean loss=87953.68359375\n",
      "fin save.\n",
      "epoch 4043\n",
      "test_train\n",
      "train mean loss=63123.21145833333\n",
      "test_test\n",
      "test mean loss=88200.671875\n",
      "fin save.\n",
      "epoch 4044\n",
      "test_train\n",
      "train mean loss=61846.20625\n",
      "test_test\n",
      "test mean loss=87931.26171875\n",
      "fin save.\n",
      "epoch 4045\n",
      "test_train\n",
      "train mean loss=62163.57578125\n",
      "test_test\n",
      "test mean loss=88097.73828125\n",
      "fin save.\n",
      "epoch 4046\n",
      "test_train\n",
      "train mean loss=62454.840625\n",
      "test_test\n",
      "test mean loss=88229.35546875\n",
      "fin save.\n",
      "epoch 4047\n",
      "test_train\n",
      "train mean loss=62421.506510416664\n",
      "test_test\n",
      "test mean loss=88064.796875\n",
      "fin save.\n",
      "epoch 4048\n",
      "test_train\n",
      "train mean loss=62966.50104166667\n",
      "test_test\n",
      "test mean loss=87899.875\n",
      "fin save.\n",
      "epoch 4049\n",
      "test_train\n",
      "train mean loss=61678.9625\n",
      "test_test\n",
      "test mean loss=87761.28515625\n",
      "fin save.\n",
      "epoch 4050\n",
      "test_train\n",
      "train mean loss=61598.05859375\n",
      "test_test\n",
      "test mean loss=87728.33203125\n",
      "fin save.\n",
      "epoch 4051\n",
      "test_train\n",
      "train mean loss=62513.19322916667\n",
      "test_test\n",
      "test mean loss=87653.56640625\n",
      "fin save.\n",
      "epoch 4052\n",
      "test_train\n",
      "train mean loss=62432.1109375\n",
      "test_test\n",
      "test mean loss=87526.6953125\n",
      "fin save.\n",
      "epoch 4053\n",
      "test_train\n",
      "train mean loss=62884.38671875\n",
      "test_test\n",
      "test mean loss=87802.11328125\n",
      "fin save.\n",
      "epoch 4054\n",
      "test_train\n",
      "train mean loss=62126.775130208334\n",
      "test_test\n",
      "test mean loss=87895.84375\n",
      "fin save.\n",
      "epoch 4055\n",
      "test_train\n",
      "train mean loss=62572.14921875\n",
      "test_test\n",
      "test mean loss=87534.0625\n",
      "fin save.\n",
      "epoch 4056\n",
      "test_train\n",
      "train mean loss=62024.353125\n",
      "test_test\n",
      "test mean loss=87787.359375\n",
      "fin save.\n",
      "epoch 4057\n",
      "test_train\n",
      "train mean loss=62358.13671875\n",
      "test_test\n",
      "test mean loss=87789.3046875\n",
      "fin save.\n",
      "epoch 4058\n",
      "test_train\n",
      "train mean loss=62224.620833333334\n",
      "test_test\n",
      "test mean loss=87944.07421875\n",
      "fin save.\n",
      "epoch 4059\n",
      "test_train\n",
      "train mean loss=62224.50690104167\n",
      "test_test\n",
      "test mean loss=87948.99609375\n",
      "fin save.\n",
      "epoch 4060\n",
      "test_train\n",
      "train mean loss=62829.86666666667\n",
      "test_test\n",
      "test mean loss=87899.0625\n",
      "fin save.\n",
      "epoch 4061\n",
      "test_train\n",
      "train mean loss=62598.84088541667\n",
      "test_test\n",
      "test mean loss=87709.88671875\n",
      "fin save.\n",
      "epoch 4062\n",
      "test_train\n",
      "train mean loss=62239.252734375\n",
      "test_test\n",
      "test mean loss=87757.04296875\n",
      "fin save.\n",
      "epoch 4063\n",
      "test_train\n",
      "train mean loss=62276.23046875\n",
      "test_test\n",
      "test mean loss=87717.0078125\n",
      "fin save.\n",
      "epoch 4064\n",
      "test_train\n",
      "train mean loss=62753.182291666664\n",
      "test_test\n",
      "test mean loss=87535.15234375\n",
      "fin save.\n",
      "epoch 4065\n",
      "test_train\n",
      "train mean loss=62184.251692708334\n",
      "test_test\n",
      "test mean loss=87708.26953125\n",
      "fin save.\n",
      "epoch 4066\n",
      "test_train\n",
      "train mean loss=62205.73815104167\n",
      "test_test\n",
      "test mean loss=87700.30859375\n",
      "fin save.\n",
      "epoch 4067\n",
      "test_train\n",
      "train mean loss=63278.440234375\n",
      "test_test\n",
      "test mean loss=87276.6484375\n",
      "fin save.\n",
      "epoch 4068\n",
      "test_train\n",
      "train mean loss=62536.407552083336\n",
      "test_test\n",
      "test mean loss=87025.91015625\n",
      "fin save.\n",
      "epoch 4069\n",
      "test_train\n",
      "train mean loss=61882.44140625\n",
      "test_test\n",
      "test mean loss=87151.89453125\n",
      "fin save.\n",
      "epoch 4070\n",
      "test_train\n",
      "train mean loss=62736.19036458333\n",
      "test_test\n",
      "test mean loss=87222.3125\n",
      "fin save.\n",
      "epoch 4071\n",
      "test_train\n",
      "train mean loss=62421.11796875\n",
      "test_test\n",
      "test mean loss=87379.5390625\n",
      "fin save.\n",
      "epoch 4072\n",
      "test_train\n",
      "train mean loss=62202.224869791666\n",
      "test_test\n",
      "test mean loss=87330.375\n",
      "fin save.\n",
      "epoch 4073\n",
      "test_train\n",
      "train mean loss=61837.31875\n",
      "test_test\n",
      "test mean loss=87515.51953125\n",
      "fin save.\n",
      "epoch 4074\n",
      "test_train\n",
      "train mean loss=61806.463541666664\n",
      "test_test\n",
      "test mean loss=87358.3046875\n",
      "fin save.\n",
      "epoch 4075\n",
      "test_train\n",
      "train mean loss=61478.031510416666\n",
      "test_test\n",
      "test mean loss=87448.234375\n",
      "fin save.\n",
      "epoch 4076\n",
      "test_train\n",
      "train mean loss=62533.04283854167\n",
      "test_test\n",
      "test mean loss=87526.65625\n",
      "fin save.\n",
      "epoch 4077\n",
      "test_train\n",
      "train mean loss=61494.91692708333\n",
      "test_test\n",
      "test mean loss=87648.6328125\n",
      "fin save.\n",
      "epoch 4078\n",
      "test_train\n",
      "train mean loss=62118.13723958333\n",
      "test_test\n",
      "test mean loss=87527.2578125\n",
      "fin save.\n",
      "epoch 4079\n",
      "test_train\n",
      "train mean loss=62013.014322916664\n",
      "test_test\n",
      "test mean loss=87454.20703125\n",
      "fin save.\n",
      "epoch 4080\n",
      "test_train\n",
      "train mean loss=62585.9046875\n",
      "test_test\n",
      "test mean loss=87292.3828125\n",
      "fin save.\n",
      "epoch 4081\n",
      "test_train\n",
      "train mean loss=62768.10052083333\n",
      "test_test\n",
      "test mean loss=87204.9296875\n",
      "fin save.\n",
      "epoch 4082\n",
      "test_train\n",
      "train mean loss=62240.279296875\n",
      "test_test\n",
      "test mean loss=87590.8984375\n",
      "fin save.\n",
      "epoch 4083\n",
      "test_train\n",
      "train mean loss=62382.67135416667\n",
      "test_test\n",
      "test mean loss=87013.74609375\n",
      "fin save.\n",
      "epoch 4084\n",
      "test_train\n",
      "train mean loss=62428.475390625\n",
      "test_test\n",
      "test mean loss=87005.40625\n",
      "fin save.\n",
      "epoch 4085\n",
      "test_train\n",
      "train mean loss=63073.91875\n",
      "test_test\n",
      "test mean loss=86996.203125\n",
      "fin save.\n",
      "epoch 4086\n",
      "test_train\n",
      "train mean loss=62514.156510416666\n",
      "test_test\n",
      "test mean loss=86975.51171875\n",
      "fin save.\n",
      "epoch 4087\n",
      "test_train\n",
      "train mean loss=62980.252213541666\n",
      "test_test\n",
      "test mean loss=86951.23828125\n",
      "fin save.\n",
      "epoch 4088\n",
      "test_train\n",
      "train mean loss=62336.0796875\n",
      "test_test\n",
      "test mean loss=87004.34765625\n",
      "fin save.\n",
      "epoch 4089\n",
      "test_train\n",
      "train mean loss=61762.27005208333\n",
      "test_test\n",
      "test mean loss=87153.53125\n",
      "fin save.\n",
      "epoch 4090\n",
      "test_train\n",
      "train mean loss=61996.92916666667\n",
      "test_test\n",
      "test mean loss=86751.66015625\n",
      "fin save.\n",
      "epoch 4091\n",
      "test_train\n",
      "train mean loss=61869.243489583336\n",
      "test_test\n",
      "test mean loss=86926.0390625\n",
      "fin save.\n",
      "epoch 4092\n",
      "test_train\n",
      "train mean loss=61571.174479166664\n",
      "test_test\n",
      "test mean loss=86877.18359375\n",
      "fin save.\n",
      "epoch 4093\n",
      "test_train\n",
      "train mean loss=62821.711197916666\n",
      "test_test\n",
      "test mean loss=86830.17578125\n",
      "fin save.\n",
      "epoch 4094\n",
      "test_train\n",
      "train mean loss=62601.408854166664\n",
      "test_test\n",
      "test mean loss=87027.7890625\n",
      "fin save.\n",
      "epoch 4095\n",
      "test_train\n",
      "train mean loss=62294.407421875\n",
      "test_test\n",
      "test mean loss=87117.59765625\n",
      "fin save.\n",
      "epoch 4096\n",
      "test_train\n",
      "train mean loss=61729.34557291667\n",
      "test_test\n",
      "test mean loss=87040.93359375\n",
      "fin save.\n",
      "epoch 4097\n",
      "test_train\n",
      "train mean loss=61913.50885416667\n",
      "test_test\n",
      "test mean loss=87113.17578125\n",
      "fin save.\n",
      "epoch 4098\n",
      "test_train\n",
      "train mean loss=62360.23580729167\n",
      "test_test\n",
      "test mean loss=87122.33203125\n",
      "fin save.\n",
      "epoch 4099\n",
      "test_train\n",
      "train mean loss=62048.115885416664\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=87335.91015625\n",
      "fin save.\n",
      "epoch 4100\n",
      "test_train\n",
      "train mean loss=62405.117838541664\n",
      "test_test\n",
      "test mean loss=87271.6953125\n",
      "fin save.\n",
      "epoch 4101\n",
      "test_train\n",
      "train mean loss=62278.416666666664\n",
      "test_test\n",
      "test mean loss=87333.08984375\n",
      "fin save.\n",
      "epoch 4102\n",
      "test_train\n",
      "train mean loss=61899.6640625\n",
      "test_test\n",
      "test mean loss=87279.16796875\n",
      "fin save.\n",
      "epoch 4103\n",
      "test_train\n",
      "train mean loss=61454.328125\n",
      "test_test\n",
      "test mean loss=87381.2421875\n",
      "fin save.\n",
      "epoch 4104\n",
      "test_train\n",
      "train mean loss=61857.50546875\n",
      "test_test\n",
      "test mean loss=87155.08203125\n",
      "fin save.\n",
      "epoch 4105\n",
      "test_train\n",
      "train mean loss=61869.91744791667\n",
      "test_test\n",
      "test mean loss=87237.640625\n",
      "fin save.\n",
      "epoch 4106\n",
      "test_train\n",
      "train mean loss=62482.71536458333\n",
      "test_test\n",
      "test mean loss=87800.9921875\n",
      "fin save.\n",
      "epoch 4107\n",
      "test_train\n",
      "train mean loss=62047.76354166667\n",
      "test_test\n",
      "test mean loss=87725.90234375\n",
      "fin save.\n",
      "epoch 4108\n",
      "test_train\n",
      "train mean loss=62561.127213541666\n",
      "test_test\n",
      "test mean loss=87840.03125\n",
      "fin save.\n",
      "epoch 4109\n",
      "test_train\n",
      "train mean loss=60958.76028645833\n",
      "test_test\n",
      "test mean loss=87646.39453125\n",
      "fin save.\n",
      "epoch 4110\n",
      "test_train\n",
      "train mean loss=61673.46536458333\n",
      "test_test\n",
      "test mean loss=87542.49609375\n",
      "fin save.\n",
      "epoch 4111\n",
      "test_train\n",
      "train mean loss=61876.939713541666\n",
      "test_test\n",
      "test mean loss=87466.60546875\n",
      "fin save.\n",
      "epoch 4112\n",
      "test_train\n",
      "train mean loss=63175.68802083333\n",
      "test_test\n",
      "test mean loss=87379.39453125\n",
      "fin save.\n",
      "epoch 4113\n",
      "test_train\n",
      "train mean loss=62161.44036458333\n",
      "test_test\n",
      "test mean loss=87594.6015625\n",
      "fin save.\n",
      "epoch 4114\n",
      "test_train\n",
      "train mean loss=62893.569921875\n",
      "test_test\n",
      "test mean loss=87728.86328125\n",
      "fin save.\n",
      "epoch 4115\n",
      "test_train\n",
      "train mean loss=62379.42864583333\n",
      "test_test\n",
      "test mean loss=87640.03125\n",
      "fin save.\n",
      "epoch 4116\n",
      "test_train\n",
      "train mean loss=62144.542708333334\n",
      "test_test\n",
      "test mean loss=87642.66015625\n",
      "fin save.\n",
      "epoch 4117\n",
      "test_train\n",
      "train mean loss=62665.445052083334\n",
      "test_test\n",
      "test mean loss=87523.0546875\n",
      "fin save.\n",
      "epoch 4118\n",
      "test_train\n",
      "train mean loss=62629.609375\n",
      "test_test\n",
      "test mean loss=87436.3046875\n",
      "fin save.\n",
      "epoch 4119\n",
      "test_train\n",
      "train mean loss=61679.265625\n",
      "test_test\n",
      "test mean loss=87506.828125\n",
      "fin save.\n",
      "epoch 4120\n",
      "test_train\n",
      "train mean loss=62538.96432291667\n",
      "test_test\n",
      "test mean loss=87698.66015625\n",
      "fin save.\n",
      "epoch 4121\n",
      "test_train\n",
      "train mean loss=62900.93450520833\n",
      "test_test\n",
      "test mean loss=87495.84375\n",
      "fin save.\n",
      "epoch 4122\n",
      "test_train\n",
      "train mean loss=62717.72513020833\n",
      "test_test\n",
      "test mean loss=87518.6875\n",
      "fin save.\n",
      "epoch 4123\n",
      "test_train\n",
      "train mean loss=61967.20703125\n",
      "test_test\n",
      "test mean loss=86770.10546875\n",
      "fin save.\n",
      "epoch 4124\n",
      "test_train\n",
      "train mean loss=62909.3609375\n",
      "test_test\n",
      "test mean loss=86801.84765625\n",
      "fin save.\n",
      "epoch 4125\n",
      "test_train\n",
      "train mean loss=62378.39375\n",
      "test_test\n",
      "test mean loss=86702.14453125\n",
      "fin save.\n",
      "epoch 4126\n",
      "test_train\n",
      "train mean loss=62819.39270833333\n",
      "test_test\n",
      "test mean loss=86612.8671875\n",
      "fin save.\n",
      "epoch 4127\n",
      "test_train\n",
      "train mean loss=62744.912109375\n",
      "test_test\n",
      "test mean loss=86922.953125\n",
      "fin save.\n",
      "epoch 4128\n",
      "test_train\n",
      "train mean loss=62240.682291666664\n",
      "test_test\n",
      "test mean loss=87344.0859375\n",
      "fin save.\n",
      "epoch 4129\n",
      "test_train\n",
      "train mean loss=62193.39791666667\n",
      "test_test\n",
      "test mean loss=87294.1328125\n",
      "fin save.\n",
      "epoch 4130\n",
      "test_train\n",
      "train mean loss=62392.654036458334\n",
      "test_test\n",
      "test mean loss=87187.88671875\n",
      "fin save.\n",
      "epoch 4131\n",
      "test_train\n",
      "train mean loss=62493.82916666667\n",
      "test_test\n",
      "test mean loss=87140.6640625\n",
      "fin save.\n",
      "epoch 4132\n",
      "test_train\n",
      "train mean loss=62546.365625\n",
      "test_test\n",
      "test mean loss=87132.88671875\n",
      "fin save.\n",
      "epoch 4133\n",
      "test_train\n",
      "train mean loss=61445.5203125\n",
      "test_test\n",
      "test mean loss=87068.265625\n",
      "fin save.\n",
      "epoch 4134\n",
      "test_train\n",
      "train mean loss=63304.35\n",
      "test_test\n",
      "test mean loss=87003.859375\n",
      "fin save.\n",
      "epoch 4135\n",
      "test_train\n",
      "train mean loss=62214.620833333334\n",
      "test_test\n",
      "test mean loss=87292.6328125\n",
      "fin save.\n",
      "epoch 4136\n",
      "test_train\n",
      "train mean loss=61980.57760416667\n",
      "test_test\n",
      "test mean loss=87307.94921875\n",
      "fin save.\n",
      "epoch 4137\n",
      "test_train\n",
      "train mean loss=62883.12421875\n",
      "test_test\n",
      "test mean loss=87571.7265625\n",
      "fin save.\n",
      "epoch 4138\n",
      "test_train\n",
      "train mean loss=61863.01328125\n",
      "test_test\n",
      "test mean loss=87527.08984375\n",
      "fin save.\n",
      "epoch 4139\n",
      "test_train\n",
      "train mean loss=62084.62057291667\n",
      "test_test\n",
      "test mean loss=87512.36328125\n",
      "fin save.\n",
      "epoch 4140\n",
      "test_train\n",
      "train mean loss=61339.269270833334\n",
      "test_test\n",
      "test mean loss=87366.20703125\n",
      "fin save.\n",
      "epoch 4141\n",
      "test_train\n",
      "train mean loss=62013.63424479167\n",
      "test_test\n",
      "test mean loss=87261.65234375\n",
      "fin save.\n",
      "epoch 4142\n",
      "test_train\n",
      "train mean loss=62099.4078125\n",
      "test_test\n",
      "test mean loss=87444.05859375\n",
      "fin save.\n",
      "epoch 4143\n",
      "test_train\n",
      "train mean loss=62412.48671875\n",
      "test_test\n",
      "test mean loss=87400.77734375\n",
      "fin save.\n",
      "epoch 4144\n",
      "test_train\n",
      "train mean loss=63218.038802083334\n",
      "test_test\n",
      "test mean loss=87070.53125\n",
      "fin save.\n",
      "epoch 4145\n",
      "test_train\n",
      "train mean loss=62599.23255208333\n",
      "test_test\n",
      "test mean loss=86851.359375\n",
      "fin save.\n",
      "epoch 4146\n",
      "test_train\n",
      "train mean loss=62189.23046875\n",
      "test_test\n",
      "test mean loss=87158.48046875\n",
      "fin save.\n",
      "epoch 4147\n",
      "test_train\n",
      "train mean loss=62021.66692708333\n",
      "test_test\n",
      "test mean loss=87165.5234375\n",
      "fin save.\n",
      "epoch 4148\n",
      "test_train\n",
      "train mean loss=64223.14296875\n",
      "test_test\n",
      "test mean loss=87050.46875\n",
      "fin save.\n",
      "epoch 4149\n",
      "test_train\n",
      "train mean loss=62439.90572916667\n",
      "test_test\n",
      "test mean loss=87132.8203125\n",
      "fin save.\n",
      "epoch 4150\n",
      "test_train\n",
      "train mean loss=62283.6890625\n",
      "test_test\n",
      "test mean loss=87008.765625\n",
      "fin save.\n",
      "epoch 4151\n",
      "test_train\n",
      "train mean loss=62663.361979166664\n",
      "test_test\n",
      "test mean loss=86996.69140625\n",
      "fin save.\n",
      "epoch 4152\n",
      "test_train\n",
      "train mean loss=62470.96953125\n",
      "test_test\n",
      "test mean loss=87081.203125\n",
      "fin save.\n",
      "epoch 4153\n",
      "test_train\n",
      "train mean loss=62687.863020833334\n",
      "test_test\n",
      "test mean loss=87033.37890625\n",
      "fin save.\n",
      "epoch 4154\n",
      "test_train\n",
      "train mean loss=61870.125\n",
      "test_test\n",
      "test mean loss=87283.9453125\n",
      "fin save.\n",
      "epoch 4155\n",
      "test_train\n",
      "train mean loss=61718.390885416666\n",
      "test_test\n",
      "test mean loss=87645.80078125\n",
      "fin save.\n",
      "epoch 4156\n",
      "test_train\n",
      "train mean loss=62018.160807291664\n",
      "test_test\n",
      "test mean loss=87459.7109375\n",
      "fin save.\n",
      "epoch 4157\n",
      "test_train\n",
      "train mean loss=63161.823828125\n",
      "test_test\n",
      "test mean loss=87439.51171875\n",
      "fin save.\n",
      "epoch 4158\n",
      "test_train\n",
      "train mean loss=62195.687239583334\n",
      "test_test\n",
      "test mean loss=87555.421875\n",
      "fin save.\n",
      "epoch 4159\n",
      "test_train\n",
      "train mean loss=62818.835677083334\n",
      "test_test\n",
      "test mean loss=87503.08984375\n",
      "fin save.\n",
      "epoch 4160\n",
      "test_train\n",
      "train mean loss=61247.24505208333\n",
      "test_test\n",
      "test mean loss=87444.4296875\n",
      "fin save.\n",
      "epoch 4161\n",
      "test_train\n",
      "train mean loss=61757.01184895833\n",
      "test_test\n",
      "test mean loss=87563.4296875\n",
      "fin save.\n",
      "epoch 4162\n",
      "test_train\n",
      "train mean loss=62248.64270833333\n",
      "test_test\n",
      "test mean loss=87447.984375\n",
      "fin save.\n",
      "epoch 4163\n",
      "test_train\n",
      "train mean loss=61878.639322916664\n",
      "test_test\n",
      "test mean loss=87472.91796875\n",
      "fin save.\n",
      "epoch 4164\n",
      "test_train\n",
      "train mean loss=62287.19518229167\n",
      "test_test\n",
      "test mean loss=87191.63671875\n",
      "fin save.\n",
      "epoch 4165\n",
      "test_train\n",
      "train mean loss=62580.53893229167\n",
      "test_test\n",
      "test mean loss=87500.29296875\n",
      "fin save.\n",
      "epoch 4166\n",
      "test_train\n",
      "train mean loss=63229.94765625\n",
      "test_test\n",
      "test mean loss=87789.53515625\n",
      "fin save.\n",
      "epoch 4167\n",
      "test_train\n",
      "train mean loss=62174.8625\n",
      "test_test\n",
      "test mean loss=87448.58203125\n",
      "fin save.\n",
      "epoch 4168\n",
      "test_train\n",
      "train mean loss=62621.39505208333\n",
      "test_test\n",
      "test mean loss=87546.85546875\n",
      "fin save.\n",
      "epoch 4169\n",
      "test_train\n",
      "train mean loss=61973.62421875\n",
      "test_test\n",
      "test mean loss=87405.859375\n",
      "fin save.\n",
      "epoch 4170\n",
      "test_train\n",
      "train mean loss=62150.04140625\n",
      "test_test\n",
      "test mean loss=87442.58203125\n",
      "fin save.\n",
      "epoch 4171\n",
      "test_train\n",
      "train mean loss=61526.72565104167\n",
      "test_test\n",
      "test mean loss=87586.22265625\n",
      "fin save.\n",
      "epoch 4172\n",
      "test_train\n",
      "train mean loss=62440.937760416666\n",
      "test_test\n",
      "test mean loss=87375.60546875\n",
      "fin save.\n",
      "epoch 4173\n",
      "test_train\n",
      "train mean loss=62558.68671875\n",
      "test_test\n",
      "test mean loss=87607.71875\n",
      "fin save.\n",
      "epoch 4174\n",
      "test_train\n",
      "train mean loss=63209.64270833333\n",
      "test_test\n",
      "test mean loss=87682.61328125\n",
      "fin save.\n",
      "epoch 4175\n",
      "test_train\n",
      "train mean loss=62829.63971354167\n",
      "test_test\n",
      "test mean loss=87615.82421875\n",
      "fin save.\n",
      "epoch 4176\n",
      "test_train\n",
      "train mean loss=62844.040364583336\n",
      "test_test\n",
      "test mean loss=87546.2265625\n",
      "fin save.\n",
      "epoch 4177\n",
      "test_train\n",
      "train mean loss=62509.797135416666\n",
      "test_test\n",
      "test mean loss=87563.2890625\n",
      "fin save.\n",
      "epoch 4178\n",
      "test_train\n",
      "train mean loss=62746.980729166666\n",
      "test_test\n",
      "test mean loss=86739.234375\n",
      "fin save.\n",
      "epoch 4179\n",
      "test_train\n",
      "train mean loss=63031.50989583333\n",
      "test_test\n",
      "test mean loss=86965.703125\n",
      "fin save.\n",
      "epoch 4180\n",
      "test_train\n",
      "train mean loss=61601.864973958334\n",
      "test_test\n",
      "test mean loss=87017.1328125\n",
      "fin save.\n",
      "epoch 4181\n",
      "test_train\n",
      "train mean loss=62486.530078125\n",
      "test_test\n",
      "test mean loss=87232.28515625\n",
      "fin save.\n",
      "epoch 4182\n",
      "test_train\n",
      "train mean loss=62240.590104166666\n",
      "test_test\n",
      "test mean loss=87307.42578125\n",
      "fin save.\n",
      "epoch 4183\n",
      "test_train\n",
      "train mean loss=61690.0515625\n",
      "test_test\n",
      "test mean loss=87239.55859375\n",
      "fin save.\n",
      "epoch 4184\n",
      "test_train\n",
      "train mean loss=61293.868359375\n",
      "test_test\n",
      "test mean loss=87165.203125\n",
      "fin save.\n",
      "epoch 4185\n",
      "test_train\n",
      "train mean loss=62087.32760416667\n",
      "test_test\n",
      "test mean loss=87302.00390625\n",
      "fin save.\n",
      "epoch 4186\n",
      "test_train\n",
      "train mean loss=62589.231770833336\n",
      "test_test\n",
      "test mean loss=87205.9140625\n",
      "fin save.\n",
      "epoch 4187\n",
      "test_train\n",
      "train mean loss=62678.27330729167\n",
      "test_test\n",
      "test mean loss=87523.27734375\n",
      "fin save.\n",
      "epoch 4188\n",
      "test_train\n",
      "train mean loss=62492.711197916666\n",
      "test_test\n",
      "test mean loss=87470.234375\n",
      "fin save.\n",
      "epoch 4189\n",
      "test_train\n",
      "train mean loss=60937.191145833334\n",
      "test_test\n",
      "test mean loss=87306.25\n",
      "fin save.\n",
      "epoch 4190\n",
      "test_train\n",
      "train mean loss=62227.3125\n",
      "test_test\n",
      "test mean loss=87220.6953125\n",
      "fin save.\n",
      "epoch 4191\n",
      "test_train\n",
      "train mean loss=62462.61875\n",
      "test_test\n",
      "test mean loss=87536.125\n",
      "fin save.\n",
      "epoch 4192\n",
      "test_train\n",
      "train mean loss=62116.562760416666\n",
      "test_test\n",
      "test mean loss=87546.3203125\n",
      "fin save.\n",
      "epoch 4193\n",
      "test_train\n",
      "train mean loss=62977.866015625\n",
      "test_test\n",
      "test mean loss=87613.61328125\n",
      "fin save.\n",
      "epoch 4194\n",
      "test_train\n",
      "train mean loss=62138.69765625\n",
      "test_test\n",
      "test mean loss=87884.21875\n",
      "fin save.\n",
      "epoch 4195\n",
      "test_train\n",
      "train mean loss=62007.34296875\n",
      "test_test\n",
      "test mean loss=87615.9453125\n",
      "fin save.\n",
      "epoch 4196\n",
      "test_train\n",
      "train mean loss=62316.18125\n",
      "test_test\n",
      "test mean loss=87536.4453125\n",
      "fin save.\n",
      "epoch 4197\n",
      "test_train\n",
      "train mean loss=62239.64921875\n",
      "test_test\n",
      "test mean loss=87561.15234375\n",
      "fin save.\n",
      "epoch 4198\n",
      "test_train\n",
      "train mean loss=62160.782552083336\n",
      "test_test\n",
      "test mean loss=87724.9296875\n",
      "fin save.\n",
      "epoch 4199\n",
      "test_train\n",
      "train mean loss=62814.6046875\n",
      "test_test\n",
      "test mean loss=87747.453125\n",
      "fin save.\n",
      "epoch 4200\n",
      "test_train\n",
      "train mean loss=62351.62994791667\n",
      "test_test\n",
      "test mean loss=87625.48046875\n",
      "fin save.\n",
      "epoch 4201\n",
      "test_train\n",
      "train mean loss=61886.78697916667\n",
      "test_test\n",
      "test mean loss=87650.26953125\n",
      "fin save.\n",
      "epoch 4202\n",
      "test_train\n",
      "train mean loss=62086.117838541664\n",
      "test_test\n",
      "test mean loss=87631.21484375\n",
      "fin save.\n",
      "epoch 4203\n",
      "test_train\n",
      "train mean loss=61683.95026041667\n",
      "test_test\n",
      "test mean loss=87602.515625\n",
      "fin save.\n",
      "epoch 4204\n",
      "test_train\n",
      "train mean loss=62317.2171875\n",
      "test_test\n",
      "test mean loss=87781.08984375\n",
      "fin save.\n",
      "epoch 4205\n",
      "test_train\n",
      "train mean loss=61638.55859375\n",
      "test_test\n",
      "test mean loss=87784.9453125\n",
      "fin save.\n",
      "epoch 4206\n",
      "test_train\n",
      "train mean loss=63116.09427083333\n",
      "test_test\n",
      "test mean loss=87702.3046875\n",
      "fin save.\n",
      "epoch 4207\n",
      "test_train\n",
      "train mean loss=61556.10559895833\n",
      "test_test\n",
      "test mean loss=87832.64453125\n",
      "fin save.\n",
      "epoch 4208\n",
      "test_train\n",
      "train mean loss=62591.40234375\n",
      "test_test\n",
      "test mean loss=88001.0\n",
      "fin save.\n",
      "epoch 4209\n",
      "test_train\n",
      "train mean loss=62412.76796875\n",
      "test_test\n",
      "test mean loss=88122.73046875\n",
      "fin save.\n",
      "epoch 4210\n",
      "test_train\n",
      "train mean loss=62290.87265625\n",
      "test_test\n",
      "test mean loss=87800.22265625\n",
      "fin save.\n",
      "epoch 4211\n",
      "test_train\n",
      "train mean loss=61228.127604166664\n",
      "test_test\n",
      "test mean loss=88019.5390625\n",
      "fin save.\n",
      "epoch 4212\n",
      "test_train\n",
      "train mean loss=61601.170182291666\n",
      "test_test\n",
      "test mean loss=88420.79296875\n",
      "fin save.\n",
      "epoch 4213\n",
      "test_train\n",
      "train mean loss=62100.312109375\n",
      "test_test\n",
      "test mean loss=88504.76171875\n",
      "fin save.\n",
      "epoch 4214\n",
      "test_train\n",
      "train mean loss=62279.715625\n",
      "test_test\n",
      "test mean loss=88558.265625\n",
      "fin save.\n",
      "epoch 4215\n",
      "test_train\n",
      "train mean loss=61848.519791666666\n",
      "test_test\n",
      "test mean loss=88518.453125\n",
      "fin save.\n",
      "epoch 4216\n",
      "test_train\n",
      "train mean loss=62123.42721354167\n",
      "test_test\n",
      "test mean loss=88312.86328125\n",
      "fin save.\n",
      "epoch 4217\n",
      "test_train\n",
      "train mean loss=62756.77786458333\n",
      "test_test\n",
      "test mean loss=88312.16796875\n",
      "fin save.\n",
      "epoch 4218\n",
      "test_train\n",
      "train mean loss=61588.76484375\n",
      "test_test\n",
      "test mean loss=88260.73046875\n",
      "fin save.\n",
      "epoch 4219\n",
      "test_train\n",
      "train mean loss=62296.886067708336\n",
      "test_test\n",
      "test mean loss=88330.53515625\n",
      "fin save.\n",
      "epoch 4220\n",
      "test_train\n",
      "train mean loss=61650.831770833334\n",
      "test_test\n",
      "test mean loss=88248.5\n",
      "fin save.\n",
      "epoch 4221\n",
      "test_train\n",
      "train mean loss=62841.97838541667\n",
      "test_test\n",
      "test mean loss=88710.1328125\n",
      "fin save.\n",
      "epoch 4222\n",
      "test_train\n",
      "train mean loss=62373.8703125\n",
      "test_test\n",
      "test mean loss=88340.0234375\n",
      "fin save.\n",
      "epoch 4223\n",
      "test_train\n",
      "train mean loss=62295.985677083336\n",
      "test_test\n",
      "test mean loss=88285.76171875\n",
      "fin save.\n",
      "epoch 4224\n",
      "test_train\n",
      "train mean loss=62376.38619791667\n",
      "test_test\n",
      "test mean loss=88411.703125\n",
      "fin save.\n",
      "epoch 4225\n",
      "test_train\n",
      "train mean loss=63019.8375\n",
      "test_test\n",
      "test mean loss=88432.91796875\n",
      "fin save.\n",
      "epoch 4226\n",
      "test_train\n",
      "train mean loss=61657.5015625\n",
      "test_test\n",
      "test mean loss=88316.59375\n",
      "fin save.\n",
      "epoch 4227\n",
      "test_train\n",
      "train mean loss=61300.704427083336\n",
      "test_test\n",
      "test mean loss=88065.2890625\n",
      "fin save.\n",
      "epoch 4228\n",
      "test_train\n",
      "train mean loss=63743.38229166667\n",
      "test_test\n",
      "test mean loss=88243.06640625\n",
      "fin save.\n",
      "epoch 4229\n",
      "test_train\n",
      "train mean loss=63236.52838541667\n",
      "test_test\n",
      "test mean loss=88030.78515625\n",
      "fin save.\n",
      "epoch 4230\n",
      "test_train\n",
      "train mean loss=62238.03359375\n",
      "test_test\n",
      "test mean loss=87735.59375\n",
      "fin save.\n",
      "epoch 4231\n",
      "test_train\n",
      "train mean loss=61767.37838541667\n",
      "test_test\n",
      "test mean loss=87693.44921875\n",
      "fin save.\n",
      "epoch 4232\n",
      "test_train\n",
      "train mean loss=62333.04153645833\n",
      "test_test\n",
      "test mean loss=87769.91796875\n",
      "fin save.\n",
      "epoch 4233\n",
      "test_train\n",
      "train mean loss=62441.3578125\n",
      "test_test\n",
      "test mean loss=87702.1640625\n",
      "fin save.\n",
      "epoch 4234\n",
      "test_train\n",
      "train mean loss=62673.45364583333\n",
      "test_test\n",
      "test mean loss=87713.65234375\n",
      "fin save.\n",
      "epoch 4235\n",
      "test_train\n",
      "train mean loss=63216.773828125\n",
      "test_test\n",
      "test mean loss=87789.359375\n",
      "fin save.\n",
      "epoch 4236\n",
      "test_train\n",
      "train mean loss=61888.55963541667\n",
      "test_test\n",
      "test mean loss=87862.08984375\n",
      "fin save.\n",
      "epoch 4237\n",
      "test_train\n",
      "train mean loss=62286.67291666667\n",
      "test_test\n",
      "test mean loss=88068.953125\n",
      "fin save.\n",
      "epoch 4238\n",
      "test_train\n",
      "train mean loss=62258.75572916667\n",
      "test_test\n",
      "test mean loss=88133.7265625\n",
      "fin save.\n",
      "epoch 4239\n",
      "test_train\n",
      "train mean loss=62502.188671875\n",
      "test_test\n",
      "test mean loss=88156.87109375\n",
      "fin save.\n",
      "epoch 4240\n",
      "test_train\n",
      "train mean loss=62392.85598958333\n",
      "test_test\n",
      "test mean loss=88059.4375\n",
      "fin save.\n",
      "epoch 4241\n",
      "test_train\n",
      "train mean loss=62405.16848958333\n",
      "test_test\n",
      "test mean loss=88462.04296875\n",
      "fin save.\n",
      "epoch 4242\n",
      "test_train\n",
      "train mean loss=62338.35364583333\n",
      "test_test\n",
      "test mean loss=88511.92578125\n",
      "fin save.\n",
      "epoch 4243\n",
      "test_train\n",
      "train mean loss=62017.80455729167\n",
      "test_test\n",
      "test mean loss=88464.36328125\n",
      "fin save.\n",
      "epoch 4244\n",
      "test_train\n",
      "train mean loss=62815.985677083336\n",
      "test_test\n",
      "test mean loss=88460.1640625\n",
      "fin save.\n",
      "epoch 4245\n",
      "test_train\n",
      "train mean loss=61821.98541666667\n",
      "test_test\n",
      "test mean loss=88326.80078125\n",
      "fin save.\n",
      "epoch 4246\n",
      "test_train\n",
      "train mean loss=62043.75182291667\n",
      "test_test\n",
      "test mean loss=88401.12890625\n",
      "fin save.\n",
      "epoch 4247\n",
      "test_train\n",
      "train mean loss=61701.3765625\n",
      "test_test\n",
      "test mean loss=88685.8515625\n",
      "fin save.\n",
      "epoch 4248\n",
      "test_train\n",
      "train mean loss=61731.19348958333\n",
      "test_test\n",
      "test mean loss=88288.76171875\n",
      "fin save.\n",
      "epoch 4249\n",
      "test_train\n",
      "train mean loss=62959.999739583334\n",
      "test_test\n",
      "test mean loss=88828.4765625\n",
      "fin save.\n",
      "epoch 4250\n",
      "test_train\n",
      "train mean loss=62561.677734375\n",
      "test_test\n",
      "test mean loss=88730.90625\n",
      "fin save.\n",
      "epoch 4251\n",
      "test_train\n",
      "train mean loss=61966.144270833334\n",
      "test_test\n",
      "test mean loss=88779.07421875\n",
      "fin save.\n",
      "epoch 4252\n",
      "test_train\n",
      "train mean loss=61926.82630208333\n",
      "test_test\n",
      "test mean loss=88722.45703125\n",
      "fin save.\n",
      "epoch 4253\n",
      "test_train\n",
      "train mean loss=62947.89348958333\n",
      "test_test\n",
      "test mean loss=88638.4296875\n",
      "fin save.\n",
      "epoch 4254\n",
      "test_train\n",
      "train mean loss=63355.34583333333\n",
      "test_test\n",
      "test mean loss=88527.9140625\n",
      "fin save.\n",
      "epoch 4255\n",
      "test_train\n",
      "train mean loss=62693.7515625\n",
      "test_test\n",
      "test mean loss=88546.72265625\n",
      "fin save.\n",
      "epoch 4256\n",
      "test_train\n",
      "train mean loss=61461.290625\n",
      "test_test\n",
      "test mean loss=88419.765625\n",
      "fin save.\n",
      "epoch 4257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_train\n",
      "train mean loss=62962.14114583333\n",
      "test_test\n",
      "test mean loss=88302.078125\n",
      "fin save.\n",
      "epoch 4258\n",
      "test_train\n",
      "train mean loss=61750.312239583334\n",
      "test_test\n",
      "test mean loss=88502.9453125\n",
      "fin save.\n",
      "epoch 4259\n",
      "test_train\n",
      "train mean loss=61712.82083333333\n",
      "test_test\n",
      "test mean loss=88520.2734375\n",
      "fin save.\n",
      "epoch 4260\n",
      "test_train\n",
      "train mean loss=62881.44973958333\n",
      "test_test\n",
      "test mean loss=88117.25390625\n",
      "fin save.\n",
      "epoch 4261\n",
      "test_train\n",
      "train mean loss=61549.60546875\n",
      "test_test\n",
      "test mean loss=88102.85546875\n",
      "fin save.\n",
      "epoch 4262\n",
      "test_train\n",
      "train mean loss=62085.58841145833\n",
      "test_test\n",
      "test mean loss=88548.96875\n",
      "fin save.\n",
      "epoch 4263\n",
      "test_train\n",
      "train mean loss=61276.59427083333\n",
      "test_test\n",
      "test mean loss=88258.21875\n",
      "fin save.\n",
      "epoch 4264\n",
      "test_train\n",
      "train mean loss=62630.92330729167\n",
      "test_test\n",
      "test mean loss=88232.28515625\n",
      "fin save.\n",
      "epoch 4265\n",
      "test_train\n",
      "train mean loss=62773.21875\n",
      "test_test\n",
      "test mean loss=88119.1953125\n",
      "fin save.\n",
      "epoch 4266\n",
      "test_train\n",
      "train mean loss=61889.007552083334\n",
      "test_test\n",
      "test mean loss=88340.83984375\n",
      "fin save.\n",
      "epoch 4267\n",
      "test_train\n",
      "train mean loss=61273.40078125\n",
      "test_test\n",
      "test mean loss=88227.8828125\n",
      "fin save.\n",
      "epoch 4268\n",
      "test_train\n",
      "train mean loss=61210.92083333333\n",
      "test_test\n",
      "test mean loss=87932.015625\n",
      "fin save.\n",
      "epoch 4269\n",
      "test_train\n",
      "train mean loss=62852.153125\n",
      "test_test\n",
      "test mean loss=88110.9375\n",
      "fin save.\n",
      "epoch 4270\n",
      "test_train\n",
      "train mean loss=61654.8765625\n",
      "test_test\n",
      "test mean loss=88051.125\n",
      "fin save.\n",
      "epoch 4271\n",
      "test_train\n",
      "train mean loss=62597.41888020833\n",
      "test_test\n",
      "test mean loss=87984.3515625\n",
      "fin save.\n",
      "epoch 4272\n",
      "test_train\n",
      "train mean loss=62186.723046875\n",
      "test_test\n",
      "test mean loss=87870.98046875\n",
      "fin save.\n",
      "epoch 4273\n",
      "test_train\n",
      "train mean loss=61797.13489583333\n",
      "test_test\n",
      "test mean loss=87942.89453125\n",
      "fin save.\n",
      "epoch 4274\n",
      "test_train\n",
      "train mean loss=62087.740234375\n",
      "test_test\n",
      "test mean loss=88141.60546875\n",
      "fin save.\n",
      "epoch 4275\n",
      "test_train\n",
      "train mean loss=61122.223307291664\n",
      "test_test\n",
      "test mean loss=88244.61328125\n",
      "fin save.\n",
      "epoch 4276\n",
      "test_train\n",
      "train mean loss=61466.30169270833\n",
      "test_test\n",
      "test mean loss=88213.79296875\n",
      "fin save.\n",
      "epoch 4277\n",
      "test_train\n",
      "train mean loss=62018.000260416666\n",
      "test_test\n",
      "test mean loss=88165.79296875\n",
      "fin save.\n",
      "epoch 4278\n",
      "test_train\n",
      "train mean loss=61839.15052083333\n",
      "test_test\n",
      "test mean loss=87921.25\n",
      "fin save.\n",
      "epoch 4279\n",
      "test_train\n",
      "train mean loss=61497.7578125\n",
      "test_test\n",
      "test mean loss=87927.0390625\n",
      "fin save.\n",
      "epoch 4280\n",
      "test_train\n",
      "train mean loss=61823.57044270833\n",
      "test_test\n",
      "test mean loss=88006.28515625\n",
      "fin save.\n",
      "epoch 4281\n",
      "test_train\n",
      "train mean loss=61960.984765625\n",
      "test_test\n",
      "test mean loss=88002.078125\n",
      "fin save.\n",
      "epoch 4282\n",
      "test_train\n",
      "train mean loss=62330.83880208333\n",
      "test_test\n",
      "test mean loss=87765.16796875\n",
      "fin save.\n",
      "epoch 4283\n",
      "test_train\n",
      "train mean loss=61774.75572916667\n",
      "test_test\n",
      "test mean loss=88000.38671875\n",
      "fin save.\n",
      "epoch 4284\n",
      "test_train\n",
      "train mean loss=61583.115494791666\n",
      "test_test\n",
      "test mean loss=87743.25390625\n",
      "fin save.\n",
      "epoch 4285\n",
      "test_train\n",
      "train mean loss=63154.05911458333\n",
      "test_test\n",
      "test mean loss=87619.23046875\n",
      "fin save.\n",
      "epoch 4286\n",
      "test_train\n",
      "train mean loss=61709.01770833333\n",
      "test_test\n",
      "test mean loss=87635.046875\n",
      "fin save.\n",
      "epoch 4287\n",
      "test_train\n",
      "train mean loss=62507.67864583333\n",
      "test_test\n",
      "test mean loss=87788.5390625\n",
      "fin save.\n",
      "epoch 4288\n",
      "test_train\n",
      "train mean loss=62002.576822916664\n",
      "test_test\n",
      "test mean loss=88027.40625\n",
      "fin save.\n",
      "epoch 4289\n",
      "test_train\n",
      "train mean loss=61594.40520833333\n",
      "test_test\n",
      "test mean loss=88408.98046875\n",
      "fin save.\n",
      "epoch 4290\n",
      "test_train\n",
      "train mean loss=62028.402083333334\n",
      "test_test\n",
      "test mean loss=90066.91796875\n",
      "fin save.\n",
      "epoch 4291\n",
      "test_train\n",
      "train mean loss=61959.646223958334\n",
      "test_test\n",
      "test mean loss=90073.73046875\n",
      "fin save.\n",
      "epoch 4292\n",
      "test_train\n",
      "train mean loss=61239.27330729167\n",
      "test_test\n",
      "test mean loss=89857.734375\n",
      "fin save.\n",
      "epoch 4293\n",
      "test_train\n",
      "train mean loss=62672.90026041667\n",
      "test_test\n",
      "test mean loss=89650.10546875\n",
      "fin save.\n",
      "epoch 4294\n",
      "test_train\n",
      "train mean loss=62274.5171875\n",
      "test_test\n",
      "test mean loss=89287.68359375\n",
      "fin save.\n",
      "epoch 4295\n",
      "test_train\n",
      "train mean loss=62328.98098958333\n",
      "test_test\n",
      "test mean loss=89230.3984375\n",
      "fin save.\n",
      "epoch 4296\n",
      "test_train\n",
      "train mean loss=61497.417317708336\n",
      "test_test\n",
      "test mean loss=89339.0390625\n",
      "fin save.\n",
      "epoch 4297\n",
      "test_train\n",
      "train mean loss=61460.65833333333\n",
      "test_test\n",
      "test mean loss=89064.4140625\n",
      "fin save.\n",
      "epoch 4298\n",
      "test_train\n",
      "train mean loss=60941.586588541664\n",
      "test_test\n",
      "test mean loss=89087.5703125\n",
      "fin save.\n",
      "epoch 4299\n",
      "test_train\n",
      "train mean loss=61513.53515625\n",
      "test_test\n",
      "test mean loss=88870.45703125\n",
      "fin save.\n",
      "epoch 4300\n",
      "test_train\n",
      "train mean loss=60952.859635416666\n",
      "test_test\n",
      "test mean loss=88884.61328125\n",
      "fin save.\n",
      "epoch 4301\n",
      "test_train\n",
      "train mean loss=61230.034375\n",
      "test_test\n",
      "test mean loss=88999.44921875\n",
      "fin save.\n",
      "epoch 4302\n",
      "test_train\n",
      "train mean loss=61543.920182291666\n",
      "test_test\n",
      "test mean loss=88600.21484375\n",
      "fin save.\n",
      "epoch 4303\n",
      "test_train\n",
      "train mean loss=62354.13098958333\n",
      "test_test\n",
      "test mean loss=88488.125\n",
      "fin save.\n",
      "epoch 4304\n",
      "test_train\n",
      "train mean loss=61671.644270833334\n",
      "test_test\n",
      "test mean loss=87988.6171875\n",
      "fin save.\n",
      "epoch 4305\n",
      "test_train\n",
      "train mean loss=61143.11432291667\n",
      "test_test\n",
      "test mean loss=88136.8671875\n",
      "fin save.\n",
      "epoch 4306\n",
      "test_train\n",
      "train mean loss=60780.81796875\n",
      "test_test\n",
      "test mean loss=88088.546875\n",
      "fin save.\n",
      "epoch 4307\n",
      "test_train\n",
      "train mean loss=62916.369140625\n",
      "test_test\n",
      "test mean loss=88150.76953125\n",
      "fin save.\n",
      "epoch 4308\n",
      "test_train\n",
      "train mean loss=60856.55859375\n",
      "test_test\n",
      "test mean loss=88160.5546875\n",
      "fin save.\n",
      "epoch 4309\n",
      "test_train\n",
      "train mean loss=62491.756510416664\n",
      "test_test\n",
      "test mean loss=88053.78125\n",
      "fin save.\n",
      "epoch 4310\n",
      "test_train\n",
      "train mean loss=61316.41484375\n",
      "test_test\n",
      "test mean loss=88337.26171875\n",
      "fin save.\n",
      "epoch 4311\n",
      "test_train\n",
      "train mean loss=62057.42109375\n",
      "test_test\n",
      "test mean loss=88349.27734375\n",
      "fin save.\n",
      "epoch 4312\n",
      "test_train\n",
      "train mean loss=61549.479166666664\n",
      "test_test\n",
      "test mean loss=88324.77734375\n",
      "fin save.\n",
      "epoch 4313\n",
      "test_train\n",
      "train mean loss=61364.194010416664\n",
      "test_test\n",
      "test mean loss=88446.234375\n",
      "fin save.\n",
      "epoch 4314\n",
      "test_train\n",
      "train mean loss=61677.96197916667\n",
      "test_test\n",
      "test mean loss=88300.515625\n",
      "fin save.\n",
      "epoch 4315\n",
      "test_train\n",
      "train mean loss=60864.031510416666\n",
      "test_test\n",
      "test mean loss=88343.984375\n",
      "fin save.\n",
      "epoch 4316\n",
      "test_train\n",
      "train mean loss=61876.71236979167\n",
      "test_test\n",
      "test mean loss=88235.703125\n",
      "fin save.\n",
      "epoch 4317\n",
      "test_train\n",
      "train mean loss=61191.340104166666\n",
      "test_test\n",
      "test mean loss=89129.03515625\n",
      "fin save.\n",
      "epoch 4318\n",
      "test_train\n",
      "train mean loss=61921.98645833333\n",
      "test_test\n",
      "test mean loss=88954.89453125\n",
      "fin save.\n",
      "epoch 4319\n",
      "test_train\n",
      "train mean loss=61342.756119791666\n",
      "test_test\n",
      "test mean loss=88784.50390625\n",
      "fin save.\n",
      "epoch 4320\n",
      "test_train\n",
      "train mean loss=61800.621484375\n",
      "test_test\n",
      "test mean loss=88852.484375\n",
      "fin save.\n",
      "epoch 4321\n",
      "test_train\n",
      "train mean loss=61901.77552083333\n",
      "test_test\n",
      "test mean loss=88650.78125\n",
      "fin save.\n",
      "epoch 4322\n",
      "test_train\n",
      "train mean loss=61489.960286458336\n",
      "test_test\n",
      "test mean loss=88885.08203125\n",
      "fin save.\n",
      "epoch 4323\n",
      "test_train\n",
      "train mean loss=61597.00885416667\n",
      "test_test\n",
      "test mean loss=88888.48046875\n",
      "fin save.\n",
      "epoch 4324\n",
      "test_train\n",
      "train mean loss=61172.044270833336\n",
      "test_test\n",
      "test mean loss=88393.3046875\n",
      "fin save.\n",
      "epoch 4325\n",
      "test_train\n",
      "train mean loss=61638.88333333333\n",
      "test_test\n",
      "test mean loss=88624.29296875\n",
      "fin save.\n",
      "epoch 4326\n",
      "test_train\n",
      "train mean loss=61894.009505208334\n",
      "test_test\n",
      "test mean loss=88636.0859375\n",
      "fin save.\n",
      "epoch 4327\n",
      "test_train\n",
      "train mean loss=61773.37161458333\n",
      "test_test\n",
      "test mean loss=88535.7265625\n",
      "fin save.\n",
      "epoch 4328\n",
      "test_train\n",
      "train mean loss=61426.95260416667\n",
      "test_test\n",
      "test mean loss=88563.0234375\n",
      "fin save.\n",
      "epoch 4329\n",
      "test_train\n",
      "train mean loss=61741.37942708333\n",
      "test_test\n",
      "test mean loss=88554.8203125\n",
      "fin save.\n",
      "epoch 4330\n",
      "test_train\n",
      "train mean loss=61881.941015625\n",
      "test_test\n",
      "test mean loss=88771.40234375\n",
      "fin save.\n",
      "epoch 4331\n",
      "test_train\n",
      "train mean loss=62370.66796875\n",
      "test_test\n",
      "test mean loss=88817.63671875\n",
      "fin save.\n",
      "epoch 4332\n",
      "test_train\n",
      "train mean loss=61891.919270833336\n",
      "test_test\n",
      "test mean loss=88580.80078125\n",
      "fin save.\n",
      "epoch 4333\n",
      "test_train\n",
      "train mean loss=61531.59479166667\n",
      "test_test\n",
      "test mean loss=89351.24609375\n",
      "fin save.\n",
      "epoch 4334\n",
      "test_train\n",
      "train mean loss=61693.75989583333\n",
      "test_test\n",
      "test mean loss=89279.40234375\n",
      "fin save.\n",
      "epoch 4335\n",
      "test_train\n",
      "train mean loss=60847.34270833333\n",
      "test_test\n",
      "test mean loss=89300.1171875\n",
      "fin save.\n",
      "epoch 4336\n",
      "test_train\n",
      "train mean loss=61094.372395833336\n",
      "test_test\n",
      "test mean loss=89418.6328125\n",
      "fin save.\n",
      "epoch 4337\n",
      "test_train\n",
      "train mean loss=61536.051041666666\n",
      "test_test\n",
      "test mean loss=89313.296875\n",
      "fin save.\n",
      "epoch 4338\n",
      "test_train\n",
      "train mean loss=61996.44036458333\n",
      "test_test\n",
      "test mean loss=89204.60546875\n",
      "fin save.\n",
      "epoch 4339\n",
      "test_train\n",
      "train mean loss=61786.48541666667\n",
      "test_test\n",
      "test mean loss=89322.73828125\n",
      "fin save.\n",
      "epoch 4340\n",
      "test_train\n",
      "train mean loss=61406.733723958336\n",
      "test_test\n",
      "test mean loss=89226.83984375\n",
      "fin save.\n",
      "epoch 4341\n",
      "test_train\n",
      "train mean loss=61461.331770833334\n",
      "test_test\n",
      "test mean loss=89591.03125\n",
      "fin save.\n",
      "epoch 4342\n",
      "test_train\n",
      "train mean loss=62175.18463541667\n",
      "test_test\n",
      "test mean loss=89191.1796875\n",
      "fin save.\n",
      "epoch 4343\n",
      "test_train\n",
      "train mean loss=61820.180989583336\n",
      "test_test\n",
      "test mean loss=89494.5859375\n",
      "fin save.\n",
      "epoch 4344\n",
      "test_train\n",
      "train mean loss=62319.780989583334\n",
      "test_test\n",
      "test mean loss=89330.16015625\n",
      "fin save.\n",
      "epoch 4345\n",
      "test_train\n",
      "train mean loss=62730.26549479167\n",
      "test_test\n",
      "test mean loss=88960.37109375\n",
      "fin save.\n",
      "epoch 4346\n",
      "test_train\n",
      "train mean loss=61448.07239583333\n",
      "test_test\n",
      "test mean loss=88917.85546875\n",
      "fin save.\n",
      "epoch 4347\n",
      "test_train\n",
      "train mean loss=61852.84661458333\n",
      "test_test\n",
      "test mean loss=88866.99609375\n",
      "fin save.\n",
      "epoch 4348\n",
      "test_train\n",
      "train mean loss=61071.141927083336\n",
      "test_test\n",
      "test mean loss=88483.46484375\n",
      "fin save.\n",
      "epoch 4349\n",
      "test_train\n",
      "train mean loss=60715.17083333333\n",
      "test_test\n",
      "test mean loss=88379.27734375\n",
      "fin save.\n",
      "epoch 4350\n",
      "test_train\n",
      "train mean loss=62521.27135416667\n",
      "test_test\n",
      "test mean loss=88379.62109375\n",
      "fin save.\n",
      "epoch 4351\n",
      "test_train\n",
      "train mean loss=61769.45911458333\n",
      "test_test\n",
      "test mean loss=88528.52734375\n",
      "fin save.\n",
      "epoch 4352\n",
      "test_train\n",
      "train mean loss=61073.153645833336\n",
      "test_test\n",
      "test mean loss=88698.5\n",
      "fin save.\n",
      "epoch 4353\n",
      "test_train\n",
      "train mean loss=61334.17278645833\n",
      "test_test\n",
      "test mean loss=88605.27734375\n",
      "fin save.\n",
      "epoch 4354\n",
      "test_train\n",
      "train mean loss=60837.60104166667\n",
      "test_test\n",
      "test mean loss=88639.16796875\n",
      "fin save.\n",
      "epoch 4355\n",
      "test_train\n",
      "train mean loss=61599.81145833333\n",
      "test_test\n",
      "test mean loss=89126.6796875\n",
      "fin save.\n",
      "epoch 4356\n",
      "test_train\n",
      "train mean loss=62444.45559895833\n",
      "test_test\n",
      "test mean loss=88927.64453125\n",
      "fin save.\n",
      "epoch 4357\n",
      "test_train\n",
      "train mean loss=60899.47565104167\n",
      "test_test\n",
      "test mean loss=88822.96875\n",
      "fin save.\n",
      "epoch 4358\n",
      "test_train\n",
      "train mean loss=62258.948046875\n",
      "test_test\n",
      "test mean loss=88942.54296875\n",
      "fin save.\n",
      "epoch 4359\n",
      "test_train\n",
      "train mean loss=61937.96302083333\n",
      "test_test\n",
      "test mean loss=88949.89453125\n",
      "fin save.\n",
      "epoch 4360\n",
      "test_train\n",
      "train mean loss=62870.180338541664\n",
      "test_test\n",
      "test mean loss=89317.890625\n",
      "fin save.\n",
      "epoch 4361\n",
      "test_train\n",
      "train mean loss=61549.94453125\n",
      "test_test\n",
      "test mean loss=89282.3203125\n",
      "fin save.\n",
      "epoch 4362\n",
      "test_train\n",
      "train mean loss=62491.66744791667\n",
      "test_test\n",
      "test mean loss=89441.6484375\n",
      "fin save.\n",
      "epoch 4363\n",
      "test_train\n",
      "train mean loss=61405.09817708333\n",
      "test_test\n",
      "test mean loss=89366.07421875\n",
      "fin save.\n",
      "epoch 4364\n",
      "test_train\n",
      "train mean loss=61634.61614583333\n",
      "test_test\n",
      "test mean loss=89555.26953125\n",
      "fin save.\n",
      "epoch 4365\n",
      "test_train\n",
      "train mean loss=62186.559765625\n",
      "test_test\n",
      "test mean loss=88350.203125\n",
      "fin save.\n",
      "epoch 4366\n",
      "test_train\n",
      "train mean loss=61364.781510416666\n",
      "test_test\n",
      "test mean loss=88675.33203125\n",
      "fin save.\n",
      "epoch 4367\n",
      "test_train\n",
      "train mean loss=61832.64635416667\n",
      "test_test\n",
      "test mean loss=88926.90234375\n",
      "fin save.\n",
      "epoch 4368\n",
      "test_train\n",
      "train mean loss=61601.66354166667\n",
      "test_test\n",
      "test mean loss=88898.7421875\n",
      "fin save.\n",
      "epoch 4369\n",
      "test_train\n",
      "train mean loss=62301.552083333336\n",
      "test_test\n",
      "test mean loss=88999.3515625\n",
      "fin save.\n",
      "epoch 4370\n",
      "test_train\n",
      "train mean loss=61307.08828125\n",
      "test_test\n",
      "test mean loss=88837.46875\n",
      "fin save.\n",
      "epoch 4371\n",
      "test_train\n",
      "train mean loss=61321.99921875\n",
      "test_test\n",
      "test mean loss=88858.94140625\n",
      "fin save.\n",
      "epoch 4372\n",
      "test_train\n",
      "train mean loss=62197.9140625\n",
      "test_test\n",
      "test mean loss=88803.06640625\n",
      "fin save.\n",
      "epoch 4373\n",
      "test_train\n",
      "train mean loss=60896.06145833333\n",
      "test_test\n",
      "test mean loss=88904.98046875\n",
      "fin save.\n",
      "epoch 4374\n",
      "test_train\n",
      "train mean loss=61600.38229166667\n",
      "test_test\n",
      "test mean loss=88900.54296875\n",
      "fin save.\n",
      "epoch 4375\n",
      "test_train\n",
      "train mean loss=63011.12942708333\n",
      "test_test\n",
      "test mean loss=88849.05078125\n",
      "fin save.\n",
      "epoch 4376\n",
      "test_train\n",
      "train mean loss=62363.41510416667\n",
      "test_test\n",
      "test mean loss=88728.7578125\n",
      "fin save.\n",
      "epoch 4377\n",
      "test_train\n",
      "train mean loss=61339.52291666667\n",
      "test_test\n",
      "test mean loss=88778.46875\n",
      "fin save.\n",
      "epoch 4378\n",
      "test_train\n",
      "train mean loss=61936.418359375\n",
      "test_test\n",
      "test mean loss=88798.23046875\n",
      "fin save.\n",
      "epoch 4379\n",
      "test_train\n",
      "train mean loss=61384.88958333333\n",
      "test_test\n",
      "test mean loss=88943.2109375\n",
      "fin save.\n",
      "epoch 4380\n",
      "test_train\n",
      "train mean loss=61381.53033854167\n",
      "test_test\n",
      "test mean loss=88497.98828125\n",
      "fin save.\n",
      "epoch 4381\n",
      "test_train\n",
      "train mean loss=61733.23541666667\n",
      "test_test\n",
      "test mean loss=88435.375\n",
      "fin save.\n",
      "epoch 4382\n",
      "test_train\n",
      "train mean loss=62126.85729166667\n",
      "test_test\n",
      "test mean loss=88505.3203125\n",
      "fin save.\n",
      "epoch 4383\n",
      "test_train\n",
      "train mean loss=61446.59765625\n",
      "test_test\n",
      "test mean loss=88520.015625\n",
      "fin save.\n",
      "epoch 4384\n",
      "test_train\n",
      "train mean loss=62355.3984375\n",
      "test_test\n",
      "test mean loss=88505.0390625\n",
      "fin save.\n",
      "epoch 4385\n",
      "test_train\n",
      "train mean loss=62343.931380208334\n",
      "test_test\n",
      "test mean loss=88559.04296875\n",
      "fin save.\n",
      "epoch 4386\n",
      "test_train\n",
      "train mean loss=61872.20807291667\n",
      "test_test\n",
      "test mean loss=88495.1015625\n",
      "fin save.\n",
      "epoch 4387\n",
      "test_train\n",
      "train mean loss=62033.90833333333\n",
      "test_test\n",
      "test mean loss=88629.953125\n",
      "fin save.\n",
      "epoch 4388\n",
      "test_train\n",
      "train mean loss=60973.035416666666\n",
      "test_test\n",
      "test mean loss=88529.0234375\n",
      "fin save.\n",
      "epoch 4389\n",
      "test_train\n",
      "train mean loss=61352.340494791664\n",
      "test_test\n",
      "test mean loss=88548.67578125\n",
      "fin save.\n",
      "epoch 4390\n",
      "test_train\n",
      "train mean loss=62009.49609375\n",
      "test_test\n",
      "test mean loss=88610.26171875\n",
      "fin save.\n",
      "epoch 4391\n",
      "test_train\n",
      "train mean loss=62338.084765625\n",
      "test_test\n",
      "test mean loss=88816.67578125\n",
      "fin save.\n",
      "epoch 4392\n",
      "test_train\n",
      "train mean loss=61169.34713541667\n",
      "test_test\n",
      "test mean loss=89167.12109375\n",
      "fin save.\n",
      "epoch 4393\n",
      "test_train\n",
      "train mean loss=61952.140885416666\n",
      "test_test\n",
      "test mean loss=88719.71484375\n",
      "fin save.\n",
      "epoch 4394\n",
      "test_train\n",
      "train mean loss=62097.81354166667\n",
      "test_test\n",
      "test mean loss=88861.12890625\n",
      "fin save.\n",
      "epoch 4395\n",
      "test_train\n",
      "train mean loss=61808.42526041667\n",
      "test_test\n",
      "test mean loss=88696.390625\n",
      "fin save.\n",
      "epoch 4396\n",
      "test_train\n",
      "train mean loss=61399.754557291664\n",
      "test_test\n",
      "test mean loss=88568.2421875\n",
      "fin save.\n",
      "epoch 4397\n",
      "test_train\n",
      "train mean loss=62086.734114583334\n",
      "test_test\n",
      "test mean loss=88591.82421875\n",
      "fin save.\n",
      "epoch 4398\n",
      "test_train\n",
      "train mean loss=62159.41354166667\n",
      "test_test\n",
      "test mean loss=88197.9375\n",
      "fin save.\n",
      "epoch 4399\n",
      "test_train\n",
      "train mean loss=61782.93177083333\n",
      "test_test\n",
      "test mean loss=88470.66015625\n",
      "fin save.\n",
      "epoch 4400\n",
      "test_train\n",
      "train mean loss=61998.283854166664\n",
      "test_test\n",
      "test mean loss=88597.32421875\n",
      "fin save.\n",
      "epoch 4401\n",
      "test_train\n",
      "train mean loss=60967.02291666667\n",
      "test_test\n",
      "test mean loss=88554.671875\n",
      "fin save.\n",
      "epoch 4402\n",
      "test_train\n",
      "train mean loss=61923.17486979167\n",
      "test_test\n",
      "test mean loss=88745.109375\n",
      "fin save.\n",
      "epoch 4403\n",
      "test_train\n",
      "train mean loss=61466.47213541667\n",
      "test_test\n",
      "test mean loss=88638.53125\n",
      "fin save.\n",
      "epoch 4404\n",
      "test_train\n",
      "train mean loss=60952.031510416666\n",
      "test_test\n",
      "test mean loss=88569.8046875\n",
      "fin save.\n",
      "epoch 4405\n",
      "test_train\n",
      "train mean loss=62352.28671875\n",
      "test_test\n",
      "test mean loss=88559.92578125\n",
      "fin save.\n",
      "epoch 4406\n",
      "test_train\n",
      "train mean loss=61745.73151041667\n",
      "test_test\n",
      "test mean loss=88596.44140625\n",
      "fin save.\n",
      "epoch 4407\n",
      "test_train\n",
      "train mean loss=61537.634114583336\n",
      "test_test\n",
      "test mean loss=88742.31640625\n",
      "fin save.\n",
      "epoch 4408\n",
      "test_train\n",
      "train mean loss=62255.32135416667\n",
      "test_test\n",
      "test mean loss=88565.78515625\n",
      "fin save.\n",
      "epoch 4409\n",
      "test_train\n",
      "train mean loss=61327.47447916667\n",
      "test_test\n",
      "test mean loss=88517.375\n",
      "fin save.\n",
      "epoch 4410\n",
      "test_train\n",
      "train mean loss=61745.272135416664\n",
      "test_test\n",
      "test mean loss=88684.56640625\n",
      "fin save.\n",
      "epoch 4411\n",
      "test_train\n",
      "train mean loss=61781.71015625\n",
      "test_test\n",
      "test mean loss=88595.05078125\n",
      "fin save.\n",
      "epoch 4412\n",
      "test_train\n",
      "train mean loss=61790.95403645833\n",
      "test_test\n",
      "test mean loss=88615.39453125\n",
      "fin save.\n",
      "epoch 4413\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=61515.52630208333\n",
      "test_test\n",
      "test mean loss=88484.40234375\n",
      "fin save.\n",
      "epoch 4414\n",
      "test_train\n",
      "train mean loss=61049.652083333334\n",
      "test_test\n",
      "test mean loss=88546.796875\n",
      "fin save.\n",
      "epoch 4415\n",
      "test_train\n",
      "train mean loss=61377.05416666667\n",
      "test_test\n",
      "test mean loss=88714.20703125\n",
      "fin save.\n",
      "epoch 4416\n",
      "test_train\n",
      "train mean loss=61339.98385416667\n",
      "test_test\n",
      "test mean loss=88889.296875\n",
      "fin save.\n",
      "epoch 4417\n",
      "test_train\n",
      "train mean loss=62825.4890625\n",
      "test_test\n",
      "test mean loss=88756.2734375\n",
      "fin save.\n",
      "epoch 4418\n",
      "test_train\n",
      "train mean loss=62423.67135416667\n",
      "test_test\n",
      "test mean loss=88607.015625\n",
      "fin save.\n",
      "epoch 4419\n",
      "test_train\n",
      "train mean loss=62230.523177083334\n",
      "test_test\n",
      "test mean loss=88696.86328125\n",
      "fin save.\n",
      "epoch 4420\n",
      "test_train\n",
      "train mean loss=62112.432291666664\n",
      "test_test\n",
      "test mean loss=88524.3125\n",
      "fin save.\n",
      "epoch 4421\n",
      "test_train\n",
      "train mean loss=61503.52734375\n",
      "test_test\n",
      "test mean loss=89122.1171875\n",
      "fin save.\n",
      "epoch 4422\n",
      "test_train\n",
      "train mean loss=62024.025130208334\n",
      "test_test\n",
      "test mean loss=89221.60546875\n",
      "fin save.\n",
      "epoch 4423\n",
      "test_train\n",
      "train mean loss=62721.019791666666\n",
      "test_test\n",
      "test mean loss=89375.515625\n",
      "fin save.\n",
      "epoch 4424\n",
      "test_train\n",
      "train mean loss=61986.85364583333\n",
      "test_test\n",
      "test mean loss=89488.046875\n",
      "fin save.\n",
      "epoch 4425\n",
      "test_train\n",
      "train mean loss=62257.67916666667\n",
      "test_test\n",
      "test mean loss=88693.30078125\n",
      "fin save.\n",
      "epoch 4426\n",
      "test_train\n",
      "train mean loss=62227.495833333334\n",
      "test_test\n",
      "test mean loss=88392.24609375\n",
      "fin save.\n",
      "epoch 4427\n",
      "test_train\n",
      "train mean loss=60104.665364583336\n",
      "test_test\n",
      "test mean loss=88765.75390625\n",
      "fin save.\n",
      "epoch 4428\n",
      "test_train\n",
      "train mean loss=62411.933333333334\n",
      "test_test\n",
      "test mean loss=88915.73046875\n",
      "fin save.\n",
      "epoch 4429\n",
      "test_train\n",
      "train mean loss=62004.34192708333\n",
      "test_test\n",
      "test mean loss=88974.02734375\n",
      "fin save.\n",
      "epoch 4430\n",
      "test_train\n",
      "train mean loss=61830.463541666664\n",
      "test_test\n",
      "test mean loss=88694.29296875\n",
      "fin save.\n",
      "epoch 4431\n",
      "test_train\n",
      "train mean loss=61838.729296875\n",
      "test_test\n",
      "test mean loss=88348.72265625\n",
      "fin save.\n",
      "epoch 4432\n",
      "test_train\n",
      "train mean loss=61288.64296875\n",
      "test_test\n",
      "test mean loss=88495.55078125\n",
      "fin save.\n",
      "epoch 4433\n",
      "test_train\n",
      "train mean loss=61154.774739583336\n",
      "test_test\n",
      "test mean loss=88715.68359375\n",
      "fin save.\n",
      "epoch 4434\n",
      "test_train\n",
      "train mean loss=61623.6515625\n",
      "test_test\n",
      "test mean loss=88315.4765625\n",
      "fin save.\n",
      "epoch 4435\n",
      "test_train\n",
      "train mean loss=61595.50690104167\n",
      "test_test\n",
      "test mean loss=88230.8203125\n",
      "fin save.\n",
      "epoch 4436\n",
      "test_train\n",
      "train mean loss=60658.9984375\n",
      "test_test\n",
      "test mean loss=88325.5078125\n",
      "fin save.\n",
      "epoch 4437\n",
      "test_train\n",
      "train mean loss=61854.60104166667\n",
      "test_test\n",
      "test mean loss=88093.16015625\n",
      "fin save.\n",
      "epoch 4438\n",
      "test_train\n",
      "train mean loss=61377.183854166666\n",
      "test_test\n",
      "test mean loss=88440.00390625\n",
      "fin save.\n",
      "epoch 4439\n",
      "test_train\n",
      "train mean loss=60261.58020833333\n",
      "test_test\n",
      "test mean loss=88278.5703125\n",
      "fin save.\n",
      "epoch 4440\n",
      "test_train\n",
      "train mean loss=61820.789713541664\n",
      "test_test\n",
      "test mean loss=88420.375\n",
      "fin save.\n",
      "epoch 4441\n",
      "test_train\n",
      "train mean loss=61620.94244791667\n",
      "test_test\n",
      "test mean loss=88465.7421875\n",
      "fin save.\n",
      "epoch 4442\n",
      "test_train\n",
      "train mean loss=61925.19427083333\n",
      "test_test\n",
      "test mean loss=88517.59375\n",
      "fin save.\n",
      "epoch 4443\n",
      "test_train\n",
      "train mean loss=61840.28111979167\n",
      "test_test\n",
      "test mean loss=88385.65625\n",
      "fin save.\n",
      "epoch 4444\n",
      "test_train\n",
      "train mean loss=61761.277604166666\n",
      "test_test\n",
      "test mean loss=88551.76171875\n",
      "fin save.\n",
      "epoch 4445\n",
      "test_train\n",
      "train mean loss=62513.66549479167\n",
      "test_test\n",
      "test mean loss=88434.09765625\n",
      "fin save.\n",
      "epoch 4446\n",
      "test_train\n",
      "train mean loss=60947.231770833336\n",
      "test_test\n",
      "test mean loss=88520.8359375\n",
      "fin save.\n",
      "epoch 4447\n",
      "test_train\n",
      "train mean loss=62857.91979166667\n",
      "test_test\n",
      "test mean loss=88799.90234375\n",
      "fin save.\n",
      "epoch 4448\n",
      "test_train\n",
      "train mean loss=61914.036458333336\n",
      "test_test\n",
      "test mean loss=88734.359375\n",
      "fin save.\n",
      "epoch 4449\n",
      "test_train\n",
      "train mean loss=61440.229166666664\n",
      "test_test\n",
      "test mean loss=88869.9453125\n",
      "fin save.\n",
      "epoch 4450\n",
      "test_train\n",
      "train mean loss=62628.61901041667\n",
      "test_test\n",
      "test mean loss=89022.82421875\n",
      "fin save.\n",
      "epoch 4451\n",
      "test_train\n",
      "train mean loss=62420.64375\n",
      "test_test\n",
      "test mean loss=87722.62890625\n",
      "fin save.\n",
      "epoch 4452\n",
      "test_train\n",
      "train mean loss=61668.2\n",
      "test_test\n",
      "test mean loss=87788.3828125\n",
      "fin save.\n",
      "epoch 4453\n",
      "test_train\n",
      "train mean loss=61903.274739583336\n",
      "test_test\n",
      "test mean loss=88153.8515625\n",
      "fin save.\n",
      "epoch 4454\n",
      "test_train\n",
      "train mean loss=61345.03802083333\n",
      "test_test\n",
      "test mean loss=88030.234375\n",
      "fin save.\n",
      "epoch 4455\n",
      "test_train\n",
      "train mean loss=61919.82890625\n",
      "test_test\n",
      "test mean loss=87805.2578125\n",
      "fin save.\n",
      "epoch 4456\n",
      "test_train\n",
      "train mean loss=62445.2375\n",
      "test_test\n",
      "test mean loss=87941.0078125\n",
      "fin save.\n",
      "epoch 4457\n",
      "test_train\n",
      "train mean loss=62959.289322916666\n",
      "test_test\n",
      "test mean loss=88267.44921875\n",
      "fin save.\n",
      "epoch 4458\n",
      "test_train\n",
      "train mean loss=62135.5953125\n",
      "test_test\n",
      "test mean loss=88213.26953125\n",
      "fin save.\n",
      "epoch 4459\n",
      "test_train\n",
      "train mean loss=61677.92877604167\n",
      "test_test\n",
      "test mean loss=88219.34765625\n",
      "fin save.\n",
      "epoch 4460\n",
      "test_train\n",
      "train mean loss=61827.89296875\n",
      "test_test\n",
      "test mean loss=88173.78515625\n",
      "fin save.\n",
      "epoch 4461\n",
      "test_train\n",
      "train mean loss=61495.743489583336\n",
      "test_test\n",
      "test mean loss=88225.90625\n",
      "fin save.\n",
      "epoch 4462\n",
      "test_train\n",
      "train mean loss=62307.36614583333\n",
      "test_test\n",
      "test mean loss=87958.50390625\n",
      "fin save.\n",
      "epoch 4463\n",
      "test_train\n",
      "train mean loss=61568.4015625\n",
      "test_test\n",
      "test mean loss=88184.14453125\n",
      "fin save.\n",
      "epoch 4464\n",
      "test_train\n",
      "train mean loss=61554.62421875\n",
      "test_test\n",
      "test mean loss=88134.98828125\n",
      "fin save.\n",
      "epoch 4465\n",
      "test_train\n",
      "train mean loss=62191.585546875\n",
      "test_test\n",
      "test mean loss=88060.4921875\n",
      "fin save.\n",
      "epoch 4466\n",
      "test_train\n",
      "train mean loss=61374.34583333333\n",
      "test_test\n",
      "test mean loss=88044.12890625\n",
      "fin save.\n",
      "epoch 4467\n",
      "test_train\n",
      "train mean loss=61910.48203125\n",
      "test_test\n",
      "test mean loss=88071.59765625\n",
      "fin save.\n",
      "epoch 4468\n",
      "test_train\n",
      "train mean loss=61794.6765625\n",
      "test_test\n",
      "test mean loss=87947.44140625\n",
      "fin save.\n",
      "epoch 4469\n",
      "test_train\n",
      "train mean loss=61920.24661458333\n",
      "test_test\n",
      "test mean loss=88184.53515625\n",
      "fin save.\n",
      "epoch 4470\n",
      "test_train\n",
      "train mean loss=61752.62747395833\n",
      "test_test\n",
      "test mean loss=88166.4765625\n",
      "fin save.\n",
      "epoch 4471\n",
      "test_train\n",
      "train mean loss=61928.04244791667\n",
      "test_test\n",
      "test mean loss=87929.20703125\n",
      "fin save.\n",
      "epoch 4472\n",
      "test_train\n",
      "train mean loss=61629.48059895833\n",
      "test_test\n",
      "test mean loss=87996.69921875\n",
      "fin save.\n",
      "epoch 4473\n",
      "test_train\n",
      "train mean loss=62662.64244791667\n",
      "test_test\n",
      "test mean loss=87980.89453125\n",
      "fin save.\n",
      "epoch 4474\n",
      "test_train\n",
      "train mean loss=61684.88919270833\n",
      "test_test\n",
      "test mean loss=88229.359375\n",
      "fin save.\n",
      "epoch 4475\n",
      "test_train\n",
      "train mean loss=60741.19140625\n",
      "test_test\n",
      "test mean loss=88139.10546875\n",
      "fin save.\n",
      "epoch 4476\n",
      "test_train\n",
      "train mean loss=60558.72369791667\n",
      "test_test\n",
      "test mean loss=88192.2578125\n",
      "fin save.\n",
      "epoch 4477\n",
      "test_train\n",
      "train mean loss=61971.581770833334\n",
      "test_test\n",
      "test mean loss=88357.6953125\n",
      "fin save.\n",
      "epoch 4478\n",
      "test_train\n",
      "train mean loss=61863.976302083334\n",
      "test_test\n",
      "test mean loss=88406.375\n",
      "fin save.\n",
      "epoch 4479\n",
      "test_train\n",
      "train mean loss=61415.14505208333\n",
      "test_test\n",
      "test mean loss=88069.82421875\n",
      "fin save.\n",
      "epoch 4480\n",
      "test_train\n",
      "train mean loss=61995.72109375\n",
      "test_test\n",
      "test mean loss=88196.6796875\n",
      "fin save.\n",
      "epoch 4481\n",
      "test_train\n",
      "train mean loss=61195.783854166664\n",
      "test_test\n",
      "test mean loss=88149.37109375\n",
      "fin save.\n",
      "epoch 4482\n",
      "test_train\n",
      "train mean loss=62338.81692708333\n",
      "test_test\n",
      "test mean loss=88148.67578125\n",
      "fin save.\n",
      "epoch 4483\n",
      "test_train\n",
      "train mean loss=61298.20234375\n",
      "test_test\n",
      "test mean loss=88461.33203125\n",
      "fin save.\n",
      "epoch 4484\n",
      "test_train\n",
      "train mean loss=61773.459765625\n",
      "test_test\n",
      "test mean loss=88452.7578125\n",
      "fin save.\n",
      "epoch 4485\n",
      "test_train\n",
      "train mean loss=62505.3734375\n",
      "test_test\n",
      "test mean loss=88262.8828125\n",
      "fin save.\n",
      "epoch 4486\n",
      "test_train\n",
      "train mean loss=61791.72994791667\n",
      "test_test\n",
      "test mean loss=88483.23046875\n",
      "fin save.\n",
      "epoch 4487\n",
      "test_train\n",
      "train mean loss=61545.15325520833\n",
      "test_test\n",
      "test mean loss=88190.125\n",
      "fin save.\n",
      "epoch 4488\n",
      "test_train\n",
      "train mean loss=61582.07317708333\n",
      "test_test\n",
      "test mean loss=88234.55859375\n",
      "fin save.\n",
      "epoch 4489\n",
      "test_train\n",
      "train mean loss=61160.29544270833\n",
      "test_test\n",
      "test mean loss=88522.82421875\n",
      "fin save.\n",
      "epoch 4490\n",
      "test_train\n",
      "train mean loss=62153.8875\n",
      "test_test\n",
      "test mean loss=88388.2421875\n",
      "fin save.\n",
      "epoch 4491\n",
      "test_train\n",
      "train mean loss=62725.972005208336\n",
      "test_test\n",
      "test mean loss=88321.65234375\n",
      "fin save.\n",
      "epoch 4492\n",
      "test_train\n",
      "train mean loss=61010.243880208334\n",
      "test_test\n",
      "test mean loss=87751.84375\n",
      "fin save.\n",
      "epoch 4493\n",
      "test_train\n",
      "train mean loss=61678.87799479167\n",
      "test_test\n",
      "test mean loss=87776.6328125\n",
      "fin save.\n",
      "epoch 4494\n",
      "test_train\n",
      "train mean loss=62110.635416666664\n",
      "test_test\n",
      "test mean loss=87916.69140625\n",
      "fin save.\n",
      "epoch 4495\n",
      "test_train\n",
      "train mean loss=61652.08203125\n",
      "test_test\n",
      "test mean loss=87921.41796875\n",
      "fin save.\n",
      "epoch 4496\n",
      "test_train\n",
      "train mean loss=62126.3859375\n",
      "test_test\n",
      "test mean loss=87916.50390625\n",
      "fin save.\n",
      "epoch 4497\n",
      "test_train\n",
      "train mean loss=61869.5015625\n",
      "test_test\n",
      "test mean loss=87924.875\n",
      "fin save.\n",
      "epoch 4498\n",
      "test_train\n",
      "train mean loss=61477.32317708333\n",
      "test_test\n",
      "test mean loss=88210.15234375\n",
      "fin save.\n",
      "epoch 4499\n",
      "test_train\n",
      "train mean loss=63799.42877604167\n",
      "test_test\n",
      "test mean loss=88176.81640625\n",
      "fin save.\n",
      "epoch 4500\n",
      "test_train\n",
      "train mean loss=61531.85546875\n",
      "test_test\n",
      "test mean loss=88350.92578125\n",
      "fin save.\n",
      "epoch 4501\n",
      "test_train\n",
      "train mean loss=62925.759375\n",
      "test_test\n",
      "test mean loss=87912.68359375\n",
      "fin save.\n",
      "epoch 4502\n",
      "test_train\n",
      "train mean loss=62248.15638020833\n",
      "test_test\n",
      "test mean loss=88280.3203125\n",
      "fin save.\n",
      "epoch 4503\n",
      "test_train\n",
      "train mean loss=62639.26119791667\n",
      "test_test\n",
      "test mean loss=88190.98046875\n",
      "fin save.\n",
      "epoch 4504\n",
      "test_train\n",
      "train mean loss=62028.684375\n",
      "test_test\n",
      "test mean loss=88376.859375\n",
      "fin save.\n",
      "epoch 4505\n",
      "test_train\n",
      "train mean loss=61482.32864583333\n",
      "test_test\n",
      "test mean loss=88339.30078125\n",
      "fin save.\n",
      "epoch 4506\n",
      "test_train\n",
      "train mean loss=61659.87291666667\n",
      "test_test\n",
      "test mean loss=88461.28515625\n",
      "fin save.\n",
      "epoch 4507\n",
      "test_train\n",
      "train mean loss=62055.91875\n",
      "test_test\n",
      "test mean loss=88353.25390625\n",
      "fin save.\n",
      "epoch 4508\n",
      "test_train\n",
      "train mean loss=62053.608072916664\n",
      "test_test\n",
      "test mean loss=88276.15625\n",
      "fin save.\n",
      "epoch 4509\n",
      "test_train\n",
      "train mean loss=62266.437760416666\n",
      "test_test\n",
      "test mean loss=88314.0390625\n",
      "fin save.\n",
      "epoch 4510\n",
      "test_train\n",
      "train mean loss=61822.00859375\n",
      "test_test\n",
      "test mean loss=88653.1171875\n",
      "fin save.\n",
      "epoch 4511\n",
      "test_train\n",
      "train mean loss=61218.265885416666\n",
      "test_test\n",
      "test mean loss=88422.8515625\n",
      "fin save.\n",
      "epoch 4512\n",
      "test_train\n",
      "train mean loss=61242.479296875\n",
      "test_test\n",
      "test mean loss=88588.52734375\n",
      "fin save.\n",
      "epoch 4513\n",
      "test_train\n",
      "train mean loss=61636.59973958333\n",
      "test_test\n",
      "test mean loss=88733.19140625\n",
      "fin save.\n",
      "epoch 4514\n",
      "test_train\n",
      "train mean loss=62227.47083333333\n",
      "test_test\n",
      "test mean loss=88499.19140625\n",
      "fin save.\n",
      "epoch 4515\n",
      "test_train\n",
      "train mean loss=62171.21979166667\n",
      "test_test\n",
      "test mean loss=88395.0234375\n",
      "fin save.\n",
      "epoch 4516\n",
      "test_train\n",
      "train mean loss=61500.11875\n",
      "test_test\n",
      "test mean loss=88379.453125\n",
      "fin save.\n",
      "epoch 4517\n",
      "test_train\n",
      "train mean loss=61491.81640625\n",
      "test_test\n",
      "test mean loss=88356.1015625\n",
      "fin save.\n",
      "epoch 4518\n",
      "test_train\n",
      "train mean loss=61254.69765625\n",
      "test_test\n",
      "test mean loss=88514.03515625\n",
      "fin save.\n",
      "epoch 4519\n",
      "test_train\n",
      "train mean loss=61655.803125\n",
      "test_test\n",
      "test mean loss=88317.78515625\n",
      "fin save.\n",
      "epoch 4520\n",
      "test_train\n",
      "train mean loss=62805.503255208336\n",
      "test_test\n",
      "test mean loss=88585.54296875\n",
      "fin save.\n",
      "epoch 4521\n",
      "test_train\n",
      "train mean loss=62358.1390625\n",
      "test_test\n",
      "test mean loss=88222.1328125\n",
      "fin save.\n",
      "epoch 4522\n",
      "test_train\n",
      "train mean loss=61545.59453125\n",
      "test_test\n",
      "test mean loss=88227.828125\n",
      "fin save.\n",
      "epoch 4523\n",
      "test_train\n",
      "train mean loss=62737.34036458333\n",
      "test_test\n",
      "test mean loss=88278.7421875\n",
      "fin save.\n",
      "epoch 4524\n",
      "test_train\n",
      "train mean loss=61416.72604166667\n",
      "test_test\n",
      "test mean loss=87858.6640625\n",
      "fin save.\n",
      "epoch 4525\n",
      "test_train\n",
      "train mean loss=61749.5625\n",
      "test_test\n",
      "test mean loss=87857.90625\n",
      "fin save.\n",
      "epoch 4526\n",
      "test_train\n",
      "train mean loss=61729.13619791667\n",
      "test_test\n",
      "test mean loss=88096.24609375\n",
      "fin save.\n",
      "epoch 4527\n",
      "test_train\n",
      "train mean loss=61881.43515625\n",
      "test_test\n",
      "test mean loss=88243.26171875\n",
      "fin save.\n",
      "epoch 4528\n",
      "test_train\n",
      "train mean loss=62398.42083333333\n",
      "test_test\n",
      "test mean loss=88280.5234375\n",
      "fin save.\n",
      "epoch 4529\n",
      "test_train\n",
      "train mean loss=61965.30416666667\n",
      "test_test\n",
      "test mean loss=87967.8359375\n",
      "fin save.\n",
      "epoch 4530\n",
      "test_train\n",
      "train mean loss=63041.54505208333\n",
      "test_test\n",
      "test mean loss=88312.1015625\n",
      "fin save.\n",
      "epoch 4531\n",
      "test_train\n",
      "train mean loss=62031.97278645833\n",
      "test_test\n",
      "test mean loss=88146.07421875\n",
      "fin save.\n",
      "epoch 4532\n",
      "test_train\n",
      "train mean loss=61119.56588541667\n",
      "test_test\n",
      "test mean loss=87765.81640625\n",
      "fin save.\n",
      "epoch 4533\n",
      "test_train\n",
      "train mean loss=61873.50494791667\n",
      "test_test\n",
      "test mean loss=87819.78515625\n",
      "fin save.\n",
      "epoch 4534\n",
      "test_train\n",
      "train mean loss=61103.74505208333\n",
      "test_test\n",
      "test mean loss=87753.6171875\n",
      "fin save.\n",
      "epoch 4535\n",
      "test_train\n",
      "train mean loss=61669.86901041667\n",
      "test_test\n",
      "test mean loss=87968.15625\n",
      "fin save.\n",
      "epoch 4536\n",
      "test_train\n",
      "train mean loss=62201.370442708336\n",
      "test_test\n",
      "test mean loss=88066.09765625\n",
      "fin save.\n",
      "epoch 4537\n",
      "test_train\n",
      "train mean loss=62274.129166666666\n",
      "test_test\n",
      "test mean loss=88219.6875\n",
      "fin save.\n",
      "epoch 4538\n",
      "test_train\n",
      "train mean loss=61850.5609375\n",
      "test_test\n",
      "test mean loss=87932.515625\n",
      "fin save.\n",
      "epoch 4539\n",
      "test_train\n",
      "train mean loss=61346.73671875\n",
      "test_test\n",
      "test mean loss=87975.53515625\n",
      "fin save.\n",
      "epoch 4540\n",
      "test_train\n",
      "train mean loss=62670.887890625\n",
      "test_test\n",
      "test mean loss=88010.6953125\n",
      "fin save.\n",
      "epoch 4541\n",
      "test_train\n",
      "train mean loss=61098.14765625\n",
      "test_test\n",
      "test mean loss=87899.84765625\n",
      "fin save.\n",
      "epoch 4542\n",
      "test_train\n",
      "train mean loss=62261.87421875\n",
      "test_test\n",
      "test mean loss=88222.06640625\n",
      "fin save.\n",
      "epoch 4543\n",
      "test_train\n",
      "train mean loss=61589.34140625\n",
      "test_test\n",
      "test mean loss=88179.27734375\n",
      "fin save.\n",
      "epoch 4544\n",
      "test_train\n",
      "train mean loss=62537.304427083334\n",
      "test_test\n",
      "test mean loss=88181.6015625\n",
      "fin save.\n",
      "epoch 4545\n",
      "test_train\n",
      "train mean loss=61428.72278645833\n",
      "test_test\n",
      "test mean loss=88198.64453125\n",
      "fin save.\n",
      "epoch 4546\n",
      "test_train\n",
      "train mean loss=62332.80364583333\n",
      "test_test\n",
      "test mean loss=87926.14453125\n",
      "fin save.\n",
      "epoch 4547\n",
      "test_train\n",
      "train mean loss=61709.56484375\n",
      "test_test\n",
      "test mean loss=88144.30078125\n",
      "fin save.\n",
      "epoch 4548\n",
      "test_train\n",
      "train mean loss=61708.59518229167\n",
      "test_test\n",
      "test mean loss=87892.0703125\n",
      "fin save.\n",
      "epoch 4549\n",
      "test_train\n",
      "train mean loss=61711.793229166666\n",
      "test_test\n",
      "test mean loss=87855.2734375\n",
      "fin save.\n",
      "epoch 4550\n",
      "test_train\n",
      "train mean loss=62363.1796875\n",
      "test_test\n",
      "test mean loss=87806.25390625\n",
      "fin save.\n",
      "epoch 4551\n",
      "test_train\n",
      "train mean loss=61991.6234375\n",
      "test_test\n",
      "test mean loss=87873.14453125\n",
      "fin save.\n",
      "epoch 4552\n",
      "test_train\n",
      "train mean loss=61987.81796875\n",
      "test_test\n",
      "test mean loss=88031.33984375\n",
      "fin save.\n",
      "epoch 4553\n",
      "test_train\n",
      "train mean loss=62221.87447916667\n",
      "test_test\n",
      "test mean loss=88164.5390625\n",
      "fin save.\n",
      "epoch 4554\n",
      "test_train\n",
      "train mean loss=61635.89270833333\n",
      "test_test\n",
      "test mean loss=88273.72265625\n",
      "fin save.\n",
      "epoch 4555\n",
      "test_train\n",
      "train mean loss=61055.8671875\n",
      "test_test\n",
      "test mean loss=88011.88671875\n",
      "fin save.\n",
      "epoch 4556\n",
      "test_train\n",
      "train mean loss=61257.49466145833\n",
      "test_test\n",
      "test mean loss=88314.4296875\n",
      "fin save.\n",
      "epoch 4557\n",
      "test_train\n",
      "train mean loss=62506.002213541666\n",
      "test_test\n",
      "test mean loss=88221.92578125\n",
      "fin save.\n",
      "epoch 4558\n",
      "test_train\n",
      "train mean loss=62040.32734375\n",
      "test_test\n",
      "test mean loss=88164.89453125\n",
      "fin save.\n",
      "epoch 4559\n",
      "test_train\n",
      "train mean loss=62265.229817708336\n",
      "test_test\n",
      "test mean loss=88127.39453125\n",
      "fin save.\n",
      "epoch 4560\n",
      "test_train\n",
      "train mean loss=62994.75234375\n",
      "test_test\n",
      "test mean loss=88315.45703125\n",
      "fin save.\n",
      "epoch 4561\n",
      "test_train\n",
      "train mean loss=62087.723046875\n",
      "test_test\n",
      "test mean loss=88105.265625\n",
      "fin save.\n",
      "epoch 4562\n",
      "test_train\n",
      "train mean loss=61808.978515625\n",
      "test_test\n",
      "test mean loss=88643.51171875\n",
      "fin save.\n",
      "epoch 4563\n",
      "test_train\n",
      "train mean loss=62192.636458333334\n",
      "test_test\n",
      "test mean loss=88475.42578125\n",
      "fin save.\n",
      "epoch 4564\n",
      "test_train\n",
      "train mean loss=62162.26614583333\n",
      "test_test\n",
      "test mean loss=88696.7109375\n",
      "fin save.\n",
      "epoch 4565\n",
      "test_train\n",
      "train mean loss=62037.74505208333\n",
      "test_test\n",
      "test mean loss=88685.86328125\n",
      "fin save.\n",
      "epoch 4566\n",
      "test_train\n",
      "train mean loss=62840.082291666666\n",
      "test_test\n",
      "test mean loss=88527.8046875\n",
      "fin save.\n",
      "epoch 4567\n",
      "test_train\n",
      "train mean loss=61108.58893229167\n",
      "test_test\n",
      "test mean loss=88708.00390625\n",
      "fin save.\n",
      "epoch 4568\n",
      "test_train\n",
      "train mean loss=62227.419270833336\n",
      "test_test\n",
      "test mean loss=88483.3046875\n",
      "fin save.\n",
      "epoch 4569\n",
      "test_train\n",
      "train mean loss=62226.17096354167\n",
      "test_test\n",
      "test mean loss=88444.8515625\n",
      "fin save.\n",
      "epoch 4570\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=62096.91263020833\n",
      "test_test\n",
      "test mean loss=88459.2109375\n",
      "fin save.\n",
      "epoch 4571\n",
      "test_train\n",
      "train mean loss=61840.98385416667\n",
      "test_test\n",
      "test mean loss=88500.09375\n",
      "fin save.\n",
      "epoch 4572\n",
      "test_train\n",
      "train mean loss=62317.481770833336\n",
      "test_test\n",
      "test mean loss=88496.765625\n",
      "fin save.\n",
      "epoch 4573\n",
      "test_train\n",
      "train mean loss=62184.56171875\n",
      "test_test\n",
      "test mean loss=88518.58203125\n",
      "fin save.\n",
      "epoch 4574\n",
      "test_train\n",
      "train mean loss=61713.00052083333\n",
      "test_test\n",
      "test mean loss=88545.9921875\n",
      "fin save.\n",
      "epoch 4575\n",
      "test_train\n",
      "train mean loss=62982.14986979167\n",
      "test_test\n",
      "test mean loss=88535.2890625\n",
      "fin save.\n",
      "epoch 4576\n",
      "test_train\n",
      "train mean loss=61577.664322916666\n",
      "test_test\n",
      "test mean loss=88611.68359375\n",
      "fin save.\n",
      "epoch 4577\n",
      "test_train\n",
      "train mean loss=62057.190625\n",
      "test_test\n",
      "test mean loss=89110.65234375\n",
      "fin save.\n",
      "epoch 4578\n",
      "test_train\n",
      "train mean loss=62103.160416666666\n",
      "test_test\n",
      "test mean loss=89036.41796875\n",
      "fin save.\n",
      "epoch 4579\n",
      "test_train\n",
      "train mean loss=61374.590625\n",
      "test_test\n",
      "test mean loss=88897.5625\n",
      "fin save.\n",
      "epoch 4580\n",
      "test_train\n",
      "train mean loss=61459.89140625\n",
      "test_test\n",
      "test mean loss=88938.0546875\n",
      "fin save.\n",
      "epoch 4581\n",
      "test_train\n",
      "train mean loss=62334.2515625\n",
      "test_test\n",
      "test mean loss=88883.27734375\n",
      "fin save.\n",
      "epoch 4582\n",
      "test_train\n",
      "train mean loss=61824.370833333334\n",
      "test_test\n",
      "test mean loss=89018.64453125\n",
      "fin save.\n",
      "epoch 4583\n",
      "test_train\n",
      "train mean loss=61716.624609375\n",
      "test_test\n",
      "test mean loss=88997.796875\n",
      "fin save.\n",
      "epoch 4584\n",
      "test_train\n",
      "train mean loss=61339.746354166666\n",
      "test_test\n",
      "test mean loss=89188.8984375\n",
      "fin save.\n",
      "epoch 4585\n",
      "test_train\n",
      "train mean loss=61508.94348958333\n",
      "test_test\n",
      "test mean loss=89087.8671875\n",
      "fin save.\n",
      "epoch 4586\n",
      "test_train\n",
      "train mean loss=61762.201822916664\n",
      "test_test\n",
      "test mean loss=89532.046875\n",
      "fin save.\n",
      "epoch 4587\n",
      "test_train\n",
      "train mean loss=61556.1671875\n",
      "test_test\n",
      "test mean loss=89497.3203125\n",
      "fin save.\n",
      "epoch 4588\n",
      "test_train\n",
      "train mean loss=61600.303125\n",
      "test_test\n",
      "test mean loss=89563.81640625\n",
      "fin save.\n",
      "epoch 4589\n",
      "test_train\n",
      "train mean loss=62449.594140625\n",
      "test_test\n",
      "test mean loss=89547.41796875\n",
      "fin save.\n",
      "epoch 4590\n",
      "test_train\n",
      "train mean loss=62265.43020833333\n",
      "test_test\n",
      "test mean loss=89624.93359375\n",
      "fin save.\n",
      "epoch 4591\n",
      "test_train\n",
      "train mean loss=61976.79973958333\n",
      "test_test\n",
      "test mean loss=89500.99609375\n",
      "fin save.\n",
      "epoch 4592\n",
      "test_train\n",
      "train mean loss=61469.84088541667\n",
      "test_test\n",
      "test mean loss=89264.17578125\n",
      "fin save.\n",
      "epoch 4593\n",
      "test_train\n",
      "train mean loss=62795.364973958334\n",
      "test_test\n",
      "test mean loss=89165.5703125\n",
      "fin save.\n",
      "epoch 4594\n",
      "test_train\n",
      "train mean loss=61723.03828125\n",
      "test_test\n",
      "test mean loss=88610.92578125\n",
      "fin save.\n",
      "epoch 4595\n",
      "test_train\n",
      "train mean loss=63203.77057291667\n",
      "test_test\n",
      "test mean loss=88659.91796875\n",
      "fin save.\n",
      "epoch 4596\n",
      "test_train\n",
      "train mean loss=62292.77747395833\n",
      "test_test\n",
      "test mean loss=88699.44140625\n",
      "fin save.\n",
      "epoch 4597\n",
      "test_train\n",
      "train mean loss=61797.59283854167\n",
      "test_test\n",
      "test mean loss=88723.79296875\n",
      "fin save.\n",
      "epoch 4598\n",
      "test_train\n",
      "train mean loss=60619.61119791667\n",
      "test_test\n",
      "test mean loss=88815.546875\n",
      "fin save.\n",
      "epoch 4599\n",
      "test_train\n",
      "train mean loss=61744.719921875\n",
      "test_test\n",
      "test mean loss=88666.12109375\n",
      "fin save.\n",
      "epoch 4600\n",
      "test_train\n",
      "train mean loss=61995.43828125\n",
      "test_test\n",
      "test mean loss=88627.0234375\n",
      "fin save.\n",
      "epoch 4601\n",
      "test_train\n",
      "train mean loss=61921.08880208333\n",
      "test_test\n",
      "test mean loss=88490.11328125\n",
      "fin save.\n",
      "epoch 4602\n",
      "test_train\n",
      "train mean loss=61759.990625\n",
      "test_test\n",
      "test mean loss=88447.3515625\n",
      "fin save.\n",
      "epoch 4603\n",
      "test_train\n",
      "train mean loss=62239.28619791667\n",
      "test_test\n",
      "test mean loss=88485.0234375\n",
      "fin save.\n",
      "epoch 4604\n",
      "test_train\n",
      "train mean loss=62069.5546875\n",
      "test_test\n",
      "test mean loss=88450.06640625\n",
      "fin save.\n",
      "epoch 4605\n",
      "test_train\n",
      "train mean loss=62455.0796875\n",
      "test_test\n",
      "test mean loss=88316.640625\n",
      "fin save.\n",
      "epoch 4606\n",
      "test_train\n",
      "train mean loss=61888.126692708334\n",
      "test_test\n",
      "test mean loss=88480.1015625\n",
      "fin save.\n",
      "epoch 4607\n",
      "test_train\n",
      "train mean loss=62201.704296875\n",
      "test_test\n",
      "test mean loss=88488.28515625\n",
      "fin save.\n",
      "epoch 4608\n",
      "test_train\n",
      "train mean loss=60408.175390625\n",
      "test_test\n",
      "test mean loss=88528.1953125\n",
      "fin save.\n",
      "epoch 4609\n",
      "test_train\n",
      "train mean loss=62123.36015625\n",
      "test_test\n",
      "test mean loss=88502.9921875\n",
      "fin save.\n",
      "epoch 4610\n",
      "test_train\n",
      "train mean loss=61459.84166666667\n",
      "test_test\n",
      "test mean loss=88380.390625\n",
      "fin save.\n",
      "epoch 4611\n",
      "test_train\n",
      "train mean loss=62176.110677083336\n",
      "test_test\n",
      "test mean loss=88404.36328125\n",
      "fin save.\n",
      "epoch 4612\n",
      "test_train\n",
      "train mean loss=61592.144270833334\n",
      "test_test\n",
      "test mean loss=88382.73046875\n",
      "fin save.\n",
      "epoch 4613\n",
      "test_train\n",
      "train mean loss=62695.320572916666\n",
      "test_test\n",
      "test mean loss=88489.47265625\n",
      "fin save.\n",
      "epoch 4614\n",
      "test_train\n",
      "train mean loss=61826.082291666666\n",
      "test_test\n",
      "test mean loss=88660.2421875\n",
      "fin save.\n",
      "epoch 4615\n",
      "test_train\n",
      "train mean loss=60988.5453125\n",
      "test_test\n",
      "test mean loss=88676.8125\n",
      "fin save.\n",
      "epoch 4616\n",
      "test_train\n",
      "train mean loss=62179.13359375\n",
      "test_test\n",
      "test mean loss=88696.17578125\n",
      "fin save.\n",
      "epoch 4617\n",
      "test_train\n",
      "train mean loss=61396.182291666664\n",
      "test_test\n",
      "test mean loss=88684.65234375\n",
      "fin save.\n",
      "epoch 4618\n",
      "test_train\n",
      "train mean loss=63127.16015625\n",
      "test_test\n",
      "test mean loss=88753.2734375\n",
      "fin save.\n",
      "epoch 4619\n",
      "test_train\n",
      "train mean loss=62409.2828125\n",
      "test_test\n",
      "test mean loss=88948.16796875\n",
      "fin save.\n",
      "epoch 4620\n",
      "test_train\n",
      "train mean loss=62345.88203125\n",
      "test_test\n",
      "test mean loss=88518.06640625\n",
      "fin save.\n",
      "epoch 4621\n",
      "test_train\n",
      "train mean loss=60501.146875\n",
      "test_test\n",
      "test mean loss=88797.51953125\n",
      "fin save.\n",
      "epoch 4622\n",
      "test_train\n",
      "train mean loss=62908.765234375\n",
      "test_test\n",
      "test mean loss=88656.75\n",
      "fin save.\n",
      "epoch 4623\n",
      "test_train\n",
      "train mean loss=61832.9953125\n",
      "test_test\n",
      "test mean loss=88502.82421875\n",
      "fin save.\n",
      "epoch 4624\n",
      "test_train\n",
      "train mean loss=61787.87786458333\n",
      "test_test\n",
      "test mean loss=88674.7421875\n",
      "fin save.\n",
      "epoch 4625\n",
      "test_train\n",
      "train mean loss=61510.21015625\n",
      "test_test\n",
      "test mean loss=88783.2734375\n",
      "fin save.\n",
      "epoch 4626\n",
      "test_train\n",
      "train mean loss=62313.38854166667\n",
      "test_test\n",
      "test mean loss=88639.61328125\n",
      "fin save.\n",
      "epoch 4627\n",
      "test_train\n",
      "train mean loss=62009.06015625\n",
      "test_test\n",
      "test mean loss=88585.703125\n",
      "fin save.\n",
      "epoch 4628\n",
      "test_train\n",
      "train mean loss=62162.5109375\n",
      "test_test\n",
      "test mean loss=88475.73046875\n",
      "fin save.\n",
      "epoch 4629\n",
      "test_train\n",
      "train mean loss=62071.15130208333\n",
      "test_test\n",
      "test mean loss=88604.21875\n",
      "fin save.\n",
      "epoch 4630\n",
      "test_train\n",
      "train mean loss=61384.544921875\n",
      "test_test\n",
      "test mean loss=88479.23828125\n",
      "fin save.\n",
      "epoch 4631\n",
      "test_train\n",
      "train mean loss=63254.71041666667\n",
      "test_test\n",
      "test mean loss=88492.75\n",
      "fin save.\n",
      "epoch 4632\n",
      "test_train\n",
      "train mean loss=61818.7453125\n",
      "test_test\n",
      "test mean loss=88513.8046875\n",
      "fin save.\n",
      "epoch 4633\n",
      "test_train\n",
      "train mean loss=62462.13424479167\n",
      "test_test\n",
      "test mean loss=88358.6875\n",
      "fin save.\n",
      "epoch 4634\n",
      "test_train\n",
      "train mean loss=61876.62317708333\n",
      "test_test\n",
      "test mean loss=88084.03515625\n",
      "fin save.\n",
      "epoch 4635\n",
      "test_train\n",
      "train mean loss=62021.836197916666\n",
      "test_test\n",
      "test mean loss=88288.76171875\n",
      "fin save.\n",
      "epoch 4636\n",
      "test_train\n",
      "train mean loss=62565.51276041667\n",
      "test_test\n",
      "test mean loss=88543.87109375\n",
      "fin save.\n",
      "epoch 4637\n",
      "test_train\n",
      "train mean loss=61485.988671875\n",
      "test_test\n",
      "test mean loss=88387.640625\n",
      "fin save.\n",
      "epoch 4638\n",
      "test_train\n",
      "train mean loss=61523.99270833333\n",
      "test_test\n",
      "test mean loss=88044.6171875\n",
      "fin save.\n",
      "epoch 4639\n",
      "test_train\n",
      "train mean loss=61400.88046875\n",
      "test_test\n",
      "test mean loss=87979.70703125\n",
      "fin save.\n",
      "epoch 4640\n",
      "test_train\n",
      "train mean loss=61641.2265625\n",
      "test_test\n",
      "test mean loss=87984.0390625\n",
      "fin save.\n",
      "epoch 4641\n",
      "test_train\n",
      "train mean loss=60851.07916666667\n",
      "test_test\n",
      "test mean loss=87853.40234375\n",
      "fin save.\n",
      "epoch 4642\n",
      "test_train\n",
      "train mean loss=62294.64440104167\n",
      "test_test\n",
      "test mean loss=87849.9921875\n",
      "fin save.\n",
      "epoch 4643\n",
      "test_train\n",
      "train mean loss=61835.169270833336\n",
      "test_test\n",
      "test mean loss=87997.8671875\n",
      "fin save.\n",
      "epoch 4644\n",
      "test_train\n",
      "train mean loss=61955.909895833334\n",
      "test_test\n",
      "test mean loss=87858.19140625\n",
      "fin save.\n",
      "epoch 4645\n",
      "test_train\n",
      "train mean loss=61524.865885416664\n",
      "test_test\n",
      "test mean loss=87938.34375\n",
      "fin save.\n",
      "epoch 4646\n",
      "test_train\n",
      "train mean loss=62165.409505208336\n",
      "test_test\n",
      "test mean loss=87820.265625\n",
      "fin save.\n",
      "epoch 4647\n",
      "test_train\n",
      "train mean loss=61684.0296875\n",
      "test_test\n",
      "test mean loss=87934.08984375\n",
      "fin save.\n",
      "epoch 4648\n",
      "test_train\n",
      "train mean loss=61569.27942708333\n",
      "test_test\n",
      "test mean loss=87919.9921875\n",
      "fin save.\n",
      "epoch 4649\n",
      "test_train\n",
      "train mean loss=61738.43645833333\n",
      "test_test\n",
      "test mean loss=87889.53515625\n",
      "fin save.\n",
      "epoch 4650\n",
      "test_train\n",
      "train mean loss=62257.649739583336\n",
      "test_test\n",
      "test mean loss=87830.5390625\n",
      "fin save.\n",
      "epoch 4651\n",
      "test_train\n",
      "train mean loss=61886.91119791667\n",
      "test_test\n",
      "test mean loss=87957.14453125\n",
      "fin save.\n",
      "epoch 4652\n",
      "test_train\n",
      "train mean loss=62027.3953125\n",
      "test_test\n",
      "test mean loss=87595.578125\n",
      "fin save.\n",
      "epoch 4653\n",
      "test_train\n",
      "train mean loss=62348.103125\n",
      "test_test\n",
      "test mean loss=87737.22265625\n",
      "fin save.\n",
      "epoch 4654\n",
      "test_train\n",
      "train mean loss=61950.03463541667\n",
      "test_test\n",
      "test mean loss=87653.375\n",
      "fin save.\n",
      "epoch 4655\n",
      "test_train\n",
      "train mean loss=61701.78723958333\n",
      "test_test\n",
      "test mean loss=88035.875\n",
      "fin save.\n",
      "epoch 4656\n",
      "test_train\n",
      "train mean loss=61102.395833333336\n",
      "test_test\n",
      "test mean loss=87926.85546875\n",
      "fin save.\n",
      "epoch 4657\n",
      "test_train\n",
      "train mean loss=61590.076822916664\n",
      "test_test\n",
      "test mean loss=88023.83984375\n",
      "fin save.\n",
      "epoch 4658\n",
      "test_train\n",
      "train mean loss=61903.613541666666\n",
      "test_test\n",
      "test mean loss=88227.58984375\n",
      "fin save.\n",
      "epoch 4659\n",
      "test_train\n",
      "train mean loss=62750.58697916667\n",
      "test_test\n",
      "test mean loss=88291.36328125\n",
      "fin save.\n",
      "epoch 4660\n",
      "test_train\n",
      "train mean loss=61834.49166666667\n",
      "test_test\n",
      "test mean loss=88333.73046875\n",
      "fin save.\n",
      "epoch 4661\n",
      "test_train\n",
      "train mean loss=62351.06067708333\n",
      "test_test\n",
      "test mean loss=88042.31640625\n",
      "fin save.\n",
      "epoch 4662\n",
      "test_train\n",
      "train mean loss=62260.552994791666\n",
      "test_test\n",
      "test mean loss=88372.8671875\n",
      "fin save.\n",
      "epoch 4663\n",
      "test_train\n",
      "train mean loss=61997.49427083333\n",
      "test_test\n",
      "test mean loss=88287.23828125\n",
      "fin save.\n",
      "epoch 4664\n",
      "test_train\n",
      "train mean loss=62219.59427083333\n",
      "test_test\n",
      "test mean loss=88181.48046875\n",
      "fin save.\n",
      "epoch 4665\n",
      "test_train\n",
      "train mean loss=62079.10260416667\n",
      "test_test\n",
      "test mean loss=88248.80078125\n",
      "fin save.\n",
      "epoch 4666\n",
      "test_train\n",
      "train mean loss=61829.23151041667\n",
      "test_test\n",
      "test mean loss=88393.3359375\n",
      "fin save.\n",
      "epoch 4667\n",
      "test_train\n",
      "train mean loss=62880.796875\n",
      "test_test\n",
      "test mean loss=88313.97265625\n",
      "fin save.\n",
      "epoch 4668\n",
      "test_train\n",
      "train mean loss=61568.471354166664\n",
      "test_test\n",
      "test mean loss=88296.50390625\n",
      "fin save.\n",
      "epoch 4669\n",
      "test_train\n",
      "train mean loss=62322.69453125\n",
      "test_test\n",
      "test mean loss=88444.984375\n",
      "fin save.\n",
      "epoch 4670\n",
      "test_train\n",
      "train mean loss=62968.93020833333\n",
      "test_test\n",
      "test mean loss=88380.078125\n",
      "fin save.\n",
      "epoch 4671\n",
      "test_train\n",
      "train mean loss=62462.24895833333\n",
      "test_test\n",
      "test mean loss=88317.3046875\n",
      "fin save.\n",
      "epoch 4672\n",
      "test_train\n",
      "train mean loss=61826.151041666664\n",
      "test_test\n",
      "test mean loss=88363.42578125\n",
      "fin save.\n",
      "epoch 4673\n",
      "test_train\n",
      "train mean loss=62576.83880208333\n",
      "test_test\n",
      "test mean loss=88339.96484375\n",
      "fin save.\n",
      "epoch 4674\n",
      "test_train\n",
      "train mean loss=61593.625390625\n",
      "test_test\n",
      "test mean loss=88313.23046875\n",
      "fin save.\n",
      "epoch 4675\n",
      "test_train\n",
      "train mean loss=62204.228125\n",
      "test_test\n",
      "test mean loss=88294.8671875\n",
      "fin save.\n",
      "epoch 4676\n",
      "test_train\n",
      "train mean loss=62820.99947916667\n",
      "test_test\n",
      "test mean loss=88359.84375\n",
      "fin save.\n",
      "epoch 4677\n",
      "test_train\n",
      "train mean loss=62086.77721354167\n",
      "test_test\n",
      "test mean loss=88219.48046875\n",
      "fin save.\n",
      "epoch 4678\n",
      "test_train\n",
      "train mean loss=62170.03046875\n",
      "test_test\n",
      "test mean loss=88039.140625\n",
      "fin save.\n",
      "epoch 4679\n",
      "test_train\n",
      "train mean loss=61793.99700520833\n",
      "test_test\n",
      "test mean loss=88217.30859375\n",
      "fin save.\n",
      "epoch 4680\n",
      "test_train\n",
      "train mean loss=62058.68502604167\n",
      "test_test\n",
      "test mean loss=88098.05859375\n",
      "fin save.\n",
      "epoch 4681\n",
      "test_train\n",
      "train mean loss=62023.32135416667\n",
      "test_test\n",
      "test mean loss=88091.78515625\n",
      "fin save.\n",
      "epoch 4682\n",
      "test_train\n",
      "train mean loss=62394.39635416667\n",
      "test_test\n",
      "test mean loss=88124.71875\n",
      "fin save.\n",
      "epoch 4683\n",
      "test_train\n",
      "train mean loss=62413.438802083336\n",
      "test_test\n",
      "test mean loss=88136.10546875\n",
      "fin save.\n",
      "epoch 4684\n",
      "test_train\n",
      "train mean loss=61531.872786458334\n",
      "test_test\n",
      "test mean loss=87873.05859375\n",
      "fin save.\n",
      "epoch 4685\n",
      "test_train\n",
      "train mean loss=62170.94153645833\n",
      "test_test\n",
      "test mean loss=88167.1796875\n",
      "fin save.\n",
      "epoch 4686\n",
      "test_train\n",
      "train mean loss=61645.460677083334\n",
      "test_test\n",
      "test mean loss=87769.18359375\n",
      "fin save.\n",
      "epoch 4687\n",
      "test_train\n",
      "train mean loss=61016.33515625\n",
      "test_test\n",
      "test mean loss=87689.2578125\n",
      "fin save.\n",
      "epoch 4688\n",
      "test_train\n",
      "train mean loss=62311.96536458333\n",
      "test_test\n",
      "test mean loss=87714.37109375\n",
      "fin save.\n",
      "epoch 4689\n",
      "test_train\n",
      "train mean loss=62256.31302083333\n",
      "test_test\n",
      "test mean loss=87647.6484375\n",
      "fin save.\n",
      "epoch 4690\n",
      "test_train\n",
      "train mean loss=62142.259375\n",
      "test_test\n",
      "test mean loss=87530.2890625\n",
      "fin save.\n",
      "epoch 4691\n",
      "test_train\n",
      "train mean loss=61942.61510416667\n",
      "test_test\n",
      "test mean loss=87758.5859375\n",
      "fin save.\n",
      "epoch 4692\n",
      "test_train\n",
      "train mean loss=61769.09192708333\n",
      "test_test\n",
      "test mean loss=87547.61328125\n",
      "fin save.\n",
      "epoch 4693\n",
      "test_train\n",
      "train mean loss=62248.980208333334\n",
      "test_test\n",
      "test mean loss=87735.734375\n",
      "fin save.\n",
      "epoch 4694\n",
      "test_train\n",
      "train mean loss=61261.12942708333\n",
      "test_test\n",
      "test mean loss=87701.90234375\n",
      "fin save.\n",
      "epoch 4695\n",
      "test_train\n",
      "train mean loss=62275.25234375\n",
      "test_test\n",
      "test mean loss=87799.6328125\n",
      "fin save.\n",
      "epoch 4696\n",
      "test_train\n",
      "train mean loss=62127.264322916664\n",
      "test_test\n",
      "test mean loss=87674.85546875\n",
      "fin save.\n",
      "epoch 4697\n",
      "test_train\n",
      "train mean loss=61682.38046875\n",
      "test_test\n",
      "test mean loss=87822.4453125\n",
      "fin save.\n",
      "epoch 4698\n",
      "test_train\n",
      "train mean loss=61560.31328125\n",
      "test_test\n",
      "test mean loss=87737.765625\n",
      "fin save.\n",
      "epoch 4699\n",
      "test_train\n",
      "train mean loss=62123.82421875\n",
      "test_test\n",
      "test mean loss=87942.4375\n",
      "fin save.\n",
      "epoch 4700\n",
      "test_train\n",
      "train mean loss=62797.430989583336\n",
      "test_test\n",
      "test mean loss=87765.66796875\n",
      "fin save.\n",
      "epoch 4701\n",
      "test_train\n",
      "train mean loss=62038.86015625\n",
      "test_test\n",
      "test mean loss=87814.09765625\n",
      "fin save.\n",
      "epoch 4702\n",
      "test_train\n",
      "train mean loss=61171.74947916667\n",
      "test_test\n",
      "test mean loss=88151.03515625\n",
      "fin save.\n",
      "epoch 4703\n",
      "test_train\n",
      "train mean loss=61383.072916666664\n",
      "test_test\n",
      "test mean loss=88252.87890625\n",
      "fin save.\n",
      "epoch 4704\n",
      "test_train\n",
      "train mean loss=61568.502604166664\n",
      "test_test\n",
      "test mean loss=88198.6640625\n",
      "fin save.\n",
      "epoch 4705\n",
      "test_train\n",
      "train mean loss=63228.36041666667\n",
      "test_test\n",
      "test mean loss=88065.53515625\n",
      "fin save.\n",
      "epoch 4706\n",
      "test_train\n",
      "train mean loss=62918.01015625\n",
      "test_test\n",
      "test mean loss=87939.50390625\n",
      "fin save.\n",
      "epoch 4707\n",
      "test_train\n",
      "train mean loss=61604.03020833333\n",
      "test_test\n",
      "test mean loss=87983.25390625\n",
      "fin save.\n",
      "epoch 4708\n",
      "test_train\n",
      "train mean loss=62156.939713541666\n",
      "test_test\n",
      "test mean loss=88069.8203125\n",
      "fin save.\n",
      "epoch 4709\n",
      "test_train\n",
      "train mean loss=62689.54739583333\n",
      "test_test\n",
      "test mean loss=87920.57421875\n",
      "fin save.\n",
      "epoch 4710\n",
      "test_train\n",
      "train mean loss=62793.9015625\n",
      "test_test\n",
      "test mean loss=87900.73828125\n",
      "fin save.\n",
      "epoch 4711\n",
      "test_train\n",
      "train mean loss=62310.14635416667\n",
      "test_test\n",
      "test mean loss=87943.69140625\n",
      "fin save.\n",
      "epoch 4712\n",
      "test_train\n",
      "train mean loss=61853.94127604167\n",
      "test_test\n",
      "test mean loss=87744.01953125\n",
      "fin save.\n",
      "epoch 4713\n",
      "test_train\n",
      "train mean loss=61220.77135416667\n",
      "test_test\n",
      "test mean loss=87825.5078125\n",
      "fin save.\n",
      "epoch 4714\n",
      "test_train\n",
      "train mean loss=62000.661458333336\n",
      "test_test\n",
      "test mean loss=87759.796875\n",
      "fin save.\n",
      "epoch 4715\n",
      "test_train\n",
      "train mean loss=62092.25104166667\n",
      "test_test\n",
      "test mean loss=87720.96484375\n",
      "fin save.\n",
      "epoch 4716\n",
      "test_train\n",
      "train mean loss=62280.261458333334\n",
      "test_test\n",
      "test mean loss=87998.06640625\n",
      "fin save.\n",
      "epoch 4717\n",
      "test_train\n",
      "train mean loss=62342.71197916667\n",
      "test_test\n",
      "test mean loss=87925.09375\n",
      "fin save.\n",
      "epoch 4718\n",
      "test_train\n",
      "train mean loss=62321.33255208333\n",
      "test_test\n",
      "test mean loss=87759.5625\n",
      "fin save.\n",
      "epoch 4719\n",
      "test_train\n",
      "train mean loss=61922.902734375\n",
      "test_test\n",
      "test mean loss=87762.1953125\n",
      "fin save.\n",
      "epoch 4720\n",
      "test_train\n",
      "train mean loss=62296.35924479167\n",
      "test_test\n",
      "test mean loss=87868.35546875\n",
      "fin save.\n",
      "epoch 4721\n",
      "test_train\n",
      "train mean loss=62317.890364583334\n",
      "test_test\n",
      "test mean loss=87905.734375\n",
      "fin save.\n",
      "epoch 4722\n",
      "test_train\n",
      "train mean loss=62313.407552083336\n",
      "test_test\n",
      "test mean loss=87818.0390625\n",
      "fin save.\n",
      "epoch 4723\n",
      "test_train\n",
      "train mean loss=61373.002604166664\n",
      "test_test\n",
      "test mean loss=87749.546875\n",
      "fin save.\n",
      "epoch 4724\n",
      "test_train\n",
      "train mean loss=61543.918619791664\n",
      "test_test\n",
      "test mean loss=87925.3515625\n",
      "fin save.\n",
      "epoch 4725\n",
      "test_train\n",
      "train mean loss=61602.66302083333\n",
      "test_test\n",
      "test mean loss=87870.1328125\n",
      "fin save.\n",
      "epoch 4726\n",
      "test_train\n",
      "train mean loss=61566.27942708333\n",
      "test_test\n",
      "test mean loss=87937.0390625\n",
      "fin save.\n",
      "epoch 4727\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=62248.007552083334\n",
      "test_test\n",
      "test mean loss=87844.7265625\n",
      "fin save.\n",
      "epoch 4728\n",
      "test_train\n",
      "train mean loss=61821.984114583334\n",
      "test_test\n",
      "test mean loss=87879.87109375\n",
      "fin save.\n",
      "epoch 4729\n",
      "test_train\n",
      "train mean loss=62227.477864583336\n",
      "test_test\n",
      "test mean loss=87838.1640625\n",
      "fin save.\n",
      "epoch 4730\n",
      "test_train\n",
      "train mean loss=61967.202864583334\n",
      "test_test\n",
      "test mean loss=88016.08984375\n",
      "fin save.\n",
      "epoch 4731\n",
      "test_train\n",
      "train mean loss=63477.23645833333\n",
      "test_test\n",
      "test mean loss=88233.48828125\n",
      "fin save.\n",
      "epoch 4732\n",
      "test_train\n",
      "train mean loss=62499.303385416664\n",
      "test_test\n",
      "test mean loss=88156.0390625\n",
      "fin save.\n",
      "epoch 4733\n",
      "test_train\n",
      "train mean loss=62293.265234375\n",
      "test_test\n",
      "test mean loss=88035.5078125\n",
      "fin save.\n",
      "epoch 4734\n",
      "test_train\n",
      "train mean loss=62036.29114583333\n",
      "test_test\n",
      "test mean loss=87992.60546875\n",
      "fin save.\n",
      "epoch 4735\n",
      "test_train\n",
      "train mean loss=62333.00546875\n",
      "test_test\n",
      "test mean loss=88060.03515625\n",
      "fin save.\n",
      "epoch 4736\n",
      "test_train\n",
      "train mean loss=62239.28216145833\n",
      "test_test\n",
      "test mean loss=88168.54296875\n",
      "fin save.\n",
      "epoch 4737\n",
      "test_train\n",
      "train mean loss=60955.16979166667\n",
      "test_test\n",
      "test mean loss=88251.9453125\n",
      "fin save.\n",
      "epoch 4738\n",
      "test_train\n",
      "train mean loss=61427.18567708333\n",
      "test_test\n",
      "test mean loss=88351.4765625\n",
      "fin save.\n",
      "epoch 4739\n",
      "test_train\n",
      "train mean loss=61758.97994791667\n",
      "test_test\n",
      "test mean loss=87984.78515625\n",
      "fin save.\n",
      "epoch 4740\n",
      "test_train\n",
      "train mean loss=61978.35703125\n",
      "test_test\n",
      "test mean loss=88020.4921875\n",
      "fin save.\n",
      "epoch 4741\n",
      "test_train\n",
      "train mean loss=61651.923177083336\n",
      "test_test\n",
      "test mean loss=87978.26953125\n",
      "fin save.\n",
      "epoch 4742\n",
      "test_train\n",
      "train mean loss=62538.840625\n",
      "test_test\n",
      "test mean loss=88764.78515625\n",
      "fin save.\n",
      "epoch 4743\n",
      "test_train\n",
      "train mean loss=61240.24114583333\n",
      "test_test\n",
      "test mean loss=88606.1796875\n",
      "fin save.\n",
      "epoch 4744\n",
      "test_train\n",
      "train mean loss=61984.761458333334\n",
      "test_test\n",
      "test mean loss=88464.71875\n",
      "fin save.\n",
      "epoch 4745\n",
      "test_train\n",
      "train mean loss=62668.168229166666\n",
      "test_test\n",
      "test mean loss=88341.23828125\n",
      "fin save.\n",
      "epoch 4746\n",
      "test_train\n",
      "train mean loss=62620.755078125\n",
      "test_test\n",
      "test mean loss=88469.58984375\n",
      "fin save.\n",
      "epoch 4747\n",
      "test_train\n",
      "train mean loss=63007.181901041666\n",
      "test_test\n",
      "test mean loss=88542.5\n",
      "fin save.\n",
      "epoch 4748\n",
      "test_train\n",
      "train mean loss=62051.54088541667\n",
      "test_test\n",
      "test mean loss=88397.90234375\n",
      "fin save.\n",
      "epoch 4749\n",
      "test_train\n",
      "train mean loss=61480.64270833333\n",
      "test_test\n",
      "test mean loss=88426.95703125\n",
      "fin save.\n",
      "epoch 4750\n",
      "test_train\n",
      "train mean loss=62218.83880208333\n",
      "test_test\n",
      "test mean loss=88307.29296875\n",
      "fin save.\n",
      "epoch 4751\n",
      "test_train\n",
      "train mean loss=62790.55963541667\n",
      "test_test\n",
      "test mean loss=88365.16796875\n",
      "fin save.\n",
      "epoch 4752\n",
      "test_train\n",
      "train mean loss=62121.81796875\n",
      "test_test\n",
      "test mean loss=88696.55078125\n",
      "fin save.\n",
      "epoch 4753\n",
      "test_train\n",
      "train mean loss=61665.778645833336\n",
      "test_test\n",
      "test mean loss=88470.3984375\n",
      "fin save.\n",
      "epoch 4754\n",
      "test_train\n",
      "train mean loss=63536.4328125\n",
      "test_test\n",
      "test mean loss=88624.0\n",
      "fin save.\n",
      "epoch 4755\n",
      "test_train\n",
      "train mean loss=62360.871354166666\n",
      "test_test\n",
      "test mean loss=88304.50390625\n",
      "fin save.\n",
      "epoch 4756\n",
      "test_train\n",
      "train mean loss=62372.833984375\n",
      "test_test\n",
      "test mean loss=88332.72265625\n",
      "fin save.\n",
      "epoch 4757\n",
      "test_train\n",
      "train mean loss=62578.767578125\n",
      "test_test\n",
      "test mean loss=88087.1640625\n",
      "fin save.\n",
      "epoch 4758\n",
      "test_train\n",
      "train mean loss=61793.881510416664\n",
      "test_test\n",
      "test mean loss=88432.94140625\n",
      "fin save.\n",
      "epoch 4759\n",
      "test_train\n",
      "train mean loss=61888.35390625\n",
      "test_test\n",
      "test mean loss=88250.62109375\n",
      "fin save.\n",
      "epoch 4760\n",
      "test_train\n",
      "train mean loss=61882.76223958333\n",
      "test_test\n",
      "test mean loss=88141.3671875\n",
      "fin save.\n",
      "epoch 4761\n",
      "test_train\n",
      "train mean loss=62761.469140625\n",
      "test_test\n",
      "test mean loss=88120.6484375\n",
      "fin save.\n",
      "epoch 4762\n",
      "test_train\n",
      "train mean loss=62714.412369791666\n",
      "test_test\n",
      "test mean loss=88276.265625\n",
      "fin save.\n",
      "epoch 4763\n",
      "test_train\n",
      "train mean loss=62264.908854166664\n",
      "test_test\n",
      "test mean loss=88509.79296875\n",
      "fin save.\n",
      "epoch 4764\n",
      "test_train\n",
      "train mean loss=61162.94036458333\n",
      "test_test\n",
      "test mean loss=88282.97265625\n",
      "fin save.\n",
      "epoch 4765\n",
      "test_train\n",
      "train mean loss=61926.4984375\n",
      "test_test\n",
      "test mean loss=88167.375\n",
      "fin save.\n",
      "epoch 4766\n",
      "test_train\n",
      "train mean loss=63371.511458333334\n",
      "test_test\n",
      "test mean loss=88162.03125\n",
      "fin save.\n",
      "epoch 4767\n",
      "test_train\n",
      "train mean loss=62390.30416666667\n",
      "test_test\n",
      "test mean loss=88062.24609375\n",
      "fin save.\n",
      "epoch 4768\n",
      "test_train\n",
      "train mean loss=61437.51354166667\n",
      "test_test\n",
      "test mean loss=88052.9296875\n",
      "fin save.\n",
      "epoch 4769\n",
      "test_train\n",
      "train mean loss=61655.359635416666\n",
      "test_test\n",
      "test mean loss=88232.6484375\n",
      "fin save.\n",
      "epoch 4770\n",
      "test_train\n",
      "train mean loss=61734.27421875\n",
      "test_test\n",
      "test mean loss=88271.8671875\n",
      "fin save.\n",
      "epoch 4771\n",
      "test_train\n",
      "train mean loss=62819.0640625\n",
      "test_test\n",
      "test mean loss=88310.1953125\n",
      "fin save.\n",
      "epoch 4772\n",
      "test_train\n",
      "train mean loss=62187.72421875\n",
      "test_test\n",
      "test mean loss=88163.03515625\n",
      "fin save.\n",
      "epoch 4773\n",
      "test_train\n",
      "train mean loss=62745.069140625\n",
      "test_test\n",
      "test mean loss=88232.21484375\n",
      "fin save.\n",
      "epoch 4774\n",
      "test_train\n",
      "train mean loss=62568.191145833334\n",
      "test_test\n",
      "test mean loss=88278.32421875\n",
      "fin save.\n",
      "epoch 4775\n",
      "test_train\n",
      "train mean loss=61965.30286458333\n",
      "test_test\n",
      "test mean loss=88196.3515625\n",
      "fin save.\n",
      "epoch 4776\n",
      "test_train\n",
      "train mean loss=62607.033203125\n",
      "test_test\n",
      "test mean loss=88138.43359375\n",
      "fin save.\n",
      "epoch 4777\n",
      "test_train\n",
      "train mean loss=61430.85078125\n",
      "test_test\n",
      "test mean loss=87951.8828125\n",
      "fin save.\n",
      "epoch 4778\n",
      "test_train\n",
      "train mean loss=61249.069010416664\n",
      "test_test\n",
      "test mean loss=88002.96484375\n",
      "fin save.\n",
      "epoch 4779\n",
      "test_train\n",
      "train mean loss=61862.008072916666\n",
      "test_test\n",
      "test mean loss=88183.4296875\n",
      "fin save.\n",
      "epoch 4780\n",
      "test_train\n",
      "train mean loss=62210.38828125\n",
      "test_test\n",
      "test mean loss=88174.3671875\n",
      "fin save.\n",
      "epoch 4781\n",
      "test_train\n",
      "train mean loss=62339.37122395833\n",
      "test_test\n",
      "test mean loss=88021.79296875\n",
      "fin save.\n",
      "epoch 4782\n",
      "test_train\n",
      "train mean loss=62096.87994791667\n",
      "test_test\n",
      "test mean loss=88176.48046875\n",
      "fin save.\n",
      "epoch 4783\n",
      "test_train\n",
      "train mean loss=61753.91171875\n",
      "test_test\n",
      "test mean loss=88272.8046875\n",
      "fin save.\n",
      "epoch 4784\n",
      "test_train\n",
      "train mean loss=61502.79791666667\n",
      "test_test\n",
      "test mean loss=88288.359375\n",
      "fin save.\n",
      "epoch 4785\n",
      "test_train\n",
      "train mean loss=62179.8375\n",
      "test_test\n",
      "test mean loss=88146.76953125\n",
      "fin save.\n",
      "epoch 4786\n",
      "test_train\n",
      "train mean loss=62133.39505208333\n",
      "test_test\n",
      "test mean loss=88007.7578125\n",
      "fin save.\n",
      "epoch 4787\n",
      "test_train\n",
      "train mean loss=61608.24817708333\n",
      "test_test\n",
      "test mean loss=88044.58984375\n",
      "fin save.\n",
      "epoch 4788\n",
      "test_train\n",
      "train mean loss=62409.79140625\n",
      "test_test\n",
      "test mean loss=88091.03515625\n",
      "fin save.\n",
      "epoch 4789\n",
      "test_train\n",
      "train mean loss=61713.557942708336\n",
      "test_test\n",
      "test mean loss=87958.328125\n",
      "fin save.\n",
      "epoch 4790\n",
      "test_train\n",
      "train mean loss=61272.202473958336\n",
      "test_test\n",
      "test mean loss=87967.39453125\n",
      "fin save.\n",
      "epoch 4791\n",
      "test_train\n",
      "train mean loss=62634.359635416666\n",
      "test_test\n",
      "test mean loss=87912.30859375\n",
      "fin save.\n",
      "epoch 4792\n",
      "test_train\n",
      "train mean loss=62017.5453125\n",
      "test_test\n",
      "test mean loss=88002.5\n",
      "fin save.\n",
      "epoch 4793\n",
      "test_train\n",
      "train mean loss=62344.14765625\n",
      "test_test\n",
      "test mean loss=88361.30859375\n",
      "fin save.\n",
      "epoch 4794\n",
      "test_train\n",
      "train mean loss=61783.29088541667\n",
      "test_test\n",
      "test mean loss=88431.98828125\n",
      "fin save.\n",
      "epoch 4795\n",
      "test_train\n",
      "train mean loss=61958.156510416666\n",
      "test_test\n",
      "test mean loss=88325.11328125\n",
      "fin save.\n",
      "epoch 4796\n",
      "test_train\n",
      "train mean loss=62371.351171875\n",
      "test_test\n",
      "test mean loss=88053.7578125\n",
      "fin save.\n",
      "epoch 4797\n",
      "test_train\n",
      "train mean loss=62005.68958333333\n",
      "test_test\n",
      "test mean loss=87936.140625\n",
      "fin save.\n",
      "epoch 4798\n",
      "test_train\n",
      "train mean loss=63201.82421875\n",
      "test_test\n",
      "test mean loss=88292.36328125\n",
      "fin save.\n",
      "epoch 4799\n",
      "test_train\n",
      "train mean loss=61947.3921875\n",
      "test_test\n",
      "test mean loss=88365.265625\n",
      "fin save.\n",
      "epoch 4800\n",
      "test_train\n",
      "train mean loss=62399.27057291667\n",
      "test_test\n",
      "test mean loss=88432.95703125\n",
      "fin save.\n",
      "epoch 4801\n",
      "test_train\n",
      "train mean loss=62121.44713541667\n",
      "test_test\n",
      "test mean loss=88562.51171875\n",
      "fin save.\n",
      "epoch 4802\n",
      "test_train\n",
      "train mean loss=61397.351822916666\n",
      "test_test\n",
      "test mean loss=88559.17578125\n",
      "fin save.\n",
      "epoch 4803\n",
      "test_train\n",
      "train mean loss=61799.42291666667\n",
      "test_test\n",
      "test mean loss=88216.88671875\n",
      "fin save.\n",
      "epoch 4804\n",
      "test_train\n",
      "train mean loss=61354.467447916664\n",
      "test_test\n",
      "test mean loss=88395.25390625\n",
      "fin save.\n",
      "epoch 4805\n",
      "test_train\n",
      "train mean loss=62066.23880208333\n",
      "test_test\n",
      "test mean loss=88571.99609375\n",
      "fin save.\n",
      "epoch 4806\n",
      "test_train\n",
      "train mean loss=62475.926041666666\n",
      "test_test\n",
      "test mean loss=88373.5859375\n",
      "fin save.\n",
      "epoch 4807\n",
      "test_train\n",
      "train mean loss=61473.2265625\n",
      "test_test\n",
      "test mean loss=88357.09765625\n",
      "fin save.\n",
      "epoch 4808\n",
      "test_train\n",
      "train mean loss=61668.140885416666\n",
      "test_test\n",
      "test mean loss=88163.77734375\n",
      "fin save.\n",
      "epoch 4809\n",
      "test_train\n",
      "train mean loss=61811.51901041667\n",
      "test_test\n",
      "test mean loss=88374.203125\n",
      "fin save.\n",
      "epoch 4810\n",
      "test_train\n",
      "train mean loss=62158.73046875\n",
      "test_test\n",
      "test mean loss=88149.2109375\n",
      "fin save.\n",
      "epoch 4811\n",
      "test_train\n",
      "train mean loss=61991.34166666667\n",
      "test_test\n",
      "test mean loss=88269.3203125\n",
      "fin save.\n",
      "epoch 4812\n",
      "test_train\n",
      "train mean loss=62028.639322916664\n",
      "test_test\n",
      "test mean loss=88258.36328125\n",
      "fin save.\n",
      "epoch 4813\n",
      "test_train\n",
      "train mean loss=61571.73424479167\n",
      "test_test\n",
      "test mean loss=88370.87109375\n",
      "fin save.\n",
      "epoch 4814\n",
      "test_train\n",
      "train mean loss=61906.9765625\n",
      "test_test\n",
      "test mean loss=88154.1328125\n",
      "fin save.\n",
      "epoch 4815\n",
      "test_train\n",
      "train mean loss=62889.79348958333\n",
      "test_test\n",
      "test mean loss=87744.2109375\n",
      "fin save.\n",
      "epoch 4816\n",
      "test_train\n",
      "train mean loss=61564.709635416664\n",
      "test_test\n",
      "test mean loss=88049.359375\n",
      "fin save.\n",
      "epoch 4817\n",
      "test_train\n",
      "train mean loss=61613.93359375\n",
      "test_test\n",
      "test mean loss=87963.77734375\n",
      "fin save.\n",
      "epoch 4818\n",
      "test_train\n",
      "train mean loss=62667.38046875\n",
      "test_test\n",
      "test mean loss=87804.11328125\n",
      "fin save.\n",
      "epoch 4819\n",
      "test_train\n",
      "train mean loss=62214.0046875\n",
      "test_test\n",
      "test mean loss=87968.9296875\n",
      "fin save.\n",
      "epoch 4820\n",
      "test_train\n",
      "train mean loss=62285.16328125\n",
      "test_test\n",
      "test mean loss=87984.8515625\n",
      "fin save.\n",
      "epoch 4821\n",
      "test_train\n",
      "train mean loss=61948.276041666664\n",
      "test_test\n",
      "test mean loss=88056.09375\n",
      "fin save.\n",
      "epoch 4822\n",
      "test_train\n",
      "train mean loss=62521.58489583333\n",
      "test_test\n",
      "test mean loss=87715.64453125\n",
      "fin save.\n",
      "epoch 4823\n",
      "test_train\n",
      "train mean loss=62640.90963541667\n",
      "test_test\n",
      "test mean loss=87689.1640625\n",
      "fin save.\n",
      "epoch 4824\n",
      "test_train\n",
      "train mean loss=61994.79583333333\n",
      "test_test\n",
      "test mean loss=88153.43359375\n",
      "fin save.\n",
      "epoch 4825\n",
      "test_train\n",
      "train mean loss=61810.79973958333\n",
      "test_test\n",
      "test mean loss=87975.34765625\n",
      "fin save.\n",
      "epoch 4826\n",
      "test_train\n",
      "train mean loss=61111.65533854167\n",
      "test_test\n",
      "test mean loss=87617.21484375\n",
      "fin save.\n",
      "epoch 4827\n",
      "test_train\n",
      "train mean loss=62243.457291666666\n",
      "test_test\n",
      "test mean loss=87624.73046875\n",
      "fin save.\n",
      "epoch 4828\n",
      "test_train\n",
      "train mean loss=63249.834375\n",
      "test_test\n",
      "test mean loss=87543.94140625\n",
      "fin save.\n",
      "epoch 4829\n",
      "test_train\n",
      "train mean loss=62809.99114583333\n",
      "test_test\n",
      "test mean loss=87815.828125\n",
      "fin save.\n",
      "epoch 4830\n",
      "test_train\n",
      "train mean loss=62528.58697916667\n",
      "test_test\n",
      "test mean loss=87768.25390625\n",
      "fin save.\n",
      "epoch 4831\n",
      "test_train\n",
      "train mean loss=61874.50546875\n",
      "test_test\n",
      "test mean loss=87667.7109375\n",
      "fin save.\n",
      "epoch 4832\n",
      "test_train\n",
      "train mean loss=62099.0796875\n",
      "test_test\n",
      "test mean loss=87559.76171875\n",
      "fin save.\n",
      "epoch 4833\n",
      "test_train\n",
      "train mean loss=62663.65716145833\n",
      "test_test\n",
      "test mean loss=87553.23828125\n",
      "fin save.\n",
      "epoch 4834\n",
      "test_train\n",
      "train mean loss=62031.84869791667\n",
      "test_test\n",
      "test mean loss=87459.06640625\n",
      "fin save.\n",
      "epoch 4835\n",
      "test_train\n",
      "train mean loss=62002.465625\n",
      "test_test\n",
      "test mean loss=87567.28125\n",
      "fin save.\n",
      "epoch 4836\n",
      "test_train\n",
      "train mean loss=62053.233723958336\n",
      "test_test\n",
      "test mean loss=87678.45703125\n",
      "fin save.\n",
      "epoch 4837\n",
      "test_train\n",
      "train mean loss=62139.0484375\n",
      "test_test\n",
      "test mean loss=87785.57421875\n",
      "fin save.\n",
      "epoch 4838\n",
      "test_train\n",
      "train mean loss=61400.66484375\n",
      "test_test\n",
      "test mean loss=88008.1875\n",
      "fin save.\n",
      "epoch 4839\n",
      "test_train\n",
      "train mean loss=61595.023697916666\n",
      "test_test\n",
      "test mean loss=88053.40625\n",
      "fin save.\n",
      "epoch 4840\n",
      "test_train\n",
      "train mean loss=62069.8640625\n",
      "test_test\n",
      "test mean loss=87764.22265625\n",
      "fin save.\n",
      "epoch 4841\n",
      "test_train\n",
      "train mean loss=61329.1390625\n",
      "test_test\n",
      "test mean loss=87896.80859375\n",
      "fin save.\n",
      "epoch 4842\n",
      "test_train\n",
      "train mean loss=61792.976171875\n",
      "test_test\n",
      "test mean loss=87372.19921875\n",
      "fin save.\n",
      "epoch 4843\n",
      "test_train\n",
      "train mean loss=61999.0328125\n",
      "test_test\n",
      "test mean loss=87352.91796875\n",
      "fin save.\n",
      "epoch 4844\n",
      "test_train\n",
      "train mean loss=62791.15963541667\n",
      "test_test\n",
      "test mean loss=87492.796875\n",
      "fin save.\n",
      "epoch 4845\n",
      "test_train\n",
      "train mean loss=63127.90520833333\n",
      "test_test\n",
      "test mean loss=87377.4296875\n",
      "fin save.\n",
      "epoch 4846\n",
      "test_train\n",
      "train mean loss=61781.61510416667\n",
      "test_test\n",
      "test mean loss=87461.3203125\n",
      "fin save.\n",
      "epoch 4847\n",
      "test_train\n",
      "train mean loss=62903.32734375\n",
      "test_test\n",
      "test mean loss=87495.44921875\n",
      "fin save.\n",
      "epoch 4848\n",
      "test_train\n",
      "train mean loss=61083.03763020833\n",
      "test_test\n",
      "test mean loss=87370.0\n",
      "fin save.\n",
      "epoch 4849\n",
      "test_train\n",
      "train mean loss=60972.40911458333\n",
      "test_test\n",
      "test mean loss=87560.66796875\n",
      "fin save.\n",
      "epoch 4850\n",
      "test_train\n",
      "train mean loss=62131.302734375\n",
      "test_test\n",
      "test mean loss=87733.15625\n",
      "fin save.\n",
      "epoch 4851\n",
      "test_train\n",
      "train mean loss=60570.72552083333\n",
      "test_test\n",
      "test mean loss=87545.01171875\n",
      "fin save.\n",
      "epoch 4852\n",
      "test_train\n",
      "train mean loss=61662.98671875\n",
      "test_test\n",
      "test mean loss=87675.73828125\n",
      "fin save.\n",
      "epoch 4853\n",
      "test_train\n",
      "train mean loss=61205.92174479167\n",
      "test_test\n",
      "test mean loss=87685.28125\n",
      "fin save.\n",
      "epoch 4854\n",
      "test_train\n",
      "train mean loss=61410.584375\n",
      "test_test\n",
      "test mean loss=87669.953125\n",
      "fin save.\n",
      "epoch 4855\n",
      "test_train\n",
      "train mean loss=62819.51354166667\n",
      "test_test\n",
      "test mean loss=87731.71484375\n",
      "fin save.\n",
      "epoch 4856\n",
      "test_train\n",
      "train mean loss=62248.63033854167\n",
      "test_test\n",
      "test mean loss=87827.12890625\n",
      "fin save.\n",
      "epoch 4857\n",
      "test_train\n",
      "train mean loss=61930.12161458333\n",
      "test_test\n",
      "test mean loss=87739.7265625\n",
      "fin save.\n",
      "epoch 4858\n",
      "test_train\n",
      "train mean loss=61902.75598958333\n",
      "test_test\n",
      "test mean loss=87830.55078125\n",
      "fin save.\n",
      "epoch 4859\n",
      "test_train\n",
      "train mean loss=62002.55703125\n",
      "test_test\n",
      "test mean loss=88029.54296875\n",
      "fin save.\n",
      "epoch 4860\n",
      "test_train\n",
      "train mean loss=62564.08971354167\n",
      "test_test\n",
      "test mean loss=88226.01953125\n",
      "fin save.\n",
      "epoch 4861\n",
      "test_train\n",
      "train mean loss=62079.62161458333\n",
      "test_test\n",
      "test mean loss=87723.8359375\n",
      "fin save.\n",
      "epoch 4862\n",
      "test_train\n",
      "train mean loss=61436.89375\n",
      "test_test\n",
      "test mean loss=87890.22265625\n",
      "fin save.\n",
      "epoch 4863\n",
      "test_train\n",
      "train mean loss=60981.26458333333\n",
      "test_test\n",
      "test mean loss=88358.80859375\n",
      "fin save.\n",
      "epoch 4864\n",
      "test_train\n",
      "train mean loss=62458.20234375\n",
      "test_test\n",
      "test mean loss=88032.1015625\n",
      "fin save.\n",
      "epoch 4865\n",
      "test_train\n",
      "train mean loss=61823.515364583334\n",
      "test_test\n",
      "test mean loss=87900.32421875\n",
      "fin save.\n",
      "epoch 4866\n",
      "test_train\n",
      "train mean loss=61732.29205729167\n",
      "test_test\n",
      "test mean loss=87825.953125\n",
      "fin save.\n",
      "epoch 4867\n",
      "test_train\n",
      "train mean loss=62312.617447916666\n",
      "test_test\n",
      "test mean loss=88304.234375\n",
      "fin save.\n",
      "epoch 4868\n",
      "test_train\n",
      "train mean loss=61415.1609375\n",
      "test_test\n",
      "test mean loss=88201.5703125\n",
      "fin save.\n",
      "epoch 4869\n",
      "test_train\n",
      "train mean loss=61796.147135416664\n",
      "test_test\n",
      "test mean loss=88331.2109375\n",
      "fin save.\n",
      "epoch 4870\n",
      "test_train\n",
      "train mean loss=61994.226822916666\n",
      "test_test\n",
      "test mean loss=88232.13671875\n",
      "fin save.\n",
      "epoch 4871\n",
      "test_train\n",
      "train mean loss=61620.330078125\n",
      "test_test\n",
      "test mean loss=88124.43359375\n",
      "fin save.\n",
      "epoch 4872\n",
      "test_train\n",
      "train mean loss=63607.916666666664\n",
      "test_test\n",
      "test mean loss=88265.5546875\n",
      "fin save.\n",
      "epoch 4873\n",
      "test_train\n",
      "train mean loss=61682.765885416666\n",
      "test_test\n",
      "test mean loss=88194.18359375\n",
      "fin save.\n",
      "epoch 4874\n",
      "test_train\n",
      "train mean loss=62134.685546875\n",
      "test_test\n",
      "test mean loss=88254.23046875\n",
      "fin save.\n",
      "epoch 4875\n",
      "test_train\n",
      "train mean loss=61629.61080729167\n",
      "test_test\n",
      "test mean loss=88161.7265625\n",
      "fin save.\n",
      "epoch 4876\n",
      "test_train\n",
      "train mean loss=61386.46041666667\n",
      "test_test\n",
      "test mean loss=88321.359375\n",
      "fin save.\n",
      "epoch 4877\n",
      "test_train\n",
      "train mean loss=61470.20104166667\n",
      "test_test\n",
      "test mean loss=88219.42578125\n",
      "fin save.\n",
      "epoch 4878\n",
      "test_train\n",
      "train mean loss=61670.34375\n",
      "test_test\n",
      "test mean loss=88357.8984375\n",
      "fin save.\n",
      "epoch 4879\n",
      "test_train\n",
      "train mean loss=61516.08489583333\n",
      "test_test\n",
      "test mean loss=88603.0\n",
      "fin save.\n",
      "epoch 4880\n",
      "test_train\n",
      "train mean loss=62610.31692708333\n",
      "test_test\n",
      "test mean loss=88461.12109375\n",
      "fin save.\n",
      "epoch 4881\n",
      "test_train\n",
      "train mean loss=62548.8234375\n",
      "test_test\n",
      "test mean loss=88808.46875\n",
      "fin save.\n",
      "epoch 4882\n",
      "test_train\n",
      "train mean loss=61574.14244791667\n",
      "test_test\n",
      "test mean loss=88718.78125\n",
      "fin save.\n",
      "epoch 4883\n",
      "test_train\n",
      "train mean loss=62892.76640625\n",
      "test_test\n",
      "test mean loss=88780.26171875\n",
      "fin save.\n",
      "epoch 4884\n",
      "test_train\n",
      "train mean loss=61903.4484375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_test\n",
      "test mean loss=88258.515625\n",
      "fin save.\n",
      "epoch 4885\n",
      "test_train\n",
      "train mean loss=62799.63984375\n",
      "test_test\n",
      "test mean loss=88234.17578125\n",
      "fin save.\n",
      "epoch 4886\n",
      "test_train\n",
      "train mean loss=61847.26015625\n",
      "test_test\n",
      "test mean loss=88185.04296875\n",
      "fin save.\n",
      "epoch 4887\n",
      "test_train\n",
      "train mean loss=62635.798828125\n",
      "test_test\n",
      "test mean loss=88310.015625\n",
      "fin save.\n",
      "epoch 4888\n",
      "test_train\n",
      "train mean loss=60717.0046875\n",
      "test_test\n",
      "test mean loss=88175.76171875\n",
      "fin save.\n",
      "epoch 4889\n",
      "test_train\n",
      "train mean loss=61970.89921875\n",
      "test_test\n",
      "test mean loss=88568.94140625\n",
      "fin save.\n",
      "epoch 4890\n",
      "test_train\n",
      "train mean loss=61649.410416666666\n",
      "test_test\n",
      "test mean loss=88526.57421875\n",
      "fin save.\n",
      "epoch 4891\n",
      "test_train\n",
      "train mean loss=62156.00390625\n",
      "test_test\n",
      "test mean loss=88462.50390625\n",
      "fin save.\n",
      "epoch 4892\n",
      "test_train\n",
      "train mean loss=61717.109635416666\n",
      "test_test\n",
      "test mean loss=88706.99609375\n",
      "fin save.\n",
      "epoch 4893\n",
      "test_train\n",
      "train mean loss=61599.608072916664\n",
      "test_test\n",
      "test mean loss=88718.16015625\n",
      "fin save.\n",
      "epoch 4894\n",
      "test_train\n",
      "train mean loss=62130.14635416667\n",
      "test_test\n",
      "test mean loss=88931.875\n",
      "fin save.\n",
      "epoch 4895\n",
      "test_train\n",
      "train mean loss=61707.651041666664\n",
      "test_test\n",
      "test mean loss=88846.953125\n",
      "fin save.\n",
      "epoch 4896\n",
      "test_train\n",
      "train mean loss=61966.71588541667\n",
      "test_test\n",
      "test mean loss=89041.9921875\n",
      "fin save.\n",
      "epoch 4897\n",
      "test_train\n",
      "train mean loss=62496.8046875\n",
      "test_test\n",
      "test mean loss=89195.33984375\n",
      "fin save.\n",
      "epoch 4898\n",
      "test_train\n",
      "train mean loss=62221.01471354167\n",
      "test_test\n",
      "test mean loss=89106.5703125\n",
      "fin save.\n",
      "epoch 4899\n",
      "test_train\n",
      "train mean loss=61562.409375\n",
      "test_test\n",
      "test mean loss=89057.5390625\n",
      "fin save.\n",
      "epoch 4900\n",
      "test_train\n",
      "train mean loss=62499.684895833336\n",
      "test_test\n",
      "test mean loss=88992.08203125\n",
      "fin save.\n",
      "epoch 4901\n",
      "test_train\n",
      "train mean loss=62048.55091145833\n",
      "test_test\n",
      "test mean loss=88922.72265625\n",
      "fin save.\n",
      "epoch 4902\n",
      "test_train\n",
      "train mean loss=62334.22317708333\n",
      "test_test\n",
      "test mean loss=88857.66015625\n",
      "fin save.\n",
      "epoch 4903\n",
      "test_train\n",
      "train mean loss=62520.570572916666\n",
      "test_test\n",
      "test mean loss=88605.359375\n",
      "fin save.\n",
      "epoch 4904\n",
      "test_train\n",
      "train mean loss=62177.75481770833\n",
      "test_test\n",
      "test mean loss=88366.8046875\n",
      "fin save.\n",
      "epoch 4905\n",
      "test_train\n",
      "train mean loss=61921.792708333334\n",
      "test_test\n",
      "test mean loss=88670.53125\n",
      "fin save.\n",
      "epoch 4906\n",
      "test_train\n",
      "train mean loss=61743.63229166667\n",
      "test_test\n",
      "test mean loss=88869.37890625\n",
      "fin save.\n",
      "epoch 4907\n",
      "test_train\n",
      "train mean loss=61975.8796875\n",
      "test_test\n",
      "test mean loss=88435.17578125\n",
      "fin save.\n",
      "epoch 4908\n",
      "test_train\n",
      "train mean loss=62550.7765625\n",
      "test_test\n",
      "test mean loss=88282.51953125\n",
      "fin save.\n",
      "epoch 4909\n",
      "test_train\n",
      "train mean loss=61003.25208333333\n",
      "test_test\n",
      "test mean loss=88776.0703125\n",
      "fin save.\n",
      "epoch 4910\n",
      "test_train\n",
      "train mean loss=61531.923177083336\n",
      "test_test\n",
      "test mean loss=88781.1484375\n",
      "fin save.\n",
      "epoch 4911\n",
      "test_train\n",
      "train mean loss=62114.99427083333\n",
      "test_test\n",
      "test mean loss=88716.65234375\n",
      "fin save.\n",
      "epoch 4912\n",
      "test_train\n",
      "train mean loss=62380.360546875\n",
      "test_test\n",
      "test mean loss=88517.29296875\n",
      "fin save.\n",
      "epoch 4913\n",
      "test_train\n",
      "train mean loss=63050.724869791666\n",
      "test_test\n",
      "test mean loss=88667.75390625\n",
      "fin save.\n",
      "epoch 4914\n",
      "test_train\n",
      "train mean loss=60836.600260416664\n",
      "test_test\n",
      "test mean loss=88705.28515625\n",
      "fin save.\n",
      "epoch 4915\n",
      "test_train\n",
      "train mean loss=61239.092447916664\n",
      "test_test\n",
      "test mean loss=88854.80859375\n",
      "fin save.\n",
      "epoch 4916\n",
      "test_train\n",
      "train mean loss=62332.8984375\n",
      "test_test\n",
      "test mean loss=88942.89453125\n",
      "fin save.\n",
      "epoch 4917\n",
      "test_train\n",
      "train mean loss=61242.91119791667\n",
      "test_test\n",
      "test mean loss=88835.6875\n",
      "fin save.\n",
      "epoch 4918\n",
      "test_train\n",
      "train mean loss=63314.23151041667\n",
      "test_test\n",
      "test mean loss=88844.1328125\n",
      "fin save.\n",
      "epoch 4919\n",
      "test_train\n",
      "train mean loss=62398.54296875\n",
      "test_test\n",
      "test mean loss=88432.53515625\n",
      "fin save.\n",
      "epoch 4920\n",
      "test_train\n",
      "train mean loss=61825.0875\n",
      "test_test\n",
      "test mean loss=88562.51171875\n",
      "fin save.\n",
      "epoch 4921\n",
      "test_train\n",
      "train mean loss=61842.48385416667\n",
      "test_test\n",
      "test mean loss=88513.609375\n",
      "fin save.\n",
      "epoch 4922\n",
      "test_train\n",
      "train mean loss=62091.103125\n",
      "test_test\n",
      "test mean loss=88825.05078125\n",
      "fin save.\n",
      "epoch 4923\n",
      "test_train\n",
      "train mean loss=61296.20598958333\n",
      "test_test\n",
      "test mean loss=88586.0859375\n",
      "fin save.\n",
      "epoch 4924\n",
      "test_train\n",
      "train mean loss=62285.47994791667\n",
      "test_test\n",
      "test mean loss=88519.29296875\n",
      "fin save.\n",
      "epoch 4925\n",
      "test_train\n",
      "train mean loss=61831.94765625\n",
      "test_test\n",
      "test mean loss=88578.44921875\n",
      "fin save.\n",
      "epoch 4926\n",
      "test_train\n",
      "train mean loss=61877.904296875\n",
      "test_test\n",
      "test mean loss=88538.80078125\n",
      "fin save.\n",
      "epoch 4927\n",
      "test_train\n",
      "train mean loss=62402.55026041667\n",
      "test_test\n",
      "test mean loss=88489.51953125\n",
      "fin save.\n",
      "epoch 4928\n",
      "test_train\n",
      "train mean loss=62630.91953125\n",
      "test_test\n",
      "test mean loss=88358.30859375\n",
      "fin save.\n",
      "epoch 4929\n",
      "test_train\n",
      "train mean loss=62379.270833333336\n",
      "test_test\n",
      "test mean loss=88495.28515625\n",
      "fin save.\n",
      "epoch 4930\n",
      "test_train\n",
      "train mean loss=61947.92109375\n",
      "test_test\n",
      "test mean loss=88347.4765625\n",
      "fin save.\n",
      "epoch 4931\n",
      "test_train\n",
      "train mean loss=61316.08893229167\n",
      "test_test\n",
      "test mean loss=88524.10546875\n",
      "fin save.\n",
      "epoch 4932\n",
      "test_train\n",
      "train mean loss=62766.75598958333\n",
      "test_test\n",
      "test mean loss=88631.33203125\n",
      "fin save.\n",
      "epoch 4933\n",
      "test_train\n",
      "train mean loss=61511.21302083333\n",
      "test_test\n",
      "test mean loss=88566.6015625\n",
      "fin save.\n",
      "epoch 4934\n",
      "test_train\n",
      "train mean loss=62050.66953125\n",
      "test_test\n",
      "test mean loss=88605.0078125\n",
      "fin save.\n",
      "epoch 4935\n",
      "test_train\n",
      "train mean loss=62182.5734375\n",
      "test_test\n",
      "test mean loss=88916.8046875\n",
      "fin save.\n",
      "epoch 4936\n",
      "test_train\n",
      "train mean loss=62262.73932291667\n",
      "test_test\n",
      "test mean loss=88842.94140625\n",
      "fin save.\n",
      "epoch 4937\n",
      "test_train\n",
      "train mean loss=62147.001171875\n",
      "test_test\n",
      "test mean loss=88636.19140625\n",
      "fin save.\n",
      "epoch 4938\n",
      "test_train\n",
      "train mean loss=61319.46015625\n",
      "test_test\n",
      "test mean loss=88628.640625\n",
      "fin save.\n",
      "epoch 4939\n",
      "test_train\n",
      "train mean loss=62400.28125\n",
      "test_test\n",
      "test mean loss=88566.15625\n",
      "fin save.\n",
      "epoch 4940\n",
      "test_train\n",
      "train mean loss=62736.33684895833\n",
      "test_test\n",
      "test mean loss=88640.96484375\n",
      "fin save.\n",
      "epoch 4941\n",
      "test_train\n",
      "train mean loss=61668.303385416664\n",
      "test_test\n",
      "test mean loss=88746.8671875\n",
      "fin save.\n",
      "epoch 4942\n",
      "test_train\n",
      "train mean loss=61847.82916666667\n",
      "test_test\n",
      "test mean loss=88767.11328125\n",
      "fin save.\n",
      "epoch 4943\n",
      "test_train\n",
      "train mean loss=62291.46979166667\n",
      "test_test\n",
      "test mean loss=88642.2421875\n",
      "fin save.\n",
      "epoch 4944\n",
      "test_train\n",
      "train mean loss=62299.65026041667\n",
      "test_test\n",
      "test mean loss=88764.328125\n",
      "fin save.\n",
      "epoch 4945\n",
      "test_train\n",
      "train mean loss=62639.218489583334\n",
      "test_test\n",
      "test mean loss=88961.703125\n",
      "fin save.\n",
      "epoch 4946\n",
      "test_train\n",
      "train mean loss=62560.396223958334\n",
      "test_test\n",
      "test mean loss=88761.87109375\n",
      "fin save.\n",
      "epoch 4947\n",
      "test_train\n",
      "train mean loss=61805.274739583336\n",
      "test_test\n",
      "test mean loss=88761.06640625\n",
      "fin save.\n",
      "epoch 4948\n",
      "test_train\n",
      "train mean loss=62423.663802083334\n",
      "test_test\n",
      "test mean loss=88745.42578125\n",
      "fin save.\n",
      "epoch 4949\n",
      "test_train\n",
      "train mean loss=62289.559244791664\n",
      "test_test\n",
      "test mean loss=89089.16796875\n",
      "fin save.\n",
      "epoch 4950\n",
      "test_train\n",
      "train mean loss=62247.641927083336\n",
      "test_test\n",
      "test mean loss=88939.1640625\n",
      "fin save.\n",
      "epoch 4951\n",
      "test_train\n",
      "train mean loss=61637.411458333336\n",
      "test_test\n",
      "test mean loss=88901.43359375\n",
      "fin save.\n",
      "epoch 4952\n",
      "test_train\n",
      "train mean loss=60888.91197916667\n",
      "test_test\n",
      "test mean loss=89090.80859375\n",
      "fin save.\n",
      "epoch 4953\n",
      "test_train\n",
      "train mean loss=62350.970052083336\n",
      "test_test\n",
      "test mean loss=86735.11328125\n",
      "fin save.\n",
      "epoch 4954\n",
      "test_train\n",
      "train mean loss=62797.516927083336\n",
      "test_test\n",
      "test mean loss=86758.12890625\n",
      "fin save.\n",
      "epoch 4955\n",
      "test_train\n",
      "train mean loss=62083.21770833333\n",
      "test_test\n",
      "test mean loss=86800.0390625\n",
      "fin save.\n",
      "epoch 4956\n",
      "test_train\n",
      "train mean loss=63115.172135416666\n",
      "test_test\n",
      "test mean loss=86565.078125\n",
      "fin save.\n",
      "epoch 4957\n",
      "test_train\n",
      "train mean loss=61939.898177083334\n",
      "test_test\n",
      "test mean loss=86829.203125\n",
      "fin save.\n",
      "epoch 4958\n",
      "test_train\n",
      "train mean loss=62868.484765625\n",
      "test_test\n",
      "test mean loss=87409.06640625\n",
      "fin save.\n",
      "epoch 4959\n",
      "test_train\n",
      "train mean loss=62357.79830729167\n",
      "test_test\n",
      "test mean loss=87974.015625\n",
      "fin save.\n",
      "epoch 4960\n",
      "test_train\n",
      "train mean loss=61922.50234375\n",
      "test_test\n",
      "test mean loss=88112.62890625\n",
      "fin save.\n",
      "epoch 4961\n",
      "test_train\n",
      "train mean loss=62212.13072916667\n",
      "test_test\n",
      "test mean loss=87824.34765625\n",
      "fin save.\n",
      "epoch 4962\n",
      "test_train\n",
      "train mean loss=62682.16223958333\n",
      "test_test\n",
      "test mean loss=87729.4375\n",
      "fin save.\n",
      "epoch 4963\n",
      "test_train\n",
      "train mean loss=62233.73828125\n",
      "test_test\n",
      "test mean loss=88046.01171875\n",
      "fin save.\n",
      "epoch 4964\n",
      "test_train\n",
      "train mean loss=61903.75572916667\n",
      "test_test\n",
      "test mean loss=87866.984375\n",
      "fin save.\n",
      "epoch 4965\n",
      "test_train\n",
      "train mean loss=62384.461197916666\n",
      "test_test\n",
      "test mean loss=88307.8203125\n",
      "fin save.\n",
      "epoch 4966\n",
      "test_train\n",
      "train mean loss=61896.933854166666\n",
      "test_test\n",
      "test mean loss=88513.07421875\n",
      "fin save.\n",
      "epoch 4967\n",
      "test_train\n",
      "train mean loss=62473.136458333334\n",
      "test_test\n",
      "test mean loss=88332.2578125\n",
      "fin save.\n",
      "epoch 4968\n",
      "test_train\n",
      "train mean loss=62494.49140625\n",
      "test_test\n",
      "test mean loss=88076.71484375\n",
      "fin save.\n",
      "epoch 4969\n",
      "test_train\n",
      "train mean loss=62048.19973958333\n",
      "test_test\n",
      "test mean loss=88030.328125\n",
      "fin save.\n",
      "epoch 4970\n",
      "test_train\n",
      "train mean loss=61673.602864583336\n",
      "test_test\n",
      "test mean loss=87962.9765625\n",
      "fin save.\n",
      "epoch 4971\n",
      "test_train\n",
      "train mean loss=61958.09322916667\n",
      "test_test\n",
      "test mean loss=88180.0859375\n",
      "fin save.\n",
      "epoch 4972\n",
      "test_train\n",
      "train mean loss=63081.27239583333\n",
      "test_test\n",
      "test mean loss=88073.921875\n",
      "fin save.\n",
      "epoch 4973\n",
      "test_train\n",
      "train mean loss=62522.13684895833\n",
      "test_test\n",
      "test mean loss=87968.71875\n",
      "fin save.\n",
      "epoch 4974\n",
      "test_train\n",
      "train mean loss=62246.73671875\n",
      "test_test\n",
      "test mean loss=88238.34375\n",
      "fin save.\n",
      "epoch 4975\n",
      "test_train\n",
      "train mean loss=62638.910546875\n",
      "test_test\n",
      "test mean loss=88455.90234375\n",
      "fin save.\n",
      "epoch 4976\n",
      "test_train\n",
      "train mean loss=62021.3140625\n",
      "test_test\n",
      "test mean loss=88420.81640625\n",
      "fin save.\n",
      "epoch 4977\n",
      "test_train\n",
      "train mean loss=61565.99010416667\n",
      "test_test\n",
      "test mean loss=88317.0234375\n",
      "fin save.\n",
      "epoch 4978\n",
      "test_train\n",
      "train mean loss=61838.216015625\n",
      "test_test\n",
      "test mean loss=88632.671875\n",
      "fin save.\n",
      "epoch 4979\n",
      "test_train\n",
      "train mean loss=62346.28411458333\n",
      "test_test\n",
      "test mean loss=88560.296875\n",
      "fin save.\n",
      "epoch 4980\n",
      "test_train\n",
      "train mean loss=62383.87708333333\n",
      "test_test\n",
      "test mean loss=88623.72265625\n",
      "fin save.\n",
      "epoch 4981\n",
      "test_train\n",
      "train mean loss=62562.24427083333\n",
      "test_test\n",
      "test mean loss=88401.85546875\n",
      "fin save.\n",
      "epoch 4982\n",
      "test_train\n",
      "train mean loss=62041.07369791667\n",
      "test_test\n",
      "test mean loss=88698.83203125\n",
      "fin save.\n",
      "epoch 4983\n",
      "test_train\n",
      "train mean loss=63342.59296875\n",
      "test_test\n",
      "test mean loss=88508.0078125\n",
      "fin save.\n",
      "epoch 4984\n",
      "test_train\n",
      "train mean loss=62378.30546875\n",
      "test_test\n",
      "test mean loss=88539.41796875\n",
      "fin save.\n",
      "epoch 4985\n",
      "test_train\n",
      "train mean loss=62539.004166666666\n",
      "test_test\n",
      "test mean loss=88398.05859375\n",
      "fin save.\n",
      "epoch 4986\n",
      "test_train\n",
      "train mean loss=62252.56171875\n",
      "test_test\n",
      "test mean loss=88472.921875\n",
      "fin save.\n",
      "epoch 4987\n",
      "test_train\n",
      "train mean loss=62781.924479166664\n",
      "test_test\n",
      "test mean loss=88521.85546875\n",
      "fin save.\n",
      "epoch 4988\n",
      "test_train\n",
      "train mean loss=62755.908854166664\n",
      "test_test\n",
      "test mean loss=88349.5234375\n",
      "fin save.\n",
      "epoch 4989\n",
      "test_train\n",
      "train mean loss=63384.20989583333\n",
      "test_test\n",
      "test mean loss=88392.66015625\n",
      "fin save.\n",
      "epoch 4990\n",
      "test_train\n",
      "train mean loss=62359.57526041667\n",
      "test_test\n",
      "test mean loss=88209.25390625\n",
      "fin save.\n",
      "epoch 4991\n",
      "test_train\n",
      "train mean loss=62924.7546875\n",
      "test_test\n",
      "test mean loss=88045.9765625\n",
      "fin save.\n",
      "epoch 4992\n",
      "test_train\n",
      "train mean loss=62598.868489583336\n",
      "test_test\n",
      "test mean loss=88169.2890625\n",
      "fin save.\n",
      "epoch 4993\n",
      "test_train\n",
      "train mean loss=61495.796614583334\n",
      "test_test\n",
      "test mean loss=88214.53125\n",
      "fin save.\n",
      "epoch 4994\n",
      "test_train\n",
      "train mean loss=63082.61041666667\n",
      "test_test\n",
      "test mean loss=88686.2421875\n",
      "fin save.\n",
      "epoch 4995\n",
      "test_train\n",
      "train mean loss=61300.30130208333\n",
      "test_test\n",
      "test mean loss=88538.80078125\n",
      "fin save.\n",
      "epoch 4996\n",
      "test_train\n",
      "train mean loss=61907.39296875\n",
      "test_test\n",
      "test mean loss=88065.0546875\n",
      "fin save.\n",
      "epoch 4997\n",
      "test_train\n",
      "train mean loss=62753.6390625\n",
      "test_test\n",
      "test mean loss=88589.13671875\n",
      "fin save.\n",
      "epoch 4998\n",
      "test_train\n",
      "train mean loss=61468.066666666666\n",
      "test_test\n",
      "test mean loss=88676.66796875\n",
      "fin save.\n",
      "epoch 4999\n",
      "test_train\n",
      "train mean loss=61661.6703125\n",
      "test_test\n",
      "test mean loss=88561.734375\n",
      "fin save.\n",
      "epoch 5000\n",
      "test_train\n",
      "train mean loss=61587.3078125\n",
      "test_test\n",
      "test mean loss=88763.8203125\n",
      "fin save.\n",
      "epoch 5001\n",
      "test_train\n",
      "train mean loss=61737.590625\n",
      "test_test\n",
      "test mean loss=88598.44921875\n",
      "fin save.\n",
      "epoch 5002\n",
      "test_train\n",
      "train mean loss=62169.93177083333\n",
      "test_test\n",
      "test mean loss=88690.51171875\n",
      "fin save.\n",
      "epoch 5003\n",
      "test_train\n",
      "train mean loss=62607.241536458336\n",
      "test_test\n",
      "test mean loss=88763.75\n",
      "fin save.\n",
      "epoch 5004\n",
      "test_train\n",
      "train mean loss=62706.63125\n",
      "test_test\n",
      "test mean loss=88806.796875\n",
      "fin save.\n",
      "epoch 5005\n",
      "test_train\n",
      "train mean loss=61374.01484375\n",
      "test_test\n",
      "test mean loss=88642.57421875\n",
      "fin save.\n",
      "epoch 5006\n",
      "test_train\n",
      "train mean loss=62483.835286458336\n",
      "test_test\n",
      "test mean loss=88357.5703125\n",
      "fin save.\n",
      "epoch 5007\n",
      "test_train\n",
      "train mean loss=61308.66640625\n",
      "test_test\n",
      "test mean loss=88575.6640625\n",
      "fin save.\n",
      "epoch 5008\n",
      "test_train\n",
      "train mean loss=61691.192708333336\n",
      "test_test\n",
      "test mean loss=88380.5703125\n",
      "fin save.\n",
      "epoch 5009\n",
      "test_train\n",
      "train mean loss=62353.72838541667\n",
      "test_test\n",
      "test mean loss=88495.14453125\n",
      "fin save.\n",
      "epoch 5010\n",
      "test_train\n",
      "train mean loss=62700.082291666666\n",
      "test_test\n",
      "test mean loss=88571.296875\n",
      "fin save.\n",
      "epoch 5011\n",
      "test_train\n",
      "train mean loss=61643.66328125\n",
      "test_test\n",
      "test mean loss=88192.46484375\n",
      "fin save.\n",
      "epoch 5012\n",
      "test_train\n",
      "train mean loss=61658.576822916664\n",
      "test_test\n",
      "test mean loss=88636.4296875\n",
      "fin save.\n",
      "epoch 5013\n",
      "test_train\n",
      "train mean loss=62075.673046875\n",
      "test_test\n",
      "test mean loss=88649.4765625\n",
      "fin save.\n",
      "epoch 5014\n",
      "test_train\n",
      "train mean loss=62287.47552083333\n",
      "test_test\n",
      "test mean loss=88462.04296875\n",
      "fin save.\n",
      "epoch 5015\n",
      "test_train\n",
      "train mean loss=61443.49427083333\n",
      "test_test\n",
      "test mean loss=88306.5703125\n",
      "fin save.\n",
      "epoch 5016\n",
      "test_train\n",
      "train mean loss=62009.976302083334\n",
      "test_test\n",
      "test mean loss=88357.0078125\n",
      "fin save.\n",
      "epoch 5017\n",
      "test_train\n",
      "train mean loss=62518.70690104167\n",
      "test_test\n",
      "test mean loss=88308.87109375\n",
      "fin save.\n",
      "epoch 5018\n",
      "test_train\n",
      "train mean loss=61903.40130208333\n",
      "test_test\n",
      "test mean loss=88461.1796875\n",
      "fin save.\n",
      "epoch 5019\n",
      "test_train\n",
      "train mean loss=62104.16744791667\n",
      "test_test\n",
      "test mean loss=88177.0234375\n",
      "fin save.\n",
      "epoch 5020\n",
      "test_train\n",
      "train mean loss=61458.08984375\n",
      "test_test\n",
      "test mean loss=88171.1640625\n",
      "fin save.\n",
      "epoch 5021\n",
      "test_train\n",
      "train mean loss=62004.5140625\n",
      "test_test\n",
      "test mean loss=88008.39453125\n",
      "fin save.\n",
      "epoch 5022\n",
      "test_train\n",
      "train mean loss=62347.307291666664\n",
      "test_test\n",
      "test mean loss=88040.03515625\n",
      "fin save.\n",
      "epoch 5023\n",
      "test_train\n",
      "train mean loss=63145.88463541667\n",
      "test_test\n",
      "test mean loss=88017.421875\n",
      "fin save.\n",
      "epoch 5024\n",
      "test_train\n",
      "train mean loss=61986.74765625\n",
      "test_test\n",
      "test mean loss=88003.24609375\n",
      "fin save.\n",
      "epoch 5025\n",
      "test_train\n",
      "train mean loss=61547.63619791667\n",
      "test_test\n",
      "test mean loss=87903.1171875\n",
      "fin save.\n",
      "epoch 5026\n",
      "test_train\n",
      "train mean loss=62438.4140625\n",
      "test_test\n",
      "test mean loss=87980.08984375\n",
      "fin save.\n",
      "epoch 5027\n",
      "test_train\n",
      "train mean loss=61955.956770833334\n",
      "test_test\n",
      "test mean loss=88012.93359375\n",
      "fin save.\n",
      "epoch 5028\n",
      "test_train\n",
      "train mean loss=62631.216796875\n",
      "test_test\n",
      "test mean loss=88109.43359375\n",
      "fin save.\n",
      "epoch 5029\n",
      "test_train\n",
      "train mean loss=62067.37109375\n",
      "test_test\n",
      "test mean loss=88545.16015625\n",
      "fin save.\n",
      "epoch 5030\n",
      "test_train\n",
      "train mean loss=62247.13098958333\n",
      "test_test\n",
      "test mean loss=88374.609375\n",
      "fin save.\n",
      "epoch 5031\n",
      "test_train\n",
      "train mean loss=62204.63489583333\n",
      "test_test\n",
      "test mean loss=88271.078125\n",
      "fin save.\n",
      "epoch 5032\n",
      "test_train\n",
      "train mean loss=61812.639322916664\n",
      "test_test\n",
      "test mean loss=87962.078125\n",
      "fin save.\n",
      "epoch 5033\n",
      "test_train\n",
      "train mean loss=62449.31848958333\n",
      "test_test\n",
      "test mean loss=87990.890625\n",
      "fin save.\n",
      "epoch 5034\n",
      "test_train\n",
      "train mean loss=62417.24166666667\n",
      "test_test\n",
      "test mean loss=88046.078125\n",
      "fin save.\n",
      "epoch 5035\n",
      "test_train\n",
      "train mean loss=62117.81588541667\n",
      "test_test\n",
      "test mean loss=88014.421875\n",
      "fin save.\n",
      "epoch 5036\n",
      "test_train\n",
      "train mean loss=63077.221875\n",
      "test_test\n",
      "test mean loss=88202.36328125\n",
      "fin save.\n",
      "epoch 5037\n",
      "test_train\n",
      "train mean loss=62034.035416666666\n",
      "test_test\n",
      "test mean loss=88263.4609375\n",
      "fin save.\n",
      "epoch 5038\n",
      "test_train\n",
      "train mean loss=62020.895833333336\n",
      "test_test\n",
      "test mean loss=87871.140625\n",
      "fin save.\n",
      "epoch 5039\n",
      "test_train\n",
      "train mean loss=62516.088671875\n",
      "test_test\n",
      "test mean loss=87815.9609375\n",
      "fin save.\n",
      "epoch 5040\n",
      "test_train\n",
      "train mean loss=60930.073046875\n",
      "test_test\n",
      "test mean loss=87487.8125\n",
      "fin save.\n",
      "epoch 5041\n",
      "test_train\n",
      "train mean loss=61400.9109375\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=87485.33203125\n",
      "fin save.\n",
      "epoch 5042\n",
      "test_train\n",
      "train mean loss=62729.2578125\n",
      "test_test\n",
      "test mean loss=87140.1640625\n",
      "fin save.\n",
      "epoch 5043\n",
      "test_train\n",
      "train mean loss=61339.438151041664\n",
      "test_test\n",
      "test mean loss=86441.48046875\n",
      "fin save.\n",
      "epoch 5044\n",
      "test_train\n",
      "train mean loss=62415.946875\n",
      "test_test\n",
      "test mean loss=86633.01171875\n",
      "fin save.\n",
      "epoch 5045\n",
      "test_train\n",
      "train mean loss=62764.85247395833\n",
      "test_test\n",
      "test mean loss=86483.8203125\n",
      "fin save.\n",
      "epoch 5046\n",
      "test_train\n",
      "train mean loss=62277.59453125\n",
      "test_test\n",
      "test mean loss=86511.58984375\n",
      "fin save.\n",
      "epoch 5047\n",
      "test_train\n",
      "train mean loss=61591.901041666664\n",
      "test_test\n",
      "test mean loss=86406.19140625\n",
      "fin save.\n",
      "epoch 5048\n",
      "test_train\n",
      "train mean loss=62390.726171875\n",
      "test_test\n",
      "test mean loss=86400.0390625\n",
      "fin save.\n",
      "epoch 5049\n",
      "test_train\n",
      "train mean loss=61558.838541666664\n",
      "test_test\n",
      "test mean loss=86384.05078125\n",
      "fin save.\n",
      "epoch 5050\n",
      "test_train\n",
      "train mean loss=61858.09427083333\n",
      "test_test\n",
      "test mean loss=86513.05078125\n",
      "fin save.\n",
      "epoch 5051\n",
      "test_train\n",
      "train mean loss=62610.622265625\n",
      "test_test\n",
      "test mean loss=86468.61328125\n",
      "fin save.\n",
      "epoch 5052\n",
      "test_train\n",
      "train mean loss=63352.25572916667\n",
      "test_test\n",
      "test mean loss=86520.5859375\n",
      "fin save.\n",
      "epoch 5053\n",
      "test_train\n",
      "train mean loss=61785.970963541666\n",
      "test_test\n",
      "test mean loss=86438.63671875\n",
      "fin save.\n",
      "epoch 5054\n",
      "test_train\n",
      "train mean loss=62108.55572916667\n",
      "test_test\n",
      "test mean loss=86634.2890625\n",
      "fin save.\n",
      "epoch 5055\n",
      "test_train\n",
      "train mean loss=61661.89505208333\n",
      "test_test\n",
      "test mean loss=86451.3046875\n",
      "fin save.\n",
      "epoch 5056\n",
      "test_train\n",
      "train mean loss=61972.8828125\n",
      "test_test\n",
      "test mean loss=86563.265625\n",
      "fin save.\n",
      "epoch 5057\n",
      "test_train\n",
      "train mean loss=62963.654296875\n",
      "test_test\n",
      "test mean loss=87368.41796875\n",
      "fin save.\n",
      "epoch 5058\n",
      "test_train\n",
      "train mean loss=62550.53177083333\n",
      "test_test\n",
      "test mean loss=87470.015625\n",
      "fin save.\n",
      "epoch 5059\n",
      "test_train\n",
      "train mean loss=61610.9515625\n",
      "test_test\n",
      "test mean loss=87363.2421875\n",
      "fin save.\n",
      "epoch 5060\n",
      "test_train\n",
      "train mean loss=62041.35494791667\n",
      "test_test\n",
      "test mean loss=86937.4609375\n",
      "fin save.\n",
      "epoch 5061\n",
      "test_train\n",
      "train mean loss=62190.38776041667\n",
      "test_test\n",
      "test mean loss=87272.40234375\n",
      "fin save.\n",
      "epoch 5062\n",
      "test_train\n",
      "train mean loss=62467.43463541667\n",
      "test_test\n",
      "test mean loss=87246.21484375\n",
      "fin save.\n",
      "epoch 5063\n",
      "test_train\n",
      "train mean loss=62364.213541666664\n",
      "test_test\n",
      "test mean loss=87258.48828125\n",
      "fin save.\n",
      "epoch 5064\n",
      "test_train\n",
      "train mean loss=63038.90026041667\n",
      "test_test\n",
      "test mean loss=87236.8046875\n",
      "fin save.\n",
      "epoch 5065\n",
      "test_train\n",
      "train mean loss=62445.555338541664\n",
      "test_test\n",
      "test mean loss=87872.734375\n",
      "fin save.\n",
      "epoch 5066\n",
      "test_train\n",
      "train mean loss=61684.95703125\n",
      "test_test\n",
      "test mean loss=87836.7109375\n",
      "fin save.\n",
      "epoch 5067\n",
      "test_train\n",
      "train mean loss=62218.178385416664\n",
      "test_test\n",
      "test mean loss=87899.44140625\n",
      "fin save.\n",
      "epoch 5068\n",
      "test_train\n",
      "train mean loss=62195.86015625\n",
      "test_test\n",
      "test mean loss=87773.6875\n",
      "fin save.\n",
      "epoch 5069\n",
      "test_train\n",
      "train mean loss=62085.222395833334\n",
      "test_test\n",
      "test mean loss=87735.98046875\n",
      "fin save.\n",
      "epoch 5070\n",
      "test_train\n",
      "train mean loss=61544.41328125\n",
      "test_test\n",
      "test mean loss=87803.8515625\n",
      "fin save.\n",
      "epoch 5071\n",
      "test_train\n",
      "train mean loss=61386.571484375\n",
      "test_test\n",
      "test mean loss=87662.95703125\n",
      "fin save.\n",
      "epoch 5072\n",
      "test_train\n",
      "train mean loss=61893.53229166667\n",
      "test_test\n",
      "test mean loss=87949.14453125\n",
      "fin save.\n",
      "epoch 5073\n",
      "test_train\n",
      "train mean loss=62707.587239583336\n",
      "test_test\n",
      "test mean loss=87921.3984375\n",
      "fin save.\n",
      "epoch 5074\n",
      "test_train\n",
      "train mean loss=63481.6578125\n",
      "test_test\n",
      "test mean loss=88011.7890625\n",
      "fin save.\n",
      "epoch 5075\n",
      "test_train\n",
      "train mean loss=61627.81822916667\n",
      "test_test\n",
      "test mean loss=88227.0234375\n",
      "fin save.\n",
      "epoch 5076\n",
      "test_train\n",
      "train mean loss=61730.62942708333\n",
      "test_test\n",
      "test mean loss=88383.01171875\n",
      "fin save.\n",
      "epoch 5077\n",
      "test_train\n",
      "train mean loss=62618.215234375\n",
      "test_test\n",
      "test mean loss=88244.05859375\n",
      "fin save.\n",
      "epoch 5078\n",
      "test_train\n",
      "train mean loss=62028.335677083334\n",
      "test_test\n",
      "test mean loss=87997.88671875\n",
      "fin save.\n",
      "epoch 5079\n",
      "test_train\n",
      "train mean loss=61588.9734375\n",
      "test_test\n",
      "test mean loss=88189.734375\n",
      "fin save.\n",
      "epoch 5080\n",
      "test_train\n",
      "train mean loss=61733.47708333333\n",
      "test_test\n",
      "test mean loss=88344.6640625\n",
      "fin save.\n",
      "epoch 5081\n",
      "test_train\n",
      "train mean loss=62346.00234375\n",
      "test_test\n",
      "test mean loss=88234.51953125\n",
      "fin save.\n",
      "epoch 5082\n",
      "test_train\n",
      "train mean loss=62587.90677083333\n",
      "test_test\n",
      "test mean loss=88218.8828125\n",
      "fin save.\n",
      "epoch 5083\n",
      "test_train\n",
      "train mean loss=61456.53984375\n",
      "test_test\n",
      "test mean loss=88462.21875\n",
      "fin save.\n",
      "epoch 5084\n",
      "test_train\n",
      "train mean loss=62956.80859375\n",
      "test_test\n",
      "test mean loss=88359.76953125\n",
      "fin save.\n",
      "epoch 5085\n",
      "test_train\n",
      "train mean loss=62527.18046875\n",
      "test_test\n",
      "test mean loss=88302.95703125\n",
      "fin save.\n",
      "epoch 5086\n",
      "test_train\n",
      "train mean loss=61631.87291666667\n",
      "test_test\n",
      "test mean loss=88075.390625\n",
      "fin save.\n",
      "epoch 5087\n",
      "test_train\n",
      "train mean loss=62608.941145833334\n",
      "test_test\n",
      "test mean loss=88044.609375\n",
      "fin save.\n",
      "epoch 5088\n",
      "test_train\n",
      "train mean loss=61718.84921875\n",
      "test_test\n",
      "test mean loss=88017.54296875\n",
      "fin save.\n",
      "epoch 5089\n",
      "test_train\n",
      "train mean loss=61422.84583333333\n",
      "test_test\n",
      "test mean loss=87870.3828125\n",
      "fin save.\n",
      "epoch 5090\n",
      "test_train\n",
      "train mean loss=62292.565625\n",
      "test_test\n",
      "test mean loss=87671.8515625\n",
      "fin save.\n",
      "epoch 5091\n",
      "test_train\n",
      "train mean loss=61549.94921875\n",
      "test_test\n",
      "test mean loss=87994.0625\n",
      "fin save.\n",
      "epoch 5092\n",
      "test_train\n",
      "train mean loss=62370.95911458333\n",
      "test_test\n",
      "test mean loss=87924.40625\n",
      "fin save.\n",
      "epoch 5093\n",
      "test_train\n",
      "train mean loss=63551.47799479167\n",
      "test_test\n",
      "test mean loss=87934.14453125\n",
      "fin save.\n",
      "epoch 5094\n",
      "test_train\n",
      "train mean loss=61871.390625\n",
      "test_test\n",
      "test mean loss=87894.875\n",
      "fin save.\n",
      "epoch 5095\n",
      "test_train\n",
      "train mean loss=62109.4109375\n",
      "test_test\n",
      "test mean loss=88095.5859375\n",
      "fin save.\n",
      "epoch 5096\n",
      "test_train\n",
      "train mean loss=61953.62786458333\n",
      "test_test\n",
      "test mean loss=87971.83984375\n",
      "fin save.\n",
      "epoch 5097\n",
      "test_train\n",
      "train mean loss=62035.49322916667\n",
      "test_test\n",
      "test mean loss=87927.1484375\n",
      "fin save.\n",
      "epoch 5098\n",
      "test_train\n",
      "train mean loss=62476.285546875\n",
      "test_test\n",
      "test mean loss=87832.83984375\n",
      "fin save.\n",
      "epoch 5099\n",
      "test_train\n",
      "train mean loss=62065.16953125\n",
      "test_test\n",
      "test mean loss=87709.55859375\n",
      "fin save.\n",
      "epoch 5100\n",
      "test_train\n",
      "train mean loss=62415.494401041666\n",
      "test_test\n",
      "test mean loss=88145.42578125\n",
      "fin save.\n",
      "epoch 5101\n",
      "test_train\n",
      "train mean loss=61769.238541666666\n",
      "test_test\n",
      "test mean loss=87926.640625\n",
      "fin save.\n",
      "epoch 5102\n",
      "test_train\n",
      "train mean loss=62375.337239583336\n",
      "test_test\n",
      "test mean loss=88083.609375\n",
      "fin save.\n",
      "epoch 5103\n",
      "test_train\n",
      "train mean loss=61746.0390625\n",
      "test_test\n",
      "test mean loss=88102.57421875\n",
      "fin save.\n",
      "epoch 5104\n",
      "test_train\n",
      "train mean loss=61519.64830729167\n",
      "test_test\n",
      "test mean loss=88070.046875\n",
      "fin save.\n",
      "epoch 5105\n",
      "test_train\n",
      "train mean loss=61925.36236979167\n",
      "test_test\n",
      "test mean loss=87719.8125\n",
      "fin save.\n",
      "epoch 5106\n",
      "test_train\n",
      "train mean loss=62373.80911458333\n",
      "test_test\n",
      "test mean loss=87893.453125\n",
      "fin save.\n",
      "epoch 5107\n",
      "test_train\n",
      "train mean loss=62450.56692708333\n",
      "test_test\n",
      "test mean loss=87632.9140625\n",
      "fin save.\n",
      "epoch 5108\n",
      "test_train\n",
      "train mean loss=62015.2875\n",
      "test_test\n",
      "test mean loss=87696.0234375\n",
      "fin save.\n",
      "epoch 5109\n",
      "test_train\n",
      "train mean loss=62320.884375\n",
      "test_test\n",
      "test mean loss=87819.58203125\n",
      "fin save.\n",
      "epoch 5110\n",
      "test_train\n",
      "train mean loss=61690.11145833333\n",
      "test_test\n",
      "test mean loss=87780.8203125\n",
      "fin save.\n",
      "epoch 5111\n",
      "test_train\n",
      "train mean loss=61829.465234375\n",
      "test_test\n",
      "test mean loss=87639.1015625\n",
      "fin save.\n",
      "epoch 5112\n",
      "test_train\n",
      "train mean loss=62371.89557291667\n",
      "test_test\n",
      "test mean loss=87797.29296875\n",
      "fin save.\n",
      "epoch 5113\n",
      "test_train\n",
      "train mean loss=61441.95950520833\n",
      "test_test\n",
      "test mean loss=87829.0703125\n",
      "fin save.\n",
      "epoch 5114\n",
      "test_train\n",
      "train mean loss=61757.861979166664\n",
      "test_test\n",
      "test mean loss=87835.82421875\n",
      "fin save.\n",
      "epoch 5115\n",
      "test_train\n",
      "train mean loss=62570.81783854167\n",
      "test_test\n",
      "test mean loss=88169.89453125\n",
      "fin save.\n",
      "epoch 5116\n",
      "test_train\n",
      "train mean loss=62459.28671875\n",
      "test_test\n",
      "test mean loss=88054.12890625\n",
      "fin save.\n",
      "epoch 5117\n",
      "test_train\n",
      "train mean loss=62314.12317708333\n",
      "test_test\n",
      "test mean loss=87875.10546875\n",
      "fin save.\n",
      "epoch 5118\n",
      "test_train\n",
      "train mean loss=63064.69036458333\n",
      "test_test\n",
      "test mean loss=88061.18359375\n",
      "fin save.\n",
      "epoch 5119\n",
      "test_train\n",
      "train mean loss=62264.19283854167\n",
      "test_test\n",
      "test mean loss=88134.1875\n",
      "fin save.\n",
      "epoch 5120\n",
      "test_train\n",
      "train mean loss=61257.69427083333\n",
      "test_test\n",
      "test mean loss=88220.87890625\n",
      "fin save.\n",
      "epoch 5121\n",
      "test_train\n",
      "train mean loss=63021.48033854167\n",
      "test_test\n",
      "test mean loss=88204.8125\n",
      "fin save.\n",
      "epoch 5122\n",
      "test_train\n",
      "train mean loss=61014.863020833334\n",
      "test_test\n",
      "test mean loss=87968.671875\n",
      "fin save.\n",
      "epoch 5123\n",
      "test_train\n",
      "train mean loss=61884.77916666667\n",
      "test_test\n",
      "test mean loss=88012.6640625\n",
      "fin save.\n",
      "epoch 5124\n",
      "test_train\n",
      "train mean loss=62335.269791666666\n",
      "test_test\n",
      "test mean loss=88103.44140625\n",
      "fin save.\n",
      "epoch 5125\n",
      "test_train\n",
      "train mean loss=62730.490885416664\n",
      "test_test\n",
      "test mean loss=87866.15234375\n",
      "fin save.\n",
      "epoch 5126\n",
      "test_train\n",
      "train mean loss=62503.1984375\n",
      "test_test\n",
      "test mean loss=87965.51953125\n",
      "fin save.\n",
      "epoch 5127\n",
      "test_train\n",
      "train mean loss=61540.125651041664\n",
      "test_test\n",
      "test mean loss=88115.5859375\n",
      "fin save.\n",
      "epoch 5128\n",
      "test_train\n",
      "train mean loss=61729.72669270833\n",
      "test_test\n",
      "test mean loss=88175.23828125\n",
      "fin save.\n",
      "epoch 5129\n",
      "test_train\n",
      "train mean loss=62230.19583333333\n",
      "test_test\n",
      "test mean loss=88132.265625\n",
      "fin save.\n",
      "epoch 5130\n",
      "test_train\n",
      "train mean loss=61821.526692708336\n",
      "test_test\n",
      "test mean loss=88129.05859375\n",
      "fin save.\n",
      "epoch 5131\n",
      "test_train\n",
      "train mean loss=61641.40625\n",
      "test_test\n",
      "test mean loss=88008.6015625\n",
      "fin save.\n",
      "epoch 5132\n",
      "test_train\n",
      "train mean loss=62366.93046875\n",
      "test_test\n",
      "test mean loss=88192.8984375\n",
      "fin save.\n",
      "epoch 5133\n",
      "test_train\n",
      "train mean loss=62884.589583333334\n",
      "test_test\n",
      "test mean loss=88035.94921875\n",
      "fin save.\n",
      "epoch 5134\n",
      "test_train\n",
      "train mean loss=62767.176171875\n",
      "test_test\n",
      "test mean loss=87970.16015625\n",
      "fin save.\n",
      "epoch 5135\n",
      "test_train\n",
      "train mean loss=61898.20598958333\n",
      "test_test\n",
      "test mean loss=88022.02734375\n",
      "fin save.\n",
      "epoch 5136\n",
      "test_train\n",
      "train mean loss=61492.31979166667\n",
      "test_test\n",
      "test mean loss=87857.21484375\n",
      "fin save.\n",
      "epoch 5137\n",
      "test_train\n",
      "train mean loss=62578.505078125\n",
      "test_test\n",
      "test mean loss=87738.01953125\n",
      "fin save.\n",
      "epoch 5138\n",
      "test_train\n",
      "train mean loss=61325.36380208333\n",
      "test_test\n",
      "test mean loss=87766.63671875\n",
      "fin save.\n",
      "epoch 5139\n",
      "test_train\n",
      "train mean loss=62273.51901041667\n",
      "test_test\n",
      "test mean loss=87804.609375\n",
      "fin save.\n",
      "epoch 5140\n",
      "test_train\n",
      "train mean loss=62011.04244791667\n",
      "test_test\n",
      "test mean loss=87904.66796875\n",
      "fin save.\n",
      "epoch 5141\n",
      "test_train\n",
      "train mean loss=61598.7859375\n",
      "test_test\n",
      "test mean loss=87656.6328125\n",
      "fin save.\n",
      "epoch 5142\n",
      "test_train\n",
      "train mean loss=62532.29205729167\n",
      "test_test\n",
      "test mean loss=87982.34375\n",
      "fin save.\n",
      "epoch 5143\n",
      "test_train\n",
      "train mean loss=61911.77265625\n",
      "test_test\n",
      "test mean loss=87744.70703125\n",
      "fin save.\n",
      "epoch 5144\n",
      "test_train\n",
      "train mean loss=61862.308854166666\n",
      "test_test\n",
      "test mean loss=87784.3046875\n",
      "fin save.\n",
      "epoch 5145\n",
      "test_train\n",
      "train mean loss=60767.01276041667\n",
      "test_test\n",
      "test mean loss=87740.4609375\n",
      "fin save.\n",
      "epoch 5146\n",
      "test_train\n",
      "train mean loss=62580.283984375\n",
      "test_test\n",
      "test mean loss=87789.5859375\n",
      "fin save.\n",
      "epoch 5147\n",
      "test_train\n",
      "train mean loss=62288.025\n",
      "test_test\n",
      "test mean loss=87985.36328125\n",
      "fin save.\n",
      "epoch 5148\n",
      "test_train\n",
      "train mean loss=61473.041666666664\n",
      "test_test\n",
      "test mean loss=87925.51171875\n",
      "fin save.\n",
      "epoch 5149\n",
      "test_train\n",
      "train mean loss=61927.87265625\n",
      "test_test\n",
      "test mean loss=88062.8046875\n",
      "fin save.\n",
      "epoch 5150\n",
      "test_train\n",
      "train mean loss=62038.71484375\n",
      "test_test\n",
      "test mean loss=88038.4140625\n",
      "fin save.\n",
      "epoch 5151\n",
      "test_train\n",
      "train mean loss=61011.846354166664\n",
      "test_test\n",
      "test mean loss=88189.015625\n",
      "fin save.\n",
      "epoch 5152\n",
      "test_train\n",
      "train mean loss=61753.454296875\n",
      "test_test\n",
      "test mean loss=88053.484375\n",
      "fin save.\n",
      "epoch 5153\n",
      "test_train\n",
      "train mean loss=61880.99518229167\n",
      "test_test\n",
      "test mean loss=87727.4453125\n",
      "fin save.\n",
      "epoch 5154\n",
      "test_train\n",
      "train mean loss=61823.00598958333\n",
      "test_test\n",
      "test mean loss=88085.88671875\n",
      "fin save.\n",
      "epoch 5155\n",
      "test_train\n",
      "train mean loss=61632.195572916666\n",
      "test_test\n",
      "test mean loss=87963.15625\n",
      "fin save.\n",
      "epoch 5156\n",
      "test_train\n",
      "train mean loss=61456.832421875\n",
      "test_test\n",
      "test mean loss=87973.9609375\n",
      "fin save.\n",
      "epoch 5157\n",
      "test_train\n",
      "train mean loss=61664.83346354167\n",
      "test_test\n",
      "test mean loss=87867.62890625\n",
      "fin save.\n",
      "epoch 5158\n",
      "test_train\n",
      "train mean loss=62605.10885416667\n",
      "test_test\n",
      "test mean loss=88042.3984375\n",
      "fin save.\n",
      "epoch 5159\n",
      "test_train\n",
      "train mean loss=61143.816796875\n",
      "test_test\n",
      "test mean loss=87970.6796875\n",
      "fin save.\n",
      "epoch 5160\n",
      "test_train\n",
      "train mean loss=61361.42395833333\n",
      "test_test\n",
      "test mean loss=88027.55859375\n",
      "fin save.\n",
      "epoch 5161\n",
      "test_train\n",
      "train mean loss=62579.176041666666\n",
      "test_test\n",
      "test mean loss=88045.49609375\n",
      "fin save.\n",
      "epoch 5162\n",
      "test_train\n",
      "train mean loss=61076.390885416666\n",
      "test_test\n",
      "test mean loss=88152.734375\n",
      "fin save.\n",
      "epoch 5163\n",
      "test_train\n",
      "train mean loss=61520.74166666667\n",
      "test_test\n",
      "test mean loss=88274.3671875\n",
      "fin save.\n",
      "epoch 5164\n",
      "test_train\n",
      "train mean loss=61786.81822916667\n",
      "test_test\n",
      "test mean loss=88126.953125\n",
      "fin save.\n",
      "epoch 5165\n",
      "test_train\n",
      "train mean loss=61658.140885416666\n",
      "test_test\n",
      "test mean loss=88184.8984375\n",
      "fin save.\n",
      "epoch 5166\n",
      "test_train\n",
      "train mean loss=61644.59856770833\n",
      "test_test\n",
      "test mean loss=88128.21875\n",
      "fin save.\n",
      "epoch 5167\n",
      "test_train\n",
      "train mean loss=61715.48880208333\n",
      "test_test\n",
      "test mean loss=88013.546875\n",
      "fin save.\n",
      "epoch 5168\n",
      "test_train\n",
      "train mean loss=62154.62395833333\n",
      "test_test\n",
      "test mean loss=88050.35546875\n",
      "fin save.\n",
      "epoch 5169\n",
      "test_train\n",
      "train mean loss=62115.55625\n",
      "test_test\n",
      "test mean loss=87799.1484375\n",
      "fin save.\n",
      "epoch 5170\n",
      "test_train\n",
      "train mean loss=62409.519791666666\n",
      "test_test\n",
      "test mean loss=88191.734375\n",
      "fin save.\n",
      "epoch 5171\n",
      "test_train\n",
      "train mean loss=62640.99947916667\n",
      "test_test\n",
      "test mean loss=88032.75\n",
      "fin save.\n",
      "epoch 5172\n",
      "test_train\n",
      "train mean loss=61249.26901041667\n",
      "test_test\n",
      "test mean loss=87983.90234375\n",
      "fin save.\n",
      "epoch 5173\n",
      "test_train\n",
      "train mean loss=62059.30755208333\n",
      "test_test\n",
      "test mean loss=87826.7109375\n",
      "fin save.\n",
      "epoch 5174\n",
      "test_train\n",
      "train mean loss=62256.51640625\n",
      "test_test\n",
      "test mean loss=88003.28515625\n",
      "fin save.\n",
      "epoch 5175\n",
      "test_train\n",
      "train mean loss=61229.5453125\n",
      "test_test\n",
      "test mean loss=87955.4921875\n",
      "fin save.\n",
      "epoch 5176\n",
      "test_train\n",
      "train mean loss=61028.89635416667\n",
      "test_test\n",
      "test mean loss=87967.0546875\n",
      "fin save.\n",
      "epoch 5177\n",
      "test_train\n",
      "train mean loss=62110.425\n",
      "test_test\n",
      "test mean loss=88201.35546875\n",
      "fin save.\n",
      "epoch 5178\n",
      "test_train\n",
      "train mean loss=61688.55859375\n",
      "test_test\n",
      "test mean loss=88194.91015625\n",
      "fin save.\n",
      "epoch 5179\n",
      "test_train\n",
      "train mean loss=62228.26575520833\n",
      "test_test\n",
      "test mean loss=88360.2421875\n",
      "fin save.\n",
      "epoch 5180\n",
      "test_train\n",
      "train mean loss=62390.14895833333\n",
      "test_test\n",
      "test mean loss=88317.765625\n",
      "fin save.\n",
      "epoch 5181\n",
      "test_train\n",
      "train mean loss=61577.139973958336\n",
      "test_test\n",
      "test mean loss=88343.0546875\n",
      "fin save.\n",
      "epoch 5182\n",
      "test_train\n",
      "train mean loss=61570.706770833334\n",
      "test_test\n",
      "test mean loss=88232.265625\n",
      "fin save.\n",
      "epoch 5183\n",
      "test_train\n",
      "train mean loss=61247.03229166667\n",
      "test_test\n",
      "test mean loss=88207.6484375\n",
      "fin save.\n",
      "epoch 5184\n",
      "test_train\n",
      "train mean loss=61637.02890625\n",
      "test_test\n",
      "test mean loss=88369.2109375\n",
      "fin save.\n",
      "epoch 5185\n",
      "test_train\n",
      "train mean loss=62044.063802083336\n",
      "test_test\n",
      "test mean loss=88281.1796875\n",
      "fin save.\n",
      "epoch 5186\n",
      "test_train\n",
      "train mean loss=61890.83020833333\n",
      "test_test\n",
      "test mean loss=88633.26953125\n",
      "fin save.\n",
      "epoch 5187\n",
      "test_train\n",
      "train mean loss=61903.29583333333\n",
      "test_test\n",
      "test mean loss=88733.15234375\n",
      "fin save.\n",
      "epoch 5188\n",
      "test_train\n",
      "train mean loss=61633.34947916667\n",
      "test_test\n",
      "test mean loss=88531.5\n",
      "fin save.\n",
      "epoch 5189\n",
      "test_train\n",
      "train mean loss=62581.44049479167\n",
      "test_test\n",
      "test mean loss=88434.8203125\n",
      "fin save.\n",
      "epoch 5190\n",
      "test_train\n",
      "train mean loss=61093.78567708333\n",
      "test_test\n",
      "test mean loss=88540.9765625\n",
      "fin save.\n",
      "epoch 5191\n",
      "test_train\n",
      "train mean loss=62793.33645833333\n",
      "test_test\n",
      "test mean loss=88594.56640625\n",
      "fin save.\n",
      "epoch 5192\n",
      "test_train\n",
      "train mean loss=61139.84557291667\n",
      "test_test\n",
      "test mean loss=88662.83203125\n",
      "fin save.\n",
      "epoch 5193\n",
      "test_train\n",
      "train mean loss=62320.83098958333\n",
      "test_test\n",
      "test mean loss=88453.10546875\n",
      "fin save.\n",
      "epoch 5194\n",
      "test_train\n",
      "train mean loss=62306.0625\n",
      "test_test\n",
      "test mean loss=88518.7890625\n",
      "fin save.\n",
      "epoch 5195\n",
      "test_train\n",
      "train mean loss=61478.6703125\n",
      "test_test\n",
      "test mean loss=88465.87109375\n",
      "fin save.\n",
      "epoch 5196\n",
      "test_train\n",
      "train mean loss=62433.36328125\n",
      "test_test\n",
      "test mean loss=88398.5390625\n",
      "fin save.\n",
      "epoch 5197\n",
      "test_train\n",
      "train mean loss=62594.97838541667\n",
      "test_test\n",
      "test mean loss=88377.9296875\n",
      "fin save.\n",
      "epoch 5198\n",
      "test_train\n",
      "train mean loss=62257.32760416667\n",
      "test_test\n",
      "test mean loss=88485.421875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fin save.\n",
      "epoch 5199\n",
      "test_train\n",
      "train mean loss=61405.9359375\n",
      "test_test\n",
      "test mean loss=88370.0078125\n",
      "fin save.\n",
      "epoch 5200\n",
      "test_train\n",
      "train mean loss=61399.44036458333\n",
      "test_test\n",
      "test mean loss=88408.76953125\n",
      "fin save.\n",
      "epoch 5201\n",
      "test_train\n",
      "train mean loss=61282.491927083334\n",
      "test_test\n",
      "test mean loss=88062.44140625\n",
      "fin save.\n",
      "epoch 5202\n",
      "test_train\n",
      "train mean loss=61836.36796875\n",
      "test_test\n",
      "test mean loss=88115.0703125\n",
      "fin save.\n",
      "epoch 5203\n",
      "test_train\n",
      "train mean loss=62080.9234375\n",
      "test_test\n",
      "test mean loss=88023.328125\n",
      "fin save.\n",
      "epoch 5204\n",
      "test_train\n",
      "train mean loss=62429.5109375\n",
      "test_test\n",
      "test mean loss=87939.37109375\n",
      "fin save.\n",
      "epoch 5205\n",
      "test_train\n",
      "train mean loss=61481.09869791667\n",
      "test_test\n",
      "test mean loss=88114.73828125\n",
      "fin save.\n",
      "epoch 5206\n",
      "test_train\n",
      "train mean loss=61319.40924479167\n",
      "test_test\n",
      "test mean loss=87977.08984375\n",
      "fin save.\n",
      "epoch 5207\n",
      "test_train\n",
      "train mean loss=61260.11953125\n",
      "test_test\n",
      "test mean loss=88100.984375\n",
      "fin save.\n",
      "epoch 5208\n",
      "test_train\n",
      "train mean loss=62717.37265625\n",
      "test_test\n",
      "test mean loss=87905.6484375\n",
      "fin save.\n",
      "epoch 5209\n",
      "test_train\n",
      "train mean loss=62617.083333333336\n",
      "test_test\n",
      "test mean loss=88076.65234375\n",
      "fin save.\n",
      "epoch 5210\n",
      "test_train\n",
      "train mean loss=61941.067708333336\n",
      "test_test\n",
      "test mean loss=88238.875\n",
      "fin save.\n",
      "epoch 5211\n",
      "test_train\n",
      "train mean loss=61658.28020833333\n",
      "test_test\n",
      "test mean loss=88184.14453125\n",
      "fin save.\n",
      "epoch 5212\n",
      "test_train\n",
      "train mean loss=61508.1734375\n",
      "test_test\n",
      "test mean loss=88040.015625\n",
      "fin save.\n",
      "epoch 5213\n",
      "test_train\n",
      "train mean loss=61633.20989583333\n",
      "test_test\n",
      "test mean loss=88286.93359375\n",
      "fin save.\n",
      "epoch 5214\n",
      "test_train\n",
      "train mean loss=62521.0921875\n",
      "test_test\n",
      "test mean loss=88145.12109375\n",
      "fin save.\n",
      "epoch 5215\n",
      "test_train\n",
      "train mean loss=62144.42239583333\n",
      "test_test\n",
      "test mean loss=87983.4921875\n",
      "fin save.\n",
      "epoch 5216\n",
      "test_train\n",
      "train mean loss=62366.039322916666\n",
      "test_test\n",
      "test mean loss=88205.5703125\n",
      "fin save.\n",
      "epoch 5217\n",
      "test_train\n",
      "train mean loss=61549.127604166664\n",
      "test_test\n",
      "test mean loss=88224.59765625\n",
      "fin save.\n",
      "epoch 5218\n",
      "test_train\n",
      "train mean loss=61833.54049479167\n",
      "test_test\n",
      "test mean loss=88197.63671875\n",
      "fin save.\n",
      "epoch 5219\n",
      "test_train\n",
      "train mean loss=61908.257552083334\n",
      "test_test\n",
      "test mean loss=88147.34375\n",
      "fin save.\n",
      "epoch 5220\n",
      "test_train\n",
      "train mean loss=61416.25729166667\n",
      "test_test\n",
      "test mean loss=87912.36328125\n",
      "fin save.\n",
      "epoch 5221\n",
      "test_train\n",
      "train mean loss=62122.572265625\n",
      "test_test\n",
      "test mean loss=87915.046875\n",
      "fin save.\n",
      "epoch 5222\n",
      "test_train\n",
      "train mean loss=61876.94739583333\n",
      "test_test\n",
      "test mean loss=88017.80078125\n",
      "fin save.\n",
      "epoch 5223\n",
      "test_train\n",
      "train mean loss=62062.050130208336\n",
      "test_test\n",
      "test mean loss=87973.51171875\n",
      "fin save.\n",
      "epoch 5224\n",
      "test_train\n",
      "train mean loss=61731.62942708333\n",
      "test_test\n",
      "test mean loss=88180.9296875\n",
      "fin save.\n",
      "epoch 5225\n",
      "test_train\n",
      "train mean loss=62298.288802083334\n",
      "test_test\n",
      "test mean loss=88192.24609375\n",
      "fin save.\n",
      "epoch 5226\n",
      "test_train\n",
      "train mean loss=62501.654036458334\n",
      "test_test\n",
      "test mean loss=88272.71875\n",
      "fin save.\n",
      "epoch 5227\n",
      "test_train\n",
      "train mean loss=62142.996354166666\n",
      "test_test\n",
      "test mean loss=88141.75\n",
      "fin save.\n",
      "epoch 5228\n",
      "test_train\n",
      "train mean loss=61958.304036458336\n",
      "test_test\n",
      "test mean loss=88326.2421875\n",
      "fin save.\n",
      "epoch 5229\n",
      "test_train\n",
      "train mean loss=61366.8203125\n",
      "test_test\n",
      "test mean loss=88193.421875\n",
      "fin save.\n",
      "epoch 5230\n",
      "test_train\n",
      "train mean loss=62041.694140625\n",
      "test_test\n",
      "test mean loss=88334.34765625\n",
      "fin save.\n",
      "epoch 5231\n",
      "test_train\n",
      "train mean loss=61524.57734375\n",
      "test_test\n",
      "test mean loss=88125.70703125\n",
      "fin save.\n",
      "epoch 5232\n",
      "test_train\n",
      "train mean loss=61284.527604166666\n",
      "test_test\n",
      "test mean loss=88399.359375\n",
      "fin save.\n",
      "epoch 5233\n",
      "test_train\n",
      "train mean loss=62827.08828125\n",
      "test_test\n",
      "test mean loss=88426.46875\n",
      "fin save.\n",
      "epoch 5234\n",
      "test_train\n",
      "train mean loss=62143.8546875\n",
      "test_test\n",
      "test mean loss=88509.234375\n",
      "fin save.\n",
      "epoch 5235\n",
      "test_train\n",
      "train mean loss=62218.36432291667\n",
      "test_test\n",
      "test mean loss=88052.421875\n",
      "fin save.\n",
      "epoch 5236\n",
      "test_train\n",
      "train mean loss=62530.67578125\n",
      "test_test\n",
      "test mean loss=88544.9296875\n",
      "fin save.\n",
      "epoch 5237\n",
      "test_train\n",
      "train mean loss=61888.571875\n",
      "test_test\n",
      "test mean loss=88320.125\n",
      "fin save.\n",
      "epoch 5238\n",
      "test_train\n",
      "train mean loss=61914.083984375\n",
      "test_test\n",
      "test mean loss=88355.60546875\n",
      "fin save.\n",
      "epoch 5239\n",
      "test_train\n",
      "train mean loss=61299.42864583333\n",
      "test_test\n",
      "test mean loss=88522.21484375\n",
      "fin save.\n",
      "epoch 5240\n",
      "test_train\n",
      "train mean loss=63154.182942708336\n",
      "test_test\n",
      "test mean loss=88559.06640625\n",
      "fin save.\n",
      "epoch 5241\n",
      "test_train\n",
      "train mean loss=62430.291015625\n",
      "test_test\n",
      "test mean loss=88605.703125\n",
      "fin save.\n",
      "epoch 5242\n",
      "test_train\n",
      "train mean loss=61552.427473958334\n",
      "test_test\n",
      "test mean loss=88407.9765625\n",
      "fin save.\n",
      "epoch 5243\n",
      "test_train\n",
      "train mean loss=62646.3140625\n",
      "test_test\n",
      "test mean loss=88373.8125\n",
      "fin save.\n",
      "epoch 5244\n",
      "test_train\n",
      "train mean loss=61823.71627604167\n",
      "test_test\n",
      "test mean loss=88185.73828125\n",
      "fin save.\n",
      "epoch 5245\n",
      "test_train\n",
      "train mean loss=61274.975260416664\n",
      "test_test\n",
      "test mean loss=87976.94921875\n",
      "fin save.\n",
      "epoch 5246\n",
      "test_train\n",
      "train mean loss=62407.151171875\n",
      "test_test\n",
      "test mean loss=88050.0703125\n",
      "fin save.\n",
      "epoch 5247\n",
      "test_train\n",
      "train mean loss=61600.22473958333\n",
      "test_test\n",
      "test mean loss=88179.125\n",
      "fin save.\n",
      "epoch 5248\n",
      "test_train\n",
      "train mean loss=62012.62708333333\n",
      "test_test\n",
      "test mean loss=88090.58203125\n",
      "fin save.\n",
      "epoch 5249\n",
      "test_train\n",
      "train mean loss=62549.14440104167\n",
      "test_test\n",
      "test mean loss=88041.95703125\n",
      "fin save.\n",
      "epoch 5250\n",
      "test_train\n",
      "train mean loss=61157.60859375\n",
      "test_test\n",
      "test mean loss=87840.11328125\n",
      "fin save.\n",
      "epoch 5251\n",
      "test_train\n",
      "train mean loss=62553.85078125\n",
      "test_test\n",
      "test mean loss=87902.39453125\n",
      "fin save.\n",
      "epoch 5252\n",
      "test_train\n",
      "train mean loss=62701.483072916664\n",
      "test_test\n",
      "test mean loss=88177.71484375\n",
      "fin save.\n",
      "epoch 5253\n",
      "test_train\n",
      "train mean loss=61432.56484375\n",
      "test_test\n",
      "test mean loss=88030.0546875\n",
      "fin save.\n",
      "epoch 5254\n",
      "test_train\n",
      "train mean loss=62811.82408854167\n",
      "test_test\n",
      "test mean loss=88110.93359375\n",
      "fin save.\n",
      "epoch 5255\n",
      "test_train\n",
      "train mean loss=61724.775390625\n",
      "test_test\n",
      "test mean loss=87746.234375\n",
      "fin save.\n",
      "epoch 5256\n",
      "test_train\n",
      "train mean loss=62136.90390625\n",
      "test_test\n",
      "test mean loss=87680.5546875\n",
      "fin save.\n",
      "epoch 5257\n",
      "test_train\n",
      "train mean loss=62290.659765625\n",
      "test_test\n",
      "test mean loss=87735.05078125\n",
      "fin save.\n",
      "epoch 5258\n",
      "test_train\n",
      "train mean loss=61732.613671875\n",
      "test_test\n",
      "test mean loss=88169.7734375\n",
      "fin save.\n",
      "epoch 5259\n",
      "test_train\n",
      "train mean loss=63068.56432291667\n",
      "test_test\n",
      "test mean loss=88094.625\n",
      "fin save.\n",
      "epoch 5260\n",
      "test_train\n",
      "train mean loss=61982.203125\n",
      "test_test\n",
      "test mean loss=87868.65625\n",
      "fin save.\n",
      "epoch 5261\n",
      "test_train\n",
      "train mean loss=61836.919270833336\n",
      "test_test\n",
      "test mean loss=87917.05859375\n",
      "fin save.\n",
      "epoch 5262\n",
      "test_train\n",
      "train mean loss=62777.559375\n",
      "test_test\n",
      "test mean loss=87875.74609375\n",
      "fin save.\n",
      "epoch 5263\n",
      "test_train\n",
      "train mean loss=62612.012369791664\n",
      "test_test\n",
      "test mean loss=88150.3203125\n",
      "fin save.\n",
      "epoch 5264\n",
      "test_train\n",
      "train mean loss=62358.79296875\n",
      "test_test\n",
      "test mean loss=88439.6171875\n",
      "fin save.\n",
      "epoch 5265\n",
      "test_train\n",
      "train mean loss=62118.7234375\n",
      "test_test\n",
      "test mean loss=87977.6328125\n",
      "fin save.\n",
      "epoch 5266\n",
      "test_train\n",
      "train mean loss=60999.12942708333\n",
      "test_test\n",
      "test mean loss=87997.21875\n",
      "fin save.\n",
      "epoch 5267\n",
      "test_train\n",
      "train mean loss=62869.188802083336\n",
      "test_test\n",
      "test mean loss=87909.21875\n",
      "fin save.\n",
      "epoch 5268\n",
      "test_train\n",
      "train mean loss=62146.699869791664\n",
      "test_test\n",
      "test mean loss=88126.59375\n",
      "fin save.\n",
      "epoch 5269\n",
      "test_train\n",
      "train mean loss=62106.78020833333\n",
      "test_test\n",
      "test mean loss=87880.80859375\n",
      "fin save.\n",
      "epoch 5270\n",
      "test_train\n",
      "train mean loss=62228.8375\n",
      "test_test\n",
      "test mean loss=88345.0625\n",
      "fin save.\n",
      "epoch 5271\n",
      "test_train\n",
      "train mean loss=62164.72447916667\n",
      "test_test\n",
      "test mean loss=88115.34765625\n",
      "fin save.\n",
      "epoch 5272\n",
      "test_train\n",
      "train mean loss=63030.25572916667\n",
      "test_test\n",
      "test mean loss=88228.16796875\n",
      "fin save.\n",
      "epoch 5273\n",
      "test_train\n",
      "train mean loss=62368.57083333333\n",
      "test_test\n",
      "test mean loss=88141.6171875\n",
      "fin save.\n",
      "epoch 5274\n",
      "test_train\n",
      "train mean loss=62693.771484375\n",
      "test_test\n",
      "test mean loss=88351.41796875\n",
      "fin save.\n",
      "epoch 5275\n",
      "test_train\n",
      "train mean loss=62648.004166666666\n",
      "test_test\n",
      "test mean loss=88196.45703125\n",
      "fin save.\n",
      "epoch 5276\n",
      "test_train\n",
      "train mean loss=61796.56328125\n",
      "test_test\n",
      "test mean loss=88054.93359375\n",
      "fin save.\n",
      "epoch 5277\n",
      "test_train\n",
      "train mean loss=62583.4015625\n",
      "test_test\n",
      "test mean loss=88193.30859375\n",
      "fin save.\n",
      "epoch 5278\n",
      "test_train\n",
      "train mean loss=61730.93020833333\n",
      "test_test\n",
      "test mean loss=88104.37109375\n",
      "fin save.\n",
      "epoch 5279\n",
      "test_train\n",
      "train mean loss=62329.734114583334\n",
      "test_test\n",
      "test mean loss=88088.921875\n",
      "fin save.\n",
      "epoch 5280\n",
      "test_train\n",
      "train mean loss=63089.49856770833\n",
      "test_test\n",
      "test mean loss=88030.83203125\n",
      "fin save.\n",
      "epoch 5281\n",
      "test_train\n",
      "train mean loss=62847.390364583334\n",
      "test_test\n",
      "test mean loss=88178.30859375\n",
      "fin save.\n",
      "epoch 5282\n",
      "test_train\n",
      "train mean loss=62936.06354166667\n",
      "test_test\n",
      "test mean loss=88040.1796875\n",
      "fin save.\n",
      "epoch 5283\n",
      "test_train\n",
      "train mean loss=62063.32408854167\n",
      "test_test\n",
      "test mean loss=87960.75390625\n",
      "fin save.\n",
      "epoch 5284\n",
      "test_train\n",
      "train mean loss=61918.001692708334\n",
      "test_test\n",
      "test mean loss=88095.6171875\n",
      "fin save.\n",
      "epoch 5285\n",
      "test_train\n",
      "train mean loss=62303.665625\n",
      "test_test\n",
      "test mean loss=88089.7265625\n",
      "fin save.\n",
      "epoch 5286\n",
      "test_train\n",
      "train mean loss=61964.03515625\n",
      "test_test\n",
      "test mean loss=88077.73046875\n",
      "fin save.\n",
      "epoch 5287\n",
      "test_train\n",
      "train mean loss=62141.19049479167\n",
      "test_test\n",
      "test mean loss=88243.83984375\n",
      "fin save.\n",
      "epoch 5288\n",
      "test_train\n",
      "train mean loss=62361.44739583333\n",
      "test_test\n",
      "test mean loss=88339.48046875\n",
      "fin save.\n",
      "epoch 5289\n",
      "test_train\n",
      "train mean loss=62230.662369791666\n",
      "test_test\n",
      "test mean loss=88070.48046875\n",
      "fin save.\n",
      "epoch 5290\n",
      "test_train\n",
      "train mean loss=62917.677083333336\n",
      "test_test\n",
      "test mean loss=88048.2734375\n",
      "fin save.\n",
      "epoch 5291\n",
      "test_train\n",
      "train mean loss=61376.780989583334\n",
      "test_test\n",
      "test mean loss=88390.390625\n",
      "fin save.\n",
      "epoch 5292\n",
      "test_train\n",
      "train mean loss=61433.21588541667\n",
      "test_test\n",
      "test mean loss=88472.19921875\n",
      "fin save.\n",
      "epoch 5293\n",
      "test_train\n",
      "train mean loss=62290.85950520833\n",
      "test_test\n",
      "test mean loss=88517.47265625\n",
      "fin save.\n",
      "epoch 5294\n",
      "test_train\n",
      "train mean loss=62628.5\n",
      "test_test\n",
      "test mean loss=88600.109375\n",
      "fin save.\n",
      "epoch 5295\n",
      "test_train\n",
      "train mean loss=61489.09375\n",
      "test_test\n",
      "test mean loss=88329.22265625\n",
      "fin save.\n",
      "epoch 5296\n",
      "test_train\n",
      "train mean loss=62030.428125\n",
      "test_test\n",
      "test mean loss=88531.60546875\n",
      "fin save.\n",
      "epoch 5297\n",
      "test_train\n",
      "train mean loss=63040.99557291667\n",
      "test_test\n",
      "test mean loss=88419.203125\n",
      "fin save.\n",
      "epoch 5298\n",
      "test_train\n",
      "train mean loss=62645.04348958333\n",
      "test_test\n",
      "test mean loss=88214.5390625\n",
      "fin save.\n",
      "epoch 5299\n",
      "test_train\n",
      "train mean loss=62421.76276041667\n",
      "test_test\n",
      "test mean loss=88483.84375\n",
      "fin save.\n",
      "epoch 5300\n",
      "test_train\n",
      "train mean loss=62123.085286458336\n",
      "test_test\n",
      "test mean loss=88612.8828125\n",
      "fin save.\n",
      "epoch 5301\n",
      "test_train\n",
      "train mean loss=62125.020833333336\n",
      "test_test\n",
      "test mean loss=88516.625\n",
      "fin save.\n",
      "epoch 5302\n",
      "test_train\n",
      "train mean loss=61669.82265625\n",
      "test_test\n",
      "test mean loss=88565.8203125\n",
      "fin save.\n",
      "epoch 5303\n",
      "test_train\n",
      "train mean loss=61055.377604166664\n",
      "test_test\n",
      "test mean loss=88557.9296875\n",
      "fin save.\n",
      "epoch 5304\n",
      "test_train\n",
      "train mean loss=62161.116927083334\n",
      "test_test\n",
      "test mean loss=88434.79296875\n",
      "fin save.\n",
      "epoch 5305\n",
      "test_train\n",
      "train mean loss=62619.34765625\n",
      "test_test\n",
      "test mean loss=88375.0625\n",
      "fin save.\n",
      "epoch 5306\n",
      "test_train\n",
      "train mean loss=62603.20208333333\n",
      "test_test\n",
      "test mean loss=88477.4140625\n",
      "fin save.\n",
      "epoch 5307\n",
      "test_train\n",
      "train mean loss=62406.15091145833\n",
      "test_test\n",
      "test mean loss=88374.8828125\n",
      "fin save.\n",
      "epoch 5308\n",
      "test_train\n",
      "train mean loss=61400.08697916667\n",
      "test_test\n",
      "test mean loss=88474.16796875\n",
      "fin save.\n",
      "epoch 5309\n",
      "test_train\n",
      "train mean loss=62167.56354166667\n",
      "test_test\n",
      "test mean loss=88572.16796875\n",
      "fin save.\n",
      "epoch 5310\n",
      "test_train\n",
      "train mean loss=61669.3625\n",
      "test_test\n",
      "test mean loss=88400.1328125\n",
      "fin save.\n",
      "epoch 5311\n",
      "test_train\n",
      "train mean loss=61909.06067708333\n",
      "test_test\n",
      "test mean loss=88244.74609375\n",
      "fin save.\n",
      "epoch 5312\n",
      "test_train\n",
      "train mean loss=61927.78359375\n",
      "test_test\n",
      "test mean loss=88525.71484375\n",
      "fin save.\n",
      "epoch 5313\n",
      "test_train\n",
      "train mean loss=61847.940104166664\n",
      "test_test\n",
      "test mean loss=88382.93359375\n",
      "fin save.\n",
      "epoch 5314\n",
      "test_train\n",
      "train mean loss=61885.20260416667\n",
      "test_test\n",
      "test mean loss=88443.10546875\n",
      "fin save.\n",
      "epoch 5315\n",
      "test_train\n",
      "train mean loss=62111.164713541664\n",
      "test_test\n",
      "test mean loss=88562.6875\n",
      "fin save.\n",
      "epoch 5316\n",
      "test_train\n",
      "train mean loss=61712.17526041667\n",
      "test_test\n",
      "test mean loss=88591.14453125\n",
      "fin save.\n",
      "epoch 5317\n",
      "test_train\n",
      "train mean loss=62108.93893229167\n",
      "test_test\n",
      "test mean loss=88662.54296875\n",
      "fin save.\n",
      "epoch 5318\n",
      "test_train\n",
      "train mean loss=61744.5046875\n",
      "test_test\n",
      "test mean loss=88686.0234375\n",
      "fin save.\n",
      "epoch 5319\n",
      "test_train\n",
      "train mean loss=62009.01458333333\n",
      "test_test\n",
      "test mean loss=88479.34375\n",
      "fin save.\n",
      "epoch 5320\n",
      "test_train\n",
      "train mean loss=61703.92864583333\n",
      "test_test\n",
      "test mean loss=88471.2421875\n",
      "fin save.\n",
      "epoch 5321\n",
      "test_train\n",
      "train mean loss=61537.29114583333\n",
      "test_test\n",
      "test mean loss=88521.0234375\n",
      "fin save.\n",
      "epoch 5322\n",
      "test_train\n",
      "train mean loss=62163.562239583334\n",
      "test_test\n",
      "test mean loss=88368.23046875\n",
      "fin save.\n",
      "epoch 5323\n",
      "test_train\n",
      "train mean loss=61996.855208333334\n",
      "test_test\n",
      "test mean loss=88247.24609375\n",
      "fin save.\n",
      "epoch 5324\n",
      "test_train\n",
      "train mean loss=62852.65572916667\n",
      "test_test\n",
      "test mean loss=88581.78515625\n",
      "fin save.\n",
      "epoch 5325\n",
      "test_train\n",
      "train mean loss=61662.727864583336\n",
      "test_test\n",
      "test mean loss=88519.82421875\n",
      "fin save.\n",
      "epoch 5326\n",
      "test_train\n",
      "train mean loss=61517.845052083336\n",
      "test_test\n",
      "test mean loss=88453.078125\n",
      "fin save.\n",
      "epoch 5327\n",
      "test_train\n",
      "train mean loss=62856.68125\n",
      "test_test\n",
      "test mean loss=88677.38671875\n",
      "fin save.\n",
      "epoch 5328\n",
      "test_train\n",
      "train mean loss=62893.53463541667\n",
      "test_test\n",
      "test mean loss=88590.20703125\n",
      "fin save.\n",
      "epoch 5329\n",
      "test_train\n",
      "train mean loss=61348.796875\n",
      "test_test\n",
      "test mean loss=88788.28515625\n",
      "fin save.\n",
      "epoch 5330\n",
      "test_train\n",
      "train mean loss=61809.014322916664\n",
      "test_test\n",
      "test mean loss=88912.3203125\n",
      "fin save.\n",
      "epoch 5331\n",
      "test_train\n",
      "train mean loss=62092.56744791667\n",
      "test_test\n",
      "test mean loss=88444.26171875\n",
      "fin save.\n",
      "epoch 5332\n",
      "test_train\n",
      "train mean loss=61800.400130208334\n",
      "test_test\n",
      "test mean loss=88381.1875\n",
      "fin save.\n",
      "epoch 5333\n",
      "test_train\n",
      "train mean loss=61661.990885416664\n",
      "test_test\n",
      "test mean loss=88391.79296875\n",
      "fin save.\n",
      "epoch 5334\n",
      "test_train\n",
      "train mean loss=62304.06875\n",
      "test_test\n",
      "test mean loss=88317.19921875\n",
      "fin save.\n",
      "epoch 5335\n",
      "test_train\n",
      "train mean loss=62488.88828125\n",
      "test_test\n",
      "test mean loss=88427.6484375\n",
      "fin save.\n",
      "epoch 5336\n",
      "test_train\n",
      "train mean loss=62689.19713541667\n",
      "test_test\n",
      "test mean loss=88151.1875\n",
      "fin save.\n",
      "epoch 5337\n",
      "test_train\n",
      "train mean loss=61866.67578125\n",
      "test_test\n",
      "test mean loss=88057.30859375\n",
      "fin save.\n",
      "epoch 5338\n",
      "test_train\n",
      "train mean loss=62993.25442708333\n",
      "test_test\n",
      "test mean loss=88148.33984375\n",
      "fin save.\n",
      "epoch 5339\n",
      "test_train\n",
      "train mean loss=62911.950520833336\n",
      "test_test\n",
      "test mean loss=88199.75390625\n",
      "fin save.\n",
      "epoch 5340\n",
      "test_train\n",
      "train mean loss=63122.32109375\n",
      "test_test\n",
      "test mean loss=88130.3515625\n",
      "fin save.\n",
      "epoch 5341\n",
      "test_train\n",
      "train mean loss=61947.821875\n",
      "test_test\n",
      "test mean loss=88372.546875\n",
      "fin save.\n",
      "epoch 5342\n",
      "test_train\n",
      "train mean loss=61827.34947916667\n",
      "test_test\n",
      "test mean loss=88291.37890625\n",
      "fin save.\n",
      "epoch 5343\n",
      "test_train\n",
      "train mean loss=63433.57135416667\n",
      "test_test\n",
      "test mean loss=88435.2734375\n",
      "fin save.\n",
      "epoch 5344\n",
      "test_train\n",
      "train mean loss=61707.41119791667\n",
      "test_test\n",
      "test mean loss=88385.78125\n",
      "fin save.\n",
      "epoch 5345\n",
      "test_train\n",
      "train mean loss=61321.971354166664\n",
      "test_test\n",
      "test mean loss=88221.58984375\n",
      "fin save.\n",
      "epoch 5346\n",
      "test_train\n",
      "train mean loss=62742.83216145833\n",
      "test_test\n",
      "test mean loss=88328.09765625\n",
      "fin save.\n",
      "epoch 5347\n",
      "test_train\n",
      "train mean loss=62177.204427083336\n",
      "test_test\n",
      "test mean loss=88179.80859375\n",
      "fin save.\n",
      "epoch 5348\n",
      "test_train\n",
      "train mean loss=62117.18020833333\n",
      "test_test\n",
      "test mean loss=88478.05078125\n",
      "fin save.\n",
      "epoch 5349\n",
      "test_train\n",
      "train mean loss=61550.62682291667\n",
      "test_test\n",
      "test mean loss=88521.1015625\n",
      "fin save.\n",
      "epoch 5350\n",
      "test_train\n",
      "train mean loss=62706.92864583333\n",
      "test_test\n",
      "test mean loss=88633.58984375\n",
      "fin save.\n",
      "epoch 5351\n",
      "test_train\n",
      "train mean loss=61899.398046875\n",
      "test_test\n",
      "test mean loss=88548.5234375\n",
      "fin save.\n",
      "epoch 5352\n",
      "test_train\n",
      "train mean loss=62170.08255208333\n",
      "test_test\n",
      "test mean loss=88704.64453125\n",
      "fin save.\n",
      "epoch 5353\n",
      "test_train\n",
      "train mean loss=62255.363020833334\n",
      "test_test\n",
      "test mean loss=88258.8984375\n",
      "fin save.\n",
      "epoch 5354\n",
      "test_train\n",
      "train mean loss=61125.909375\n",
      "test_test\n",
      "test mean loss=88320.85546875\n",
      "fin save.\n",
      "epoch 5355\n",
      "test_train\n",
      "train mean loss=61266.04895833333\n",
      "test_test\n",
      "test mean loss=88252.7265625\n",
      "fin save.\n",
      "epoch 5356\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=62325.97864583333\n",
      "test_test\n",
      "test mean loss=88257.765625\n",
      "fin save.\n",
      "epoch 5357\n",
      "test_train\n",
      "train mean loss=62747.09609375\n",
      "test_test\n",
      "test mean loss=88127.66796875\n",
      "fin save.\n",
      "epoch 5358\n",
      "test_train\n",
      "train mean loss=61640.28411458333\n",
      "test_test\n",
      "test mean loss=88254.41796875\n",
      "fin save.\n",
      "epoch 5359\n",
      "test_train\n",
      "train mean loss=61687.25885416667\n",
      "test_test\n",
      "test mean loss=88435.96875\n",
      "fin save.\n",
      "epoch 5360\n",
      "test_train\n",
      "train mean loss=62427.86901041667\n",
      "test_test\n",
      "test mean loss=88287.0859375\n",
      "fin save.\n",
      "epoch 5361\n",
      "test_train\n",
      "train mean loss=61871.310546875\n",
      "test_test\n",
      "test mean loss=88592.3125\n",
      "fin save.\n",
      "epoch 5362\n",
      "test_train\n",
      "train mean loss=61444.465625\n",
      "test_test\n",
      "test mean loss=88485.19921875\n",
      "fin save.\n",
      "epoch 5363\n",
      "test_train\n",
      "train mean loss=61812.678385416664\n",
      "test_test\n",
      "test mean loss=88582.39453125\n",
      "fin save.\n",
      "epoch 5364\n",
      "test_train\n",
      "train mean loss=62221.043229166666\n",
      "test_test\n",
      "test mean loss=88348.5390625\n",
      "fin save.\n",
      "epoch 5365\n",
      "test_train\n",
      "train mean loss=62131.260416666664\n",
      "test_test\n",
      "test mean loss=88461.4453125\n",
      "fin save.\n",
      "epoch 5366\n",
      "test_train\n",
      "train mean loss=61791.82864583333\n",
      "test_test\n",
      "test mean loss=88379.3984375\n",
      "fin save.\n",
      "epoch 5367\n",
      "test_train\n",
      "train mean loss=62646.80911458333\n",
      "test_test\n",
      "test mean loss=88513.0703125\n",
      "fin save.\n",
      "epoch 5368\n",
      "test_train\n",
      "train mean loss=62330.11640625\n",
      "test_test\n",
      "test mean loss=88246.390625\n",
      "fin save.\n",
      "epoch 5369\n",
      "test_train\n",
      "train mean loss=62087.83385416667\n",
      "test_test\n",
      "test mean loss=88254.34375\n",
      "fin save.\n",
      "epoch 5370\n",
      "test_train\n",
      "train mean loss=62790.72265625\n",
      "test_test\n",
      "test mean loss=88233.01171875\n",
      "fin save.\n",
      "epoch 5371\n",
      "test_train\n",
      "train mean loss=62689.99270833333\n",
      "test_test\n",
      "test mean loss=88591.4296875\n",
      "fin save.\n",
      "epoch 5372\n",
      "test_train\n",
      "train mean loss=62386.21888020833\n",
      "test_test\n",
      "test mean loss=88620.6875\n",
      "fin save.\n",
      "epoch 5373\n",
      "test_train\n",
      "train mean loss=61706.22356770833\n",
      "test_test\n",
      "test mean loss=88619.015625\n",
      "fin save.\n",
      "epoch 5374\n",
      "test_train\n",
      "train mean loss=62001.504557291664\n",
      "test_test\n",
      "test mean loss=88542.359375\n",
      "fin save.\n",
      "epoch 5375\n",
      "test_train\n",
      "train mean loss=62666.6296875\n",
      "test_test\n",
      "test mean loss=88184.99609375\n",
      "fin save.\n",
      "epoch 5376\n",
      "test_train\n",
      "train mean loss=61760.14010416667\n",
      "test_test\n",
      "test mean loss=88258.34765625\n",
      "fin save.\n",
      "epoch 5377\n",
      "test_train\n",
      "train mean loss=61644.677473958334\n",
      "test_test\n",
      "test mean loss=88315.296875\n",
      "fin save.\n",
      "epoch 5378\n",
      "test_train\n",
      "train mean loss=62799.20598958333\n",
      "test_test\n",
      "test mean loss=88412.15625\n",
      "fin save.\n",
      "epoch 5379\n",
      "test_train\n",
      "train mean loss=62275.55078125\n",
      "test_test\n",
      "test mean loss=88434.453125\n",
      "fin save.\n",
      "epoch 5380\n",
      "test_train\n",
      "train mean loss=61478.00546875\n",
      "test_test\n",
      "test mean loss=88259.97265625\n",
      "fin save.\n",
      "epoch 5381\n",
      "test_train\n",
      "train mean loss=61995.344921875\n",
      "test_test\n",
      "test mean loss=88217.5859375\n",
      "fin save.\n",
      "epoch 5382\n",
      "test_train\n",
      "train mean loss=62731.58541666667\n",
      "test_test\n",
      "test mean loss=88113.09765625\n",
      "fin save.\n",
      "epoch 5383\n",
      "test_train\n",
      "train mean loss=62708.51328125\n",
      "test_test\n",
      "test mean loss=88259.2109375\n",
      "fin save.\n",
      "epoch 5384\n",
      "test_train\n",
      "train mean loss=62168.668229166666\n",
      "test_test\n",
      "test mean loss=88214.19140625\n",
      "fin save.\n",
      "epoch 5385\n",
      "test_train\n",
      "train mean loss=62441.841145833336\n",
      "test_test\n",
      "test mean loss=88235.4921875\n",
      "fin save.\n",
      "epoch 5386\n",
      "test_train\n",
      "train mean loss=61903.167708333334\n",
      "test_test\n",
      "test mean loss=88018.8046875\n",
      "fin save.\n",
      "epoch 5387\n",
      "test_train\n",
      "train mean loss=61942.13880208333\n",
      "test_test\n",
      "test mean loss=88044.0546875\n",
      "fin save.\n",
      "epoch 5388\n",
      "test_train\n",
      "train mean loss=62659.882161458336\n",
      "test_test\n",
      "test mean loss=88095.1484375\n",
      "fin save.\n",
      "epoch 5389\n",
      "test_train\n",
      "train mean loss=61674.89166666667\n",
      "test_test\n",
      "test mean loss=87933.23046875\n",
      "fin save.\n",
      "epoch 5390\n",
      "test_train\n",
      "train mean loss=63011.99375\n",
      "test_test\n",
      "test mean loss=87656.6328125\n",
      "fin save.\n",
      "epoch 5391\n",
      "test_train\n",
      "train mean loss=62396.51354166667\n",
      "test_test\n",
      "test mean loss=87979.17578125\n",
      "fin save.\n",
      "epoch 5392\n",
      "test_train\n",
      "train mean loss=61750.16953125\n",
      "test_test\n",
      "test mean loss=88077.03515625\n",
      "fin save.\n",
      "epoch 5393\n",
      "test_train\n",
      "train mean loss=61896.66953125\n",
      "test_test\n",
      "test mean loss=88064.51171875\n",
      "fin save.\n",
      "epoch 5394\n",
      "test_train\n",
      "train mean loss=61767.023697916666\n",
      "test_test\n",
      "test mean loss=87831.54296875\n",
      "fin save.\n",
      "epoch 5395\n",
      "test_train\n",
      "train mean loss=62066.29375\n",
      "test_test\n",
      "test mean loss=87750.6875\n",
      "fin save.\n",
      "epoch 5396\n",
      "test_train\n",
      "train mean loss=63036.92096354167\n",
      "test_test\n",
      "test mean loss=87650.6875\n",
      "fin save.\n",
      "epoch 5397\n",
      "test_train\n",
      "train mean loss=62581.42591145833\n",
      "test_test\n",
      "test mean loss=87605.26171875\n",
      "fin save.\n",
      "epoch 5398\n",
      "test_train\n",
      "train mean loss=62682.3203125\n",
      "test_test\n",
      "test mean loss=87723.16796875\n",
      "fin save.\n",
      "epoch 5399\n",
      "test_train\n",
      "train mean loss=62796.437760416666\n",
      "test_test\n",
      "test mean loss=87861.4140625\n",
      "fin save.\n",
      "epoch 5400\n",
      "test_train\n",
      "train mean loss=61620.725260416664\n",
      "test_test\n",
      "test mean loss=87730.49609375\n",
      "fin save.\n",
      "epoch 5401\n",
      "test_train\n",
      "train mean loss=62512.66171875\n",
      "test_test\n",
      "test mean loss=87749.2109375\n",
      "fin save.\n",
      "epoch 5402\n",
      "test_train\n",
      "train mean loss=62664.75494791667\n",
      "test_test\n",
      "test mean loss=87756.80859375\n",
      "fin save.\n",
      "epoch 5403\n",
      "test_train\n",
      "train mean loss=62288.65026041667\n",
      "test_test\n",
      "test mean loss=87917.859375\n",
      "fin save.\n",
      "epoch 5404\n",
      "test_train\n",
      "train mean loss=62707.31588541667\n",
      "test_test\n",
      "test mean loss=87895.8984375\n",
      "fin save.\n",
      "epoch 5405\n",
      "test_train\n",
      "train mean loss=61565.172135416666\n",
      "test_test\n",
      "test mean loss=87975.546875\n",
      "fin save.\n",
      "epoch 5406\n",
      "test_train\n",
      "train mean loss=61379.378125\n",
      "test_test\n",
      "test mean loss=88049.66796875\n",
      "fin save.\n",
      "epoch 5407\n",
      "test_train\n",
      "train mean loss=62005.81822916667\n",
      "test_test\n",
      "test mean loss=87898.41796875\n",
      "fin save.\n",
      "epoch 5408\n",
      "test_train\n",
      "train mean loss=62848.405989583334\n",
      "test_test\n",
      "test mean loss=87917.36328125\n",
      "fin save.\n",
      "epoch 5409\n",
      "test_train\n",
      "train mean loss=61966.46588541667\n",
      "test_test\n",
      "test mean loss=87973.37890625\n",
      "fin save.\n",
      "epoch 5410\n",
      "test_train\n",
      "train mean loss=61986.37395833333\n",
      "test_test\n",
      "test mean loss=87823.34765625\n",
      "fin save.\n",
      "epoch 5411\n",
      "test_train\n",
      "train mean loss=62136.83216145833\n",
      "test_test\n",
      "test mean loss=87833.6015625\n",
      "fin save.\n",
      "epoch 5412\n",
      "test_train\n",
      "train mean loss=63071.19583333333\n",
      "test_test\n",
      "test mean loss=87870.75390625\n",
      "fin save.\n",
      "epoch 5413\n",
      "test_train\n",
      "train mean loss=61224.6546875\n",
      "test_test\n",
      "test mean loss=88042.59765625\n",
      "fin save.\n",
      "epoch 5414\n",
      "test_train\n",
      "train mean loss=62499.41171875\n",
      "test_test\n",
      "test mean loss=88101.5078125\n",
      "fin save.\n",
      "epoch 5415\n",
      "test_train\n",
      "train mean loss=62255.36041666667\n",
      "test_test\n",
      "test mean loss=87912.46875\n",
      "fin save.\n",
      "epoch 5416\n",
      "test_train\n",
      "train mean loss=62894.19296875\n",
      "test_test\n",
      "test mean loss=88061.3515625\n",
      "fin save.\n",
      "epoch 5417\n",
      "test_train\n",
      "train mean loss=62928.65833333333\n",
      "test_test\n",
      "test mean loss=87875.2578125\n",
      "fin save.\n",
      "epoch 5418\n",
      "test_train\n",
      "train mean loss=62035.08828125\n",
      "test_test\n",
      "test mean loss=87919.796875\n",
      "fin save.\n",
      "epoch 5419\n",
      "test_train\n",
      "train mean loss=62175.417578125\n",
      "test_test\n",
      "test mean loss=87756.23046875\n",
      "fin save.\n",
      "epoch 5420\n",
      "test_train\n",
      "train mean loss=62770.96953125\n",
      "test_test\n",
      "test mean loss=87940.921875\n",
      "fin save.\n",
      "epoch 5421\n",
      "test_train\n",
      "train mean loss=61964.201171875\n",
      "test_test\n",
      "test mean loss=87887.9375\n",
      "fin save.\n",
      "epoch 5422\n",
      "test_train\n",
      "train mean loss=62052.3859375\n",
      "test_test\n",
      "test mean loss=87837.1484375\n",
      "fin save.\n",
      "epoch 5423\n",
      "test_train\n",
      "train mean loss=61675.7578125\n",
      "test_test\n",
      "test mean loss=87751.34765625\n",
      "fin save.\n",
      "epoch 5424\n",
      "test_train\n",
      "train mean loss=63437.76705729167\n",
      "test_test\n",
      "test mean loss=87789.56640625\n",
      "fin save.\n",
      "epoch 5425\n",
      "test_train\n",
      "train mean loss=62317.47578125\n",
      "test_test\n",
      "test mean loss=87568.296875\n",
      "fin save.\n",
      "epoch 5426\n",
      "test_train\n",
      "train mean loss=62058.795572916664\n",
      "test_test\n",
      "test mean loss=87949.69921875\n",
      "fin save.\n",
      "epoch 5427\n",
      "test_train\n",
      "train mean loss=62006.83828125\n",
      "test_test\n",
      "test mean loss=88057.625\n",
      "fin save.\n",
      "epoch 5428\n",
      "test_train\n",
      "train mean loss=62221.09973958333\n",
      "test_test\n",
      "test mean loss=87882.40234375\n",
      "fin save.\n",
      "epoch 5429\n",
      "test_train\n",
      "train mean loss=62894.8171875\n",
      "test_test\n",
      "test mean loss=88373.0625\n",
      "fin save.\n",
      "epoch 5430\n",
      "test_train\n",
      "train mean loss=62866.451822916664\n",
      "test_test\n",
      "test mean loss=88472.34375\n",
      "fin save.\n",
      "epoch 5431\n",
      "test_train\n",
      "train mean loss=62799.528515625\n",
      "test_test\n",
      "test mean loss=88492.90234375\n",
      "fin save.\n",
      "epoch 5432\n",
      "test_train\n",
      "train mean loss=62554.37903645833\n",
      "test_test\n",
      "test mean loss=88564.02734375\n",
      "fin save.\n",
      "epoch 5433\n",
      "test_train\n",
      "train mean loss=62778.073958333334\n",
      "test_test\n",
      "test mean loss=88581.66015625\n",
      "fin save.\n",
      "epoch 5434\n",
      "test_train\n",
      "train mean loss=61788.119791666664\n",
      "test_test\n",
      "test mean loss=88455.11328125\n",
      "fin save.\n",
      "epoch 5435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_train\n",
      "train mean loss=61209.61276041667\n",
      "test_test\n",
      "test mean loss=88352.87109375\n",
      "fin save.\n",
      "epoch 5436\n",
      "test_train\n",
      "train mean loss=63324.798177083336\n",
      "test_test\n",
      "test mean loss=88367.6484375\n",
      "fin save.\n",
      "epoch 5437\n",
      "test_train\n",
      "train mean loss=62645.964583333334\n",
      "test_test\n",
      "test mean loss=88294.33203125\n",
      "fin save.\n",
      "epoch 5438\n",
      "test_train\n",
      "train mean loss=62085.496484375\n",
      "test_test\n",
      "test mean loss=88160.265625\n",
      "fin save.\n",
      "epoch 5439\n",
      "test_train\n",
      "train mean loss=62514.121484375\n",
      "test_test\n",
      "test mean loss=88313.890625\n",
      "fin save.\n",
      "epoch 5440\n",
      "test_train\n",
      "train mean loss=62479.28411458333\n",
      "test_test\n",
      "test mean loss=88295.41796875\n",
      "fin save.\n",
      "epoch 5441\n",
      "test_train\n",
      "train mean loss=61671.384375\n",
      "test_test\n",
      "test mean loss=88459.16015625\n",
      "fin save.\n",
      "epoch 5442\n",
      "test_train\n",
      "train mean loss=62190.71015625\n",
      "test_test\n",
      "test mean loss=88402.04296875\n",
      "fin save.\n",
      "epoch 5443\n",
      "test_train\n",
      "train mean loss=62448.218489583334\n",
      "test_test\n",
      "test mean loss=88470.75\n",
      "fin save.\n",
      "epoch 5444\n",
      "test_train\n",
      "train mean loss=62192.639973958336\n",
      "test_test\n",
      "test mean loss=88443.05078125\n",
      "fin save.\n",
      "epoch 5445\n",
      "test_train\n",
      "train mean loss=61938.244791666664\n",
      "test_test\n",
      "test mean loss=88469.12109375\n",
      "fin save.\n",
      "epoch 5446\n",
      "test_train\n",
      "train mean loss=62255.89114583333\n",
      "test_test\n",
      "test mean loss=88270.8203125\n",
      "fin save.\n",
      "epoch 5447\n",
      "test_train\n",
      "train mean loss=62612.38854166667\n",
      "test_test\n",
      "test mean loss=88387.34765625\n",
      "fin save.\n",
      "epoch 5448\n",
      "test_train\n",
      "train mean loss=62721.726822916666\n",
      "test_test\n",
      "test mean loss=88203.74609375\n",
      "fin save.\n",
      "epoch 5449\n",
      "test_train\n",
      "train mean loss=62976.73333333333\n",
      "test_test\n",
      "test mean loss=88200.62109375\n",
      "fin save.\n",
      "epoch 5450\n",
      "test_train\n",
      "train mean loss=60884.59375\n",
      "test_test\n",
      "test mean loss=88500.96875\n",
      "fin save.\n",
      "epoch 5451\n",
      "test_train\n",
      "train mean loss=63541.136458333334\n",
      "test_test\n",
      "test mean loss=88102.7109375\n",
      "fin save.\n",
      "epoch 5452\n",
      "test_train\n",
      "train mean loss=62754.7203125\n",
      "test_test\n",
      "test mean loss=88181.99609375\n",
      "fin save.\n",
      "epoch 5453\n",
      "test_train\n",
      "train mean loss=63618.393229166664\n",
      "test_test\n",
      "test mean loss=88071.43359375\n",
      "fin save.\n",
      "epoch 5454\n",
      "test_train\n",
      "train mean loss=61988.4453125\n",
      "test_test\n",
      "test mean loss=88173.3828125\n",
      "fin save.\n",
      "epoch 5455\n",
      "test_train\n",
      "train mean loss=62991.45169270833\n",
      "test_test\n",
      "test mean loss=88430.765625\n",
      "fin save.\n",
      "epoch 5456\n",
      "test_train\n",
      "train mean loss=61705.73046875\n",
      "test_test\n",
      "test mean loss=88195.96484375\n",
      "fin save.\n",
      "epoch 5457\n",
      "test_train\n",
      "train mean loss=62969.85442708333\n",
      "test_test\n",
      "test mean loss=88124.515625\n",
      "fin save.\n",
      "epoch 5458\n",
      "test_train\n",
      "train mean loss=61973.00833333333\n",
      "test_test\n",
      "test mean loss=88198.59765625\n",
      "fin save.\n",
      "epoch 5459\n",
      "test_train\n",
      "train mean loss=62011.52734375\n",
      "test_test\n",
      "test mean loss=88170.6328125\n",
      "fin save.\n",
      "epoch 5460\n",
      "test_train\n",
      "train mean loss=62698.94817708333\n",
      "test_test\n",
      "test mean loss=88179.76953125\n",
      "fin save.\n",
      "epoch 5461\n",
      "test_train\n",
      "train mean loss=62582.19283854167\n",
      "test_test\n",
      "test mean loss=88312.828125\n",
      "fin save.\n",
      "epoch 5462\n",
      "test_train\n",
      "train mean loss=62219.168229166666\n",
      "test_test\n",
      "test mean loss=88126.29296875\n",
      "fin save.\n",
      "epoch 5463\n",
      "test_train\n",
      "train mean loss=61930.69921875\n",
      "test_test\n",
      "test mean loss=88369.89453125\n",
      "fin save.\n",
      "epoch 5464\n",
      "test_train\n",
      "train mean loss=62327.31640625\n",
      "test_test\n",
      "test mean loss=87965.19921875\n",
      "fin save.\n",
      "epoch 5465\n",
      "test_train\n",
      "train mean loss=62087.4\n",
      "test_test\n",
      "test mean loss=88022.546875\n",
      "fin save.\n",
      "epoch 5466\n",
      "test_train\n",
      "train mean loss=62642.12421875\n",
      "test_test\n",
      "test mean loss=88166.66015625\n",
      "fin save.\n",
      "epoch 5467\n",
      "test_train\n",
      "train mean loss=62700.104166666664\n",
      "test_test\n",
      "test mean loss=88016.84375\n",
      "fin save.\n",
      "epoch 5468\n",
      "test_train\n",
      "train mean loss=62303.15078125\n",
      "test_test\n",
      "test mean loss=88236.7578125\n",
      "fin save.\n",
      "epoch 5469\n",
      "test_train\n",
      "train mean loss=62662.183333333334\n",
      "test_test\n",
      "test mean loss=88218.671875\n",
      "fin save.\n",
      "epoch 5470\n",
      "test_train\n",
      "train mean loss=61857.72109375\n",
      "test_test\n",
      "test mean loss=88349.5546875\n",
      "fin save.\n",
      "epoch 5471\n",
      "test_train\n",
      "train mean loss=62005.16875\n",
      "test_test\n",
      "test mean loss=88377.65625\n",
      "fin save.\n",
      "epoch 5472\n",
      "test_train\n",
      "train mean loss=62307.39661458333\n",
      "test_test\n",
      "test mean loss=88324.1328125\n",
      "fin save.\n",
      "epoch 5473\n",
      "test_train\n",
      "train mean loss=62036.821614583336\n",
      "test_test\n",
      "test mean loss=88185.84375\n",
      "fin save.\n",
      "epoch 5474\n",
      "test_train\n",
      "train mean loss=61805.255598958334\n",
      "test_test\n",
      "test mean loss=88156.1484375\n",
      "fin save.\n",
      "epoch 5475\n",
      "test_train\n",
      "train mean loss=61689.08645833333\n",
      "test_test\n",
      "test mean loss=88060.0\n",
      "fin save.\n",
      "epoch 5476\n",
      "test_train\n",
      "train mean loss=63340.96953125\n",
      "test_test\n",
      "test mean loss=88126.4921875\n",
      "fin save.\n",
      "epoch 5477\n",
      "test_train\n",
      "train mean loss=61771.23619791667\n",
      "test_test\n",
      "test mean loss=88133.24609375\n",
      "fin save.\n",
      "epoch 5478\n",
      "test_train\n",
      "train mean loss=61581.948046875\n",
      "test_test\n",
      "test mean loss=88221.2421875\n",
      "fin save.\n",
      "epoch 5479\n",
      "test_train\n",
      "train mean loss=62220.6296875\n",
      "test_test\n",
      "test mean loss=88196.95703125\n",
      "fin save.\n",
      "epoch 5480\n",
      "test_train\n",
      "train mean loss=61712.294270833336\n",
      "test_test\n",
      "test mean loss=88186.97265625\n",
      "fin save.\n",
      "epoch 5481\n",
      "test_train\n",
      "train mean loss=62680.087890625\n",
      "test_test\n",
      "test mean loss=88183.796875\n",
      "fin save.\n",
      "epoch 5482\n",
      "test_train\n",
      "train mean loss=63243.505078125\n",
      "test_test\n",
      "test mean loss=88132.97265625\n",
      "fin save.\n",
      "epoch 5483\n",
      "test_train\n",
      "train mean loss=62314.91067708333\n",
      "test_test\n",
      "test mean loss=88012.72265625\n",
      "fin save.\n",
      "epoch 5484\n",
      "test_train\n",
      "train mean loss=63099.4875\n",
      "test_test\n",
      "test mean loss=87894.9921875\n",
      "fin save.\n",
      "epoch 5485\n",
      "test_train\n",
      "train mean loss=61807.25338541667\n",
      "test_test\n",
      "test mean loss=88087.71875\n",
      "fin save.\n",
      "epoch 5486\n",
      "test_train\n",
      "train mean loss=63478.38828125\n",
      "test_test\n",
      "test mean loss=87539.08203125\n",
      "fin save.\n",
      "epoch 5487\n",
      "test_train\n",
      "train mean loss=62110.605729166666\n",
      "test_test\n",
      "test mean loss=87683.52734375\n",
      "fin save.\n",
      "epoch 5488\n",
      "test_train\n",
      "train mean loss=62481.708333333336\n",
      "test_test\n",
      "test mean loss=87546.12890625\n",
      "fin save.\n",
      "epoch 5489\n",
      "test_train\n",
      "train mean loss=62059.904036458334\n",
      "test_test\n",
      "test mean loss=87858.921875\n",
      "fin save.\n",
      "epoch 5490\n",
      "test_train\n",
      "train mean loss=61625.24661458333\n",
      "test_test\n",
      "test mean loss=87336.02734375\n",
      "fin save.\n",
      "epoch 5491\n",
      "test_train\n",
      "train mean loss=62112.9125\n",
      "test_test\n",
      "test mean loss=87739.5\n",
      "fin save.\n",
      "epoch 5492\n",
      "test_train\n",
      "train mean loss=62170.644270833334\n",
      "test_test\n",
      "test mean loss=87573.953125\n",
      "fin save.\n",
      "epoch 5493\n",
      "test_train\n",
      "train mean loss=61903.36015625\n",
      "test_test\n",
      "test mean loss=87448.828125\n",
      "fin save.\n",
      "epoch 5494\n",
      "test_train\n",
      "train mean loss=62171.47083333333\n",
      "test_test\n",
      "test mean loss=87389.49609375\n",
      "fin save.\n",
      "epoch 5495\n",
      "test_train\n",
      "train mean loss=62300.499739583334\n",
      "test_test\n",
      "test mean loss=87426.30078125\n",
      "fin save.\n",
      "epoch 5496\n",
      "test_train\n",
      "train mean loss=61401.09270833333\n",
      "test_test\n",
      "test mean loss=87437.81640625\n",
      "fin save.\n",
      "epoch 5497\n",
      "test_train\n",
      "train mean loss=61606.55625\n",
      "test_test\n",
      "test mean loss=87721.72265625\n",
      "fin save.\n",
      "epoch 5498\n",
      "test_train\n",
      "train mean loss=62032.739583333336\n",
      "test_test\n",
      "test mean loss=87777.94921875\n",
      "fin save.\n",
      "epoch 5499\n",
      "test_train\n",
      "train mean loss=61638.84270833333\n",
      "test_test\n",
      "test mean loss=87553.78125\n",
      "fin save.\n",
      "epoch 5500\n",
      "test_train\n",
      "train mean loss=61898.98385416667\n",
      "test_test\n",
      "test mean loss=87772.1484375\n",
      "fin save.\n",
      "epoch 5501\n",
      "test_train\n",
      "train mean loss=61392.42565104167\n",
      "test_test\n",
      "test mean loss=87730.81640625\n",
      "fin save.\n",
      "epoch 5502\n",
      "test_train\n",
      "train mean loss=61775.39635416667\n",
      "test_test\n",
      "test mean loss=87450.1953125\n",
      "fin save.\n",
      "epoch 5503\n",
      "test_train\n",
      "train mean loss=62496.13880208333\n",
      "test_test\n",
      "test mean loss=88008.63671875\n",
      "fin save.\n",
      "epoch 5504\n",
      "test_train\n",
      "train mean loss=62444.107682291666\n",
      "test_test\n",
      "test mean loss=88099.54296875\n",
      "fin save.\n",
      "epoch 5505\n",
      "test_train\n",
      "train mean loss=62500.592057291666\n",
      "test_test\n",
      "test mean loss=87951.21875\n",
      "fin save.\n",
      "epoch 5506\n",
      "test_train\n",
      "train mean loss=61839.78333333333\n",
      "test_test\n",
      "test mean loss=88159.11328125\n",
      "fin save.\n",
      "epoch 5507\n",
      "test_train\n",
      "train mean loss=62607.8015625\n",
      "test_test\n",
      "test mean loss=88291.24609375\n",
      "fin save.\n",
      "epoch 5508\n",
      "test_train\n",
      "train mean loss=61969.0984375\n",
      "test_test\n",
      "test mean loss=88372.79296875\n",
      "fin save.\n",
      "epoch 5509\n",
      "test_train\n",
      "train mean loss=61962.73932291667\n",
      "test_test\n",
      "test mean loss=88276.27734375\n",
      "fin save.\n",
      "epoch 5510\n",
      "test_train\n",
      "train mean loss=62742.39166666667\n",
      "test_test\n",
      "test mean loss=88170.34375\n",
      "fin save.\n",
      "epoch 5511\n",
      "test_train\n",
      "train mean loss=62415.43125\n",
      "test_test\n",
      "test mean loss=88102.27734375\n",
      "fin save.\n",
      "epoch 5512\n",
      "test_train\n",
      "train mean loss=62626.358203125\n",
      "test_test\n",
      "test mean loss=87207.85546875\n",
      "fin save.\n",
      "epoch 5513\n",
      "test_train\n",
      "train mean loss=62087.754296875\n",
      "test_test\n",
      "test mean loss=87334.03125\n",
      "fin save.\n",
      "epoch 5514\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_train\n",
      "train mean loss=62361.201432291666\n",
      "test_test\n",
      "test mean loss=87272.859375\n",
      "fin save.\n",
      "epoch 5515\n",
      "test_train\n",
      "train mean loss=61470.159375\n",
      "test_test\n",
      "test mean loss=87221.59375\n",
      "fin save.\n",
      "epoch 5516\n",
      "test_train\n",
      "train mean loss=62415.63958333333\n",
      "test_test\n",
      "test mean loss=87011.5078125\n",
      "fin save.\n",
      "epoch 5517\n",
      "test_train\n",
      "train mean loss=62236.69609375\n",
      "test_test\n",
      "test mean loss=87083.515625\n",
      "fin save.\n",
      "epoch 5518\n",
      "test_train\n",
      "train mean loss=62150.41549479167\n",
      "test_test\n",
      "test mean loss=86875.6953125\n",
      "fin save.\n",
      "epoch 5519\n",
      "test_train\n",
      "train mean loss=61589.977864583336\n",
      "test_test\n",
      "test mean loss=87348.8828125\n",
      "fin save.\n",
      "epoch 5520\n",
      "test_train\n",
      "train mean loss=61805.67864583333\n",
      "test_test\n",
      "test mean loss=86890.0625\n",
      "fin save.\n",
      "epoch 5521\n",
      "test_train\n",
      "train mean loss=62150.23229166667\n",
      "test_test\n",
      "test mean loss=86860.1015625\n",
      "fin save.\n",
      "epoch 5522\n",
      "test_train\n",
      "train mean loss=61577.16744791667\n",
      "test_test\n",
      "test mean loss=86952.65234375\n",
      "fin save.\n",
      "epoch 5523\n",
      "test_train\n",
      "train mean loss=62010.069010416664\n",
      "test_test\n",
      "test mean loss=86759.61328125\n",
      "fin save.\n",
      "epoch 5524\n",
      "test_train\n",
      "train mean loss=62954.32135416667\n",
      "test_test\n",
      "test mean loss=86895.65234375\n",
      "fin save.\n",
      "epoch 5525\n",
      "test_train\n",
      "train mean loss=63924.01953125\n",
      "test_test\n",
      "test mean loss=87232.05078125\n",
      "fin save.\n",
      "epoch 5526\n",
      "test_train\n",
      "train mean loss=62784.725\n",
      "test_test\n",
      "test mean loss=87409.7265625\n",
      "fin save.\n",
      "epoch 5527\n",
      "test_train\n",
      "train mean loss=61814.54440104167\n",
      "test_test\n",
      "test mean loss=87066.8203125\n",
      "fin save.\n",
      "epoch 5528\n",
      "test_train\n",
      "train mean loss=61076.3\n",
      "test_test\n",
      "test mean loss=87633.703125\n",
      "fin save.\n",
      "epoch 5529\n",
      "test_train\n",
      "train mean loss=62298.48125\n",
      "test_test\n",
      "test mean loss=87858.84375\n",
      "fin save.\n",
      "epoch 5530\n",
      "test_train\n",
      "train mean loss=61994.28515625\n",
      "test_test\n",
      "test mean loss=87807.72265625\n",
      "fin save.\n",
      "epoch 5531\n",
      "test_train\n",
      "train mean loss=61954.858723958336\n",
      "test_test\n",
      "test mean loss=87895.1640625\n",
      "fin save.\n",
      "epoch 5532\n",
      "test_train\n",
      "train mean loss=62694.47578125\n",
      "test_test\n",
      "test mean loss=87756.76171875\n",
      "fin save.\n",
      "epoch 5533\n",
      "test_train\n",
      "train mean loss=63382.22604166667\n",
      "test_test\n",
      "test mean loss=87634.3125\n",
      "fin save.\n",
      "epoch 5534\n",
      "test_train\n",
      "train mean loss=63025.57122395833\n",
      "test_test\n",
      "test mean loss=87551.96484375\n",
      "fin save.\n",
      "epoch 5535\n",
      "test_train\n",
      "train mean loss=61995.87734375\n",
      "test_test\n",
      "test mean loss=87766.24609375\n",
      "fin save.\n",
      "epoch 5536\n",
      "test_train\n",
      "train mean loss=63245.08216145833\n",
      "test_test\n",
      "test mean loss=88669.41015625\n",
      "fin save.\n",
      "epoch 5537\n",
      "test_train\n",
      "train mean loss=62373.43958333333\n",
      "test_test\n",
      "test mean loss=88493.6640625\n",
      "fin save.\n",
      "epoch 5538\n",
      "test_train\n",
      "train mean loss=62419.770703125\n",
      "test_test\n",
      "test mean loss=88018.40625\n",
      "fin save.\n",
      "epoch 5539\n",
      "test_train\n",
      "train mean loss=62886.462239583336\n",
      "test_test\n",
      "test mean loss=88111.6484375\n",
      "fin save.\n",
      "epoch 5540\n",
      "test_train\n",
      "train mean loss=61977.45520833333\n",
      "test_test\n",
      "test mean loss=88242.078125\n",
      "fin save.\n",
      "epoch 5541\n",
      "test_train\n",
      "train mean loss=62105.46041666667\n",
      "test_test\n",
      "test mean loss=88191.7890625\n",
      "fin save.\n",
      "epoch 5542\n",
      "test_train\n",
      "train mean loss=62793.984635416666\n",
      "test_test\n",
      "test mean loss=88074.76171875\n",
      "fin save.\n",
      "epoch 5543\n",
      "test_train\n",
      "train mean loss=62719.742447916666\n",
      "test_test\n",
      "test mean loss=87780.3125\n",
      "fin save.\n",
      "epoch 5544\n",
      "test_train\n",
      "train mean loss=62810.74453125\n",
      "test_test\n",
      "test mean loss=87935.71484375\n",
      "fin save.\n",
      "epoch 5545\n",
      "test_train\n",
      "train mean loss=62569.24752604167\n",
      "test_test\n",
      "test mean loss=87893.33203125\n",
      "fin save.\n",
      "epoch 5546\n",
      "test_train\n",
      "train mean loss=62685.92109375\n",
      "test_test\n",
      "test mean loss=87880.29296875\n",
      "fin save.\n",
      "epoch 5547\n",
      "test_train\n",
      "train mean loss=63364.17526041667\n",
      "test_test\n",
      "test mean loss=87733.58203125\n",
      "fin save.\n",
      "epoch 5548\n",
      "test_train\n",
      "train mean loss=62275.02057291667\n",
      "test_test\n",
      "test mean loss=87747.6328125\n",
      "fin save.\n",
      "epoch 5549\n",
      "test_train\n",
      "train mean loss=62554.37799479167\n",
      "test_test\n",
      "test mean loss=87610.7890625\n",
      "fin save.\n",
      "epoch 5550\n",
      "test_train\n",
      "train mean loss=63373.898046875\n",
      "test_test\n",
      "test mean loss=87808.09375\n",
      "fin save.\n",
      "epoch 5551\n",
      "test_train\n",
      "train mean loss=63220.83776041667\n",
      "test_test\n",
      "test mean loss=87428.859375\n",
      "fin save.\n",
      "epoch 5552\n",
      "test_train\n",
      "train mean loss=62151.88723958333\n",
      "test_test\n",
      "test mean loss=88087.0625\n",
      "fin save.\n",
      "epoch 5553\n",
      "test_train\n",
      "train mean loss=63278.221875\n",
      "test_test\n",
      "test mean loss=87995.14453125\n",
      "fin save.\n",
      "epoch 5554\n",
      "test_train\n",
      "train mean loss=63534.551041666666\n",
      "test_test\n",
      "test mean loss=87603.6171875\n",
      "fin save.\n",
      "epoch 5555\n",
      "test_train\n",
      "train mean loss=62659.20625\n",
      "test_test\n",
      "test mean loss=87783.61328125\n",
      "fin save.\n",
      "epoch 5556\n",
      "test_train\n",
      "train mean loss=62498.925130208336\n",
      "test_test\n",
      "test mean loss=88318.46484375\n",
      "fin save.\n",
      "epoch 5557\n",
      "test_train\n",
      "train mean loss=63280.05911458333\n",
      "test_test\n",
      "test mean loss=88019.59765625\n",
      "fin save.\n",
      "epoch 5558\n",
      "test_train\n",
      "train mean loss=62615.22317708333\n",
      "test_test\n",
      "test mean loss=88224.60546875\n",
      "fin save.\n",
      "epoch 5559\n",
      "test_train\n",
      "train mean loss=62427.20494791667\n",
      "test_test\n",
      "test mean loss=88083.671875\n",
      "fin save.\n",
      "epoch 5560\n",
      "test_train\n",
      "train mean loss=63421.288802083334\n",
      "test_test\n",
      "test mean loss=87930.21875\n",
      "fin save.\n",
      "epoch 5561\n",
      "test_train\n",
      "train mean loss=62640.554427083334\n",
      "test_test\n",
      "test mean loss=88013.328125\n",
      "fin save.\n",
      "epoch 5562\n",
      "test_train\n",
      "train mean loss=63334.861588541666\n",
      "test_test\n",
      "test mean loss=88270.1953125\n",
      "fin save.\n",
      "epoch 5563\n",
      "test_train\n",
      "train mean loss=62437.97057291667\n",
      "test_test\n",
      "test mean loss=88147.46875\n",
      "fin save.\n",
      "epoch 5564\n",
      "test_train\n",
      "train mean loss=62456.335677083334\n",
      "test_test\n",
      "test mean loss=88386.734375\n",
      "fin save.\n",
      "epoch 5565\n",
      "test_train\n",
      "train mean loss=63448.925520833334\n",
      "test_test\n",
      "test mean loss=88244.65234375\n",
      "fin save.\n",
      "epoch 5566\n",
      "test_train\n",
      "train mean loss=62595.1578125\n",
      "test_test\n",
      "test mean loss=88097.0078125\n",
      "fin save.\n",
      "epoch 5567\n",
      "test_train\n",
      "train mean loss=63541.945052083334\n",
      "test_test\n",
      "test mean loss=88007.0546875\n",
      "fin save.\n",
      "epoch 5568\n",
      "test_train\n",
      "train mean loss=62784.51354166667\n",
      "test_test\n",
      "test mean loss=88102.59765625\n",
      "fin save.\n",
      "epoch 5569\n",
      "test_train\n",
      "train mean loss=62681.67369791667\n",
      "test_test\n",
      "test mean loss=88020.51171875\n",
      "fin save.\n",
      "epoch 5570\n",
      "test_train\n",
      "train mean loss=62641.38984375\n",
      "test_test\n",
      "test mean loss=88121.41796875\n",
      "fin save.\n",
      "epoch 5571\n",
      "test_train\n",
      "train mean loss=62744.42265625\n",
      "test_test\n",
      "test mean loss=88100.6484375\n",
      "fin save.\n",
      "epoch 5572\n",
      "test_train\n",
      "train mean loss=62195.35078125\n",
      "test_test\n",
      "test mean loss=87974.6015625\n",
      "fin save.\n",
      "epoch 5573\n",
      "test_train\n",
      "train mean loss=62374.93893229167\n",
      "test_test\n",
      "test mean loss=87975.640625\n",
      "fin save.\n",
      "epoch 5574\n",
      "test_train\n",
      "train mean loss=61768.335546875\n",
      "test_test\n",
      "test mean loss=88012.88671875\n",
      "fin save.\n",
      "epoch 5575\n",
      "test_train\n",
      "train mean loss=62661.77682291667\n",
      "test_test\n",
      "test mean loss=88404.7734375\n",
      "fin save.\n",
      "epoch 5576\n",
      "test_train\n",
      "train mean loss=63790.85598958333\n",
      "test_test\n",
      "test mean loss=88491.34375\n",
      "fin save.\n",
      "epoch 5577\n",
      "test_train\n",
      "train mean loss=62534.88385416667\n",
      "test_test\n",
      "test mean loss=88510.9609375\n",
      "fin save.\n",
      "epoch 5578\n",
      "test_train\n",
      "train mean loss=62530.44088541667\n",
      "test_test\n",
      "test mean loss=88384.01953125\n",
      "fin save.\n",
      "epoch 5579\n",
      "test_train\n",
      "train mean loss=62687.61432291667\n",
      "test_test\n",
      "test mean loss=88534.328125\n",
      "fin save.\n",
      "epoch 5580\n",
      "test_train\n",
      "train mean loss=63263.11432291667\n",
      "test_test\n",
      "test mean loss=88554.71875\n",
      "fin save.\n",
      "epoch 5581\n",
      "test_train\n",
      "train mean loss=62366.254166666666\n",
      "test_test\n",
      "test mean loss=88564.59765625\n",
      "fin save.\n",
      "epoch 5582\n",
      "test_train\n",
      "train mean loss=62142.64765625\n",
      "test_test\n",
      "test mean loss=88553.7265625\n",
      "fin save.\n",
      "epoch 5583\n",
      "test_train\n",
      "train mean loss=64208.69322916667\n",
      "test_test\n",
      "test mean loss=88088.8671875\n",
      "fin save.\n",
      "epoch 5584\n",
      "test_train\n",
      "train mean loss=64192.2375\n",
      "test_test\n",
      "test mean loss=87988.5625\n",
      "fin save.\n",
      "epoch 5585\n",
      "test_train\n",
      "train mean loss=62125.83997395833\n",
      "test_test\n",
      "test mean loss=88020.17578125\n",
      "fin save.\n",
      "epoch 5586\n",
      "test_train\n",
      "train mean loss=62068.53359375\n",
      "test_test\n",
      "test mean loss=88212.23828125\n",
      "fin save.\n",
      "epoch 5587\n",
      "test_train\n",
      "train mean loss=62280.79296875\n",
      "test_test\n",
      "test mean loss=88212.99609375\n",
      "fin save.\n",
      "epoch 5588\n",
      "test_train\n",
      "train mean loss=62039.41171875\n",
      "test_test\n",
      "test mean loss=87969.8125\n",
      "fin save.\n",
      "epoch 5589\n",
      "test_train\n",
      "train mean loss=62512.172265625\n",
      "test_test\n",
      "test mean loss=88454.7421875\n",
      "fin save.\n",
      "epoch 5590\n",
      "test_train\n",
      "train mean loss=63050.01119791667\n",
      "test_test\n",
      "test mean loss=88381.6640625\n",
      "fin save.\n",
      "epoch 5591\n",
      "test_train\n",
      "train mean loss=63148.052083333336\n",
      "test_test\n",
      "test mean loss=88556.25\n",
      "fin save.\n",
      "epoch 5592\n",
      "test_train\n",
      "train mean loss=62082.51380208333\n",
      "test_test\n",
      "test mean loss=88753.26953125\n",
      "fin save.\n",
      "epoch 5593\n",
      "test_train\n",
      "train mean loss=63074.00729166667\n",
      "test_test\n",
      "test mean loss=88864.890625\n",
      "fin save.\n",
      "epoch 5594\n",
      "test_train\n",
      "train mean loss=62524.90520833333\n",
      "test_test\n",
      "test mean loss=88495.171875\n",
      "fin save.\n",
      "epoch 5595\n",
      "test_train\n",
      "train mean loss=62504.81953125\n",
      "test_test\n",
      "test mean loss=88458.0859375\n",
      "fin save.\n",
      "epoch 5596\n",
      "test_train\n",
      "train mean loss=62264.2703125\n",
      "test_test\n",
      "test mean loss=88465.4921875\n",
      "fin save.\n",
      "epoch 5597\n",
      "test_train\n",
      "train mean loss=61946.860677083336\n",
      "test_test\n",
      "test mean loss=88460.83984375\n",
      "fin save.\n",
      "epoch 5598\n",
      "test_train\n",
      "train mean loss=62799.07135416667\n",
      "test_test\n",
      "test mean loss=88437.15625\n",
      "fin save.\n",
      "epoch 5599\n",
      "test_train\n",
      "train mean loss=61731.812239583334\n",
      "test_test\n",
      "test mean loss=88455.4375\n",
      "fin save.\n",
      "epoch 5600\n",
      "test_train\n",
      "train mean loss=62918.46145833333\n",
      "test_test\n",
      "test mean loss=88560.6484375\n",
      "fin save.\n",
      "epoch 5601\n",
      "test_train\n",
      "train mean loss=62723.48645833333\n",
      "test_test\n",
      "test mean loss=88613.23046875\n",
      "fin save.\n",
      "epoch 5602\n",
      "test_train\n",
      "train mean loss=63530.02330729167\n",
      "test_test\n",
      "test mean loss=88665.1875\n",
      "fin save.\n",
      "epoch 5603\n",
      "test_train\n",
      "train mean loss=62821.7984375\n",
      "test_test\n",
      "test mean loss=88627.6015625\n",
      "fin save.\n",
      "epoch 5604\n",
      "test_train\n",
      "train mean loss=62885.313802083336\n",
      "test_test\n",
      "test mean loss=88770.40625\n",
      "fin save.\n",
      "epoch 5605\n",
      "test_train\n",
      "train mean loss=62605.65234375\n",
      "test_test\n",
      "test mean loss=88669.29296875\n",
      "fin save.\n",
      "epoch 5606\n",
      "test_train\n",
      "train mean loss=63057.94739583333\n",
      "test_test\n",
      "test mean loss=88695.6796875\n",
      "fin save.\n",
      "epoch 5607\n",
      "test_train\n",
      "train mean loss=63023.82994791667\n",
      "test_test\n",
      "test mean loss=88743.1328125\n",
      "fin save.\n",
      "epoch 5608\n",
      "test_train\n",
      "train mean loss=62600.8390625\n",
      "test_test\n",
      "test mean loss=88754.109375\n",
      "fin save.\n",
      "epoch 5609\n",
      "test_train\n",
      "train mean loss=62418.714583333334\n",
      "test_test\n",
      "test mean loss=88751.19921875\n",
      "fin save.\n",
      "epoch 5610\n",
      "test_train\n",
      "train mean loss=62303.015885416666\n",
      "test_test\n",
      "test mean loss=88728.37890625\n",
      "fin save.\n",
      "epoch 5611\n",
      "test_train\n",
      "train mean loss=62481.0984375\n",
      "test_test\n",
      "test mean loss=88808.26171875\n",
      "fin save.\n",
      "epoch 5612\n",
      "test_train\n",
      "train mean loss=63136.3203125\n",
      "test_test\n",
      "test mean loss=88707.7578125\n",
      "fin save.\n",
      "epoch 5613\n",
      "test_train\n",
      "train mean loss=62637.56692708333\n",
      "test_test\n",
      "test mean loss=89054.04296875\n",
      "fin save.\n",
      "epoch 5614\n",
      "test_train\n",
      "train mean loss=63509.45130208333\n",
      "test_test\n",
      "test mean loss=88852.65234375\n",
      "fin save.\n",
      "epoch 5615\n",
      "test_train\n",
      "train mean loss=62608.09479166667\n",
      "test_test\n",
      "test mean loss=88842.54296875\n",
      "fin save.\n",
      "epoch 5616\n",
      "test_train\n",
      "train mean loss=61536.992447916666\n",
      "test_test\n",
      "test mean loss=88956.1484375\n",
      "fin save.\n",
      "epoch 5617\n",
      "test_train\n",
      "train mean loss=62775.225\n",
      "test_test\n",
      "test mean loss=88614.24609375\n",
      "fin save.\n",
      "epoch 5618\n",
      "test_train\n",
      "train mean loss=62527.120833333334\n",
      "test_test\n",
      "test mean loss=88717.77734375\n",
      "fin save.\n",
      "epoch 5619\n",
      "test_train\n",
      "train mean loss=62529.56197916667\n",
      "test_test\n",
      "test mean loss=88518.44921875\n",
      "fin save.\n",
      "epoch 5620\n",
      "test_train\n",
      "train mean loss=62712.23984375\n",
      "test_test\n",
      "test mean loss=88325.82421875\n",
      "fin save.\n",
      "epoch 5621\n",
      "test_train\n",
      "train mean loss=62039.74427083333\n",
      "test_test\n",
      "test mean loss=88619.6171875\n",
      "fin save.\n",
      "epoch 5622\n",
      "test_train\n",
      "train mean loss=63073.95104166667\n",
      "test_test\n",
      "test mean loss=88521.65625\n",
      "fin save.\n",
      "epoch 5623\n",
      "test_train\n",
      "train mean loss=62155.4265625\n",
      "test_test\n",
      "test mean loss=88429.953125\n",
      "fin save.\n",
      "epoch 5624\n",
      "test_train\n",
      "train mean loss=61702.16614583333\n",
      "test_test\n",
      "test mean loss=88367.40625\n",
      "fin save.\n",
      "epoch 5625\n",
      "test_train\n",
      "train mean loss=63274.7234375\n",
      "test_test\n",
      "test mean loss=88328.50390625\n",
      "fin save.\n",
      "epoch 5626\n",
      "test_train\n",
      "train mean loss=61461.212239583336\n",
      "test_test\n",
      "test mean loss=88472.53515625\n",
      "fin save.\n",
      "epoch 5627\n",
      "test_train\n",
      "train mean loss=62559.375260416666\n",
      "test_test\n",
      "test mean loss=88444.84375\n",
      "fin save.\n",
      "epoch 5628\n",
      "test_train\n",
      "train mean loss=63294.9625\n",
      "test_test\n",
      "test mean loss=88470.12109375\n",
      "fin save.\n",
      "epoch 5629\n",
      "test_train\n",
      "train mean loss=63324.49401041667\n",
      "test_test\n",
      "test mean loss=88324.0703125\n",
      "fin save.\n",
      "epoch 5630\n",
      "test_train\n",
      "train mean loss=63074.5125\n",
      "test_test\n",
      "test mean loss=88330.91015625\n",
      "fin save.\n",
      "epoch 5631\n",
      "test_train\n",
      "train mean loss=61820.844010416666\n",
      "test_test\n",
      "test mean loss=88383.53515625\n",
      "fin save.\n",
      "epoch 5632\n",
      "test_train\n",
      "train mean loss=62210.70611979167\n",
      "test_test\n",
      "test mean loss=88147.15234375\n",
      "fin save.\n",
      "epoch 5633\n",
      "test_train\n",
      "train mean loss=62541.365885416664\n",
      "test_test\n",
      "test mean loss=88263.15625\n",
      "fin save.\n",
      "epoch 5634\n",
      "test_train\n",
      "train mean loss=62872.67669270833\n",
      "test_test\n",
      "test mean loss=88324.83984375\n",
      "fin save.\n",
      "epoch 5635\n",
      "test_train\n",
      "train mean loss=63250.86015625\n",
      "test_test\n",
      "test mean loss=88026.984375\n",
      "fin save.\n",
      "epoch 5636\n",
      "test_train\n",
      "train mean loss=63739.68697916667\n",
      "test_test\n",
      "test mean loss=88465.3046875\n",
      "fin save.\n",
      "epoch 5637\n",
      "test_train\n",
      "train mean loss=63035.10494791667\n",
      "test_test\n",
      "test mean loss=88386.640625\n",
      "fin save.\n",
      "epoch 5638\n",
      "test_train\n",
      "train mean loss=62224.463541666664\n",
      "test_test\n",
      "test mean loss=88525.8671875\n",
      "fin save.\n",
      "epoch 5639\n",
      "test_train\n",
      "train mean loss=62334.748046875\n",
      "test_test\n",
      "test mean loss=88469.75390625\n",
      "fin save.\n",
      "epoch 5640\n",
      "test_train\n",
      "train mean loss=62701.496875\n",
      "test_test\n",
      "test mean loss=88505.375\n",
      "fin save.\n",
      "epoch 5641\n",
      "test_train\n",
      "train mean loss=60682.270833333336\n",
      "test_test\n",
      "test mean loss=88441.875\n",
      "fin save.\n",
      "epoch 5642\n",
      "test_train\n",
      "train mean loss=62970.426432291664\n",
      "test_test\n",
      "test mean loss=88468.8203125\n",
      "fin save.\n",
      "epoch 5643\n",
      "test_train\n",
      "train mean loss=62991.03763020833\n",
      "test_test\n",
      "test mean loss=88672.24609375\n",
      "fin save.\n",
      "epoch 5644\n",
      "test_train\n",
      "train mean loss=62729.527994791664\n",
      "test_test\n",
      "test mean loss=88379.33203125\n",
      "fin save.\n",
      "epoch 5645\n",
      "test_train\n",
      "train mean loss=61553.285416666666\n",
      "test_test\n",
      "test mean loss=88221.6953125\n",
      "fin save.\n",
      "epoch 5646\n",
      "test_train\n",
      "train mean loss=61423.205338541666\n",
      "test_test\n",
      "test mean loss=88255.515625\n",
      "fin save.\n",
      "epoch 5647\n",
      "test_train\n",
      "train mean loss=63327.88580729167\n",
      "test_test\n",
      "test mean loss=88071.734375\n",
      "fin save.\n",
      "epoch 5648\n",
      "test_train\n",
      "train mean loss=62311.83776041667\n",
      "test_test\n",
      "test mean loss=88292.41796875\n",
      "fin save.\n",
      "epoch 5649\n",
      "test_train\n",
      "train mean loss=63080.528125\n",
      "test_test\n",
      "test mean loss=88300.7578125\n",
      "fin save.\n",
      "epoch 5650\n",
      "test_train\n",
      "train mean loss=62799.51953125\n",
      "test_test\n",
      "test mean loss=88274.89453125\n",
      "fin save.\n",
      "epoch 5651\n",
      "test_train\n",
      "train mean loss=62519.34661458333\n",
      "test_test\n",
      "test mean loss=88347.6484375\n",
      "fin save.\n",
      "epoch 5652\n",
      "test_train\n",
      "train mean loss=62126.93932291667\n",
      "test_test\n",
      "test mean loss=88027.1171875\n",
      "fin save.\n",
      "epoch 5653\n",
      "test_train\n",
      "train mean loss=63246.534505208336\n",
      "test_test\n",
      "test mean loss=88129.08984375\n",
      "fin save.\n",
      "epoch 5654\n",
      "test_train\n",
      "train mean loss=62347.88515625\n",
      "test_test\n",
      "test mean loss=88192.828125\n",
      "fin save.\n",
      "epoch 5655\n",
      "test_train\n",
      "train mean loss=62464.50104166667\n",
      "test_test\n",
      "test mean loss=88080.3671875\n",
      "fin save.\n",
      "epoch 5656\n",
      "test_train\n",
      "train mean loss=62929.606770833336\n",
      "test_test\n",
      "test mean loss=88132.203125\n",
      "fin save.\n",
      "epoch 5657\n",
      "test_train\n",
      "train mean loss=62900.259375\n",
      "test_test\n",
      "test mean loss=88060.84375\n",
      "fin save.\n",
      "epoch 5658\n",
      "test_train\n",
      "train mean loss=62284.71276041667\n",
      "test_test\n",
      "test mean loss=88660.6953125\n",
      "fin save.\n",
      "epoch 5659\n",
      "test_train\n",
      "train mean loss=62161.50104166667\n",
      "test_test\n",
      "test mean loss=88516.0\n",
      "fin save.\n",
      "epoch 5660\n",
      "test_train\n",
      "train mean loss=62887.30234375\n",
      "test_test\n",
      "test mean loss=88454.77734375\n",
      "fin save.\n",
      "epoch 5661\n",
      "test_train\n",
      "train mean loss=62202.88333333333\n",
      "test_test\n",
      "test mean loss=88347.7265625\n",
      "fin save.\n",
      "epoch 5662\n",
      "test_train\n",
      "train mean loss=61798.79153645833\n",
      "test_test\n",
      "test mean loss=88325.6875\n",
      "fin save.\n",
      "epoch 5663\n",
      "test_train\n",
      "train mean loss=62760.154036458334\n",
      "test_test\n",
      "test mean loss=88356.16015625\n",
      "fin save.\n",
      "epoch 5664\n",
      "test_train\n",
      "train mean loss=62693.33828125\n",
      "test_test\n",
      "test mean loss=88552.78125\n",
      "fin save.\n",
      "epoch 5665\n",
      "test_train\n",
      "train mean loss=62496.7984375\n",
      "test_test\n",
      "test mean loss=88407.76171875\n",
      "fin save.\n",
      "epoch 5666\n",
      "test_train\n",
      "train mean loss=61587.26484375\n",
      "test_test\n",
      "test mean loss=88551.03125\n",
      "fin save.\n",
      "epoch 5667\n",
      "test_train\n",
      "train mean loss=61555.76484375\n",
      "test_test\n",
      "test mean loss=88399.98046875\n",
      "fin save.\n",
      "epoch 5668\n",
      "test_train\n",
      "train mean loss=63390.538802083334\n",
      "test_test\n",
      "test mean loss=88569.46484375\n",
      "fin save.\n",
      "epoch 5669\n",
      "test_train\n",
      "train mean loss=61516.51640625\n",
      "test_test\n",
      "test mean loss=88451.8046875\n",
      "fin save.\n",
      "epoch 5670\n",
      "test_train\n",
      "train mean loss=62267.02109375\n",
      "test_test\n",
      "test mean loss=88851.44140625\n",
      "fin save.\n",
      "epoch 5671\n",
      "test_train\n",
      "train mean loss=62297.498307291666\n",
      "test_test\n",
      "test mean loss=88620.390625\n",
      "fin save.\n",
      "epoch 5672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_train\n",
      "train mean loss=62315.43255208333\n",
      "test_test\n",
      "test mean loss=88567.421875\n",
      "fin save.\n",
      "epoch 5673\n",
      "test_train\n",
      "train mean loss=62144.402083333334\n",
      "test_test\n",
      "test mean loss=88437.6875\n",
      "fin save.\n",
      "epoch 5674\n",
      "test_train\n",
      "train mean loss=61763.84713541667\n",
      "test_test\n",
      "test mean loss=88415.88671875\n",
      "fin save.\n",
      "epoch 5675\n",
      "test_train\n",
      "train mean loss=62262.19479166667\n",
      "test_test\n",
      "test mean loss=88623.734375\n",
      "fin save.\n",
      "epoch 5676\n",
      "test_train\n",
      "train mean loss=62304.36119791667\n",
      "test_test\n",
      "test mean loss=89029.52734375\n",
      "fin save.\n",
      "epoch 5677\n",
      "test_train\n",
      "train mean loss=62139.02916666667\n",
      "test_test\n",
      "test mean loss=89115.28515625\n",
      "fin save.\n",
      "epoch 5678\n",
      "test_train\n",
      "train mean loss=62822.83151041667\n",
      "test_test\n",
      "test mean loss=89046.09375\n",
      "fin save.\n",
      "epoch 5679\n",
      "test_train\n",
      "train mean loss=63004.30416666667\n",
      "test_test\n",
      "test mean loss=88981.1953125\n",
      "fin save.\n",
      "epoch 5680\n",
      "test_train\n",
      "train mean loss=62762.8859375\n",
      "test_test\n",
      "test mean loss=88711.28125\n",
      "fin save.\n",
      "epoch 5681\n",
      "test_train\n",
      "train mean loss=63414.7921875\n",
      "test_test\n",
      "test mean loss=88455.515625\n",
      "fin save.\n",
      "epoch 5682\n",
      "test_train\n",
      "train mean loss=62659.694140625\n",
      "test_test\n",
      "test mean loss=88485.34765625\n",
      "fin save.\n",
      "epoch 5683\n",
      "test_train\n",
      "train mean loss=63344.20104166667\n",
      "test_test\n",
      "test mean loss=87867.40234375\n",
      "fin save.\n",
      "epoch 5684\n",
      "test_train\n",
      "train mean loss=62416.171614583334\n",
      "test_test\n",
      "test mean loss=88080.58203125\n",
      "fin save.\n",
      "epoch 5685\n",
      "test_train\n",
      "train mean loss=62696.4875\n",
      "test_test\n",
      "test mean loss=88004.53125\n",
      "fin save.\n",
      "epoch 5686\n",
      "test_train\n",
      "train mean loss=62294.227213541664\n",
      "test_test\n",
      "test mean loss=87948.27734375\n",
      "fin save.\n",
      "epoch 5687\n",
      "test_train\n",
      "train mean loss=61826.10989583333\n",
      "test_test\n",
      "test mean loss=87959.65234375\n",
      "fin save.\n",
      "epoch 5688\n",
      "test_train\n",
      "train mean loss=63118.620442708336\n",
      "test_test\n",
      "test mean loss=87994.41015625\n",
      "fin save.\n",
      "epoch 5689\n",
      "test_train\n",
      "train mean loss=62230.601822916666\n",
      "test_test\n",
      "test mean loss=87861.29296875\n",
      "fin save.\n",
      "epoch 5690\n",
      "test_train\n",
      "train mean loss=61646.61953125\n",
      "test_test\n",
      "test mean loss=87863.66796875\n",
      "fin save.\n",
      "epoch 5691\n",
      "test_train\n",
      "train mean loss=62455.010416666664\n",
      "test_test\n",
      "test mean loss=87886.625\n",
      "fin save.\n",
      "epoch 5692\n",
      "test_train\n",
      "train mean loss=62658.147135416664\n",
      "test_test\n",
      "test mean loss=87954.22265625\n",
      "fin save.\n",
      "epoch 5693\n",
      "test_train\n",
      "train mean loss=61287.402604166666\n",
      "test_test\n",
      "test mean loss=87896.98828125\n",
      "fin save.\n",
      "epoch 5694\n",
      "test_train\n",
      "train mean loss=62606.809765625\n",
      "test_test\n",
      "test mean loss=87693.9296875\n",
      "fin save.\n",
      "epoch 5695\n",
      "test_train\n",
      "train mean loss=62410.909375\n",
      "test_test\n",
      "test mean loss=88223.84375\n",
      "fin save.\n",
      "epoch 5696\n",
      "test_train\n",
      "train mean loss=61578.626302083336\n",
      "test_test\n",
      "test mean loss=87952.578125\n",
      "fin save.\n",
      "epoch 5697\n",
      "test_train\n",
      "train mean loss=61222.17473958333\n",
      "test_test\n",
      "test mean loss=88338.53515625\n",
      "fin save.\n",
      "epoch 5698\n",
      "test_train\n",
      "train mean loss=62069.23229166667\n",
      "test_test\n",
      "test mean loss=88214.47265625\n",
      "fin save.\n",
      "epoch 5699\n",
      "test_train\n",
      "train mean loss=62382.3515625\n",
      "test_test\n",
      "test mean loss=88288.98828125\n",
      "fin save.\n",
      "epoch 5700\n",
      "test_train\n",
      "train mean loss=61488.30963541667\n",
      "test_test\n",
      "test mean loss=88166.40625\n",
      "fin save.\n",
      "epoch 5701\n",
      "test_train\n",
      "train mean loss=62045.045572916664\n",
      "test_test\n",
      "test mean loss=88347.9609375\n",
      "fin save.\n",
      "epoch 5702\n",
      "test_train\n",
      "train mean loss=61886.432291666664\n",
      "test_test\n",
      "test mean loss=88337.37109375\n",
      "fin save.\n",
      "epoch 5703\n",
      "test_train\n",
      "train mean loss=62877.75286458333\n",
      "test_test\n",
      "test mean loss=88295.984375\n",
      "fin save.\n",
      "epoch 5704\n",
      "test_train\n",
      "train mean loss=62782.991796875\n",
      "test_test\n",
      "test mean loss=88316.18359375\n",
      "fin save.\n",
      "epoch 5705\n",
      "test_train\n",
      "train mean loss=62178.9015625\n",
      "test_test\n",
      "test mean loss=88073.84375\n",
      "fin save.\n",
      "epoch 5706\n",
      "test_train\n",
      "train mean loss=62204.98932291667\n",
      "test_test\n",
      "test mean loss=88154.7578125\n",
      "fin save.\n",
      "epoch 5707\n",
      "test_train\n",
      "train mean loss=62435.7890625\n",
      "test_test\n",
      "test mean loss=88198.2421875\n",
      "fin save.\n",
      "epoch 5708\n",
      "test_train\n",
      "train mean loss=61609.3703125\n",
      "test_test\n",
      "test mean loss=88281.5\n",
      "fin save.\n",
      "epoch 5709\n",
      "test_train\n",
      "train mean loss=62309.02239583333\n",
      "test_test\n",
      "test mean loss=88336.265625\n",
      "fin save.\n",
      "epoch 5710\n",
      "test_train\n",
      "train mean loss=62418.265364583334\n",
      "test_test\n",
      "test mean loss=88182.48828125\n",
      "fin save.\n",
      "epoch 5711\n",
      "test_train\n",
      "train mean loss=62659.02161458333\n",
      "test_test\n",
      "test mean loss=87985.8671875\n",
      "fin save.\n",
      "epoch 5712\n",
      "test_train\n",
      "train mean loss=61672.14661458333\n",
      "test_test\n",
      "test mean loss=88277.93359375\n",
      "fin save.\n",
      "epoch 5713\n",
      "test_train\n",
      "train mean loss=61727.17473958333\n",
      "test_test\n",
      "test mean loss=88468.859375\n",
      "fin save.\n",
      "epoch 5714\n",
      "test_train\n",
      "train mean loss=61732.022135416664\n",
      "test_test\n",
      "test mean loss=88436.4921875\n",
      "fin save.\n",
      "epoch 5715\n",
      "test_train\n",
      "train mean loss=63573.54244791667\n",
      "test_test\n",
      "test mean loss=88647.078125\n",
      "fin save.\n",
      "epoch 5716\n",
      "test_train\n",
      "train mean loss=62213.95885416667\n",
      "test_test\n",
      "test mean loss=88696.12890625\n",
      "fin save.\n",
      "epoch 5717\n",
      "test_train\n",
      "train mean loss=62263.242578125\n",
      "test_test\n",
      "test mean loss=88409.234375\n",
      "fin save.\n",
      "epoch 5718\n",
      "test_train\n",
      "train mean loss=61947.78515625\n",
      "test_test\n",
      "test mean loss=87539.421875\n",
      "fin save.\n",
      "epoch 5719\n",
      "test_train\n",
      "train mean loss=63337.2265625\n",
      "test_test\n",
      "test mean loss=87283.078125\n",
      "fin save.\n",
      "epoch 5720\n",
      "test_train\n",
      "train mean loss=61788.90390625\n",
      "test_test\n",
      "test mean loss=87499.77734375\n",
      "fin save.\n",
      "epoch 5721\n",
      "test_train\n",
      "train mean loss=61736.40091145833\n",
      "test_test\n",
      "test mean loss=87448.94140625\n",
      "fin save.\n",
      "epoch 5722\n",
      "test_train\n",
      "train mean loss=61916.53072916667\n",
      "test_test\n",
      "test mean loss=87875.50390625\n",
      "fin save.\n",
      "epoch 5723\n",
      "test_train\n",
      "train mean loss=62272.8546875\n",
      "test_test\n",
      "test mean loss=87181.73046875\n",
      "fin save.\n",
      "epoch 5724\n",
      "test_train\n",
      "train mean loss=62016.546223958336\n",
      "test_test\n",
      "test mean loss=87072.03515625\n",
      "fin save.\n",
      "epoch 5725\n",
      "test_train\n",
      "train mean loss=61945.32135416667\n",
      "test_test\n",
      "test mean loss=87332.08984375\n",
      "fin save.\n",
      "epoch 5726\n",
      "test_train\n",
      "train mean loss=62436.96666666667\n",
      "test_test\n",
      "test mean loss=87527.00390625\n",
      "fin save.\n",
      "epoch 5727\n",
      "test_train\n",
      "train mean loss=61630.001171875\n",
      "test_test\n",
      "test mean loss=87307.51953125\n",
      "fin save.\n",
      "epoch 5728\n",
      "test_train\n",
      "train mean loss=62306.04609375\n",
      "test_test\n",
      "test mean loss=87132.76953125\n",
      "fin save.\n",
      "epoch 5729\n",
      "test_train\n",
      "train mean loss=62758.28828125\n",
      "test_test\n",
      "test mean loss=87489.859375\n",
      "fin save.\n",
      "epoch 5730\n",
      "test_train\n",
      "train mean loss=62128.61875\n",
      "test_test\n",
      "test mean loss=87248.3984375\n",
      "fin save.\n",
      "epoch 5731\n",
      "test_train\n",
      "train mean loss=61663.516927083336\n",
      "test_test\n",
      "test mean loss=87489.56640625\n",
      "fin save.\n",
      "epoch 5732\n",
      "test_train\n",
      "train mean loss=62513.244921875\n",
      "test_test\n",
      "test mean loss=87504.0546875\n",
      "fin save.\n",
      "epoch 5733\n",
      "test_train\n",
      "train mean loss=62020.146875\n",
      "test_test\n",
      "test mean loss=87383.640625\n",
      "fin save.\n",
      "epoch 5734\n",
      "test_train\n",
      "train mean loss=62476.115494791666\n",
      "test_test\n",
      "test mean loss=87535.7265625\n",
      "fin save.\n",
      "epoch 5735\n",
      "test_train\n",
      "train mean loss=62268.86822916667\n",
      "test_test\n",
      "test mean loss=87423.61328125\n",
      "fin save.\n",
      "epoch 5736\n",
      "test_train\n",
      "train mean loss=62369.95598958333\n",
      "test_test\n",
      "test mean loss=87783.3515625\n",
      "fin save.\n",
      "epoch 5737\n",
      "test_train\n",
      "train mean loss=62769.458203125\n",
      "test_test\n",
      "test mean loss=87625.0234375\n",
      "fin save.\n",
      "epoch 5738\n",
      "test_train\n",
      "train mean loss=62485.365625\n",
      "test_test\n",
      "test mean loss=87642.87890625\n",
      "fin save.\n",
      "epoch 5739\n",
      "test_train\n",
      "train mean loss=62774.71731770833\n",
      "test_test\n",
      "test mean loss=87813.9921875\n",
      "fin save.\n",
      "epoch 5740\n",
      "test_train\n",
      "train mean loss=62113.403645833336\n",
      "test_test\n",
      "test mean loss=87737.69140625\n",
      "fin save.\n",
      "epoch 5741\n",
      "test_train\n",
      "train mean loss=62526.694010416664\n",
      "test_test\n",
      "test mean loss=88095.4609375\n",
      "fin save.\n",
      "epoch 5742\n",
      "test_train\n",
      "train mean loss=62486.48515625\n",
      "test_test\n",
      "test mean loss=87578.53125\n",
      "fin save.\n",
      "epoch 5743\n",
      "test_train\n",
      "train mean loss=62547.98046875\n",
      "test_test\n",
      "test mean loss=87870.1953125\n",
      "fin save.\n",
      "epoch 5744\n",
      "test_train\n",
      "train mean loss=62441.85598958333\n",
      "test_test\n",
      "test mean loss=87808.01171875\n",
      "fin save.\n",
      "epoch 5745\n",
      "test_train\n",
      "train mean loss=62476.763020833336\n",
      "test_test\n",
      "test mean loss=87828.9921875\n",
      "fin save.\n",
      "epoch 5746\n",
      "test_train\n",
      "train mean loss=62350.84752604167\n",
      "test_test\n",
      "test mean loss=87925.92578125\n",
      "fin save.\n",
      "epoch 5747\n",
      "test_train\n",
      "train mean loss=62850.33502604167\n",
      "test_test\n",
      "test mean loss=87829.5703125\n",
      "fin save.\n",
      "epoch 5748\n",
      "test_train\n",
      "train mean loss=62057.497395833336\n",
      "test_test\n",
      "test mean loss=88424.37890625\n",
      "fin save.\n",
      "epoch 5749\n",
      "test_train\n",
      "train mean loss=62257.30846354167\n",
      "test_test\n",
      "test mean loss=88410.1328125\n",
      "fin save.\n",
      "epoch 5750\n",
      "test_train\n",
      "train mean loss=62218.648177083334\n",
      "test_test\n",
      "test mean loss=88124.5859375\n",
      "fin save.\n",
      "epoch 5751\n",
      "test_train\n",
      "train mean loss=62281.14296875\n",
      "test_test\n",
      "test mean loss=88450.609375\n",
      "fin save.\n",
      "epoch 5752\n",
      "test_train\n",
      "train mean loss=62922.41354166667\n",
      "test_test\n",
      "test mean loss=88242.04296875\n",
      "fin save.\n",
      "epoch 5753\n",
      "test_train\n",
      "train mean loss=61808.59947916667\n",
      "test_test\n",
      "test mean loss=88161.828125\n",
      "fin save.\n",
      "epoch 5754\n",
      "test_train\n",
      "train mean loss=62058.25872395833\n",
      "test_test\n",
      "test mean loss=88209.3515625\n",
      "fin save.\n",
      "epoch 5755\n",
      "test_train\n",
      "train mean loss=62810.0125\n",
      "test_test\n",
      "test mean loss=88159.2265625\n",
      "fin save.\n",
      "epoch 5756\n",
      "test_train\n",
      "train mean loss=62400.65533854167\n",
      "test_test\n",
      "test mean loss=88515.51953125\n",
      "fin save.\n",
      "epoch 5757\n",
      "test_train\n",
      "train mean loss=62672.52786458333\n",
      "test_test\n",
      "test mean loss=88510.65234375\n",
      "fin save.\n",
      "epoch 5758\n",
      "test_train\n",
      "train mean loss=62317.98059895833\n",
      "test_test\n",
      "test mean loss=88600.01953125\n",
      "fin save.\n",
      "epoch 5759\n",
      "test_train\n",
      "train mean loss=61653.24322916667\n",
      "test_test\n",
      "test mean loss=88585.08203125\n",
      "fin save.\n",
      "epoch 5760\n",
      "test_train\n",
      "train mean loss=62555.097395833334\n",
      "test_test\n",
      "test mean loss=88433.11328125\n",
      "fin save.\n",
      "epoch 5761\n",
      "test_train\n",
      "train mean loss=62503.393229166664\n",
      "test_test\n",
      "test mean loss=88613.890625\n",
      "fin save.\n",
      "epoch 5762\n",
      "test_train\n",
      "train mean loss=63013.687239583334\n",
      "test_test\n",
      "test mean loss=88671.74609375\n",
      "fin save.\n",
      "epoch 5763\n",
      "test_train\n",
      "train mean loss=63375.59947916667\n",
      "test_test\n",
      "test mean loss=88526.8828125\n",
      "fin save.\n",
      "epoch 5764\n",
      "test_train\n",
      "train mean loss=62115.62552083333\n",
      "test_test\n",
      "test mean loss=88468.0078125\n",
      "fin save.\n",
      "epoch 5765\n",
      "test_train\n",
      "train mean loss=62037.27734375\n",
      "test_test\n",
      "test mean loss=88499.54296875\n",
      "fin save.\n",
      "epoch 5766\n",
      "test_train\n",
      "train mean loss=62770.2984375\n",
      "test_test\n",
      "test mean loss=88485.3046875\n",
      "fin save.\n",
      "epoch 5767\n",
      "test_train\n",
      "train mean loss=62805.13177083333\n",
      "test_test\n",
      "test mean loss=88418.60546875\n",
      "fin save.\n",
      "epoch 5768\n",
      "test_train\n",
      "train mean loss=62276.11419270833\n",
      "test_test\n",
      "test mean loss=88625.6640625\n",
      "fin save.\n",
      "epoch 5769\n",
      "test_train\n",
      "train mean loss=62934.45716145833\n",
      "test_test\n",
      "test mean loss=88558.80859375\n",
      "fin save.\n",
      "epoch 5770\n",
      "test_train\n",
      "train mean loss=62181.2640625\n",
      "test_test\n",
      "test mean loss=88571.2890625\n",
      "fin save.\n",
      "epoch 5771\n",
      "test_train\n",
      "train mean loss=62417.99661458333\n",
      "test_test\n",
      "test mean loss=88619.86328125\n",
      "fin save.\n",
      "epoch 5772\n",
      "test_train\n",
      "train mean loss=62408.79895833333\n",
      "test_test\n",
      "test mean loss=88796.55078125\n",
      "fin save.\n",
      "epoch 5773\n",
      "test_train\n",
      "train mean loss=62513.20130208333\n",
      "test_test\n",
      "test mean loss=88909.078125\n",
      "fin save.\n",
      "epoch 5774\n",
      "test_train\n",
      "train mean loss=62323.972395833334\n",
      "test_test\n",
      "test mean loss=88698.18359375\n",
      "fin save.\n",
      "epoch 5775\n",
      "test_train\n",
      "train mean loss=62965.75703125\n",
      "test_test\n",
      "test mean loss=88707.86328125\n",
      "fin save.\n",
      "epoch 5776\n",
      "test_train\n",
      "train mean loss=61661.424088541666\n",
      "test_test\n",
      "test mean loss=88664.44140625\n",
      "fin save.\n",
      "epoch 5777\n",
      "test_train\n",
      "train mean loss=62705.25377604167\n",
      "test_test\n",
      "test mean loss=88462.9921875\n",
      "fin save.\n",
      "epoch 5778\n",
      "test_train\n",
      "train mean loss=61771.286458333336\n",
      "test_test\n",
      "test mean loss=88321.5625\n",
      "fin save.\n",
      "epoch 5779\n",
      "test_train\n",
      "train mean loss=62428.715104166666\n",
      "test_test\n",
      "test mean loss=88411.17578125\n",
      "fin save.\n",
      "epoch 5780\n",
      "test_train\n",
      "train mean loss=62605.299479166664\n",
      "test_test\n",
      "test mean loss=88402.83984375\n",
      "fin save.\n",
      "epoch 5781\n",
      "test_train\n",
      "train mean loss=62310.40182291667\n",
      "test_test\n",
      "test mean loss=88489.00390625\n",
      "fin save.\n",
      "epoch 5782\n",
      "test_train\n",
      "train mean loss=62948.64361979167\n",
      "test_test\n",
      "test mean loss=88543.40625\n",
      "fin save.\n",
      "epoch 5783\n",
      "test_train\n",
      "train mean loss=61377.16171875\n",
      "test_test\n",
      "test mean loss=88567.93359375\n",
      "fin save.\n",
      "epoch 5784\n",
      "test_train\n",
      "train mean loss=62525.880078125\n",
      "test_test\n",
      "test mean loss=88708.48046875\n",
      "fin save.\n",
      "epoch 5785\n",
      "test_train\n",
      "train mean loss=62408.167708333334\n",
      "test_test\n",
      "test mean loss=88695.54296875\n",
      "fin save.\n",
      "epoch 5786\n",
      "test_train\n",
      "train mean loss=63833.41223958333\n",
      "test_test\n",
      "test mean loss=88624.27734375\n",
      "fin save.\n",
      "epoch 5787\n",
      "test_train\n",
      "train mean loss=62997.7359375\n",
      "test_test\n",
      "test mean loss=88656.859375\n",
      "fin save.\n",
      "epoch 5788\n",
      "test_train\n",
      "train mean loss=62766.396875\n",
      "test_test\n",
      "test mean loss=88595.7890625\n",
      "fin save.\n",
      "epoch 5789\n",
      "test_train\n",
      "train mean loss=62241.806901041666\n",
      "test_test\n",
      "test mean loss=88443.19140625\n",
      "fin save.\n",
      "epoch 5790\n",
      "test_train\n",
      "train mean loss=62109.165364583336\n",
      "test_test\n",
      "test mean loss=88471.6796875\n",
      "fin save.\n",
      "epoch 5791\n",
      "test_train\n",
      "train mean loss=61798.6828125\n",
      "test_test\n",
      "test mean loss=88411.78515625\n",
      "fin save.\n",
      "epoch 5792\n",
      "test_train\n",
      "train mean loss=61917.4984375\n",
      "test_test\n",
      "test mean loss=88409.609375\n",
      "fin save.\n",
      "epoch 5793\n",
      "test_train\n",
      "train mean loss=62512.38203125\n",
      "test_test\n",
      "test mean loss=88396.35546875\n",
      "fin save.\n",
      "epoch 5794\n",
      "test_train\n",
      "train mean loss=62568.92682291667\n",
      "test_test\n",
      "test mean loss=88377.6640625\n",
      "fin save.\n",
      "epoch 5795\n",
      "test_train\n",
      "train mean loss=62236.93645833333\n",
      "test_test\n",
      "test mean loss=88256.828125\n",
      "fin save.\n",
      "epoch 5796\n",
      "test_train\n",
      "train mean loss=62853.07083333333\n",
      "test_test\n",
      "test mean loss=88466.23046875\n",
      "fin save.\n",
      "epoch 5797\n",
      "test_train\n",
      "train mean loss=63123.01848958333\n",
      "test_test\n",
      "test mean loss=88089.69921875\n",
      "fin save.\n",
      "epoch 5798\n",
      "test_train\n",
      "train mean loss=62145.12005208333\n",
      "test_test\n",
      "test mean loss=88144.71484375\n",
      "fin save.\n",
      "epoch 5799\n",
      "test_train\n",
      "train mean loss=61908.35625\n",
      "test_test\n",
      "test mean loss=87976.80859375\n",
      "fin save.\n",
      "epoch 5800\n",
      "test_train\n",
      "train mean loss=62723.916666666664\n",
      "test_test\n",
      "test mean loss=88032.65234375\n",
      "fin save.\n",
      "epoch 5801\n",
      "test_train\n",
      "train mean loss=62463.02734375\n",
      "test_test\n",
      "test mean loss=88010.2265625\n",
      "fin save.\n",
      "epoch 5802\n",
      "test_train\n",
      "train mean loss=62225.15963541667\n",
      "test_test\n",
      "test mean loss=88240.109375\n",
      "fin save.\n",
      "epoch 5803\n",
      "test_train\n",
      "train mean loss=63098.523177083334\n",
      "test_test\n",
      "test mean loss=88257.0078125\n",
      "fin save.\n",
      "epoch 5804\n",
      "test_train\n",
      "train mean loss=62567.933333333334\n",
      "test_test\n",
      "test mean loss=88007.515625\n",
      "fin save.\n",
      "epoch 5805\n",
      "test_train\n",
      "train mean loss=63410.24401041667\n",
      "test_test\n",
      "test mean loss=87936.20703125\n",
      "fin save.\n",
      "epoch 5806\n",
      "test_train\n",
      "train mean loss=61399.53411458333\n",
      "test_test\n",
      "test mean loss=88177.1953125\n",
      "fin save.\n",
      "epoch 5807\n",
      "test_train\n",
      "train mean loss=62721.15807291667\n",
      "test_test\n",
      "test mean loss=88103.2421875\n",
      "fin save.\n",
      "epoch 5808\n",
      "test_train\n",
      "train mean loss=62581.437109375\n",
      "test_test\n",
      "test mean loss=88226.88671875\n",
      "fin save.\n",
      "epoch 5809\n",
      "test_train\n",
      "train mean loss=61164.758984375\n",
      "test_test\n",
      "test mean loss=88158.0234375\n",
      "fin save.\n",
      "epoch 5810\n",
      "test_train\n",
      "train mean loss=62005.98984375\n",
      "test_test\n",
      "test mean loss=88266.5703125\n",
      "fin save.\n",
      "epoch 5811\n",
      "test_train\n",
      "train mean loss=62837.01276041667\n",
      "test_test\n",
      "test mean loss=88360.3671875\n",
      "fin save.\n",
      "epoch 5812\n",
      "test_train\n",
      "train mean loss=62880.47994791667\n",
      "test_test\n",
      "test mean loss=88269.46875\n",
      "fin save.\n",
      "epoch 5813\n",
      "test_train\n",
      "train mean loss=62996.790364583336\n",
      "test_test\n",
      "test mean loss=88062.4375\n",
      "fin save.\n",
      "epoch 5814\n",
      "test_train\n",
      "train mean loss=62128.05130208333\n",
      "test_test\n",
      "test mean loss=88150.3359375\n",
      "fin save.\n",
      "epoch 5815\n",
      "test_train\n",
      "train mean loss=62299.398177083334\n",
      "test_test\n",
      "test mean loss=88186.22265625\n",
      "fin save.\n",
      "epoch 5816\n",
      "test_train\n",
      "train mean loss=62078.322916666664\n",
      "test_test\n",
      "test mean loss=88268.04296875\n",
      "fin save.\n",
      "epoch 5817\n",
      "test_train\n",
      "train mean loss=62952.350911458336\n",
      "test_test\n",
      "test mean loss=88337.0546875\n",
      "fin save.\n",
      "epoch 5818\n",
      "test_train\n",
      "train mean loss=62077.4171875\n",
      "test_test\n",
      "test mean loss=88405.1953125\n",
      "fin save.\n",
      "epoch 5819\n",
      "test_train\n",
      "train mean loss=62122.014973958336\n",
      "test_test\n",
      "test mean loss=88225.20703125\n",
      "fin save.\n",
      "epoch 5820\n",
      "test_train\n",
      "train mean loss=61919.28203125\n",
      "test_test\n",
      "test mean loss=88324.4921875\n",
      "fin save.\n",
      "epoch 5821\n",
      "test_train\n",
      "train mean loss=61753.729166666664\n",
      "test_test\n",
      "test mean loss=88336.43359375\n",
      "fin save.\n",
      "epoch 5822\n",
      "test_train\n",
      "train mean loss=62242.54934895833\n",
      "test_test\n",
      "test mean loss=88249.5703125\n",
      "fin save.\n",
      "epoch 5823\n",
      "test_train\n",
      "train mean loss=62769.805989583336\n",
      "test_test\n",
      "test mean loss=88322.7265625\n",
      "fin save.\n",
      "epoch 5824\n",
      "test_train\n",
      "train mean loss=63496.33203125\n",
      "test_test\n",
      "test mean loss=87960.6171875\n",
      "fin save.\n",
      "epoch 5825\n",
      "test_train\n",
      "train mean loss=63086.011458333334\n",
      "test_test\n",
      "test mean loss=87842.265625\n",
      "fin save.\n",
      "epoch 5826\n",
      "test_train\n",
      "train mean loss=61807.291796875\n",
      "test_test\n",
      "test mean loss=87928.5859375\n",
      "fin save.\n",
      "epoch 5827\n",
      "test_train\n",
      "train mean loss=62037.25989583333\n",
      "test_test\n",
      "test mean loss=87891.35546875\n",
      "fin save.\n",
      "epoch 5828\n",
      "test_train\n",
      "train mean loss=61694.257552083334\n",
      "test_test\n",
      "test mean loss=87876.45703125\n",
      "fin save.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5829\n",
      "test_train\n",
      "train mean loss=61988.08255208333\n",
      "test_test\n",
      "test mean loss=88020.1875\n",
      "fin save.\n",
      "epoch 5830\n",
      "test_train\n",
      "train mean loss=63055.020703125\n",
      "test_test\n",
      "test mean loss=88318.53515625\n",
      "fin save.\n",
      "epoch 5831\n",
      "test_train\n",
      "train mean loss=62372.7296875\n",
      "test_test\n",
      "test mean loss=88107.25\n",
      "fin save.\n",
      "epoch 5832\n",
      "test_train\n",
      "train mean loss=63845.79791666667\n",
      "test_test\n",
      "test mean loss=88001.3359375\n",
      "fin save.\n",
      "epoch 5833\n",
      "test_train\n",
      "train mean loss=62942.246875\n",
      "test_test\n",
      "test mean loss=88457.79296875\n",
      "fin save.\n",
      "epoch 5834\n",
      "test_train\n",
      "train mean loss=62001.11770833333\n",
      "test_test\n",
      "test mean loss=88204.96484375\n",
      "fin save.\n",
      "epoch 5835\n",
      "test_train\n",
      "train mean loss=63495.20703125\n",
      "test_test\n",
      "test mean loss=88167.78515625\n",
      "fin save.\n",
      "epoch 5836\n",
      "test_train\n",
      "train mean loss=63414.207291666666\n",
      "test_test\n",
      "test mean loss=88268.26171875\n",
      "fin save.\n",
      "epoch 5837\n",
      "test_train\n",
      "train mean loss=61948.77239583333\n",
      "test_test\n",
      "test mean loss=88812.6796875\n",
      "fin save.\n",
      "epoch 5838\n",
      "test_train\n",
      "train mean loss=62591.8890625\n",
      "test_test\n",
      "test mean loss=88828.87109375\n",
      "fin save.\n",
      "epoch 5839\n",
      "test_train\n",
      "train mean loss=61915.130208333336\n",
      "test_test\n",
      "test mean loss=88893.73828125\n",
      "fin save.\n",
      "epoch 5840\n",
      "test_train\n",
      "train mean loss=62545.31432291667\n",
      "test_test\n",
      "test mean loss=88832.41796875\n",
      "fin save.\n",
      "epoch 5841\n",
      "test_train\n",
      "train mean loss=61902.165364583336\n",
      "test_test\n",
      "test mean loss=88713.265625\n",
      "fin save.\n",
      "epoch 5842\n",
      "test_train\n",
      "train mean loss=62139.903645833336\n",
      "test_test\n",
      "test mean loss=88709.97265625\n",
      "fin save.\n",
      "epoch 5843\n",
      "test_train\n",
      "train mean loss=62259.394140625\n",
      "test_test\n",
      "test mean loss=88679.703125\n",
      "fin save.\n",
      "epoch 5844\n",
      "test_train\n",
      "train mean loss=62385.921614583334\n",
      "test_test\n",
      "test mean loss=88570.90234375\n",
      "fin save.\n",
      "epoch 5845\n",
      "test_train\n",
      "train mean loss=62762.886979166666\n",
      "test_test\n",
      "test mean loss=88383.23828125\n",
      "fin save.\n",
      "epoch 5846\n",
      "test_train\n",
      "train mean loss=62478.6484375\n",
      "test_test\n",
      "test mean loss=88362.796875\n",
      "fin save.\n",
      "epoch 5847\n",
      "test_train\n",
      "train mean loss=62540.05520833333\n",
      "test_test\n",
      "test mean loss=88301.56640625\n",
      "fin save.\n",
      "epoch 5848\n",
      "test_train\n",
      "train mean loss=62280.7109375\n",
      "test_test\n",
      "test mean loss=88376.2890625\n",
      "fin save.\n",
      "epoch 5849\n",
      "test_train\n",
      "train mean loss=62533.019270833334\n",
      "test_test\n",
      "test mean loss=88328.77734375\n",
      "fin save.\n",
      "epoch 5850\n",
      "test_train\n",
      "train mean loss=61891.3265625\n",
      "test_test\n",
      "test mean loss=88353.77734375\n",
      "fin save.\n",
      "epoch 5851\n",
      "test_train\n",
      "train mean loss=62936.89609375\n",
      "test_test\n",
      "test mean loss=88104.0703125\n",
      "fin save.\n",
      "epoch 5852\n",
      "test_train\n",
      "train mean loss=62786.083333333336\n",
      "test_test\n",
      "test mean loss=88234.859375\n",
      "fin save.\n",
      "epoch 5853\n",
      "test_train\n",
      "train mean loss=61653.781510416666\n",
      "test_test\n",
      "test mean loss=88094.89453125\n",
      "fin save.\n",
      "epoch 5854\n",
      "test_train\n",
      "train mean loss=62918.9609375\n",
      "test_test\n",
      "test mean loss=88215.86328125\n",
      "fin save.\n",
      "epoch 5855\n",
      "test_train\n",
      "train mean loss=62857.63528645833\n",
      "test_test\n",
      "test mean loss=88307.03515625\n",
      "fin save.\n",
      "epoch 5856\n",
      "test_train\n",
      "train mean loss=62571.203385416666\n",
      "test_test\n",
      "test mean loss=88293.13671875\n",
      "fin save.\n",
      "epoch 5857\n",
      "test_train\n",
      "train mean loss=62967.16484375\n",
      "test_test\n",
      "test mean loss=88260.5078125\n",
      "fin save.\n",
      "epoch 5858\n",
      "test_train\n",
      "train mean loss=62306.70807291667\n",
      "test_test\n",
      "test mean loss=88084.7890625\n",
      "fin save.\n",
      "epoch 5859\n",
      "test_train\n",
      "train mean loss=61785.49557291667\n",
      "test_test\n",
      "test mean loss=87846.46484375\n",
      "fin save.\n",
      "epoch 5860\n",
      "test_train\n",
      "train mean loss=61405.492447916666\n",
      "test_test\n",
      "test mean loss=87872.3203125\n",
      "fin save.\n",
      "epoch 5861\n",
      "test_train\n",
      "train mean loss=62247.704817708334\n",
      "test_test\n",
      "test mean loss=87880.41796875\n",
      "fin save.\n",
      "epoch 5862\n",
      "test_train\n",
      "train mean loss=62257.37005208333\n",
      "test_test\n",
      "test mean loss=87797.7421875\n",
      "fin save.\n",
      "epoch 5863\n",
      "test_train\n",
      "train mean loss=61970.225\n",
      "test_test\n",
      "test mean loss=87855.66015625\n",
      "fin save.\n",
      "epoch 5864\n",
      "test_train\n",
      "train mean loss=62732.8578125\n",
      "test_test\n",
      "test mean loss=87778.359375\n",
      "fin save.\n",
      "epoch 5865\n",
      "test_train\n",
      "train mean loss=63037.329427083336\n",
      "test_test\n",
      "test mean loss=87852.765625\n",
      "fin save.\n",
      "epoch 5866\n",
      "test_train\n",
      "train mean loss=63102.76119791667\n",
      "test_test\n",
      "test mean loss=87528.87109375\n",
      "fin save.\n",
      "epoch 5867\n",
      "test_train\n",
      "train mean loss=63169.99114583333\n",
      "test_test\n",
      "test mean loss=87438.66015625\n",
      "fin save.\n",
      "epoch 5868\n",
      "test_train\n",
      "train mean loss=61622.291796875\n",
      "test_test\n",
      "test mean loss=87531.2734375\n",
      "fin save.\n",
      "epoch 5869\n",
      "test_train\n",
      "train mean loss=61968.972395833334\n",
      "test_test\n",
      "test mean loss=87561.5625\n",
      "fin save.\n",
      "epoch 5870\n",
      "test_train\n",
      "train mean loss=62315.90729166667\n",
      "test_test\n",
      "test mean loss=87553.34375\n",
      "fin save.\n",
      "epoch 5871\n",
      "test_train\n",
      "train mean loss=62687.875260416666\n",
      "test_test\n",
      "test mean loss=87963.0859375\n",
      "fin save.\n",
      "epoch 5872\n",
      "test_train\n",
      "train mean loss=62492.63567708333\n",
      "test_test\n",
      "test mean loss=87853.7265625\n",
      "fin save.\n",
      "epoch 5873\n",
      "test_train\n",
      "train mean loss=62434.14947916667\n",
      "test_test\n",
      "test mean loss=87851.3046875\n",
      "fin save.\n",
      "epoch 5874\n",
      "test_train\n",
      "train mean loss=63369.07526041667\n",
      "test_test\n",
      "test mean loss=87694.734375\n",
      "fin save.\n",
      "epoch 5875\n",
      "test_train\n",
      "train mean loss=63325.84427083333\n",
      "test_test\n",
      "test mean loss=87851.765625\n",
      "fin save.\n",
      "epoch 5876\n",
      "test_train\n",
      "train mean loss=63073.841536458334\n",
      "test_test\n",
      "test mean loss=87712.54296875\n",
      "fin save.\n",
      "epoch 5877\n",
      "test_train\n",
      "train mean loss=61923.883072916666\n",
      "test_test\n",
      "test mean loss=87732.33203125\n",
      "fin save.\n",
      "epoch 5878\n",
      "test_train\n",
      "train mean loss=62778.13658854167\n",
      "test_test\n",
      "test mean loss=87748.7109375\n",
      "fin save.\n",
      "epoch 5879\n",
      "test_train\n",
      "train mean loss=61201.79479166667\n",
      "test_test\n",
      "test mean loss=87563.05859375\n",
      "fin save.\n",
      "epoch 5880\n",
      "test_train\n",
      "train mean loss=61740.44127604167\n",
      "test_test\n",
      "test mean loss=87629.203125\n",
      "fin save.\n",
      "epoch 5881\n",
      "test_train\n",
      "train mean loss=62515.27747395833\n",
      "test_test\n",
      "test mean loss=87344.15234375\n",
      "fin save.\n",
      "epoch 5882\n",
      "test_train\n",
      "train mean loss=62380.115625\n",
      "test_test\n",
      "test mean loss=87324.8828125\n",
      "fin save.\n",
      "epoch 5883\n",
      "test_train\n",
      "train mean loss=61953.61901041667\n",
      "test_test\n",
      "test mean loss=87362.3359375\n",
      "fin save.\n",
      "epoch 5884\n",
      "test_train\n",
      "train mean loss=62205.98828125\n",
      "test_test\n",
      "test mean loss=87534.61328125\n",
      "fin save.\n",
      "epoch 5885\n",
      "test_train\n",
      "train mean loss=61885.104166666664\n",
      "test_test\n",
      "test mean loss=87531.87109375\n",
      "fin save.\n",
      "epoch 5886\n",
      "test_train\n",
      "train mean loss=63647.39765625\n",
      "test_test\n",
      "test mean loss=87410.7109375\n",
      "fin save.\n",
      "epoch 5887\n",
      "test_train\n",
      "train mean loss=61653.491536458336\n",
      "test_test\n",
      "test mean loss=87439.90234375\n",
      "fin save.\n",
      "epoch 5888\n",
      "test_train\n",
      "train mean loss=63121.21197916667\n",
      "test_test\n",
      "test mean loss=87597.4609375\n",
      "fin save.\n",
      "epoch 5889\n",
      "test_train\n",
      "train mean loss=62453.36536458333\n",
      "test_test\n",
      "test mean loss=87649.96875\n",
      "fin save.\n",
      "epoch 5890\n",
      "test_train\n",
      "train mean loss=62429.965104166666\n",
      "test_test\n",
      "test mean loss=87617.25\n",
      "fin save.\n",
      "epoch 5891\n",
      "test_train\n",
      "train mean loss=61655.55963541667\n",
      "test_test\n",
      "test mean loss=88001.17578125\n",
      "fin save.\n",
      "epoch 5892\n",
      "test_train\n",
      "train mean loss=61836.921223958336\n",
      "test_test\n",
      "test mean loss=87908.59765625\n",
      "fin save.\n",
      "epoch 5893\n",
      "test_train\n",
      "train mean loss=62725.975260416664\n",
      "test_test\n",
      "test mean loss=88119.45703125\n",
      "fin save.\n",
      "epoch 5894\n",
      "test_train\n",
      "train mean loss=62202.240885416664\n",
      "test_test\n",
      "test mean loss=87957.15234375\n",
      "fin save.\n",
      "epoch 5895\n",
      "test_train\n",
      "train mean loss=62805.480729166666\n",
      "test_test\n",
      "test mean loss=88031.2890625\n",
      "fin save.\n",
      "epoch 5896\n",
      "test_train\n",
      "train mean loss=60682.418229166666\n",
      "test_test\n",
      "test mean loss=87972.265625\n",
      "fin save.\n",
      "epoch 5897\n",
      "test_train\n",
      "train mean loss=61961.694010416664\n",
      "test_test\n",
      "test mean loss=87872.171875\n",
      "fin save.\n",
      "epoch 5898\n",
      "test_train\n",
      "train mean loss=63409.126302083336\n",
      "test_test\n",
      "test mean loss=88043.44921875\n",
      "fin save.\n",
      "epoch 5899\n",
      "test_train\n",
      "train mean loss=62085.610677083336\n",
      "test_test\n",
      "test mean loss=87816.14453125\n",
      "fin save.\n",
      "epoch 5900\n",
      "test_train\n",
      "train mean loss=62084.556380208334\n",
      "test_test\n",
      "test mean loss=87815.5390625\n",
      "fin save.\n",
      "epoch 5901\n",
      "test_train\n",
      "train mean loss=61721.32317708333\n",
      "test_test\n",
      "test mean loss=87785.0078125\n",
      "fin save.\n",
      "epoch 5902\n",
      "test_train\n",
      "train mean loss=62859.99010416667\n",
      "test_test\n",
      "test mean loss=87902.6875\n",
      "fin save.\n",
      "epoch 5903\n",
      "test_train\n",
      "train mean loss=62214.215625\n",
      "test_test\n",
      "test mean loss=87645.4140625\n",
      "fin save.\n",
      "epoch 5904\n",
      "test_train\n",
      "train mean loss=62327.00182291667\n",
      "test_test\n",
      "test mean loss=87834.62890625\n",
      "fin save.\n",
      "epoch 5905\n",
      "test_train\n",
      "train mean loss=62655.58776041667\n",
      "test_test\n",
      "test mean loss=87748.63671875\n",
      "fin save.\n",
      "epoch 5906\n",
      "test_train\n",
      "train mean loss=61994.8078125\n",
      "test_test\n",
      "test mean loss=87734.76171875\n",
      "fin save.\n",
      "epoch 5907\n",
      "test_train\n",
      "train mean loss=63119.94479166667\n",
      "test_test\n",
      "test mean loss=87621.36328125\n",
      "fin save.\n",
      "epoch 5908\n",
      "test_train\n",
      "train mean loss=61987.06822916667\n",
      "test_test\n",
      "test mean loss=87706.4296875\n",
      "fin save.\n",
      "epoch 5909\n",
      "test_train\n",
      "train mean loss=61919.24375\n",
      "test_test\n",
      "test mean loss=87820.9921875\n",
      "fin save.\n",
      "epoch 5910\n",
      "test_train\n",
      "train mean loss=61342.040755208334\n",
      "test_test\n",
      "test mean loss=87745.21484375\n",
      "fin save.\n",
      "epoch 5911\n",
      "test_train\n",
      "train mean loss=62665.884114583336\n",
      "test_test\n",
      "test mean loss=87748.4453125\n",
      "fin save.\n",
      "epoch 5912\n",
      "test_train\n",
      "train mean loss=62552.885026041666\n",
      "test_test\n",
      "test mean loss=87617.96875\n",
      "fin save.\n",
      "epoch 5913\n",
      "test_train\n",
      "train mean loss=61783.218098958336\n",
      "test_test\n",
      "test mean loss=87628.140625\n",
      "fin save.\n",
      "epoch 5914\n",
      "test_train\n",
      "train mean loss=62065.153125\n",
      "test_test\n",
      "test mean loss=87944.1640625\n",
      "fin save.\n",
      "epoch 5915\n",
      "test_train\n",
      "train mean loss=62805.17239583333\n",
      "test_test\n",
      "test mean loss=87890.20703125\n",
      "fin save.\n",
      "epoch 5916\n",
      "test_train\n",
      "train mean loss=62786.265885416666\n",
      "test_test\n",
      "test mean loss=87783.1875\n",
      "fin save.\n",
      "epoch 5917\n",
      "test_train\n",
      "train mean loss=63235.451822916664\n",
      "test_test\n",
      "test mean loss=87679.78125\n",
      "fin save.\n",
      "epoch 5918\n",
      "test_train\n",
      "train mean loss=61992.2828125\n",
      "test_test\n",
      "test mean loss=87832.95703125\n",
      "fin save.\n",
      "epoch 5919\n",
      "test_train\n",
      "train mean loss=63125.16901041667\n",
      "test_test\n",
      "test mean loss=87810.515625\n",
      "fin save.\n",
      "epoch 5920\n",
      "test_train\n",
      "train mean loss=62692.951953125\n",
      "test_test\n",
      "test mean loss=87613.73046875\n",
      "fin save.\n",
      "epoch 5921\n",
      "test_train\n",
      "train mean loss=62359.87734375\n",
      "test_test\n",
      "test mean loss=87686.8203125\n",
      "fin save.\n",
      "epoch 5922\n",
      "test_train\n",
      "train mean loss=62159.97669270833\n",
      "test_test\n",
      "test mean loss=87783.79296875\n",
      "fin save.\n",
      "epoch 5923\n",
      "test_train\n",
      "train mean loss=61974.0140625\n",
      "test_test\n",
      "test mean loss=87784.08203125\n",
      "fin save.\n",
      "epoch 5924\n",
      "test_train\n",
      "train mean loss=62507.00546875\n",
      "test_test\n",
      "test mean loss=87639.4453125\n",
      "fin save.\n",
      "epoch 5925\n",
      "test_train\n",
      "train mean loss=62139.030598958336\n",
      "test_test\n",
      "test mean loss=87482.89453125\n",
      "fin save.\n",
      "epoch 5926\n",
      "test_train\n",
      "train mean loss=62123.766015625\n",
      "test_test\n",
      "test mean loss=87854.453125\n",
      "fin save.\n",
      "epoch 5927\n",
      "test_train\n",
      "train mean loss=63022.21953125\n",
      "test_test\n",
      "test mean loss=87867.6953125\n",
      "fin save.\n",
      "epoch 5928\n",
      "test_train\n",
      "train mean loss=61853.559895833336\n",
      "test_test\n",
      "test mean loss=87742.39453125\n",
      "fin save.\n",
      "epoch 5929\n",
      "test_train\n",
      "train mean loss=61674.19739583333\n",
      "test_test\n",
      "test mean loss=87866.67578125\n",
      "fin save.\n",
      "epoch 5930\n",
      "test_train\n",
      "train mean loss=62660.03307291667\n",
      "test_test\n",
      "test mean loss=87843.06640625\n",
      "fin save.\n",
      "epoch 5931\n",
      "test_train\n",
      "train mean loss=61732.25286458333\n",
      "test_test\n",
      "test mean loss=87472.15625\n",
      "fin save.\n",
      "epoch 5932\n",
      "test_train\n",
      "train mean loss=62710.97369791667\n",
      "test_test\n",
      "test mean loss=87077.12109375\n",
      "fin save.\n",
      "epoch 5933\n",
      "test_train\n",
      "train mean loss=61226.252604166664\n",
      "test_test\n",
      "test mean loss=87200.5859375\n",
      "fin save.\n",
      "epoch 5934\n",
      "test_train\n",
      "train mean loss=61431.35703125\n",
      "test_test\n",
      "test mean loss=87365.6875\n",
      "fin save.\n",
      "epoch 5935\n",
      "test_train\n",
      "train mean loss=61563.94322916667\n",
      "test_test\n",
      "test mean loss=87116.6328125\n",
      "fin save.\n",
      "epoch 5936\n",
      "test_train\n",
      "train mean loss=61694.75703125\n",
      "test_test\n",
      "test mean loss=87152.38671875\n",
      "fin save.\n",
      "epoch 5937\n",
      "test_train\n",
      "train mean loss=61254.708333333336\n",
      "test_test\n",
      "test mean loss=86958.0859375\n",
      "fin save.\n",
      "epoch 5938\n",
      "test_train\n",
      "train mean loss=61725.41614583333\n",
      "test_test\n",
      "test mean loss=86823.3828125\n",
      "fin save.\n",
      "epoch 5939\n",
      "test_train\n",
      "train mean loss=62508.10338541667\n",
      "test_test\n",
      "test mean loss=87064.73828125\n",
      "fin save.\n",
      "epoch 5940\n",
      "test_train\n",
      "train mean loss=62018.590104166666\n",
      "test_test\n",
      "test mean loss=87025.66015625\n",
      "fin save.\n",
      "epoch 5941\n",
      "test_train\n",
      "train mean loss=61900.60989583333\n",
      "test_test\n",
      "test mean loss=87274.73828125\n",
      "fin save.\n",
      "epoch 5942\n",
      "test_train\n",
      "train mean loss=61123.48776041667\n",
      "test_test\n",
      "test mean loss=87158.03515625\n",
      "fin save.\n",
      "epoch 5943\n",
      "test_train\n",
      "train mean loss=61410.562239583334\n",
      "test_test\n",
      "test mean loss=87038.6953125\n",
      "fin save.\n",
      "epoch 5944\n",
      "test_train\n",
      "train mean loss=62946.891927083336\n",
      "test_test\n",
      "test mean loss=87150.390625\n",
      "fin save.\n",
      "epoch 5945\n",
      "test_train\n",
      "train mean loss=61922.34518229167\n",
      "test_test\n",
      "test mean loss=87123.421875\n",
      "fin save.\n",
      "epoch 5946\n",
      "test_train\n",
      "train mean loss=61172.254166666666\n",
      "test_test\n",
      "test mean loss=87172.25\n",
      "fin save.\n",
      "epoch 5947\n",
      "test_train\n",
      "train mean loss=61979.223828125\n",
      "test_test\n",
      "test mean loss=86936.37109375\n",
      "fin save.\n",
      "epoch 5948\n",
      "test_train\n",
      "train mean loss=61569.37447916667\n",
      "test_test\n",
      "test mean loss=87067.2578125\n",
      "fin save.\n",
      "epoch 5949\n",
      "test_train\n",
      "train mean loss=62084.84166666667\n",
      "test_test\n",
      "test mean loss=86988.484375\n",
      "fin save.\n",
      "epoch 5950\n",
      "test_train\n",
      "train mean loss=61238.73203125\n",
      "test_test\n",
      "test mean loss=87012.51171875\n",
      "fin save.\n",
      "epoch 5951\n",
      "test_train\n",
      "train mean loss=61568.47109375\n",
      "test_test\n",
      "test mean loss=86970.3125\n",
      "fin save.\n",
      "epoch 5952\n",
      "test_train\n",
      "train mean loss=62063.70651041667\n",
      "test_test\n",
      "test mean loss=87083.0859375\n",
      "fin save.\n",
      "epoch 5953\n",
      "test_train\n",
      "train mean loss=62274.97838541667\n",
      "test_test\n",
      "test mean loss=87356.5546875\n",
      "fin save.\n",
      "epoch 5954\n",
      "test_train\n",
      "train mean loss=61454.490625\n",
      "test_test\n",
      "test mean loss=87216.8671875\n",
      "fin save.\n",
      "epoch 5955\n",
      "test_train\n",
      "train mean loss=62213.19869791667\n",
      "test_test\n",
      "test mean loss=87339.4609375\n",
      "fin save.\n",
      "epoch 5956\n",
      "test_train\n",
      "train mean loss=62241.787760416664\n",
      "test_test\n",
      "test mean loss=87301.42578125\n",
      "fin save.\n",
      "epoch 5957\n",
      "test_train\n",
      "train mean loss=60596.16692708333\n",
      "test_test\n",
      "test mean loss=87259.0234375\n",
      "fin save.\n",
      "epoch 5958\n",
      "test_train\n",
      "train mean loss=63086.579427083336\n",
      "test_test\n",
      "test mean loss=87161.16015625\n",
      "fin save.\n",
      "epoch 5959\n",
      "test_train\n",
      "train mean loss=62313.775\n",
      "test_test\n",
      "test mean loss=87265.609375\n",
      "fin save.\n",
      "epoch 5960\n",
      "test_train\n",
      "train mean loss=61127.55182291667\n",
      "test_test\n",
      "test mean loss=87227.29296875\n",
      "fin save.\n",
      "epoch 5961\n",
      "test_train\n",
      "train mean loss=61682.51705729167\n",
      "test_test\n",
      "test mean loss=87406.11328125\n",
      "fin save.\n",
      "epoch 5962\n",
      "test_train\n",
      "train mean loss=62137.815625\n",
      "test_test\n",
      "test mean loss=87391.11328125\n",
      "fin save.\n",
      "epoch 5963\n",
      "test_train\n",
      "train mean loss=61821.7265625\n",
      "test_test\n",
      "test mean loss=87451.51953125\n",
      "fin save.\n",
      "epoch 5964\n",
      "test_train\n",
      "train mean loss=62221.70364583333\n",
      "test_test\n",
      "test mean loss=87503.359375\n",
      "fin save.\n",
      "epoch 5965\n",
      "test_train\n",
      "train mean loss=62837.56744791667\n",
      "test_test\n",
      "test mean loss=87308.00390625\n",
      "fin save.\n",
      "epoch 5966\n",
      "test_train\n",
      "train mean loss=63261.4046875\n",
      "test_test\n",
      "test mean loss=87339.54296875\n",
      "fin save.\n",
      "epoch 5967\n",
      "test_train\n",
      "train mean loss=62486.321614583336\n",
      "test_test\n",
      "test mean loss=87259.484375\n",
      "fin save.\n",
      "epoch 5968\n",
      "test_train\n",
      "train mean loss=62510.681901041666\n",
      "test_test\n",
      "test mean loss=87349.85546875\n",
      "fin save.\n",
      "epoch 5969\n",
      "test_train\n",
      "train mean loss=62205.62447916667\n",
      "test_test\n",
      "test mean loss=87365.84765625\n",
      "fin save.\n",
      "epoch 5970\n",
      "test_train\n",
      "train mean loss=62591.859375\n",
      "test_test\n",
      "test mean loss=87485.04296875\n",
      "fin save.\n",
      "epoch 5971\n",
      "test_train\n",
      "train mean loss=62197.63229166667\n",
      "test_test\n",
      "test mean loss=87543.890625\n",
      "fin save.\n",
      "epoch 5972\n",
      "test_train\n",
      "train mean loss=61426.3671875\n",
      "test_test\n",
      "test mean loss=87151.54296875\n",
      "fin save.\n",
      "epoch 5973\n",
      "test_train\n",
      "train mean loss=63297.63098958333\n",
      "test_test\n",
      "test mean loss=87563.89453125\n",
      "fin save.\n",
      "epoch 5974\n",
      "test_train\n",
      "train mean loss=62602.25963541667\n",
      "test_test\n",
      "test mean loss=87722.734375\n",
      "fin save.\n",
      "epoch 5975\n",
      "test_train\n",
      "train mean loss=62644.873307291666\n",
      "test_test\n",
      "test mean loss=87537.43359375\n",
      "fin save.\n",
      "epoch 5976\n",
      "test_train\n",
      "train mean loss=61613.584375\n",
      "test_test\n",
      "test mean loss=87465.12890625\n",
      "fin save.\n",
      "epoch 5977\n",
      "test_train\n",
      "train mean loss=63454.71627604167\n",
      "test_test\n",
      "test mean loss=87591.20703125\n",
      "fin save.\n",
      "epoch 5978\n",
      "test_train\n",
      "train mean loss=63109.848828125\n",
      "test_test\n",
      "test mean loss=87543.88671875\n",
      "fin save.\n",
      "epoch 5979\n",
      "test_train\n",
      "train mean loss=61752.98489583333\n",
      "test_test\n",
      "test mean loss=87390.52734375\n",
      "fin save.\n",
      "epoch 5980\n",
      "test_train\n",
      "train mean loss=61873.028645833336\n",
      "test_test\n",
      "test mean loss=87107.890625\n",
      "fin save.\n",
      "epoch 5981\n",
      "test_train\n",
      "train mean loss=62644.51549479167\n",
      "test_test\n",
      "test mean loss=87580.390625\n",
      "fin save.\n",
      "epoch 5982\n",
      "test_train\n",
      "train mean loss=62388.2328125\n",
      "test_test\n",
      "test mean loss=87474.78515625\n",
      "fin save.\n",
      "epoch 5983\n",
      "test_train\n",
      "train mean loss=61428.3890625\n",
      "test_test\n",
      "test mean loss=87510.546875\n",
      "fin save.\n",
      "epoch 5984\n",
      "test_train\n",
      "train mean loss=61936.26966145833\n",
      "test_test\n",
      "test mean loss=87249.09375\n",
      "fin save.\n",
      "epoch 5985\n",
      "test_train\n",
      "train mean loss=62351.90442708333\n",
      "test_test\n",
      "test mean loss=87106.328125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fin save.\n",
      "epoch 5986\n",
      "test_train\n",
      "train mean loss=61022.384114583336\n",
      "test_test\n",
      "test mean loss=87214.609375\n",
      "fin save.\n",
      "epoch 5987\n",
      "test_train\n",
      "train mean loss=62361.547135416666\n",
      "test_test\n",
      "test mean loss=87049.47265625\n",
      "fin save.\n",
      "epoch 5988\n",
      "test_train\n",
      "train mean loss=63415.902604166666\n",
      "test_test\n",
      "test mean loss=86928.37890625\n",
      "fin save.\n",
      "epoch 5989\n",
      "test_train\n",
      "train mean loss=62010.77838541667\n",
      "test_test\n",
      "test mean loss=86975.26953125\n",
      "fin save.\n",
      "epoch 5990\n",
      "test_train\n",
      "train mean loss=62832.08671875\n",
      "test_test\n",
      "test mean loss=87271.38671875\n",
      "fin save.\n",
      "epoch 5991\n",
      "test_train\n",
      "train mean loss=62441.796614583334\n",
      "test_test\n",
      "test mean loss=87320.1171875\n",
      "fin save.\n",
      "epoch 5992\n",
      "test_train\n",
      "train mean loss=62274.75078125\n",
      "test_test\n",
      "test mean loss=87423.35546875\n",
      "fin save.\n",
      "epoch 5993\n",
      "test_train\n",
      "train mean loss=62734.098307291664\n",
      "test_test\n",
      "test mean loss=87369.05078125\n",
      "fin save.\n",
      "epoch 5994\n",
      "test_train\n",
      "train mean loss=62249.70859375\n",
      "test_test\n",
      "test mean loss=87447.578125\n",
      "fin save.\n",
      "epoch 5995\n",
      "test_train\n",
      "train mean loss=62149.996875\n",
      "test_test\n",
      "test mean loss=87304.453125\n",
      "fin save.\n",
      "epoch 5996\n",
      "test_train\n",
      "train mean loss=62093.57526041667\n",
      "test_test\n",
      "test mean loss=87377.59375\n",
      "fin save.\n",
      "epoch 5997\n",
      "test_train\n",
      "train mean loss=63292.059375\n",
      "test_test\n",
      "test mean loss=87371.0703125\n",
      "fin save.\n",
      "epoch 5998\n",
      "test_train\n",
      "train mean loss=62516.684895833336\n",
      "test_test\n",
      "test mean loss=87418.578125\n",
      "fin save.\n",
      "epoch 5999\n",
      "test_train\n",
      "train mean loss=62492.66419270833\n",
      "test_test\n",
      "test mean loss=87380.30859375\n",
      "fin save.\n",
      "epoch 6000\n",
      "test_train\n",
      "train mean loss=61485.9625\n",
      "test_test\n",
      "test mean loss=87410.46484375\n",
      "fin save.\n",
      "epoch 6001\n",
      "test_train\n",
      "train mean loss=62180.60494791667\n",
      "test_test\n",
      "test mean loss=87205.5625\n",
      "fin save.\n",
      "epoch 6002\n",
      "test_train\n",
      "train mean loss=62519.45390625\n",
      "test_test\n",
      "test mean loss=87273.34375\n",
      "fin save.\n",
      "epoch 6003\n",
      "test_train\n",
      "train mean loss=61966.18177083333\n",
      "test_test\n",
      "test mean loss=87118.9765625\n",
      "fin save.\n",
      "epoch 6004\n",
      "test_train\n",
      "train mean loss=62311.2125\n",
      "test_test\n",
      "test mean loss=87409.01171875\n",
      "fin save.\n",
      "epoch 6005\n",
      "test_train\n",
      "train mean loss=61666.65611979167\n",
      "test_test\n",
      "test mean loss=87407.3203125\n",
      "fin save.\n",
      "epoch 6006\n",
      "test_train\n",
      "train mean loss=62256.378125\n",
      "test_test\n",
      "test mean loss=87193.17578125\n",
      "fin save.\n",
      "epoch 6007\n",
      "test_train\n",
      "train mean loss=61748.60703125\n",
      "test_test\n",
      "test mean loss=87165.34375\n",
      "fin save.\n",
      "epoch 6008\n",
      "test_train\n",
      "train mean loss=62069.50546875\n",
      "test_test\n",
      "test mean loss=87220.5234375\n",
      "fin save.\n",
      "epoch 6009\n",
      "test_train\n",
      "train mean loss=61483.2078125\n",
      "test_test\n",
      "test mean loss=87038.390625\n",
      "fin save.\n",
      "epoch 6010\n",
      "test_train\n",
      "train mean loss=61273.915625\n",
      "test_test\n",
      "test mean loss=87017.01953125\n",
      "fin save.\n",
      "epoch 6011\n",
      "test_train\n",
      "train mean loss=62285.31653645833\n",
      "test_test\n",
      "test mean loss=87270.734375\n",
      "fin save.\n",
      "epoch 6012\n",
      "test_train\n",
      "train mean loss=61805.845052083336\n",
      "test_test\n",
      "test mean loss=87092.640625\n",
      "fin save.\n",
      "epoch 6013\n",
      "test_train\n",
      "train mean loss=62762.78802083333\n",
      "test_test\n",
      "test mean loss=87343.62890625\n",
      "fin save.\n",
      "epoch 6014\n",
      "test_train\n",
      "train mean loss=62734.49010416667\n",
      "test_test\n",
      "test mean loss=87251.38671875\n",
      "fin save.\n",
      "epoch 6015\n",
      "test_train\n",
      "train mean loss=62345.86861979167\n",
      "test_test\n",
      "test mean loss=87270.94921875\n",
      "fin save.\n",
      "epoch 6016\n",
      "test_train\n",
      "train mean loss=62222.46184895833\n",
      "test_test\n",
      "test mean loss=87286.26171875\n",
      "fin save.\n",
      "epoch 6017\n",
      "test_train\n",
      "train mean loss=62775.179036458336\n",
      "test_test\n",
      "test mean loss=87299.38671875\n",
      "fin save.\n",
      "epoch 6018\n",
      "test_train\n",
      "train mean loss=61986.32578125\n",
      "test_test\n",
      "test mean loss=87284.9453125\n",
      "fin save.\n",
      "epoch 6019\n",
      "test_train\n",
      "train mean loss=61581.279557291666\n",
      "test_test\n",
      "test mean loss=87527.66796875\n",
      "fin save.\n",
      "epoch 6020\n",
      "test_train\n",
      "train mean loss=62013.930078125\n",
      "test_test\n",
      "test mean loss=87342.81640625\n",
      "fin save.\n",
      "epoch 6021\n",
      "test_train\n",
      "train mean loss=63002.20625\n",
      "test_test\n",
      "test mean loss=87261.3984375\n",
      "fin save.\n",
      "epoch 6022\n",
      "test_train\n",
      "train mean loss=62095.2734375\n",
      "test_test\n",
      "test mean loss=87079.64453125\n",
      "fin save.\n",
      "epoch 6023\n",
      "test_train\n",
      "train mean loss=62337.97447916667\n",
      "test_test\n",
      "test mean loss=87332.80078125\n",
      "fin save.\n",
      "epoch 6024\n",
      "test_train\n",
      "train mean loss=62183.00598958333\n",
      "test_test\n",
      "test mean loss=87304.90234375\n",
      "fin save.\n",
      "epoch 6025\n",
      "test_train\n",
      "train mean loss=62103.6015625\n",
      "test_test\n",
      "test mean loss=87294.484375\n",
      "fin save.\n",
      "epoch 6026\n",
      "test_train\n",
      "train mean loss=61695.4890625\n",
      "test_test\n",
      "test mean loss=87329.25\n",
      "fin save.\n",
      "epoch 6027\n",
      "test_train\n",
      "train mean loss=62478.25859375\n",
      "test_test\n",
      "test mean loss=87408.4921875\n",
      "fin save.\n",
      "epoch 6028\n",
      "test_train\n",
      "train mean loss=61900.85442708333\n",
      "test_test\n",
      "test mean loss=87267.63671875\n",
      "fin save.\n",
      "epoch 6029\n",
      "test_train\n",
      "train mean loss=62019.23776041667\n",
      "test_test\n",
      "test mean loss=87241.43359375\n",
      "fin save.\n",
      "epoch 6030\n",
      "test_train\n",
      "train mean loss=62109.21822916667\n",
      "test_test\n",
      "test mean loss=87234.4921875\n",
      "fin save.\n",
      "epoch 6031\n",
      "test_train\n",
      "train mean loss=61709.025390625\n",
      "test_test\n",
      "test mean loss=87249.84375\n",
      "fin save.\n",
      "epoch 6032\n",
      "test_train\n",
      "train mean loss=62354.01848958333\n",
      "test_test\n",
      "test mean loss=87323.25\n",
      "fin save.\n",
      "epoch 6033\n",
      "test_train\n",
      "train mean loss=62469.75729166667\n",
      "test_test\n",
      "test mean loss=87492.21875\n",
      "fin save.\n",
      "epoch 6034\n",
      "test_train\n",
      "train mean loss=61867.50546875\n",
      "test_test\n",
      "test mean loss=87501.89453125\n",
      "fin save.\n",
      "epoch 6035\n",
      "test_train\n",
      "train mean loss=62874.553385416664\n",
      "test_test\n",
      "test mean loss=87368.40625\n",
      "fin save.\n",
      "epoch 6036\n",
      "test_train\n",
      "train mean loss=61695.624739583334\n",
      "test_test\n",
      "test mean loss=87329.85546875\n",
      "fin save.\n",
      "epoch 6037\n",
      "test_train\n",
      "train mean loss=62064.07473958333\n",
      "test_test\n",
      "test mean loss=87251.58984375\n",
      "fin save.\n",
      "epoch 6038\n",
      "test_train\n",
      "train mean loss=62269.49309895833\n",
      "test_test\n",
      "test mean loss=87177.54296875\n",
      "fin save.\n",
      "epoch 6039\n",
      "test_train\n",
      "train mean loss=61964.1984375\n",
      "test_test\n",
      "test mean loss=86780.10546875\n",
      "fin save.\n",
      "epoch 6040\n",
      "test_train\n",
      "train mean loss=62589.97838541667\n",
      "test_test\n",
      "test mean loss=87047.6796875\n",
      "fin save.\n",
      "epoch 6041\n",
      "test_train\n",
      "train mean loss=62622.019791666666\n",
      "test_test\n",
      "test mean loss=87046.9140625\n",
      "fin save.\n",
      "epoch 6042\n",
      "test_train\n",
      "train mean loss=61098.09713541667\n",
      "test_test\n",
      "test mean loss=86867.4609375\n",
      "fin save.\n",
      "epoch 6043\n",
      "test_train\n",
      "train mean loss=63461.76158854167\n",
      "test_test\n",
      "test mean loss=86850.42578125\n",
      "fin save.\n",
      "epoch 6044\n",
      "test_train\n",
      "train mean loss=61180.01875\n",
      "test_test\n",
      "test mean loss=86724.7109375\n",
      "fin save.\n",
      "epoch 6045\n",
      "test_train\n",
      "train mean loss=62768.032421875\n",
      "test_test\n",
      "test mean loss=86937.6171875\n",
      "fin save.\n",
      "epoch 6046\n",
      "test_train\n",
      "train mean loss=62944.44296875\n",
      "test_test\n",
      "test mean loss=86745.234375\n",
      "fin save.\n",
      "epoch 6047\n",
      "test_train\n",
      "train mean loss=62084.03046875\n",
      "test_test\n",
      "test mean loss=86685.87890625\n",
      "fin save.\n",
      "epoch 6048\n",
      "test_train\n",
      "train mean loss=61598.945052083334\n",
      "test_test\n",
      "test mean loss=86650.203125\n",
      "fin save.\n",
      "epoch 6049\n",
      "test_train\n",
      "train mean loss=61898.6109375\n",
      "test_test\n",
      "test mean loss=86942.3671875\n",
      "fin save.\n",
      "epoch 6050\n",
      "test_train\n",
      "train mean loss=61731.39166666667\n",
      "test_test\n",
      "test mean loss=86892.45703125\n",
      "fin save.\n",
      "epoch 6051\n",
      "test_train\n",
      "train mean loss=61774.598307291664\n",
      "test_test\n",
      "test mean loss=86919.640625\n",
      "fin save.\n",
      "epoch 6052\n",
      "test_train\n",
      "train mean loss=62082.28515625\n",
      "test_test\n",
      "test mean loss=87178.8515625\n",
      "fin save.\n",
      "epoch 6053\n",
      "test_train\n",
      "train mean loss=62420.602864583336\n",
      "test_test\n",
      "test mean loss=87397.8828125\n",
      "fin save.\n",
      "epoch 6054\n",
      "test_train\n",
      "train mean loss=62333.978125\n",
      "test_test\n",
      "test mean loss=87142.5703125\n",
      "fin save.\n",
      "epoch 6055\n",
      "test_train\n",
      "train mean loss=61929.8203125\n",
      "test_test\n",
      "test mean loss=86888.54296875\n",
      "fin save.\n",
      "epoch 6056\n",
      "test_train\n",
      "train mean loss=63064.9\n",
      "test_test\n",
      "test mean loss=86905.80859375\n",
      "fin save.\n",
      "epoch 6057\n",
      "test_train\n",
      "train mean loss=62389.57760416667\n",
      "test_test\n",
      "test mean loss=87330.5703125\n",
      "fin save.\n",
      "epoch 6058\n",
      "test_train\n",
      "train mean loss=61911.077864583334\n",
      "test_test\n",
      "test mean loss=87429.2890625\n",
      "fin save.\n",
      "epoch 6059\n",
      "test_train\n",
      "train mean loss=61873.05572916667\n",
      "test_test\n",
      "test mean loss=87405.73828125\n",
      "fin save.\n",
      "epoch 6060\n",
      "test_train\n",
      "train mean loss=61969.422135416666\n",
      "test_test\n",
      "test mean loss=87145.078125\n",
      "fin save.\n",
      "epoch 6061\n",
      "test_train\n",
      "train mean loss=62713.799479166664\n",
      "test_test\n",
      "test mean loss=87397.41015625\n",
      "fin save.\n",
      "epoch 6062\n",
      "test_train\n",
      "train mean loss=61418.26666666667\n",
      "test_test\n",
      "test mean loss=86784.125\n",
      "fin save.\n",
      "epoch 6063\n",
      "test_train\n",
      "train mean loss=61527.8453125\n",
      "test_test\n",
      "test mean loss=86690.81640625\n",
      "fin save.\n",
      "epoch 6064\n",
      "test_train\n",
      "train mean loss=62599.10364583333\n",
      "test_test\n",
      "test mean loss=86748.66796875\n",
      "fin save.\n",
      "epoch 6065\n",
      "test_train\n",
      "train mean loss=62775.82630208333\n",
      "test_test\n",
      "test mean loss=86909.69921875\n",
      "fin save.\n",
      "epoch 6066\n",
      "test_train\n",
      "train mean loss=63239.4796875\n",
      "test_test\n",
      "test mean loss=86644.19921875\n",
      "fin save.\n",
      "epoch 6067\n",
      "test_train\n",
      "train mean loss=62044.87643229167\n",
      "test_test\n",
      "test mean loss=86723.01953125\n",
      "fin save.\n",
      "epoch 6068\n",
      "test_train\n",
      "train mean loss=62855.459375\n",
      "test_test\n",
      "test mean loss=86718.45703125\n",
      "fin save.\n",
      "epoch 6069\n",
      "test_train\n",
      "train mean loss=61712.34713541667\n",
      "test_test\n",
      "test mean loss=87390.40234375\n",
      "fin save.\n",
      "epoch 6070\n",
      "test_train\n",
      "train mean loss=62568.3375\n",
      "test_test\n",
      "test mean loss=87481.6484375\n",
      "fin save.\n",
      "epoch 6071\n",
      "test_train\n",
      "train mean loss=62453.34817708333\n",
      "test_test\n",
      "test mean loss=87494.52734375\n",
      "fin save.\n",
      "epoch 6072\n",
      "test_train\n",
      "train mean loss=62846.4015625\n",
      "test_test\n",
      "test mean loss=87019.5703125\n",
      "fin save.\n",
      "epoch 6073\n",
      "test_train\n",
      "train mean loss=61634.07369791667\n",
      "test_test\n",
      "test mean loss=86883.859375\n",
      "fin save.\n",
      "epoch 6074\n",
      "test_train\n",
      "train mean loss=62936.550520833334\n",
      "test_test\n",
      "test mean loss=87080.5859375\n",
      "fin save.\n",
      "epoch 6075\n",
      "test_train\n",
      "train mean loss=62165.91393229167\n",
      "test_test\n",
      "test mean loss=87526.89453125\n",
      "fin save.\n",
      "epoch 6076\n",
      "test_train\n",
      "train mean loss=61649.66328125\n",
      "test_test\n",
      "test mean loss=87547.703125\n",
      "fin save.\n",
      "epoch 6077\n",
      "test_train\n",
      "train mean loss=63047.27239583333\n",
      "test_test\n",
      "test mean loss=87735.0078125\n",
      "fin save.\n",
      "epoch 6078\n",
      "test_train\n",
      "train mean loss=63315.79010416667\n",
      "test_test\n",
      "test mean loss=87571.66015625\n",
      "fin save.\n",
      "epoch 6079\n",
      "test_train\n",
      "train mean loss=62555.85638020833\n",
      "test_test\n",
      "test mean loss=87813.8125\n",
      "fin save.\n",
      "epoch 6080\n",
      "test_train\n",
      "train mean loss=61142.441666666666\n",
      "test_test\n",
      "test mean loss=87886.77734375\n",
      "fin save.\n",
      "epoch 6081\n",
      "test_train\n",
      "train mean loss=62697.46588541667\n",
      "test_test\n",
      "test mean loss=87771.8125\n",
      "fin save.\n",
      "epoch 6082\n",
      "test_train\n",
      "train mean loss=62589.58880208333\n",
      "test_test\n",
      "test mean loss=87785.36328125\n",
      "fin save.\n",
      "epoch 6083\n",
      "test_train\n",
      "train mean loss=61924.73932291667\n",
      "test_test\n",
      "test mean loss=88125.98828125\n",
      "fin save.\n",
      "epoch 6084\n",
      "test_train\n",
      "train mean loss=61213.40677083333\n",
      "test_test\n",
      "test mean loss=87882.015625\n",
      "fin save.\n",
      "epoch 6085\n",
      "test_train\n",
      "train mean loss=62231.0265625\n",
      "test_test\n",
      "test mean loss=87971.109375\n",
      "fin save.\n",
      "epoch 6086\n",
      "test_train\n",
      "train mean loss=62404.95013020833\n",
      "test_test\n",
      "test mean loss=87855.2109375\n",
      "fin save.\n",
      "epoch 6087\n",
      "test_train\n",
      "train mean loss=62553.820963541664\n",
      "test_test\n",
      "test mean loss=87873.76171875\n",
      "fin save.\n",
      "epoch 6088\n",
      "test_train\n",
      "train mean loss=62892.21796875\n",
      "test_test\n",
      "test mean loss=87973.30859375\n",
      "fin save.\n",
      "epoch 6089\n",
      "test_train\n",
      "train mean loss=62729.68020833333\n",
      "test_test\n",
      "test mean loss=88037.9609375\n",
      "fin save.\n",
      "epoch 6090\n",
      "test_train\n",
      "train mean loss=62510.03333333333\n",
      "test_test\n",
      "test mean loss=88065.953125\n",
      "fin save.\n",
      "epoch 6091\n",
      "test_train\n",
      "train mean loss=62195.46666666667\n",
      "test_test\n",
      "test mean loss=88413.11328125\n",
      "fin save.\n",
      "epoch 6092\n",
      "test_train\n",
      "train mean loss=61685.01263020833\n",
      "test_test\n",
      "test mean loss=87956.00390625\n",
      "fin save.\n",
      "epoch 6093\n",
      "test_train\n",
      "train mean loss=62946.71536458333\n",
      "test_test\n",
      "test mean loss=87877.51171875\n",
      "fin save.\n",
      "epoch 6094\n",
      "test_train\n",
      "train mean loss=63133.484635416666\n",
      "test_test\n",
      "test mean loss=87940.2265625\n",
      "fin save.\n",
      "epoch 6095\n",
      "test_train\n",
      "train mean loss=62922.66302083333\n",
      "test_test\n",
      "test mean loss=87947.671875\n",
      "fin save.\n",
      "epoch 6096\n",
      "test_train\n",
      "train mean loss=62714.833984375\n",
      "test_test\n",
      "test mean loss=88311.38671875\n",
      "fin save.\n",
      "epoch 6097\n",
      "test_train\n",
      "train mean loss=63120.7625\n",
      "test_test\n",
      "test mean loss=88170.54296875\n",
      "fin save.\n",
      "epoch 6098\n",
      "test_train\n",
      "train mean loss=62466.592057291666\n",
      "test_test\n",
      "test mean loss=87990.8828125\n",
      "fin save.\n",
      "epoch 6099\n",
      "test_train\n",
      "train mean loss=63437.29739583333\n",
      "test_test\n",
      "test mean loss=88129.53515625\n",
      "fin save.\n",
      "epoch 6100\n",
      "test_train\n",
      "train mean loss=62154.402083333334\n",
      "test_test\n",
      "test mean loss=88219.265625\n",
      "fin save.\n",
      "epoch 6101\n",
      "test_train\n",
      "train mean loss=62886.701953125\n",
      "test_test\n",
      "test mean loss=88097.03515625\n",
      "fin save.\n",
      "epoch 6102\n",
      "test_train\n",
      "train mean loss=62959.491927083334\n",
      "test_test\n",
      "test mean loss=88013.5703125\n",
      "fin save.\n",
      "epoch 6103\n",
      "test_train\n",
      "train mean loss=63085.1\n",
      "test_test\n",
      "test mean loss=88031.9375\n",
      "fin save.\n",
      "epoch 6104\n",
      "test_train\n",
      "train mean loss=62635.16692708333\n",
      "test_test\n",
      "test mean loss=87914.578125\n",
      "fin save.\n",
      "epoch 6105\n",
      "test_train\n",
      "train mean loss=62608.80703125\n",
      "test_test\n",
      "test mean loss=88113.4765625\n",
      "fin save.\n",
      "epoch 6106\n",
      "test_train\n",
      "train mean loss=61915.56640625\n",
      "test_test\n",
      "test mean loss=88095.8203125\n",
      "fin save.\n",
      "epoch 6107\n",
      "test_train\n",
      "train mean loss=62075.33515625\n",
      "test_test\n",
      "test mean loss=88207.44140625\n",
      "fin save.\n",
      "epoch 6108\n",
      "test_train\n",
      "train mean loss=63445.97473958333\n",
      "test_test\n",
      "test mean loss=88034.671875\n",
      "fin save.\n",
      "epoch 6109\n",
      "test_train\n",
      "train mean loss=62337.5234375\n",
      "test_test\n",
      "test mean loss=88104.9140625\n",
      "fin save.\n",
      "epoch 6110\n",
      "test_train\n",
      "train mean loss=61988.00833333333\n",
      "test_test\n",
      "test mean loss=88201.77734375\n",
      "fin save.\n",
      "epoch 6111\n",
      "test_train\n",
      "train mean loss=62322.871354166666\n",
      "test_test\n",
      "test mean loss=87795.07421875\n",
      "fin save.\n",
      "epoch 6112\n",
      "test_train\n",
      "train mean loss=61987.24765625\n",
      "test_test\n",
      "test mean loss=87777.6953125\n",
      "fin save.\n",
      "epoch 6113\n",
      "test_train\n",
      "train mean loss=62264.82760416667\n",
      "test_test\n",
      "test mean loss=87688.3046875\n",
      "fin save.\n",
      "epoch 6114\n",
      "test_train\n",
      "train mean loss=62538.0765625\n",
      "test_test\n",
      "test mean loss=87550.68359375\n",
      "fin save.\n",
      "epoch 6115\n",
      "test_train\n",
      "train mean loss=61239.35338541667\n",
      "test_test\n",
      "test mean loss=87503.19921875\n",
      "fin save.\n",
      "epoch 6116\n",
      "test_train\n",
      "train mean loss=62381.351953125\n",
      "test_test\n",
      "test mean loss=87760.078125\n",
      "fin save.\n",
      "epoch 6117\n",
      "test_train\n",
      "train mean loss=62633.62421875\n",
      "test_test\n",
      "test mean loss=87507.90625\n",
      "fin save.\n",
      "epoch 6118\n",
      "test_train\n",
      "train mean loss=62272.53802083333\n",
      "test_test\n",
      "test mean loss=87789.52734375\n",
      "fin save.\n",
      "epoch 6119\n",
      "test_train\n",
      "train mean loss=61578.834765625\n",
      "test_test\n",
      "test mean loss=87600.5\n",
      "fin save.\n",
      "epoch 6120\n",
      "test_train\n",
      "train mean loss=61861.08489583333\n",
      "test_test\n",
      "test mean loss=87467.609375\n",
      "fin save.\n",
      "epoch 6121\n",
      "test_train\n",
      "train mean loss=61483.93958333333\n",
      "test_test\n",
      "test mean loss=87511.828125\n",
      "fin save.\n",
      "epoch 6122\n",
      "test_train\n",
      "train mean loss=62203.151041666664\n",
      "test_test\n",
      "test mean loss=87499.96484375\n",
      "fin save.\n",
      "epoch 6123\n",
      "test_train\n",
      "train mean loss=63285.825520833336\n",
      "test_test\n",
      "test mean loss=87597.890625\n",
      "fin save.\n",
      "epoch 6124\n",
      "test_train\n",
      "train mean loss=62968.653125\n",
      "test_test\n",
      "test mean loss=87672.05078125\n",
      "fin save.\n",
      "epoch 6125\n",
      "test_train\n",
      "train mean loss=62076.494791666664\n",
      "test_test\n",
      "test mean loss=87660.56640625\n",
      "fin save.\n",
      "epoch 6126\n",
      "test_train\n",
      "train mean loss=62325.070052083334\n",
      "test_test\n",
      "test mean loss=87584.10546875\n",
      "fin save.\n",
      "epoch 6127\n",
      "test_train\n",
      "train mean loss=62511.7109375\n",
      "test_test\n",
      "test mean loss=87521.6953125\n",
      "fin save.\n",
      "epoch 6128\n",
      "test_train\n",
      "train mean loss=62934.77838541667\n",
      "test_test\n",
      "test mean loss=87434.02734375\n",
      "fin save.\n",
      "epoch 6129\n",
      "test_train\n",
      "train mean loss=62326.72864583333\n",
      "test_test\n",
      "test mean loss=87504.78125\n",
      "fin save.\n",
      "epoch 6130\n",
      "test_train\n",
      "train mean loss=62654.39140625\n",
      "test_test\n",
      "test mean loss=87484.6171875\n",
      "fin save.\n",
      "epoch 6131\n",
      "test_train\n",
      "train mean loss=62393.768229166664\n",
      "test_test\n",
      "test mean loss=87628.40625\n",
      "fin save.\n",
      "epoch 6132\n",
      "test_train\n",
      "train mean loss=62450.24114583333\n",
      "test_test\n",
      "test mean loss=87531.80859375\n",
      "fin save.\n",
      "epoch 6133\n",
      "test_train\n",
      "train mean loss=62580.97213541667\n",
      "test_test\n",
      "test mean loss=87597.84375\n",
      "fin save.\n",
      "epoch 6134\n",
      "test_train\n",
      "train mean loss=62518.83385416667\n",
      "test_test\n",
      "test mean loss=87767.578125\n",
      "fin save.\n",
      "epoch 6135\n",
      "test_train\n",
      "train mean loss=62908.386979166666\n",
      "test_test\n",
      "test mean loss=87774.51171875\n",
      "fin save.\n",
      "epoch 6136\n",
      "test_train\n",
      "train mean loss=61698.940625\n",
      "test_test\n",
      "test mean loss=87789.73828125\n",
      "fin save.\n",
      "epoch 6137\n",
      "test_train\n",
      "train mean loss=62002.93841145833\n",
      "test_test\n",
      "test mean loss=87800.203125\n",
      "fin save.\n",
      "epoch 6138\n",
      "test_train\n",
      "train mean loss=61835.505598958334\n",
      "test_test\n",
      "test mean loss=87567.6015625\n",
      "fin save.\n",
      "epoch 6139\n",
      "test_train\n",
      "train mean loss=62119.122265625\n",
      "test_test\n",
      "test mean loss=87779.43359375\n",
      "fin save.\n",
      "epoch 6140\n",
      "test_train\n",
      "train mean loss=61776.85703125\n",
      "test_test\n",
      "test mean loss=87945.55859375\n",
      "fin save.\n",
      "epoch 6141\n",
      "test_train\n",
      "train mean loss=62423.745833333334\n",
      "test_test\n",
      "test mean loss=87685.19140625\n",
      "fin save.\n",
      "epoch 6142\n",
      "test_train\n",
      "train mean loss=62539.8453125\n",
      "test_test\n",
      "test mean loss=87667.015625\n",
      "fin save.\n",
      "epoch 6143\n",
      "test_train\n",
      "train mean loss=61715.92083333333\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=87710.4453125\n",
      "fin save.\n",
      "epoch 6144\n",
      "test_train\n",
      "train mean loss=62704.79583333333\n",
      "test_test\n",
      "test mean loss=87584.359375\n",
      "fin save.\n",
      "epoch 6145\n",
      "test_train\n",
      "train mean loss=62377.82174479167\n",
      "test_test\n",
      "test mean loss=87726.6171875\n",
      "fin save.\n",
      "epoch 6146\n",
      "test_train\n",
      "train mean loss=61988.66901041667\n",
      "test_test\n",
      "test mean loss=87691.953125\n",
      "fin save.\n",
      "epoch 6147\n",
      "test_train\n",
      "train mean loss=62121.98723958333\n",
      "test_test\n",
      "test mean loss=87646.82421875\n",
      "fin save.\n",
      "epoch 6148\n",
      "test_train\n",
      "train mean loss=61582.102864583336\n",
      "test_test\n",
      "test mean loss=87545.09375\n",
      "fin save.\n",
      "epoch 6149\n",
      "test_train\n",
      "train mean loss=61658.30130208333\n",
      "test_test\n",
      "test mean loss=87428.640625\n",
      "fin save.\n",
      "epoch 6150\n",
      "test_train\n",
      "train mean loss=62268.221875\n",
      "test_test\n",
      "test mean loss=87782.765625\n",
      "fin save.\n",
      "epoch 6151\n",
      "test_train\n",
      "train mean loss=61915.13880208333\n",
      "test_test\n",
      "test mean loss=87758.125\n",
      "fin save.\n",
      "epoch 6152\n",
      "test_train\n",
      "train mean loss=62581.296875\n",
      "test_test\n",
      "test mean loss=87671.546875\n",
      "fin save.\n",
      "epoch 6153\n",
      "test_train\n",
      "train mean loss=61950.123697916664\n",
      "test_test\n",
      "test mean loss=87807.1328125\n",
      "fin save.\n",
      "epoch 6154\n",
      "test_train\n",
      "train mean loss=62515.978125\n",
      "test_test\n",
      "test mean loss=87565.5859375\n",
      "fin save.\n",
      "epoch 6155\n",
      "test_train\n",
      "train mean loss=62131.096484375\n",
      "test_test\n",
      "test mean loss=87610.796875\n",
      "fin save.\n",
      "epoch 6156\n",
      "test_train\n",
      "train mean loss=62371.73671875\n",
      "test_test\n",
      "test mean loss=87865.671875\n",
      "fin save.\n",
      "epoch 6157\n",
      "test_train\n",
      "train mean loss=62219.48385416667\n",
      "test_test\n",
      "test mean loss=87628.83203125\n",
      "fin save.\n",
      "epoch 6158\n",
      "test_train\n",
      "train mean loss=62479.421875\n",
      "test_test\n",
      "test mean loss=88014.57421875\n",
      "fin save.\n",
      "epoch 6159\n",
      "test_train\n",
      "train mean loss=62576.68125\n",
      "test_test\n",
      "test mean loss=87937.48046875\n",
      "fin save.\n",
      "epoch 6160\n",
      "test_train\n",
      "train mean loss=61780.065104166664\n",
      "test_test\n",
      "test mean loss=87771.8671875\n",
      "fin save.\n",
      "epoch 6161\n",
      "test_train\n",
      "train mean loss=62125.64635416667\n",
      "test_test\n",
      "test mean loss=87752.20703125\n",
      "fin save.\n",
      "epoch 6162\n",
      "test_train\n",
      "train mean loss=61826.366927083334\n",
      "test_test\n",
      "test mean loss=87840.4609375\n",
      "fin save.\n",
      "epoch 6163\n",
      "test_train\n",
      "train mean loss=63013.46536458333\n",
      "test_test\n",
      "test mean loss=87716.76953125\n",
      "fin save.\n",
      "epoch 6164\n",
      "test_train\n",
      "train mean loss=62690.321614583336\n",
      "test_test\n",
      "test mean loss=87641.6953125\n",
      "fin save.\n",
      "epoch 6165\n",
      "test_train\n",
      "train mean loss=62959.92526041667\n",
      "test_test\n",
      "test mean loss=87891.33203125\n",
      "fin save.\n",
      "epoch 6166\n",
      "test_train\n",
      "train mean loss=62130.81041666667\n",
      "test_test\n",
      "test mean loss=88033.890625\n",
      "fin save.\n",
      "epoch 6167\n",
      "test_train\n",
      "train mean loss=62741.11640625\n",
      "test_test\n",
      "test mean loss=87956.63671875\n",
      "fin save.\n",
      "epoch 6168\n",
      "test_train\n",
      "train mean loss=61630.0671875\n",
      "test_test\n",
      "test mean loss=88266.296875\n",
      "fin save.\n",
      "epoch 6169\n",
      "test_train\n",
      "train mean loss=62348.82083333333\n",
      "test_test\n",
      "test mean loss=87972.4609375\n",
      "fin save.\n",
      "epoch 6170\n",
      "test_train\n",
      "train mean loss=61986.621875\n",
      "test_test\n",
      "test mean loss=88192.91015625\n",
      "fin save.\n",
      "epoch 6171\n",
      "test_train\n",
      "train mean loss=61960.65833333333\n",
      "test_test\n",
      "test mean loss=87918.828125\n",
      "fin save.\n",
      "epoch 6172\n",
      "test_train\n",
      "train mean loss=61716.784895833334\n",
      "test_test\n",
      "test mean loss=87927.05078125\n",
      "fin save.\n",
      "epoch 6173\n",
      "test_train\n",
      "train mean loss=62871.71796875\n",
      "test_test\n",
      "test mean loss=88087.54296875\n",
      "fin save.\n",
      "epoch 6174\n",
      "test_train\n",
      "train mean loss=63176.325\n",
      "test_test\n",
      "test mean loss=88117.1875\n",
      "fin save.\n",
      "epoch 6175\n",
      "test_train\n",
      "train mean loss=60997.94479166667\n",
      "test_test\n",
      "test mean loss=88269.15234375\n",
      "fin save.\n",
      "epoch 6176\n",
      "test_train\n",
      "train mean loss=62464.3140625\n",
      "test_test\n",
      "test mean loss=88196.16015625\n",
      "fin save.\n",
      "epoch 6177\n",
      "test_train\n",
      "train mean loss=61707.01080729167\n",
      "test_test\n",
      "test mean loss=88092.3203125\n",
      "fin save.\n",
      "epoch 6178\n",
      "test_train\n",
      "train mean loss=62246.3046875\n",
      "test_test\n",
      "test mean loss=88317.32421875\n",
      "fin save.\n",
      "epoch 6179\n",
      "test_train\n",
      "train mean loss=62814.933854166666\n",
      "test_test\n",
      "test mean loss=87484.95703125\n",
      "fin save.\n",
      "epoch 6180\n",
      "test_train\n",
      "train mean loss=61619.32369791667\n",
      "test_test\n",
      "test mean loss=87648.6328125\n",
      "fin save.\n",
      "epoch 6181\n",
      "test_train\n",
      "train mean loss=62117.270833333336\n",
      "test_test\n",
      "test mean loss=87268.4765625\n",
      "fin save.\n",
      "epoch 6182\n",
      "test_train\n",
      "train mean loss=61254.63333333333\n",
      "test_test\n",
      "test mean loss=87383.359375\n",
      "fin save.\n",
      "epoch 6183\n",
      "test_train\n",
      "train mean loss=62071.55260416667\n",
      "test_test\n",
      "test mean loss=87353.03515625\n",
      "fin save.\n",
      "epoch 6184\n",
      "test_train\n",
      "train mean loss=62564.17877604167\n",
      "test_test\n",
      "test mean loss=87092.01171875\n",
      "fin save.\n",
      "epoch 6185\n",
      "test_train\n",
      "train mean loss=62904.749739583334\n",
      "test_test\n",
      "test mean loss=87693.546875\n",
      "fin save.\n",
      "epoch 6186\n",
      "test_train\n",
      "train mean loss=61801.348046875\n",
      "test_test\n",
      "test mean loss=87830.203125\n",
      "fin save.\n",
      "epoch 6187\n",
      "test_train\n",
      "train mean loss=62251.2203125\n",
      "test_test\n",
      "test mean loss=87626.31640625\n",
      "fin save.\n",
      "epoch 6188\n",
      "test_train\n",
      "train mean loss=61961.33932291667\n",
      "test_test\n",
      "test mean loss=87728.03515625\n",
      "fin save.\n",
      "epoch 6189\n",
      "test_train\n",
      "train mean loss=62339.22942708333\n",
      "test_test\n",
      "test mean loss=87836.1015625\n",
      "fin save.\n",
      "epoch 6190\n",
      "test_train\n",
      "train mean loss=62378.722916666666\n",
      "test_test\n",
      "test mean loss=87507.58203125\n",
      "fin save.\n",
      "epoch 6191\n",
      "test_train\n",
      "train mean loss=63438.0703125\n",
      "test_test\n",
      "test mean loss=87640.92578125\n",
      "fin save.\n",
      "epoch 6192\n",
      "test_train\n",
      "train mean loss=62304.59661458333\n",
      "test_test\n",
      "test mean loss=87583.26953125\n",
      "fin save.\n",
      "epoch 6193\n",
      "test_train\n",
      "train mean loss=62002.35794270833\n",
      "test_test\n",
      "test mean loss=87243.05859375\n",
      "fin save.\n",
      "epoch 6194\n",
      "test_train\n",
      "train mean loss=61941.146875\n",
      "test_test\n",
      "test mean loss=87460.45703125\n",
      "fin save.\n",
      "epoch 6195\n",
      "test_train\n",
      "train mean loss=62289.283203125\n",
      "test_test\n",
      "test mean loss=87516.54296875\n",
      "fin save.\n",
      "epoch 6196\n",
      "test_train\n",
      "train mean loss=62433.81536458333\n",
      "test_test\n",
      "test mean loss=87355.85546875\n",
      "fin save.\n",
      "epoch 6197\n",
      "test_train\n",
      "train mean loss=61330.11640625\n",
      "test_test\n",
      "test mean loss=87364.30859375\n",
      "fin save.\n",
      "epoch 6198\n",
      "test_train\n",
      "train mean loss=63120.46106770833\n",
      "test_test\n",
      "test mean loss=87414.6328125\n",
      "fin save.\n",
      "epoch 6199\n",
      "test_train\n",
      "train mean loss=61956.496875\n",
      "test_test\n",
      "test mean loss=87286.875\n",
      "fin save.\n",
      "epoch 6200\n",
      "test_train\n",
      "train mean loss=62298.925\n",
      "test_test\n",
      "test mean loss=87241.59375\n",
      "fin save.\n",
      "epoch 6201\n",
      "test_train\n",
      "train mean loss=61849.54765625\n",
      "test_test\n",
      "test mean loss=87118.00390625\n",
      "fin save.\n",
      "epoch 6202\n",
      "test_train\n",
      "train mean loss=62774.392578125\n",
      "test_test\n",
      "test mean loss=87285.4609375\n",
      "fin save.\n",
      "epoch 6203\n",
      "test_train\n",
      "train mean loss=61708.84453125\n",
      "test_test\n",
      "test mean loss=87221.94921875\n",
      "fin save.\n",
      "epoch 6204\n",
      "test_train\n",
      "train mean loss=62681.069010416664\n",
      "test_test\n",
      "test mean loss=87038.71484375\n",
      "fin save.\n",
      "epoch 6205\n",
      "test_train\n",
      "train mean loss=61910.47760416667\n",
      "test_test\n",
      "test mean loss=87218.0\n",
      "fin save.\n",
      "epoch 6206\n",
      "test_train\n",
      "train mean loss=62321.24791666667\n",
      "test_test\n",
      "test mean loss=87230.7890625\n",
      "fin save.\n",
      "epoch 6207\n",
      "test_train\n",
      "train mean loss=61993.46731770833\n",
      "test_test\n",
      "test mean loss=87485.7890625\n",
      "fin save.\n",
      "epoch 6208\n",
      "test_train\n",
      "train mean loss=62156.601953125\n",
      "test_test\n",
      "test mean loss=87404.28125\n",
      "fin save.\n",
      "epoch 6209\n",
      "test_train\n",
      "train mean loss=62305.32018229167\n",
      "test_test\n",
      "test mean loss=87361.1640625\n",
      "fin save.\n",
      "epoch 6210\n",
      "test_train\n",
      "train mean loss=62558.741927083334\n",
      "test_test\n",
      "test mean loss=87297.00390625\n",
      "fin save.\n",
      "epoch 6211\n",
      "test_train\n",
      "train mean loss=62342.584635416664\n",
      "test_test\n",
      "test mean loss=87316.87890625\n",
      "fin save.\n",
      "epoch 6212\n",
      "test_train\n",
      "train mean loss=63057.50963541667\n",
      "test_test\n",
      "test mean loss=87351.94140625\n",
      "fin save.\n",
      "epoch 6213\n",
      "test_train\n",
      "train mean loss=62547.165625\n",
      "test_test\n",
      "test mean loss=87331.87109375\n",
      "fin save.\n",
      "epoch 6214\n",
      "test_train\n",
      "train mean loss=62730.625390625\n",
      "test_test\n",
      "test mean loss=87287.25\n",
      "fin save.\n",
      "epoch 6215\n",
      "test_train\n",
      "train mean loss=62051.996875\n",
      "test_test\n",
      "test mean loss=87198.2421875\n",
      "fin save.\n",
      "epoch 6216\n",
      "test_train\n",
      "train mean loss=61902.174479166664\n",
      "test_test\n",
      "test mean loss=87229.26953125\n",
      "fin save.\n",
      "epoch 6217\n",
      "test_train\n",
      "train mean loss=61776.242838541664\n",
      "test_test\n",
      "test mean loss=87528.5390625\n",
      "fin save.\n",
      "epoch 6218\n",
      "test_train\n",
      "train mean loss=61328.065104166664\n",
      "test_test\n",
      "test mean loss=87140.65625\n",
      "fin save.\n",
      "epoch 6219\n",
      "test_train\n",
      "train mean loss=63058.25963541667\n",
      "test_test\n",
      "test mean loss=87086.796875\n",
      "fin save.\n",
      "epoch 6220\n",
      "test_train\n",
      "train mean loss=63174.97213541667\n",
      "test_test\n",
      "test mean loss=87179.92578125\n",
      "fin save.\n",
      "epoch 6221\n",
      "test_train\n",
      "train mean loss=61925.886458333334\n",
      "test_test\n",
      "test mean loss=87368.7109375\n",
      "fin save.\n",
      "epoch 6222\n",
      "test_train\n",
      "train mean loss=62680.10598958333\n",
      "test_test\n",
      "test mean loss=87657.20703125\n",
      "fin save.\n",
      "epoch 6223\n",
      "test_train\n",
      "train mean loss=63844.14049479167\n",
      "test_test\n",
      "test mean loss=87542.65625\n",
      "fin save.\n",
      "epoch 6224\n",
      "test_train\n",
      "train mean loss=61654.24661458333\n",
      "test_test\n",
      "test mean loss=87398.19140625\n",
      "fin save.\n",
      "epoch 6225\n",
      "test_train\n",
      "train mean loss=62641.370442708336\n",
      "test_test\n",
      "test mean loss=87633.296875\n",
      "fin save.\n",
      "epoch 6226\n",
      "test_train\n",
      "train mean loss=63856.65625\n",
      "test_test\n",
      "test mean loss=87382.08984375\n",
      "fin save.\n",
      "epoch 6227\n",
      "test_train\n",
      "train mean loss=62568.700390625\n",
      "test_test\n",
      "test mean loss=87327.2734375\n",
      "fin save.\n",
      "epoch 6228\n",
      "test_train\n",
      "train mean loss=61727.96731770833\n",
      "test_test\n",
      "test mean loss=87360.1328125\n",
      "fin save.\n",
      "epoch 6229\n",
      "test_train\n",
      "train mean loss=61138.640885416666\n",
      "test_test\n",
      "test mean loss=87386.87109375\n",
      "fin save.\n",
      "epoch 6230\n",
      "test_train\n",
      "train mean loss=62468.485677083336\n",
      "test_test\n",
      "test mean loss=87063.39453125\n",
      "fin save.\n",
      "epoch 6231\n",
      "test_train\n",
      "train mean loss=61798.774739583336\n",
      "test_test\n",
      "test mean loss=87172.09765625\n",
      "fin save.\n",
      "epoch 6232\n",
      "test_train\n",
      "train mean loss=61903.916666666664\n",
      "test_test\n",
      "test mean loss=87303.96484375\n",
      "fin save.\n",
      "epoch 6233\n",
      "test_train\n",
      "train mean loss=62399.60703125\n",
      "test_test\n",
      "test mean loss=87551.953125\n",
      "fin save.\n",
      "epoch 6234\n",
      "test_train\n",
      "train mean loss=63080.649739583336\n",
      "test_test\n",
      "test mean loss=87362.1328125\n",
      "fin save.\n",
      "epoch 6235\n",
      "test_train\n",
      "train mean loss=62597.68541666667\n",
      "test_test\n",
      "test mean loss=87453.2109375\n",
      "fin save.\n",
      "epoch 6236\n",
      "test_train\n",
      "train mean loss=62809.280598958336\n",
      "test_test\n",
      "test mean loss=87297.125\n",
      "fin save.\n",
      "epoch 6237\n",
      "test_train\n",
      "train mean loss=62673.211328125\n",
      "test_test\n",
      "test mean loss=87477.97265625\n",
      "fin save.\n",
      "epoch 6238\n",
      "test_train\n",
      "train mean loss=61362.69348958333\n",
      "test_test\n",
      "test mean loss=87335.16015625\n",
      "fin save.\n",
      "epoch 6239\n",
      "test_train\n",
      "train mean loss=61997.739453125\n",
      "test_test\n",
      "test mean loss=87292.55078125\n",
      "fin save.\n",
      "epoch 6240\n",
      "test_train\n",
      "train mean loss=62517.30416666667\n",
      "test_test\n",
      "test mean loss=87290.03515625\n",
      "fin save.\n",
      "epoch 6241\n",
      "test_train\n",
      "train mean loss=62200.756640625\n",
      "test_test\n",
      "test mean loss=87266.58203125\n",
      "fin save.\n",
      "epoch 6242\n",
      "test_train\n",
      "train mean loss=62147.36901041667\n",
      "test_test\n",
      "test mean loss=87631.48828125\n",
      "fin save.\n",
      "epoch 6243\n",
      "test_train\n",
      "train mean loss=61804.2203125\n",
      "test_test\n",
      "test mean loss=87512.6875\n",
      "fin save.\n",
      "epoch 6244\n",
      "test_train\n",
      "train mean loss=62257.1375\n",
      "test_test\n",
      "test mean loss=87391.30859375\n",
      "fin save.\n",
      "epoch 6245\n",
      "test_train\n",
      "train mean loss=62384.09088541667\n",
      "test_test\n",
      "test mean loss=87378.4921875\n",
      "fin save.\n",
      "epoch 6246\n",
      "test_train\n",
      "train mean loss=63227.4953125\n",
      "test_test\n",
      "test mean loss=87408.32421875\n",
      "fin save.\n",
      "epoch 6247\n",
      "test_train\n",
      "train mean loss=62692.46145833333\n",
      "test_test\n",
      "test mean loss=87225.82421875\n",
      "fin save.\n",
      "epoch 6248\n",
      "test_train\n",
      "train mean loss=62423.1046875\n",
      "test_test\n",
      "test mean loss=87199.0703125\n",
      "fin save.\n",
      "epoch 6249\n",
      "test_train\n",
      "train mean loss=62007.634114583336\n",
      "test_test\n",
      "test mean loss=87097.671875\n",
      "fin save.\n",
      "epoch 6250\n",
      "test_train\n",
      "train mean loss=62785.46588541667\n",
      "test_test\n",
      "test mean loss=87232.4921875\n",
      "fin save.\n",
      "epoch 6251\n",
      "test_train\n",
      "train mean loss=62209.888411458334\n",
      "test_test\n",
      "test mean loss=87159.18359375\n",
      "fin save.\n",
      "epoch 6252\n",
      "test_train\n",
      "train mean loss=61715.309895833336\n",
      "test_test\n",
      "test mean loss=87332.53515625\n",
      "fin save.\n",
      "epoch 6253\n",
      "test_train\n",
      "train mean loss=61885.96627604167\n",
      "test_test\n",
      "test mean loss=87233.9765625\n",
      "fin save.\n",
      "epoch 6254\n",
      "test_train\n",
      "train mean loss=62368.89791666667\n",
      "test_test\n",
      "test mean loss=87388.42578125\n",
      "fin save.\n",
      "epoch 6255\n",
      "test_train\n",
      "train mean loss=61925.337239583336\n",
      "test_test\n",
      "test mean loss=87300.89453125\n",
      "fin save.\n",
      "epoch 6256\n",
      "test_train\n",
      "train mean loss=62236.752604166664\n",
      "test_test\n",
      "test mean loss=87388.7578125\n",
      "fin save.\n",
      "epoch 6257\n",
      "test_train\n",
      "train mean loss=62425.4375\n",
      "test_test\n",
      "test mean loss=87463.3671875\n",
      "fin save.\n",
      "epoch 6258\n",
      "test_train\n",
      "train mean loss=62681.487890625\n",
      "test_test\n",
      "test mean loss=87434.10546875\n",
      "fin save.\n",
      "epoch 6259\n",
      "test_train\n",
      "train mean loss=62548.681640625\n",
      "test_test\n",
      "test mean loss=87473.01953125\n",
      "fin save.\n",
      "epoch 6260\n",
      "test_train\n",
      "train mean loss=61764.510416666664\n",
      "test_test\n",
      "test mean loss=87515.484375\n",
      "fin save.\n",
      "epoch 6261\n",
      "test_train\n",
      "train mean loss=62399.06484375\n",
      "test_test\n",
      "test mean loss=87324.5546875\n",
      "fin save.\n",
      "epoch 6262\n",
      "test_train\n",
      "train mean loss=61634.67473958333\n",
      "test_test\n",
      "test mean loss=87403.8515625\n",
      "fin save.\n",
      "epoch 6263\n",
      "test_train\n",
      "train mean loss=61666.18828125\n",
      "test_test\n",
      "test mean loss=87680.2265625\n",
      "fin save.\n",
      "epoch 6264\n",
      "test_train\n",
      "train mean loss=62651.15703125\n",
      "test_test\n",
      "test mean loss=87545.5078125\n",
      "fin save.\n",
      "epoch 6265\n",
      "test_train\n",
      "train mean loss=61849.553385416664\n",
      "test_test\n",
      "test mean loss=87431.984375\n",
      "fin save.\n",
      "epoch 6266\n",
      "test_train\n",
      "train mean loss=62299.151041666664\n",
      "test_test\n",
      "test mean loss=87127.05078125\n",
      "fin save.\n",
      "epoch 6267\n",
      "test_train\n",
      "train mean loss=62183.4015625\n",
      "test_test\n",
      "test mean loss=87395.48046875\n",
      "fin save.\n",
      "epoch 6268\n",
      "test_train\n",
      "train mean loss=62747.984765625\n",
      "test_test\n",
      "test mean loss=87682.3984375\n",
      "fin save.\n",
      "epoch 6269\n",
      "test_train\n",
      "train mean loss=62861.73489583333\n",
      "test_test\n",
      "test mean loss=87509.71875\n",
      "fin save.\n",
      "epoch 6270\n",
      "test_train\n",
      "train mean loss=62471.551953125\n",
      "test_test\n",
      "test mean loss=87696.7265625\n",
      "fin save.\n",
      "epoch 6271\n",
      "test_train\n",
      "train mean loss=62425.955729166664\n",
      "test_test\n",
      "test mean loss=87769.96875\n",
      "fin save.\n",
      "epoch 6272\n",
      "test_train\n",
      "train mean loss=62293.024088541664\n",
      "test_test\n",
      "test mean loss=87703.4453125\n",
      "fin save.\n",
      "epoch 6273\n",
      "test_train\n",
      "train mean loss=62465.099869791666\n",
      "test_test\n",
      "test mean loss=87608.51953125\n",
      "fin save.\n",
      "epoch 6274\n",
      "test_train\n",
      "train mean loss=62299.874348958336\n",
      "test_test\n",
      "test mean loss=87763.02734375\n",
      "fin save.\n",
      "epoch 6275\n",
      "test_train\n",
      "train mean loss=63359.77109375\n",
      "test_test\n",
      "test mean loss=87384.296875\n",
      "fin save.\n",
      "epoch 6276\n",
      "test_train\n",
      "train mean loss=62234.09166666667\n",
      "test_test\n",
      "test mean loss=87352.5\n",
      "fin save.\n",
      "epoch 6277\n",
      "test_train\n",
      "train mean loss=62266.813802083336\n",
      "test_test\n",
      "test mean loss=87467.4453125\n",
      "fin save.\n",
      "epoch 6278\n",
      "test_train\n",
      "train mean loss=62753.090625\n",
      "test_test\n",
      "test mean loss=87486.91796875\n",
      "fin save.\n",
      "epoch 6279\n",
      "test_train\n",
      "train mean loss=62075.975260416664\n",
      "test_test\n",
      "test mean loss=87619.81640625\n",
      "fin save.\n",
      "epoch 6280\n",
      "test_train\n",
      "train mean loss=61987.871354166666\n",
      "test_test\n",
      "test mean loss=87570.90625\n",
      "fin save.\n",
      "epoch 6281\n",
      "test_train\n",
      "train mean loss=62457.85390625\n",
      "test_test\n",
      "test mean loss=87094.44140625\n",
      "fin save.\n",
      "epoch 6282\n",
      "test_train\n",
      "train mean loss=61607.89947916667\n",
      "test_test\n",
      "test mean loss=87310.5\n",
      "fin save.\n",
      "epoch 6283\n",
      "test_train\n",
      "train mean loss=63262.46536458333\n",
      "test_test\n",
      "test mean loss=87445.234375\n",
      "fin save.\n",
      "epoch 6284\n",
      "test_train\n",
      "train mean loss=62914.690104166664\n",
      "test_test\n",
      "test mean loss=87224.80859375\n",
      "fin save.\n",
      "epoch 6285\n",
      "test_train\n",
      "train mean loss=62892.0953125\n",
      "test_test\n",
      "test mean loss=87345.09375\n",
      "fin save.\n",
      "epoch 6286\n",
      "test_train\n",
      "train mean loss=62479.43463541667\n",
      "test_test\n",
      "test mean loss=87657.25390625\n",
      "fin save.\n",
      "epoch 6287\n",
      "test_train\n",
      "train mean loss=62637.429947916666\n",
      "test_test\n",
      "test mean loss=87167.0\n",
      "fin save.\n",
      "epoch 6288\n",
      "test_train\n",
      "train mean loss=61731.35703125\n",
      "test_test\n",
      "test mean loss=87656.0078125\n",
      "fin save.\n",
      "epoch 6289\n",
      "test_train\n",
      "train mean loss=62220.303385416664\n",
      "test_test\n",
      "test mean loss=87070.078125\n",
      "fin save.\n",
      "epoch 6290\n",
      "test_train\n",
      "train mean loss=62878.10559895833\n",
      "test_test\n",
      "test mean loss=86974.59765625\n",
      "fin save.\n",
      "epoch 6291\n",
      "test_train\n",
      "train mean loss=62791.749739583334\n",
      "test_test\n",
      "test mean loss=86996.2890625\n",
      "fin save.\n",
      "epoch 6292\n",
      "test_train\n",
      "train mean loss=62677.819010416664\n",
      "test_test\n",
      "test mean loss=87126.60546875\n",
      "fin save.\n",
      "epoch 6293\n",
      "test_train\n",
      "train mean loss=62876.65703125\n",
      "test_test\n",
      "test mean loss=86847.0546875\n",
      "fin save.\n",
      "epoch 6294\n",
      "test_train\n",
      "train mean loss=61881.10651041667\n",
      "test_test\n",
      "test mean loss=86879.14453125\n",
      "fin save.\n",
      "epoch 6295\n",
      "test_train\n",
      "train mean loss=61974.27682291667\n",
      "test_test\n",
      "test mean loss=87096.25\n",
      "fin save.\n",
      "epoch 6296\n",
      "test_train\n",
      "train mean loss=63026.02265625\n",
      "test_test\n",
      "test mean loss=87177.61328125\n",
      "fin save.\n",
      "epoch 6297\n",
      "test_train\n",
      "train mean loss=62433.95546875\n",
      "test_test\n",
      "test mean loss=87354.60546875\n",
      "fin save.\n",
      "epoch 6298\n",
      "test_train\n",
      "train mean loss=63347.69088541667\n",
      "test_test\n",
      "test mean loss=87194.3828125\n",
      "fin save.\n",
      "epoch 6299\n",
      "test_train\n",
      "train mean loss=62794.31953125\n",
      "test_test\n",
      "test mean loss=87221.1015625\n",
      "fin save.\n",
      "epoch 6300\n",
      "test_train\n",
      "train mean loss=61916.99010416667\n",
      "test_test\n",
      "test mean loss=87339.140625\n",
      "fin save.\n",
      "epoch 6301\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=62160.73151041667\n",
      "test_test\n",
      "test mean loss=87325.7265625\n",
      "fin save.\n",
      "epoch 6302\n",
      "test_train\n",
      "train mean loss=62154.2109375\n",
      "test_test\n",
      "test mean loss=87551.26953125\n",
      "fin save.\n",
      "epoch 6303\n",
      "test_train\n",
      "train mean loss=63214.890625\n",
      "test_test\n",
      "test mean loss=87771.328125\n",
      "fin save.\n",
      "epoch 6304\n",
      "test_train\n",
      "train mean loss=62562.79401041667\n",
      "test_test\n",
      "test mean loss=87330.41015625\n",
      "fin save.\n",
      "epoch 6305\n",
      "test_train\n",
      "train mean loss=61621.31354166667\n",
      "test_test\n",
      "test mean loss=87824.4921875\n",
      "fin save.\n",
      "epoch 6306\n",
      "test_train\n",
      "train mean loss=61718.38294270833\n",
      "test_test\n",
      "test mean loss=87764.73046875\n",
      "fin save.\n",
      "epoch 6307\n",
      "test_train\n",
      "train mean loss=62517.18151041667\n",
      "test_test\n",
      "test mean loss=87879.296875\n",
      "fin save.\n",
      "epoch 6308\n",
      "test_train\n",
      "train mean loss=62253.01458333333\n",
      "test_test\n",
      "test mean loss=87746.33984375\n",
      "fin save.\n",
      "epoch 6309\n",
      "test_train\n",
      "train mean loss=62737.8859375\n",
      "test_test\n",
      "test mean loss=87922.87890625\n",
      "fin save.\n",
      "epoch 6310\n",
      "test_train\n",
      "train mean loss=61812.508463541664\n",
      "test_test\n",
      "test mean loss=87531.66015625\n",
      "fin save.\n",
      "epoch 6311\n",
      "test_train\n",
      "train mean loss=61937.64140625\n",
      "test_test\n",
      "test mean loss=87454.79296875\n",
      "fin save.\n",
      "epoch 6312\n",
      "test_train\n",
      "train mean loss=61382.539322916666\n",
      "test_test\n",
      "test mean loss=87408.97265625\n",
      "fin save.\n",
      "epoch 6313\n",
      "test_train\n",
      "train mean loss=62203.73684895833\n",
      "test_test\n",
      "test mean loss=87594.24609375\n",
      "fin save.\n",
      "epoch 6314\n",
      "test_train\n",
      "train mean loss=62619.91940104167\n",
      "test_test\n",
      "test mean loss=87634.6328125\n",
      "fin save.\n",
      "epoch 6315\n",
      "test_train\n",
      "train mean loss=61656.10208333333\n",
      "test_test\n",
      "test mean loss=87489.37890625\n",
      "fin save.\n",
      "epoch 6316\n",
      "test_train\n",
      "train mean loss=62438.11770833333\n",
      "test_test\n",
      "test mean loss=87700.79296875\n",
      "fin save.\n",
      "epoch 6317\n",
      "test_train\n",
      "train mean loss=62167.174479166664\n",
      "test_test\n",
      "test mean loss=87392.7890625\n",
      "fin save.\n",
      "epoch 6318\n",
      "test_train\n",
      "train mean loss=62340.58046875\n",
      "test_test\n",
      "test mean loss=87460.10546875\n",
      "fin save.\n",
      "epoch 6319\n",
      "test_train\n",
      "train mean loss=61743.138020833336\n",
      "test_test\n",
      "test mean loss=87387.77734375\n",
      "fin save.\n",
      "epoch 6320\n",
      "test_train\n",
      "train mean loss=62806.574479166666\n",
      "test_test\n",
      "test mean loss=87537.65625\n",
      "fin save.\n",
      "epoch 6321\n",
      "test_train\n",
      "train mean loss=62594.05481770833\n",
      "test_test\n",
      "test mean loss=87503.0390625\n",
      "fin save.\n",
      "epoch 6322\n",
      "test_train\n",
      "train mean loss=61739.54544270833\n",
      "test_test\n",
      "test mean loss=87406.765625\n",
      "fin save.\n",
      "epoch 6323\n",
      "test_train\n",
      "train mean loss=61887.8921875\n",
      "test_test\n",
      "test mean loss=88272.9921875\n",
      "fin save.\n",
      "epoch 6324\n",
      "test_train\n",
      "train mean loss=62463.75598958333\n",
      "test_test\n",
      "test mean loss=87811.83203125\n",
      "fin save.\n",
      "epoch 6325\n",
      "test_train\n",
      "train mean loss=62578.75703125\n",
      "test_test\n",
      "test mean loss=87918.9921875\n",
      "fin save.\n",
      "epoch 6326\n",
      "test_train\n",
      "train mean loss=63955.75677083333\n",
      "test_test\n",
      "test mean loss=87999.9765625\n",
      "fin save.\n",
      "epoch 6327\n",
      "test_train\n",
      "train mean loss=62752.60078125\n",
      "test_test\n",
      "test mean loss=88165.97265625\n",
      "fin save.\n",
      "epoch 6328\n",
      "test_train\n",
      "train mean loss=62044.14296875\n",
      "test_test\n",
      "test mean loss=88062.70703125\n",
      "fin save.\n",
      "epoch 6329\n",
      "test_train\n",
      "train mean loss=62306.527083333334\n",
      "test_test\n",
      "test mean loss=88182.515625\n",
      "fin save.\n",
      "epoch 6330\n",
      "test_train\n",
      "train mean loss=62217.42239583333\n",
      "test_test\n",
      "test mean loss=88218.22265625\n",
      "fin save.\n",
      "epoch 6331\n",
      "test_train\n",
      "train mean loss=61737.1046875\n",
      "test_test\n",
      "test mean loss=88250.80078125\n",
      "fin save.\n",
      "epoch 6332\n",
      "test_train\n",
      "train mean loss=62428.52786458333\n",
      "test_test\n",
      "test mean loss=88067.6953125\n",
      "fin save.\n",
      "epoch 6333\n",
      "test_train\n",
      "train mean loss=63124.136458333334\n",
      "test_test\n",
      "test mean loss=88053.2734375\n",
      "fin save.\n",
      "epoch 6334\n",
      "test_train\n",
      "train mean loss=62534.968489583334\n",
      "test_test\n",
      "test mean loss=88234.86328125\n",
      "fin save.\n",
      "epoch 6335\n",
      "test_train\n",
      "train mean loss=62833.944010416664\n",
      "test_test\n",
      "test mean loss=88125.01171875\n",
      "fin save.\n",
      "epoch 6336\n",
      "test_train\n",
      "train mean loss=62249.1046875\n",
      "test_test\n",
      "test mean loss=88169.671875\n",
      "fin save.\n",
      "epoch 6337\n",
      "test_train\n",
      "train mean loss=62055.863020833334\n",
      "test_test\n",
      "test mean loss=88338.76171875\n",
      "fin save.\n",
      "epoch 6338\n",
      "test_train\n",
      "train mean loss=62151.961197916666\n",
      "test_test\n",
      "test mean loss=88473.16796875\n",
      "fin save.\n",
      "epoch 6339\n",
      "test_train\n",
      "train mean loss=62261.87942708333\n",
      "test_test\n",
      "test mean loss=88167.93359375\n",
      "fin save.\n",
      "epoch 6340\n",
      "test_train\n",
      "train mean loss=62301.8515625\n",
      "test_test\n",
      "test mean loss=88053.5625\n",
      "fin save.\n",
      "epoch 6341\n",
      "test_train\n",
      "train mean loss=62551.57734375\n",
      "test_test\n",
      "test mean loss=87980.84765625\n",
      "fin save.\n",
      "epoch 6342\n",
      "test_train\n",
      "train mean loss=61387.01119791667\n",
      "test_test\n",
      "test mean loss=88035.28515625\n",
      "fin save.\n",
      "epoch 6343\n",
      "test_train\n",
      "train mean loss=63221.78411458333\n",
      "test_test\n",
      "test mean loss=87908.2265625\n",
      "fin save.\n",
      "epoch 6344\n",
      "test_train\n",
      "train mean loss=61288.03515625\n",
      "test_test\n",
      "test mean loss=88028.1328125\n",
      "fin save.\n",
      "epoch 6345\n",
      "test_train\n",
      "train mean loss=62349.858203125\n",
      "test_test\n",
      "test mean loss=87876.98046875\n",
      "fin save.\n",
      "epoch 6346\n",
      "test_train\n",
      "train mean loss=62659.60338541667\n",
      "test_test\n",
      "test mean loss=88042.6640625\n",
      "fin save.\n",
      "epoch 6347\n",
      "test_train\n",
      "train mean loss=60901.23255208333\n",
      "test_test\n",
      "test mean loss=88091.046875\n",
      "fin save.\n",
      "epoch 6348\n",
      "test_train\n",
      "train mean loss=61919.245833333334\n",
      "test_test\n",
      "test mean loss=87981.1796875\n",
      "fin save.\n",
      "epoch 6349\n",
      "test_train\n",
      "train mean loss=62524.996744791664\n",
      "test_test\n",
      "test mean loss=88098.5703125\n",
      "fin save.\n",
      "epoch 6350\n",
      "test_train\n",
      "train mean loss=62207.09921875\n",
      "test_test\n",
      "test mean loss=88091.0703125\n",
      "fin save.\n",
      "epoch 6351\n",
      "test_train\n",
      "train mean loss=61556.730078125\n",
      "test_test\n",
      "test mean loss=88159.640625\n",
      "fin save.\n",
      "epoch 6352\n",
      "test_train\n",
      "train mean loss=62402.13385416667\n",
      "test_test\n",
      "test mean loss=87835.8203125\n",
      "fin save.\n",
      "epoch 6353\n",
      "test_train\n",
      "train mean loss=61889.17916666667\n",
      "test_test\n",
      "test mean loss=87873.4765625\n",
      "fin save.\n",
      "epoch 6354\n",
      "test_train\n",
      "train mean loss=62138.87161458333\n",
      "test_test\n",
      "test mean loss=87734.171875\n",
      "fin save.\n",
      "epoch 6355\n",
      "test_train\n",
      "train mean loss=61927.438671875\n",
      "test_test\n",
      "test mean loss=87832.640625\n",
      "fin save.\n",
      "epoch 6356\n",
      "test_train\n",
      "train mean loss=62454.14166666667\n",
      "test_test\n",
      "test mean loss=87807.37890625\n",
      "fin save.\n",
      "epoch 6357\n",
      "test_train\n",
      "train mean loss=62201.245833333334\n",
      "test_test\n",
      "test mean loss=87997.6171875\n",
      "fin save.\n",
      "epoch 6358\n",
      "test_train\n",
      "train mean loss=62755.713541666664\n",
      "test_test\n",
      "test mean loss=87767.28515625\n",
      "fin save.\n",
      "epoch 6359\n",
      "test_train\n",
      "train mean loss=61876.01223958333\n",
      "test_test\n",
      "test mean loss=87705.08203125\n",
      "fin save.\n",
      "epoch 6360\n",
      "test_train\n",
      "train mean loss=61982.502604166664\n",
      "test_test\n",
      "test mean loss=87521.05078125\n",
      "fin save.\n",
      "epoch 6361\n",
      "test_train\n",
      "train mean loss=62855.55377604167\n",
      "test_test\n",
      "test mean loss=87557.10546875\n",
      "fin save.\n",
      "epoch 6362\n",
      "test_train\n",
      "train mean loss=62460.08411458333\n",
      "test_test\n",
      "test mean loss=87680.99609375\n",
      "fin save.\n",
      "epoch 6363\n",
      "test_train\n",
      "train mean loss=62717.93893229167\n",
      "test_test\n",
      "test mean loss=87903.5703125\n",
      "fin save.\n",
      "epoch 6364\n",
      "test_train\n",
      "train mean loss=61663.29401041667\n",
      "test_test\n",
      "test mean loss=87915.03515625\n",
      "fin save.\n",
      "epoch 6365\n",
      "test_train\n",
      "train mean loss=61255.96276041667\n",
      "test_test\n",
      "test mean loss=87831.53515625\n",
      "fin save.\n",
      "epoch 6366\n",
      "test_train\n",
      "train mean loss=62149.083723958334\n",
      "test_test\n",
      "test mean loss=87620.07421875\n",
      "fin save.\n",
      "epoch 6367\n",
      "test_train\n",
      "train mean loss=62253.933333333334\n",
      "test_test\n",
      "test mean loss=87608.4453125\n",
      "fin save.\n",
      "epoch 6368\n",
      "test_train\n",
      "train mean loss=63181.42369791667\n",
      "test_test\n",
      "test mean loss=87641.98828125\n",
      "fin save.\n",
      "epoch 6369\n",
      "test_train\n",
      "train mean loss=62075.848958333336\n",
      "test_test\n",
      "test mean loss=87535.390625\n",
      "fin save.\n",
      "epoch 6370\n",
      "test_train\n",
      "train mean loss=61908.801432291664\n",
      "test_test\n",
      "test mean loss=87631.50390625\n",
      "fin save.\n",
      "epoch 6371\n",
      "test_train\n",
      "train mean loss=62625.66796875\n",
      "test_test\n",
      "test mean loss=87741.95703125\n",
      "fin save.\n",
      "epoch 6372\n",
      "test_train\n",
      "train mean loss=62537.57265625\n",
      "test_test\n",
      "test mean loss=87927.890625\n",
      "fin save.\n",
      "epoch 6373\n",
      "test_train\n",
      "train mean loss=62400.17786458333\n",
      "test_test\n",
      "test mean loss=88187.8359375\n",
      "fin save.\n",
      "epoch 6374\n",
      "test_train\n",
      "train mean loss=62334.304296875\n",
      "test_test\n",
      "test mean loss=87835.890625\n",
      "fin save.\n",
      "epoch 6375\n",
      "test_train\n",
      "train mean loss=61335.72903645833\n",
      "test_test\n",
      "test mean loss=88114.34375\n",
      "fin save.\n",
      "epoch 6376\n",
      "test_train\n",
      "train mean loss=61823.53697916667\n",
      "test_test\n",
      "test mean loss=88888.2890625\n",
      "fin save.\n",
      "epoch 6377\n",
      "test_train\n",
      "train mean loss=61735.348307291664\n",
      "test_test\n",
      "test mean loss=89021.515625\n",
      "fin save.\n",
      "epoch 6378\n",
      "test_train\n",
      "train mean loss=62229.82239583333\n",
      "test_test\n",
      "test mean loss=88800.953125\n",
      "fin save.\n",
      "epoch 6379\n",
      "test_train\n",
      "train mean loss=62168.72161458333\n",
      "test_test\n",
      "test mean loss=88913.984375\n",
      "fin save.\n",
      "epoch 6380\n",
      "test_train\n",
      "train mean loss=62022.46770833333\n",
      "test_test\n",
      "test mean loss=88637.27734375\n",
      "fin save.\n",
      "epoch 6381\n",
      "test_train\n",
      "train mean loss=62901.065104166664\n",
      "test_test\n",
      "test mean loss=88581.71875\n",
      "fin save.\n",
      "epoch 6382\n",
      "test_train\n",
      "train mean loss=62573.702864583334\n",
      "test_test\n",
      "test mean loss=88756.5546875\n",
      "fin save.\n",
      "epoch 6383\n",
      "test_train\n",
      "train mean loss=62339.890234375\n",
      "test_test\n",
      "test mean loss=88852.60546875\n",
      "fin save.\n",
      "epoch 6384\n",
      "test_train\n",
      "train mean loss=62284.81432291667\n",
      "test_test\n",
      "test mean loss=88645.76171875\n",
      "fin save.\n",
      "epoch 6385\n",
      "test_train\n",
      "train mean loss=62832.42109375\n",
      "test_test\n",
      "test mean loss=88665.28125\n",
      "fin save.\n",
      "epoch 6386\n",
      "test_train\n",
      "train mean loss=62399.40859375\n",
      "test_test\n",
      "test mean loss=88471.10546875\n",
      "fin save.\n",
      "epoch 6387\n",
      "test_train\n",
      "train mean loss=63074.95559895833\n",
      "test_test\n",
      "test mean loss=88207.59375\n",
      "fin save.\n",
      "epoch 6388\n",
      "test_train\n",
      "train mean loss=62360.68541666667\n",
      "test_test\n",
      "test mean loss=88545.1328125\n",
      "fin save.\n",
      "epoch 6389\n",
      "test_train\n",
      "train mean loss=62432.85494791667\n",
      "test_test\n",
      "test mean loss=88206.5\n",
      "fin save.\n",
      "epoch 6390\n",
      "test_train\n",
      "train mean loss=62563.51666666667\n",
      "test_test\n",
      "test mean loss=88442.1328125\n",
      "fin save.\n",
      "epoch 6391\n",
      "test_train\n",
      "train mean loss=62193.65520833333\n",
      "test_test\n",
      "test mean loss=88126.44140625\n",
      "fin save.\n",
      "epoch 6392\n",
      "test_train\n",
      "train mean loss=62472.69296875\n",
      "test_test\n",
      "test mean loss=88274.83203125\n",
      "fin save.\n",
      "epoch 6393\n",
      "test_train\n",
      "train mean loss=63047.707291666666\n",
      "test_test\n",
      "test mean loss=88284.39453125\n",
      "fin save.\n",
      "epoch 6394\n",
      "test_train\n",
      "train mean loss=62632.53229166667\n",
      "test_test\n",
      "test mean loss=88556.45703125\n",
      "fin save.\n",
      "epoch 6395\n",
      "test_train\n",
      "train mean loss=63322.773177083334\n",
      "test_test\n",
      "test mean loss=88293.3359375\n",
      "fin save.\n",
      "epoch 6396\n",
      "test_train\n",
      "train mean loss=62114.68072916667\n",
      "test_test\n",
      "test mean loss=88115.0859375\n",
      "fin save.\n",
      "epoch 6397\n",
      "test_train\n",
      "train mean loss=61838.7953125\n",
      "test_test\n",
      "test mean loss=88195.6171875\n",
      "fin save.\n",
      "epoch 6398\n",
      "test_train\n",
      "train mean loss=62762.32526041667\n",
      "test_test\n",
      "test mean loss=88131.2109375\n",
      "fin save.\n",
      "epoch 6399\n",
      "test_train\n",
      "train mean loss=62509.9984375\n",
      "test_test\n",
      "test mean loss=87049.01171875\n",
      "fin save.\n",
      "epoch 6400\n",
      "test_train\n",
      "train mean loss=62501.46015625\n",
      "test_test\n",
      "test mean loss=87199.78515625\n",
      "fin save.\n",
      "epoch 6401\n",
      "test_train\n",
      "train mean loss=61362.70260416667\n",
      "test_test\n",
      "test mean loss=87420.75390625\n",
      "fin save.\n",
      "epoch 6402\n",
      "test_train\n",
      "train mean loss=62340.928385416664\n",
      "test_test\n",
      "test mean loss=87531.40625\n",
      "fin save.\n",
      "epoch 6403\n",
      "test_train\n",
      "train mean loss=62407.982682291666\n",
      "test_test\n",
      "test mean loss=87444.27734375\n",
      "fin save.\n",
      "epoch 6404\n",
      "test_train\n",
      "train mean loss=62618.309375\n",
      "test_test\n",
      "test mean loss=87573.59765625\n",
      "fin save.\n",
      "epoch 6405\n",
      "test_train\n",
      "train mean loss=62101.446875\n",
      "test_test\n",
      "test mean loss=87677.25\n",
      "fin save.\n",
      "epoch 6406\n",
      "test_train\n",
      "train mean loss=63331.4328125\n",
      "test_test\n",
      "test mean loss=87822.91015625\n",
      "fin save.\n",
      "epoch 6407\n",
      "test_train\n",
      "train mean loss=61888.447916666664\n",
      "test_test\n",
      "test mean loss=87787.95703125\n",
      "fin save.\n",
      "epoch 6408\n",
      "test_train\n",
      "train mean loss=61963.855208333334\n",
      "test_test\n",
      "test mean loss=87608.578125\n",
      "fin save.\n",
      "epoch 6409\n",
      "test_train\n",
      "train mean loss=62761.12057291667\n",
      "test_test\n",
      "test mean loss=87503.19921875\n",
      "fin save.\n",
      "epoch 6410\n",
      "test_train\n",
      "train mean loss=62589.92369791667\n",
      "test_test\n",
      "test mean loss=87709.58203125\n",
      "fin save.\n",
      "epoch 6411\n",
      "test_train\n",
      "train mean loss=62582.175\n",
      "test_test\n",
      "test mean loss=87755.67578125\n",
      "fin save.\n",
      "epoch 6412\n",
      "test_train\n",
      "train mean loss=62058.444010416664\n",
      "test_test\n",
      "test mean loss=87682.44140625\n",
      "fin save.\n",
      "epoch 6413\n",
      "test_train\n",
      "train mean loss=61536.43072916667\n",
      "test_test\n",
      "test mean loss=87881.890625\n",
      "fin save.\n",
      "epoch 6414\n",
      "test_train\n",
      "train mean loss=62520.79192708333\n",
      "test_test\n",
      "test mean loss=87874.60546875\n",
      "fin save.\n",
      "epoch 6415\n",
      "test_train\n",
      "train mean loss=62282.33880208333\n",
      "test_test\n",
      "test mean loss=87933.71484375\n",
      "fin save.\n",
      "epoch 6416\n",
      "test_train\n",
      "train mean loss=61753.4125\n",
      "test_test\n",
      "test mean loss=87587.20703125\n",
      "fin save.\n",
      "epoch 6417\n",
      "test_train\n",
      "train mean loss=62514.35364583333\n",
      "test_test\n",
      "test mean loss=87693.9921875\n",
      "fin save.\n",
      "epoch 6418\n",
      "test_train\n",
      "train mean loss=61966.254557291664\n",
      "test_test\n",
      "test mean loss=87724.3203125\n",
      "fin save.\n",
      "epoch 6419\n",
      "test_train\n",
      "train mean loss=61998.26067708333\n",
      "test_test\n",
      "test mean loss=87737.29296875\n",
      "fin save.\n",
      "epoch 6420\n",
      "test_train\n",
      "train mean loss=62225.533463541666\n",
      "test_test\n",
      "test mean loss=87715.56640625\n",
      "fin save.\n",
      "epoch 6421\n",
      "test_train\n",
      "train mean loss=61550.67174479167\n",
      "test_test\n",
      "test mean loss=87697.13671875\n",
      "fin save.\n",
      "epoch 6422\n",
      "test_train\n",
      "train mean loss=62934.600260416664\n",
      "test_test\n",
      "test mean loss=87602.76171875\n",
      "fin save.\n",
      "epoch 6423\n",
      "test_train\n",
      "train mean loss=62172.94192708333\n",
      "test_test\n",
      "test mean loss=87534.40625\n",
      "fin save.\n",
      "epoch 6424\n",
      "test_train\n",
      "train mean loss=62886.21171875\n",
      "test_test\n",
      "test mean loss=87463.8671875\n",
      "fin save.\n",
      "epoch 6425\n",
      "test_train\n",
      "train mean loss=62091.943359375\n",
      "test_test\n",
      "test mean loss=87724.796875\n",
      "fin save.\n",
      "epoch 6426\n",
      "test_train\n",
      "train mean loss=62002.44375\n",
      "test_test\n",
      "test mean loss=87678.484375\n",
      "fin save.\n",
      "epoch 6427\n",
      "test_train\n",
      "train mean loss=61909.5484375\n",
      "test_test\n",
      "test mean loss=87408.8359375\n",
      "fin save.\n",
      "epoch 6428\n",
      "test_train\n",
      "train mean loss=62271.359375\n",
      "test_test\n",
      "test mean loss=87772.265625\n",
      "fin save.\n",
      "epoch 6429\n",
      "test_train\n",
      "train mean loss=62325.96692708333\n",
      "test_test\n",
      "test mean loss=87758.1328125\n",
      "fin save.\n",
      "epoch 6430\n",
      "test_train\n",
      "train mean loss=62256.235677083336\n",
      "test_test\n",
      "test mean loss=87727.375\n",
      "fin save.\n",
      "epoch 6431\n",
      "test_train\n",
      "train mean loss=62194.495833333334\n",
      "test_test\n",
      "test mean loss=87351.6796875\n",
      "fin save.\n",
      "epoch 6432\n",
      "test_train\n",
      "train mean loss=62364.55234375\n",
      "test_test\n",
      "test mean loss=88864.26171875\n",
      "fin save.\n",
      "epoch 6433\n",
      "test_train\n",
      "train mean loss=61955.989583333336\n",
      "test_test\n",
      "test mean loss=88828.23046875\n",
      "fin save.\n",
      "epoch 6434\n",
      "test_train\n",
      "train mean loss=62521.64244791667\n",
      "test_test\n",
      "test mean loss=88374.734375\n",
      "fin save.\n",
      "epoch 6435\n",
      "test_train\n",
      "train mean loss=61904.209765625\n",
      "test_test\n",
      "test mean loss=88514.83203125\n",
      "fin save.\n",
      "epoch 6436\n",
      "test_train\n",
      "train mean loss=61309.625260416666\n",
      "test_test\n",
      "test mean loss=88422.23046875\n",
      "fin save.\n",
      "epoch 6437\n",
      "test_train\n",
      "train mean loss=62461.92135416667\n",
      "test_test\n",
      "test mean loss=88560.05078125\n",
      "fin save.\n",
      "epoch 6438\n",
      "test_train\n",
      "train mean loss=61934.346354166664\n",
      "test_test\n",
      "test mean loss=88409.60546875\n",
      "fin save.\n",
      "epoch 6439\n",
      "test_train\n",
      "train mean loss=61831.60533854167\n",
      "test_test\n",
      "test mean loss=88591.15625\n",
      "fin save.\n",
      "epoch 6440\n",
      "test_train\n",
      "train mean loss=62472.19231770833\n",
      "test_test\n",
      "test mean loss=88295.2734375\n",
      "fin save.\n",
      "epoch 6441\n",
      "test_train\n",
      "train mean loss=62368.470442708334\n",
      "test_test\n",
      "test mean loss=88279.95703125\n",
      "fin save.\n",
      "epoch 6442\n",
      "test_train\n",
      "train mean loss=62143.023697916666\n",
      "test_test\n",
      "test mean loss=88472.9296875\n",
      "fin save.\n",
      "epoch 6443\n",
      "test_train\n",
      "train mean loss=62599.61640625\n",
      "test_test\n",
      "test mean loss=88545.51171875\n",
      "fin save.\n",
      "epoch 6444\n",
      "test_train\n",
      "train mean loss=61212.527994791664\n",
      "test_test\n",
      "test mean loss=88403.01171875\n",
      "fin save.\n",
      "epoch 6445\n",
      "test_train\n",
      "train mean loss=61611.075\n",
      "test_test\n",
      "test mean loss=88500.2578125\n",
      "fin save.\n",
      "epoch 6446\n",
      "test_train\n",
      "train mean loss=62618.978125\n",
      "test_test\n",
      "test mean loss=88350.8359375\n",
      "fin save.\n",
      "epoch 6447\n",
      "test_train\n",
      "train mean loss=61757.712890625\n",
      "test_test\n",
      "test mean loss=88435.32421875\n",
      "fin save.\n",
      "epoch 6448\n",
      "test_train\n",
      "train mean loss=62252.820572916666\n",
      "test_test\n",
      "test mean loss=88691.80078125\n",
      "fin save.\n",
      "epoch 6449\n",
      "test_train\n",
      "train mean loss=62171.752604166664\n",
      "test_test\n",
      "test mean loss=88790.90625\n",
      "fin save.\n",
      "epoch 6450\n",
      "test_train\n",
      "train mean loss=62227.38984375\n",
      "test_test\n",
      "test mean loss=88426.66796875\n",
      "fin save.\n",
      "epoch 6451\n",
      "test_train\n",
      "train mean loss=62780.65442708333\n",
      "test_test\n",
      "test mean loss=88441.15625\n",
      "fin save.\n",
      "epoch 6452\n",
      "test_train\n",
      "train mean loss=62370.29309895833\n",
      "test_test\n",
      "test mean loss=88395.9375\n",
      "fin save.\n",
      "epoch 6453\n",
      "test_train\n",
      "train mean loss=61948.30807291667\n",
      "test_test\n",
      "test mean loss=88311.6640625\n",
      "fin save.\n",
      "epoch 6454\n",
      "test_train\n",
      "train mean loss=62462.4078125\n",
      "test_test\n",
      "test mean loss=88391.16796875\n",
      "fin save.\n",
      "epoch 6455\n",
      "test_train\n",
      "train mean loss=62919.59427083333\n",
      "test_test\n",
      "test mean loss=88377.03125\n",
      "fin save.\n",
      "epoch 6456\n",
      "test_train\n",
      "train mean loss=61868.83020833333\n",
      "test_test\n",
      "test mean loss=88553.0390625\n",
      "fin save.\n",
      "epoch 6457\n",
      "test_train\n",
      "train mean loss=62716.146875\n",
      "test_test\n",
      "test mean loss=88599.4453125\n",
      "fin save.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6458\n",
      "test_train\n",
      "train mean loss=61830.504166666666\n",
      "test_test\n",
      "test mean loss=88559.8515625\n",
      "fin save.\n",
      "epoch 6459\n",
      "test_train\n",
      "train mean loss=62236.22356770833\n",
      "test_test\n",
      "test mean loss=88585.8046875\n",
      "fin save.\n",
      "epoch 6460\n",
      "test_train\n",
      "train mean loss=61911.42421875\n",
      "test_test\n",
      "test mean loss=88266.32421875\n",
      "fin save.\n",
      "epoch 6461\n",
      "test_train\n",
      "train mean loss=61973.55130208333\n",
      "test_test\n",
      "test mean loss=88335.45703125\n",
      "fin save.\n",
      "epoch 6462\n",
      "test_train\n",
      "train mean loss=62660.19583333333\n",
      "test_test\n",
      "test mean loss=88540.22265625\n",
      "fin save.\n",
      "epoch 6463\n",
      "test_train\n",
      "train mean loss=63456.15\n",
      "test_test\n",
      "test mean loss=88412.55859375\n",
      "fin save.\n",
      "epoch 6464\n",
      "test_train\n",
      "train mean loss=61822.29375\n",
      "test_test\n",
      "test mean loss=88545.74609375\n",
      "fin save.\n",
      "epoch 6465\n",
      "test_train\n",
      "train mean loss=61618.2296875\n",
      "test_test\n",
      "test mean loss=88593.65625\n",
      "fin save.\n",
      "epoch 6466\n",
      "test_train\n",
      "train mean loss=62668.40286458333\n",
      "test_test\n",
      "test mean loss=88510.21875\n",
      "fin save.\n",
      "epoch 6467\n",
      "test_train\n",
      "train mean loss=61869.024088541664\n",
      "test_test\n",
      "test mean loss=88652.4609375\n",
      "fin save.\n",
      "epoch 6468\n",
      "test_train\n",
      "train mean loss=62972.316666666666\n",
      "test_test\n",
      "test mean loss=88373.078125\n",
      "fin save.\n",
      "epoch 6469\n",
      "test_train\n",
      "train mean loss=62545.21484375\n",
      "test_test\n",
      "test mean loss=88316.625\n",
      "fin save.\n",
      "epoch 6470\n",
      "test_train\n",
      "train mean loss=63037.644270833334\n",
      "test_test\n",
      "test mean loss=88319.921875\n",
      "fin save.\n",
      "epoch 6471\n",
      "test_train\n",
      "train mean loss=62856.55364583333\n",
      "test_test\n",
      "test mean loss=88289.2578125\n",
      "fin save.\n",
      "epoch 6472\n",
      "test_train\n",
      "train mean loss=62402.423046875\n",
      "test_test\n",
      "test mean loss=88194.75\n",
      "fin save.\n",
      "epoch 6473\n",
      "test_train\n",
      "train mean loss=61997.04401041667\n",
      "test_test\n",
      "test mean loss=88536.94921875\n",
      "fin save.\n",
      "epoch 6474\n",
      "test_train\n",
      "train mean loss=62381.36536458333\n",
      "test_test\n",
      "test mean loss=88420.19140625\n",
      "fin save.\n",
      "epoch 6475\n",
      "test_train\n",
      "train mean loss=62419.87552083333\n",
      "test_test\n",
      "test mean loss=88355.81640625\n",
      "fin save.\n",
      "epoch 6476\n",
      "test_train\n",
      "train mean loss=62628.505208333336\n",
      "test_test\n",
      "test mean loss=88558.7109375\n",
      "fin save.\n",
      "epoch 6477\n",
      "test_train\n",
      "train mean loss=62141.05807291667\n",
      "test_test\n",
      "test mean loss=88491.90625\n",
      "fin save.\n",
      "epoch 6478\n",
      "test_train\n",
      "train mean loss=61800.82421875\n",
      "test_test\n",
      "test mean loss=88459.796875\n",
      "fin save.\n",
      "epoch 6479\n",
      "test_train\n",
      "train mean loss=62142.98125\n",
      "test_test\n",
      "test mean loss=88491.6328125\n",
      "fin save.\n",
      "epoch 6480\n",
      "test_train\n",
      "train mean loss=61798.08255208333\n",
      "test_test\n",
      "test mean loss=88505.67578125\n",
      "fin save.\n",
      "epoch 6481\n",
      "test_train\n",
      "train mean loss=61559.35078125\n",
      "test_test\n",
      "test mean loss=88440.046875\n",
      "fin save.\n",
      "epoch 6482\n",
      "test_train\n",
      "train mean loss=62190.04401041667\n",
      "test_test\n",
      "test mean loss=88543.79296875\n",
      "fin save.\n",
      "epoch 6483\n",
      "test_train\n",
      "train mean loss=62666.91588541667\n",
      "test_test\n",
      "test mean loss=88633.6875\n",
      "fin save.\n",
      "epoch 6484\n",
      "test_train\n",
      "train mean loss=61498.321484375\n",
      "test_test\n",
      "test mean loss=88558.9296875\n",
      "fin save.\n",
      "epoch 6485\n",
      "test_train\n",
      "train mean loss=62477.653125\n",
      "test_test\n",
      "test mean loss=88128.53515625\n",
      "fin save.\n",
      "epoch 6486\n",
      "test_train\n",
      "train mean loss=61580.43463541667\n",
      "test_test\n",
      "test mean loss=88090.78515625\n",
      "fin save.\n",
      "epoch 6487\n",
      "test_train\n",
      "train mean loss=62428.58671875\n",
      "test_test\n",
      "test mean loss=88250.89453125\n",
      "fin save.\n",
      "epoch 6488\n",
      "test_train\n",
      "train mean loss=62175.52265625\n",
      "test_test\n",
      "test mean loss=88206.0625\n",
      "fin save.\n",
      "epoch 6489\n",
      "test_train\n",
      "train mean loss=62329.320052083334\n",
      "test_test\n",
      "test mean loss=88577.2578125\n",
      "fin save.\n",
      "epoch 6490\n",
      "test_train\n",
      "train mean loss=62392.419140625\n",
      "test_test\n",
      "test mean loss=88460.12890625\n",
      "fin save.\n",
      "epoch 6491\n",
      "test_train\n",
      "train mean loss=63202.77096354167\n",
      "test_test\n",
      "test mean loss=88235.14453125\n",
      "fin save.\n",
      "epoch 6492\n",
      "test_train\n",
      "train mean loss=62706.498697916664\n",
      "test_test\n",
      "test mean loss=88231.87109375\n",
      "fin save.\n",
      "epoch 6493\n",
      "test_train\n",
      "train mean loss=62941.428515625\n",
      "test_test\n",
      "test mean loss=88187.5390625\n",
      "fin save.\n",
      "epoch 6494\n",
      "test_train\n",
      "train mean loss=62509.79505208333\n",
      "test_test\n",
      "test mean loss=88130.39453125\n",
      "fin save.\n",
      "epoch 6495\n",
      "test_train\n",
      "train mean loss=63065.055078125\n",
      "test_test\n",
      "test mean loss=88379.05078125\n",
      "fin save.\n",
      "epoch 6496\n",
      "test_train\n",
      "train mean loss=62524.79192708333\n",
      "test_test\n",
      "test mean loss=88081.9609375\n",
      "fin save.\n",
      "epoch 6497\n",
      "test_train\n",
      "train mean loss=62261.71666666667\n",
      "test_test\n",
      "test mean loss=88257.94921875\n",
      "fin save.\n",
      "epoch 6498\n",
      "test_train\n",
      "train mean loss=61582.8703125\n",
      "test_test\n",
      "test mean loss=88149.6484375\n",
      "fin save.\n",
      "epoch 6499\n",
      "test_train\n",
      "train mean loss=62867.628515625\n",
      "test_test\n",
      "test mean loss=88191.6484375\n",
      "fin save.\n",
      "epoch 6500\n",
      "test_train\n",
      "train mean loss=62623.18046875\n",
      "test_test\n",
      "test mean loss=88360.34765625\n",
      "fin save.\n",
      "epoch 6501\n",
      "test_train\n",
      "train mean loss=62781.751171875\n",
      "test_test\n",
      "test mean loss=88304.51953125\n",
      "fin save.\n",
      "epoch 6502\n",
      "test_train\n",
      "train mean loss=62397.59713541667\n",
      "test_test\n",
      "test mean loss=88208.74609375\n",
      "fin save.\n",
      "epoch 6503\n",
      "test_train\n",
      "train mean loss=62732.11145833333\n",
      "test_test\n",
      "test mean loss=88652.15234375\n",
      "fin save.\n",
      "epoch 6504\n",
      "test_train\n",
      "train mean loss=61398.277083333334\n",
      "test_test\n",
      "test mean loss=88082.26953125\n",
      "fin save.\n",
      "epoch 6505\n",
      "test_train\n",
      "train mean loss=62457.70208333333\n",
      "test_test\n",
      "test mean loss=88210.79296875\n",
      "fin save.\n",
      "epoch 6506\n",
      "test_train\n",
      "train mean loss=61722.98151041667\n",
      "test_test\n",
      "test mean loss=88487.53515625\n",
      "fin save.\n",
      "epoch 6507\n",
      "test_train\n",
      "train mean loss=61614.22317708333\n",
      "test_test\n",
      "test mean loss=88511.484375\n",
      "fin save.\n",
      "epoch 6508\n",
      "test_train\n",
      "train mean loss=62365.69479166667\n",
      "test_test\n",
      "test mean loss=88571.16796875\n",
      "fin save.\n",
      "epoch 6509\n",
      "test_train\n",
      "train mean loss=61724.64765625\n",
      "test_test\n",
      "test mean loss=88542.9296875\n",
      "fin save.\n",
      "epoch 6510\n",
      "test_train\n",
      "train mean loss=61720.821614583336\n",
      "test_test\n",
      "test mean loss=88256.92578125\n",
      "fin save.\n",
      "epoch 6511\n",
      "test_train\n",
      "train mean loss=62022.93411458333\n",
      "test_test\n",
      "test mean loss=88246.40234375\n",
      "fin save.\n",
      "epoch 6512\n",
      "test_train\n",
      "train mean loss=61863.65182291667\n",
      "test_test\n",
      "test mean loss=88159.1484375\n",
      "fin save.\n",
      "epoch 6513\n",
      "test_train\n",
      "train mean loss=62391.97317708333\n",
      "test_test\n",
      "test mean loss=88152.8203125\n",
      "fin save.\n",
      "epoch 6514\n",
      "test_train\n",
      "train mean loss=62708.0890625\n",
      "test_test\n",
      "test mean loss=88254.57421875\n",
      "fin save.\n",
      "epoch 6515\n",
      "test_train\n",
      "train mean loss=61491.88958333333\n",
      "test_test\n",
      "test mean loss=88230.84375\n",
      "fin save.\n",
      "epoch 6516\n",
      "test_train\n",
      "train mean loss=61879.925520833334\n",
      "test_test\n",
      "test mean loss=88234.13671875\n",
      "fin save.\n",
      "epoch 6517\n",
      "test_train\n",
      "train mean loss=61599.314192708334\n",
      "test_test\n",
      "test mean loss=88024.55859375\n",
      "fin save.\n",
      "epoch 6518\n",
      "test_train\n",
      "train mean loss=62142.156901041664\n",
      "test_test\n",
      "test mean loss=88317.20703125\n",
      "fin save.\n",
      "epoch 6519\n",
      "test_train\n",
      "train mean loss=63045.33880208333\n",
      "test_test\n",
      "test mean loss=88485.28125\n",
      "fin save.\n",
      "epoch 6520\n",
      "test_train\n",
      "train mean loss=62231.4203125\n",
      "test_test\n",
      "test mean loss=88162.06640625\n",
      "fin save.\n",
      "epoch 6521\n",
      "test_train\n",
      "train mean loss=61549.55390625\n",
      "test_test\n",
      "test mean loss=88323.05859375\n",
      "fin save.\n",
      "epoch 6522\n",
      "test_train\n",
      "train mean loss=62360.157552083336\n",
      "test_test\n",
      "test mean loss=88233.125\n",
      "fin save.\n",
      "epoch 6523\n",
      "test_train\n",
      "train mean loss=62431.46666666667\n",
      "test_test\n",
      "test mean loss=88754.74609375\n",
      "fin save.\n",
      "epoch 6524\n",
      "test_train\n",
      "train mean loss=62194.89270833333\n",
      "test_test\n",
      "test mean loss=88749.1171875\n",
      "fin save.\n",
      "epoch 6525\n",
      "test_train\n",
      "train mean loss=62507.44739583333\n",
      "test_test\n",
      "test mean loss=88540.97265625\n",
      "fin save.\n",
      "epoch 6526\n",
      "test_train\n",
      "train mean loss=61907.23515625\n",
      "test_test\n",
      "test mean loss=88380.15234375\n",
      "fin save.\n",
      "epoch 6527\n",
      "test_train\n",
      "train mean loss=61459.059895833336\n",
      "test_test\n",
      "test mean loss=88228.578125\n",
      "fin save.\n",
      "epoch 6528\n",
      "test_train\n",
      "train mean loss=61435.56041666667\n",
      "test_test\n",
      "test mean loss=87906.6875\n",
      "fin save.\n",
      "epoch 6529\n",
      "test_train\n",
      "train mean loss=62527.41744791667\n",
      "test_test\n",
      "test mean loss=88300.13671875\n",
      "fin save.\n",
      "epoch 6530\n",
      "test_train\n",
      "train mean loss=61671.571875\n",
      "test_test\n",
      "test mean loss=88198.92578125\n",
      "fin save.\n",
      "epoch 6531\n",
      "test_train\n",
      "train mean loss=62372.28984375\n",
      "test_test\n",
      "test mean loss=88000.2109375\n",
      "fin save.\n",
      "epoch 6532\n",
      "test_train\n",
      "train mean loss=63644.037760416664\n",
      "test_test\n",
      "test mean loss=88161.96875\n",
      "fin save.\n",
      "epoch 6533\n",
      "test_train\n",
      "train mean loss=61995.3890625\n",
      "test_test\n",
      "test mean loss=88026.31640625\n",
      "fin save.\n",
      "epoch 6534\n",
      "test_train\n",
      "train mean loss=62093.93177083333\n",
      "test_test\n",
      "test mean loss=88156.7890625\n",
      "fin save.\n",
      "epoch 6535\n",
      "test_train\n",
      "train mean loss=62686.945572916666\n",
      "test_test\n",
      "test mean loss=88044.4453125\n",
      "fin save.\n",
      "epoch 6536\n",
      "test_train\n",
      "train mean loss=62107.12057291667\n",
      "test_test\n",
      "test mean loss=88122.0703125\n",
      "fin save.\n",
      "epoch 6537\n",
      "test_train\n",
      "train mean loss=62178.14270833333\n",
      "test_test\n",
      "test mean loss=88206.0078125\n",
      "fin save.\n",
      "epoch 6538\n",
      "test_train\n",
      "train mean loss=62048.12018229167\n",
      "test_test\n",
      "test mean loss=88267.17578125\n",
      "fin save.\n",
      "epoch 6539\n",
      "test_train\n",
      "train mean loss=62051.35338541667\n",
      "test_test\n",
      "test mean loss=88127.5546875\n",
      "fin save.\n",
      "epoch 6540\n",
      "test_train\n",
      "train mean loss=62818.67630208333\n",
      "test_test\n",
      "test mean loss=88031.2421875\n",
      "fin save.\n",
      "epoch 6541\n",
      "test_train\n",
      "train mean loss=61973.58450520833\n",
      "test_test\n",
      "test mean loss=88429.34375\n",
      "fin save.\n",
      "epoch 6542\n",
      "test_train\n",
      "train mean loss=62964.913671875\n",
      "test_test\n",
      "test mean loss=88193.72265625\n",
      "fin save.\n",
      "epoch 6543\n",
      "test_train\n",
      "train mean loss=62431.09713541667\n",
      "test_test\n",
      "test mean loss=87988.90234375\n",
      "fin save.\n",
      "epoch 6544\n",
      "test_train\n",
      "train mean loss=61576.055989583336\n",
      "test_test\n",
      "test mean loss=88304.49609375\n",
      "fin save.\n",
      "epoch 6545\n",
      "test_train\n",
      "train mean loss=61805.49700520833\n",
      "test_test\n",
      "test mean loss=88193.1796875\n",
      "fin save.\n",
      "epoch 6546\n",
      "test_train\n",
      "train mean loss=61972.739583333336\n",
      "test_test\n",
      "test mean loss=88161.2734375\n",
      "fin save.\n",
      "epoch 6547\n",
      "test_train\n",
      "train mean loss=62260.1046875\n",
      "test_test\n",
      "test mean loss=88158.58984375\n",
      "fin save.\n",
      "epoch 6548\n",
      "test_train\n",
      "train mean loss=62257.515364583334\n",
      "test_test\n",
      "test mean loss=88214.7421875\n",
      "fin save.\n",
      "epoch 6549\n",
      "test_train\n",
      "train mean loss=62198.88359375\n",
      "test_test\n",
      "test mean loss=88270.66796875\n",
      "fin save.\n",
      "epoch 6550\n",
      "test_train\n",
      "train mean loss=62444.49661458333\n",
      "test_test\n",
      "test mean loss=88158.89453125\n",
      "fin save.\n",
      "epoch 6551\n",
      "test_train\n",
      "train mean loss=62234.56484375\n",
      "test_test\n",
      "test mean loss=87929.94140625\n",
      "fin save.\n",
      "epoch 6552\n",
      "test_train\n",
      "train mean loss=62416.121744791664\n",
      "test_test\n",
      "test mean loss=88057.7734375\n",
      "fin save.\n",
      "epoch 6553\n",
      "test_train\n",
      "train mean loss=61447.76953125\n",
      "test_test\n",
      "test mean loss=87888.609375\n",
      "fin save.\n",
      "epoch 6554\n",
      "test_train\n",
      "train mean loss=61865.35859375\n",
      "test_test\n",
      "test mean loss=88156.4609375\n",
      "fin save.\n",
      "epoch 6555\n",
      "test_train\n",
      "train mean loss=62944.46484375\n",
      "test_test\n",
      "test mean loss=88029.26953125\n",
      "fin save.\n",
      "epoch 6556\n",
      "test_train\n",
      "train mean loss=61634.934895833336\n",
      "test_test\n",
      "test mean loss=88310.7421875\n",
      "fin save.\n",
      "epoch 6557\n",
      "test_train\n",
      "train mean loss=62427.45794270833\n",
      "test_test\n",
      "test mean loss=88199.015625\n",
      "fin save.\n",
      "epoch 6558\n",
      "test_train\n",
      "train mean loss=63059.553385416664\n",
      "test_test\n",
      "test mean loss=88408.81640625\n",
      "fin save.\n",
      "epoch 6559\n",
      "test_train\n",
      "train mean loss=62149.432291666664\n",
      "test_test\n",
      "test mean loss=88323.48046875\n",
      "fin save.\n",
      "epoch 6560\n",
      "test_train\n",
      "train mean loss=62401.81484375\n",
      "test_test\n",
      "test mean loss=88030.9609375\n",
      "fin save.\n",
      "epoch 6561\n",
      "test_train\n",
      "train mean loss=61133.71627604167\n",
      "test_test\n",
      "test mean loss=88246.171875\n",
      "fin save.\n",
      "epoch 6562\n",
      "test_train\n",
      "train mean loss=61811.67421875\n",
      "test_test\n",
      "test mean loss=88088.37109375\n",
      "fin save.\n",
      "epoch 6563\n",
      "test_train\n",
      "train mean loss=62212.37890625\n",
      "test_test\n",
      "test mean loss=88103.1484375\n",
      "fin save.\n",
      "epoch 6564\n",
      "test_train\n",
      "train mean loss=62157.816145833334\n",
      "test_test\n",
      "test mean loss=87897.421875\n",
      "fin save.\n",
      "epoch 6565\n",
      "test_train\n",
      "train mean loss=61889.015625\n",
      "test_test\n",
      "test mean loss=88014.60546875\n",
      "fin save.\n",
      "epoch 6566\n",
      "test_train\n",
      "train mean loss=61976.266927083336\n",
      "test_test\n",
      "test mean loss=88045.69921875\n",
      "fin save.\n",
      "epoch 6567\n",
      "test_train\n",
      "train mean loss=61719.22890625\n",
      "test_test\n",
      "test mean loss=88044.7265625\n",
      "fin save.\n",
      "epoch 6568\n",
      "test_train\n",
      "train mean loss=62706.881510416664\n",
      "test_test\n",
      "test mean loss=88227.03515625\n",
      "fin save.\n",
      "epoch 6569\n",
      "test_train\n",
      "train mean loss=62354.97317708333\n",
      "test_test\n",
      "test mean loss=88317.203125\n",
      "fin save.\n",
      "epoch 6570\n",
      "test_train\n",
      "train mean loss=62932.57083333333\n",
      "test_test\n",
      "test mean loss=88297.9140625\n",
      "fin save.\n",
      "epoch 6571\n",
      "test_train\n",
      "train mean loss=63035.765885416666\n",
      "test_test\n",
      "test mean loss=88244.89453125\n",
      "fin save.\n",
      "epoch 6572\n",
      "test_train\n",
      "train mean loss=62097.28671875\n",
      "test_test\n",
      "test mean loss=88355.47265625\n",
      "fin save.\n",
      "epoch 6573\n",
      "test_train\n",
      "train mean loss=61535.89010416667\n",
      "test_test\n",
      "test mean loss=88166.59765625\n",
      "fin save.\n",
      "epoch 6574\n",
      "test_train\n",
      "train mean loss=62862.189192708334\n",
      "test_test\n",
      "test mean loss=88363.47265625\n",
      "fin save.\n",
      "epoch 6575\n",
      "test_train\n",
      "train mean loss=62791.33984375\n",
      "test_test\n",
      "test mean loss=88538.91796875\n",
      "fin save.\n",
      "epoch 6576\n",
      "test_train\n",
      "train mean loss=61488.11380208333\n",
      "test_test\n",
      "test mean loss=88293.7265625\n",
      "fin save.\n",
      "epoch 6577\n",
      "test_train\n",
      "train mean loss=62784.22161458333\n",
      "test_test\n",
      "test mean loss=88105.8046875\n",
      "fin save.\n",
      "epoch 6578\n",
      "test_train\n",
      "train mean loss=63026.28984375\n",
      "test_test\n",
      "test mean loss=88067.93359375\n",
      "fin save.\n",
      "epoch 6579\n",
      "test_train\n",
      "train mean loss=62139.76666666667\n",
      "test_test\n",
      "test mean loss=88044.265625\n",
      "fin save.\n",
      "epoch 6580\n",
      "test_train\n",
      "train mean loss=63373.31263020833\n",
      "test_test\n",
      "test mean loss=87999.39453125\n",
      "fin save.\n",
      "epoch 6581\n",
      "test_train\n",
      "train mean loss=61154.36796875\n",
      "test_test\n",
      "test mean loss=88037.16796875\n",
      "fin save.\n",
      "epoch 6582\n",
      "test_train\n",
      "train mean loss=63202.96106770833\n",
      "test_test\n",
      "test mean loss=88188.0859375\n",
      "fin save.\n",
      "epoch 6583\n",
      "test_train\n",
      "train mean loss=62123.991927083334\n",
      "test_test\n",
      "test mean loss=88318.13671875\n",
      "fin save.\n",
      "epoch 6584\n",
      "test_train\n",
      "train mean loss=62407.25494791667\n",
      "test_test\n",
      "test mean loss=88194.1484375\n",
      "fin save.\n",
      "epoch 6585\n",
      "test_train\n",
      "train mean loss=61748.785416666666\n",
      "test_test\n",
      "test mean loss=88670.56640625\n",
      "fin save.\n",
      "epoch 6586\n",
      "test_train\n",
      "train mean loss=62226.913802083334\n",
      "test_test\n",
      "test mean loss=88478.73828125\n",
      "fin save.\n",
      "epoch 6587\n",
      "test_train\n",
      "train mean loss=61864.27578125\n",
      "test_test\n",
      "test mean loss=88177.90234375\n",
      "fin save.\n",
      "epoch 6588\n",
      "test_train\n",
      "train mean loss=62838.357161458334\n",
      "test_test\n",
      "test mean loss=88092.86328125\n",
      "fin save.\n",
      "epoch 6589\n",
      "test_train\n",
      "train mean loss=62276.460677083334\n",
      "test_test\n",
      "test mean loss=88138.27734375\n",
      "fin save.\n",
      "epoch 6590\n",
      "test_train\n",
      "train mean loss=62477.62122395833\n",
      "test_test\n",
      "test mean loss=88296.125\n",
      "fin save.\n",
      "epoch 6591\n",
      "test_train\n",
      "train mean loss=61856.46822916667\n",
      "test_test\n",
      "test mean loss=88140.0625\n",
      "fin save.\n",
      "epoch 6592\n",
      "test_train\n",
      "train mean loss=61887.24752604167\n",
      "test_test\n",
      "test mean loss=87995.42578125\n",
      "fin save.\n",
      "epoch 6593\n",
      "test_train\n",
      "train mean loss=62703.964583333334\n",
      "test_test\n",
      "test mean loss=88103.32421875\n",
      "fin save.\n",
      "epoch 6594\n",
      "test_train\n",
      "train mean loss=61934.50859375\n",
      "test_test\n",
      "test mean loss=88099.1640625\n",
      "fin save.\n",
      "epoch 6595\n",
      "test_train\n",
      "train mean loss=62400.27057291667\n",
      "test_test\n",
      "test mean loss=87989.23828125\n",
      "fin save.\n",
      "epoch 6596\n",
      "test_train\n",
      "train mean loss=62046.11953125\n",
      "test_test\n",
      "test mean loss=87668.65625\n",
      "fin save.\n",
      "epoch 6597\n",
      "test_train\n",
      "train mean loss=61659.315625\n",
      "test_test\n",
      "test mean loss=87707.7578125\n",
      "fin save.\n",
      "epoch 6598\n",
      "test_train\n",
      "train mean loss=61614.1\n",
      "test_test\n",
      "test mean loss=87827.3359375\n",
      "fin save.\n",
      "epoch 6599\n",
      "test_train\n",
      "train mean loss=61184.73125\n",
      "test_test\n",
      "test mean loss=87537.5703125\n",
      "fin save.\n",
      "epoch 6600\n",
      "test_train\n",
      "train mean loss=62266.101302083334\n",
      "test_test\n",
      "test mean loss=87743.0625\n",
      "fin save.\n",
      "epoch 6601\n",
      "test_train\n",
      "train mean loss=63052.13854166667\n",
      "test_test\n",
      "test mean loss=88113.61328125\n",
      "fin save.\n",
      "epoch 6602\n",
      "test_train\n",
      "train mean loss=62437.56354166667\n",
      "test_test\n",
      "test mean loss=87510.2890625\n",
      "fin save.\n",
      "epoch 6603\n",
      "test_train\n",
      "train mean loss=62037.65625\n",
      "test_test\n",
      "test mean loss=87655.73828125\n",
      "fin save.\n",
      "epoch 6604\n",
      "test_train\n",
      "train mean loss=61765.226302083334\n",
      "test_test\n",
      "test mean loss=87549.42578125\n",
      "fin save.\n",
      "epoch 6605\n",
      "test_train\n",
      "train mean loss=61965.42473958333\n",
      "test_test\n",
      "test mean loss=87592.7265625\n",
      "fin save.\n",
      "epoch 6606\n",
      "test_train\n",
      "train mean loss=61682.596354166664\n",
      "test_test\n",
      "test mean loss=87962.96484375\n",
      "fin save.\n",
      "epoch 6607\n",
      "test_train\n",
      "train mean loss=63047.095442708334\n",
      "test_test\n",
      "test mean loss=87887.50390625\n",
      "fin save.\n",
      "epoch 6608\n",
      "test_train\n",
      "train mean loss=62442.054947916666\n",
      "test_test\n",
      "test mean loss=87960.671875\n",
      "fin save.\n",
      "epoch 6609\n",
      "test_train\n",
      "train mean loss=62744.90963541667\n",
      "test_test\n",
      "test mean loss=87742.0625\n",
      "fin save.\n",
      "epoch 6610\n",
      "test_train\n",
      "train mean loss=63024.4484375\n",
      "test_test\n",
      "test mean loss=87705.6171875\n",
      "fin save.\n",
      "epoch 6611\n",
      "test_train\n",
      "train mean loss=62651.592057291666\n",
      "test_test\n",
      "test mean loss=87686.0546875\n",
      "fin save.\n",
      "epoch 6612\n",
      "test_train\n",
      "train mean loss=62360.70208333333\n",
      "test_test\n",
      "test mean loss=88230.5546875\n",
      "fin save.\n",
      "epoch 6613\n",
      "test_train\n",
      "train mean loss=61626.91197916667\n",
      "test_test\n",
      "test mean loss=87879.30078125\n",
      "fin save.\n",
      "epoch 6614\n",
      "test_train\n",
      "train mean loss=62605.7375\n",
      "test_test\n",
      "test mean loss=88286.03125\n",
      "fin save.\n",
      "epoch 6615\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=61458.7140625\n",
      "test_test\n",
      "test mean loss=88329.90234375\n",
      "fin save.\n",
      "epoch 6616\n",
      "test_train\n",
      "train mean loss=61891.00338541667\n",
      "test_test\n",
      "test mean loss=88154.93359375\n",
      "fin save.\n",
      "epoch 6617\n",
      "test_train\n",
      "train mean loss=62857.12200520833\n",
      "test_test\n",
      "test mean loss=87952.4609375\n",
      "fin save.\n",
      "epoch 6618\n",
      "test_train\n",
      "train mean loss=62281.433333333334\n",
      "test_test\n",
      "test mean loss=87943.41796875\n",
      "fin save.\n",
      "epoch 6619\n",
      "test_train\n",
      "train mean loss=61903.1328125\n",
      "test_test\n",
      "test mean loss=88297.6875\n",
      "fin save.\n",
      "epoch 6620\n",
      "test_train\n",
      "train mean loss=62627.62213541667\n",
      "test_test\n",
      "test mean loss=88330.1328125\n",
      "fin save.\n",
      "epoch 6621\n",
      "test_train\n",
      "train mean loss=62749.634114583336\n",
      "test_test\n",
      "test mean loss=88420.09375\n",
      "fin save.\n",
      "epoch 6622\n",
      "test_train\n",
      "train mean loss=62239.81484375\n",
      "test_test\n",
      "test mean loss=88395.63671875\n",
      "fin save.\n",
      "epoch 6623\n",
      "test_train\n",
      "train mean loss=61876.88229166667\n",
      "test_test\n",
      "test mean loss=88366.34375\n",
      "fin save.\n",
      "epoch 6624\n",
      "test_train\n",
      "train mean loss=61543.97057291667\n",
      "test_test\n",
      "test mean loss=88130.8828125\n",
      "fin save.\n",
      "epoch 6625\n",
      "test_train\n",
      "train mean loss=62279.6140625\n",
      "test_test\n",
      "test mean loss=88033.96875\n",
      "fin save.\n",
      "epoch 6626\n",
      "test_train\n",
      "train mean loss=62348.684895833336\n",
      "test_test\n",
      "test mean loss=87702.84765625\n",
      "fin save.\n",
      "epoch 6627\n",
      "test_train\n",
      "train mean loss=62246.628255208336\n",
      "test_test\n",
      "test mean loss=87976.73046875\n",
      "fin save.\n",
      "epoch 6628\n",
      "test_train\n",
      "train mean loss=61946.53333333333\n",
      "test_test\n",
      "test mean loss=88142.50390625\n",
      "fin save.\n",
      "epoch 6629\n",
      "test_train\n",
      "train mean loss=62821.633072916666\n",
      "test_test\n",
      "test mean loss=88145.76953125\n",
      "fin save.\n",
      "epoch 6630\n",
      "test_train\n",
      "train mean loss=61953.05286458333\n",
      "test_test\n",
      "test mean loss=88707.55078125\n",
      "fin save.\n",
      "epoch 6631\n",
      "test_train\n",
      "train mean loss=62530.929296875\n",
      "test_test\n",
      "test mean loss=88332.18359375\n",
      "fin save.\n",
      "epoch 6632\n",
      "test_train\n",
      "train mean loss=61927.394791666666\n",
      "test_test\n",
      "test mean loss=88450.67578125\n",
      "fin save.\n",
      "epoch 6633\n",
      "test_train\n",
      "train mean loss=62276.694921875\n",
      "test_test\n",
      "test mean loss=88558.8203125\n",
      "fin save.\n",
      "epoch 6634\n",
      "test_train\n",
      "train mean loss=62287.11315104167\n",
      "test_test\n",
      "test mean loss=88843.078125\n",
      "fin save.\n",
      "epoch 6635\n",
      "test_train\n",
      "train mean loss=61296.17630208333\n",
      "test_test\n",
      "test mean loss=88607.14453125\n",
      "fin save.\n",
      "epoch 6636\n",
      "test_train\n",
      "train mean loss=62167.234635416666\n",
      "test_test\n",
      "test mean loss=88602.0078125\n",
      "fin save.\n",
      "epoch 6637\n",
      "test_train\n",
      "train mean loss=62456.31927083333\n",
      "test_test\n",
      "test mean loss=89341.1015625\n",
      "fin save.\n",
      "epoch 6638\n",
      "test_train\n",
      "train mean loss=62776.847005208336\n",
      "test_test\n",
      "test mean loss=89252.69921875\n",
      "fin save.\n",
      "epoch 6639\n",
      "test_train\n",
      "train mean loss=62007.62682291667\n",
      "test_test\n",
      "test mean loss=89409.77734375\n",
      "fin save.\n",
      "epoch 6640\n",
      "test_train\n",
      "train mean loss=62884.335677083334\n",
      "test_test\n",
      "test mean loss=89568.23046875\n",
      "fin save.\n",
      "epoch 6641\n",
      "test_train\n",
      "train mean loss=61607.929296875\n",
      "test_test\n",
      "test mean loss=89326.98046875\n",
      "fin save.\n",
      "epoch 6642\n",
      "test_train\n",
      "train mean loss=61719.72421875\n",
      "test_test\n",
      "test mean loss=89095.5546875\n",
      "fin save.\n",
      "epoch 6643\n",
      "test_train\n",
      "train mean loss=62817.41028645833\n",
      "test_test\n",
      "test mean loss=89413.18359375\n",
      "fin save.\n",
      "epoch 6644\n",
      "test_train\n",
      "train mean loss=62036.55260416667\n",
      "test_test\n",
      "test mean loss=89059.1796875\n",
      "fin save.\n",
      "epoch 6645\n",
      "test_train\n",
      "train mean loss=62533.116796875\n",
      "test_test\n",
      "test mean loss=89071.34765625\n",
      "fin save.\n",
      "epoch 6646\n",
      "test_train\n",
      "train mean loss=62572.85442708333\n",
      "test_test\n",
      "test mean loss=89057.57421875\n",
      "fin save.\n",
      "epoch 6647\n",
      "test_train\n",
      "train mean loss=62276.69127604167\n",
      "test_test\n",
      "test mean loss=89005.05078125\n",
      "fin save.\n",
      "epoch 6648\n",
      "test_train\n",
      "train mean loss=63345.894791666666\n",
      "test_test\n",
      "test mean loss=88535.0859375\n",
      "fin save.\n",
      "epoch 6649\n",
      "test_train\n",
      "train mean loss=61665.03854166667\n",
      "test_test\n",
      "test mean loss=88735.97265625\n",
      "fin save.\n",
      "epoch 6650\n",
      "test_train\n",
      "train mean loss=61785.764453125\n",
      "test_test\n",
      "test mean loss=88826.34375\n",
      "fin save.\n",
      "epoch 6651\n",
      "test_train\n",
      "train mean loss=62769.32864583333\n",
      "test_test\n",
      "test mean loss=88784.98046875\n",
      "fin save.\n",
      "epoch 6652\n",
      "test_train\n",
      "train mean loss=63035.13203125\n",
      "test_test\n",
      "test mean loss=89056.15625\n",
      "fin save.\n",
      "epoch 6653\n",
      "test_train\n",
      "train mean loss=63159.30716145833\n",
      "test_test\n",
      "test mean loss=88873.78515625\n",
      "fin save.\n",
      "epoch 6654\n",
      "test_train\n",
      "train mean loss=62738.09166666667\n",
      "test_test\n",
      "test mean loss=88732.40234375\n",
      "fin save.\n",
      "epoch 6655\n",
      "test_train\n",
      "train mean loss=62017.924479166664\n",
      "test_test\n",
      "test mean loss=88236.17578125\n",
      "fin save.\n",
      "epoch 6656\n",
      "test_train\n",
      "train mean loss=63003.0609375\n",
      "test_test\n",
      "test mean loss=88226.9765625\n",
      "fin save.\n",
      "epoch 6657\n",
      "test_train\n",
      "train mean loss=63353.78203125\n",
      "test_test\n",
      "test mean loss=88271.84375\n",
      "fin save.\n",
      "epoch 6658\n",
      "test_train\n",
      "train mean loss=62628.953125\n",
      "test_test\n",
      "test mean loss=88216.61328125\n",
      "fin save.\n",
      "epoch 6659\n",
      "test_train\n",
      "train mean loss=62505.505078125\n",
      "test_test\n",
      "test mean loss=88277.09765625\n",
      "fin save.\n",
      "epoch 6660\n",
      "test_train\n",
      "train mean loss=62546.855729166666\n",
      "test_test\n",
      "test mean loss=88155.484375\n",
      "fin save.\n",
      "epoch 6661\n",
      "test_train\n",
      "train mean loss=63191.080729166664\n",
      "test_test\n",
      "test mean loss=88220.4765625\n",
      "fin save.\n",
      "epoch 6662\n",
      "test_train\n",
      "train mean loss=63263.166796875\n",
      "test_test\n",
      "test mean loss=88222.15234375\n",
      "fin save.\n",
      "epoch 6663\n",
      "test_train\n",
      "train mean loss=60998.61927083333\n",
      "test_test\n",
      "test mean loss=88208.03125\n",
      "fin save.\n",
      "epoch 6664\n",
      "test_train\n",
      "train mean loss=61701.93958333333\n",
      "test_test\n",
      "test mean loss=88279.00390625\n",
      "fin save.\n",
      "epoch 6665\n",
      "test_train\n",
      "train mean loss=62675.792708333334\n",
      "test_test\n",
      "test mean loss=88536.16796875\n",
      "fin save.\n",
      "epoch 6666\n",
      "test_train\n",
      "train mean loss=62432.855729166666\n",
      "test_test\n",
      "test mean loss=88256.65625\n",
      "fin save.\n",
      "epoch 6667\n",
      "test_train\n",
      "train mean loss=62270.93125\n",
      "test_test\n",
      "test mean loss=88371.03515625\n",
      "fin save.\n",
      "epoch 6668\n",
      "test_train\n",
      "train mean loss=62018.376692708334\n",
      "test_test\n",
      "test mean loss=88504.21875\n",
      "fin save.\n",
      "epoch 6669\n",
      "test_train\n",
      "train mean loss=63012.07265625\n",
      "test_test\n",
      "test mean loss=88454.2578125\n",
      "fin save.\n",
      "epoch 6670\n",
      "test_train\n",
      "train mean loss=61647.1296875\n",
      "test_test\n",
      "test mean loss=88492.7578125\n",
      "fin save.\n",
      "epoch 6671\n",
      "test_train\n",
      "train mean loss=62899.29869791667\n",
      "test_test\n",
      "test mean loss=88487.296875\n",
      "fin save.\n",
      "epoch 6672\n",
      "test_train\n",
      "train mean loss=61081.38515625\n",
      "test_test\n",
      "test mean loss=88222.0234375\n",
      "fin save.\n",
      "epoch 6673\n",
      "test_train\n",
      "train mean loss=62189.95\n",
      "test_test\n",
      "test mean loss=88284.0859375\n",
      "fin save.\n",
      "epoch 6674\n",
      "test_train\n",
      "train mean loss=63223.930989583336\n",
      "test_test\n",
      "test mean loss=88152.69921875\n",
      "fin save.\n",
      "epoch 6675\n",
      "test_train\n",
      "train mean loss=63220.820572916666\n",
      "test_test\n",
      "test mean loss=88196.87890625\n",
      "fin save.\n",
      "epoch 6676\n",
      "test_train\n",
      "train mean loss=62180.8859375\n",
      "test_test\n",
      "test mean loss=88193.05078125\n",
      "fin save.\n",
      "epoch 6677\n",
      "test_train\n",
      "train mean loss=62690.053125\n",
      "test_test\n",
      "test mean loss=88296.90625\n",
      "fin save.\n",
      "epoch 6678\n",
      "test_train\n",
      "train mean loss=61504.92877604167\n",
      "test_test\n",
      "test mean loss=88360.0\n",
      "fin save.\n",
      "epoch 6679\n",
      "test_train\n",
      "train mean loss=62625.38489583333\n",
      "test_test\n",
      "test mean loss=88338.26171875\n",
      "fin save.\n",
      "epoch 6680\n",
      "test_train\n",
      "train mean loss=63042.68463541667\n",
      "test_test\n",
      "test mean loss=88440.59765625\n",
      "fin save.\n",
      "epoch 6681\n",
      "test_train\n",
      "train mean loss=62739.593489583334\n",
      "test_test\n",
      "test mean loss=88490.65625\n",
      "fin save.\n",
      "epoch 6682\n",
      "test_train\n",
      "train mean loss=61173.56692708333\n",
      "test_test\n",
      "test mean loss=88576.92578125\n",
      "fin save.\n",
      "epoch 6683\n",
      "test_train\n",
      "train mean loss=62786.20130208333\n",
      "test_test\n",
      "test mean loss=88461.91796875\n",
      "fin save.\n",
      "epoch 6684\n",
      "test_train\n",
      "train mean loss=62341.790234375\n",
      "test_test\n",
      "test mean loss=87909.30078125\n",
      "fin save.\n",
      "epoch 6685\n",
      "test_train\n",
      "train mean loss=63018.4640625\n",
      "test_test\n",
      "test mean loss=88082.2890625\n",
      "fin save.\n",
      "epoch 6686\n",
      "test_train\n",
      "train mean loss=61997.322916666664\n",
      "test_test\n",
      "test mean loss=88205.15625\n",
      "fin save.\n",
      "epoch 6687\n",
      "test_train\n",
      "train mean loss=63204.597265625\n",
      "test_test\n",
      "test mean loss=88283.57421875\n",
      "fin save.\n",
      "epoch 6688\n",
      "test_train\n",
      "train mean loss=61204.37096354167\n",
      "test_test\n",
      "test mean loss=87931.17578125\n",
      "fin save.\n",
      "epoch 6689\n",
      "test_train\n",
      "train mean loss=62735.80755208333\n",
      "test_test\n",
      "test mean loss=88109.88671875\n",
      "fin save.\n",
      "epoch 6690\n",
      "test_train\n",
      "train mean loss=61733.60338541667\n",
      "test_test\n",
      "test mean loss=88283.05859375\n",
      "fin save.\n",
      "epoch 6691\n",
      "test_train\n",
      "train mean loss=62457.418229166666\n",
      "test_test\n",
      "test mean loss=88161.54296875\n",
      "fin save.\n",
      "epoch 6692\n",
      "test_train\n",
      "train mean loss=62332.854166666664\n",
      "test_test\n",
      "test mean loss=88162.17578125\n",
      "fin save.\n",
      "epoch 6693\n",
      "test_train\n",
      "train mean loss=62679.28203125\n",
      "test_test\n",
      "test mean loss=88243.70703125\n",
      "fin save.\n",
      "epoch 6694\n",
      "test_train\n",
      "train mean loss=62156.3375\n",
      "test_test\n",
      "test mean loss=88190.84765625\n",
      "fin save.\n",
      "epoch 6695\n",
      "test_train\n",
      "train mean loss=62312.03502604167\n",
      "test_test\n",
      "test mean loss=88327.19921875\n",
      "fin save.\n",
      "epoch 6696\n",
      "test_train\n",
      "train mean loss=62317.6375\n",
      "test_test\n",
      "test mean loss=88407.9453125\n",
      "fin save.\n",
      "epoch 6697\n",
      "test_train\n",
      "train mean loss=63099.42526041667\n",
      "test_test\n",
      "test mean loss=88251.1015625\n",
      "fin save.\n",
      "epoch 6698\n",
      "test_train\n",
      "train mean loss=62896.288802083334\n",
      "test_test\n",
      "test mean loss=88488.12890625\n",
      "fin save.\n",
      "epoch 6699\n",
      "test_train\n",
      "train mean loss=63520.356770833336\n",
      "test_test\n",
      "test mean loss=88405.515625\n",
      "fin save.\n",
      "epoch 6700\n",
      "test_train\n",
      "train mean loss=61789.77265625\n",
      "test_test\n",
      "test mean loss=88750.62109375\n",
      "fin save.\n",
      "epoch 6701\n",
      "test_train\n",
      "train mean loss=63467.946614583336\n",
      "test_test\n",
      "test mean loss=88613.85546875\n",
      "fin save.\n",
      "epoch 6702\n",
      "test_train\n",
      "train mean loss=62807.931380208334\n",
      "test_test\n",
      "test mean loss=88889.47265625\n",
      "fin save.\n",
      "epoch 6703\n",
      "test_train\n",
      "train mean loss=62132.813802083336\n",
      "test_test\n",
      "test mean loss=88637.06640625\n",
      "fin save.\n",
      "epoch 6704\n",
      "test_train\n",
      "train mean loss=61615.92005208333\n",
      "test_test\n",
      "test mean loss=88286.26953125\n",
      "fin save.\n",
      "epoch 6705\n",
      "test_train\n",
      "train mean loss=62381.892578125\n",
      "test_test\n",
      "test mean loss=88287.62890625\n",
      "fin save.\n",
      "epoch 6706\n",
      "test_train\n",
      "train mean loss=62614.83151041667\n",
      "test_test\n",
      "test mean loss=88365.51953125\n",
      "fin save.\n",
      "epoch 6707\n",
      "test_train\n",
      "train mean loss=62389.441666666666\n",
      "test_test\n",
      "test mean loss=88352.69140625\n",
      "fin save.\n",
      "epoch 6708\n",
      "test_train\n",
      "train mean loss=62389.85234375\n",
      "test_test\n",
      "test mean loss=88616.7421875\n",
      "fin save.\n",
      "epoch 6709\n",
      "test_train\n",
      "train mean loss=61887.32239583333\n",
      "test_test\n",
      "test mean loss=88424.66796875\n",
      "fin save.\n",
      "epoch 6710\n",
      "test_train\n",
      "train mean loss=61782.49856770833\n",
      "test_test\n",
      "test mean loss=88560.73046875\n",
      "fin save.\n",
      "epoch 6711\n",
      "test_train\n",
      "train mean loss=62234.317057291664\n",
      "test_test\n",
      "test mean loss=88610.828125\n",
      "fin save.\n",
      "epoch 6712\n",
      "test_train\n",
      "train mean loss=62973.52942708333\n",
      "test_test\n",
      "test mean loss=88637.94140625\n",
      "fin save.\n",
      "epoch 6713\n",
      "test_train\n",
      "train mean loss=61588.54140625\n",
      "test_test\n",
      "test mean loss=88348.74609375\n",
      "fin save.\n",
      "epoch 6714\n",
      "test_train\n",
      "train mean loss=61004.195572916666\n",
      "test_test\n",
      "test mean loss=88324.83203125\n",
      "fin save.\n",
      "epoch 6715\n",
      "test_train\n",
      "train mean loss=62298.83151041667\n",
      "test_test\n",
      "test mean loss=88317.72265625\n",
      "fin save.\n",
      "epoch 6716\n",
      "test_train\n",
      "train mean loss=61963.33046875\n",
      "test_test\n",
      "test mean loss=88340.2734375\n",
      "fin save.\n",
      "epoch 6717\n",
      "test_train\n",
      "train mean loss=62257.843489583334\n",
      "test_test\n",
      "test mean loss=88347.59765625\n",
      "fin save.\n",
      "epoch 6718\n",
      "test_train\n",
      "train mean loss=62752.749609375\n",
      "test_test\n",
      "test mean loss=88262.0078125\n",
      "fin save.\n",
      "epoch 6719\n",
      "test_train\n",
      "train mean loss=62578.06458333333\n",
      "test_test\n",
      "test mean loss=88316.05078125\n",
      "fin save.\n",
      "epoch 6720\n",
      "test_train\n",
      "train mean loss=61886.49205729167\n",
      "test_test\n",
      "test mean loss=88401.89453125\n",
      "fin save.\n",
      "epoch 6721\n",
      "test_train\n",
      "train mean loss=62720.79153645833\n",
      "test_test\n",
      "test mean loss=88466.9140625\n",
      "fin save.\n",
      "epoch 6722\n",
      "test_train\n",
      "train mean loss=62685.53606770833\n",
      "test_test\n",
      "test mean loss=88474.15625\n",
      "fin save.\n",
      "epoch 6723\n",
      "test_train\n",
      "train mean loss=62686.170182291666\n",
      "test_test\n",
      "test mean loss=88193.328125\n",
      "fin save.\n",
      "epoch 6724\n",
      "test_train\n",
      "train mean loss=61983.89166666667\n",
      "test_test\n",
      "test mean loss=88588.98046875\n",
      "fin save.\n",
      "epoch 6725\n",
      "test_train\n",
      "train mean loss=61875.09557291667\n",
      "test_test\n",
      "test mean loss=88921.86328125\n",
      "fin save.\n",
      "epoch 6726\n",
      "test_train\n",
      "train mean loss=63075.106705729166\n",
      "test_test\n",
      "test mean loss=88606.7109375\n",
      "fin save.\n",
      "epoch 6727\n",
      "test_train\n",
      "train mean loss=62592.53802083333\n",
      "test_test\n",
      "test mean loss=88674.78515625\n",
      "fin save.\n",
      "epoch 6728\n",
      "test_train\n",
      "train mean loss=62634.125\n",
      "test_test\n",
      "test mean loss=88567.21875\n",
      "fin save.\n",
      "epoch 6729\n",
      "test_train\n",
      "train mean loss=63049.57421875\n",
      "test_test\n",
      "test mean loss=88554.58203125\n",
      "fin save.\n",
      "epoch 6730\n",
      "test_train\n",
      "train mean loss=62639.13958333333\n",
      "test_test\n",
      "test mean loss=88666.765625\n",
      "fin save.\n",
      "epoch 6731\n",
      "test_train\n",
      "train mean loss=62438.183333333334\n",
      "test_test\n",
      "test mean loss=88841.859375\n",
      "fin save.\n",
      "epoch 6732\n",
      "test_train\n",
      "train mean loss=63001.772786458336\n",
      "test_test\n",
      "test mean loss=88801.87109375\n",
      "fin save.\n",
      "epoch 6733\n",
      "test_train\n",
      "train mean loss=62949.16419270833\n",
      "test_test\n",
      "test mean loss=88776.03125\n",
      "fin save.\n",
      "epoch 6734\n",
      "test_train\n",
      "train mean loss=61556.908854166664\n",
      "test_test\n",
      "test mean loss=88852.97265625\n",
      "fin save.\n",
      "epoch 6735\n",
      "test_train\n",
      "train mean loss=62348.58020833333\n",
      "test_test\n",
      "test mean loss=88912.52734375\n",
      "fin save.\n",
      "epoch 6736\n",
      "test_train\n",
      "train mean loss=62426.490885416664\n",
      "test_test\n",
      "test mean loss=88756.54296875\n",
      "fin save.\n",
      "epoch 6737\n",
      "test_train\n",
      "train mean loss=62510.4\n",
      "test_test\n",
      "test mean loss=88571.03125\n",
      "fin save.\n",
      "epoch 6738\n",
      "test_train\n",
      "train mean loss=62898.825\n",
      "test_test\n",
      "test mean loss=88779.34375\n",
      "fin save.\n",
      "epoch 6739\n",
      "test_train\n",
      "train mean loss=61329.59518229167\n",
      "test_test\n",
      "test mean loss=88700.3515625\n",
      "fin save.\n",
      "epoch 6740\n",
      "test_train\n",
      "train mean loss=63364.21666666667\n",
      "test_test\n",
      "test mean loss=88686.9296875\n",
      "fin save.\n",
      "epoch 6741\n",
      "test_train\n",
      "train mean loss=61527.40338541667\n",
      "test_test\n",
      "test mean loss=88844.25\n",
      "fin save.\n",
      "epoch 6742\n",
      "test_train\n",
      "train mean loss=62233.1515625\n",
      "test_test\n",
      "test mean loss=88724.625\n",
      "fin save.\n",
      "epoch 6743\n",
      "test_train\n",
      "train mean loss=61905.9078125\n",
      "test_test\n",
      "test mean loss=88823.359375\n",
      "fin save.\n",
      "epoch 6744\n",
      "test_train\n",
      "train mean loss=61901.473307291664\n",
      "test_test\n",
      "test mean loss=88928.30078125\n",
      "fin save.\n",
      "epoch 6745\n",
      "test_train\n",
      "train mean loss=61596.686197916664\n",
      "test_test\n",
      "test mean loss=88636.9296875\n",
      "fin save.\n",
      "epoch 6746\n",
      "test_train\n",
      "train mean loss=62030.95130208333\n",
      "test_test\n",
      "test mean loss=88941.11328125\n",
      "fin save.\n",
      "epoch 6747\n",
      "test_train\n",
      "train mean loss=61340.16640625\n",
      "test_test\n",
      "test mean loss=88754.08203125\n",
      "fin save.\n",
      "epoch 6748\n",
      "test_train\n",
      "train mean loss=63177.211588541664\n",
      "test_test\n",
      "test mean loss=88713.9453125\n",
      "fin save.\n",
      "epoch 6749\n",
      "test_train\n",
      "train mean loss=61735.790625\n",
      "test_test\n",
      "test mean loss=88569.6796875\n",
      "fin save.\n",
      "epoch 6750\n",
      "test_train\n",
      "train mean loss=62562.37994791667\n",
      "test_test\n",
      "test mean loss=88332.2265625\n",
      "fin save.\n",
      "epoch 6751\n",
      "test_train\n",
      "train mean loss=62898.37604166667\n",
      "test_test\n",
      "test mean loss=88543.51171875\n",
      "fin save.\n",
      "epoch 6752\n",
      "test_train\n",
      "train mean loss=62389.636979166666\n",
      "test_test\n",
      "test mean loss=88456.140625\n",
      "fin save.\n",
      "epoch 6753\n",
      "test_train\n",
      "train mean loss=62095.35052083333\n",
      "test_test\n",
      "test mean loss=88721.6875\n",
      "fin save.\n",
      "epoch 6754\n",
      "test_train\n",
      "train mean loss=61607.49296875\n",
      "test_test\n",
      "test mean loss=88907.828125\n",
      "fin save.\n",
      "epoch 6755\n",
      "test_train\n",
      "train mean loss=62770.18359375\n",
      "test_test\n",
      "test mean loss=87375.98046875\n",
      "fin save.\n",
      "epoch 6756\n",
      "test_train\n",
      "train mean loss=62075.38268229167\n",
      "test_test\n",
      "test mean loss=87395.51953125\n",
      "fin save.\n",
      "epoch 6757\n",
      "test_train\n",
      "train mean loss=63112.62994791667\n",
      "test_test\n",
      "test mean loss=87342.6875\n",
      "fin save.\n",
      "epoch 6758\n",
      "test_train\n",
      "train mean loss=62142.968489583334\n",
      "test_test\n",
      "test mean loss=87347.3984375\n",
      "fin save.\n",
      "epoch 6759\n",
      "test_train\n",
      "train mean loss=62986.761979166666\n",
      "test_test\n",
      "test mean loss=87351.02734375\n",
      "fin save.\n",
      "epoch 6760\n",
      "test_train\n",
      "train mean loss=62333.33359375\n",
      "test_test\n",
      "test mean loss=87528.23828125\n",
      "fin save.\n",
      "epoch 6761\n",
      "test_train\n",
      "train mean loss=61962.937760416666\n",
      "test_test\n",
      "test mean loss=87725.1015625\n",
      "fin save.\n",
      "epoch 6762\n",
      "test_train\n",
      "train mean loss=62943.430078125\n",
      "test_test\n",
      "test mean loss=87685.265625\n",
      "fin save.\n",
      "epoch 6763\n",
      "test_train\n",
      "train mean loss=62251.80286458333\n",
      "test_test\n",
      "test mean loss=87692.703125\n",
      "fin save.\n",
      "epoch 6764\n",
      "test_train\n",
      "train mean loss=62248.96341145833\n",
      "test_test\n",
      "test mean loss=87736.5234375\n",
      "fin save.\n",
      "epoch 6765\n",
      "test_train\n",
      "train mean loss=61863.200520833336\n",
      "test_test\n",
      "test mean loss=87721.46875\n",
      "fin save.\n",
      "epoch 6766\n",
      "test_train\n",
      "train mean loss=62483.89765625\n",
      "test_test\n",
      "test mean loss=87651.015625\n",
      "fin save.\n",
      "epoch 6767\n",
      "test_train\n",
      "train mean loss=62259.42890625\n",
      "test_test\n",
      "test mean loss=87747.578125\n",
      "fin save.\n",
      "epoch 6768\n",
      "test_train\n",
      "train mean loss=62991.60625\n",
      "test_test\n",
      "test mean loss=87792.265625\n",
      "fin save.\n",
      "epoch 6769\n",
      "test_train\n",
      "train mean loss=62648.2515625\n",
      "test_test\n",
      "test mean loss=87728.30078125\n",
      "fin save.\n",
      "epoch 6770\n",
      "test_train\n",
      "train mean loss=62948.877734375\n",
      "test_test\n",
      "test mean loss=87646.83984375\n",
      "fin save.\n",
      "epoch 6771\n",
      "test_train\n",
      "train mean loss=61840.45546875\n",
      "test_test\n",
      "test mean loss=87560.83984375\n",
      "fin save.\n",
      "epoch 6772\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=62181.85598958333\n",
      "test_test\n",
      "test mean loss=87607.96484375\n",
      "fin save.\n",
      "epoch 6773\n",
      "test_train\n",
      "train mean loss=64463.72864583333\n",
      "test_test\n",
      "test mean loss=87410.6953125\n",
      "fin save.\n",
      "epoch 6774\n",
      "test_train\n",
      "train mean loss=61373.8171875\n",
      "test_test\n",
      "test mean loss=87530.28125\n",
      "fin save.\n",
      "epoch 6775\n",
      "test_train\n",
      "train mean loss=62064.32734375\n",
      "test_test\n",
      "test mean loss=87432.09765625\n",
      "fin save.\n",
      "epoch 6776\n",
      "test_train\n",
      "train mean loss=63209.38515625\n",
      "test_test\n",
      "test mean loss=87469.8203125\n",
      "fin save.\n",
      "epoch 6777\n",
      "test_train\n",
      "train mean loss=62565.631119791666\n",
      "test_test\n",
      "test mean loss=87515.0703125\n",
      "fin save.\n",
      "epoch 6778\n",
      "test_train\n",
      "train mean loss=61416.992447916666\n",
      "test_test\n",
      "test mean loss=87668.8359375\n",
      "fin save.\n",
      "epoch 6779\n",
      "test_train\n",
      "train mean loss=61825.632421875\n",
      "test_test\n",
      "test mean loss=87479.828125\n",
      "fin save.\n",
      "epoch 6780\n",
      "test_train\n",
      "train mean loss=61800.82630208333\n",
      "test_test\n",
      "test mean loss=87494.5546875\n",
      "fin save.\n",
      "epoch 6781\n",
      "test_train\n",
      "train mean loss=61541.55755208333\n",
      "test_test\n",
      "test mean loss=87528.72265625\n",
      "fin save.\n",
      "epoch 6782\n",
      "test_train\n",
      "train mean loss=62535.27916666667\n",
      "test_test\n",
      "test mean loss=87609.390625\n",
      "fin save.\n",
      "epoch 6783\n",
      "test_train\n",
      "train mean loss=62470.33203125\n",
      "test_test\n",
      "test mean loss=87695.3203125\n",
      "fin save.\n",
      "epoch 6784\n",
      "test_train\n",
      "train mean loss=62579.70364583333\n",
      "test_test\n",
      "test mean loss=87494.2734375\n",
      "fin save.\n",
      "epoch 6785\n",
      "test_train\n",
      "train mean loss=63283.3109375\n",
      "test_test\n",
      "test mean loss=87646.91015625\n",
      "fin save.\n",
      "epoch 6786\n",
      "test_train\n",
      "train mean loss=61735.699479166666\n",
      "test_test\n",
      "test mean loss=87875.03125\n",
      "fin save.\n",
      "epoch 6787\n",
      "test_train\n",
      "train mean loss=62636.53307291667\n",
      "test_test\n",
      "test mean loss=87622.0234375\n",
      "fin save.\n",
      "epoch 6788\n",
      "test_train\n",
      "train mean loss=63144.326822916664\n",
      "test_test\n",
      "test mean loss=87784.46875\n",
      "fin save.\n",
      "epoch 6789\n",
      "test_train\n",
      "train mean loss=62289.56536458333\n",
      "test_test\n",
      "test mean loss=87894.578125\n",
      "fin save.\n",
      "epoch 6790\n",
      "test_train\n",
      "train mean loss=62953.68658854167\n",
      "test_test\n",
      "test mean loss=88080.65625\n",
      "fin save.\n",
      "epoch 6791\n",
      "test_train\n",
      "train mean loss=62115.078385416666\n",
      "test_test\n",
      "test mean loss=87298.08984375\n",
      "fin save.\n",
      "epoch 6792\n",
      "test_train\n",
      "train mean loss=62884.285416666666\n",
      "test_test\n",
      "test mean loss=87322.22265625\n",
      "fin save.\n",
      "epoch 6793\n",
      "test_train\n",
      "train mean loss=62707.33880208333\n",
      "test_test\n",
      "test mean loss=87081.62109375\n",
      "fin save.\n",
      "epoch 6794\n",
      "test_train\n",
      "train mean loss=62345.29700520833\n",
      "test_test\n",
      "test mean loss=87276.0078125\n",
      "fin save.\n",
      "epoch 6795\n",
      "test_train\n",
      "train mean loss=62197.81953125\n",
      "test_test\n",
      "test mean loss=87631.38671875\n",
      "fin save.\n",
      "epoch 6796\n",
      "test_train\n",
      "train mean loss=61993.36015625\n",
      "test_test\n",
      "test mean loss=87569.8515625\n",
      "fin save.\n",
      "epoch 6797\n",
      "test_train\n",
      "train mean loss=61716.938151041664\n",
      "test_test\n",
      "test mean loss=87573.78515625\n",
      "fin save.\n",
      "epoch 6798\n",
      "test_train\n",
      "train mean loss=61629.99427083333\n",
      "test_test\n",
      "test mean loss=87574.14453125\n",
      "fin save.\n",
      "epoch 6799\n",
      "test_train\n",
      "train mean loss=62338.515364583334\n",
      "test_test\n",
      "test mean loss=87726.61328125\n",
      "fin save.\n",
      "epoch 6800\n",
      "test_train\n",
      "train mean loss=64028.12421875\n",
      "test_test\n",
      "test mean loss=87591.125\n",
      "fin save.\n",
      "epoch 6801\n",
      "test_train\n",
      "train mean loss=62669.650130208334\n",
      "test_test\n",
      "test mean loss=87840.76171875\n",
      "fin save.\n",
      "epoch 6802\n",
      "test_train\n",
      "train mean loss=62764.252734375\n",
      "test_test\n",
      "test mean loss=87702.7890625\n",
      "fin save.\n",
      "epoch 6803\n",
      "test_train\n",
      "train mean loss=62612.754166666666\n",
      "test_test\n",
      "test mean loss=87702.23046875\n",
      "fin save.\n",
      "epoch 6804\n",
      "test_train\n",
      "train mean loss=61808.37513020833\n",
      "test_test\n",
      "test mean loss=88020.796875\n",
      "fin save.\n",
      "epoch 6805\n",
      "test_train\n",
      "train mean loss=62304.811328125\n",
      "test_test\n",
      "test mean loss=87703.61328125\n",
      "fin save.\n",
      "epoch 6806\n",
      "test_train\n",
      "train mean loss=61288.79296875\n",
      "test_test\n",
      "test mean loss=87875.40625\n",
      "fin save.\n",
      "epoch 6807\n",
      "test_train\n",
      "train mean loss=60339.23671875\n",
      "test_test\n",
      "test mean loss=87944.6875\n",
      "fin save.\n",
      "epoch 6808\n",
      "test_train\n",
      "train mean loss=62517.640364583334\n",
      "test_test\n",
      "test mean loss=87922.1953125\n",
      "fin save.\n",
      "epoch 6809\n",
      "test_train\n",
      "train mean loss=62042.01861979167\n",
      "test_test\n",
      "test mean loss=88157.37109375\n",
      "fin save.\n",
      "epoch 6810\n",
      "test_train\n",
      "train mean loss=62417.3859375\n",
      "test_test\n",
      "test mean loss=87956.76953125\n",
      "fin save.\n",
      "epoch 6811\n",
      "test_train\n",
      "train mean loss=62406.105208333334\n",
      "test_test\n",
      "test mean loss=87924.66015625\n",
      "fin save.\n",
      "epoch 6812\n",
      "test_train\n",
      "train mean loss=63067.09609375\n",
      "test_test\n",
      "test mean loss=87989.2890625\n",
      "fin save.\n",
      "epoch 6813\n",
      "test_train\n",
      "train mean loss=63683.84557291667\n",
      "test_test\n",
      "test mean loss=88096.25\n",
      "fin save.\n",
      "epoch 6814\n",
      "test_train\n",
      "train mean loss=61561.952864583334\n",
      "test_test\n",
      "test mean loss=88258.75390625\n",
      "fin save.\n",
      "epoch 6815\n",
      "test_train\n",
      "train mean loss=62103.701822916664\n",
      "test_test\n",
      "test mean loss=88079.25390625\n",
      "fin save.\n",
      "epoch 6816\n",
      "test_train\n",
      "train mean loss=62169.5171875\n",
      "test_test\n",
      "test mean loss=88076.78125\n",
      "fin save.\n",
      "epoch 6817\n",
      "test_train\n",
      "train mean loss=62807.86328125\n",
      "test_test\n",
      "test mean loss=88007.34765625\n",
      "fin save.\n",
      "epoch 6818\n",
      "test_train\n",
      "train mean loss=62562.74322916667\n",
      "test_test\n",
      "test mean loss=87867.4375\n",
      "fin save.\n",
      "epoch 6819\n",
      "test_train\n",
      "train mean loss=62408.34296875\n",
      "test_test\n",
      "test mean loss=88017.2734375\n",
      "fin save.\n",
      "epoch 6820\n",
      "test_train\n",
      "train mean loss=61909.4640625\n",
      "test_test\n",
      "test mean loss=87829.4453125\n",
      "fin save.\n",
      "epoch 6821\n",
      "test_train\n",
      "train mean loss=62782.54440104167\n",
      "test_test\n",
      "test mean loss=88415.16796875\n",
      "fin save.\n",
      "epoch 6822\n",
      "test_train\n",
      "train mean loss=62885.984375\n",
      "test_test\n",
      "test mean loss=88072.484375\n",
      "fin save.\n",
      "epoch 6823\n",
      "test_train\n",
      "train mean loss=62904.275390625\n",
      "test_test\n",
      "test mean loss=87802.1484375\n",
      "fin save.\n",
      "epoch 6824\n",
      "test_train\n",
      "train mean loss=61566.85442708333\n",
      "test_test\n",
      "test mean loss=87556.95703125\n",
      "fin save.\n",
      "epoch 6825\n",
      "test_train\n",
      "train mean loss=62508.734635416666\n",
      "test_test\n",
      "test mean loss=87741.078125\n",
      "fin save.\n",
      "epoch 6826\n",
      "test_train\n",
      "train mean loss=61937.41796875\n",
      "test_test\n",
      "test mean loss=87473.8671875\n",
      "fin save.\n",
      "epoch 6827\n",
      "test_train\n",
      "train mean loss=61572.74921875\n",
      "test_test\n",
      "test mean loss=87786.4921875\n",
      "fin save.\n",
      "epoch 6828\n",
      "test_train\n",
      "train mean loss=62170.71783854167\n",
      "test_test\n",
      "test mean loss=87856.1015625\n",
      "fin save.\n",
      "epoch 6829\n",
      "test_train\n",
      "train mean loss=61733.004166666666\n",
      "test_test\n",
      "test mean loss=87808.52734375\n",
      "fin save.\n",
      "epoch 6830\n",
      "test_train\n",
      "train mean loss=62435.97578125\n",
      "test_test\n",
      "test mean loss=87580.2890625\n",
      "fin save.\n",
      "epoch 6831\n",
      "test_train\n",
      "train mean loss=61988.459375\n",
      "test_test\n",
      "test mean loss=87268.953125\n",
      "fin save.\n",
      "epoch 6832\n",
      "test_train\n",
      "train mean loss=61759.030078125\n",
      "test_test\n",
      "test mean loss=87501.59375\n",
      "fin save.\n",
      "epoch 6833\n",
      "test_train\n",
      "train mean loss=62768.014973958336\n",
      "test_test\n",
      "test mean loss=87427.453125\n",
      "fin save.\n",
      "epoch 6834\n",
      "test_train\n",
      "train mean loss=62154.2953125\n",
      "test_test\n",
      "test mean loss=87504.73828125\n",
      "fin save.\n",
      "epoch 6835\n",
      "test_train\n",
      "train mean loss=62802.69244791667\n",
      "test_test\n",
      "test mean loss=87574.98046875\n",
      "fin save.\n",
      "epoch 6836\n",
      "test_train\n",
      "train mean loss=62945.636979166666\n",
      "test_test\n",
      "test mean loss=87705.6484375\n",
      "fin save.\n",
      "epoch 6837\n",
      "test_train\n",
      "train mean loss=62200.88203125\n",
      "test_test\n",
      "test mean loss=87433.84375\n",
      "fin save.\n",
      "epoch 6838\n",
      "test_train\n",
      "train mean loss=62391.55091145833\n",
      "test_test\n",
      "test mean loss=87676.30859375\n",
      "fin save.\n",
      "epoch 6839\n",
      "test_train\n",
      "train mean loss=62987.92239583333\n",
      "test_test\n",
      "test mean loss=87340.59375\n",
      "fin save.\n",
      "epoch 6840\n",
      "test_train\n",
      "train mean loss=61236.76940104167\n",
      "test_test\n",
      "test mean loss=87269.44921875\n",
      "fin save.\n",
      "epoch 6841\n",
      "test_train\n",
      "train mean loss=62400.04635416667\n",
      "test_test\n",
      "test mean loss=87367.71484375\n",
      "fin save.\n",
      "epoch 6842\n",
      "test_train\n",
      "train mean loss=61511.14348958333\n",
      "test_test\n",
      "test mean loss=87425.72265625\n",
      "fin save.\n",
      "epoch 6843\n",
      "test_train\n",
      "train mean loss=61733.9421875\n",
      "test_test\n",
      "test mean loss=87643.41015625\n",
      "fin save.\n",
      "epoch 6844\n",
      "test_train\n",
      "train mean loss=62419.99765625\n",
      "test_test\n",
      "test mean loss=87617.1171875\n",
      "fin save.\n",
      "epoch 6845\n",
      "test_train\n",
      "train mean loss=63043.902994791664\n",
      "test_test\n",
      "test mean loss=87399.734375\n",
      "fin save.\n",
      "epoch 6846\n",
      "test_train\n",
      "train mean loss=61246.433333333334\n",
      "test_test\n",
      "test mean loss=87443.6875\n",
      "fin save.\n",
      "epoch 6847\n",
      "test_train\n",
      "train mean loss=61987.03697916667\n",
      "test_test\n",
      "test mean loss=88159.9609375\n",
      "fin save.\n",
      "epoch 6848\n",
      "test_train\n",
      "train mean loss=61549.898177083334\n",
      "test_test\n",
      "test mean loss=87747.06640625\n",
      "fin save.\n",
      "epoch 6849\n",
      "test_train\n",
      "train mean loss=61965.6484375\n",
      "test_test\n",
      "test mean loss=87539.953125\n",
      "fin save.\n",
      "epoch 6850\n",
      "test_train\n",
      "train mean loss=61261.98515625\n",
      "test_test\n",
      "test mean loss=87341.05078125\n",
      "fin save.\n",
      "epoch 6851\n",
      "test_train\n",
      "train mean loss=62203.2375\n",
      "test_test\n",
      "test mean loss=87478.1328125\n",
      "fin save.\n",
      "epoch 6852\n",
      "test_train\n",
      "train mean loss=61928.77265625\n",
      "test_test\n",
      "test mean loss=87382.85546875\n",
      "fin save.\n",
      "epoch 6853\n",
      "test_train\n",
      "train mean loss=61917.002734375\n",
      "test_test\n",
      "test mean loss=87851.26171875\n",
      "fin save.\n",
      "epoch 6854\n",
      "test_train\n",
      "train mean loss=62489.499739583334\n",
      "test_test\n",
      "test mean loss=87937.59765625\n",
      "fin save.\n",
      "epoch 6855\n",
      "test_train\n",
      "train mean loss=62783.40546875\n",
      "test_test\n",
      "test mean loss=87800.0390625\n",
      "fin save.\n",
      "epoch 6856\n",
      "test_train\n",
      "train mean loss=60919.7859375\n",
      "test_test\n",
      "test mean loss=87749.6953125\n",
      "fin save.\n",
      "epoch 6857\n",
      "test_train\n",
      "train mean loss=61870.897135416664\n",
      "test_test\n",
      "test mean loss=87912.53125\n",
      "fin save.\n",
      "epoch 6858\n",
      "test_train\n",
      "train mean loss=62542.93958333333\n",
      "test_test\n",
      "test mean loss=88236.2109375\n",
      "fin save.\n",
      "epoch 6859\n",
      "test_train\n",
      "train mean loss=62530.4265625\n",
      "test_test\n",
      "test mean loss=88263.22265625\n",
      "fin save.\n",
      "epoch 6860\n",
      "test_train\n",
      "train mean loss=62860.085677083334\n",
      "test_test\n",
      "test mean loss=88331.0390625\n",
      "fin save.\n",
      "epoch 6861\n",
      "test_train\n",
      "train mean loss=62906.152083333334\n",
      "test_test\n",
      "test mean loss=88156.0390625\n",
      "fin save.\n",
      "epoch 6862\n",
      "test_train\n",
      "train mean loss=62970.35104166667\n",
      "test_test\n",
      "test mean loss=88020.625\n",
      "fin save.\n",
      "epoch 6863\n",
      "test_train\n",
      "train mean loss=61847.600911458336\n",
      "test_test\n",
      "test mean loss=87992.22265625\n",
      "fin save.\n",
      "epoch 6864\n",
      "test_train\n",
      "train mean loss=62661.7578125\n",
      "test_test\n",
      "test mean loss=88008.74609375\n",
      "fin save.\n",
      "epoch 6865\n",
      "test_train\n",
      "train mean loss=61791.357682291666\n",
      "test_test\n",
      "test mean loss=88294.37109375\n",
      "fin save.\n",
      "epoch 6866\n",
      "test_train\n",
      "train mean loss=61762.77630208333\n",
      "test_test\n",
      "test mean loss=88092.60546875\n",
      "fin save.\n",
      "epoch 6867\n",
      "test_train\n",
      "train mean loss=62919.91354166667\n",
      "test_test\n",
      "test mean loss=88028.0703125\n",
      "fin save.\n",
      "epoch 6868\n",
      "test_train\n",
      "train mean loss=63397.36575520833\n",
      "test_test\n",
      "test mean loss=87902.19921875\n",
      "fin save.\n",
      "epoch 6869\n",
      "test_train\n",
      "train mean loss=62110.34609375\n",
      "test_test\n",
      "test mean loss=88198.6796875\n",
      "fin save.\n",
      "epoch 6870\n",
      "test_train\n",
      "train mean loss=62108.60260416667\n",
      "test_test\n",
      "test mean loss=88011.33203125\n",
      "fin save.\n",
      "epoch 6871\n",
      "test_train\n",
      "train mean loss=62483.484765625\n",
      "test_test\n",
      "test mean loss=87993.68359375\n",
      "fin save.\n",
      "epoch 6872\n",
      "test_train\n",
      "train mean loss=61649.38177083333\n",
      "test_test\n",
      "test mean loss=88097.0078125\n",
      "fin save.\n",
      "epoch 6873\n",
      "test_train\n",
      "train mean loss=61990.041015625\n",
      "test_test\n",
      "test mean loss=87759.578125\n",
      "fin save.\n",
      "epoch 6874\n",
      "test_train\n",
      "train mean loss=62784.15234375\n",
      "test_test\n",
      "test mean loss=87938.44921875\n",
      "fin save.\n",
      "epoch 6875\n",
      "test_train\n",
      "train mean loss=62522.576953125\n",
      "test_test\n",
      "test mean loss=88036.90625\n",
      "fin save.\n",
      "epoch 6876\n",
      "test_train\n",
      "train mean loss=62578.775390625\n",
      "test_test\n",
      "test mean loss=87891.60546875\n",
      "fin save.\n",
      "epoch 6877\n",
      "test_train\n",
      "train mean loss=62090.81041666667\n",
      "test_test\n",
      "test mean loss=87940.72265625\n",
      "fin save.\n",
      "epoch 6878\n",
      "test_train\n",
      "train mean loss=62588.08880208333\n",
      "test_test\n",
      "test mean loss=87761.38671875\n",
      "fin save.\n",
      "epoch 6879\n",
      "test_train\n",
      "train mean loss=61738.55755208333\n",
      "test_test\n",
      "test mean loss=88057.27734375\n",
      "fin save.\n",
      "epoch 6880\n",
      "test_train\n",
      "train mean loss=62380.19908854167\n",
      "test_test\n",
      "test mean loss=87808.22265625\n",
      "fin save.\n",
      "epoch 6881\n",
      "test_train\n",
      "train mean loss=61479.78020833333\n",
      "test_test\n",
      "test mean loss=88013.3828125\n",
      "fin save.\n",
      "epoch 6882\n",
      "test_train\n",
      "train mean loss=62059.70416666667\n",
      "test_test\n",
      "test mean loss=88147.03125\n",
      "fin save.\n",
      "epoch 6883\n",
      "test_train\n",
      "train mean loss=62077.221354166664\n",
      "test_test\n",
      "test mean loss=87733.66015625\n",
      "fin save.\n",
      "epoch 6884\n",
      "test_train\n",
      "train mean loss=62358.16484375\n",
      "test_test\n",
      "test mean loss=88223.75\n",
      "fin save.\n",
      "epoch 6885\n",
      "test_train\n",
      "train mean loss=62162.691796875\n",
      "test_test\n",
      "test mean loss=87834.32421875\n",
      "fin save.\n",
      "epoch 6886\n",
      "test_train\n",
      "train mean loss=62333.02330729167\n",
      "test_test\n",
      "test mean loss=87984.5703125\n",
      "fin save.\n",
      "epoch 6887\n",
      "test_train\n",
      "train mean loss=61687.58828125\n",
      "test_test\n",
      "test mean loss=87526.34375\n",
      "fin save.\n",
      "epoch 6888\n",
      "test_train\n",
      "train mean loss=63595.23046875\n",
      "test_test\n",
      "test mean loss=87760.30859375\n",
      "fin save.\n",
      "epoch 6889\n",
      "test_train\n",
      "train mean loss=61772.27109375\n",
      "test_test\n",
      "test mean loss=87605.3515625\n",
      "fin save.\n",
      "epoch 6890\n",
      "test_train\n",
      "train mean loss=62403.14791666667\n",
      "test_test\n",
      "test mean loss=87700.47265625\n",
      "fin save.\n",
      "epoch 6891\n",
      "test_train\n",
      "train mean loss=61993.4390625\n",
      "test_test\n",
      "test mean loss=87576.10546875\n",
      "fin save.\n",
      "epoch 6892\n",
      "test_train\n",
      "train mean loss=61438.54296875\n",
      "test_test\n",
      "test mean loss=87751.23828125\n",
      "fin save.\n",
      "epoch 6893\n",
      "test_train\n",
      "train mean loss=62322.847395833334\n",
      "test_test\n",
      "test mean loss=87741.734375\n",
      "fin save.\n",
      "epoch 6894\n",
      "test_train\n",
      "train mean loss=62330.77734375\n",
      "test_test\n",
      "test mean loss=87789.171875\n",
      "fin save.\n",
      "epoch 6895\n",
      "test_train\n",
      "train mean loss=61930.914322916666\n",
      "test_test\n",
      "test mean loss=87657.19921875\n",
      "fin save.\n",
      "epoch 6896\n",
      "test_train\n",
      "train mean loss=63271.57630208333\n",
      "test_test\n",
      "test mean loss=87973.86328125\n",
      "fin save.\n",
      "epoch 6897\n",
      "test_train\n",
      "train mean loss=62593.1671875\n",
      "test_test\n",
      "test mean loss=87661.6484375\n",
      "fin save.\n",
      "epoch 6898\n",
      "test_train\n",
      "train mean loss=61999.104166666664\n",
      "test_test\n",
      "test mean loss=87949.1015625\n",
      "fin save.\n",
      "epoch 6899\n",
      "test_train\n",
      "train mean loss=62570.075\n",
      "test_test\n",
      "test mean loss=87844.6484375\n",
      "fin save.\n",
      "epoch 6900\n",
      "test_train\n",
      "train mean loss=62303.3453125\n",
      "test_test\n",
      "test mean loss=87698.5859375\n",
      "fin save.\n",
      "epoch 6901\n",
      "test_train\n",
      "train mean loss=61201.382421875\n",
      "test_test\n",
      "test mean loss=87790.71875\n",
      "fin save.\n",
      "epoch 6902\n",
      "test_train\n",
      "train mean loss=61779.74375\n",
      "test_test\n",
      "test mean loss=87735.0390625\n",
      "fin save.\n",
      "epoch 6903\n",
      "test_train\n",
      "train mean loss=62553.23255208333\n",
      "test_test\n",
      "test mean loss=87495.26171875\n",
      "fin save.\n",
      "epoch 6904\n",
      "test_train\n",
      "train mean loss=62234.60260416667\n",
      "test_test\n",
      "test mean loss=87725.24609375\n",
      "fin save.\n",
      "epoch 6905\n",
      "test_train\n",
      "train mean loss=62411.257161458336\n",
      "test_test\n",
      "test mean loss=87934.03125\n",
      "fin save.\n",
      "epoch 6906\n",
      "test_train\n",
      "train mean loss=62038.330338541666\n",
      "test_test\n",
      "test mean loss=87906.75\n",
      "fin save.\n",
      "epoch 6907\n",
      "test_train\n",
      "train mean loss=61803.958723958334\n",
      "test_test\n",
      "test mean loss=87725.68359375\n",
      "fin save.\n",
      "epoch 6908\n",
      "test_train\n",
      "train mean loss=62689.428125\n",
      "test_test\n",
      "test mean loss=87658.2421875\n",
      "fin save.\n",
      "epoch 6909\n",
      "test_train\n",
      "train mean loss=62921.250260416666\n",
      "test_test\n",
      "test mean loss=87531.83203125\n",
      "fin save.\n",
      "epoch 6910\n",
      "test_train\n",
      "train mean loss=62372.54348958333\n",
      "test_test\n",
      "test mean loss=87719.12109375\n",
      "fin save.\n",
      "epoch 6911\n",
      "test_train\n",
      "train mean loss=62171.154947916664\n",
      "test_test\n",
      "test mean loss=87924.62109375\n",
      "fin save.\n",
      "epoch 6912\n",
      "test_train\n",
      "train mean loss=62607.340104166666\n",
      "test_test\n",
      "test mean loss=87512.5859375\n",
      "fin save.\n",
      "epoch 6913\n",
      "test_train\n",
      "train mean loss=62527.30651041667\n",
      "test_test\n",
      "test mean loss=87187.16796875\n",
      "fin save.\n",
      "epoch 6914\n",
      "test_train\n",
      "train mean loss=62687.93046875\n",
      "test_test\n",
      "test mean loss=87313.05859375\n",
      "fin save.\n",
      "epoch 6915\n",
      "test_train\n",
      "train mean loss=62375.300520833334\n",
      "test_test\n",
      "test mean loss=87167.7421875\n",
      "fin save.\n",
      "epoch 6916\n",
      "test_train\n",
      "train mean loss=61826.8046875\n",
      "test_test\n",
      "test mean loss=87411.46484375\n",
      "fin save.\n",
      "epoch 6917\n",
      "test_train\n",
      "train mean loss=62357.765885416666\n",
      "test_test\n",
      "test mean loss=87408.63671875\n",
      "fin save.\n",
      "epoch 6918\n",
      "test_train\n",
      "train mean loss=62756.64544270833\n",
      "test_test\n",
      "test mean loss=87410.56640625\n",
      "fin save.\n",
      "epoch 6919\n",
      "test_train\n",
      "train mean loss=61912.53463541667\n",
      "test_test\n",
      "test mean loss=87399.8359375\n",
      "fin save.\n",
      "epoch 6920\n",
      "test_train\n",
      "train mean loss=62567.301041666666\n",
      "test_test\n",
      "test mean loss=87515.94140625\n",
      "fin save.\n",
      "epoch 6921\n",
      "test_train\n",
      "train mean loss=62020.46432291667\n",
      "test_test\n",
      "test mean loss=87313.3671875\n",
      "fin save.\n",
      "epoch 6922\n",
      "test_train\n",
      "train mean loss=62222.45403645833\n",
      "test_test\n",
      "test mean loss=87439.64453125\n",
      "fin save.\n",
      "epoch 6923\n",
      "test_train\n",
      "train mean loss=62273.55911458333\n",
      "test_test\n",
      "test mean loss=87266.6875\n",
      "fin save.\n",
      "epoch 6924\n",
      "test_train\n",
      "train mean loss=62186.13333333333\n",
      "test_test\n",
      "test mean loss=87278.95703125\n",
      "fin save.\n",
      "epoch 6925\n",
      "test_train\n",
      "train mean loss=61239.471484375\n",
      "test_test\n",
      "test mean loss=87393.7734375\n",
      "fin save.\n",
      "epoch 6926\n",
      "test_train\n",
      "train mean loss=62176.88489583333\n",
      "test_test\n",
      "test mean loss=87687.43359375\n",
      "fin save.\n",
      "epoch 6927\n",
      "test_train\n",
      "train mean loss=62461.738932291664\n",
      "test_test\n",
      "test mean loss=87699.71484375\n",
      "fin save.\n",
      "epoch 6928\n",
      "test_train\n",
      "train mean loss=62085.3015625\n",
      "test_test\n",
      "test mean loss=87463.2578125\n",
      "fin save.\n",
      "epoch 6929\n",
      "test_train\n",
      "train mean loss=62701.96731770833\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=87436.140625\n",
      "fin save.\n",
      "epoch 6930\n",
      "test_train\n",
      "train mean loss=61788.7828125\n",
      "test_test\n",
      "test mean loss=87537.16015625\n",
      "fin save.\n",
      "epoch 6931\n",
      "test_train\n",
      "train mean loss=61660.34947916667\n",
      "test_test\n",
      "test mean loss=87223.19140625\n",
      "fin save.\n",
      "epoch 6932\n",
      "test_train\n",
      "train mean loss=61619.6625\n",
      "test_test\n",
      "test mean loss=87844.98046875\n",
      "fin save.\n",
      "epoch 6933\n",
      "test_train\n",
      "train mean loss=62916.505078125\n",
      "test_test\n",
      "test mean loss=87612.01953125\n",
      "fin save.\n",
      "epoch 6934\n",
      "test_train\n",
      "train mean loss=62634.31354166667\n",
      "test_test\n",
      "test mean loss=87644.515625\n",
      "fin save.\n",
      "epoch 6935\n",
      "test_train\n",
      "train mean loss=61418.872395833336\n",
      "test_test\n",
      "test mean loss=87653.7734375\n",
      "fin save.\n",
      "epoch 6936\n",
      "test_train\n",
      "train mean loss=62043.01614583333\n",
      "test_test\n",
      "test mean loss=87811.56640625\n",
      "fin save.\n",
      "epoch 6937\n",
      "test_train\n",
      "train mean loss=62267.95\n",
      "test_test\n",
      "test mean loss=87945.16796875\n",
      "fin save.\n",
      "epoch 6938\n",
      "test_train\n",
      "train mean loss=62890.480078125\n",
      "test_test\n",
      "test mean loss=88157.2578125\n",
      "fin save.\n",
      "epoch 6939\n",
      "test_train\n",
      "train mean loss=61422.043229166666\n",
      "test_test\n",
      "test mean loss=88112.01953125\n",
      "fin save.\n",
      "epoch 6940\n",
      "test_train\n",
      "train mean loss=62101.33541666667\n",
      "test_test\n",
      "test mean loss=88319.359375\n",
      "fin save.\n",
      "epoch 6941\n",
      "test_train\n",
      "train mean loss=62095.698567708336\n",
      "test_test\n",
      "test mean loss=88210.16796875\n",
      "fin save.\n",
      "epoch 6942\n",
      "test_train\n",
      "train mean loss=62015.9203125\n",
      "test_test\n",
      "test mean loss=87908.3984375\n",
      "fin save.\n",
      "epoch 6943\n",
      "test_train\n",
      "train mean loss=62262.92135416667\n",
      "test_test\n",
      "test mean loss=88065.359375\n",
      "fin save.\n",
      "epoch 6944\n",
      "test_train\n",
      "train mean loss=62187.98255208333\n",
      "test_test\n",
      "test mean loss=88006.91796875\n",
      "fin save.\n",
      "epoch 6945\n",
      "test_train\n",
      "train mean loss=62572.962890625\n",
      "test_test\n",
      "test mean loss=88105.6875\n",
      "fin save.\n",
      "epoch 6946\n",
      "test_train\n",
      "train mean loss=62026.581770833334\n",
      "test_test\n",
      "test mean loss=88125.265625\n",
      "fin save.\n",
      "epoch 6947\n",
      "test_train\n",
      "train mean loss=62824.50390625\n",
      "test_test\n",
      "test mean loss=88096.8828125\n",
      "fin save.\n",
      "epoch 6948\n",
      "test_train\n",
      "train mean loss=62738.130208333336\n",
      "test_test\n",
      "test mean loss=88054.84765625\n",
      "fin save.\n",
      "epoch 6949\n",
      "test_train\n",
      "train mean loss=61792.08932291667\n",
      "test_test\n",
      "test mean loss=88129.7734375\n",
      "fin save.\n",
      "epoch 6950\n",
      "test_train\n",
      "train mean loss=61756.51653645833\n",
      "test_test\n",
      "test mean loss=87959.93359375\n",
      "fin save.\n",
      "epoch 6951\n",
      "test_train\n",
      "train mean loss=60964.948046875\n",
      "test_test\n",
      "test mean loss=87876.91015625\n",
      "fin save.\n",
      "epoch 6952\n",
      "test_train\n",
      "train mean loss=61859.891796875\n",
      "test_test\n",
      "test mean loss=87767.29296875\n",
      "fin save.\n",
      "epoch 6953\n",
      "test_train\n",
      "train mean loss=62092.84140625\n",
      "test_test\n",
      "test mean loss=87775.6953125\n",
      "fin save.\n",
      "epoch 6954\n",
      "test_train\n",
      "train mean loss=63413.57434895833\n",
      "test_test\n",
      "test mean loss=88191.62890625\n",
      "fin save.\n",
      "epoch 6955\n",
      "test_train\n",
      "train mean loss=62333.08385416667\n",
      "test_test\n",
      "test mean loss=88204.92578125\n",
      "fin save.\n",
      "epoch 6956\n",
      "test_train\n",
      "train mean loss=63361.67369791667\n",
      "test_test\n",
      "test mean loss=87989.4765625\n",
      "fin save.\n",
      "epoch 6957\n",
      "test_train\n",
      "train mean loss=61904.640625\n",
      "test_test\n",
      "test mean loss=87879.23046875\n",
      "fin save.\n",
      "epoch 6958\n",
      "test_train\n",
      "train mean loss=61437.875260416666\n",
      "test_test\n",
      "test mean loss=88064.98828125\n",
      "fin save.\n",
      "epoch 6959\n",
      "test_train\n",
      "train mean loss=62186.970052083336\n",
      "test_test\n",
      "test mean loss=87949.30078125\n",
      "fin save.\n",
      "epoch 6960\n",
      "test_train\n",
      "train mean loss=62178.57434895833\n",
      "test_test\n",
      "test mean loss=88195.91015625\n",
      "fin save.\n",
      "epoch 6961\n",
      "test_train\n",
      "train mean loss=62889.6359375\n",
      "test_test\n",
      "test mean loss=87913.35546875\n",
      "fin save.\n",
      "epoch 6962\n",
      "test_train\n",
      "train mean loss=62080.605208333334\n",
      "test_test\n",
      "test mean loss=88142.48828125\n",
      "fin save.\n",
      "epoch 6963\n",
      "test_train\n",
      "train mean loss=61754.796875\n",
      "test_test\n",
      "test mean loss=87916.23828125\n",
      "fin save.\n",
      "epoch 6964\n",
      "test_train\n",
      "train mean loss=63336.288671875\n",
      "test_test\n",
      "test mean loss=87866.23828125\n",
      "fin save.\n",
      "epoch 6965\n",
      "test_train\n",
      "train mean loss=62291.80963541667\n",
      "test_test\n",
      "test mean loss=88122.203125\n",
      "fin save.\n",
      "epoch 6966\n",
      "test_train\n",
      "train mean loss=62402.7\n",
      "test_test\n",
      "test mean loss=87955.63671875\n",
      "fin save.\n",
      "epoch 6967\n",
      "test_train\n",
      "train mean loss=61970.055989583336\n",
      "test_test\n",
      "test mean loss=88082.67578125\n",
      "fin save.\n",
      "epoch 6968\n",
      "test_train\n",
      "train mean loss=62407.92864583333\n",
      "test_test\n",
      "test mean loss=88137.23828125\n",
      "fin save.\n",
      "epoch 6969\n",
      "test_train\n",
      "train mean loss=62943.757552083334\n",
      "test_test\n",
      "test mean loss=87949.9140625\n",
      "fin save.\n",
      "epoch 6970\n",
      "test_train\n",
      "train mean loss=61662.641927083336\n",
      "test_test\n",
      "test mean loss=88046.8828125\n",
      "fin save.\n",
      "epoch 6971\n",
      "test_train\n",
      "train mean loss=63068.97890625\n",
      "test_test\n",
      "test mean loss=87839.984375\n",
      "fin save.\n",
      "epoch 6972\n",
      "test_train\n",
      "train mean loss=62937.74270833333\n",
      "test_test\n",
      "test mean loss=88121.16796875\n",
      "fin save.\n",
      "epoch 6973\n",
      "test_train\n",
      "train mean loss=61276.58346354167\n",
      "test_test\n",
      "test mean loss=88173.125\n",
      "fin save.\n",
      "epoch 6974\n",
      "test_train\n",
      "train mean loss=62000.638411458334\n",
      "test_test\n",
      "test mean loss=88042.6171875\n",
      "fin save.\n",
      "epoch 6975\n",
      "test_train\n",
      "train mean loss=63097.337109375\n",
      "test_test\n",
      "test mean loss=88294.3203125\n",
      "fin save.\n",
      "epoch 6976\n",
      "test_train\n",
      "train mean loss=61793.2375\n",
      "test_test\n",
      "test mean loss=88278.34375\n",
      "fin save.\n",
      "epoch 6977\n",
      "test_train\n",
      "train mean loss=62661.168359375\n",
      "test_test\n",
      "test mean loss=88146.96484375\n",
      "fin save.\n",
      "epoch 6978\n",
      "test_train\n",
      "train mean loss=62126.31731770833\n",
      "test_test\n",
      "test mean loss=88210.515625\n",
      "fin save.\n",
      "epoch 6979\n",
      "test_train\n",
      "train mean loss=61419.188802083336\n",
      "test_test\n",
      "test mean loss=88187.75390625\n",
      "fin save.\n",
      "epoch 6980\n",
      "test_train\n",
      "train mean loss=62884.05625\n",
      "test_test\n",
      "test mean loss=88161.45703125\n",
      "fin save.\n",
      "epoch 6981\n",
      "test_train\n",
      "train mean loss=62250.611588541666\n",
      "test_test\n",
      "test mean loss=88164.0546875\n",
      "fin save.\n",
      "epoch 6982\n",
      "test_train\n",
      "train mean loss=62062.383072916666\n",
      "test_test\n",
      "test mean loss=88110.8359375\n",
      "fin save.\n",
      "epoch 6983\n",
      "test_train\n",
      "train mean loss=62395.910807291664\n",
      "test_test\n",
      "test mean loss=88043.64453125\n",
      "fin save.\n",
      "epoch 6984\n",
      "test_train\n",
      "train mean loss=62139.94817708333\n",
      "test_test\n",
      "test mean loss=88090.1171875\n",
      "fin save.\n",
      "epoch 6985\n",
      "test_train\n",
      "train mean loss=62803.13854166667\n",
      "test_test\n",
      "test mean loss=88181.18359375\n",
      "fin save.\n",
      "epoch 6986\n",
      "test_train\n",
      "train mean loss=62924.26028645833\n",
      "test_test\n",
      "test mean loss=88013.125\n",
      "fin save.\n",
      "epoch 6987\n",
      "test_train\n",
      "train mean loss=61809.34947916667\n",
      "test_test\n",
      "test mean loss=88102.34765625\n",
      "fin save.\n",
      "epoch 6988\n",
      "test_train\n",
      "train mean loss=61206.55455729167\n",
      "test_test\n",
      "test mean loss=88230.50390625\n",
      "fin save.\n",
      "epoch 6989\n",
      "test_train\n",
      "train mean loss=63118.294270833336\n",
      "test_test\n",
      "test mean loss=87914.265625\n",
      "fin save.\n",
      "epoch 6990\n",
      "test_train\n",
      "train mean loss=62501.08893229167\n",
      "test_test\n",
      "test mean loss=88023.890625\n",
      "fin save.\n",
      "epoch 6991\n",
      "test_train\n",
      "train mean loss=62226.18125\n",
      "test_test\n",
      "test mean loss=88210.796875\n",
      "fin save.\n",
      "epoch 6992\n",
      "test_train\n",
      "train mean loss=62341.41796875\n",
      "test_test\n",
      "test mean loss=88076.00390625\n",
      "fin save.\n",
      "epoch 6993\n",
      "test_train\n",
      "train mean loss=62398.628645833334\n",
      "test_test\n",
      "test mean loss=88020.49609375\n",
      "fin save.\n",
      "epoch 6994\n",
      "test_train\n",
      "train mean loss=63223.57708333333\n",
      "test_test\n",
      "test mean loss=88084.97265625\n",
      "fin save.\n",
      "epoch 6995\n",
      "test_train\n",
      "train mean loss=61683.53984375\n",
      "test_test\n",
      "test mean loss=88205.83203125\n",
      "fin save.\n",
      "epoch 6996\n",
      "test_train\n",
      "train mean loss=62146.69231770833\n",
      "test_test\n",
      "test mean loss=88045.09765625\n",
      "fin save.\n",
      "epoch 6997\n",
      "test_train\n",
      "train mean loss=63128.89010416667\n",
      "test_test\n",
      "test mean loss=88165.55078125\n",
      "fin save.\n",
      "epoch 6998\n",
      "test_train\n",
      "train mean loss=61178.105208333334\n",
      "test_test\n",
      "test mean loss=88191.49609375\n",
      "fin save.\n",
      "epoch 6999\n",
      "test_train\n",
      "train mean loss=62522.68854166667\n",
      "test_test\n",
      "test mean loss=88386.984375\n",
      "fin save.\n",
      "epoch 7000\n",
      "test_train\n",
      "train mean loss=61847.89166666667\n",
      "test_test\n",
      "test mean loss=88270.94921875\n",
      "fin save.\n",
      "epoch 7001\n",
      "test_train\n",
      "train mean loss=62063.135416666664\n",
      "test_test\n",
      "test mean loss=88235.41015625\n",
      "fin save.\n",
      "epoch 7002\n",
      "test_train\n",
      "train mean loss=62002.909375\n",
      "test_test\n",
      "test mean loss=88219.7578125\n",
      "fin save.\n",
      "epoch 7003\n",
      "test_train\n",
      "train mean loss=61910.68645833333\n",
      "test_test\n",
      "test mean loss=88050.45703125\n",
      "fin save.\n",
      "epoch 7004\n",
      "test_train\n",
      "train mean loss=62929.7375\n",
      "test_test\n",
      "test mean loss=88204.97265625\n",
      "fin save.\n",
      "epoch 7005\n",
      "test_train\n",
      "train mean loss=63926.55078125\n",
      "test_test\n",
      "test mean loss=88208.76953125\n",
      "fin save.\n",
      "epoch 7006\n",
      "test_train\n",
      "train mean loss=62127.48333333333\n",
      "test_test\n",
      "test mean loss=88226.01953125\n",
      "fin save.\n",
      "epoch 7007\n",
      "test_train\n",
      "train mean loss=63197.63385416667\n",
      "test_test\n",
      "test mean loss=88166.828125\n",
      "fin save.\n",
      "epoch 7008\n",
      "test_train\n",
      "train mean loss=62545.14010416667\n",
      "test_test\n",
      "test mean loss=87940.56640625\n",
      "fin save.\n",
      "epoch 7009\n",
      "test_train\n",
      "train mean loss=62504.180989583336\n",
      "test_test\n",
      "test mean loss=88129.4375\n",
      "fin save.\n",
      "epoch 7010\n",
      "test_train\n",
      "train mean loss=62510.676041666666\n",
      "test_test\n",
      "test mean loss=88062.79296875\n",
      "fin save.\n",
      "epoch 7011\n",
      "test_train\n",
      "train mean loss=61405.62890625\n",
      "test_test\n",
      "test mean loss=88092.515625\n",
      "fin save.\n",
      "epoch 7012\n",
      "test_train\n",
      "train mean loss=62631.3625\n",
      "test_test\n",
      "test mean loss=88013.7109375\n",
      "fin save.\n",
      "epoch 7013\n",
      "test_train\n",
      "train mean loss=61732.001953125\n",
      "test_test\n",
      "test mean loss=87983.33984375\n",
      "fin save.\n",
      "epoch 7014\n",
      "test_train\n",
      "train mean loss=61122.286458333336\n",
      "test_test\n",
      "test mean loss=87897.1328125\n",
      "fin save.\n",
      "epoch 7015\n",
      "test_train\n",
      "train mean loss=61982.015885416666\n",
      "test_test\n",
      "test mean loss=88015.24609375\n",
      "fin save.\n",
      "epoch 7016\n",
      "test_train\n",
      "train mean loss=63228.53763020833\n",
      "test_test\n",
      "test mean loss=87934.08984375\n",
      "fin save.\n",
      "epoch 7017\n",
      "test_train\n",
      "train mean loss=62510.81458333333\n",
      "test_test\n",
      "test mean loss=88298.32421875\n",
      "fin save.\n",
      "epoch 7018\n",
      "test_train\n",
      "train mean loss=61586.740234375\n",
      "test_test\n",
      "test mean loss=87994.4140625\n",
      "fin save.\n",
      "epoch 7019\n",
      "test_train\n",
      "train mean loss=61503.35364583333\n",
      "test_test\n",
      "test mean loss=88017.79296875\n",
      "fin save.\n",
      "epoch 7020\n",
      "test_train\n",
      "train mean loss=62052.872395833336\n",
      "test_test\n",
      "test mean loss=87658.0078125\n",
      "fin save.\n",
      "epoch 7021\n",
      "test_train\n",
      "train mean loss=62103.65572916667\n",
      "test_test\n",
      "test mean loss=87695.75390625\n",
      "fin save.\n",
      "epoch 7022\n",
      "test_train\n",
      "train mean loss=62352.6359375\n",
      "test_test\n",
      "test mean loss=87856.0859375\n",
      "fin save.\n",
      "epoch 7023\n",
      "test_train\n",
      "train mean loss=61760.77265625\n",
      "test_test\n",
      "test mean loss=87426.765625\n",
      "fin save.\n",
      "epoch 7024\n",
      "test_train\n",
      "train mean loss=63085.98333333333\n",
      "test_test\n",
      "test mean loss=87691.48828125\n",
      "fin save.\n",
      "epoch 7025\n",
      "test_train\n",
      "train mean loss=62762.96197916667\n",
      "test_test\n",
      "test mean loss=87705.65234375\n",
      "fin save.\n",
      "epoch 7026\n",
      "test_train\n",
      "train mean loss=62172.00963541667\n",
      "test_test\n",
      "test mean loss=87822.80859375\n",
      "fin save.\n",
      "epoch 7027\n",
      "test_train\n",
      "train mean loss=61970.5140625\n",
      "test_test\n",
      "test mean loss=87961.0859375\n",
      "fin save.\n",
      "epoch 7028\n",
      "test_train\n",
      "train mean loss=63127.726822916666\n",
      "test_test\n",
      "test mean loss=87579.6171875\n",
      "fin save.\n",
      "epoch 7029\n",
      "test_train\n",
      "train mean loss=62158.513020833336\n",
      "test_test\n",
      "test mean loss=87589.51171875\n",
      "fin save.\n",
      "epoch 7030\n",
      "test_train\n",
      "train mean loss=62352.88046875\n",
      "test_test\n",
      "test mean loss=87971.22265625\n",
      "fin save.\n",
      "epoch 7031\n",
      "test_train\n",
      "train mean loss=61654.27942708333\n",
      "test_test\n",
      "test mean loss=88129.66015625\n",
      "fin save.\n",
      "epoch 7032\n",
      "test_train\n",
      "train mean loss=62851.184895833336\n",
      "test_test\n",
      "test mean loss=88124.8828125\n",
      "fin save.\n",
      "epoch 7033\n",
      "test_train\n",
      "train mean loss=62655.40234375\n",
      "test_test\n",
      "test mean loss=88127.7890625\n",
      "fin save.\n",
      "epoch 7034\n",
      "test_train\n",
      "train mean loss=62257.49817708333\n",
      "test_test\n",
      "test mean loss=88016.90234375\n",
      "fin save.\n",
      "epoch 7035\n",
      "test_train\n",
      "train mean loss=62827.83515625\n",
      "test_test\n",
      "test mean loss=88180.0390625\n",
      "fin save.\n",
      "epoch 7036\n",
      "test_train\n",
      "train mean loss=62068.97942708333\n",
      "test_test\n",
      "test mean loss=88180.8828125\n",
      "fin save.\n",
      "epoch 7037\n",
      "test_train\n",
      "train mean loss=62178.902994791664\n",
      "test_test\n",
      "test mean loss=88266.234375\n",
      "fin save.\n",
      "epoch 7038\n",
      "test_train\n",
      "train mean loss=61694.10755208333\n",
      "test_test\n",
      "test mean loss=88069.6328125\n",
      "fin save.\n",
      "epoch 7039\n",
      "test_train\n",
      "train mean loss=62689.84088541667\n",
      "test_test\n",
      "test mean loss=87786.7890625\n",
      "fin save.\n",
      "epoch 7040\n",
      "test_train\n",
      "train mean loss=62247.04921875\n",
      "test_test\n",
      "test mean loss=88058.24609375\n",
      "fin save.\n",
      "epoch 7041\n",
      "test_train\n",
      "train mean loss=62441.980208333334\n",
      "test_test\n",
      "test mean loss=87726.89453125\n",
      "fin save.\n",
      "epoch 7042\n",
      "test_train\n",
      "train mean loss=61803.738541666666\n",
      "test_test\n",
      "test mean loss=87814.98046875\n",
      "fin save.\n",
      "epoch 7043\n",
      "test_train\n",
      "train mean loss=61697.64296875\n",
      "test_test\n",
      "test mean loss=87712.26171875\n",
      "fin save.\n",
      "epoch 7044\n",
      "test_train\n",
      "train mean loss=62930.82916666667\n",
      "test_test\n",
      "test mean loss=87805.40234375\n",
      "fin save.\n",
      "epoch 7045\n",
      "test_train\n",
      "train mean loss=62482.64765625\n",
      "test_test\n",
      "test mean loss=87705.08203125\n",
      "fin save.\n",
      "epoch 7046\n",
      "test_train\n",
      "train mean loss=62418.234114583334\n",
      "test_test\n",
      "test mean loss=88120.03515625\n",
      "fin save.\n",
      "epoch 7047\n",
      "test_train\n",
      "train mean loss=61933.80963541667\n",
      "test_test\n",
      "test mean loss=88114.171875\n",
      "fin save.\n",
      "epoch 7048\n",
      "test_train\n",
      "train mean loss=62177.73645833333\n",
      "test_test\n",
      "test mean loss=88144.421875\n",
      "fin save.\n",
      "epoch 7049\n",
      "test_train\n",
      "train mean loss=62088.89700520833\n",
      "test_test\n",
      "test mean loss=88109.41796875\n",
      "fin save.\n",
      "epoch 7050\n",
      "test_train\n",
      "train mean loss=62390.164322916666\n",
      "test_test\n",
      "test mean loss=88341.44140625\n",
      "fin save.\n",
      "epoch 7051\n",
      "test_train\n",
      "train mean loss=62180.48203125\n",
      "test_test\n",
      "test mean loss=88185.84375\n",
      "fin save.\n",
      "epoch 7052\n",
      "test_train\n",
      "train mean loss=62429.512369791664\n",
      "test_test\n",
      "test mean loss=88200.73046875\n",
      "fin save.\n",
      "epoch 7053\n",
      "test_train\n",
      "train mean loss=62384.901171875\n",
      "test_test\n",
      "test mean loss=87748.8046875\n",
      "fin save.\n",
      "epoch 7054\n",
      "test_train\n",
      "train mean loss=62044.469140625\n",
      "test_test\n",
      "test mean loss=88281.8984375\n",
      "fin save.\n",
      "epoch 7055\n",
      "test_train\n",
      "train mean loss=62024.62552083333\n",
      "test_test\n",
      "test mean loss=88329.8984375\n",
      "fin save.\n",
      "epoch 7056\n",
      "test_train\n",
      "train mean loss=61320.570572916666\n",
      "test_test\n",
      "test mean loss=88114.8515625\n",
      "fin save.\n",
      "epoch 7057\n",
      "test_train\n",
      "train mean loss=62148.5453125\n",
      "test_test\n",
      "test mean loss=88194.98828125\n",
      "fin save.\n",
      "epoch 7058\n",
      "test_train\n",
      "train mean loss=63056.96979166667\n",
      "test_test\n",
      "test mean loss=88122.55859375\n",
      "fin save.\n",
      "epoch 7059\n",
      "test_train\n",
      "train mean loss=62407.081770833334\n",
      "test_test\n",
      "test mean loss=88066.296875\n",
      "fin save.\n",
      "epoch 7060\n",
      "test_train\n",
      "train mean loss=62786.092447916664\n",
      "test_test\n",
      "test mean loss=88060.93359375\n",
      "fin save.\n",
      "epoch 7061\n",
      "test_train\n",
      "train mean loss=61895.14557291667\n",
      "test_test\n",
      "test mean loss=88038.82421875\n",
      "fin save.\n",
      "epoch 7062\n",
      "test_train\n",
      "train mean loss=63117.065104166664\n",
      "test_test\n",
      "test mean loss=88144.37890625\n",
      "fin save.\n",
      "epoch 7063\n",
      "test_train\n",
      "train mean loss=61810.022786458336\n",
      "test_test\n",
      "test mean loss=88198.85546875\n",
      "fin save.\n",
      "epoch 7064\n",
      "test_train\n",
      "train mean loss=61121.54244791667\n",
      "test_test\n",
      "test mean loss=88148.546875\n",
      "fin save.\n",
      "epoch 7065\n",
      "test_train\n",
      "train mean loss=62211.225260416664\n",
      "test_test\n",
      "test mean loss=88157.03125\n",
      "fin save.\n",
      "epoch 7066\n",
      "test_train\n",
      "train mean loss=61303.362109375\n",
      "test_test\n",
      "test mean loss=88240.77734375\n",
      "fin save.\n",
      "epoch 7067\n",
      "test_train\n",
      "train mean loss=62192.6140625\n",
      "test_test\n",
      "test mean loss=88214.1875\n",
      "fin save.\n",
      "epoch 7068\n",
      "test_train\n",
      "train mean loss=62140.30026041667\n",
      "test_test\n",
      "test mean loss=88158.48828125\n",
      "fin save.\n",
      "epoch 7069\n",
      "test_train\n",
      "train mean loss=62628.47994791667\n",
      "test_test\n",
      "test mean loss=87938.6796875\n",
      "fin save.\n",
      "epoch 7070\n",
      "test_train\n",
      "train mean loss=62099.08802083333\n",
      "test_test\n",
      "test mean loss=88097.6796875\n",
      "fin save.\n",
      "epoch 7071\n",
      "test_train\n",
      "train mean loss=62646.20807291667\n",
      "test_test\n",
      "test mean loss=87983.79296875\n",
      "fin save.\n",
      "epoch 7072\n",
      "test_train\n",
      "train mean loss=62932.084375\n",
      "test_test\n",
      "test mean loss=88003.8046875\n",
      "fin save.\n",
      "epoch 7073\n",
      "test_train\n",
      "train mean loss=61704.458203125\n",
      "test_test\n",
      "test mean loss=88186.94140625\n",
      "fin save.\n",
      "epoch 7074\n",
      "test_train\n",
      "train mean loss=61895.846354166664\n",
      "test_test\n",
      "test mean loss=88032.79296875\n",
      "fin save.\n",
      "epoch 7075\n",
      "test_train\n",
      "train mean loss=62345.99361979167\n",
      "test_test\n",
      "test mean loss=87987.12890625\n",
      "fin save.\n",
      "epoch 7076\n",
      "test_train\n",
      "train mean loss=61653.998697916664\n",
      "test_test\n",
      "test mean loss=87981.92578125\n",
      "fin save.\n",
      "epoch 7077\n",
      "test_train\n",
      "train mean loss=61806.8375\n",
      "test_test\n",
      "test mean loss=88037.76953125\n",
      "fin save.\n",
      "epoch 7078\n",
      "test_train\n",
      "train mean loss=63219.29192708333\n",
      "test_test\n",
      "test mean loss=87887.32421875\n",
      "fin save.\n",
      "epoch 7079\n",
      "test_train\n",
      "train mean loss=62435.023697916666\n",
      "test_test\n",
      "test mean loss=87681.296875\n",
      "fin save.\n",
      "epoch 7080\n",
      "test_train\n",
      "train mean loss=63056.991536458336\n",
      "test_test\n",
      "test mean loss=87948.12109375\n",
      "fin save.\n",
      "epoch 7081\n",
      "test_train\n",
      "train mean loss=62792.20078125\n",
      "test_test\n",
      "test mean loss=87530.60546875\n",
      "fin save.\n",
      "epoch 7082\n",
      "test_train\n",
      "train mean loss=61873.753125\n",
      "test_test\n",
      "test mean loss=87704.296875\n",
      "fin save.\n",
      "epoch 7083\n",
      "test_train\n",
      "train mean loss=62167.066796875\n",
      "test_test\n",
      "test mean loss=87970.86328125\n",
      "fin save.\n",
      "epoch 7084\n",
      "test_train\n",
      "train mean loss=62108.53372395833\n",
      "test_test\n",
      "test mean loss=88281.8984375\n",
      "fin save.\n",
      "epoch 7085\n",
      "test_train\n",
      "train mean loss=63301.53411458333\n",
      "test_test\n",
      "test mean loss=88011.328125\n",
      "fin save.\n",
      "epoch 7086\n",
      "test_train\n",
      "train mean loss=61567.85390625\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_test\n",
      "test mean loss=88155.5625\n",
      "fin save.\n",
      "epoch 7087\n",
      "test_train\n",
      "train mean loss=61834.661458333336\n",
      "test_test\n",
      "test mean loss=87930.5625\n",
      "fin save.\n",
      "epoch 7088\n",
      "test_train\n",
      "train mean loss=63194.39947916667\n",
      "test_test\n",
      "test mean loss=87937.828125\n",
      "fin save.\n",
      "epoch 7089\n",
      "test_train\n",
      "train mean loss=62927.63567708333\n",
      "test_test\n",
      "test mean loss=87823.2578125\n",
      "fin save.\n",
      "epoch 7090\n",
      "test_train\n",
      "train mean loss=62140.58385416667\n",
      "test_test\n",
      "test mean loss=87815.640625\n",
      "fin save.\n",
      "epoch 7091\n",
      "test_train\n",
      "train mean loss=61748.826822916664\n",
      "test_test\n",
      "test mean loss=87891.7421875\n",
      "fin save.\n",
      "epoch 7092\n",
      "test_train\n",
      "train mean loss=62656.350390625\n",
      "test_test\n",
      "test mean loss=87839.55078125\n",
      "fin save.\n",
      "epoch 7093\n",
      "test_train\n",
      "train mean loss=62233.52578125\n",
      "test_test\n",
      "test mean loss=88100.2578125\n",
      "fin save.\n",
      "epoch 7094\n",
      "test_train\n",
      "train mean loss=61514.38528645833\n",
      "test_test\n",
      "test mean loss=88097.06640625\n",
      "fin save.\n",
      "epoch 7095\n",
      "test_train\n",
      "train mean loss=61801.765625\n",
      "test_test\n",
      "test mean loss=88048.8203125\n",
      "fin save.\n",
      "epoch 7096\n",
      "test_train\n",
      "train mean loss=61305.253125\n",
      "test_test\n",
      "test mean loss=87806.77734375\n",
      "fin save.\n",
      "epoch 7097\n",
      "test_train\n",
      "train mean loss=61329.55768229167\n",
      "test_test\n",
      "test mean loss=88214.17578125\n",
      "fin save.\n",
      "epoch 7098\n",
      "test_train\n",
      "train mean loss=61809.548177083336\n",
      "test_test\n",
      "test mean loss=88188.9375\n",
      "fin save.\n",
      "epoch 7099\n",
      "test_train\n",
      "train mean loss=61931.4359375\n",
      "test_test\n",
      "test mean loss=88181.89453125\n",
      "fin save.\n",
      "epoch 7100\n",
      "test_train\n",
      "train mean loss=61833.96484375\n",
      "test_test\n",
      "test mean loss=88227.4921875\n",
      "fin save.\n",
      "epoch 7101\n",
      "test_train\n",
      "train mean loss=61850.38958333333\n",
      "test_test\n",
      "test mean loss=88217.6328125\n",
      "fin save.\n",
      "epoch 7102\n",
      "test_train\n",
      "train mean loss=62481.6921875\n",
      "test_test\n",
      "test mean loss=88258.87109375\n",
      "fin save.\n",
      "epoch 7103\n",
      "test_train\n",
      "train mean loss=61672.027083333334\n",
      "test_test\n",
      "test mean loss=88130.97265625\n",
      "fin save.\n",
      "epoch 7104\n",
      "test_train\n",
      "train mean loss=62007.090625\n",
      "test_test\n",
      "test mean loss=88080.0859375\n",
      "fin save.\n",
      "epoch 7105\n",
      "test_train\n",
      "train mean loss=61812.232421875\n",
      "test_test\n",
      "test mean loss=88196.29296875\n",
      "fin save.\n",
      "epoch 7106\n",
      "test_train\n",
      "train mean loss=62966.806640625\n",
      "test_test\n",
      "test mean loss=88276.21875\n",
      "fin save.\n",
      "epoch 7107\n",
      "test_train\n",
      "train mean loss=61787.40026041667\n",
      "test_test\n",
      "test mean loss=88266.41796875\n",
      "fin save.\n",
      "epoch 7108\n",
      "test_train\n",
      "train mean loss=62234.058854166666\n",
      "test_test\n",
      "test mean loss=88174.09375\n",
      "fin save.\n",
      "epoch 7109\n",
      "test_train\n",
      "train mean loss=62039.38229166667\n",
      "test_test\n",
      "test mean loss=88374.45703125\n",
      "fin save.\n",
      "epoch 7110\n",
      "test_train\n",
      "train mean loss=61815.772135416664\n",
      "test_test\n",
      "test mean loss=88217.0\n",
      "fin save.\n",
      "epoch 7111\n",
      "test_train\n",
      "train mean loss=62652.002213541666\n",
      "test_test\n",
      "test mean loss=88247.6796875\n",
      "fin save.\n",
      "epoch 7112\n",
      "test_train\n",
      "train mean loss=62353.421875\n",
      "test_test\n",
      "test mean loss=88108.140625\n",
      "fin save.\n",
      "epoch 7113\n",
      "test_train\n",
      "train mean loss=62442.06354166667\n",
      "test_test\n",
      "test mean loss=88378.25\n",
      "fin save.\n",
      "epoch 7114\n",
      "test_train\n",
      "train mean loss=62670.35338541667\n",
      "test_test\n",
      "test mean loss=88104.01171875\n",
      "fin save.\n",
      "epoch 7115\n",
      "test_train\n",
      "train mean loss=62645.915364583336\n",
      "test_test\n",
      "test mean loss=88045.1640625\n",
      "fin save.\n",
      "epoch 7116\n",
      "test_train\n",
      "train mean loss=62708.76744791667\n",
      "test_test\n",
      "test mean loss=88179.02734375\n",
      "fin save.\n",
      "epoch 7117\n",
      "test_train\n",
      "train mean loss=61893.777994791664\n",
      "test_test\n",
      "test mean loss=87851.65234375\n",
      "fin save.\n",
      "epoch 7118\n",
      "test_train\n",
      "train mean loss=62901.28854166667\n",
      "test_test\n",
      "test mean loss=88007.26171875\n",
      "fin save.\n",
      "epoch 7119\n",
      "test_train\n",
      "train mean loss=62153.76796875\n",
      "test_test\n",
      "test mean loss=88190.02734375\n",
      "fin save.\n",
      "epoch 7120\n",
      "test_train\n",
      "train mean loss=62196.320572916666\n",
      "test_test\n",
      "test mean loss=88082.2734375\n",
      "fin save.\n",
      "epoch 7121\n",
      "test_train\n",
      "train mean loss=61655.464583333334\n",
      "test_test\n",
      "test mean loss=88039.66015625\n",
      "fin save.\n",
      "epoch 7122\n",
      "test_train\n",
      "train mean loss=62237.82890625\n",
      "test_test\n",
      "test mean loss=87967.80078125\n",
      "fin save.\n",
      "epoch 7123\n",
      "test_train\n",
      "train mean loss=61487.846484375\n",
      "test_test\n",
      "test mean loss=88087.60546875\n",
      "fin save.\n",
      "epoch 7124\n",
      "test_train\n",
      "train mean loss=62443.99895833333\n",
      "test_test\n",
      "test mean loss=87979.21875\n",
      "fin save.\n",
      "epoch 7125\n",
      "test_train\n",
      "train mean loss=62706.06236979167\n",
      "test_test\n",
      "test mean loss=87807.21875\n",
      "fin save.\n",
      "epoch 7126\n",
      "test_train\n",
      "train mean loss=62882.691666666666\n",
      "test_test\n",
      "test mean loss=87652.35546875\n",
      "fin save.\n",
      "epoch 7127\n",
      "test_train\n",
      "train mean loss=61283.788802083334\n",
      "test_test\n",
      "test mean loss=87407.0234375\n",
      "fin save.\n",
      "epoch 7128\n",
      "test_train\n",
      "train mean loss=62506.0421875\n",
      "test_test\n",
      "test mean loss=87665.1015625\n",
      "fin save.\n",
      "epoch 7129\n",
      "test_train\n",
      "train mean loss=62190.180989583336\n",
      "test_test\n",
      "test mean loss=87798.2421875\n",
      "fin save.\n",
      "epoch 7130\n",
      "test_train\n",
      "train mean loss=62799.70234375\n",
      "test_test\n",
      "test mean loss=87783.6875\n",
      "fin save.\n",
      "epoch 7131\n",
      "test_train\n",
      "train mean loss=62671.49114583333\n",
      "test_test\n",
      "test mean loss=87695.0078125\n",
      "fin save.\n",
      "epoch 7132\n",
      "test_train\n",
      "train mean loss=62821.24765625\n",
      "test_test\n",
      "test mean loss=87849.12890625\n",
      "fin save.\n",
      "epoch 7133\n",
      "test_train\n",
      "train mean loss=62909.89765625\n",
      "test_test\n",
      "test mean loss=87656.4375\n",
      "fin save.\n",
      "epoch 7134\n",
      "test_train\n",
      "train mean loss=61900.45546875\n",
      "test_test\n",
      "test mean loss=87948.3203125\n",
      "fin save.\n",
      "epoch 7135\n",
      "test_train\n",
      "train mean loss=61934.578125\n",
      "test_test\n",
      "test mean loss=87782.875\n",
      "fin save.\n",
      "epoch 7136\n",
      "test_train\n",
      "train mean loss=62580.66848958333\n",
      "test_test\n",
      "test mean loss=88103.58984375\n",
      "fin save.\n",
      "epoch 7137\n",
      "test_train\n",
      "train mean loss=61358.44453125\n",
      "test_test\n",
      "test mean loss=88075.41796875\n",
      "fin save.\n",
      "epoch 7138\n",
      "test_train\n",
      "train mean loss=62173.959635416664\n",
      "test_test\n",
      "test mean loss=87993.46484375\n",
      "fin save.\n",
      "epoch 7139\n",
      "test_train\n",
      "train mean loss=62083.84583333333\n",
      "test_test\n",
      "test mean loss=88287.00390625\n",
      "fin save.\n",
      "epoch 7140\n",
      "test_train\n",
      "train mean loss=62060.88359375\n",
      "test_test\n",
      "test mean loss=88066.265625\n",
      "fin save.\n",
      "epoch 7141\n",
      "test_train\n",
      "train mean loss=63080.689453125\n",
      "test_test\n",
      "test mean loss=88091.22265625\n",
      "fin save.\n",
      "epoch 7142\n",
      "test_train\n",
      "train mean loss=61653.564192708334\n",
      "test_test\n",
      "test mean loss=87828.80859375\n",
      "fin save.\n",
      "epoch 7143\n",
      "test_train\n",
      "train mean loss=62079.85833333333\n",
      "test_test\n",
      "test mean loss=88088.46875\n",
      "fin save.\n",
      "epoch 7144\n",
      "test_train\n",
      "train mean loss=62389.188151041664\n",
      "test_test\n",
      "test mean loss=88163.55859375\n",
      "fin save.\n",
      "epoch 7145\n",
      "test_train\n",
      "train mean loss=62397.245833333334\n",
      "test_test\n",
      "test mean loss=88059.83984375\n",
      "fin save.\n",
      "epoch 7146\n",
      "test_train\n",
      "train mean loss=62247.02526041667\n",
      "test_test\n",
      "test mean loss=88107.65625\n",
      "fin save.\n",
      "epoch 7147\n",
      "test_train\n",
      "train mean loss=62090.79921875\n",
      "test_test\n",
      "test mean loss=88187.546875\n",
      "fin save.\n",
      "epoch 7148\n",
      "test_train\n",
      "train mean loss=61394.770833333336\n",
      "test_test\n",
      "test mean loss=88220.3671875\n",
      "fin save.\n",
      "epoch 7149\n",
      "test_train\n",
      "train mean loss=61961.358072916664\n",
      "test_test\n",
      "test mean loss=88416.0234375\n",
      "fin save.\n",
      "epoch 7150\n",
      "test_train\n",
      "train mean loss=61923.83828125\n",
      "test_test\n",
      "test mean loss=88015.58984375\n",
      "fin save.\n",
      "epoch 7151\n",
      "test_train\n",
      "train mean loss=62123.52109375\n",
      "test_test\n",
      "test mean loss=87840.86328125\n",
      "fin save.\n",
      "epoch 7152\n",
      "test_train\n",
      "train mean loss=61634.55559895833\n",
      "test_test\n",
      "test mean loss=87860.55859375\n",
      "fin save.\n",
      "epoch 7153\n",
      "test_train\n",
      "train mean loss=60770.844140625\n",
      "test_test\n",
      "test mean loss=88016.73046875\n",
      "fin save.\n",
      "epoch 7154\n",
      "test_train\n",
      "train mean loss=61881.27526041667\n",
      "test_test\n",
      "test mean loss=88053.546875\n",
      "fin save.\n",
      "epoch 7155\n",
      "test_train\n",
      "train mean loss=62434.38984375\n",
      "test_test\n",
      "test mean loss=88086.53125\n",
      "fin save.\n",
      "epoch 7156\n",
      "test_train\n",
      "train mean loss=62574.93359375\n",
      "test_test\n",
      "test mean loss=87925.15625\n",
      "fin save.\n",
      "epoch 7157\n",
      "test_train\n",
      "train mean loss=61991.65416666667\n",
      "test_test\n",
      "test mean loss=87958.65625\n",
      "fin save.\n",
      "epoch 7158\n",
      "test_train\n",
      "train mean loss=61330.3703125\n",
      "test_test\n",
      "test mean loss=87777.8828125\n",
      "fin save.\n",
      "epoch 7159\n",
      "test_train\n",
      "train mean loss=61899.990234375\n",
      "test_test\n",
      "test mean loss=87808.0390625\n",
      "fin save.\n",
      "epoch 7160\n",
      "test_train\n",
      "train mean loss=62171.875\n",
      "test_test\n",
      "test mean loss=87848.06640625\n",
      "fin save.\n",
      "epoch 7161\n",
      "test_train\n",
      "train mean loss=62375.861979166664\n",
      "test_test\n",
      "test mean loss=87981.46875\n",
      "fin save.\n",
      "epoch 7162\n",
      "test_train\n",
      "train mean loss=61848.2609375\n",
      "test_test\n",
      "test mean loss=88078.984375\n",
      "fin save.\n",
      "epoch 7163\n",
      "test_train\n",
      "train mean loss=63831.0578125\n",
      "test_test\n",
      "test mean loss=87977.66796875\n",
      "fin save.\n",
      "epoch 7164\n",
      "test_train\n",
      "train mean loss=63481.80859375\n",
      "test_test\n",
      "test mean loss=87901.60546875\n",
      "fin save.\n",
      "epoch 7165\n",
      "test_train\n",
      "train mean loss=62292.726822916666\n",
      "test_test\n",
      "test mean loss=87803.609375\n",
      "fin save.\n",
      "epoch 7166\n",
      "test_train\n",
      "train mean loss=62104.812239583334\n",
      "test_test\n",
      "test mean loss=87965.47265625\n",
      "fin save.\n",
      "epoch 7167\n",
      "test_train\n",
      "train mean loss=61899.39244791667\n",
      "test_test\n",
      "test mean loss=87441.27734375\n",
      "fin save.\n",
      "epoch 7168\n",
      "test_train\n",
      "train mean loss=61441.289453125\n",
      "test_test\n",
      "test mean loss=88145.44921875\n",
      "fin save.\n",
      "epoch 7169\n",
      "test_train\n",
      "train mean loss=62357.60989583333\n",
      "test_test\n",
      "test mean loss=88104.69140625\n",
      "fin save.\n",
      "epoch 7170\n",
      "test_train\n",
      "train mean loss=63060.377604166664\n",
      "test_test\n",
      "test mean loss=88225.27734375\n",
      "fin save.\n",
      "epoch 7171\n",
      "test_train\n",
      "train mean loss=62114.79244791667\n",
      "test_test\n",
      "test mean loss=88321.32421875\n",
      "fin save.\n",
      "epoch 7172\n",
      "test_train\n",
      "train mean loss=61669.528645833336\n",
      "test_test\n",
      "test mean loss=88382.48046875\n",
      "fin save.\n",
      "epoch 7173\n",
      "test_train\n",
      "train mean loss=62906.083723958334\n",
      "test_test\n",
      "test mean loss=88578.66015625\n",
      "fin save.\n",
      "epoch 7174\n",
      "test_train\n",
      "train mean loss=61911.68606770833\n",
      "test_test\n",
      "test mean loss=88874.921875\n",
      "fin save.\n",
      "epoch 7175\n",
      "test_train\n",
      "train mean loss=61164.36028645833\n",
      "test_test\n",
      "test mean loss=88577.7421875\n",
      "fin save.\n",
      "epoch 7176\n",
      "test_train\n",
      "train mean loss=62265.333333333336\n",
      "test_test\n",
      "test mean loss=88706.4921875\n",
      "fin save.\n",
      "epoch 7177\n",
      "test_train\n",
      "train mean loss=61982.88854166667\n",
      "test_test\n",
      "test mean loss=88675.21484375\n",
      "fin save.\n",
      "epoch 7178\n",
      "test_train\n",
      "train mean loss=62663.788802083334\n",
      "test_test\n",
      "test mean loss=88587.24609375\n",
      "fin save.\n",
      "epoch 7179\n",
      "test_train\n",
      "train mean loss=62932.428385416664\n",
      "test_test\n",
      "test mean loss=88814.2734375\n",
      "fin save.\n",
      "epoch 7180\n",
      "test_train\n",
      "train mean loss=62217.355208333334\n",
      "test_test\n",
      "test mean loss=88873.7265625\n",
      "fin save.\n",
      "epoch 7181\n",
      "test_train\n",
      "train mean loss=61900.142317708334\n",
      "test_test\n",
      "test mean loss=88611.6796875\n",
      "fin save.\n",
      "epoch 7182\n",
      "test_train\n",
      "train mean loss=62190.68125\n",
      "test_test\n",
      "test mean loss=89014.57421875\n",
      "fin save.\n",
      "epoch 7183\n",
      "test_train\n",
      "train mean loss=61903.93072916667\n",
      "test_test\n",
      "test mean loss=88808.5859375\n",
      "fin save.\n",
      "epoch 7184\n",
      "test_train\n",
      "train mean loss=62990.959635416664\n",
      "test_test\n",
      "test mean loss=88628.640625\n",
      "fin save.\n",
      "epoch 7185\n",
      "test_train\n",
      "train mean loss=61616.401041666664\n",
      "test_test\n",
      "test mean loss=88786.53125\n",
      "fin save.\n",
      "epoch 7186\n",
      "test_train\n",
      "train mean loss=62028.081380208336\n",
      "test_test\n",
      "test mean loss=88577.35546875\n",
      "fin save.\n",
      "epoch 7187\n",
      "test_train\n",
      "train mean loss=62062.97369791667\n",
      "test_test\n",
      "test mean loss=88628.3515625\n",
      "fin save.\n",
      "epoch 7188\n",
      "test_train\n",
      "train mean loss=61252.98190104167\n",
      "test_test\n",
      "test mean loss=88540.23046875\n",
      "fin save.\n",
      "epoch 7189\n",
      "test_train\n",
      "train mean loss=61856.548828125\n",
      "test_test\n",
      "test mean loss=89076.0390625\n",
      "fin save.\n",
      "epoch 7190\n",
      "test_train\n",
      "train mean loss=61418.35338541667\n",
      "test_test\n",
      "test mean loss=88882.453125\n",
      "fin save.\n",
      "epoch 7191\n",
      "test_train\n",
      "train mean loss=61768.382552083334\n",
      "test_test\n",
      "test mean loss=88763.21484375\n",
      "fin save.\n",
      "epoch 7192\n",
      "test_train\n",
      "train mean loss=62738.847916666666\n",
      "test_test\n",
      "test mean loss=88724.19140625\n",
      "fin save.\n",
      "epoch 7193\n",
      "test_train\n",
      "train mean loss=61619.812760416666\n",
      "test_test\n",
      "test mean loss=88816.25\n",
      "fin save.\n",
      "epoch 7194\n",
      "test_train\n",
      "train mean loss=62024.60950520833\n",
      "test_test\n",
      "test mean loss=88641.1015625\n",
      "fin save.\n",
      "epoch 7195\n",
      "test_train\n",
      "train mean loss=62468.17486979167\n",
      "test_test\n",
      "test mean loss=88708.78515625\n",
      "fin save.\n",
      "epoch 7196\n",
      "test_train\n",
      "train mean loss=61448.1046875\n",
      "test_test\n",
      "test mean loss=88572.89453125\n",
      "fin save.\n",
      "epoch 7197\n",
      "test_train\n",
      "train mean loss=61932.092057291666\n",
      "test_test\n",
      "test mean loss=88648.51953125\n",
      "fin save.\n",
      "epoch 7198\n",
      "test_train\n",
      "train mean loss=62533.23333333333\n",
      "test_test\n",
      "test mean loss=88660.89453125\n",
      "fin save.\n",
      "epoch 7199\n",
      "test_train\n",
      "train mean loss=62778.815625\n",
      "test_test\n",
      "test mean loss=88421.80078125\n",
      "fin save.\n",
      "epoch 7200\n",
      "test_train\n",
      "train mean loss=62464.78177083333\n",
      "test_test\n",
      "test mean loss=88499.73046875\n",
      "fin save.\n",
      "epoch 7201\n",
      "test_train\n",
      "train mean loss=62059.134114583336\n",
      "test_test\n",
      "test mean loss=88826.625\n",
      "fin save.\n",
      "epoch 7202\n",
      "test_train\n",
      "train mean loss=62896.833984375\n",
      "test_test\n",
      "test mean loss=88972.36328125\n",
      "fin save.\n",
      "epoch 7203\n",
      "test_train\n",
      "train mean loss=61701.01901041667\n",
      "test_test\n",
      "test mean loss=89102.71875\n",
      "fin save.\n",
      "epoch 7204\n",
      "test_train\n",
      "train mean loss=62342.94192708333\n",
      "test_test\n",
      "test mean loss=88984.52734375\n",
      "fin save.\n",
      "epoch 7205\n",
      "test_train\n",
      "train mean loss=62861.902734375\n",
      "test_test\n",
      "test mean loss=88817.3046875\n",
      "fin save.\n",
      "epoch 7206\n",
      "test_train\n",
      "train mean loss=61901.11419270833\n",
      "test_test\n",
      "test mean loss=89090.3046875\n",
      "fin save.\n",
      "epoch 7207\n",
      "test_train\n",
      "train mean loss=62524.577734375\n",
      "test_test\n",
      "test mean loss=89022.32421875\n",
      "fin save.\n",
      "epoch 7208\n",
      "test_train\n",
      "train mean loss=62319.21484375\n",
      "test_test\n",
      "test mean loss=88946.40625\n",
      "fin save.\n",
      "epoch 7209\n",
      "test_train\n",
      "train mean loss=63563.55260416667\n",
      "test_test\n",
      "test mean loss=89070.171875\n",
      "fin save.\n",
      "epoch 7210\n",
      "test_train\n",
      "train mean loss=62506.992578125\n",
      "test_test\n",
      "test mean loss=89068.984375\n",
      "fin save.\n",
      "epoch 7211\n",
      "test_train\n",
      "train mean loss=62086.4609375\n",
      "test_test\n",
      "test mean loss=88964.32421875\n",
      "fin save.\n",
      "epoch 7212\n",
      "test_train\n",
      "train mean loss=61818.16354166667\n",
      "test_test\n",
      "test mean loss=88917.38671875\n",
      "fin save.\n",
      "epoch 7213\n",
      "test_train\n",
      "train mean loss=62273.53984375\n",
      "test_test\n",
      "test mean loss=89207.8515625\n",
      "fin save.\n",
      "epoch 7214\n",
      "test_train\n",
      "train mean loss=62879.96276041667\n",
      "test_test\n",
      "test mean loss=89198.95703125\n",
      "fin save.\n",
      "epoch 7215\n",
      "test_train\n",
      "train mean loss=62663.838151041666\n",
      "test_test\n",
      "test mean loss=89172.8125\n",
      "fin save.\n",
      "epoch 7216\n",
      "test_train\n",
      "train mean loss=62173.1609375\n",
      "test_test\n",
      "test mean loss=89055.70703125\n",
      "fin save.\n",
      "epoch 7217\n",
      "test_train\n",
      "train mean loss=62118.905989583334\n",
      "test_test\n",
      "test mean loss=88977.9921875\n",
      "fin save.\n",
      "epoch 7218\n",
      "test_train\n",
      "train mean loss=62668.80260416667\n",
      "test_test\n",
      "test mean loss=88975.07421875\n",
      "fin save.\n",
      "epoch 7219\n",
      "test_train\n",
      "train mean loss=63215.97604166667\n",
      "test_test\n",
      "test mean loss=88973.46484375\n",
      "fin save.\n",
      "epoch 7220\n",
      "test_train\n",
      "train mean loss=61576.22473958333\n",
      "test_test\n",
      "test mean loss=88905.69921875\n",
      "fin save.\n",
      "epoch 7221\n",
      "test_train\n",
      "train mean loss=62386.26354166667\n",
      "test_test\n",
      "test mean loss=88881.49609375\n",
      "fin save.\n",
      "epoch 7222\n",
      "test_train\n",
      "train mean loss=62419.28619791667\n",
      "test_test\n",
      "test mean loss=88898.5546875\n",
      "fin save.\n",
      "epoch 7223\n",
      "test_train\n",
      "train mean loss=62763.506510416664\n",
      "test_test\n",
      "test mean loss=89044.07421875\n",
      "fin save.\n",
      "epoch 7224\n",
      "test_train\n",
      "train mean loss=61020.519791666666\n",
      "test_test\n",
      "test mean loss=88195.671875\n",
      "fin save.\n",
      "epoch 7225\n",
      "test_train\n",
      "train mean loss=62348.013932291666\n",
      "test_test\n",
      "test mean loss=88220.390625\n",
      "fin save.\n",
      "epoch 7226\n",
      "test_train\n",
      "train mean loss=62613.084765625\n",
      "test_test\n",
      "test mean loss=88261.9375\n",
      "fin save.\n",
      "epoch 7227\n",
      "test_train\n",
      "train mean loss=61830.45013020833\n",
      "test_test\n",
      "test mean loss=88154.6328125\n",
      "fin save.\n",
      "epoch 7228\n",
      "test_train\n",
      "train mean loss=62303.2234375\n",
      "test_test\n",
      "test mean loss=88171.24609375\n",
      "fin save.\n",
      "epoch 7229\n",
      "test_train\n",
      "train mean loss=61188.68046875\n",
      "test_test\n",
      "test mean loss=87993.19140625\n",
      "fin save.\n",
      "epoch 7230\n",
      "test_train\n",
      "train mean loss=62014.236067708334\n",
      "test_test\n",
      "test mean loss=87612.859375\n",
      "fin save.\n",
      "epoch 7231\n",
      "test_train\n",
      "train mean loss=61377.35989583333\n",
      "test_test\n",
      "test mean loss=88085.71484375\n",
      "fin save.\n",
      "epoch 7232\n",
      "test_train\n",
      "train mean loss=62440.03033854167\n",
      "test_test\n",
      "test mean loss=88040.59765625\n",
      "fin save.\n",
      "epoch 7233\n",
      "test_train\n",
      "train mean loss=62341.21536458333\n",
      "test_test\n",
      "test mean loss=87579.66015625\n",
      "fin save.\n",
      "epoch 7234\n",
      "test_train\n",
      "train mean loss=61995.175\n",
      "test_test\n",
      "test mean loss=87639.09375\n",
      "fin save.\n",
      "epoch 7235\n",
      "test_train\n",
      "train mean loss=62685.770182291664\n",
      "test_test\n",
      "test mean loss=87748.9765625\n",
      "fin save.\n",
      "epoch 7236\n",
      "test_train\n",
      "train mean loss=62138.843489583334\n",
      "test_test\n",
      "test mean loss=87780.9921875\n",
      "fin save.\n",
      "epoch 7237\n",
      "test_train\n",
      "train mean loss=60829.421875\n",
      "test_test\n",
      "test mean loss=87991.40234375\n",
      "fin save.\n",
      "epoch 7238\n",
      "test_train\n",
      "train mean loss=61498.77109375\n",
      "test_test\n",
      "test mean loss=88199.83984375\n",
      "fin save.\n",
      "epoch 7239\n",
      "test_train\n",
      "train mean loss=62052.75546875\n",
      "test_test\n",
      "test mean loss=88049.875\n",
      "fin save.\n",
      "epoch 7240\n",
      "test_train\n",
      "train mean loss=61848.84921875\n",
      "test_test\n",
      "test mean loss=87936.11328125\n",
      "fin save.\n",
      "epoch 7241\n",
      "test_train\n",
      "train mean loss=61146.54088541667\n",
      "test_test\n",
      "test mean loss=88066.53515625\n",
      "fin save.\n",
      "epoch 7242\n",
      "test_train\n",
      "train mean loss=61664.802734375\n",
      "test_test\n",
      "test mean loss=88129.203125\n",
      "fin save.\n",
      "epoch 7243\n",
      "test_train\n",
      "train mean loss=62165.52421875\n",
      "test_test\n",
      "test mean loss=87908.8828125\n",
      "fin save.\n",
      "epoch 7244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_train\n",
      "train mean loss=61151.31744791667\n",
      "test_test\n",
      "test mean loss=87946.09765625\n",
      "fin save.\n",
      "epoch 7245\n",
      "test_train\n",
      "train mean loss=62677.07135416667\n",
      "test_test\n",
      "test mean loss=87467.5234375\n",
      "fin save.\n",
      "epoch 7246\n",
      "test_train\n",
      "train mean loss=62309.74296875\n",
      "test_test\n",
      "test mean loss=87435.3125\n",
      "fin save.\n",
      "epoch 7247\n",
      "test_train\n",
      "train mean loss=61979.628125\n",
      "test_test\n",
      "test mean loss=87612.953125\n",
      "fin save.\n",
      "epoch 7248\n",
      "test_train\n",
      "train mean loss=61304.394791666666\n",
      "test_test\n",
      "test mean loss=87868.3125\n",
      "fin save.\n",
      "epoch 7249\n",
      "test_train\n",
      "train mean loss=61804.584375\n",
      "test_test\n",
      "test mean loss=87734.125\n",
      "fin save.\n",
      "epoch 7250\n",
      "test_train\n",
      "train mean loss=61946.159765625\n",
      "test_test\n",
      "test mean loss=87819.625\n",
      "fin save.\n",
      "epoch 7251\n",
      "test_train\n",
      "train mean loss=62439.1875\n",
      "test_test\n",
      "test mean loss=87861.12109375\n",
      "fin save.\n",
      "epoch 7252\n",
      "test_train\n",
      "train mean loss=61869.62109375\n",
      "test_test\n",
      "test mean loss=87898.41015625\n",
      "fin save.\n",
      "epoch 7253\n",
      "test_train\n",
      "train mean loss=61150.82916666667\n",
      "test_test\n",
      "test mean loss=87950.12109375\n",
      "fin save.\n",
      "epoch 7254\n",
      "test_train\n",
      "train mean loss=62267.25104166667\n",
      "test_test\n",
      "test mean loss=87970.984375\n",
      "fin save.\n",
      "epoch 7255\n",
      "test_train\n",
      "train mean loss=62021.51380208333\n",
      "test_test\n",
      "test mean loss=87969.9296875\n",
      "fin save.\n",
      "epoch 7256\n",
      "test_train\n",
      "train mean loss=62692.66692708333\n",
      "test_test\n",
      "test mean loss=88090.9921875\n",
      "fin save.\n",
      "epoch 7257\n",
      "test_train\n",
      "train mean loss=62191.204427083336\n",
      "test_test\n",
      "test mean loss=87950.6796875\n",
      "fin save.\n",
      "epoch 7258\n",
      "test_train\n",
      "train mean loss=61568.718098958336\n",
      "test_test\n",
      "test mean loss=87922.4453125\n",
      "fin save.\n",
      "epoch 7259\n",
      "test_train\n",
      "train mean loss=62399.627604166664\n",
      "test_test\n",
      "test mean loss=87857.3984375\n",
      "fin save.\n",
      "epoch 7260\n",
      "test_train\n",
      "train mean loss=62369.77552083333\n",
      "test_test\n",
      "test mean loss=88034.44140625\n",
      "fin save.\n",
      "epoch 7261\n",
      "test_train\n",
      "train mean loss=61706.09947916667\n",
      "test_test\n",
      "test mean loss=87954.6953125\n",
      "fin save.\n",
      "epoch 7262\n",
      "test_train\n",
      "train mean loss=61651.93854166667\n",
      "test_test\n",
      "test mean loss=87920.00390625\n",
      "fin save.\n",
      "epoch 7263\n",
      "test_train\n",
      "train mean loss=61592.93072916667\n",
      "test_test\n",
      "test mean loss=87814.13671875\n",
      "fin save.\n",
      "epoch 7264\n",
      "test_train\n",
      "train mean loss=62852.81041666667\n",
      "test_test\n",
      "test mean loss=87989.98828125\n",
      "fin save.\n",
      "epoch 7265\n",
      "test_train\n",
      "train mean loss=61415.844010416666\n",
      "test_test\n",
      "test mean loss=87968.5625\n",
      "fin save.\n",
      "epoch 7266\n",
      "test_train\n",
      "train mean loss=61306.3484375\n",
      "test_test\n",
      "test mean loss=87722.02734375\n",
      "fin save.\n",
      "epoch 7267\n",
      "test_train\n",
      "train mean loss=62308.969401041664\n",
      "test_test\n",
      "test mean loss=87788.484375\n",
      "fin save.\n",
      "epoch 7268\n",
      "test_train\n",
      "train mean loss=61687.901692708336\n",
      "test_test\n",
      "test mean loss=87706.26953125\n",
      "fin save.\n",
      "epoch 7269\n",
      "test_train\n",
      "train mean loss=62216.50078125\n",
      "test_test\n",
      "test mean loss=88017.8515625\n",
      "fin save.\n",
      "epoch 7270\n",
      "test_train\n",
      "train mean loss=62716.000260416666\n",
      "test_test\n",
      "test mean loss=87870.6875\n",
      "fin save.\n",
      "epoch 7271\n",
      "test_train\n",
      "train mean loss=62524.910416666666\n",
      "test_test\n",
      "test mean loss=87764.4375\n",
      "fin save.\n",
      "epoch 7272\n",
      "test_train\n",
      "train mean loss=61885.815625\n",
      "test_test\n",
      "test mean loss=87784.59375\n",
      "fin save.\n",
      "epoch 7273\n",
      "test_train\n",
      "train mean loss=61172.78723958333\n",
      "test_test\n",
      "test mean loss=87784.6953125\n",
      "fin save.\n",
      "epoch 7274\n",
      "test_train\n",
      "train mean loss=62037.96640625\n",
      "test_test\n",
      "test mean loss=87668.18359375\n",
      "fin save.\n",
      "epoch 7275\n",
      "test_train\n",
      "train mean loss=62216.179296875\n",
      "test_test\n",
      "test mean loss=87928.2890625\n",
      "fin save.\n",
      "epoch 7276\n",
      "test_train\n",
      "train mean loss=62694.21328125\n",
      "test_test\n",
      "test mean loss=87889.890625\n",
      "fin save.\n",
      "epoch 7277\n",
      "test_train\n",
      "train mean loss=61675.710677083334\n",
      "test_test\n",
      "test mean loss=87806.78515625\n",
      "fin save.\n",
      "epoch 7278\n",
      "test_train\n",
      "train mean loss=62832.59296875\n",
      "test_test\n",
      "test mean loss=88076.796875\n",
      "fin save.\n",
      "epoch 7279\n",
      "test_train\n",
      "train mean loss=62794.25598958333\n",
      "test_test\n",
      "test mean loss=87998.046875\n",
      "fin save.\n",
      "epoch 7280\n",
      "test_train\n",
      "train mean loss=62283.898828125\n",
      "test_test\n",
      "test mean loss=88189.21484375\n",
      "fin save.\n",
      "epoch 7281\n",
      "test_train\n",
      "train mean loss=62155.87942708333\n",
      "test_test\n",
      "test mean loss=88162.921875\n",
      "fin save.\n",
      "epoch 7282\n",
      "test_train\n",
      "train mean loss=63017.46145833333\n",
      "test_test\n",
      "test mean loss=88385.07421875\n",
      "fin save.\n",
      "epoch 7283\n",
      "test_train\n",
      "train mean loss=61707.56145833333\n",
      "test_test\n",
      "test mean loss=88246.34765625\n",
      "fin save.\n",
      "epoch 7284\n",
      "test_train\n",
      "train mean loss=62358.28671875\n",
      "test_test\n",
      "test mean loss=88128.95703125\n",
      "fin save.\n",
      "epoch 7285\n",
      "test_train\n",
      "train mean loss=62299.54986979167\n",
      "test_test\n",
      "test mean loss=88219.51953125\n",
      "fin save.\n",
      "epoch 7286\n",
      "test_train\n",
      "train mean loss=61860.526041666664\n",
      "test_test\n",
      "test mean loss=88126.859375\n",
      "fin save.\n",
      "epoch 7287\n",
      "test_train\n",
      "train mean loss=62270.63072916667\n",
      "test_test\n",
      "test mean loss=88088.35546875\n",
      "fin save.\n",
      "epoch 7288\n",
      "test_train\n",
      "train mean loss=62010.789453125\n",
      "test_test\n",
      "test mean loss=88245.5703125\n",
      "fin save.\n",
      "epoch 7289\n",
      "test_train\n",
      "train mean loss=62502.63177083333\n",
      "test_test\n",
      "test mean loss=88370.96484375\n",
      "fin save.\n",
      "epoch 7290\n",
      "test_train\n",
      "train mean loss=62982.56979166667\n",
      "test_test\n",
      "test mean loss=88285.0859375\n",
      "fin save.\n",
      "epoch 7291\n",
      "test_train\n",
      "train mean loss=62528.37252604167\n",
      "test_test\n",
      "test mean loss=88427.453125\n",
      "fin save.\n",
      "epoch 7292\n",
      "test_train\n",
      "train mean loss=61702.50091145833\n",
      "test_test\n",
      "test mean loss=88469.8828125\n",
      "fin save.\n",
      "epoch 7293\n",
      "test_train\n",
      "train mean loss=61192.51875\n",
      "test_test\n",
      "test mean loss=88196.1875\n",
      "fin save.\n",
      "epoch 7294\n",
      "test_train\n",
      "train mean loss=63124.19778645833\n",
      "test_test\n",
      "test mean loss=88020.37109375\n",
      "fin save.\n",
      "epoch 7295\n",
      "test_train\n",
      "train mean loss=62189.05364583333\n",
      "test_test\n",
      "test mean loss=87983.04296875\n",
      "fin save.\n",
      "epoch 7296\n",
      "test_train\n",
      "train mean loss=62810.61432291667\n",
      "test_test\n",
      "test mean loss=87904.78515625\n",
      "fin save.\n",
      "epoch 7297\n",
      "test_train\n",
      "train mean loss=62227.16783854167\n",
      "test_test\n",
      "test mean loss=88045.265625\n",
      "fin save.\n",
      "epoch 7298\n",
      "test_train\n",
      "train mean loss=61985.870442708336\n",
      "test_test\n",
      "test mean loss=87948.82421875\n",
      "fin save.\n",
      "epoch 7299\n",
      "test_train\n",
      "train mean loss=62177.44283854167\n",
      "test_test\n",
      "test mean loss=87944.33203125\n",
      "fin save.\n",
      "epoch 7300\n",
      "test_train\n",
      "train mean loss=62804.78723958333\n",
      "test_test\n",
      "test mean loss=87894.00390625\n",
      "fin save.\n",
      "epoch 7301\n",
      "test_train\n",
      "train mean loss=62484.13619791667\n",
      "test_test\n",
      "test mean loss=87826.2890625\n",
      "fin save.\n",
      "epoch 7302\n",
      "test_train\n",
      "train mean loss=62319.0015625\n",
      "test_test\n",
      "test mean loss=87940.11328125\n",
      "fin save.\n",
      "epoch 7303\n",
      "test_train\n",
      "train mean loss=61646.420572916664\n",
      "test_test\n",
      "test mean loss=87864.0859375\n",
      "fin save.\n",
      "epoch 7304\n",
      "test_train\n",
      "train mean loss=62177.0953125\n",
      "test_test\n",
      "test mean loss=87851.7734375\n",
      "fin save.\n",
      "epoch 7305\n",
      "test_train\n",
      "train mean loss=62681.69713541667\n",
      "test_test\n",
      "test mean loss=87566.92578125\n",
      "fin save.\n",
      "epoch 7306\n",
      "test_train\n",
      "train mean loss=62083.09166666667\n",
      "test_test\n",
      "test mean loss=88032.62109375\n",
      "fin save.\n",
      "epoch 7307\n",
      "test_train\n",
      "train mean loss=61901.92890625\n",
      "test_test\n",
      "test mean loss=87926.69921875\n",
      "fin save.\n",
      "epoch 7308\n",
      "test_train\n",
      "train mean loss=62207.116927083334\n",
      "test_test\n",
      "test mean loss=87920.26953125\n",
      "fin save.\n",
      "epoch 7309\n",
      "test_train\n",
      "train mean loss=61933.426953125\n",
      "test_test\n",
      "test mean loss=87821.32421875\n",
      "fin save.\n",
      "epoch 7310\n",
      "test_train\n",
      "train mean loss=61603.39140625\n",
      "test_test\n",
      "test mean loss=87910.79296875\n",
      "fin save.\n",
      "epoch 7311\n",
      "test_train\n",
      "train mean loss=62128.871354166666\n",
      "test_test\n",
      "test mean loss=87766.2578125\n",
      "fin save.\n",
      "epoch 7312\n",
      "test_train\n",
      "train mean loss=62693.79140625\n",
      "test_test\n",
      "test mean loss=87693.0546875\n",
      "fin save.\n",
      "epoch 7313\n",
      "test_train\n",
      "train mean loss=62015.616796875\n",
      "test_test\n",
      "test mean loss=87589.29296875\n",
      "fin save.\n",
      "epoch 7314\n",
      "test_train\n",
      "train mean loss=61510.41809895833\n",
      "test_test\n",
      "test mean loss=87557.875\n",
      "fin save.\n",
      "epoch 7315\n",
      "test_train\n",
      "train mean loss=61858.18541666667\n",
      "test_test\n",
      "test mean loss=87612.1015625\n",
      "fin save.\n",
      "epoch 7316\n",
      "test_train\n",
      "train mean loss=60987.249609375\n",
      "test_test\n",
      "test mean loss=87825.64453125\n",
      "fin save.\n",
      "epoch 7317\n",
      "test_train\n",
      "train mean loss=62800.55703125\n",
      "test_test\n",
      "test mean loss=87686.015625\n",
      "fin save.\n",
      "epoch 7318\n",
      "test_train\n",
      "train mean loss=62228.46796875\n",
      "test_test\n",
      "test mean loss=87814.46484375\n",
      "fin save.\n",
      "epoch 7319\n",
      "test_train\n",
      "train mean loss=62325.11419270833\n",
      "test_test\n",
      "test mean loss=87813.01953125\n",
      "fin save.\n",
      "epoch 7320\n",
      "test_train\n",
      "train mean loss=61686.074479166666\n",
      "test_test\n",
      "test mean loss=87745.0390625\n",
      "fin save.\n",
      "epoch 7321\n",
      "test_train\n",
      "train mean loss=63032.25729166667\n",
      "test_test\n",
      "test mean loss=87760.671875\n",
      "fin save.\n",
      "epoch 7322\n",
      "test_train\n",
      "train mean loss=61985.5390625\n",
      "test_test\n",
      "test mean loss=87829.6328125\n",
      "fin save.\n",
      "epoch 7323\n",
      "test_train\n",
      "train mean loss=62571.38763020833\n",
      "test_test\n",
      "test mean loss=87703.65625\n",
      "fin save.\n",
      "epoch 7324\n",
      "test_train\n",
      "train mean loss=62027.39505208333\n",
      "test_test\n",
      "test mean loss=87738.65625\n",
      "fin save.\n",
      "epoch 7325\n",
      "test_train\n",
      "train mean loss=61389.64140625\n",
      "test_test\n",
      "test mean loss=87652.5703125\n",
      "fin save.\n",
      "epoch 7326\n",
      "test_train\n",
      "train mean loss=62027.48359375\n",
      "test_test\n",
      "test mean loss=87580.53515625\n",
      "fin save.\n",
      "epoch 7327\n",
      "test_train\n",
      "train mean loss=62338.41328125\n",
      "test_test\n",
      "test mean loss=87644.5078125\n",
      "fin save.\n",
      "epoch 7328\n",
      "test_train\n",
      "train mean loss=62495.331380208336\n",
      "test_test\n",
      "test mean loss=87934.9453125\n",
      "fin save.\n",
      "epoch 7329\n",
      "test_train\n",
      "train mean loss=63261.622395833336\n",
      "test_test\n",
      "test mean loss=87681.203125\n",
      "fin save.\n",
      "epoch 7330\n",
      "test_train\n",
      "train mean loss=64012.33411458333\n",
      "test_test\n",
      "test mean loss=87402.14453125\n",
      "fin save.\n",
      "epoch 7331\n",
      "test_train\n",
      "train mean loss=62995.08411458333\n",
      "test_test\n",
      "test mean loss=87633.4375\n",
      "fin save.\n",
      "epoch 7332\n",
      "test_train\n",
      "train mean loss=62266.04674479167\n",
      "test_test\n",
      "test mean loss=87836.76953125\n",
      "fin save.\n",
      "epoch 7333\n",
      "test_train\n",
      "train mean loss=61866.71770833333\n",
      "test_test\n",
      "test mean loss=87243.6015625\n",
      "fin save.\n",
      "epoch 7334\n",
      "test_train\n",
      "train mean loss=61834.989583333336\n",
      "test_test\n",
      "test mean loss=87158.828125\n",
      "fin save.\n",
      "epoch 7335\n",
      "test_train\n",
      "train mean loss=61526.64375\n",
      "test_test\n",
      "test mean loss=87291.2578125\n",
      "fin save.\n",
      "epoch 7336\n",
      "test_train\n",
      "train mean loss=62783.633984375\n",
      "test_test\n",
      "test mean loss=87276.83203125\n",
      "fin save.\n",
      "epoch 7337\n",
      "test_train\n",
      "train mean loss=61160.033984375\n",
      "test_test\n",
      "test mean loss=87298.71484375\n",
      "fin save.\n",
      "epoch 7338\n",
      "test_train\n",
      "train mean loss=62259.235677083336\n",
      "test_test\n",
      "test mean loss=87949.60546875\n",
      "fin save.\n",
      "epoch 7339\n",
      "test_train\n",
      "train mean loss=61723.37200520833\n",
      "test_test\n",
      "test mean loss=87869.1796875\n",
      "fin save.\n",
      "epoch 7340\n",
      "test_train\n",
      "train mean loss=61443.368489583336\n",
      "test_test\n",
      "test mean loss=88099.69921875\n",
      "fin save.\n",
      "epoch 7341\n",
      "test_train\n",
      "train mean loss=61627.52825520833\n",
      "test_test\n",
      "test mean loss=87992.13671875\n",
      "fin save.\n",
      "epoch 7342\n",
      "test_train\n",
      "train mean loss=62736.06041666667\n",
      "test_test\n",
      "test mean loss=88102.1796875\n",
      "fin save.\n",
      "epoch 7343\n",
      "test_train\n",
      "train mean loss=62644.077864583334\n",
      "test_test\n",
      "test mean loss=88189.08984375\n",
      "fin save.\n",
      "epoch 7344\n",
      "test_train\n",
      "train mean loss=61800.956770833334\n",
      "test_test\n",
      "test mean loss=87885.41796875\n",
      "fin save.\n",
      "epoch 7345\n",
      "test_train\n",
      "train mean loss=61971.46796875\n",
      "test_test\n",
      "test mean loss=87816.8515625\n",
      "fin save.\n",
      "epoch 7346\n",
      "test_train\n",
      "train mean loss=62121.04244791667\n",
      "test_test\n",
      "test mean loss=87546.109375\n",
      "fin save.\n",
      "epoch 7347\n",
      "test_train\n",
      "train mean loss=61147.346354166664\n",
      "test_test\n",
      "test mean loss=87370.9453125\n",
      "fin save.\n",
      "epoch 7348\n",
      "test_train\n",
      "train mean loss=61927.216145833336\n",
      "test_test\n",
      "test mean loss=87435.72265625\n",
      "fin save.\n",
      "epoch 7349\n",
      "test_train\n",
      "train mean loss=62017.990234375\n",
      "test_test\n",
      "test mean loss=87333.79296875\n",
      "fin save.\n",
      "epoch 7350\n",
      "test_train\n",
      "train mean loss=61450.45234375\n",
      "test_test\n",
      "test mean loss=87555.0703125\n",
      "fin save.\n",
      "epoch 7351\n",
      "test_train\n",
      "train mean loss=62766.6375\n",
      "test_test\n",
      "test mean loss=87923.2734375\n",
      "fin save.\n",
      "epoch 7352\n",
      "test_train\n",
      "train mean loss=62060.80963541667\n",
      "test_test\n",
      "test mean loss=87590.17578125\n",
      "fin save.\n",
      "epoch 7353\n",
      "test_train\n",
      "train mean loss=62510.64140625\n",
      "test_test\n",
      "test mean loss=87576.1875\n",
      "fin save.\n",
      "epoch 7354\n",
      "test_train\n",
      "train mean loss=63065.347395833334\n",
      "test_test\n",
      "test mean loss=87870.2265625\n",
      "fin save.\n",
      "epoch 7355\n",
      "test_train\n",
      "train mean loss=61467.753125\n",
      "test_test\n",
      "test mean loss=88136.21484375\n",
      "fin save.\n",
      "epoch 7356\n",
      "test_train\n",
      "train mean loss=61182.683333333334\n",
      "test_test\n",
      "test mean loss=88222.375\n",
      "fin save.\n",
      "epoch 7357\n",
      "test_train\n",
      "train mean loss=62016.192708333336\n",
      "test_test\n",
      "test mean loss=88179.15625\n",
      "fin save.\n",
      "epoch 7358\n",
      "test_train\n",
      "train mean loss=63247.08489583333\n",
      "test_test\n",
      "test mean loss=87469.01171875\n",
      "fin save.\n",
      "epoch 7359\n",
      "test_train\n",
      "train mean loss=63282.814713541666\n",
      "test_test\n",
      "test mean loss=87643.4609375\n",
      "fin save.\n",
      "epoch 7360\n",
      "test_train\n",
      "train mean loss=63022.3171875\n",
      "test_test\n",
      "test mean loss=87490.99609375\n",
      "fin save.\n",
      "epoch 7361\n",
      "test_train\n",
      "train mean loss=62195.316145833334\n",
      "test_test\n",
      "test mean loss=87499.50390625\n",
      "fin save.\n",
      "epoch 7362\n",
      "test_train\n",
      "train mean loss=62639.507552083334\n",
      "test_test\n",
      "test mean loss=87389.953125\n",
      "fin save.\n",
      "epoch 7363\n",
      "test_train\n",
      "train mean loss=63246.07760416667\n",
      "test_test\n",
      "test mean loss=87448.84765625\n",
      "fin save.\n",
      "epoch 7364\n",
      "test_train\n",
      "train mean loss=62699.464583333334\n",
      "test_test\n",
      "test mean loss=87653.046875\n",
      "fin save.\n",
      "epoch 7365\n",
      "test_train\n",
      "train mean loss=62271.770833333336\n",
      "test_test\n",
      "test mean loss=87775.27734375\n",
      "fin save.\n",
      "epoch 7366\n",
      "test_train\n",
      "train mean loss=62575.78046875\n",
      "test_test\n",
      "test mean loss=87458.33203125\n",
      "fin save.\n",
      "epoch 7367\n",
      "test_train\n",
      "train mean loss=62066.17890625\n",
      "test_test\n",
      "test mean loss=87224.58984375\n",
      "fin save.\n",
      "epoch 7368\n",
      "test_train\n",
      "train mean loss=62988.652604166666\n",
      "test_test\n",
      "test mean loss=87132.6953125\n",
      "fin save.\n",
      "epoch 7369\n",
      "test_train\n",
      "train mean loss=61708.30130208333\n",
      "test_test\n",
      "test mean loss=86971.1875\n",
      "fin save.\n",
      "epoch 7370\n",
      "test_train\n",
      "train mean loss=62132.860677083336\n",
      "test_test\n",
      "test mean loss=87060.19921875\n",
      "fin save.\n",
      "epoch 7371\n",
      "test_train\n",
      "train mean loss=62010.23619791667\n",
      "test_test\n",
      "test mean loss=87339.0390625\n",
      "fin save.\n",
      "epoch 7372\n",
      "test_train\n",
      "train mean loss=63464.54791666667\n",
      "test_test\n",
      "test mean loss=87310.90234375\n",
      "fin save.\n",
      "epoch 7373\n",
      "test_train\n",
      "train mean loss=62200.356119791664\n",
      "test_test\n",
      "test mean loss=87242.75\n",
      "fin save.\n",
      "epoch 7374\n",
      "test_train\n",
      "train mean loss=62215.097265625\n",
      "test_test\n",
      "test mean loss=87414.79296875\n",
      "fin save.\n",
      "epoch 7375\n",
      "test_train\n",
      "train mean loss=62564.894791666666\n",
      "test_test\n",
      "test mean loss=87398.140625\n",
      "fin save.\n",
      "epoch 7376\n",
      "test_train\n",
      "train mean loss=62239.58541666667\n",
      "test_test\n",
      "test mean loss=87290.48046875\n",
      "fin save.\n",
      "epoch 7377\n",
      "test_train\n",
      "train mean loss=62286.336197916666\n",
      "test_test\n",
      "test mean loss=87444.8671875\n",
      "fin save.\n",
      "epoch 7378\n",
      "test_train\n",
      "train mean loss=61639.04700520833\n",
      "test_test\n",
      "test mean loss=87272.2734375\n",
      "fin save.\n",
      "epoch 7379\n",
      "test_train\n",
      "train mean loss=62513.25\n",
      "test_test\n",
      "test mean loss=87168.30078125\n",
      "fin save.\n",
      "epoch 7380\n",
      "test_train\n",
      "train mean loss=62730.09192708333\n",
      "test_test\n",
      "test mean loss=87127.546875\n",
      "fin save.\n",
      "epoch 7381\n",
      "test_train\n",
      "train mean loss=62290.10833333333\n",
      "test_test\n",
      "test mean loss=87602.296875\n",
      "fin save.\n",
      "epoch 7382\n",
      "test_train\n",
      "train mean loss=61393.352864583336\n",
      "test_test\n",
      "test mean loss=87330.73046875\n",
      "fin save.\n",
      "epoch 7383\n",
      "test_train\n",
      "train mean loss=61170.2984375\n",
      "test_test\n",
      "test mean loss=87447.4453125\n",
      "fin save.\n",
      "epoch 7384\n",
      "test_train\n",
      "train mean loss=62035.3109375\n",
      "test_test\n",
      "test mean loss=87077.3671875\n",
      "fin save.\n",
      "epoch 7385\n",
      "test_train\n",
      "train mean loss=62655.527994791664\n",
      "test_test\n",
      "test mean loss=87168.015625\n",
      "fin save.\n",
      "epoch 7386\n",
      "test_train\n",
      "train mean loss=62060.91692708333\n",
      "test_test\n",
      "test mean loss=87363.07421875\n",
      "fin save.\n",
      "epoch 7387\n",
      "test_train\n",
      "train mean loss=62195.760416666664\n",
      "test_test\n",
      "test mean loss=87721.390625\n",
      "fin save.\n",
      "epoch 7388\n",
      "test_train\n",
      "train mean loss=61696.616927083334\n",
      "test_test\n",
      "test mean loss=87208.8671875\n",
      "fin save.\n",
      "epoch 7389\n",
      "test_train\n",
      "train mean loss=62154.34947916667\n",
      "test_test\n",
      "test mean loss=87376.546875\n",
      "fin save.\n",
      "epoch 7390\n",
      "test_train\n",
      "train mean loss=62732.15390625\n",
      "test_test\n",
      "test mean loss=87265.8203125\n",
      "fin save.\n",
      "epoch 7391\n",
      "test_train\n",
      "train mean loss=63406.28828125\n",
      "test_test\n",
      "test mean loss=86965.66796875\n",
      "fin save.\n",
      "epoch 7392\n",
      "test_train\n",
      "train mean loss=62119.63984375\n",
      "test_test\n",
      "test mean loss=86977.859375\n",
      "fin save.\n",
      "epoch 7393\n",
      "test_train\n",
      "train mean loss=61589.423177083336\n",
      "test_test\n",
      "test mean loss=87271.62109375\n",
      "fin save.\n",
      "epoch 7394\n",
      "test_train\n",
      "train mean loss=63149.18411458333\n",
      "test_test\n",
      "test mean loss=87188.33203125\n",
      "fin save.\n",
      "epoch 7395\n",
      "test_train\n",
      "train mean loss=62687.25494791667\n",
      "test_test\n",
      "test mean loss=87246.16796875\n",
      "fin save.\n",
      "epoch 7396\n",
      "test_train\n",
      "train mean loss=63126.63229166667\n",
      "test_test\n",
      "test mean loss=87263.54296875\n",
      "fin save.\n",
      "epoch 7397\n",
      "test_train\n",
      "train mean loss=63112.1828125\n",
      "test_test\n",
      "test mean loss=87459.44921875\n",
      "fin save.\n",
      "epoch 7398\n",
      "test_train\n",
      "train mean loss=62100.87005208333\n",
      "test_test\n",
      "test mean loss=87182.2578125\n",
      "fin save.\n",
      "epoch 7399\n",
      "test_train\n",
      "train mean loss=62951.02265625\n",
      "test_test\n",
      "test mean loss=87279.9375\n",
      "fin save.\n",
      "epoch 7400\n",
      "test_train\n",
      "train mean loss=62361.049479166664\n",
      "test_test\n",
      "test mean loss=87265.484375\n",
      "fin save.\n",
      "epoch 7401\n",
      "test_train\n",
      "train mean loss=62256.38880208333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_test\n",
      "test mean loss=87151.19921875\n",
      "fin save.\n",
      "epoch 7402\n",
      "test_train\n",
      "train mean loss=62302.439192708334\n",
      "test_test\n",
      "test mean loss=87513.25390625\n",
      "fin save.\n",
      "epoch 7403\n",
      "test_train\n",
      "train mean loss=61507.82864583333\n",
      "test_test\n",
      "test mean loss=87059.05078125\n",
      "fin save.\n",
      "epoch 7404\n",
      "test_train\n",
      "train mean loss=61835.48828125\n",
      "test_test\n",
      "test mean loss=87233.6875\n",
      "fin save.\n",
      "epoch 7405\n",
      "test_train\n",
      "train mean loss=62306.865885416664\n",
      "test_test\n",
      "test mean loss=87332.12109375\n",
      "fin save.\n",
      "epoch 7406\n",
      "test_train\n",
      "train mean loss=62969.708984375\n",
      "test_test\n",
      "test mean loss=87443.9921875\n",
      "fin save.\n",
      "epoch 7407\n",
      "test_train\n",
      "train mean loss=62324.39010416667\n",
      "test_test\n",
      "test mean loss=87240.0234375\n",
      "fin save.\n",
      "epoch 7408\n",
      "test_train\n",
      "train mean loss=63273.918359375\n",
      "test_test\n",
      "test mean loss=87090.76953125\n",
      "fin save.\n",
      "epoch 7409\n",
      "test_train\n",
      "train mean loss=62114.68567708333\n",
      "test_test\n",
      "test mean loss=87261.265625\n",
      "fin save.\n",
      "epoch 7410\n",
      "test_train\n",
      "train mean loss=62077.74401041667\n",
      "test_test\n",
      "test mean loss=87250.22265625\n",
      "fin save.\n",
      "epoch 7411\n",
      "test_train\n",
      "train mean loss=61800.95130208333\n",
      "test_test\n",
      "test mean loss=87237.62890625\n",
      "fin save.\n",
      "epoch 7412\n",
      "test_train\n",
      "train mean loss=62644.993359375\n",
      "test_test\n",
      "test mean loss=87457.8828125\n",
      "fin save.\n",
      "epoch 7413\n",
      "test_train\n",
      "train mean loss=63563.522135416664\n",
      "test_test\n",
      "test mean loss=87314.8046875\n",
      "fin save.\n",
      "epoch 7414\n",
      "test_train\n",
      "train mean loss=62502.17734375\n",
      "test_test\n",
      "test mean loss=87352.76953125\n",
      "fin save.\n",
      "epoch 7415\n",
      "test_train\n",
      "train mean loss=62532.3390625\n",
      "test_test\n",
      "test mean loss=87416.10546875\n",
      "fin save.\n",
      "epoch 7416\n",
      "test_train\n",
      "train mean loss=63263.56744791667\n",
      "test_test\n",
      "test mean loss=87244.140625\n",
      "fin save.\n",
      "epoch 7417\n",
      "test_train\n",
      "train mean loss=62271.33385416667\n",
      "test_test\n",
      "test mean loss=86936.9765625\n",
      "fin save.\n",
      "epoch 7418\n",
      "test_train\n",
      "train mean loss=62652.36380208333\n",
      "test_test\n",
      "test mean loss=86786.27734375\n",
      "fin save.\n",
      "epoch 7419\n",
      "test_train\n",
      "train mean loss=62173.25078125\n",
      "test_test\n",
      "test mean loss=87564.3984375\n",
      "fin save.\n",
      "epoch 7420\n",
      "test_train\n",
      "train mean loss=61853.64791666667\n",
      "test_test\n",
      "test mean loss=87307.9375\n",
      "fin save.\n",
      "epoch 7421\n",
      "test_train\n",
      "train mean loss=62257.839583333334\n",
      "test_test\n",
      "test mean loss=87277.109375\n",
      "fin save.\n",
      "epoch 7422\n",
      "test_train\n",
      "train mean loss=62064.30026041667\n",
      "test_test\n",
      "test mean loss=87206.45703125\n",
      "fin save.\n",
      "epoch 7423\n",
      "test_train\n",
      "train mean loss=62624.50390625\n",
      "test_test\n",
      "test mean loss=87153.72265625\n",
      "fin save.\n",
      "epoch 7424\n",
      "test_train\n",
      "train mean loss=62638.78671875\n",
      "test_test\n",
      "test mean loss=87468.02734375\n",
      "fin save.\n",
      "epoch 7425\n",
      "test_train\n",
      "train mean loss=62474.08359375\n",
      "test_test\n",
      "test mean loss=87384.3828125\n",
      "fin save.\n",
      "epoch 7426\n",
      "test_train\n",
      "train mean loss=61845.9796875\n",
      "test_test\n",
      "test mean loss=87300.32421875\n",
      "fin save.\n",
      "epoch 7427\n",
      "test_train\n",
      "train mean loss=61754.592057291666\n",
      "test_test\n",
      "test mean loss=86663.10546875\n",
      "fin save.\n",
      "epoch 7428\n",
      "test_train\n",
      "train mean loss=62115.36875\n",
      "test_test\n",
      "test mean loss=86760.08984375\n",
      "fin save.\n",
      "epoch 7429\n",
      "test_train\n",
      "train mean loss=62861.084375\n",
      "test_test\n",
      "test mean loss=86785.1328125\n",
      "fin save.\n",
      "epoch 7430\n",
      "test_train\n",
      "train mean loss=62349.7640625\n",
      "test_test\n",
      "test mean loss=86649.89453125\n",
      "fin save.\n",
      "epoch 7431\n",
      "test_train\n",
      "train mean loss=62739.91028645833\n",
      "test_test\n",
      "test mean loss=86954.80859375\n",
      "fin save.\n",
      "epoch 7432\n",
      "test_train\n",
      "train mean loss=62299.455338541666\n",
      "test_test\n",
      "test mean loss=87456.55859375\n",
      "fin save.\n",
      "epoch 7433\n",
      "test_train\n",
      "train mean loss=61695.2828125\n",
      "test_test\n",
      "test mean loss=87354.2265625\n",
      "fin save.\n",
      "epoch 7434\n",
      "test_train\n",
      "train mean loss=62142.59140625\n",
      "test_test\n",
      "test mean loss=87417.12109375\n",
      "fin save.\n",
      "epoch 7435\n",
      "test_train\n",
      "train mean loss=62118.71953125\n",
      "test_test\n",
      "test mean loss=87372.50390625\n",
      "fin save.\n",
      "epoch 7436\n",
      "test_train\n",
      "train mean loss=61890.83255208333\n",
      "test_test\n",
      "test mean loss=87546.60546875\n",
      "fin save.\n",
      "epoch 7437\n",
      "test_train\n",
      "train mean loss=61761.130208333336\n",
      "test_test\n",
      "test mean loss=87458.90625\n",
      "fin save.\n",
      "epoch 7438\n",
      "test_train\n",
      "train mean loss=61153.119791666664\n",
      "test_test\n",
      "test mean loss=87247.9296875\n",
      "fin save.\n",
      "epoch 7439\n",
      "test_train\n",
      "train mean loss=61884.20546875\n",
      "test_test\n",
      "test mean loss=87264.0703125\n",
      "fin save.\n",
      "epoch 7440\n",
      "test_train\n",
      "train mean loss=62742.36145833333\n",
      "test_test\n",
      "test mean loss=87420.3203125\n",
      "fin save.\n",
      "epoch 7441\n",
      "test_train\n",
      "train mean loss=62795.03020833333\n",
      "test_test\n",
      "test mean loss=87410.97265625\n",
      "fin save.\n",
      "epoch 7442\n",
      "test_train\n",
      "train mean loss=61034.24427083333\n",
      "test_test\n",
      "test mean loss=87478.08203125\n",
      "fin save.\n",
      "epoch 7443\n",
      "test_train\n",
      "train mean loss=62012.9828125\n",
      "test_test\n",
      "test mean loss=87263.5859375\n",
      "fin save.\n",
      "epoch 7444\n",
      "test_train\n",
      "train mean loss=62487.753125\n",
      "test_test\n",
      "test mean loss=87324.375\n",
      "fin save.\n",
      "epoch 7445\n",
      "test_train\n",
      "train mean loss=62509.36731770833\n",
      "test_test\n",
      "test mean loss=87432.8984375\n",
      "fin save.\n",
      "epoch 7446\n",
      "test_train\n",
      "train mean loss=63094.603776041666\n",
      "test_test\n",
      "test mean loss=87159.5078125\n",
      "fin save.\n",
      "epoch 7447\n",
      "test_train\n",
      "train mean loss=63177.728125\n",
      "test_test\n",
      "test mean loss=87383.03515625\n",
      "fin save.\n",
      "epoch 7448\n",
      "test_train\n",
      "train mean loss=62501.359375\n",
      "test_test\n",
      "test mean loss=87733.58203125\n",
      "fin save.\n",
      "epoch 7449\n",
      "test_train\n",
      "train mean loss=62652.02786458333\n",
      "test_test\n",
      "test mean loss=87630.56640625\n",
      "fin save.\n",
      "epoch 7450\n",
      "test_train\n",
      "train mean loss=61645.10364583333\n",
      "test_test\n",
      "test mean loss=87382.37890625\n",
      "fin save.\n",
      "epoch 7451\n",
      "test_train\n",
      "train mean loss=62694.0796875\n",
      "test_test\n",
      "test mean loss=87436.34375\n",
      "fin save.\n",
      "epoch 7452\n",
      "test_train\n",
      "train mean loss=62192.00104166667\n",
      "test_test\n",
      "test mean loss=87704.0703125\n",
      "fin save.\n",
      "epoch 7453\n",
      "test_train\n",
      "train mean loss=62007.90078125\n",
      "test_test\n",
      "test mean loss=87617.85546875\n",
      "fin save.\n",
      "epoch 7454\n",
      "test_train\n",
      "train mean loss=62881.477864583336\n",
      "test_test\n",
      "test mean loss=87517.2421875\n",
      "fin save.\n",
      "epoch 7455\n",
      "test_train\n",
      "train mean loss=63046.89765625\n",
      "test_test\n",
      "test mean loss=87431.5546875\n",
      "fin save.\n",
      "epoch 7456\n",
      "test_train\n",
      "train mean loss=61399.09817708333\n",
      "test_test\n",
      "test mean loss=87540.32421875\n",
      "fin save.\n",
      "epoch 7457\n",
      "test_train\n",
      "train mean loss=62974.789322916666\n",
      "test_test\n",
      "test mean loss=87623.7734375\n",
      "fin save.\n",
      "epoch 7458\n",
      "test_train\n",
      "train mean loss=62259.578776041664\n",
      "test_test\n",
      "test mean loss=87394.3359375\n",
      "fin save.\n",
      "epoch 7459\n",
      "test_train\n",
      "train mean loss=61800.391796875\n",
      "test_test\n",
      "test mean loss=87582.46484375\n",
      "fin save.\n",
      "epoch 7460\n",
      "test_train\n",
      "train mean loss=63060.003125\n",
      "test_test\n",
      "test mean loss=87395.09375\n",
      "fin save.\n",
      "epoch 7461\n",
      "test_train\n",
      "train mean loss=63030.08515625\n",
      "test_test\n",
      "test mean loss=87400.6953125\n",
      "fin save.\n",
      "epoch 7462\n",
      "test_train\n",
      "train mean loss=61827.1046875\n",
      "test_test\n",
      "test mean loss=87486.87109375\n",
      "fin save.\n",
      "epoch 7463\n",
      "test_train\n",
      "train mean loss=61696.92890625\n",
      "test_test\n",
      "test mean loss=87570.578125\n",
      "fin save.\n",
      "epoch 7464\n",
      "test_train\n",
      "train mean loss=62504.00104166667\n",
      "test_test\n",
      "test mean loss=87449.796875\n",
      "fin save.\n",
      "epoch 7465\n",
      "test_train\n",
      "train mean loss=61461.804036458336\n",
      "test_test\n",
      "test mean loss=87511.30859375\n",
      "fin save.\n",
      "epoch 7466\n",
      "test_train\n",
      "train mean loss=61456.30182291667\n",
      "test_test\n",
      "test mean loss=87467.13671875\n",
      "fin save.\n",
      "epoch 7467\n",
      "test_train\n",
      "train mean loss=62461.40677083333\n",
      "test_test\n",
      "test mean loss=87463.14453125\n",
      "fin save.\n",
      "epoch 7468\n",
      "test_train\n",
      "train mean loss=62089.97760416667\n",
      "test_test\n",
      "test mean loss=87372.5078125\n",
      "fin save.\n",
      "epoch 7469\n",
      "test_train\n",
      "train mean loss=62301.89153645833\n",
      "test_test\n",
      "test mean loss=87506.43359375\n",
      "fin save.\n",
      "epoch 7470\n",
      "test_train\n",
      "train mean loss=62167.46197916667\n",
      "test_test\n",
      "test mean loss=87508.55078125\n",
      "fin save.\n",
      "epoch 7471\n",
      "test_train\n",
      "train mean loss=61729.43020833333\n",
      "test_test\n",
      "test mean loss=87423.890625\n",
      "fin save.\n",
      "epoch 7472\n",
      "test_train\n",
      "train mean loss=62179.134114583336\n",
      "test_test\n",
      "test mean loss=87396.4921875\n",
      "fin save.\n",
      "epoch 7473\n",
      "test_train\n",
      "train mean loss=62485.88880208333\n",
      "test_test\n",
      "test mean loss=87363.78125\n",
      "fin save.\n",
      "epoch 7474\n",
      "test_train\n",
      "train mean loss=63359.326432291666\n",
      "test_test\n",
      "test mean loss=87365.3046875\n",
      "fin save.\n",
      "epoch 7475\n",
      "test_train\n",
      "train mean loss=62587.83203125\n",
      "test_test\n",
      "test mean loss=87527.86328125\n",
      "fin save.\n",
      "epoch 7476\n",
      "test_train\n",
      "train mean loss=62571.15963541667\n",
      "test_test\n",
      "test mean loss=87380.2265625\n",
      "fin save.\n",
      "epoch 7477\n",
      "test_train\n",
      "train mean loss=62636.23255208333\n",
      "test_test\n",
      "test mean loss=87334.46484375\n",
      "fin save.\n",
      "epoch 7478\n",
      "test_train\n",
      "train mean loss=62096.292708333334\n",
      "test_test\n",
      "test mean loss=87279.703125\n",
      "fin save.\n",
      "epoch 7479\n",
      "test_train\n",
      "train mean loss=62903.73723958333\n",
      "test_test\n",
      "test mean loss=87541.37109375\n",
      "fin save.\n",
      "epoch 7480\n",
      "test_train\n",
      "train mean loss=62507.46328125\n",
      "test_test\n",
      "test mean loss=87414.40625\n",
      "fin save.\n",
      "epoch 7481\n",
      "test_train\n",
      "train mean loss=62209.10013020833\n",
      "test_test\n",
      "test mean loss=87340.51953125\n",
      "fin save.\n",
      "epoch 7482\n",
      "test_train\n",
      "train mean loss=62066.11666666667\n",
      "test_test\n",
      "test mean loss=87237.14453125\n",
      "fin save.\n",
      "epoch 7483\n",
      "test_train\n",
      "train mean loss=62416.81796875\n",
      "test_test\n",
      "test mean loss=87295.375\n",
      "fin save.\n",
      "epoch 7484\n",
      "test_train\n",
      "train mean loss=61536.3546875\n",
      "test_test\n",
      "test mean loss=87225.6953125\n",
      "fin save.\n",
      "epoch 7485\n",
      "test_train\n",
      "train mean loss=62733.509375\n",
      "test_test\n",
      "test mean loss=87241.77734375\n",
      "fin save.\n",
      "epoch 7486\n",
      "test_train\n",
      "train mean loss=62655.4734375\n",
      "test_test\n",
      "test mean loss=87295.2578125\n",
      "fin save.\n",
      "epoch 7487\n",
      "test_train\n",
      "train mean loss=61341.450520833336\n",
      "test_test\n",
      "test mean loss=86998.0625\n",
      "fin save.\n",
      "epoch 7488\n",
      "test_train\n",
      "train mean loss=62382.24817708333\n",
      "test_test\n",
      "test mean loss=87059.33984375\n",
      "fin save.\n",
      "epoch 7489\n",
      "test_train\n",
      "train mean loss=61774.57604166667\n",
      "test_test\n",
      "test mean loss=87396.39453125\n",
      "fin save.\n",
      "epoch 7490\n",
      "test_train\n",
      "train mean loss=62734.115625\n",
      "test_test\n",
      "test mean loss=87218.33984375\n",
      "fin save.\n",
      "epoch 7491\n",
      "test_train\n",
      "train mean loss=62114.377604166664\n",
      "test_test\n",
      "test mean loss=87293.09765625\n",
      "fin save.\n",
      "epoch 7492\n",
      "test_train\n",
      "train mean loss=62276.30390625\n",
      "test_test\n",
      "test mean loss=87356.453125\n",
      "fin save.\n",
      "epoch 7493\n",
      "test_train\n",
      "train mean loss=61505.66328125\n",
      "test_test\n",
      "test mean loss=87277.6328125\n",
      "fin save.\n",
      "epoch 7494\n",
      "test_train\n",
      "train mean loss=62370.72161458333\n",
      "test_test\n",
      "test mean loss=87488.68359375\n",
      "fin save.\n",
      "epoch 7495\n",
      "test_train\n",
      "train mean loss=61792.518359375\n",
      "test_test\n",
      "test mean loss=87562.30078125\n",
      "fin save.\n",
      "epoch 7496\n",
      "test_train\n",
      "train mean loss=63239.62213541667\n",
      "test_test\n",
      "test mean loss=87451.390625\n",
      "fin save.\n",
      "epoch 7497\n",
      "test_train\n",
      "train mean loss=62246.89114583333\n",
      "test_test\n",
      "test mean loss=87473.1328125\n",
      "fin save.\n",
      "epoch 7498\n",
      "test_train\n",
      "train mean loss=61419.10260416667\n",
      "test_test\n",
      "test mean loss=87429.8203125\n",
      "fin save.\n",
      "epoch 7499\n",
      "test_train\n",
      "train mean loss=62385.74427083333\n",
      "test_test\n",
      "test mean loss=87863.03515625\n",
      "fin save.\n",
      "epoch 7500\n",
      "test_train\n",
      "train mean loss=61247.5671875\n",
      "test_test\n",
      "test mean loss=87859.28125\n",
      "fin save.\n",
      "epoch 7501\n",
      "test_train\n",
      "train mean loss=62191.07135416667\n",
      "test_test\n",
      "test mean loss=87758.3203125\n",
      "fin save.\n",
      "epoch 7502\n",
      "test_train\n",
      "train mean loss=63342.441145833334\n",
      "test_test\n",
      "test mean loss=87630.4140625\n",
      "fin save.\n",
      "epoch 7503\n",
      "test_train\n",
      "train mean loss=62039.68567708333\n",
      "test_test\n",
      "test mean loss=87669.93359375\n",
      "fin save.\n",
      "epoch 7504\n",
      "test_train\n",
      "train mean loss=62524.48776041667\n",
      "test_test\n",
      "test mean loss=87559.4765625\n",
      "fin save.\n",
      "epoch 7505\n",
      "test_train\n",
      "train mean loss=61467.83932291667\n",
      "test_test\n",
      "test mean loss=87510.140625\n",
      "fin save.\n",
      "epoch 7506\n",
      "test_train\n",
      "train mean loss=62209.44674479167\n",
      "test_test\n",
      "test mean loss=87589.546875\n",
      "fin save.\n",
      "epoch 7507\n",
      "test_train\n",
      "train mean loss=62042.559895833336\n",
      "test_test\n",
      "test mean loss=87464.95703125\n",
      "fin save.\n",
      "epoch 7508\n",
      "test_train\n",
      "train mean loss=62955.98984375\n",
      "test_test\n",
      "test mean loss=87517.65234375\n",
      "fin save.\n",
      "epoch 7509\n",
      "test_train\n",
      "train mean loss=61914.76770833333\n",
      "test_test\n",
      "test mean loss=87473.33203125\n",
      "fin save.\n",
      "epoch 7510\n",
      "test_train\n",
      "train mean loss=62635.606770833336\n",
      "test_test\n",
      "test mean loss=87343.83203125\n",
      "fin save.\n",
      "epoch 7511\n",
      "test_train\n",
      "train mean loss=61791.74609375\n",
      "test_test\n",
      "test mean loss=87313.8515625\n",
      "fin save.\n",
      "epoch 7512\n",
      "test_train\n",
      "train mean loss=62192.073958333334\n",
      "test_test\n",
      "test mean loss=87408.49609375\n",
      "fin save.\n",
      "epoch 7513\n",
      "test_train\n",
      "train mean loss=62983.673177083336\n",
      "test_test\n",
      "test mean loss=87134.36328125\n",
      "fin save.\n",
      "epoch 7514\n",
      "test_train\n",
      "train mean loss=61961.41171875\n",
      "test_test\n",
      "test mean loss=87269.66015625\n",
      "fin save.\n",
      "epoch 7515\n",
      "test_train\n",
      "train mean loss=61765.759375\n",
      "test_test\n",
      "test mean loss=87412.16796875\n",
      "fin save.\n",
      "epoch 7516\n",
      "test_train\n",
      "train mean loss=63133.167317708336\n",
      "test_test\n",
      "test mean loss=87650.01953125\n",
      "fin save.\n",
      "epoch 7517\n",
      "test_train\n",
      "train mean loss=61849.044661458334\n",
      "test_test\n",
      "test mean loss=87320.57421875\n",
      "fin save.\n",
      "epoch 7518\n",
      "test_train\n",
      "train mean loss=62783.543619791664\n",
      "test_test\n",
      "test mean loss=87219.89453125\n",
      "fin save.\n",
      "epoch 7519\n",
      "test_train\n",
      "train mean loss=63236.58203125\n",
      "test_test\n",
      "test mean loss=87307.9921875\n",
      "fin save.\n",
      "epoch 7520\n",
      "test_train\n",
      "train mean loss=61658.85598958333\n",
      "test_test\n",
      "test mean loss=87256.80078125\n",
      "fin save.\n",
      "epoch 7521\n",
      "test_train\n",
      "train mean loss=62235.64505208333\n",
      "test_test\n",
      "test mean loss=87350.12890625\n",
      "fin save.\n",
      "epoch 7522\n",
      "test_train\n",
      "train mean loss=61853.16940104167\n",
      "test_test\n",
      "test mean loss=87388.02734375\n",
      "fin save.\n",
      "epoch 7523\n",
      "test_train\n",
      "train mean loss=63232.33645833333\n",
      "test_test\n",
      "test mean loss=87200.1953125\n",
      "fin save.\n",
      "epoch 7524\n",
      "test_train\n",
      "train mean loss=63570.57083333333\n",
      "test_test\n",
      "test mean loss=87226.84375\n",
      "fin save.\n",
      "epoch 7525\n",
      "test_train\n",
      "train mean loss=61835.0234375\n",
      "test_test\n",
      "test mean loss=87444.11328125\n",
      "fin save.\n",
      "epoch 7526\n",
      "test_train\n",
      "train mean loss=62039.37057291667\n",
      "test_test\n",
      "test mean loss=87279.98828125\n",
      "fin save.\n",
      "epoch 7527\n",
      "test_train\n",
      "train mean loss=62377.735677083336\n",
      "test_test\n",
      "test mean loss=87099.25\n",
      "fin save.\n",
      "epoch 7528\n",
      "test_train\n",
      "train mean loss=62245.67421875\n",
      "test_test\n",
      "test mean loss=87353.0859375\n",
      "fin save.\n",
      "epoch 7529\n",
      "test_train\n",
      "train mean loss=61499.426041666666\n",
      "test_test\n",
      "test mean loss=87444.7734375\n",
      "fin save.\n",
      "epoch 7530\n",
      "test_train\n",
      "train mean loss=62300.297265625\n",
      "test_test\n",
      "test mean loss=87304.87890625\n",
      "fin save.\n",
      "epoch 7531\n",
      "test_train\n",
      "train mean loss=61460.73151041667\n",
      "test_test\n",
      "test mean loss=87338.99609375\n",
      "fin save.\n",
      "epoch 7532\n",
      "test_train\n",
      "train mean loss=62075.784375\n",
      "test_test\n",
      "test mean loss=87442.4453125\n",
      "fin save.\n",
      "epoch 7533\n",
      "test_train\n",
      "train mean loss=61790.00989583333\n",
      "test_test\n",
      "test mean loss=87425.8359375\n",
      "fin save.\n",
      "epoch 7534\n",
      "test_train\n",
      "train mean loss=61563.2625\n",
      "test_test\n",
      "test mean loss=87418.609375\n",
      "fin save.\n",
      "epoch 7535\n",
      "test_train\n",
      "train mean loss=61999.209635416664\n",
      "test_test\n",
      "test mean loss=87589.63671875\n",
      "fin save.\n",
      "epoch 7536\n",
      "test_train\n",
      "train mean loss=62365.15572916667\n",
      "test_test\n",
      "test mean loss=87494.26953125\n",
      "fin save.\n",
      "epoch 7537\n",
      "test_train\n",
      "train mean loss=62654.729166666664\n",
      "test_test\n",
      "test mean loss=87501.42578125\n",
      "fin save.\n",
      "epoch 7538\n",
      "test_train\n",
      "train mean loss=61684.445963541664\n",
      "test_test\n",
      "test mean loss=87596.05078125\n",
      "fin save.\n",
      "epoch 7539\n",
      "test_train\n",
      "train mean loss=62032.71276041667\n",
      "test_test\n",
      "test mean loss=87501.8046875\n",
      "fin save.\n",
      "epoch 7540\n",
      "test_train\n",
      "train mean loss=62355.284895833334\n",
      "test_test\n",
      "test mean loss=87664.0703125\n",
      "fin save.\n",
      "epoch 7541\n",
      "test_train\n",
      "train mean loss=61793.1890625\n",
      "test_test\n",
      "test mean loss=87562.26953125\n",
      "fin save.\n",
      "epoch 7542\n",
      "test_train\n",
      "train mean loss=62065.10052083333\n",
      "test_test\n",
      "test mean loss=87406.5703125\n",
      "fin save.\n",
      "epoch 7543\n",
      "test_train\n",
      "train mean loss=62178.48671875\n",
      "test_test\n",
      "test mean loss=87482.73828125\n",
      "fin save.\n",
      "epoch 7544\n",
      "test_train\n",
      "train mean loss=62756.44140625\n",
      "test_test\n",
      "test mean loss=87507.8984375\n",
      "fin save.\n",
      "epoch 7545\n",
      "test_train\n",
      "train mean loss=62543.77239583333\n",
      "test_test\n",
      "test mean loss=87425.24609375\n",
      "fin save.\n",
      "epoch 7546\n",
      "test_train\n",
      "train mean loss=62702.414322916666\n",
      "test_test\n",
      "test mean loss=87388.6484375\n",
      "fin save.\n",
      "epoch 7547\n",
      "test_train\n",
      "train mean loss=61878.0390625\n",
      "test_test\n",
      "test mean loss=87039.3125\n",
      "fin save.\n",
      "epoch 7548\n",
      "test_train\n",
      "train mean loss=62378.62005208333\n",
      "test_test\n",
      "test mean loss=86926.8203125\n",
      "fin save.\n",
      "epoch 7549\n",
      "test_train\n",
      "train mean loss=62371.57109375\n",
      "test_test\n",
      "test mean loss=87015.42578125\n",
      "fin save.\n",
      "epoch 7550\n",
      "test_train\n",
      "train mean loss=61686.49114583333\n",
      "test_test\n",
      "test mean loss=87102.68359375\n",
      "fin save.\n",
      "epoch 7551\n",
      "test_train\n",
      "train mean loss=62322.17395833333\n",
      "test_test\n",
      "test mean loss=87104.27734375\n",
      "fin save.\n",
      "epoch 7552\n",
      "test_train\n",
      "train mean loss=62647.7453125\n",
      "test_test\n",
      "test mean loss=87024.91015625\n",
      "fin save.\n",
      "epoch 7553\n",
      "test_train\n",
      "train mean loss=62534.62005208333\n",
      "test_test\n",
      "test mean loss=86993.5390625\n",
      "fin save.\n",
      "epoch 7554\n",
      "test_train\n",
      "train mean loss=62569.871354166666\n",
      "test_test\n",
      "test mean loss=86948.63671875\n",
      "fin save.\n",
      "epoch 7555\n",
      "test_train\n",
      "train mean loss=62135.809375\n",
      "test_test\n",
      "test mean loss=87392.11328125\n",
      "fin save.\n",
      "epoch 7556\n",
      "test_train\n",
      "train mean loss=63002.59453125\n",
      "test_test\n",
      "test mean loss=87538.109375\n",
      "fin save.\n",
      "epoch 7557\n",
      "test_train\n",
      "train mean loss=62347.2421875\n",
      "test_test\n",
      "test mean loss=87509.23828125\n",
      "fin save.\n",
      "epoch 7558\n",
      "test_train\n",
      "train mean loss=63076.55963541667\n",
      "test_test\n",
      "test mean loss=87575.99609375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fin save.\n",
      "epoch 7559\n",
      "test_train\n",
      "train mean loss=62666.23450520833\n",
      "test_test\n",
      "test mean loss=87762.66796875\n",
      "fin save.\n",
      "epoch 7560\n",
      "test_train\n",
      "train mean loss=63153.77942708333\n",
      "test_test\n",
      "test mean loss=87604.55078125\n",
      "fin save.\n",
      "epoch 7561\n",
      "test_train\n",
      "train mean loss=63318.585546875\n",
      "test_test\n",
      "test mean loss=87670.58203125\n",
      "fin save.\n",
      "epoch 7562\n",
      "test_train\n",
      "train mean loss=62856.64765625\n",
      "test_test\n",
      "test mean loss=87641.515625\n",
      "fin save.\n",
      "epoch 7563\n",
      "test_train\n",
      "train mean loss=61719.93307291667\n",
      "test_test\n",
      "test mean loss=87577.81640625\n",
      "fin save.\n",
      "epoch 7564\n",
      "test_train\n",
      "train mean loss=61927.598958333336\n",
      "test_test\n",
      "test mean loss=87519.5625\n",
      "fin save.\n",
      "epoch 7565\n",
      "test_train\n",
      "train mean loss=62520.633072916666\n",
      "test_test\n",
      "test mean loss=87275.4453125\n",
      "fin save.\n",
      "epoch 7566\n",
      "test_train\n",
      "train mean loss=62054.43463541667\n",
      "test_test\n",
      "test mean loss=87187.95703125\n",
      "fin save.\n",
      "epoch 7567\n",
      "test_train\n",
      "train mean loss=61473.09817708333\n",
      "test_test\n",
      "test mean loss=87337.2421875\n",
      "fin save.\n",
      "epoch 7568\n",
      "test_train\n",
      "train mean loss=62641.380859375\n",
      "test_test\n",
      "test mean loss=87486.34375\n",
      "fin save.\n",
      "epoch 7569\n",
      "test_train\n",
      "train mean loss=62557.0765625\n",
      "test_test\n",
      "test mean loss=87398.8046875\n",
      "fin save.\n",
      "epoch 7570\n",
      "test_train\n",
      "train mean loss=62198.825\n",
      "test_test\n",
      "test mean loss=87510.77734375\n",
      "fin save.\n",
      "epoch 7571\n",
      "test_train\n",
      "train mean loss=62068.01953125\n",
      "test_test\n",
      "test mean loss=87645.0078125\n",
      "fin save.\n",
      "epoch 7572\n",
      "test_train\n",
      "train mean loss=61477.222395833334\n",
      "test_test\n",
      "test mean loss=87621.87890625\n",
      "fin save.\n",
      "epoch 7573\n",
      "test_train\n",
      "train mean loss=61929.611979166664\n",
      "test_test\n",
      "test mean loss=87571.7578125\n",
      "fin save.\n",
      "epoch 7574\n",
      "test_train\n",
      "train mean loss=62503.97317708333\n",
      "test_test\n",
      "test mean loss=87496.609375\n",
      "fin save.\n",
      "epoch 7575\n",
      "test_train\n",
      "train mean loss=62740.71953125\n",
      "test_test\n",
      "test mean loss=88381.46875\n",
      "fin save.\n",
      "epoch 7576\n",
      "test_train\n",
      "train mean loss=61035.646875\n",
      "test_test\n",
      "test mean loss=88272.828125\n",
      "fin save.\n",
      "epoch 7577\n",
      "test_train\n",
      "train mean loss=62502.4015625\n",
      "test_test\n",
      "test mean loss=88478.0625\n",
      "fin save.\n",
      "epoch 7578\n",
      "test_train\n",
      "train mean loss=62374.331770833334\n",
      "test_test\n",
      "test mean loss=88189.53515625\n",
      "fin save.\n",
      "epoch 7579\n",
      "test_train\n",
      "train mean loss=61601.622395833336\n",
      "test_test\n",
      "test mean loss=88215.5703125\n",
      "fin save.\n",
      "epoch 7580\n",
      "test_train\n",
      "train mean loss=62509.042708333334\n",
      "test_test\n",
      "test mean loss=88110.390625\n",
      "fin save.\n",
      "epoch 7581\n",
      "test_train\n",
      "train mean loss=62220.34270833333\n",
      "test_test\n",
      "test mean loss=88203.90234375\n",
      "fin save.\n",
      "epoch 7582\n",
      "test_train\n",
      "train mean loss=62184.39921875\n",
      "test_test\n",
      "test mean loss=88329.6796875\n",
      "fin save.\n",
      "epoch 7583\n",
      "test_train\n",
      "train mean loss=61869.35052083333\n",
      "test_test\n",
      "test mean loss=87832.3125\n",
      "fin save.\n",
      "epoch 7584\n",
      "test_train\n",
      "train mean loss=62825.142578125\n",
      "test_test\n",
      "test mean loss=87030.0625\n",
      "fin save.\n",
      "epoch 7585\n",
      "test_train\n",
      "train mean loss=62500.628125\n",
      "test_test\n",
      "test mean loss=87066.2734375\n",
      "fin save.\n",
      "epoch 7586\n",
      "test_train\n",
      "train mean loss=61916.36927083333\n",
      "test_test\n",
      "test mean loss=86945.26171875\n",
      "fin save.\n",
      "epoch 7587\n",
      "test_train\n",
      "train mean loss=61402.11015625\n",
      "test_test\n",
      "test mean loss=86916.91796875\n",
      "fin save.\n",
      "epoch 7588\n",
      "test_train\n",
      "train mean loss=61167.47473958333\n",
      "test_test\n",
      "test mean loss=86763.1328125\n",
      "fin save.\n",
      "epoch 7589\n",
      "test_train\n",
      "train mean loss=62634.22447916667\n",
      "test_test\n",
      "test mean loss=86956.6015625\n",
      "fin save.\n",
      "epoch 7590\n",
      "test_train\n",
      "train mean loss=62618.87734375\n",
      "test_test\n",
      "test mean loss=86815.55859375\n",
      "fin save.\n",
      "epoch 7591\n",
      "test_train\n",
      "train mean loss=62061.450911458334\n",
      "test_test\n",
      "test mean loss=86922.43359375\n",
      "fin save.\n",
      "epoch 7592\n",
      "test_train\n",
      "train mean loss=63664.75182291667\n",
      "test_test\n",
      "test mean loss=86810.94921875\n",
      "fin save.\n",
      "epoch 7593\n",
      "test_train\n",
      "train mean loss=62050.436328125\n",
      "test_test\n",
      "test mean loss=86845.2265625\n",
      "fin save.\n",
      "epoch 7594\n",
      "test_train\n",
      "train mean loss=62615.406510416666\n",
      "test_test\n",
      "test mean loss=86836.8515625\n",
      "fin save.\n",
      "epoch 7595\n",
      "test_train\n",
      "train mean loss=61739.80625\n",
      "test_test\n",
      "test mean loss=86921.50390625\n",
      "fin save.\n",
      "epoch 7596\n",
      "test_train\n",
      "train mean loss=62199.03020833333\n",
      "test_test\n",
      "test mean loss=87239.6328125\n",
      "fin save.\n",
      "epoch 7597\n",
      "test_train\n",
      "train mean loss=61644.06171875\n",
      "test_test\n",
      "test mean loss=87126.38671875\n",
      "fin save.\n",
      "epoch 7598\n",
      "test_train\n",
      "train mean loss=63724.29895833333\n",
      "test_test\n",
      "test mean loss=85961.25390625\n",
      "fin save.\n",
      "epoch 7599\n",
      "test_train\n",
      "train mean loss=62095.17734375\n",
      "test_test\n",
      "test mean loss=86239.609375\n",
      "fin save.\n",
      "epoch 7600\n",
      "test_train\n",
      "train mean loss=62094.920703125\n",
      "test_test\n",
      "test mean loss=86003.04296875\n",
      "fin save.\n",
      "epoch 7601\n",
      "test_train\n",
      "train mean loss=63161.10651041667\n",
      "test_test\n",
      "test mean loss=86226.23046875\n",
      "fin save.\n",
      "epoch 7602\n",
      "test_train\n",
      "train mean loss=62336.54375\n",
      "test_test\n",
      "test mean loss=86090.71484375\n",
      "fin save.\n",
      "epoch 7603\n",
      "test_train\n",
      "train mean loss=61861.29635416667\n",
      "test_test\n",
      "test mean loss=85965.37890625\n",
      "fin save.\n",
      "epoch 7604\n",
      "test_train\n",
      "train mean loss=62759.022265625\n",
      "test_test\n",
      "test mean loss=85953.7734375\n",
      "fin save.\n",
      "epoch 7605\n",
      "test_train\n",
      "train mean loss=62170.71002604167\n",
      "test_test\n",
      "test mean loss=86325.58984375\n",
      "fin save.\n",
      "epoch 7606\n",
      "test_train\n",
      "train mean loss=63415.78072916667\n",
      "test_test\n",
      "test mean loss=86337.1640625\n",
      "fin save.\n",
      "epoch 7607\n",
      "test_train\n",
      "train mean loss=61816.01354166667\n",
      "test_test\n",
      "test mean loss=86499.67578125\n",
      "fin save.\n",
      "epoch 7608\n",
      "test_train\n",
      "train mean loss=62345.85989583333\n",
      "test_test\n",
      "test mean loss=86551.94140625\n",
      "fin save.\n",
      "epoch 7609\n",
      "test_train\n",
      "train mean loss=61955.40325520833\n",
      "test_test\n",
      "test mean loss=86543.5625\n",
      "fin save.\n",
      "epoch 7610\n",
      "test_train\n",
      "train mean loss=62647.40143229167\n",
      "test_test\n",
      "test mean loss=86683.43359375\n",
      "fin save.\n",
      "epoch 7611\n",
      "test_train\n",
      "train mean loss=61669.682291666664\n",
      "test_test\n",
      "test mean loss=86694.140625\n",
      "fin save.\n",
      "epoch 7612\n",
      "test_train\n",
      "train mean loss=62154.173177083336\n",
      "test_test\n",
      "test mean loss=86660.3203125\n",
      "fin save.\n",
      "epoch 7613\n",
      "test_train\n",
      "train mean loss=61850.036458333336\n",
      "test_test\n",
      "test mean loss=86729.59375\n",
      "fin save.\n",
      "epoch 7614\n",
      "test_train\n",
      "train mean loss=62610.99609375\n",
      "test_test\n",
      "test mean loss=86637.89453125\n",
      "fin save.\n",
      "epoch 7615\n",
      "test_train\n",
      "train mean loss=62881.555859375\n",
      "test_test\n",
      "test mean loss=86632.77734375\n",
      "fin save.\n",
      "epoch 7616\n",
      "test_train\n",
      "train mean loss=62314.138020833336\n",
      "test_test\n",
      "test mean loss=86749.6171875\n",
      "fin save.\n",
      "epoch 7617\n",
      "test_train\n",
      "train mean loss=61618.7078125\n",
      "test_test\n",
      "test mean loss=86672.85546875\n",
      "fin save.\n",
      "epoch 7618\n",
      "test_train\n",
      "train mean loss=62200.795703125\n",
      "test_test\n",
      "test mean loss=87055.671875\n",
      "fin save.\n",
      "epoch 7619\n",
      "test_train\n",
      "train mean loss=62601.83020833333\n",
      "test_test\n",
      "test mean loss=86980.0625\n",
      "fin save.\n",
      "epoch 7620\n",
      "test_train\n",
      "train mean loss=62935.88671875\n",
      "test_test\n",
      "test mean loss=87174.98046875\n",
      "fin save.\n",
      "epoch 7621\n",
      "test_train\n",
      "train mean loss=62203.165625\n",
      "test_test\n",
      "test mean loss=87270.1796875\n",
      "fin save.\n",
      "epoch 7622\n",
      "test_train\n",
      "train mean loss=62565.19635416667\n",
      "test_test\n",
      "test mean loss=87190.1875\n",
      "fin save.\n",
      "epoch 7623\n",
      "test_train\n",
      "train mean loss=62640.842447916664\n",
      "test_test\n",
      "test mean loss=87189.32421875\n",
      "fin save.\n",
      "epoch 7624\n",
      "test_train\n",
      "train mean loss=62108.658203125\n",
      "test_test\n",
      "test mean loss=87175.5625\n",
      "fin save.\n",
      "epoch 7625\n",
      "test_train\n",
      "train mean loss=61881.740494791666\n",
      "test_test\n",
      "test mean loss=86989.64453125\n",
      "fin save.\n",
      "epoch 7626\n",
      "test_train\n",
      "train mean loss=62233.198958333334\n",
      "test_test\n",
      "test mean loss=87361.08203125\n",
      "fin save.\n",
      "epoch 7627\n",
      "test_train\n",
      "train mean loss=62906.401171875\n",
      "test_test\n",
      "test mean loss=87221.52734375\n",
      "fin save.\n",
      "epoch 7628\n",
      "test_train\n",
      "train mean loss=62077.90546875\n",
      "test_test\n",
      "test mean loss=86966.77734375\n",
      "fin save.\n",
      "epoch 7629\n",
      "test_train\n",
      "train mean loss=61761.68203125\n",
      "test_test\n",
      "test mean loss=87275.875\n",
      "fin save.\n",
      "epoch 7630\n",
      "test_train\n",
      "train mean loss=62543.4609375\n",
      "test_test\n",
      "test mean loss=87415.6953125\n",
      "fin save.\n",
      "epoch 7631\n",
      "test_train\n",
      "train mean loss=61695.01354166667\n",
      "test_test\n",
      "test mean loss=87586.99609375\n",
      "fin save.\n",
      "epoch 7632\n",
      "test_train\n",
      "train mean loss=61518.444010416664\n",
      "test_test\n",
      "test mean loss=87594.0390625\n",
      "fin save.\n",
      "epoch 7633\n",
      "test_train\n",
      "train mean loss=62776.28723958333\n",
      "test_test\n",
      "test mean loss=87471.41796875\n",
      "fin save.\n",
      "epoch 7634\n",
      "test_train\n",
      "train mean loss=62295.53333333333\n",
      "test_test\n",
      "test mean loss=87389.73828125\n",
      "fin save.\n",
      "epoch 7635\n",
      "test_train\n",
      "train mean loss=61308.68541666667\n",
      "test_test\n",
      "test mean loss=87373.8046875\n",
      "fin save.\n",
      "epoch 7636\n",
      "test_train\n",
      "train mean loss=62159.41640625\n",
      "test_test\n",
      "test mean loss=87390.07421875\n",
      "fin save.\n",
      "epoch 7637\n",
      "test_train\n",
      "train mean loss=61896.075\n",
      "test_test\n",
      "test mean loss=87275.84375\n",
      "fin save.\n",
      "epoch 7638\n",
      "test_train\n",
      "train mean loss=62955.426041666666\n",
      "test_test\n",
      "test mean loss=87294.8359375\n",
      "fin save.\n",
      "epoch 7639\n",
      "test_train\n",
      "train mean loss=62132.59765625\n",
      "test_test\n",
      "test mean loss=87291.39453125\n",
      "fin save.\n",
      "epoch 7640\n",
      "test_train\n",
      "train mean loss=62958.116927083334\n",
      "test_test\n",
      "test mean loss=87228.9296875\n",
      "fin save.\n",
      "epoch 7641\n",
      "test_train\n",
      "train mean loss=63303.22838541667\n",
      "test_test\n",
      "test mean loss=87391.9921875\n",
      "fin save.\n",
      "epoch 7642\n",
      "test_train\n",
      "train mean loss=61813.29114583333\n",
      "test_test\n",
      "test mean loss=87170.81640625\n",
      "fin save.\n",
      "epoch 7643\n",
      "test_train\n",
      "train mean loss=62386.640625\n",
      "test_test\n",
      "test mean loss=87315.91796875\n",
      "fin save.\n",
      "epoch 7644\n",
      "test_train\n",
      "train mean loss=62206.784505208336\n",
      "test_test\n",
      "test mean loss=87281.14453125\n",
      "fin save.\n",
      "epoch 7645\n",
      "test_train\n",
      "train mean loss=62651.37005208333\n",
      "test_test\n",
      "test mean loss=87283.72265625\n",
      "fin save.\n",
      "epoch 7646\n",
      "test_train\n",
      "train mean loss=62494.8\n",
      "test_test\n",
      "test mean loss=87196.71484375\n",
      "fin save.\n",
      "epoch 7647\n",
      "test_train\n",
      "train mean loss=62660.83346354167\n",
      "test_test\n",
      "test mean loss=87468.3671875\n",
      "fin save.\n",
      "epoch 7648\n",
      "test_train\n",
      "train mean loss=62213.041015625\n",
      "test_test\n",
      "test mean loss=87434.18359375\n",
      "fin save.\n",
      "epoch 7649\n",
      "test_train\n",
      "train mean loss=61983.17135416667\n",
      "test_test\n",
      "test mean loss=87301.19140625\n",
      "fin save.\n",
      "epoch 7650\n",
      "test_train\n",
      "train mean loss=62898.0921875\n",
      "test_test\n",
      "test mean loss=87488.765625\n",
      "fin save.\n",
      "epoch 7651\n",
      "test_train\n",
      "train mean loss=61433.268880208336\n",
      "test_test\n",
      "test mean loss=87309.50390625\n",
      "fin save.\n",
      "epoch 7652\n",
      "test_train\n",
      "train mean loss=62637.812239583334\n",
      "test_test\n",
      "test mean loss=87488.0703125\n",
      "fin save.\n",
      "epoch 7653\n",
      "test_train\n",
      "train mean loss=61561.558984375\n",
      "test_test\n",
      "test mean loss=87282.80078125\n",
      "fin save.\n",
      "epoch 7654\n",
      "test_train\n",
      "train mean loss=62728.17291666667\n",
      "test_test\n",
      "test mean loss=87317.45703125\n",
      "fin save.\n",
      "epoch 7655\n",
      "test_train\n",
      "train mean loss=62376.705078125\n",
      "test_test\n",
      "test mean loss=87162.3125\n",
      "fin save.\n",
      "epoch 7656\n",
      "test_train\n",
      "train mean loss=61248.60859375\n",
      "test_test\n",
      "test mean loss=87261.8359375\n",
      "fin save.\n",
      "epoch 7657\n",
      "test_train\n",
      "train mean loss=61994.15546875\n",
      "test_test\n",
      "test mean loss=87265.58203125\n",
      "fin save.\n",
      "epoch 7658\n",
      "test_train\n",
      "train mean loss=62637.14075520833\n",
      "test_test\n",
      "test mean loss=87448.421875\n",
      "fin save.\n",
      "epoch 7659\n",
      "test_train\n",
      "train mean loss=62031.551953125\n",
      "test_test\n",
      "test mean loss=87452.01171875\n",
      "fin save.\n",
      "epoch 7660\n",
      "test_train\n",
      "train mean loss=62627.02005208333\n",
      "test_test\n",
      "test mean loss=87208.609375\n",
      "fin save.\n",
      "epoch 7661\n",
      "test_train\n",
      "train mean loss=62535.18828125\n",
      "test_test\n",
      "test mean loss=87343.78515625\n",
      "fin save.\n",
      "epoch 7662\n",
      "test_train\n",
      "train mean loss=61719.37200520833\n",
      "test_test\n",
      "test mean loss=87290.73046875\n",
      "fin save.\n",
      "epoch 7663\n",
      "test_train\n",
      "train mean loss=62090.228515625\n",
      "test_test\n",
      "test mean loss=87315.73046875\n",
      "fin save.\n",
      "epoch 7664\n",
      "test_train\n",
      "train mean loss=62178.06302083333\n",
      "test_test\n",
      "test mean loss=87357.68359375\n",
      "fin save.\n",
      "epoch 7665\n",
      "test_train\n",
      "train mean loss=62948.45416666667\n",
      "test_test\n",
      "test mean loss=87270.44921875\n",
      "fin save.\n",
      "epoch 7666\n",
      "test_train\n",
      "train mean loss=62155.548177083336\n",
      "test_test\n",
      "test mean loss=87191.72265625\n",
      "fin save.\n",
      "epoch 7667\n",
      "test_train\n",
      "train mean loss=63068.890234375\n",
      "test_test\n",
      "test mean loss=87151.39453125\n",
      "fin save.\n",
      "epoch 7668\n",
      "test_train\n",
      "train mean loss=62061.994791666664\n",
      "test_test\n",
      "test mean loss=87138.52734375\n",
      "fin save.\n",
      "epoch 7669\n",
      "test_train\n",
      "train mean loss=62226.339583333334\n",
      "test_test\n",
      "test mean loss=86826.02734375\n",
      "fin save.\n",
      "epoch 7670\n",
      "test_train\n",
      "train mean loss=61914.363020833334\n",
      "test_test\n",
      "test mean loss=86941.40625\n",
      "fin save.\n",
      "epoch 7671\n",
      "test_train\n",
      "train mean loss=61794.65026041667\n",
      "test_test\n",
      "test mean loss=86680.26953125\n",
      "fin save.\n",
      "epoch 7672\n",
      "test_train\n",
      "train mean loss=61873.659895833334\n",
      "test_test\n",
      "test mean loss=86647.58203125\n",
      "fin save.\n",
      "epoch 7673\n",
      "test_train\n",
      "train mean loss=62043.053385416664\n",
      "test_test\n",
      "test mean loss=86765.5234375\n",
      "fin save.\n",
      "epoch 7674\n",
      "test_train\n",
      "train mean loss=62653.38098958333\n",
      "test_test\n",
      "test mean loss=86703.3671875\n",
      "fin save.\n",
      "epoch 7675\n",
      "test_train\n",
      "train mean loss=62718.337890625\n",
      "test_test\n",
      "test mean loss=86683.78125\n",
      "fin save.\n",
      "epoch 7676\n",
      "test_train\n",
      "train mean loss=63305.26328125\n",
      "test_test\n",
      "test mean loss=86712.98828125\n",
      "fin save.\n",
      "epoch 7677\n",
      "test_train\n",
      "train mean loss=62836.43072916667\n",
      "test_test\n",
      "test mean loss=86818.109375\n",
      "fin save.\n",
      "epoch 7678\n",
      "test_train\n",
      "train mean loss=63049.63489583333\n",
      "test_test\n",
      "test mean loss=86917.09375\n",
      "fin save.\n",
      "epoch 7679\n",
      "test_train\n",
      "train mean loss=62274.355078125\n",
      "test_test\n",
      "test mean loss=86780.66015625\n",
      "fin save.\n",
      "epoch 7680\n",
      "test_train\n",
      "train mean loss=62988.5734375\n",
      "test_test\n",
      "test mean loss=86972.96875\n",
      "fin save.\n",
      "epoch 7681\n",
      "test_train\n",
      "train mean loss=62852.348958333336\n",
      "test_test\n",
      "test mean loss=86901.02734375\n",
      "fin save.\n",
      "epoch 7682\n",
      "test_train\n",
      "train mean loss=62233.71822916667\n",
      "test_test\n",
      "test mean loss=86995.15625\n",
      "fin save.\n",
      "epoch 7683\n",
      "test_train\n",
      "train mean loss=61812.19348958333\n",
      "test_test\n",
      "test mean loss=87006.42578125\n",
      "fin save.\n",
      "epoch 7684\n",
      "test_train\n",
      "train mean loss=62571.22578125\n",
      "test_test\n",
      "test mean loss=87156.39453125\n",
      "fin save.\n",
      "epoch 7685\n",
      "test_train\n",
      "train mean loss=63166.47942708333\n",
      "test_test\n",
      "test mean loss=87035.6796875\n",
      "fin save.\n",
      "epoch 7686\n",
      "test_train\n",
      "train mean loss=62504.054427083334\n",
      "test_test\n",
      "test mean loss=87071.9296875\n",
      "fin save.\n",
      "epoch 7687\n",
      "test_train\n",
      "train mean loss=62318.64453125\n",
      "test_test\n",
      "test mean loss=87004.12109375\n",
      "fin save.\n",
      "epoch 7688\n",
      "test_train\n",
      "train mean loss=62270.49986979167\n",
      "test_test\n",
      "test mean loss=87180.61328125\n",
      "fin save.\n",
      "epoch 7689\n",
      "test_train\n",
      "train mean loss=61765.19921875\n",
      "test_test\n",
      "test mean loss=87094.84375\n",
      "fin save.\n",
      "epoch 7690\n",
      "test_train\n",
      "train mean loss=62212.35703125\n",
      "test_test\n",
      "test mean loss=87087.62109375\n",
      "fin save.\n",
      "epoch 7691\n",
      "test_train\n",
      "train mean loss=62183.078125\n",
      "test_test\n",
      "test mean loss=87059.81640625\n",
      "fin save.\n",
      "epoch 7692\n",
      "test_train\n",
      "train mean loss=61041.24765625\n",
      "test_test\n",
      "test mean loss=87154.66796875\n",
      "fin save.\n",
      "epoch 7693\n",
      "test_train\n",
      "train mean loss=62190.12682291667\n",
      "test_test\n",
      "test mean loss=86852.12109375\n",
      "fin save.\n",
      "epoch 7694\n",
      "test_train\n",
      "train mean loss=61275.19479166667\n",
      "test_test\n",
      "test mean loss=86976.66796875\n",
      "fin save.\n",
      "epoch 7695\n",
      "test_train\n",
      "train mean loss=63465.235677083336\n",
      "test_test\n",
      "test mean loss=86873.2109375\n",
      "fin save.\n",
      "epoch 7696\n",
      "test_train\n",
      "train mean loss=62362.266927083336\n",
      "test_test\n",
      "test mean loss=86885.7109375\n",
      "fin save.\n",
      "epoch 7697\n",
      "test_train\n",
      "train mean loss=61985.558854166666\n",
      "test_test\n",
      "test mean loss=87016.703125\n",
      "fin save.\n",
      "epoch 7698\n",
      "test_train\n",
      "train mean loss=61731.43125\n",
      "test_test\n",
      "test mean loss=87069.9453125\n",
      "fin save.\n",
      "epoch 7699\n",
      "test_train\n",
      "train mean loss=62914.1\n",
      "test_test\n",
      "test mean loss=87311.671875\n",
      "fin save.\n",
      "epoch 7700\n",
      "test_train\n",
      "train mean loss=62304.152734375\n",
      "test_test\n",
      "test mean loss=87445.4609375\n",
      "fin save.\n",
      "epoch 7701\n",
      "test_train\n",
      "train mean loss=62699.07122395833\n",
      "test_test\n",
      "test mean loss=87612.8203125\n",
      "fin save.\n",
      "epoch 7702\n",
      "test_train\n",
      "train mean loss=60965.282552083336\n",
      "test_test\n",
      "test mean loss=87843.00390625\n",
      "fin save.\n",
      "epoch 7703\n",
      "test_train\n",
      "train mean loss=62035.473958333336\n",
      "test_test\n",
      "test mean loss=88118.0859375\n",
      "fin save.\n",
      "epoch 7704\n",
      "test_train\n",
      "train mean loss=62315.690234375\n",
      "test_test\n",
      "test mean loss=87524.171875\n",
      "fin save.\n",
      "epoch 7705\n",
      "test_train\n",
      "train mean loss=61911.619791666664\n",
      "test_test\n",
      "test mean loss=87404.71875\n",
      "fin save.\n",
      "epoch 7706\n",
      "test_train\n",
      "train mean loss=61798.68046875\n",
      "test_test\n",
      "test mean loss=87384.62109375\n",
      "fin save.\n",
      "epoch 7707\n",
      "test_train\n",
      "train mean loss=62065.43997395833\n",
      "test_test\n",
      "test mean loss=87323.53515625\n",
      "fin save.\n",
      "epoch 7708\n",
      "test_train\n",
      "train mean loss=61594.484114583334\n",
      "test_test\n",
      "test mean loss=87397.1953125\n",
      "fin save.\n",
      "epoch 7709\n",
      "test_train\n",
      "train mean loss=62852.501302083336\n",
      "test_test\n",
      "test mean loss=87374.6015625\n",
      "fin save.\n",
      "epoch 7710\n",
      "test_train\n",
      "train mean loss=61754.8140625\n",
      "test_test\n",
      "test mean loss=87359.74609375\n",
      "fin save.\n",
      "epoch 7711\n",
      "test_train\n",
      "train mean loss=62229.597395833334\n",
      "test_test\n",
      "test mean loss=87339.1328125\n",
      "fin save.\n",
      "epoch 7712\n",
      "test_train\n",
      "train mean loss=61861.42473958333\n",
      "test_test\n",
      "test mean loss=87321.875\n",
      "fin save.\n",
      "epoch 7713\n",
      "test_train\n",
      "train mean loss=62619.58411458333\n",
      "test_test\n",
      "test mean loss=87387.02734375\n",
      "fin save.\n",
      "epoch 7714\n",
      "test_train\n",
      "train mean loss=62701.22513020833\n",
      "test_test\n",
      "test mean loss=87546.328125\n",
      "fin save.\n",
      "epoch 7715\n",
      "test_train\n",
      "train mean loss=62517.20104166667\n",
      "test_test\n",
      "test mean loss=87457.390625\n",
      "fin save.\n",
      "epoch 7716\n",
      "test_train\n",
      "train mean loss=62479.871354166666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_test\n",
      "test mean loss=87300.6953125\n",
      "fin save.\n",
      "epoch 7717\n",
      "test_train\n",
      "train mean loss=62215.970052083336\n",
      "test_test\n",
      "test mean loss=87264.17578125\n",
      "fin save.\n",
      "epoch 7718\n",
      "test_train\n",
      "train mean loss=62348.63984375\n",
      "test_test\n",
      "test mean loss=87637.60546875\n",
      "fin save.\n",
      "epoch 7719\n",
      "test_train\n",
      "train mean loss=61954.52421875\n",
      "test_test\n",
      "test mean loss=87678.79296875\n",
      "fin save.\n",
      "epoch 7720\n",
      "test_train\n",
      "train mean loss=61769.90052083333\n",
      "test_test\n",
      "test mean loss=87139.859375\n",
      "fin save.\n",
      "epoch 7721\n",
      "test_train\n",
      "train mean loss=61830.89114583333\n",
      "test_test\n",
      "test mean loss=87023.33984375\n",
      "fin save.\n",
      "epoch 7722\n",
      "test_train\n",
      "train mean loss=61869.86341145833\n",
      "test_test\n",
      "test mean loss=87311.9140625\n",
      "fin save.\n",
      "epoch 7723\n",
      "test_train\n",
      "train mean loss=61441.84453125\n",
      "test_test\n",
      "test mean loss=87280.90234375\n",
      "fin save.\n",
      "epoch 7724\n",
      "test_train\n",
      "train mean loss=62018.719921875\n",
      "test_test\n",
      "test mean loss=87268.35546875\n",
      "fin save.\n",
      "epoch 7725\n",
      "test_train\n",
      "train mean loss=62593.23359375\n",
      "test_test\n",
      "test mean loss=87326.171875\n",
      "fin save.\n",
      "epoch 7726\n",
      "test_train\n",
      "train mean loss=62205.26380208333\n",
      "test_test\n",
      "test mean loss=87335.41015625\n",
      "fin save.\n",
      "epoch 7727\n",
      "test_train\n",
      "train mean loss=63038.222395833334\n",
      "test_test\n",
      "test mean loss=87203.2890625\n",
      "fin save.\n",
      "epoch 7728\n",
      "test_train\n",
      "train mean loss=61587.573958333334\n",
      "test_test\n",
      "test mean loss=87266.3359375\n",
      "fin save.\n",
      "epoch 7729\n",
      "test_train\n",
      "train mean loss=62929.0921875\n",
      "test_test\n",
      "test mean loss=87118.26171875\n",
      "fin save.\n",
      "epoch 7730\n",
      "test_train\n",
      "train mean loss=62458.981770833336\n",
      "test_test\n",
      "test mean loss=87262.921875\n",
      "fin save.\n",
      "epoch 7731\n",
      "test_train\n",
      "train mean loss=61474.725260416664\n",
      "test_test\n",
      "test mean loss=87162.07421875\n",
      "fin save.\n",
      "epoch 7732\n",
      "test_train\n",
      "train mean loss=62445.60299479167\n",
      "test_test\n",
      "test mean loss=87409.37109375\n",
      "fin save.\n",
      "epoch 7733\n",
      "test_train\n",
      "train mean loss=62544.50963541667\n",
      "test_test\n",
      "test mean loss=87475.05859375\n",
      "fin save.\n",
      "epoch 7734\n",
      "test_train\n",
      "train mean loss=61828.666015625\n",
      "test_test\n",
      "test mean loss=87205.71875\n",
      "fin save.\n",
      "epoch 7735\n",
      "test_train\n",
      "train mean loss=62869.08359375\n",
      "test_test\n",
      "test mean loss=87173.15234375\n",
      "fin save.\n",
      "epoch 7736\n",
      "test_train\n",
      "train mean loss=63011.23828125\n",
      "test_test\n",
      "test mean loss=87426.1171875\n",
      "fin save.\n",
      "epoch 7737\n",
      "test_train\n",
      "train mean loss=62663.835546875\n",
      "test_test\n",
      "test mean loss=87542.5078125\n",
      "fin save.\n",
      "epoch 7738\n",
      "test_train\n",
      "train mean loss=62359.131510416664\n",
      "test_test\n",
      "test mean loss=87490.03515625\n",
      "fin save.\n",
      "epoch 7739\n",
      "test_train\n",
      "train mean loss=61548.908854166664\n",
      "test_test\n",
      "test mean loss=87410.51171875\n",
      "fin save.\n",
      "epoch 7740\n",
      "test_train\n",
      "train mean loss=62686.234375\n",
      "test_test\n",
      "test mean loss=87409.2578125\n",
      "fin save.\n",
      "epoch 7741\n",
      "test_train\n",
      "train mean loss=62158.830338541666\n",
      "test_test\n",
      "test mean loss=87335.55859375\n",
      "fin save.\n",
      "epoch 7742\n",
      "test_train\n",
      "train mean loss=63034.782942708334\n",
      "test_test\n",
      "test mean loss=87225.7265625\n",
      "fin save.\n",
      "epoch 7743\n",
      "test_train\n",
      "train mean loss=63389.46171875\n",
      "test_test\n",
      "test mean loss=87335.6640625\n",
      "fin save.\n",
      "epoch 7744\n",
      "test_train\n",
      "train mean loss=61529.98671875\n",
      "test_test\n",
      "test mean loss=87309.51953125\n",
      "fin save.\n",
      "epoch 7745\n",
      "test_train\n",
      "train mean loss=61660.52916666667\n",
      "test_test\n",
      "test mean loss=87484.78125\n",
      "fin save.\n",
      "epoch 7746\n",
      "test_train\n",
      "train mean loss=62413.667708333334\n",
      "test_test\n",
      "test mean loss=87664.40625\n",
      "fin save.\n",
      "epoch 7747\n",
      "test_train\n",
      "train mean loss=61515.10078125\n",
      "test_test\n",
      "test mean loss=87613.17578125\n",
      "fin save.\n",
      "epoch 7748\n",
      "test_train\n",
      "train mean loss=62158.27265625\n",
      "test_test\n",
      "test mean loss=87771.19921875\n",
      "fin save.\n",
      "epoch 7749\n",
      "test_train\n",
      "train mean loss=62445.511458333334\n",
      "test_test\n",
      "test mean loss=87587.33203125\n",
      "fin save.\n",
      "epoch 7750\n",
      "test_train\n",
      "train mean loss=62740.443098958334\n",
      "test_test\n",
      "test mean loss=87586.328125\n",
      "fin save.\n",
      "epoch 7751\n",
      "test_train\n",
      "train mean loss=62050.870442708336\n",
      "test_test\n",
      "test mean loss=87620.28125\n",
      "fin save.\n",
      "epoch 7752\n",
      "test_train\n",
      "train mean loss=62274.82630208333\n",
      "test_test\n",
      "test mean loss=87667.234375\n",
      "fin save.\n",
      "epoch 7753\n",
      "test_train\n",
      "train mean loss=62409.14375\n",
      "test_test\n",
      "test mean loss=87642.5234375\n",
      "fin save.\n",
      "epoch 7754\n",
      "test_train\n",
      "train mean loss=62020.120703125\n",
      "test_test\n",
      "test mean loss=87627.171875\n",
      "fin save.\n",
      "epoch 7755\n",
      "test_train\n",
      "train mean loss=62653.162760416664\n",
      "test_test\n",
      "test mean loss=87327.96484375\n",
      "fin save.\n",
      "epoch 7756\n",
      "test_train\n",
      "train mean loss=62294.215625\n",
      "test_test\n",
      "test mean loss=87371.9921875\n",
      "fin save.\n",
      "epoch 7757\n",
      "test_train\n",
      "train mean loss=62090.94583333333\n",
      "test_test\n",
      "test mean loss=87243.58984375\n",
      "fin save.\n",
      "epoch 7758\n",
      "test_train\n",
      "train mean loss=62520.89153645833\n",
      "test_test\n",
      "test mean loss=87526.7578125\n",
      "fin save.\n",
      "epoch 7759\n",
      "test_train\n",
      "train mean loss=62211.52916666667\n",
      "test_test\n",
      "test mean loss=87215.00390625\n",
      "fin save.\n",
      "epoch 7760\n",
      "test_train\n",
      "train mean loss=62373.49895833333\n",
      "test_test\n",
      "test mean loss=87402.65625\n",
      "fin save.\n",
      "epoch 7761\n",
      "test_train\n",
      "train mean loss=61182.01315104167\n",
      "test_test\n",
      "test mean loss=87418.0625\n",
      "fin save.\n",
      "epoch 7762\n",
      "test_train\n",
      "train mean loss=62453.904557291666\n",
      "test_test\n",
      "test mean loss=87559.890625\n",
      "fin save.\n",
      "epoch 7763\n",
      "test_train\n",
      "train mean loss=62598.57916666667\n",
      "test_test\n",
      "test mean loss=87788.0390625\n",
      "fin save.\n",
      "epoch 7764\n",
      "test_train\n",
      "train mean loss=62876.00338541667\n",
      "test_test\n",
      "test mean loss=87498.6640625\n",
      "fin save.\n",
      "epoch 7765\n",
      "test_train\n",
      "train mean loss=62846.04375\n",
      "test_test\n",
      "test mean loss=87572.6484375\n",
      "fin save.\n",
      "epoch 7766\n",
      "test_train\n",
      "train mean loss=62400.2125\n",
      "test_test\n",
      "test mean loss=87559.66015625\n",
      "fin save.\n",
      "epoch 7767\n",
      "test_train\n",
      "train mean loss=61526.97161458333\n",
      "test_test\n",
      "test mean loss=87480.859375\n",
      "fin save.\n",
      "epoch 7768\n",
      "test_train\n",
      "train mean loss=62392.80625\n",
      "test_test\n",
      "test mean loss=87653.23828125\n",
      "fin save.\n",
      "epoch 7769\n",
      "test_train\n",
      "train mean loss=61971.566145833334\n",
      "test_test\n",
      "test mean loss=87342.55859375\n",
      "fin save.\n",
      "epoch 7770\n",
      "test_train\n",
      "train mean loss=62643.467578125\n",
      "test_test\n",
      "test mean loss=87532.92578125\n",
      "fin save.\n",
      "epoch 7771\n",
      "test_train\n",
      "train mean loss=62418.535416666666\n",
      "test_test\n",
      "test mean loss=87383.9375\n",
      "fin save.\n",
      "epoch 7772\n",
      "test_train\n",
      "train mean loss=62406.3453125\n",
      "test_test\n",
      "test mean loss=87861.65625\n",
      "fin save.\n",
      "epoch 7773\n",
      "test_train\n",
      "train mean loss=62036.191015625\n",
      "test_test\n",
      "test mean loss=87603.23828125\n",
      "fin save.\n",
      "epoch 7774\n",
      "test_train\n",
      "train mean loss=62768.72838541667\n",
      "test_test\n",
      "test mean loss=87754.52734375\n",
      "fin save.\n",
      "epoch 7775\n",
      "test_train\n",
      "train mean loss=61373.07630208333\n",
      "test_test\n",
      "test mean loss=87455.86328125\n",
      "fin save.\n",
      "epoch 7776\n",
      "test_train\n",
      "train mean loss=61841.625260416666\n",
      "test_test\n",
      "test mean loss=87456.38671875\n",
      "fin save.\n",
      "epoch 7777\n",
      "test_train\n",
      "train mean loss=63406.22356770833\n",
      "test_test\n",
      "test mean loss=87458.87890625\n",
      "fin save.\n",
      "epoch 7778\n",
      "test_train\n",
      "train mean loss=61637.05651041667\n",
      "test_test\n",
      "test mean loss=87486.74609375\n",
      "fin save.\n",
      "epoch 7779\n",
      "test_train\n",
      "train mean loss=62293.8765625\n",
      "test_test\n",
      "test mean loss=87313.36328125\n",
      "fin save.\n",
      "epoch 7780\n",
      "test_train\n",
      "train mean loss=62319.96731770833\n",
      "test_test\n",
      "test mean loss=87442.0\n",
      "fin save.\n",
      "epoch 7781\n",
      "test_train\n",
      "train mean loss=62231.778125\n",
      "test_test\n",
      "test mean loss=87629.1015625\n",
      "fin save.\n",
      "epoch 7782\n",
      "test_train\n",
      "train mean loss=62481.34453125\n",
      "test_test\n",
      "test mean loss=87484.54296875\n",
      "fin save.\n",
      "epoch 7783\n",
      "test_train\n",
      "train mean loss=63302.43645833333\n",
      "test_test\n",
      "test mean loss=87455.6171875\n",
      "fin save.\n",
      "epoch 7784\n",
      "test_train\n",
      "train mean loss=62558.367838541664\n",
      "test_test\n",
      "test mean loss=87548.59375\n",
      "fin save.\n",
      "epoch 7785\n",
      "test_train\n",
      "train mean loss=61957.58515625\n",
      "test_test\n",
      "test mean loss=87644.12109375\n",
      "fin save.\n",
      "epoch 7786\n",
      "test_train\n",
      "train mean loss=62123.32369791667\n",
      "test_test\n",
      "test mean loss=87629.265625\n",
      "fin save.\n",
      "epoch 7787\n",
      "test_train\n",
      "train mean loss=62558.888020833336\n",
      "test_test\n",
      "test mean loss=87595.62890625\n",
      "fin save.\n",
      "epoch 7788\n",
      "test_train\n",
      "train mean loss=61950.88385416667\n",
      "test_test\n",
      "test mean loss=87525.71875\n",
      "fin save.\n",
      "epoch 7789\n",
      "test_train\n",
      "train mean loss=61369.9265625\n",
      "test_test\n",
      "test mean loss=87487.3203125\n",
      "fin save.\n",
      "epoch 7790\n",
      "test_train\n",
      "train mean loss=62090.9765625\n",
      "test_test\n",
      "test mean loss=87640.6796875\n",
      "fin save.\n",
      "epoch 7791\n",
      "test_train\n",
      "train mean loss=62600.61380208333\n",
      "test_test\n",
      "test mean loss=87438.2109375\n",
      "fin save.\n",
      "epoch 7792\n",
      "test_train\n",
      "train mean loss=62036.26848958333\n",
      "test_test\n",
      "test mean loss=87345.19921875\n",
      "fin save.\n",
      "epoch 7793\n",
      "test_train\n",
      "train mean loss=62579.95494791667\n",
      "test_test\n",
      "test mean loss=87349.12109375\n",
      "fin save.\n",
      "epoch 7794\n",
      "test_train\n",
      "train mean loss=62299.21197916667\n",
      "test_test\n",
      "test mean loss=87577.0078125\n",
      "fin save.\n",
      "epoch 7795\n",
      "test_train\n",
      "train mean loss=62348.30026041667\n",
      "test_test\n",
      "test mean loss=87629.90234375\n",
      "fin save.\n",
      "epoch 7796\n",
      "test_train\n",
      "train mean loss=62758.854166666664\n",
      "test_test\n",
      "test mean loss=87596.75\n",
      "fin save.\n",
      "epoch 7797\n",
      "test_train\n",
      "train mean loss=63461.528645833336\n",
      "test_test\n",
      "test mean loss=87601.04296875\n",
      "fin save.\n",
      "epoch 7798\n",
      "test_train\n",
      "train mean loss=62383.649609375\n",
      "test_test\n",
      "test mean loss=87769.9765625\n",
      "fin save.\n",
      "epoch 7799\n",
      "test_train\n",
      "train mean loss=62782.9796875\n",
      "test_test\n",
      "test mean loss=87596.0390625\n",
      "fin save.\n",
      "epoch 7800\n",
      "test_train\n",
      "train mean loss=62277.505208333336\n",
      "test_test\n",
      "test mean loss=87552.25390625\n",
      "fin save.\n",
      "epoch 7801\n",
      "test_train\n",
      "train mean loss=61956.53802083333\n",
      "test_test\n",
      "test mean loss=87477.48046875\n",
      "fin save.\n",
      "epoch 7802\n",
      "test_train\n",
      "train mean loss=61233.5125\n",
      "test_test\n",
      "test mean loss=87626.3125\n",
      "fin save.\n",
      "epoch 7803\n",
      "test_train\n",
      "train mean loss=61771.3453125\n",
      "test_test\n",
      "test mean loss=87592.87890625\n",
      "fin save.\n",
      "epoch 7804\n",
      "test_train\n",
      "train mean loss=61635.25\n",
      "test_test\n",
      "test mean loss=87639.37890625\n",
      "fin save.\n",
      "epoch 7805\n",
      "test_train\n",
      "train mean loss=62262.31067708333\n",
      "test_test\n",
      "test mean loss=87651.2734375\n",
      "fin save.\n",
      "epoch 7806\n",
      "test_train\n",
      "train mean loss=61786.305989583336\n",
      "test_test\n",
      "test mean loss=87611.40625\n",
      "fin save.\n",
      "epoch 7807\n",
      "test_train\n",
      "train mean loss=62218.375\n",
      "test_test\n",
      "test mean loss=87529.734375\n",
      "fin save.\n",
      "epoch 7808\n",
      "test_train\n",
      "train mean loss=62309.19479166667\n",
      "test_test\n",
      "test mean loss=87527.8046875\n",
      "fin save.\n",
      "epoch 7809\n",
      "test_train\n",
      "train mean loss=61826.683854166666\n",
      "test_test\n",
      "test mean loss=87601.74609375\n",
      "fin save.\n",
      "epoch 7810\n",
      "test_train\n",
      "train mean loss=62986.856770833336\n",
      "test_test\n",
      "test mean loss=87584.85546875\n",
      "fin save.\n",
      "epoch 7811\n",
      "test_train\n",
      "train mean loss=61457.60755208333\n",
      "test_test\n",
      "test mean loss=87613.9765625\n",
      "fin save.\n",
      "epoch 7812\n",
      "test_train\n",
      "train mean loss=62251.26666666667\n",
      "test_test\n",
      "test mean loss=87690.98828125\n",
      "fin save.\n",
      "epoch 7813\n",
      "test_train\n",
      "train mean loss=62688.896875\n",
      "test_test\n",
      "test mean loss=87618.6796875\n",
      "fin save.\n",
      "epoch 7814\n",
      "test_train\n",
      "train mean loss=62384.77552083333\n",
      "test_test\n",
      "test mean loss=87588.5546875\n",
      "fin save.\n",
      "epoch 7815\n",
      "test_train\n",
      "train mean loss=61435.4765625\n",
      "test_test\n",
      "test mean loss=87506.87109375\n",
      "fin save.\n",
      "epoch 7816\n",
      "test_train\n",
      "train mean loss=62822.35247395833\n",
      "test_test\n",
      "test mean loss=87383.76953125\n",
      "fin save.\n",
      "epoch 7817\n",
      "test_train\n",
      "train mean loss=62874.578385416666\n",
      "test_test\n",
      "test mean loss=87606.85546875\n",
      "fin save.\n",
      "epoch 7818\n",
      "test_train\n",
      "train mean loss=62719.607161458334\n",
      "test_test\n",
      "test mean loss=87402.515625\n",
      "fin save.\n",
      "epoch 7819\n",
      "test_train\n",
      "train mean loss=61904.37096354167\n",
      "test_test\n",
      "test mean loss=87291.4140625\n",
      "fin save.\n",
      "epoch 7820\n",
      "test_train\n",
      "train mean loss=62239.8921875\n",
      "test_test\n",
      "test mean loss=87412.6953125\n",
      "fin save.\n",
      "epoch 7821\n",
      "test_train\n",
      "train mean loss=62738.059244791664\n",
      "test_test\n",
      "test mean loss=87662.890625\n",
      "fin save.\n",
      "epoch 7822\n",
      "test_train\n",
      "train mean loss=61454.85260416667\n",
      "test_test\n",
      "test mean loss=87658.6015625\n",
      "fin save.\n",
      "epoch 7823\n",
      "test_train\n",
      "train mean loss=61569.07864583333\n",
      "test_test\n",
      "test mean loss=87490.265625\n",
      "fin save.\n",
      "epoch 7824\n",
      "test_train\n",
      "train mean loss=63159.745833333334\n",
      "test_test\n",
      "test mean loss=87500.3125\n",
      "fin save.\n",
      "epoch 7825\n",
      "test_train\n",
      "train mean loss=63302.6171875\n",
      "test_test\n",
      "test mean loss=87254.5078125\n",
      "fin save.\n",
      "epoch 7826\n",
      "test_train\n",
      "train mean loss=62237.04205729167\n",
      "test_test\n",
      "test mean loss=87443.31640625\n",
      "fin save.\n",
      "epoch 7827\n",
      "test_train\n",
      "train mean loss=62775.855208333334\n",
      "test_test\n",
      "test mean loss=87612.9765625\n",
      "fin save.\n",
      "epoch 7828\n",
      "test_train\n",
      "train mean loss=62159.75143229167\n",
      "test_test\n",
      "test mean loss=87600.01953125\n",
      "fin save.\n",
      "epoch 7829\n",
      "test_train\n",
      "train mean loss=61952.274088541664\n",
      "test_test\n",
      "test mean loss=87663.0234375\n",
      "fin save.\n",
      "epoch 7830\n",
      "test_train\n",
      "train mean loss=62121.75703125\n",
      "test_test\n",
      "test mean loss=87577.9921875\n",
      "fin save.\n",
      "epoch 7831\n",
      "test_train\n",
      "train mean loss=61544.0078125\n",
      "test_test\n",
      "test mean loss=87655.7734375\n",
      "fin save.\n",
      "epoch 7832\n",
      "test_train\n",
      "train mean loss=63261.893359375\n",
      "test_test\n",
      "test mean loss=87617.9140625\n",
      "fin save.\n",
      "epoch 7833\n",
      "test_train\n",
      "train mean loss=61066.290364583336\n",
      "test_test\n",
      "test mean loss=87663.8203125\n",
      "fin save.\n",
      "epoch 7834\n",
      "test_train\n",
      "train mean loss=61682.7390625\n",
      "test_test\n",
      "test mean loss=87809.41015625\n",
      "fin save.\n",
      "epoch 7835\n",
      "test_train\n",
      "train mean loss=62511.63958333333\n",
      "test_test\n",
      "test mean loss=87904.0625\n",
      "fin save.\n",
      "epoch 7836\n",
      "test_train\n",
      "train mean loss=62502.57604166667\n",
      "test_test\n",
      "test mean loss=87914.6640625\n",
      "fin save.\n",
      "epoch 7837\n",
      "test_train\n",
      "train mean loss=63074.878645833334\n",
      "test_test\n",
      "test mean loss=87534.54296875\n",
      "fin save.\n",
      "epoch 7838\n",
      "test_train\n",
      "train mean loss=62158.17760416667\n",
      "test_test\n",
      "test mean loss=87504.15234375\n",
      "fin save.\n",
      "epoch 7839\n",
      "test_train\n",
      "train mean loss=62498.91497395833\n",
      "test_test\n",
      "test mean loss=87514.015625\n",
      "fin save.\n",
      "epoch 7840\n",
      "test_train\n",
      "train mean loss=62013.8046875\n",
      "test_test\n",
      "test mean loss=87681.390625\n",
      "fin save.\n",
      "epoch 7841\n",
      "test_train\n",
      "train mean loss=61884.452864583334\n",
      "test_test\n",
      "test mean loss=87401.9609375\n",
      "fin save.\n",
      "epoch 7842\n",
      "test_train\n",
      "train mean loss=62504.581770833334\n",
      "test_test\n",
      "test mean loss=87606.546875\n",
      "fin save.\n",
      "epoch 7843\n",
      "test_train\n",
      "train mean loss=62028.231640625\n",
      "test_test\n",
      "test mean loss=87580.5703125\n",
      "fin save.\n",
      "epoch 7844\n",
      "test_train\n",
      "train mean loss=61637.13046875\n",
      "test_test\n",
      "test mean loss=87597.95703125\n",
      "fin save.\n",
      "epoch 7845\n",
      "test_train\n",
      "train mean loss=61662.837239583336\n",
      "test_test\n",
      "test mean loss=87600.55859375\n",
      "fin save.\n",
      "epoch 7846\n",
      "test_train\n",
      "train mean loss=62899.741927083334\n",
      "test_test\n",
      "test mean loss=87394.328125\n",
      "fin save.\n",
      "epoch 7847\n",
      "test_train\n",
      "train mean loss=62698.994791666664\n",
      "test_test\n",
      "test mean loss=87481.59375\n",
      "fin save.\n",
      "epoch 7848\n",
      "test_train\n",
      "train mean loss=62253.6953125\n",
      "test_test\n",
      "test mean loss=87513.39453125\n",
      "fin save.\n",
      "epoch 7849\n",
      "test_train\n",
      "train mean loss=62485.65807291667\n",
      "test_test\n",
      "test mean loss=87392.23046875\n",
      "fin save.\n",
      "epoch 7850\n",
      "test_train\n",
      "train mean loss=61552.16940104167\n",
      "test_test\n",
      "test mean loss=87548.36328125\n",
      "fin save.\n",
      "epoch 7851\n",
      "test_train\n",
      "train mean loss=62951.01184895833\n",
      "test_test\n",
      "test mean loss=87515.13671875\n",
      "fin save.\n",
      "epoch 7852\n",
      "test_train\n",
      "train mean loss=61932.66796875\n",
      "test_test\n",
      "test mean loss=87748.19921875\n",
      "fin save.\n",
      "epoch 7853\n",
      "test_train\n",
      "train mean loss=61985.40442708333\n",
      "test_test\n",
      "test mean loss=87766.9140625\n",
      "fin save.\n",
      "epoch 7854\n",
      "test_train\n",
      "train mean loss=62813.99713541667\n",
      "test_test\n",
      "test mean loss=87892.01171875\n",
      "fin save.\n",
      "epoch 7855\n",
      "test_train\n",
      "train mean loss=62267.351822916666\n",
      "test_test\n",
      "test mean loss=87790.86328125\n",
      "fin save.\n",
      "epoch 7856\n",
      "test_train\n",
      "train mean loss=62594.457291666666\n",
      "test_test\n",
      "test mean loss=87789.453125\n",
      "fin save.\n",
      "epoch 7857\n",
      "test_train\n",
      "train mean loss=62072.299479166664\n",
      "test_test\n",
      "test mean loss=87921.890625\n",
      "fin save.\n",
      "epoch 7858\n",
      "test_train\n",
      "train mean loss=61012.86901041667\n",
      "test_test\n",
      "test mean loss=87826.19140625\n",
      "fin save.\n",
      "epoch 7859\n",
      "test_train\n",
      "train mean loss=62690.68255208333\n",
      "test_test\n",
      "test mean loss=87744.72265625\n",
      "fin save.\n",
      "epoch 7860\n",
      "test_train\n",
      "train mean loss=63399.370442708336\n",
      "test_test\n",
      "test mean loss=87739.90234375\n",
      "fin save.\n",
      "epoch 7861\n",
      "test_train\n",
      "train mean loss=61732.15416666667\n",
      "test_test\n",
      "test mean loss=87687.7578125\n",
      "fin save.\n",
      "epoch 7862\n",
      "test_train\n",
      "train mean loss=61973.35690104167\n",
      "test_test\n",
      "test mean loss=87491.94140625\n",
      "fin save.\n",
      "epoch 7863\n",
      "test_train\n",
      "train mean loss=61959.88567708333\n",
      "test_test\n",
      "test mean loss=87637.26953125\n",
      "fin save.\n",
      "epoch 7864\n",
      "test_train\n",
      "train mean loss=62581.875\n",
      "test_test\n",
      "test mean loss=87547.77734375\n",
      "fin save.\n",
      "epoch 7865\n",
      "test_train\n",
      "train mean loss=62323.3234375\n",
      "test_test\n",
      "test mean loss=87611.4921875\n",
      "fin save.\n",
      "epoch 7866\n",
      "test_train\n",
      "train mean loss=62013.326822916664\n",
      "test_test\n",
      "test mean loss=87525.796875\n",
      "fin save.\n",
      "epoch 7867\n",
      "test_train\n",
      "train mean loss=62081.69869791667\n",
      "test_test\n",
      "test mean loss=87443.82421875\n",
      "fin save.\n",
      "epoch 7868\n",
      "test_train\n",
      "train mean loss=62070.25598958333\n",
      "test_test\n",
      "test mean loss=87448.01171875\n",
      "fin save.\n",
      "epoch 7869\n",
      "test_train\n",
      "train mean loss=62391.34270833333\n",
      "test_test\n",
      "test mean loss=87352.20703125\n",
      "fin save.\n",
      "epoch 7870\n",
      "test_train\n",
      "train mean loss=62378.12682291667\n",
      "test_test\n",
      "test mean loss=87330.62109375\n",
      "fin save.\n",
      "epoch 7871\n",
      "test_train\n",
      "train mean loss=62239.379166666666\n",
      "test_test\n",
      "test mean loss=87472.375\n",
      "fin save.\n",
      "epoch 7872\n",
      "test_train\n",
      "train mean loss=62710.83125\n",
      "test_test\n",
      "test mean loss=87459.30859375\n",
      "fin save.\n",
      "epoch 7873\n",
      "test_train\n",
      "train mean loss=62895.291666666664\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=87432.22265625\n",
      "fin save.\n",
      "epoch 7874\n",
      "test_train\n",
      "train mean loss=62340.396875\n",
      "test_test\n",
      "test mean loss=87618.3203125\n",
      "fin save.\n",
      "epoch 7875\n",
      "test_train\n",
      "train mean loss=61573.7203125\n",
      "test_test\n",
      "test mean loss=87707.66796875\n",
      "fin save.\n",
      "epoch 7876\n",
      "test_train\n",
      "train mean loss=61402.205859375\n",
      "test_test\n",
      "test mean loss=87427.3359375\n",
      "fin save.\n",
      "epoch 7877\n",
      "test_train\n",
      "train mean loss=61788.561848958336\n",
      "test_test\n",
      "test mean loss=87349.046875\n",
      "fin save.\n",
      "epoch 7878\n",
      "test_train\n",
      "train mean loss=62482.79739583333\n",
      "test_test\n",
      "test mean loss=87480.43359375\n",
      "fin save.\n",
      "epoch 7879\n",
      "test_train\n",
      "train mean loss=62195.972395833334\n",
      "test_test\n",
      "test mean loss=87418.72265625\n",
      "fin save.\n",
      "epoch 7880\n",
      "test_train\n",
      "train mean loss=62673.24453125\n",
      "test_test\n",
      "test mean loss=87292.35546875\n",
      "fin save.\n",
      "epoch 7881\n",
      "test_train\n",
      "train mean loss=62689.83580729167\n",
      "test_test\n",
      "test mean loss=87200.9296875\n",
      "fin save.\n",
      "epoch 7882\n",
      "test_train\n",
      "train mean loss=61734.760546875\n",
      "test_test\n",
      "test mean loss=87210.67578125\n",
      "fin save.\n",
      "epoch 7883\n",
      "test_train\n",
      "train mean loss=62139.98151041667\n",
      "test_test\n",
      "test mean loss=87233.3125\n",
      "fin save.\n",
      "epoch 7884\n",
      "test_train\n",
      "train mean loss=61436.6734375\n",
      "test_test\n",
      "test mean loss=87316.2109375\n",
      "fin save.\n",
      "epoch 7885\n",
      "test_train\n",
      "train mean loss=61600.3421875\n",
      "test_test\n",
      "test mean loss=87660.59765625\n",
      "fin save.\n",
      "epoch 7886\n",
      "test_train\n",
      "train mean loss=62062.304947916666\n",
      "test_test\n",
      "test mean loss=87366.40234375\n",
      "fin save.\n",
      "epoch 7887\n",
      "test_train\n",
      "train mean loss=61985.343489583334\n",
      "test_test\n",
      "test mean loss=87224.65625\n",
      "fin save.\n",
      "epoch 7888\n",
      "test_train\n",
      "train mean loss=61790.127604166664\n",
      "test_test\n",
      "test mean loss=87339.64453125\n",
      "fin save.\n",
      "epoch 7889\n",
      "test_train\n",
      "train mean loss=62003.430989583336\n",
      "test_test\n",
      "test mean loss=87261.51953125\n",
      "fin save.\n",
      "epoch 7890\n",
      "test_train\n",
      "train mean loss=63032.89153645833\n",
      "test_test\n",
      "test mean loss=87099.2734375\n",
      "fin save.\n",
      "epoch 7891\n",
      "test_train\n",
      "train mean loss=62213.40377604167\n",
      "test_test\n",
      "test mean loss=87436.3359375\n",
      "fin save.\n",
      "epoch 7892\n",
      "test_train\n",
      "train mean loss=62102.403125\n",
      "test_test\n",
      "test mean loss=87273.2734375\n",
      "fin save.\n",
      "epoch 7893\n",
      "test_train\n",
      "train mean loss=62931.508072916666\n",
      "test_test\n",
      "test mean loss=87542.09375\n",
      "fin save.\n",
      "epoch 7894\n",
      "test_train\n",
      "train mean loss=62238.757552083334\n",
      "test_test\n",
      "test mean loss=87459.39453125\n",
      "fin save.\n",
      "epoch 7895\n",
      "test_train\n",
      "train mean loss=62951.39947916667\n",
      "test_test\n",
      "test mean loss=87230.46484375\n",
      "fin save.\n",
      "epoch 7896\n",
      "test_train\n",
      "train mean loss=62764.18255208333\n",
      "test_test\n",
      "test mean loss=87317.99609375\n",
      "fin save.\n",
      "epoch 7897\n",
      "test_train\n",
      "train mean loss=63962.93567708333\n",
      "test_test\n",
      "test mean loss=87157.296875\n",
      "fin save.\n",
      "epoch 7898\n",
      "test_train\n",
      "train mean loss=62292.70169270833\n",
      "test_test\n",
      "test mean loss=87641.0625\n",
      "fin save.\n",
      "epoch 7899\n",
      "test_train\n",
      "train mean loss=62383.83307291667\n",
      "test_test\n",
      "test mean loss=87642.66796875\n",
      "fin save.\n",
      "epoch 7900\n",
      "test_train\n",
      "train mean loss=63017.28828125\n",
      "test_test\n",
      "test mean loss=87583.23828125\n",
      "fin save.\n",
      "epoch 7901\n",
      "test_train\n",
      "train mean loss=61938.16953125\n",
      "test_test\n",
      "test mean loss=87508.80078125\n",
      "fin save.\n",
      "epoch 7902\n",
      "test_train\n",
      "train mean loss=62990.037760416664\n",
      "test_test\n",
      "test mean loss=87312.84765625\n",
      "fin save.\n",
      "epoch 7903\n",
      "test_train\n",
      "train mean loss=62168.14153645833\n",
      "test_test\n",
      "test mean loss=87480.8984375\n",
      "fin save.\n",
      "epoch 7904\n",
      "test_train\n",
      "train mean loss=63080.720052083336\n",
      "test_test\n",
      "test mean loss=87368.12109375\n",
      "fin save.\n",
      "epoch 7905\n",
      "test_train\n",
      "train mean loss=61760.273177083334\n",
      "test_test\n",
      "test mean loss=87660.66796875\n",
      "fin save.\n",
      "epoch 7906\n",
      "test_train\n",
      "train mean loss=62044.78958333333\n",
      "test_test\n",
      "test mean loss=87562.84765625\n",
      "fin save.\n",
      "epoch 7907\n",
      "test_train\n",
      "train mean loss=61891.722395833334\n",
      "test_test\n",
      "test mean loss=87393.38671875\n",
      "fin save.\n",
      "epoch 7908\n",
      "test_train\n",
      "train mean loss=62876.66171875\n",
      "test_test\n",
      "test mean loss=87621.34375\n",
      "fin save.\n",
      "epoch 7909\n",
      "test_train\n",
      "train mean loss=61094.011979166666\n",
      "test_test\n",
      "test mean loss=87475.109375\n",
      "fin save.\n",
      "epoch 7910\n",
      "test_train\n",
      "train mean loss=61605.186197916664\n",
      "test_test\n",
      "test mean loss=87426.3671875\n",
      "fin save.\n",
      "epoch 7911\n",
      "test_train\n",
      "train mean loss=63003.98515625\n",
      "test_test\n",
      "test mean loss=87396.47265625\n",
      "fin save.\n",
      "epoch 7912\n",
      "test_train\n",
      "train mean loss=61712.71171875\n",
      "test_test\n",
      "test mean loss=87523.2890625\n",
      "fin save.\n",
      "epoch 7913\n",
      "test_train\n",
      "train mean loss=61408.055989583336\n",
      "test_test\n",
      "test mean loss=87388.8046875\n",
      "fin save.\n",
      "epoch 7914\n",
      "test_train\n",
      "train mean loss=62218.61223958333\n",
      "test_test\n",
      "test mean loss=87278.01953125\n",
      "fin save.\n",
      "epoch 7915\n",
      "test_train\n",
      "train mean loss=62239.159375\n",
      "test_test\n",
      "test mean loss=87137.47265625\n",
      "fin save.\n",
      "epoch 7916\n",
      "test_train\n",
      "train mean loss=62892.03463541667\n",
      "test_test\n",
      "test mean loss=87394.734375\n",
      "fin save.\n",
      "epoch 7917\n",
      "test_train\n",
      "train mean loss=61964.7109375\n",
      "test_test\n",
      "test mean loss=87453.203125\n",
      "fin save.\n",
      "epoch 7918\n",
      "test_train\n",
      "train mean loss=62247.27135416667\n",
      "test_test\n",
      "test mean loss=87452.01953125\n",
      "fin save.\n",
      "epoch 7919\n",
      "test_train\n",
      "train mean loss=62131.39739583333\n",
      "test_test\n",
      "test mean loss=87513.03515625\n",
      "fin save.\n",
      "epoch 7920\n",
      "test_train\n",
      "train mean loss=61523.55755208333\n",
      "test_test\n",
      "test mean loss=87455.203125\n",
      "fin save.\n",
      "epoch 7921\n",
      "test_train\n",
      "train mean loss=62283.66901041667\n",
      "test_test\n",
      "test mean loss=87462.953125\n",
      "fin save.\n",
      "epoch 7922\n",
      "test_train\n",
      "train mean loss=62264.85690104167\n",
      "test_test\n",
      "test mean loss=87565.296875\n",
      "fin save.\n",
      "epoch 7923\n",
      "test_train\n",
      "train mean loss=63499.601302083334\n",
      "test_test\n",
      "test mean loss=87564.625\n",
      "fin save.\n",
      "epoch 7924\n",
      "test_train\n",
      "train mean loss=61997.111067708334\n",
      "test_test\n",
      "test mean loss=87425.65625\n",
      "fin save.\n",
      "epoch 7925\n",
      "test_train\n",
      "train mean loss=63492.436197916664\n",
      "test_test\n",
      "test mean loss=87542.37890625\n",
      "fin save.\n",
      "epoch 7926\n",
      "test_train\n",
      "train mean loss=62191.64505208333\n",
      "test_test\n",
      "test mean loss=87506.8984375\n",
      "fin save.\n",
      "epoch 7927\n",
      "test_train\n",
      "train mean loss=62190.26666666667\n",
      "test_test\n",
      "test mean loss=87587.57421875\n",
      "fin save.\n",
      "epoch 7928\n",
      "test_train\n",
      "train mean loss=61782.962239583336\n",
      "test_test\n",
      "test mean loss=87734.35546875\n",
      "fin save.\n",
      "epoch 7929\n",
      "test_train\n",
      "train mean loss=63177.010546875\n",
      "test_test\n",
      "test mean loss=87716.03125\n",
      "fin save.\n",
      "epoch 7930\n",
      "test_train\n",
      "train mean loss=61554.632552083334\n",
      "test_test\n",
      "test mean loss=87608.9765625\n",
      "fin save.\n",
      "epoch 7931\n",
      "test_train\n",
      "train mean loss=61757.923828125\n",
      "test_test\n",
      "test mean loss=87594.93359375\n",
      "fin save.\n",
      "epoch 7932\n",
      "test_train\n",
      "train mean loss=62690.396223958334\n",
      "test_test\n",
      "test mean loss=87609.5859375\n",
      "fin save.\n",
      "epoch 7933\n",
      "test_train\n",
      "train mean loss=61828.34557291667\n",
      "test_test\n",
      "test mean loss=87673.39453125\n",
      "fin save.\n",
      "epoch 7934\n",
      "test_train\n",
      "train mean loss=62712.077734375\n",
      "test_test\n",
      "test mean loss=87589.81640625\n",
      "fin save.\n",
      "epoch 7935\n",
      "test_train\n",
      "train mean loss=63041.256510416664\n",
      "test_test\n",
      "test mean loss=87488.171875\n",
      "fin save.\n",
      "epoch 7936\n",
      "test_train\n",
      "train mean loss=61008.834244791666\n",
      "test_test\n",
      "test mean loss=87662.89453125\n",
      "fin save.\n",
      "epoch 7937\n",
      "test_train\n",
      "train mean loss=61460.81588541667\n",
      "test_test\n",
      "test mean loss=87529.3828125\n",
      "fin save.\n",
      "epoch 7938\n",
      "test_train\n",
      "train mean loss=61965.84479166667\n",
      "test_test\n",
      "test mean loss=87751.61328125\n",
      "fin save.\n",
      "epoch 7939\n",
      "test_train\n",
      "train mean loss=61452.60546875\n",
      "test_test\n",
      "test mean loss=87747.03125\n",
      "fin save.\n",
      "epoch 7940\n",
      "test_train\n",
      "train mean loss=62764.85052083333\n",
      "test_test\n",
      "test mean loss=88154.2890625\n",
      "fin save.\n",
      "epoch 7941\n",
      "test_train\n",
      "train mean loss=61932.57708333333\n",
      "test_test\n",
      "test mean loss=88098.8203125\n",
      "fin save.\n",
      "epoch 7942\n",
      "test_train\n",
      "train mean loss=62416.8390625\n",
      "test_test\n",
      "test mean loss=87673.56640625\n",
      "fin save.\n",
      "epoch 7943\n",
      "test_train\n",
      "train mean loss=61387.581770833334\n",
      "test_test\n",
      "test mean loss=87824.57421875\n",
      "fin save.\n",
      "epoch 7944\n",
      "test_train\n",
      "train mean loss=62723.91940104167\n",
      "test_test\n",
      "test mean loss=87856.32421875\n",
      "fin save.\n",
      "epoch 7945\n",
      "test_train\n",
      "train mean loss=62213.29869791667\n",
      "test_test\n",
      "test mean loss=88146.1015625\n",
      "fin save.\n",
      "epoch 7946\n",
      "test_train\n",
      "train mean loss=61734.94921875\n",
      "test_test\n",
      "test mean loss=88460.05078125\n",
      "fin save.\n",
      "epoch 7947\n",
      "test_train\n",
      "train mean loss=62676.601171875\n",
      "test_test\n",
      "test mean loss=88026.296875\n",
      "fin save.\n",
      "epoch 7948\n",
      "test_train\n",
      "train mean loss=62979.984114583334\n",
      "test_test\n",
      "test mean loss=87856.1875\n",
      "fin save.\n",
      "epoch 7949\n",
      "test_train\n",
      "train mean loss=61646.24140625\n",
      "test_test\n",
      "test mean loss=87887.3203125\n",
      "fin save.\n",
      "epoch 7950\n",
      "test_train\n",
      "train mean loss=61550.901171875\n",
      "test_test\n",
      "test mean loss=87868.7578125\n",
      "fin save.\n",
      "epoch 7951\n",
      "test_train\n",
      "train mean loss=61997.11432291667\n",
      "test_test\n",
      "test mean loss=87772.3046875\n",
      "fin save.\n",
      "epoch 7952\n",
      "test_train\n",
      "train mean loss=61863.73515625\n",
      "test_test\n",
      "test mean loss=88005.8515625\n",
      "fin save.\n",
      "epoch 7953\n",
      "test_train\n",
      "train mean loss=62984.41354166667\n",
      "test_test\n",
      "test mean loss=87962.25\n",
      "fin save.\n",
      "epoch 7954\n",
      "test_train\n",
      "train mean loss=61816.308333333334\n",
      "test_test\n",
      "test mean loss=87754.18359375\n",
      "fin save.\n",
      "epoch 7955\n",
      "test_train\n",
      "train mean loss=62749.23736979167\n",
      "test_test\n",
      "test mean loss=87830.5234375\n",
      "fin save.\n",
      "epoch 7956\n",
      "test_train\n",
      "train mean loss=61156.02421875\n",
      "test_test\n",
      "test mean loss=87639.5546875\n",
      "fin save.\n",
      "epoch 7957\n",
      "test_train\n",
      "train mean loss=63137.83684895833\n",
      "test_test\n",
      "test mean loss=87731.68359375\n",
      "fin save.\n",
      "epoch 7958\n",
      "test_train\n",
      "train mean loss=62027.770833333336\n",
      "test_test\n",
      "test mean loss=87954.78515625\n",
      "fin save.\n",
      "epoch 7959\n",
      "test_train\n",
      "train mean loss=63096.8328125\n",
      "test_test\n",
      "test mean loss=87851.29296875\n",
      "fin save.\n",
      "epoch 7960\n",
      "test_train\n",
      "train mean loss=62104.18125\n",
      "test_test\n",
      "test mean loss=87943.6953125\n",
      "fin save.\n",
      "epoch 7961\n",
      "test_train\n",
      "train mean loss=61134.921614583334\n",
      "test_test\n",
      "test mean loss=88308.7890625\n",
      "fin save.\n",
      "epoch 7962\n",
      "test_train\n",
      "train mean loss=62067.16067708333\n",
      "test_test\n",
      "test mean loss=88031.28125\n",
      "fin save.\n",
      "epoch 7963\n",
      "test_train\n",
      "train mean loss=61647.73255208333\n",
      "test_test\n",
      "test mean loss=88042.6171875\n",
      "fin save.\n",
      "epoch 7964\n",
      "test_train\n",
      "train mean loss=61900.583333333336\n",
      "test_test\n",
      "test mean loss=88232.3203125\n",
      "fin save.\n",
      "epoch 7965\n",
      "test_train\n",
      "train mean loss=63293.72057291667\n",
      "test_test\n",
      "test mean loss=88094.9296875\n",
      "fin save.\n",
      "epoch 7966\n",
      "test_train\n",
      "train mean loss=62295.98333333333\n",
      "test_test\n",
      "test mean loss=88173.98828125\n",
      "fin save.\n",
      "epoch 7967\n",
      "test_train\n",
      "train mean loss=62428.34453125\n",
      "test_test\n",
      "test mean loss=88050.25390625\n",
      "fin save.\n",
      "epoch 7968\n",
      "test_train\n",
      "train mean loss=62473.82473958333\n",
      "test_test\n",
      "test mean loss=88043.15625\n",
      "fin save.\n",
      "epoch 7969\n",
      "test_train\n",
      "train mean loss=61702.194921875\n",
      "test_test\n",
      "test mean loss=88240.51171875\n",
      "fin save.\n",
      "epoch 7970\n",
      "test_train\n",
      "train mean loss=63704.64296875\n",
      "test_test\n",
      "test mean loss=87773.18359375\n",
      "fin save.\n",
      "epoch 7971\n",
      "test_train\n",
      "train mean loss=61929.066015625\n",
      "test_test\n",
      "test mean loss=87734.9375\n",
      "fin save.\n",
      "epoch 7972\n",
      "test_train\n",
      "train mean loss=62542.44765625\n",
      "test_test\n",
      "test mean loss=87715.2109375\n",
      "fin save.\n",
      "epoch 7973\n",
      "test_train\n",
      "train mean loss=63028.67682291667\n",
      "test_test\n",
      "test mean loss=87656.9609375\n",
      "fin save.\n",
      "epoch 7974\n",
      "test_train\n",
      "train mean loss=63079.259114583336\n",
      "test_test\n",
      "test mean loss=87633.69140625\n",
      "fin save.\n",
      "epoch 7975\n",
      "test_train\n",
      "train mean loss=61314.7859375\n",
      "test_test\n",
      "test mean loss=87424.74609375\n",
      "fin save.\n",
      "epoch 7976\n",
      "test_train\n",
      "train mean loss=62058.287890625\n",
      "test_test\n",
      "test mean loss=87565.6640625\n",
      "fin save.\n",
      "epoch 7977\n",
      "test_train\n",
      "train mean loss=61731.5265625\n",
      "test_test\n",
      "test mean loss=87632.56640625\n",
      "fin save.\n",
      "epoch 7978\n",
      "test_train\n",
      "train mean loss=61995.65234375\n",
      "test_test\n",
      "test mean loss=87634.28515625\n",
      "fin save.\n",
      "epoch 7979\n",
      "test_train\n",
      "train mean loss=61853.576432291666\n",
      "test_test\n",
      "test mean loss=87682.5625\n",
      "fin save.\n",
      "epoch 7980\n",
      "test_train\n",
      "train mean loss=62045.195052083334\n",
      "test_test\n",
      "test mean loss=87658.68359375\n",
      "fin save.\n",
      "epoch 7981\n",
      "test_train\n",
      "train mean loss=62447.883203125\n",
      "test_test\n",
      "test mean loss=87664.87890625\n",
      "fin save.\n",
      "epoch 7982\n",
      "test_train\n",
      "train mean loss=61318.671875\n",
      "test_test\n",
      "test mean loss=87724.5546875\n",
      "fin save.\n",
      "epoch 7983\n",
      "test_train\n",
      "train mean loss=62275.2375\n",
      "test_test\n",
      "test mean loss=87702.95703125\n",
      "fin save.\n",
      "epoch 7984\n",
      "test_train\n",
      "train mean loss=61587.440625\n",
      "test_test\n",
      "test mean loss=87744.4140625\n",
      "fin save.\n",
      "epoch 7985\n",
      "test_train\n",
      "train mean loss=63634.268229166664\n",
      "test_test\n",
      "test mean loss=87734.14453125\n",
      "fin save.\n",
      "epoch 7986\n",
      "test_train\n",
      "train mean loss=62686.947916666664\n",
      "test_test\n",
      "test mean loss=87744.2734375\n",
      "fin save.\n",
      "epoch 7987\n",
      "test_train\n",
      "train mean loss=61853.15416666667\n",
      "test_test\n",
      "test mean loss=87534.09765625\n",
      "fin save.\n",
      "epoch 7988\n",
      "test_train\n",
      "train mean loss=62427.6546875\n",
      "test_test\n",
      "test mean loss=87654.0546875\n",
      "fin save.\n",
      "epoch 7989\n",
      "test_train\n",
      "train mean loss=62502.0296875\n",
      "test_test\n",
      "test mean loss=87824.30859375\n",
      "fin save.\n",
      "epoch 7990\n",
      "test_train\n",
      "train mean loss=62339.83776041667\n",
      "test_test\n",
      "test mean loss=87592.4609375\n",
      "fin save.\n",
      "epoch 7991\n",
      "test_train\n",
      "train mean loss=63728.83151041667\n",
      "test_test\n",
      "test mean loss=87698.73046875\n",
      "fin save.\n",
      "epoch 7992\n",
      "test_train\n",
      "train mean loss=62165.51067708333\n",
      "test_test\n",
      "test mean loss=87666.37890625\n",
      "fin save.\n",
      "epoch 7993\n",
      "test_train\n",
      "train mean loss=62214.314192708334\n",
      "test_test\n",
      "test mean loss=87675.90234375\n",
      "fin save.\n",
      "epoch 7994\n",
      "test_train\n",
      "train mean loss=61621.73046875\n",
      "test_test\n",
      "test mean loss=88139.44921875\n",
      "fin save.\n",
      "epoch 7995\n",
      "test_train\n",
      "train mean loss=62908.055338541664\n",
      "test_test\n",
      "test mean loss=87929.09765625\n",
      "fin save.\n",
      "epoch 7996\n",
      "test_train\n",
      "train mean loss=61472.86380208333\n",
      "test_test\n",
      "test mean loss=87638.89453125\n",
      "fin save.\n",
      "epoch 7997\n",
      "test_train\n",
      "train mean loss=62703.57890625\n",
      "test_test\n",
      "test mean loss=87838.55859375\n",
      "fin save.\n",
      "epoch 7998\n",
      "test_train\n",
      "train mean loss=62602.303385416664\n",
      "test_test\n",
      "test mean loss=87760.12890625\n",
      "fin save.\n",
      "epoch 7999\n",
      "test_train\n",
      "train mean loss=62201.420572916664\n",
      "test_test\n",
      "test mean loss=87700.07421875\n",
      "fin save.\n",
      "epoch 8000\n",
      "test_train\n",
      "train mean loss=61638.84231770833\n",
      "test_test\n",
      "test mean loss=87513.75\n",
      "fin save.\n",
      "epoch 8001\n",
      "test_train\n",
      "train mean loss=61814.5921875\n",
      "test_test\n",
      "test mean loss=87546.29296875\n",
      "fin save.\n",
      "epoch 8002\n",
      "test_train\n",
      "train mean loss=62697.62395833333\n",
      "test_test\n",
      "test mean loss=87436.8984375\n",
      "fin save.\n",
      "epoch 8003\n",
      "test_train\n",
      "train mean loss=61633.02838541667\n",
      "test_test\n",
      "test mean loss=87504.16796875\n",
      "fin save.\n",
      "epoch 8004\n",
      "test_train\n",
      "train mean loss=63244.97161458333\n",
      "test_test\n",
      "test mean loss=87548.5546875\n",
      "fin save.\n",
      "epoch 8005\n",
      "test_train\n",
      "train mean loss=61614.15963541667\n",
      "test_test\n",
      "test mean loss=87659.84765625\n",
      "fin save.\n",
      "epoch 8006\n",
      "test_train\n",
      "train mean loss=62101.613020833334\n",
      "test_test\n",
      "test mean loss=87712.90625\n",
      "fin save.\n",
      "epoch 8007\n",
      "test_train\n",
      "train mean loss=61991.37994791667\n",
      "test_test\n",
      "test mean loss=87642.2578125\n",
      "fin save.\n",
      "epoch 8008\n",
      "test_train\n",
      "train mean loss=62101.6515625\n",
      "test_test\n",
      "test mean loss=87787.33203125\n",
      "fin save.\n",
      "epoch 8009\n",
      "test_train\n",
      "train mean loss=61995.732161458334\n",
      "test_test\n",
      "test mean loss=87901.12109375\n",
      "fin save.\n",
      "epoch 8010\n",
      "test_train\n",
      "train mean loss=63304.040234375\n",
      "test_test\n",
      "test mean loss=87792.37890625\n",
      "fin save.\n",
      "epoch 8011\n",
      "test_train\n",
      "train mean loss=62724.00598958333\n",
      "test_test\n",
      "test mean loss=87721.890625\n",
      "fin save.\n",
      "epoch 8012\n",
      "test_train\n",
      "train mean loss=62907.25546875\n",
      "test_test\n",
      "test mean loss=87326.3671875\n",
      "fin save.\n",
      "epoch 8013\n",
      "test_train\n",
      "train mean loss=63194.128125\n",
      "test_test\n",
      "test mean loss=87133.71875\n",
      "fin save.\n",
      "epoch 8014\n",
      "test_train\n",
      "train mean loss=62583.900390625\n",
      "test_test\n",
      "test mean loss=87064.25\n",
      "fin save.\n",
      "epoch 8015\n",
      "test_train\n",
      "train mean loss=62030.3921875\n",
      "test_test\n",
      "test mean loss=87171.61328125\n",
      "fin save.\n",
      "epoch 8016\n",
      "test_train\n",
      "train mean loss=63434.22161458333\n",
      "test_test\n",
      "test mean loss=87121.41796875\n",
      "fin save.\n",
      "epoch 8017\n",
      "test_train\n",
      "train mean loss=62823.126171875\n",
      "test_test\n",
      "test mean loss=87195.84765625\n",
      "fin save.\n",
      "epoch 8018\n",
      "test_train\n",
      "train mean loss=62488.343098958336\n",
      "test_test\n",
      "test mean loss=87255.78125\n",
      "fin save.\n",
      "epoch 8019\n",
      "test_train\n",
      "train mean loss=62672.13815104167\n",
      "test_test\n",
      "test mean loss=87382.18359375\n",
      "fin save.\n",
      "epoch 8020\n",
      "test_train\n",
      "train mean loss=62063.83346354167\n",
      "test_test\n",
      "test mean loss=87374.01171875\n",
      "fin save.\n",
      "epoch 8021\n",
      "test_train\n",
      "train mean loss=61973.65442708333\n",
      "test_test\n",
      "test mean loss=87283.5703125\n",
      "fin save.\n",
      "epoch 8022\n",
      "test_train\n",
      "train mean loss=62605.71302083333\n",
      "test_test\n",
      "test mean loss=87115.9453125\n",
      "fin save.\n",
      "epoch 8023\n",
      "test_train\n",
      "train mean loss=61836.10729166667\n",
      "test_test\n",
      "test mean loss=87430.109375\n",
      "fin save.\n",
      "epoch 8024\n",
      "test_train\n",
      "train mean loss=62564.76015625\n",
      "test_test\n",
      "test mean loss=86955.59765625\n",
      "fin save.\n",
      "epoch 8025\n",
      "test_train\n",
      "train mean loss=62154.39401041667\n",
      "test_test\n",
      "test mean loss=86947.36328125\n",
      "fin save.\n",
      "epoch 8026\n",
      "test_train\n",
      "train mean loss=63124.22578125\n",
      "test_test\n",
      "test mean loss=86913.1640625\n",
      "fin save.\n",
      "epoch 8027\n",
      "test_train\n",
      "train mean loss=62254.73932291667\n",
      "test_test\n",
      "test mean loss=86672.171875\n",
      "fin save.\n",
      "epoch 8028\n",
      "test_train\n",
      "train mean loss=61541.054427083334\n",
      "test_test\n",
      "test mean loss=86687.6171875\n",
      "fin save.\n",
      "epoch 8029\n",
      "test_train\n",
      "train mean loss=62328.086197916666\n",
      "test_test\n",
      "test mean loss=86523.6328125\n",
      "fin save.\n",
      "epoch 8030\n",
      "test_train\n",
      "train mean loss=61882.95546875\n",
      "test_test\n",
      "test mean loss=86615.08984375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fin save.\n",
      "epoch 8031\n",
      "test_train\n",
      "train mean loss=62863.10299479167\n",
      "test_test\n",
      "test mean loss=86654.63671875\n",
      "fin save.\n",
      "epoch 8032\n",
      "test_train\n",
      "train mean loss=61953.325520833336\n",
      "test_test\n",
      "test mean loss=86917.50390625\n",
      "fin save.\n",
      "epoch 8033\n",
      "test_train\n",
      "train mean loss=62885.56432291667\n",
      "test_test\n",
      "test mean loss=86904.6796875\n",
      "fin save.\n",
      "epoch 8034\n",
      "test_train\n",
      "train mean loss=61349.153645833336\n",
      "test_test\n",
      "test mean loss=86699.13671875\n",
      "fin save.\n",
      "epoch 8035\n",
      "test_train\n",
      "train mean loss=62882.178125\n",
      "test_test\n",
      "test mean loss=87021.34375\n",
      "fin save.\n",
      "epoch 8036\n",
      "test_train\n",
      "train mean loss=63021.02578125\n",
      "test_test\n",
      "test mean loss=86826.3125\n",
      "fin save.\n",
      "epoch 8037\n",
      "test_train\n",
      "train mean loss=62141.08307291667\n",
      "test_test\n",
      "test mean loss=86832.5859375\n",
      "fin save.\n",
      "epoch 8038\n",
      "test_train\n",
      "train mean loss=62018.05364583333\n",
      "test_test\n",
      "test mean loss=86929.4453125\n",
      "fin save.\n",
      "epoch 8039\n",
      "test_train\n",
      "train mean loss=62556.711197916666\n",
      "test_test\n",
      "test mean loss=86953.234375\n",
      "fin save.\n",
      "epoch 8040\n",
      "test_train\n",
      "train mean loss=62278.53177083333\n",
      "test_test\n",
      "test mean loss=87107.8359375\n",
      "fin save.\n",
      "epoch 8041\n",
      "test_train\n",
      "train mean loss=61991.92786458333\n",
      "test_test\n",
      "test mean loss=87104.01171875\n",
      "fin save.\n",
      "epoch 8042\n",
      "test_train\n",
      "train mean loss=62637.584635416664\n",
      "test_test\n",
      "test mean loss=87085.453125\n",
      "fin save.\n",
      "epoch 8043\n",
      "test_train\n",
      "train mean loss=62664.620833333334\n",
      "test_test\n",
      "test mean loss=87046.87109375\n",
      "fin save.\n",
      "epoch 8044\n",
      "test_train\n",
      "train mean loss=63202.059895833336\n",
      "test_test\n",
      "test mean loss=86984.64453125\n",
      "fin save.\n",
      "epoch 8045\n",
      "test_train\n",
      "train mean loss=61851.359375\n",
      "test_test\n",
      "test mean loss=87193.375\n",
      "fin save.\n",
      "epoch 8046\n",
      "test_train\n",
      "train mean loss=63194.85833333333\n",
      "test_test\n",
      "test mean loss=87113.12890625\n",
      "fin save.\n",
      "epoch 8047\n",
      "test_train\n",
      "train mean loss=61958.70208333333\n",
      "test_test\n",
      "test mean loss=87182.48828125\n",
      "fin save.\n",
      "epoch 8048\n",
      "test_train\n",
      "train mean loss=62441.228776041666\n",
      "test_test\n",
      "test mean loss=87245.16015625\n",
      "fin save.\n",
      "epoch 8049\n",
      "test_train\n",
      "train mean loss=62150.19921875\n",
      "test_test\n",
      "test mean loss=87273.19140625\n",
      "fin save.\n",
      "epoch 8050\n",
      "test_train\n",
      "train mean loss=62189.105729166666\n",
      "test_test\n",
      "test mean loss=87476.76171875\n",
      "fin save.\n",
      "epoch 8051\n",
      "test_train\n",
      "train mean loss=62545.49231770833\n",
      "test_test\n",
      "test mean loss=87037.92578125\n",
      "fin save.\n",
      "epoch 8052\n",
      "test_train\n",
      "train mean loss=62629.096875\n",
      "test_test\n",
      "test mean loss=87237.65625\n",
      "fin save.\n",
      "epoch 8053\n",
      "test_train\n",
      "train mean loss=61516.83346354167\n",
      "test_test\n",
      "test mean loss=87181.65625\n",
      "fin save.\n",
      "epoch 8054\n",
      "test_train\n",
      "train mean loss=61334.507552083334\n",
      "test_test\n",
      "test mean loss=87027.37890625\n",
      "fin save.\n",
      "epoch 8055\n",
      "test_train\n",
      "train mean loss=62670.70364583333\n",
      "test_test\n",
      "test mean loss=87067.2578125\n",
      "fin save.\n",
      "epoch 8056\n",
      "test_train\n",
      "train mean loss=61625.564453125\n",
      "test_test\n",
      "test mean loss=87045.59765625\n",
      "fin save.\n",
      "epoch 8057\n",
      "test_train\n",
      "train mean loss=62758.83776041667\n",
      "test_test\n",
      "test mean loss=87145.14453125\n",
      "fin save.\n",
      "epoch 8058\n",
      "test_train\n",
      "train mean loss=62007.28463541667\n",
      "test_test\n",
      "test mean loss=87109.33984375\n",
      "fin save.\n",
      "epoch 8059\n",
      "test_train\n",
      "train mean loss=62115.16979166667\n",
      "test_test\n",
      "test mean loss=87058.86328125\n",
      "fin save.\n",
      "epoch 8060\n",
      "test_train\n",
      "train mean loss=62889.13515625\n",
      "test_test\n",
      "test mean loss=87203.80859375\n",
      "fin save.\n",
      "epoch 8061\n",
      "test_train\n",
      "train mean loss=61353.36223958333\n",
      "test_test\n",
      "test mean loss=87299.734375\n",
      "fin save.\n",
      "epoch 8062\n",
      "test_train\n",
      "train mean loss=61637.08645833333\n",
      "test_test\n",
      "test mean loss=87281.96484375\n",
      "fin save.\n",
      "epoch 8063\n",
      "test_train\n",
      "train mean loss=62493.86536458333\n",
      "test_test\n",
      "test mean loss=87319.98046875\n",
      "fin save.\n",
      "epoch 8064\n",
      "test_train\n",
      "train mean loss=61529.608072916664\n",
      "test_test\n",
      "test mean loss=87293.93359375\n",
      "fin save.\n",
      "epoch 8065\n",
      "test_train\n",
      "train mean loss=62543.90416666667\n",
      "test_test\n",
      "test mean loss=87243.91796875\n",
      "fin save.\n",
      "epoch 8066\n",
      "test_train\n",
      "train mean loss=62504.791666666664\n",
      "test_test\n",
      "test mean loss=87238.078125\n",
      "fin save.\n",
      "epoch 8067\n",
      "test_train\n",
      "train mean loss=61203.06015625\n",
      "test_test\n",
      "test mean loss=87190.4921875\n",
      "fin save.\n",
      "epoch 8068\n",
      "test_train\n",
      "train mean loss=61998.32239583333\n",
      "test_test\n",
      "test mean loss=87272.2265625\n",
      "fin save.\n",
      "epoch 8069\n",
      "test_train\n",
      "train mean loss=61180.876302083336\n",
      "test_test\n",
      "test mean loss=87289.546875\n",
      "fin save.\n",
      "epoch 8070\n",
      "test_train\n",
      "train mean loss=61752.004557291664\n",
      "test_test\n",
      "test mean loss=87275.67578125\n",
      "fin save.\n",
      "epoch 8071\n",
      "test_train\n",
      "train mean loss=62296.98098958333\n",
      "test_test\n",
      "test mean loss=87236.26953125\n",
      "fin save.\n",
      "epoch 8072\n",
      "test_train\n",
      "train mean loss=63058.61901041667\n",
      "test_test\n",
      "test mean loss=87269.5078125\n",
      "fin save.\n",
      "epoch 8073\n",
      "test_train\n",
      "train mean loss=62698.1953125\n",
      "test_test\n",
      "test mean loss=87110.625\n",
      "fin save.\n",
      "epoch 8074\n",
      "test_train\n",
      "train mean loss=61710.83307291667\n",
      "test_test\n",
      "test mean loss=87212.84375\n",
      "fin save.\n",
      "epoch 8075\n",
      "test_train\n",
      "train mean loss=62413.69713541667\n",
      "test_test\n",
      "test mean loss=87275.83984375\n",
      "fin save.\n",
      "epoch 8076\n",
      "test_train\n",
      "train mean loss=62105.149739583336\n",
      "test_test\n",
      "test mean loss=86643.45703125\n",
      "fin save.\n",
      "epoch 8077\n",
      "test_train\n",
      "train mean loss=62399.015625\n",
      "test_test\n",
      "test mean loss=86425.4609375\n",
      "fin save.\n",
      "epoch 8078\n",
      "test_train\n",
      "train mean loss=62083.14557291667\n",
      "test_test\n",
      "test mean loss=86817.8359375\n",
      "fin save.\n",
      "epoch 8079\n",
      "test_train\n",
      "train mean loss=62995.355208333334\n",
      "test_test\n",
      "test mean loss=86567.94921875\n",
      "fin save.\n",
      "epoch 8080\n",
      "test_train\n",
      "train mean loss=62950.983072916664\n",
      "test_test\n",
      "test mean loss=86491.078125\n",
      "fin save.\n",
      "epoch 8081\n",
      "test_train\n",
      "train mean loss=63135.039713541664\n",
      "test_test\n",
      "test mean loss=86716.109375\n",
      "fin save.\n",
      "epoch 8082\n",
      "test_train\n",
      "train mean loss=61208.38372395833\n",
      "test_test\n",
      "test mean loss=86576.27734375\n",
      "fin save.\n",
      "epoch 8083\n",
      "test_train\n",
      "train mean loss=62137.67578125\n",
      "test_test\n",
      "test mean loss=86406.015625\n",
      "fin save.\n",
      "epoch 8084\n",
      "test_train\n",
      "train mean loss=62070.91067708333\n",
      "test_test\n",
      "test mean loss=86309.70703125\n",
      "fin save.\n",
      "epoch 8085\n",
      "test_train\n",
      "train mean loss=62306.991927083334\n",
      "test_test\n",
      "test mean loss=86534.91015625\n",
      "fin save.\n",
      "epoch 8086\n",
      "test_train\n",
      "train mean loss=63840.80026041667\n",
      "test_test\n",
      "test mean loss=86737.08984375\n",
      "fin save.\n",
      "epoch 8087\n",
      "test_train\n",
      "train mean loss=62181.719010416666\n",
      "test_test\n",
      "test mean loss=86939.92578125\n",
      "fin save.\n",
      "epoch 8088\n",
      "test_train\n",
      "train mean loss=63369.521484375\n",
      "test_test\n",
      "test mean loss=86861.1796875\n",
      "fin save.\n",
      "epoch 8089\n",
      "test_train\n",
      "train mean loss=62402.38229166667\n",
      "test_test\n",
      "test mean loss=86802.171875\n",
      "fin save.\n",
      "epoch 8090\n",
      "test_train\n",
      "train mean loss=62158.78502604167\n",
      "test_test\n",
      "test mean loss=87040.140625\n",
      "fin save.\n",
      "epoch 8091\n",
      "test_train\n",
      "train mean loss=62227.22890625\n",
      "test_test\n",
      "test mean loss=87145.78125\n",
      "fin save.\n",
      "epoch 8092\n",
      "test_train\n",
      "train mean loss=62439.905859375\n",
      "test_test\n",
      "test mean loss=87059.65625\n",
      "fin save.\n",
      "epoch 8093\n",
      "test_train\n",
      "train mean loss=62429.3625\n",
      "test_test\n",
      "test mean loss=86920.08203125\n",
      "fin save.\n",
      "epoch 8094\n",
      "test_train\n",
      "train mean loss=61762.634114583336\n",
      "test_test\n",
      "test mean loss=87159.8828125\n",
      "fin save.\n",
      "epoch 8095\n",
      "test_train\n",
      "train mean loss=62900.82760416667\n",
      "test_test\n",
      "test mean loss=87222.5703125\n",
      "fin save.\n",
      "epoch 8096\n",
      "test_train\n",
      "train mean loss=62521.13190104167\n",
      "test_test\n",
      "test mean loss=87164.984375\n",
      "fin save.\n",
      "epoch 8097\n",
      "test_train\n",
      "train mean loss=62129.17005208333\n",
      "test_test\n",
      "test mean loss=86917.64453125\n",
      "fin save.\n",
      "epoch 8098\n",
      "test_train\n",
      "train mean loss=62709.00833333333\n",
      "test_test\n",
      "test mean loss=86869.63671875\n",
      "fin save.\n",
      "epoch 8099\n",
      "test_train\n",
      "train mean loss=62275.66588541667\n",
      "test_test\n",
      "test mean loss=87184.890625\n",
      "fin save.\n",
      "epoch 8100\n",
      "test_train\n",
      "train mean loss=61332.43697916667\n",
      "test_test\n",
      "test mean loss=87089.06640625\n",
      "fin save.\n",
      "epoch 8101\n",
      "test_train\n",
      "train mean loss=61272.897135416664\n",
      "test_test\n",
      "test mean loss=86837.12890625\n",
      "fin save.\n",
      "epoch 8102\n",
      "test_train\n",
      "train mean loss=61804.62057291667\n",
      "test_test\n",
      "test mean loss=86896.96875\n",
      "fin save.\n",
      "epoch 8103\n",
      "test_train\n",
      "train mean loss=62017.495833333334\n",
      "test_test\n",
      "test mean loss=87372.0546875\n",
      "fin save.\n",
      "epoch 8104\n",
      "test_train\n",
      "train mean loss=63095.00703125\n",
      "test_test\n",
      "test mean loss=87063.78125\n",
      "fin save.\n",
      "epoch 8105\n",
      "test_train\n",
      "train mean loss=63131.004166666666\n",
      "test_test\n",
      "test mean loss=86861.90625\n",
      "fin save.\n",
      "epoch 8106\n",
      "test_train\n",
      "train mean loss=61923.195572916666\n",
      "test_test\n",
      "test mean loss=86723.08203125\n",
      "fin save.\n",
      "epoch 8107\n",
      "test_train\n",
      "train mean loss=62052.69088541667\n",
      "test_test\n",
      "test mean loss=86885.1015625\n",
      "fin save.\n",
      "epoch 8108\n",
      "test_train\n",
      "train mean loss=62887.25390625\n",
      "test_test\n",
      "test mean loss=87006.75390625\n",
      "fin save.\n",
      "epoch 8109\n",
      "test_train\n",
      "train mean loss=62471.446614583336\n",
      "test_test\n",
      "test mean loss=86892.79296875\n",
      "fin save.\n",
      "epoch 8110\n",
      "test_train\n",
      "train mean loss=62359.813802083336\n",
      "test_test\n",
      "test mean loss=86928.1328125\n",
      "fin save.\n",
      "epoch 8111\n",
      "test_train\n",
      "train mean loss=62026.70651041667\n",
      "test_test\n",
      "test mean loss=86945.73046875\n",
      "fin save.\n",
      "epoch 8112\n",
      "test_train\n",
      "train mean loss=61870.6421875\n",
      "test_test\n",
      "test mean loss=86975.33203125\n",
      "fin save.\n",
      "epoch 8113\n",
      "test_train\n",
      "train mean loss=63481.80234375\n",
      "test_test\n",
      "test mean loss=87144.96875\n",
      "fin save.\n",
      "epoch 8114\n",
      "test_train\n",
      "train mean loss=61546.565625\n",
      "test_test\n",
      "test mean loss=87266.73828125\n",
      "fin save.\n",
      "epoch 8115\n",
      "test_train\n",
      "train mean loss=62144.271223958334\n",
      "test_test\n",
      "test mean loss=87278.05859375\n",
      "fin save.\n",
      "epoch 8116\n",
      "test_train\n",
      "train mean loss=62113.43671875\n",
      "test_test\n",
      "test mean loss=87131.24609375\n",
      "fin save.\n",
      "epoch 8117\n",
      "test_train\n",
      "train mean loss=62079.81015625\n",
      "test_test\n",
      "test mean loss=87219.84375\n",
      "fin save.\n",
      "epoch 8118\n",
      "test_train\n",
      "train mean loss=62055.70807291667\n",
      "test_test\n",
      "test mean loss=87134.1484375\n",
      "fin save.\n",
      "epoch 8119\n",
      "test_train\n",
      "train mean loss=62332.773177083334\n",
      "test_test\n",
      "test mean loss=87360.89453125\n",
      "fin save.\n",
      "epoch 8120\n",
      "test_train\n",
      "train mean loss=62588.33385416667\n",
      "test_test\n",
      "test mean loss=87499.05078125\n",
      "fin save.\n",
      "epoch 8121\n",
      "test_train\n",
      "train mean loss=63325.92083333333\n",
      "test_test\n",
      "test mean loss=87428.1484375\n",
      "fin save.\n",
      "epoch 8122\n",
      "test_train\n",
      "train mean loss=62281.36796875\n",
      "test_test\n",
      "test mean loss=87464.83203125\n",
      "fin save.\n",
      "epoch 8123\n",
      "test_train\n",
      "train mean loss=62620.01484375\n",
      "test_test\n",
      "test mean loss=87553.328125\n",
      "fin save.\n",
      "epoch 8124\n",
      "test_train\n",
      "train mean loss=62227.89505208333\n",
      "test_test\n",
      "test mean loss=87287.9921875\n",
      "fin save.\n",
      "epoch 8125\n",
      "test_train\n",
      "train mean loss=62865.44609375\n",
      "test_test\n",
      "test mean loss=87112.41796875\n",
      "fin save.\n",
      "epoch 8126\n",
      "test_train\n",
      "train mean loss=62199.92044270833\n",
      "test_test\n",
      "test mean loss=87268.109375\n",
      "fin save.\n",
      "epoch 8127\n",
      "test_train\n",
      "train mean loss=62742.10078125\n",
      "test_test\n",
      "test mean loss=87655.3203125\n",
      "fin save.\n",
      "epoch 8128\n",
      "test_train\n",
      "train mean loss=61825.58645833333\n",
      "test_test\n",
      "test mean loss=87501.8125\n",
      "fin save.\n",
      "epoch 8129\n",
      "test_train\n",
      "train mean loss=62436.59322916667\n",
      "test_test\n",
      "test mean loss=87356.234375\n",
      "fin save.\n",
      "epoch 8130\n",
      "test_train\n",
      "train mean loss=61375.05234375\n",
      "test_test\n",
      "test mean loss=87276.68359375\n",
      "fin save.\n",
      "epoch 8131\n",
      "test_train\n",
      "train mean loss=62593.933333333334\n",
      "test_test\n",
      "test mean loss=87213.21484375\n",
      "fin save.\n",
      "epoch 8132\n",
      "test_train\n",
      "train mean loss=62253.25638020833\n",
      "test_test\n",
      "test mean loss=87327.94140625\n",
      "fin save.\n",
      "epoch 8133\n",
      "test_train\n",
      "train mean loss=62314.63854166667\n",
      "test_test\n",
      "test mean loss=87460.765625\n",
      "fin save.\n",
      "epoch 8134\n",
      "test_train\n",
      "train mean loss=62356.123697916664\n",
      "test_test\n",
      "test mean loss=87644.93359375\n",
      "fin save.\n",
      "epoch 8135\n",
      "test_train\n",
      "train mean loss=62540.63619791667\n",
      "test_test\n",
      "test mean loss=87604.63671875\n",
      "fin save.\n",
      "epoch 8136\n",
      "test_train\n",
      "train mean loss=62809.34453125\n",
      "test_test\n",
      "test mean loss=87736.0546875\n",
      "fin save.\n",
      "epoch 8137\n",
      "test_train\n",
      "train mean loss=61523.86328125\n",
      "test_test\n",
      "test mean loss=87750.609375\n",
      "fin save.\n",
      "epoch 8138\n",
      "test_train\n",
      "train mean loss=62310.86640625\n",
      "test_test\n",
      "test mean loss=87938.015625\n",
      "fin save.\n",
      "epoch 8139\n",
      "test_train\n",
      "train mean loss=62389.325\n",
      "test_test\n",
      "test mean loss=87666.70703125\n",
      "fin save.\n",
      "epoch 8140\n",
      "test_train\n",
      "train mean loss=62445.23880208333\n",
      "test_test\n",
      "test mean loss=87614.4765625\n",
      "fin save.\n",
      "epoch 8141\n",
      "test_train\n",
      "train mean loss=62814.3265625\n",
      "test_test\n",
      "test mean loss=87452.55078125\n",
      "fin save.\n",
      "epoch 8142\n",
      "test_train\n",
      "train mean loss=63680.22252604167\n",
      "test_test\n",
      "test mean loss=87683.88671875\n",
      "fin save.\n",
      "epoch 8143\n",
      "test_train\n",
      "train mean loss=63048.5046875\n",
      "test_test\n",
      "test mean loss=87467.14453125\n",
      "fin save.\n",
      "epoch 8144\n",
      "test_train\n",
      "train mean loss=62948.16197916667\n",
      "test_test\n",
      "test mean loss=87471.44140625\n",
      "fin save.\n",
      "epoch 8145\n",
      "test_train\n",
      "train mean loss=63037.95416666667\n",
      "test_test\n",
      "test mean loss=87615.35546875\n",
      "fin save.\n",
      "epoch 8146\n",
      "test_train\n",
      "train mean loss=61992.69921875\n",
      "test_test\n",
      "test mean loss=87591.49609375\n",
      "fin save.\n",
      "epoch 8147\n",
      "test_train\n",
      "train mean loss=63585.870833333334\n",
      "test_test\n",
      "test mean loss=88324.61328125\n",
      "fin save.\n",
      "epoch 8148\n",
      "test_train\n",
      "train mean loss=63460.899739583336\n",
      "test_test\n",
      "test mean loss=88004.59375\n",
      "fin save.\n",
      "epoch 8149\n",
      "test_train\n",
      "train mean loss=62397.638020833336\n",
      "test_test\n",
      "test mean loss=88015.20703125\n",
      "fin save.\n",
      "epoch 8150\n",
      "test_train\n",
      "train mean loss=63494.03619791667\n",
      "test_test\n",
      "test mean loss=88072.96484375\n",
      "fin save.\n",
      "epoch 8151\n",
      "test_train\n",
      "train mean loss=63003.1890625\n",
      "test_test\n",
      "test mean loss=87933.92578125\n",
      "fin save.\n",
      "epoch 8152\n",
      "test_train\n",
      "train mean loss=63109.33841145833\n",
      "test_test\n",
      "test mean loss=87924.5234375\n",
      "fin save.\n",
      "epoch 8153\n",
      "test_train\n",
      "train mean loss=61917.818359375\n",
      "test_test\n",
      "test mean loss=87892.69140625\n",
      "fin save.\n",
      "epoch 8154\n",
      "test_train\n",
      "train mean loss=62147.55859375\n",
      "test_test\n",
      "test mean loss=88292.2734375\n",
      "fin save.\n",
      "epoch 8155\n",
      "test_train\n",
      "train mean loss=62101.842578125\n",
      "test_test\n",
      "test mean loss=88223.3359375\n",
      "fin save.\n",
      "epoch 8156\n",
      "test_train\n",
      "train mean loss=63177.43541666667\n",
      "test_test\n",
      "test mean loss=88084.6328125\n",
      "fin save.\n",
      "epoch 8157\n",
      "test_train\n",
      "train mean loss=63086.2296875\n",
      "test_test\n",
      "test mean loss=88248.09765625\n",
      "fin save.\n",
      "epoch 8158\n",
      "test_train\n",
      "train mean loss=61955.07473958333\n",
      "test_test\n",
      "test mean loss=88187.125\n",
      "fin save.\n",
      "epoch 8159\n",
      "test_train\n",
      "train mean loss=63299.590104166666\n",
      "test_test\n",
      "test mean loss=88241.1953125\n",
      "fin save.\n",
      "epoch 8160\n",
      "test_train\n",
      "train mean loss=62560.246875\n",
      "test_test\n",
      "test mean loss=88294.34765625\n",
      "fin save.\n",
      "epoch 8161\n",
      "test_train\n",
      "train mean loss=62856.859765625\n",
      "test_test\n",
      "test mean loss=87974.41015625\n",
      "fin save.\n",
      "epoch 8162\n",
      "test_train\n",
      "train mean loss=62168.151041666664\n",
      "test_test\n",
      "test mean loss=88112.265625\n",
      "fin save.\n",
      "epoch 8163\n",
      "test_train\n",
      "train mean loss=62296.67734375\n",
      "test_test\n",
      "test mean loss=88168.75390625\n",
      "fin save.\n",
      "epoch 8164\n",
      "test_train\n",
      "train mean loss=62095.4890625\n",
      "test_test\n",
      "test mean loss=88121.91015625\n",
      "fin save.\n",
      "epoch 8165\n",
      "test_train\n",
      "train mean loss=61617.6140625\n",
      "test_test\n",
      "test mean loss=88141.1484375\n",
      "fin save.\n",
      "epoch 8166\n",
      "test_train\n",
      "train mean loss=63352.720442708334\n",
      "test_test\n",
      "test mean loss=88203.48046875\n",
      "fin save.\n",
      "epoch 8167\n",
      "test_train\n",
      "train mean loss=62297.79973958333\n",
      "test_test\n",
      "test mean loss=88249.08203125\n",
      "fin save.\n",
      "epoch 8168\n",
      "test_train\n",
      "train mean loss=62792.017317708334\n",
      "test_test\n",
      "test mean loss=87976.5\n",
      "fin save.\n",
      "epoch 8169\n",
      "test_train\n",
      "train mean loss=62624.788802083334\n",
      "test_test\n",
      "test mean loss=88106.99609375\n",
      "fin save.\n",
      "epoch 8170\n",
      "test_train\n",
      "train mean loss=62546.225390625\n",
      "test_test\n",
      "test mean loss=88108.1953125\n",
      "fin save.\n",
      "epoch 8171\n",
      "test_train\n",
      "train mean loss=61564.87317708333\n",
      "test_test\n",
      "test mean loss=88057.0\n",
      "fin save.\n",
      "epoch 8172\n",
      "test_train\n",
      "train mean loss=62533.60338541667\n",
      "test_test\n",
      "test mean loss=88218.88671875\n",
      "fin save.\n",
      "epoch 8173\n",
      "test_train\n",
      "train mean loss=62178.6421875\n",
      "test_test\n",
      "test mean loss=87974.8828125\n",
      "fin save.\n",
      "epoch 8174\n",
      "test_train\n",
      "train mean loss=62323.363671875\n",
      "test_test\n",
      "test mean loss=87938.8515625\n",
      "fin save.\n",
      "epoch 8175\n",
      "test_train\n",
      "train mean loss=61708.135416666664\n",
      "test_test\n",
      "test mean loss=88247.10546875\n",
      "fin save.\n",
      "epoch 8176\n",
      "test_train\n",
      "train mean loss=61748.45559895833\n",
      "test_test\n",
      "test mean loss=88245.04296875\n",
      "fin save.\n",
      "epoch 8177\n",
      "test_train\n",
      "train mean loss=62409.76666666667\n",
      "test_test\n",
      "test mean loss=88361.765625\n",
      "fin save.\n",
      "epoch 8178\n",
      "test_train\n",
      "train mean loss=63239.619140625\n",
      "test_test\n",
      "test mean loss=88239.0078125\n",
      "fin save.\n",
      "epoch 8179\n",
      "test_train\n",
      "train mean loss=61671.042708333334\n",
      "test_test\n",
      "test mean loss=88193.23046875\n",
      "fin save.\n",
      "epoch 8180\n",
      "test_train\n",
      "train mean loss=61802.70078125\n",
      "test_test\n",
      "test mean loss=88109.58984375\n",
      "fin save.\n",
      "epoch 8181\n",
      "test_train\n",
      "train mean loss=61881.3234375\n",
      "test_test\n",
      "test mean loss=88040.71484375\n",
      "fin save.\n",
      "epoch 8182\n",
      "test_train\n",
      "train mean loss=62534.30520833333\n",
      "test_test\n",
      "test mean loss=88243.6875\n",
      "fin save.\n",
      "epoch 8183\n",
      "test_train\n",
      "train mean loss=62573.40859375\n",
      "test_test\n",
      "test mean loss=88253.5703125\n",
      "fin save.\n",
      "epoch 8184\n",
      "test_train\n",
      "train mean loss=62963.56484375\n",
      "test_test\n",
      "test mean loss=88227.515625\n",
      "fin save.\n",
      "epoch 8185\n",
      "test_train\n",
      "train mean loss=62051.24322916667\n",
      "test_test\n",
      "test mean loss=88135.08203125\n",
      "fin save.\n",
      "epoch 8186\n",
      "test_train\n",
      "train mean loss=62530.33359375\n",
      "test_test\n",
      "test mean loss=88129.171875\n",
      "fin save.\n",
      "epoch 8187\n",
      "test_train\n",
      "train mean loss=62295.768229166664\n",
      "test_test\n",
      "test mean loss=88145.46484375\n",
      "fin save.\n",
      "epoch 8188\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_train\n",
      "train mean loss=61728.21640625\n",
      "test_test\n",
      "test mean loss=88296.23828125\n",
      "fin save.\n",
      "epoch 8189\n",
      "test_train\n",
      "train mean loss=62854.40026041667\n",
      "test_test\n",
      "test mean loss=88193.6875\n",
      "fin save.\n",
      "epoch 8190\n",
      "test_train\n",
      "train mean loss=62695.94140625\n",
      "test_test\n",
      "test mean loss=88373.08984375\n",
      "fin save.\n",
      "epoch 8191\n",
      "test_train\n",
      "train mean loss=62638.441145833334\n",
      "test_test\n",
      "test mean loss=88058.5625\n",
      "fin save.\n",
      "epoch 8192\n",
      "test_train\n",
      "train mean loss=62243.36484375\n",
      "test_test\n",
      "test mean loss=88176.08203125\n",
      "fin save.\n",
      "epoch 8193\n",
      "test_train\n",
      "train mean loss=62280.266927083336\n",
      "test_test\n",
      "test mean loss=88216.42578125\n",
      "fin save.\n",
      "epoch 8194\n",
      "test_train\n",
      "train mean loss=62413.77395833333\n",
      "test_test\n",
      "test mean loss=88133.69921875\n",
      "fin save.\n",
      "epoch 8195\n",
      "test_train\n",
      "train mean loss=63201.83411458333\n",
      "test_test\n",
      "test mean loss=88108.53125\n",
      "fin save.\n",
      "epoch 8196\n",
      "test_train\n",
      "train mean loss=62412.51744791667\n",
      "test_test\n",
      "test mean loss=88096.61328125\n",
      "fin save.\n",
      "epoch 8197\n",
      "test_train\n",
      "train mean loss=62031.286458333336\n",
      "test_test\n",
      "test mean loss=88110.0\n",
      "fin save.\n",
      "epoch 8198\n",
      "test_train\n",
      "train mean loss=61796.72799479167\n",
      "test_test\n",
      "test mean loss=88272.75\n",
      "fin save.\n",
      "epoch 8199\n",
      "test_train\n",
      "train mean loss=62942.70078125\n",
      "test_test\n",
      "test mean loss=88218.3359375\n",
      "fin save.\n",
      "epoch 8200\n",
      "test_train\n",
      "train mean loss=62402.53307291667\n",
      "test_test\n",
      "test mean loss=88128.59765625\n",
      "fin save.\n",
      "epoch 8201\n",
      "test_train\n",
      "train mean loss=61446.437109375\n",
      "test_test\n",
      "test mean loss=88210.06640625\n",
      "fin save.\n",
      "epoch 8202\n",
      "test_train\n",
      "train mean loss=62792.682291666664\n",
      "test_test\n",
      "test mean loss=88149.4921875\n",
      "fin save.\n",
      "epoch 8203\n",
      "test_train\n",
      "train mean loss=62119.57473958333\n",
      "test_test\n",
      "test mean loss=88163.38671875\n",
      "fin save.\n",
      "epoch 8204\n",
      "test_train\n",
      "train mean loss=61922.105208333334\n",
      "test_test\n",
      "test mean loss=88084.8515625\n",
      "fin save.\n",
      "epoch 8205\n",
      "test_train\n",
      "train mean loss=62751.706770833334\n",
      "test_test\n",
      "test mean loss=87978.14453125\n",
      "fin save.\n",
      "epoch 8206\n",
      "test_train\n",
      "train mean loss=61317.4484375\n",
      "test_test\n",
      "test mean loss=87999.0078125\n",
      "fin save.\n",
      "epoch 8207\n",
      "test_train\n",
      "train mean loss=61570.975\n",
      "test_test\n",
      "test mean loss=88117.5703125\n",
      "fin save.\n",
      "epoch 8208\n",
      "test_train\n",
      "train mean loss=61550.85885416667\n",
      "test_test\n",
      "test mean loss=88106.2421875\n",
      "fin save.\n",
      "epoch 8209\n",
      "test_train\n",
      "train mean loss=62413.15859375\n",
      "test_test\n",
      "test mean loss=88063.63671875\n",
      "fin save.\n",
      "epoch 8210\n",
      "test_train\n",
      "train mean loss=62810.07760416667\n",
      "test_test\n",
      "test mean loss=88055.890625\n",
      "fin save.\n",
      "epoch 8211\n",
      "test_train\n",
      "train mean loss=62466.367578125\n",
      "test_test\n",
      "test mean loss=87895.71875\n",
      "fin save.\n",
      "epoch 8212\n",
      "test_train\n",
      "train mean loss=62308.59817708333\n",
      "test_test\n",
      "test mean loss=88122.8203125\n",
      "fin save.\n",
      "epoch 8213\n",
      "test_train\n",
      "train mean loss=61742.162109375\n",
      "test_test\n",
      "test mean loss=88097.796875\n",
      "fin save.\n",
      "epoch 8214\n",
      "test_train\n",
      "train mean loss=62216.062109375\n",
      "test_test\n",
      "test mean loss=87942.0546875\n",
      "fin save.\n",
      "epoch 8215\n",
      "test_train\n",
      "train mean loss=61821.318619791666\n",
      "test_test\n",
      "test mean loss=88046.4296875\n",
      "fin save.\n",
      "epoch 8216\n",
      "test_train\n",
      "train mean loss=62409.166666666664\n",
      "test_test\n",
      "test mean loss=87974.96484375\n",
      "fin save.\n",
      "epoch 8217\n",
      "test_train\n",
      "train mean loss=62697.617447916666\n",
      "test_test\n",
      "test mean loss=88026.55859375\n",
      "fin save.\n",
      "epoch 8218\n",
      "test_train\n",
      "train mean loss=62750.69244791667\n",
      "test_test\n",
      "test mean loss=88031.16796875\n",
      "fin save.\n",
      "epoch 8219\n",
      "test_train\n",
      "train mean loss=62887.85260416667\n",
      "test_test\n",
      "test mean loss=88067.07421875\n",
      "fin save.\n",
      "epoch 8220\n",
      "test_train\n",
      "train mean loss=62967.074479166666\n",
      "test_test\n",
      "test mean loss=87916.53515625\n",
      "fin save.\n",
      "epoch 8221\n",
      "test_train\n",
      "train mean loss=61824.79192708333\n",
      "test_test\n",
      "test mean loss=87919.05859375\n",
      "fin save.\n",
      "epoch 8222\n",
      "test_train\n",
      "train mean loss=62656.410416666666\n",
      "test_test\n",
      "test mean loss=88073.7890625\n",
      "fin save.\n",
      "epoch 8223\n",
      "test_train\n",
      "train mean loss=62776.17265625\n",
      "test_test\n",
      "test mean loss=88021.140625\n",
      "fin save.\n",
      "epoch 8224\n",
      "test_train\n",
      "train mean loss=61673.00052083333\n",
      "test_test\n",
      "test mean loss=87905.6875\n",
      "fin save.\n",
      "epoch 8225\n",
      "test_train\n",
      "train mean loss=61944.598958333336\n",
      "test_test\n",
      "test mean loss=88006.7109375\n",
      "fin save.\n",
      "epoch 8226\n",
      "test_train\n",
      "train mean loss=62968.894921875\n",
      "test_test\n",
      "test mean loss=88143.0625\n",
      "fin save.\n",
      "epoch 8227\n",
      "test_train\n",
      "train mean loss=62216.1515625\n",
      "test_test\n",
      "test mean loss=88204.98828125\n",
      "fin save.\n",
      "epoch 8228\n",
      "test_train\n",
      "train mean loss=61898.00247395833\n",
      "test_test\n",
      "test mean loss=88146.5703125\n",
      "fin save.\n",
      "epoch 8229\n",
      "test_train\n",
      "train mean loss=62530.423177083336\n",
      "test_test\n",
      "test mean loss=88196.38671875\n",
      "fin save.\n",
      "epoch 8230\n",
      "test_train\n",
      "train mean loss=61628.077734375\n",
      "test_test\n",
      "test mean loss=88317.06640625\n",
      "fin save.\n",
      "epoch 8231\n",
      "test_train\n",
      "train mean loss=62945.929427083334\n",
      "test_test\n",
      "test mean loss=88085.0\n",
      "fin save.\n",
      "epoch 8232\n",
      "test_train\n",
      "train mean loss=62000.051041666666\n",
      "test_test\n",
      "test mean loss=88120.640625\n",
      "fin save.\n",
      "epoch 8233\n",
      "test_train\n",
      "train mean loss=62302.971875\n",
      "test_test\n",
      "test mean loss=88169.4296875\n",
      "fin save.\n",
      "epoch 8234\n",
      "test_train\n",
      "train mean loss=61915.5203125\n",
      "test_test\n",
      "test mean loss=88218.6484375\n",
      "fin save.\n",
      "epoch 8235\n",
      "test_train\n",
      "train mean loss=62309.48776041667\n",
      "test_test\n",
      "test mean loss=87903.7578125\n",
      "fin save.\n",
      "epoch 8236\n",
      "test_train\n",
      "train mean loss=62076.61145833333\n",
      "test_test\n",
      "test mean loss=87692.9375\n",
      "fin save.\n",
      "epoch 8237\n",
      "test_train\n",
      "train mean loss=61272.18046875\n",
      "test_test\n",
      "test mean loss=88266.3828125\n",
      "fin save.\n",
      "epoch 8238\n",
      "test_train\n",
      "train mean loss=63234.87734375\n",
      "test_test\n",
      "test mean loss=87791.8515625\n",
      "fin save.\n",
      "epoch 8239\n",
      "test_train\n",
      "train mean loss=62674.880598958334\n",
      "test_test\n",
      "test mean loss=87864.94921875\n",
      "fin save.\n",
      "epoch 8240\n",
      "test_train\n",
      "train mean loss=62412.5578125\n",
      "test_test\n",
      "test mean loss=87794.53125\n",
      "fin save.\n",
      "epoch 8241\n",
      "test_train\n",
      "train mean loss=62310.600260416664\n",
      "test_test\n",
      "test mean loss=87842.90625\n",
      "fin save.\n",
      "epoch 8242\n",
      "test_train\n",
      "train mean loss=63184.047135416666\n",
      "test_test\n",
      "test mean loss=87712.7890625\n",
      "fin save.\n",
      "epoch 8243\n",
      "test_train\n",
      "train mean loss=62293.269791666666\n",
      "test_test\n",
      "test mean loss=87383.35546875\n",
      "fin save.\n",
      "epoch 8244\n",
      "test_train\n",
      "train mean loss=62072.51471354167\n",
      "test_test\n",
      "test mean loss=87629.2890625\n",
      "fin save.\n",
      "epoch 8245\n",
      "test_train\n",
      "train mean loss=63035.11666666667\n",
      "test_test\n",
      "test mean loss=87630.8203125\n",
      "fin save.\n",
      "epoch 8246\n",
      "test_train\n",
      "train mean loss=61834.277994791664\n",
      "test_test\n",
      "test mean loss=87704.7734375\n",
      "fin save.\n",
      "epoch 8247\n",
      "test_train\n",
      "train mean loss=61099.6015625\n",
      "test_test\n",
      "test mean loss=87614.07421875\n",
      "fin save.\n",
      "epoch 8248\n",
      "test_train\n",
      "train mean loss=62121.39609375\n",
      "test_test\n",
      "test mean loss=87679.84765625\n",
      "fin save.\n",
      "epoch 8249\n",
      "test_train\n",
      "train mean loss=61961.37109375\n",
      "test_test\n",
      "test mean loss=87747.19921875\n",
      "fin save.\n",
      "epoch 8250\n",
      "test_train\n",
      "train mean loss=61607.86875\n",
      "test_test\n",
      "test mean loss=87737.11328125\n",
      "fin save.\n",
      "epoch 8251\n",
      "test_train\n",
      "train mean loss=62694.76861979167\n",
      "test_test\n",
      "test mean loss=87569.53515625\n",
      "fin save.\n",
      "epoch 8252\n",
      "test_train\n",
      "train mean loss=61740.963541666664\n",
      "test_test\n",
      "test mean loss=87775.234375\n",
      "fin save.\n",
      "epoch 8253\n",
      "test_train\n",
      "train mean loss=62310.227864583336\n",
      "test_test\n",
      "test mean loss=87768.41015625\n",
      "fin save.\n",
      "epoch 8254\n",
      "test_train\n",
      "train mean loss=62874.04791666667\n",
      "test_test\n",
      "test mean loss=87898.38671875\n",
      "fin save.\n",
      "epoch 8255\n",
      "test_train\n",
      "train mean loss=62329.3125\n",
      "test_test\n",
      "test mean loss=87805.875\n",
      "fin save.\n",
      "epoch 8256\n",
      "test_train\n",
      "train mean loss=62082.180859375\n",
      "test_test\n",
      "test mean loss=87724.50390625\n",
      "fin save.\n",
      "epoch 8257\n",
      "test_train\n",
      "train mean loss=62367.740885416664\n",
      "test_test\n",
      "test mean loss=88025.14453125\n",
      "fin save.\n",
      "epoch 8258\n",
      "test_train\n",
      "train mean loss=62783.59817708333\n",
      "test_test\n",
      "test mean loss=87791.0703125\n",
      "fin save.\n",
      "epoch 8259\n",
      "test_train\n",
      "train mean loss=62148.496354166666\n",
      "test_test\n",
      "test mean loss=87911.19140625\n",
      "fin save.\n",
      "epoch 8260\n",
      "test_train\n",
      "train mean loss=62325.89596354167\n",
      "test_test\n",
      "test mean loss=87937.8125\n",
      "fin save.\n",
      "epoch 8261\n",
      "test_train\n",
      "train mean loss=62593.93411458333\n",
      "test_test\n",
      "test mean loss=87910.875\n",
      "fin save.\n",
      "epoch 8262\n",
      "test_train\n",
      "train mean loss=61994.925390625\n",
      "test_test\n",
      "test mean loss=88029.82421875\n",
      "fin save.\n",
      "epoch 8263\n",
      "test_train\n",
      "train mean loss=62542.859635416666\n",
      "test_test\n",
      "test mean loss=87851.2734375\n",
      "fin save.\n",
      "epoch 8264\n",
      "test_train\n",
      "train mean loss=61911.31953125\n",
      "test_test\n",
      "test mean loss=87989.4609375\n",
      "fin save.\n",
      "epoch 8265\n",
      "test_train\n",
      "train mean loss=62238.32526041667\n",
      "test_test\n",
      "test mean loss=87990.0390625\n",
      "fin save.\n",
      "epoch 8266\n",
      "test_train\n",
      "train mean loss=62572.3296875\n",
      "test_test\n",
      "test mean loss=87968.33203125\n",
      "fin save.\n",
      "epoch 8267\n",
      "test_train\n",
      "train mean loss=61979.94427083333\n",
      "test_test\n",
      "test mean loss=88106.609375\n",
      "fin save.\n",
      "epoch 8268\n",
      "test_train\n",
      "train mean loss=62005.298177083336\n",
      "test_test\n",
      "test mean loss=88107.8828125\n",
      "fin save.\n",
      "epoch 8269\n",
      "test_train\n",
      "train mean loss=62554.70364583333\n",
      "test_test\n",
      "test mean loss=87951.09765625\n",
      "fin save.\n",
      "epoch 8270\n",
      "test_train\n",
      "train mean loss=61767.37877604167\n",
      "test_test\n",
      "test mean loss=87917.13671875\n",
      "fin save.\n",
      "epoch 8271\n",
      "test_train\n",
      "train mean loss=62297.296614583334\n",
      "test_test\n",
      "test mean loss=87783.1328125\n",
      "fin save.\n",
      "epoch 8272\n",
      "test_train\n",
      "train mean loss=61195.64765625\n",
      "test_test\n",
      "test mean loss=87947.58984375\n",
      "fin save.\n",
      "epoch 8273\n",
      "test_train\n",
      "train mean loss=62723.522135416664\n",
      "test_test\n",
      "test mean loss=87816.4296875\n",
      "fin save.\n",
      "epoch 8274\n",
      "test_train\n",
      "train mean loss=62643.72109375\n",
      "test_test\n",
      "test mean loss=87943.54296875\n",
      "fin save.\n",
      "epoch 8275\n",
      "test_train\n",
      "train mean loss=62883.31744791667\n",
      "test_test\n",
      "test mean loss=88008.30859375\n",
      "fin save.\n",
      "epoch 8276\n",
      "test_train\n",
      "train mean loss=62349.237630208336\n",
      "test_test\n",
      "test mean loss=88090.60546875\n",
      "fin save.\n",
      "epoch 8277\n",
      "test_train\n",
      "train mean loss=62518.65052083333\n",
      "test_test\n",
      "test mean loss=88133.5859375\n",
      "fin save.\n",
      "epoch 8278\n",
      "test_train\n",
      "train mean loss=61945.50625\n",
      "test_test\n",
      "test mean loss=87859.6796875\n",
      "fin save.\n",
      "epoch 8279\n",
      "test_train\n",
      "train mean loss=62347.398697916666\n",
      "test_test\n",
      "test mean loss=87959.5625\n",
      "fin save.\n",
      "epoch 8280\n",
      "test_train\n",
      "train mean loss=61773.04739583333\n",
      "test_test\n",
      "test mean loss=87810.23046875\n",
      "fin save.\n",
      "epoch 8281\n",
      "test_train\n",
      "train mean loss=61413.54973958333\n",
      "test_test\n",
      "test mean loss=87970.40234375\n",
      "fin save.\n",
      "epoch 8282\n",
      "test_train\n",
      "train mean loss=62665.094010416666\n",
      "test_test\n",
      "test mean loss=88066.4296875\n",
      "fin save.\n",
      "epoch 8283\n",
      "test_train\n",
      "train mean loss=63508.522135416664\n",
      "test_test\n",
      "test mean loss=87880.83984375\n",
      "fin save.\n",
      "epoch 8284\n",
      "test_train\n",
      "train mean loss=61624.25677083333\n",
      "test_test\n",
      "test mean loss=87920.8203125\n",
      "fin save.\n",
      "epoch 8285\n",
      "test_train\n",
      "train mean loss=61447.78333333333\n",
      "test_test\n",
      "test mean loss=87858.76953125\n",
      "fin save.\n",
      "epoch 8286\n",
      "test_train\n",
      "train mean loss=62443.515364583334\n",
      "test_test\n",
      "test mean loss=87987.86328125\n",
      "fin save.\n",
      "epoch 8287\n",
      "test_train\n",
      "train mean loss=61170.75572916667\n",
      "test_test\n",
      "test mean loss=87913.26953125\n",
      "fin save.\n",
      "epoch 8288\n",
      "test_train\n",
      "train mean loss=62364.15182291667\n",
      "test_test\n",
      "test mean loss=87887.5\n",
      "fin save.\n",
      "epoch 8289\n",
      "test_train\n",
      "train mean loss=62471.92005208333\n",
      "test_test\n",
      "test mean loss=88024.94140625\n",
      "fin save.\n",
      "epoch 8290\n",
      "test_train\n",
      "train mean loss=61919.44635416667\n",
      "test_test\n",
      "test mean loss=87852.6796875\n",
      "fin save.\n",
      "epoch 8291\n",
      "test_train\n",
      "train mean loss=61621.70546875\n",
      "test_test\n",
      "test mean loss=87916.9921875\n",
      "fin save.\n",
      "epoch 8292\n",
      "test_train\n",
      "train mean loss=62512.859635416666\n",
      "test_test\n",
      "test mean loss=87979.58984375\n",
      "fin save.\n",
      "epoch 8293\n",
      "test_train\n",
      "train mean loss=62689.039322916666\n",
      "test_test\n",
      "test mean loss=87969.06640625\n",
      "fin save.\n",
      "epoch 8294\n",
      "test_train\n",
      "train mean loss=62416.41640625\n",
      "test_test\n",
      "test mean loss=87986.97265625\n",
      "fin save.\n",
      "epoch 8295\n",
      "test_train\n",
      "train mean loss=62884.094010416666\n",
      "test_test\n",
      "test mean loss=87823.1484375\n",
      "fin save.\n",
      "epoch 8296\n",
      "test_train\n",
      "train mean loss=62575.9859375\n",
      "test_test\n",
      "test mean loss=87945.875\n",
      "fin save.\n",
      "epoch 8297\n",
      "test_train\n",
      "train mean loss=61717.268880208336\n",
      "test_test\n",
      "test mean loss=87927.2421875\n",
      "fin save.\n",
      "epoch 8298\n",
      "test_train\n",
      "train mean loss=62289.65026041667\n",
      "test_test\n",
      "test mean loss=87705.1015625\n",
      "fin save.\n",
      "epoch 8299\n",
      "test_train\n",
      "train mean loss=62819.1265625\n",
      "test_test\n",
      "test mean loss=87913.453125\n",
      "fin save.\n",
      "epoch 8300\n",
      "test_train\n",
      "train mean loss=62357.64635416667\n",
      "test_test\n",
      "test mean loss=87949.7265625\n",
      "fin save.\n",
      "epoch 8301\n",
      "test_train\n",
      "train mean loss=62855.15533854167\n",
      "test_test\n",
      "test mean loss=87756.84375\n",
      "fin save.\n",
      "epoch 8302\n",
      "test_train\n",
      "train mean loss=61618.29453125\n",
      "test_test\n",
      "test mean loss=87949.171875\n",
      "fin save.\n",
      "epoch 8303\n",
      "test_train\n",
      "train mean loss=61125.95208333333\n",
      "test_test\n",
      "test mean loss=88090.83984375\n",
      "fin save.\n",
      "epoch 8304\n",
      "test_train\n",
      "train mean loss=62422.79674479167\n",
      "test_test\n",
      "test mean loss=87904.4453125\n",
      "fin save.\n",
      "epoch 8305\n",
      "test_train\n",
      "train mean loss=62435.6359375\n",
      "test_test\n",
      "test mean loss=87829.98046875\n",
      "fin save.\n",
      "epoch 8306\n",
      "test_train\n",
      "train mean loss=62100.11041666667\n",
      "test_test\n",
      "test mean loss=87724.97265625\n",
      "fin save.\n",
      "epoch 8307\n",
      "test_train\n",
      "train mean loss=62348.01223958333\n",
      "test_test\n",
      "test mean loss=87627.3125\n",
      "fin save.\n",
      "epoch 8308\n",
      "test_train\n",
      "train mean loss=62310.5671875\n",
      "test_test\n",
      "test mean loss=87668.8515625\n",
      "fin save.\n",
      "epoch 8309\n",
      "test_train\n",
      "train mean loss=63276.351822916666\n",
      "test_test\n",
      "test mean loss=87822.4375\n",
      "fin save.\n",
      "epoch 8310\n",
      "test_train\n",
      "train mean loss=62926.30677083333\n",
      "test_test\n",
      "test mean loss=87688.47265625\n",
      "fin save.\n",
      "epoch 8311\n",
      "test_train\n",
      "train mean loss=61633.42486979167\n",
      "test_test\n",
      "test mean loss=87577.96484375\n",
      "fin save.\n",
      "epoch 8312\n",
      "test_train\n",
      "train mean loss=61944.53958333333\n",
      "test_test\n",
      "test mean loss=87562.92578125\n",
      "fin save.\n",
      "epoch 8313\n",
      "test_train\n",
      "train mean loss=63537.5578125\n",
      "test_test\n",
      "test mean loss=87716.58984375\n",
      "fin save.\n",
      "epoch 8314\n",
      "test_train\n",
      "train mean loss=62265.58098958333\n",
      "test_test\n",
      "test mean loss=87653.11328125\n",
      "fin save.\n",
      "epoch 8315\n",
      "test_train\n",
      "train mean loss=63375.979166666664\n",
      "test_test\n",
      "test mean loss=87652.8984375\n",
      "fin save.\n",
      "epoch 8316\n",
      "test_train\n",
      "train mean loss=62050.25533854167\n",
      "test_test\n",
      "test mean loss=87889.6640625\n",
      "fin save.\n",
      "epoch 8317\n",
      "test_train\n",
      "train mean loss=63231.28359375\n",
      "test_test\n",
      "test mean loss=87751.140625\n",
      "fin save.\n",
      "epoch 8318\n",
      "test_train\n",
      "train mean loss=62917.6234375\n",
      "test_test\n",
      "test mean loss=87754.19140625\n",
      "fin save.\n",
      "epoch 8319\n",
      "test_train\n",
      "train mean loss=62444.405859375\n",
      "test_test\n",
      "test mean loss=87875.84765625\n",
      "fin save.\n",
      "epoch 8320\n",
      "test_train\n",
      "train mean loss=62584.46875\n",
      "test_test\n",
      "test mean loss=87935.30078125\n",
      "fin save.\n",
      "epoch 8321\n",
      "test_train\n",
      "train mean loss=61872.97708333333\n",
      "test_test\n",
      "test mean loss=87672.77734375\n",
      "fin save.\n",
      "epoch 8322\n",
      "test_train\n",
      "train mean loss=62424.86822916667\n",
      "test_test\n",
      "test mean loss=87680.83203125\n",
      "fin save.\n",
      "epoch 8323\n",
      "test_train\n",
      "train mean loss=63066.25442708333\n",
      "test_test\n",
      "test mean loss=87821.7421875\n",
      "fin save.\n",
      "epoch 8324\n",
      "test_train\n",
      "train mean loss=62743.52682291667\n",
      "test_test\n",
      "test mean loss=87820.48046875\n",
      "fin save.\n",
      "epoch 8325\n",
      "test_train\n",
      "train mean loss=62278.02395833333\n",
      "test_test\n",
      "test mean loss=87459.5390625\n",
      "fin save.\n",
      "epoch 8326\n",
      "test_train\n",
      "train mean loss=62160.55\n",
      "test_test\n",
      "test mean loss=88114.0703125\n",
      "fin save.\n",
      "epoch 8327\n",
      "test_train\n",
      "train mean loss=62243.45807291667\n",
      "test_test\n",
      "test mean loss=88012.62109375\n",
      "fin save.\n",
      "epoch 8328\n",
      "test_train\n",
      "train mean loss=61985.578125\n",
      "test_test\n",
      "test mean loss=88200.25\n",
      "fin save.\n",
      "epoch 8329\n",
      "test_train\n",
      "train mean loss=62245.057291666664\n",
      "test_test\n",
      "test mean loss=88449.2578125\n",
      "fin save.\n",
      "epoch 8330\n",
      "test_train\n",
      "train mean loss=61729.304296875\n",
      "test_test\n",
      "test mean loss=88037.1875\n",
      "fin save.\n",
      "epoch 8331\n",
      "test_train\n",
      "train mean loss=63427.7890625\n",
      "test_test\n",
      "test mean loss=87998.7734375\n",
      "fin save.\n",
      "epoch 8332\n",
      "test_train\n",
      "train mean loss=62717.8234375\n",
      "test_test\n",
      "test mean loss=88172.68359375\n",
      "fin save.\n",
      "epoch 8333\n",
      "test_train\n",
      "train mean loss=61923.89635416667\n",
      "test_test\n",
      "test mean loss=87968.49609375\n",
      "fin save.\n",
      "epoch 8334\n",
      "test_train\n",
      "train mean loss=62101.630208333336\n",
      "test_test\n",
      "test mean loss=88057.0\n",
      "fin save.\n",
      "epoch 8335\n",
      "test_train\n",
      "train mean loss=61986.73333333333\n",
      "test_test\n",
      "test mean loss=88075.23828125\n",
      "fin save.\n",
      "epoch 8336\n",
      "test_train\n",
      "train mean loss=62558.04869791667\n",
      "test_test\n",
      "test mean loss=88157.28515625\n",
      "fin save.\n",
      "epoch 8337\n",
      "test_train\n",
      "train mean loss=61758.99140625\n",
      "test_test\n",
      "test mean loss=87913.0078125\n",
      "fin save.\n",
      "epoch 8338\n",
      "test_train\n",
      "train mean loss=61889.623307291666\n",
      "test_test\n",
      "test mean loss=87996.8828125\n",
      "fin save.\n",
      "epoch 8339\n",
      "test_train\n",
      "train mean loss=61806.046223958336\n",
      "test_test\n",
      "test mean loss=87950.5\n",
      "fin save.\n",
      "epoch 8340\n",
      "test_train\n",
      "train mean loss=63509.3359375\n",
      "test_test\n",
      "test mean loss=87961.69921875\n",
      "fin save.\n",
      "epoch 8341\n",
      "test_train\n",
      "train mean loss=62324.488671875\n",
      "test_test\n",
      "test mean loss=88172.0859375\n",
      "fin save.\n",
      "epoch 8342\n",
      "test_train\n",
      "train mean loss=62684.29973958333\n",
      "test_test\n",
      "test mean loss=88506.9765625\n",
      "fin save.\n",
      "epoch 8343\n",
      "test_train\n",
      "train mean loss=61596.756640625\n",
      "test_test\n",
      "test mean loss=88105.64453125\n",
      "fin save.\n",
      "epoch 8344\n",
      "test_train\n",
      "train mean loss=62695.12942708333\n",
      "test_test\n",
      "test mean loss=88089.10546875\n",
      "fin save.\n",
      "epoch 8345\n",
      "test_train\n",
      "train mean loss=62105.73424479167\n",
      "test_test\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test mean loss=88137.51953125\n",
      "fin save.\n",
      "epoch 8346\n",
      "test_train\n",
      "train mean loss=62079.63125\n",
      "test_test\n",
      "test mean loss=88239.5859375\n",
      "fin save.\n",
      "epoch 8347\n",
      "test_train\n",
      "train mean loss=61576.65\n",
      "test_test\n",
      "test mean loss=88370.953125\n",
      "fin save.\n",
      "epoch 8348\n",
      "test_train\n",
      "train mean loss=61259.472395833334\n",
      "test_test\n",
      "test mean loss=88159.77734375\n",
      "fin save.\n",
      "epoch 8349\n",
      "test_train\n",
      "train mean loss=63084.92864583333\n",
      "test_test\n",
      "test mean loss=88864.99609375\n",
      "fin save.\n",
      "epoch 8350\n",
      "test_train\n",
      "train mean loss=61985.34713541667\n",
      "test_test\n",
      "test mean loss=88707.7265625\n",
      "fin save.\n",
      "epoch 8351\n",
      "test_train\n",
      "train mean loss=62346.110026041664\n",
      "test_test\n",
      "test mean loss=88959.26953125\n",
      "fin save.\n",
      "epoch 8352\n",
      "test_train\n",
      "train mean loss=61987.349869791666\n",
      "test_test\n",
      "test mean loss=88667.1328125\n",
      "fin save.\n",
      "epoch 8353\n",
      "test_train\n",
      "train mean loss=62787.47604166667\n",
      "test_test\n",
      "test mean loss=88598.21484375\n",
      "fin save.\n",
      "epoch 8354\n",
      "test_train\n",
      "train mean loss=61840.44739583333\n",
      "test_test\n",
      "test mean loss=88556.2421875\n",
      "fin save.\n",
      "epoch 8355\n",
      "test_train\n",
      "train mean loss=62719.26875\n",
      "test_test\n",
      "test mean loss=88671.75\n",
      "fin save.\n",
      "epoch 8356\n",
      "test_train\n",
      "train mean loss=63068.761979166666\n",
      "test_test\n",
      "test mean loss=88544.4296875\n",
      "fin save.\n",
      "epoch 8357\n",
      "test_train\n",
      "train mean loss=62302.207291666666\n",
      "test_test\n",
      "test mean loss=87909.58984375\n",
      "fin save.\n",
      "epoch 8358\n",
      "test_train\n",
      "train mean loss=62243.56145833333\n",
      "test_test\n",
      "test mean loss=88024.3984375\n",
      "fin save.\n",
      "epoch 8359\n",
      "test_train\n",
      "train mean loss=62739.15182291667\n",
      "test_test\n",
      "test mean loss=88184.83984375\n",
      "fin save.\n",
      "epoch 8360\n",
      "test_train\n",
      "train mean loss=61769.761458333334\n",
      "test_test\n",
      "test mean loss=88450.24609375\n",
      "fin save.\n",
      "epoch 8361\n",
      "test_train\n",
      "train mean loss=62208.993489583336\n",
      "test_test\n",
      "test mean loss=88016.04296875\n",
      "fin save.\n",
      "epoch 8362\n",
      "test_train\n",
      "train mean loss=61625.072916666664\n",
      "test_test\n",
      "test mean loss=88013.80078125\n",
      "fin save.\n",
      "epoch 8363\n",
      "test_train\n",
      "train mean loss=62013.734635416666\n",
      "test_test\n",
      "test mean loss=88132.95703125\n",
      "fin save.\n",
      "epoch 8364\n",
      "test_train\n",
      "train mean loss=61748.50729166667\n",
      "test_test\n",
      "test mean loss=88020.0\n",
      "fin save.\n",
      "epoch 8365\n",
      "test_train\n",
      "train mean loss=62931.814192708334\n",
      "test_test\n",
      "test mean loss=88295.17578125\n",
      "fin save.\n",
      "epoch 8366\n",
      "test_train\n",
      "train mean loss=62043.796484375\n",
      "test_test\n",
      "test mean loss=88295.23046875\n",
      "fin save.\n",
      "epoch 8367\n",
      "test_train\n",
      "train mean loss=62354.489583333336\n",
      "test_test\n",
      "test mean loss=88384.9765625\n",
      "fin save.\n",
      "epoch 8368\n",
      "test_train\n",
      "train mean loss=63126.21796875\n",
      "test_test\n",
      "test mean loss=88293.82421875\n",
      "fin save.\n",
      "epoch 8369\n",
      "test_train\n",
      "train mean loss=62904.98880208333\n",
      "test_test\n",
      "test mean loss=88130.09375\n",
      "fin save.\n",
      "epoch 8370\n",
      "test_train\n",
      "train mean loss=63437.36080729167\n",
      "test_test\n",
      "test mean loss=88309.30859375\n",
      "fin save.\n",
      "epoch 8371\n",
      "test_train\n",
      "train mean loss=62133.56145833333\n",
      "test_test\n",
      "test mean loss=88110.8984375\n",
      "fin save.\n",
      "epoch 8372\n",
      "test_train\n",
      "train mean loss=61753.33020833333\n",
      "test_test\n",
      "test mean loss=88077.10546875\n",
      "fin save.\n",
      "epoch 8373\n",
      "test_train\n",
      "train mean loss=62307.61822916667\n",
      "test_test\n",
      "test mean loss=88166.09765625\n",
      "fin save.\n",
      "epoch 8374\n",
      "test_train\n",
      "train mean loss=62004.73190104167\n",
      "test_test\n",
      "test mean loss=88104.46875\n",
      "fin save.\n",
      "epoch 8375\n",
      "test_train\n",
      "train mean loss=60707.76705729167\n",
      "test_test\n",
      "test mean loss=88189.16015625\n",
      "fin save.\n",
      "epoch 8376\n",
      "test_train\n",
      "train mean loss=62150.26575520833\n",
      "test_test\n",
      "test mean loss=88206.06640625\n",
      "fin save.\n",
      "epoch 8377\n",
      "test_train\n",
      "train mean loss=61952.041276041666\n",
      "test_test\n",
      "test mean loss=88179.07421875\n",
      "fin save.\n",
      "epoch 8378\n",
      "test_train\n",
      "train mean loss=62755.82239583333\n",
      "test_test\n",
      "test mean loss=88200.39453125\n",
      "fin save.\n",
      "epoch 8379\n",
      "test_train\n",
      "train mean loss=61574.25078125\n",
      "test_test\n",
      "test mean loss=88188.06640625\n",
      "fin save.\n",
      "epoch 8380\n",
      "test_train\n",
      "train mean loss=61980.92630208333\n",
      "test_test\n",
      "test mean loss=88312.828125\n",
      "fin save.\n",
      "epoch 8381\n",
      "test_train\n",
      "train mean loss=62551.9875\n",
      "test_test\n",
      "test mean loss=88101.47265625\n",
      "fin save.\n",
      "epoch 8382\n",
      "test_train\n",
      "train mean loss=62232.72421875\n",
      "test_test\n",
      "test mean loss=88284.5\n",
      "fin save.\n",
      "epoch 8383\n",
      "test_train\n",
      "train mean loss=61853.66119791667\n",
      "test_test\n",
      "test mean loss=88412.1953125\n",
      "fin save.\n",
      "epoch 8384\n",
      "test_train\n",
      "train mean loss=62729.74557291667\n",
      "test_test\n",
      "test mean loss=88395.90625\n",
      "fin save.\n",
      "epoch 8385\n",
      "test_train\n",
      "train mean loss=63007.33046875\n",
      "test_test\n",
      "test mean loss=88044.80078125\n",
      "fin save.\n",
      "epoch 8386\n",
      "test_train\n",
      "train mean loss=61868.437239583334\n",
      "test_test\n",
      "test mean loss=88130.19921875\n",
      "fin save.\n",
      "epoch 8387\n",
      "test_train\n",
      "train mean loss=61809.12513020833\n",
      "test_test\n",
      "test mean loss=88133.890625\n",
      "fin save.\n",
      "epoch 8388\n",
      "test_train\n",
      "train mean loss=61617.433854166666\n",
      "test_test\n",
      "test mean loss=88008.1953125\n",
      "fin save.\n",
      "epoch 8389\n",
      "test_train\n",
      "train mean loss=61778.94322916667\n",
      "test_test\n",
      "test mean loss=88425.96875\n",
      "fin save.\n",
      "epoch 8390\n",
      "test_train\n",
      "train mean loss=61862.41901041667\n",
      "test_test\n",
      "test mean loss=88178.24609375\n",
      "fin save.\n",
      "epoch 8391\n",
      "test_train\n",
      "train mean loss=62257.25234375\n",
      "test_test\n",
      "test mean loss=88367.59375\n",
      "fin save.\n",
      "epoch 8392\n",
      "test_train\n",
      "train mean loss=61705.05546875\n",
      "test_test\n",
      "test mean loss=88577.9375\n",
      "fin save.\n",
      "epoch 8393\n",
      "test_train\n",
      "train mean loss=62785.667578125\n",
      "test_test\n",
      "test mean loss=88484.1328125\n",
      "fin save.\n",
      "epoch 8394\n",
      "test_train\n",
      "train mean loss=62605.562760416666\n",
      "test_test\n",
      "test mean loss=88464.88671875\n",
      "fin save.\n",
      "epoch 8395\n",
      "test_train\n",
      "train mean loss=62248.94518229167\n",
      "test_test\n",
      "test mean loss=88426.30078125\n",
      "fin save.\n",
      "epoch 8396\n",
      "test_train\n",
      "train mean loss=62023.72942708333\n",
      "test_test\n",
      "test mean loss=88540.31640625\n",
      "fin save.\n",
      "epoch 8397\n",
      "test_train\n",
      "train mean loss=62903.1890625\n",
      "test_test\n",
      "test mean loss=88449.828125\n",
      "fin save.\n",
      "epoch 8398\n",
      "test_train\n",
      "train mean loss=61012.66640625\n",
      "test_test\n",
      "test mean loss=88445.484375\n",
      "fin save.\n",
      "epoch 8399\n",
      "test_train\n",
      "train mean loss=63299.96145833333\n",
      "test_test\n",
      "test mean loss=88318.6328125\n",
      "fin save.\n",
      "epoch 8400\n",
      "test_train\n",
      "train mean loss=62428.83541666667\n",
      "test_test\n",
      "test mean loss=88693.01171875\n",
      "fin save.\n",
      "epoch 8401\n",
      "test_train\n",
      "train mean loss=62369.41783854167\n",
      "test_test\n",
      "test mean loss=88458.3125\n",
      "fin save.\n",
      "epoch 8402\n",
      "test_train\n",
      "train mean loss=62868.611588541666\n",
      "test_test\n",
      "test mean loss=88671.0625\n",
      "fin save.\n",
      "epoch 8403\n",
      "test_train\n",
      "train mean loss=62314.951822916664\n",
      "test_test\n",
      "test mean loss=88152.08203125\n",
      "fin save.\n",
      "epoch 8404\n",
      "test_train\n",
      "train mean loss=62386.411328125\n",
      "test_test\n",
      "test mean loss=88178.24609375\n",
      "fin save.\n",
      "epoch 8405\n",
      "test_train\n",
      "train mean loss=62089.44244791667\n",
      "test_test\n",
      "test mean loss=88176.9765625\n",
      "fin save.\n",
      "epoch 8406\n",
      "test_train\n",
      "train mean loss=62132.01171875\n",
      "test_test\n",
      "test mean loss=88024.0546875\n",
      "fin save.\n",
      "epoch 8407\n",
      "test_train\n",
      "train mean loss=62230.146875\n",
      "test_test\n",
      "test mean loss=88174.6640625\n",
      "fin save.\n",
      "epoch 8408\n",
      "test_train\n",
      "train mean loss=62367.249739583334\n",
      "test_test\n",
      "test mean loss=88227.18359375\n",
      "fin save.\n",
      "epoch 8409\n",
      "test_train\n",
      "train mean loss=61475.89166666667\n",
      "test_test\n",
      "test mean loss=88012.4453125\n",
      "fin save.\n",
      "epoch 8410\n",
      "test_train\n",
      "train mean loss=61594.986588541666\n",
      "test_test\n",
      "test mean loss=88186.7265625\n",
      "fin save.\n",
      "epoch 8411\n",
      "test_train\n",
      "train mean loss=61767.4421875\n",
      "test_test\n",
      "test mean loss=88164.7421875\n",
      "fin save.\n",
      "epoch 8412\n",
      "test_train\n",
      "train mean loss=62296.3078125\n",
      "test_test\n",
      "test mean loss=88465.8984375\n",
      "fin save.\n",
      "epoch 8413\n",
      "test_train\n",
      "train mean loss=62907.43151041667\n",
      "test_test\n",
      "test mean loss=88362.453125\n",
      "fin save.\n",
      "epoch 8414\n",
      "test_train\n",
      "train mean loss=62033.94231770833\n",
      "test_test\n",
      "test mean loss=88536.47265625\n",
      "fin save.\n",
      "epoch 8415\n",
      "test_train\n",
      "train mean loss=62149.21575520833\n",
      "test_test\n",
      "test mean loss=88336.42578125\n",
      "fin save.\n",
      "epoch 8416\n",
      "test_train\n",
      "train mean loss=62377.888932291666\n",
      "test_test\n",
      "test mean loss=88144.3828125\n",
      "fin save.\n",
      "epoch 8417\n",
      "test_train\n",
      "train mean loss=62335.02161458333\n",
      "test_test\n",
      "test mean loss=88221.90234375\n",
      "fin save.\n",
      "epoch 8418\n",
      "test_train\n",
      "train mean loss=61366.0515625\n",
      "test_test\n",
      "test mean loss=88225.2734375\n",
      "fin save.\n",
      "epoch 8419\n",
      "test_train\n",
      "train mean loss=61835.5828125\n",
      "test_test\n",
      "test mean loss=88344.86328125\n",
      "fin save.\n",
      "epoch 8420\n",
      "test_train\n",
      "train mean loss=61462.76171875\n",
      "test_test\n",
      "test mean loss=88305.44921875\n",
      "fin save.\n",
      "epoch 8421\n",
      "test_train\n",
      "train mean loss=63145.502604166664\n",
      "test_test\n",
      "test mean loss=88191.140625\n",
      "fin save.\n",
      "epoch 8422\n",
      "test_train\n",
      "train mean loss=62464.68828125\n",
      "test_test\n",
      "test mean loss=88365.578125\n",
      "fin save.\n",
      "epoch 8423\n",
      "test_train\n",
      "train mean loss=62664.00768229167\n",
      "test_test\n",
      "test mean loss=88295.0625\n",
      "fin save.\n",
      "epoch 8424\n",
      "test_train\n",
      "train mean loss=61899.504166666666\n",
      "test_test\n",
      "test mean loss=88223.88671875\n",
      "fin save.\n",
      "epoch 8425\n",
      "test_train\n",
      "train mean loss=62408.600260416664\n",
      "test_test\n",
      "test mean loss=88093.23046875\n",
      "fin save.\n",
      "epoch 8426\n",
      "test_train\n",
      "train mean loss=62557.93020833333\n",
      "test_test\n",
      "test mean loss=88368.0234375\n",
      "fin save.\n",
      "epoch 8427\n",
      "test_train\n",
      "train mean loss=62541.44622395833\n",
      "test_test\n",
      "test mean loss=87961.91796875\n",
      "fin save.\n",
      "epoch 8428\n",
      "test_train\n",
      "train mean loss=61167.81627604167\n",
      "test_test\n",
      "test mean loss=88111.8984375\n",
      "fin save.\n",
      "epoch 8429\n",
      "test_train\n",
      "train mean loss=63213.9375\n",
      "test_test\n",
      "test mean loss=88295.15625\n",
      "fin save.\n",
      "epoch 8430\n",
      "test_train\n",
      "train mean loss=62011.61171875\n",
      "test_test\n",
      "test mean loss=88450.37890625\n",
      "fin save.\n",
      "epoch 8431\n",
      "test_train\n",
      "train mean loss=61236.960677083334\n",
      "test_test\n",
      "test mean loss=88345.04296875\n",
      "fin save.\n",
      "epoch 8432\n",
      "test_train\n",
      "train mean loss=62532.44322916667\n",
      "test_test\n",
      "test mean loss=88514.7265625\n",
      "fin save.\n",
      "epoch 8433\n",
      "test_train\n",
      "train mean loss=62013.459375\n",
      "test_test\n",
      "test mean loss=88475.796875\n",
      "fin save.\n",
      "epoch 8434\n",
      "test_train\n",
      "train mean loss=61881.2671875\n",
      "test_test\n",
      "test mean loss=88315.12890625\n",
      "fin save.\n",
      "epoch 8435\n",
      "test_train\n",
      "train mean loss=62650.44739583333\n",
      "test_test\n",
      "test mean loss=88441.5546875\n",
      "fin save.\n",
      "epoch 8436\n",
      "test_train\n",
      "train mean loss=62565.566796875\n",
      "test_test\n",
      "test mean loss=88494.37109375\n",
      "fin save.\n",
      "epoch 8437\n",
      "test_train\n",
      "train mean loss=63126.8125\n",
      "test_test\n",
      "test mean loss=88382.6953125\n",
      "fin save.\n",
      "epoch 8438\n",
      "test_train\n",
      "train mean loss=61266.44427083333\n",
      "test_test\n",
      "test mean loss=88084.76171875\n",
      "fin save.\n",
      "epoch 8439\n",
      "test_train\n",
      "train mean loss=61932.13294270833\n",
      "test_test\n",
      "test mean loss=88336.5625\n",
      "fin save.\n",
      "epoch 8440\n",
      "test_train\n",
      "train mean loss=62130.0203125\n",
      "test_test\n",
      "test mean loss=88433.15625\n",
      "fin save.\n",
      "epoch 8441\n",
      "test_train\n",
      "train mean loss=62140.15026041667\n",
      "test_test\n",
      "test mean loss=88671.484375\n",
      "fin save.\n",
      "epoch 8442\n",
      "test_train\n",
      "train mean loss=62448.82708333333\n",
      "test_test\n",
      "test mean loss=88246.37890625\n",
      "fin save.\n",
      "epoch 8443\n",
      "test_train\n",
      "train mean loss=63105.58515625\n",
      "test_test\n",
      "test mean loss=88248.54296875\n",
      "fin save.\n",
      "epoch 8444\n",
      "test_train\n",
      "train mean loss=62446.454817708334\n",
      "test_test\n",
      "test mean loss=88192.1484375\n",
      "fin save.\n",
      "epoch 8445\n",
      "test_train\n",
      "train mean loss=61552.4453125\n",
      "test_test\n",
      "test mean loss=88312.3984375\n",
      "fin save.\n",
      "epoch 8446\n",
      "test_train\n",
      "train mean loss=61769.284375\n",
      "test_test\n",
      "test mean loss=88361.51171875\n",
      "fin save.\n",
      "epoch 8447\n",
      "test_train\n",
      "train mean loss=62876.549479166664\n",
      "test_test\n",
      "test mean loss=88467.94921875\n",
      "fin save.\n",
      "epoch 8448\n",
      "test_train\n",
      "train mean loss=61681.13671875\n",
      "test_test\n",
      "test mean loss=88484.30078125\n",
      "fin save.\n",
      "epoch 8449\n",
      "test_train\n",
      "train mean loss=61118.722005208336\n",
      "test_test\n",
      "test mean loss=88458.90234375\n",
      "fin save.\n",
      "epoch 8450\n",
      "test_train\n",
      "train mean loss=62005.29544270833\n",
      "test_test\n",
      "test mean loss=88572.41015625\n",
      "fin save.\n",
      "epoch 8451\n",
      "test_train\n",
      "train mean loss=61735.79765625\n",
      "test_test\n",
      "test mean loss=88558.015625\n",
      "fin save.\n",
      "epoch 8452\n",
      "test_train\n",
      "train mean loss=63109.79674479167\n",
      "test_test\n",
      "test mean loss=88653.44140625\n",
      "fin save.\n",
      "epoch 8453\n",
      "test_train\n",
      "train mean loss=62563.146744791666\n",
      "test_test\n",
      "test mean loss=88727.92578125\n",
      "fin save.\n",
      "epoch 8454\n",
      "test_train\n",
      "train mean loss=62452.627604166664\n",
      "test_test\n",
      "test mean loss=88543.90625\n",
      "fin save.\n",
      "epoch 8455\n",
      "test_train\n",
      "train mean loss=62726.334635416664\n",
      "test_test\n",
      "test mean loss=88572.86328125\n",
      "fin save.\n",
      "epoch 8456\n",
      "test_train\n",
      "train mean loss=62023.079817708334\n",
      "test_test\n",
      "test mean loss=88386.875\n",
      "fin save.\n",
      "epoch 8457\n",
      "test_train\n",
      "train mean loss=62737.734765625\n",
      "test_test\n",
      "test mean loss=88453.6015625\n",
      "fin save.\n",
      "epoch 8458\n",
      "test_train\n",
      "train mean loss=62019.28723958333\n",
      "test_test\n",
      "test mean loss=88386.1875\n",
      "fin save.\n",
      "epoch 8459\n",
      "test_train\n",
      "train mean loss=63175.397786458336\n",
      "test_test\n",
      "test mean loss=88461.96875\n",
      "fin save.\n",
      "epoch 8460\n",
      "test_train\n",
      "train mean loss=62289.03020833333\n",
      "test_test\n",
      "test mean loss=88373.40625\n",
      "fin save.\n",
      "epoch 8461\n",
      "test_train\n",
      "train mean loss=62073.641276041664\n",
      "test_test\n",
      "test mean loss=88337.38671875\n",
      "fin save.\n",
      "epoch 8462\n",
      "test_train\n",
      "train mean loss=62043.25859375\n",
      "test_test\n",
      "test mean loss=88572.62109375\n",
      "fin save.\n",
      "epoch 8463\n",
      "test_train\n",
      "train mean loss=62672.54244791667\n",
      "test_test\n",
      "test mean loss=88434.828125\n",
      "fin save.\n",
      "epoch 8464\n",
      "test_train\n",
      "train mean loss=62768.93020833333\n",
      "test_test\n",
      "test mean loss=88545.8046875\n",
      "fin save.\n",
      "epoch 8465\n",
      "test_train\n",
      "train mean loss=62088.2171875\n",
      "test_test\n",
      "test mean loss=88386.62890625\n",
      "fin save.\n",
      "epoch 8466\n",
      "test_train\n",
      "train mean loss=61926.98229166667\n",
      "test_test\n",
      "test mean loss=88366.75\n",
      "fin save.\n",
      "epoch 8467\n",
      "test_train\n",
      "train mean loss=62235.29505208333\n",
      "test_test\n",
      "test mean loss=88450.6171875\n",
      "fin save.\n",
      "epoch 8468\n",
      "test_train\n",
      "train mean loss=62158.510416666664\n",
      "test_test\n",
      "test mean loss=88673.70703125\n",
      "fin save.\n",
      "epoch 8469\n",
      "test_train\n",
      "train mean loss=61666.541666666664\n",
      "test_test\n",
      "test mean loss=88426.12109375\n",
      "fin save.\n",
      "epoch 8470\n",
      "test_train\n",
      "train mean loss=62033.78359375\n",
      "test_test\n",
      "test mean loss=88446.109375\n",
      "fin save.\n",
      "epoch 8471\n",
      "test_train\n",
      "train mean loss=62036.96171875\n",
      "test_test\n",
      "test mean loss=88462.56640625\n",
      "fin save.\n",
      "epoch 8472\n",
      "test_train\n",
      "train mean loss=61941.47213541667\n",
      "test_test\n",
      "test mean loss=88568.32421875\n",
      "fin save.\n",
      "epoch 8473\n",
      "test_train\n",
      "train mean loss=62614.070052083334\n",
      "test_test\n",
      "test mean loss=88516.84765625\n",
      "fin save.\n",
      "epoch 8474\n",
      "test_train\n",
      "train mean loss=62041.28216145833\n",
      "test_test\n",
      "test mean loss=88411.99609375\n",
      "fin save.\n",
      "epoch 8475\n",
      "test_train\n",
      "train mean loss=62287.9125\n",
      "test_test\n",
      "test mean loss=88479.58203125\n",
      "fin save.\n",
      "epoch 8476\n",
      "test_train\n",
      "train mean loss=62864.731770833336\n",
      "test_test\n",
      "test mean loss=88479.58984375\n",
      "fin save.\n",
      "epoch 8477\n",
      "test_train\n",
      "train mean loss=62265.01796875\n",
      "test_test\n",
      "test mean loss=88359.16796875\n",
      "fin save.\n",
      "epoch 8478\n",
      "test_train\n",
      "train mean loss=61670.71041666667\n",
      "test_test\n",
      "test mean loss=88140.734375\n",
      "fin save.\n",
      "epoch 8479\n",
      "test_train\n",
      "train mean loss=63041.010416666664\n",
      "test_test\n",
      "test mean loss=88165.5859375\n",
      "fin save.\n",
      "epoch 8480\n",
      "test_train\n",
      "train mean loss=61498.32239583333\n",
      "test_test\n",
      "test mean loss=88259.83984375\n",
      "fin save.\n",
      "epoch 8481\n",
      "test_train\n",
      "train mean loss=61992.97942708333\n",
      "test_test\n",
      "test mean loss=88249.94140625\n",
      "fin save.\n",
      "epoch 8482\n",
      "test_train\n",
      "train mean loss=62749.25885416667\n",
      "test_test\n",
      "test mean loss=88464.3046875\n",
      "fin save.\n",
      "epoch 8483\n",
      "test_train\n",
      "train mean loss=62111.65807291667\n",
      "test_test\n",
      "test mean loss=88575.7890625\n",
      "fin save.\n",
      "epoch 8484\n",
      "test_train\n",
      "train mean loss=62476.06796875\n",
      "test_test\n",
      "test mean loss=88355.6328125\n",
      "fin save.\n",
      "epoch 8485\n",
      "test_train\n",
      "train mean loss=61590.18645833333\n",
      "test_test\n",
      "test mean loss=88445.65625\n",
      "fin save.\n",
      "epoch 8486\n",
      "test_train\n",
      "train mean loss=62119.52421875\n",
      "test_test\n",
      "test mean loss=88236.921875\n",
      "fin save.\n",
      "epoch 8487\n",
      "test_train\n",
      "train mean loss=62114.61484375\n",
      "test_test\n",
      "test mean loss=88093.3046875\n",
      "fin save.\n",
      "epoch 8488\n",
      "test_train\n",
      "train mean loss=63100.4453125\n",
      "test_test\n",
      "test mean loss=88308.25\n",
      "fin save.\n",
      "epoch 8489\n",
      "test_train\n",
      "train mean loss=61872.459635416664\n",
      "test_test\n",
      "test mean loss=88193.76171875\n",
      "fin save.\n",
      "epoch 8490\n",
      "test_train\n",
      "train mean loss=62322.43515625\n",
      "test_test\n",
      "test mean loss=88260.66796875\n",
      "fin save.\n",
      "epoch 8491\n",
      "test_train\n",
      "train mean loss=62273.16328125\n",
      "test_test\n",
      "test mean loss=88438.6953125\n",
      "fin save.\n",
      "epoch 8492\n",
      "test_train\n",
      "train mean loss=61966.79739583333\n",
      "test_test\n",
      "test mean loss=88429.23046875\n",
      "fin save.\n",
      "epoch 8493\n",
      "test_train\n",
      "train mean loss=62667.070963541664\n",
      "test_test\n",
      "test mean loss=88335.5\n",
      "fin save.\n",
      "epoch 8494\n",
      "test_train\n",
      "train mean loss=61811.88658854167\n",
      "test_test\n",
      "test mean loss=88251.6328125\n",
      "fin save.\n",
      "epoch 8495\n",
      "test_train\n",
      "train mean loss=61353.265885416666\n",
      "test_test\n",
      "test mean loss=88466.4375\n",
      "fin save.\n",
      "epoch 8496\n",
      "test_train\n",
      "train mean loss=61579.064713541666\n",
      "test_test\n",
      "test mean loss=88233.80859375\n",
      "fin save.\n",
      "epoch 8497\n",
      "test_train\n",
      "train mean loss=62786.90390625\n",
      "test_test\n",
      "test mean loss=88380.26953125\n",
      "fin save.\n",
      "epoch 8498\n",
      "test_train\n",
      "train mean loss=62083.059375\n",
      "test_test\n",
      "test mean loss=88207.92578125\n",
      "fin save.\n",
      "epoch 8499\n",
      "test_train\n",
      "train mean loss=62152.23255208333\n",
      "test_test\n",
      "test mean loss=88201.72265625\n",
      "fin save.\n",
      "epoch 8500\n",
      "test_train\n",
      "train mean loss=63224.63880208333\n",
      "test_test\n",
      "test mean loss=88119.04296875\n",
      "fin save.\n",
      "epoch 8501\n",
      "test_train\n",
      "train mean loss=61520.60234375\n",
      "test_test\n",
      "test mean loss=88289.35546875\n",
      "fin save.\n",
      "epoch 8502\n",
      "test_train\n",
      "train mean loss=62799.36328125\n",
      "test_test\n",
      "test mean loss=88341.9921875\n",
      "fin save.\n",
      "epoch 8503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_train\n",
      "train mean loss=61855.22213541667\n",
      "test_test\n",
      "test mean loss=88338.2578125\n",
      "fin save.\n",
      "epoch 8504\n",
      "test_train\n",
      "train mean loss=61742.562239583334\n",
      "test_test\n",
      "test mean loss=88462.22265625\n",
      "fin save.\n",
      "epoch 8505\n",
      "test_train\n",
      "train mean loss=61902.354166666664\n",
      "test_test\n",
      "test mean loss=88288.97265625\n",
      "fin save.\n",
      "epoch 8506\n",
      "test_train\n",
      "train mean loss=62790.9734375\n",
      "test_test\n",
      "test mean loss=88091.828125\n",
      "fin save.\n",
      "epoch 8507\n",
      "test_train\n",
      "train mean loss=62726.63671875\n",
      "test_test\n",
      "test mean loss=88110.4296875\n",
      "fin save.\n",
      "epoch 8508\n",
      "test_train\n",
      "train mean loss=62457.8265625\n",
      "test_test\n",
      "test mean loss=88033.26171875\n",
      "fin save.\n",
      "epoch 8509\n",
      "test_train\n",
      "train mean loss=62028.65078125\n",
      "test_test\n",
      "test mean loss=87911.92578125\n",
      "fin save.\n",
      "epoch 8510\n",
      "test_train\n",
      "train mean loss=62747.998828125\n",
      "test_test\n",
      "test mean loss=88154.23046875\n",
      "fin save.\n",
      "epoch 8511\n",
      "test_train\n",
      "train mean loss=63767.184895833336\n",
      "test_test\n",
      "test mean loss=88076.03125\n",
      "fin save.\n",
      "epoch 8512\n",
      "test_train\n",
      "train mean loss=62714.09947916667\n",
      "test_test\n",
      "test mean loss=88063.23046875\n",
      "fin save.\n",
      "epoch 8513\n",
      "test_train\n",
      "train mean loss=62820.172526041664\n",
      "test_test\n",
      "test mean loss=88099.09765625\n",
      "fin save.\n",
      "epoch 8514\n",
      "test_train\n",
      "train mean loss=62632.27916666667\n",
      "test_test\n",
      "test mean loss=88187.67578125\n",
      "fin save.\n",
      "epoch 8515\n",
      "test_train\n",
      "train mean loss=61836.78697916667\n",
      "test_test\n",
      "test mean loss=87966.015625\n",
      "fin save.\n",
      "epoch 8516\n",
      "test_train\n",
      "train mean loss=62013.688151041664\n",
      "test_test\n",
      "test mean loss=87891.0703125\n",
      "fin save.\n",
      "epoch 8517\n",
      "test_train\n",
      "train mean loss=61976.67734375\n",
      "test_test\n",
      "test mean loss=88044.8359375\n",
      "fin save.\n",
      "epoch 8518\n",
      "test_train\n",
      "train mean loss=62242.49140625\n",
      "test_test\n",
      "test mean loss=88188.98046875\n",
      "fin save.\n",
      "epoch 8519\n",
      "test_train\n",
      "train mean loss=62277.81796875\n",
      "test_test\n",
      "test mean loss=88061.109375\n",
      "fin save.\n",
      "epoch 8520\n",
      "test_train\n",
      "train mean loss=62309.64166666667\n",
      "test_test\n",
      "test mean loss=88163.06640625\n",
      "fin save.\n",
      "epoch 8521\n",
      "test_train\n",
      "train mean loss=61963.40625\n",
      "test_test\n",
      "test mean loss=88073.03515625\n",
      "fin save.\n",
      "epoch 8522\n",
      "test_train\n",
      "train mean loss=62203.2125\n",
      "test_test\n",
      "test mean loss=88279.8671875\n",
      "fin save.\n",
      "epoch 8523\n",
      "test_train\n",
      "train mean loss=62316.4703125\n",
      "test_test\n",
      "test mean loss=88165.375\n",
      "fin save.\n",
      "epoch 8524\n",
      "test_train\n",
      "train mean loss=61328.5375\n",
      "test_test\n",
      "test mean loss=88137.96484375\n",
      "fin save.\n",
      "epoch 8525\n",
      "test_train\n",
      "train mean loss=61330.59583333333\n",
      "test_test\n",
      "test mean loss=88333.59375\n",
      "fin save.\n",
      "epoch 8526\n",
      "test_train\n",
      "train mean loss=62141.823958333334\n",
      "test_test\n",
      "test mean loss=88118.97265625\n",
      "fin save.\n",
      "epoch 8527\n",
      "test_train\n",
      "train mean loss=62114.24453125\n",
      "test_test\n",
      "test mean loss=88213.21484375\n",
      "fin save.\n",
      "epoch 8528\n",
      "test_train\n",
      "train mean loss=62751.393229166664\n",
      "test_test\n",
      "test mean loss=88273.85546875\n",
      "fin save.\n",
      "epoch 8529\n",
      "test_train\n",
      "train mean loss=61946.70494791667\n",
      "test_test\n",
      "test mean loss=88251.91796875\n",
      "fin save.\n",
      "epoch 8530\n",
      "test_train\n",
      "train mean loss=61513.73580729167\n",
      "test_test\n",
      "test mean loss=88174.7265625\n",
      "fin save.\n",
      "epoch 8531\n",
      "test_train\n",
      "train mean loss=62023.7171875\n",
      "test_test\n",
      "test mean loss=88261.7578125\n",
      "fin save.\n",
      "epoch 8532\n",
      "test_train\n",
      "train mean loss=61359.961197916666\n",
      "test_test\n",
      "test mean loss=88208.41796875\n",
      "fin save.\n",
      "epoch 8533\n",
      "test_train\n",
      "train mean loss=61948.80963541667\n",
      "test_test\n",
      "test mean loss=88341.4609375\n",
      "fin save.\n",
      "epoch 8534\n",
      "test_train\n",
      "train mean loss=62227.242578125\n",
      "test_test\n",
      "test mean loss=88393.21484375\n",
      "fin save.\n",
      "epoch 8535\n",
      "test_train\n",
      "train mean loss=62248.49114583333\n",
      "test_test\n",
      "test mean loss=88098.359375\n",
      "fin save.\n",
      "epoch 8536\n",
      "test_train\n",
      "train mean loss=62869.54895833333\n",
      "test_test\n",
      "test mean loss=88382.82421875\n",
      "fin save.\n",
      "epoch 8537\n",
      "test_train\n",
      "train mean loss=62236.71432291667\n",
      "test_test\n",
      "test mean loss=88589.578125\n",
      "fin save.\n",
      "epoch 8538\n",
      "test_train\n",
      "train mean loss=62830.26080729167\n",
      "test_test\n",
      "test mean loss=88227.5078125\n",
      "fin save.\n",
      "epoch 8539\n",
      "test_train\n",
      "train mean loss=62398.290625\n",
      "test_test\n",
      "test mean loss=88237.625\n",
      "fin save.\n",
      "epoch 8540\n",
      "test_train\n",
      "train mean loss=61908.83802083333\n",
      "test_test\n",
      "test mean loss=87872.88671875\n",
      "fin save.\n",
      "epoch 8541\n",
      "test_train\n",
      "train mean loss=62416.96953125\n",
      "test_test\n",
      "test mean loss=87838.83203125\n",
      "fin save.\n",
      "epoch 8542\n",
      "test_train\n",
      "train mean loss=61844.877604166664\n",
      "test_test\n",
      "test mean loss=87854.7578125\n",
      "fin save.\n",
      "epoch 8543\n",
      "test_train\n",
      "train mean loss=62138.08841145833\n",
      "test_test\n",
      "test mean loss=88204.8828125\n",
      "fin save.\n",
      "epoch 8544\n",
      "test_train\n",
      "train mean loss=62235.58489583333\n",
      "test_test\n",
      "test mean loss=88027.28515625\n",
      "fin save.\n",
      "epoch 8545\n",
      "test_train\n",
      "train mean loss=61965.01614583333\n",
      "test_test\n",
      "test mean loss=87892.40234375\n",
      "fin save.\n",
      "epoch 8546\n",
      "test_train\n",
      "train mean loss=62346.00286458333\n",
      "test_test\n",
      "test mean loss=88133.70703125\n",
      "fin save.\n",
      "epoch 8547\n",
      "test_train\n",
      "train mean loss=62147.01328125\n",
      "test_test\n",
      "test mean loss=88307.765625\n",
      "fin save.\n",
      "epoch 8548\n",
      "test_train\n",
      "train mean loss=62597.0828125\n",
      "test_test\n",
      "test mean loss=88389.9375\n",
      "fin save.\n",
      "epoch 8549\n",
      "test_train\n",
      "train mean loss=62187.33645833333\n",
      "test_test\n",
      "test mean loss=88245.453125\n",
      "fin save.\n",
      "epoch 8550\n",
      "test_train\n",
      "train mean loss=61762.346354166664\n",
      "test_test\n",
      "test mean loss=88229.94921875\n",
      "fin save.\n",
      "epoch 8551\n",
      "test_train\n",
      "train mean loss=62297.97421875\n",
      "test_test\n",
      "test mean loss=88389.796875\n",
      "fin save.\n",
      "epoch 8552\n",
      "test_train\n",
      "train mean loss=62684.12786458333\n",
      "test_test\n",
      "test mean loss=88334.1015625\n",
      "fin save.\n",
      "epoch 8553\n",
      "test_train\n",
      "train mean loss=62830.69231770833\n",
      "test_test\n",
      "test mean loss=88220.0546875\n",
      "fin save.\n",
      "epoch 8554\n",
      "test_train\n",
      "train mean loss=62682.481119791664\n",
      "test_test\n",
      "test mean loss=88162.34765625\n",
      "fin save.\n",
      "epoch 8555\n",
      "test_train\n",
      "train mean loss=62233.057291666664\n",
      "test_test\n",
      "test mean loss=88295.80859375\n",
      "fin save.\n",
      "epoch 8556\n",
      "test_train\n",
      "train mean loss=61353.371484375\n",
      "test_test\n",
      "test mean loss=88350.4375\n",
      "fin save.\n",
      "epoch 8557\n",
      "test_train\n",
      "train mean loss=61916.603776041666\n",
      "test_test\n",
      "test mean loss=88363.33203125\n",
      "fin save.\n",
      "epoch 8558\n",
      "test_train\n",
      "train mean loss=61799.94322916667\n",
      "test_test\n",
      "test mean loss=88304.8984375\n",
      "fin save.\n",
      "epoch 8559\n",
      "test_train\n",
      "train mean loss=62224.73776041667\n",
      "test_test\n",
      "test mean loss=88234.96875\n",
      "fin save.\n",
      "epoch 8560\n",
      "test_train\n",
      "train mean loss=62063.9921875\n",
      "test_test\n",
      "test mean loss=87945.22265625\n",
      "fin save.\n",
      "epoch 8561\n",
      "test_train\n",
      "train mean loss=61319.47799479167\n",
      "test_test\n",
      "test mean loss=87936.48046875\n",
      "fin save.\n",
      "epoch 8562\n",
      "test_train\n",
      "train mean loss=62131.568359375\n",
      "test_test\n",
      "test mean loss=88305.6328125\n",
      "fin save.\n",
      "epoch 8563\n",
      "test_train\n",
      "train mean loss=62908.04869791667\n",
      "test_test\n",
      "test mean loss=88450.9140625\n",
      "fin save.\n",
      "epoch 8564\n",
      "test_train\n",
      "train mean loss=62438.503255208336\n",
      "test_test\n",
      "test mean loss=88445.57421875\n",
      "fin save.\n",
      "epoch 8565\n",
      "test_train\n",
      "train mean loss=63042.213151041666\n",
      "test_test\n",
      "test mean loss=88176.703125\n",
      "fin save.\n",
      "epoch 8566\n",
      "test_train\n",
      "train mean loss=61821.472395833334\n",
      "test_test\n",
      "test mean loss=88257.98828125\n",
      "fin save.\n",
      "epoch 8567\n",
      "test_train\n",
      "train mean loss=62406.31536458333\n",
      "test_test\n",
      "test mean loss=88480.5703125\n",
      "fin save.\n",
      "epoch 8568\n",
      "test_train\n",
      "train mean loss=63814.78359375\n",
      "test_test\n",
      "test mean loss=88307.1015625\n",
      "fin save.\n",
      "epoch 8569\n",
      "test_train\n",
      "train mean loss=60874.52005208333\n",
      "test_test\n",
      "test mean loss=88439.703125\n",
      "fin save.\n",
      "epoch 8570\n",
      "test_train\n",
      "train mean loss=63155.63177083333\n",
      "test_test\n",
      "test mean loss=88334.1953125\n",
      "fin save.\n",
      "epoch 8571\n",
      "test_train\n",
      "train mean loss=61950.25338541667\n",
      "test_test\n",
      "test mean loss=88447.37890625\n",
      "fin save.\n",
      "epoch 8572\n",
      "test_train\n",
      "train mean loss=62103.22473958333\n",
      "test_test\n",
      "test mean loss=88400.484375\n",
      "fin save.\n",
      "epoch 8573\n",
      "test_train\n",
      "train mean loss=62346.460286458336\n",
      "test_test\n",
      "test mean loss=88390.76953125\n",
      "fin save.\n",
      "epoch 8574\n",
      "test_train\n",
      "train mean loss=61017.43515625\n",
      "test_test\n",
      "test mean loss=88356.26171875\n",
      "fin save.\n",
      "epoch 8575\n",
      "test_train\n",
      "train mean loss=62178.773177083334\n",
      "test_test\n",
      "test mean loss=88107.3125\n",
      "fin save.\n",
      "epoch 8576\n",
      "test_train\n",
      "train mean loss=61795.538802083334\n",
      "test_test\n",
      "test mean loss=88119.50390625\n",
      "fin save.\n",
      "epoch 8577\n",
      "test_train\n",
      "train mean loss=61613.49322916667\n",
      "test_test\n",
      "test mean loss=88277.16796875\n",
      "fin save.\n",
      "epoch 8578\n",
      "test_train\n",
      "train mean loss=62060.10794270833\n",
      "test_test\n",
      "test mean loss=88085.87109375\n",
      "fin save.\n",
      "epoch 8579\n",
      "test_train\n",
      "train mean loss=62527.01796875\n",
      "test_test\n",
      "test mean loss=88100.3984375\n",
      "fin save.\n",
      "epoch 8580\n",
      "test_train\n",
      "train mean loss=61930.815625\n",
      "test_test\n",
      "test mean loss=88315.265625\n",
      "fin save.\n",
      "epoch 8581\n",
      "test_train\n",
      "train mean loss=62067.76484375\n",
      "test_test\n",
      "test mean loss=88152.5390625\n",
      "fin save.\n",
      "epoch 8582\n",
      "test_train\n",
      "train mean loss=62582.450520833336\n",
      "test_test\n",
      "test mean loss=88065.72265625\n",
      "fin save.\n",
      "epoch 8583\n",
      "test_train\n",
      "train mean loss=61021.33971354167\n",
      "test_test\n",
      "test mean loss=88143.3125\n",
      "fin save.\n",
      "epoch 8584\n",
      "test_train\n",
      "train mean loss=61808.179947916666\n",
      "test_test\n",
      "test mean loss=88197.98046875\n",
      "fin save.\n",
      "epoch 8585\n",
      "test_train\n",
      "train mean loss=61476.02330729167\n",
      "test_test\n",
      "test mean loss=87977.4765625\n",
      "fin save.\n",
      "epoch 8586\n",
      "test_train\n",
      "train mean loss=61634.69778645833\n",
      "test_test\n",
      "test mean loss=88030.1484375\n",
      "fin save.\n",
      "epoch 8587\n",
      "test_train\n",
      "train mean loss=63872.750260416666\n",
      "test_test\n",
      "test mean loss=88268.77734375\n",
      "fin save.\n",
      "epoch 8588\n",
      "test_train\n",
      "train mean loss=63113.27239583333\n",
      "test_test\n",
      "test mean loss=88078.56640625\n",
      "fin save.\n",
      "epoch 8589\n",
      "test_train\n",
      "train mean loss=62257.86901041667\n",
      "test_test\n",
      "test mean loss=88066.890625\n",
      "fin save.\n",
      "epoch 8590\n",
      "test_train\n",
      "train mean loss=62786.27526041667\n",
      "test_test\n",
      "test mean loss=88140.2265625\n",
      "fin save.\n",
      "epoch 8591\n",
      "test_train\n",
      "train mean loss=61444.052994791666\n",
      "test_test\n",
      "test mean loss=87990.2578125\n",
      "fin save.\n",
      "epoch 8592\n",
      "test_train\n",
      "train mean loss=62309.03203125\n",
      "test_test\n",
      "test mean loss=87898.1875\n",
      "fin save.\n",
      "epoch 8593\n",
      "test_train\n",
      "train mean loss=61321.86666666667\n",
      "test_test\n",
      "test mean loss=87863.4296875\n",
      "fin save.\n",
      "epoch 8594\n",
      "test_train\n",
      "train mean loss=62472.3953125\n",
      "test_test\n",
      "test mean loss=87985.87109375\n",
      "fin save.\n",
      "epoch 8595\n",
      "test_train\n",
      "train mean loss=62121.47447916667\n",
      "test_test\n",
      "test mean loss=88011.88671875\n",
      "fin save.\n",
      "epoch 8596\n",
      "test_train\n",
      "train mean loss=62447.48151041667\n",
      "test_test\n",
      "test mean loss=88003.80859375\n",
      "fin save.\n",
      "epoch 8597\n",
      "test_train\n",
      "train mean loss=61615.582421875\n",
      "test_test\n",
      "test mean loss=87831.84375\n",
      "fin save.\n",
      "epoch 8598\n",
      "test_train\n",
      "train mean loss=62260.68893229167\n",
      "test_test\n",
      "test mean loss=87687.04296875\n",
      "fin save.\n",
      "epoch 8599\n",
      "test_train\n",
      "train mean loss=62233.29778645833\n",
      "test_test\n",
      "test mean loss=87681.6015625\n",
      "fin save.\n",
      "epoch 8600\n",
      "test_train\n",
      "train mean loss=62136.53177083333\n",
      "test_test\n",
      "test mean loss=87832.1953125\n",
      "fin save.\n",
      "epoch 8601\n",
      "test_train\n",
      "train mean loss=62954.078385416666\n",
      "test_test\n",
      "test mean loss=88001.84765625\n",
      "fin save.\n",
      "epoch 8602\n",
      "test_train\n",
      "train mean loss=62733.587239583336\n",
      "test_test\n",
      "test mean loss=87751.875\n",
      "fin save.\n",
      "epoch 8603\n",
      "test_train\n",
      "train mean loss=62582.62447916667\n",
      "test_test\n",
      "test mean loss=87760.3359375\n",
      "fin save.\n",
      "epoch 8604\n",
      "test_train\n",
      "train mean loss=62945.46796875\n",
      "test_test\n",
      "test mean loss=87640.48046875\n",
      "fin save.\n",
      "epoch 8605\n",
      "test_train\n",
      "train mean loss=62312.236979166664\n",
      "test_test\n",
      "test mean loss=87871.20703125\n",
      "fin save.\n",
      "epoch 8606\n",
      "test_train\n",
      "train mean loss=63214.56432291667\n",
      "test_test\n",
      "test mean loss=87882.09765625\n",
      "fin save.\n",
      "epoch 8607\n",
      "test_train\n",
      "train mean loss=61127.67526041667\n",
      "test_test\n",
      "test mean loss=88076.52734375\n",
      "fin save.\n",
      "epoch 8608\n",
      "test_train\n",
      "train mean loss=62645.140625\n",
      "test_test\n",
      "test mean loss=87842.77734375\n",
      "fin save.\n",
      "epoch 8609\n",
      "test_train\n",
      "train mean loss=63200.60052083333\n",
      "test_test\n",
      "test mean loss=88081.44921875\n",
      "fin save.\n",
      "epoch 8610\n",
      "test_train\n",
      "train mean loss=61329.009114583336\n",
      "test_test\n",
      "test mean loss=87824.00390625\n",
      "fin save.\n",
      "epoch 8611\n",
      "test_train\n",
      "train mean loss=62228.35703125\n",
      "test_test\n",
      "test mean loss=87818.52734375\n",
      "fin save.\n",
      "epoch 8612\n",
      "test_train\n",
      "train mean loss=62268.55481770833\n",
      "test_test\n",
      "test mean loss=87924.6328125\n",
      "fin save.\n",
      "epoch 8613\n",
      "test_train\n",
      "train mean loss=61695.57421875\n",
      "test_test\n",
      "test mean loss=87872.46484375\n",
      "fin save.\n",
      "epoch 8614\n",
      "test_train\n",
      "train mean loss=62447.40221354167\n",
      "test_test\n",
      "test mean loss=87728.2421875\n",
      "fin save.\n",
      "epoch 8615\n",
      "test_train\n",
      "train mean loss=62056.33489583333\n",
      "test_test\n",
      "test mean loss=87783.6875\n",
      "fin save.\n",
      "epoch 8616\n",
      "test_train\n",
      "train mean loss=61841.463671875\n",
      "test_test\n",
      "test mean loss=87790.37109375\n",
      "fin save.\n",
      "epoch 8617\n",
      "test_train\n",
      "train mean loss=62601.23932291667\n",
      "test_test\n",
      "test mean loss=87691.29296875\n",
      "fin save.\n",
      "epoch 8618\n",
      "test_train\n",
      "train mean loss=61713.28828125\n",
      "test_test\n",
      "test mean loss=87764.1875\n",
      "fin save.\n",
      "epoch 8619\n",
      "test_train\n",
      "train mean loss=61400.184895833336\n",
      "test_test\n",
      "test mean loss=87732.19140625\n",
      "fin save.\n",
      "epoch 8620\n",
      "test_train\n",
      "train mean loss=62189.57734375\n",
      "test_test\n",
      "test mean loss=87808.0625\n",
      "fin save.\n",
      "epoch 8621\n",
      "test_train\n",
      "train mean loss=62819.046614583334\n",
      "test_test\n",
      "test mean loss=87836.6640625\n",
      "fin save.\n",
      "epoch 8622\n",
      "test_train\n",
      "train mean loss=62106.561197916664\n",
      "test_test\n",
      "test mean loss=87981.81640625\n",
      "fin save.\n",
      "epoch 8623\n",
      "test_train\n",
      "train mean loss=62765.12578125\n",
      "test_test\n",
      "test mean loss=87850.98046875\n",
      "fin save.\n",
      "epoch 8624\n",
      "test_train\n",
      "train mean loss=62766.94778645833\n",
      "test_test\n",
      "test mean loss=87808.38671875\n",
      "fin save.\n",
      "epoch 8625\n",
      "test_train\n",
      "train mean loss=61868.552083333336\n",
      "test_test\n",
      "test mean loss=87816.1953125\n",
      "fin save.\n",
      "epoch 8626\n",
      "test_train\n",
      "train mean loss=61924.63385416667\n",
      "test_test\n",
      "test mean loss=87762.22265625\n",
      "fin save.\n",
      "epoch 8627\n",
      "test_train\n",
      "train mean loss=62376.552083333336\n",
      "test_test\n",
      "test mean loss=87937.5390625\n",
      "fin save.\n",
      "epoch 8628\n",
      "test_train\n",
      "train mean loss=62025.11119791667\n",
      "test_test\n",
      "test mean loss=88289.38671875\n",
      "fin save.\n",
      "epoch 8629\n",
      "test_train\n",
      "train mean loss=62697.48385416667\n",
      "test_test\n",
      "test mean loss=87962.5703125\n",
      "fin save.\n",
      "epoch 8630\n",
      "test_train\n",
      "train mean loss=62042.876302083336\n",
      "test_test\n",
      "test mean loss=88075.48046875\n",
      "fin save.\n",
      "epoch 8631\n",
      "test_train\n",
      "train mean loss=61947.29596354167\n",
      "test_test\n",
      "test mean loss=87830.8515625\n",
      "fin save.\n",
      "epoch 8632\n",
      "test_train\n",
      "train mean loss=62905.543229166666\n",
      "test_test\n",
      "test mean loss=87964.66796875\n",
      "fin save.\n",
      "epoch 8633\n",
      "test_train\n",
      "train mean loss=61944.141927083336\n",
      "test_test\n",
      "test mean loss=88098.4765625\n",
      "fin save.\n",
      "epoch 8634\n",
      "test_train\n",
      "train mean loss=61881.29505208333\n",
      "test_test\n",
      "test mean loss=87954.8125\n",
      "fin save.\n",
      "epoch 8635\n",
      "test_train\n",
      "train mean loss=61867.761458333334\n",
      "test_test\n",
      "test mean loss=87849.625\n",
      "fin save.\n",
      "epoch 8636\n",
      "test_train\n",
      "train mean loss=61634.46979166667\n",
      "test_test\n",
      "test mean loss=87743.27734375\n",
      "fin save.\n",
      "epoch 8637\n",
      "test_train\n",
      "train mean loss=61609.16302083333\n",
      "test_test\n",
      "test mean loss=87695.5546875\n",
      "fin save.\n",
      "epoch 8638\n",
      "test_train\n",
      "train mean loss=61744.84817708333\n",
      "test_test\n",
      "test mean loss=87683.03125\n",
      "fin save.\n",
      "epoch 8639\n",
      "test_train\n",
      "train mean loss=63757.472395833334\n",
      "test_test\n",
      "test mean loss=87793.078125\n",
      "fin save.\n",
      "epoch 8640\n",
      "test_train\n",
      "train mean loss=62582.13567708333\n",
      "test_test\n",
      "test mean loss=87789.9296875\n",
      "fin save.\n",
      "epoch 8641\n",
      "test_train\n",
      "train mean loss=62202.594010416666\n",
      "test_test\n",
      "test mean loss=88222.3828125\n",
      "fin save.\n",
      "epoch 8642\n",
      "test_train\n",
      "train mean loss=62684.390364583334\n",
      "test_test\n",
      "test mean loss=88147.109375\n",
      "fin save.\n",
      "epoch 8643\n",
      "test_train\n",
      "train mean loss=62047.993489583336\n",
      "test_test\n",
      "test mean loss=88507.2578125\n",
      "fin save.\n",
      "epoch 8644\n",
      "test_train\n",
      "train mean loss=62427.46015625\n",
      "test_test\n",
      "test mean loss=88597.1796875\n",
      "fin save.\n",
      "epoch 8645\n",
      "test_train\n",
      "train mean loss=61983.076171875\n",
      "test_test\n",
      "test mean loss=88410.5\n",
      "fin save.\n",
      "epoch 8646\n",
      "test_train\n",
      "train mean loss=60796.49765625\n",
      "test_test\n",
      "test mean loss=88487.78125\n",
      "fin save.\n",
      "epoch 8647\n",
      "test_train\n",
      "train mean loss=61701.211197916666\n",
      "test_test\n",
      "test mean loss=88446.85546875\n",
      "fin save.\n",
      "epoch 8648\n",
      "test_train\n",
      "train mean loss=61787.213541666664\n",
      "test_test\n",
      "test mean loss=88404.80859375\n",
      "fin save.\n",
      "epoch 8649\n",
      "test_train\n",
      "train mean loss=62311.173177083336\n",
      "test_test\n",
      "test mean loss=88296.96484375\n",
      "fin save.\n",
      "epoch 8650\n",
      "test_train\n",
      "train mean loss=61709.723958333336\n",
      "test_test\n",
      "test mean loss=88335.078125\n",
      "fin save.\n",
      "epoch 8651\n",
      "test_train\n",
      "train mean loss=62006.99895833333\n",
      "test_test\n",
      "test mean loss=88064.515625\n",
      "fin save.\n",
      "epoch 8652\n",
      "test_train\n",
      "train mean loss=63057.475260416664\n",
      "test_test\n",
      "test mean loss=88002.35546875\n",
      "fin save.\n",
      "epoch 8653\n",
      "test_train\n",
      "train mean loss=61339.99270833333\n",
      "test_test\n",
      "test mean loss=88429.7890625\n",
      "fin save.\n",
      "epoch 8654\n",
      "test_train\n",
      "train mean loss=62349.490625\n",
      "test_test\n",
      "test mean loss=88064.63671875\n",
      "fin save.\n",
      "epoch 8655\n",
      "test_train\n",
      "train mean loss=62070.232421875\n",
      "test_test\n",
      "test mean loss=88177.65234375\n",
      "fin save.\n",
      "epoch 8656\n",
      "test_train\n",
      "train mean loss=61750.09609375\n",
      "test_test\n",
      "test mean loss=88104.12109375\n",
      "fin save.\n",
      "epoch 8657\n",
      "test_train\n",
      "train mean loss=62052.59583333333\n",
      "test_test\n",
      "test mean loss=88359.03515625\n",
      "fin save.\n",
      "epoch 8658\n",
      "test_train\n",
      "train mean loss=61086.215625\n",
      "test_test\n",
      "test mean loss=88121.9453125\n",
      "fin save.\n",
      "epoch 8659\n",
      "test_train\n",
      "train mean loss=62021.953385416666\n",
      "test_test\n",
      "test mean loss=88164.01953125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fin save.\n",
      "epoch 8660\n",
      "test_train\n",
      "train mean loss=61860.566145833334\n",
      "test_test\n",
      "test mean loss=88170.046875\n",
      "fin save.\n",
      "epoch 8661\n",
      "test_train\n",
      "train mean loss=62171.67421875\n",
      "test_test\n",
      "test mean loss=88169.5\n",
      "fin save.\n",
      "epoch 8662\n",
      "test_train\n",
      "train mean loss=63653.333203125\n",
      "test_test\n",
      "test mean loss=88129.38671875\n",
      "fin save.\n",
      "epoch 8663\n",
      "test_train\n",
      "train mean loss=62833.75078125\n",
      "test_test\n",
      "test mean loss=88012.28125\n",
      "fin save.\n",
      "epoch 8664\n",
      "test_train\n",
      "train mean loss=61903.136328125\n",
      "test_test\n",
      "test mean loss=88314.02734375\n",
      "fin save.\n",
      "epoch 8665\n",
      "test_train\n",
      "train mean loss=62548.981640625\n",
      "test_test\n",
      "test mean loss=88236.5546875\n",
      "fin save.\n",
      "epoch 8666\n",
      "test_train\n",
      "train mean loss=62153.99700520833\n",
      "test_test\n",
      "test mean loss=88197.359375\n",
      "fin save.\n",
      "epoch 8667\n",
      "test_train\n",
      "train mean loss=62297.981770833336\n",
      "test_test\n",
      "test mean loss=88041.8515625\n",
      "fin save.\n",
      "epoch 8668\n",
      "test_train\n",
      "train mean loss=61837.58697916667\n",
      "test_test\n",
      "test mean loss=88242.546875\n",
      "fin save.\n",
      "epoch 8669\n",
      "test_train\n",
      "train mean loss=61745.106770833336\n",
      "test_test\n",
      "test mean loss=88284.453125\n",
      "fin save.\n",
      "epoch 8670\n",
      "test_train\n",
      "train mean loss=62121.40729166667\n",
      "test_test\n",
      "test mean loss=88407.140625\n",
      "fin save.\n",
      "epoch 8671\n",
      "test_train\n",
      "train mean loss=62580.660807291664\n",
      "test_test\n",
      "test mean loss=88200.2109375\n",
      "fin save.\n",
      "epoch 8672\n",
      "test_train\n",
      "train mean loss=62085.553515625\n",
      "test_test\n",
      "test mean loss=88176.68359375\n",
      "fin save.\n",
      "epoch 8673\n",
      "test_train\n",
      "train mean loss=62683.839453125\n",
      "test_test\n",
      "test mean loss=88234.96875\n",
      "fin save.\n",
      "epoch 8674\n",
      "test_train\n",
      "train mean loss=61773.30286458333\n",
      "test_test\n",
      "test mean loss=88158.515625\n",
      "fin save.\n",
      "epoch 8675\n",
      "test_train\n",
      "train mean loss=61589.447526041666\n",
      "test_test\n",
      "test mean loss=87985.203125\n",
      "fin save.\n",
      "epoch 8676\n",
      "test_train\n",
      "train mean loss=62286.87591145833\n",
      "test_test\n",
      "test mean loss=87991.7578125\n",
      "fin save.\n",
      "epoch 8677\n",
      "test_train\n",
      "train mean loss=61947.36822916667\n",
      "test_test\n",
      "test mean loss=87966.82421875\n",
      "fin save.\n",
      "epoch 8678\n",
      "test_train\n",
      "train mean loss=62478.60208333333\n",
      "test_test\n",
      "test mean loss=88224.5546875\n",
      "fin save.\n",
      "epoch 8679\n",
      "test_train\n",
      "train mean loss=61307.863020833334\n",
      "test_test\n",
      "test mean loss=87954.63671875\n",
      "fin save.\n",
      "epoch 8680\n",
      "test_train\n",
      "train mean loss=61569.98619791667\n",
      "test_test\n",
      "test mean loss=88115.94140625\n",
      "fin save.\n",
      "epoch 8681\n",
      "test_train\n",
      "train mean loss=62228.58046875\n",
      "test_test\n",
      "test mean loss=87974.15234375\n",
      "fin save.\n",
      "epoch 8682\n",
      "test_train\n",
      "train mean loss=61644.82994791667\n",
      "test_test\n",
      "test mean loss=88147.8828125\n",
      "fin save.\n",
      "epoch 8683\n",
      "test_train\n",
      "train mean loss=61802.659895833334\n",
      "test_test\n",
      "test mean loss=87901.0703125\n",
      "fin save.\n",
      "epoch 8684\n",
      "test_train\n",
      "train mean loss=61556.35546875\n",
      "test_test\n",
      "test mean loss=87861.63671875\n",
      "fin save.\n",
      "epoch 8685\n",
      "test_train\n",
      "train mean loss=62257.93854166667\n",
      "test_test\n",
      "test mean loss=87693.95703125\n",
      "fin save.\n",
      "epoch 8686\n",
      "test_train\n",
      "train mean loss=62301.49609375\n",
      "test_test\n",
      "test mean loss=87665.3828125\n",
      "fin save.\n",
      "epoch 8687\n",
      "test_train\n",
      "train mean loss=61969.82760416667\n",
      "test_test\n",
      "test mean loss=87846.70703125\n",
      "fin save.\n",
      "epoch 8688\n",
      "test_train\n",
      "train mean loss=61559.65052083333\n",
      "test_test\n",
      "test mean loss=87678.77734375\n",
      "fin save.\n",
      "epoch 8689\n",
      "test_train\n",
      "train mean loss=62106.208723958334\n",
      "test_test\n",
      "test mean loss=87733.73046875\n",
      "fin save.\n",
      "epoch 8690\n",
      "test_train\n",
      "train mean loss=61703.46380208333\n",
      "test_test\n",
      "test mean loss=88030.6484375\n",
      "fin save.\n",
      "epoch 8691\n",
      "test_train\n",
      "train mean loss=62715.77135416667\n",
      "test_test\n",
      "test mean loss=88032.80859375\n",
      "fin save.\n",
      "epoch 8692\n",
      "test_train\n",
      "train mean loss=61639.150130208334\n",
      "test_test\n",
      "test mean loss=87988.33984375\n",
      "fin save.\n",
      "epoch 8693\n",
      "test_train\n",
      "train mean loss=62358.545572916664\n",
      "test_test\n",
      "test mean loss=87922.94140625\n",
      "fin save.\n",
      "epoch 8694\n",
      "test_train\n",
      "train mean loss=62545.151041666664\n",
      "test_test\n",
      "test mean loss=87893.12109375\n",
      "fin save.\n",
      "epoch 8695\n",
      "test_train\n",
      "train mean loss=62700.2640625\n",
      "test_test\n",
      "test mean loss=87915.44921875\n",
      "fin save.\n",
      "epoch 8696\n",
      "test_train\n",
      "train mean loss=62369.527083333334\n",
      "test_test\n",
      "test mean loss=87839.859375\n",
      "fin save.\n",
      "epoch 8697\n",
      "test_train\n",
      "train mean loss=61511.28802083333\n",
      "test_test\n",
      "test mean loss=88011.40234375\n",
      "fin save.\n",
      "epoch 8698\n",
      "test_train\n",
      "train mean loss=61379.337239583336\n",
      "test_test\n",
      "test mean loss=88010.7109375\n",
      "fin save.\n",
      "epoch 8699\n",
      "test_train\n",
      "train mean loss=62512.38619791667\n",
      "test_test\n",
      "test mean loss=87805.47265625\n",
      "fin save.\n",
      "epoch 8700\n",
      "test_train\n",
      "train mean loss=62097.22604166667\n",
      "test_test\n",
      "test mean loss=88329.00390625\n",
      "fin save.\n",
      "epoch 8701\n",
      "test_train\n",
      "train mean loss=62048.18125\n",
      "test_test\n",
      "test mean loss=88194.7578125\n",
      "fin save.\n",
      "epoch 8702\n",
      "test_train\n",
      "train mean loss=61528.394921875\n",
      "test_test\n",
      "test mean loss=88299.40625\n",
      "fin save.\n",
      "epoch 8703\n",
      "test_train\n",
      "train mean loss=63400.80455729167\n",
      "test_test\n",
      "test mean loss=88241.6875\n",
      "fin save.\n",
      "epoch 8704\n",
      "test_train\n",
      "train mean loss=61898.807421875\n",
      "test_test\n",
      "test mean loss=88153.93359375\n",
      "fin save.\n",
      "epoch 8705\n",
      "test_train\n",
      "train mean loss=61759.02057291667\n",
      "test_test\n",
      "test mean loss=88042.66015625\n",
      "fin save.\n",
      "epoch 8706\n",
      "test_train\n",
      "train mean loss=62397.917708333334\n",
      "test_test\n",
      "test mean loss=88020.55078125\n",
      "fin save.\n",
      "epoch 8707\n",
      "test_train\n",
      "train mean loss=62368.342447916664\n",
      "test_test\n",
      "test mean loss=87980.82421875\n",
      "fin save.\n",
      "epoch 8708\n",
      "test_train\n",
      "train mean loss=62530.01901041667\n",
      "test_test\n",
      "test mean loss=87907.4921875\n",
      "fin save.\n",
      "epoch 8709\n",
      "test_train\n",
      "train mean loss=61764.32213541667\n",
      "test_test\n",
      "test mean loss=87855.62890625\n",
      "fin save.\n",
      "epoch 8710\n",
      "test_train\n",
      "train mean loss=61710.07630208333\n",
      "test_test\n",
      "test mean loss=87630.23828125\n",
      "fin save.\n",
      "epoch 8711\n",
      "test_train\n",
      "train mean loss=62147.679947916666\n",
      "test_test\n",
      "test mean loss=87553.35546875\n",
      "fin save.\n",
      "epoch 8712\n",
      "test_train\n",
      "train mean loss=61926.4765625\n",
      "test_test\n",
      "test mean loss=87629.48828125\n",
      "fin save.\n",
      "epoch 8713\n",
      "test_train\n",
      "train mean loss=61944.20234375\n",
      "test_test\n",
      "test mean loss=87934.21484375\n",
      "fin save.\n",
      "epoch 8714\n",
      "test_train\n",
      "train mean loss=62216.93177083333\n",
      "test_test\n",
      "test mean loss=87938.78125\n",
      "fin save.\n",
      "epoch 8715\n",
      "test_train\n",
      "train mean loss=61848.52421875\n",
      "test_test\n",
      "test mean loss=87957.671875\n",
      "fin save.\n",
      "epoch 8716\n",
      "test_train\n",
      "train mean loss=61190.62877604167\n",
      "test_test\n",
      "test mean loss=87917.609375\n",
      "fin save.\n",
      "epoch 8717\n",
      "test_train\n",
      "train mean loss=61295.019921875\n",
      "test_test\n",
      "test mean loss=88068.7890625\n",
      "fin save.\n",
      "epoch 8718\n",
      "test_train\n",
      "train mean loss=62086.94739583333\n",
      "test_test\n",
      "test mean loss=88066.29296875\n",
      "fin save.\n",
      "epoch 8719\n",
      "test_train\n",
      "train mean loss=61660.1453125\n",
      "test_test\n",
      "test mean loss=88002.39453125\n",
      "fin save.\n",
      "epoch 8720\n",
      "test_train\n",
      "train mean loss=62231.01171875\n",
      "test_test\n",
      "test mean loss=87977.52734375\n",
      "fin save.\n",
      "epoch 8721\n",
      "test_train\n",
      "train mean loss=63406.242578125\n",
      "test_test\n",
      "test mean loss=87777.4609375\n",
      "fin save.\n",
      "epoch 8722\n",
      "test_train\n",
      "train mean loss=62066.091145833336\n",
      "test_test\n",
      "test mean loss=87944.3125\n",
      "fin save.\n",
      "epoch 8723\n",
      "test_train\n",
      "train mean loss=62867.39895833333\n",
      "test_test\n",
      "test mean loss=88011.1171875\n",
      "fin save.\n",
      "epoch 8724\n",
      "test_train\n",
      "train mean loss=61786.52786458333\n",
      "test_test\n",
      "test mean loss=88114.99609375\n",
      "fin save.\n",
      "epoch 8725\n",
      "test_train\n",
      "train mean loss=61847.47799479167\n",
      "test_test\n",
      "test mean loss=87867.109375\n",
      "fin save.\n",
      "epoch 8726\n",
      "test_train\n",
      "train mean loss=62508.30182291667\n",
      "test_test\n",
      "test mean loss=88143.734375\n",
      "fin save.\n",
      "epoch 8727\n",
      "test_train\n",
      "train mean loss=61904.87213541667\n",
      "test_test\n",
      "test mean loss=88006.19921875\n",
      "fin save.\n",
      "epoch 8728\n",
      "test_train\n",
      "train mean loss=61781.81848958333\n",
      "test_test\n",
      "test mean loss=88040.45703125\n",
      "fin save.\n",
      "epoch 8729\n",
      "test_train\n",
      "train mean loss=62025.154947916664\n",
      "test_test\n",
      "test mean loss=88078.453125\n",
      "fin save.\n",
      "epoch 8730\n",
      "test_train\n",
      "train mean loss=62244.94635416667\n",
      "test_test\n",
      "test mean loss=87886.1953125\n",
      "fin save.\n",
      "epoch 8731\n",
      "test_train\n",
      "train mean loss=62275.359635416666\n",
      "test_test\n",
      "test mean loss=87808.890625\n",
      "fin save.\n",
      "epoch 8732\n",
      "test_train\n",
      "train mean loss=62231.554036458336\n",
      "test_test\n",
      "test mean loss=88057.4921875\n",
      "fin save.\n",
      "epoch 8733\n",
      "test_train\n",
      "train mean loss=61593.2265625\n",
      "test_test\n",
      "test mean loss=88011.640625\n",
      "fin save.\n",
      "epoch 8734\n",
      "test_train\n",
      "train mean loss=61727.330729166664\n",
      "test_test\n",
      "test mean loss=88022.8828125\n",
      "fin save.\n",
      "epoch 8735\n",
      "test_train\n",
      "train mean loss=61970.73919270833\n",
      "test_test\n",
      "test mean loss=87984.91796875\n",
      "fin save.\n",
      "epoch 8736\n",
      "test_train\n",
      "train mean loss=62784.84973958333\n",
      "test_test\n",
      "test mean loss=87801.6640625\n",
      "fin save.\n",
      "epoch 8737\n",
      "test_train\n",
      "train mean loss=63247.78997395833\n",
      "test_test\n",
      "test mean loss=87976.5625\n",
      "fin save.\n",
      "epoch 8738\n",
      "test_train\n",
      "train mean loss=62418.2640625\n",
      "test_test\n",
      "test mean loss=87891.21484375\n",
      "fin save.\n",
      "epoch 8739\n",
      "test_train\n",
      "train mean loss=61826.024739583336\n",
      "test_test\n",
      "test mean loss=87825.1953125\n",
      "fin save.\n",
      "epoch 8740\n",
      "test_train\n",
      "train mean loss=61461.69765625\n",
      "test_test\n",
      "test mean loss=87983.1640625\n",
      "fin save.\n",
      "epoch 8741\n",
      "test_train\n",
      "train mean loss=62046.127604166664\n",
      "test_test\n",
      "test mean loss=88012.44921875\n",
      "fin save.\n",
      "epoch 8742\n",
      "test_train\n",
      "train mean loss=61731.68359375\n",
      "test_test\n",
      "test mean loss=87958.77734375\n",
      "fin save.\n",
      "epoch 8743\n",
      "test_train\n",
      "train mean loss=62407.79700520833\n",
      "test_test\n",
      "test mean loss=88045.296875\n",
      "fin save.\n",
      "epoch 8744\n",
      "test_train\n",
      "train mean loss=62379.01458333333\n",
      "test_test\n",
      "test mean loss=88001.34765625\n",
      "fin save.\n",
      "epoch 8745\n",
      "test_train\n",
      "train mean loss=62053.0140625\n",
      "test_test\n",
      "test mean loss=88074.82421875\n",
      "fin save.\n",
      "epoch 8746\n",
      "test_train\n",
      "train mean loss=62860.92669270833\n",
      "test_test\n",
      "test mean loss=88173.3984375\n",
      "fin save.\n",
      "epoch 8747\n",
      "test_train\n",
      "train mean loss=62557.55377604167\n",
      "test_test\n",
      "test mean loss=87997.37890625\n",
      "fin save.\n",
      "epoch 8748\n",
      "test_train\n",
      "train mean loss=62378.049088541666\n",
      "test_test\n",
      "test mean loss=88067.75\n",
      "fin save.\n",
      "epoch 8749\n",
      "test_train\n",
      "train mean loss=61985.90481770833\n",
      "test_test\n",
      "test mean loss=88174.08984375\n",
      "fin save.\n",
      "epoch 8750\n",
      "test_train\n",
      "train mean loss=61614.4953125\n",
      "test_test\n",
      "test mean loss=87970.640625\n",
      "fin save.\n",
      "epoch 8751\n",
      "test_train\n",
      "train mean loss=61660.88723958333\n",
      "test_test\n",
      "test mean loss=88325.359375\n",
      "fin save.\n",
      "epoch 8752\n",
      "test_train\n",
      "train mean loss=63324.04609375\n",
      "test_test\n",
      "test mean loss=88325.46484375\n",
      "fin save.\n",
      "epoch 8753\n",
      "test_train\n",
      "train mean loss=61618.65338541667\n",
      "test_test\n",
      "test mean loss=88262.5\n",
      "fin save.\n",
      "epoch 8754\n",
      "test_train\n",
      "train mean loss=62201.94765625\n",
      "test_test\n",
      "test mean loss=88232.33984375\n",
      "fin save.\n",
      "epoch 8755\n",
      "test_train\n",
      "train mean loss=62828.51119791667\n",
      "test_test\n",
      "test mean loss=87898.51953125\n",
      "fin save.\n",
      "epoch 8756\n",
      "test_train\n",
      "train mean loss=62107.0125\n",
      "test_test\n",
      "test mean loss=88014.0546875\n",
      "fin save.\n",
      "epoch 8757\n",
      "test_train\n",
      "train mean loss=62152.729166666664\n",
      "test_test\n",
      "test mean loss=88021.921875\n",
      "fin save.\n",
      "epoch 8758\n",
      "test_train\n",
      "train mean loss=62004.42005208333\n",
      "test_test\n",
      "test mean loss=88085.44921875\n",
      "fin save.\n",
      "epoch 8759\n",
      "test_train\n",
      "train mean loss=61684.2140625\n",
      "test_test\n",
      "test mean loss=88231.921875\n",
      "fin save.\n",
      "epoch 8760\n",
      "test_train\n",
      "train mean loss=62601.76809895833\n",
      "test_test\n",
      "test mean loss=87788.015625\n",
      "fin save.\n",
      "epoch 8761\n",
      "test_train\n",
      "train mean loss=63046.75963541667\n",
      "test_test\n",
      "test mean loss=87919.26953125\n",
      "fin save.\n",
      "epoch 8762\n",
      "test_train\n",
      "train mean loss=63491.34713541667\n",
      "test_test\n",
      "test mean loss=87877.328125\n",
      "fin save.\n",
      "epoch 8763\n",
      "test_train\n",
      "train mean loss=62567.00989583333\n",
      "test_test\n",
      "test mean loss=87919.7265625\n",
      "fin save.\n",
      "epoch 8764\n",
      "test_train\n",
      "train mean loss=62729.13919270833\n",
      "test_test\n",
      "test mean loss=88036.25\n",
      "fin save.\n",
      "epoch 8765\n",
      "test_train\n",
      "train mean loss=61684.68828125\n",
      "test_test\n",
      "test mean loss=88133.5546875\n",
      "fin save.\n",
      "epoch 8766\n",
      "test_train\n",
      "train mean loss=61518.697916666664\n",
      "test_test\n",
      "test mean loss=88146.3359375\n",
      "fin save.\n",
      "epoch 8767\n",
      "test_train\n",
      "train mean loss=61970.057291666664\n",
      "test_test\n",
      "test mean loss=88314.29296875\n",
      "fin save.\n",
      "epoch 8768\n",
      "test_train\n",
      "train mean loss=61170.99895833333\n",
      "test_test\n",
      "test mean loss=88374.74609375\n",
      "fin save.\n",
      "epoch 8769\n",
      "test_train\n",
      "train mean loss=62281.682291666664\n",
      "test_test\n",
      "test mean loss=88173.96875\n",
      "fin save.\n",
      "epoch 8770\n",
      "test_train\n",
      "train mean loss=62319.200390625\n",
      "test_test\n",
      "test mean loss=88191.1015625\n",
      "fin save.\n",
      "epoch 8771\n",
      "test_train\n",
      "train mean loss=62247.003125\n",
      "test_test\n",
      "test mean loss=88172.609375\n",
      "fin save.\n",
      "epoch 8772\n",
      "test_train\n",
      "train mean loss=61068.62291666667\n",
      "test_test\n",
      "test mean loss=88214.1484375\n",
      "fin save.\n",
      "epoch 8773\n",
      "test_train\n",
      "train mean loss=62774.289453125\n",
      "test_test\n",
      "test mean loss=88086.85546875\n",
      "fin save.\n",
      "epoch 8774\n",
      "test_train\n",
      "train mean loss=61584.55572916667\n",
      "test_test\n",
      "test mean loss=88006.9296875\n",
      "fin save.\n",
      "epoch 8775\n",
      "test_train\n",
      "train mean loss=61794.78411458333\n",
      "test_test\n",
      "test mean loss=87770.41796875\n",
      "fin save.\n",
      "epoch 8776\n",
      "test_train\n",
      "train mean loss=63134.184895833336\n",
      "test_test\n",
      "test mean loss=88196.4375\n",
      "fin save.\n",
      "epoch 8777\n",
      "test_train\n",
      "train mean loss=62683.74765625\n",
      "test_test\n",
      "test mean loss=87923.09765625\n",
      "fin save.\n",
      "epoch 8778\n",
      "test_train\n",
      "train mean loss=61093.54140625\n",
      "test_test\n",
      "test mean loss=88009.00390625\n",
      "fin save.\n",
      "epoch 8779\n",
      "test_train\n",
      "train mean loss=62790.3546875\n",
      "test_test\n",
      "test mean loss=88333.75390625\n",
      "fin save.\n",
      "epoch 8780\n",
      "test_train\n",
      "train mean loss=62765.66953125\n",
      "test_test\n",
      "test mean loss=88039.17578125\n",
      "fin save.\n",
      "epoch 8781\n",
      "test_train\n",
      "train mean loss=61642.48580729167\n",
      "test_test\n",
      "test mean loss=87961.62109375\n",
      "fin save.\n",
      "epoch 8782\n",
      "test_train\n",
      "train mean loss=62599.21979166667\n",
      "test_test\n",
      "test mean loss=88111.171875\n",
      "fin save.\n",
      "epoch 8783\n",
      "test_train\n",
      "train mean loss=62303.648697916666\n",
      "test_test\n",
      "test mean loss=88142.265625\n",
      "fin save.\n",
      "epoch 8784\n",
      "test_train\n",
      "train mean loss=62329.247395833336\n",
      "test_test\n",
      "test mean loss=87974.44921875\n",
      "fin save.\n",
      "epoch 8785\n",
      "test_train\n",
      "train mean loss=62902.15286458333\n",
      "test_test\n",
      "test mean loss=88014.015625\n",
      "fin save.\n",
      "epoch 8786\n",
      "test_train\n",
      "train mean loss=62151.0484375\n",
      "test_test\n",
      "test mean loss=88182.59765625\n",
      "fin save.\n",
      "epoch 8787\n",
      "test_train\n",
      "train mean loss=63127.71380208333\n",
      "test_test\n",
      "test mean loss=88208.9921875\n",
      "fin save.\n",
      "epoch 8788\n",
      "test_train\n",
      "train mean loss=61819.171614583334\n",
      "test_test\n",
      "test mean loss=88322.6875\n",
      "fin save.\n",
      "epoch 8789\n",
      "test_train\n",
      "train mean loss=62245.020182291664\n",
      "test_test\n",
      "test mean loss=88610.984375\n",
      "fin save.\n",
      "epoch 8790\n",
      "test_train\n",
      "train mean loss=61941.977864583336\n",
      "test_test\n",
      "test mean loss=88480.46484375\n",
      "fin save.\n",
      "epoch 8791\n",
      "test_train\n",
      "train mean loss=61728.86666666667\n",
      "test_test\n",
      "test mean loss=88354.8671875\n",
      "fin save.\n",
      "epoch 8792\n",
      "test_train\n",
      "train mean loss=63443.76953125\n",
      "test_test\n",
      "test mean loss=88671.95703125\n",
      "fin save.\n",
      "epoch 8793\n",
      "test_train\n",
      "train mean loss=61874.79244791667\n",
      "test_test\n",
      "test mean loss=88560.78125\n",
      "fin save.\n",
      "epoch 8794\n",
      "test_train\n",
      "train mean loss=62301.291666666664\n",
      "test_test\n",
      "test mean loss=88460.8125\n",
      "fin save.\n",
      "epoch 8795\n",
      "test_train\n",
      "train mean loss=62342.28359375\n",
      "test_test\n",
      "test mean loss=88544.4296875\n",
      "fin save.\n",
      "epoch 8796\n",
      "test_train\n",
      "train mean loss=61512.146875\n",
      "test_test\n",
      "test mean loss=88258.11328125\n",
      "fin save.\n",
      "epoch 8797\n",
      "test_train\n",
      "train mean loss=62524.527083333334\n",
      "test_test\n",
      "test mean loss=88465.55859375\n",
      "fin save.\n",
      "epoch 8798\n",
      "test_train\n",
      "train mean loss=62110.58697916667\n",
      "test_test\n",
      "test mean loss=88274.18359375\n",
      "fin save.\n",
      "epoch 8799\n",
      "test_train\n",
      "train mean loss=62022.76875\n",
      "test_test\n",
      "test mean loss=88368.78125\n",
      "fin save.\n",
      "epoch 8800\n",
      "test_train\n",
      "train mean loss=62586.258072916666\n",
      "test_test\n",
      "test mean loss=88142.765625\n",
      "fin save.\n",
      "epoch 8801\n",
      "test_train\n",
      "train mean loss=62202.07825520833\n",
      "test_test\n",
      "test mean loss=88219.6953125\n",
      "fin save.\n",
      "epoch 8802\n",
      "test_train\n",
      "train mean loss=62453.731119791664\n",
      "test_test\n",
      "test mean loss=88082.4765625\n",
      "fin save.\n",
      "epoch 8803\n",
      "test_train\n",
      "train mean loss=61499.61536458333\n",
      "test_test\n",
      "test mean loss=88244.84765625\n",
      "fin save.\n",
      "epoch 8804\n",
      "test_train\n",
      "train mean loss=63182.7953125\n",
      "test_test\n",
      "test mean loss=88200.8515625\n",
      "fin save.\n",
      "epoch 8805\n",
      "test_train\n",
      "train mean loss=61643.394791666666\n",
      "test_test\n",
      "test mean loss=88212.4296875\n",
      "fin save.\n",
      "epoch 8806\n",
      "test_train\n",
      "train mean loss=62324.118489583336\n",
      "test_test\n",
      "test mean loss=88255.05078125\n",
      "fin save.\n",
      "epoch 8807\n",
      "test_train\n",
      "train mean loss=63110.983072916664\n",
      "test_test\n",
      "test mean loss=88243.8515625\n",
      "fin save.\n",
      "epoch 8808\n",
      "test_train\n",
      "train mean loss=62650.114583333336\n",
      "test_test\n",
      "test mean loss=88215.63671875\n",
      "fin save.\n",
      "epoch 8809\n",
      "test_train\n",
      "train mean loss=63424.30091145833\n",
      "test_test\n",
      "test mean loss=88257.05859375\n",
      "fin save.\n",
      "epoch 8810\n",
      "test_train\n",
      "train mean loss=63469.764453125\n",
      "test_test\n",
      "test mean loss=88374.28515625\n",
      "fin save.\n",
      "epoch 8811\n",
      "test_train\n",
      "train mean loss=61380.155989583334\n",
      "test_test\n",
      "test mean loss=88252.86328125\n",
      "fin save.\n",
      "epoch 8812\n",
      "test_train\n",
      "train mean loss=62396.497395833336\n",
      "test_test\n",
      "test mean loss=86893.890625\n",
      "fin save.\n",
      "epoch 8813\n",
      "test_train\n",
      "train mean loss=62797.88671875\n",
      "test_test\n",
      "test mean loss=86931.6640625\n",
      "fin save.\n",
      "epoch 8814\n",
      "test_train\n",
      "train mean loss=63326.703515625\n",
      "test_test\n",
      "test mean loss=87403.546875\n",
      "fin save.\n",
      "epoch 8815\n",
      "test_train\n",
      "train mean loss=62061.2671875\n",
      "test_test\n",
      "test mean loss=87288.1484375\n",
      "fin save.\n",
      "epoch 8816\n",
      "test_train\n",
      "train mean loss=62907.68125\n",
      "test_test\n",
      "test mean loss=87161.7421875\n",
      "fin save.\n",
      "epoch 8817\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_train\n",
      "train mean loss=62036.99166666667\n",
      "test_test\n",
      "test mean loss=87068.63671875\n",
      "fin save.\n",
      "epoch 8818\n",
      "test_train\n",
      "train mean loss=62625.16223958333\n",
      "test_test\n",
      "test mean loss=87081.0\n",
      "fin save.\n",
      "epoch 8819\n",
      "test_train\n",
      "train mean loss=62267.26744791667\n",
      "test_test\n",
      "test mean loss=86885.3828125\n",
      "fin save.\n",
      "epoch 8820\n",
      "test_train\n",
      "train mean loss=62560.11875\n",
      "test_test\n",
      "test mean loss=86958.61328125\n",
      "fin save.\n",
      "epoch 8821\n",
      "test_train\n",
      "train mean loss=62515.26875\n",
      "test_test\n",
      "test mean loss=86999.3515625\n",
      "fin save.\n",
      "epoch 8822\n",
      "test_train\n",
      "train mean loss=61834.48880208333\n",
      "test_test\n",
      "test mean loss=86915.078125\n",
      "fin save.\n",
      "epoch 8823\n",
      "test_train\n",
      "train mean loss=62009.92473958333\n",
      "test_test\n",
      "test mean loss=87069.046875\n",
      "fin save.\n",
      "epoch 8824\n",
      "test_train\n",
      "train mean loss=61647.86510416667\n",
      "test_test\n",
      "test mean loss=87146.578125\n",
      "fin save.\n",
      "epoch 8825\n",
      "test_train\n",
      "train mean loss=61604.68645833333\n",
      "test_test\n",
      "test mean loss=87237.85546875\n",
      "fin save.\n",
      "epoch 8826\n",
      "test_train\n",
      "train mean loss=62420.9421875\n",
      "test_test\n",
      "test mean loss=87334.6640625\n",
      "fin save.\n",
      "epoch 8827\n",
      "test_train\n",
      "train mean loss=61946.402083333334\n",
      "test_test\n",
      "test mean loss=87284.17578125\n",
      "fin save.\n",
      "epoch 8828\n",
      "test_train\n",
      "train mean loss=62606.92291666667\n",
      "test_test\n",
      "test mean loss=87244.62109375\n",
      "fin save.\n",
      "epoch 8829\n",
      "test_train\n",
      "train mean loss=62203.752734375\n",
      "test_test\n",
      "test mean loss=87372.359375\n",
      "fin save.\n",
      "epoch 8830\n",
      "test_train\n",
      "train mean loss=62259.58736979167\n",
      "test_test\n",
      "test mean loss=87483.8828125\n",
      "fin save.\n",
      "epoch 8831\n",
      "test_train\n",
      "train mean loss=62148.42981770833\n",
      "test_test\n",
      "test mean loss=87569.359375\n",
      "fin save.\n",
      "epoch 8832\n",
      "test_train\n",
      "train mean loss=62265.991927083334\n",
      "test_test\n",
      "test mean loss=87515.01171875\n",
      "fin save.\n",
      "epoch 8833\n",
      "test_train\n",
      "train mean loss=62032.25859375\n",
      "test_test\n",
      "test mean loss=87666.48046875\n",
      "fin save.\n",
      "epoch 8834\n",
      "test_train\n",
      "train mean loss=62071.68255208333\n",
      "test_test\n",
      "test mean loss=87622.24609375\n",
      "fin save.\n",
      "epoch 8835\n",
      "test_train\n",
      "train mean loss=61101.079296875\n",
      "test_test\n",
      "test mean loss=87718.9609375\n",
      "fin save.\n",
      "epoch 8836\n",
      "test_train\n",
      "train mean loss=61972.59427083333\n",
      "test_test\n",
      "test mean loss=87488.359375\n",
      "fin save.\n",
      "epoch 8837\n",
      "test_train\n",
      "train mean loss=61586.9828125\n",
      "test_test\n",
      "test mean loss=87407.7109375\n",
      "fin save.\n",
      "epoch 8838\n",
      "test_train\n",
      "train mean loss=62070.03697916667\n",
      "test_test\n",
      "test mean loss=87807.43359375\n",
      "fin save.\n",
      "epoch 8839\n",
      "test_train\n",
      "train mean loss=63025.37734375\n",
      "test_test\n",
      "test mean loss=87673.68359375\n",
      "fin save.\n",
      "epoch 8840\n",
      "test_train\n",
      "train mean loss=61709.25286458333\n",
      "test_test\n",
      "test mean loss=87919.296875\n",
      "fin save.\n",
      "epoch 8841\n",
      "test_train\n",
      "train mean loss=62310.58502604167\n",
      "test_test\n",
      "test mean loss=88312.18359375\n",
      "fin save.\n",
      "epoch 8842\n",
      "test_train\n",
      "train mean loss=62112.013411458334\n",
      "test_test\n",
      "test mean loss=88392.62890625\n",
      "fin save.\n",
      "epoch 8843\n",
      "test_train\n",
      "train mean loss=61624.754166666666\n",
      "test_test\n",
      "test mean loss=88173.265625\n",
      "fin save.\n",
      "epoch 8844\n",
      "test_train\n",
      "train mean loss=62444.67916666667\n",
      "test_test\n",
      "test mean loss=88194.5703125\n",
      "fin save.\n",
      "epoch 8845\n",
      "test_train\n",
      "train mean loss=62536.42369791667\n",
      "test_test\n",
      "test mean loss=88301.17578125\n",
      "fin save.\n",
      "epoch 8846\n",
      "test_train\n",
      "train mean loss=62249.537369791666\n",
      "test_test\n",
      "test mean loss=88115.03515625\n",
      "fin save.\n",
      "epoch 8847\n",
      "test_train\n",
      "train mean loss=62823.07421875\n",
      "test_test\n",
      "test mean loss=88039.953125\n",
      "fin save.\n",
      "epoch 8848\n",
      "test_train\n",
      "train mean loss=61188.22161458333\n",
      "test_test\n",
      "test mean loss=88000.828125\n",
      "fin save.\n",
      "epoch 8849\n",
      "test_train\n",
      "train mean loss=61357.9125\n",
      "test_test\n",
      "test mean loss=88006.00390625\n",
      "fin save.\n",
      "epoch 8850\n",
      "test_train\n",
      "train mean loss=61789.415625\n",
      "test_test\n",
      "test mean loss=87970.45703125\n",
      "fin save.\n",
      "epoch 8851\n",
      "test_train\n",
      "train mean loss=62593.452864583334\n",
      "test_test\n",
      "test mean loss=87927.390625\n",
      "fin save.\n",
      "epoch 8852\n",
      "test_train\n",
      "train mean loss=61693.41901041667\n",
      "test_test\n",
      "test mean loss=87903.67578125\n",
      "fin save.\n",
      "epoch 8853\n",
      "test_train\n",
      "train mean loss=61001.441666666666\n",
      "test_test\n",
      "test mean loss=87999.6171875\n",
      "fin save.\n",
      "epoch 8854\n",
      "test_train\n",
      "train mean loss=62361.92200520833\n",
      "test_test\n",
      "test mean loss=87956.1953125\n",
      "fin save.\n",
      "epoch 8855\n",
      "test_train\n",
      "train mean loss=62626.729166666664\n",
      "test_test\n",
      "test mean loss=88054.8828125\n",
      "fin save.\n",
      "epoch 8856\n",
      "test_train\n",
      "train mean loss=62176.87265625\n",
      "test_test\n",
      "test mean loss=88057.62890625\n",
      "fin save.\n",
      "epoch 8857\n",
      "test_train\n",
      "train mean loss=62082.397786458336\n",
      "test_test\n",
      "test mean loss=88189.484375\n",
      "fin save.\n",
      "epoch 8858\n",
      "test_train\n",
      "train mean loss=62219.51354166667\n",
      "test_test\n",
      "test mean loss=88247.94140625\n",
      "fin save.\n",
      "epoch 8859\n",
      "test_train\n",
      "train mean loss=61589.4984375\n",
      "test_test\n",
      "test mean loss=87959.76953125\n",
      "fin save.\n",
      "epoch 8860\n",
      "test_train\n",
      "train mean loss=62910.2546875\n",
      "test_test\n",
      "test mean loss=87900.71875\n",
      "fin save.\n",
      "epoch 8861\n",
      "test_train\n",
      "train mean loss=62430.288411458336\n",
      "test_test\n",
      "test mean loss=87852.0390625\n",
      "fin save.\n",
      "epoch 8862\n",
      "test_train\n",
      "train mean loss=62656.2859375\n",
      "test_test\n",
      "test mean loss=87799.1953125\n",
      "fin save.\n",
      "epoch 8863\n",
      "test_train\n",
      "train mean loss=62359.202864583334\n",
      "test_test\n",
      "test mean loss=87866.84375\n",
      "fin save.\n",
      "epoch 8864\n",
      "test_train\n",
      "train mean loss=61416.402604166666\n",
      "test_test\n",
      "test mean loss=88062.66015625\n",
      "fin save.\n",
      "epoch 8865\n",
      "test_train\n",
      "train mean loss=62005.21484375\n",
      "test_test\n",
      "test mean loss=88137.015625\n",
      "fin save.\n",
      "epoch 8866\n",
      "test_train\n",
      "train mean loss=61889.326171875\n",
      "test_test\n",
      "test mean loss=88101.65625\n",
      "fin save.\n",
      "epoch 8867\n",
      "test_train\n",
      "train mean loss=62468.77942708333\n",
      "test_test\n",
      "test mean loss=88232.79296875\n",
      "fin save.\n",
      "epoch 8868\n",
      "test_train\n",
      "train mean loss=62528.32135416667\n",
      "test_test\n",
      "test mean loss=87978.44921875\n",
      "fin save.\n",
      "epoch 8869\n",
      "test_train\n",
      "train mean loss=61898.11536458333\n",
      "test_test\n",
      "test mean loss=87953.40234375\n",
      "fin save.\n",
      "epoch 8870\n",
      "test_train\n",
      "train mean loss=61335.02330729167\n",
      "test_test\n",
      "test mean loss=87832.19921875\n",
      "fin save.\n",
      "epoch 8871\n",
      "test_train\n",
      "train mean loss=61566.0921875\n",
      "test_test\n",
      "test mean loss=87947.9453125\n",
      "fin save.\n",
      "epoch 8872\n",
      "test_train\n",
      "train mean loss=62480.34192708333\n",
      "test_test\n",
      "test mean loss=87984.83203125\n",
      "fin save.\n",
      "epoch 8873\n",
      "test_train\n",
      "train mean loss=62359.19088541667\n",
      "test_test\n",
      "test mean loss=87901.203125\n",
      "fin save.\n",
      "epoch 8874\n",
      "test_train\n",
      "train mean loss=62423.47864583333\n",
      "test_test\n",
      "test mean loss=88007.4296875\n",
      "fin save.\n",
      "epoch 8875\n",
      "test_train\n",
      "train mean loss=62681.31888020833\n",
      "test_test\n",
      "test mean loss=88063.69140625\n",
      "fin save.\n",
      "epoch 8876\n",
      "test_train\n",
      "train mean loss=61950.23971354167\n",
      "test_test\n",
      "test mean loss=87982.75\n",
      "fin save.\n",
      "epoch 8877\n",
      "test_train\n",
      "train mean loss=62508.51171875\n",
      "test_test\n",
      "test mean loss=88022.08984375\n",
      "fin save.\n",
      "epoch 8878\n",
      "test_train\n",
      "train mean loss=63136.8953125\n",
      "test_test\n",
      "test mean loss=88175.44921875\n",
      "fin save.\n",
      "epoch 8879\n",
      "test_train\n",
      "train mean loss=62201.4328125\n",
      "test_test\n",
      "test mean loss=88049.73046875\n",
      "fin save.\n",
      "epoch 8880\n",
      "test_train\n",
      "train mean loss=63184.6703125\n",
      "test_test\n",
      "test mean loss=87866.09375\n",
      "fin save.\n",
      "epoch 8881\n",
      "test_train\n",
      "train mean loss=61658.7671875\n",
      "test_test\n",
      "test mean loss=87853.0859375\n",
      "fin save.\n",
      "epoch 8882\n",
      "test_train\n",
      "train mean loss=61759.85794270833\n",
      "test_test\n",
      "test mean loss=88137.828125\n",
      "fin save.\n",
      "epoch 8883\n",
      "test_train\n",
      "train mean loss=61683.9109375\n",
      "test_test\n",
      "test mean loss=88145.546875\n",
      "fin save.\n",
      "epoch 8884\n",
      "test_train\n",
      "train mean loss=62378.35833333333\n",
      "test_test\n",
      "test mean loss=87866.59375\n",
      "fin save.\n",
      "epoch 8885\n",
      "test_train\n",
      "train mean loss=61815.44635416667\n",
      "test_test\n",
      "test mean loss=87994.9296875\n",
      "fin save.\n",
      "epoch 8886\n",
      "test_train\n",
      "train mean loss=61935.66744791667\n",
      "test_test\n",
      "test mean loss=88016.1953125\n",
      "fin save.\n",
      "epoch 8887\n",
      "test_train\n",
      "train mean loss=61735.155989583334\n",
      "test_test\n",
      "test mean loss=88157.01171875\n",
      "fin save.\n",
      "epoch 8888\n",
      "test_train\n",
      "train mean loss=61676.783854166664\n",
      "test_test\n",
      "test mean loss=87968.3359375\n",
      "fin save.\n",
      "epoch 8889\n",
      "test_train\n",
      "train mean loss=63226.12981770833\n",
      "test_test\n",
      "test mean loss=88042.16796875\n",
      "fin save.\n",
      "epoch 8890\n",
      "test_train\n",
      "train mean loss=62047.81145833333\n",
      "test_test\n",
      "test mean loss=88192.0859375\n",
      "fin save.\n",
      "epoch 8891\n",
      "test_train\n",
      "train mean loss=61894.10234375\n",
      "test_test\n",
      "test mean loss=88266.25390625\n",
      "fin save.\n",
      "epoch 8892\n",
      "test_train\n",
      "train mean loss=61613.23046875\n",
      "test_test\n",
      "test mean loss=88093.2109375\n",
      "fin save.\n",
      "epoch 8893\n",
      "test_train\n",
      "train mean loss=61391.291666666664\n",
      "test_test\n",
      "test mean loss=88315.64453125\n",
      "fin save.\n",
      "epoch 8894\n",
      "test_train\n",
      "train mean loss=61994.95625\n",
      "test_test\n",
      "test mean loss=88343.890625\n",
      "fin save.\n",
      "epoch 8895\n",
      "test_train\n",
      "train mean loss=62117.33385416667\n",
      "test_test\n",
      "test mean loss=87996.2578125\n",
      "fin save.\n",
      "epoch 8896\n",
      "test_train\n",
      "train mean loss=62832.30234375\n",
      "test_test\n",
      "test mean loss=88028.8125\n",
      "fin save.\n",
      "epoch 8897\n",
      "test_train\n",
      "train mean loss=62754.955078125\n",
      "test_test\n",
      "test mean loss=87661.87890625\n",
      "fin save.\n",
      "epoch 8898\n",
      "test_train\n",
      "train mean loss=62087.222916666666\n",
      "test_test\n",
      "test mean loss=87994.2578125\n",
      "fin save.\n",
      "epoch 8899\n",
      "test_train\n",
      "train mean loss=62457.990625\n",
      "test_test\n",
      "test mean loss=87824.1875\n",
      "fin save.\n",
      "epoch 8900\n",
      "test_train\n",
      "train mean loss=62950.925520833334\n",
      "test_test\n",
      "test mean loss=87634.40234375\n",
      "fin save.\n",
      "epoch 8901\n",
      "test_train\n",
      "train mean loss=62570.727734375\n",
      "test_test\n",
      "test mean loss=87834.5859375\n",
      "fin save.\n",
      "epoch 8902\n",
      "test_train\n",
      "train mean loss=62262.38684895833\n",
      "test_test\n",
      "test mean loss=87874.3984375\n",
      "fin save.\n",
      "epoch 8903\n",
      "test_train\n",
      "train mean loss=62018.453125\n",
      "test_test\n",
      "test mean loss=87797.2109375\n",
      "fin save.\n",
      "epoch 8904\n",
      "test_train\n",
      "train mean loss=61649.961197916666\n",
      "test_test\n",
      "test mean loss=87588.9765625\n",
      "fin save.\n",
      "epoch 8905\n",
      "test_train\n",
      "train mean loss=62272.83098958333\n",
      "test_test\n",
      "test mean loss=87629.8984375\n",
      "fin save.\n",
      "epoch 8906\n",
      "test_train\n",
      "train mean loss=61509.65638020833\n",
      "test_test\n",
      "test mean loss=87696.30859375\n",
      "fin save.\n",
      "epoch 8907\n",
      "test_train\n",
      "train mean loss=62754.133072916666\n",
      "test_test\n",
      "test mean loss=87684.3828125\n",
      "fin save.\n",
      "epoch 8908\n",
      "test_train\n",
      "train mean loss=62348.053385416664\n",
      "test_test\n",
      "test mean loss=87789.69140625\n",
      "fin save.\n",
      "epoch 8909\n",
      "test_train\n",
      "train mean loss=62101.035416666666\n",
      "test_test\n",
      "test mean loss=87570.68359375\n",
      "fin save.\n",
      "epoch 8910\n",
      "test_train\n",
      "train mean loss=61559.87018229167\n",
      "test_test\n",
      "test mean loss=87961.71484375\n",
      "fin save.\n",
      "epoch 8911\n",
      "test_train\n",
      "train mean loss=63106.182291666664\n",
      "test_test\n",
      "test mean loss=87826.30859375\n",
      "fin save.\n",
      "epoch 8912\n",
      "test_train\n",
      "train mean loss=62156.64348958333\n",
      "test_test\n",
      "test mean loss=87518.75390625\n",
      "fin save.\n",
      "epoch 8913\n",
      "test_train\n",
      "train mean loss=62251.55130208333\n",
      "test_test\n",
      "test mean loss=87687.01953125\n",
      "fin save.\n",
      "epoch 8914\n",
      "test_train\n",
      "train mean loss=62339.11953125\n",
      "test_test\n",
      "test mean loss=87995.61328125\n",
      "fin save.\n",
      "epoch 8915\n",
      "test_train\n",
      "train mean loss=61681.033854166664\n",
      "test_test\n",
      "test mean loss=88004.26171875\n",
      "fin save.\n",
      "epoch 8916\n",
      "test_train\n",
      "train mean loss=62025.254166666666\n",
      "test_test\n",
      "test mean loss=87953.16796875\n",
      "fin save.\n",
      "epoch 8917\n",
      "test_train\n",
      "train mean loss=62130.34088541667\n",
      "test_test\n",
      "test mean loss=87990.578125\n",
      "fin save.\n",
      "epoch 8918\n",
      "test_train\n",
      "train mean loss=61474.38125\n",
      "test_test\n",
      "test mean loss=87929.0234375\n",
      "fin save.\n",
      "epoch 8919\n",
      "test_train\n",
      "train mean loss=61588.395833333336\n",
      "test_test\n",
      "test mean loss=88038.02734375\n",
      "fin save.\n",
      "epoch 8920\n",
      "test_train\n",
      "train mean loss=62339.52421875\n",
      "test_test\n",
      "test mean loss=87853.0625\n",
      "fin save.\n",
      "epoch 8921\n",
      "test_train\n",
      "train mean loss=62419.738020833334\n",
      "test_test\n",
      "test mean loss=88137.671875\n",
      "fin save.\n",
      "epoch 8922\n",
      "test_train\n",
      "train mean loss=62470.328385416666\n",
      "test_test\n",
      "test mean loss=88171.76171875\n",
      "fin save.\n",
      "epoch 8923\n",
      "test_train\n",
      "train mean loss=61578.43932291667\n",
      "test_test\n",
      "test mean loss=88212.390625\n",
      "fin save.\n",
      "epoch 8924\n",
      "test_train\n",
      "train mean loss=62154.23880208333\n",
      "test_test\n",
      "test mean loss=88150.17578125\n",
      "fin save.\n",
      "epoch 8925\n",
      "test_train\n",
      "train mean loss=61778.99895833333\n",
      "test_test\n",
      "test mean loss=88286.71875\n",
      "fin save.\n",
      "epoch 8926\n",
      "test_train\n",
      "train mean loss=62609.92239583333\n",
      "test_test\n",
      "test mean loss=88269.625\n",
      "fin save.\n",
      "epoch 8927\n",
      "test_train\n",
      "train mean loss=61701.61822916667\n",
      "test_test\n",
      "test mean loss=88204.69140625\n",
      "fin save.\n",
      "epoch 8928\n",
      "test_train\n",
      "train mean loss=61882.53424479167\n",
      "test_test\n",
      "test mean loss=88315.140625\n",
      "fin save.\n",
      "epoch 8929\n",
      "test_train\n",
      "train mean loss=61912.453385416666\n",
      "test_test\n",
      "test mean loss=88418.70703125\n",
      "fin save.\n",
      "epoch 8930\n",
      "test_train\n",
      "train mean loss=61869.59622395833\n",
      "test_test\n",
      "test mean loss=88498.7734375\n",
      "fin save.\n",
      "epoch 8931\n",
      "test_train\n",
      "train mean loss=62665.695963541664\n",
      "test_test\n",
      "test mean loss=88556.2421875\n",
      "fin save.\n",
      "epoch 8932\n",
      "test_train\n",
      "train mean loss=62056.55546875\n",
      "test_test\n",
      "test mean loss=88594.3359375\n",
      "fin save.\n",
      "epoch 8933\n",
      "test_train\n",
      "train mean loss=62049.014322916664\n",
      "test_test\n",
      "test mean loss=88444.51171875\n",
      "fin save.\n",
      "epoch 8934\n",
      "test_train\n",
      "train mean loss=62678.319921875\n",
      "test_test\n",
      "test mean loss=88611.66796875\n",
      "fin save.\n",
      "epoch 8935\n",
      "test_train\n",
      "train mean loss=62800.90286458333\n",
      "test_test\n",
      "test mean loss=88496.3359375\n",
      "fin save.\n",
      "epoch 8936\n",
      "test_train\n",
      "train mean loss=61465.28125\n",
      "test_test\n",
      "test mean loss=88268.48046875\n",
      "fin save.\n",
      "epoch 8937\n",
      "test_train\n",
      "train mean loss=62115.866536458336\n",
      "test_test\n",
      "test mean loss=88455.74609375\n",
      "fin save.\n",
      "epoch 8938\n",
      "test_train\n",
      "train mean loss=62934.18756510417\n",
      "test_test\n",
      "test mean loss=88188.6171875\n",
      "fin save.\n",
      "epoch 8939\n",
      "test_train\n",
      "train mean loss=62380.13463541667\n",
      "test_test\n",
      "test mean loss=88303.03125\n",
      "fin save.\n",
      "epoch 8940\n",
      "test_train\n",
      "train mean loss=61779.524739583336\n",
      "test_test\n",
      "test mean loss=88659.8984375\n",
      "fin save.\n",
      "epoch 8941\n",
      "test_train\n",
      "train mean loss=62107.79283854167\n",
      "test_test\n",
      "test mean loss=88651.66796875\n",
      "fin save.\n",
      "epoch 8942\n",
      "test_train\n",
      "train mean loss=62597.94453125\n",
      "test_test\n",
      "test mean loss=88243.53515625\n",
      "fin save.\n",
      "epoch 8943\n",
      "test_train\n",
      "train mean loss=61848.877734375\n",
      "test_test\n",
      "test mean loss=88125.60546875\n",
      "fin save.\n",
      "epoch 8944\n",
      "test_train\n",
      "train mean loss=62180.625651041664\n",
      "test_test\n",
      "test mean loss=88153.76953125\n",
      "fin save.\n",
      "epoch 8945\n",
      "test_train\n",
      "train mean loss=62351.11432291667\n",
      "test_test\n",
      "test mean loss=88241.171875\n",
      "fin save.\n",
      "epoch 8946\n",
      "test_train\n",
      "train mean loss=62813.43463541667\n",
      "test_test\n",
      "test mean loss=88140.2421875\n",
      "fin save.\n",
      "epoch 8947\n",
      "test_train\n",
      "train mean loss=63277.13359375\n",
      "test_test\n",
      "test mean loss=88183.89453125\n",
      "fin save.\n",
      "epoch 8948\n",
      "test_train\n",
      "train mean loss=61493.453385416666\n",
      "test_test\n",
      "test mean loss=88122.80859375\n",
      "fin save.\n",
      "epoch 8949\n",
      "test_train\n",
      "train mean loss=62292.148046875\n",
      "test_test\n",
      "test mean loss=88204.33984375\n",
      "fin save.\n",
      "epoch 8950\n",
      "test_train\n",
      "train mean loss=62710.8796875\n",
      "test_test\n",
      "test mean loss=88375.52734375\n",
      "fin save.\n",
      "epoch 8951\n",
      "test_train\n",
      "train mean loss=62395.19375\n",
      "test_test\n",
      "test mean loss=88283.0859375\n",
      "fin save.\n",
      "epoch 8952\n",
      "test_train\n",
      "train mean loss=61654.481770833336\n",
      "test_test\n",
      "test mean loss=88395.58203125\n",
      "fin save.\n",
      "epoch 8953\n",
      "test_train\n",
      "train mean loss=62304.6453125\n",
      "test_test\n",
      "test mean loss=88370.13671875\n",
      "fin save.\n",
      "epoch 8954\n",
      "test_train\n",
      "train mean loss=62853.65234375\n",
      "test_test\n",
      "test mean loss=88475.9765625\n",
      "fin save.\n",
      "epoch 8955\n",
      "test_train\n",
      "train mean loss=61783.16015625\n",
      "test_test\n",
      "test mean loss=88255.2734375\n",
      "fin save.\n",
      "epoch 8956\n",
      "test_train\n",
      "train mean loss=61983.5890625\n",
      "test_test\n",
      "test mean loss=88161.5234375\n",
      "fin save.\n",
      "epoch 8957\n",
      "test_train\n",
      "train mean loss=62358.946875\n",
      "test_test\n",
      "test mean loss=88430.63671875\n",
      "fin save.\n",
      "epoch 8958\n",
      "test_train\n",
      "train mean loss=62631.30755208333\n",
      "test_test\n",
      "test mean loss=88310.92578125\n",
      "fin save.\n",
      "epoch 8959\n",
      "test_train\n",
      "train mean loss=62394.17135416667\n",
      "test_test\n",
      "test mean loss=88465.984375\n",
      "fin save.\n",
      "epoch 8960\n",
      "test_train\n",
      "train mean loss=61521.961588541664\n",
      "test_test\n",
      "test mean loss=88399.36328125\n",
      "fin save.\n",
      "epoch 8961\n",
      "test_train\n",
      "train mean loss=62336.38828125\n",
      "test_test\n",
      "test mean loss=88314.53515625\n",
      "fin save.\n",
      "epoch 8962\n",
      "test_train\n",
      "train mean loss=62306.43177083333\n",
      "test_test\n",
      "test mean loss=88180.16015625\n",
      "fin save.\n",
      "epoch 8963\n",
      "test_train\n",
      "train mean loss=62698.07578125\n",
      "test_test\n",
      "test mean loss=88377.19921875\n",
      "fin save.\n",
      "epoch 8964\n",
      "test_train\n",
      "train mean loss=61815.991796875\n",
      "test_test\n",
      "test mean loss=88552.55859375\n",
      "fin save.\n",
      "epoch 8965\n",
      "test_train\n",
      "train mean loss=61677.80234375\n",
      "test_test\n",
      "test mean loss=88530.90234375\n",
      "fin save.\n",
      "epoch 8966\n",
      "test_train\n",
      "train mean loss=62426.33359375\n",
      "test_test\n",
      "test mean loss=88554.91796875\n",
      "fin save.\n",
      "epoch 8967\n",
      "test_train\n",
      "train mean loss=61214.61145833333\n",
      "test_test\n",
      "test mean loss=88445.578125\n",
      "fin save.\n",
      "epoch 8968\n",
      "test_train\n",
      "train mean loss=61879.152604166666\n",
      "test_test\n",
      "test mean loss=88392.0078125\n",
      "fin save.\n",
      "epoch 8969\n",
      "test_train\n",
      "train mean loss=61860.2890625\n",
      "test_test\n",
      "test mean loss=88329.59375\n",
      "fin save.\n",
      "epoch 8970\n",
      "test_train\n",
      "train mean loss=62346.57083333333\n",
      "test_test\n",
      "test mean loss=88451.26953125\n",
      "fin save.\n",
      "epoch 8971\n",
      "test_train\n",
      "train mean loss=63230.240885416664\n",
      "test_test\n",
      "test mean loss=88177.484375\n",
      "fin save.\n",
      "epoch 8972\n",
      "test_train\n",
      "train mean loss=62216.19244791667\n",
      "test_test\n",
      "test mean loss=88223.35546875\n",
      "fin save.\n",
      "epoch 8973\n",
      "test_train\n",
      "train mean loss=61031.260416666664\n",
      "test_test\n",
      "test mean loss=88182.64453125\n",
      "fin save.\n",
      "epoch 8974\n",
      "test_train\n",
      "train mean loss=62345.22213541667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_test\n",
      "test mean loss=88406.34765625\n",
      "fin save.\n",
      "epoch 8975\n",
      "test_train\n",
      "train mean loss=61614.77330729167\n",
      "test_test\n",
      "test mean loss=88363.9453125\n",
      "fin save.\n",
      "epoch 8976\n",
      "test_train\n",
      "train mean loss=62326.836197916666\n",
      "test_test\n",
      "test mean loss=88421.85546875\n",
      "fin save.\n",
      "epoch 8977\n",
      "test_train\n",
      "train mean loss=61993.24895833333\n",
      "test_test\n",
      "test mean loss=88555.55078125\n",
      "fin save.\n",
      "epoch 8978\n",
      "test_train\n",
      "train mean loss=62300.560286458334\n",
      "test_test\n",
      "test mean loss=88082.23828125\n",
      "fin save.\n",
      "epoch 8979\n",
      "test_train\n",
      "train mean loss=61943.247395833336\n",
      "test_test\n",
      "test mean loss=88008.19921875\n",
      "fin save.\n",
      "epoch 8980\n",
      "test_train\n",
      "train mean loss=61449.7609375\n",
      "test_test\n",
      "test mean loss=87834.4921875\n",
      "fin save.\n",
      "epoch 8981\n",
      "test_train\n",
      "train mean loss=62667.591015625\n",
      "test_test\n",
      "test mean loss=87791.625\n",
      "fin save.\n",
      "epoch 8982\n",
      "test_train\n",
      "train mean loss=62003.698958333334\n",
      "test_test\n",
      "test mean loss=88090.94921875\n",
      "fin save.\n",
      "epoch 8983\n",
      "test_train\n",
      "train mean loss=63303.124739583334\n",
      "test_test\n",
      "test mean loss=88058.35546875\n",
      "fin save.\n",
      "epoch 8984\n",
      "test_train\n",
      "train mean loss=62770.729296875\n",
      "test_test\n",
      "test mean loss=88030.51953125\n",
      "fin save.\n",
      "epoch 8985\n",
      "test_train\n",
      "train mean loss=63521.014322916664\n",
      "test_test\n",
      "test mean loss=88105.28125\n",
      "fin save.\n",
      "epoch 8986\n",
      "test_train\n",
      "train mean loss=62274.69283854167\n",
      "test_test\n",
      "test mean loss=88085.73828125\n",
      "fin save.\n",
      "epoch 8987\n",
      "test_train\n",
      "train mean loss=62983.86119791667\n",
      "test_test\n",
      "test mean loss=87961.34375\n",
      "fin save.\n",
      "epoch 8988\n",
      "test_train\n",
      "train mean loss=62336.94296875\n",
      "test_test\n",
      "test mean loss=88094.10546875\n",
      "fin save.\n",
      "epoch 8989\n",
      "test_train\n",
      "train mean loss=62594.70104166667\n",
      "test_test\n",
      "test mean loss=88167.51953125\n",
      "fin save.\n",
      "epoch 8990\n",
      "test_train\n",
      "train mean loss=62787.852864583336\n",
      "test_test\n",
      "test mean loss=88127.78125\n",
      "fin save.\n",
      "epoch 8991\n",
      "test_train\n",
      "train mean loss=62891.30859375\n",
      "test_test\n",
      "test mean loss=88487.14453125\n",
      "fin save.\n",
      "epoch 8992\n",
      "test_train\n",
      "train mean loss=62293.4875\n",
      "test_test\n",
      "test mean loss=88518.3125\n",
      "fin save.\n",
      "epoch 8993\n",
      "test_train\n",
      "train mean loss=62722.646875\n",
      "test_test\n",
      "test mean loss=88488.0625\n",
      "fin save.\n",
      "epoch 8994\n",
      "test_train\n",
      "train mean loss=62276.617447916666\n",
      "test_test\n",
      "test mean loss=88715.9921875\n",
      "fin save.\n",
      "epoch 8995\n",
      "test_train\n",
      "train mean loss=62797.975390625\n",
      "test_test\n",
      "test mean loss=88590.87890625\n",
      "fin save.\n",
      "epoch 8996\n",
      "test_train\n",
      "train mean loss=62452.86484375\n",
      "test_test\n",
      "test mean loss=88577.625\n",
      "fin save.\n",
      "epoch 8997\n",
      "test_train\n",
      "train mean loss=62342.92265625\n",
      "test_test\n",
      "test mean loss=88674.75390625\n",
      "fin save.\n",
      "epoch 8998\n",
      "test_train\n",
      "train mean loss=62405.238020833334\n",
      "test_test\n",
      "test mean loss=88732.921875\n",
      "fin save.\n",
      "epoch 8999\n",
      "test_train\n",
      "train mean loss=61493.929947916666\n",
      "test_test\n",
      "test mean loss=88857.1875\n",
      "fin save.\n",
      "epoch 9000\n",
      "test_train\n",
      "train mean loss=61013.27578125\n",
      "test_test\n",
      "test mean loss=88923.4375\n",
      "fin save.\n",
      "epoch 9001\n",
      "test_train\n",
      "train mean loss=61918.56640625\n",
      "test_test\n",
      "test mean loss=88536.84375\n",
      "fin save.\n",
      "epoch 9002\n",
      "test_train\n",
      "train mean loss=61719.183333333334\n",
      "test_test\n",
      "test mean loss=88776.8984375\n",
      "fin save.\n",
      "epoch 9003\n",
      "test_train\n",
      "train mean loss=63214.66510416667\n",
      "test_test\n",
      "test mean loss=88827.80078125\n",
      "fin save.\n",
      "epoch 9004\n",
      "test_train\n",
      "train mean loss=62587.99791666667\n",
      "test_test\n",
      "test mean loss=88746.96484375\n",
      "fin save.\n",
      "epoch 9005\n",
      "test_train\n",
      "train mean loss=61402.308854166666\n",
      "test_test\n",
      "test mean loss=88255.73828125\n",
      "fin save.\n",
      "epoch 9006\n",
      "test_train\n",
      "train mean loss=61279.30768229167\n",
      "test_test\n",
      "test mean loss=88425.0\n",
      "fin save.\n",
      "epoch 9007\n",
      "test_train\n",
      "train mean loss=61996.466536458334\n",
      "test_test\n",
      "test mean loss=88594.30078125\n",
      "fin save.\n",
      "epoch 9008\n",
      "test_train\n",
      "train mean loss=61320.61536458333\n",
      "test_test\n",
      "test mean loss=88467.98046875\n",
      "fin save.\n",
      "epoch 9009\n",
      "test_train\n",
      "train mean loss=63182.47643229167\n",
      "test_test\n",
      "test mean loss=88681.25\n",
      "fin save.\n",
      "epoch 9010\n",
      "test_train\n",
      "train mean loss=62659.37682291667\n",
      "test_test\n",
      "test mean loss=88483.92578125\n",
      "fin save.\n",
      "epoch 9011\n",
      "test_train\n",
      "train mean loss=62085.15729166667\n",
      "test_test\n",
      "test mean loss=88725.0078125\n",
      "fin save.\n",
      "epoch 9012\n",
      "test_train\n",
      "train mean loss=62212.243489583336\n",
      "test_test\n",
      "test mean loss=88500.3671875\n",
      "fin save.\n",
      "epoch 9013\n",
      "test_train\n",
      "train mean loss=61198.251302083336\n",
      "test_test\n",
      "test mean loss=88645.796875\n",
      "fin save.\n",
      "epoch 9014\n",
      "test_train\n",
      "train mean loss=62149.54388020833\n",
      "test_test\n",
      "test mean loss=88429.98828125\n",
      "fin save.\n",
      "epoch 9015\n",
      "test_train\n",
      "train mean loss=62300.13046875\n",
      "test_test\n",
      "test mean loss=88529.6953125\n",
      "fin save.\n",
      "epoch 9016\n",
      "test_train\n",
      "train mean loss=62992.63359375\n",
      "test_test\n",
      "test mean loss=88543.3359375\n",
      "fin save.\n",
      "epoch 9017\n",
      "test_train\n",
      "train mean loss=62213.34713541667\n",
      "test_test\n",
      "test mean loss=88387.83203125\n",
      "fin save.\n",
      "epoch 9018\n",
      "test_train\n",
      "train mean loss=62356.548567708334\n",
      "test_test\n",
      "test mean loss=88518.578125\n",
      "fin save.\n",
      "epoch 9019\n",
      "test_train\n",
      "train mean loss=63429.259114583336\n",
      "test_test\n",
      "test mean loss=88483.578125\n",
      "fin save.\n",
      "epoch 9020\n",
      "test_train\n",
      "train mean loss=62216.271223958334\n",
      "test_test\n",
      "test mean loss=88912.875\n",
      "fin save.\n",
      "epoch 9021\n",
      "test_train\n",
      "train mean loss=62284.5171875\n",
      "test_test\n",
      "test mean loss=88483.84375\n",
      "fin save.\n",
      "epoch 9022\n",
      "test_train\n",
      "train mean loss=61875.474348958334\n",
      "test_test\n",
      "test mean loss=88536.69140625\n",
      "fin save.\n",
      "epoch 9023\n",
      "test_train\n",
      "train mean loss=63397.474348958334\n",
      "test_test\n",
      "test mean loss=88468.03515625\n",
      "fin save.\n",
      "epoch 9024\n",
      "test_train\n",
      "train mean loss=61605.804296875\n",
      "test_test\n",
      "test mean loss=88515.625\n",
      "fin save.\n",
      "epoch 9025\n",
      "test_train\n",
      "train mean loss=61217.575\n",
      "test_test\n",
      "test mean loss=88617.72265625\n",
      "fin save.\n",
      "epoch 9026\n",
      "test_train\n",
      "train mean loss=62975.666666666664\n",
      "test_test\n",
      "test mean loss=88764.55859375\n",
      "fin save.\n",
      "epoch 9027\n",
      "test_train\n",
      "train mean loss=63026.78997395833\n",
      "test_test\n",
      "test mean loss=88635.80078125\n",
      "fin save.\n",
      "epoch 9028\n",
      "test_train\n",
      "train mean loss=62856.79348958333\n",
      "test_test\n",
      "test mean loss=88640.0\n",
      "fin save.\n",
      "epoch 9029\n",
      "test_train\n",
      "train mean loss=61629.71041666667\n",
      "test_test\n",
      "test mean loss=88702.6953125\n",
      "fin save.\n",
      "epoch 9030\n",
      "test_train\n",
      "train mean loss=62255.85078125\n",
      "test_test\n",
      "test mean loss=88675.71484375\n",
      "fin save.\n",
      "epoch 9031\n",
      "test_train\n",
      "train mean loss=61768.5046875\n",
      "test_test\n",
      "test mean loss=88676.73046875\n",
      "fin save.\n",
      "epoch 9032\n",
      "test_train\n",
      "train mean loss=62426.494791666664\n",
      "test_test\n",
      "test mean loss=88768.98828125\n",
      "fin save.\n",
      "epoch 9033\n",
      "test_train\n",
      "train mean loss=62245.891796875\n",
      "test_test\n",
      "test mean loss=88649.28515625\n",
      "fin save.\n",
      "epoch 9034\n",
      "test_train\n",
      "train mean loss=62293.409375\n",
      "test_test\n",
      "test mean loss=88467.046875\n",
      "fin save.\n",
      "epoch 9035\n",
      "test_train\n",
      "train mean loss=61862.50052083333\n",
      "test_test\n",
      "test mean loss=88569.95703125\n",
      "fin save.\n",
      "epoch 9036\n",
      "test_train\n",
      "train mean loss=61859.54609375\n",
      "test_test\n",
      "test mean loss=88785.77734375\n",
      "fin save.\n",
      "epoch 9037\n",
      "test_train\n",
      "train mean loss=61489.61822916667\n",
      "test_test\n",
      "test mean loss=88550.421875\n",
      "fin save.\n",
      "epoch 9038\n",
      "test_train\n",
      "train mean loss=61891.65703125\n",
      "test_test\n",
      "test mean loss=88295.984375\n",
      "fin save.\n",
      "epoch 9039\n",
      "test_train\n",
      "train mean loss=62485.950520833336\n",
      "test_test\n",
      "test mean loss=88455.640625\n",
      "fin save.\n",
      "epoch 9040\n",
      "test_train\n",
      "train mean loss=62511.65052083333\n",
      "test_test\n",
      "test mean loss=88487.0\n",
      "fin save.\n",
      "epoch 9041\n",
      "test_train\n",
      "train mean loss=62239.10390625\n",
      "test_test\n",
      "test mean loss=88376.08984375\n",
      "fin save.\n",
      "epoch 9042\n",
      "test_train\n",
      "train mean loss=61707.769791666666\n",
      "test_test\n",
      "test mean loss=88372.8984375\n",
      "fin save.\n",
      "epoch 9043\n",
      "test_train\n",
      "train mean loss=62371.60533854167\n",
      "test_test\n",
      "test mean loss=88540.3515625\n",
      "fin save.\n",
      "epoch 9044\n",
      "test_train\n",
      "train mean loss=62636.72057291667\n",
      "test_test\n",
      "test mean loss=88749.4296875\n",
      "fin save.\n",
      "epoch 9045\n",
      "test_train\n",
      "train mean loss=62417.71328125\n",
      "test_test\n",
      "test mean loss=88681.5546875\n",
      "fin save.\n",
      "epoch 9046\n",
      "test_train\n",
      "train mean loss=61807.55390625\n",
      "test_test\n",
      "test mean loss=88819.41796875\n",
      "fin save.\n",
      "epoch 9047\n",
      "test_train\n",
      "train mean loss=61766.248828125\n",
      "test_test\n",
      "test mean loss=88501.3203125\n",
      "fin save.\n",
      "epoch 9048\n",
      "test_train\n",
      "train mean loss=62024.1828125\n",
      "test_test\n",
      "test mean loss=88599.71484375\n",
      "fin save.\n",
      "epoch 9049\n",
      "test_train\n",
      "train mean loss=62045.40833333333\n",
      "test_test\n",
      "test mean loss=88201.80859375\n",
      "fin save.\n",
      "epoch 9050\n",
      "test_train\n",
      "train mean loss=62513.29114583333\n",
      "test_test\n",
      "test mean loss=88380.41015625\n",
      "fin save.\n",
      "epoch 9051\n",
      "test_train\n",
      "train mean loss=62044.55677083333\n",
      "test_test\n",
      "test mean loss=88132.1484375\n",
      "fin save.\n",
      "epoch 9052\n",
      "test_train\n",
      "train mean loss=61601.555989583336\n",
      "test_test\n",
      "test mean loss=88299.15625\n",
      "fin save.\n",
      "epoch 9053\n",
      "test_train\n",
      "train mean loss=63193.81927083333\n",
      "test_test\n",
      "test mean loss=88715.07421875\n",
      "fin save.\n",
      "epoch 9054\n",
      "test_train\n",
      "train mean loss=61816.040625\n",
      "test_test\n",
      "test mean loss=88340.21875\n",
      "fin save.\n",
      "epoch 9055\n",
      "test_train\n",
      "train mean loss=61330.749739583334\n",
      "test_test\n",
      "test mean loss=88260.4453125\n",
      "fin save.\n",
      "epoch 9056\n",
      "test_train\n",
      "train mean loss=61616.89635416667\n",
      "test_test\n",
      "test mean loss=88415.1484375\n",
      "fin save.\n",
      "epoch 9057\n",
      "test_train\n",
      "train mean loss=61553.862109375\n",
      "test_test\n",
      "test mean loss=88283.1953125\n",
      "fin save.\n",
      "epoch 9058\n",
      "test_train\n",
      "train mean loss=61311.96966145833\n",
      "test_test\n",
      "test mean loss=88241.37890625\n",
      "fin save.\n",
      "epoch 9059\n",
      "test_train\n",
      "train mean loss=61755.69036458333\n",
      "test_test\n",
      "test mean loss=88456.62109375\n",
      "fin save.\n",
      "epoch 9060\n",
      "test_train\n",
      "train mean loss=62108.70234375\n",
      "test_test\n",
      "test mean loss=88476.66796875\n",
      "fin save.\n",
      "epoch 9061\n",
      "test_train\n",
      "train mean loss=62997.950520833336\n",
      "test_test\n",
      "test mean loss=88358.46875\n",
      "fin save.\n",
      "epoch 9062\n",
      "test_train\n",
      "train mean loss=62206.2046875\n",
      "test_test\n",
      "test mean loss=88327.61328125\n",
      "fin save.\n",
      "epoch 9063\n",
      "test_train\n",
      "train mean loss=62705.448567708336\n",
      "test_test\n",
      "test mean loss=88334.43359375\n",
      "fin save.\n",
      "epoch 9064\n",
      "test_train\n",
      "train mean loss=62172.62356770833\n",
      "test_test\n",
      "test mean loss=88468.23828125\n",
      "fin save.\n",
      "epoch 9065\n",
      "test_train\n",
      "train mean loss=62239.341536458334\n",
      "test_test\n",
      "test mean loss=88454.421875\n",
      "fin save.\n",
      "epoch 9066\n",
      "test_train\n",
      "train mean loss=61826.08046875\n",
      "test_test\n",
      "test mean loss=89004.19140625\n",
      "fin save.\n",
      "epoch 9067\n",
      "test_train\n",
      "train mean loss=62027.88385416667\n",
      "test_test\n",
      "test mean loss=89109.921875\n",
      "fin save.\n",
      "epoch 9068\n",
      "test_train\n",
      "train mean loss=62278.05078125\n",
      "test_test\n",
      "test mean loss=88933.85546875\n",
      "fin save.\n",
      "epoch 9069\n",
      "test_train\n",
      "train mean loss=62140.68020833333\n",
      "test_test\n",
      "test mean loss=89031.1875\n",
      "fin save.\n",
      "epoch 9070\n",
      "test_train\n",
      "train mean loss=62308.78984375\n",
      "test_test\n",
      "test mean loss=89033.22265625\n",
      "fin save.\n",
      "epoch 9071\n",
      "test_train\n",
      "train mean loss=61423.16692708333\n",
      "test_test\n",
      "test mean loss=88780.26171875\n",
      "fin save.\n",
      "epoch 9072\n",
      "test_train\n",
      "train mean loss=62077.28763020833\n",
      "test_test\n",
      "test mean loss=88477.265625\n",
      "fin save.\n",
      "epoch 9073\n",
      "test_train\n",
      "train mean loss=61514.296875\n",
      "test_test\n",
      "test mean loss=88565.98046875\n",
      "fin save.\n",
      "epoch 9074\n",
      "test_train\n",
      "train mean loss=61808.323958333334\n",
      "test_test\n",
      "test mean loss=88490.53125\n",
      "fin save.\n",
      "epoch 9075\n",
      "test_train\n",
      "train mean loss=62397.3171875\n",
      "test_test\n",
      "test mean loss=88278.9140625\n",
      "fin save.\n",
      "epoch 9076\n",
      "test_train\n",
      "train mean loss=62344.36822916667\n",
      "test_test\n",
      "test mean loss=88700.171875\n",
      "fin save.\n",
      "epoch 9077\n",
      "test_train\n",
      "train mean loss=61848.27057291667\n",
      "test_test\n",
      "test mean loss=88853.0078125\n",
      "fin save.\n",
      "epoch 9078\n",
      "test_train\n",
      "train mean loss=62768.15286458333\n",
      "test_test\n",
      "test mean loss=88494.01171875\n",
      "fin save.\n",
      "epoch 9079\n",
      "test_train\n",
      "train mean loss=62192.162109375\n",
      "test_test\n",
      "test mean loss=88434.06640625\n",
      "fin save.\n",
      "epoch 9080\n",
      "test_train\n",
      "train mean loss=61778.226822916666\n",
      "test_test\n",
      "test mean loss=88559.64453125\n",
      "fin save.\n",
      "epoch 9081\n",
      "test_train\n",
      "train mean loss=62878.36614583333\n",
      "test_test\n",
      "test mean loss=88579.98046875\n",
      "fin save.\n",
      "epoch 9082\n",
      "test_train\n",
      "train mean loss=62703.53203125\n",
      "test_test\n",
      "test mean loss=88453.4140625\n",
      "fin save.\n",
      "epoch 9083\n",
      "test_train\n",
      "train mean loss=61910.35924479167\n",
      "test_test\n",
      "test mean loss=87894.6875\n",
      "fin save.\n",
      "epoch 9084\n",
      "test_train\n",
      "train mean loss=62085.390364583334\n",
      "test_test\n",
      "test mean loss=87846.9921875\n",
      "fin save.\n",
      "epoch 9085\n",
      "test_train\n",
      "train mean loss=62662.68125\n",
      "test_test\n",
      "test mean loss=87850.453125\n",
      "fin save.\n",
      "epoch 9086\n",
      "test_train\n",
      "train mean loss=62332.2109375\n",
      "test_test\n",
      "test mean loss=88021.06640625\n",
      "fin save.\n",
      "epoch 9087\n",
      "test_train\n",
      "train mean loss=62686.831640625\n",
      "test_test\n",
      "test mean loss=87907.26171875\n",
      "fin save.\n",
      "epoch 9088\n",
      "test_train\n",
      "train mean loss=62774.24270833333\n",
      "test_test\n",
      "test mean loss=88030.3359375\n",
      "fin save.\n",
      "epoch 9089\n",
      "test_train\n",
      "train mean loss=61932.52916666667\n",
      "test_test\n",
      "test mean loss=88051.12109375\n",
      "fin save.\n",
      "epoch 9090\n",
      "test_train\n",
      "train mean loss=61599.83802083333\n",
      "test_test\n",
      "test mean loss=87929.6015625\n",
      "fin save.\n",
      "epoch 9091\n",
      "test_train\n",
      "train mean loss=61908.50182291667\n",
      "test_test\n",
      "test mean loss=87833.99609375\n",
      "fin save.\n",
      "epoch 9092\n",
      "test_train\n",
      "train mean loss=61818.37994791667\n",
      "test_test\n",
      "test mean loss=87854.5\n",
      "fin save.\n",
      "epoch 9093\n",
      "test_train\n",
      "train mean loss=61651.300130208336\n",
      "test_test\n",
      "test mean loss=87847.9921875\n",
      "fin save.\n",
      "epoch 9094\n",
      "test_train\n",
      "train mean loss=62164.994791666664\n",
      "test_test\n",
      "test mean loss=88119.578125\n",
      "fin save.\n",
      "epoch 9095\n",
      "test_train\n",
      "train mean loss=62048.293359375\n",
      "test_test\n",
      "test mean loss=88057.83984375\n",
      "fin save.\n",
      "epoch 9096\n",
      "test_train\n",
      "train mean loss=61802.68828125\n",
      "test_test\n",
      "test mean loss=87874.91015625\n",
      "fin save.\n",
      "epoch 9097\n",
      "test_train\n",
      "train mean loss=62671.950520833336\n",
      "test_test\n",
      "test mean loss=88062.56640625\n",
      "fin save.\n",
      "epoch 9098\n",
      "test_train\n",
      "train mean loss=62821.38984375\n",
      "test_test\n",
      "test mean loss=88031.8125\n",
      "fin save.\n",
      "epoch 9099\n",
      "test_train\n",
      "train mean loss=61993.68932291667\n",
      "test_test\n",
      "test mean loss=87989.94140625\n",
      "fin save.\n",
      "epoch 9100\n",
      "test_train\n",
      "train mean loss=62913.49609375\n",
      "test_test\n",
      "test mean loss=87915.1953125\n",
      "fin save.\n",
      "epoch 9101\n",
      "test_train\n",
      "train mean loss=61461.31822916667\n",
      "test_test\n",
      "test mean loss=87836.77734375\n",
      "fin save.\n",
      "epoch 9102\n",
      "test_train\n",
      "train mean loss=62272.164322916666\n",
      "test_test\n",
      "test mean loss=88165.5546875\n",
      "fin save.\n",
      "epoch 9103\n",
      "test_train\n",
      "train mean loss=61825.73880208333\n",
      "test_test\n",
      "test mean loss=87988.73046875\n",
      "fin save.\n",
      "epoch 9104\n",
      "test_train\n",
      "train mean loss=61906.52057291667\n",
      "test_test\n",
      "test mean loss=88037.97265625\n",
      "fin save.\n",
      "epoch 9105\n",
      "test_train\n",
      "train mean loss=61649.33385416667\n",
      "test_test\n",
      "test mean loss=87841.80078125\n",
      "fin save.\n",
      "epoch 9106\n",
      "test_train\n",
      "train mean loss=61618.048567708334\n",
      "test_test\n",
      "test mean loss=87672.18359375\n",
      "fin save.\n",
      "epoch 9107\n",
      "test_train\n",
      "train mean loss=62492.265885416666\n",
      "test_test\n",
      "test mean loss=87778.96875\n",
      "fin save.\n",
      "epoch 9108\n",
      "test_train\n",
      "train mean loss=61993.555078125\n",
      "test_test\n",
      "test mean loss=87681.11328125\n",
      "fin save.\n",
      "epoch 9109\n",
      "test_train\n",
      "train mean loss=61702.08020833333\n",
      "test_test\n",
      "test mean loss=87649.94140625\n",
      "fin save.\n",
      "epoch 9110\n",
      "test_train\n",
      "train mean loss=62626.981770833336\n",
      "test_test\n",
      "test mean loss=87606.88671875\n",
      "fin save.\n",
      "epoch 9111\n",
      "test_train\n",
      "train mean loss=63342.906510416666\n",
      "test_test\n",
      "test mean loss=87784.0859375\n",
      "fin save.\n",
      "epoch 9112\n",
      "test_train\n",
      "train mean loss=62206.48385416667\n",
      "test_test\n",
      "test mean loss=87784.8203125\n",
      "fin save.\n",
      "epoch 9113\n",
      "test_train\n",
      "train mean loss=61866.933984375\n",
      "test_test\n",
      "test mean loss=88040.68359375\n",
      "fin save.\n",
      "epoch 9114\n",
      "test_train\n",
      "train mean loss=61176.78125\n",
      "test_test\n",
      "test mean loss=88197.63671875\n",
      "fin save.\n",
      "epoch 9115\n",
      "test_train\n",
      "train mean loss=62615.80651041667\n",
      "test_test\n",
      "test mean loss=88109.00390625\n",
      "fin save.\n",
      "epoch 9116\n",
      "test_train\n",
      "train mean loss=62727.704296875\n",
      "test_test\n",
      "test mean loss=88189.50390625\n",
      "fin save.\n",
      "epoch 9117\n",
      "test_train\n",
      "train mean loss=62507.787369791666\n",
      "test_test\n",
      "test mean loss=88008.1640625\n",
      "fin save.\n",
      "epoch 9118\n",
      "test_train\n",
      "train mean loss=61545.72734375\n",
      "test_test\n",
      "test mean loss=87721.09375\n",
      "fin save.\n",
      "epoch 9119\n",
      "test_train\n",
      "train mean loss=62126.63619791667\n",
      "test_test\n",
      "test mean loss=87724.33984375\n",
      "fin save.\n",
      "epoch 9120\n",
      "test_train\n",
      "train mean loss=62389.991927083334\n",
      "test_test\n",
      "test mean loss=87841.24609375\n",
      "fin save.\n",
      "epoch 9121\n",
      "test_train\n",
      "train mean loss=61969.76953125\n",
      "test_test\n",
      "test mean loss=87783.5546875\n",
      "fin save.\n",
      "epoch 9122\n",
      "test_train\n",
      "train mean loss=62277.91588541667\n",
      "test_test\n",
      "test mean loss=88015.0703125\n",
      "fin save.\n",
      "epoch 9123\n",
      "test_train\n",
      "train mean loss=62539.31640625\n",
      "test_test\n",
      "test mean loss=87906.6953125\n",
      "fin save.\n",
      "epoch 9124\n",
      "test_train\n",
      "train mean loss=62563.119791666664\n",
      "test_test\n",
      "test mean loss=88050.609375\n",
      "fin save.\n",
      "epoch 9125\n",
      "test_train\n",
      "train mean loss=62769.0953125\n",
      "test_test\n",
      "test mean loss=88006.078125\n",
      "fin save.\n",
      "epoch 9126\n",
      "test_train\n",
      "train mean loss=62479.558333333334\n",
      "test_test\n",
      "test mean loss=88121.875\n",
      "fin save.\n",
      "epoch 9127\n",
      "test_train\n",
      "train mean loss=61633.848307291664\n",
      "test_test\n",
      "test mean loss=88205.15625\n",
      "fin save.\n",
      "epoch 9128\n",
      "test_train\n",
      "train mean loss=61925.503125\n",
      "test_test\n",
      "test mean loss=88436.92578125\n",
      "fin save.\n",
      "epoch 9129\n",
      "test_train\n",
      "train mean loss=62941.72109375\n",
      "test_test\n",
      "test mean loss=88382.55078125\n",
      "fin save.\n",
      "epoch 9130\n",
      "test_train\n",
      "train mean loss=63089.41302083333\n",
      "test_test\n",
      "test mean loss=88414.01171875\n",
      "fin save.\n",
      "epoch 9131\n",
      "test_train\n",
      "train mean loss=62647.427994791666\n",
      "test_test\n",
      "test mean loss=88348.609375\n",
      "fin save.\n",
      "epoch 9132\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=62893.276041666664\n",
      "test_test\n",
      "test mean loss=88380.59375\n",
      "fin save.\n",
      "epoch 9133\n",
      "test_train\n",
      "train mean loss=62776.5703125\n",
      "test_test\n",
      "test mean loss=88325.55078125\n",
      "fin save.\n",
      "epoch 9134\n",
      "test_train\n",
      "train mean loss=63560.16223958333\n",
      "test_test\n",
      "test mean loss=88380.0546875\n",
      "fin save.\n",
      "epoch 9135\n",
      "test_train\n",
      "train mean loss=62095.002604166664\n",
      "test_test\n",
      "test mean loss=88239.2265625\n",
      "fin save.\n",
      "epoch 9136\n",
      "test_train\n",
      "train mean loss=62202.29505208333\n",
      "test_test\n",
      "test mean loss=88282.22265625\n",
      "fin save.\n",
      "epoch 9137\n",
      "test_train\n",
      "train mean loss=61635.317708333336\n",
      "test_test\n",
      "test mean loss=88227.21484375\n",
      "fin save.\n",
      "epoch 9138\n",
      "test_train\n",
      "train mean loss=62380.171875\n",
      "test_test\n",
      "test mean loss=88468.640625\n",
      "fin save.\n",
      "epoch 9139\n",
      "test_train\n",
      "train mean loss=62801.10260416667\n",
      "test_test\n",
      "test mean loss=88616.296875\n",
      "fin save.\n",
      "epoch 9140\n",
      "test_train\n",
      "train mean loss=63144.3484375\n",
      "test_test\n",
      "test mean loss=88406.0546875\n",
      "fin save.\n",
      "epoch 9141\n",
      "test_train\n",
      "train mean loss=61880.871875\n",
      "test_test\n",
      "test mean loss=88245.93359375\n",
      "fin save.\n",
      "epoch 9142\n",
      "test_train\n",
      "train mean loss=62131.1109375\n",
      "test_test\n",
      "test mean loss=88101.6484375\n",
      "fin save.\n",
      "epoch 9143\n",
      "test_train\n",
      "train mean loss=62378.03229166667\n",
      "test_test\n",
      "test mean loss=88312.54296875\n",
      "fin save.\n",
      "epoch 9144\n",
      "test_train\n",
      "train mean loss=62150.19739583333\n",
      "test_test\n",
      "test mean loss=88328.0234375\n",
      "fin save.\n",
      "epoch 9145\n",
      "test_train\n",
      "train mean loss=62532.1359375\n",
      "test_test\n",
      "test mean loss=88141.6796875\n",
      "fin save.\n",
      "epoch 9146\n",
      "test_train\n",
      "train mean loss=61888.153125\n",
      "test_test\n",
      "test mean loss=88052.1953125\n",
      "fin save.\n",
      "epoch 9147\n",
      "test_train\n",
      "train mean loss=63050.80677083333\n",
      "test_test\n",
      "test mean loss=87936.56640625\n",
      "fin save.\n",
      "epoch 9148\n",
      "test_train\n",
      "train mean loss=61677.098958333336\n",
      "test_test\n",
      "test mean loss=88037.5625\n",
      "fin save.\n",
      "epoch 9149\n",
      "test_train\n",
      "train mean loss=62566.334375\n",
      "test_test\n",
      "test mean loss=88289.515625\n",
      "fin save.\n",
      "epoch 9150\n",
      "test_train\n",
      "train mean loss=61920.03046875\n",
      "test_test\n",
      "test mean loss=88195.234375\n",
      "fin save.\n",
      "epoch 9151\n",
      "test_train\n",
      "train mean loss=63298.430338541664\n",
      "test_test\n",
      "test mean loss=88204.74609375\n",
      "fin save.\n",
      "epoch 9152\n",
      "test_train\n",
      "train mean loss=61242.942708333336\n",
      "test_test\n",
      "test mean loss=87978.74609375\n",
      "fin save.\n",
      "epoch 9153\n",
      "test_train\n",
      "train mean loss=62637.27734375\n",
      "test_test\n",
      "test mean loss=87910.62109375\n",
      "fin save.\n",
      "epoch 9154\n",
      "test_train\n",
      "train mean loss=62855.20807291667\n",
      "test_test\n",
      "test mean loss=87736.05859375\n",
      "fin save.\n",
      "epoch 9155\n",
      "test_train\n",
      "train mean loss=61703.334635416664\n",
      "test_test\n",
      "test mean loss=87968.890625\n",
      "fin save.\n",
      "epoch 9156\n",
      "test_train\n",
      "train mean loss=61591.2765625\n",
      "test_test\n",
      "test mean loss=88128.1484375\n",
      "fin save.\n",
      "epoch 9157\n",
      "test_train\n",
      "train mean loss=62098.18697916667\n",
      "test_test\n",
      "test mean loss=88123.703125\n",
      "fin save.\n",
      "epoch 9158\n",
      "test_train\n",
      "train mean loss=62856.690234375\n",
      "test_test\n",
      "test mean loss=88165.9375\n",
      "fin save.\n",
      "epoch 9159\n",
      "test_train\n",
      "train mean loss=60731.8234375\n",
      "test_test\n",
      "test mean loss=88217.53515625\n",
      "fin save.\n",
      "epoch 9160\n",
      "test_train\n",
      "train mean loss=62674.2359375\n",
      "test_test\n",
      "test mean loss=88019.74609375\n",
      "fin save.\n",
      "epoch 9161\n",
      "test_train\n",
      "train mean loss=62721.78463541667\n",
      "test_test\n",
      "test mean loss=87930.74609375\n",
      "fin save.\n",
      "epoch 9162\n",
      "test_train\n",
      "train mean loss=61321.775\n",
      "test_test\n",
      "test mean loss=87990.32421875\n",
      "fin save.\n",
      "epoch 9163\n",
      "test_train\n",
      "train mean loss=62401.65052083333\n",
      "test_test\n",
      "test mean loss=87919.2421875\n",
      "fin save.\n",
      "epoch 9164\n",
      "test_train\n",
      "train mean loss=61460.51223958333\n",
      "test_test\n",
      "test mean loss=87976.17578125\n",
      "fin save.\n",
      "epoch 9165\n",
      "test_train\n",
      "train mean loss=62850.50091145833\n",
      "test_test\n",
      "test mean loss=87986.41015625\n",
      "fin save.\n",
      "epoch 9166\n",
      "test_train\n",
      "train mean loss=62515.396875\n",
      "test_test\n",
      "test mean loss=88183.96875\n",
      "fin save.\n",
      "epoch 9167\n",
      "test_train\n",
      "train mean loss=62787.47994791667\n",
      "test_test\n",
      "test mean loss=88066.13671875\n",
      "fin save.\n",
      "epoch 9168\n",
      "test_train\n",
      "train mean loss=62684.193359375\n",
      "test_test\n",
      "test mean loss=88046.375\n",
      "fin save.\n",
      "epoch 9169\n",
      "test_train\n",
      "train mean loss=61002.47799479167\n",
      "test_test\n",
      "test mean loss=87937.2265625\n",
      "fin save.\n",
      "epoch 9170\n",
      "test_train\n",
      "train mean loss=62646.21106770833\n",
      "test_test\n",
      "test mean loss=87868.484375\n",
      "fin save.\n",
      "epoch 9171\n",
      "test_train\n",
      "train mean loss=62338.69192708333\n",
      "test_test\n",
      "test mean loss=87805.71875\n",
      "fin save.\n",
      "epoch 9172\n",
      "test_train\n",
      "train mean loss=62592.55390625\n",
      "test_test\n",
      "test mean loss=87952.875\n",
      "fin save.\n",
      "epoch 9173\n",
      "test_train\n",
      "train mean loss=62461.99505208333\n",
      "test_test\n",
      "test mean loss=88145.0546875\n",
      "fin save.\n",
      "epoch 9174\n",
      "test_train\n",
      "train mean loss=61512.08411458333\n",
      "test_test\n",
      "test mean loss=87904.2265625\n",
      "fin save.\n",
      "epoch 9175\n",
      "test_train\n",
      "train mean loss=62104.317708333336\n",
      "test_test\n",
      "test mean loss=88020.13671875\n",
      "fin save.\n",
      "epoch 9176\n",
      "test_train\n",
      "train mean loss=62448.31875\n",
      "test_test\n",
      "test mean loss=87960.98046875\n",
      "fin save.\n",
      "epoch 9177\n",
      "test_train\n",
      "train mean loss=61495.71979166667\n",
      "test_test\n",
      "test mean loss=87996.25\n",
      "fin save.\n",
      "epoch 9178\n",
      "test_train\n",
      "train mean loss=63320.745833333334\n",
      "test_test\n",
      "test mean loss=87898.359375\n",
      "fin save.\n",
      "epoch 9179\n",
      "test_train\n",
      "train mean loss=62277.49791666667\n",
      "test_test\n",
      "test mean loss=88010.734375\n",
      "fin save.\n",
      "epoch 9180\n",
      "test_train\n",
      "train mean loss=62069.06432291667\n",
      "test_test\n",
      "test mean loss=88023.8984375\n",
      "fin save.\n",
      "epoch 9181\n",
      "test_train\n",
      "train mean loss=62569.49609375\n",
      "test_test\n",
      "test mean loss=87893.4375\n",
      "fin save.\n",
      "epoch 9182\n",
      "test_train\n",
      "train mean loss=62701.877734375\n",
      "test_test\n",
      "test mean loss=88068.59765625\n",
      "fin save.\n",
      "epoch 9183\n",
      "test_train\n",
      "train mean loss=62927.620833333334\n",
      "test_test\n",
      "test mean loss=87910.828125\n",
      "fin save.\n",
      "epoch 9184\n",
      "test_train\n",
      "train mean loss=61657.179427083334\n",
      "test_test\n",
      "test mean loss=87966.91796875\n",
      "fin save.\n",
      "epoch 9185\n",
      "test_train\n",
      "train mean loss=62767.953385416666\n",
      "test_test\n",
      "test mean loss=87935.51953125\n",
      "fin save.\n",
      "epoch 9186\n",
      "test_train\n",
      "train mean loss=62654.063802083336\n",
      "test_test\n",
      "test mean loss=87810.87890625\n",
      "fin save.\n",
      "epoch 9187\n",
      "test_train\n",
      "train mean loss=62086.03854166667\n",
      "test_test\n",
      "test mean loss=87821.5078125\n",
      "fin save.\n",
      "epoch 9188\n",
      "test_train\n",
      "train mean loss=62238.73151041667\n",
      "test_test\n",
      "test mean loss=87823.62890625\n",
      "fin save.\n",
      "epoch 9189\n",
      "test_train\n",
      "train mean loss=62119.17083333333\n",
      "test_test\n",
      "test mean loss=87977.58984375\n",
      "fin save.\n",
      "epoch 9190\n",
      "test_train\n",
      "train mean loss=63184.05703125\n",
      "test_test\n",
      "test mean loss=88038.5234375\n",
      "fin save.\n",
      "epoch 9191\n",
      "test_train\n",
      "train mean loss=62481.896875\n",
      "test_test\n",
      "test mean loss=87971.4765625\n",
      "fin save.\n",
      "epoch 9192\n",
      "test_train\n",
      "train mean loss=62178.21302083333\n",
      "test_test\n",
      "test mean loss=88008.84375\n",
      "fin save.\n",
      "epoch 9193\n",
      "test_train\n",
      "train mean loss=62297.657552083336\n",
      "test_test\n",
      "test mean loss=87845.3203125\n",
      "fin save.\n",
      "epoch 9194\n",
      "test_train\n",
      "train mean loss=62460.08828125\n",
      "test_test\n",
      "test mean loss=87911.2421875\n",
      "fin save.\n",
      "epoch 9195\n",
      "test_train\n",
      "train mean loss=62277.45013020833\n",
      "test_test\n",
      "test mean loss=87892.515625\n",
      "fin save.\n",
      "epoch 9196\n",
      "test_train\n",
      "train mean loss=62167.315755208336\n",
      "test_test\n",
      "test mean loss=87953.31640625\n",
      "fin save.\n",
      "epoch 9197\n",
      "test_train\n",
      "train mean loss=62216.60638020833\n",
      "test_test\n",
      "test mean loss=88167.2578125\n",
      "fin save.\n",
      "epoch 9198\n",
      "test_train\n",
      "train mean loss=62746.73489583333\n",
      "test_test\n",
      "test mean loss=88036.03125\n",
      "fin save.\n",
      "epoch 9199\n",
      "test_train\n",
      "train mean loss=62149.661458333336\n",
      "test_test\n",
      "test mean loss=88023.6796875\n",
      "fin save.\n",
      "epoch 9200\n",
      "test_train\n",
      "train mean loss=62332.29583333333\n",
      "test_test\n",
      "test mean loss=88063.9765625\n",
      "fin save.\n",
      "epoch 9201\n",
      "test_train\n",
      "train mean loss=62344.3\n",
      "test_test\n",
      "test mean loss=88206.79296875\n",
      "fin save.\n",
      "epoch 9202\n",
      "test_train\n",
      "train mean loss=62328.14609375\n",
      "test_test\n",
      "test mean loss=88283.9609375\n",
      "fin save.\n",
      "epoch 9203\n",
      "test_train\n",
      "train mean loss=61940.87552083333\n",
      "test_test\n",
      "test mean loss=88227.625\n",
      "fin save.\n",
      "epoch 9204\n",
      "test_train\n",
      "train mean loss=62890.78606770833\n",
      "test_test\n",
      "test mean loss=88155.26171875\n",
      "fin save.\n",
      "epoch 9205\n",
      "test_train\n",
      "train mean loss=62499.00078125\n",
      "test_test\n",
      "test mean loss=88279.140625\n",
      "fin save.\n",
      "epoch 9206\n",
      "test_train\n",
      "train mean loss=62558.77916666667\n",
      "test_test\n",
      "test mean loss=88053.98828125\n",
      "fin save.\n",
      "epoch 9207\n",
      "test_train\n",
      "train mean loss=61854.047265625\n",
      "test_test\n",
      "test mean loss=88284.15625\n",
      "fin save.\n",
      "epoch 9208\n",
      "test_train\n",
      "train mean loss=62196.367447916666\n",
      "test_test\n",
      "test mean loss=88317.16015625\n",
      "fin save.\n",
      "epoch 9209\n",
      "test_train\n",
      "train mean loss=61866.60364583333\n",
      "test_test\n",
      "test mean loss=88405.30078125\n",
      "fin save.\n",
      "epoch 9210\n",
      "test_train\n",
      "train mean loss=62088.81822916667\n",
      "test_test\n",
      "test mean loss=88390.671875\n",
      "fin save.\n",
      "epoch 9211\n",
      "test_train\n",
      "train mean loss=61322.285546875\n",
      "test_test\n",
      "test mean loss=88456.69140625\n",
      "fin save.\n",
      "epoch 9212\n",
      "test_train\n",
      "train mean loss=61925.35234375\n",
      "test_test\n",
      "test mean loss=88338.2578125\n",
      "fin save.\n",
      "epoch 9213\n",
      "test_train\n",
      "train mean loss=60869.807291666664\n",
      "test_test\n",
      "test mean loss=88167.40234375\n",
      "fin save.\n",
      "epoch 9214\n",
      "test_train\n",
      "train mean loss=61276.52942708333\n",
      "test_test\n",
      "test mean loss=88344.6015625\n",
      "fin save.\n",
      "epoch 9215\n",
      "test_train\n",
      "train mean loss=63059.45494791667\n",
      "test_test\n",
      "test mean loss=88216.41015625\n",
      "fin save.\n",
      "epoch 9216\n",
      "test_train\n",
      "train mean loss=62177.35859375\n",
      "test_test\n",
      "test mean loss=88151.46875\n",
      "fin save.\n",
      "epoch 9217\n",
      "test_train\n",
      "train mean loss=62582.45520833333\n",
      "test_test\n",
      "test mean loss=88168.2890625\n",
      "fin save.\n",
      "epoch 9218\n",
      "test_train\n",
      "train mean loss=62345.2359375\n",
      "test_test\n",
      "test mean loss=88121.63671875\n",
      "fin save.\n",
      "epoch 9219\n",
      "test_train\n",
      "train mean loss=62178.460677083334\n",
      "test_test\n",
      "test mean loss=88021.48046875\n",
      "fin save.\n",
      "epoch 9220\n",
      "test_train\n",
      "train mean loss=63249.271875\n",
      "test_test\n",
      "test mean loss=88052.20703125\n",
      "fin save.\n",
      "epoch 9221\n",
      "test_train\n",
      "train mean loss=61970.342447916664\n",
      "test_test\n",
      "test mean loss=88153.328125\n",
      "fin save.\n",
      "epoch 9222\n",
      "test_train\n",
      "train mean loss=62751.03567708333\n",
      "test_test\n",
      "test mean loss=88178.21875\n",
      "fin save.\n",
      "epoch 9223\n",
      "test_train\n",
      "train mean loss=62258.85729166667\n",
      "test_test\n",
      "test mean loss=87993.796875\n",
      "fin save.\n",
      "epoch 9224\n",
      "test_train\n",
      "train mean loss=62096.34088541667\n",
      "test_test\n",
      "test mean loss=88118.61328125\n",
      "fin save.\n",
      "epoch 9225\n",
      "test_train\n",
      "train mean loss=61805.047265625\n",
      "test_test\n",
      "test mean loss=88055.82421875\n",
      "fin save.\n",
      "epoch 9226\n",
      "test_train\n",
      "train mean loss=62294.14075520833\n",
      "test_test\n",
      "test mean loss=88400.8203125\n",
      "fin save.\n",
      "epoch 9227\n",
      "test_train\n",
      "train mean loss=61930.52890625\n",
      "test_test\n",
      "test mean loss=88205.50390625\n",
      "fin save.\n",
      "epoch 9228\n",
      "test_train\n",
      "train mean loss=63021.81692708333\n",
      "test_test\n",
      "test mean loss=88010.6796875\n",
      "fin save.\n",
      "epoch 9229\n",
      "test_train\n",
      "train mean loss=62223.4421875\n",
      "test_test\n",
      "test mean loss=88181.59375\n",
      "fin save.\n",
      "epoch 9230\n",
      "test_train\n",
      "train mean loss=61666.847395833334\n",
      "test_test\n",
      "test mean loss=88062.1171875\n",
      "fin save.\n",
      "epoch 9231\n",
      "test_train\n",
      "train mean loss=62388.62890625\n",
      "test_test\n",
      "test mean loss=88072.3828125\n",
      "fin save.\n",
      "epoch 9232\n",
      "test_train\n",
      "train mean loss=62798.20390625\n",
      "test_test\n",
      "test mean loss=88138.0078125\n",
      "fin save.\n",
      "epoch 9233\n",
      "test_train\n",
      "train mean loss=61896.85390625\n",
      "test_test\n",
      "test mean loss=88375.19140625\n",
      "fin save.\n",
      "epoch 9234\n",
      "test_train\n",
      "train mean loss=61894.76119791667\n",
      "test_test\n",
      "test mean loss=88158.68359375\n",
      "fin save.\n",
      "epoch 9235\n",
      "test_train\n",
      "train mean loss=61428.7\n",
      "test_test\n",
      "test mean loss=88254.875\n",
      "fin save.\n",
      "epoch 9236\n",
      "test_train\n",
      "train mean loss=63195.190104166664\n",
      "test_test\n",
      "test mean loss=88155.72265625\n",
      "fin save.\n",
      "epoch 9237\n",
      "test_train\n",
      "train mean loss=61901.613671875\n",
      "test_test\n",
      "test mean loss=88077.83984375\n",
      "fin save.\n",
      "epoch 9238\n",
      "test_train\n",
      "train mean loss=62607.84296875\n",
      "test_test\n",
      "test mean loss=88174.0\n",
      "fin save.\n",
      "epoch 9239\n",
      "test_train\n",
      "train mean loss=61213.40546875\n",
      "test_test\n",
      "test mean loss=88299.0703125\n",
      "fin save.\n",
      "epoch 9240\n",
      "test_train\n",
      "train mean loss=62278.030598958336\n",
      "test_test\n",
      "test mean loss=88334.16015625\n",
      "fin save.\n",
      "epoch 9241\n",
      "test_train\n",
      "train mean loss=62351.471875\n",
      "test_test\n",
      "test mean loss=88132.02734375\n",
      "fin save.\n",
      "epoch 9242\n",
      "test_train\n",
      "train mean loss=61566.345442708334\n",
      "test_test\n",
      "test mean loss=88370.8828125\n",
      "fin save.\n",
      "epoch 9243\n",
      "test_train\n",
      "train mean loss=61821.7390625\n",
      "test_test\n",
      "test mean loss=88264.45703125\n",
      "fin save.\n",
      "epoch 9244\n",
      "test_train\n",
      "train mean loss=62055.53802083333\n",
      "test_test\n",
      "test mean loss=88500.453125\n",
      "fin save.\n",
      "epoch 9245\n",
      "test_train\n",
      "train mean loss=62141.61015625\n",
      "test_test\n",
      "test mean loss=88327.2109375\n",
      "fin save.\n",
      "epoch 9246\n",
      "test_train\n",
      "train mean loss=62545.96927083333\n",
      "test_test\n",
      "test mean loss=88399.12890625\n",
      "fin save.\n",
      "epoch 9247\n",
      "test_train\n",
      "train mean loss=61571.605729166666\n",
      "test_test\n",
      "test mean loss=88228.3359375\n",
      "fin save.\n",
      "epoch 9248\n",
      "test_train\n",
      "train mean loss=62284.26223958333\n",
      "test_test\n",
      "test mean loss=88121.734375\n",
      "fin save.\n",
      "epoch 9249\n",
      "test_train\n",
      "train mean loss=62021.42786458333\n",
      "test_test\n",
      "test mean loss=88162.703125\n",
      "fin save.\n",
      "epoch 9250\n",
      "test_train\n",
      "train mean loss=62496.679036458336\n",
      "test_test\n",
      "test mean loss=88191.06640625\n",
      "fin save.\n",
      "epoch 9251\n",
      "test_train\n",
      "train mean loss=61397.58385416667\n",
      "test_test\n",
      "test mean loss=88159.484375\n",
      "fin save.\n",
      "epoch 9252\n",
      "test_train\n",
      "train mean loss=61538.19375\n",
      "test_test\n",
      "test mean loss=88224.59375\n",
      "fin save.\n",
      "epoch 9253\n",
      "test_train\n",
      "train mean loss=62884.32825520833\n",
      "test_test\n",
      "test mean loss=88182.1328125\n",
      "fin save.\n",
      "epoch 9254\n",
      "test_train\n",
      "train mean loss=62199.009375\n",
      "test_test\n",
      "test mean loss=88335.703125\n",
      "fin save.\n",
      "epoch 9255\n",
      "test_train\n",
      "train mean loss=62089.523177083334\n",
      "test_test\n",
      "test mean loss=88223.66796875\n",
      "fin save.\n",
      "epoch 9256\n",
      "test_train\n",
      "train mean loss=61612.03567708333\n",
      "test_test\n",
      "test mean loss=88116.16015625\n",
      "fin save.\n",
      "epoch 9257\n",
      "test_train\n",
      "train mean loss=61239.969010416666\n",
      "test_test\n",
      "test mean loss=88073.94140625\n",
      "fin save.\n",
      "epoch 9258\n",
      "test_train\n",
      "train mean loss=62852.160416666666\n",
      "test_test\n",
      "test mean loss=88044.97265625\n",
      "fin save.\n",
      "epoch 9259\n",
      "test_train\n",
      "train mean loss=62915.692057291664\n",
      "test_test\n",
      "test mean loss=88125.69140625\n",
      "fin save.\n",
      "epoch 9260\n",
      "test_train\n",
      "train mean loss=62644.023177083334\n",
      "test_test\n",
      "test mean loss=88144.4453125\n",
      "fin save.\n",
      "epoch 9261\n",
      "test_train\n",
      "train mean loss=61627.617838541664\n",
      "test_test\n",
      "test mean loss=88138.9765625\n",
      "fin save.\n",
      "epoch 9262\n",
      "test_train\n",
      "train mean loss=62606.26640625\n",
      "test_test\n",
      "test mean loss=88142.3125\n",
      "fin save.\n",
      "epoch 9263\n",
      "test_train\n",
      "train mean loss=62949.58489583333\n",
      "test_test\n",
      "test mean loss=88039.92578125\n",
      "fin save.\n",
      "epoch 9264\n",
      "test_train\n",
      "train mean loss=62297.53828125\n",
      "test_test\n",
      "test mean loss=87954.9453125\n",
      "fin save.\n",
      "epoch 9265\n",
      "test_train\n",
      "train mean loss=63346.06588541667\n",
      "test_test\n",
      "test mean loss=87972.0703125\n",
      "fin save.\n",
      "epoch 9266\n",
      "test_train\n",
      "train mean loss=62529.301041666666\n",
      "test_test\n",
      "test mean loss=87821.3984375\n",
      "fin save.\n",
      "epoch 9267\n",
      "test_train\n",
      "train mean loss=62774.524609375\n",
      "test_test\n",
      "test mean loss=88009.15234375\n",
      "fin save.\n",
      "epoch 9268\n",
      "test_train\n",
      "train mean loss=62458.43463541667\n",
      "test_test\n",
      "test mean loss=88170.76171875\n",
      "fin save.\n",
      "epoch 9269\n",
      "test_train\n",
      "train mean loss=62419.54283854167\n",
      "test_test\n",
      "test mean loss=87944.1640625\n",
      "fin save.\n",
      "epoch 9270\n",
      "test_train\n",
      "train mean loss=61615.661458333336\n",
      "test_test\n",
      "test mean loss=88036.44921875\n",
      "fin save.\n",
      "epoch 9271\n",
      "test_train\n",
      "train mean loss=62276.16510416667\n",
      "test_test\n",
      "test mean loss=88144.1640625\n",
      "fin save.\n",
      "epoch 9272\n",
      "test_train\n",
      "train mean loss=61355.73776041667\n",
      "test_test\n",
      "test mean loss=88220.734375\n",
      "fin save.\n",
      "epoch 9273\n",
      "test_train\n",
      "train mean loss=62399.04791666667\n",
      "test_test\n",
      "test mean loss=88268.609375\n",
      "fin save.\n",
      "epoch 9274\n",
      "test_train\n",
      "train mean loss=63154.78359375\n",
      "test_test\n",
      "test mean loss=88357.35546875\n",
      "fin save.\n",
      "epoch 9275\n",
      "test_train\n",
      "train mean loss=62670.115625\n",
      "test_test\n",
      "test mean loss=88480.48046875\n",
      "fin save.\n",
      "epoch 9276\n",
      "test_train\n",
      "train mean loss=62823.990234375\n",
      "test_test\n",
      "test mean loss=88506.3515625\n",
      "fin save.\n",
      "epoch 9277\n",
      "test_train\n",
      "train mean loss=61615.73359375\n",
      "test_test\n",
      "test mean loss=88425.4609375\n",
      "fin save.\n",
      "epoch 9278\n",
      "test_train\n",
      "train mean loss=62771.0578125\n",
      "test_test\n",
      "test mean loss=88117.07421875\n",
      "fin save.\n",
      "epoch 9279\n",
      "test_train\n",
      "train mean loss=62287.60442708333\n",
      "test_test\n",
      "test mean loss=88153.65625\n",
      "fin save.\n",
      "epoch 9280\n",
      "test_train\n",
      "train mean loss=61436.15911458333\n",
      "test_test\n",
      "test mean loss=88280.5078125\n",
      "fin save.\n",
      "epoch 9281\n",
      "test_train\n",
      "train mean loss=62440.33828125\n",
      "test_test\n",
      "test mean loss=88194.4296875\n",
      "fin save.\n",
      "epoch 9282\n",
      "test_train\n",
      "train mean loss=62514.801432291664\n",
      "test_test\n",
      "test mean loss=88454.078125\n",
      "fin save.\n",
      "epoch 9283\n",
      "test_train\n",
      "train mean loss=62285.19322916667\n",
      "test_test\n",
      "test mean loss=88237.80859375\n",
      "fin save.\n",
      "epoch 9284\n",
      "test_train\n",
      "train mean loss=62378.196484375\n",
      "test_test\n",
      "test mean loss=88281.81640625\n",
      "fin save.\n",
      "epoch 9285\n",
      "test_train\n",
      "train mean loss=61601.245833333334\n",
      "test_test\n",
      "test mean loss=88119.4375\n",
      "fin save.\n",
      "epoch 9286\n",
      "test_train\n",
      "train mean loss=61874.43125\n",
      "test_test\n",
      "test mean loss=88175.3671875\n",
      "fin save.\n",
      "epoch 9287\n",
      "test_train\n",
      "train mean loss=61516.146875\n",
      "test_test\n",
      "test mean loss=88266.2265625\n",
      "fin save.\n",
      "epoch 9288\n",
      "test_train\n",
      "train mean loss=62768.43346354167\n",
      "test_test\n",
      "test mean loss=88066.8203125\n",
      "fin save.\n",
      "epoch 9289\n",
      "test_train\n",
      "train mean loss=61092.022135416664\n",
      "test_test\n",
      "test mean loss=88109.2578125\n",
      "fin save.\n",
      "epoch 9290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_train\n",
      "train mean loss=61680.59973958333\n",
      "test_test\n",
      "test mean loss=88019.91796875\n",
      "fin save.\n",
      "epoch 9291\n",
      "test_train\n",
      "train mean loss=62819.84609375\n",
      "test_test\n",
      "test mean loss=88196.578125\n",
      "fin save.\n",
      "epoch 9292\n",
      "test_train\n",
      "train mean loss=62968.44934895833\n",
      "test_test\n",
      "test mean loss=88320.0\n",
      "fin save.\n",
      "epoch 9293\n",
      "test_train\n",
      "train mean loss=61137.123046875\n",
      "test_test\n",
      "test mean loss=87954.1953125\n",
      "fin save.\n",
      "epoch 9294\n",
      "test_train\n",
      "train mean loss=62704.91354166667\n",
      "test_test\n",
      "test mean loss=87963.7734375\n",
      "fin save.\n",
      "epoch 9295\n",
      "test_train\n",
      "train mean loss=61620.71796875\n",
      "test_test\n",
      "test mean loss=87971.48046875\n",
      "fin save.\n",
      "epoch 9296\n",
      "test_train\n",
      "train mean loss=62828.11471354167\n",
      "test_test\n",
      "test mean loss=87888.14453125\n",
      "fin save.\n",
      "epoch 9297\n",
      "test_train\n",
      "train mean loss=62312.90377604167\n",
      "test_test\n",
      "test mean loss=87926.61328125\n",
      "fin save.\n",
      "epoch 9298\n",
      "test_train\n",
      "train mean loss=62869.009765625\n",
      "test_test\n",
      "test mean loss=88017.42578125\n",
      "fin save.\n",
      "epoch 9299\n",
      "test_train\n",
      "train mean loss=62527.32708333333\n",
      "test_test\n",
      "test mean loss=88084.9765625\n",
      "fin save.\n",
      "epoch 9300\n",
      "test_train\n",
      "train mean loss=61404.297526041664\n",
      "test_test\n",
      "test mean loss=87819.578125\n",
      "fin save.\n",
      "epoch 9301\n",
      "test_train\n",
      "train mean loss=61982.0515625\n",
      "test_test\n",
      "test mean loss=87939.9296875\n",
      "fin save.\n",
      "epoch 9302\n",
      "test_train\n",
      "train mean loss=62166.636458333334\n",
      "test_test\n",
      "test mean loss=87820.5546875\n",
      "fin save.\n",
      "epoch 9303\n",
      "test_train\n",
      "train mean loss=63485.02734375\n",
      "test_test\n",
      "test mean loss=87819.29296875\n",
      "fin save.\n",
      "epoch 9304\n",
      "test_train\n",
      "train mean loss=62233.66744791667\n",
      "test_test\n",
      "test mean loss=87847.65234375\n",
      "fin save.\n",
      "epoch 9305\n",
      "test_train\n",
      "train mean loss=62772.300130208336\n",
      "test_test\n",
      "test mean loss=87694.4375\n",
      "fin save.\n",
      "epoch 9306\n",
      "test_train\n",
      "train mean loss=62403.98815104167\n",
      "test_test\n",
      "test mean loss=87580.14453125\n",
      "fin save.\n",
      "epoch 9307\n",
      "test_train\n",
      "train mean loss=62049.258203125\n",
      "test_test\n",
      "test mean loss=87686.77734375\n",
      "fin save.\n",
      "epoch 9308\n",
      "test_train\n",
      "train mean loss=62609.163671875\n",
      "test_test\n",
      "test mean loss=87550.59765625\n",
      "fin save.\n",
      "epoch 9309\n",
      "test_train\n",
      "train mean loss=61406.91067708333\n",
      "test_test\n",
      "test mean loss=87593.03515625\n",
      "fin save.\n",
      "epoch 9310\n",
      "test_train\n",
      "train mean loss=62490.375\n",
      "test_test\n",
      "test mean loss=87733.375\n",
      "fin save.\n",
      "epoch 9311\n",
      "test_train\n",
      "train mean loss=61874.47578125\n",
      "test_test\n",
      "test mean loss=87676.9453125\n",
      "fin save.\n",
      "epoch 9312\n",
      "test_train\n",
      "train mean loss=61543.37942708333\n",
      "test_test\n",
      "test mean loss=87731.04296875\n",
      "fin save.\n",
      "epoch 9313\n",
      "test_train\n",
      "train mean loss=62459.221484375\n",
      "test_test\n",
      "test mean loss=87913.6171875\n",
      "fin save.\n",
      "epoch 9314\n",
      "test_train\n",
      "train mean loss=61237.384505208334\n",
      "test_test\n",
      "test mean loss=87970.33203125\n",
      "fin save.\n",
      "epoch 9315\n",
      "test_train\n",
      "train mean loss=61798.89635416667\n",
      "test_test\n",
      "test mean loss=87897.12890625\n",
      "fin save.\n",
      "epoch 9316\n",
      "test_train\n",
      "train mean loss=61379.751171875\n",
      "test_test\n",
      "test mean loss=87847.12890625\n",
      "fin save.\n",
      "epoch 9317\n",
      "test_train\n",
      "train mean loss=61843.99401041667\n",
      "test_test\n",
      "test mean loss=87880.98828125\n",
      "fin save.\n",
      "epoch 9318\n",
      "test_train\n",
      "train mean loss=62241.34296875\n",
      "test_test\n",
      "test mean loss=88038.734375\n",
      "fin save.\n",
      "epoch 9319\n",
      "test_train\n",
      "train mean loss=62161.734114583334\n",
      "test_test\n",
      "test mean loss=87993.41015625\n",
      "fin save.\n",
      "epoch 9320\n",
      "test_train\n",
      "train mean loss=62652.149609375\n",
      "test_test\n",
      "test mean loss=87949.953125\n",
      "fin save.\n",
      "epoch 9321\n",
      "test_train\n",
      "train mean loss=62426.682291666664\n",
      "test_test\n",
      "test mean loss=87719.19921875\n",
      "fin save.\n",
      "epoch 9322\n",
      "test_train\n",
      "train mean loss=62861.877604166664\n",
      "test_test\n",
      "test mean loss=87477.2890625\n",
      "fin save.\n",
      "epoch 9323\n",
      "test_train\n",
      "train mean loss=61660.17877604167\n",
      "test_test\n",
      "test mean loss=87551.8515625\n",
      "fin save.\n",
      "epoch 9324\n",
      "test_train\n",
      "train mean loss=61855.71927083333\n",
      "test_test\n",
      "test mean loss=87869.3125\n",
      "fin save.\n",
      "epoch 9325\n",
      "test_train\n",
      "train mean loss=63495.23880208333\n",
      "test_test\n",
      "test mean loss=87728.578125\n",
      "fin save.\n",
      "epoch 9326\n",
      "test_train\n",
      "train mean loss=62279.12578125\n",
      "test_test\n",
      "test mean loss=87917.77734375\n",
      "fin save.\n",
      "epoch 9327\n",
      "test_train\n",
      "train mean loss=62099.17630208333\n",
      "test_test\n",
      "test mean loss=87701.5234375\n",
      "fin save.\n",
      "epoch 9328\n",
      "test_train\n",
      "train mean loss=62173.96640625\n",
      "test_test\n",
      "test mean loss=87670.46484375\n",
      "fin save.\n",
      "epoch 9329\n",
      "test_train\n",
      "train mean loss=61753.983723958336\n",
      "test_test\n",
      "test mean loss=87576.6484375\n",
      "fin save.\n",
      "epoch 9330\n",
      "test_train\n",
      "train mean loss=61714.77265625\n",
      "test_test\n",
      "test mean loss=87573.25390625\n",
      "fin save.\n",
      "epoch 9331\n",
      "test_train\n",
      "train mean loss=62352.88203125\n",
      "test_test\n",
      "test mean loss=87670.8046875\n",
      "fin save.\n",
      "epoch 9332\n",
      "test_train\n",
      "train mean loss=61529.236067708334\n",
      "test_test\n",
      "test mean loss=87798.18359375\n",
      "fin save.\n",
      "epoch 9333\n",
      "test_train\n",
      "train mean loss=62132.902994791664\n",
      "test_test\n",
      "test mean loss=87582.09375\n",
      "fin save.\n",
      "epoch 9334\n",
      "test_train\n",
      "train mean loss=61823.99427083333\n",
      "test_test\n",
      "test mean loss=87781.84765625\n",
      "fin save.\n",
      "epoch 9335\n",
      "test_train\n",
      "train mean loss=61864.74296875\n",
      "test_test\n",
      "test mean loss=87815.01171875\n",
      "fin save.\n",
      "epoch 9336\n",
      "test_train\n",
      "train mean loss=63815.984375\n",
      "test_test\n",
      "test mean loss=87789.234375\n",
      "fin save.\n",
      "epoch 9337\n",
      "test_train\n",
      "train mean loss=62460.94244791667\n",
      "test_test\n",
      "test mean loss=87865.4921875\n",
      "fin save.\n",
      "epoch 9338\n",
      "test_train\n",
      "train mean loss=63256.438802083336\n",
      "test_test\n",
      "test mean loss=87880.15625\n",
      "fin save.\n",
      "epoch 9339\n",
      "test_train\n",
      "train mean loss=61906.76901041667\n",
      "test_test\n",
      "test mean loss=88085.0390625\n",
      "fin save.\n",
      "epoch 9340\n",
      "test_train\n",
      "train mean loss=62671.918359375\n",
      "test_test\n",
      "test mean loss=87815.55078125\n",
      "fin save.\n",
      "epoch 9341\n",
      "test_train\n",
      "train mean loss=62401.682291666664\n",
      "test_test\n",
      "test mean loss=87598.62890625\n",
      "fin save.\n",
      "epoch 9342\n",
      "test_train\n",
      "train mean loss=62558.1734375\n",
      "test_test\n",
      "test mean loss=87644.73828125\n",
      "fin save.\n",
      "epoch 9343\n",
      "test_train\n",
      "train mean loss=61696.6140625\n",
      "test_test\n",
      "test mean loss=87658.8203125\n",
      "fin save.\n",
      "epoch 9344\n",
      "test_train\n",
      "train mean loss=62865.38125\n",
      "test_test\n",
      "test mean loss=87741.42578125\n",
      "fin save.\n",
      "epoch 9345\n",
      "test_train\n",
      "train mean loss=62651.013020833336\n",
      "test_test\n",
      "test mean loss=87588.3828125\n",
      "fin save.\n",
      "epoch 9346\n",
      "test_train\n",
      "train mean loss=61385.508984375\n",
      "test_test\n",
      "test mean loss=87703.8203125\n",
      "fin save.\n",
      "epoch 9347\n",
      "test_train\n",
      "train mean loss=61317.23619791667\n",
      "test_test\n",
      "test mean loss=87405.6015625\n",
      "fin save.\n",
      "epoch 9348\n",
      "test_train\n",
      "train mean loss=62214.687239583334\n",
      "test_test\n",
      "test mean loss=87475.06640625\n",
      "fin save.\n",
      "epoch 9349\n",
      "test_train\n",
      "train mean loss=61707.80911458333\n",
      "test_test\n",
      "test mean loss=87481.296875\n",
      "fin save.\n",
      "epoch 9350\n",
      "test_train\n",
      "train mean loss=62135.32760416667\n",
      "test_test\n",
      "test mean loss=87420.0625\n",
      "fin save.\n",
      "epoch 9351\n",
      "test_train\n",
      "train mean loss=62674.1484375\n",
      "test_test\n",
      "test mean loss=87841.87890625\n",
      "fin save.\n",
      "epoch 9352\n",
      "test_train\n",
      "train mean loss=62221.859114583334\n",
      "test_test\n",
      "test mean loss=87765.76953125\n",
      "fin save.\n",
      "epoch 9353\n",
      "test_train\n",
      "train mean loss=61385.97369791667\n",
      "test_test\n",
      "test mean loss=87672.23046875\n",
      "fin save.\n",
      "epoch 9354\n",
      "test_train\n",
      "train mean loss=62620.84973958333\n",
      "test_test\n",
      "test mean loss=87675.78515625\n",
      "fin save.\n",
      "epoch 9355\n",
      "test_train\n",
      "train mean loss=62421.77747395833\n",
      "test_test\n",
      "test mean loss=87872.7578125\n",
      "fin save.\n",
      "epoch 9356\n",
      "test_train\n",
      "train mean loss=62602.19427083333\n",
      "test_test\n",
      "test mean loss=87911.77734375\n",
      "fin save.\n",
      "epoch 9357\n",
      "test_train\n",
      "train mean loss=62662.716536458334\n",
      "test_test\n",
      "test mean loss=87582.02734375\n",
      "fin save.\n",
      "epoch 9358\n",
      "test_train\n",
      "train mean loss=62110.429427083334\n",
      "test_test\n",
      "test mean loss=87743.72265625\n",
      "fin save.\n",
      "epoch 9359\n",
      "test_train\n",
      "train mean loss=63635.27395833333\n",
      "test_test\n",
      "test mean loss=87731.54296875\n",
      "fin save.\n",
      "epoch 9360\n",
      "test_train\n",
      "train mean loss=62739.465104166666\n",
      "test_test\n",
      "test mean loss=88049.84375\n",
      "fin save.\n",
      "epoch 9361\n",
      "test_train\n",
      "train mean loss=62428.42682291667\n",
      "test_test\n",
      "test mean loss=88100.8125\n",
      "fin save.\n",
      "epoch 9362\n",
      "test_train\n",
      "train mean loss=61972.78984375\n",
      "test_test\n",
      "test mean loss=88012.5078125\n",
      "fin save.\n",
      "epoch 9363\n",
      "test_train\n",
      "train mean loss=62576.636458333334\n",
      "test_test\n",
      "test mean loss=87882.52734375\n",
      "fin save.\n",
      "epoch 9364\n",
      "test_train\n",
      "train mean loss=62489.061197916664\n",
      "test_test\n",
      "test mean loss=87701.5625\n",
      "fin save.\n",
      "epoch 9365\n",
      "test_train\n",
      "train mean loss=61899.4109375\n",
      "test_test\n",
      "test mean loss=87686.609375\n",
      "fin save.\n",
      "epoch 9366\n",
      "test_train\n",
      "train mean loss=62363.970963541666\n",
      "test_test\n",
      "test mean loss=87886.2734375\n",
      "fin save.\n",
      "epoch 9367\n",
      "test_train\n",
      "train mean loss=63330.54921875\n",
      "test_test\n",
      "test mean loss=87759.80078125\n",
      "fin save.\n",
      "epoch 9368\n",
      "test_train\n",
      "train mean loss=62631.117447916666\n",
      "test_test\n",
      "test mean loss=87837.390625\n",
      "fin save.\n",
      "epoch 9369\n",
      "test_train\n",
      "train mean loss=62179.530989583334\n",
      "test_test\n",
      "test mean loss=88022.80078125\n",
      "fin save.\n",
      "epoch 9370\n",
      "test_train\n",
      "train mean loss=62403.31953125\n",
      "test_test\n",
      "test mean loss=88046.53515625\n",
      "fin save.\n",
      "epoch 9371\n",
      "test_train\n",
      "train mean loss=62905.92096354167\n",
      "test_test\n",
      "test mean loss=88042.17578125\n",
      "fin save.\n",
      "epoch 9372\n",
      "test_train\n",
      "train mean loss=62561.404947916664\n",
      "test_test\n",
      "test mean loss=88117.81640625\n",
      "fin save.\n",
      "epoch 9373\n",
      "test_train\n",
      "train mean loss=62367.66223958333\n",
      "test_test\n",
      "test mean loss=88164.57421875\n",
      "fin save.\n",
      "epoch 9374\n",
      "test_train\n",
      "train mean loss=61765.38828125\n",
      "test_test\n",
      "test mean loss=88169.49609375\n",
      "fin save.\n",
      "epoch 9375\n",
      "test_train\n",
      "train mean loss=61044.320572916666\n",
      "test_test\n",
      "test mean loss=88144.21484375\n",
      "fin save.\n",
      "epoch 9376\n",
      "test_train\n",
      "train mean loss=61690.927083333336\n",
      "test_test\n",
      "test mean loss=88044.4609375\n",
      "fin save.\n",
      "epoch 9377\n",
      "test_train\n",
      "train mean loss=62529.082421875\n",
      "test_test\n",
      "test mean loss=88085.90234375\n",
      "fin save.\n",
      "epoch 9378\n",
      "test_train\n",
      "train mean loss=62971.9640625\n",
      "test_test\n",
      "test mean loss=88274.11328125\n",
      "fin save.\n",
      "epoch 9379\n",
      "test_train\n",
      "train mean loss=62735.10651041667\n",
      "test_test\n",
      "test mean loss=88206.421875\n",
      "fin save.\n",
      "epoch 9380\n",
      "test_train\n",
      "train mean loss=61834.9\n",
      "test_test\n",
      "test mean loss=88213.78515625\n",
      "fin save.\n",
      "epoch 9381\n",
      "test_train\n",
      "train mean loss=63428.00286458333\n",
      "test_test\n",
      "test mean loss=88108.1015625\n",
      "fin save.\n",
      "epoch 9382\n",
      "test_train\n",
      "train mean loss=61876.063802083336\n",
      "test_test\n",
      "test mean loss=88252.2265625\n",
      "fin save.\n",
      "epoch 9383\n",
      "test_train\n",
      "train mean loss=61721.14765625\n",
      "test_test\n",
      "test mean loss=88277.796875\n",
      "fin save.\n",
      "epoch 9384\n",
      "test_train\n",
      "train mean loss=62852.96302083333\n",
      "test_test\n",
      "test mean loss=88271.76953125\n",
      "fin save.\n",
      "epoch 9385\n",
      "test_train\n",
      "train mean loss=61066.95494791667\n",
      "test_test\n",
      "test mean loss=88387.22265625\n",
      "fin save.\n",
      "epoch 9386\n",
      "test_train\n",
      "train mean loss=61791.74557291667\n",
      "test_test\n",
      "test mean loss=88526.7109375\n",
      "fin save.\n",
      "epoch 9387\n",
      "test_train\n",
      "train mean loss=62342.94322916667\n",
      "test_test\n",
      "test mean loss=88444.1640625\n",
      "fin save.\n",
      "epoch 9388\n",
      "test_train\n",
      "train mean loss=61639.51484375\n",
      "test_test\n",
      "test mean loss=88351.78515625\n",
      "fin save.\n",
      "epoch 9389\n",
      "test_train\n",
      "train mean loss=63071.822005208334\n",
      "test_test\n",
      "test mean loss=88525.59765625\n",
      "fin save.\n",
      "epoch 9390\n",
      "test_train\n",
      "train mean loss=61200.39791666667\n",
      "test_test\n",
      "test mean loss=88272.02734375\n",
      "fin save.\n",
      "epoch 9391\n",
      "test_train\n",
      "train mean loss=61963.36028645833\n",
      "test_test\n",
      "test mean loss=88319.26171875\n",
      "fin save.\n",
      "epoch 9392\n",
      "test_train\n",
      "train mean loss=62105.13815104167\n",
      "test_test\n",
      "test mean loss=88281.61328125\n",
      "fin save.\n",
      "epoch 9393\n",
      "test_train\n",
      "train mean loss=61412.79375\n",
      "test_test\n",
      "test mean loss=88334.625\n",
      "fin save.\n",
      "epoch 9394\n",
      "test_train\n",
      "train mean loss=63183.36184895833\n",
      "test_test\n",
      "test mean loss=88292.3828125\n",
      "fin save.\n",
      "epoch 9395\n",
      "test_train\n",
      "train mean loss=62418.89895833333\n",
      "test_test\n",
      "test mean loss=88077.52734375\n",
      "fin save.\n",
      "epoch 9396\n",
      "test_train\n",
      "train mean loss=61507.41848958333\n",
      "test_test\n",
      "test mean loss=88139.0390625\n",
      "fin save.\n",
      "epoch 9397\n",
      "test_train\n",
      "train mean loss=62457.90026041667\n",
      "test_test\n",
      "test mean loss=88168.95703125\n",
      "fin save.\n",
      "epoch 9398\n",
      "test_train\n",
      "train mean loss=62213.72734375\n",
      "test_test\n",
      "test mean loss=88214.33203125\n",
      "fin save.\n",
      "epoch 9399\n",
      "test_train\n",
      "train mean loss=61834.101953125\n",
      "test_test\n",
      "test mean loss=88172.88671875\n",
      "fin save.\n",
      "epoch 9400\n",
      "test_train\n",
      "train mean loss=62490.926041666666\n",
      "test_test\n",
      "test mean loss=88456.5390625\n",
      "fin save.\n",
      "epoch 9401\n",
      "test_train\n",
      "train mean loss=61578.559375\n",
      "test_test\n",
      "test mean loss=88402.16015625\n",
      "fin save.\n",
      "epoch 9402\n",
      "test_train\n",
      "train mean loss=61721.765885416666\n",
      "test_test\n",
      "test mean loss=88471.9140625\n",
      "fin save.\n",
      "epoch 9403\n",
      "test_train\n",
      "train mean loss=62060.35338541667\n",
      "test_test\n",
      "test mean loss=88503.33984375\n",
      "fin save.\n",
      "epoch 9404\n",
      "test_train\n",
      "train mean loss=63425.7921875\n",
      "test_test\n",
      "test mean loss=88534.4453125\n",
      "fin save.\n",
      "epoch 9405\n",
      "test_train\n",
      "train mean loss=61228.143229166664\n",
      "test_test\n",
      "test mean loss=88665.75\n",
      "fin save.\n",
      "epoch 9406\n",
      "test_train\n",
      "train mean loss=62303.086197916666\n",
      "test_test\n",
      "test mean loss=88580.53125\n",
      "fin save.\n",
      "epoch 9407\n",
      "test_train\n",
      "train mean loss=62982.31067708333\n",
      "test_test\n",
      "test mean loss=88593.5703125\n",
      "fin save.\n",
      "epoch 9408\n",
      "test_train\n",
      "train mean loss=62581.58997395833\n",
      "test_test\n",
      "test mean loss=88594.74609375\n",
      "fin save.\n",
      "epoch 9409\n",
      "test_train\n",
      "train mean loss=62372.57421875\n",
      "test_test\n",
      "test mean loss=88457.6484375\n",
      "fin save.\n",
      "epoch 9410\n",
      "test_train\n",
      "train mean loss=61572.497395833336\n",
      "test_test\n",
      "test mean loss=88432.65625\n",
      "fin save.\n",
      "epoch 9411\n",
      "test_train\n",
      "train mean loss=61452.175520833334\n",
      "test_test\n",
      "test mean loss=88551.2734375\n",
      "fin save.\n",
      "epoch 9412\n",
      "test_train\n",
      "train mean loss=61748.1953125\n",
      "test_test\n",
      "test mean loss=88431.828125\n",
      "fin save.\n",
      "epoch 9413\n",
      "test_train\n",
      "train mean loss=61432.57526041667\n",
      "test_test\n",
      "test mean loss=88389.34765625\n",
      "fin save.\n",
      "epoch 9414\n",
      "test_train\n",
      "train mean loss=62399.83489583333\n",
      "test_test\n",
      "test mean loss=88411.09765625\n",
      "fin save.\n",
      "epoch 9415\n",
      "test_train\n",
      "train mean loss=62675.27734375\n",
      "test_test\n",
      "test mean loss=88375.34765625\n",
      "fin save.\n",
      "epoch 9416\n",
      "test_train\n",
      "train mean loss=61649.93125\n",
      "test_test\n",
      "test mean loss=88356.2890625\n",
      "fin save.\n",
      "epoch 9417\n",
      "test_train\n",
      "train mean loss=62106.16263020833\n",
      "test_test\n",
      "test mean loss=88339.6796875\n",
      "fin save.\n",
      "epoch 9418\n",
      "test_train\n",
      "train mean loss=60692.708333333336\n",
      "test_test\n",
      "test mean loss=88309.140625\n",
      "fin save.\n",
      "epoch 9419\n",
      "test_train\n",
      "train mean loss=61957.7234375\n",
      "test_test\n",
      "test mean loss=88095.09765625\n",
      "fin save.\n",
      "epoch 9420\n",
      "test_train\n",
      "train mean loss=62515.995833333334\n",
      "test_test\n",
      "test mean loss=88068.51953125\n",
      "fin save.\n",
      "epoch 9421\n",
      "test_train\n",
      "train mean loss=62638.872395833336\n",
      "test_test\n",
      "test mean loss=88152.17578125\n",
      "fin save.\n",
      "epoch 9422\n",
      "test_train\n",
      "train mean loss=61877.26614583333\n",
      "test_test\n",
      "test mean loss=88269.21875\n",
      "fin save.\n",
      "epoch 9423\n",
      "test_train\n",
      "train mean loss=61675.70807291667\n",
      "test_test\n",
      "test mean loss=87922.375\n",
      "fin save.\n",
      "epoch 9424\n",
      "test_train\n",
      "train mean loss=61899.94518229167\n",
      "test_test\n",
      "test mean loss=87936.34765625\n",
      "fin save.\n",
      "epoch 9425\n",
      "test_train\n",
      "train mean loss=61923.816666666666\n",
      "test_test\n",
      "test mean loss=87788.21484375\n",
      "fin save.\n",
      "epoch 9426\n",
      "test_train\n",
      "train mean loss=62381.95950520833\n",
      "test_test\n",
      "test mean loss=87645.4375\n",
      "fin save.\n",
      "epoch 9427\n",
      "test_train\n",
      "train mean loss=62238.08411458333\n",
      "test_test\n",
      "test mean loss=87790.92578125\n",
      "fin save.\n",
      "epoch 9428\n",
      "test_train\n",
      "train mean loss=61553.65963541667\n",
      "test_test\n",
      "test mean loss=87848.2109375\n",
      "fin save.\n",
      "epoch 9429\n",
      "test_train\n",
      "train mean loss=62289.85755208333\n",
      "test_test\n",
      "test mean loss=87765.25390625\n",
      "fin save.\n",
      "epoch 9430\n",
      "test_train\n",
      "train mean loss=62577.13229166667\n",
      "test_test\n",
      "test mean loss=87825.8828125\n",
      "fin save.\n",
      "epoch 9431\n",
      "test_train\n",
      "train mean loss=61888.37838541667\n",
      "test_test\n",
      "test mean loss=87770.17578125\n",
      "fin save.\n",
      "epoch 9432\n",
      "test_train\n",
      "train mean loss=63536.7671875\n",
      "test_test\n",
      "test mean loss=87955.0703125\n",
      "fin save.\n",
      "epoch 9433\n",
      "test_train\n",
      "train mean loss=61710.782552083336\n",
      "test_test\n",
      "test mean loss=88075.9296875\n",
      "fin save.\n",
      "epoch 9434\n",
      "test_train\n",
      "train mean loss=61358.949479166666\n",
      "test_test\n",
      "test mean loss=88006.47265625\n",
      "fin save.\n",
      "epoch 9435\n",
      "test_train\n",
      "train mean loss=62186.613020833334\n",
      "test_test\n",
      "test mean loss=88057.35546875\n",
      "fin save.\n",
      "epoch 9436\n",
      "test_train\n",
      "train mean loss=61480.44427083333\n",
      "test_test\n",
      "test mean loss=88078.046875\n",
      "fin save.\n",
      "epoch 9437\n",
      "test_train\n",
      "train mean loss=61554.844010416666\n",
      "test_test\n",
      "test mean loss=88027.3359375\n",
      "fin save.\n",
      "epoch 9438\n",
      "test_train\n",
      "train mean loss=62173.321875\n",
      "test_test\n",
      "test mean loss=88147.25390625\n",
      "fin save.\n",
      "epoch 9439\n",
      "test_train\n",
      "train mean loss=61284.875\n",
      "test_test\n",
      "test mean loss=88250.453125\n",
      "fin save.\n",
      "epoch 9440\n",
      "test_train\n",
      "train mean loss=62033.101171875\n",
      "test_test\n",
      "test mean loss=88140.9765625\n",
      "fin save.\n",
      "epoch 9441\n",
      "test_train\n",
      "train mean loss=62265.9921875\n",
      "test_test\n",
      "test mean loss=87888.24609375\n",
      "fin save.\n",
      "epoch 9442\n",
      "test_train\n",
      "train mean loss=62931.40924479167\n",
      "test_test\n",
      "test mean loss=87778.0234375\n",
      "fin save.\n",
      "epoch 9443\n",
      "test_train\n",
      "train mean loss=61770.82721354167\n",
      "test_test\n",
      "test mean loss=87990.84765625\n",
      "fin save.\n",
      "epoch 9444\n",
      "test_train\n",
      "train mean loss=62240.9125\n",
      "test_test\n",
      "test mean loss=87900.40234375\n",
      "fin save.\n",
      "epoch 9445\n",
      "test_train\n",
      "train mean loss=62092.888020833336\n",
      "test_test\n",
      "test mean loss=88149.84375\n",
      "fin save.\n",
      "epoch 9446\n",
      "test_train\n",
      "train mean loss=62584.24466145833\n",
      "test_test\n",
      "test mean loss=88063.1328125\n",
      "fin save.\n",
      "epoch 9447\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=63319.28697916667\n",
      "test_test\n",
      "test mean loss=88047.11328125\n",
      "fin save.\n",
      "epoch 9448\n",
      "test_train\n",
      "train mean loss=62360.109114583334\n",
      "test_test\n",
      "test mean loss=87943.75390625\n",
      "fin save.\n",
      "epoch 9449\n",
      "test_train\n",
      "train mean loss=62152.38033854167\n",
      "test_test\n",
      "test mean loss=88046.75390625\n",
      "fin save.\n",
      "epoch 9450\n",
      "test_train\n",
      "train mean loss=61847.90859375\n",
      "test_test\n",
      "test mean loss=88164.484375\n",
      "fin save.\n",
      "epoch 9451\n",
      "test_train\n",
      "train mean loss=61737.15677083333\n",
      "test_test\n",
      "test mean loss=88423.94921875\n",
      "fin save.\n",
      "epoch 9452\n",
      "test_train\n",
      "train mean loss=62015.76419270833\n",
      "test_test\n",
      "test mean loss=88441.96875\n",
      "fin save.\n",
      "epoch 9453\n",
      "test_train\n",
      "train mean loss=62194.64895833333\n",
      "test_test\n",
      "test mean loss=88499.03515625\n",
      "fin save.\n",
      "epoch 9454\n",
      "test_train\n",
      "train mean loss=62522.79973958333\n",
      "test_test\n",
      "test mean loss=88466.56640625\n",
      "fin save.\n",
      "epoch 9455\n",
      "test_train\n",
      "train mean loss=62293.205729166664\n",
      "test_test\n",
      "test mean loss=88519.12890625\n",
      "fin save.\n",
      "epoch 9456\n",
      "test_train\n",
      "train mean loss=63176.486979166664\n",
      "test_test\n",
      "test mean loss=88317.91015625\n",
      "fin save.\n",
      "epoch 9457\n",
      "test_train\n",
      "train mean loss=62328.596875\n",
      "test_test\n",
      "test mean loss=88156.49609375\n",
      "fin save.\n",
      "epoch 9458\n",
      "test_train\n",
      "train mean loss=61492.11276041667\n",
      "test_test\n",
      "test mean loss=87963.41796875\n",
      "fin save.\n",
      "epoch 9459\n",
      "test_train\n",
      "train mean loss=62439.22942708333\n",
      "test_test\n",
      "test mean loss=87998.828125\n",
      "fin save.\n",
      "epoch 9460\n",
      "test_train\n",
      "train mean loss=62515.018359375\n",
      "test_test\n",
      "test mean loss=87948.07421875\n",
      "fin save.\n",
      "epoch 9461\n",
      "test_train\n",
      "train mean loss=62344.7796875\n",
      "test_test\n",
      "test mean loss=88008.7734375\n",
      "fin save.\n",
      "epoch 9462\n",
      "test_train\n",
      "train mean loss=61683.136067708336\n",
      "test_test\n",
      "test mean loss=88056.87109375\n",
      "fin save.\n",
      "epoch 9463\n",
      "test_train\n",
      "train mean loss=62937.539713541664\n",
      "test_test\n",
      "test mean loss=87963.73046875\n",
      "fin save.\n",
      "epoch 9464\n",
      "test_train\n",
      "train mean loss=61486.87356770833\n",
      "test_test\n",
      "test mean loss=88054.51953125\n",
      "fin save.\n",
      "epoch 9465\n",
      "test_train\n",
      "train mean loss=62412.353125\n",
      "test_test\n",
      "test mean loss=88076.0234375\n",
      "fin save.\n",
      "epoch 9466\n",
      "test_train\n",
      "train mean loss=62301.0828125\n",
      "test_test\n",
      "test mean loss=87913.74609375\n",
      "fin save.\n",
      "epoch 9467\n",
      "test_train\n",
      "train mean loss=62174.480208333334\n",
      "test_test\n",
      "test mean loss=88091.79296875\n",
      "fin save.\n",
      "epoch 9468\n",
      "test_train\n",
      "train mean loss=61696.055989583336\n",
      "test_test\n",
      "test mean loss=88148.43359375\n",
      "fin save.\n",
      "epoch 9469\n",
      "test_train\n",
      "train mean loss=62887.16328125\n",
      "test_test\n",
      "test mean loss=87958.4921875\n",
      "fin save.\n",
      "epoch 9470\n",
      "test_train\n",
      "train mean loss=61726.69921875\n",
      "test_test\n",
      "test mean loss=87994.17578125\n",
      "fin save.\n",
      "epoch 9471\n",
      "test_train\n",
      "train mean loss=61775.89140625\n",
      "test_test\n",
      "test mean loss=88057.90625\n",
      "fin save.\n",
      "epoch 9472\n",
      "test_train\n",
      "train mean loss=61821.766015625\n",
      "test_test\n",
      "test mean loss=87710.70703125\n",
      "fin save.\n",
      "epoch 9473\n",
      "test_train\n",
      "train mean loss=62004.03072916667\n",
      "test_test\n",
      "test mean loss=87821.875\n",
      "fin save.\n",
      "epoch 9474\n",
      "test_train\n",
      "train mean loss=62570.628645833334\n",
      "test_test\n",
      "test mean loss=88015.5390625\n",
      "fin save.\n",
      "epoch 9475\n",
      "test_train\n",
      "train mean loss=61895.71302083333\n",
      "test_test\n",
      "test mean loss=87949.6015625\n",
      "fin save.\n",
      "epoch 9476\n",
      "test_train\n",
      "train mean loss=62519.223307291664\n",
      "test_test\n",
      "test mean loss=87846.5234375\n",
      "fin save.\n",
      "epoch 9477\n",
      "test_train\n",
      "train mean loss=62625.90390625\n",
      "test_test\n",
      "test mean loss=87884.4609375\n",
      "fin save.\n",
      "epoch 9478\n",
      "test_train\n",
      "train mean loss=61987.816666666666\n",
      "test_test\n",
      "test mean loss=87900.0859375\n",
      "fin save.\n",
      "epoch 9479\n",
      "test_train\n",
      "train mean loss=61322.866015625\n",
      "test_test\n",
      "test mean loss=87926.5859375\n",
      "fin save.\n",
      "epoch 9480\n",
      "test_train\n",
      "train mean loss=62511.052083333336\n",
      "test_test\n",
      "test mean loss=88011.0390625\n",
      "fin save.\n",
      "epoch 9481\n",
      "test_train\n",
      "train mean loss=62138.32473958333\n",
      "test_test\n",
      "test mean loss=87826.015625\n",
      "fin save.\n",
      "epoch 9482\n",
      "test_train\n",
      "train mean loss=62178.55078125\n",
      "test_test\n",
      "test mean loss=87832.85546875\n",
      "fin save.\n",
      "epoch 9483\n",
      "test_train\n",
      "train mean loss=63057.38776041667\n",
      "test_test\n",
      "test mean loss=87979.0703125\n",
      "fin save.\n",
      "epoch 9484\n",
      "test_train\n",
      "train mean loss=62245.72942708333\n",
      "test_test\n",
      "test mean loss=87912.3125\n",
      "fin save.\n",
      "epoch 9485\n",
      "test_train\n",
      "train mean loss=62136.650130208334\n",
      "test_test\n",
      "test mean loss=87894.109375\n",
      "fin save.\n",
      "epoch 9486\n",
      "test_train\n",
      "train mean loss=61283.566145833334\n",
      "test_test\n",
      "test mean loss=87925.8671875\n",
      "fin save.\n",
      "epoch 9487\n",
      "test_train\n",
      "train mean loss=62166.711197916666\n",
      "test_test\n",
      "test mean loss=88275.3515625\n",
      "fin save.\n",
      "epoch 9488\n",
      "test_train\n",
      "train mean loss=62316.6\n",
      "test_test\n",
      "test mean loss=88074.0390625\n",
      "fin save.\n",
      "epoch 9489\n",
      "test_train\n",
      "train mean loss=61558.033854166664\n",
      "test_test\n",
      "test mean loss=88205.890625\n",
      "fin save.\n",
      "epoch 9490\n",
      "test_train\n",
      "train mean loss=63048.646875\n",
      "test_test\n",
      "test mean loss=88328.96484375\n",
      "fin save.\n",
      "epoch 9491\n",
      "test_train\n",
      "train mean loss=61751.98151041667\n",
      "test_test\n",
      "test mean loss=88321.28515625\n",
      "fin save.\n",
      "epoch 9492\n",
      "test_train\n",
      "train mean loss=61552.972265625\n",
      "test_test\n",
      "test mean loss=88135.48828125\n",
      "fin save.\n",
      "epoch 9493\n",
      "test_train\n",
      "train mean loss=61840.728125\n",
      "test_test\n",
      "test mean loss=88193.61328125\n",
      "fin save.\n",
      "epoch 9494\n",
      "test_train\n",
      "train mean loss=62038.290364583336\n",
      "test_test\n",
      "test mean loss=88257.6171875\n",
      "fin save.\n",
      "epoch 9495\n",
      "test_train\n",
      "train mean loss=61843.46041666667\n",
      "test_test\n",
      "test mean loss=88192.34375\n",
      "fin save.\n",
      "epoch 9496\n",
      "test_train\n",
      "train mean loss=62140.64244791667\n",
      "test_test\n",
      "test mean loss=88157.6484375\n",
      "fin save.\n",
      "epoch 9497\n",
      "test_train\n",
      "train mean loss=62066.60494791667\n",
      "test_test\n",
      "test mean loss=88193.578125\n",
      "fin save.\n",
      "epoch 9498\n",
      "test_train\n",
      "train mean loss=61146.80703125\n",
      "test_test\n",
      "test mean loss=88112.49609375\n",
      "fin save.\n",
      "epoch 9499\n",
      "test_train\n",
      "train mean loss=62587.97057291667\n",
      "test_test\n",
      "test mean loss=88224.67578125\n",
      "fin save.\n",
      "epoch 9500\n",
      "test_train\n",
      "train mean loss=61809.675\n",
      "test_test\n",
      "test mean loss=88275.50390625\n",
      "fin save.\n",
      "epoch 9501\n",
      "test_train\n",
      "train mean loss=62254.019791666666\n",
      "test_test\n",
      "test mean loss=88330.94921875\n",
      "fin save.\n",
      "epoch 9502\n",
      "test_train\n",
      "train mean loss=60999.40963541667\n",
      "test_test\n",
      "test mean loss=88232.71484375\n",
      "fin save.\n",
      "epoch 9503\n",
      "test_train\n",
      "train mean loss=62076.68958333333\n",
      "test_test\n",
      "test mean loss=88390.87109375\n",
      "fin save.\n",
      "epoch 9504\n",
      "test_train\n",
      "train mean loss=62365.76028645833\n",
      "test_test\n",
      "test mean loss=88411.91796875\n",
      "fin save.\n",
      "epoch 9505\n",
      "test_train\n",
      "train mean loss=62078.53229166667\n",
      "test_test\n",
      "test mean loss=88413.953125\n",
      "fin save.\n",
      "epoch 9506\n",
      "test_train\n",
      "train mean loss=63017.782552083336\n",
      "test_test\n",
      "test mean loss=88403.65234375\n",
      "fin save.\n",
      "epoch 9507\n",
      "test_train\n",
      "train mean loss=61869.97734375\n",
      "test_test\n",
      "test mean loss=88396.109375\n",
      "fin save.\n",
      "epoch 9508\n",
      "test_train\n",
      "train mean loss=63130.940104166664\n",
      "test_test\n",
      "test mean loss=88518.3359375\n",
      "fin save.\n",
      "epoch 9509\n",
      "test_train\n",
      "train mean loss=61882.804427083334\n",
      "test_test\n",
      "test mean loss=88530.22265625\n",
      "fin save.\n",
      "epoch 9510\n",
      "test_train\n",
      "train mean loss=62059.72083333333\n",
      "test_test\n",
      "test mean loss=88375.48828125\n",
      "fin save.\n",
      "epoch 9511\n",
      "test_train\n",
      "train mean loss=62026.04401041667\n",
      "test_test\n",
      "test mean loss=88421.6640625\n",
      "fin save.\n",
      "epoch 9512\n",
      "test_train\n",
      "train mean loss=61412.69296875\n",
      "test_test\n",
      "test mean loss=88451.3515625\n",
      "fin save.\n",
      "epoch 9513\n",
      "test_train\n",
      "train mean loss=61637.57044270833\n",
      "test_test\n",
      "test mean loss=88335.30078125\n",
      "fin save.\n",
      "epoch 9514\n",
      "test_train\n",
      "train mean loss=62076.14401041667\n",
      "test_test\n",
      "test mean loss=88382.875\n",
      "fin save.\n",
      "epoch 9515\n",
      "test_train\n",
      "train mean loss=62536.915625\n",
      "test_test\n",
      "test mean loss=88394.65625\n",
      "fin save.\n",
      "epoch 9516\n",
      "test_train\n",
      "train mean loss=62035.48528645833\n",
      "test_test\n",
      "test mean loss=88544.59765625\n",
      "fin save.\n",
      "epoch 9517\n",
      "test_train\n",
      "train mean loss=62053.32760416667\n",
      "test_test\n",
      "test mean loss=88529.58984375\n",
      "fin save.\n",
      "epoch 9518\n",
      "test_train\n",
      "train mean loss=61829.37838541667\n",
      "test_test\n",
      "test mean loss=88378.17578125\n",
      "fin save.\n",
      "epoch 9519\n",
      "test_train\n",
      "train mean loss=62810.95390625\n",
      "test_test\n",
      "test mean loss=88376.26171875\n",
      "fin save.\n",
      "epoch 9520\n",
      "test_train\n",
      "train mean loss=61928.794270833336\n",
      "test_test\n",
      "test mean loss=88407.60546875\n",
      "fin save.\n",
      "epoch 9521\n",
      "test_train\n",
      "train mean loss=62480.2015625\n",
      "test_test\n",
      "test mean loss=88462.2890625\n",
      "fin save.\n",
      "epoch 9522\n",
      "test_train\n",
      "train mean loss=61448.6171875\n",
      "test_test\n",
      "test mean loss=88418.1015625\n",
      "fin save.\n",
      "epoch 9523\n",
      "test_train\n",
      "train mean loss=62197.77434895833\n",
      "test_test\n",
      "test mean loss=88323.7421875\n",
      "fin save.\n",
      "epoch 9524\n",
      "test_train\n",
      "train mean loss=62096.250260416666\n",
      "test_test\n",
      "test mean loss=88506.59765625\n",
      "fin save.\n",
      "epoch 9525\n",
      "test_train\n",
      "train mean loss=62956.323958333334\n",
      "test_test\n",
      "test mean loss=88321.8671875\n",
      "fin save.\n",
      "epoch 9526\n",
      "test_train\n",
      "train mean loss=62746.876692708334\n",
      "test_test\n",
      "test mean loss=88428.16796875\n",
      "fin save.\n",
      "epoch 9527\n",
      "test_train\n",
      "train mean loss=62033.1625\n",
      "test_test\n",
      "test mean loss=88258.22265625\n",
      "fin save.\n",
      "epoch 9528\n",
      "test_train\n",
      "train mean loss=62753.82526041667\n",
      "test_test\n",
      "test mean loss=88365.9296875\n",
      "fin save.\n",
      "epoch 9529\n",
      "test_train\n",
      "train mean loss=61698.68346354167\n",
      "test_test\n",
      "test mean loss=88263.84765625\n",
      "fin save.\n",
      "epoch 9530\n",
      "test_train\n",
      "train mean loss=61303.31067708333\n",
      "test_test\n",
      "test mean loss=88302.0234375\n",
      "fin save.\n",
      "epoch 9531\n",
      "test_train\n",
      "train mean loss=62181.20403645833\n",
      "test_test\n",
      "test mean loss=88299.5703125\n",
      "fin save.\n",
      "epoch 9532\n",
      "test_train\n",
      "train mean loss=61500.69622395833\n",
      "test_test\n",
      "test mean loss=88291.625\n",
      "fin save.\n",
      "epoch 9533\n",
      "test_train\n",
      "train mean loss=62227.39739583333\n",
      "test_test\n",
      "test mean loss=88775.94921875\n",
      "fin save.\n",
      "epoch 9534\n",
      "test_train\n",
      "train mean loss=62814.47955729167\n",
      "test_test\n",
      "test mean loss=88658.91015625\n",
      "fin save.\n",
      "epoch 9535\n",
      "test_train\n",
      "train mean loss=62249.90247395833\n",
      "test_test\n",
      "test mean loss=88641.60546875\n",
      "fin save.\n",
      "epoch 9536\n",
      "test_train\n",
      "train mean loss=62644.823958333334\n",
      "test_test\n",
      "test mean loss=88583.87109375\n",
      "fin save.\n",
      "epoch 9537\n",
      "test_train\n",
      "train mean loss=61767.16875\n",
      "test_test\n",
      "test mean loss=88637.85546875\n",
      "fin save.\n",
      "epoch 9538\n",
      "test_train\n",
      "train mean loss=61536.99361979167\n",
      "test_test\n",
      "test mean loss=88765.00390625\n",
      "fin save.\n",
      "epoch 9539\n",
      "test_train\n",
      "train mean loss=61445.410807291664\n",
      "test_test\n",
      "test mean loss=88857.87890625\n",
      "fin save.\n",
      "epoch 9540\n",
      "test_train\n",
      "train mean loss=62004.44869791667\n",
      "test_test\n",
      "test mean loss=88938.9375\n",
      "fin save.\n",
      "epoch 9541\n",
      "test_train\n",
      "train mean loss=62483.45234375\n",
      "test_test\n",
      "test mean loss=88840.234375\n",
      "fin save.\n",
      "epoch 9542\n",
      "test_train\n",
      "train mean loss=61386.33255208333\n",
      "test_test\n",
      "test mean loss=88544.47265625\n",
      "fin save.\n",
      "epoch 9543\n",
      "test_train\n",
      "train mean loss=62226.102734375\n",
      "test_test\n",
      "test mean loss=88566.85546875\n",
      "fin save.\n",
      "epoch 9544\n",
      "test_train\n",
      "train mean loss=62254.221354166664\n",
      "test_test\n",
      "test mean loss=88430.0390625\n",
      "fin save.\n",
      "epoch 9545\n",
      "test_train\n",
      "train mean loss=62249.835677083334\n",
      "test_test\n",
      "test mean loss=88691.32421875\n",
      "fin save.\n",
      "epoch 9546\n",
      "test_train\n",
      "train mean loss=62665.753125\n",
      "test_test\n",
      "test mean loss=88712.1171875\n",
      "fin save.\n",
      "epoch 9547\n",
      "test_train\n",
      "train mean loss=62875.4125\n",
      "test_test\n",
      "test mean loss=88597.65625\n",
      "fin save.\n",
      "epoch 9548\n",
      "test_train\n",
      "train mean loss=62942.87109375\n",
      "test_test\n",
      "test mean loss=88554.3125\n",
      "fin save.\n",
      "epoch 9549\n",
      "test_train\n",
      "train mean loss=61498.882552083334\n",
      "test_test\n",
      "test mean loss=88523.96875\n",
      "fin save.\n",
      "epoch 9550\n",
      "test_train\n",
      "train mean loss=61863.761458333334\n",
      "test_test\n",
      "test mean loss=88300.75390625\n",
      "fin save.\n",
      "epoch 9551\n",
      "test_train\n",
      "train mean loss=62470.77591145833\n",
      "test_test\n",
      "test mean loss=88123.5234375\n",
      "fin save.\n",
      "epoch 9552\n",
      "test_train\n",
      "train mean loss=61877.372395833336\n",
      "test_test\n",
      "test mean loss=88085.765625\n",
      "fin save.\n",
      "epoch 9553\n",
      "test_train\n",
      "train mean loss=62239.13098958333\n",
      "test_test\n",
      "test mean loss=88187.68359375\n",
      "fin save.\n",
      "epoch 9554\n",
      "test_train\n",
      "train mean loss=61224.7203125\n",
      "test_test\n",
      "test mean loss=87823.23828125\n",
      "fin save.\n",
      "epoch 9555\n",
      "test_train\n",
      "train mean loss=62387.23828125\n",
      "test_test\n",
      "test mean loss=87869.48046875\n",
      "fin save.\n",
      "epoch 9556\n",
      "test_train\n",
      "train mean loss=62583.899739583336\n",
      "test_test\n",
      "test mean loss=88097.09375\n",
      "fin save.\n",
      "epoch 9557\n",
      "test_train\n",
      "train mean loss=61843.59661458333\n",
      "test_test\n",
      "test mean loss=88373.74609375\n",
      "fin save.\n",
      "epoch 9558\n",
      "test_train\n",
      "train mean loss=61619.69583333333\n",
      "test_test\n",
      "test mean loss=88112.28125\n",
      "fin save.\n",
      "epoch 9559\n",
      "test_train\n",
      "train mean loss=62625.66979166667\n",
      "test_test\n",
      "test mean loss=88540.703125\n",
      "fin save.\n",
      "epoch 9560\n",
      "test_train\n",
      "train mean loss=61424.102864583336\n",
      "test_test\n",
      "test mean loss=88443.63671875\n",
      "fin save.\n",
      "epoch 9561\n",
      "test_train\n",
      "train mean loss=62526.44244791667\n",
      "test_test\n",
      "test mean loss=88394.28515625\n",
      "fin save.\n",
      "epoch 9562\n",
      "test_train\n",
      "train mean loss=61792.92109375\n",
      "test_test\n",
      "test mean loss=88283.0546875\n",
      "fin save.\n",
      "epoch 9563\n",
      "test_train\n",
      "train mean loss=62654.19479166667\n",
      "test_test\n",
      "test mean loss=88457.015625\n",
      "fin save.\n",
      "epoch 9564\n",
      "test_train\n",
      "train mean loss=62424.06263020833\n",
      "test_test\n",
      "test mean loss=88192.03125\n",
      "fin save.\n",
      "epoch 9565\n",
      "test_train\n",
      "train mean loss=63113.400390625\n",
      "test_test\n",
      "test mean loss=88389.17578125\n",
      "fin save.\n",
      "epoch 9566\n",
      "test_train\n",
      "train mean loss=61388.61419270833\n",
      "test_test\n",
      "test mean loss=88321.12890625\n",
      "fin save.\n",
      "epoch 9567\n",
      "test_train\n",
      "train mean loss=61401.46979166667\n",
      "test_test\n",
      "test mean loss=88200.99609375\n",
      "fin save.\n",
      "epoch 9568\n",
      "test_train\n",
      "train mean loss=62533.01953125\n",
      "test_test\n",
      "test mean loss=88260.8203125\n",
      "fin save.\n",
      "epoch 9569\n",
      "test_train\n",
      "train mean loss=62554.654296875\n",
      "test_test\n",
      "test mean loss=88278.27734375\n",
      "fin save.\n",
      "epoch 9570\n",
      "test_train\n",
      "train mean loss=63852.18255208333\n",
      "test_test\n",
      "test mean loss=88302.8828125\n",
      "fin save.\n",
      "epoch 9571\n",
      "test_train\n",
      "train mean loss=62761.68932291667\n",
      "test_test\n",
      "test mean loss=88260.671875\n",
      "fin save.\n",
      "epoch 9572\n",
      "test_train\n",
      "train mean loss=63199.99036458333\n",
      "test_test\n",
      "test mean loss=88199.33984375\n",
      "fin save.\n",
      "epoch 9573\n",
      "test_train\n",
      "train mean loss=62002.60494791667\n",
      "test_test\n",
      "test mean loss=88338.609375\n",
      "fin save.\n",
      "epoch 9574\n",
      "test_train\n",
      "train mean loss=61612.623697916664\n",
      "test_test\n",
      "test mean loss=88411.2578125\n",
      "fin save.\n",
      "epoch 9575\n",
      "test_train\n",
      "train mean loss=61814.14765625\n",
      "test_test\n",
      "test mean loss=88411.69921875\n",
      "fin save.\n",
      "epoch 9576\n",
      "test_train\n",
      "train mean loss=62117.96432291667\n",
      "test_test\n",
      "test mean loss=88081.0703125\n",
      "fin save.\n",
      "epoch 9577\n",
      "test_train\n",
      "train mean loss=62471.49010416667\n",
      "test_test\n",
      "test mean loss=87892.546875\n",
      "fin save.\n",
      "epoch 9578\n",
      "test_train\n",
      "train mean loss=62750.022135416664\n",
      "test_test\n",
      "test mean loss=87937.0703125\n",
      "fin save.\n",
      "epoch 9579\n",
      "test_train\n",
      "train mean loss=62227.14557291667\n",
      "test_test\n",
      "test mean loss=88069.31640625\n",
      "fin save.\n",
      "epoch 9580\n",
      "test_train\n",
      "train mean loss=61652.84908854167\n",
      "test_test\n",
      "test mean loss=88107.16796875\n",
      "fin save.\n",
      "epoch 9581\n",
      "test_train\n",
      "train mean loss=61483.29088541667\n",
      "test_test\n",
      "test mean loss=88083.77734375\n",
      "fin save.\n",
      "epoch 9582\n",
      "test_train\n",
      "train mean loss=61578.418229166666\n",
      "test_test\n",
      "test mean loss=88199.640625\n",
      "fin save.\n",
      "epoch 9583\n",
      "test_train\n",
      "train mean loss=62105.678385416664\n",
      "test_test\n",
      "test mean loss=88063.30078125\n",
      "fin save.\n",
      "epoch 9584\n",
      "test_train\n",
      "train mean loss=62556.745442708336\n",
      "test_test\n",
      "test mean loss=87975.07421875\n",
      "fin save.\n",
      "epoch 9585\n",
      "test_train\n",
      "train mean loss=61947.72473958333\n",
      "test_test\n",
      "test mean loss=88171.66796875\n",
      "fin save.\n",
      "epoch 9586\n",
      "test_train\n",
      "train mean loss=62308.01666666667\n",
      "test_test\n",
      "test mean loss=87458.90234375\n",
      "fin save.\n",
      "epoch 9587\n",
      "test_train\n",
      "train mean loss=62429.9984375\n",
      "test_test\n",
      "test mean loss=87709.6484375\n",
      "fin save.\n",
      "epoch 9588\n",
      "test_train\n",
      "train mean loss=62285.41640625\n",
      "test_test\n",
      "test mean loss=88022.328125\n",
      "fin save.\n",
      "epoch 9589\n",
      "test_train\n",
      "train mean loss=61415.50690104167\n",
      "test_test\n",
      "test mean loss=87728.91015625\n",
      "fin save.\n",
      "epoch 9590\n",
      "test_train\n",
      "train mean loss=61318.558333333334\n",
      "test_test\n",
      "test mean loss=87763.6796875\n",
      "fin save.\n",
      "epoch 9591\n",
      "test_train\n",
      "train mean loss=62285.08880208333\n",
      "test_test\n",
      "test mean loss=87667.03515625\n",
      "fin save.\n",
      "epoch 9592\n",
      "test_train\n",
      "train mean loss=62550.6515625\n",
      "test_test\n",
      "test mean loss=87825.1484375\n",
      "fin save.\n",
      "epoch 9593\n",
      "test_train\n",
      "train mean loss=62934.530078125\n",
      "test_test\n",
      "test mean loss=87587.47265625\n",
      "fin save.\n",
      "epoch 9594\n",
      "test_train\n",
      "train mean loss=62185.97578125\n",
      "test_test\n",
      "test mean loss=87790.54296875\n",
      "fin save.\n",
      "epoch 9595\n",
      "test_train\n",
      "train mean loss=62579.63619791667\n",
      "test_test\n",
      "test mean loss=87847.375\n",
      "fin save.\n",
      "epoch 9596\n",
      "test_train\n",
      "train mean loss=62357.70755208333\n",
      "test_test\n",
      "test mean loss=87989.4140625\n",
      "fin save.\n",
      "epoch 9597\n",
      "test_train\n",
      "train mean loss=62480.39466145833\n",
      "test_test\n",
      "test mean loss=87752.71484375\n",
      "fin save.\n",
      "epoch 9598\n",
      "test_train\n",
      "train mean loss=62413.136458333334\n",
      "test_test\n",
      "test mean loss=87693.2734375\n",
      "fin save.\n",
      "epoch 9599\n",
      "test_train\n",
      "train mean loss=62495.970442708334\n",
      "test_test\n",
      "test mean loss=87643.4609375\n",
      "fin save.\n",
      "epoch 9600\n",
      "test_train\n",
      "train mean loss=62009.59479166667\n",
      "test_test\n",
      "test mean loss=87714.9921875\n",
      "fin save.\n",
      "epoch 9601\n",
      "test_train\n",
      "train mean loss=63276.8484375\n",
      "test_test\n",
      "test mean loss=87763.03125\n",
      "fin save.\n",
      "epoch 9602\n",
      "test_train\n",
      "train mean loss=62162.90130208333\n",
      "test_test\n",
      "test mean loss=87573.0390625\n",
      "fin save.\n",
      "epoch 9603\n",
      "test_train\n",
      "train mean loss=61712.81106770833\n",
      "test_test\n",
      "test mean loss=87635.32421875\n",
      "fin save.\n",
      "epoch 9604\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_train\n",
      "train mean loss=61726.12317708333\n",
      "test_test\n",
      "test mean loss=87792.81640625\n",
      "fin save.\n",
      "epoch 9605\n",
      "test_train\n",
      "train mean loss=62471.01328125\n",
      "test_test\n",
      "test mean loss=87782.08984375\n",
      "fin save.\n",
      "epoch 9606\n",
      "test_train\n",
      "train mean loss=61816.02591145833\n",
      "test_test\n",
      "test mean loss=87535.6015625\n",
      "fin save.\n",
      "epoch 9607\n",
      "test_train\n",
      "train mean loss=61815.05416666667\n",
      "test_test\n",
      "test mean loss=87764.84375\n",
      "fin save.\n",
      "epoch 9608\n",
      "test_train\n",
      "train mean loss=62753.459375\n",
      "test_test\n",
      "test mean loss=87759.4609375\n",
      "fin save.\n",
      "epoch 9609\n",
      "test_train\n",
      "train mean loss=62283.434895833336\n",
      "test_test\n",
      "test mean loss=87381.1015625\n",
      "fin save.\n",
      "epoch 9610\n",
      "test_train\n",
      "train mean loss=63122.48151041667\n",
      "test_test\n",
      "test mean loss=87676.921875\n",
      "fin save.\n",
      "epoch 9611\n",
      "test_train\n",
      "train mean loss=61895.59713541667\n",
      "test_test\n",
      "test mean loss=87908.38671875\n",
      "fin save.\n",
      "epoch 9612\n",
      "test_train\n",
      "train mean loss=62342.10442708333\n",
      "test_test\n",
      "test mean loss=87895.24609375\n",
      "fin save.\n",
      "epoch 9613\n",
      "test_train\n",
      "train mean loss=62604.23229166667\n",
      "test_test\n",
      "test mean loss=87896.6484375\n",
      "fin save.\n",
      "epoch 9614\n",
      "test_train\n",
      "train mean loss=62623.589192708336\n",
      "test_test\n",
      "test mean loss=87773.55859375\n",
      "fin save.\n",
      "epoch 9615\n",
      "test_train\n",
      "train mean loss=62163.85078125\n",
      "test_test\n",
      "test mean loss=87670.18359375\n",
      "fin save.\n",
      "epoch 9616\n",
      "test_train\n",
      "train mean loss=62398.492447916666\n",
      "test_test\n",
      "test mean loss=87739.7734375\n",
      "fin save.\n",
      "epoch 9617\n",
      "test_train\n",
      "train mean loss=62186.54765625\n",
      "test_test\n",
      "test mean loss=87729.52734375\n",
      "fin save.\n",
      "epoch 9618\n",
      "test_train\n",
      "train mean loss=61335.62265625\n",
      "test_test\n",
      "test mean loss=87416.953125\n",
      "fin save.\n",
      "epoch 9619\n",
      "test_train\n",
      "train mean loss=62913.003125\n",
      "test_test\n",
      "test mean loss=87538.98046875\n",
      "fin save.\n",
      "epoch 9620\n",
      "test_train\n",
      "train mean loss=62622.178125\n",
      "test_test\n",
      "test mean loss=87620.59765625\n",
      "fin save.\n",
      "epoch 9621\n",
      "test_train\n",
      "train mean loss=62776.62421875\n",
      "test_test\n",
      "test mean loss=87696.82421875\n",
      "fin save.\n",
      "epoch 9622\n",
      "test_train\n",
      "train mean loss=62216.385416666664\n",
      "test_test\n",
      "test mean loss=87743.46484375\n",
      "fin save.\n",
      "epoch 9623\n",
      "test_train\n",
      "train mean loss=61981.99817708333\n",
      "test_test\n",
      "test mean loss=87910.34375\n",
      "fin save.\n",
      "epoch 9624\n",
      "test_train\n",
      "train mean loss=62521.29244791667\n",
      "test_test\n",
      "test mean loss=87937.7109375\n",
      "fin save.\n",
      "epoch 9625\n",
      "test_train\n",
      "train mean loss=63905.934895833336\n",
      "test_test\n",
      "test mean loss=87620.5703125\n",
      "fin save.\n",
      "epoch 9626\n",
      "test_train\n",
      "train mean loss=61884.62395833333\n",
      "test_test\n",
      "test mean loss=87752.99609375\n",
      "fin save.\n",
      "epoch 9627\n",
      "test_train\n",
      "train mean loss=61894.064453125\n",
      "test_test\n",
      "test mean loss=87578.62109375\n",
      "fin save.\n",
      "epoch 9628\n",
      "test_train\n",
      "train mean loss=62393.21015625\n",
      "test_test\n",
      "test mean loss=87601.10546875\n",
      "fin save.\n",
      "epoch 9629\n",
      "test_train\n",
      "train mean loss=63305.851822916666\n",
      "test_test\n",
      "test mean loss=87574.98046875\n",
      "fin save.\n",
      "epoch 9630\n",
      "test_train\n",
      "train mean loss=75972.03255208333\n",
      "test_test\n",
      "test mean loss=96787.67578125\n",
      "fin save.\n",
      "epoch 9631\n",
      "test_train\n",
      "train mean loss=71028.24010416666\n",
      "test_test\n",
      "test mean loss=92050.85546875\n",
      "fin save.\n",
      "epoch 9632\n",
      "test_train\n",
      "train mean loss=68597.17734375\n",
      "test_test\n",
      "test mean loss=90584.765625\n",
      "fin save.\n",
      "epoch 9633\n",
      "test_train\n",
      "train mean loss=67295.0640625\n",
      "test_test\n",
      "test mean loss=90689.28125\n",
      "fin save.\n",
      "epoch 9634\n",
      "test_train\n",
      "train mean loss=67939.76848958334\n",
      "test_test\n",
      "test mean loss=90849.390625\n",
      "fin save.\n",
      "epoch 9635\n",
      "test_train\n",
      "train mean loss=66841.15338541666\n",
      "test_test\n",
      "test mean loss=91002.3125\n",
      "fin save.\n",
      "epoch 9636\n",
      "test_train\n",
      "train mean loss=67496.75182291666\n",
      "test_test\n",
      "test mean loss=91687.8671875\n",
      "fin save.\n",
      "epoch 9637\n",
      "test_train\n",
      "train mean loss=65790.7859375\n",
      "test_test\n",
      "test mean loss=91098.671875\n",
      "fin save.\n",
      "epoch 9638\n",
      "test_train\n",
      "train mean loss=65507.20989583333\n",
      "test_test\n",
      "test mean loss=90985.35546875\n",
      "fin save.\n",
      "epoch 9639\n",
      "test_train\n",
      "train mean loss=65043.71927083333\n",
      "test_test\n",
      "test mean loss=90528.8125\n",
      "fin save.\n",
      "epoch 9640\n",
      "test_train\n",
      "train mean loss=64711.8734375\n",
      "test_test\n",
      "test mean loss=90603.5625\n",
      "fin save.\n",
      "epoch 9641\n",
      "test_train\n",
      "train mean loss=64874.86484375\n",
      "test_test\n",
      "test mean loss=91368.35546875\n",
      "fin save.\n",
      "epoch 9642\n",
      "test_train\n",
      "train mean loss=64671.87213541667\n",
      "test_test\n",
      "test mean loss=91473.58203125\n",
      "fin save.\n",
      "epoch 9643\n",
      "test_train\n",
      "train mean loss=63458.553385416664\n",
      "test_test\n",
      "test mean loss=91515.68359375\n",
      "fin save.\n",
      "epoch 9644\n",
      "test_train\n",
      "train mean loss=64834.6734375\n",
      "test_test\n",
      "test mean loss=91959.265625\n",
      "fin save.\n",
      "epoch 9645\n",
      "test_train\n",
      "train mean loss=64065.16614583333\n",
      "test_test\n",
      "test mean loss=91564.5703125\n",
      "fin save.\n",
      "epoch 9646\n",
      "test_train\n",
      "train mean loss=64309.68671875\n",
      "test_test\n",
      "test mean loss=91603.05859375\n",
      "fin save.\n",
      "epoch 9647\n",
      "test_train\n",
      "train mean loss=63622.53828125\n",
      "test_test\n",
      "test mean loss=91563.67578125\n",
      "fin save.\n",
      "epoch 9648\n",
      "test_train\n",
      "train mean loss=63847.67174479167\n",
      "test_test\n",
      "test mean loss=91126.64453125\n",
      "fin save.\n",
      "epoch 9649\n",
      "test_train\n",
      "train mean loss=64176.125260416666\n",
      "test_test\n",
      "test mean loss=91253.56640625\n",
      "fin save.\n",
      "epoch 9650\n",
      "test_train\n",
      "train mean loss=63914.707291666666\n",
      "test_test\n",
      "test mean loss=91332.3125\n",
      "fin save.\n",
      "epoch 9651\n",
      "test_train\n",
      "train mean loss=63968.43984375\n",
      "test_test\n",
      "test mean loss=91036.4921875\n",
      "fin save.\n",
      "epoch 9652\n",
      "test_train\n",
      "train mean loss=63565.17239583333\n",
      "test_test\n",
      "test mean loss=90791.5546875\n",
      "fin save.\n",
      "epoch 9653\n",
      "test_train\n",
      "train mean loss=63895.09322916667\n",
      "test_test\n",
      "test mean loss=91007.68359375\n",
      "fin save.\n",
      "epoch 9654\n",
      "test_train\n",
      "train mean loss=63451.295703125\n",
      "test_test\n",
      "test mean loss=91134.0859375\n",
      "fin save.\n",
      "epoch 9655\n",
      "test_train\n",
      "train mean loss=63274.59296875\n",
      "test_test\n",
      "test mean loss=90700.63671875\n",
      "fin save.\n",
      "epoch 9656\n",
      "test_train\n",
      "train mean loss=64192.58307291667\n",
      "test_test\n",
      "test mean loss=90711.875\n",
      "fin save.\n",
      "epoch 9657\n",
      "test_train\n",
      "train mean loss=63647.03515625\n",
      "test_test\n",
      "test mean loss=90575.98828125\n",
      "fin save.\n",
      "epoch 9658\n",
      "test_train\n",
      "train mean loss=63423.40703125\n",
      "test_test\n",
      "test mean loss=90587.140625\n",
      "fin save.\n",
      "epoch 9659\n",
      "test_train\n",
      "train mean loss=62825.833333333336\n",
      "test_test\n",
      "test mean loss=90403.078125\n",
      "fin save.\n",
      "epoch 9660\n",
      "test_train\n",
      "train mean loss=63399.025390625\n",
      "test_test\n",
      "test mean loss=89961.69921875\n",
      "fin save.\n",
      "epoch 9661\n",
      "test_train\n",
      "train mean loss=63677.021875\n",
      "test_test\n",
      "test mean loss=89980.484375\n",
      "fin save.\n",
      "epoch 9662\n",
      "test_train\n",
      "train mean loss=64421.00885416667\n",
      "test_test\n",
      "test mean loss=89934.234375\n",
      "fin save.\n",
      "epoch 9663\n",
      "test_train\n",
      "train mean loss=63432.785546875\n",
      "test_test\n",
      "test mean loss=90133.5859375\n",
      "fin save.\n",
      "epoch 9664\n",
      "test_train\n",
      "train mean loss=64152.93541666667\n",
      "test_test\n",
      "test mean loss=90180.3125\n",
      "fin save.\n",
      "epoch 9665\n",
      "test_train\n",
      "train mean loss=63803.14375\n",
      "test_test\n",
      "test mean loss=90143.68359375\n",
      "fin save.\n",
      "epoch 9666\n",
      "test_train\n",
      "train mean loss=63068.81940104167\n",
      "test_test\n",
      "test mean loss=90027.390625\n",
      "fin save.\n",
      "epoch 9667\n",
      "test_train\n",
      "train mean loss=63735.77838541667\n",
      "test_test\n",
      "test mean loss=90226.92578125\n",
      "fin save.\n",
      "epoch 9668\n",
      "test_train\n",
      "train mean loss=64057.153515625\n",
      "test_test\n",
      "test mean loss=89725.9296875\n",
      "fin save.\n",
      "epoch 9669\n",
      "test_train\n",
      "train mean loss=63200.70026041667\n",
      "test_test\n",
      "test mean loss=89676.9765625\n",
      "fin save.\n",
      "epoch 9670\n",
      "test_train\n",
      "train mean loss=63200.48059895833\n",
      "test_test\n",
      "test mean loss=89499.9921875\n",
      "fin save.\n",
      "epoch 9671\n",
      "test_train\n",
      "train mean loss=63152.11966145833\n",
      "test_test\n",
      "test mean loss=89396.62890625\n",
      "fin save.\n",
      "epoch 9672\n",
      "test_train\n",
      "train mean loss=63167.079427083336\n",
      "test_test\n",
      "test mean loss=89169.55078125\n",
      "fin save.\n",
      "epoch 9673\n",
      "test_train\n",
      "train mean loss=62703.74986979167\n",
      "test_test\n",
      "test mean loss=90027.47265625\n",
      "fin save.\n",
      "epoch 9674\n",
      "test_train\n",
      "train mean loss=62967.959635416664\n",
      "test_test\n",
      "test mean loss=89617.29296875\n",
      "fin save.\n",
      "epoch 9675\n",
      "test_train\n",
      "train mean loss=61351.259375\n",
      "test_test\n",
      "test mean loss=90001.58984375\n",
      "fin save.\n",
      "epoch 9676\n",
      "test_train\n",
      "train mean loss=63185.028125\n",
      "test_test\n",
      "test mean loss=89951.4765625\n",
      "fin save.\n",
      "epoch 9677\n",
      "test_train\n",
      "train mean loss=62781.540364583336\n",
      "test_test\n",
      "test mean loss=89840.0078125\n",
      "fin save.\n",
      "epoch 9678\n",
      "test_train\n",
      "train mean loss=62979.03958333333\n",
      "test_test\n",
      "test mean loss=90253.5546875\n",
      "fin save.\n",
      "epoch 9679\n",
      "test_train\n",
      "train mean loss=63066.20130208333\n",
      "test_test\n",
      "test mean loss=90039.48046875\n",
      "fin save.\n",
      "epoch 9680\n",
      "test_train\n",
      "train mean loss=63204.749739583334\n",
      "test_test\n",
      "test mean loss=89755.2890625\n",
      "fin save.\n",
      "epoch 9681\n",
      "test_train\n",
      "train mean loss=63352.74270833333\n",
      "test_test\n",
      "test mean loss=89936.546875\n",
      "fin save.\n",
      "epoch 9682\n",
      "test_train\n",
      "train mean loss=62745.12682291667\n",
      "test_test\n",
      "test mean loss=89933.9453125\n",
      "fin save.\n",
      "epoch 9683\n",
      "test_train\n",
      "train mean loss=62648.234114583334\n",
      "test_test\n",
      "test mean loss=90085.73828125\n",
      "fin save.\n",
      "epoch 9684\n",
      "test_train\n",
      "train mean loss=62380.28125\n",
      "test_test\n",
      "test mean loss=90172.00390625\n",
      "fin save.\n",
      "epoch 9685\n",
      "test_train\n",
      "train mean loss=62767.274739583336\n",
      "test_test\n",
      "test mean loss=89939.9765625\n",
      "fin save.\n",
      "epoch 9686\n",
      "test_train\n",
      "train mean loss=62465.85442708333\n",
      "test_test\n",
      "test mean loss=89941.21484375\n",
      "fin save.\n",
      "epoch 9687\n",
      "test_train\n",
      "train mean loss=62765.745833333334\n",
      "test_test\n",
      "test mean loss=89869.8359375\n",
      "fin save.\n",
      "epoch 9688\n",
      "test_train\n",
      "train mean loss=63150.901041666664\n",
      "test_test\n",
      "test mean loss=89829.10546875\n",
      "fin save.\n",
      "epoch 9689\n",
      "test_train\n",
      "train mean loss=62351.99661458333\n",
      "test_test\n",
      "test mean loss=89888.5234375\n",
      "fin save.\n",
      "epoch 9690\n",
      "test_train\n",
      "train mean loss=63102.8296875\n",
      "test_test\n",
      "test mean loss=89783.92578125\n",
      "fin save.\n",
      "epoch 9691\n",
      "test_train\n",
      "train mean loss=62604.84479166667\n",
      "test_test\n",
      "test mean loss=89650.09375\n",
      "fin save.\n",
      "epoch 9692\n",
      "test_train\n",
      "train mean loss=62968.135416666664\n",
      "test_test\n",
      "test mean loss=89769.47265625\n",
      "fin save.\n",
      "epoch 9693\n",
      "test_train\n",
      "train mean loss=62051.187239583334\n",
      "test_test\n",
      "test mean loss=88935.44140625\n",
      "fin save.\n",
      "epoch 9694\n",
      "test_train\n",
      "train mean loss=63556.91705729167\n",
      "test_test\n",
      "test mean loss=89046.71875\n",
      "fin save.\n",
      "epoch 9695\n",
      "test_train\n",
      "train mean loss=63246.55963541667\n",
      "test_test\n",
      "test mean loss=89096.11328125\n",
      "fin save.\n",
      "epoch 9696\n",
      "test_train\n",
      "train mean loss=61790.322916666664\n",
      "test_test\n",
      "test mean loss=89123.953125\n",
      "fin save.\n",
      "epoch 9697\n",
      "test_train\n",
      "train mean loss=62480.3671875\n",
      "test_test\n",
      "test mean loss=89147.546875\n",
      "fin save.\n",
      "epoch 9698\n",
      "test_train\n",
      "train mean loss=62892.90182291667\n",
      "test_test\n",
      "test mean loss=89291.35546875\n",
      "fin save.\n",
      "epoch 9699\n",
      "test_train\n",
      "train mean loss=63575.68671875\n",
      "test_test\n",
      "test mean loss=89244.98828125\n",
      "fin save.\n",
      "epoch 9700\n",
      "test_train\n",
      "train mean loss=62221.74609375\n",
      "test_test\n",
      "test mean loss=89388.7421875\n",
      "fin save.\n",
      "epoch 9701\n",
      "test_train\n",
      "train mean loss=63415.17473958333\n",
      "test_test\n",
      "test mean loss=89332.1640625\n",
      "fin save.\n",
      "epoch 9702\n",
      "test_train\n",
      "train mean loss=62676.43046875\n",
      "test_test\n",
      "test mean loss=89253.54296875\n",
      "fin save.\n",
      "epoch 9703\n",
      "test_train\n",
      "train mean loss=63566.70416666667\n",
      "test_test\n",
      "test mean loss=89152.015625\n",
      "fin save.\n",
      "epoch 9704\n",
      "test_train\n",
      "train mean loss=63171.55859375\n",
      "test_test\n",
      "test mean loss=89462.734375\n",
      "fin save.\n",
      "epoch 9705\n",
      "test_train\n",
      "train mean loss=63508.669270833336\n",
      "test_test\n",
      "test mean loss=89380.6328125\n",
      "fin save.\n",
      "epoch 9706\n",
      "test_train\n",
      "train mean loss=62926.99609375\n",
      "test_test\n",
      "test mean loss=89293.375\n",
      "fin save.\n",
      "epoch 9707\n",
      "test_train\n",
      "train mean loss=62380.7765625\n",
      "test_test\n",
      "test mean loss=89366.06640625\n",
      "fin save.\n",
      "epoch 9708\n",
      "test_train\n",
      "train mean loss=62050.842447916664\n",
      "test_test\n",
      "test mean loss=89273.3359375\n",
      "fin save.\n",
      "epoch 9709\n",
      "test_train\n",
      "train mean loss=61089.25078125\n",
      "test_test\n",
      "test mean loss=89285.609375\n",
      "fin save.\n",
      "epoch 9710\n",
      "test_train\n",
      "train mean loss=63625.95755208333\n",
      "test_test\n",
      "test mean loss=89041.37109375\n",
      "fin save.\n",
      "epoch 9711\n",
      "test_train\n",
      "train mean loss=63096.41705729167\n",
      "test_test\n",
      "test mean loss=88701.5546875\n",
      "fin save.\n",
      "epoch 9712\n",
      "test_train\n",
      "train mean loss=63716.159895833334\n",
      "test_test\n",
      "test mean loss=88898.4296875\n",
      "fin save.\n",
      "epoch 9713\n",
      "test_train\n",
      "train mean loss=62728.34713541667\n",
      "test_test\n",
      "test mean loss=88938.73828125\n",
      "fin save.\n",
      "epoch 9714\n",
      "test_train\n",
      "train mean loss=62607.505859375\n",
      "test_test\n",
      "test mean loss=88996.27734375\n",
      "fin save.\n",
      "epoch 9715\n",
      "test_train\n",
      "train mean loss=61750.90703125\n",
      "test_test\n",
      "test mean loss=89199.609375\n",
      "fin save.\n",
      "epoch 9716\n",
      "test_train\n",
      "train mean loss=62600.48098958333\n",
      "test_test\n",
      "test mean loss=88993.75\n",
      "fin save.\n",
      "epoch 9717\n",
      "test_train\n",
      "train mean loss=62663.102864583336\n",
      "test_test\n",
      "test mean loss=89022.015625\n",
      "fin save.\n",
      "epoch 9718\n",
      "test_train\n",
      "train mean loss=61937.23528645833\n",
      "test_test\n",
      "test mean loss=89034.23828125\n",
      "fin save.\n",
      "epoch 9719\n",
      "test_train\n",
      "train mean loss=63301.19713541667\n",
      "test_test\n",
      "test mean loss=89054.39453125\n",
      "fin save.\n",
      "epoch 9720\n",
      "test_train\n",
      "train mean loss=63468.9921875\n",
      "test_test\n",
      "test mean loss=89103.625\n",
      "fin save.\n",
      "epoch 9721\n",
      "test_train\n",
      "train mean loss=63454.60638020833\n",
      "test_test\n",
      "test mean loss=89793.0390625\n",
      "fin save.\n",
      "epoch 9722\n",
      "test_train\n",
      "train mean loss=62487.61028645833\n",
      "test_test\n",
      "test mean loss=89941.1875\n",
      "fin save.\n",
      "epoch 9723\n",
      "test_train\n",
      "train mean loss=62561.895833333336\n",
      "test_test\n",
      "test mean loss=90074.203125\n",
      "fin save.\n",
      "epoch 9724\n",
      "test_train\n",
      "train mean loss=63117.89348958333\n",
      "test_test\n",
      "test mean loss=89888.265625\n",
      "fin save.\n",
      "epoch 9725\n",
      "test_train\n",
      "train mean loss=62058.14270833333\n",
      "test_test\n",
      "test mean loss=89611.015625\n",
      "fin save.\n",
      "epoch 9726\n",
      "test_train\n",
      "train mean loss=62465.85546875\n",
      "test_test\n",
      "test mean loss=89301.5\n",
      "fin save.\n",
      "epoch 9727\n",
      "test_train\n",
      "train mean loss=62570.66419270833\n",
      "test_test\n",
      "test mean loss=88290.53125\n",
      "fin save.\n",
      "epoch 9728\n",
      "test_train\n",
      "train mean loss=61727.17265625\n",
      "test_test\n",
      "test mean loss=88513.0\n",
      "fin save.\n",
      "epoch 9729\n",
      "test_train\n",
      "train mean loss=62158.93072916667\n",
      "test_test\n",
      "test mean loss=88472.70703125\n",
      "fin save.\n",
      "epoch 9730\n",
      "test_train\n",
      "train mean loss=62761.70651041667\n",
      "test_test\n",
      "test mean loss=87956.35546875\n",
      "fin save.\n",
      "epoch 9731\n",
      "test_train\n",
      "train mean loss=62800.35885416667\n",
      "test_test\n",
      "test mean loss=87972.19921875\n",
      "fin save.\n",
      "epoch 9732\n",
      "test_train\n",
      "train mean loss=62088.58151041667\n",
      "test_test\n",
      "test mean loss=88231.98046875\n",
      "fin save.\n",
      "epoch 9733\n",
      "test_train\n",
      "train mean loss=63289.77421875\n",
      "test_test\n",
      "test mean loss=88264.30078125\n",
      "fin save.\n",
      "epoch 9734\n",
      "test_train\n",
      "train mean loss=61773.601822916666\n",
      "test_test\n",
      "test mean loss=88590.76953125\n",
      "fin save.\n",
      "epoch 9735\n",
      "test_train\n",
      "train mean loss=62258.83190104167\n",
      "test_test\n",
      "test mean loss=88382.4375\n",
      "fin save.\n",
      "epoch 9736\n",
      "test_train\n",
      "train mean loss=62138.704427083336\n",
      "test_test\n",
      "test mean loss=88645.7421875\n",
      "fin save.\n",
      "epoch 9737\n",
      "test_train\n",
      "train mean loss=63692.87578125\n",
      "test_test\n",
      "test mean loss=88843.8203125\n",
      "fin save.\n",
      "epoch 9738\n",
      "test_train\n",
      "train mean loss=62683.86927083333\n",
      "test_test\n",
      "test mean loss=88672.59765625\n",
      "fin save.\n",
      "epoch 9739\n",
      "test_train\n",
      "train mean loss=62248.57421875\n",
      "test_test\n",
      "test mean loss=88901.55078125\n",
      "fin save.\n",
      "epoch 9740\n",
      "test_train\n",
      "train mean loss=62556.976953125\n",
      "test_test\n",
      "test mean loss=89064.86328125\n",
      "fin save.\n",
      "epoch 9741\n",
      "test_train\n",
      "train mean loss=62257.902994791664\n",
      "test_test\n",
      "test mean loss=89503.3203125\n",
      "fin save.\n",
      "epoch 9742\n",
      "test_train\n",
      "train mean loss=62498.66458333333\n",
      "test_test\n",
      "test mean loss=89306.0078125\n",
      "fin save.\n",
      "epoch 9743\n",
      "test_train\n",
      "train mean loss=63158.53203125\n",
      "test_test\n",
      "test mean loss=89400.890625\n",
      "fin save.\n",
      "epoch 9744\n",
      "test_train\n",
      "train mean loss=62485.55\n",
      "test_test\n",
      "test mean loss=89787.2890625\n",
      "fin save.\n",
      "epoch 9745\n",
      "test_train\n",
      "train mean loss=62220.82369791667\n",
      "test_test\n",
      "test mean loss=89529.29296875\n",
      "fin save.\n",
      "epoch 9746\n",
      "test_train\n",
      "train mean loss=62842.52109375\n",
      "test_test\n",
      "test mean loss=89611.90234375\n",
      "fin save.\n",
      "epoch 9747\n",
      "test_train\n",
      "train mean loss=62890.0\n",
      "test_test\n",
      "test mean loss=89547.296875\n",
      "fin save.\n",
      "epoch 9748\n",
      "test_train\n",
      "train mean loss=62626.75390625\n",
      "test_test\n",
      "test mean loss=89391.65234375\n",
      "fin save.\n",
      "epoch 9749\n",
      "test_train\n",
      "train mean loss=61855.20494791667\n",
      "test_test\n",
      "test mean loss=89332.5625\n",
      "fin save.\n",
      "epoch 9750\n",
      "test_train\n",
      "train mean loss=62099.824479166666\n",
      "test_test\n",
      "test mean loss=89301.7578125\n",
      "fin save.\n",
      "epoch 9751\n",
      "test_train\n",
      "train mean loss=62889.6234375\n",
      "test_test\n",
      "test mean loss=88614.73046875\n",
      "fin save.\n",
      "epoch 9752\n",
      "test_train\n",
      "train mean loss=62741.55260416667\n",
      "test_test\n",
      "test mean loss=88683.71484375\n",
      "fin save.\n",
      "epoch 9753\n",
      "test_train\n",
      "train mean loss=62425.59427083333\n",
      "test_test\n",
      "test mean loss=88602.25390625\n",
      "fin save.\n",
      "epoch 9754\n",
      "test_train\n",
      "train mean loss=62610.915364583336\n",
      "test_test\n",
      "test mean loss=88600.3125\n",
      "fin save.\n",
      "epoch 9755\n",
      "test_train\n",
      "train mean loss=63033.515625\n",
      "test_test\n",
      "test mean loss=88671.328125\n",
      "fin save.\n",
      "epoch 9756\n",
      "test_train\n",
      "train mean loss=62644.417708333334\n",
      "test_test\n",
      "test mean loss=88391.03125\n",
      "fin save.\n",
      "epoch 9757\n",
      "test_train\n",
      "train mean loss=62740.34869791667\n",
      "test_test\n",
      "test mean loss=88408.8828125\n",
      "fin save.\n",
      "epoch 9758\n",
      "test_train\n",
      "train mean loss=62382.253125\n",
      "test_test\n",
      "test mean loss=88568.02734375\n",
      "fin save.\n",
      "epoch 9759\n",
      "test_train\n",
      "train mean loss=62256.96822916667\n",
      "test_test\n",
      "test mean loss=88529.10546875\n",
      "fin save.\n",
      "epoch 9760\n",
      "test_train\n",
      "train mean loss=62193.177083333336\n",
      "test_test\n",
      "test mean loss=88428.8671875\n",
      "fin save.\n",
      "epoch 9761\n",
      "test_train\n",
      "train mean loss=62666.47890625\n",
      "test_test\n",
      "test mean loss=88418.79296875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fin save.\n",
      "epoch 9762\n",
      "test_train\n",
      "train mean loss=62215.87005208333\n",
      "test_test\n",
      "test mean loss=88662.26953125\n",
      "fin save.\n",
      "epoch 9763\n",
      "test_train\n",
      "train mean loss=62369.61770833333\n",
      "test_test\n",
      "test mean loss=88887.1796875\n",
      "fin save.\n",
      "epoch 9764\n",
      "test_train\n",
      "train mean loss=63262.93255208333\n",
      "test_test\n",
      "test mean loss=88778.4453125\n",
      "fin save.\n",
      "epoch 9765\n",
      "test_train\n",
      "train mean loss=62902.30651041667\n",
      "test_test\n",
      "test mean loss=88642.03515625\n",
      "fin save.\n",
      "epoch 9766\n",
      "test_train\n",
      "train mean loss=62572.53411458333\n",
      "test_test\n",
      "test mean loss=88648.27734375\n",
      "fin save.\n",
      "epoch 9767\n",
      "test_train\n",
      "train mean loss=61388.50052083333\n",
      "test_test\n",
      "test mean loss=88672.85546875\n",
      "fin save.\n",
      "epoch 9768\n",
      "test_train\n",
      "train mean loss=62294.84140625\n",
      "test_test\n",
      "test mean loss=88621.6015625\n",
      "fin save.\n",
      "epoch 9769\n",
      "test_train\n",
      "train mean loss=63751.34973958333\n",
      "test_test\n",
      "test mean loss=88747.46875\n",
      "fin save.\n",
      "epoch 9770\n",
      "test_train\n",
      "train mean loss=62856.05130208333\n",
      "test_test\n",
      "test mean loss=88692.49609375\n",
      "fin save.\n",
      "epoch 9771\n",
      "test_train\n",
      "train mean loss=62412.646875\n",
      "test_test\n",
      "test mean loss=88734.88671875\n",
      "fin save.\n",
      "epoch 9772\n",
      "test_train\n",
      "train mean loss=62726.94244791667\n",
      "test_test\n",
      "test mean loss=88903.87890625\n",
      "fin save.\n",
      "epoch 9773\n",
      "test_train\n",
      "train mean loss=62960.59973958333\n",
      "test_test\n",
      "test mean loss=88941.171875\n",
      "fin save.\n",
      "epoch 9774\n",
      "test_train\n",
      "train mean loss=62601.66484375\n",
      "test_test\n",
      "test mean loss=88793.71484375\n",
      "fin save.\n",
      "epoch 9775\n",
      "test_train\n",
      "train mean loss=61895.445572916666\n",
      "test_test\n",
      "test mean loss=88641.1875\n",
      "fin save.\n",
      "epoch 9776\n",
      "test_train\n",
      "train mean loss=62721.71497395833\n",
      "test_test\n",
      "test mean loss=88488.234375\n",
      "fin save.\n",
      "epoch 9777\n",
      "test_train\n",
      "train mean loss=62770.42981770833\n",
      "test_test\n",
      "test mean loss=88480.4453125\n",
      "fin save.\n",
      "epoch 9778\n",
      "test_train\n",
      "train mean loss=62338.50729166667\n",
      "test_test\n",
      "test mean loss=88458.984375\n",
      "fin save.\n",
      "epoch 9779\n",
      "test_train\n",
      "train mean loss=62805.876953125\n",
      "test_test\n",
      "test mean loss=88723.34765625\n",
      "fin save.\n",
      "epoch 9780\n",
      "test_train\n",
      "train mean loss=62431.000260416666\n",
      "test_test\n",
      "test mean loss=88680.3359375\n",
      "fin save.\n",
      "epoch 9781\n",
      "test_train\n",
      "train mean loss=61854.737890625\n",
      "test_test\n",
      "test mean loss=88379.734375\n",
      "fin save.\n",
      "epoch 9782\n",
      "test_train\n",
      "train mean loss=62605.44739583333\n",
      "test_test\n",
      "test mean loss=88707.1015625\n",
      "fin save.\n",
      "epoch 9783\n",
      "test_train\n",
      "train mean loss=63123.711197916666\n",
      "test_test\n",
      "test mean loss=88650.8046875\n",
      "fin save.\n",
      "epoch 9784\n",
      "test_train\n",
      "train mean loss=62527.83359375\n",
      "test_test\n",
      "test mean loss=88691.23046875\n",
      "fin save.\n",
      "epoch 9785\n",
      "test_train\n",
      "train mean loss=62467.115885416664\n",
      "test_test\n",
      "test mean loss=88613.06640625\n",
      "fin save.\n",
      "epoch 9786\n",
      "test_train\n",
      "train mean loss=61700.86015625\n",
      "test_test\n",
      "test mean loss=88425.0625\n",
      "fin save.\n",
      "epoch 9787\n",
      "test_train\n",
      "train mean loss=62776.44088541667\n",
      "test_test\n",
      "test mean loss=88698.140625\n",
      "fin save.\n",
      "epoch 9788\n",
      "test_train\n",
      "train mean loss=61436.9390625\n",
      "test_test\n",
      "test mean loss=88608.234375\n",
      "fin save.\n",
      "epoch 9789\n",
      "test_train\n",
      "train mean loss=63040.34479166667\n",
      "test_test\n",
      "test mean loss=88726.92578125\n",
      "fin save.\n",
      "epoch 9790\n",
      "test_train\n",
      "train mean loss=62590.425\n",
      "test_test\n",
      "test mean loss=88350.5625\n",
      "fin save.\n",
      "epoch 9791\n",
      "test_train\n",
      "train mean loss=61588.53697916667\n",
      "test_test\n",
      "test mean loss=88514.59765625\n",
      "fin save.\n",
      "epoch 9792\n",
      "test_train\n",
      "train mean loss=62416.77578125\n",
      "test_test\n",
      "test mean loss=88491.171875\n",
      "fin save.\n",
      "epoch 9793\n",
      "test_train\n",
      "train mean loss=62089.57083333333\n",
      "test_test\n",
      "test mean loss=88381.01953125\n",
      "fin save.\n",
      "epoch 9794\n",
      "test_train\n",
      "train mean loss=62664.61171875\n",
      "test_test\n",
      "test mean loss=88502.21484375\n",
      "fin save.\n",
      "epoch 9795\n",
      "test_train\n",
      "train mean loss=61626.00442708333\n",
      "test_test\n",
      "test mean loss=88333.66796875\n",
      "fin save.\n",
      "epoch 9796\n",
      "test_train\n",
      "train mean loss=62313.507552083334\n",
      "test_test\n",
      "test mean loss=88223.4296875\n",
      "fin save.\n",
      "epoch 9797\n",
      "test_train\n",
      "train mean loss=63140.21822916667\n",
      "test_test\n",
      "test mean loss=88124.578125\n",
      "fin save.\n",
      "epoch 9798\n",
      "test_train\n",
      "train mean loss=62888.861979166664\n",
      "test_test\n",
      "test mean loss=88278.8046875\n",
      "fin save.\n",
      "epoch 9799\n",
      "test_train\n",
      "train mean loss=63178.73776041667\n",
      "test_test\n",
      "test mean loss=88317.96875\n",
      "fin save.\n",
      "epoch 9800\n",
      "test_train\n",
      "train mean loss=62680.86041666667\n",
      "test_test\n",
      "test mean loss=88150.19921875\n",
      "fin save.\n",
      "epoch 9801\n",
      "test_train\n",
      "train mean loss=62091.420572916664\n",
      "test_test\n",
      "test mean loss=88361.9765625\n",
      "fin save.\n",
      "epoch 9802\n",
      "test_train\n",
      "train mean loss=63477.04583333333\n",
      "test_test\n",
      "test mean loss=88240.03125\n",
      "fin save.\n",
      "epoch 9803\n",
      "test_train\n",
      "train mean loss=63528.79388020833\n",
      "test_test\n",
      "test mean loss=88273.70703125\n",
      "fin save.\n",
      "epoch 9804\n",
      "test_train\n",
      "train mean loss=63257.290364583336\n",
      "test_test\n",
      "test mean loss=88089.6015625\n",
      "fin save.\n",
      "epoch 9805\n",
      "test_train\n",
      "train mean loss=61665.312239583334\n",
      "test_test\n",
      "test mean loss=88128.44921875\n",
      "fin save.\n",
      "epoch 9806\n",
      "test_train\n",
      "train mean loss=62756.99921875\n",
      "test_test\n",
      "test mean loss=87762.859375\n",
      "fin save.\n",
      "epoch 9807\n",
      "test_train\n",
      "train mean loss=61470.754166666666\n",
      "test_test\n",
      "test mean loss=88079.66015625\n",
      "fin save.\n",
      "epoch 9808\n",
      "test_train\n",
      "train mean loss=61577.51770833333\n",
      "test_test\n",
      "test mean loss=88281.78125\n",
      "fin save.\n",
      "epoch 9809\n",
      "test_train\n",
      "train mean loss=62265.1734375\n",
      "test_test\n",
      "test mean loss=88311.89453125\n",
      "fin save.\n",
      "epoch 9810\n",
      "test_train\n",
      "train mean loss=62991.31848958333\n",
      "test_test\n",
      "test mean loss=88528.109375\n",
      "fin save.\n",
      "epoch 9811\n",
      "test_train\n",
      "train mean loss=61896.66901041667\n",
      "test_test\n",
      "test mean loss=88539.8125\n",
      "fin save.\n",
      "epoch 9812\n",
      "test_train\n",
      "train mean loss=62368.27942708333\n",
      "test_test\n",
      "test mean loss=88421.3125\n",
      "fin save.\n",
      "epoch 9813\n",
      "test_train\n",
      "train mean loss=62128.52161458333\n",
      "test_test\n",
      "test mean loss=88305.88671875\n",
      "fin save.\n",
      "epoch 9814\n",
      "test_train\n",
      "train mean loss=63233.940625\n",
      "test_test\n",
      "test mean loss=88337.09375\n",
      "fin save.\n",
      "epoch 9815\n",
      "test_train\n",
      "train mean loss=61690.35078125\n",
      "test_test\n",
      "test mean loss=88314.0078125\n",
      "fin save.\n",
      "epoch 9816\n",
      "test_train\n",
      "train mean loss=63059.99661458333\n",
      "test_test\n",
      "test mean loss=88444.015625\n",
      "fin save.\n",
      "epoch 9817\n",
      "test_train\n",
      "train mean loss=62752.955729166664\n",
      "test_test\n",
      "test mean loss=88265.63671875\n",
      "fin save.\n",
      "epoch 9818\n",
      "test_train\n",
      "train mean loss=62942.89296875\n",
      "test_test\n",
      "test mean loss=88268.3046875\n",
      "fin save.\n",
      "epoch 9819\n",
      "test_train\n",
      "train mean loss=62792.52447916667\n",
      "test_test\n",
      "test mean loss=88199.49609375\n",
      "fin save.\n",
      "epoch 9820\n",
      "test_train\n",
      "train mean loss=62506.57369791667\n",
      "test_test\n",
      "test mean loss=88008.83203125\n",
      "fin save.\n",
      "epoch 9821\n",
      "test_train\n",
      "train mean loss=62304.31640625\n",
      "test_test\n",
      "test mean loss=88176.4609375\n",
      "fin save.\n",
      "epoch 9822\n",
      "test_train\n",
      "train mean loss=61726.349609375\n",
      "test_test\n",
      "test mean loss=88201.67578125\n",
      "fin save.\n",
      "epoch 9823\n",
      "test_train\n",
      "train mean loss=62161.36432291667\n",
      "test_test\n",
      "test mean loss=88038.80078125\n",
      "fin save.\n",
      "epoch 9824\n",
      "test_train\n",
      "train mean loss=63233.43697916667\n",
      "test_test\n",
      "test mean loss=87857.63671875\n",
      "fin save.\n",
      "epoch 9825\n",
      "test_train\n",
      "train mean loss=62514.866796875\n",
      "test_test\n",
      "test mean loss=87768.2421875\n",
      "fin save.\n",
      "epoch 9826\n",
      "test_train\n",
      "train mean loss=63008.86380208333\n",
      "test_test\n",
      "test mean loss=87906.515625\n",
      "fin save.\n",
      "epoch 9827\n",
      "test_train\n",
      "train mean loss=63181.15833333333\n",
      "test_test\n",
      "test mean loss=87922.015625\n",
      "fin save.\n",
      "epoch 9828\n",
      "test_train\n",
      "train mean loss=61852.080729166664\n",
      "test_test\n",
      "test mean loss=87762.3125\n",
      "fin save.\n",
      "epoch 9829\n",
      "test_train\n",
      "train mean loss=62477.958203125\n",
      "test_test\n",
      "test mean loss=87981.4296875\n",
      "fin save.\n",
      "epoch 9830\n",
      "test_train\n",
      "train mean loss=61987.5296875\n",
      "test_test\n",
      "test mean loss=87950.34375\n",
      "fin save.\n",
      "epoch 9831\n",
      "test_train\n",
      "train mean loss=62303.94453125\n",
      "test_test\n",
      "test mean loss=87933.8125\n",
      "fin save.\n",
      "epoch 9832\n",
      "test_train\n",
      "train mean loss=63316.23880208333\n",
      "test_test\n",
      "test mean loss=88031.6328125\n",
      "fin save.\n",
      "epoch 9833\n",
      "test_train\n",
      "train mean loss=62712.31484375\n",
      "test_test\n",
      "test mean loss=88072.14453125\n",
      "fin save.\n",
      "epoch 9834\n",
      "test_train\n",
      "train mean loss=63260.182421875\n",
      "test_test\n",
      "test mean loss=88213.16796875\n",
      "fin save.\n",
      "epoch 9835\n",
      "test_train\n",
      "train mean loss=62717.63203125\n",
      "test_test\n",
      "test mean loss=88493.0703125\n",
      "fin save.\n",
      "epoch 9836\n",
      "test_train\n",
      "train mean loss=62851.06953125\n",
      "test_test\n",
      "test mean loss=88353.8515625\n",
      "fin save.\n",
      "epoch 9837\n",
      "test_train\n",
      "train mean loss=62282.43854166667\n",
      "test_test\n",
      "test mean loss=88216.04296875\n",
      "fin save.\n",
      "epoch 9838\n",
      "test_train\n",
      "train mean loss=61813.205729166664\n",
      "test_test\n",
      "test mean loss=88460.84765625\n",
      "fin save.\n",
      "epoch 9839\n",
      "test_train\n",
      "train mean loss=62617.4359375\n",
      "test_test\n",
      "test mean loss=88795.765625\n",
      "fin save.\n",
      "epoch 9840\n",
      "test_train\n",
      "train mean loss=63364.0875\n",
      "test_test\n",
      "test mean loss=88688.08203125\n",
      "fin save.\n",
      "epoch 9841\n",
      "test_train\n",
      "train mean loss=62523.88203125\n",
      "test_test\n",
      "test mean loss=88318.15234375\n",
      "fin save.\n",
      "epoch 9842\n",
      "test_train\n",
      "train mean loss=62822.40729166667\n",
      "test_test\n",
      "test mean loss=88341.1328125\n",
      "fin save.\n",
      "epoch 9843\n",
      "test_train\n",
      "train mean loss=62728.73645833333\n",
      "test_test\n",
      "test mean loss=88633.13671875\n",
      "fin save.\n",
      "epoch 9844\n",
      "test_train\n",
      "train mean loss=63430.500260416666\n",
      "test_test\n",
      "test mean loss=88175.46484375\n",
      "fin save.\n",
      "epoch 9845\n",
      "test_train\n",
      "train mean loss=62347.45755208333\n",
      "test_test\n",
      "test mean loss=88358.8125\n",
      "fin save.\n",
      "epoch 9846\n",
      "test_train\n",
      "train mean loss=62435.00729166667\n",
      "test_test\n",
      "test mean loss=88659.42578125\n",
      "fin save.\n",
      "epoch 9847\n",
      "test_train\n",
      "train mean loss=62795.047526041664\n",
      "test_test\n",
      "test mean loss=88317.43359375\n",
      "fin save.\n",
      "epoch 9848\n",
      "test_train\n",
      "train mean loss=62513.88880208333\n",
      "test_test\n",
      "test mean loss=88835.265625\n",
      "fin save.\n",
      "epoch 9849\n",
      "test_train\n",
      "train mean loss=61688.885546875\n",
      "test_test\n",
      "test mean loss=88703.90234375\n",
      "fin save.\n",
      "epoch 9850\n",
      "test_train\n",
      "train mean loss=62446.2828125\n",
      "test_test\n",
      "test mean loss=88614.578125\n",
      "fin save.\n",
      "epoch 9851\n",
      "test_train\n",
      "train mean loss=61546.67760416667\n",
      "test_test\n",
      "test mean loss=88613.73828125\n",
      "fin save.\n",
      "epoch 9852\n",
      "test_train\n",
      "train mean loss=62198.142838541666\n",
      "test_test\n",
      "test mean loss=88632.43359375\n",
      "fin save.\n",
      "epoch 9853\n",
      "test_train\n",
      "train mean loss=62170.75338541667\n",
      "test_test\n",
      "test mean loss=88648.03515625\n",
      "fin save.\n",
      "epoch 9854\n",
      "test_train\n",
      "train mean loss=62622.5125\n",
      "test_test\n",
      "test mean loss=88671.8125\n",
      "fin save.\n",
      "epoch 9855\n",
      "test_train\n",
      "train mean loss=62200.81041666667\n",
      "test_test\n",
      "test mean loss=88676.859375\n",
      "fin save.\n",
      "epoch 9856\n",
      "test_train\n",
      "train mean loss=62551.03229166667\n",
      "test_test\n",
      "test mean loss=88521.78125\n",
      "fin save.\n",
      "epoch 9857\n",
      "test_train\n",
      "train mean loss=62874.403645833336\n",
      "test_test\n",
      "test mean loss=87929.90625\n",
      "fin save.\n",
      "epoch 9858\n",
      "test_train\n",
      "train mean loss=62918.37942708333\n",
      "test_test\n",
      "test mean loss=88167.92578125\n",
      "fin save.\n",
      "epoch 9859\n",
      "test_train\n",
      "train mean loss=62906.241927083334\n",
      "test_test\n",
      "test mean loss=87625.23046875\n",
      "fin save.\n",
      "epoch 9860\n",
      "test_train\n",
      "train mean loss=63078.84388020833\n",
      "test_test\n",
      "test mean loss=87729.4140625\n",
      "fin save.\n",
      "epoch 9861\n",
      "test_train\n",
      "train mean loss=64111.847005208336\n",
      "test_test\n",
      "test mean loss=87700.05078125\n",
      "fin save.\n",
      "epoch 9862\n",
      "test_train\n",
      "train mean loss=62517.18515625\n",
      "test_test\n",
      "test mean loss=87800.61328125\n",
      "fin save.\n",
      "epoch 9863\n",
      "test_train\n",
      "train mean loss=62248.2203125\n",
      "test_test\n",
      "test mean loss=87717.13671875\n",
      "fin save.\n",
      "epoch 9864\n",
      "test_train\n",
      "train mean loss=63133.05950520833\n",
      "test_test\n",
      "test mean loss=87890.24609375\n",
      "fin save.\n",
      "epoch 9865\n",
      "test_train\n",
      "train mean loss=62059.04140625\n",
      "test_test\n",
      "test mean loss=87841.92578125\n",
      "fin save.\n",
      "epoch 9866\n",
      "test_train\n",
      "train mean loss=62977.59557291667\n",
      "test_test\n",
      "test mean loss=88065.0234375\n",
      "fin save.\n",
      "epoch 9867\n",
      "test_train\n",
      "train mean loss=62088.890885416666\n",
      "test_test\n",
      "test mean loss=88209.21875\n",
      "fin save.\n",
      "epoch 9868\n",
      "test_train\n",
      "train mean loss=62967.825520833336\n",
      "test_test\n",
      "test mean loss=88075.33984375\n",
      "fin save.\n",
      "epoch 9869\n",
      "test_train\n",
      "train mean loss=63376.0296875\n",
      "test_test\n",
      "test mean loss=88063.54296875\n",
      "fin save.\n",
      "epoch 9870\n",
      "test_train\n",
      "train mean loss=62706.49375\n",
      "test_test\n",
      "test mean loss=87916.24609375\n",
      "fin save.\n",
      "epoch 9871\n",
      "test_train\n",
      "train mean loss=62658.183854166666\n",
      "test_test\n",
      "test mean loss=87817.30859375\n",
      "fin save.\n",
      "epoch 9872\n",
      "test_train\n",
      "train mean loss=62701.866927083334\n",
      "test_test\n",
      "test mean loss=88032.50390625\n",
      "fin save.\n",
      "epoch 9873\n",
      "test_train\n",
      "train mean loss=62464.93567708333\n",
      "test_test\n",
      "test mean loss=88079.3984375\n",
      "fin save.\n",
      "epoch 9874\n",
      "test_train\n",
      "train mean loss=62076.00859375\n",
      "test_test\n",
      "test mean loss=87882.1953125\n",
      "fin save.\n",
      "epoch 9875\n",
      "test_train\n",
      "train mean loss=61914.67005208333\n",
      "test_test\n",
      "test mean loss=87890.94921875\n",
      "fin save.\n",
      "epoch 9876\n",
      "test_train\n",
      "train mean loss=62340.021875\n",
      "test_test\n",
      "test mean loss=87975.58984375\n",
      "fin save.\n",
      "epoch 9877\n",
      "test_train\n",
      "train mean loss=62355.4671875\n",
      "test_test\n",
      "test mean loss=88208.57421875\n",
      "fin save.\n",
      "epoch 9878\n",
      "test_train\n",
      "train mean loss=62371.111067708334\n",
      "test_test\n",
      "test mean loss=88400.5703125\n",
      "fin save.\n",
      "epoch 9879\n",
      "test_train\n",
      "train mean loss=61774.61614583333\n",
      "test_test\n",
      "test mean loss=88595.04296875\n",
      "fin save.\n",
      "epoch 9880\n",
      "test_train\n",
      "train mean loss=63751.33515625\n",
      "test_test\n",
      "test mean loss=88532.2109375\n",
      "fin save.\n",
      "epoch 9881\n",
      "test_train\n",
      "train mean loss=62846.11666666667\n",
      "test_test\n",
      "test mean loss=88130.765625\n",
      "fin save.\n",
      "epoch 9882\n",
      "test_train\n",
      "train mean loss=61889.644791666666\n",
      "test_test\n",
      "test mean loss=88560.89453125\n",
      "fin save.\n",
      "epoch 9883\n",
      "test_train\n",
      "train mean loss=62269.93463541667\n",
      "test_test\n",
      "test mean loss=88298.72265625\n",
      "fin save.\n",
      "epoch 9884\n",
      "test_train\n",
      "train mean loss=62493.308854166666\n",
      "test_test\n",
      "test mean loss=88393.78125\n",
      "fin save.\n",
      "epoch 9885\n",
      "test_train\n",
      "train mean loss=62937.416276041666\n",
      "test_test\n",
      "test mean loss=88610.359375\n",
      "fin save.\n",
      "epoch 9886\n",
      "test_train\n",
      "train mean loss=61784.06848958333\n",
      "test_test\n",
      "test mean loss=88395.71484375\n",
      "fin save.\n",
      "epoch 9887\n",
      "test_train\n",
      "train mean loss=63404.165364583336\n",
      "test_test\n",
      "test mean loss=88379.5859375\n",
      "fin save.\n",
      "epoch 9888\n",
      "test_train\n",
      "train mean loss=62443.550520833334\n",
      "test_test\n",
      "test mean loss=88229.5\n",
      "fin save.\n",
      "epoch 9889\n",
      "test_train\n",
      "train mean loss=63008.97760416667\n",
      "test_test\n",
      "test mean loss=87847.22265625\n",
      "fin save.\n",
      "epoch 9890\n",
      "test_train\n",
      "train mean loss=62259.77109375\n",
      "test_test\n",
      "test mean loss=88213.03125\n",
      "fin save.\n",
      "epoch 9891\n",
      "test_train\n",
      "train mean loss=63115.225911458336\n",
      "test_test\n",
      "test mean loss=88610.7578125\n",
      "fin save.\n",
      "epoch 9892\n",
      "test_train\n",
      "train mean loss=62734.77395833333\n",
      "test_test\n",
      "test mean loss=88374.68359375\n",
      "fin save.\n",
      "epoch 9893\n",
      "test_train\n",
      "train mean loss=63026.76276041667\n",
      "test_test\n",
      "test mean loss=88486.24609375\n",
      "fin save.\n",
      "epoch 9894\n",
      "test_train\n",
      "train mean loss=62085.560286458334\n",
      "test_test\n",
      "test mean loss=88494.87109375\n",
      "fin save.\n",
      "epoch 9895\n",
      "test_train\n",
      "train mean loss=61570.192057291664\n",
      "test_test\n",
      "test mean loss=88660.37109375\n",
      "fin save.\n",
      "epoch 9896\n",
      "test_train\n",
      "train mean loss=62784.261458333334\n",
      "test_test\n",
      "test mean loss=88509.203125\n",
      "fin save.\n",
      "epoch 9897\n",
      "test_train\n",
      "train mean loss=63126.120833333334\n",
      "test_test\n",
      "test mean loss=88465.06640625\n",
      "fin save.\n",
      "epoch 9898\n",
      "test_train\n",
      "train mean loss=62065.01328125\n",
      "test_test\n",
      "test mean loss=88227.06640625\n",
      "fin save.\n",
      "epoch 9899\n",
      "test_train\n",
      "train mean loss=62708.51901041667\n",
      "test_test\n",
      "test mean loss=88417.0\n",
      "fin save.\n",
      "epoch 9900\n",
      "test_train\n",
      "train mean loss=62310.29505208333\n",
      "test_test\n",
      "test mean loss=88543.578125\n",
      "fin save.\n",
      "epoch 9901\n",
      "test_train\n",
      "train mean loss=62447.75546875\n",
      "test_test\n",
      "test mean loss=88565.5546875\n",
      "fin save.\n",
      "epoch 9902\n",
      "test_train\n",
      "train mean loss=62039.15729166667\n",
      "test_test\n",
      "test mean loss=88282.35546875\n",
      "fin save.\n",
      "epoch 9903\n",
      "test_train\n",
      "train mean loss=63431.97265625\n",
      "test_test\n",
      "test mean loss=88327.16796875\n",
      "fin save.\n",
      "epoch 9904\n",
      "test_train\n",
      "train mean loss=61843.409375\n",
      "test_test\n",
      "test mean loss=88469.625\n",
      "fin save.\n",
      "epoch 9905\n",
      "test_train\n",
      "train mean loss=62848.548177083336\n",
      "test_test\n",
      "test mean loss=88416.3671875\n",
      "fin save.\n",
      "epoch 9906\n",
      "test_train\n",
      "train mean loss=62477.64453125\n",
      "test_test\n",
      "test mean loss=88402.71484375\n",
      "fin save.\n",
      "epoch 9907\n",
      "test_train\n",
      "train mean loss=63175.747395833336\n",
      "test_test\n",
      "test mean loss=88186.22265625\n",
      "fin save.\n",
      "epoch 9908\n",
      "test_train\n",
      "train mean loss=62892.11666666667\n",
      "test_test\n",
      "test mean loss=88447.34765625\n",
      "fin save.\n",
      "epoch 9909\n",
      "test_train\n",
      "train mean loss=63172.675520833334\n",
      "test_test\n",
      "test mean loss=88565.0625\n",
      "fin save.\n",
      "epoch 9910\n",
      "test_train\n",
      "train mean loss=62441.38671875\n",
      "test_test\n",
      "test mean loss=88450.8203125\n",
      "fin save.\n",
      "epoch 9911\n",
      "test_train\n",
      "train mean loss=62437.9\n",
      "test_test\n",
      "test mean loss=88400.0859375\n",
      "fin save.\n",
      "epoch 9912\n",
      "test_train\n",
      "train mean loss=62214.263932291666\n",
      "test_test\n",
      "test mean loss=88273.75\n",
      "fin save.\n",
      "epoch 9913\n",
      "test_train\n",
      "train mean loss=62658.774739583336\n",
      "test_test\n",
      "test mean loss=88274.95703125\n",
      "fin save.\n",
      "epoch 9914\n",
      "test_train\n",
      "train mean loss=62366.441145833334\n",
      "test_test\n",
      "test mean loss=88529.8671875\n",
      "fin save.\n",
      "epoch 9915\n",
      "test_train\n",
      "train mean loss=62558.62265625\n",
      "test_test\n",
      "test mean loss=88345.328125\n",
      "fin save.\n",
      "epoch 9916\n",
      "test_train\n",
      "train mean loss=62381.16640625\n",
      "test_test\n",
      "test mean loss=88501.42578125\n",
      "fin save.\n",
      "epoch 9917\n",
      "test_train\n",
      "train mean loss=61883.65677083333\n",
      "test_test\n",
      "test mean loss=88577.20703125\n",
      "fin save.\n",
      "epoch 9918\n",
      "test_train\n",
      "train mean loss=63353.328385416666\n",
      "test_test\n",
      "test mean loss=88291.30078125\n",
      "fin save.\n",
      "epoch 9919\n",
      "test_train\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mean loss=62692.587239583336\n",
      "test_test\n",
      "test mean loss=88261.34375\n",
      "fin save.\n",
      "epoch 9920\n",
      "test_train\n",
      "train mean loss=61730.34921875\n",
      "test_test\n",
      "test mean loss=88437.890625\n",
      "fin save.\n",
      "epoch 9921\n",
      "test_train\n",
      "train mean loss=62248.454296875\n",
      "test_test\n",
      "test mean loss=88161.984375\n",
      "fin save.\n",
      "epoch 9922\n",
      "test_train\n",
      "train mean loss=62976.15286458333\n",
      "test_test\n",
      "test mean loss=88058.921875\n",
      "fin save.\n",
      "epoch 9923\n",
      "test_train\n",
      "train mean loss=62197.32018229167\n",
      "test_test\n",
      "test mean loss=88093.91015625\n",
      "fin save.\n",
      "epoch 9924\n",
      "test_train\n",
      "train mean loss=62232.0453125\n",
      "test_test\n",
      "test mean loss=88224.21484375\n",
      "fin save.\n",
      "epoch 9925\n",
      "test_train\n",
      "train mean loss=62491.00390625\n",
      "test_test\n",
      "test mean loss=88667.25\n",
      "fin save.\n",
      "epoch 9926\n",
      "test_train\n",
      "train mean loss=62124.117578125\n",
      "test_test\n",
      "test mean loss=88712.14453125\n",
      "fin save.\n",
      "epoch 9927\n",
      "test_train\n",
      "train mean loss=61650.26953125\n",
      "test_test\n",
      "test mean loss=88600.984375\n",
      "fin save.\n",
      "epoch 9928\n",
      "test_train\n",
      "train mean loss=62125.238541666666\n",
      "test_test\n",
      "test mean loss=88173.03515625\n",
      "fin save.\n",
      "epoch 9929\n",
      "test_train\n",
      "train mean loss=62313.29440104167\n",
      "test_test\n",
      "test mean loss=88257.8203125\n",
      "fin save.\n",
      "epoch 9930\n",
      "test_train\n",
      "train mean loss=61976.333723958334\n",
      "test_test\n",
      "test mean loss=88464.76953125\n",
      "fin save.\n",
      "epoch 9931\n",
      "test_train\n",
      "train mean loss=62291.760416666664\n",
      "test_test\n",
      "test mean loss=88499.4375\n",
      "fin save.\n",
      "epoch 9932\n",
      "test_train\n",
      "train mean loss=62282.01875\n",
      "test_test\n",
      "test mean loss=88754.9921875\n",
      "fin save.\n",
      "epoch 9933\n",
      "test_train\n",
      "train mean loss=61325.21432291667\n",
      "test_test\n",
      "test mean loss=88723.5859375\n",
      "fin save.\n",
      "epoch 9934\n",
      "test_train\n",
      "train mean loss=62610.0734375\n",
      "test_test\n",
      "test mean loss=88670.1640625\n",
      "fin save.\n",
      "epoch 9935\n",
      "test_train\n",
      "train mean loss=62090.83515625\n",
      "test_test\n",
      "test mean loss=88630.75\n",
      "fin save.\n",
      "epoch 9936\n",
      "test_train\n",
      "train mean loss=63011.235677083336\n",
      "test_test\n",
      "test mean loss=88804.37109375\n",
      "fin save.\n",
      "epoch 9937\n",
      "test_train\n",
      "train mean loss=62144.441145833334\n",
      "test_test\n",
      "test mean loss=88538.359375\n",
      "fin save.\n",
      "epoch 9938\n",
      "test_train\n",
      "train mean loss=62628.916666666664\n",
      "test_test\n",
      "test mean loss=88318.66015625\n",
      "fin save.\n",
      "epoch 9939\n",
      "test_train\n",
      "train mean loss=62344.835677083334\n",
      "test_test\n",
      "test mean loss=88275.09375\n",
      "fin save.\n",
      "epoch 9940\n",
      "test_train\n",
      "train mean loss=62079.55377604167\n",
      "test_test\n",
      "test mean loss=88456.796875\n",
      "fin save.\n",
      "epoch 9941\n",
      "test_train\n",
      "train mean loss=62894.17864583333\n",
      "test_test\n",
      "test mean loss=88429.0859375\n",
      "fin save.\n",
      "epoch 9942\n",
      "test_train\n",
      "train mean loss=63600.026041666664\n",
      "test_test\n",
      "test mean loss=88371.21875\n",
      "fin save.\n",
      "epoch 9943\n",
      "test_train\n",
      "train mean loss=62046.01796875\n",
      "test_test\n",
      "test mean loss=88284.2734375\n",
      "fin save.\n",
      "epoch 9944\n",
      "test_train\n",
      "train mean loss=62835.07135416667\n",
      "test_test\n",
      "test mean loss=88484.8828125\n",
      "fin save.\n",
      "epoch 9945\n",
      "test_train\n",
      "train mean loss=62193.64401041667\n",
      "test_test\n",
      "test mean loss=88694.140625\n",
      "fin save.\n",
      "epoch 9946\n",
      "test_train\n",
      "train mean loss=62126.3953125\n",
      "test_test\n",
      "test mean loss=88760.5703125\n",
      "fin save.\n",
      "epoch 9947\n",
      "test_train\n",
      "train mean loss=62672.70859375\n",
      "test_test\n",
      "test mean loss=88644.39453125\n",
      "fin save.\n",
      "epoch 9948\n",
      "test_train\n",
      "train mean loss=62282.225911458336\n",
      "test_test\n",
      "test mean loss=88502.97265625\n",
      "fin save.\n",
      "epoch 9949\n",
      "test_train\n",
      "train mean loss=62295.852734375\n",
      "test_test\n",
      "test mean loss=88560.0390625\n",
      "fin save.\n",
      "epoch 9950\n",
      "test_train\n",
      "train mean loss=62703.05182291667\n",
      "test_test\n",
      "test mean loss=88719.046875\n",
      "fin save.\n",
      "epoch 9951\n",
      "test_train\n",
      "train mean loss=62638.19427083333\n",
      "test_test\n",
      "test mean loss=88704.8203125\n",
      "fin save.\n",
      "epoch 9952\n",
      "test_train\n",
      "train mean loss=62681.48880208333\n",
      "test_test\n",
      "test mean loss=88590.73046875\n",
      "fin save.\n",
      "epoch 9953\n",
      "test_train\n",
      "train mean loss=61679.070572916666\n",
      "test_test\n",
      "test mean loss=88450.73046875\n",
      "fin save.\n",
      "epoch 9954\n",
      "test_train\n",
      "train mean loss=62414.73541666667\n",
      "test_test\n",
      "test mean loss=88695.57421875\n",
      "fin save.\n",
      "epoch 9955\n",
      "test_train\n",
      "train mean loss=62390.31953125\n",
      "test_test\n",
      "test mean loss=88666.30078125\n",
      "fin save.\n",
      "epoch 9956\n",
      "test_train\n",
      "train mean loss=62446.24700520833\n",
      "test_test\n",
      "test mean loss=88816.7109375\n",
      "fin save.\n",
      "epoch 9957\n",
      "test_train\n",
      "train mean loss=62767.179947916666\n",
      "test_test\n",
      "test mean loss=88564.109375\n",
      "fin save.\n",
      "epoch 9958\n",
      "test_train\n",
      "train mean loss=61766.72122395833\n",
      "test_test\n",
      "test mean loss=88211.40625\n",
      "fin save.\n",
      "epoch 9959\n",
      "test_train\n",
      "train mean loss=62330.19713541667\n",
      "test_test\n",
      "test mean loss=88294.1796875\n",
      "fin save.\n",
      "epoch 9960\n",
      "test_train\n",
      "train mean loss=62761.79635416667\n",
      "test_test\n",
      "test mean loss=88365.203125\n",
      "fin save.\n",
      "epoch 9961\n",
      "test_train\n",
      "train mean loss=63352.682291666664\n",
      "test_test\n",
      "test mean loss=88294.86328125\n",
      "fin save.\n",
      "epoch 9962\n",
      "test_train\n",
      "train mean loss=61934.57083333333\n",
      "test_test\n",
      "test mean loss=88670.61328125\n",
      "fin save.\n",
      "epoch 9963\n",
      "test_train\n",
      "train mean loss=62577.66328125\n",
      "test_test\n",
      "test mean loss=88443.1484375\n",
      "fin save.\n",
      "epoch 9964\n",
      "test_train\n",
      "train mean loss=62031.00078125\n",
      "test_test\n",
      "test mean loss=88391.61328125\n",
      "fin save.\n",
      "epoch 9965\n",
      "test_train\n",
      "train mean loss=63190.79153645833\n",
      "test_test\n",
      "test mean loss=88065.671875\n",
      "fin save.\n",
      "epoch 9966\n",
      "test_train\n",
      "train mean loss=62951.73229166667\n",
      "test_test\n",
      "test mean loss=88120.90234375\n",
      "fin save.\n",
      "epoch 9967\n",
      "test_train\n",
      "train mean loss=62464.44036458333\n",
      "test_test\n",
      "test mean loss=88368.89453125\n",
      "fin save.\n",
      "epoch 9968\n",
      "test_train\n",
      "train mean loss=62269.720703125\n",
      "test_test\n",
      "test mean loss=88191.37890625\n",
      "fin save.\n",
      "epoch 9969\n",
      "test_train\n",
      "train mean loss=64619.44635416667\n",
      "test_test\n",
      "test mean loss=88323.33203125\n",
      "fin save.\n",
      "epoch 9970\n",
      "test_train\n",
      "train mean loss=63175.67578125\n",
      "test_test\n",
      "test mean loss=88519.5\n",
      "fin save.\n",
      "epoch 9971\n",
      "test_train\n",
      "train mean loss=62216.33203125\n",
      "test_test\n",
      "test mean loss=88696.58203125\n",
      "fin save.\n",
      "epoch 9972\n",
      "test_train\n",
      "train mean loss=62478.17630208333\n",
      "test_test\n",
      "test mean loss=88717.59375\n",
      "fin save.\n",
      "epoch 9973\n",
      "test_train\n",
      "train mean loss=61826.78697916667\n",
      "test_test\n",
      "test mean loss=88484.55078125\n",
      "fin save.\n",
      "epoch 9974\n",
      "test_train\n",
      "train mean loss=62517.540625\n",
      "test_test\n",
      "test mean loss=88657.17578125\n",
      "fin save.\n",
      "epoch 9975\n",
      "test_train\n",
      "train mean loss=61942.535807291664\n",
      "test_test\n",
      "test mean loss=88450.91015625\n",
      "fin save.\n",
      "epoch 9976\n",
      "test_train\n",
      "train mean loss=61898.059895833336\n",
      "test_test\n",
      "test mean loss=88415.96875\n",
      "fin save.\n",
      "epoch 9977\n",
      "test_train\n",
      "train mean loss=63109.196875\n",
      "test_test\n",
      "test mean loss=88362.84375\n",
      "fin save.\n",
      "epoch 9978\n",
      "test_train\n",
      "train mean loss=62526.3734375\n",
      "test_test\n",
      "test mean loss=88559.5703125\n",
      "fin save.\n",
      "epoch 9979\n",
      "test_train\n",
      "train mean loss=63017.37981770833\n",
      "test_test\n",
      "test mean loss=88453.9375\n",
      "fin save.\n",
      "epoch 9980\n",
      "test_train\n",
      "train mean loss=62382.65716145833\n",
      "test_test\n",
      "test mean loss=88432.51953125\n",
      "fin save.\n",
      "epoch 9981\n",
      "test_train\n",
      "train mean loss=62770.77838541667\n",
      "test_test\n",
      "test mean loss=88944.421875\n",
      "fin save.\n",
      "epoch 9982\n",
      "test_train\n",
      "train mean loss=62361.160416666666\n",
      "test_test\n",
      "test mean loss=88623.25390625\n",
      "fin save.\n",
      "epoch 9983\n",
      "test_train\n",
      "train mean loss=61502.72447916667\n",
      "test_test\n",
      "test mean loss=88823.72265625\n",
      "fin save.\n",
      "epoch 9984\n",
      "test_train\n",
      "train mean loss=63351.96432291667\n",
      "test_test\n",
      "test mean loss=88536.1796875\n",
      "fin save.\n",
      "epoch 9985\n",
      "test_train\n",
      "train mean loss=62640.802994791666\n",
      "test_test\n",
      "test mean loss=88600.06640625\n",
      "fin save.\n",
      "epoch 9986\n",
      "test_train\n",
      "train mean loss=62731.08697916667\n",
      "test_test\n",
      "test mean loss=88601.73046875\n",
      "fin save.\n",
      "epoch 9987\n",
      "test_train\n",
      "train mean loss=62242.6046875\n",
      "test_test\n",
      "test mean loss=88623.56640625\n",
      "fin save.\n",
      "epoch 9988\n",
      "test_train\n",
      "train mean loss=62927.41354166667\n",
      "test_test\n",
      "test mean loss=88321.94921875\n",
      "fin save.\n",
      "epoch 9989\n",
      "test_train\n",
      "train mean loss=62241.511458333334\n",
      "test_test\n",
      "test mean loss=88269.7109375\n",
      "fin save.\n",
      "epoch 9990\n",
      "test_train\n",
      "train mean loss=62783.34661458333\n",
      "test_test\n",
      "test mean loss=88252.0\n",
      "fin save.\n",
      "epoch 9991\n",
      "test_train\n",
      "train mean loss=62751.58098958333\n",
      "test_test\n",
      "test mean loss=88437.15234375\n",
      "fin save.\n",
      "epoch 9992\n",
      "test_train\n",
      "train mean loss=63807.20625\n",
      "test_test\n",
      "test mean loss=88588.859375\n",
      "fin save.\n",
      "epoch 9993\n",
      "test_train\n",
      "train mean loss=62452.82760416667\n",
      "test_test\n",
      "test mean loss=88549.015625\n",
      "fin save.\n",
      "epoch 9994\n",
      "test_train\n",
      "train mean loss=63705.26666666667\n",
      "test_test\n",
      "test mean loss=88398.29296875\n",
      "fin save.\n",
      "epoch 9995\n",
      "test_train\n",
      "train mean loss=62542.98098958333\n",
      "test_test\n",
      "test mean loss=88344.4765625\n",
      "fin save.\n",
      "epoch 9996\n",
      "test_train\n",
      "train mean loss=63013.61796875\n",
      "test_test\n",
      "test mean loss=88551.578125\n",
      "fin save.\n",
      "epoch 9997\n",
      "test_train\n",
      "train mean loss=62063.726302083334\n",
      "test_test\n",
      "test mean loss=88470.30078125\n",
      "fin save.\n",
      "epoch 9998\n",
      "test_train\n",
      "train mean loss=62456.528125\n",
      "test_test\n",
      "test mean loss=88409.13671875\n",
      "fin save.\n",
      "epoch 9999\n",
      "test_train\n",
      "train mean loss=62567.646875\n",
      "test_test\n",
      "test mean loss=88587.7265625\n",
      "fin save.\n",
      "epoch 10000\n",
      "test_train\n",
      "train mean loss=62465.25403645833\n",
      "test_test\n",
      "test mean loss=88675.546875\n",
      "fin save.\n"
     ]
    }
   ],
   "source": [
    "EPOCH = 10000\n",
    "net.train()\n",
    "train_100_loss = []\n",
    "test_100_loss = []\n",
    "train_100_state = []\n",
    "test_100_state = []\n",
    "for epoch in range(EPOCH):#EPOCH):\n",
    "    print('epoch', epoch+1)    #epoch数の出力\n",
    "    num = 0\n",
    "    for (inputs, labels, input_img, input_mask, input_mask2, label_mask, img_mask) in trainloader:\n",
    "    #for batch in trainloader:\n",
    "        #num += 1\n",
    "        #print(num)\n",
    "        inputs, labels, input_img, input_mask, input_mask2, label_mask, img_mask = \\\n",
    "        inputs.to(device), labels.to(device), input_img.to(device),\\\n",
    "        input_mask.to(device), input_mask2.to(device), label_mask.to(device), img_mask.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        handloc, pose_h, posedesc = net(input_img, inputs, input_mask, img_mask)\n",
    "        #print(\"inputs\", inputs[0])\n",
    "        #print(\"labels\", labels[0])\n",
    "        #print(\"handloc\", handloc[0])\n",
    "        #print(\"pose_h\", pose_h[0])\n",
    "        #print(\"posedesc\", posedesc[0])\n",
    "        #手首位置基準座標→物体位置基準座標\n",
    "        add = torch.zeros_like(pose_h).to(device)\n",
    "        for bsize in range(pose_h.size()[0]):\n",
    "            xval = handloc[bsize][0].item()\n",
    "            yval = handloc[bsize][1].item()\n",
    "            zval = handloc[bsize][2].item()\n",
    "            for i in range(int(pose_h.size()[1] / 3)):\n",
    "                add[bsize][i*3+0] = xval\n",
    "                add[bsize][i*3+1] = yval\n",
    "                add[bsize][i*3+2] = zval\n",
    "        pose_o = (pose_h + add).to(device)\n",
    "        #print(\"pose_o\", pose_o[0])\n",
    "        loss = criterion(pose_o, labels, input_mask2, label_mask)#crit_outputs, crit_labels)\n",
    "        #print(\"loss: \", loss)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    sum_loss = 0.0          #lossの合計\n",
    "    sum_total = 0           #dataの数の合計\n",
    "\n",
    "    print(\"test_train\")\n",
    "    ttrain = 0\n",
    "    #train dataを使ってテストをする(パラメータ更新がないようになっている)\n",
    "    for (inputs, labels, input_img, input_mask, input_mask2, label_mask, img_mask) in trainloader:\n",
    "        ttrain += 1\n",
    "        inputs, labels, input_img, input_mask, input_mask2, label_mask, img_mask = \\\n",
    "        inputs.to(device), labels.to(device), input_img.to(device),\\\n",
    "        input_mask.to(device), input_mask2.to(device), label_mask.to(device), img_mask.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        handloc, pose_h, posedesc = net(input_img, inputs, input_mask, img_mask)\n",
    "        #手首位置基準座標→物体位置基準座標\n",
    "        add = torch.zeros_like(pose_h).to(device)\n",
    "        for bsize in range(pose_h.size()[0]):\n",
    "            xval = handloc[bsize][0].item()\n",
    "            yval = handloc[bsize][1].item()\n",
    "            zval = handloc[bsize][2].item()\n",
    "            for i in range(int(pose_h.size()[1] / 3)):\n",
    "                add[bsize][i*3+0] = xval\n",
    "                add[bsize][i*3+1] = yval\n",
    "                add[bsize][i*3+2] = zval\n",
    "        pose_o = (pose_h + add).to(device)\n",
    "        if ttrain == int(train_size / BATCH_SIZE):\n",
    "            train_input_value.append(inputs.to(device_cpu))\n",
    "            train_output_value.append(pose_o.to(device_cpu))\n",
    "            train_desc_value.append(posedesc.to(device_cpu))\n",
    "            train_handloc_value.append(handloc.to(device_cpu))\n",
    "        loss = criterion(pose_o*100, labels*100, input_mask2, label_mask)\n",
    "        sum_loss += loss.item()                            #lossを足していく\n",
    "        sum_total += labels.size(0)                        #labelの数を足していくことでデータの総和を取る\n",
    "    #print(\"len train dataset: \", len(trainloader.dataset))\n",
    "    train_mean_loss = sum_loss*BATCH_SIZE/len(trainloader.dataset)\n",
    "    print(\"train mean loss={}\".format(train_mean_loss))  #loss出力\n",
    "    train_loss_value.append(train_mean_loss)  #traindataのlossをグラフ描画のためにlistに保持\n",
    "    train_100_loss.append(train_mean_loss)\n",
    "    train_100_state.append(net.state_dict())\n",
    "    if train_mean_loss > max_train_loss_value:\n",
    "        max_train_loss_value = train_mean_loss\n",
    "    if len(train_100_loss) == 100:\n",
    "        tr_idx = train_100_loss.index(min(train_100_loss))\n",
    "        torch.save(train_100_state[tr_idx], PATH + \"\\\\model_epoch\" + str(epoch+1) + \"_trainloss_\" + str(train_100_loss[tr_idx]))\n",
    "        train_100_loss.clear()\n",
    "        train_100_state.clear()\n",
    "\n",
    "    sum_loss = 0.0\n",
    "    sum_total = 0\n",
    "\n",
    "    print(\"test_test\")\n",
    "    ttest = 0\n",
    "    #test dataを使ってテストをする\n",
    "    for (inputs, labels, input_img, input_mask, input_mask2, label_mask, img_mask) in testloader:\n",
    "        ttest += 1\n",
    "        inputs, labels, input_img, input_mask, input_mask2, label_mask, img_mask = \\\n",
    "        inputs.to(device), labels.to(device), input_img.to(device),\\\n",
    "        input_mask.to(device), input_mask2.to(device), label_mask.to(device), img_mask.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        handloc, pose_h, posedesc = net(input_img, inputs, input_mask, img_mask)\n",
    "        #手首位置基準座標→物体位置基準座標\n",
    "        add = torch.zeros_like(pose_h).to(device)\n",
    "        for bsize in range(pose_h.size()[0]):\n",
    "            xval = handloc[bsize][0].item()\n",
    "            yval = handloc[bsize][1].item()\n",
    "            zval = handloc[bsize][2].item()\n",
    "            for i in range(int(pose_h.size()[1] / 3)):\n",
    "                add[bsize][i*3+0] = xval\n",
    "                add[bsize][i*3+1] = yval\n",
    "                add[bsize][i*3+2] = zval\n",
    "        pose_o = (pose_h + add).to(device)\n",
    "        if ttest == int(test_size / BATCH_SIZE):\n",
    "            test_input_value.append(inputs.to(device_cpu))\n",
    "            test_output_value.append(pose_o.to(device_cpu))\n",
    "            test_desc_value.append(posedesc.to(device_cpu))\n",
    "            test_handloc_value.append(handloc.to(device_cpu))\n",
    "        loss = criterion(pose_o*100, labels*100, input_mask2, label_mask)\n",
    "        sum_loss += loss.item()\n",
    "        sum_total += labels.size(0)\n",
    "    #print(\"len test dataset: \", len(testloader.dataset))\n",
    "    test_mean_loss = sum_loss*BATCH_SIZE/len(testloader.dataset)\n",
    "    print(\"test mean loss={}\".format(test_mean_loss))\n",
    "    test_loss_value.append(test_mean_loss)\n",
    "    test_100_loss.append(test_mean_loss)\n",
    "    test_100_state.append(net.state_dict())\n",
    "    if test_mean_loss > max_test_loss_value:\n",
    "        max_test_loss_value = test_mean_loss\n",
    "    if len(test_100_loss) == 100:\n",
    "        te_idx = test_100_loss.index(min(test_100_loss))\n",
    "        torch.save(test_100_state[te_idx], PATH + \"\\\\model_epoch\" + str(epoch+1) + \"_testloss_\" + str(test_100_loss[te_idx]))\n",
    "        test_100_loss.clear()\n",
    "        test_100_state.clear()\n",
    "    outcsv(epoch+1, train_input_value, train_output_value, train_desc_value, train_handloc_value,\\\n",
    "           test_input_value, test_output_value, test_desc_value, test_handloc_value)\n",
    "    saveloss(train_mean_loss, test_mean_loss)\n",
    "    train_input_value.clear()\n",
    "    train_output_value.clear()\n",
    "    train_desc_value.clear()\n",
    "    train_handloc_value.clear()\n",
    "    test_input_value.clear()\n",
    "    test_output_value.clear()\n",
    "    test_desc_value.clear()\n",
    "    test_handloc_value.clear()\n",
    "    #if (min_test_loss_value != None and test_mean_loss < min_test_loss_value) or min_test_loss_value == None:\n",
    "    #      min_test_loss_value = test_mean_loss\n",
    "    #      torch.save(net.state_dict(), PATH + \"\\\\model_epoch\" + str(epoch+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'nvidia-smi' は、内部コマンドまたは外部コマンド、\n",
      "操作可能なプログラムまたはバッチ ファイルとして認識されていません。\n"
     ]
    }
   ],
   "source": [
    "#for k, p in zip(keys, net.parameters()):\n",
    "#    print(k, \"\\n\", p, \"\\n\")\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Figure size 504x504 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(7,7))      #グラフ描画用\n",
    "train_loss_value = []\n",
    "test_loss_value = []\n",
    "with open(PATH + \"\\\\outputs\\\\loss_values.csv\", mode=\"r\") as f:\n",
    "    reader = csv.reader(f)\n",
    "    for row in reader:\n",
    "        train_loss_value.append(float(row[0]))\n",
    "        test_loss_value.append(float(row[1]))\n",
    "max_train_loss_value = max(train_loss_value)\n",
    "max_test_loss_value = max(test_loss_value)\n",
    "ylim = max(max_train_loss_value, max_test_loss_value)\n",
    "\n",
    "baseEPOCH = 100\n",
    "num_epoch = 1\n",
    "#act_num_epoch = baseEPOCH * num_epoch\n",
    "act_num_epoch = len(train_loss_value)\n",
    "\n",
    "#以下グラフ描画\n",
    "plt.plot(range(act_num_epoch), train_loss_value)\n",
    "plt.plot(range(act_num_epoch), test_loss_value, c='#00ff00')\n",
    "plt.xlim(0, act_num_epoch)\n",
    "plt.ylim(0, ylim)\n",
    "plt.xlabel('EPOCH')\n",
    "plt.ylabel('LOSS(mm^2)')\n",
    "plt.legend(['train loss', 'test loss'])\n",
    "plt.title('loocation and pose LOSS')\n",
    "plt.savefig(PATH + \"\\\\loss_image_\" + str(act_num_epoch) + \".png\")\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "#matplotlib.use('Agg')\n",
    "import seaborn as sns\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "#結果画像出力\n",
    "target_epoch = 19\n",
    "\n",
    "HAND_PNT_NUM = 21\n",
    "\n",
    "#fig = plt.figure(figsize=(6,6))\n",
    "fig = plt.figure()\n",
    "for i in range(len(train_input_value[target_epoch])):\n",
    "    input_x = []\n",
    "    input_y = []\n",
    "    input_z = []\n",
    "    mid = []\n",
    "    output_x = []\n",
    "    output_y = []\n",
    "    output_z = []\n",
    "    connect_x = []\n",
    "    connect_y = []\n",
    "    connect_z = []\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    for j in range(int(len(train_input_value[target_epoch][0])/3)):\n",
    "        input_x.append(train_input_value[target_epoch][i][j*3+0].item())\n",
    "        input_y.append(-1*train_input_value[target_epoch][i][j*3+1].item())\n",
    "        input_z.append(train_input_value[target_epoch][i][j*3+2].item())\n",
    "        output_x.append(train_output_value[target_epoch][i][j*3+0].item())\n",
    "        output_y.append(-1*train_output_value[target_epoch][i][j*3+1].item())\n",
    "        output_z.append(train_output_value[target_epoch][i][j*3+2].item())\n",
    "    x_max = max([max(input_x), max(output_x)], default = -10000)\n",
    "    x_min = min([min(input_x), min(output_x)], default = 10000)\n",
    "    y_max = max([max(input_y), max(output_y)], default = -10000)\n",
    "    y_min = min([min(input_y), min(output_y)], default = 10000)\n",
    "    z_max = max([max(input_z), max(output_z)], default = -10000)\n",
    "    z_min = min([min(input_z), min(output_z)], default = 10000)\n",
    "    \n",
    "    #print(x_min, x_max, y_min, y_max, z_min, z_max, \"(fixed: x_min, x_max, y_min, y_max, z_min, z_max)\")\n",
    "    \n",
    "    #点が描画範囲内かどうか\n",
    "    isInputPointsIn = [False] * HAND_PNT_NUM\n",
    "    isOutputPointsIn = [False] * HAND_PNT_NUM\n",
    "    #print(isPointsIn)\n",
    "    \n",
    "    for p in range(HAND_PNT_NUM):\n",
    "        if x_min <= input_x[p] <= x_max and y_min <= input_y[p] <= y_max and z_min <= input_z[p] <= z_max:\n",
    "            isInputPointsIn[p] = True\n",
    "        if x_min <= output_x[p] <= x_max and y_min <= output_y[p] <= y_max and z_min <= output_z[p] <= z_max:\n",
    "            isOutputPointsIn[p] = True\n",
    "    \n",
    "    #各点をプロット\n",
    "    ax.scatter(input_x[0], input_y[0], zs=input_z[0], zdir='y', s=10, c='#e53528', marker = \".\")\n",
    "    ax.scatter(input_x[1], input_y[1], zs=input_z[1], zdir='y', s=10, c='#e77340', marker = \".\")\n",
    "    ax.scatter(input_x[2], input_y[2], zs=input_z[2], zdir='y', s=10, c='#eb8e25', marker = \".\")\n",
    "    ax.scatter(input_x[3], input_y[3], zs=input_z[3], zdir='y', s=10, c='#d7a10e', marker = \".\")\n",
    "    ax.scatter(input_x[4], input_y[4], zs=input_z[4], zdir='y', s=10, c='#d9c812', marker = \".\")\n",
    "    ax.scatter(input_x[5], input_y[5], zs=input_z[5], zdir='y', s=10, c='#a7cf21', marker = \".\")\n",
    "    ax.scatter(input_x[6], input_y[6], zs=input_z[6], zdir='y', s=10, c='#7fe545', marker = \".\")\n",
    "    ax.scatter(input_x[7], input_y[7], zs=input_z[7], zdir='y', s=10, c='#53d62d', marker = \".\")\n",
    "    ax.scatter(input_x[8], input_y[8], zs=input_z[8], zdir='y', s=10, c='#4abc2f', marker = \".\")\n",
    "    ax.scatter(input_x[9], input_y[9], zs=input_z[9], zdir='y', s=10, c='#52d686', marker = \".\")\n",
    "    ax.scatter(input_x[10], input_y[10], zs=input_z[10], zdir='y', s=10, c='#52dfbe', marker = \".\")\n",
    "    ax.scatter(input_x[11], input_y[11], zs=input_z[11], zdir='y', s=10, c='#52b9c5', marker = \".\")\n",
    "    ax.scatter(input_x[12], input_y[12], zs=input_z[12], zdir='y', s=10, c='#508ab7', marker = \".\")\n",
    "    ax.scatter(input_x[13], input_y[13], zs=input_z[13], zdir='y', s=10, c='#556fd0', marker = \".\")\n",
    "    ax.scatter(input_x[14], input_y[14], zs=input_z[14], zdir='y', s=10, c='#5245d5', marker = \".\")\n",
    "    ax.scatter(input_x[15], input_y[15], zs=input_z[15], zdir='y', s=10, c='#7e2fba', marker = \".\")\n",
    "    ax.scatter(input_x[16], input_y[16], zs=input_z[16], zdir='y', s=10, c='#bc64fb', marker = \".\")\n",
    "    ax.scatter(input_x[17], input_y[17], zs=input_z[17], zdir='y', s=10, c='#da53e8', marker = \".\")\n",
    "    ax.scatter(input_x[18], input_y[18], zs=input_z[18], zdir='y', s=10, c='#eb45bc', marker = \".\")\n",
    "    ax.scatter(input_x[19], input_y[19], zs=input_z[19], zdir='y', s=10, c='#ec3c89', marker = \".\")\n",
    "    ax.scatter(input_x[20], input_y[20], zs=input_z[20], zdir='y', s=10, c='#ff6691', marker = \".\")\n",
    "    \n",
    "    #点同士を結ぶ\n",
    "    if isInputPointsIn[0] and isInputPointsIn[1]:\n",
    "        ax.plot([input_x[0],input_x[1]], [input_y[0],input_y[1]], [input_z[0],input_z[1]], zdir='y', c='#cc0000')\n",
    "    if isInputPointsIn[1] and isInputPointsIn[2]:\n",
    "        ax.plot([input_x[1],input_x[2]], [input_y[1],input_y[2]], [input_z[1],input_z[2]], zdir='y', c='#b30000')\n",
    "    if isInputPointsIn[2] and isInputPointsIn[3]:\n",
    "        ax.plot([input_x[2],input_x[3]], [input_y[2],input_y[3]], [input_z[2],input_z[3]], zdir='y', c='#e60000')\n",
    "    if isInputPointsIn[3] and isInputPointsIn[4]:\n",
    "        ax.plot([input_x[3],input_x[4]], [input_y[3],input_y[4]], [input_z[3],input_z[4]], zdir='y', c='#ff0000')\n",
    "    if isInputPointsIn[0] and isInputPointsIn[5]:\n",
    "        ax.plot([input_x[0],input_x[5]], [input_y[0],input_y[5]], [input_z[0],input_z[5]], zdir='y', c='#a3cc00')\n",
    "    if isInputPointsIn[5] and isInputPointsIn[6]:\n",
    "        ax.plot([input_x[5],input_x[6]], [input_y[5],input_y[6]], [input_z[5],input_z[6]], zdir='y', c='#8fb300')\n",
    "    if isInputPointsIn[6] and isInputPointsIn[7]:        \n",
    "        ax.plot([input_x[6],input_x[7]], [input_y[6],input_y[7]], [input_z[6],input_z[7]], zdir='y', c='#b8e600')\n",
    "    if isInputPointsIn[7] and isInputPointsIn[8]:\n",
    "        ax.plot([input_x[7],input_x[8]], [input_y[7],input_y[8]], [input_z[7],input_z[8]], zdir='y', c='#ccff00')\n",
    "    if isInputPointsIn[0] and isInputPointsIn[9]:\n",
    "        ax.plot([input_x[0],input_x[9]], [input_y[0],input_y[9]], [input_z[0],input_z[9]], zdir='y', c='#00cc52')\n",
    "    if isInputPointsIn[9] and isInputPointsIn[10]:\n",
    "        ax.plot([input_x[9],input_x[10]], [input_y[9],input_y[10]], [input_z[9],input_z[10]], zdir='y', c='#00b347')\n",
    "    if isInputPointsIn[10] and isInputPointsIn[11]:\n",
    "        ax.plot([input_x[10],input_x[11]], [input_y[10],input_y[11]], [input_z[10],input_z[11]], zdir='y', c='#00e65c')\n",
    "    if isInputPointsIn[11] and isInputPointsIn[12]:\n",
    "        ax.plot([input_x[11],input_x[12]], [input_y[11],input_y[12]], [input_z[11],input_z[12]], zdir='y', c='#00ff66')\n",
    "    if isInputPointsIn[0] and isInputPointsIn[13]:\n",
    "        ax.plot([input_x[0],input_x[13]], [input_y[0],input_y[13]], [input_z[0],input_z[13]], zdir='y', c='#0052cc')\n",
    "    if isInputPointsIn[13] and isInputPointsIn[14]:\n",
    "        ax.plot([input_x[13],input_x[14]], [input_y[13],input_y[14]], [input_z[13],input_z[14]], zdir='y', c='#0047b3')\n",
    "    if isInputPointsIn[14] and isInputPointsIn[15]:\n",
    "        ax.plot([input_x[14],input_x[15]], [input_y[14],input_y[15]], [input_z[14],input_z[15]], zdir='y', c='#005ce6')\n",
    "    if isInputPointsIn[15] and isInputPointsIn[16]:\n",
    "        ax.plot([input_x[15],input_x[16]], [input_y[15],input_y[16]], [input_z[15],input_z[16]], zdir='y', c='#0066ff')\n",
    "    if isInputPointsIn[0] and isInputPointsIn[17]:\n",
    "        ax.plot([input_x[0],input_x[17]], [input_y[0],input_y[17]], [input_z[0],input_z[17]], zdir='y', c='#a300cc')\n",
    "    if isInputPointsIn[17] and isInputPointsIn[18]:\n",
    "        ax.plot([input_x[17],input_x[18]], [input_y[17],input_y[18]], [input_z[17],input_z[18]], zdir='y', c='#8f00b3')\n",
    "    if isInputPointsIn[18] and isInputPointsIn[19]:\n",
    "        ax.plot([input_x[18],input_x[19]], [input_y[18],input_y[19]], [input_z[18],input_z[19]], zdir='y', c='#b800e6')\n",
    "    if isInputPointsIn[19] and isInputPointsIn[20]:\n",
    "        ax.plot([input_x[19],input_x[20]], [input_y[19],input_y[20]], [input_z[19],input_z[20]], zdir='y', c='#cc00ff')\n",
    "    \n",
    "    ##stradrs = str(train_adrs[target_epoch][i].item()) #202011221813290002\n",
    "    ##d_adrs = \"dataset_\" + stradrs[4:8] + \"_\" + stradrs[8:14] + \"_\" + stradrs[14:]\n",
    "    ##ax.set_title('input(train data, ' + str(target_epoch+1) + 'th epoch)\\n' + d_adrs)\n",
    "    ax.set_title('input(train data, ' + str(target_epoch+1) + 'th epoch)\\n' + str(i))\n",
    "    ax.set_xlim([x_min, x_max])\n",
    "    ax.set_ylim([z_min, z_max])\n",
    "    ax.set_zlim([y_min, y_max])\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('z')\n",
    "    ax.set_zlabel('y')\n",
    "    #plt.subplots_adjust(left=0.04, right=0.80, bottom=0.04, top=0.80)\n",
    "    #ax.legend(loc='upper right')\n",
    "    fig.savefig(PATH + \"\\\\outputs\\\\Input_train_\" + str(target_epoch) + \"th_epoch_\" + str(i) + \".png\", dpi = 300, transparent = False, bbox_inches = 'tight', pad_inches = 0)\n",
    "    fig.clf()\n",
    "    \n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    #各点をプロット\n",
    "    ax.scatter(output_x[0], output_y[0], zs=output_z[0], zdir='y', s=10, c='#e53528', marker = \".\")\n",
    "    ax.scatter(output_x[1], output_y[1], zs=output_z[1], zdir='y', s=10, c='#e77340', marker = \".\")\n",
    "    ax.scatter(output_x[2], output_y[2], zs=output_z[2], zdir='y', s=10, c='#eb8e25', marker = \".\")\n",
    "    ax.scatter(output_x[3], output_y[3], zs=output_z[3], zdir='y', s=10, c='#d7a10e', marker = \".\")\n",
    "    ax.scatter(output_x[4], output_y[4], zs=output_z[4], zdir='y', s=10, c='#d9c812', marker = \".\")\n",
    "    ax.scatter(output_x[5], output_y[5], zs=output_z[5], zdir='y', s=10, c='#a7cf21', marker = \".\")\n",
    "    ax.scatter(output_x[6], output_y[6], zs=output_z[6], zdir='y', s=10, c='#7fe545', marker = \".\")\n",
    "    ax.scatter(output_x[7], output_y[7], zs=output_z[7], zdir='y', s=10, c='#53d62d', marker = \".\")\n",
    "    ax.scatter(output_x[8], output_y[8], zs=output_z[8], zdir='y', s=10, c='#4abc2f', marker = \".\")\n",
    "    ax.scatter(output_x[9], output_y[9], zs=output_z[9], zdir='y', s=10, c='#52d686', marker = \".\")\n",
    "    ax.scatter(output_x[10], output_y[10], zs=output_z[10], zdir='y', s=10, c='#52dfbe', marker = \".\")\n",
    "    ax.scatter(output_x[11], output_y[11], zs=output_z[11], zdir='y', s=10, c='#52b9c5', marker = \".\")\n",
    "    ax.scatter(output_x[12], output_y[12], zs=output_z[12], zdir='y', s=10, c='#508ab7', marker = \".\")\n",
    "    ax.scatter(output_x[13], output_y[13], zs=output_z[13], zdir='y', s=10, c='#556fd0', marker = \".\")\n",
    "    ax.scatter(output_x[14], output_y[14], zs=output_z[14], zdir='y', s=10, c='#5245d5', marker = \".\")\n",
    "    ax.scatter(output_x[15], output_y[15], zs=output_z[15], zdir='y', s=10, c='#7e2fba', marker = \".\")\n",
    "    ax.scatter(output_x[16], output_y[16], zs=output_z[16], zdir='y', s=10, c='#bc64fb', marker = \".\")\n",
    "    ax.scatter(output_x[17], output_y[17], zs=output_z[17], zdir='y', s=10, c='#da53e8', marker = \".\")\n",
    "    ax.scatter(output_x[18], output_y[18], zs=output_z[18], zdir='y', s=10, c='#eb45bc', marker = \".\")\n",
    "    ax.scatter(output_x[19], output_y[19], zs=output_z[19], zdir='y', s=10, c='#ec3c89', marker = \".\")\n",
    "    ax.scatter(output_x[20], output_y[20], zs=output_z[20], zdir='y', s=10, c='#ff6691', marker = \".\")\n",
    "    \n",
    "    #点同士を結ぶ\n",
    "    if isOutputPointsIn[0] and isOutputPointsIn[1]:\n",
    "        ax.plot([output_x[0],output_x[1]], [output_y[0],output_y[1]], [output_z[0],output_z[1]], zdir='y', c='#cc0000')\n",
    "    if isOutputPointsIn[1] and isOutputPointsIn[2]:\n",
    "        ax.plot([output_x[1],output_x[2]], [output_y[1],output_y[2]], [output_z[1],output_z[2]], zdir='y', c='#b30000')\n",
    "    if isOutputPointsIn[2] and isOutputPointsIn[3]:\n",
    "        ax.plot([output_x[2],output_x[3]], [output_y[2],output_y[3]], [output_z[2],output_z[3]], zdir='y', c='#e60000')\n",
    "    if isOutputPointsIn[3] and isOutputPointsIn[4]:\n",
    "        ax.plot([output_x[3],output_x[4]], [output_y[3],output_y[4]], [output_z[3],output_z[4]], zdir='y', c='#ff0000')\n",
    "    if isOutputPointsIn[0] and isOutputPointsIn[5]:\n",
    "        ax.plot([output_x[0],output_x[5]], [output_y[0],output_y[5]], [output_z[0],output_z[5]], zdir='y', c='#a3cc00')\n",
    "    if isOutputPointsIn[5] and isOutputPointsIn[6]:\n",
    "        ax.plot([output_x[5],output_x[6]], [output_y[5],output_y[6]], [output_z[5],output_z[6]], zdir='y', c='#8fb300')\n",
    "    if isOutputPointsIn[6] and isOutputPointsIn[7]:        \n",
    "        ax.plot([output_x[6],output_x[7]], [output_y[6],output_y[7]], [output_z[6],output_z[7]], zdir='y', c='#b8e600')\n",
    "    if isOutputPointsIn[7] and isOutputPointsIn[8]:\n",
    "        ax.plot([output_x[7],output_x[8]], [output_y[7],output_y[8]], [output_z[7],output_z[8]], zdir='y', c='#ccff00')\n",
    "    if isOutputPointsIn[0] and isOutputPointsIn[9]:\n",
    "        ax.plot([output_x[0],output_x[9]], [output_y[0],output_y[9]], [output_z[0],output_z[9]], zdir='y', c='#00cc52')\n",
    "    if isOutputPointsIn[9] and isOutputPointsIn[10]:\n",
    "        ax.plot([output_x[9],output_x[10]], [output_y[9],output_y[10]], [output_z[9],output_z[10]], zdir='y', c='#00b347')\n",
    "    if isOutputPointsIn[10] and isOutputPointsIn[11]:\n",
    "        ax.plot([output_x[10],output_x[11]], [output_y[10],output_y[11]], [output_z[10],output_z[11]], zdir='y', c='#00e65c')\n",
    "    if isOutputPointsIn[11] and isOutputPointsIn[12]:\n",
    "        ax.plot([output_x[11],output_x[12]], [output_y[11],output_y[12]], [output_z[11],output_z[12]], zdir='y', c='#00ff66')\n",
    "    if isOutputPointsIn[0] and isOutputPointsIn[13]:\n",
    "        ax.plot([output_x[0],output_x[13]], [output_y[0],output_y[13]], [output_z[0],output_z[13]], zdir='y', c='#0052cc')\n",
    "    if isOutputPointsIn[13] and isOutputPointsIn[14]:\n",
    "        ax.plot([output_x[13],output_x[14]], [output_y[13],output_y[14]], [output_z[13],output_z[14]], zdir='y', c='#0047b3')\n",
    "    if isOutputPointsIn[14] and isOutputPointsIn[15]:\n",
    "        ax.plot([output_x[14],output_x[15]], [output_y[14],output_y[15]], [output_z[14],output_z[15]], zdir='y', c='#005ce6')\n",
    "    if isOutputPointsIn[15] and isOutputPointsIn[16]:\n",
    "        ax.plot([output_x[15],output_x[16]], [output_y[15],output_y[16]], [output_z[15],output_z[16]], zdir='y', c='#0066ff')\n",
    "    if isOutputPointsIn[0] and isOutputPointsIn[17]:\n",
    "        ax.plot([output_x[0],output_x[17]], [output_y[0],output_y[17]], [output_z[0],output_z[17]], zdir='y', c='#a300cc')\n",
    "    if isOutputPointsIn[17] and isOutputPointsIn[18]:\n",
    "        ax.plot([output_x[17],output_x[18]], [output_y[17],output_y[18]], [output_z[17],output_z[18]], zdir='y', c='#8f00b3')\n",
    "    if isOutputPointsIn[18] and isOutputPointsIn[19]:\n",
    "        ax.plot([output_x[18],output_x[19]], [output_y[18],output_y[19]], [output_z[18],output_z[19]], zdir='y', c='#b800e6')\n",
    "    if isOutputPointsIn[19] and isOutputPointsIn[20]:\n",
    "        ax.plot([output_x[19],output_x[20]], [output_y[19],output_y[20]], [output_z[19],output_z[20]], zdir='y', c='#cc00ff')\n",
    "    #ax.scatter(input_x, input_y, c='red', label = 'input')\n",
    "    #ax.scatter(output_x, output_y, c='blue', label = 'output')\n",
    "    \n",
    "    #3stradrs = str(train_adrs[target_epoch][i].item()) #202011221813290002\n",
    "    ##d_adrs = \"dataset_\" + stradrs[4:8] + \"_\" + stradrs[8:14] + \"_\" + stradrs[14:]\n",
    "    ##ax.set_title('output(train data, ' + str(target_epoch+1) + 'th epoch)\\n' + d_adrs)\n",
    "    ax.set_title('output(train data, ' + str(target_epoch+1) + 'th epoch)\\n' + str(i))\n",
    "    ax.set_xlim([x_min, x_max])\n",
    "    ax.set_ylim([z_min, z_max])\n",
    "    ax.set_zlim([y_min, y_max])\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('z')\n",
    "    ax.set_zlabel('y')\n",
    "    #plt.subplots_adjust(left=0.04, right=0.80, bottom=0.04, top=0.80)\n",
    "    #ax.legend(loc='upper right')\n",
    "    fig.savefig(PATH + \"\\\\outputs\\\\Output_train_\" + str(target_epoch) + \"th_epoch_\" + str(i) + \".png\", dpi = 300,transparent = False, bbox_inches = 'tight', pad_inches = 0)\n",
    "    fig.clf()\n",
    "for i in range(len(test_input_value[target_epoch])):\n",
    "    input_x = []\n",
    "    input_y = []\n",
    "    input_z = []\n",
    "    mid = []\n",
    "    output_x = []\n",
    "    output_y = []\n",
    "    output_z = []\n",
    "    connect_x = []\n",
    "    connect_y = []\n",
    "    connect_z = []\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    for j in range(int(len(test_input_value[target_epoch][0])/3)):\n",
    "        input_x.append(test_input_value[target_epoch][i][j*3+0].item())\n",
    "        input_y.append(-1*test_input_value[target_epoch][i][j*3+1].item())\n",
    "        input_z.append(test_input_value[target_epoch][i][j*3+2].item())\n",
    "        output_x.append(test_output_value[target_epoch][i][j*3+0].item())\n",
    "        output_y.append(-1*test_output_value[target_epoch][i][j*3+1].item())\n",
    "        output_z.append(test_output_value[target_epoch][i][j*3+2].item())\n",
    "    x_max = max([max(input_x), max(output_x)], default = -10000)\n",
    "    x_min = min([min(input_x), min(output_x)], default = 10000)\n",
    "    y_max = max([max(input_y), max(output_y)], default = -10000)\n",
    "    y_min = min([min(input_y), min(output_y)], default = 10000)\n",
    "    z_max = max([max(input_z), max(output_z)], default = -10000)\n",
    "    z_min = min([min(input_z), min(output_z)], default = 10000)\n",
    "    \n",
    "    #print(x_min, x_max, y_min, y_max, z_min, z_max, \"(fixed: x_min, x_max, y_min, y_max, z_min, z_max)\")\n",
    "    \n",
    "    #点が描画範囲内かどうか\n",
    "    isInputPointsIn = [False] * HAND_PNT_NUM\n",
    "    isOutputPointsIn = [False] * HAND_PNT_NUM\n",
    "    #print(isPointsIn)\n",
    "    \n",
    "    for p in range(HAND_PNT_NUM):\n",
    "        if x_min <= input_x[p] <= x_max and y_min <= input_y[p] <= y_max and z_min <= input_z[p] <= z_max:\n",
    "            isInputPointsIn[p] = True\n",
    "        if x_min <= output_x[p] <= x_max and y_min <= output_y[p] <= y_max and z_min <= output_z[p] <= z_max:\n",
    "            isOutputPointsIn[p] = True\n",
    "    \n",
    "    #各点をプロット\n",
    "    ax.scatter(input_x[0], input_y[0], zs=input_z[0], zdir='y', s=10, c='#e53528', marker = \".\")\n",
    "    ax.scatter(input_x[1], input_y[1], zs=input_z[1], zdir='y', s=10, c='#e77340', marker = \".\")\n",
    "    ax.scatter(input_x[2], input_y[2], zs=input_z[2], zdir='y', s=10, c='#eb8e25', marker = \".\")\n",
    "    ax.scatter(input_x[3], input_y[3], zs=input_z[3], zdir='y', s=10, c='#d7a10e', marker = \".\")\n",
    "    ax.scatter(input_x[4], input_y[4], zs=input_z[4], zdir='y', s=10, c='#d9c812', marker = \".\")\n",
    "    ax.scatter(input_x[5], input_y[5], zs=input_z[5], zdir='y', s=10, c='#a7cf21', marker = \".\")\n",
    "    ax.scatter(input_x[6], input_y[6], zs=input_z[6], zdir='y', s=10, c='#7fe545', marker = \".\")\n",
    "    ax.scatter(input_x[7], input_y[7], zs=input_z[7], zdir='y', s=10, c='#53d62d', marker = \".\")\n",
    "    ax.scatter(input_x[8], input_y[8], zs=input_z[8], zdir='y', s=10, c='#4abc2f', marker = \".\")\n",
    "    ax.scatter(input_x[9], input_y[9], zs=input_z[9], zdir='y', s=10, c='#52d686', marker = \".\")\n",
    "    ax.scatter(input_x[10], input_y[10], zs=input_z[10], zdir='y', s=10, c='#52dfbe', marker = \".\")\n",
    "    ax.scatter(input_x[11], input_y[11], zs=input_z[11], zdir='y', s=10, c='#52b9c5', marker = \".\")\n",
    "    ax.scatter(input_x[12], input_y[12], zs=input_z[12], zdir='y', s=10, c='#508ab7', marker = \".\")\n",
    "    ax.scatter(input_x[13], input_y[13], zs=input_z[13], zdir='y', s=10, c='#556fd0', marker = \".\")\n",
    "    ax.scatter(input_x[14], input_y[14], zs=input_z[14], zdir='y', s=10, c='#5245d5', marker = \".\")\n",
    "    ax.scatter(input_x[15], input_y[15], zs=input_z[15], zdir='y', s=10, c='#7e2fba', marker = \".\")\n",
    "    ax.scatter(input_x[16], input_y[16], zs=input_z[16], zdir='y', s=10, c='#bc64fb', marker = \".\")\n",
    "    ax.scatter(input_x[17], input_y[17], zs=input_z[17], zdir='y', s=10, c='#da53e8', marker = \".\")\n",
    "    ax.scatter(input_x[18], input_y[18], zs=input_z[18], zdir='y', s=10, c='#eb45bc', marker = \".\")\n",
    "    ax.scatter(input_x[19], input_y[19], zs=input_z[19], zdir='y', s=10, c='#ec3c89', marker = \".\")\n",
    "    ax.scatter(input_x[20], input_y[20], zs=input_z[20], zdir='y', s=10, c='#ff6691', marker = \".\")\n",
    "    \n",
    "    #点同士を結ぶ\n",
    "    if isInputPointsIn[0] and isInputPointsIn[1]:\n",
    "        ax.plot([input_x[0],input_x[1]], [input_y[0],input_y[1]], [input_z[0],input_z[1]], zdir='y', c='#cc0000')\n",
    "    if isInputPointsIn[1] and isInputPointsIn[2]:\n",
    "        ax.plot([input_x[1],input_x[2]], [input_y[1],input_y[2]], [input_z[1],input_z[2]], zdir='y', c='#b30000')\n",
    "    if isInputPointsIn[2] and isInputPointsIn[3]:\n",
    "        ax.plot([input_x[2],input_x[3]], [input_y[2],input_y[3]], [input_z[2],input_z[3]], zdir='y', c='#e60000')\n",
    "    if isInputPointsIn[3] and isInputPointsIn[4]:\n",
    "        ax.plot([input_x[3],input_x[4]], [input_y[3],input_y[4]], [input_z[3],input_z[4]], zdir='y', c='#ff0000')\n",
    "    if isInputPointsIn[0] and isInputPointsIn[5]:\n",
    "        ax.plot([input_x[0],input_x[5]], [input_y[0],input_y[5]], [input_z[0],input_z[5]], zdir='y', c='#a3cc00')\n",
    "    if isInputPointsIn[5] and isInputPointsIn[6]:\n",
    "        ax.plot([input_x[5],input_x[6]], [input_y[5],input_y[6]], [input_z[5],input_z[6]], zdir='y', c='#8fb300')\n",
    "    if isInputPointsIn[6] and isInputPointsIn[7]:        \n",
    "        ax.plot([input_x[6],input_x[7]], [input_y[6],input_y[7]], [input_z[6],input_z[7]], zdir='y', c='#b8e600')\n",
    "    if isInputPointsIn[7] and isInputPointsIn[8]:\n",
    "        ax.plot([input_x[7],input_x[8]], [input_y[7],input_y[8]], [input_z[7],input_z[8]], zdir='y', c='#ccff00')\n",
    "    if isInputPointsIn[0] and isInputPointsIn[9]:\n",
    "        ax.plot([input_x[0],input_x[9]], [input_y[0],input_y[9]], [input_z[0],input_z[9]], zdir='y', c='#00cc52')\n",
    "    if isInputPointsIn[9] and isInputPointsIn[10]:\n",
    "        ax.plot([input_x[9],input_x[10]], [input_y[9],input_y[10]], [input_z[9],input_z[10]], zdir='y', c='#00b347')\n",
    "    if isInputPointsIn[10] and isInputPointsIn[11]:\n",
    "        ax.plot([input_x[10],input_x[11]], [input_y[10],input_y[11]], [input_z[10],input_z[11]], zdir='y', c='#00e65c')\n",
    "    if isInputPointsIn[11] and isInputPointsIn[12]:\n",
    "        ax.plot([input_x[11],input_x[12]], [input_y[11],input_y[12]], [input_z[11],input_z[12]], zdir='y', c='#00ff66')\n",
    "    if isInputPointsIn[0] and isInputPointsIn[13]:\n",
    "        ax.plot([input_x[0],input_x[13]], [input_y[0],input_y[13]], [input_z[0],input_z[13]], zdir='y', c='#0052cc')\n",
    "    if isInputPointsIn[13] and isInputPointsIn[14]:\n",
    "        ax.plot([input_x[13],input_x[14]], [input_y[13],input_y[14]], [input_z[13],input_z[14]], zdir='y', c='#0047b3')\n",
    "    if isInputPointsIn[14] and isInputPointsIn[15]:\n",
    "        ax.plot([input_x[14],input_x[15]], [input_y[14],input_y[15]], [input_z[14],input_z[15]], zdir='y', c='#005ce6')\n",
    "    if isInputPointsIn[15] and isInputPointsIn[16]:\n",
    "        ax.plot([input_x[15],input_x[16]], [input_y[15],input_y[16]], [input_z[15],input_z[16]], zdir='y', c='#0066ff')\n",
    "    if isInputPointsIn[0] and isInputPointsIn[17]:\n",
    "        ax.plot([input_x[0],input_x[17]], [input_y[0],input_y[17]], [input_z[0],input_z[17]], zdir='y', c='#a300cc')\n",
    "    if isInputPointsIn[17] and isInputPointsIn[18]:\n",
    "        ax.plot([input_x[17],input_x[18]], [input_y[17],input_y[18]], [input_z[17],input_z[18]], zdir='y', c='#8f00b3')\n",
    "    if isInputPointsIn[18] and isInputPointsIn[19]:\n",
    "        ax.plot([input_x[18],input_x[19]], [input_y[18],input_y[19]], [input_z[18],input_z[19]], zdir='y', c='#b800e6')\n",
    "    if isInputPointsIn[19] and isInputPointsIn[20]:\n",
    "        ax.plot([input_x[19],input_x[20]], [input_y[19],input_y[20]], [input_z[19],input_z[20]], zdir='y', c='#cc00ff')\n",
    "    \n",
    "    ##stradrs = str(test_adrs[target_epoch][i].item()) #202011221813290002\n",
    "    ##d_adrs = \"dataset_\" + stradrs[4:8] + \"_\" + stradrs[8:14] + \"_\" + stradrs[14:]\n",
    "    ##ax.set_title('input(test data, ' + str(target_epoch+1) + 'th epoch)\\n' + d_adrs)\n",
    "    ax.set_title('input(test data, ' + str(target_epoch+1) + 'th epoch)\\n' + str(i))\n",
    "    ax.set_xlim([x_min, x_max])\n",
    "    ax.set_ylim([z_min, z_max])\n",
    "    ax.set_zlim([y_min, y_max])\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('z')\n",
    "    ax.set_zlabel('y')\n",
    "    #plt.subplots_adjust(left=0.04, right=0.80, bottom=0.04, top=0.80)\n",
    "    #ax.legend(loc='upper right')\n",
    "    fig.savefig(PATH + \"\\\\outputs\\\\Input_test_\" + str(target_epoch) + \"th_epoch_\" + str(i) + \".png\", dpi = 300, transparent = False, bbox_inches = 'tight', pad_inches = 0)\n",
    "    fig.clf()\n",
    "    \n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    #各点をプロット\n",
    "    ax.scatter(output_x[0], output_y[0], zs=output_z[0], zdir='y', s=10, c='#e53528', marker = \".\")\n",
    "    ax.scatter(output_x[1], output_y[1], zs=output_z[1], zdir='y', s=10, c='#e77340', marker = \".\")\n",
    "    ax.scatter(output_x[2], output_y[2], zs=output_z[2], zdir='y', s=10, c='#eb8e25', marker = \".\")\n",
    "    ax.scatter(output_x[3], output_y[3], zs=output_z[3], zdir='y', s=10, c='#d7a10e', marker = \".\")\n",
    "    ax.scatter(output_x[4], output_y[4], zs=output_z[4], zdir='y', s=10, c='#d9c812', marker = \".\")\n",
    "    ax.scatter(output_x[5], output_y[5], zs=output_z[5], zdir='y', s=10, c='#a7cf21', marker = \".\")\n",
    "    ax.scatter(output_x[6], output_y[6], zs=output_z[6], zdir='y', s=10, c='#7fe545', marker = \".\")\n",
    "    ax.scatter(output_x[7], output_y[7], zs=output_z[7], zdir='y', s=10, c='#53d62d', marker = \".\")\n",
    "    ax.scatter(output_x[8], output_y[8], zs=output_z[8], zdir='y', s=10, c='#4abc2f', marker = \".\")\n",
    "    ax.scatter(output_x[9], output_y[9], zs=output_z[9], zdir='y', s=10, c='#52d686', marker = \".\")\n",
    "    ax.scatter(output_x[10], output_y[10], zs=output_z[10], zdir='y', s=10, c='#52dfbe', marker = \".\")\n",
    "    ax.scatter(output_x[11], output_y[11], zs=output_z[11], zdir='y', s=10, c='#52b9c5', marker = \".\")\n",
    "    ax.scatter(output_x[12], output_y[12], zs=output_z[12], zdir='y', s=10, c='#508ab7', marker = \".\")\n",
    "    ax.scatter(output_x[13], output_y[13], zs=output_z[13], zdir='y', s=10, c='#556fd0', marker = \".\")\n",
    "    ax.scatter(output_x[14], output_y[14], zs=output_z[14], zdir='y', s=10, c='#5245d5', marker = \".\")\n",
    "    ax.scatter(output_x[15], output_y[15], zs=output_z[15], zdir='y', s=10, c='#7e2fba', marker = \".\")\n",
    "    ax.scatter(output_x[16], output_y[16], zs=output_z[16], zdir='y', s=10, c='#bc64fb', marker = \".\")\n",
    "    ax.scatter(output_x[17], output_y[17], zs=output_z[17], zdir='y', s=10, c='#da53e8', marker = \".\")\n",
    "    ax.scatter(output_x[18], output_y[18], zs=output_z[18], zdir='y', s=10, c='#eb45bc', marker = \".\")\n",
    "    ax.scatter(output_x[19], output_y[19], zs=output_z[19], zdir='y', s=10, c='#ec3c89', marker = \".\")\n",
    "    ax.scatter(output_x[20], output_y[20], zs=output_z[20], zdir='y', s=10, c='#ff6691', marker = \".\")\n",
    "    \n",
    "    #点同士を結ぶ\n",
    "    if isOutputPointsIn[0] and isOutputPointsIn[1]:\n",
    "        ax.plot([output_x[0],output_x[1]], [output_y[0],output_y[1]], [output_z[0],output_z[1]], zdir='y', c='#cc0000')\n",
    "    if isOutputPointsIn[1] and isOutputPointsIn[2]:\n",
    "        ax.plot([output_x[1],output_x[2]], [output_y[1],output_y[2]], [output_z[1],output_z[2]], zdir='y', c='#b30000')\n",
    "    if isOutputPointsIn[2] and isOutputPointsIn[3]:\n",
    "        ax.plot([output_x[2],output_x[3]], [output_y[2],output_y[3]], [output_z[2],output_z[3]], zdir='y', c='#e60000')\n",
    "    if isOutputPointsIn[3] and isOutputPointsIn[4]:\n",
    "        ax.plot([output_x[3],output_x[4]], [output_y[3],output_y[4]], [output_z[3],output_z[4]], zdir='y', c='#ff0000')\n",
    "    if isOutputPointsIn[0] and isOutputPointsIn[5]:\n",
    "        ax.plot([output_x[0],output_x[5]], [output_y[0],output_y[5]], [output_z[0],output_z[5]], zdir='y', c='#a3cc00')\n",
    "    if isOutputPointsIn[5] and isOutputPointsIn[6]:\n",
    "        ax.plot([output_x[5],output_x[6]], [output_y[5],output_y[6]], [output_z[5],output_z[6]], zdir='y', c='#8fb300')\n",
    "    if isOutputPointsIn[6] and isOutputPointsIn[7]:        \n",
    "        ax.plot([output_x[6],output_x[7]], [output_y[6],output_y[7]], [output_z[6],output_z[7]], zdir='y', c='#b8e600')\n",
    "    if isOutputPointsIn[7] and isOutputPointsIn[8]:\n",
    "        ax.plot([output_x[7],output_x[8]], [output_y[7],output_y[8]], [output_z[7],output_z[8]], zdir='y', c='#ccff00')\n",
    "    if isOutputPointsIn[0] and isOutputPointsIn[9]:\n",
    "        ax.plot([output_x[0],output_x[9]], [output_y[0],output_y[9]], [output_z[0],output_z[9]], zdir='y', c='#00cc52')\n",
    "    if isOutputPointsIn[9] and isOutputPointsIn[10]:\n",
    "        ax.plot([output_x[9],output_x[10]], [output_y[9],output_y[10]], [output_z[9],output_z[10]], zdir='y', c='#00b347')\n",
    "    if isOutputPointsIn[10] and isOutputPointsIn[11]:\n",
    "        ax.plot([output_x[10],output_x[11]], [output_y[10],output_y[11]], [output_z[10],output_z[11]], zdir='y', c='#00e65c')\n",
    "    if isOutputPointsIn[11] and isOutputPointsIn[12]:\n",
    "        ax.plot([output_x[11],output_x[12]], [output_y[11],output_y[12]], [output_z[11],output_z[12]], zdir='y', c='#00ff66')\n",
    "    if isOutputPointsIn[0] and isOutputPointsIn[13]:\n",
    "        ax.plot([output_x[0],output_x[13]], [output_y[0],output_y[13]], [output_z[0],output_z[13]], zdir='y', c='#0052cc')\n",
    "    if isOutputPointsIn[13] and isOutputPointsIn[14]:\n",
    "        ax.plot([output_x[13],output_x[14]], [output_y[13],output_y[14]], [output_z[13],output_z[14]], zdir='y', c='#0047b3')\n",
    "    if isOutputPointsIn[14] and isOutputPointsIn[15]:\n",
    "        ax.plot([output_x[14],output_x[15]], [output_y[14],output_y[15]], [output_z[14],output_z[15]], zdir='y', c='#005ce6')\n",
    "    if isOutputPointsIn[15] and isOutputPointsIn[16]:\n",
    "        ax.plot([output_x[15],output_x[16]], [output_y[15],output_y[16]], [output_z[15],output_z[16]], zdir='y', c='#0066ff')\n",
    "    if isOutputPointsIn[0] and isOutputPointsIn[17]:\n",
    "        ax.plot([output_x[0],output_x[17]], [output_y[0],output_y[17]], [output_z[0],output_z[17]], zdir='y', c='#a300cc')\n",
    "    if isOutputPointsIn[17] and isOutputPointsIn[18]:\n",
    "        ax.plot([output_x[17],output_x[18]], [output_y[17],output_y[18]], [output_z[17],output_z[18]], zdir='y', c='#8f00b3')\n",
    "    if isOutputPointsIn[18] and isOutputPointsIn[19]:\n",
    "        ax.plot([output_x[18],output_x[19]], [output_y[18],output_y[19]], [output_z[18],output_z[19]], zdir='y', c='#b800e6')\n",
    "    if isOutputPointsIn[19] and isOutputPointsIn[20]:\n",
    "        ax.plot([output_x[19],output_x[20]], [output_y[19],output_y[20]], [output_z[19],output_z[20]], zdir='y', c='#cc00ff')\n",
    "    #ax.scatter(input_x, input_y, c='red', label = 'input')\n",
    "    #ax.scatter(output_x, output_y, c='blue', label = 'output')\n",
    "    \n",
    "    ##stradrs = str(test_adrs[target_epoch][i].item()) #11221813290002\n",
    "    ##d_adrs = \"dataset_\" + stradrs[4:8] + \"_\" + stradrs[8:14] + \"_\" + stradrs[14:]\n",
    "    ##ax.set_title('output(test data, ' + str(target_epoch+1) + 'th epoch)\\n' + d_adrs)\n",
    "    ax.set_title('output(test data, ' + str(target_epoch+1) + 'th epoch)\\n' + str(i))\n",
    "    ax.set_xlim([x_min, x_max])\n",
    "    ax.set_ylim([z_min, z_max])\n",
    "    ax.set_zlim([y_min, y_max])\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('z')\n",
    "    ax.set_zlabel('y')\n",
    "    #plt.subplots_adjust(left=0.04, right=0.80, bottom=0.04, top=0.80)\n",
    "    #ax.legend(loc='upper right')\n",
    "    fig.savefig(PATH + \"\\\\outputs\\\\Output_test_\" + str(target_epoch) + \"th_epoch_\" + str(i) + \".png\", dpi = 300, transparent = False, bbox_inches = 'tight', pad_inches = 0)\n",
    "    fig.clf()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fin loading\n",
      "data [-267. -214.  151.    0.    0.    0. -229. -102.  -87. -228.  -74.  -66.\n",
      "    0.    0.    0. -247. -151.  192. -249. -108.  208. -224.  -48.   -8.\n",
      " -225.  -33.  -62. -247. -145.  180.    0.    0.    0. -225.  -42.  -62.\n",
      " -234.  -34.  -73. -250. -145.  180. -224.  -73.  -36. -231.  -49.  -79.\n",
      " -239.  -40.  -96. -225.  -97.  -60. -228.  -74.  -66. -235.  -56.  -96.\n",
      " -238.  -51. -105.    0.]\n",
      "img [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "dmask [1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "imgmask [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "sean_firsts = []\n",
    "for sean in train_seanset:\n",
    "    #sean_imgcfile = glob.glob(sean + \"\\\\object*.png\")[0]\n",
    "    sean_imgdfile = glob.glob(sean + \"\\\\objectd*.png\")[0]\n",
    "    s_datafile = glob.glob(sean + \"\\\\data\\\\*0.csv\")[0]\n",
    "    #s_labelfile = glob.glob(sean + \"\\\\label\\\\*.csv\")[0]\n",
    "    pair = []\n",
    "    pair.append(s_datafile)\n",
    "    #pair.append(s_labelfile)\n",
    "    pair.append(sean_imgdfile)\n",
    "    sean_firsts.append(pair)\n",
    "\n",
    "data_recall = []\n",
    "img_recall = []\n",
    "mask_recall = []\n",
    "imgmask_recall = []\n",
    "for i in range(len(sean_firsts)):\n",
    "    # 画像読み込み\n",
    "    image = Image.open(sean_firsts[i][1])\n",
    "    # グレイスケール変換\n",
    "    #image = image.convert('L')\n",
    "    # リサイズ\n",
    "    image = image.resize((image_size, image_size))\n",
    "    ## 画像から配列に変換\n",
    "    #img_recall.append(np.asarray(image))\n",
    "    # 画像から配列に変換\n",
    "    img_array = np.asarray(image)\n",
    "    img_recall.append(img_array)\n",
    "    img_mask_array = np.zeros((image_size, image_size), np.uint8) #画像マスク\n",
    "    \n",
    "    #元画像の画素値が0の部分のみマスク画像の画素値を1にする\n",
    "    for h in range(img_array.shape[0]):\n",
    "        for w in range(img_array.shape[1]):\n",
    "            if 0 <= img_array[h,w] < 500:\n",
    "                img_mask_array[h,w] = 1\n",
    "    #img_names.append(os.path.basename(imgfile))\n",
    "    #file_split = [i for i in file.split('_')]\n",
    "    imgmask_recall.append(img_mask_array)\n",
    "    \n",
    "    data_points = []\n",
    "    data_masks = []\n",
    "    with open(sean_firsts[i][0]) as f:\n",
    "        reader = csv.reader(f)\n",
    "        num = 0\n",
    "        for row in reader:\n",
    "            if num == 0:\n",
    "                for point in row:\n",
    "                    if int(point) == -10000:\n",
    "                        data_points.append(float(0))\n",
    "                        data_masks.append(0)\n",
    "                    else:\n",
    "                        data_points.append(float(point))\n",
    "                        data_masks.append(1)\n",
    "                data_points = np.asarray(data_points)\n",
    "                data_masks = np.asarray(data_masks)\n",
    "                num += 1\n",
    "    data_recall.append(np.asarray(data_points))\n",
    "    mask_recall.append(np.asarray(data_masks))\n",
    "\n",
    "print(\"fin loading\")\n",
    "\n",
    "data_recall = np.array(data_recall).astype('float32')\n",
    "img_recall = np.array(img_recall).astype('float32')/1000\n",
    "mask_recall = np.array(mask_recall).astype('float32')\n",
    "imgmask_recall = np.array(imgmask_recall).astype('float32')\n",
    "\n",
    "print(\"data\",data_recall[0])\n",
    "print(\"img\",img_recall[0])\n",
    "print(\"dmask\",mask_recall[0])\n",
    "print(\"imgmask\",imgmask_recall[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#trans = torchvision.transforms.Compose(\n",
    "#    [torchvision.transforms.ToTensor()]#,torchvision.transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))]\n",
    "#)\n",
    "\n",
    "class Mydatasets2(torch.utils.data.Dataset):\n",
    "    def __init__(self, datas, img_array, data_masks, img_masks, transform = None):\n",
    "        self.transform = transform\n",
    "        #self.transform2 = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "        self.data = datas\n",
    "        self.img_array = img_array\n",
    "        self.masks = data_masks\n",
    "        self.img_masks = img_masks\n",
    "\n",
    "        self.datanum = datas.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.datanum\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #batch_set = []\n",
    "        \n",
    "        i_data = self.data\n",
    "        i_img = self.img_array\n",
    "        i_mask = self.masks\n",
    "        i_imgmask = self.img_masks\n",
    "        \n",
    "        #print(out_label)\n",
    "        #print(type(i_label))\n",
    "        out_data = np.array(i_data.astype(np.float32))\n",
    "        out_img = np.array(i_img.astype(np.float32))\n",
    "        out_mask = np.array(i_mask.astype(np.float32))\n",
    "        out_imgmask = np.array(i_imgmask.astype(np.float32))\n",
    "        #out_label.append(i_label.astype(np.float32))\n",
    "        #print(type(out_label))\n",
    "\n",
    "        if self.transform:\n",
    "            #out_data = self.transform(i_data)\n",
    "            out_img = self.transform(out_img)\n",
    "            out_imgmask = self.transform(out_imgmask)\n",
    "            #out_label = self.transform2(out_label)\n",
    "        \n",
    "        #batch_set.append(out_data)\n",
    "        #batch_set.append(out_label)\n",
    "        #batch_set.append(out_img)\n",
    "        #batch_set.append(out_mask)\n",
    "        #batch_set.append(out_lmask)\n",
    "\n",
    "        return out_data, out_img, out_mask, out_imgmask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: [-2.67 -2.14  1.51  0.    0.    0.   -2.29 -1.02 -0.87 -2.28 -0.74 -0.66\n",
      "  0.    0.    0.   -2.47 -1.51  1.92 -2.49 -1.08  2.08 -2.24 -0.48 -0.08\n",
      " -2.25 -0.33 -0.62 -2.47 -1.45  1.8   0.    0.    0.   -2.25 -0.42 -0.62\n",
      " -2.34 -0.34 -0.73 -2.5  -1.45  1.8  -2.24 -0.73 -0.36 -2.31 -0.49 -0.79\n",
      " -2.39 -0.4  -0.96 -2.25 -0.97 -0.6  -2.28 -0.74 -0.66 -2.35 -0.56 -0.96\n",
      " -2.38 -0.51 -1.05  0.  ]\n",
      "mask: [1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[-0.0860,  0.1340,  0.0328,  ...,  0.0711, -0.1427, -0.2274],\n",
      "        [-0.0860,  0.1340,  0.0328,  ...,  0.0711, -0.1427, -0.2274],\n",
      "        [-0.0860,  0.1340,  0.0328,  ...,  0.0711, -0.1427, -0.2274],\n",
      "        ...,\n",
      "        [ 0.3463, -0.4288,  1.2898,  ..., -1.1044,  0.0302,  0.9177],\n",
      "        [ 0.3201, -0.4484,  1.2825,  ..., -1.1012, -0.0286,  0.8106],\n",
      "        [ 0.3201, -0.4484,  1.2825,  ..., -1.1012, -0.0286,  0.8106]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.08597917  0.13398013  0.03284734 -0.2238421  -0.04775222 -0.2922598\n",
      " -0.36770087 -0.22261012 -0.50042355 -0.45858705 -0.37620264 -0.5588087\n",
      " -0.54167795 -0.5281545  -0.61268413 -0.36605376 -0.18920404 -0.7838677\n",
      " -0.2628851  -0.27281672 -0.4279192  -0.3213694  -0.4122167  -0.44215828\n",
      " -0.32549918 -0.48252574 -0.51983476 -0.28749037 -0.07497916 -0.77171046\n",
      " -0.323761   -0.23467702 -0.72324586 -0.30025572 -0.3496486  -0.7174445\n",
      " -0.19910835 -0.47472093 -0.68265104 -0.21936345 -0.02476467 -0.6186186\n",
      " -0.26692802 -0.07169417 -0.60641974 -0.19495836 -0.20871592 -0.58904445\n",
      " -0.01565662 -0.30983743 -0.42578673 -0.18403143  0.10871729 -0.5133198\n",
      " -0.11204502  0.03398013 -0.40560213 -0.06528944 -0.03204098 -0.4173532\n",
      "  0.071097   -0.14273044 -0.22741136]\n",
      "init: [-0.08597917  0.13398013  0.03284734 -0.2238421  -0.04775222 -0.2922598\n",
      " -0.36770087 -0.22261012 -0.50042355 -0.45858705 -0.37620264 -0.5588087\n",
      " -0.54167795 -0.5281545  -0.61268413 -0.36605376 -0.18920404 -0.7838677\n",
      " -0.2628851  -0.27281672 -0.4279192  -0.3213694  -0.4122167  -0.44215828\n",
      " -0.32549918 -0.48252574 -0.51983476 -0.28749037 -0.07497916 -0.77171046\n",
      " -0.323761   -0.23467702 -0.72324586 -0.30025572 -0.3496486  -0.7174445\n",
      " -0.19910835 -0.47472093 -0.68265104 -0.21936345 -0.02476467 -0.6186186\n",
      " -0.26692802 -0.07169417 -0.60641974 -0.19495836 -0.20871592 -0.58904445\n",
      " -0.01565662 -0.30983743 -0.42578673 -0.18403143  0.10871729 -0.5133198\n",
      " -0.11204502  0.03398013 -0.40560213 -0.06528944 -0.03204098 -0.4173532\n",
      "  0.071097   -0.14273044 -0.22741136]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [-0.08597918  0.13398013  0.03284734 -0.2238421  -0.04775222 -0.2922598\n",
      " -0.36770087 -0.22261012 -0.50042355 -0.45858705 -0.37620267 -0.5588087\n",
      " -0.54167795 -0.5281545  -0.61268413 -0.36605376 -0.18920404 -0.7838677\n",
      " -0.2628851  -0.27281672 -0.4279192  -0.3213694  -0.4122167  -0.44215828\n",
      " -0.32549918 -0.48252574 -0.51983476 -0.28749037 -0.07497916 -0.77171046\n",
      " -0.323761   -0.23467702 -0.72324586 -0.30025572 -0.3496486  -0.7174445\n",
      " -0.19910835 -0.47472093 -0.68265104 -0.21936344 -0.02476467 -0.6186186\n",
      " -0.26692802 -0.07169417 -0.60641974 -0.19495836 -0.20871592 -0.58904445\n",
      " -0.01565662 -0.30983743 -0.42578673 -0.18403143  0.10871729 -0.5133198\n",
      " -0.11204502  0.03398013 -0.4056021  -0.06528944 -0.03204098 -0.4173532\n",
      "  0.071097   -0.14273044 -0.22741136  0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FDA0>\n",
      "tensor([[ 0.1491, -0.2437,  0.3445,  ...,  0.2580, -0.4064, -0.7267],\n",
      "        [ 0.1491, -0.2437,  0.3445,  ...,  0.2580, -0.4064, -0.7267],\n",
      "        [ 0.1491, -0.2437,  0.3445,  ...,  0.2580, -0.4064, -0.7267],\n",
      "        ...,\n",
      "        [ 0.2593, -0.2058, -0.3711,  ..., -0.1222,  0.4656, -0.6661],\n",
      "        [-0.3658,  0.1735,  0.2365,  ..., -0.9804,  1.0799, -0.3212],\n",
      "        [-0.3658,  0.1735,  0.2365,  ..., -0.9804,  1.0799, -0.3212]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.1491305  -0.24365897  0.3444673   0.13450278 -0.4040655  -0.04541725\n",
      " -0.05680074 -0.6011403  -0.7496413  -0.21032171 -0.6777573  -0.96631074\n",
      " -0.39172965 -0.7471763  -1.399001   -0.06907193 -0.85724676 -0.9219812\n",
      "  0.0408899  -0.88717747 -0.7843728   0.0916306  -0.7786629  -0.81302595\n",
      "  0.16463493 -0.90831864 -0.8880998  -0.03256339 -0.7288414  -0.888672\n",
      "  0.06478751 -0.77906907 -0.8111974   0.12203465 -0.7327889  -0.86319315\n",
      "  0.40195885 -0.7160346  -0.95672596  0.05297945 -0.6893811  -0.76610386\n",
      "  0.00772129 -0.44120762 -1.168393    0.17801066 -0.57505786 -1.1632432\n",
      "  0.4269132  -0.50683737 -0.8698549  -0.02877736 -0.4288116  -0.6961113\n",
      "  0.00515783 -0.36748904 -0.76567495  0.11535676 -0.3621868  -0.8974221\n",
      "  0.25802037 -0.40644443 -0.7266755 ]\n",
      "data: [ 0.1491305  -0.24365897  0.3444673   0.13450278 -0.4040655  -0.04541725\n",
      " -0.05680074 -0.6011403  -0.74964124 -0.21032171 -0.6777573  -0.96631074\n",
      " -0.39172965 -0.7471763  -1.399001   -0.06907193 -0.85724676 -0.9219812\n",
      "  0.0408899  -0.8871774  -0.7843728   0.0916306  -0.7786629  -0.81302595\n",
      "  0.16463493 -0.90831864 -0.88809985 -0.03256339 -0.7288414  -0.88867205\n",
      "  0.06478751 -0.77906907 -0.81119746  0.12203465 -0.7327889  -0.86319315\n",
      "  0.40195885 -0.71603465 -0.9567259   0.05297945 -0.6893811  -0.7661039\n",
      "  0.00772129 -0.44120762 -1.168393    0.17801066 -0.57505786 -1.1632432\n",
      "  0.42691317 -0.50683737 -0.86985487 -0.02877736 -0.4288116  -0.6961113\n",
      "  0.00515783 -0.36748904 -0.76567495  0.11535676 -0.3621868  -0.8974221\n",
      "  0.25802037 -0.40644443 -0.7266755   0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[ 0.0960, -0.0523, -0.0680,  ...,  0.0507, -0.2375, -1.1908],\n",
      "        [ 0.0960, -0.0523, -0.0680,  ...,  0.0507, -0.2375, -1.1908],\n",
      "        [ 0.0960, -0.0523, -0.0680,  ...,  0.0507, -0.2375, -1.1908],\n",
      "        ...,\n",
      "        [-0.2718,  0.1218,  0.4762,  ..., -0.1439,  0.7968,  0.0094],\n",
      "        [-0.2433,  0.3189,  0.5029,  ..., -0.2702,  0.7665,  0.2391],\n",
      "        [-0.2433,  0.3189,  0.5029,  ..., -0.2702,  0.7665,  0.2391]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 9.6038580e-02 -5.2291222e-02 -6.7999817e-02  5.1687039e-02\n",
      " -2.3939218e-01 -5.0626493e-01  1.0077007e-02 -3.8684389e-01\n",
      " -1.0978034e+00 -1.6531838e-01 -4.4782996e-01 -1.4219295e+00\n",
      " -4.1501081e-01 -5.8628190e-01 -1.8885095e+00 -1.7112000e-01\n",
      " -6.1159968e-01 -1.3764247e+00  1.6435236e-03 -6.4138615e-01\n",
      " -1.2573211e+00 -5.2158400e-02 -5.5940002e-01 -1.3180797e+00\n",
      " -1.8985391e-02 -6.9690025e-01 -1.3816382e+00 -1.1860241e-01\n",
      " -4.7981763e-01 -1.3040875e+00 -4.9213707e-02 -5.4546475e-01\n",
      " -1.2597202e+00 -9.6074477e-02 -5.7732505e-01 -1.4004545e+00\n",
      "  5.4986775e-03 -5.2787882e-01 -1.4430389e+00 -1.9105569e-02\n",
      " -4.3280280e-01 -1.1492953e+00 -7.8854278e-02 -2.6317918e-01\n",
      " -1.5595404e+00 -2.4113759e-02 -3.8943660e-01 -1.5284729e+00\n",
      "  9.1003396e-02 -3.7618202e-01 -1.2865201e+00 -7.4549094e-02\n",
      " -2.0443019e-01 -1.1287098e+00 -3.0365989e-02 -2.1793890e-01\n",
      " -1.1821213e+00  9.5929950e-03 -2.4661072e-01 -1.2809902e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5.0687633e-02 -2.3753284e-01 -1.1907634e+00]\n",
      "data: [ 9.6038580e-02 -5.2291222e-02 -6.7999817e-02  5.1687039e-02\n",
      " -2.3939219e-01 -5.0626493e-01  1.0077007e-02 -3.8684386e-01\n",
      " -1.0978034e+00 -1.6531840e-01 -4.4782996e-01 -1.4219295e+00\n",
      " -4.1501081e-01 -5.8628190e-01 -1.8885095e+00 -1.7111999e-01\n",
      " -6.1159968e-01 -1.3764247e+00  1.6435236e-03 -6.4138621e-01\n",
      " -1.2573211e+00 -5.2158400e-02 -5.5940002e-01 -1.3180797e+00\n",
      " -1.8985391e-02 -6.9690025e-01 -1.3816382e+00 -1.1860241e-01\n",
      " -4.7981763e-01 -1.3040875e+00 -4.9213704e-02 -5.4546475e-01\n",
      " -1.2597202e+00 -9.6074477e-02 -5.7732505e-01 -1.4004545e+00\n",
      "  5.4986775e-03 -5.2787882e-01 -1.4430389e+00 -1.9105569e-02\n",
      " -4.3280280e-01 -1.1492953e+00 -7.8854278e-02 -2.6317918e-01\n",
      " -1.5595404e+00 -2.4113759e-02 -3.8943660e-01 -1.5284729e+00\n",
      "  9.1003396e-02 -3.7618202e-01 -1.2865201e+00 -7.4549094e-02\n",
      " -2.0443019e-01 -1.1287098e+00 -3.0365989e-02 -2.1793890e-01\n",
      " -1.1821213e+00  9.5929950e-03 -2.4661072e-01 -1.2809902e+00\n",
      "  5.0687633e-02 -2.3753284e-01 -1.1907634e+00  2.9999999e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F400>\n",
      "tensor([[ 0.0517, -0.1195, -0.2515,  ...,  0.0938, -0.2959, -1.2988],\n",
      "        [ 0.0517, -0.1195, -0.2515,  ...,  0.0938, -0.2959, -1.2988],\n",
      "        [ 0.0517, -0.1195, -0.2515,  ...,  0.0938, -0.2959, -1.2988],\n",
      "        ...,\n",
      "        [-0.1652,  0.4453, -0.0036,  ..., -0.4342,  1.0224, -0.3573],\n",
      "        [-0.1283, -0.0405,  0.6267,  ..., -0.3206,  0.7289,  0.2536],\n",
      "        [-0.1283, -0.0405,  0.6267,  ..., -0.3206,  0.7289,  0.2536]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.05170729 -0.11946306 -0.25146177  0.07439709 -0.26663268 -0.6698185\n",
      " -0.02113421 -0.44802582 -1.4049542  -0.16715124 -0.50781727 -1.6923715\n",
      " -0.33744368 -0.6230785  -2.157974   -0.15572062 -0.72213465 -1.5714961\n",
      "  0.06470686 -0.74647266 -1.3723397   0.02478246 -0.6757747  -1.4218055\n",
      "  0.03174589 -0.8012068  -1.5336429  -0.11246248 -0.6101552  -1.494319\n",
      " -0.02147976 -0.66381603 -1.4599551  -0.01979355 -0.6344015  -1.5412269\n",
      "  0.12551402 -0.6550004  -1.5942454  -0.0166036  -0.5321289  -1.3227704\n",
      " -0.12631305 -0.29151246 -1.941459    0.03436853 -0.4532817  -1.9322101\n",
      "  0.20034423 -0.40837586 -1.4543331  -0.12133425 -0.28988224 -1.2590694\n",
      " -0.03955041 -0.25902027 -1.3332468   0.0172718  -0.2766142  -1.4525557\n",
      "  0.09380374 -0.29593563 -1.2987741 ]\n",
      "data: [ 0.05170729 -0.11946306 -0.25146177  0.07439709 -0.26663268 -0.6698185\n",
      " -0.02113421 -0.44802582 -1.4049542  -0.16715124 -0.50781727 -1.6923715\n",
      " -0.3374437  -0.6230785  -2.157974   -0.15572062 -0.72213465 -1.5714961\n",
      "  0.06470686 -0.7464726  -1.3723397   0.02478246 -0.6757747  -1.4218056\n",
      "  0.03174589 -0.8012068  -1.5336429  -0.11246248 -0.6101552  -1.494319\n",
      " -0.02147976 -0.6638161  -1.4599551  -0.01979355 -0.6344015  -1.5412269\n",
      "  0.12551402 -0.6550004  -1.5942454  -0.0166036  -0.5321289  -1.3227704\n",
      " -0.12631305 -0.29151246 -1.941459    0.03436853 -0.4532817  -1.9322101\n",
      "  0.20034423 -0.40837586 -1.4543331  -0.12133425 -0.28988224 -1.2590694\n",
      " -0.03955041 -0.25902027 -1.3332467   0.0172718  -0.2766142  -1.4525557\n",
      "  0.09380374 -0.29593563 -1.2987741   0.04      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B320>\n",
      "tensor([[ 0.0380, -0.1556, -0.2420,  ...,  0.0770, -0.3407, -1.2998],\n",
      "        [ 0.0380, -0.1556, -0.2420,  ...,  0.0770, -0.3407, -1.2998],\n",
      "        [ 0.0380, -0.1556, -0.2420,  ...,  0.0770, -0.3407, -1.2998],\n",
      "        ...,\n",
      "        [-0.0930,  0.4554, -0.1095,  ..., -0.6148,  0.9472, -0.4325],\n",
      "        [-0.1379, -0.0513,  0.6226,  ..., -0.2056,  0.7047,  0.2742],\n",
      "        [-0.1379, -0.0513,  0.6226,  ..., -0.2056,  0.7047,  0.2742]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03795699 -0.15555266 -0.24200672  0.05743864 -0.29964176 -0.6476401\n",
      " -0.01988611 -0.49178782 -1.4056079  -0.1666744  -0.5544102  -1.7140906\n",
      " -0.3400792  -0.681386   -2.185159   -0.17322038 -0.7627593  -1.5851539\n",
      "  0.07524262 -0.79819214 -1.3767084   0.01663141 -0.7403382  -1.4245104\n",
      "  0.00875751 -0.87122    -1.5435308  -0.12116672 -0.6526816  -1.4904157\n",
      " -0.02940217 -0.71626925 -1.4676257  -0.0341679  -0.69218683 -1.5640594\n",
      "  0.08570001 -0.72597635 -1.6132058  -0.01717698 -0.5624913  -1.3122189\n",
      " -0.13964127 -0.33529326 -1.9580334   0.02002636 -0.5028813  -1.9498049\n",
      "  0.17467405 -0.46362105 -1.4609582  -0.13316567 -0.3215391  -1.2467562\n",
      " -0.0346853  -0.3021739  -1.3244467   0.01424332 -0.3319726  -1.4377847\n",
      "  0.07695127 -0.34066582 -1.2998099 ]\n",
      "data: [ 0.03795699 -0.15555266 -0.24200672  0.05743863 -0.29964176 -0.64764005\n",
      " -0.01988611 -0.49178782 -1.4056079  -0.1666744  -0.5544102  -1.7140906\n",
      " -0.3400792  -0.68138593 -2.185159   -0.17322038 -0.7627593  -1.5851539\n",
      "  0.07524262 -0.79819214 -1.3767084   0.01663141 -0.7403382  -1.4245104\n",
      "  0.00875751 -0.87122    -1.543531   -0.12116673 -0.6526816  -1.4904157\n",
      " -0.02940217 -0.71626925 -1.4676257  -0.0341679  -0.69218683 -1.5640595\n",
      "  0.08570001 -0.72597635 -1.6132057  -0.01717698 -0.5624913  -1.3122189\n",
      " -0.13964127 -0.33529326 -1.9580334   0.02002636 -0.5028813  -1.9498048\n",
      "  0.17467405 -0.46362105 -1.4609582  -0.13316567 -0.3215391  -1.2467562\n",
      " -0.0346853  -0.3021739  -1.3244467   0.01424332 -0.33197257 -1.4377847\n",
      "  0.07695127 -0.34066582 -1.2998099   0.05      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FB70>\n",
      "tensor([[ 0.0257, -0.1406, -0.2046,  ...,  0.0690, -0.3370, -1.1910],\n",
      "        [ 0.0257, -0.1406, -0.2046,  ...,  0.0690, -0.3370, -1.1910],\n",
      "        [ 0.0257, -0.1406, -0.2046,  ...,  0.0690, -0.3370, -1.1910],\n",
      "        ...,\n",
      "        [-0.0457,  0.4998, -0.1163,  ..., -0.4902,  1.0347, -0.4927],\n",
      "        [-0.1237, -0.0380,  0.6224,  ..., -0.2079,  0.6663,  0.2787],\n",
      "        [-0.1237, -0.0380,  0.6224,  ..., -0.2079,  0.6663,  0.2787]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.5730249e-02 -1.4060399e-01 -2.0463538e-01  5.8656860e-02\n",
      " -2.4520200e-01 -4.9579999e-01 -8.2119428e-02 -4.7766930e-01\n",
      " -1.3501356e+00 -2.3825027e-01 -5.4416931e-01 -1.6405212e+00\n",
      " -3.8466990e-01 -6.4039922e-01 -2.1518991e+00 -1.6676651e-01\n",
      " -7.7880025e-01 -1.5363030e+00  1.2954071e-02 -8.4877813e-01\n",
      " -1.3861394e+00 -4.3935135e-02 -7.7385831e-01 -1.4352542e+00\n",
      " -5.2355930e-02 -9.4461143e-01 -1.5604768e+00 -1.1822359e-01\n",
      " -6.9223118e-01 -1.4325460e+00 -6.0313076e-02 -7.4817026e-01\n",
      " -1.4056648e+00 -6.9597527e-02 -7.1392894e-01 -1.4858637e+00\n",
      "  6.4905971e-02 -7.5272739e-01 -1.4982280e+00 -2.8449707e-02\n",
      " -5.7736778e-01 -1.2687986e+00 -1.9063140e-01 -3.3866975e-01\n",
      " -2.0409422e+00  4.2874366e-04 -5.2188027e-01 -2.0645864e+00\n",
      "  1.7584090e-01 -4.7852436e-01 -1.3652276e+00 -1.5443091e-01\n",
      " -3.4993386e-01 -1.1884551e+00 -7.7305838e-02 -3.1976962e-01\n",
      " -1.2773614e+00 -4.3809175e-02 -3.2594058e-01 -1.3891813e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6.9013499e-02 -3.3703291e-01 -1.1909983e+00]\n",
      "data: [ 2.5730247e-02 -1.4060399e-01 -2.0463540e-01  5.8656860e-02\n",
      " -2.4520200e-01 -4.9579999e-01 -8.2119428e-02 -4.7766930e-01\n",
      " -1.3501354e+00 -2.3825027e-01 -5.4416931e-01 -1.6405213e+00\n",
      " -3.8466990e-01 -6.4039922e-01 -2.1518991e+00 -1.6676651e-01\n",
      " -7.7880025e-01 -1.5363030e+00  1.2954070e-02 -8.4877813e-01\n",
      " -1.3861394e+00 -4.3935135e-02 -7.7385831e-01 -1.4352542e+00\n",
      " -5.2355930e-02 -9.4461143e-01 -1.5604768e+00 -1.1822359e-01\n",
      " -6.9223112e-01 -1.4325461e+00 -6.0313076e-02 -7.4817026e-01\n",
      " -1.4056648e+00 -6.9597527e-02 -7.1392894e-01 -1.4858637e+00\n",
      "  6.4905971e-02 -7.5272733e-01 -1.4982280e+00 -2.8449707e-02\n",
      " -5.7736778e-01 -1.2687986e+00 -1.9063140e-01 -3.3866975e-01\n",
      " -2.0409422e+00  4.2874366e-04 -5.2188027e-01 -2.0645864e+00\n",
      "  1.7584090e-01 -4.7852436e-01 -1.3652275e+00 -1.5443091e-01\n",
      " -3.4993386e-01 -1.1884551e+00 -7.7305838e-02 -3.1976962e-01\n",
      " -1.2773614e+00 -4.3809175e-02 -3.2594058e-01 -1.3891813e+00\n",
      "  6.9013499e-02 -3.3703291e-01 -1.1909983e+00  5.9999999e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0139, -0.0638, -0.1882,  ...,  0.0297, -0.2533, -1.1683],\n",
      "        [-0.0139, -0.0638, -0.1882,  ...,  0.0297, -0.2533, -1.1683],\n",
      "        [-0.0139, -0.0638, -0.1882,  ...,  0.0297, -0.2533, -1.1683],\n",
      "        ...,\n",
      "        [-0.1627,  0.3758,  0.0143,  ..., -0.7044,  0.9467, -0.3858],\n",
      "        [-0.0911, -0.0405,  0.6090,  ..., -0.1961,  0.6513,  0.2416],\n",
      "        [-0.0911, -0.0405,  0.6090,  ..., -0.1961,  0.6513,  0.2416]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-1.3876754e-02 -6.3771307e-02 -1.8822914e-01  1.3270367e-02\n",
      " -1.7788915e-01 -4.7703427e-01 -1.0728800e-01 -4.0041131e-01\n",
      " -1.3239269e+00 -2.6284224e-01 -4.6242693e-01 -1.6289883e+00\n",
      " -4.3067086e-01 -5.7259107e-01 -2.1302638e+00 -2.2180603e-01\n",
      " -6.9373572e-01 -1.5099089e+00 -1.4320314e-03 -7.4882376e-01\n",
      " -1.3240731e+00 -5.7948202e-02 -6.8343109e-01 -1.3697226e+00\n",
      " -6.0290620e-02 -8.3902746e-01 -1.4995049e+00 -1.7008436e-01\n",
      " -5.9603840e-01 -1.4004632e+00 -9.3163364e-02 -6.5570039e-01\n",
      " -1.3767358e+00 -8.8775486e-02 -6.2227798e-01 -1.4707146e+00\n",
      "  5.3144544e-02 -6.6327888e-01 -1.5017090e+00 -7.0022948e-02\n",
      " -4.8664042e-01 -1.2251292e+00 -2.2902830e-01 -2.5099140e-01\n",
      " -1.9896284e+00 -3.0143298e-02 -4.3228027e-01 -2.0031240e+00\n",
      "  1.5404172e-01 -3.8843554e-01 -1.3478401e+00 -2.0112698e-01\n",
      " -2.5140196e-01 -1.1487209e+00 -1.0981971e-01 -2.2801712e-01\n",
      " -1.2287613e+00 -6.9668025e-02 -2.4472743e-01 -1.3443445e+00\n",
      "  2.9733084e-02 -2.5328368e-01 -1.1682668e+00]\n",
      "data: [-1.38767539e-02 -6.37713075e-02 -1.88229144e-01  1.32703669e-02\n",
      " -1.77889153e-01 -4.77034271e-01 -1.07287996e-01 -4.00411308e-01\n",
      " -1.32392704e+00 -2.62842238e-01 -4.62426960e-01 -1.62898839e+00\n",
      " -4.30670857e-01 -5.72591066e-01 -2.13026381e+00 -2.21806034e-01\n",
      " -6.93735719e-01 -1.50990891e+00 -1.43203139e-03 -7.48823762e-01\n",
      " -1.32407308e+00 -5.79482019e-02 -6.83431089e-01 -1.36972260e+00\n",
      " -6.02906197e-02 -8.39027464e-01 -1.49950480e+00 -1.70084357e-01\n",
      " -5.96038401e-01 -1.40046322e+00 -9.31633636e-02 -6.55700386e-01\n",
      " -1.37673581e+00 -8.87754858e-02 -6.22277975e-01 -1.47071457e+00\n",
      "  5.31445444e-02 -6.63278878e-01 -1.50170898e+00 -7.00229481e-02\n",
      " -4.86640424e-01 -1.22512925e+00 -2.29028299e-01 -2.50991404e-01\n",
      " -1.98962843e+00 -3.01432982e-02 -4.32280272e-01 -2.00312400e+00\n",
      "  1.54041722e-01 -3.88435543e-01 -1.34784007e+00 -2.01126978e-01\n",
      " -2.51401961e-01 -1.14872086e+00 -1.09819710e-01 -2.28017122e-01\n",
      " -1.22876132e+00 -6.96680248e-02 -2.44727433e-01 -1.34434450e+00\n",
      "  2.97330841e-02 -2.53283679e-01 -1.16826677e+00  7.00000003e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[-1.0087e-03, -8.4842e-02, -2.5648e-01,  ..., -8.8715e-03,\n",
      "         -2.4809e-01, -1.2953e+00],\n",
      "        [-1.0087e-03, -8.4842e-02, -2.5648e-01,  ..., -8.8715e-03,\n",
      "         -2.4809e-01, -1.2953e+00],\n",
      "        [-1.0087e-03, -8.4842e-02, -2.5648e-01,  ..., -8.8715e-03,\n",
      "         -2.4809e-01, -1.2953e+00],\n",
      "        ...,\n",
      "        [-2.6754e-01,  2.3781e-01, -1.4234e-01,  ..., -6.7272e-01,\n",
      "          7.1797e-01, -4.3869e-01],\n",
      "        [-5.0797e-02,  2.4181e-03,  6.7341e-01,  ..., -1.7392e-01,\n",
      "          7.7135e-01,  3.2186e-01],\n",
      "        [-5.0797e-02,  2.4181e-03,  6.7341e-01,  ..., -1.7392e-01,\n",
      "          7.7135e-01,  3.2186e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-1.00868475e-03 -8.48416537e-02 -2.56480098e-01  2.48454250e-02\n",
      " -2.06156239e-01 -6.37540817e-01 -9.50557217e-02 -4.07911897e-01\n",
      " -1.42587519e+00 -2.45064884e-01 -4.68462050e-01 -1.72141671e+00\n",
      " -4.08176839e-01 -5.58960676e-01 -2.21309519e+00 -2.02247307e-01\n",
      " -7.06532001e-01 -1.57842815e+00 -2.05951929e-02 -7.47577310e-01\n",
      " -1.39404833e+00 -6.66933358e-02 -6.78790748e-01 -1.45280707e+00\n",
      " -7.98221380e-02 -8.29724908e-01 -1.57897854e+00 -1.66841760e-01\n",
      " -6.10492527e-01 -1.48816752e+00 -1.03575572e-01 -6.58003688e-01\n",
      " -1.45968282e+00 -1.17697120e-01 -6.23752654e-01 -1.55550969e+00\n",
      "  2.62253284e-02 -6.47030354e-01 -1.59065652e+00 -9.02500227e-02\n",
      " -5.04711747e-01 -1.32391703e+00 -2.28123188e-01 -2.73421645e-01\n",
      " -2.03083992e+00 -5.93100488e-02 -4.27047610e-01 -2.05036211e+00\n",
      "  1.08567715e-01 -3.91930163e-01 -1.45127881e+00 -1.98347732e-01\n",
      " -2.72338331e-01 -1.25221479e+00 -1.41074717e-01 -2.39351049e-01\n",
      " -1.33900928e+00 -1.05349377e-01 -2.36848578e-01 -1.46082127e+00\n",
      " -8.87148082e-03 -2.48091221e-01 -1.29528534e+00]\n",
      "data: [-1.00868475e-03 -8.48416537e-02 -2.56480098e-01  2.48454269e-02\n",
      " -2.06156239e-01 -6.37540817e-01 -9.50557217e-02 -4.07911897e-01\n",
      " -1.42587519e+00 -2.45064884e-01 -4.68462080e-01 -1.72141683e+00\n",
      " -4.08176839e-01 -5.58960676e-01 -2.21309519e+00 -2.02247322e-01\n",
      " -7.06532001e-01 -1.57842815e+00 -2.05951929e-02 -7.47577310e-01\n",
      " -1.39404833e+00 -6.66933358e-02 -6.78790748e-01 -1.45280695e+00\n",
      " -7.98221380e-02 -8.29724908e-01 -1.57897854e+00 -1.66841760e-01\n",
      " -6.10492527e-01 -1.48816752e+00 -1.03575572e-01 -6.58003688e-01\n",
      " -1.45968282e+00 -1.17697127e-01 -6.23752654e-01 -1.55550969e+00\n",
      "  2.62253284e-02 -6.47030354e-01 -1.59065664e+00 -9.02500227e-02\n",
      " -5.04711747e-01 -1.32391703e+00 -2.28123188e-01 -2.73421645e-01\n",
      " -2.03083992e+00 -5.93100488e-02 -4.27047610e-01 -2.05036211e+00\n",
      "  1.08567715e-01 -3.91930163e-01 -1.45127881e+00 -1.98347747e-01\n",
      " -2.72338331e-01 -1.25221479e+00 -1.41074717e-01 -2.39351049e-01\n",
      " -1.33900928e+00 -1.05349377e-01 -2.36848578e-01 -1.46082127e+00\n",
      " -8.87148082e-03 -2.48091221e-01 -1.29528534e+00  7.99999982e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F198>\n",
      "tensor([[ 0.0351, -0.0222, -0.1994,  ...,  0.0352, -0.2148, -1.2256],\n",
      "        [ 0.0351, -0.0222, -0.1994,  ...,  0.0352, -0.2148, -1.2256],\n",
      "        [ 0.0351, -0.0222, -0.1994,  ...,  0.0352, -0.2148, -1.2256],\n",
      "        ...,\n",
      "        [-0.2375,  0.3523, -0.1429,  ..., -0.8935,  0.8591, -0.3615],\n",
      "        [-0.1459, -0.1740,  0.5588,  ..., -0.2204,  0.5775,  0.2597],\n",
      "        [-0.1459, -0.1740,  0.5588,  ..., -0.2204,  0.5775,  0.2597]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03507571 -0.02217044 -0.19935161  0.05034405 -0.1386372  -0.5647582\n",
      " -0.07828549 -0.33181655 -1.3458166  -0.23150101 -0.3966332  -1.6337163\n",
      " -0.39514634 -0.4803506  -2.1395338  -0.15575352 -0.6514964  -1.5005147\n",
      " -0.01187785 -0.6993803  -1.3609922  -0.06082909 -0.62053776 -1.425339\n",
      " -0.06160775 -0.7817609  -1.5416181  -0.12078133 -0.5644287  -1.4168632\n",
      " -0.06788393 -0.60624874 -1.3853378  -0.09689394 -0.5774303  -1.4809196\n",
      "  0.04489978 -0.58815604 -1.4992704  -0.05218808 -0.46751106 -1.2604277\n",
      " -0.17539936 -0.23938526 -1.9414468  -0.02616435 -0.38380224 -1.9661252\n",
      "  0.1371652  -0.36215842 -1.3712687  -0.14776783 -0.24019973 -1.1909404\n",
      " -0.10166125 -0.21535783 -1.2838671  -0.07532749 -0.2012226  -1.4014685\n",
      "  0.03516836 -0.21477407 -1.2256479 ]\n",
      "data: [ 0.03507571 -0.02217044 -0.19935161  0.05034405 -0.1386372  -0.5647582\n",
      " -0.07828549 -0.33181655 -1.3458166  -0.23150101 -0.39663324 -1.6337162\n",
      " -0.39514634 -0.4803506  -2.1395338  -0.15575352 -0.6514964  -1.5005146\n",
      " -0.01187785 -0.6993803  -1.3609921  -0.06082909 -0.62053776 -1.4253391\n",
      " -0.06160775 -0.7817609  -1.541618   -0.12078133 -0.5644287  -1.4168632\n",
      " -0.06788393 -0.60624874 -1.3853378  -0.09689394 -0.5774303  -1.4809196\n",
      "  0.04489978 -0.58815604 -1.4992704  -0.05218808 -0.46751106 -1.2604277\n",
      " -0.17539936 -0.23938526 -1.9414468  -0.02616435 -0.38380224 -1.9661251\n",
      "  0.1371652  -0.36215842 -1.3712687  -0.14776783 -0.24019974 -1.1909404\n",
      " -0.10166125 -0.21535783 -1.2838672  -0.07532749 -0.2012226  -1.4014685\n",
      "  0.03516836 -0.21477407 -1.2256479   0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B320>\n",
      "tensor([[ 0.0250, -0.0627, -0.2426,  ...,  0.0312, -0.2463, -1.2969],\n",
      "        [ 0.0250, -0.0627, -0.2426,  ...,  0.0312, -0.2463, -1.2969],\n",
      "        [ 0.0250, -0.0627, -0.2426,  ...,  0.0312, -0.2463, -1.2969],\n",
      "        ...,\n",
      "        [-0.2666,  0.2449, -0.1916,  ..., -0.7968,  0.6594, -0.3203],\n",
      "        [-0.1487, -0.1058,  0.5424,  ..., -0.2431,  0.6788,  0.2608],\n",
      "        [-0.1487, -0.1058,  0.5424,  ..., -0.2431,  0.6788,  0.2608]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0249923  -0.06267391 -0.24257971  0.04633604 -0.20032646 -0.6567104\n",
      " -0.06556109 -0.38695255 -1.4216447  -0.21118894 -0.4548484  -1.7020816\n",
      " -0.37591034 -0.5543032  -2.188117   -0.17363372 -0.67525244 -1.5715396\n",
      "  0.0022566  -0.7127839  -1.3921955  -0.04325658 -0.64176905 -1.4491018\n",
      " -0.04758931 -0.7805176  -1.5600841  -0.13804361 -0.57593334 -1.4949554\n",
      " -0.07005025 -0.62617975 -1.4559921  -0.09312885 -0.59943974 -1.5434619\n",
      "  0.0429154  -0.6115702  -1.5788007  -0.06478358 -0.49390295 -1.3322514\n",
      " -0.17384617 -0.26438954 -1.9605533  -0.03054584 -0.41066968 -1.9678513\n",
      "  0.12193918 -0.3844598  -1.4447172  -0.1567909  -0.258793   -1.2663392\n",
      " -0.09985889 -0.2338386  -1.3462411  -0.05667391 -0.23233655 -1.4617989\n",
      "  0.03116909 -0.24632965 -1.2968881 ]\n",
      "data: [ 0.0249923  -0.06267391 -0.24257971  0.04633604 -0.20032646 -0.6567104\n",
      " -0.06556109 -0.38695255 -1.4216447  -0.21118894 -0.4548484  -1.7020816\n",
      " -0.37591034 -0.5543032  -2.188117   -0.17363372 -0.67525244 -1.5715396\n",
      "  0.0022566  -0.7127839  -1.3921955  -0.04325658 -0.64176905 -1.4491019\n",
      " -0.04758931 -0.7805176  -1.5600841  -0.13804361 -0.57593334 -1.4949554\n",
      " -0.07005025 -0.62617975 -1.4559921  -0.09312885 -0.59943974 -1.5434619\n",
      "  0.0429154  -0.6115702  -1.5788007  -0.06478358 -0.49390298 -1.3322514\n",
      " -0.17384617 -0.26438954 -1.9605533  -0.03054584 -0.41066968 -1.9678513\n",
      "  0.12193918 -0.3844598  -1.444717   -0.1567909  -0.258793   -1.2663392\n",
      " -0.09985889 -0.2338386  -1.3462411  -0.05667391 -0.23233657 -1.4617989\n",
      "  0.03116909 -0.24632965 -1.2968881   0.1       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FE80>\n",
      "tensor([[ 0.0273, -0.0723, -0.2512,  ...,  0.0545, -0.2603, -1.2833],\n",
      "        [ 0.0273, -0.0723, -0.2512,  ...,  0.0545, -0.2603, -1.2833],\n",
      "        [ 0.0273, -0.0723, -0.2512,  ...,  0.0545, -0.2603, -1.2833],\n",
      "        ...,\n",
      "        [-0.1147,  0.3829, -0.1070,  ..., -0.7222,  0.8922, -0.3708],\n",
      "        [-0.1350, -0.1530,  0.5647,  ..., -0.2409,  0.6200,  0.2245],\n",
      "        [-0.1350, -0.1530,  0.5647,  ..., -0.2409,  0.6200,  0.2245]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02732201 -0.07232016 -0.2512137   0.05029817 -0.19940645 -0.6430003\n",
      " -0.05081048 -0.38769922 -1.4050951  -0.19401923 -0.4491844  -1.6987998\n",
      " -0.35390437 -0.5533388  -2.182774   -0.1674723  -0.6832994  -1.5639303\n",
      "  0.02628723 -0.7204339  -1.3973858  -0.02389716 -0.6529386  -1.4549313\n",
      " -0.02448418 -0.79695314 -1.572959   -0.12612775 -0.5876136  -1.4772487\n",
      " -0.05276941 -0.6380237  -1.4517019  -0.06739634 -0.61080235 -1.5438981\n",
      "  0.06535512 -0.6338418  -1.5793803  -0.04310311 -0.4960271  -1.309813\n",
      " -0.16274446 -0.26742136 -1.9758792  -0.00504131 -0.42237768 -1.9847386\n",
      "  0.15353785 -0.3926072  -1.4395666  -0.145431   -0.26548567 -1.2423384\n",
      " -0.07331772 -0.24156529 -1.3264349  -0.03345931 -0.2473535  -1.4432251\n",
      "  0.05451205 -0.26034933 -1.2833054 ]\n",
      "data: [ 0.02732201 -0.07232016 -0.2512137   0.05029817 -0.19940645 -0.64300036\n",
      " -0.05081048 -0.38769922 -1.4050951  -0.19401923 -0.4491844  -1.6987998\n",
      " -0.35390437 -0.5533388  -2.182774   -0.1674723  -0.6832994  -1.5639302\n",
      "  0.02628723 -0.7204339  -1.3973858  -0.02389716 -0.6529386  -1.4549314\n",
      " -0.02448418 -0.79695314 -1.572959   -0.12612775 -0.5876136  -1.4772487\n",
      " -0.05276941 -0.6380237  -1.4517018  -0.06739634 -0.61080235 -1.5438981\n",
      "  0.06535512 -0.6338418  -1.5793804  -0.04310311 -0.4960271  -1.309813\n",
      " -0.16274446 -0.26742136 -1.9758792  -0.00504131 -0.42237768 -1.9847386\n",
      "  0.15353785 -0.39260718 -1.4395666  -0.145431   -0.26548567 -1.2423384\n",
      " -0.07331772 -0.24156529 -1.3264347  -0.03345931 -0.2473535  -1.4432251\n",
      "  0.05451205 -0.26034933 -1.2833054   0.11      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63EB8>\n",
      "tensor([[ 0.0187, -0.0485, -0.2510,  ...,  0.0491, -0.2421, -1.2870],\n",
      "        [ 0.0187, -0.0485, -0.2510,  ...,  0.0491, -0.2421, -1.2870],\n",
      "        [ 0.0187, -0.0485, -0.2510,  ...,  0.0491, -0.2421, -1.2870],\n",
      "        ...,\n",
      "        [-0.1197,  0.3711, -0.0781,  ..., -0.6859,  0.8580, -0.3422],\n",
      "        [-0.1402, -0.1497,  0.5552,  ..., -0.2179,  0.6167,  0.2140],\n",
      "        [-0.1402, -0.1497,  0.5552,  ..., -0.2179,  0.6167,  0.2140]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01874799 -0.04850404 -0.25096795  0.03320645 -0.1838903  -0.6518812\n",
      " -0.06039329 -0.36836034 -1.3959366  -0.20543364 -0.42977303 -1.6945834\n",
      " -0.37793696 -0.541868   -2.1683137  -0.1842438  -0.6591872  -1.5560855\n",
      "  0.02207795 -0.6930299  -1.3712317  -0.02787951 -0.6272257  -1.428272\n",
      " -0.02681943 -0.76745605 -1.5446892  -0.14011277 -0.55752414 -1.470197\n",
      " -0.06127507 -0.6113831  -1.4443246  -0.07275748 -0.5884774  -1.5408065\n",
      "  0.06173359 -0.60828066 -1.5823805  -0.0512602  -0.4712786  -1.3008949\n",
      " -0.16524501 -0.2474503  -1.946117   -0.01156202 -0.40139365 -1.9481653\n",
      "  0.14849731 -0.37148708 -1.438381   -0.15189523 -0.23799118 -1.237548\n",
      " -0.07693371 -0.21852031 -1.3211024  -0.03380622 -0.22933227 -1.4379308\n",
      "  0.04907358 -0.24213773 -1.2869728 ]\n",
      "data: [ 0.01874799 -0.04850404 -0.25096795  0.03320645 -0.1838903  -0.6518813\n",
      " -0.06039329 -0.36836034 -1.3959366  -0.20543364 -0.42977303 -1.6945834\n",
      " -0.37793696 -0.541868   -2.1683137  -0.1842438  -0.65918714 -1.5560855\n",
      "  0.02207795 -0.6930299  -1.3712317  -0.0278795  -0.6272257  -1.4282719\n",
      " -0.02681943 -0.76745605 -1.5446892  -0.14011277 -0.55752414 -1.470197\n",
      " -0.06127507 -0.6113831  -1.4443246  -0.07275748 -0.5884774  -1.5408065\n",
      "  0.06173359 -0.60828066 -1.5823805  -0.0512602  -0.4712786  -1.300895\n",
      " -0.16524501 -0.2474503  -1.946117   -0.01156202 -0.40139365 -1.9481653\n",
      "  0.14849731 -0.37148708 -1.4383808  -0.15189523 -0.23799118 -1.237548\n",
      " -0.07693371 -0.21852031 -1.3211025  -0.03380622 -0.22933227 -1.4379307\n",
      "  0.04907359 -0.24213773 -1.2869728   0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[ 0.0145, -0.0753, -0.2504,  ...,  0.0355, -0.2645, -1.2998],\n",
      "        [ 0.0145, -0.0753, -0.2504,  ...,  0.0355, -0.2645, -1.2998],\n",
      "        [ 0.0145, -0.0753, -0.2504,  ...,  0.0355, -0.2645, -1.2998],\n",
      "        ...,\n",
      "        [-0.1586,  0.3989, -0.1210,  ..., -0.7198,  0.8820, -0.3590],\n",
      "        [-0.1607, -0.1410,  0.5707,  ..., -0.2516,  0.6394,  0.2268],\n",
      "        [-0.1607, -0.1410,  0.5707,  ..., -0.2516,  0.6394,  0.2268]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01448518 -0.07533549 -0.250422    0.03403421 -0.20885229 -0.6604619\n",
      " -0.06322769 -0.39482063 -1.4190624  -0.20539202 -0.45834577 -1.7123097\n",
      " -0.3699121  -0.5641551  -2.1922314  -0.18258895 -0.68556786 -1.5751933\n",
      "  0.01494904 -0.7207495  -1.3918016  -0.0340876  -0.65404534 -1.4494851\n",
      " -0.03683443 -0.79367685 -1.5663205  -0.1424328  -0.5859747  -1.4906396\n",
      " -0.06813048 -0.63730097 -1.4626365  -0.08441047 -0.61252296 -1.5555032\n",
      "  0.04793979 -0.63130164 -1.5956916  -0.06070674 -0.49977285 -1.3229884\n",
      " -0.17439969 -0.27319485 -1.9684286  -0.02453074 -0.42404366 -1.9736928\n",
      "  0.13134307 -0.3953394  -1.4535506  -0.1598148  -0.2662546  -1.256148\n",
      " -0.08988532 -0.24389663 -1.3397253  -0.04742311 -0.25075737 -1.455316\n",
      "  0.0355012  -0.2644673  -1.2997947 ]\n",
      "data: [ 0.01448518 -0.07533549 -0.250422    0.03403421 -0.20885229 -0.6604619\n",
      " -0.06322769 -0.39482063 -1.4190624  -0.20539202 -0.45834577 -1.7123097\n",
      " -0.36991206 -0.5641551  -2.1922314  -0.18258896 -0.68556786 -1.5751933\n",
      "  0.01494904 -0.7207495  -1.3918016  -0.0340876  -0.65404534 -1.4494851\n",
      " -0.03683443 -0.79367685 -1.5663205  -0.1424328  -0.5859747  -1.4906394\n",
      " -0.06813048 -0.63730097 -1.4626365  -0.08441047 -0.61252296 -1.5555032\n",
      "  0.04793979 -0.63130164 -1.5956916  -0.06070675 -0.49977285 -1.3229884\n",
      " -0.17439967 -0.27319485 -1.9684286  -0.02453074 -0.42404366 -1.9736928\n",
      "  0.13134307 -0.3953394  -1.4535506  -0.1598148  -0.2662546  -1.256148\n",
      " -0.08988532 -0.24389663 -1.3397251  -0.04742311 -0.25075737 -1.4553161\n",
      "  0.0355012  -0.2644673  -1.2997947   0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[ 0.0173, -0.0354, -0.2431,  ...,  0.0361, -0.2307, -1.2651],\n",
      "        [ 0.0173, -0.0354, -0.2431,  ...,  0.0361, -0.2307, -1.2651],\n",
      "        [ 0.0173, -0.0354, -0.2431,  ...,  0.0361, -0.2307, -1.2651],\n",
      "        ...,\n",
      "        [-0.1204,  0.3861, -0.1149,  ..., -0.6878,  0.8834, -0.3846],\n",
      "        [-0.1407, -0.1778,  0.5557,  ..., -0.2263,  0.5851,  0.2194],\n",
      "        [-0.1407, -0.1778,  0.5557,  ..., -0.2263,  0.5851,  0.2194]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.7261777e-02 -3.5385914e-02 -2.4313793e-01  3.4169208e-02\n",
      " -1.5928105e-01 -6.2569642e-01 -7.6377816e-02 -3.5100621e-01\n",
      " -1.3878474e+00 -2.2231638e-01 -4.1319871e-01 -1.6798260e+00\n",
      " -3.8684031e-01 -5.1150036e-01 -2.1649861e+00 -1.7806679e-01\n",
      " -6.5361428e-01 -1.5442851e+00 -2.0855069e-03 -6.9554728e-01\n",
      " -1.3818297e+00 -5.0241113e-02 -6.2423861e-01 -1.4418741e+00\n",
      " -4.9515508e-02 -7.7639484e-01 -1.5584356e+00 -1.3836181e-01\n",
      " -5.5977356e-01 -1.4584433e+00 -7.3275611e-02 -6.0868520e-01\n",
      " -1.4295902e+00 -9.1111757e-02 -5.8413875e-01 -1.5226591e+00\n",
      "  4.6438947e-02 -6.0105306e-01 -1.5532525e+00 -5.9567921e-02\n",
      " -4.6746880e-01 -1.2960186e+00 -1.8156470e-01 -2.4276485e-01\n",
      " -1.9691582e+00 -2.5783688e-02 -3.9514589e-01 -1.9823489e+00\n",
      "  1.3565096e-01 -3.6713660e-01 -1.4163207e+00 -1.5803590e-01\n",
      " -2.3945588e-01 -1.2286668e+00 -9.6747592e-02 -2.1677272e-01\n",
      " -1.3153106e+00 -6.0539231e-02 -2.1657723e-01 -1.4318361e+00\n",
      "  3.6081918e-02 -2.3069325e-01 -1.2650706e+00]\n",
      "data: [ 1.7261777e-02 -3.5385914e-02 -2.4313793e-01  3.4169208e-02\n",
      " -1.5928105e-01 -6.2569642e-01 -7.6377816e-02 -3.5100621e-01\n",
      " -1.3878474e+00 -2.2231638e-01 -4.1319871e-01 -1.6798260e+00\n",
      " -3.8684031e-01 -5.1150036e-01 -2.1649861e+00 -1.7806679e-01\n",
      " -6.5361428e-01 -1.5442852e+00 -2.0855069e-03 -6.9554728e-01\n",
      " -1.3818297e+00 -5.0241113e-02 -6.2423861e-01 -1.4418740e+00\n",
      " -4.9515508e-02 -7.7639478e-01 -1.5584356e+00 -1.3836181e-01\n",
      " -5.5977356e-01 -1.4584433e+00 -7.3275611e-02 -6.0868520e-01\n",
      " -1.4295901e+00 -9.1111757e-02 -5.8413875e-01 -1.5226589e+00\n",
      "  4.6438947e-02 -6.0105306e-01 -1.5532525e+00 -5.9567917e-02\n",
      " -4.6746880e-01 -1.2960187e+00 -1.8156472e-01 -2.4276486e-01\n",
      " -1.9691582e+00 -2.5783686e-02 -3.9514586e-01 -1.9823489e+00\n",
      "  1.3565096e-01 -3.6713660e-01 -1.4163207e+00 -1.5803590e-01\n",
      " -2.3945588e-01 -1.2286668e+00 -9.6747592e-02 -2.1677274e-01\n",
      " -1.3153107e+00 -6.0539231e-02 -2.1657723e-01 -1.4318361e+00\n",
      "  3.6081918e-02 -2.3069325e-01 -1.2650706e+00  1.4000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[ 0.0170, -0.0300, -0.2272,  ...,  0.0267, -0.2212, -1.2757],\n",
      "        [ 0.0170, -0.0300, -0.2272,  ...,  0.0267, -0.2212, -1.2757],\n",
      "        [ 0.0170, -0.0300, -0.2272,  ...,  0.0267, -0.2212, -1.2757],\n",
      "        ...,\n",
      "        [-0.3493,  0.1591, -0.3064,  ..., -0.8789,  0.5628, -0.4436],\n",
      "        [-0.1160, -0.0984,  0.5654,  ..., -0.1994,  0.6887,  0.2471],\n",
      "        [-0.1160, -0.0984,  0.5654,  ..., -0.1994,  0.6887,  0.2471]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.69519149e-02 -2.99693812e-02 -2.27203429e-01  2.84996741e-02\n",
      " -1.71295568e-01 -6.51422977e-01 -7.21160993e-02 -3.49619448e-01\n",
      " -1.38884068e+00 -2.16424778e-01 -4.14399147e-01 -1.67734456e+00\n",
      " -3.90652895e-01 -5.18220782e-01 -2.15308690e+00 -1.85134366e-01\n",
      " -6.38769507e-01 -1.53820324e+00 -1.96789205e-03 -6.69143796e-01\n",
      " -1.35329664e+00 -4.54071611e-02 -6.00442767e-01 -1.41392112e+00\n",
      " -4.43481505e-02 -7.37146616e-01 -1.52524352e+00 -1.48511320e-01\n",
      " -5.35856247e-01 -1.46138787e+00 -7.61550665e-02 -5.85995674e-01\n",
      " -1.42662668e+00 -9.60064530e-02 -5.64546227e-01 -1.52090657e+00\n",
      "  4.33887541e-02 -5.72460651e-01 -1.56280649e+00 -7.11591467e-02\n",
      " -4.57448483e-01 -1.29666734e+00 -1.72260955e-01 -2.36700028e-01\n",
      " -1.90188646e+00 -3.45960408e-02 -3.77856702e-01 -1.90494418e+00\n",
      "  1.20547384e-01 -3.53629619e-01 -1.42095757e+00 -1.59079447e-01\n",
      " -2.24041060e-01 -1.23478997e+00 -1.01063952e-01 -2.03981832e-01\n",
      " -1.31345785e+00 -5.78167289e-02 -2.05514938e-01 -1.42992735e+00\n",
      "  2.66869441e-02 -2.21198395e-01 -1.27567112e+00]\n",
      "data: [ 1.69519149e-02 -2.99693830e-02 -2.27203429e-01  2.84996741e-02\n",
      " -1.71295568e-01 -6.51422977e-01 -7.21160993e-02 -3.49619448e-01\n",
      " -1.38884068e+00 -2.16424763e-01 -4.14399147e-01 -1.67734456e+00\n",
      " -3.90652895e-01 -5.18220782e-01 -2.15308690e+00 -1.85134366e-01\n",
      " -6.38769507e-01 -1.53820324e+00 -1.96789205e-03 -6.69143856e-01\n",
      " -1.35329664e+00 -4.54071611e-02 -6.00442767e-01 -1.41392100e+00\n",
      " -4.43481505e-02 -7.37146616e-01 -1.52524352e+00 -1.48511320e-01\n",
      " -5.35856247e-01 -1.46138799e+00 -7.61550665e-02 -5.85995674e-01\n",
      " -1.42662668e+00 -9.60064530e-02 -5.64546227e-01 -1.52090657e+00\n",
      "  4.33887541e-02 -5.72460651e-01 -1.56280661e+00 -7.11591467e-02\n",
      " -4.57448512e-01 -1.29666734e+00 -1.72260955e-01 -2.36700013e-01\n",
      " -1.90188646e+00 -3.45960408e-02 -3.77856702e-01 -1.90494418e+00\n",
      "  1.20547384e-01 -3.53629619e-01 -1.42095768e+00 -1.59079447e-01\n",
      " -2.24041060e-01 -1.23478997e+00 -1.01063944e-01 -2.03981832e-01\n",
      " -1.31345785e+00 -5.78167289e-02 -2.05514953e-01 -1.42992735e+00\n",
      "  2.66869441e-02 -2.21198380e-01 -1.27567112e+00  1.50000006e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63A58>\n",
      "tensor([[ 0.0386, -0.0751, -0.2299,  ...,  0.0435, -0.2616, -1.2800],\n",
      "        [ 0.0386, -0.0751, -0.2299,  ...,  0.0435, -0.2616, -1.2800],\n",
      "        [ 0.0386, -0.0751, -0.2299,  ...,  0.0435, -0.2616, -1.2800],\n",
      "        ...,\n",
      "        [-0.3091,  0.2773, -0.3181,  ..., -0.8438,  0.7381, -0.4869],\n",
      "        [-0.1214, -0.0881,  0.6083,  ..., -0.2262,  0.7038,  0.2859],\n",
      "        [-0.1214, -0.0881,  0.6083,  ..., -0.2262,  0.7038,  0.2859]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03857948 -0.07513815 -0.22987834  0.06133197 -0.2067047  -0.6382133\n",
      " -0.05068244 -0.3898953  -1.3959136  -0.19415426 -0.45553184 -1.6787052\n",
      " -0.35366735 -0.5465573  -2.1706254  -0.15021402 -0.6898576  -1.5476344\n",
      "  0.01294938 -0.72448444 -1.3831147  -0.0295637  -0.6522169  -1.445961\n",
      " -0.03236635 -0.79542255 -1.5589366  -0.11827615 -0.5947976  -1.4722121\n",
      " -0.05357993 -0.6397846  -1.4371079  -0.08008794 -0.61281943 -1.52795\n",
      "  0.05875532 -0.621994   -1.5617527  -0.04986887 -0.5082443  -1.3114879\n",
      " -0.15661398 -0.28333616 -1.9438337  -0.01621469 -0.42335236 -1.9570093\n",
      "  0.13713777 -0.3990592  -1.4283487  -0.13784538 -0.27869904 -1.2467731\n",
      " -0.08774139 -0.25263906 -1.3274988  -0.04965791 -0.24545856 -1.4454632\n",
      "  0.04346736 -0.26160258 -1.2800086 ]\n",
      "data: [ 0.03857948 -0.07513815 -0.22987834  0.06133197 -0.2067047  -0.6382133\n",
      " -0.05068244 -0.3898953  -1.3959136  -0.19415426 -0.45553184 -1.6787051\n",
      " -0.35366735 -0.5465573  -2.1706254  -0.15021402 -0.68985766 -1.5476345\n",
      "  0.01294938 -0.7244844  -1.3831146  -0.02956369 -0.652217   -1.445961\n",
      " -0.03236635 -0.7954225  -1.5589366  -0.11827615 -0.5947976  -1.4722121\n",
      " -0.05357994 -0.6397846  -1.4371078  -0.08008794 -0.61281943 -1.5279499\n",
      "  0.05875532 -0.621994   -1.5617527  -0.04986887 -0.5082443  -1.3114879\n",
      " -0.15661398 -0.28333616 -1.9438338  -0.01621469 -0.42335236 -1.9570093\n",
      "  0.13713777 -0.3990592  -1.4283487  -0.13784538 -0.27869904 -1.2467731\n",
      " -0.0877414  -0.25263906 -1.3274988  -0.04965791 -0.24545856 -1.4454633\n",
      "  0.04346736 -0.26160258 -1.2800086   0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F5C0>\n",
      "tensor([[ 0.0298, -0.0746, -0.2468,  ...,  0.0630, -0.2643, -1.2804],\n",
      "        [ 0.0298, -0.0746, -0.2468,  ...,  0.0630, -0.2643, -1.2804],\n",
      "        [ 0.0298, -0.0746, -0.2468,  ...,  0.0630, -0.2643, -1.2804],\n",
      "        ...,\n",
      "        [-0.1325,  0.3728, -0.0746,  ..., -0.7433,  0.8639, -0.3324],\n",
      "        [-0.1396, -0.1354,  0.5763,  ..., -0.2280,  0.6424,  0.2201],\n",
      "        [-0.1396, -0.1354,  0.5763,  ..., -0.2280,  0.6424,  0.2201]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.9819656e-02 -7.4626081e-02 -2.4682638e-01  5.0947558e-02\n",
      " -2.0512022e-01 -6.4604533e-01 -4.8014976e-02 -3.9857802e-01\n",
      " -1.4111958e+00 -1.9253074e-01 -4.6227273e-01 -1.7086776e+00\n",
      " -3.5668975e-01 -5.7275516e-01 -2.1868243e+00 -1.6964625e-01\n",
      " -6.8745595e-01 -1.5682746e+00  3.6602303e-02 -7.2769701e-01\n",
      " -1.3838881e+00 -1.6951680e-02 -6.6248238e-01 -1.4392496e+00\n",
      " -2.3693070e-02 -8.0678111e-01 -1.5589192e+00 -1.2472798e-01\n",
      " -5.8938146e-01 -1.4777297e+00 -4.9420416e-02 -6.4451146e-01\n",
      " -1.4519429e+00 -6.3015945e-02 -6.1809176e-01 -1.5440259e+00\n",
      "  6.6588238e-02 -6.4491481e-01 -1.5809865e+00 -3.6519669e-02\n",
      " -4.9691001e-01 -1.3075234e+00 -1.5977582e-01 -2.6866546e-01\n",
      " -1.9780556e+00  2.1839887e-04 -4.2845002e-01 -1.9837867e+00\n",
      "  1.5893404e-01 -3.9664054e-01 -1.4377582e+00 -1.4217435e-01\n",
      " -2.6400059e-01 -1.2382743e+00 -6.4016089e-02 -2.4123509e-01\n",
      " -1.3237092e+00 -2.1665990e-02 -2.5244457e-01 -1.4392008e+00\n",
      "  6.2972002e-02 -2.6427943e-01 -1.2804472e+00]\n",
      "data: [ 2.9819656e-02 -7.4626081e-02 -2.4682638e-01  5.0947558e-02\n",
      " -2.0512022e-01 -6.4604533e-01 -4.8014976e-02 -3.9857805e-01\n",
      " -1.4111956e+00 -1.9253072e-01 -4.6227273e-01 -1.7086776e+00\n",
      " -3.5668975e-01 -5.7275516e-01 -2.1868243e+00 -1.6964625e-01\n",
      " -6.8745595e-01 -1.5682747e+00  3.6602303e-02 -7.2769701e-01\n",
      " -1.3838881e+00 -1.6951680e-02 -6.6248238e-01 -1.4392495e+00\n",
      " -2.3693070e-02 -8.0678105e-01 -1.5589192e+00 -1.2472799e-01\n",
      " -5.8938146e-01 -1.4777297e+00 -4.9420413e-02 -6.4451146e-01\n",
      " -1.4519429e+00 -6.3015945e-02 -6.1809176e-01 -1.5440259e+00\n",
      "  6.6588238e-02 -6.4491481e-01 -1.5809865e+00 -3.6519669e-02\n",
      " -4.9691001e-01 -1.3075234e+00 -1.5977582e-01 -2.6866546e-01\n",
      " -1.9780556e+00  2.1839887e-04 -4.2845002e-01 -1.9837868e+00\n",
      "  1.5893404e-01 -3.9664054e-01 -1.4377582e+00 -1.4217435e-01\n",
      " -2.6400059e-01 -1.2382743e+00 -6.4016089e-02 -2.4123508e-01\n",
      " -1.3237092e+00 -2.1665990e-02 -2.5244457e-01 -1.4392008e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6.2972002e-02 -2.6427943e-01 -1.2804472e+00  1.7000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[ 0.0259, -0.0872, -0.2544,  ...,  0.0662, -0.2757, -1.2994],\n",
      "        [ 0.0259, -0.0872, -0.2544,  ...,  0.0662, -0.2757, -1.2994],\n",
      "        [ 0.0259, -0.0872, -0.2544,  ...,  0.0662, -0.2757, -1.2994],\n",
      "        ...,\n",
      "        [-0.1313,  0.3851, -0.1198,  ..., -0.7582,  0.8743, -0.3614],\n",
      "        [-0.1339, -0.1134,  0.5809,  ..., -0.2222,  0.6557,  0.2212],\n",
      "        [-0.1339, -0.1134,  0.5809,  ..., -0.2222,  0.6557,  0.2212]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02588398 -0.08715253 -0.25438562  0.04626234 -0.22595072 -0.66037667\n",
      " -0.03643303 -0.41060978 -1.4077094  -0.17847724 -0.47177112 -1.7101657\n",
      " -0.34778523 -0.5911978  -2.180196   -0.1766006  -0.6929511  -1.5722888\n",
      "  0.050726   -0.7243571  -1.3829188  -0.00289744 -0.66406846 -1.4359193\n",
      " -0.00465088 -0.7983529  -1.5538218  -0.12916629 -0.5885216  -1.4833288\n",
      " -0.04193226 -0.64610976 -1.4611421  -0.05006805 -0.6218126  -1.5572429\n",
      "  0.07684715 -0.65046364 -1.6043265  -0.03432382 -0.50096834 -1.3088682\n",
      " -0.15036273 -0.27491647 -1.9584079   0.00759219 -0.43481416 -1.9558158\n",
      "  0.16326609 -0.40151995 -1.4563942  -0.14107299 -0.2648769  -1.2448671\n",
      " -0.05323659 -0.24519199 -1.3265877  -0.00635345 -0.26445693 -1.4435072\n",
      "  0.06620256 -0.2757413  -1.2993793 ]\n",
      "data: [ 0.02588398 -0.08715253 -0.25438562  0.04626234 -0.22595072 -0.66037667\n",
      " -0.03643303 -0.41060978 -1.4077094  -0.17847724 -0.47177112 -1.7101657\n",
      " -0.34778523 -0.5911978  -2.180196   -0.1766006  -0.692951   -1.5722889\n",
      "  0.05072599 -0.7243571  -1.3829188  -0.00289744 -0.66406846 -1.4359193\n",
      " -0.00465088 -0.7983529  -1.5538219  -0.12916629 -0.5885216  -1.4833288\n",
      " -0.04193226 -0.64610976 -1.4611421  -0.05006805 -0.6218126  -1.5572429\n",
      "  0.07684715 -0.65046364 -1.6043265  -0.03432382 -0.50096834 -1.308868\n",
      " -0.15036273 -0.27491647 -1.9584079   0.00759219 -0.43481416 -1.9558158\n",
      "  0.16326609 -0.40151995 -1.4563942  -0.14107299 -0.2648769  -1.2448671\n",
      " -0.05323659 -0.24519199 -1.3265877  -0.00635345 -0.26445693 -1.4435072\n",
      "  0.06620256 -0.2757413  -1.2993792   0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0226, -0.1044, -0.2622,  ...,  0.0652, -0.2911, -1.3121],\n",
      "        [ 0.0226, -0.1044, -0.2622,  ...,  0.0652, -0.2911, -1.3121],\n",
      "        [ 0.0226, -0.1044, -0.2622,  ...,  0.0652, -0.2911, -1.3121],\n",
      "        ...,\n",
      "        [-0.1008,  0.4293, -0.1373,  ..., -0.6559,  0.9307, -0.4308],\n",
      "        [-0.1350, -0.1073,  0.5940,  ..., -0.2325,  0.6575,  0.2294],\n",
      "        [-0.1350, -0.1073,  0.5940,  ..., -0.2325,  0.6575,  0.2294]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.25977264e-02 -1.04401916e-01 -2.62196511e-01  4.42381017e-02\n",
      " -2.46924862e-01 -6.68742955e-01 -3.15579921e-02 -4.31958765e-01\n",
      " -1.41585469e+00 -1.73063248e-01 -4.92870986e-01 -1.72113705e+00\n",
      " -3.43282402e-01 -6.16792262e-01 -2.18898726e+00 -1.81993753e-01\n",
      " -7.08323777e-01 -1.58590722e+00  5.95096424e-02 -7.38010466e-01\n",
      " -1.38683426e+00  4.30025905e-03 -6.80703402e-01 -1.43722653e+00\n",
      "  9.02414322e-05 -8.10525060e-01 -1.55570221e+00 -1.32788301e-01\n",
      " -6.00404263e-01 -1.49533677e+00 -4.04967964e-02 -6.60409570e-01\n",
      " -1.47498667e+00 -4.59268317e-02 -6.35925531e-01 -1.57121670e+00\n",
      "  7.69936070e-02 -6.68141663e-01 -1.62262607e+00 -3.30610871e-02\n",
      " -5.12665629e-01 -1.31835556e+00 -1.49672717e-01 -2.86810994e-01\n",
      " -1.96153450e+00  8.67974013e-03 -4.49475765e-01 -1.95480108e+00\n",
      "  1.61927968e-01 -4.12792861e-01 -1.47170877e+00 -1.43499553e-01\n",
      " -2.74528444e-01 -1.25498092e+00 -4.88245413e-02 -2.55202293e-01\n",
      " -1.33402133e+00  5.04776835e-05 -2.80350327e-01 -1.45040882e+00\n",
      "  6.52384609e-02 -2.91149914e-01 -1.31211197e+00]\n",
      "data: [ 2.25977246e-02 -1.04401916e-01 -2.62196511e-01  4.42381017e-02\n",
      " -2.46924862e-01 -6.68742955e-01 -3.15579921e-02 -4.31958765e-01\n",
      " -1.41585469e+00 -1.73063233e-01 -4.92870986e-01 -1.72113705e+00\n",
      " -3.43282402e-01 -6.16792262e-01 -2.18898726e+00 -1.81993753e-01\n",
      " -7.08323717e-01 -1.58590734e+00  5.95096461e-02 -7.38010466e-01\n",
      " -1.38683426e+00  4.30025905e-03 -6.80703402e-01 -1.43722653e+00\n",
      "  9.02414322e-05 -8.10525060e-01 -1.55570221e+00 -1.32788301e-01\n",
      " -6.00404263e-01 -1.49533677e+00 -4.04967964e-02 -6.60409570e-01\n",
      " -1.47498667e+00 -4.59268317e-02 -6.35925531e-01 -1.57121670e+00\n",
      "  7.69936070e-02 -6.68141603e-01 -1.62262607e+00 -3.30610871e-02\n",
      " -5.12665629e-01 -1.31835556e+00 -1.49672717e-01 -2.86810994e-01\n",
      " -1.96153438e+00  8.67974013e-03 -4.49475795e-01 -1.95480108e+00\n",
      "  1.61927968e-01 -4.12792861e-01 -1.47170877e+00 -1.43499553e-01\n",
      " -2.74528444e-01 -1.25498092e+00 -4.88245375e-02 -2.55202293e-01\n",
      " -1.33402133e+00  5.04776835e-05 -2.80350327e-01 -1.45040882e+00\n",
      "  6.52384609e-02 -2.91149914e-01 -1.31211197e+00  1.89999998e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63FD0>\n",
      "tensor([[ 0.0090, -0.1131, -0.2335,  ...,  0.0542, -0.2974, -1.2914],\n",
      "        [ 0.0090, -0.1131, -0.2335,  ...,  0.0542, -0.2974, -1.2914],\n",
      "        [ 0.0090, -0.1131, -0.2335,  ...,  0.0542, -0.2974, -1.2914],\n",
      "        ...,\n",
      "        [-0.0897,  0.4511, -0.1500,  ..., -0.6360,  0.9345, -0.4249],\n",
      "        [-0.1324, -0.0972,  0.5988,  ..., -0.2360,  0.6382,  0.2624],\n",
      "        [-0.1324, -0.0972,  0.5988,  ..., -0.2360,  0.6382,  0.2624]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 9.0141715e-03 -1.1312097e-01 -2.3348421e-01  3.0680601e-02\n",
      " -2.5773668e-01 -6.3660949e-01 -3.7923351e-02 -4.4357717e-01\n",
      " -1.3829203e+00 -1.8011741e-01 -5.0364399e-01 -1.6925247e+00\n",
      " -3.5141981e-01 -6.3284039e-01 -2.1596243e+00 -1.9917084e-01\n",
      " -7.1543181e-01 -1.5642771e+00  5.6436703e-02 -7.4570012e-01\n",
      " -1.3637466e+00 -2.5160313e-03 -6.9257188e-01 -1.4105352e+00\n",
      " -6.9022179e-03 -8.2077575e-01 -1.5296371e+00 -1.4636782e-01\n",
      " -6.0487974e-01 -1.4711919e+00 -4.9271159e-02 -6.6868132e-01\n",
      " -1.4538028e+00 -5.1734917e-02 -6.4522231e-01 -1.5522280e+00\n",
      "  6.5968782e-02 -6.8427467e-01 -1.6054389e+00 -4.1091673e-02\n",
      " -5.1455957e-01 -1.2922649e+00 -1.6133398e-01 -2.8952056e-01\n",
      " -1.9393276e+00  9.6559525e-05 -4.5764118e-01 -1.9302826e+00\n",
      "  1.5175794e-01 -4.1931468e-01 -1.4529577e+00 -1.5716989e-01\n",
      " -2.7418742e-01 -1.2286062e+00 -5.3842992e-02 -2.5643346e-01\n",
      " -1.3069291e+00 -4.8837662e-03 -2.8806657e-01 -1.4234759e+00\n",
      "  5.4249786e-02 -2.9737088e-01 -1.2914088e+00]\n",
      "data: [ 9.0141715e-03 -1.1312097e-01 -2.3348421e-01  3.0680602e-02\n",
      " -2.5773668e-01 -6.3660949e-01 -3.7923351e-02 -4.4357717e-01\n",
      " -1.3829203e+00 -1.8011741e-01 -5.0364399e-01 -1.6925247e+00\n",
      " -3.5141981e-01 -6.3284039e-01 -2.1596243e+00 -1.9917084e-01\n",
      " -7.1543181e-01 -1.5642771e+00  5.6436703e-02 -7.4570012e-01\n",
      " -1.3637466e+00 -2.5160313e-03 -6.9257188e-01 -1.4105353e+00\n",
      " -6.9022179e-03 -8.2077575e-01 -1.5296371e+00 -1.4636782e-01\n",
      " -6.0487974e-01 -1.4711919e+00 -4.9271159e-02 -6.6868132e-01\n",
      " -1.4538028e+00 -5.1734913e-02 -6.4522231e-01 -1.5522280e+00\n",
      "  6.5968782e-02 -6.8427467e-01 -1.6054389e+00 -4.1091669e-02\n",
      " -5.1455957e-01 -1.2922651e+00 -1.6133398e-01 -2.8952056e-01\n",
      " -1.9393276e+00  9.6559525e-05 -4.5764118e-01 -1.9302826e+00\n",
      "  1.5175794e-01 -4.1931468e-01 -1.4529577e+00 -1.5716989e-01\n",
      " -2.7418742e-01 -1.2286062e+00 -5.3842992e-02 -2.5643346e-01\n",
      " -1.3069291e+00 -4.8837662e-03 -2.8806657e-01 -1.4234757e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5.4249786e-02 -2.9737088e-01 -1.2914089e+00  2.0000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.425 3.425 3.429 ... 3.441 3.441 3.441]\n",
      " [3.416 3.416 3.416 ... 3.418 3.418 3.419]\n",
      " [3.415 3.415 3.412 ... 3.399 3.399 3.396]\n",
      " ...\n",
      " [3.028 3.028 3.024 ... 2.922 2.922 2.954]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]\n",
      " [3.015 3.015 3.014 ... 2.927 2.927 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0342, -0.1050, -0.2405,  ...,  0.0577, -0.2947, -1.2622],\n",
      "        [ 0.0342, -0.1050, -0.2405,  ...,  0.0577, -0.2947, -1.2622],\n",
      "        [ 0.0342, -0.1050, -0.2405,  ...,  0.0577, -0.2947, -1.2622],\n",
      "        ...,\n",
      "        [-0.1026,  0.4213, -0.1311,  ..., -0.6193,  0.9290, -0.4598],\n",
      "        [-0.1241, -0.1126,  0.6135,  ..., -0.2092,  0.6470,  0.2430],\n",
      "        [-0.1241, -0.1126,  0.6135,  ..., -0.2092,  0.6470,  0.2430]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0342036  -0.10504125 -0.2404619   0.05964918 -0.23213796 -0.6128378\n",
      " -0.04763417 -0.44040835 -1.4085243  -0.1931315  -0.5059398  -1.7054672\n",
      " -0.35421264 -0.61241627 -2.1896567  -0.16354333 -0.72758675 -1.5703604\n",
      "  0.03954951 -0.77576816 -1.3818561  -0.01655474 -0.7117801  -1.4348028\n",
      " -0.03114222 -0.8623034  -1.5570683  -0.11925372 -0.6287842  -1.4746377\n",
      " -0.05040395 -0.6854348  -1.4477929  -0.06548917 -0.65829444 -1.5363334\n",
      "  0.05959456 -0.6894864  -1.5697329  -0.03145251 -0.5279356  -1.3058387\n",
      " -0.17139868 -0.299464   -2.0143576  -0.00388039 -0.46667245 -2.0238032\n",
      "  0.1523678  -0.42916176 -1.4247906  -0.14341184 -0.29567558 -1.2335042\n",
      " -0.06725806 -0.27132958 -1.3167198  -0.02814963 -0.28249246 -1.4308361\n",
      "  0.05771741 -0.2946912  -1.2622112 ]\n",
      "data: [-4.09 -5.15  4.49 -4.01 -4.93  4.55 -4.03 -4.86  4.55 -3.59 -3.45  1.68\n",
      " -3.22 -4.39  2.39  0.    0.    0.   -3.42 -3.95  2.02 -3.57 -3.48  1.68\n",
      " -3.38 -4.1   2.17 -3.41 -3.75  2.12 -3.38 -3.89  2.02 -3.59 -3.45  1.68\n",
      " -3.59 -3.35  1.77 -3.39 -3.75  2.12 -3.38 -3.79  2.19 -3.39 -3.78  2.12\n",
      " -3.34 -4.1   2.17 -4.07 -5.    4.6  -4.01 -4.86  4.55 -3.26 -4.11  2.36\n",
      " -3.38 -4.13  2.17  0.  ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.1135,  0.1386, -0.3019,  ..., -0.0672, -0.0924, -0.7998],\n",
      "        [ 0.1135,  0.1386, -0.3019,  ..., -0.0672, -0.0924, -0.7998],\n",
      "        [ 0.1135,  0.1386, -0.3019,  ..., -0.0672, -0.0924, -0.7998],\n",
      "        ...,\n",
      "        [ 0.6224, -1.0931,  1.0334,  ...,  0.0474, -1.1104,  1.3214],\n",
      "        [ 0.0039, -0.1968,  0.3351,  ..., -0.4219, -0.6519,  2.3795],\n",
      "        [ 0.0039, -0.1968,  0.3351,  ..., -0.4219, -0.6519,  2.3795]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.1135028   0.13860197 -0.3018914  -0.0383043   0.01270307 -0.657121\n",
      " -0.14454655 -0.1252211  -0.9100406  -0.1892139  -0.27022737 -0.8628144\n",
      " -0.18323639 -0.32835796 -0.92522657 -0.14317006 -0.10651645 -1.1907085\n",
      " -0.02395029 -0.17912084 -0.5287641  -0.07348701 -0.32355568 -0.4983814\n",
      " -0.1793763  -0.29161876 -0.5860312  -0.13472009 -0.01953173 -1.212257\n",
      " -0.21418369 -0.12854114 -1.1554188  -0.2194294  -0.20533776 -1.1055541\n",
      " -0.18965736 -0.30985492 -1.0899811  -0.13139957  0.00138968 -1.1712888\n",
      " -0.19471124 -0.05988425 -0.974097   -0.22262213 -0.11195624 -0.9656918\n",
      " -0.13276473 -0.20883414 -0.9476019  -0.12287658  0.13136432 -1.0271984\n",
      " -0.10651629  0.06642249 -0.9368485  -0.10360169  0.01052997 -0.8962343\n",
      " -0.06717324 -0.09240885 -0.79979235]\n",
      "init: [ 0.1135028   0.13860197 -0.3018914  -0.0383043   0.01270307 -0.657121\n",
      " -0.14454655 -0.1252211  -0.9100406  -0.1892139  -0.27022737 -0.8628144\n",
      " -0.18323639 -0.32835796 -0.92522657 -0.14317006 -0.10651645 -1.1907085\n",
      " -0.02395029 -0.17912084 -0.5287641  -0.07348701 -0.32355568 -0.4983814\n",
      " -0.1793763  -0.29161876 -0.5860312  -0.13472009 -0.01953173 -1.212257\n",
      " -0.21418369 -0.12854114 -1.1554188  -0.2194294  -0.20533776 -1.1055541\n",
      " -0.18965736 -0.30985492 -1.0899811  -0.13139957  0.00138968 -1.1712888\n",
      " -0.19471124 -0.05988425 -0.974097   -0.22262213 -0.11195624 -0.9656918\n",
      " -0.13276473 -0.20883414 -0.9476019  -0.12287658  0.13136432 -1.0271984\n",
      " -0.10651629  0.06642249 -0.9368485  -0.10360169  0.01052997 -0.8962343\n",
      " -0.06717324 -0.09240885 -0.79979235]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [ 0.1135028   0.13860197 -0.3018914  -0.0383043   0.01270307 -0.65712094\n",
      " -0.14454655 -0.1252211  -0.9100406  -0.1892139  -0.27022737 -0.8628144\n",
      " -0.18323639 -0.32835796 -0.92522657 -0.14317006 -0.10651645 -1.1907085\n",
      " -0.02395029 -0.17912084 -0.5287641  -0.07348701 -0.32355568 -0.49838144\n",
      " -0.1793763  -0.29161876 -0.5860312  -0.13472009 -0.01953173 -1.212257\n",
      " -0.21418369 -0.12854114 -1.1554188  -0.2194294  -0.20533775 -1.1055541\n",
      " -0.18965736 -0.30985492 -1.0899811  -0.13139957  0.00138968 -1.1712888\n",
      " -0.19471125 -0.05988425 -0.974097   -0.22262213 -0.11195623 -0.9656918\n",
      " -0.13276473 -0.20883413 -0.9476019  -0.12287658  0.13136432 -1.0271984\n",
      " -0.10651629  0.06642249 -0.9368485  -0.10360169  0.01052997 -0.8962343\n",
      " -0.06717324 -0.09240885 -0.79979235  0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.1602, -0.4051,  0.1639,  ...,  0.2574, -0.5467, -0.9587],\n",
      "        [ 0.1602, -0.4051,  0.1639,  ...,  0.2574, -0.5467, -0.9587],\n",
      "        [ 0.1602, -0.4051,  0.1639,  ...,  0.2574, -0.5467, -0.9587],\n",
      "        ...,\n",
      "        [-0.1657,  0.2956, -0.8783,  ..., -0.8114,  0.5911, -0.9623],\n",
      "        [-0.3673,  0.2040, -0.2801,  ..., -0.6720,  1.0207, -0.6437],\n",
      "        [-0.3673,  0.2040, -0.2801,  ..., -0.6720,  1.0207, -0.6437]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.16017921 -0.4051434   0.16393928  0.19989458 -0.5483488  -0.2678945\n",
      "  0.1538266  -0.67075384 -0.9363775   0.01539564 -0.70503473 -1.2366107\n",
      " -0.12487699 -0.8357067  -1.7311622  -0.04807936 -0.9568534  -1.1009752\n",
      "  0.24393708 -0.93193793 -0.8956922   0.19163254 -0.85586333 -0.94736576\n",
      "  0.17359374 -0.9367373  -1.064082    0.00215216 -0.8616656  -1.0392659\n",
      "  0.13916296 -0.8920789  -1.0571449   0.14297588 -0.8241582  -1.1460712\n",
      "  0.2535962  -0.8573941  -1.2169355   0.13315192 -0.79181087 -0.87051237\n",
      "  0.07833014 -0.53297067 -1.3399767   0.21397133 -0.6714797  -1.3130996\n",
      "  0.34281176 -0.614589   -1.1168182   0.029211   -0.56486773 -0.83082485\n",
      "  0.15746891 -0.5233587  -0.91869533  0.21676601 -0.5512974  -1.047764\n",
      "  0.25736678 -0.54666686 -0.9587301 ]\n",
      "data: [ 0.16017921 -0.40514338  0.16393928  0.19989458 -0.5483488  -0.2678945\n",
      "  0.1538266  -0.67075384 -0.9363776   0.01539564 -0.70503473 -1.2366107\n",
      " -0.124877   -0.8357067  -1.7311623  -0.04807936 -0.9568534  -1.1009752\n",
      "  0.24393708 -0.93193793 -0.8956922   0.19163254 -0.85586333 -0.9473657\n",
      "  0.17359374 -0.9367373  -1.064082    0.00215216 -0.86166555 -1.0392659\n",
      "  0.13916296 -0.8920789  -1.0571449   0.14297588 -0.8241582  -1.1460712\n",
      "  0.2535962  -0.8573941  -1.2169355   0.13315192 -0.7918108  -0.87051237\n",
      "  0.07833014 -0.53297067 -1.3399767   0.21397133 -0.6714797  -1.3130996\n",
      "  0.34281176 -0.614589   -1.1168182   0.029211   -0.56486773 -0.8308249\n",
      "  0.15746891 -0.5233587  -0.9186953   0.21676601 -0.5512974  -1.047764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.25736678 -0.54666686 -0.9587301   0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[-0.0334, -0.0939, -0.1177,  ..., -0.3148, -0.3309, -1.2189],\n",
      "        [-0.0334, -0.0939, -0.1177,  ..., -0.3148, -0.3309, -1.2189],\n",
      "        [-0.0334, -0.0939, -0.1177,  ..., -0.3148, -0.3309, -1.2189],\n",
      "        ...,\n",
      "        [-0.3577,  0.1258,  0.0942,  ..., -0.4307,  0.7695, -0.4187],\n",
      "        [-0.0446,  0.1069,  0.5536,  ...,  0.4018,  0.6670,  0.2595],\n",
      "        [-0.0446,  0.1069,  0.5536,  ...,  0.4018,  0.6670,  0.2595]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.0334381  -0.09391993 -0.11766744 -0.17232025 -0.25477058 -0.54740334\n",
      " -0.33839718 -0.47608477 -1.2631865  -0.5332308  -0.55949205 -1.572409\n",
      " -0.85768014 -0.60890007 -2.046666   -0.31841648 -0.76885104 -1.443176\n",
      " -0.42913505 -0.8730893  -1.5050011  -0.44774643 -0.74057925 -1.5858111\n",
      " -0.36683384 -0.9899876  -1.623803   -0.31002054 -0.6351512  -1.3546723\n",
      " -0.36689416 -0.675948   -1.2605525  -0.44795763 -0.73495173 -1.4098656\n",
      " -0.26952147 -0.6045157  -1.4210923  -0.2961398  -0.5866374  -1.2691082\n",
      " -0.41421524 -0.44543156 -1.7740445  -0.38393357 -0.530101   -1.8063436\n",
      " -0.23448169 -0.52898633 -1.2754089  -0.33568156 -0.358482   -1.2046802\n",
      " -0.448632   -0.38101828 -1.3032202  -0.45365098 -0.32424164 -1.3995064\n",
      " -0.3147705  -0.33086842 -1.2188908 ]\n",
      "data: [-0.0334381  -0.09391993 -0.11766744 -0.17232025 -0.25477058 -0.54740334\n",
      " -0.33839718 -0.4760848  -1.2631865  -0.5332308  -0.55949205 -1.572409\n",
      " -0.85768014 -0.60890007 -2.046666   -0.31841648 -0.76885104 -1.4431759\n",
      " -0.42913505 -0.8730893  -1.5050011  -0.44774643 -0.74057925 -1.5858111\n",
      " -0.36683384 -0.9899876  -1.6238029  -0.31002054 -0.6351512  -1.3546722\n",
      " -0.36689416 -0.675948   -1.2605525  -0.44795763 -0.73495173 -1.4098656\n",
      " -0.26952147 -0.6045157  -1.4210923  -0.2961398  -0.5866374  -1.2691082\n",
      " -0.41421524 -0.44543156 -1.7740445  -0.38393357 -0.530101   -1.8063436\n",
      " -0.23448169 -0.52898633 -1.2754089  -0.33568156 -0.358482   -1.2046802\n",
      " -0.448632   -0.38101828 -1.3032203  -0.45365098 -0.32424164 -1.3995063\n",
      " -0.3147705  -0.33086842 -1.2188908   0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0699,  0.1512, -0.2614,  ...,  0.2533, -0.0417, -1.2337],\n",
      "        [ 0.0699,  0.1512, -0.2614,  ...,  0.2533, -0.0417, -1.2337],\n",
      "        [ 0.0699,  0.1512, -0.2614,  ...,  0.2533, -0.0417, -1.2337],\n",
      "        ...,\n",
      "        [-0.0379,  0.0048,  0.4350,  ..., -0.9046,  0.5665,  0.3202],\n",
      "        [-0.1648, -0.2547,  0.5143,  ..., -0.7425,  0.1045,  0.3385],\n",
      "        [-0.1648, -0.2547,  0.5143,  ..., -0.7425,  0.1045,  0.3385]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 6.99033663e-02  1.51156783e-01 -2.61448890e-01  1.19549111e-01\n",
      "  2.93130279e-02 -5.43207288e-01  2.97788009e-02 -1.23320520e-01\n",
      " -1.33725369e+00 -1.12143606e-01 -1.74609363e-01 -1.62533951e+00\n",
      " -2.59303629e-01 -3.10584307e-01 -2.12210464e+00 -1.39170125e-01\n",
      " -4.02989984e-01 -1.56105995e+00  1.49341673e-01 -4.11797643e-01\n",
      " -1.42315733e+00  1.09756425e-01 -3.57660472e-01 -1.45302606e+00\n",
      "  1.56548947e-01 -4.57286179e-01 -1.56990659e+00 -6.86003864e-02\n",
      " -3.04624677e-01 -1.47157073e+00  7.36121312e-02 -3.74638259e-01\n",
      " -1.46953475e+00  1.15439117e-01 -3.32537591e-01 -1.55637383e+00\n",
      "  2.84997582e-01 -3.95836830e-01 -1.63124931e+00  5.75557575e-02\n",
      " -2.46782362e-01 -1.26469517e+00 -3.84383425e-02  1.84829533e-02\n",
      " -1.91711617e+00  1.76382765e-01 -1.70586467e-01 -1.90179276e+00\n",
      "  3.76626849e-01 -1.33134842e-01 -1.45201302e+00 -6.14939630e-02\n",
      " -7.02887774e-04 -1.19445586e+00  8.96493942e-02  2.35058814e-02\n",
      " -1.23936772e+00  1.74811944e-01 -1.79033577e-02 -1.36716247e+00\n",
      "  2.53294051e-01 -4.17291075e-02 -1.23367190e+00]\n",
      "data: [ 6.99033663e-02  1.51156783e-01 -2.61448890e-01  1.19549111e-01\n",
      "  2.93130279e-02 -5.43207288e-01  2.97788009e-02 -1.23320520e-01\n",
      " -1.33725369e+00 -1.12143606e-01 -1.74609363e-01 -1.62533951e+00\n",
      " -2.59303629e-01 -3.10584307e-01 -2.12210464e+00 -1.39170125e-01\n",
      " -4.02989984e-01 -1.56105983e+00  1.49341673e-01 -4.11797643e-01\n",
      " -1.42315733e+00  1.09756425e-01 -3.57660472e-01 -1.45302618e+00\n",
      "  1.56548947e-01 -4.57286179e-01 -1.56990659e+00 -6.86003864e-02\n",
      " -3.04624677e-01 -1.47157073e+00  7.36121312e-02 -3.74638259e-01\n",
      " -1.46953475e+00  1.15439117e-01 -3.32537562e-01 -1.55637395e+00\n",
      "  2.84997582e-01 -3.95836830e-01 -1.63124919e+00  5.75557575e-02\n",
      " -2.46782362e-01 -1.26469517e+00 -3.84383425e-02  1.84829533e-02\n",
      " -1.91711605e+00  1.76382765e-01 -1.70586467e-01 -1.90179276e+00\n",
      "  3.76626849e-01 -1.33134842e-01 -1.45201290e+00 -6.14939630e-02\n",
      " -7.02887774e-04 -1.19445586e+00  8.96493942e-02  2.35058814e-02\n",
      " -1.23936772e+00  1.74811929e-01 -1.79033577e-02 -1.36716247e+00\n",
      "  2.53294051e-01 -4.17291075e-02 -1.23367190e+00  3.99999991e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.1432, -0.2105, -0.1863,  ...,  0.1663, -0.3578, -1.3294],\n",
      "        [ 0.1432, -0.2105, -0.1863,  ...,  0.1663, -0.3578, -1.3294],\n",
      "        [ 0.1432, -0.2105, -0.1863,  ...,  0.1663, -0.3578, -1.3294],\n",
      "        ...,\n",
      "        [-0.3827,  0.2049, -0.1858,  ..., -1.0910,  0.5998, -0.3408],\n",
      "        [-0.2558,  0.2660,  0.3116,  ..., -0.3240,  1.1376, -0.0852],\n",
      "        [-0.2558,  0.2660,  0.3116,  ..., -0.3240,  1.1376, -0.0852]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.1432059  -0.21052748 -0.18632755  0.16941363 -0.36954445 -0.70796597\n",
      "  0.13952586 -0.4963228  -1.3714465   0.02088247 -0.5427698  -1.6643\n",
      " -0.12015444 -0.66731083 -2.1403348  -0.0557498  -0.7637105  -1.5074732\n",
      "  0.2129384  -0.7399956  -1.2719747   0.1601766  -0.67541873 -1.3332368\n",
      "  0.13040993 -0.7536354  -1.4495611  -0.02629492 -0.6586012  -1.4488463\n",
      "  0.0916284  -0.6914902  -1.4551237   0.06852809 -0.64058363 -1.5415162\n",
      "  0.16484347 -0.65823144 -1.6112019   0.07757672 -0.59314096 -1.2880424\n",
      "  0.0172157  -0.35452387 -1.7699162   0.12665832 -0.4777042  -1.7455903\n",
      "  0.23267397 -0.43849966 -1.4892144  -0.00810279 -0.36607325 -1.233816\n",
      "  0.0935331  -0.3348303  -1.3075162   0.14117527 -0.35381395 -1.4255501\n",
      "  0.1662721  -0.35780275 -1.3294244 ]\n",
      "data: [ 0.1432059  -0.21052748 -0.18632755  0.16941363 -0.36954445 -0.707966\n",
      "  0.13952586 -0.4963228  -1.3714465   0.02088247 -0.5427698  -1.6643\n",
      " -0.12015444 -0.6673109  -2.1403348  -0.0557498  -0.7637105  -1.5074733\n",
      "  0.2129384  -0.7399956  -1.2719747   0.1601766  -0.6754187  -1.3332368\n",
      "  0.13040993 -0.7536354  -1.4495611  -0.02629492 -0.6586012  -1.4488463\n",
      "  0.0916284  -0.6914902  -1.4551235   0.06852809 -0.64058363 -1.5415161\n",
      "  0.16484347 -0.65823144 -1.6112019   0.07757672 -0.59314096 -1.2880424\n",
      "  0.0172157  -0.35452384 -1.7699162   0.12665832 -0.4777042  -1.7455903\n",
      "  0.23267397 -0.43849963 -1.4892144  -0.00810279 -0.36607325 -1.233816\n",
      "  0.0935331  -0.3348303  -1.3075162   0.14117527 -0.35381395 -1.4255501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.1662721  -0.35780275 -1.3294244   0.05      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0278, -0.1576, -0.1970,  ...,  0.0048, -0.3358, -1.2338],\n",
      "        [ 0.0278, -0.1576, -0.1970,  ...,  0.0048, -0.3358, -1.2338],\n",
      "        [ 0.0278, -0.1576, -0.1970,  ...,  0.0048, -0.3358, -1.2338],\n",
      "        ...,\n",
      "        [-0.0623,  0.5207, -0.0932,  ..., -0.3492,  0.9612, -0.5547],\n",
      "        [-0.1563, -0.0172,  0.5468,  ..., -0.1780,  0.7615,  0.0187],\n",
      "        [-0.1563, -0.0172,  0.5468,  ..., -0.1780,  0.7615,  0.0187]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02779173 -0.15759471 -0.1970347   0.0464009  -0.28490627 -0.59267724\n",
      " -0.05449248 -0.51010156 -1.3987176  -0.20909393 -0.5735185  -1.714052\n",
      " -0.3852718  -0.68400836 -2.2039046  -0.1930222  -0.76981056 -1.592379\n",
      "  0.01309989 -0.8305828  -1.3959595  -0.05128671 -0.7680013  -1.4445158\n",
      " -0.07859538 -0.9356681  -1.5655506  -0.14664741 -0.66544193 -1.4796745\n",
      " -0.08946232 -0.73312527 -1.4383212  -0.11418641 -0.71886706 -1.5327303\n",
      " -0.00642267 -0.75250196 -1.559629   -0.05359244 -0.55503434 -1.3105865\n",
      " -0.22077163 -0.33699724 -2.0436525  -0.05459569 -0.5216341  -2.0512648\n",
      "  0.09026657 -0.4783132  -1.3981428  -0.17483659 -0.326905   -1.2311004\n",
      " -0.10210972 -0.30614147 -1.2978581  -0.06997655 -0.32984078 -1.407114\n",
      "  0.00484529 -0.33580637 -1.233827  ]\n",
      "data: [ 0.02779173 -0.15759471 -0.1970347   0.0464009  -0.28490627 -0.59267724\n",
      " -0.05449248 -0.51010156 -1.3987176  -0.20909393 -0.5735185  -1.714052\n",
      " -0.3852718  -0.68400836 -2.2039046  -0.1930222  -0.76981056 -1.592379\n",
      "  0.01309989 -0.8305828  -1.3959595  -0.05128671 -0.7680013  -1.4445158\n",
      " -0.07859538 -0.9356681  -1.5655506  -0.14664741 -0.6654419  -1.4796746\n",
      " -0.08946232 -0.7331253  -1.4383212  -0.1141864  -0.71886706 -1.5327305\n",
      " -0.00642267 -0.75250196 -1.559629   -0.05359243 -0.55503434 -1.3105865\n",
      " -0.22077161 -0.3369972  -2.0436525  -0.05459569 -0.5216341  -2.0512648\n",
      "  0.09026657 -0.4783132  -1.3981428  -0.17483659 -0.326905   -1.2311004\n",
      " -0.10210972 -0.30614147 -1.2978581  -0.06997655 -0.32984078 -1.4071139\n",
      "  0.00484529 -0.33580634 -1.233827    0.06      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FB00>\n",
      "tensor([[-0.0082, -0.0334, -0.1715,  ...,  0.0353, -0.2252, -1.1483],\n",
      "        [-0.0082, -0.0334, -0.1715,  ...,  0.0353, -0.2252, -1.1483],\n",
      "        [-0.0082, -0.0334, -0.1715,  ...,  0.0353, -0.2252, -1.1483],\n",
      "        ...,\n",
      "        [-0.1368,  0.3876, -0.0391,  ..., -0.7826,  0.9739, -0.4153],\n",
      "        [-0.0802, -0.1087,  0.6058,  ..., -0.1693,  0.5522,  0.2898],\n",
      "        [-0.0802, -0.1087,  0.6058,  ..., -0.1693,  0.5522,  0.2898]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.00819958 -0.03343464 -0.1714707   0.01353532 -0.1426571  -0.45122483\n",
      " -0.11433256 -0.36654255 -1.2956767  -0.26699692 -0.42696962 -1.5947983\n",
      " -0.42568326 -0.5307266  -2.0961304  -0.21379419 -0.66565853 -1.4844841\n",
      " -0.01268597 -0.722515   -1.3249288  -0.06503347 -0.65499383 -1.3724076\n",
      " -0.05569609 -0.8153595  -1.5015239  -0.16429432 -0.57028395 -1.3787768\n",
      " -0.09208129 -0.6261864  -1.3560662  -0.08446524 -0.5934911  -1.4475945\n",
      "  0.06409857 -0.63318443 -1.4741794  -0.06775572 -0.458564   -1.2112051\n",
      " -0.22670807 -0.22621831 -1.9775367  -0.02544835 -0.40479004 -1.9971625\n",
      "  0.16472362 -0.36239117 -1.3288504  -0.19663133 -0.22726871 -1.1325954\n",
      " -0.1102545  -0.20329028 -1.2150395  -0.07383424 -0.21407631 -1.3314275\n",
      "  0.03526255 -0.22515719 -1.1482692 ]\n",
      "data: [-0.00819958 -0.03343464 -0.1714707   0.01353532 -0.1426571  -0.45122483\n",
      " -0.11433256 -0.36654255 -1.2956767  -0.26699692 -0.42696962 -1.5947983\n",
      " -0.42568326 -0.5307266  -2.0961304  -0.21379419 -0.6656586  -1.4844841\n",
      " -0.01268597 -0.7225149  -1.3249288  -0.06503347 -0.65499383 -1.3724076\n",
      " -0.05569609 -0.8153595  -1.5015239  -0.16429432 -0.57028395 -1.3787769\n",
      " -0.09208129 -0.6261864  -1.3560662  -0.08446524 -0.5934911  -1.4475944\n",
      "  0.06409857 -0.63318443 -1.4741794  -0.06775572 -0.45856398 -1.2112051\n",
      " -0.22670807 -0.22621831 -1.9775367  -0.02544835 -0.40479004 -1.9971625\n",
      "  0.16472362 -0.36239117 -1.3288504  -0.19663134 -0.22726871 -1.1325954\n",
      " -0.1102545  -0.20329028 -1.2150395  -0.07383424 -0.21407631 -1.3314275\n",
      "  0.03526255 -0.22515719 -1.1482692   0.07      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[-0.0226, -0.0523, -0.2686,  ..., -0.0048, -0.2205, -1.3349],\n",
      "        [-0.0226, -0.0523, -0.2686,  ..., -0.0048, -0.2205, -1.3349],\n",
      "        [-0.0226, -0.0523, -0.2686,  ..., -0.0048, -0.2205, -1.3349],\n",
      "        ...,\n",
      "        [-0.2505,  0.3023, -0.0786,  ..., -0.7184,  0.7760, -0.2955],\n",
      "        [-0.1565, -0.0883,  0.5919,  ..., -0.2880,  0.6795,  0.3154],\n",
      "        [-0.1565, -0.0883,  0.5919,  ..., -0.2880,  0.6795,  0.3154]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-2.2600356e-02 -5.2307822e-02 -2.6859143e-01  1.4869310e-03\n",
      " -1.9255911e-01 -7.0027220e-01 -8.9733101e-02 -3.6624268e-01\n",
      " -1.4296548e+00 -2.3699170e-01 -4.2377803e-01 -1.7260404e+00\n",
      " -4.0848893e-01 -5.3445041e-01 -2.2008295e+00 -2.2972642e-01\n",
      " -6.5435570e-01 -1.5852687e+00 -1.5936449e-02 -6.7993045e-01\n",
      " -1.3908867e+00 -6.4611316e-02 -6.1319870e-01 -1.4474344e+00\n",
      " -6.7567118e-02 -7.4280524e-01 -1.5632819e+00 -1.8770707e-01\n",
      " -5.5111617e-01 -1.5056241e+00 -1.0559043e-01 -6.0171652e-01\n",
      " -1.4802194e+00 -1.1590132e-01 -5.7328403e-01 -1.5765589e+00\n",
      "  1.8424764e-02 -5.9237343e-01 -1.6227341e+00 -1.0230053e-01\n",
      " -4.6706015e-01 -1.3328280e+00 -2.1128561e-01 -2.3160255e-01\n",
      " -1.9654030e+00 -5.8145046e-02 -3.8296765e-01 -1.9653114e+00\n",
      "  9.8024309e-02 -3.5053569e-01 -1.4823465e+00 -2.0199871e-01\n",
      " -2.2867984e-01 -1.2723328e+00 -1.2899975e-01 -2.0095889e-01\n",
      " -1.3564904e+00 -8.1598088e-02 -2.0979324e-01 -1.4776871e+00\n",
      " -4.7581941e-03 -2.2046980e-01 -1.3349354e+00]\n",
      "data: [-2.2600358e-02 -5.2307822e-02 -2.6859143e-01  1.4869310e-03\n",
      " -1.9255911e-01 -7.0027220e-01 -8.9733101e-02 -3.6624268e-01\n",
      " -1.4296548e+00 -2.3699170e-01 -4.2377803e-01 -1.7260404e+00\n",
      " -4.0848893e-01 -5.3445041e-01 -2.2008295e+00 -2.2972640e-01\n",
      " -6.5435570e-01 -1.5852687e+00 -1.5936449e-02 -6.7993045e-01\n",
      " -1.3908867e+00 -6.4611316e-02 -6.1319870e-01 -1.4474344e+00\n",
      " -6.7567118e-02 -7.4280524e-01 -1.5632819e+00 -1.8770707e-01\n",
      " -5.5111617e-01 -1.5056241e+00 -1.0559043e-01 -6.0171652e-01\n",
      " -1.4802194e+00 -1.1590132e-01 -5.7328403e-01 -1.5765589e+00\n",
      "  1.8424764e-02 -5.9237343e-01 -1.6227341e+00 -1.0230053e-01\n",
      " -4.6706018e-01 -1.3328280e+00 -2.1128561e-01 -2.3160255e-01\n",
      " -1.9654030e+00 -5.8145046e-02 -3.8296765e-01 -1.9653114e+00\n",
      "  9.8024309e-02 -3.5053569e-01 -1.4823465e+00 -2.0199871e-01\n",
      " -2.2867984e-01 -1.2723328e+00 -1.2899975e-01 -2.0095891e-01\n",
      " -1.3564904e+00 -8.1598088e-02 -2.0979324e-01 -1.4776871e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -4.7581941e-03 -2.2046980e-01 -1.3349354e+00  7.9999998e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[ 0.0596, -0.1176, -0.2143,  ...,  0.0643, -0.2948, -1.3023],\n",
      "        [ 0.0596, -0.1176, -0.2143,  ...,  0.0643, -0.2948, -1.3023],\n",
      "        [ 0.0596, -0.1176, -0.2143,  ...,  0.0643, -0.2948, -1.3023],\n",
      "        ...,\n",
      "        [-0.3674,  0.2082, -0.4376,  ..., -0.8666,  0.6508, -0.5823],\n",
      "        [-0.1475, -0.0656,  0.5776,  ..., -0.2274,  0.6872,  0.2935],\n",
      "        [-0.1475, -0.0656,  0.5776,  ..., -0.2274,  0.6872,  0.2935]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 5.96457459e-02 -1.17640719e-01 -2.14345634e-01  8.24525952e-02\n",
      " -2.51705855e-01 -6.15646124e-01  4.89874184e-03 -4.22789603e-01\n",
      " -1.36882377e+00 -1.41683877e-01 -4.80409384e-01 -1.67711508e+00\n",
      " -3.09059709e-01 -5.91980040e-01 -2.17833948e+00 -1.47638917e-01\n",
      " -7.15536594e-01 -1.55112123e+00  7.67873749e-02 -7.40836561e-01\n",
      " -1.36925459e+00  1.83089599e-02 -6.81398869e-01 -1.42535651e+00\n",
      "  7.67754018e-03 -8.10687423e-01 -1.54457378e+00 -1.04438789e-01\n",
      " -6.15440428e-01 -1.46383190e+00 -2.09475085e-02 -6.66535914e-01\n",
      " -1.45200503e+00 -3.92624661e-02 -6.38852179e-01 -1.55846012e+00\n",
      "  7.73941502e-02 -6.65098608e-01 -1.60580754e+00 -1.50423795e-02\n",
      " -5.28153062e-01 -1.29061294e+00 -1.24691539e-01 -3.00639808e-01\n",
      " -1.90944231e+00  1.73903704e-02 -4.49576676e-01 -1.91080570e+00\n",
      "  1.59155786e-01 -4.22375500e-01 -1.45797098e+00 -1.20187052e-01\n",
      " -2.93921530e-01 -1.23102677e+00 -3.83670405e-02 -2.74247646e-01\n",
      " -1.30974185e+00 -6.50547445e-04 -2.88246781e-01 -1.42817032e+00\n",
      "  6.42787069e-02 -2.94822156e-01 -1.30231369e+00]\n",
      "data: [ 5.9645750e-02 -1.1764071e-01 -2.1434563e-01  8.2452595e-02\n",
      " -2.5170586e-01 -6.1564612e-01  4.8987418e-03 -4.2278960e-01\n",
      " -1.3688236e+00 -1.4168388e-01 -4.8040938e-01 -1.6771150e+00\n",
      " -3.0905971e-01 -5.9198004e-01 -2.1783395e+00 -1.4763892e-01\n",
      " -7.1553659e-01 -1.5511212e+00  7.6787375e-02 -7.4083656e-01\n",
      " -1.3692546e+00  1.8308960e-02 -6.8139887e-01 -1.4253564e+00\n",
      "  7.6775402e-03 -8.1068742e-01 -1.5445738e+00 -1.0443879e-01\n",
      " -6.1544043e-01 -1.4638319e+00 -2.0947509e-02 -6.6653597e-01\n",
      " -1.4520050e+00 -3.9262466e-02 -6.3885218e-01 -1.5584601e+00\n",
      "  7.7394150e-02 -6.6509855e-01 -1.6058075e+00 -1.5042379e-02\n",
      " -5.2815306e-01 -1.2906129e+00 -1.2469153e-01 -3.0063981e-01\n",
      " -1.9094423e+00  1.7390370e-02 -4.4957668e-01 -1.9108057e+00\n",
      "  1.5915579e-01 -4.2237550e-01 -1.4579711e+00 -1.2018705e-01\n",
      " -2.9392153e-01 -1.2310268e+00 -3.8367040e-02 -2.7424765e-01\n",
      " -1.3097419e+00 -6.5054744e-04 -2.8824678e-01 -1.4281703e+00\n",
      "  6.4278707e-02 -2.9482216e-01 -1.3023137e+00  9.0000004e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0303, -0.1228, -0.1985,  ...,  0.0862, -0.3237, -1.2027],\n",
      "        [ 0.0303, -0.1228, -0.1985,  ...,  0.0862, -0.3237, -1.2027],\n",
      "        [ 0.0303, -0.1228, -0.1985,  ...,  0.0862, -0.3237, -1.2027],\n",
      "        ...,\n",
      "        [-0.1382,  0.4364, -0.0655,  ..., -0.6589,  0.9591, -0.4086],\n",
      "        [-0.1886, -0.0659,  0.5941,  ..., -0.2734,  0.6847,  0.2042],\n",
      "        [-0.1886, -0.0659,  0.5941,  ..., -0.2734,  0.6847,  0.2042]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03030055 -0.12284511 -0.19853176  0.05869651 -0.24294102 -0.539866\n",
      " -0.05225748 -0.46127164 -1.3530447  -0.19959484 -0.52779156 -1.6508893\n",
      " -0.35673815 -0.6398021  -2.1352882  -0.16517214 -0.747419   -1.5285672\n",
      "  0.04743916 -0.8046612  -1.3522646  -0.00888327 -0.7386512  -1.399524\n",
      " -0.01712462 -0.89423615 -1.5211601  -0.11311483 -0.65152377 -1.4259443\n",
      " -0.03945835 -0.7136482  -1.4005822  -0.04477409 -0.68572116 -1.4855134\n",
      "  0.08309081 -0.72391427 -1.5176634  -0.01663242 -0.54979694 -1.2549803\n",
      " -0.16284151 -0.31718925 -1.9846568   0.01908871 -0.4967401  -1.9926947\n",
      "  0.18481411 -0.45388383 -1.3732296  -0.13817324 -0.31756097 -1.1799595\n",
      " -0.0487459  -0.29313937 -1.2643037  -0.00372848 -0.31255922 -1.37522\n",
      "  0.08623118 -0.32369906 -1.2026589 ]\n",
      "data: [ 0.03030055 -0.12284511 -0.19853176  0.05869651 -0.24294102 -0.539866\n",
      " -0.05225748 -0.46127164 -1.3530447  -0.19959484 -0.52779156 -1.6508893\n",
      " -0.35673818 -0.6398021  -2.1352882  -0.16517214 -0.747419   -1.5285672\n",
      "  0.04743915 -0.80466115 -1.3522648  -0.00888327 -0.7386512  -1.399524\n",
      " -0.01712462 -0.89423615 -1.5211601  -0.11311483 -0.65152377 -1.4259443\n",
      " -0.03945835 -0.7136482  -1.4005821  -0.04477409 -0.68572116 -1.4855134\n",
      "  0.08309081 -0.72391427 -1.5176635  -0.01663242 -0.54979694 -1.2549803\n",
      " -0.16284151 -0.31718925 -1.9846568   0.01908871 -0.4967401  -1.9926947\n",
      "  0.18481411 -0.45388383 -1.3732296  -0.13817324 -0.31756097 -1.1799595\n",
      " -0.0487459  -0.29313937 -1.2643037  -0.00372848 -0.31255922 -1.3752198\n",
      "  0.08623119 -0.3236991  -1.2026589   0.1       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0096, -0.0901, -0.1872,  ...,  0.0464, -0.2933, -1.1650],\n",
      "        [ 0.0096, -0.0901, -0.1872,  ...,  0.0464, -0.2933, -1.1650],\n",
      "        [ 0.0096, -0.0901, -0.1872,  ...,  0.0464, -0.2933, -1.1650],\n",
      "        ...,\n",
      "        [-0.1430,  0.3701, -0.0841,  ..., -0.6822,  0.8937, -0.4106],\n",
      "        [-0.0861, -0.0529,  0.6024,  ..., -0.1710,  0.6869,  0.2310],\n",
      "        [-0.0861, -0.0529,  0.6024,  ..., -0.1710,  0.6869,  0.2310]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00963612 -0.09008961 -0.18717673  0.04569377 -0.18766327 -0.47119838\n",
      " -0.10660978 -0.42386115 -1.3433268  -0.26219937 -0.49402434 -1.6301234\n",
      " -0.40931845 -0.58136237 -2.1478498  -0.17567629 -0.7329436  -1.5185766\n",
      " -0.01330282 -0.80719537 -1.3652346  -0.06731093 -0.7305334  -1.4172721\n",
      " -0.08255896 -0.908142   -1.5433712  -0.13102916 -0.65197235 -1.4138153\n",
      " -0.08193601 -0.7065499  -1.3832529  -0.0980024  -0.6720361  -1.4631948\n",
      "  0.04104792 -0.7061639  -1.4735956  -0.05114567 -0.538066   -1.2514443\n",
      " -0.21659298 -0.29929495 -2.047228   -0.02454271 -0.47902638 -2.0769827\n",
      "  0.15065625 -0.43936336 -1.3379292  -0.17221004 -0.31344825 -1.1691978\n",
      " -0.10732059 -0.28274596 -1.2588141  -0.07434496 -0.28077638 -1.3706312\n",
      "  0.04639412 -0.29334444 -1.1649671 ]\n",
      "data: [ 0.00963612 -0.0900896  -0.18717675  0.04569377 -0.18766327 -0.47119838\n",
      " -0.10660978 -0.42386115 -1.3433269  -0.26219937 -0.49402437 -1.6301235\n",
      " -0.40931848 -0.58136237 -2.1478498  -0.17567629 -0.7329436  -1.5185766\n",
      " -0.01330282 -0.80719537 -1.3652347  -0.06731093 -0.7305334  -1.4172721\n",
      " -0.08255896 -0.9081419  -1.5433713  -0.13102916 -0.65197235 -1.4138153\n",
      " -0.08193601 -0.7065499  -1.3832529  -0.0980024  -0.6720361  -1.4631948\n",
      "  0.04104792 -0.7061639  -1.4735956  -0.05114566 -0.538066   -1.2514443\n",
      " -0.21659298 -0.29929495 -2.047228   -0.02454271 -0.47902638 -2.0769827\n",
      "  0.15065625 -0.43936336 -1.3379292  -0.17221004 -0.31344825 -1.1691978\n",
      " -0.10732059 -0.28274596 -1.2588141  -0.07434496 -0.28077638 -1.3706312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.04639412 -0.29334444 -1.1649671   0.11      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0251,  0.0077, -0.2003,  ...,  0.0163, -0.1805, -1.1829],\n",
      "        [-0.0251,  0.0077, -0.2003,  ...,  0.0163, -0.1805, -1.1829],\n",
      "        [-0.0251,  0.0077, -0.2003,  ...,  0.0163, -0.1805, -1.1829],\n",
      "        ...,\n",
      "        [-0.1698,  0.3071,  0.0230,  ..., -0.7215,  0.8649, -0.3488],\n",
      "        [-0.1090, -0.1313,  0.5701,  ..., -0.2348,  0.5769,  0.2266],\n",
      "        [-0.1090, -0.1313,  0.5701,  ..., -0.2348,  0.5769,  0.2266]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.02506301  0.00767981 -0.20029971 -0.00299393 -0.10513404 -0.5064422\n",
      " -0.14155167 -0.32573846 -1.3429211  -0.29832292 -0.38956454 -1.6374122\n",
      " -0.4633646  -0.48742545 -2.136681   -0.22734502 -0.6292278  -1.511663\n",
      " -0.03892125 -0.68462205 -1.3337073  -0.08613478 -0.6100898  -1.3859998\n",
      " -0.08369921 -0.7711586  -1.5146451  -0.18182799 -0.53464335 -1.4112207\n",
      " -0.11357761 -0.587212   -1.3815132  -0.11188478 -0.5515962  -1.471473\n",
      "  0.04684195 -0.5816051  -1.4974954  -0.09196217 -0.42755795 -1.2429688\n",
      " -0.24232952 -0.1892187  -1.9948983  -0.04813685 -0.3603575  -2.0153096\n",
      "  0.14626318 -0.3201536  -1.3545833  -0.21330693 -0.19315888 -1.1645849\n",
      " -0.13956638 -0.16429117 -1.2522075  -0.10018086 -0.16713041 -1.3705217\n",
      "  0.01629459 -0.18048699 -1.1828576 ]\n",
      "data: [-0.02506301  0.00767981 -0.2002997  -0.00299393 -0.10513404 -0.5064422\n",
      " -0.14155167 -0.32573846 -1.3429211  -0.29832292 -0.38956454 -1.6374123\n",
      " -0.4633646  -0.48742545 -2.136681   -0.22734503 -0.6292278  -1.511663\n",
      " -0.03892125 -0.68462205 -1.3337073  -0.08613478 -0.6100898  -1.3859998\n",
      " -0.0836992  -0.7711586  -1.5146451  -0.18182798 -0.53464335 -1.4112207\n",
      " -0.11357761 -0.587212   -1.3815132  -0.11188479 -0.5515962  -1.471473\n",
      "  0.04684195 -0.5816051  -1.4974954  -0.09196217 -0.42755795 -1.2429688\n",
      " -0.24232952 -0.1892187  -1.9948983  -0.04813685 -0.36035746 -2.0153096\n",
      "  0.14626318 -0.3201536  -1.3545833  -0.21330695 -0.19315888 -1.1645849\n",
      " -0.13956638 -0.16429117 -1.2522075  -0.10018086 -0.16713041 -1.3705217\n",
      "  0.01629459 -0.18048698 -1.1828576   0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0135, -0.0862, -0.2031,  ...,  0.0043, -0.2437, -1.3270],\n",
      "        [-0.0135, -0.0862, -0.2031,  ...,  0.0043, -0.2437, -1.3270],\n",
      "        [-0.0135, -0.0862, -0.2031,  ...,  0.0043, -0.2437, -1.3270],\n",
      "        ...,\n",
      "        [-0.2669,  0.3239, -0.1873,  ..., -0.7800,  0.7758, -0.3572],\n",
      "        [-0.1776, -0.0958,  0.5226,  ..., -0.2633,  0.6621,  0.2441],\n",
      "        [-0.1776, -0.0958,  0.5226,  ..., -0.2633,  0.6621,  0.2441]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-1.3468411e-02 -8.6243801e-02 -2.0310763e-01 -4.2848662e-04\n",
      " -2.5184369e-01 -6.8247825e-01 -4.0245004e-02 -3.9169395e-01\n",
      " -1.3502425e+00 -1.7991562e-01 -4.4308913e-01 -1.6606810e+00\n",
      " -3.6528736e-01 -5.7971394e-01 -2.1199713e+00 -2.3970166e-01\n",
      " -6.6138756e-01 -1.5110071e+00  3.8483813e-02 -6.5453577e-01\n",
      " -1.2797641e+00 -1.0931879e-02 -6.0126138e-01 -1.3325801e+00\n",
      " -1.1248082e-02 -6.9266069e-01 -1.4477191e+00 -1.9542858e-01\n",
      " -5.4269671e-01 -1.4386098e+00 -7.7489488e-02 -5.9619772e-01\n",
      " -1.4298600e+00 -7.7368036e-02 -5.6549776e-01 -1.5406710e+00\n",
      "  4.8474640e-02 -5.8662772e-01 -1.6183753e+00 -8.9746125e-02\n",
      " -4.7535866e-01 -1.2596284e+00 -1.6332206e-01 -2.4888664e-01\n",
      " -1.7709616e+00 -3.2793388e-02 -3.8447624e-01 -1.7466403e+00\n",
      "  1.1125071e-01 -3.5403863e-01 -1.4711313e+00 -1.8834177e-01\n",
      " -2.2843115e-01 -1.2124146e+00 -8.8113666e-02 -2.0988655e-01\n",
      " -1.2893416e+00 -3.2016829e-02 -2.3892835e-01 -1.4130062e+00\n",
      "  4.3363944e-03 -2.4371727e-01 -1.3270196e+00]\n",
      "data: [-1.3468411e-02 -8.6243801e-02 -2.0310763e-01 -4.2848662e-04\n",
      " -2.5184369e-01 -6.8247825e-01 -4.0245004e-02 -3.9169395e-01\n",
      " -1.3502425e+00 -1.7991562e-01 -4.4308913e-01 -1.6606810e+00\n",
      " -3.6528736e-01 -5.7971394e-01 -2.1199713e+00 -2.3970166e-01\n",
      " -6.6138756e-01 -1.5110071e+00  3.8483813e-02 -6.5453577e-01\n",
      " -1.2797641e+00 -1.0931879e-02 -6.0126138e-01 -1.3325801e+00\n",
      " -1.1248082e-02 -6.9266069e-01 -1.4477191e+00 -1.9542858e-01\n",
      " -5.4269671e-01 -1.4386097e+00 -7.7489488e-02 -5.9619772e-01\n",
      " -1.4298599e+00 -7.7368036e-02 -5.6549776e-01 -1.5406709e+00\n",
      "  4.8474640e-02 -5.8662772e-01 -1.6183753e+00 -8.9746125e-02\n",
      " -4.7535866e-01 -1.2596284e+00 -1.6332206e-01 -2.4888664e-01\n",
      " -1.7709616e+00 -3.2793388e-02 -3.8447624e-01 -1.7466403e+00\n",
      "  1.1125071e-01 -3.5403863e-01 -1.4711313e+00 -1.8834177e-01\n",
      " -2.2843115e-01 -1.2124146e+00 -8.8113673e-02 -2.0988655e-01\n",
      " -1.2893416e+00 -3.2016829e-02 -2.3892836e-01 -1.4130062e+00\n",
      "  4.3363944e-03 -2.4371727e-01 -1.3270195e+00  1.3000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[ 4.8055e-02, -1.5091e-01, -2.8487e-01,  ...,  4.6260e-02,\n",
      "         -3.2083e-01, -1.3532e+00],\n",
      "        [ 4.8055e-02, -1.5091e-01, -2.8487e-01,  ...,  4.6260e-02,\n",
      "         -3.2083e-01, -1.3532e+00],\n",
      "        [ 4.8055e-02, -1.5091e-01, -2.8487e-01,  ...,  4.6260e-02,\n",
      "         -3.2083e-01, -1.3532e+00],\n",
      "        ...,\n",
      "        [-7.2021e-02,  5.8000e-01, -1.0430e-03,  ..., -6.7258e-01,\n",
      "          1.1112e+00, -3.0882e-01],\n",
      "        [-1.4100e-01, -2.8695e-02,  6.7268e-01,  ..., -2.5122e-01,\n",
      "          7.5562e-01,  3.3042e-01],\n",
      "        [-1.4100e-01, -2.8695e-02,  6.7268e-01,  ..., -2.5122e-01,\n",
      "          7.5562e-01,  3.3042e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04805486 -0.15091251 -0.28487065  0.07932787 -0.27578476 -0.6898874\n",
      " -0.02692776 -0.47194755 -1.4729586  -0.170616   -0.53402066 -1.7652043\n",
      " -0.31711966 -0.62788653 -2.26736    -0.14637534 -0.7639618  -1.639223\n",
      "  0.03992005 -0.80343306 -1.4732802  -0.01054409 -0.73642576 -1.5308204\n",
      " -0.02659941 -0.8807397  -1.6520678  -0.11039403 -0.6692821  -1.5519323\n",
      " -0.04426868 -0.7174239  -1.5282845  -0.06542212 -0.6841042  -1.6170274\n",
      "  0.05905686 -0.7109908  -1.6522796  -0.03232472 -0.567825   -1.3891727\n",
      " -0.1608751  -0.33578435 -2.061142   -0.00513659 -0.4904355  -2.0757077\n",
      "  0.14247015 -0.45508894 -1.5167933  -0.1377099  -0.33846816 -1.3166729\n",
      " -0.07171547 -0.30571795 -1.3956816  -0.03562343 -0.30908024 -1.512522\n",
      "  0.04625954 -0.32083225 -1.3531711 ]\n",
      "data: [ 0.04805486 -0.15091251 -0.28487065  0.07932787 -0.27578476 -0.6898874\n",
      " -0.02692776 -0.47194755 -1.4729586  -0.170616   -0.53402066 -1.7652043\n",
      " -0.31711966 -0.62788653 -2.26736    -0.14637534 -0.7639618  -1.639223\n",
      "  0.03992005 -0.80343306 -1.4732802  -0.01054409 -0.73642576 -1.5308204\n",
      " -0.02659941 -0.8807397  -1.6520677  -0.11039403 -0.6692821  -1.5519323\n",
      " -0.04426868 -0.7174239  -1.5282845  -0.06542212 -0.6841042  -1.6170274\n",
      "  0.05905686 -0.7109907  -1.6522796  -0.03232472 -0.567825   -1.3891727\n",
      " -0.1608751  -0.33578435 -2.061142   -0.00513659 -0.4904355  -2.0757077\n",
      "  0.14247015 -0.45508897 -1.5167933  -0.1377099  -0.33846816 -1.3166729\n",
      " -0.07171547 -0.30571795 -1.3956816  -0.03562343 -0.30908024 -1.512522\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.04625954 -0.32083225 -1.3531711   0.14      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0087, -0.1074, -0.1901,  ...,  0.0840, -0.3039, -1.2325],\n",
      "        [ 0.0087, -0.1074, -0.1901,  ...,  0.0840, -0.3039, -1.2325],\n",
      "        [ 0.0087, -0.1074, -0.1901,  ...,  0.0840, -0.3039, -1.2325],\n",
      "        ...,\n",
      "        [-0.1142,  0.4405, -0.0984,  ..., -0.7780,  0.9554, -0.3937],\n",
      "        [-0.1143, -0.0833,  0.5506,  ..., -0.1935,  0.5963,  0.2004],\n",
      "        [-0.1143, -0.0833,  0.5506,  ..., -0.1935,  0.5963,  0.2004]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00865267 -0.10735635 -0.19006687  0.02649902 -0.25265473 -0.5630299\n",
      " -0.02545842 -0.43534392 -1.3157665  -0.16937472 -0.49155992 -1.6410501\n",
      " -0.3535143  -0.63827217 -2.1025443  -0.20841713 -0.7026583  -1.5183188\n",
      "  0.08191426 -0.73091686 -1.32217     0.0170621  -0.6838362  -1.3633372\n",
      "  0.02723789 -0.8087214  -1.4827918  -0.14349209 -0.5871717  -1.4144418\n",
      " -0.03126264 -0.65886676 -1.4040053  -0.02103614 -0.64217603 -1.5122614\n",
      "  0.09525347 -0.6887965  -1.5738946  -0.02280102 -0.5020576  -1.2226593\n",
      " -0.14572354 -0.278133   -1.8847485   0.02688552 -0.45792648 -1.8665873\n",
      "  0.18634851 -0.41920277 -1.4028906  -0.14851972 -0.25760484 -1.1619514\n",
      " -0.02222894 -0.24961415 -1.2368594   0.03292446 -0.29707006 -1.3526368\n",
      "  0.08403292 -0.3039196  -1.2324789 ]\n",
      "data: [ 0.00865267 -0.10735635 -0.19006687  0.02649902 -0.25265473 -0.5630299\n",
      " -0.02545842 -0.43534392 -1.3157665  -0.16937472 -0.4915599  -1.6410501\n",
      " -0.3535143  -0.63827217 -2.1025443  -0.20841713 -0.7026583  -1.5183188\n",
      "  0.08191426 -0.7309168  -1.3221699   0.0170621  -0.6838362  -1.363337\n",
      "  0.02723789 -0.80872136 -1.4827918  -0.14349209 -0.5871717  -1.4144418\n",
      " -0.03126264 -0.6588667  -1.4040053  -0.02103614 -0.64217603 -1.5122614\n",
      "  0.09525347 -0.6887965  -1.5738946  -0.02280102 -0.5020576  -1.2226593\n",
      " -0.14572354 -0.278133   -1.8847486   0.02688552 -0.45792648 -1.8665872\n",
      "  0.18634851 -0.41920277 -1.4028907  -0.14851972 -0.25760484 -1.1619514\n",
      " -0.02222894 -0.24961415 -1.2368594   0.03292446 -0.29707006 -1.3526368\n",
      "  0.08403292 -0.3039196  -1.2324789   0.15      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63EB8>\n",
      "tensor([[ 0.0114, -0.0999, -0.1867,  ...,  0.0416, -0.3001, -1.1721],\n",
      "        [ 0.0114, -0.0999, -0.1867,  ...,  0.0416, -0.3001, -1.1721],\n",
      "        [ 0.0114, -0.0999, -0.1867,  ...,  0.0416, -0.3001, -1.1721],\n",
      "        ...,\n",
      "        [-0.1307,  0.4531, -0.1307,  ..., -0.4649,  0.9923, -0.5054],\n",
      "        [-0.1384, -0.0584,  0.5994,  ..., -0.2428,  0.6902,  0.2195],\n",
      "        [-0.1384, -0.0584,  0.5994,  ..., -0.2428,  0.6902,  0.2195]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01141683 -0.09993247 -0.18670729  0.04650087 -0.19860561 -0.48099715\n",
      " -0.10717803 -0.43402037 -1.3472028  -0.26081643 -0.5044422  -1.6310844\n",
      " -0.4042293  -0.5879251  -2.1482275  -0.17213456 -0.7446693  -1.5179377\n",
      " -0.01599708 -0.8166703  -1.364825   -0.06711902 -0.7385831  -1.4175105\n",
      " -0.08248418 -0.9162408  -1.5434246  -0.13040435 -0.6624323  -1.4166133\n",
      " -0.08303383 -0.7140721  -1.3848524  -0.10021477 -0.67837083 -1.4618139\n",
      "  0.04109006 -0.71146786 -1.4744923  -0.05289594 -0.5485877  -1.2580938\n",
      " -0.21731484 -0.30739698 -2.0478108  -0.02801073 -0.48496374 -2.0784173\n",
      "  0.14616245 -0.44438663 -1.3431973  -0.17264456 -0.32280856 -1.1748242\n",
      " -0.11159906 -0.28902262 -1.2649305  -0.07933672 -0.2844589  -1.3781321\n",
      "  0.04160044 -0.300072   -1.1721332 ]\n",
      "data: [ 0.01141683 -0.09993247 -0.18670729  0.04650087 -0.19860561 -0.48099717\n",
      " -0.10717803 -0.4340204  -1.3472028  -0.26081643 -0.5044422  -1.6310844\n",
      " -0.4042293  -0.5879251  -2.1482275  -0.17213458 -0.7446693  -1.5179377\n",
      " -0.01599708 -0.8166703  -1.364825   -0.06711902 -0.7385831  -1.4175105\n",
      " -0.08248418 -0.9162409  -1.5434247  -0.13040435 -0.6624323  -1.4166133\n",
      " -0.08303383 -0.7140721  -1.3848524  -0.10021476 -0.67837083 -1.4618139\n",
      "  0.04109006 -0.7114679  -1.4744923  -0.05289594 -0.5485877  -1.2580938\n",
      " -0.21731484 -0.30739698 -2.0478108  -0.02801073 -0.48496377 -2.0784173\n",
      "  0.14616245 -0.44438663 -1.3431973  -0.17264456 -0.32280856 -1.1748242\n",
      " -0.11159906 -0.28902262 -1.2649305  -0.07933672 -0.2844589  -1.3781322\n",
      "  0.04160044 -0.300072   -1.1721332   0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FDD8>\n",
      "tensor([[-0.0247,  0.0115, -0.1925,  ...,  0.0195, -0.1763, -1.1737],\n",
      "        [-0.0247,  0.0115, -0.1925,  ...,  0.0195, -0.1763, -1.1737],\n",
      "        [-0.0247,  0.0115, -0.1925,  ...,  0.0195, -0.1763, -1.1737],\n",
      "        ...,\n",
      "        [-0.1777,  0.3095,  0.0042,  ..., -0.7333,  0.8745, -0.3764],\n",
      "        [-0.1078, -0.1395,  0.5792,  ..., -0.2367,  0.5620,  0.2348],\n",
      "        [-0.1078, -0.1395,  0.5792,  ..., -0.2367,  0.5620,  0.2348]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.02468424  0.01146082 -0.1925053  -0.00212982 -0.10373852 -0.49652576\n",
      " -0.13639319 -0.32432267 -1.3339226  -0.29270023 -0.38778785 -1.6302752\n",
      " -0.45918489 -0.48945794 -2.1277828  -0.22908966 -0.6237427  -1.5059549\n",
      " -0.03084973 -0.6775615  -1.3226165  -0.07908294 -0.60567975 -1.3729503\n",
      " -0.07648388 -0.7636235  -1.5019853  -0.18209907 -0.52668524 -1.4042203\n",
      " -0.10979872 -0.5812137  -1.3751223  -0.10542218 -0.54592717 -1.4654043\n",
      "  0.0516434  -0.5786946  -1.494257   -0.08887643 -0.41991702 -1.233668\n",
      " -0.24025573 -0.1818071  -1.9855635  -0.04380989 -0.35548747 -2.0031605\n",
      "  0.15005653 -0.31376496 -1.3479531  -0.21253    -0.18421969 -1.1557239\n",
      " -0.1336402  -0.15642917 -1.2402334  -0.09267758 -0.16315015 -1.3584547\n",
      "  0.01954701 -0.1763254  -1.1737242 ]\n",
      "data: [-0.02468424  0.01146082 -0.1925053  -0.00212982 -0.10373852 -0.49652576\n",
      " -0.13639319 -0.32432267 -1.3339226  -0.29270023 -0.38778785 -1.6302752\n",
      " -0.45918489 -0.48945794 -2.1277828  -0.22908966 -0.6237427  -1.5059549\n",
      " -0.03084972 -0.6775615  -1.3226165  -0.07908294 -0.60567975 -1.3729503\n",
      " -0.07648388 -0.7636235  -1.5019853  -0.18209907 -0.52668524 -1.4042202\n",
      " -0.10979871 -0.5812137  -1.3751224  -0.10542217 -0.54592717 -1.4654042\n",
      "  0.0516434  -0.5786946  -1.4942569  -0.08887644 -0.41991702 -1.233668\n",
      " -0.24025574 -0.1818071  -1.9855635  -0.04380989 -0.35548747 -2.0031605\n",
      "  0.15005653 -0.31376496 -1.3479531  -0.21253    -0.18421969 -1.1557239\n",
      " -0.1336402  -0.15642917 -1.2402334  -0.09267757 -0.16315013 -1.3584547\n",
      "  0.01954701 -0.1763254  -1.1737242   0.17      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0043, -0.1056, -0.2007,  ...,  0.0256, -0.2619, -1.3209],\n",
      "        [-0.0043, -0.1056, -0.2007,  ...,  0.0256, -0.2619, -1.3209],\n",
      "        [-0.0043, -0.1056, -0.2007,  ...,  0.0256, -0.2619, -1.3209],\n",
      "        ...,\n",
      "        [-0.2704,  0.3295, -0.2187,  ..., -0.7519,  0.7566, -0.3918],\n",
      "        [-0.1855, -0.1040,  0.5011,  ..., -0.2684,  0.6442,  0.2162],\n",
      "        [-0.1855, -0.1040,  0.5011,  ..., -0.2684,  0.6442,  0.2162]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.00427515 -0.10563953 -0.200748    0.0085842  -0.27272475 -0.6754503\n",
      " -0.02927957 -0.41506582 -1.3411218  -0.16988008 -0.46486863 -1.6539208\n",
      " -0.3554112  -0.6072756  -2.111018   -0.23319218 -0.6826782  -1.4992207\n",
      "  0.0593389  -0.6743258  -1.2498568   0.00601623 -0.6198305  -1.3013797\n",
      " -0.00224013 -0.7096442  -1.41925    -0.18638355 -0.5640447  -1.4263815\n",
      " -0.06296831 -0.6175035  -1.421144   -0.06149351 -0.5815568  -1.5296355\n",
      "  0.05996765 -0.6066197  -1.6055317  -0.07129753 -0.4929802  -1.2486863\n",
      " -0.14768827 -0.26447856 -1.765989   -0.01298191 -0.40411606 -1.7387694\n",
      "  0.1300439  -0.36785814 -1.4648434  -0.1736828  -0.2474949  -1.2024821\n",
      " -0.0651193  -0.22804274 -1.2836045  -0.00953631 -0.2603566  -1.4079671\n",
      "  0.02555553 -0.2619446  -1.3209368 ]\n",
      "data: [-0.00427515 -0.10563953 -0.20074801  0.0085842  -0.27272475 -0.67545027\n",
      " -0.02927957 -0.41506585 -1.3411218  -0.16988009 -0.46486863 -1.6539208\n",
      " -0.35541117 -0.6072756  -2.111018   -0.23319218 -0.6826782  -1.4992207\n",
      "  0.0593389  -0.67432576 -1.2498568   0.00601623 -0.6198305  -1.3013797\n",
      " -0.00224013 -0.70964414 -1.41925    -0.18638355 -0.5640447  -1.4263816\n",
      " -0.06296831 -0.6175035  -1.421144   -0.0614935  -0.5815568  -1.5296357\n",
      "  0.05996765 -0.6066197  -1.6055316  -0.07129753 -0.49298018 -1.2486863\n",
      " -0.14768827 -0.26447856 -1.765989   -0.01298191 -0.40411606 -1.7387694\n",
      "  0.1300439  -0.3678581  -1.4648434  -0.17368278 -0.2474949  -1.2024821\n",
      " -0.0651193  -0.22804274 -1.2836044  -0.00953631 -0.2603566  -1.4079671\n",
      "  0.02555553 -0.2619446  -1.3209367   0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F9E8>\n",
      "tensor([[ 0.0326, -0.1335, -0.2903,  ...,  0.0494, -0.3053, -1.3505],\n",
      "        [ 0.0326, -0.1335, -0.2903,  ...,  0.0494, -0.3053, -1.3505],\n",
      "        [ 0.0326, -0.1335, -0.2903,  ...,  0.0494, -0.3053, -1.3505],\n",
      "        ...,\n",
      "        [-0.1099,  0.5298, -0.0924,  ..., -0.6706,  1.0577, -0.4248],\n",
      "        [-0.1639, -0.0416,  0.6425,  ..., -0.2696,  0.7291,  0.2749],\n",
      "        [-0.1639, -0.0416,  0.6425,  ..., -0.2696,  0.7291,  0.2749]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03262119 -0.13346234 -0.2902773   0.06460452 -0.2590211  -0.68614\n",
      " -0.03514447 -0.46212494 -1.4838027  -0.17938146 -0.5238657  -1.784474\n",
      " -0.32906452 -0.6298678  -2.2819731  -0.16937038 -0.7437218  -1.6591263\n",
      "  0.04759867 -0.7856762  -1.4713885  -0.00784097 -0.7238554  -1.5232136\n",
      " -0.02654514 -0.86726516 -1.6496315  -0.12616608 -0.64534235 -1.5622057\n",
      " -0.05131063 -0.70120984 -1.5426208  -0.06300519 -0.66837656 -1.6315877\n",
      "  0.05946875 -0.7068192  -1.6711092  -0.03567176 -0.54230285 -1.3913068\n",
      " -0.17422667 -0.30695254 -2.085402   -0.00465276 -0.47550794 -2.0944152\n",
      "  0.14902043 -0.43518645 -1.5242803  -0.15265068 -0.3094076  -1.3145016\n",
      " -0.06858455 -0.27878976 -1.3914398  -0.02777866 -0.29450187 -1.5074515\n",
      "  0.04936224 -0.305301   -1.3504504 ]\n",
      "data: [ 0.03262119 -0.13346234 -0.2902773   0.06460452 -0.2590211  -0.68614\n",
      " -0.03514447 -0.46212494 -1.4838027  -0.17938146 -0.5238657  -1.784474\n",
      " -0.32906452 -0.6298678  -2.2819731  -0.16937038 -0.7437218  -1.6591263\n",
      "  0.04759867 -0.7856762  -1.4713883  -0.00784097 -0.7238554  -1.5232136\n",
      " -0.02654514 -0.86726516 -1.6496315  -0.12616608 -0.64534235 -1.5622057\n",
      " -0.05131063 -0.70120984 -1.5426209  -0.06300519 -0.66837656 -1.6315876\n",
      "  0.05946876 -0.7068192  -1.6711092  -0.03567176 -0.54230285 -1.3913068\n",
      " -0.17422667 -0.30695254 -2.085402   -0.00465276 -0.47550792 -2.0944152\n",
      "  0.14902043 -0.43518648 -1.5242802  -0.15265068 -0.3094076  -1.3145016\n",
      " -0.06858455 -0.27878976 -1.3914398  -0.02777866 -0.29450187 -1.5074515\n",
      "  0.04936224 -0.305301   -1.3504504   0.19      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0070, -0.0969, -0.2178,  ...,  0.0426, -0.2761, -1.3033],\n",
      "        [ 0.0070, -0.0969, -0.2178,  ...,  0.0426, -0.2761, -1.3033],\n",
      "        [ 0.0070, -0.0969, -0.2178,  ...,  0.0426, -0.2761, -1.3033],\n",
      "        ...,\n",
      "        [-0.1417,  0.4637, -0.1617,  ..., -0.8217,  0.9503, -0.3850],\n",
      "        [-0.1136, -0.0762,  0.5604,  ..., -0.1843,  0.6370,  0.2317],\n",
      "        [-0.1136, -0.0762,  0.5604,  ..., -0.1843,  0.6370,  0.2317]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 7.0356922e-03 -9.6850961e-02 -2.1775162e-01  1.6732913e-02\n",
      " -2.5604385e-01 -6.6719341e-01 -1.0255657e-02 -4.1734356e-01\n",
      " -1.3684937e+00 -1.4995214e-01 -4.6944270e-01 -1.6994272e+00\n",
      " -3.4173989e-01 -6.1784828e-01 -2.1504321e+00 -2.1762656e-01\n",
      " -6.7805791e-01 -1.5557268e+00  8.1927404e-02 -6.8830776e-01\n",
      " -1.3402852e+00  1.7713621e-02 -6.4463603e-01 -1.3869878e+00\n",
      "  2.2388577e-02 -7.5384057e-01 -1.5053779e+00 -1.6076607e-01\n",
      " -5.5554396e-01 -1.4588927e+00 -4.3784901e-02 -6.2239307e-01\n",
      " -1.4486797e+00 -4.0666036e-02 -6.0662127e-01 -1.5638949e+00\n",
      "  6.7910567e-02 -6.4450192e-01 -1.6356707e+00 -4.3288015e-02\n",
      " -4.7666311e-01 -1.2680669e+00 -1.4948016e-01 -2.5795731e-01\n",
      " -1.8649697e+00 -5.2103400e-04 -4.2076701e-01 -1.8392006e+00\n",
      "  1.4441626e-01 -3.8673025e-01 -1.4627355e+00 -1.6073099e-01\n",
      " -2.2998556e-01 -1.2110412e+00 -3.9932221e-02 -2.2243495e-01\n",
      " -1.2816963e+00  1.2054920e-02 -2.7045509e-01 -1.3983492e+00\n",
      "  4.2617314e-02 -2.7607578e-01 -1.3033262e+00]\n",
      "data: [ 7.0356922e-03 -9.6850961e-02 -2.1775162e-01  1.6732913e-02\n",
      " -2.5604385e-01 -6.6719347e-01 -1.0255657e-02 -4.1734356e-01\n",
      " -1.3684937e+00 -1.4995214e-01 -4.6944273e-01 -1.6994271e+00\n",
      " -3.4173989e-01 -6.1784828e-01 -2.1504321e+00 -2.1762656e-01\n",
      " -6.7805791e-01 -1.5557268e+00  8.1927404e-02 -6.8830782e-01\n",
      " -1.3402852e+00  1.7713621e-02 -6.4463598e-01 -1.3869878e+00\n",
      "  2.2388577e-02 -7.5384057e-01 -1.5053780e+00 -1.6076607e-01\n",
      " -5.5554396e-01 -1.4588927e+00 -4.3784901e-02 -6.2239307e-01\n",
      " -1.4486797e+00 -4.0666036e-02 -6.0662127e-01 -1.5638947e+00\n",
      "  6.7910567e-02 -6.4450192e-01 -1.6356707e+00 -4.3288015e-02\n",
      " -4.7666314e-01 -1.2680669e+00 -1.4948016e-01 -2.5795731e-01\n",
      " -1.8649697e+00 -5.2103400e-04 -4.2076701e-01 -1.8392006e+00\n",
      "  1.4441626e-01 -3.8673028e-01 -1.4627357e+00 -1.6073099e-01\n",
      " -2.2998556e-01 -1.2110412e+00 -3.9932221e-02 -2.2243495e-01\n",
      " -1.2816963e+00  1.2054920e-02 -2.7045509e-01 -1.3983492e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4.2617310e-02 -2.7607578e-01 -1.3033262e+00  2.0000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.068 3.069 3.069 ... 3.021 3.006 2.976]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " [3.056 3.054 3.054 ... 3.02  3.007 2.979]\n",
      " ...\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.834 2.832 2.832 ... 2.816 2.815 2.814]\n",
      " [2.825 2.823 2.823 ... 2.818 2.818 2.82 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[ 0.0247, -0.0935, -0.2560,  ...,  0.0486, -0.2782, -1.3111],\n",
      "        [ 0.0247, -0.0935, -0.2560,  ...,  0.0486, -0.2782, -1.3111],\n",
      "        [ 0.0247, -0.0935, -0.2560,  ...,  0.0486, -0.2782, -1.3111],\n",
      "        ...,\n",
      "        [-0.1838,  0.4493, -0.1534,  ..., -0.7209,  0.9508, -0.4417],\n",
      "        [-0.1854, -0.1253,  0.6214,  ..., -0.2596,  0.6475,  0.2765],\n",
      "        [-0.1854, -0.1253,  0.6214,  ..., -0.2596,  0.6475,  0.2765]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02468301 -0.0935058  -0.25598815  0.04193247 -0.23445457 -0.67044806\n",
      " -0.05205783 -0.42976588 -1.4321262  -0.19475989 -0.49445963 -1.7265804\n",
      " -0.36017787 -0.60776424 -2.1978452  -0.18055582 -0.70741737 -1.5925772\n",
      "  0.03215575 -0.74585176 -1.395459   -0.01981468 -0.68114626 -1.447797\n",
      " -0.0254728  -0.81775475 -1.5645902  -0.1365512  -0.6010356  -1.5054306\n",
      " -0.05887941 -0.6566522  -1.4769921  -0.06915159 -0.63132966 -1.5655944\n",
      "  0.05767934 -0.65512025 -1.6083504  -0.04612709 -0.5116872  -1.3379695\n",
      " -0.16618462 -0.2846583  -1.9813769  -0.01197887 -0.44267532 -1.9813204\n",
      "  0.14267875 -0.4050835  -1.4680167  -0.15213948 -0.27443224 -1.2694407\n",
      " -0.07292378 -0.25093564 -1.3525494  -0.02728613 -0.26594535 -1.46591\n",
      "  0.04860941 -0.2782368  -1.3111407 ]\n",
      "data: [-1.57 -5.38  2.26 -1.57 -5.38  2.26 -1.48 -5.35  2.   -1.18 -5.19  1.49\n",
      " -1.06 -5.2   1.69 -1.17 -5.62  1.67 -0.95 -5.44  1.39 -0.87 -5.22  1.4\n",
      " -0.9  -5.06  1.56 -1.03 -5.53  1.54 -0.8  -5.37  1.33 -0.77 -5.11  1.4\n",
      " -0.81 -4.96  1.75 -0.98 -5.38  1.48 -0.76 -5.31  1.43 -0.74 -5.12  1.54\n",
      " -0.77 -4.93  1.75 -1.03 -5.25  1.8  -0.74 -5.23  1.42 -0.72 -5.11  1.53\n",
      " -0.71 -5.02  1.64  0.  ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.1447,  0.4578, -0.2134,  ..., -0.6502,  0.3539, -0.9377],\n",
      "        [-0.1447,  0.4578, -0.2134,  ..., -0.6502,  0.3539, -0.9377],\n",
      "        [-0.1447,  0.4578, -0.2134,  ..., -0.6502,  0.3539, -0.9377],\n",
      "        ...,\n",
      "        [ 0.1771, -1.4245,  0.6418,  ...,  0.9812, -1.8877,  0.8260],\n",
      "        [ 0.6873, -0.0614,  0.8035,  ...,  0.7089, -0.5549,  2.6446],\n",
      "        [ 0.6873, -0.0614,  0.8035,  ...,  0.7089, -0.5549,  2.6446]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.14470384  0.4577782  -0.21339183 -0.29177222  0.23722306 -0.81913614\n",
      " -0.3141812   0.14809576 -0.974751   -0.37062156  0.02301043 -0.95745224\n",
      " -0.3906479  -0.02304527 -1.0514605  -0.41679344  0.19915307 -1.208922\n",
      " -0.3548407   0.14050919 -0.7058409  -0.43382907 -0.03274691 -0.7115595\n",
      " -0.5454329   0.01152238 -0.79704905 -0.47145742  0.33365065 -1.250814\n",
      " -0.5801183   0.24696335 -1.2654159  -0.6311618   0.12989506 -1.2546251\n",
      " -0.6881596   0.03914297 -1.2015773  -0.5265731   0.39771166 -1.2173185\n",
      " -0.599712    0.3149409  -1.0559056  -0.6900051   0.2768198  -1.0546579\n",
      " -0.7100867   0.14577702 -1.0422747  -0.4990098   0.543129   -1.0824943\n",
      " -0.55345535  0.4712126  -1.003942   -0.6220791   0.4476981  -0.98603624\n",
      " -0.65017104  0.35392675 -0.9377027 ]\n",
      "init: [-0.14470384  0.4577782  -0.21339183 -0.29177222  0.23722306 -0.81913614\n",
      " -0.3141812   0.14809576 -0.974751   -0.37062156  0.02301043 -0.95745224\n",
      " -0.3906479  -0.02304527 -1.0514605  -0.41679344  0.19915307 -1.208922\n",
      " -0.3548407   0.14050919 -0.7058409  -0.43382907 -0.03274691 -0.7115595\n",
      " -0.5454329   0.01152238 -0.79704905 -0.47145742  0.33365065 -1.250814\n",
      " -0.5801183   0.24696335 -1.2654159  -0.6311618   0.12989506 -1.2546251\n",
      " -0.6881596   0.03914297 -1.2015773  -0.5265731   0.39771166 -1.2173185\n",
      " -0.599712    0.3149409  -1.0559056  -0.6900051   0.2768198  -1.0546579\n",
      " -0.7100867   0.14577702 -1.0422747  -0.4990098   0.543129   -1.0824943\n",
      " -0.55345535  0.4712126  -1.003942   -0.6220791   0.4476981  -0.98603624\n",
      " -0.65017104  0.35392675 -0.9377027 ]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [-0.14470384  0.45777816 -0.21339183 -0.29177222  0.23722306 -0.81913614\n",
      " -0.3141812   0.14809576 -0.974751   -0.37062156  0.02301043 -0.95745224\n",
      " -0.3906479  -0.02304527 -1.0514605  -0.41679344  0.19915307 -1.208922\n",
      " -0.3548407   0.14050919 -0.7058409  -0.43382907 -0.03274691 -0.7115595\n",
      " -0.5454329   0.01152238 -0.79704905 -0.4714574   0.33365068 -1.250814\n",
      " -0.5801183   0.24696335 -1.2654159  -0.6311618   0.12989506 -1.2546251\n",
      " -0.6881596   0.03914297 -1.2015773  -0.5265731   0.39771166 -1.2173185\n",
      " -0.599712    0.3149409  -1.0559056  -0.6900051   0.2768198  -1.0546579\n",
      " -0.71008664  0.14577702 -1.0422747  -0.4990098   0.543129   -1.0824943\n",
      " -0.55345535  0.47121257 -1.003942   -0.6220791   0.4476981  -0.98603624\n",
      " -0.65017104  0.35392675 -0.9377027   0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F4A8>\n",
      "tensor([[-0.0364, -0.3380, -0.1397,  ...,  0.0187, -0.4481, -1.2069],\n",
      "        [-0.0364, -0.3380, -0.1397,  ...,  0.0187, -0.4481, -1.2069],\n",
      "        [-0.0364, -0.3380, -0.1397,  ...,  0.0187, -0.4481, -1.2069],\n",
      "        ...,\n",
      "        [ 0.1806,  0.3661, -0.0942,  ..., -0.7425,  0.7939, -0.0380],\n",
      "        [-0.1895,  0.1565,  0.4940,  ..., -0.6909,  0.9880,  0.0776],\n",
      "        [-0.1895,  0.1565,  0.4940,  ..., -0.6909,  0.9880,  0.0776]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.03642026 -0.3380056  -0.13965856 -0.00929187 -0.44483206 -0.5141993\n",
      " -0.11908264 -0.60154176 -1.2071812  -0.22776811 -0.6201043  -1.426877\n",
      " -0.34060055 -0.6968729  -1.847966   -0.24547952 -0.8740549  -1.2843134\n",
      " -0.0945859  -0.8630572  -1.2353566  -0.09029917 -0.7401204  -1.2661052\n",
      " -0.05413382 -0.8279687  -1.3454041  -0.21874423 -0.7940334  -1.2456641\n",
      " -0.11718924 -0.7899364  -1.2410796  -0.07729789 -0.6940919  -1.2730057\n",
      "  0.07492493 -0.68703663 -1.3495975  -0.11029968 -0.7378117  -1.1564541\n",
      " -0.17086203 -0.47995842 -1.5893025  -0.0190953  -0.5923694  -1.5758367\n",
      "  0.11955222 -0.4868039  -1.3446546  -0.20530854 -0.5341603  -1.1092417\n",
      " -0.13170344 -0.46239197 -1.2380917  -0.05344532 -0.46021757 -1.3540683\n",
      "  0.01866261 -0.44810966 -1.2068787 ]\n",
      "data: [-0.03642026 -0.3380056  -0.13965856 -0.00929187 -0.44483203 -0.5141993\n",
      " -0.11908264 -0.60154176 -1.2071812  -0.22776812 -0.6201043  -1.426877\n",
      " -0.34060055 -0.6968729  -1.847966   -0.24547952 -0.87405485 -1.2843136\n",
      " -0.0945859  -0.8630572  -1.2353566  -0.09029917 -0.7401204  -1.2661052\n",
      " -0.05413382 -0.8279688  -1.3454041  -0.21874423 -0.7940334  -1.2456641\n",
      " -0.11718924 -0.7899364  -1.2410796  -0.07729789 -0.694092   -1.2730057\n",
      "  0.07492493 -0.6870367  -1.3495975  -0.11029968 -0.7378117  -1.1564541\n",
      " -0.17086202 -0.47995842 -1.5893025  -0.0190953  -0.5923694  -1.5758367\n",
      "  0.11955222 -0.4868039  -1.3446546  -0.20530853 -0.5341603  -1.1092417\n",
      " -0.13170344 -0.46239197 -1.2380917  -0.05344532 -0.46021757 -1.3540683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.01866261 -0.44810966 -1.2068787   0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63438>\n",
      "tensor([[-0.0029, -0.0019, -0.2214,  ...,  0.0233, -0.1648, -1.3025],\n",
      "        [-0.0029, -0.0019, -0.2214,  ...,  0.0233, -0.1648, -1.3025],\n",
      "        [-0.0029, -0.0019, -0.2214,  ...,  0.0233, -0.1648, -1.3025],\n",
      "        ...,\n",
      "        [-0.2341,  0.4323,  0.1254,  ..., -0.1321,  1.2427, -0.4316],\n",
      "        [-0.1449,  0.0446,  0.5125,  ..., -0.4511,  0.6057,  0.1903],\n",
      "        [-0.1449,  0.0446,  0.5125,  ..., -0.4511,  0.6057,  0.1903]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-2.9453887e-03 -1.9448176e-03 -2.2138436e-01  2.5224801e-02\n",
      " -1.3184737e-01 -5.6970191e-01 -3.8254149e-02 -3.3038998e-01\n",
      " -1.3757561e+00 -1.9337918e-01 -3.8292208e-01 -1.7068348e+00\n",
      " -3.7391940e-01 -5.1553571e-01 -2.2041979e+00 -2.3189062e-01\n",
      " -5.9662181e-01 -1.6202488e+00  8.1667066e-02 -6.2857097e-01\n",
      " -1.3696659e+00  2.3589000e-02 -5.7714641e-01 -1.3997867e+00\n",
      "  1.8675044e-02 -7.0416284e-01 -1.5342171e+00 -1.7606561e-01\n",
      " -4.7951877e-01 -1.5055285e+00 -6.1120123e-02 -5.5053085e-01\n",
      " -1.4862926e+00 -3.7958317e-02 -5.1828200e-01 -1.5921278e+00\n",
      "  9.6385598e-02 -5.7774711e-01 -1.6577042e+00 -5.1971801e-02\n",
      " -3.7959170e-01 -1.3169435e+00 -2.0650208e-01 -1.3539600e-01\n",
      " -2.0202236e+00 -9.3507320e-03 -3.2981706e-01 -2.0085647e+00\n",
      "  1.7311314e-01 -2.7517515e-01 -1.4860572e+00 -2.0974392e-01\n",
      " -1.2606372e-01 -1.2390251e+00 -8.0463037e-02 -1.0273780e-01\n",
      " -1.3025372e+00 -3.0307129e-02 -1.5617599e-01 -1.4217057e+00\n",
      "  2.3289450e-02 -1.6483845e-01 -1.3025465e+00]\n",
      "data: [-2.9453887e-03 -1.9448176e-03 -2.2138435e-01  2.5224799e-02\n",
      " -1.3184737e-01 -5.6970191e-01 -3.8254149e-02 -3.3038998e-01\n",
      " -1.3757560e+00 -1.9337918e-01 -3.8292208e-01 -1.7068347e+00\n",
      " -3.7391940e-01 -5.1553571e-01 -2.2041979e+00 -2.3189062e-01\n",
      " -5.9662181e-01 -1.6202487e+00  8.1667058e-02 -6.2857097e-01\n",
      " -1.3696659e+00  2.3589000e-02 -5.7714641e-01 -1.3997867e+00\n",
      "  1.8675044e-02 -7.0416284e-01 -1.5342171e+00 -1.7606562e-01\n",
      " -4.7951877e-01 -1.5055285e+00 -6.1120123e-02 -5.5053085e-01\n",
      " -1.4862926e+00 -3.7958317e-02 -5.1828200e-01 -1.5921278e+00\n",
      "  9.6385591e-02 -5.7774711e-01 -1.6577041e+00 -5.1971804e-02\n",
      " -3.7959170e-01 -1.3169435e+00 -2.0650208e-01 -1.3539600e-01\n",
      " -2.0202236e+00 -9.3507320e-03 -3.2981706e-01 -2.0085647e+00\n",
      "  1.7311314e-01 -2.7517515e-01 -1.4860572e+00 -2.0974392e-01\n",
      " -1.2606372e-01 -1.2390251e+00 -8.0463037e-02 -1.0273780e-01\n",
      " -1.3025372e+00 -3.0307129e-02 -1.5617599e-01 -1.4217057e+00\n",
      "  2.3289450e-02 -1.6483845e-01 -1.3025465e+00  2.9999999e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B9B0>\n",
      "tensor([[-0.0095, -0.1327, -0.2922,  ...,  0.0168, -0.2928, -1.3986],\n",
      "        [-0.0095, -0.1327, -0.2922,  ...,  0.0168, -0.2928, -1.3986],\n",
      "        [-0.0095, -0.1327, -0.2922,  ...,  0.0168, -0.2928, -1.3986],\n",
      "        ...,\n",
      "        [-0.1785,  0.4093, -0.1256,  ..., -0.7288,  0.9351, -0.3186],\n",
      "        [-0.1858, -0.0477,  0.5880,  ..., -0.2673,  0.6956,  0.3003],\n",
      "        [-0.1858, -0.0477,  0.5880,  ..., -0.2673,  0.6956,  0.3003]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-9.5029054e-03 -1.3266036e-01 -2.9215938e-01  9.9590458e-03\n",
      " -2.9414850e-01 -7.5806499e-01 -1.5735574e-02 -4.3794119e-01\n",
      " -1.4431326e+00 -1.4873692e-01 -4.8744434e-01 -1.7543347e+00\n",
      " -3.1505787e-01 -6.3069117e-01 -2.2241631e+00 -2.2744022e-01\n",
      " -7.0537615e-01 -1.6010759e+00  6.8266436e-02 -6.9656676e-01\n",
      " -1.3719404e+00  1.6524941e-03 -6.4269584e-01 -1.4235665e+00\n",
      " -1.4923170e-02 -7.2895485e-01 -1.5430046e+00 -1.8269597e-01\n",
      " -5.9190500e-01 -1.5238608e+00 -6.1133668e-02 -6.3941443e-01\n",
      " -1.5253142e+00 -7.0674442e-02 -5.9794146e-01 -1.6241639e+00\n",
      "  2.2958502e-02 -6.3020122e-01 -1.6896045e+00 -6.4182572e-02\n",
      " -5.1505935e-01 -1.3481183e+00 -1.4807066e-01 -2.8303319e-01\n",
      " -1.8755178e+00 -2.0254463e-02 -4.2501950e-01 -1.8478971e+00\n",
      "  1.0181968e-01 -3.8651174e-01 -1.5531133e+00 -1.7170271e-01\n",
      " -2.7619642e-01 -1.2969444e+00 -5.0924629e-02 -2.5757238e-01\n",
      " -1.3745879e+00 -6.3944757e-03 -2.9262573e-01 -1.4909886e+00\n",
      "  1.6826771e-02 -2.9276624e-01 -1.3985637e+00]\n",
      "data: [-9.5029054e-03 -1.3266036e-01 -2.9215938e-01  9.9590458e-03\n",
      " -2.9414850e-01 -7.5806499e-01 -1.5735574e-02 -4.3794119e-01\n",
      " -1.4431326e+00 -1.4873692e-01 -4.8744434e-01 -1.7543347e+00\n",
      " -3.1505787e-01 -6.3069117e-01 -2.2241631e+00 -2.2744022e-01\n",
      " -7.0537615e-01 -1.6010759e+00  6.8266436e-02 -6.9656676e-01\n",
      " -1.3719403e+00  1.6524941e-03 -6.4269584e-01 -1.4235665e+00\n",
      " -1.4923169e-02 -7.2895485e-01 -1.5430046e+00 -1.8269596e-01\n",
      " -5.9190500e-01 -1.5238608e+00 -6.1133668e-02 -6.3941443e-01\n",
      " -1.5253142e+00 -7.0674442e-02 -5.9794146e-01 -1.6241639e+00\n",
      "  2.2958502e-02 -6.3020122e-01 -1.6896045e+00 -6.4182572e-02\n",
      " -5.1505935e-01 -1.3481183e+00 -1.4807066e-01 -2.8303319e-01\n",
      " -1.8755178e+00 -2.0254465e-02 -4.2501950e-01 -1.8478971e+00\n",
      "  1.0181968e-01 -3.8651171e-01 -1.5531135e+00 -1.7170271e-01\n",
      " -2.7619642e-01 -1.2969444e+00 -5.0924629e-02 -2.5757238e-01\n",
      " -1.3745879e+00 -6.3944757e-03 -2.9262573e-01 -1.4909886e+00\n",
      "  1.6826771e-02 -2.9276624e-01 -1.3985637e+00  3.9999999e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63630>\n",
      "tensor([[ 0.0591, -0.1850, -0.2498,  ...,  0.0747, -0.3560, -1.3406],\n",
      "        [ 0.0591, -0.1850, -0.2498,  ...,  0.0747, -0.3560, -1.3406],\n",
      "        [ 0.0591, -0.1850, -0.2498,  ...,  0.0747, -0.3560, -1.3406],\n",
      "        ...,\n",
      "        [-0.0927,  0.5011, -0.1290,  ..., -0.6795,  1.0145, -0.4270],\n",
      "        [-0.1968, -0.0605,  0.6418,  ..., -0.2772,  0.6648,  0.3495],\n",
      "        [-0.1968, -0.0605,  0.6418,  ..., -0.2772,  0.6648,  0.3495]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 5.90724163e-02 -1.85014576e-01 -2.49761194e-01  8.61811191e-02\n",
      " -3.21497858e-01 -6.59040809e-01  2.06348151e-02 -5.08428097e-01\n",
      " -1.42037725e+00 -1.23126484e-01 -5.62249184e-01 -1.73551369e+00\n",
      " -2.86538631e-01 -6.83504224e-01 -2.22129941e+00 -1.51128471e-01\n",
      " -7.83803105e-01 -1.61817408e+00  1.03809260e-01 -8.14338505e-01\n",
      " -1.43205595e+00  4.45636734e-02 -7.60929525e-01 -1.47899294e+00\n",
      "  3.77988145e-02 -8.90317023e-01 -1.60123324e+00 -1.01848610e-01\n",
      " -6.75648868e-01 -1.52047372e+00 -8.23934376e-03 -7.35937417e-01\n",
      " -1.50785470e+00 -9.63964313e-03 -7.09882975e-01 -1.60902810e+00\n",
      "  1.02227770e-01 -7.52042115e-01 -1.66209507e+00  4.56675887e-04\n",
      " -5.77978015e-01 -1.34337354e+00 -1.29447073e-01 -3.49623859e-01\n",
      " -2.00255156e+00  3.51215079e-02 -5.19485295e-01 -1.99796176e+00\n",
      "  1.81821436e-01 -4.77096856e-01 -1.50967789e+00 -1.23567857e-01\n",
      " -3.40013683e-01 -1.27600121e+00 -2.24439874e-02 -3.17164183e-01\n",
      " -1.34985781e+00  2.15338841e-02 -3.49722683e-01 -1.46630096e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7.47092366e-02 -3.55993867e-01 -1.34063792e+00]\n",
      "data: [ 5.90724200e-02 -1.85014576e-01 -2.49761194e-01  8.61811191e-02\n",
      " -3.21497828e-01 -6.59040809e-01  2.06348151e-02 -5.08428097e-01\n",
      " -1.42037725e+00 -1.23126484e-01 -5.62249184e-01 -1.73551357e+00\n",
      " -2.86538631e-01 -6.83504283e-01 -2.22129941e+00 -1.51128471e-01\n",
      " -7.83803105e-01 -1.61817408e+00  1.03809260e-01 -8.14338505e-01\n",
      " -1.43205595e+00  4.45636734e-02 -7.60929465e-01 -1.47899294e+00\n",
      "  3.77988145e-02 -8.90317023e-01 -1.60123324e+00 -1.01848610e-01\n",
      " -6.75648868e-01 -1.52047384e+00 -8.23934376e-03 -7.35937417e-01\n",
      " -1.50785482e+00 -9.63964313e-03 -7.09882975e-01 -1.60902822e+00\n",
      "  1.02227777e-01 -7.52042055e-01 -1.66209507e+00  4.56675887e-04\n",
      " -5.77978015e-01 -1.34337354e+00 -1.29447073e-01 -3.49623859e-01\n",
      " -2.00255156e+00  3.51215079e-02 -5.19485295e-01 -1.99796176e+00\n",
      "  1.81821436e-01 -4.77096856e-01 -1.50967789e+00 -1.23567857e-01\n",
      " -3.40013683e-01 -1.27600121e+00 -2.24439874e-02 -3.17164183e-01\n",
      " -1.34985781e+00  2.15338841e-02 -3.49722683e-01 -1.46630096e+00\n",
      "  7.47092366e-02 -3.55993867e-01 -1.34063792e+00  5.00000007e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0175, -0.1731, -0.1889,  ...,  0.0709, -0.3640, -1.2235],\n",
      "        [ 0.0175, -0.1731, -0.1889,  ...,  0.0709, -0.3640, -1.2235],\n",
      "        [ 0.0175, -0.1731, -0.1889,  ...,  0.0709, -0.3640, -1.2235],\n",
      "        ...,\n",
      "        [-0.0186,  0.5448, -0.1421,  ..., -0.4881,  1.0903, -0.5259],\n",
      "        [-0.1184,  0.0146,  0.5961,  ..., -0.1574,  0.6931,  0.2581],\n",
      "        [-0.1184,  0.0146,  0.5961,  ..., -0.1574,  0.6931,  0.2581]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.7520551e-02 -1.7305997e-01 -1.8892342e-01  4.3140542e-02\n",
      " -3.1027788e-01 -5.4719007e-01 -3.9128691e-02 -5.1713634e-01\n",
      " -1.3400429e+00 -1.8925482e-01 -5.8056587e-01 -1.6545188e+00\n",
      " -3.6258161e-01 -7.1238732e-01 -2.1322975e+00 -1.9424441e-01\n",
      " -7.8704071e-01 -1.5376487e+00  6.5750591e-02 -8.3259642e-01\n",
      " -1.3321809e+00  8.1776828e-04 -7.7762711e-01 -1.3747048e+00\n",
      " -8.0283061e-03 -9.1732001e-01 -1.4975944e+00 -1.3600215e-01\n",
      " -6.7791820e-01 -1.4325269e+00 -4.4030651e-02 -7.4764800e-01\n",
      " -1.4127330e+00 -4.3999910e-02 -7.2421181e-01 -1.5092771e+00\n",
      "  7.2996907e-02 -7.6945555e-01 -1.5541321e+00 -2.5182158e-02\n",
      " -5.7943124e-01 -1.2491406e+00 -1.6731223e-01 -3.4982216e-01\n",
      " -1.9519949e+00  1.0497734e-02 -5.3378803e-01 -1.9460123e+00\n",
      "  1.7090085e-01 -4.8954383e-01 -1.3948077e+00 -1.5363240e-01\n",
      " -3.3829355e-01 -1.1803831e+00 -4.4569053e-02 -3.2073373e-01\n",
      " -1.2579411e+00  3.6885664e-03 -3.5671863e-01 -1.3710475e+00\n",
      "  7.0917115e-02 -3.6404783e-01 -1.2235252e+00]\n",
      "data: [ 1.7520551e-02 -1.7305999e-01 -1.8892342e-01  4.3140542e-02\n",
      " -3.1027788e-01 -5.4719007e-01 -3.9128691e-02 -5.1713634e-01\n",
      " -1.3400428e+00 -1.8925482e-01 -5.8056587e-01 -1.6545188e+00\n",
      " -3.6258161e-01 -7.1238732e-01 -2.1322975e+00 -1.9424443e-01\n",
      " -7.8704071e-01 -1.5376487e+00  6.5750591e-02 -8.3259642e-01\n",
      " -1.3321807e+00  8.1776828e-04 -7.7762711e-01 -1.3747048e+00\n",
      " -8.0283061e-03 -9.1732001e-01 -1.4975944e+00 -1.3600215e-01\n",
      " -6.7791820e-01 -1.4325271e+00 -4.4030651e-02 -7.4764800e-01\n",
      " -1.4127330e+00 -4.3999910e-02 -7.2421181e-01 -1.5092770e+00\n",
      "  7.2996907e-02 -7.6945555e-01 -1.5541321e+00 -2.5182156e-02\n",
      " -5.7943124e-01 -1.2491406e+00 -1.6731223e-01 -3.4982216e-01\n",
      " -1.9519949e+00  1.0497735e-02 -5.3378803e-01 -1.9460123e+00\n",
      "  1.7090087e-01 -4.8954383e-01 -1.3948077e+00 -1.5363240e-01\n",
      " -3.3829352e-01 -1.1803831e+00 -4.4569053e-02 -3.2073373e-01\n",
      " -1.2579411e+00  3.6885664e-03 -3.5671863e-01 -1.3710475e+00\n",
      "  7.0917115e-02 -3.6404783e-01 -1.2235252e+00  5.9999999e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0102, -0.1086, -0.1792,  ...,  0.0185, -0.2989, -1.1794],\n",
      "        [ 0.0102, -0.1086, -0.1792,  ...,  0.0185, -0.2989, -1.1794],\n",
      "        [ 0.0102, -0.1086, -0.1792,  ...,  0.0185, -0.2989, -1.1794],\n",
      "        ...,\n",
      "        [-0.1258,  0.4809, -0.1308,  ..., -0.3168,  1.1075, -0.5877],\n",
      "        [-0.0777, -0.0060,  0.6431,  ..., -0.1611,  0.6827,  0.2745],\n",
      "        [-0.0777, -0.0060,  0.6431,  ..., -0.1611,  0.6827,  0.2745]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01020281 -0.10859967 -0.17924003  0.03775402 -0.21249242 -0.4711085\n",
      " -0.10941502 -0.4491854  -1.3348416  -0.26971966 -0.5184037  -1.6225156\n",
      " -0.42213053 -0.60580385 -2.141693   -0.18874867 -0.7539109  -1.5202556\n",
      " -0.02658065 -0.8280952  -1.3788602  -0.07987402 -0.74971914 -1.4255798\n",
      " -0.08511242 -0.9218252  -1.5475569  -0.14502168 -0.66612434 -1.416309\n",
      " -0.09471361 -0.71899045 -1.3801761  -0.10585975 -0.6831758  -1.4621166\n",
      "  0.03314781 -0.71537054 -1.4743974  -0.06271941 -0.55023646 -1.2596669\n",
      " -0.2255962  -0.31304535 -2.0102632  -0.04211506 -0.48792133 -2.0376616\n",
      "  0.13468952 -0.44518873 -1.3474199  -0.1903201  -0.31852698 -1.1775383\n",
      " -0.12454188 -0.28722548 -1.2661086  -0.09475225 -0.2889618  -1.3758003\n",
      "  0.01853719 -0.29891276 -1.1794188 ]\n",
      "data: [ 0.01020281 -0.10859967 -0.17924003  0.03775402 -0.21249242 -0.47110853\n",
      " -0.10941502 -0.4491854  -1.3348416  -0.26971966 -0.5184037  -1.6225156\n",
      " -0.4221305  -0.60580385 -2.141693   -0.18874866 -0.7539109  -1.5202556\n",
      " -0.02658065 -0.8280952  -1.3788601  -0.07987402 -0.74971914 -1.4255798\n",
      " -0.08511242 -0.9218252  -1.5475569  -0.14502168 -0.66612434 -1.416309\n",
      " -0.09471361 -0.7189905  -1.3801761  -0.10585975 -0.6831758  -1.4621166\n",
      "  0.03314781 -0.71537054 -1.4743974  -0.06271941 -0.55023646 -1.2596669\n",
      " -0.2255962  -0.31304535 -2.0102632  -0.04211506 -0.48792133 -2.0376616\n",
      "  0.13468952 -0.4451887  -1.3474199  -0.1903201  -0.31852698 -1.1775383\n",
      " -0.12454187 -0.28722548 -1.2661086  -0.09475225 -0.2889618  -1.3758004\n",
      "  0.01853719 -0.29891276 -1.1794188   0.07      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[-1.6819e-02, -5.6355e-04, -1.9779e-01,  ...,  1.4863e-02,\n",
      "         -1.9508e-01, -1.1660e+00],\n",
      "        [-1.6819e-02, -5.6355e-04, -1.9779e-01,  ...,  1.4863e-02,\n",
      "         -1.9508e-01, -1.1660e+00],\n",
      "        [-1.6819e-02, -5.6355e-04, -1.9779e-01,  ...,  1.4863e-02,\n",
      "         -1.9508e-01, -1.1660e+00],\n",
      "        ...,\n",
      "        [-1.7181e-01,  3.3961e-01,  4.2966e-02,  ..., -6.7701e-01,\n",
      "          9.2376e-01, -3.3824e-01],\n",
      "        [-1.0294e-01, -1.2261e-01,  5.7994e-01,  ..., -2.2720e-01,\n",
      "          5.7772e-01,  2.4540e-01],\n",
      "        [-1.0294e-01, -1.2261e-01,  5.7994e-01,  ..., -2.2720e-01,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          5.7772e-01,  2.4540e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-1.6819250e-02 -5.6354608e-04 -1.9778728e-01  4.2392500e-03\n",
      " -1.0545981e-01 -4.8524234e-01 -1.5276209e-01 -3.3418426e-01\n",
      " -1.3384398e+00 -3.1080359e-01 -4.0058574e-01 -1.6215489e+00\n",
      " -4.6952236e-01 -4.8567009e-01 -2.1286128e+00 -2.1157922e-01\n",
      " -6.4726603e-01 -1.5055493e+00 -5.3436264e-02 -7.1177757e-01\n",
      " -1.3420292e+00 -9.5812842e-02 -6.2929577e-01 -1.3957763e+00\n",
      " -8.8554740e-02 -7.9929519e-01 -1.5223240e+00 -1.7154750e-01\n",
      " -5.5794948e-01 -1.4080766e+00 -1.1524980e-01 -6.0582870e-01\n",
      " -1.3704023e+00 -1.1663039e-01 -5.6920660e-01 -1.4536875e+00\n",
      "  5.0062254e-02 -5.9229314e-01 -1.4682957e+00 -9.1434501e-02\n",
      " -4.4893262e-01 -1.2487530e+00 -2.4506116e-01 -2.1025494e-01\n",
      " -2.0089550e+00 -5.1548831e-02 -3.7826920e-01 -2.0378401e+00\n",
      "  1.4930539e-01 -3.3915848e-01 -1.3357584e+00 -2.1081254e-01\n",
      " -2.1743996e-01 -1.1663624e+00 -1.5110576e-01 -1.8633360e-01\n",
      " -1.2565464e+00 -1.1694752e-01 -1.7885359e-01 -1.3722122e+00\n",
      "  1.4862604e-02 -1.9508068e-01 -1.1660423e+00]\n",
      "data: [-1.6819250e-02 -5.6354608e-04 -1.9778728e-01  4.2392500e-03\n",
      " -1.0545980e-01 -4.8524234e-01 -1.5276209e-01 -3.3418426e-01\n",
      " -1.3384398e+00 -3.1080359e-01 -4.0058574e-01 -1.6215489e+00\n",
      " -4.6952236e-01 -4.8567009e-01 -2.1286128e+00 -2.1157923e-01\n",
      " -6.4726603e-01 -1.5055493e+00 -5.3436264e-02 -7.1177757e-01\n",
      " -1.3420292e+00 -9.5812842e-02 -6.2929577e-01 -1.3957763e+00\n",
      " -8.8554747e-02 -7.9929519e-01 -1.5223240e+00 -1.7154750e-01\n",
      " -5.5794948e-01 -1.4080766e+00 -1.1524980e-01 -6.0582870e-01\n",
      " -1.3704023e+00 -1.1663039e-01 -5.6920660e-01 -1.4536875e+00\n",
      "  5.0062254e-02 -5.9229314e-01 -1.4682957e+00 -9.1434501e-02\n",
      " -4.4893262e-01 -1.2487530e+00 -2.4506114e-01 -2.1025494e-01\n",
      " -2.0089550e+00 -5.1548827e-02 -3.7826920e-01 -2.0378401e+00\n",
      "  1.4930539e-01 -3.3915848e-01 -1.3357586e+00 -2.1081252e-01\n",
      " -2.1743995e-01 -1.1663624e+00 -1.5110576e-01 -1.8633360e-01\n",
      " -1.2565464e+00 -1.1694752e-01 -1.7885359e-01 -1.3722122e+00\n",
      "  1.4862604e-02 -1.9508068e-01 -1.1660423e+00  7.9999998e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0133, -0.0649, -0.2082,  ...,  0.0030, -0.2226, -1.3257],\n",
      "        [-0.0133, -0.0649, -0.2082,  ...,  0.0030, -0.2226, -1.3257],\n",
      "        [-0.0133, -0.0649, -0.2082,  ...,  0.0030, -0.2226, -1.3257],\n",
      "        ...,\n",
      "        [-0.2492,  0.2933, -0.1269,  ..., -0.7698,  0.7566, -0.3114],\n",
      "        [-0.1814, -0.0993,  0.5137,  ..., -0.2818,  0.6559,  0.2478],\n",
      "        [-0.1814, -0.0993,  0.5137,  ..., -0.2818,  0.6559,  0.2478]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-1.33090056e-02 -6.48792386e-02 -2.08212957e-01 -8.76832753e-04\n",
      " -2.27402657e-01 -6.71548545e-01 -5.03395200e-02 -3.75289053e-01\n",
      " -1.35564137e+00 -1.93037108e-01 -4.28318441e-01 -1.66474867e+00\n",
      " -3.80682737e-01 -5.60806394e-01 -2.12577677e+00 -2.38848686e-01\n",
      " -6.45482957e-01 -1.52087712e+00  3.12743336e-02 -6.44653320e-01\n",
      " -1.29398561e+00 -1.56930387e-02 -5.89426696e-01 -1.34533715e+00\n",
      " -1.40166283e-02 -6.86631680e-01 -1.46043849e+00 -1.94471866e-01\n",
      " -5.26352644e-01 -1.44586325e+00 -8.03589821e-02 -5.81020951e-01\n",
      " -1.43315411e+00 -7.81932175e-02 -5.50911725e-01 -1.54322147e+00\n",
      "  5.40527552e-02 -5.71516693e-01 -1.61921358e+00 -9.04940292e-02\n",
      " -4.56933528e-01 -1.26774573e+00 -1.71444520e-01 -2.29048550e-01\n",
      " -1.79868698e+00 -3.47393528e-02 -3.68194282e-01 -1.77741122e+00\n",
      "  1.16013795e-01 -3.36047173e-01 -1.47055268e+00 -1.92479044e-01\n",
      " -2.08598286e-01 -1.21786189e+00 -9.60744023e-02 -1.88822895e-01\n",
      " -1.29480004e+00 -3.95839959e-02 -2.16573611e-01 -1.41807985e+00\n",
      "  2.96448916e-03 -2.22594485e-01 -1.32566500e+00]\n",
      "data: [-1.33090056e-02 -6.48792386e-02 -2.08212942e-01 -8.76832753e-04\n",
      " -2.27402642e-01 -6.71548545e-01 -5.03395163e-02 -3.75289053e-01\n",
      " -1.35564137e+00 -1.93037108e-01 -4.28318441e-01 -1.66474867e+00\n",
      " -3.80682766e-01 -5.60806394e-01 -2.12577677e+00 -2.38848686e-01\n",
      " -6.45482957e-01 -1.52087712e+00  3.12743336e-02 -6.44653320e-01\n",
      " -1.29398561e+00 -1.56930387e-02 -5.89426696e-01 -1.34533727e+00\n",
      " -1.40166283e-02 -6.86631680e-01 -1.46043849e+00 -1.94471881e-01\n",
      " -5.26352644e-01 -1.44586325e+00 -8.03589821e-02 -5.81020951e-01\n",
      " -1.43315411e+00 -7.81932175e-02 -5.50911725e-01 -1.54322147e+00\n",
      "  5.40527552e-02 -5.71516693e-01 -1.61921358e+00 -9.04940292e-02\n",
      " -4.56933528e-01 -1.26774573e+00 -1.71444505e-01 -2.29048550e-01\n",
      " -1.79868698e+00 -3.47393528e-02 -3.68194282e-01 -1.77741122e+00\n",
      "  1.16013795e-01 -3.36047173e-01 -1.47055268e+00 -1.92479044e-01\n",
      " -2.08598286e-01 -1.21786189e+00 -9.60744023e-02 -1.88822895e-01\n",
      " -1.29480016e+00 -3.95839959e-02 -2.16573626e-01 -1.41807985e+00\n",
      "  2.96448916e-03 -2.22594485e-01 -1.32566500e+00  9.00000036e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0465, -0.1490, -0.2877,  ...,  0.0420, -0.3204, -1.3552],\n",
      "        [ 0.0465, -0.1490, -0.2877,  ...,  0.0420, -0.3204, -1.3552],\n",
      "        [ 0.0465, -0.1490, -0.2877,  ...,  0.0420, -0.3204, -1.3552],\n",
      "        ...,\n",
      "        [-0.3064,  0.3552, -0.2983,  ..., -0.8380,  0.8516, -0.5328],\n",
      "        [-0.1424, -0.0267,  0.6755,  ..., -0.2370,  0.7585,  0.3522],\n",
      "        [-0.1424, -0.0267,  0.6755,  ..., -0.2370,  0.7585,  0.3522]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04647163 -0.14900476 -0.28769627  0.07747386 -0.27098387 -0.6900381\n",
      " -0.03444604 -0.4623539  -1.470678   -0.17962055 -0.5238558  -1.7590039\n",
      " -0.32527888 -0.612857   -2.265153   -0.14699674 -0.760885   -1.6354606\n",
      "  0.02748543 -0.7997848  -1.4783206  -0.0203504  -0.7296723  -1.5379416\n",
      " -0.03197715 -0.87412953 -1.6572409  -0.11248966 -0.66919816 -1.5517142\n",
      " -0.0496574  -0.7144563  -1.5264516  -0.07241561 -0.6814035  -1.6156499\n",
      "  0.05659296 -0.703192   -1.6488023  -0.03927139 -0.5712695  -1.390132\n",
      " -0.16209415 -0.33824018 -2.051125   -0.01051659 -0.48794416 -2.0680134\n",
      "  0.13915189 -0.45647874 -1.5157169  -0.13985172 -0.34269977 -1.3195381\n",
      " -0.08041924 -0.3095029  -1.3991727  -0.04477857 -0.30771592 -1.5161792\n",
      "  0.04198956 -0.32035112 -1.3551668 ]\n",
      "data: [ 0.04647163 -0.14900476 -0.28769627  0.07747386 -0.27098387 -0.6900381\n",
      " -0.03444604 -0.4623539  -1.470678   -0.17962055 -0.5238558  -1.7590039\n",
      " -0.32527888 -0.612857   -2.265153   -0.14699674 -0.760885   -1.6354606\n",
      "  0.02748543 -0.7997848  -1.4783206  -0.0203504  -0.7296723  -1.5379416\n",
      " -0.03197715 -0.87412953 -1.6572409  -0.11248966 -0.66919816 -1.5517142\n",
      " -0.0496574  -0.7144563  -1.5264516  -0.07241561 -0.6814035  -1.6156498\n",
      "  0.05659296 -0.703192   -1.6488023  -0.03927139 -0.5712695  -1.390132\n",
      " -0.16209416 -0.33824018 -2.051125   -0.01051659 -0.48794416 -2.0680134\n",
      "  0.13915189 -0.45647871 -1.5157169  -0.13985172 -0.34269977 -1.3195381\n",
      " -0.08041924 -0.3095029  -1.3991727  -0.04477857 -0.30771592 -1.5161792\n",
      "  0.04198956 -0.3203511  -1.3551668   0.1       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0240, -0.1530, -0.2037,  ...,  0.0913, -0.3390, -1.2781],\n",
      "        [ 0.0240, -0.1530, -0.2037,  ...,  0.0913, -0.3390, -1.2781],\n",
      "        [ 0.0240, -0.1530, -0.2037,  ...,  0.0913, -0.3390, -1.2781],\n",
      "        ...,\n",
      "        [-0.0529,  0.4615, -0.0894,  ..., -0.6785,  0.9912, -0.4075],\n",
      "        [-0.1286, -0.0434,  0.5628,  ..., -0.2094,  0.6323,  0.2412],\n",
      "        [-0.1286, -0.0434,  0.5628,  ..., -0.2094,  0.6323,  0.2412]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.40258165e-02 -1.52990878e-01 -2.03694165e-01  4.84417565e-02\n",
      " -2.96729624e-01 -5.77549696e-01  8.22087377e-03 -4.77489591e-01\n",
      " -1.34058177e+00 -1.37368292e-01 -5.30560970e-01 -1.67688048e+00\n",
      " -3.21060956e-01 -6.80165529e-01 -2.15042973e+00 -1.97223857e-01\n",
      " -7.40165114e-01 -1.56408465e+00  1.18897393e-01 -7.65230179e-01\n",
      " -1.35188413e+00  5.04586697e-02 -7.23143697e-01 -1.38988924e+00\n",
      "  5.09654731e-02 -8.43318582e-01 -1.51394999e+00 -1.30514175e-01\n",
      " -6.23310804e-01 -1.45412481e+00 -1.11821145e-02 -6.97905064e-01\n",
      " -1.45071030e+00  1.25468522e-03 -6.78989649e-01 -1.56530130e+00\n",
      "  1.10216767e-01 -7.33552217e-01 -1.63440263e+00 -4.28303331e-03\n",
      " -5.35384178e-01 -1.25673258e+00 -1.31954700e-01 -3.08096230e-01\n",
      " -1.92088330e+00  4.34994251e-02 -4.92971867e-01 -1.89990568e+00\n",
      "  1.98266521e-01 -4.50474948e-01 -1.45524585e+00 -1.39653206e-01\n",
      " -2.88967907e-01 -1.19564974e+00 -3.54677439e-03 -2.79498875e-01\n",
      " -1.26526368e+00  5.24904430e-02 -3.35767508e-01 -1.38210881e+00\n",
      "  9.13379714e-02 -3.39022279e-01 -1.27807760e+00]\n",
      "data: [ 2.4025816e-02 -1.5299088e-01 -2.0369416e-01  4.8441757e-02\n",
      " -2.9672962e-01 -5.7754970e-01  8.2208738e-03 -4.7748959e-01\n",
      " -1.3405818e+00 -1.3736829e-01 -5.3056097e-01 -1.6768805e+00\n",
      " -3.2106096e-01 -6.8016553e-01 -2.1504297e+00 -1.9722386e-01\n",
      " -7.4016511e-01 -1.5640846e+00  1.1889739e-01 -7.6523018e-01\n",
      " -1.3518841e+00  5.0458670e-02 -7.2314370e-01 -1.3898892e+00\n",
      "  5.0965473e-02 -8.4331858e-01 -1.5139500e+00 -1.3051417e-01\n",
      " -6.2331080e-01 -1.4541248e+00 -1.1182115e-02 -6.9790506e-01\n",
      " -1.4507103e+00  1.2546852e-03 -6.7898965e-01 -1.5653014e+00\n",
      "  1.1021677e-01 -7.3355222e-01 -1.6344026e+00 -4.2830333e-03\n",
      " -5.3538418e-01 -1.2567326e+00 -1.3195470e-01 -3.0809623e-01\n",
      " -1.9208833e+00  4.3499425e-02 -4.9297187e-01 -1.8999057e+00\n",
      "  1.9826652e-01 -4.5047492e-01 -1.4552459e+00 -1.3965321e-01\n",
      " -2.8896791e-01 -1.1956497e+00 -3.5467744e-03 -2.7949888e-01\n",
      " -1.2652637e+00  5.2490443e-02 -3.3576751e-01 -1.3821088e+00\n",
      "  9.1337964e-02 -3.3902228e-01 -1.2780776e+00  1.1000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63828>\n",
      "tensor([[ 0.0150, -0.1440, -0.1727,  ...,  0.0488, -0.3396, -1.1698],\n",
      "        [ 0.0150, -0.1440, -0.1727,  ...,  0.0488, -0.3396, -1.1698],\n",
      "        [ 0.0150, -0.1440, -0.1727,  ...,  0.0488, -0.3396, -1.1698],\n",
      "        ...,\n",
      "        [-0.0950,  0.4782, -0.1017,  ..., -0.3899,  1.0060, -0.4982],\n",
      "        [-0.1797, -0.0275,  0.6249,  ..., -0.2608,  0.6778,  0.2649],\n",
      "        [-0.1797, -0.0275,  0.6249,  ..., -0.2608,  0.6778,  0.2649]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01501909 -0.14399457 -0.17271474  0.04632432 -0.25660253 -0.47988537\n",
      " -0.0903391  -0.49197322 -1.3307326  -0.24538396 -0.56210107 -1.6213887\n",
      " -0.3948462  -0.66149735 -2.1271744  -0.18064664 -0.785351   -1.5135846\n",
      "  0.00794476 -0.85418516 -1.3417704  -0.04856071 -0.78290325 -1.3891534\n",
      " -0.06421585 -0.94921637 -1.5147893  -0.1334615  -0.6927298  -1.4103565\n",
      " -0.07417632 -0.7516148  -1.381612   -0.08379225 -0.71786904 -1.459806\n",
      "  0.0486418  -0.7574029  -1.4786395  -0.04239341 -0.57890093 -1.2463672\n",
      " -0.20512198 -0.34091175 -2.0062103  -0.01749465 -0.52428955 -2.0253987\n",
      "  0.15389709 -0.47855693 -1.3426952  -0.16941963 -0.34730256 -1.1658779\n",
      " -0.09162812 -0.31679553 -1.2513003  -0.05599073 -0.32653835 -1.3622516\n",
      "  0.04880612 -0.33964533 -1.16976   ]\n",
      "data: [ 0.01501909 -0.14399457 -0.17271475  0.04632432 -0.25660253 -0.47988537\n",
      " -0.09033909 -0.49197322 -1.3307326  -0.24538396 -0.56210107 -1.6213887\n",
      " -0.3948462  -0.66149735 -2.1271744  -0.18064664 -0.785351   -1.5135846\n",
      "  0.00794476 -0.85418516 -1.3417705  -0.04856071 -0.7829033  -1.3891532\n",
      " -0.06421585 -0.94921637 -1.5147892  -0.1334615  -0.6927298  -1.4103564\n",
      " -0.07417632 -0.7516148  -1.381612   -0.08379225 -0.71786904 -1.459806\n",
      "  0.0486418  -0.7574029  -1.4786395  -0.04239341 -0.57890093 -1.2463672\n",
      " -0.20512198 -0.34091175 -2.0062103  -0.01749465 -0.52428955 -2.0253987\n",
      "  0.15389709 -0.47855693 -1.3426954  -0.16941963 -0.34730256 -1.1658779\n",
      " -0.09162812 -0.31679553 -1.2513003  -0.05599073 -0.32653835 -1.3622516\n",
      "  0.04880612 -0.3396453  -1.16976     0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B320>\n",
      "tensor([[-0.0372, -0.0448, -0.2262,  ..., -0.0014, -0.2329, -1.1884],\n",
      "        [-0.0372, -0.0448, -0.2262,  ..., -0.0014, -0.2329, -1.1884],\n",
      "        [-0.0372, -0.0448, -0.2262,  ..., -0.0014, -0.2329, -1.1884],\n",
      "        ...,\n",
      "        [-0.1542,  0.3764,  0.0155,  ..., -0.5991,  0.9921, -0.4012],\n",
      "        [-0.0590, -0.0509,  0.6532,  ..., -0.1968,  0.6442,  0.2988],\n",
      "        [-0.0590, -0.0509,  0.6532,  ..., -0.1968,  0.6442,  0.2988]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-3.71553786e-02 -4.48319763e-02 -2.26187214e-01 -5.76576963e-03\n",
      " -1.50408953e-01 -4.94719386e-01 -1.46658391e-01 -3.86159599e-01\n",
      " -1.36786890e+00 -3.02451491e-01 -4.51026082e-01 -1.65996528e+00\n",
      " -4.56575751e-01 -5.49570024e-01 -2.16960216e+00 -2.38347009e-01\n",
      " -6.83065176e-01 -1.54983997e+00 -4.38196808e-02 -7.47960389e-01\n",
      " -1.37790632e+00 -9.77991372e-02 -6.75449491e-01 -1.42263246e+00\n",
      " -1.01008266e-01 -8.39084625e-01 -1.55236387e+00 -1.91583037e-01\n",
      " -5.90628982e-01 -1.44154453e+00 -1.26563281e-01 -6.45783067e-01\n",
      " -1.41098237e+00 -1.24382205e-01 -6.07077718e-01 -1.49264097e+00\n",
      "  2.09633410e-02 -6.47435904e-01 -1.51170969e+00 -9.81171355e-02\n",
      " -4.75363314e-01 -1.27470756e+00 -2.66839504e-01 -2.34197274e-01\n",
      " -2.05710101e+00 -6.36155829e-02 -4.17730629e-01 -2.07873392e+00\n",
      "  1.24136373e-01 -3.70183468e-01 -1.37005091e+00 -2.31817216e-01\n",
      " -2.43032560e-01 -1.19195461e+00 -1.49294272e-01 -2.13453427e-01\n",
      " -1.27360129e+00 -1.13946393e-01 -2.21788228e-01 -1.38655829e+00\n",
      " -1.38758868e-03 -2.32911408e-01 -1.18840790e+00]\n",
      "data: [-3.71553786e-02 -4.48319763e-02 -2.26187214e-01 -5.76576963e-03\n",
      " -1.50408953e-01 -4.94719386e-01 -1.46658391e-01 -3.86159599e-01\n",
      " -1.36786890e+00 -3.02451491e-01 -4.51026082e-01 -1.65996516e+00\n",
      " -4.56575751e-01 -5.49570024e-01 -2.16960216e+00 -2.38347009e-01\n",
      " -6.83065176e-01 -1.54983997e+00 -4.38196808e-02 -7.47960329e-01\n",
      " -1.37790632e+00 -9.77991372e-02 -6.75449550e-01 -1.42263246e+00\n",
      " -1.01008266e-01 -8.39084625e-01 -1.55236387e+00 -1.91583037e-01\n",
      " -5.90628982e-01 -1.44154453e+00 -1.26563281e-01 -6.45783067e-01\n",
      " -1.41098237e+00 -1.24382213e-01 -6.07077718e-01 -1.49264097e+00\n",
      "  2.09633391e-02 -6.47435904e-01 -1.51170969e+00 -9.81171355e-02\n",
      " -4.75363314e-01 -1.27470756e+00 -2.66839504e-01 -2.34197274e-01\n",
      " -2.05710101e+00 -6.36155829e-02 -4.17730629e-01 -2.07873392e+00\n",
      "  1.24136373e-01 -3.70183498e-01 -1.37005091e+00 -2.31817201e-01\n",
      " -2.43032545e-01 -1.19195461e+00 -1.49294272e-01 -2.13453427e-01\n",
      " -1.27360129e+00 -1.13946393e-01 -2.21788228e-01 -1.38655818e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -1.38758868e-03 -2.32911408e-01 -1.18840790e+00  1.29999995e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0265, -0.0516, -0.1624,  ...,  0.0279, -0.2119, -1.2493],\n",
      "        [ 0.0265, -0.0516, -0.1624,  ...,  0.0279, -0.2119, -1.2493],\n",
      "        [ 0.0265, -0.0516, -0.1624,  ...,  0.0279, -0.2119, -1.2493],\n",
      "        ...,\n",
      "        [-0.2809,  0.2497, -0.2050,  ..., -0.7615,  0.7611, -0.4509],\n",
      "        [-0.2170, -0.1474,  0.5268,  ..., -0.3284,  0.5615,  0.2854],\n",
      "        [-0.2170, -0.1474,  0.5268,  ..., -0.3284,  0.5615,  0.2854]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02650787 -0.05161843 -0.1623535   0.04003753 -0.20217451 -0.60606134\n",
      " -0.02674905 -0.37451464 -1.3255734  -0.16986959 -0.42948943 -1.6331747\n",
      " -0.35415345 -0.5519863  -2.0921469  -0.1956976  -0.64936936 -1.4804482\n",
      "  0.05792084 -0.6658148  -1.258643    0.00977057 -0.61184597 -1.3068986\n",
      "  0.00580392 -0.726618   -1.4265264  -0.1517129  -0.53318566 -1.3946203\n",
      " -0.05286826 -0.59013045 -1.3764503  -0.04897276 -0.5607705  -1.4803816\n",
      "  0.08372834 -0.58931506 -1.5481089  -0.05341145 -0.44875413 -1.2213382\n",
      " -0.16522196 -0.22079514 -1.8341304  -0.0080751  -0.3723384  -1.8237265\n",
      "  0.14708433 -0.33424383 -1.399098   -0.16522127 -0.20208582 -1.1601884\n",
      " -0.0758498  -0.1789908  -1.2398511  -0.02456805 -0.20359538 -1.3613939\n",
      "  0.02786615 -0.21194579 -1.2493348 ]\n",
      "data: [ 0.02650787 -0.05161843 -0.1623535   0.04003753 -0.20217451 -0.60606134\n",
      " -0.02674905 -0.37451467 -1.3255734  -0.1698696  -0.42948943 -1.6331745\n",
      " -0.35415345 -0.5519863  -2.0921469  -0.1956976  -0.64936936 -1.4804482\n",
      "  0.05792084 -0.6658148  -1.258643    0.00977057 -0.61184597 -1.3068986\n",
      "  0.00580392 -0.726618   -1.4265265  -0.1517129  -0.53318566 -1.3946204\n",
      " -0.05286826 -0.59013045 -1.3764503  -0.04897276 -0.5607705  -1.4803816\n",
      "  0.08372834 -0.58931506 -1.5481089  -0.05341145 -0.44875413 -1.2213382\n",
      " -0.16522196 -0.22079514 -1.8341304  -0.0080751  -0.3723384  -1.8237265\n",
      "  0.14708433 -0.33424386 -1.399098   -0.16522127 -0.20208582 -1.1601884\n",
      " -0.0758498  -0.1789908  -1.2398511  -0.02456805 -0.20359538 -1.3613939\n",
      "  0.02786615 -0.21194579 -1.2493348   0.14      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F630B8>\n",
      "tensor([[ 0.0083, -0.0579, -0.2560,  ...,  0.0195, -0.2354, -1.2954],\n",
      "        [ 0.0083, -0.0579, -0.2560,  ...,  0.0195, -0.2354, -1.2954],\n",
      "        [ 0.0083, -0.0579, -0.2560,  ...,  0.0195, -0.2354, -1.2954],\n",
      "        ...,\n",
      "        [-0.1059,  0.4795, -0.0518,  ..., -0.6687,  1.0010, -0.3326],\n",
      "        [-0.1309, -0.0632,  0.6311,  ..., -0.2337,  0.7368,  0.2933],\n",
      "        [-0.1309, -0.0632,  0.6311,  ..., -0.2337,  0.7368,  0.2933]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00825763 -0.05785453 -0.25601447  0.03414811 -0.18941998 -0.6541708\n",
      " -0.08828551 -0.38576865 -1.4348245  -0.23327143 -0.4528693  -1.7126966\n",
      " -0.3866433  -0.5460757  -2.2041464  -0.1875109  -0.67297125 -1.5896004\n",
      " -0.01818214 -0.7130439  -1.4138547  -0.0598051  -0.6397002  -1.4717423\n",
      " -0.06501586 -0.7824435  -1.5871472  -0.15368997 -0.5754032  -1.5108773\n",
      " -0.08893299 -0.6236831  -1.4730749  -0.10793693 -0.59256244 -1.5553004\n",
      "  0.03451487 -0.6073642  -1.5879875  -0.07986187 -0.4854985  -1.3495215\n",
      " -0.19651534 -0.25371543 -1.9946752  -0.04403173 -0.40327218 -2.0071049\n",
      "  0.11651768 -0.37123045 -1.4539583  -0.17493677 -0.25367898 -1.2789217\n",
      " -0.11875986 -0.22244039 -1.3552816  -0.07625508 -0.2189771  -1.4712019\n",
      "  0.01945891 -0.23536338 -1.29538   ]\n",
      "data: [ 0.00825763 -0.05785452 -0.25601447  0.03414811 -0.18941997 -0.6541708\n",
      " -0.08828551 -0.38576865 -1.4348245  -0.23327142 -0.4528693  -1.7126966\n",
      " -0.3866433  -0.5460757  -2.2041464  -0.1875109  -0.67297125 -1.5896003\n",
      " -0.01818214 -0.7130439  -1.4138547  -0.0598051  -0.6397002  -1.4717423\n",
      " -0.06501586 -0.7824435  -1.5871472  -0.15368997 -0.5754032  -1.5108773\n",
      " -0.08893299 -0.6236831  -1.4730749  -0.10793693 -0.59256244 -1.5553002\n",
      "  0.03451487 -0.6073642  -1.5879875  -0.07986187 -0.48549852 -1.3495215\n",
      " -0.19651534 -0.25371543 -1.9946752  -0.04403173 -0.40327218 -2.0071049\n",
      "  0.11651768 -0.37123048 -1.4539583  -0.17493677 -0.25367898 -1.2789217\n",
      " -0.11875985 -0.22244039 -1.3552815  -0.07625508 -0.2189771  -1.4712019\n",
      "  0.01945891 -0.2353634  -1.29538     0.15      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FDD8>\n",
      "tensor([[ 0.0239, -0.0313, -0.2153,  ...,  0.0466, -0.2257, -1.2533],\n",
      "        [ 0.0239, -0.0313, -0.2153,  ...,  0.0466, -0.2257, -1.2533],\n",
      "        [ 0.0239, -0.0313, -0.2153,  ...,  0.0466, -0.2257, -1.2533],\n",
      "        ...,\n",
      "        [-0.2045,  0.3466, -0.1601,  ..., -0.8942,  0.8334, -0.3581],\n",
      "        [-0.1498, -0.2145,  0.5325,  ..., -0.2322,  0.5498,  0.2224],\n",
      "        [-0.1498, -0.2145,  0.5325,  ..., -0.2322,  0.5498,  0.2224]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02394261 -0.03128098 -0.21532257  0.03637404 -0.1681694  -0.6227683\n",
      " -0.05996666 -0.34400576 -1.3553085  -0.20370115 -0.40528393 -1.6477247\n",
      " -0.37546217 -0.51093745 -2.1244552  -0.17421854 -0.642357   -1.5093186\n",
      "  0.01337433 -0.67149985 -1.3432794  -0.03198099 -0.6029171  -1.4039216\n",
      " -0.02280718 -0.7411097  -1.5164633  -0.13506074 -0.54164445 -1.4308519\n",
      " -0.058431   -0.58994484 -1.4025795  -0.07318492 -0.5670427  -1.49912\n",
      "  0.06658228 -0.5792142  -1.5393516  -0.05409939 -0.45963398 -1.2652963\n",
      " -0.15782407 -0.23696697 -1.8896902  -0.0120737  -0.38116112 -1.8941714\n",
      "  0.14714827 -0.35620752 -1.4001485  -0.14658166 -0.22734568 -1.2042611\n",
      " -0.08139986 -0.20800751 -1.2869941  -0.04046783 -0.2105462  -1.4054716\n",
      "  0.0466109  -0.22568719 -1.253287  ]\n",
      "data: [ 0.02394261 -0.03128098 -0.21532257  0.03637404 -0.16816941 -0.6227683\n",
      " -0.05996666 -0.34400576 -1.3553085  -0.20370115 -0.40528393 -1.6477247\n",
      " -0.37546217 -0.51093745 -2.1244552  -0.17421854 -0.64235705 -1.5093186\n",
      "  0.01337433 -0.67149985 -1.3432794  -0.03198099 -0.6029171  -1.4039216\n",
      " -0.02280718 -0.74110967 -1.5164633  -0.13506074 -0.54164445 -1.4308519\n",
      " -0.058431   -0.58994484 -1.4025795  -0.07318492 -0.5670427  -1.49912\n",
      "  0.06658228 -0.5792142  -1.5393517  -0.05409939 -0.45963398 -1.2652963\n",
      " -0.15782407 -0.23696697 -1.88969    -0.0120737  -0.38116112 -1.8941712\n",
      "  0.14714827 -0.3562075  -1.4001485  -0.14658166 -0.22734568 -1.2042611\n",
      " -0.08139986 -0.20800751 -1.2869942  -0.04046783 -0.2105462  -1.4054714\n",
      "  0.0466109  -0.2256872  -1.253287    0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0114, -0.0664, -0.2472,  ...,  0.0271, -0.2479, -1.2942],\n",
      "        [ 0.0114, -0.0664, -0.2472,  ...,  0.0271, -0.2479, -1.2942],\n",
      "        [ 0.0114, -0.0664, -0.2472,  ...,  0.0271, -0.2479, -1.2942],\n",
      "        ...,\n",
      "        [-0.3090,  0.2513, -0.3000,  ..., -0.8169,  0.7164, -0.4880],\n",
      "        [-0.1167, -0.0562,  0.6014,  ..., -0.2349,  0.7367,  0.2640],\n",
      "        [-0.1167, -0.0562,  0.6014,  ..., -0.2349,  0.7367,  0.2640]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01137023 -0.06637156 -0.24724682  0.03717667 -0.2006263  -0.6557169\n",
      " -0.06741492 -0.38653135 -1.4218414  -0.2095192  -0.45125014 -1.7087492\n",
      " -0.36842257 -0.5515937  -2.1957266  -0.18361127 -0.6741159  -1.576788\n",
      "  0.00678496 -0.7067818  -1.3900076  -0.03898333 -0.63905835 -1.4477748\n",
      " -0.04697705 -0.7761368  -1.5642627  -0.14754039 -0.57521445 -1.4961427\n",
      " -0.07387318 -0.6254903  -1.4638149  -0.09414987 -0.59658694 -1.5528859\n",
      "  0.04088284 -0.6148165  -1.5926446  -0.06920344 -0.48886538 -1.3293898\n",
      " -0.18104565 -0.25976968 -1.9672958  -0.03287525 -0.4088452  -1.9741385\n",
      "  0.12095606 -0.3796543  -1.4511735  -0.16502725 -0.2561427  -1.2621231\n",
      " -0.10020116 -0.22984187 -1.3379502  -0.0571526  -0.23282947 -1.4550656\n",
      "  0.02710215 -0.24791595 -1.2941653 ]\n",
      "data: [ 0.01137023 -0.06637156 -0.24724682  0.03717667 -0.2006263  -0.65571684\n",
      " -0.06741492 -0.38653138 -1.4218414  -0.2095192  -0.45125017 -1.7087493\n",
      " -0.3684226  -0.5515937  -2.1957266  -0.18361127 -0.6741159  -1.5767881\n",
      "  0.00678496 -0.70678174 -1.3900076  -0.03898333 -0.63905835 -1.4477748\n",
      " -0.04697705 -0.77613676 -1.5642627  -0.14754039 -0.57521445 -1.4961427\n",
      " -0.07387318 -0.6254903  -1.4638149  -0.09414987 -0.59658694 -1.5528859\n",
      "  0.04088284 -0.6148165  -1.5926445  -0.06920344 -0.48886535 -1.3293898\n",
      " -0.18104565 -0.25976968 -1.9672959  -0.03287525 -0.4088452  -1.9741385\n",
      "  0.12095606 -0.3796543  -1.4511735  -0.16502723 -0.2561427  -1.2621231\n",
      " -0.10020116 -0.22984189 -1.3379502  -0.0571526  -0.23282948 -1.4550656\n",
      "  0.02710215 -0.24791595 -1.2941651   0.17      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0059, -0.0363, -0.2393,  ...,  0.0432, -0.2288, -1.2763],\n",
      "        [ 0.0059, -0.0363, -0.2393,  ...,  0.0432, -0.2288, -1.2763],\n",
      "        [ 0.0059, -0.0363, -0.2393,  ...,  0.0432, -0.2288, -1.2763],\n",
      "        ...,\n",
      "        [-0.1916,  0.3516, -0.1647,  ..., -0.8527,  0.8390, -0.3785],\n",
      "        [-0.1482, -0.1960,  0.5444,  ..., -0.2414,  0.5629,  0.2211],\n",
      "        [-0.1482, -0.1960,  0.5444,  ..., -0.2414,  0.5629,  0.2211]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00594495 -0.03628188 -0.23926434  0.01956272 -0.17675601 -0.64458066\n",
      " -0.06395949 -0.35437202 -1.3756526  -0.20502402 -0.4139031  -1.6746788\n",
      " -0.37849376 -0.5316376  -2.1417735  -0.19833997 -0.6414379  -1.535551\n",
      "  0.01967691 -0.6680681  -1.3521104  -0.02939759 -0.60582614 -1.4073044\n",
      " -0.0223679  -0.73816717 -1.5223368  -0.15324207 -0.53597724 -1.4519552\n",
      " -0.06607234 -0.5901132  -1.4291724  -0.07234344 -0.5673207  -1.526197\n",
      "  0.06175731 -0.58898973 -1.5746136  -0.06079417 -0.45368046 -1.2812234\n",
      " -0.1692028  -0.2302889  -1.9131179  -0.01478368 -0.38345462 -1.9102216\n",
      "  0.14368656 -0.35286033 -1.4290503  -0.16120842 -0.21877007 -1.2202986\n",
      " -0.07925028 -0.20104183 -1.3010587  -0.03297161 -0.21558803 -1.4191822\n",
      "  0.04322781 -0.22881411 -1.276276  ]\n",
      "data: [ 0.00594495 -0.03628188 -0.23926434  0.01956272 -0.176756   -0.64458066\n",
      " -0.06395949 -0.35437202 -1.3756527  -0.20502402 -0.4139031  -1.6746788\n",
      " -0.37849376 -0.5316376  -2.1417735  -0.19833998 -0.6414379  -1.535551\n",
      "  0.01967691 -0.6680681  -1.3521104  -0.02939759 -0.60582614 -1.4073044\n",
      " -0.0223679  -0.73816717 -1.5223368  -0.15324207 -0.53597724 -1.4519553\n",
      " -0.06607234 -0.5901132  -1.4291724  -0.07234344 -0.5673207  -1.526197\n",
      "  0.06175731 -0.58898973 -1.5746137  -0.06079417 -0.45368046 -1.2812234\n",
      " -0.1692028  -0.2302889  -1.9131179  -0.01478368 -0.38345462 -1.9102216\n",
      "  0.14368656 -0.35286033 -1.4290503  -0.16120842 -0.21877007 -1.2202986\n",
      " -0.07925028 -0.20104183 -1.3010587  -0.03297161 -0.21558803 -1.4191822\n",
      "  0.04322781 -0.22881411 -1.276276    0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[ 0.0057, -0.0886, -0.2359,  ...,  0.0261, -0.2717, -1.2943],\n",
      "        [ 0.0057, -0.0886, -0.2359,  ...,  0.0261, -0.2717, -1.2943],\n",
      "        [ 0.0057, -0.0886, -0.2359,  ...,  0.0261, -0.2717, -1.2943],\n",
      "        ...,\n",
      "        [-0.3265,  0.2158, -0.3643,  ..., -0.8209,  0.6672, -0.5315],\n",
      "        [-0.1376, -0.0841,  0.5991,  ..., -0.2498,  0.7055,  0.2568],\n",
      "        [-0.1376, -0.0841,  0.5991,  ..., -0.2498,  0.7055,  0.2568]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00568414 -0.08858857 -0.23594591  0.02708668 -0.2279847  -0.65670484\n",
      " -0.06226032 -0.40786123 -1.4051393  -0.20208333 -0.46989155 -1.6989813\n",
      " -0.36750725 -0.57930267 -2.1756296  -0.19350389 -0.6918194  -1.5617558\n",
      "  0.0149745  -0.71934307 -1.3706614  -0.03245257 -0.6554198  -1.4275925\n",
      " -0.03641355 -0.78672576 -1.5437948  -0.15420489 -0.58839476 -1.4798814\n",
      " -0.07327312 -0.64031243 -1.4541439  -0.08784895 -0.61454046 -1.5474602\n",
      "  0.04346867 -0.6337117  -1.5950457  -0.06997847 -0.5055869  -1.3102418\n",
      " -0.17821549 -0.2789694  -1.9375938  -0.03078853 -0.42823297 -1.937951\n",
      "  0.12104359 -0.39785472 -1.4496744  -0.16768987 -0.27090073 -1.246061\n",
      " -0.09451103 -0.24803594 -1.3246398  -0.04862496 -0.25800133 -1.4417293\n",
      "  0.02608547 -0.27168834 -1.2943256 ]\n",
      "data: [ 0.00568414 -0.08858857 -0.23594591  0.02708668 -0.2279847  -0.65670484\n",
      " -0.06226032 -0.40786126 -1.4051393  -0.20208333 -0.46989155 -1.6989813\n",
      " -0.36750725 -0.57930267 -2.1756296  -0.1935039  -0.6918194  -1.5617558\n",
      "  0.0149745  -0.719343   -1.3706613  -0.03245257 -0.6554198  -1.4275925\n",
      " -0.03641355 -0.78672576 -1.5437948  -0.15420489 -0.58839476 -1.4798814\n",
      " -0.07327312 -0.64031243 -1.4541439  -0.08784895 -0.61454046 -1.5474602\n",
      "  0.04346867 -0.6337117  -1.5950456  -0.06997847 -0.5055869  -1.3102418\n",
      " -0.17821549 -0.2789694  -1.9375938  -0.03078853 -0.42823297 -1.9379508\n",
      "  0.12104359 -0.39785472 -1.4496744  -0.16768987 -0.27090073 -1.246061\n",
      " -0.09451103 -0.24803595 -1.3246398  -0.04862496 -0.25800133 -1.4417293\n",
      "  0.02608547 -0.27168834 -1.2943256   0.19      ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[ 0.0294, -0.0693, -0.2301,  ...,  0.0464, -0.2594, -1.2498],\n",
      "        [ 0.0294, -0.0693, -0.2301,  ...,  0.0464, -0.2594, -1.2498],\n",
      "        [ 0.0294, -0.0693, -0.2301,  ...,  0.0464, -0.2594, -1.2498],\n",
      "        ...,\n",
      "        [-0.1352,  0.3906, -0.1465,  ..., -0.7293,  0.8910, -0.4097],\n",
      "        [-0.1420, -0.1668,  0.5806,  ..., -0.2436,  0.6062,  0.2322],\n",
      "        [-0.1420, -0.1668,  0.5806,  ..., -0.2436,  0.6062,  0.2322]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02938665 -0.06927525 -0.23013915  0.05357434 -0.18804555 -0.607044\n",
      " -0.0640386  -0.3907786  -1.3932365  -0.20841219 -0.45499748 -1.6820849\n",
      " -0.36351842 -0.549121   -2.171799   -0.16020803 -0.6925251  -1.54549\n",
      "  0.01063946 -0.74131995 -1.3874277  -0.03959849 -0.6697106  -1.4459944\n",
      " -0.04561781 -0.8266799  -1.5651968  -0.12134619 -0.6016968  -1.4559704\n",
      " -0.06166451 -0.6503561  -1.426917   -0.08157521 -0.6221718  -1.5144693\n",
      "  0.05159412 -0.64442396 -1.5404295  -0.04536697 -0.5020546  -1.2950352\n",
      " -0.17873527 -0.27298957 -2.0009127  -0.015772   -0.43052006 -2.0190442\n",
      "  0.1434416  -0.39915    -1.4064761  -0.14858724 -0.27468848 -1.2219706\n",
      " -0.08742175 -0.24769586 -1.31113    -0.05260602 -0.2459687  -1.4263986\n",
      "  0.04635625 -0.2594483  -1.2498344 ]\n",
      "data: [ 0.02938665 -0.06927525 -0.23013917  0.05357434 -0.18804555 -0.607044\n",
      " -0.0640386  -0.39077863 -1.3932365  -0.20841219 -0.45499748 -1.6820849\n",
      " -0.36351842 -0.549121   -2.171799   -0.16020803 -0.6925251  -1.5454899\n",
      "  0.01063946 -0.74131995 -1.3874277  -0.03959849 -0.6697105  -1.4459944\n",
      " -0.04561781 -0.82667994 -1.5651966  -0.12134619 -0.6016968  -1.4559704\n",
      " -0.06166451 -0.6503561  -1.426917   -0.08157521 -0.6221718  -1.5144693\n",
      "  0.05159412 -0.64442396 -1.5404296  -0.04536697 -0.5020546  -1.2950352\n",
      " -0.17873527 -0.27298957 -2.0009127  -0.015772   -0.43052006 -2.0190442\n",
      "  0.1434416  -0.39915    -1.4064761  -0.14858724 -0.27468848 -1.2219706\n",
      " -0.08742175 -0.24769586 -1.31113    -0.05260602 -0.2459687  -1.4263986\n",
      "  0.04635625 -0.2594483  -1.2498344   0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.028 3.034 3.034 ... 3.034 3.035 3.035]\n",
      " [2.996 0.    0.    ... 3.017 3.015 3.015]\n",
      " [0.    0.    0.    ... 3.003 2.997 2.997]\n",
      " ...\n",
      " [2.675 2.669 2.669 ... 2.63  2.634 2.634]\n",
      " [2.667 2.658 2.658 ... 2.628 2.631 2.631]\n",
      " [2.66  2.658 2.658 ... 2.634 2.636 2.636]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[ 0.0171, -0.0174, -0.2292,  ...,  0.0401, -0.2102, -1.2607],\n",
      "        [ 0.0171, -0.0174, -0.2292,  ...,  0.0401, -0.2102, -1.2607],\n",
      "        [ 0.0171, -0.0174, -0.2292,  ...,  0.0401, -0.2102, -1.2607],\n",
      "        ...,\n",
      "        [-0.1845,  0.2965, -0.0777,  ..., -0.8214,  0.7397, -0.2555],\n",
      "        [-0.1385, -0.1582,  0.5493,  ..., -0.1973,  0.6088,  0.2082],\n",
      "        [-0.1385, -0.1582,  0.5493,  ..., -0.1973,  0.6088,  0.2082]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0171468  -0.01736991 -0.22917752  0.02947116 -0.14984067 -0.63332725\n",
      " -0.07441956 -0.34151226 -1.3867683  -0.22118196 -0.40572643 -1.6834462\n",
      " -0.3937736  -0.51333815 -2.1581042  -0.18709925 -0.6344318  -1.5374537\n",
      "  0.00638203 -0.6742419  -1.352134   -0.04383609 -0.60712045 -1.4101381\n",
      " -0.04730592 -0.7542515  -1.527811   -0.14397165 -0.5351474  -1.4500821\n",
      " -0.07279253 -0.5890913  -1.4203639  -0.08814267 -0.565513   -1.515707\n",
      "  0.04846983 -0.58500344 -1.55269    -0.05920677 -0.44498008 -1.2837472\n",
      " -0.17926139 -0.22122796 -1.9460714  -0.02347808 -0.37505108 -1.953327\n",
      "  0.13838166 -0.3467728  -1.4108584  -0.15868115 -0.21216497 -1.2165134\n",
      " -0.09033271 -0.19130832 -1.3028767  -0.04933346 -0.1974168  -1.4194694\n",
      "  0.04006791 -0.2101889  -1.2607293 ]\n",
      "data: [ 0.    0.    0.    0.    0.    0.   -8.46 -0.61  0.1  -8.42 -0.3   0.38\n",
      " -8.44 -0.14  0.72 -8.53 -0.65  0.58 -8.52 -0.31  1.02 -8.48 -0.06  0.95\n",
      "  0.    0.    0.   -8.45 -0.52  0.06 -8.61 -0.14  0.8  -8.82  0.09  1.5\n",
      "  0.    0.    0.   -8.75 -0.47  0.62 -8.81 -0.1   1.07 -8.8   0.15  1.05\n",
      "  0.    0.    0.    0.    0.    0.   -7.6   0.17 -2.81 -7.63  0.31 -2.71\n",
      "  0.    0.    0.    0.  ]\n",
      "mask: [0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[-0.2816, -0.0488, -0.1691,  ..., -0.2471, -0.2301, -0.6500],\n",
      "        [-0.2816, -0.0488, -0.1691,  ..., -0.2471, -0.2301, -0.6500],\n",
      "        [-0.2816, -0.0488, -0.1691,  ..., -0.2471, -0.2301, -0.6500],\n",
      "        ...,\n",
      "        [ 0.4689,  0.1797,  0.1205,  ..., -0.8369,  0.3846,  1.1313],\n",
      "        [ 0.4761,  0.1755,  0.1468,  ..., -0.8331,  0.4379,  1.0892],\n",
      "        [ 0.4761,  0.1755,  0.1468,  ..., -0.8331,  0.4379,  1.0892]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.28158638 -0.0488023  -0.16910145 -0.36200875 -0.17189893 -0.58977807\n",
      " -0.39095274 -0.26041842 -0.7993145  -0.41816318 -0.36564514 -0.8408325\n",
      " -0.4198986  -0.42162788 -1.005614   -0.41485903 -0.28842625 -1.0799657\n",
      " -0.23579425 -0.31075013 -0.49964848 -0.28054255 -0.43200815 -0.510266\n",
      " -0.36073685 -0.44608524 -0.61491203 -0.39232093 -0.21030739 -1.0786285\n",
      " -0.40137398 -0.2793372  -1.0371735  -0.41426477 -0.35568026 -1.035018\n",
      " -0.386344   -0.46170193 -1.0029961  -0.38529998 -0.15418561 -0.9845083\n",
      " -0.39196604 -0.18104032 -0.90971226 -0.38979036 -0.24522579 -0.91184944\n",
      " -0.30398172 -0.34240836 -0.82105136 -0.3675751  -0.03947402 -0.8587854\n",
      " -0.31246522 -0.09233785 -0.76397    -0.31390652 -0.13705117 -0.7680932\n",
      " -0.24709597 -0.23008211 -0.6500087 ]\n",
      "init: [-0.28158638 -0.0488023  -0.16910145 -0.36200875 -0.17189893 -0.58977807\n",
      " -0.39095274 -0.26041842 -0.7993145  -0.41816318 -0.36564514 -0.8408325\n",
      " -0.4198986  -0.42162788 -1.005614   -0.41485903 -0.28842625 -1.0799657\n",
      " -0.23579425 -0.31075013 -0.49964848 -0.28054255 -0.43200815 -0.510266\n",
      " -0.36073685 -0.44608524 -0.61491203 -0.39232093 -0.21030739 -1.0786285\n",
      " -0.40137398 -0.2793372  -1.0371735  -0.41426477 -0.35568026 -1.035018\n",
      " -0.386344   -0.46170193 -1.0029961  -0.38529998 -0.15418561 -0.9845083\n",
      " -0.39196604 -0.18104032 -0.90971226 -0.38979036 -0.24522579 -0.91184944\n",
      " -0.30398172 -0.34240836 -0.82105136 -0.3675751  -0.03947402 -0.8587854\n",
      " -0.31246522 -0.09233785 -0.76397    -0.31390652 -0.13705117 -0.7680932\n",
      " -0.24709597 -0.23008211 -0.6500087 ]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [-0.28158638 -0.0488023  -0.16910145 -0.36200875 -0.17189893 -0.58977807\n",
      " -0.3909527  -0.26041842 -0.7993145  -0.41816318 -0.36564514 -0.8408325\n",
      " -0.4198986  -0.42162788 -1.005614   -0.414859   -0.28842625 -1.0799657\n",
      " -0.23579425 -0.31075013 -0.49964848 -0.28054255 -0.43200815 -0.510266\n",
      " -0.36073685 -0.44608524 -0.61491203 -0.39232093 -0.21030739 -1.0786285\n",
      " -0.40137398 -0.2793372  -1.0371735  -0.41426477 -0.3556803  -1.035018\n",
      " -0.386344   -0.46170193 -1.0029961  -0.38529998 -0.15418561 -0.9845083\n",
      " -0.39196604 -0.18104033 -0.9097122  -0.38979036 -0.24522579 -0.91184944\n",
      " -0.30398172 -0.34240836 -0.82105136 -0.3675751  -0.03947402 -0.8587854\n",
      " -0.31246522 -0.09233785 -0.76397    -0.31390652 -0.13705117 -0.7680933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.24709597 -0.23008211 -0.6500087   0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.1319, -0.2304,  0.1002,  ...,  0.2415, -0.3807, -0.9350],\n",
      "        [ 0.1319, -0.2304,  0.1002,  ...,  0.2415, -0.3807, -0.9350],\n",
      "        [ 0.1319, -0.2304,  0.1002,  ...,  0.2415, -0.3807, -0.9350],\n",
      "        ...,\n",
      "        [-0.0282,  0.0057, -0.4391,  ..., -0.3467,  0.8690, -1.0598],\n",
      "        [-0.1855,  0.1991,  0.4314,  ..., -1.0253,  0.7348,  0.2183],\n",
      "        [-0.1855,  0.1991,  0.4314,  ..., -1.0253,  0.7348,  0.2183]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.1318639  -0.2303869   0.10023476  0.17880651 -0.37416744 -0.3468114\n",
      "  0.14634539 -0.5011836  -1.0269408   0.02203929 -0.521203   -1.3388352\n",
      " -0.12351906 -0.665187   -1.8197253  -0.08164009 -0.77383995 -1.180109\n",
      "  0.21407175 -0.73845387 -1.0411699   0.16478896 -0.67560184 -1.0969927\n",
      "  0.18121313 -0.7677082  -1.2208765  -0.03224665 -0.6703857  -1.0992777\n",
      "  0.11265976 -0.7065619  -1.1191392   0.13930449 -0.6510037  -1.205003\n",
      "  0.25780737 -0.7011914  -1.276401    0.10365962 -0.5913057  -0.90933543\n",
      "  0.01557708 -0.33712527 -1.5076783   0.20399016 -0.5052834  -1.4797626\n",
      "  0.34336966 -0.4425589  -1.1323743  -0.00536409 -0.3755792  -0.85421306\n",
      "  0.1346611  -0.3408438  -0.91461223  0.19618735 -0.37667382 -1.0537164\n",
      "  0.2415272  -0.3806727  -0.93498284]\n",
      "data: [ 0.1318639  -0.23038691  0.10023477  0.17880651 -0.37416744 -0.3468114\n",
      "  0.14634539 -0.5011836  -1.0269408   0.02203929 -0.521203   -1.3388352\n",
      " -0.12351906 -0.665187   -1.8197254  -0.08164009 -0.77383995 -1.180109\n",
      "  0.21407175 -0.7384538  -1.0411699   0.16478898 -0.6756018  -1.0969927\n",
      "  0.18121313 -0.7677082  -1.2208765  -0.03224665 -0.6703857  -1.0992777\n",
      "  0.11265976 -0.70656186 -1.1191392   0.13930449 -0.6510037  -1.205003\n",
      "  0.25780737 -0.7011914  -1.276401    0.10365962 -0.5913057  -0.9093354\n",
      "  0.01557708 -0.33712527 -1.5076783   0.20399016 -0.5052834  -1.4797626\n",
      "  0.34336966 -0.44255888 -1.1323743  -0.00536409 -0.37557924 -0.854213\n",
      "  0.1346611  -0.3408438  -0.9146122   0.19618735 -0.37667382 -1.0537164\n",
      "  0.2415272  -0.3806727  -0.93498284  0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0404, -0.0882, -0.1656,  ..., -0.0390, -0.3125, -1.2017],\n",
      "        [ 0.0404, -0.0882, -0.1656,  ..., -0.0390, -0.3125, -1.2017],\n",
      "        [ 0.0404, -0.0882, -0.1656,  ..., -0.0390, -0.3125, -1.2017],\n",
      "        ...,\n",
      "        [-0.3536,  0.3142, -0.3092,  ..., -0.5533,  0.8565, -0.7709],\n",
      "        [-0.2351,  0.0553,  0.4538,  ..., -0.0258,  0.8021,  0.0126],\n",
      "        [-0.2351,  0.0553,  0.4538,  ..., -0.0258,  0.8021,  0.0126]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04043444 -0.08818559 -0.1655556  -0.00940496 -0.24634272 -0.58488333\n",
      " -0.17071691 -0.4665178  -1.3535826  -0.3520116  -0.5553601  -1.64114\n",
      " -0.5846191  -0.64058894 -2.1336603  -0.20067713 -0.73461276 -1.5513\n",
      " -0.14889485 -0.81729454 -1.4135203  -0.18941629 -0.71243703 -1.4818952\n",
      " -0.16330263 -0.9150678  -1.5643425  -0.17030716 -0.61426246 -1.4681392\n",
      " -0.16375771 -0.6716799  -1.3718851  -0.22296324 -0.69595444 -1.4719095\n",
      " -0.06244195 -0.64612144 -1.4722996  -0.11599431 -0.5491049  -1.3249655\n",
      " -0.23585594 -0.34925702 -1.9117243  -0.14222038 -0.4924497  -1.9262285\n",
      "  0.02804362 -0.48233837 -1.3169415  -0.18182054 -0.3116151  -1.2506561\n",
      " -0.19515532 -0.30905378 -1.317559   -0.17171761 -0.2878957  -1.4191027\n",
      " -0.03904781 -0.31254452 -1.2017195 ]\n",
      "data: [ 0.04043444 -0.08818559 -0.1655556  -0.00940496 -0.24634272 -0.58488333\n",
      " -0.17071691 -0.4665178  -1.3535826  -0.3520116  -0.5553601  -1.64114\n",
      " -0.5846191  -0.64058894 -2.1336603  -0.20067713 -0.7346127  -1.5513\n",
      " -0.14889485 -0.81729454 -1.4135203  -0.18941629 -0.71243703 -1.4818951\n",
      " -0.16330263 -0.91506785 -1.5643425  -0.17030716 -0.61426246 -1.4681392\n",
      " -0.16375771 -0.6716799  -1.3718851  -0.22296324 -0.69595444 -1.4719095\n",
      " -0.06244196 -0.64612144 -1.4722995  -0.11599431 -0.5491049  -1.3249655\n",
      " -0.23585594 -0.34925702 -1.9117244  -0.14222038 -0.49244967 -1.9262285\n",
      "  0.02804362 -0.48233837 -1.3169415  -0.18182054 -0.3116151  -1.2506561\n",
      " -0.19515532 -0.30905378 -1.317559   -0.1717176  -0.2878957  -1.4191027\n",
      " -0.03904781 -0.31254452 -1.2017195   0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[-4.6998e-04,  9.8541e-02, -1.6500e-01,  ...,  6.6502e-02,\n",
      "         -1.1896e-01, -1.1011e+00],\n",
      "        [-4.6998e-04,  9.8541e-02, -1.6500e-01,  ...,  6.6502e-02,\n",
      "         -1.1896e-01, -1.1011e+00],\n",
      "        [-4.6998e-04,  9.8541e-02, -1.6500e-01,  ...,  6.6502e-02,\n",
      "         -1.1896e-01, -1.1011e+00],\n",
      "        ...,\n",
      "        [-1.6090e-01,  2.9696e-01, -7.7101e-03,  ..., -9.3079e-01,\n",
      "          8.8677e-01, -3.5259e-01],\n",
      "        [-1.6641e-01, -2.7535e-01,  5.2900e-01,  ..., -3.0949e-01,\n",
      "          3.8612e-01,  2.1143e-01],\n",
      "        [-1.6641e-01, -2.7535e-01,  5.2900e-01,  ..., -3.0949e-01,\n",
      "          3.8612e-01,  2.1143e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-4.69977967e-04  9.85407159e-02 -1.65001303e-01  6.51182607e-03\n",
      "  8.72448087e-04 -4.65353817e-01 -1.56562731e-01 -2.11984575e-01\n",
      " -1.28988194e+00 -3.06411147e-01 -2.79586732e-01 -1.56761098e+00\n",
      " -4.68125820e-01 -3.58485401e-01 -2.05538511e+00 -1.82920128e-01\n",
      " -5.41720748e-01 -1.44247341e+00 -6.07262552e-02 -6.01284921e-01\n",
      " -1.33194852e+00 -9.03936923e-02 -5.15671015e-01 -1.39327097e+00\n",
      " -4.84537035e-02 -6.97652340e-01 -1.51530766e+00 -1.44376308e-01\n",
      " -4.57875371e-01 -1.35094976e+00 -8.73658434e-02 -5.04446328e-01\n",
      " -1.30595160e+00 -8.69422257e-02 -4.77377355e-01 -1.39417434e+00\n",
      "  1.10577956e-01 -4.93685961e-01 -1.41076899e+00 -7.48550519e-02\n",
      " -3.62383842e-01 -1.19140625e+00 -2.13302895e-01 -1.28966749e-01\n",
      " -1.96381402e+00 -1.59293413e-02 -2.89068788e-01 -2.00007653e+00\n",
      "  2.09441572e-01 -2.68140912e-01 -1.27079725e+00 -1.78569883e-01\n",
      " -1.33016527e-01 -1.10173166e+00 -1.27531126e-01 -1.08462438e-01\n",
      " -1.19555140e+00 -8.94266069e-02 -9.06354636e-02 -1.31738997e+00\n",
      "  6.65019527e-02 -1.18960276e-01 -1.10107398e+00]\n",
      "data: [-4.69977967e-04  9.85407159e-02 -1.65001303e-01  6.51182607e-03\n",
      "  8.72448087e-04 -4.65353817e-01 -1.56562731e-01 -2.11984575e-01\n",
      " -1.28988194e+00 -3.06411147e-01 -2.79586732e-01 -1.56761098e+00\n",
      " -4.68125850e-01 -3.58485401e-01 -2.05538511e+00 -1.82920128e-01\n",
      " -5.41720748e-01 -1.44247341e+00 -6.07262552e-02 -6.01284921e-01\n",
      " -1.33194852e+00 -9.03936923e-02 -5.15671015e-01 -1.39327097e+00\n",
      " -4.84537035e-02 -6.97652340e-01 -1.51530766e+00 -1.44376308e-01\n",
      " -4.57875371e-01 -1.35094976e+00 -8.73658434e-02 -5.04446328e-01\n",
      " -1.30595160e+00 -8.69422257e-02 -4.77377355e-01 -1.39417434e+00\n",
      "  1.10577956e-01 -4.93685961e-01 -1.41076899e+00 -7.48550519e-02\n",
      " -3.62383842e-01 -1.19140625e+00 -2.13302895e-01 -1.28966749e-01\n",
      " -1.96381414e+00 -1.59293413e-02 -2.89068788e-01 -2.00007653e+00\n",
      "  2.09441572e-01 -2.68140912e-01 -1.27079725e+00 -1.78569883e-01\n",
      " -1.33016527e-01 -1.10173166e+00 -1.27531126e-01 -1.08462438e-01\n",
      " -1.19555140e+00 -8.94266069e-02 -9.06354636e-02 -1.31738997e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6.65019527e-02 -1.18960276e-01 -1.10107398e+00  3.99999991e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0449, -0.0780, -0.1768,  ...,  0.0860, -0.2435, -1.2960],\n",
      "        [ 0.0449, -0.0780, -0.1768,  ...,  0.0860, -0.2435, -1.2960],\n",
      "        [ 0.0449, -0.0780, -0.1768,  ...,  0.0860, -0.2435, -1.2960],\n",
      "        ...,\n",
      "        [-0.3044,  0.3837, -0.0086,  ..., -0.9048,  0.8060, -0.1288],\n",
      "        [-0.2819,  0.0716,  0.3699,  ..., -0.3789,  0.8282,  0.1045],\n",
      "        [-0.2819,  0.0716,  0.3699,  ..., -0.3789,  0.8282,  0.1045]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04491925 -0.07803901 -0.17680395  0.04724599 -0.24454732 -0.6642203\n",
      "  0.007253   -0.3808941  -1.3073819  -0.13302815 -0.42567867 -1.6111269\n",
      " -0.3152041  -0.5647667  -2.0653884  -0.18280578 -0.6566229  -1.4575593\n",
      "  0.08149973 -0.65212715 -1.2398472   0.02178811 -0.5810133  -1.2938523\n",
      "  0.02492026 -0.67839915 -1.3990304  -0.13195926 -0.5428573  -1.3934603\n",
      " -0.01906124 -0.5844814  -1.3823087  -0.02807032 -0.55256224 -1.4823711\n",
      "  0.07715163 -0.5639212  -1.5413382  -0.01723249 -0.4778277  -1.2291074\n",
      " -0.08378207 -0.24698463 -1.7241089   0.03295127 -0.38188127 -1.6965528\n",
      "  0.16123998 -0.3433109  -1.4277079  -0.1075724  -0.23862782 -1.1861551\n",
      " -0.00521214 -0.21997078 -1.2814205   0.04494075 -0.24512349 -1.4002957\n",
      "  0.08604647 -0.24348076 -1.2960072 ]\n",
      "data: [ 0.04491925 -0.07803901 -0.17680395  0.04724599 -0.24454732 -0.6642203\n",
      "  0.007253   -0.3808941  -1.3073819  -0.13302815 -0.42567867 -1.6111269\n",
      " -0.3152041  -0.5647667  -2.0653884  -0.18280579 -0.65662295 -1.4575593\n",
      "  0.08149973 -0.65212715 -1.2398472   0.02178811 -0.5810133  -1.2938523\n",
      "  0.02492026 -0.67839915 -1.3990304  -0.13195926 -0.5428573  -1.3934603\n",
      " -0.01906124 -0.5844814  -1.3823086  -0.02807032 -0.55256224 -1.4823711\n",
      "  0.07715163 -0.5639212  -1.5413382  -0.01723249 -0.47782767 -1.2291074\n",
      " -0.08378207 -0.24698463 -1.7241089   0.03295127 -0.38188127 -1.6965528\n",
      "  0.16123998 -0.3433109  -1.427708   -0.10757241 -0.23862782 -1.1861551\n",
      " -0.00521214 -0.21997078 -1.2814205   0.04494075 -0.24512348 -1.4002957\n",
      "  0.08604648 -0.24348076 -1.296007    0.05      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0510, -0.0838, -0.3019,  ...,  0.0710, -0.2628, -1.3410],\n",
      "        [ 0.0510, -0.0838, -0.3019,  ...,  0.0710, -0.2628, -1.3410],\n",
      "        [ 0.0510, -0.0838, -0.3019,  ...,  0.0710, -0.2628, -1.3410],\n",
      "        ...,\n",
      "        [-0.1515,  0.4691, -0.0997,  ..., -0.6862,  0.9805, -0.4128],\n",
      "        [-0.1861, -0.0917,  0.5990,  ..., -0.2894,  0.7068,  0.2233],\n",
      "        [-0.1861, -0.0917,  0.5990,  ..., -0.2894,  0.7068,  0.2233]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.05103404 -0.08380418 -0.30193368  0.08089772 -0.21199858 -0.68441975\n",
      " -0.03867421 -0.4133027  -1.4905689  -0.18734647 -0.47819763 -1.7771769\n",
      " -0.34239668 -0.57614017 -2.276234   -0.14830728 -0.6968262  -1.6627011\n",
      "  0.04275323 -0.73992956 -1.474252   -0.00376567 -0.66901064 -1.5283866\n",
      " -0.01159112 -0.81252074 -1.6486404  -0.10933118 -0.5980408  -1.5744762\n",
      " -0.03967734 -0.6506561  -1.5395975  -0.05323449 -0.62013376 -1.6233339\n",
      "  0.08592072 -0.6435907  -1.6564484  -0.02740473 -0.5054305  -1.4045434\n",
      " -0.15445136 -0.26936856 -2.072768    0.00771895 -0.43095773 -2.0828118\n",
      "  0.17242621 -0.3945618  -1.5105653  -0.13360634 -0.27151018 -1.3300269\n",
      " -0.06525558 -0.2412515  -1.4025078  -0.02158034 -0.24692848 -1.5174711\n",
      "  0.07101654 -0.26282603 -1.3409743 ]\n",
      "data: [ 0.05103404 -0.08380418 -0.30193368  0.08089772 -0.21199858 -0.6844198\n",
      " -0.03867421 -0.4133027  -1.4905689  -0.18734647 -0.47819763 -1.7771769\n",
      " -0.34239665 -0.57614017 -2.276234   -0.14830728 -0.6968262  -1.6627011\n",
      "  0.04275323 -0.73992956 -1.474252   -0.00376567 -0.66901064 -1.5283866\n",
      " -0.01159112 -0.81252074 -1.6486404  -0.10933118 -0.5980408  -1.5744764\n",
      " -0.03967734 -0.6506561  -1.5395975  -0.05323449 -0.62013376 -1.6233339\n",
      "  0.08592072 -0.6435907  -1.6564484  -0.02740473 -0.5054305  -1.4045434\n",
      " -0.15445136 -0.26936856 -2.072768    0.00771895 -0.4309577  -2.0828118\n",
      "  0.17242621 -0.3945618  -1.5105653  -0.13360634 -0.27151018 -1.3300269\n",
      " -0.06525558 -0.24125151 -1.4025078  -0.02158034 -0.24692848 -1.517471\n",
      "  0.07101654 -0.26282603 -1.3409743   0.06      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[-0.0089, -0.0991, -0.2427,  ...,  0.0565, -0.2851, -1.3054],\n",
      "        [-0.0089, -0.0991, -0.2427,  ...,  0.0565, -0.2851, -1.3054],\n",
      "        [-0.0089, -0.0991, -0.2427,  ...,  0.0565, -0.2851, -1.3054],\n",
      "        ...,\n",
      "        [-0.0786,  0.4825, -0.1180,  ..., -0.7055,  0.9671, -0.3189],\n",
      "        [-0.1318, -0.0591,  0.5813,  ..., -0.2361,  0.6446,  0.2756],\n",
      "        [-0.1318, -0.0591,  0.5813,  ..., -0.2361,  0.6446,  0.2756]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-8.9161834e-03 -9.9076636e-02 -2.4265632e-01  1.5095931e-02\n",
      " -2.5559777e-01 -6.7174685e-01  4.6350714e-04 -4.0464479e-01\n",
      " -1.3726841e+00 -1.3258477e-01 -4.5167291e-01 -1.7013468e+00\n",
      " -3.0324626e-01 -6.0851091e-01 -2.1638045e+00 -2.2266352e-01\n",
      " -6.6576946e-01 -1.5659418e+00  1.0200712e-01 -6.6310126e-01\n",
      " -1.3402822e+00  2.7866200e-02 -6.1958158e-01 -1.3888507e+00\n",
      "  2.1125406e-02 -7.1698302e-01 -1.5113436e+00 -1.6604748e-01\n",
      " -5.4968643e-01 -1.4735817e+00 -3.6010534e-02 -6.1297029e-01\n",
      " -1.4755629e+00 -3.9905213e-02 -5.8805120e-01 -1.5812194e+00\n",
      "  5.0433740e-02 -6.3538677e-01 -1.6469053e+00 -3.5929359e-02\n",
      " -4.7232956e-01 -1.2781849e+00 -1.3752732e-01 -2.4516389e-01\n",
      " -1.8724041e+00  8.9370310e-03 -4.1428459e-01 -1.8399656e+00\n",
      "  1.3970935e-01 -3.7796116e-01 -1.4766790e+00 -1.5382294e-01\n",
      " -2.3450546e-01 -1.2247902e+00 -1.3567388e-02 -2.2686227e-01\n",
      " -1.2879192e+00  3.4134984e-02 -2.7933446e-01 -1.4042242e+00\n",
      "  5.6518398e-02 -2.8508288e-01 -1.3053516e+00]\n",
      "data: [-8.9161834e-03 -9.9076636e-02 -2.4265632e-01  1.5095931e-02\n",
      " -2.5559777e-01 -6.7174685e-01  4.6350714e-04 -4.0464479e-01\n",
      " -1.3726841e+00 -1.3258477e-01 -4.5167291e-01 -1.7013468e+00\n",
      " -3.0324626e-01 -6.0851091e-01 -2.1638045e+00 -2.2266352e-01\n",
      " -6.6576940e-01 -1.5659418e+00  1.0200712e-01 -6.6310126e-01\n",
      " -1.3402821e+00  2.7866200e-02 -6.1958158e-01 -1.3888507e+00\n",
      "  2.1125408e-02 -7.1698302e-01 -1.5113435e+00 -1.6604748e-01\n",
      " -5.4968643e-01 -1.4735817e+00 -3.6010534e-02 -6.1297029e-01\n",
      " -1.4755629e+00 -3.9905213e-02 -5.8805120e-01 -1.5812194e+00\n",
      "  5.0433740e-02 -6.3538677e-01 -1.6469054e+00 -3.5929359e-02\n",
      " -4.7232956e-01 -1.2781849e+00 -1.3752732e-01 -2.4516387e-01\n",
      " -1.8724042e+00  8.9370310e-03 -4.1428459e-01 -1.8399655e+00\n",
      "  1.3970935e-01 -3.7796116e-01 -1.4766790e+00 -1.5382294e-01\n",
      " -2.3450546e-01 -1.2247902e+00 -1.3567388e-02 -2.2686225e-01\n",
      " -1.2879192e+00  3.4134984e-02 -2.7933446e-01 -1.4042240e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5.6518398e-02 -2.8508288e-01 -1.3053516e+00  7.0000000e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FAC8>\n",
      "tensor([[ 0.0418, -0.1188, -0.2645,  ...,  0.0624, -0.3007, -1.3431],\n",
      "        [ 0.0418, -0.1188, -0.2645,  ...,  0.0624, -0.3007, -1.3431],\n",
      "        [ 0.0418, -0.1188, -0.2645,  ...,  0.0624, -0.3007, -1.3431],\n",
      "        ...,\n",
      "        [-0.1847,  0.4511, -0.1289,  ..., -0.7168,  0.9648, -0.4159],\n",
      "        [-0.1849, -0.1220,  0.6352,  ..., -0.2521,  0.6449,  0.2897],\n",
      "        [-0.1849, -0.1220,  0.6352,  ..., -0.2521,  0.6449,  0.2897]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 4.17801999e-02 -1.18841186e-01 -2.64512271e-01  5.61653785e-02\n",
      " -2.69047052e-01 -7.03698039e-01 -1.98578984e-02 -4.54274893e-01\n",
      " -1.44417644e+00 -1.60279542e-01 -5.16141891e-01 -1.74335504e+00\n",
      " -3.33897710e-01 -6.37135863e-01 -2.20442557e+00 -1.68985754e-01\n",
      " -7.23729551e-01 -1.60918927e+00  6.51101544e-02 -7.53362715e-01\n",
      " -1.39930415e+00  1.46699771e-02 -6.93006992e-01 -1.44911480e+00\n",
      "  1.28940120e-02 -8.17836404e-01 -1.56364298e+00 -1.24130033e-01\n",
      " -6.10297024e-01 -1.52357554e+00 -3.56027558e-02 -6.68171823e-01\n",
      " -1.49668479e+00 -3.98165807e-02 -6.45457506e-01 -1.58925962e+00\n",
      "  8.49436447e-02 -6.68452978e-01 -1.64359736e+00 -2.91736871e-02\n",
      " -5.27997017e-01 -1.35271764e+00 -1.40249789e-01 -3.03778023e-01\n",
      " -1.96283484e+00  8.84733349e-03 -4.59426641e-01 -1.95341587e+00\n",
      "  1.60147548e-01 -4.20041919e-01 -1.49823999e+00 -1.36133075e-01\n",
      " -2.86612988e-01 -1.28775072e+00 -5.00724688e-02 -2.65774906e-01\n",
      " -1.36735439e+00  8.69609416e-04 -2.89280683e-01 -1.48073387e+00\n",
      "  6.23656362e-02 -3.00749660e-01 -1.34310746e+00]\n",
      "data: [ 4.1780200e-02 -1.1884119e-01 -2.6451227e-01  5.6165382e-02\n",
      " -2.6904705e-01 -7.0369804e-01 -1.9857898e-02 -4.5427489e-01\n",
      " -1.4441764e+00 -1.6027954e-01 -5.1614189e-01 -1.7433552e+00\n",
      " -3.3389771e-01 -6.3713586e-01 -2.2044256e+00 -1.6898575e-01\n",
      " -7.2372955e-01 -1.6091893e+00  6.5110154e-02 -7.5336272e-01\n",
      " -1.3993042e+00  1.4669977e-02 -6.9300699e-01 -1.4491148e+00\n",
      "  1.2894012e-02 -8.1783640e-01 -1.5636430e+00 -1.2413003e-01\n",
      " -6.1029702e-01 -1.5235755e+00 -3.5602756e-02 -6.6817182e-01\n",
      " -1.4966847e+00 -3.9816581e-02 -6.4545751e-01 -1.5892596e+00\n",
      "  8.4943645e-02 -6.6845298e-01 -1.6435974e+00 -2.9173687e-02\n",
      " -5.2799702e-01 -1.3527176e+00 -1.4024979e-01 -3.0377802e-01\n",
      " -1.9628348e+00  8.8473335e-03 -4.5942664e-01 -1.9534159e+00\n",
      "  1.6014755e-01 -4.2004192e-01 -1.4982400e+00 -1.3613307e-01\n",
      " -2.8661299e-01 -1.2877507e+00 -5.0072469e-02 -2.6577491e-01\n",
      " -1.3673544e+00  8.6960942e-04 -2.8928068e-01 -1.4807340e+00\n",
      "  6.2365636e-02 -3.0074966e-01 -1.3431075e+00  7.9999998e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63630>\n",
      "tensor([[ 0.0233, -0.1423, -0.2335,  ...,  0.0644, -0.3238, -1.3001],\n",
      "        [ 0.0233, -0.1423, -0.2335,  ...,  0.0644, -0.3238, -1.3001],\n",
      "        [ 0.0233, -0.1423, -0.2335,  ...,  0.0644, -0.3238, -1.3001],\n",
      "        ...,\n",
      "        [-0.1060,  0.4684, -0.1557,  ..., -0.6788,  0.9399, -0.4287],\n",
      "        [-0.1368, -0.0762,  0.6080,  ..., -0.2123,  0.6564,  0.2963],\n",
      "        [-0.1368, -0.0762,  0.6080,  ..., -0.2123,  0.6564,  0.2963]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02328847 -0.14233115 -0.23353784  0.04170341 -0.29083514 -0.64477384\n",
      " -0.02275998 -0.47621903 -1.3832507  -0.16696884 -0.5357582  -1.6947656\n",
      " -0.3416217  -0.6684576  -2.1586952  -0.18971875 -0.74408567 -1.569447\n",
      "  0.06950581 -0.7743348  -1.3703933   0.00908111 -0.7208065  -1.4164302\n",
      "  0.00718683 -0.8469019  -1.5336587  -0.13566393 -0.63064945 -1.4765458\n",
      " -0.03732016 -0.6954237  -1.4579959  -0.03869403 -0.673437   -1.5574901\n",
      "  0.07640131 -0.7109847  -1.6108103  -0.02786327 -0.54077506 -1.2976258\n",
      " -0.14767194 -0.3164076  -1.9357827   0.01157595 -0.48480836 -1.9239635\n",
      "  0.16239107 -0.44523218 -1.4594748  -0.1451122  -0.2987786  -1.2351544\n",
      " -0.03981361 -0.28161287 -1.3132193   0.00939146 -0.31615782 -1.4282908\n",
      "  0.06439696 -0.3238203  -1.3001001 ]\n",
      "data: [ 0.02328847 -0.14233115 -0.23353785  0.04170341 -0.29083514 -0.64477384\n",
      " -0.02275998 -0.47621903 -1.3832507  -0.16696884 -0.5357582  -1.6947656\n",
      " -0.3416217  -0.6684576  -2.1586952  -0.18971877 -0.74408567 -1.569447\n",
      "  0.06950581 -0.7743348  -1.3703933   0.00908111 -0.7208065  -1.4164302\n",
      "  0.00718683 -0.84690183 -1.5336587  -0.13566393 -0.63064945 -1.4765458\n",
      " -0.03732016 -0.6954237  -1.4579959  -0.03869403 -0.67343694 -1.5574901\n",
      "  0.07640131 -0.7109847  -1.6108103  -0.02786327 -0.54077506 -1.2976258\n",
      " -0.14767194 -0.3164076  -1.9357827   0.01157595 -0.48480836 -1.9239637\n",
      "  0.16239107 -0.4452322  -1.4594748  -0.1451122  -0.2987786  -1.2351544\n",
      " -0.03981361 -0.28161287 -1.3132193   0.00939146 -0.31615782 -1.4282908\n",
      "  0.06439696 -0.3238203  -1.3001001   0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FA90>\n",
      "tensor([[ 0.0291, -0.1134, -0.1765,  ...,  0.0643, -0.3142, -1.1620],\n",
      "        [ 0.0291, -0.1134, -0.1765,  ...,  0.0643, -0.3142, -1.1620],\n",
      "        [ 0.0291, -0.1134, -0.1765,  ...,  0.0643, -0.3142, -1.1620],\n",
      "        ...,\n",
      "        [-0.0891,  0.4621, -0.1212,  ..., -0.5568,  0.9766, -0.4609],\n",
      "        [-0.1439, -0.0739,  0.6067,  ..., -0.2362,  0.6465,  0.2659],\n",
      "        [-0.1439, -0.0739,  0.6067,  ..., -0.2362,  0.6465,  0.2659]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02910377 -0.11335324 -0.17653164  0.05939888 -0.21521993 -0.47578412\n",
      " -0.08689307 -0.45018682 -1.328801   -0.24083997 -0.5183469  -1.6137425\n",
      " -0.38492543 -0.60772085 -2.1232882  -0.15850185 -0.75555384 -1.5060815\n",
      "  0.0041668  -0.8295232  -1.3620396  -0.05034915 -0.7516253  -1.4126823\n",
      " -0.05955356 -0.9276444  -1.5357558  -0.11330631 -0.6716521  -1.4043387\n",
      " -0.06267364 -0.72547877 -1.3737702  -0.07637963 -0.6920366  -1.4508778\n",
      "  0.058935   -0.72661984 -1.4596604  -0.03005718 -0.55699086 -1.2469647\n",
      " -0.19272494 -0.32005647 -2.0219092  -0.00502396 -0.49990043 -2.0493004\n",
      "  0.16812672 -0.45780197 -1.3325596  -0.15228245 -0.3318128  -1.1639485\n",
      " -0.0842903  -0.30087775 -1.2556064  -0.05304717 -0.30165422 -1.3659396\n",
      "  0.06425186 -0.31421363 -1.1619902 ]\n",
      "data: [ 0.02910377 -0.11335323 -0.17653164  0.05939888 -0.21521993 -0.47578412\n",
      " -0.08689307 -0.45018682 -1.3288009  -0.24083997 -0.5183469  -1.6137425\n",
      " -0.38492543 -0.60772085 -2.1232882  -0.15850185 -0.75555384 -1.5060813\n",
      "  0.0041668  -0.82952327 -1.3620394  -0.05034915 -0.7516253  -1.4126823\n",
      " -0.05955357 -0.9276444  -1.5357558  -0.11330631 -0.6716521  -1.4043387\n",
      " -0.06267364 -0.72547877 -1.3737702  -0.07637963 -0.69203657 -1.4508778\n",
      "  0.058935   -0.7266199  -1.4596603  -0.03005718 -0.55699086 -1.2469647\n",
      " -0.19272496 -0.32005647 -2.0219092  -0.00502396 -0.49990043 -2.0493004\n",
      "  0.16812672 -0.45780197 -1.3325595  -0.15228245 -0.33181277 -1.1639485\n",
      " -0.0842903  -0.30087775 -1.2556064  -0.05304717 -0.30165422 -1.3659396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.06425186 -0.31421363 -1.1619902   0.1       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0447, -0.0099, -0.2112,  ...,  0.0023, -0.1994, -1.1810],\n",
      "        [-0.0447, -0.0099, -0.2112,  ...,  0.0023, -0.1994, -1.1810],\n",
      "        [-0.0447, -0.0099, -0.2112,  ...,  0.0023, -0.1994, -1.1810],\n",
      "        ...,\n",
      "        [-0.1630,  0.3232,  0.0319,  ..., -0.6999,  0.8846, -0.3683],\n",
      "        [-0.0943, -0.0882,  0.5888,  ..., -0.2202,  0.6221,  0.2271],\n",
      "        [-0.0943, -0.0882,  0.5888,  ..., -0.2202,  0.6221,  0.2271]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.04466238 -0.00991441 -0.21122311 -0.01890791 -0.11908093 -0.501126\n",
      " -0.15346298 -0.3441281  -1.3487312  -0.3097052  -0.40708205 -1.6476009\n",
      " -0.47122014 -0.5098951  -2.1500366  -0.24854417 -0.64459354 -1.5228227\n",
      " -0.04913591 -0.70261925 -1.3478032  -0.10254259 -0.63101    -1.3976724\n",
      " -0.10438426 -0.7934896  -1.5282651  -0.19930679 -0.55144995 -1.416248\n",
      " -0.13011697 -0.6067312  -1.3918399  -0.12824294 -0.570586   -1.4813042\n",
      "  0.02118631 -0.6080713  -1.5060737  -0.1037811  -0.44058526 -1.2452269\n",
      " -0.2627347  -0.20094705 -2.0170534  -0.0629913  -0.3797381  -2.0365658\n",
      "  0.12675755 -0.3372528  -1.3591261  -0.23078512 -0.20797381 -1.165863\n",
      " -0.14787358 -0.18020898 -1.2515088  -0.1096863  -0.1883061  -1.3680953\n",
      "  0.00227641 -0.19939159 -1.1810211 ]\n",
      "data: [-0.04466238 -0.00991441 -0.21122311 -0.01890791 -0.11908093 -0.501126\n",
      " -0.15346298 -0.3441281  -1.3487313  -0.3097052  -0.40708205 -1.6476009\n",
      " -0.47122014 -0.5098951  -2.1500366  -0.24854417 -0.6445935  -1.5228227\n",
      " -0.04913591 -0.70261925 -1.3478032  -0.10254259 -0.63101    -1.3976724\n",
      " -0.10438426 -0.79348963 -1.5282651  -0.19930679 -0.55144995 -1.416248\n",
      " -0.13011697 -0.6067312  -1.3918399  -0.12824294 -0.570586   -1.4813042\n",
      "  0.02118631 -0.6080713  -1.5060737  -0.1037811  -0.44058526 -1.2452269\n",
      " -0.2627347  -0.20094703 -2.0170534  -0.0629913  -0.3797381  -2.0365658\n",
      "  0.12675755 -0.3372528  -1.3591261  -0.23078512 -0.20797381 -1.165863\n",
      " -0.14787358 -0.18020898 -1.2515088  -0.1096863  -0.18830608 -1.3680953\n",
      "  0.00227641 -0.19939159 -1.1810211   0.11      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63EB8>\n",
      "tensor([[-0.0071, -0.0854, -0.1918,  ...,  0.0123, -0.2413, -1.3160],\n",
      "        [-0.0071, -0.0854, -0.1918,  ...,  0.0123, -0.2413, -1.3160],\n",
      "        [-0.0071, -0.0854, -0.1918,  ...,  0.0123, -0.2413, -1.3160],\n",
      "        ...,\n",
      "        [-0.2620,  0.3032, -0.1823,  ..., -0.7650,  0.7891, -0.3902],\n",
      "        [-0.1901, -0.1139,  0.5259,  ..., -0.2995,  0.6235,  0.2653],\n",
      "        [-0.1901, -0.1139,  0.5259,  ..., -0.2995,  0.6235,  0.2653]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.00710196 -0.08544847 -0.19175628  0.00689047 -0.24859251 -0.66455984\n",
      " -0.02927459 -0.3917185  -1.3328781  -0.16832565 -0.44094014 -1.6465324\n",
      " -0.3562644  -0.5791039  -2.0991259  -0.23400325 -0.66077095 -1.4965847\n",
      "  0.05403343 -0.65575945 -1.2659844   0.00606884 -0.6051889  -1.314957\n",
      "  0.00799252 -0.6972367  -1.4308643  -0.18721217 -0.5403768  -1.4200785\n",
      " -0.06654487 -0.5965224  -1.4145501  -0.05805758 -0.5664909  -1.526382\n",
      "  0.06942295 -0.5923652  -1.6097248  -0.07891139 -0.4711054  -1.240496\n",
      " -0.16029449 -0.24344303 -1.7734765  -0.0192635  -0.3850494  -1.7481052\n",
      "  0.12775147 -0.3499766  -1.4605434  -0.18464401 -0.2221608  -1.1924318\n",
      " -0.07989353 -0.20267934 -1.2714406  -0.02071533 -0.2367297  -1.3956954\n",
      "  0.01226703 -0.24125206 -1.3159512 ]\n",
      "data: [-0.00710196 -0.08544847 -0.1917563   0.00689047 -0.24859251 -0.66455984\n",
      " -0.02927459 -0.3917185  -1.3328781  -0.16832565 -0.44094014 -1.6465324\n",
      " -0.3562644  -0.5791039  -2.0991259  -0.23400325 -0.66077095 -1.4965847\n",
      "  0.05403343 -0.65575945 -1.2659844   0.00606884 -0.6051889  -1.314957\n",
      "  0.00799252 -0.6972367  -1.4308642  -0.18721217 -0.5403768  -1.4200786\n",
      " -0.06654487 -0.5965224  -1.4145501  -0.05805758 -0.5664909  -1.526382\n",
      "  0.06942295 -0.5923652  -1.6097248  -0.07891139 -0.4711054  -1.240496\n",
      " -0.16029449 -0.24344303 -1.7734764  -0.0192635  -0.3850494  -1.7481052\n",
      "  0.12775147 -0.34997663 -1.4605434  -0.18464401 -0.2221608  -1.1924318\n",
      " -0.07989353 -0.20267934 -1.2714406  -0.02071533 -0.2367297  -1.3956954\n",
      "  0.01226703 -0.24125206 -1.3159512   0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FC50>\n",
      "tensor([[ 0.0348, -0.1272, -0.2980,  ...,  0.0456, -0.2974, -1.3525],\n",
      "        [ 0.0348, -0.1272, -0.2980,  ...,  0.0456, -0.2974, -1.3525],\n",
      "        [ 0.0348, -0.1272, -0.2980,  ...,  0.0456, -0.2974, -1.3525],\n",
      "        ...,\n",
      "        [-0.1554,  0.4809, -0.1023,  ..., -0.7234,  1.0083, -0.4150],\n",
      "        [-0.1839, -0.0729,  0.6280,  ..., -0.2774,  0.7054,  0.2781],\n",
      "        [-0.1839, -0.0729,  0.6280,  ..., -0.2774,  0.7054,  0.2781]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03479575 -0.12716934 -0.2980082   0.06816307 -0.24769329 -0.6868527\n",
      " -0.04168709 -0.44789168 -1.4854026  -0.18676606 -0.50911796 -1.7798524\n",
      " -0.33176348 -0.6062664  -2.2837603  -0.16396332 -0.7378944  -1.655648\n",
      "  0.0329927  -0.7797581  -1.4808252  -0.0190076  -0.71329165 -1.535991\n",
      " -0.03463219 -0.858744   -1.6609514  -0.12417128 -0.64434814 -1.5632508\n",
      " -0.05580775 -0.6949662  -1.5411422  -0.07134379 -0.6605401  -1.6293509\n",
      "  0.05624149 -0.6927711  -1.6642585  -0.0411061  -0.54218066 -1.3958988\n",
      " -0.17495298 -0.30594853 -2.0829067  -0.00986494 -0.46749887 -2.0973337\n",
      "  0.14547694 -0.4308587  -1.5231369  -0.15175262 -0.311927   -1.32079\n",
      " -0.07814237 -0.27901924 -1.3989279  -0.03971011 -0.2858339  -1.5156388\n",
      "  0.04561578 -0.2973566  -1.35253   ]\n",
      "data: [ 0.03479575 -0.12716934 -0.2980082   0.06816307 -0.24769329 -0.6868527\n",
      " -0.04168709 -0.44789168 -1.4854026  -0.18676606 -0.50911796 -1.7798524\n",
      " -0.33176345 -0.6062664  -2.2837603  -0.16396332 -0.7378944  -1.655648\n",
      "  0.0329927  -0.7797581  -1.4808252  -0.0190076  -0.71329165 -1.535991\n",
      " -0.03463219 -0.858744   -1.6609514  -0.12417128 -0.64434814 -1.5632508\n",
      " -0.05580775 -0.6949662  -1.5411422  -0.07134379 -0.6605401  -1.6293509\n",
      "  0.05624149 -0.6927711  -1.6642585  -0.0411061  -0.54218066 -1.3958987\n",
      " -0.17495298 -0.30594853 -2.0829067  -0.00986494 -0.46749887 -2.0973337\n",
      "  0.14547694 -0.4308587  -1.5231369  -0.15175262 -0.311927   -1.32079\n",
      " -0.07814237 -0.27901924 -1.3989279  -0.03971011 -0.2858339  -1.5156388\n",
      "  0.04561578 -0.2973566  -1.35253     0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0068, -0.0981, -0.2198,  ...,  0.0444, -0.2776, -1.3065],\n",
      "        [ 0.0068, -0.0981, -0.2198,  ...,  0.0444, -0.2776, -1.3065],\n",
      "        [ 0.0068, -0.0981, -0.2198,  ...,  0.0444, -0.2776, -1.3065],\n",
      "        ...,\n",
      "        [-0.1340,  0.4523, -0.1283,  ..., -0.8093,  0.9405, -0.3509],\n",
      "        [-0.1165, -0.0782,  0.5533,  ..., -0.1983,  0.6356,  0.2372],\n",
      "        [-0.1165, -0.0782,  0.5533,  ..., -0.1983,  0.6356,  0.2372]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 6.8180235e-03 -9.8123841e-02 -2.1978985e-01  1.6795430e-02\n",
      " -2.5753403e-01 -6.7051750e-01 -8.4934160e-03 -4.1815364e-01\n",
      " -1.3703275e+00 -1.4733003e-01 -4.7023582e-01 -1.7014606e+00\n",
      " -3.3831617e-01 -6.1956018e-01 -2.1516662e+00 -2.1743491e-01\n",
      " -6.7795700e-01 -1.5586362e+00  8.5143089e-02 -6.8759763e-01\n",
      " -1.3398592e+00  2.0501986e-02 -6.4455611e-01 -1.3863173e+00\n",
      "  2.4438471e-02 -7.5300252e-01 -1.5050209e+00 -1.6035941e-01\n",
      " -5.5530649e-01 -1.4619217e+00 -4.2370424e-02 -6.2247169e-01\n",
      " -1.4522295e+00 -3.9060436e-02 -6.0676759e-01 -1.5671775e+00\n",
      "  6.8648905e-02 -6.4543301e-01 -1.6395242e+00 -4.2191707e-02\n",
      " -4.7692567e-01 -1.2707615e+00 -1.4805509e-01 -2.5797176e-01\n",
      " -1.8669505e+00  9.6100569e-04 -4.2129111e-01 -1.8404675e+00\n",
      "  1.4539075e-01 -3.8713688e-01 -1.4662571e+00 -1.5994033e-01\n",
      " -2.3028283e-01 -1.2136528e+00 -3.7574723e-02 -2.2289427e-01\n",
      " -1.2840316e+00  1.4714792e-02 -2.7177471e-01 -1.4005921e+00\n",
      "  4.4389077e-02 -2.7758071e-01 -1.3064964e+00]\n",
      "data: [ 6.8180235e-03 -9.8123834e-02 -2.1978985e-01  1.6795430e-02\n",
      " -2.5753403e-01 -6.7051750e-01 -8.4934160e-03 -4.1815364e-01\n",
      " -1.3703275e+00 -1.4733003e-01 -4.7023582e-01 -1.7014606e+00\n",
      " -3.3831614e-01 -6.1956018e-01 -2.1516662e+00 -2.1743493e-01\n",
      " -6.7795700e-01 -1.5586362e+00  8.5143089e-02 -6.8759763e-01\n",
      " -1.3398594e+00  2.0501986e-02 -6.4455611e-01 -1.3863173e+00\n",
      "  2.4438472e-02 -7.5300252e-01 -1.5050209e+00 -1.6035943e-01\n",
      " -5.5530649e-01 -1.4619217e+00 -4.2370424e-02 -6.2247169e-01\n",
      " -1.4522295e+00 -3.9060436e-02 -6.0676759e-01 -1.5671775e+00\n",
      "  6.8648905e-02 -6.4543307e-01 -1.6395242e+00 -4.2191707e-02\n",
      " -4.7692567e-01 -1.2707615e+00 -1.4805509e-01 -2.5797176e-01\n",
      " -1.8669505e+00  9.6100569e-04 -4.2129111e-01 -1.8404676e+00\n",
      "  1.4539075e-01 -3.8713688e-01 -1.4662570e+00 -1.5994033e-01\n",
      " -2.3028283e-01 -1.2136528e+00 -3.7574723e-02 -2.2289427e-01\n",
      " -1.2840316e+00  1.4714791e-02 -2.7177471e-01 -1.4005921e+00\n",
      "  4.4389077e-02 -2.7758071e-01 -1.3064964e+00  1.4000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0288, -0.0976, -0.2605,  ...,  0.0463, -0.2823, -1.3142],\n",
      "        [ 0.0288, -0.0976, -0.2605,  ...,  0.0463, -0.2823, -1.3142],\n",
      "        [ 0.0288, -0.0976, -0.2605,  ...,  0.0463, -0.2823, -1.3142],\n",
      "        ...,\n",
      "        [-0.1758,  0.4528, -0.1444,  ..., -0.7083,  0.9520, -0.4326],\n",
      "        [-0.1791, -0.1274,  0.6284,  ..., -0.2488,  0.6463,  0.2859],\n",
      "        [-0.1791, -0.1274,  0.6284,  ..., -0.2488,  0.6463,  0.2859]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02881786 -0.09755558 -0.2605119   0.04628595 -0.23547585 -0.67168856\n",
      " -0.05501786 -0.43342078 -1.4390726  -0.19891363 -0.49899018 -1.7301688\n",
      " -0.3622626  -0.60667384 -2.2061715  -0.17418915 -0.7150379  -1.5982358\n",
      "  0.02568904 -0.7566886  -1.4067383  -0.02515845 -0.68909484 -1.4604459\n",
      " -0.03131668 -0.8296802  -1.5768359  -0.13247122 -0.6112688  -1.512181\n",
      " -0.06033859 -0.6648136  -1.4809844  -0.07370999 -0.63875026 -1.568189\n",
      "  0.05492058 -0.6598557  -1.6060262  -0.04649133 -0.5200242  -1.3479186\n",
      " -0.16794789 -0.2930768  -1.9955894  -0.01488914 -0.4491341  -1.999625\n",
      "  0.14062056 -0.4124893  -1.4696878  -0.15081161 -0.28434992 -1.2780819\n",
      " -0.07826245 -0.25952646 -1.3624914  -0.03531438 -0.26972023 -1.4754897\n",
      "  0.04625187 -0.28229505 -1.3141934 ]\n",
      "data: [ 0.02881786 -0.09755558 -0.2605119   0.04628595 -0.23547584 -0.67168856\n",
      " -0.05501786 -0.43342078 -1.4390726  -0.19891363 -0.49899018 -1.7301688\n",
      " -0.3622626  -0.60667384 -2.2061715  -0.17418915 -0.71503794 -1.5982357\n",
      "  0.02568903 -0.7566886  -1.4067383  -0.02515845 -0.68909484 -1.4604459\n",
      " -0.03131668 -0.8296802  -1.576836   -0.13247122 -0.6112688  -1.512181\n",
      " -0.06033859 -0.66481364 -1.4809844  -0.07370999 -0.63875026 -1.5681891\n",
      "  0.05492058 -0.6598557  -1.6060262  -0.04649133 -0.5200242  -1.3479187\n",
      " -0.16794789 -0.2930768  -1.9955895  -0.01488914 -0.4491341  -1.999625\n",
      "  0.14062056 -0.4124893  -1.4696878  -0.15081161 -0.28434992 -1.2780819\n",
      " -0.07826245 -0.25952646 -1.3624913  -0.03531438 -0.26972023 -1.4754899\n",
      "  0.04625187 -0.28229505 -1.3141934   0.15      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[ 3.1886e-04, -4.8311e-02, -2.1638e-01,  ...,  3.8449e-02,\n",
      "         -2.3808e-01, -1.2554e+00],\n",
      "        [ 3.1886e-04, -4.8311e-02, -2.1638e-01,  ...,  3.8449e-02,\n",
      "         -2.3808e-01, -1.2554e+00],\n",
      "        [ 3.1886e-04, -4.8311e-02, -2.1638e-01,  ...,  3.8449e-02,\n",
      "         -2.3808e-01, -1.2554e+00],\n",
      "        ...,\n",
      "        [-1.2968e-01,  3.9781e-01, -1.3685e-01,  ..., -7.5204e-01,\n",
      "          8.7439e-01, -3.7451e-01],\n",
      "        [-1.3274e-01, -1.4971e-01,  5.7057e-01,  ..., -2.2266e-01,\n",
      "          5.7863e-01,  2.5948e-01],\n",
      "        [-1.3274e-01, -1.4971e-01,  5.7057e-01,  ..., -2.2266e-01,\n",
      "          5.7863e-01,  2.5948e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 3.1885970e-04 -4.8311271e-02 -2.1637717e-01  1.7045598e-02\n",
      " -1.8425995e-01 -6.0566938e-01 -6.4464368e-02 -3.6973351e-01\n",
      " -1.3490306e+00 -2.0923923e-01 -4.2810249e-01 -1.6551596e+00\n",
      " -3.7990928e-01 -5.4835325e-01 -2.1275864e+00 -2.0586888e-01\n",
      " -6.5534592e-01 -1.5241964e+00  2.3285031e-02 -6.8885499e-01\n",
      " -1.3431900e+00 -3.3422902e-02 -6.2934637e-01 -1.3951894e+00\n",
      " -3.3196367e-02 -7.6717335e-01 -1.5133837e+00 -1.5590288e-01\n",
      " -5.5117172e-01 -1.4334040e+00 -6.9122016e-02 -6.0971731e-01\n",
      " -1.4152445e+00 -7.5942419e-02 -5.8684754e-01 -1.5140942e+00\n",
      "  4.8336819e-02 -6.1884469e-01 -1.5581280e+00 -5.6946628e-02\n",
      " -4.5946640e-01 -1.2608051e+00 -1.7892669e-01 -2.3533897e-01\n",
      " -1.9216877e+00 -1.8025234e-02 -3.9926338e-01 -1.9203882e+00\n",
      "  1.3794176e-01 -3.6548972e-01 -1.4116827e+00 -1.6729531e-01\n",
      " -2.2471626e-01 -1.1974972e+00 -7.6779932e-02 -2.0679168e-01\n",
      " -1.2798890e+00 -3.4347400e-02 -2.2778177e-01 -1.3971599e+00\n",
      "  3.8449265e-02 -2.3808324e-01 -1.2554359e+00]\n",
      "data: [ 3.1885970e-04 -4.8311271e-02 -2.1637717e-01  1.7045598e-02\n",
      " -1.8425995e-01 -6.0566938e-01 -6.4464368e-02 -3.6973351e-01\n",
      " -1.3490306e+00 -2.0923923e-01 -4.2810249e-01 -1.6551596e+00\n",
      " -3.7990928e-01 -5.4835325e-01 -2.1275864e+00 -2.0586890e-01\n",
      " -6.5534592e-01 -1.5241963e+00  2.3285031e-02 -6.8885499e-01\n",
      " -1.3431900e+00 -3.3422902e-02 -6.2934637e-01 -1.3951894e+00\n",
      " -3.3196367e-02 -7.6717341e-01 -1.5133837e+00 -1.5590288e-01\n",
      " -5.5117172e-01 -1.4334040e+00 -6.9122016e-02 -6.0971731e-01\n",
      " -1.4152445e+00 -7.5942419e-02 -5.8684754e-01 -1.5140942e+00\n",
      "  4.8336819e-02 -6.1884469e-01 -1.5581280e+00 -5.6946624e-02\n",
      " -4.5946640e-01 -1.2608051e+00 -1.7892669e-01 -2.3533897e-01\n",
      " -1.9216877e+00 -1.8025234e-02 -3.9926338e-01 -1.9203882e+00\n",
      "  1.3794176e-01 -3.6548972e-01 -1.4116827e+00 -1.6729531e-01\n",
      " -2.2471626e-01 -1.1974972e+00 -7.6779932e-02 -2.0679168e-01\n",
      " -1.2798890e+00 -3.4347400e-02 -2.2778177e-01 -1.3971599e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3.8449265e-02 -2.3808324e-01 -1.2554359e+00  1.6000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0172, -0.0667, -0.2470,  ...,  0.0199, -0.2493, -1.2865],\n",
      "        [ 0.0172, -0.0667, -0.2470,  ...,  0.0199, -0.2493, -1.2865],\n",
      "        [ 0.0172, -0.0667, -0.2470,  ...,  0.0199, -0.2493, -1.2865],\n",
      "        ...,\n",
      "        [-0.3572,  0.1935, -0.3323,  ..., -0.8209,  0.6218, -0.5109],\n",
      "        [-0.1114, -0.0612,  0.6160,  ..., -0.2128,  0.7280,  0.2779],\n",
      "        [-0.1114, -0.0612,  0.6160,  ..., -0.2128,  0.7280,  0.2779]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01717216 -0.06672306 -0.24698877  0.04282324 -0.1920174  -0.6456078\n",
      " -0.07636719 -0.3884147  -1.4292643  -0.22077706 -0.4549068  -1.7139211\n",
      " -0.3764491  -0.54615116 -2.206637   -0.17550704 -0.68470454 -1.5776258\n",
      " -0.00711485 -0.7276391  -1.4007967  -0.05455852 -0.6568361  -1.4607122\n",
      " -0.06699421 -0.80667007 -1.5790746  -0.14117235 -0.5915387  -1.4941926\n",
      " -0.08148327 -0.6397402  -1.4594116  -0.1074842  -0.61080533 -1.5470643\n",
      "  0.02747693 -0.62840056 -1.5772064  -0.07023528 -0.49758807 -1.3324556\n",
      " -0.19439891 -0.2682377  -2.007444   -0.04226754 -0.41843295 -2.0239167\n",
      "  0.11255118 -0.39052886 -1.4409914  -0.16627085 -0.26783958 -1.2609932\n",
      " -0.11223782 -0.2394356  -1.3436275  -0.0752892  -0.23444788 -1.4602132\n",
      "  0.01986508 -0.24927376 -1.2865    ]\n",
      "data: [ 0.01717216 -0.06672306 -0.24698877  0.04282324 -0.1920174  -0.6456078\n",
      " -0.07636719 -0.38841474 -1.4292644  -0.22077708 -0.45490682 -1.7139211\n",
      " -0.37644914 -0.54615116 -2.206637   -0.17550702 -0.68470454 -1.5776258\n",
      " -0.00711485 -0.7276391  -1.4007967  -0.05455853 -0.6568361  -1.4607121\n",
      " -0.06699421 -0.80667007 -1.5790745  -0.14117235 -0.5915387  -1.4941926\n",
      " -0.08148327 -0.6397402  -1.4594116  -0.1074842  -0.61080533 -1.5470643\n",
      "  0.02747693 -0.62840056 -1.5772064  -0.07023528 -0.49758807 -1.3324556\n",
      " -0.19439892 -0.2682377  -2.007444   -0.04226754 -0.41843295 -2.0239167\n",
      "  0.11255118 -0.39052886 -1.4409914  -0.16627085 -0.26783958 -1.2609932\n",
      " -0.11223782 -0.2394356  -1.3436275  -0.0752892  -0.23444788 -1.4602132\n",
      "  0.01986508 -0.24927376 -1.2865      0.17      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0363, -0.0199, -0.2101,  ...,  0.0521, -0.2156, -1.2395],\n",
      "        [ 0.0363, -0.0199, -0.2101,  ...,  0.0521, -0.2156, -1.2395],\n",
      "        [ 0.0363, -0.0199, -0.2101,  ...,  0.0521, -0.2156, -1.2395],\n",
      "        ...,\n",
      "        [-0.2047,  0.3285, -0.1399,  ..., -0.8833,  0.7973, -0.3254],\n",
      "        [-0.1438, -0.2110,  0.5418,  ..., -0.2173,  0.5558,  0.2194],\n",
      "        [-0.1438, -0.2110,  0.5418,  ..., -0.2173,  0.5558,  0.2194]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03627275 -0.01990418 -0.21006435  0.04883624 -0.15114179 -0.60978734\n",
      " -0.0617114  -0.33568987 -1.3536876  -0.20773649 -0.39943114 -1.6418747\n",
      " -0.3764325  -0.49675244 -2.122766   -0.1581668  -0.6394461  -1.5032092\n",
      "  0.00865642 -0.6766433  -1.3424815  -0.03602809 -0.6041948  -1.405287\n",
      " -0.03070365 -0.7525334  -1.5182843  -0.12113331 -0.54306084 -1.4246709\n",
      " -0.05536785 -0.58983827 -1.3913026  -0.07584118 -0.5668515  -1.4852614\n",
      "  0.06617888 -0.57652396 -1.5168452  -0.04645373 -0.45559487 -1.2639717\n",
      " -0.15718678 -0.2336781  -1.910546   -0.01023859 -0.37782133 -1.922479\n",
      "  0.1508441  -0.3538342  -1.3833165  -0.13686523 -0.22612381 -1.2003347\n",
      " -0.08230048 -0.20452516 -1.2867551  -0.04548328 -0.19981205 -1.4047902\n",
      "  0.052093   -0.21562843 -1.2395489 ]\n",
      "data: [ 0.03627275 -0.01990418 -0.21006435  0.04883624 -0.15114179 -0.60978734\n",
      " -0.0617114  -0.3356899  -1.3536876  -0.20773649 -0.39943114 -1.6418747\n",
      " -0.3764325  -0.49675244 -2.122766   -0.1581668  -0.6394461  -1.5032092\n",
      "  0.00865642 -0.6766433  -1.3424815  -0.03602809 -0.6041948  -1.405287\n",
      " -0.03070365 -0.7525333  -1.5182843  -0.12113331 -0.54306084 -1.4246708\n",
      " -0.05536785 -0.58983827 -1.3913026  -0.07584118 -0.5668515  -1.4852614\n",
      "  0.06617888 -0.57652396 -1.5168452  -0.04645373 -0.45559487 -1.2639717\n",
      " -0.15718678 -0.23367809 -1.910546   -0.01023859 -0.37782133 -1.9224792\n",
      "  0.1508441  -0.35383424 -1.3833165  -0.13686523 -0.22612381 -1.2003347\n",
      " -0.08230047 -0.20452517 -1.2867551  -0.04548328 -0.19981205 -1.4047902\n",
      "  0.052093   -0.21562843 -1.2395489   0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0109, -0.0659, -0.2377,  ...,  0.0323, -0.2474, -1.2868],\n",
      "        [ 0.0109, -0.0659, -0.2377,  ...,  0.0323, -0.2474, -1.2868],\n",
      "        [ 0.0109, -0.0659, -0.2377,  ...,  0.0323, -0.2474, -1.2868],\n",
      "        ...,\n",
      "        [-0.3327,  0.2297, -0.2980,  ..., -0.8713,  0.6586, -0.4468],\n",
      "        [-0.1220, -0.0559,  0.5827,  ..., -0.2404,  0.7425,  0.2450],\n",
      "        [-0.1220, -0.0559,  0.5827,  ..., -0.2404,  0.7425,  0.2450]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01090908 -0.06592315 -0.23774406  0.03691807 -0.20456097 -0.6542568\n",
      " -0.05912696 -0.3860446  -1.4130268  -0.19941014 -0.4497704  -1.7023133\n",
      " -0.36018163 -0.5565107  -2.1846428  -0.18621841 -0.6688101  -1.5673097\n",
      "  0.01791365 -0.6967647  -1.3727038  -0.02880234 -0.63182473 -1.4292709\n",
      " -0.0360641  -0.7629993  -1.5456527  -0.14871919 -0.56717    -1.4867613\n",
      " -0.0682091  -0.61935854 -1.4559184  -0.08611922 -0.5909852  -1.5459585\n",
      "  0.04674046 -0.6110302  -1.5904617  -0.0663797  -0.4841186  -1.316765\n",
      " -0.1747534  -0.25489062 -1.9458338  -0.02671438 -0.405032   -1.9476631\n",
      "  0.12519515 -0.37572947 -1.4452381  -0.16271287 -0.24987616 -1.2511406\n",
      " -0.09127849 -0.22533754 -1.3240632  -0.04527774 -0.23294008 -1.441414\n",
      "  0.03225398 -0.24743976 -1.2868003 ]\n",
      "data: [ 0.01090908 -0.06592315 -0.23774406  0.03691807 -0.20456097 -0.6542568\n",
      " -0.05912696 -0.3860446  -1.4130267  -0.19941014 -0.4497704  -1.7023132\n",
      " -0.36018163 -0.5565107  -2.1846428  -0.18621841 -0.6688101  -1.5673097\n",
      "  0.01791365 -0.6967647  -1.3727039  -0.02880234 -0.63182473 -1.429271\n",
      " -0.0360641  -0.7629993  -1.5456527  -0.14871919 -0.56717    -1.4867613\n",
      " -0.0682091  -0.61935854 -1.4559184  -0.08611922 -0.5909852  -1.5459585\n",
      "  0.04674046 -0.6110302  -1.5904617  -0.0663797  -0.4841186  -1.316765\n",
      " -0.1747534  -0.25489062 -1.9458337  -0.02671438 -0.405032   -1.9476631\n",
      "  0.12519515 -0.37572947 -1.445238   -0.16271287 -0.24987616 -1.2511406\n",
      " -0.09127849 -0.22533755 -1.3240631  -0.04527774 -0.23294008 -1.441414\n",
      "  0.03225398 -0.24743977 -1.2868003   0.19      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B320>\n",
      "tensor([[ 0.0167, -0.0719, -0.2385,  ...,  0.0548, -0.2576, -1.2927],\n",
      "        [ 0.0167, -0.0719, -0.2385,  ...,  0.0548, -0.2576, -1.2927],\n",
      "        [ 0.0167, -0.0719, -0.2385,  ...,  0.0548, -0.2576, -1.2927],\n",
      "        ...,\n",
      "        [-0.1714,  0.3802, -0.1756,  ..., -0.8114,  0.8724, -0.3900],\n",
      "        [-0.1454, -0.1637,  0.5690,  ..., -0.2468,  0.6062,  0.2353],\n",
      "        [-0.1454, -0.1637,  0.5690,  ..., -0.2468,  0.6062,  0.2353]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.6667534e-02 -7.1930282e-02 -2.3846328e-01  3.4477551e-02\n",
      " -2.1622261e-01 -6.5814352e-01 -4.1843377e-02 -3.9561301e-01\n",
      " -1.3942775e+00 -1.8044338e-01 -4.5627028e-01 -1.6940213e+00\n",
      " -3.5114777e-01 -5.7800204e-01 -2.1580336e+00 -1.8712647e-01\n",
      " -6.7387122e-01 -1.5549089e+00  4.4343442e-02 -7.0012474e-01\n",
      " -1.3626275e+00 -6.6201240e-03 -6.4046162e-01 -1.4147683e+00\n",
      " -3.9515793e-03 -7.6750702e-01 -1.5303699e+00 -1.4107139e-01\n",
      " -5.6566453e-01 -1.4696307e+00 -4.9788103e-02 -6.2203598e-01\n",
      " -1.4477836e+00 -5.4930747e-02 -5.9790117e-01 -1.5429060e+00\n",
      "  7.3002607e-02 -6.2355167e-01 -1.5954995e+00 -4.6468250e-02\n",
      " -4.8340148e-01 -1.2965751e+00 -1.5571813e-01 -2.5720042e-01\n",
      " -1.9259683e+00 -1.1917949e-03 -4.1298491e-01 -1.9195025e+00\n",
      "  1.5275852e-01 -3.7931705e-01 -1.4486051e+00 -1.5100384e-01\n",
      " -2.4503931e-01 -1.2336488e+00 -6.2211707e-02 -2.2571073e-01\n",
      " -1.3143731e+00 -1.2451872e-02 -2.4583481e-01 -1.4308788e+00\n",
      "  5.4836191e-02 -2.5762028e-01 -1.2927065e+00]\n",
      "data: [ 1.6667534e-02 -7.1930282e-02 -2.3846328e-01  3.4477551e-02\n",
      " -2.1622261e-01 -6.5814352e-01 -4.1843377e-02 -3.9561301e-01\n",
      " -1.3942775e+00 -1.8044338e-01 -4.5627031e-01 -1.6940213e+00\n",
      " -3.5114777e-01 -5.7800204e-01 -2.1580336e+00 -1.8712646e-01\n",
      " -6.7387122e-01 -1.5549089e+00  4.4343442e-02 -7.0012474e-01\n",
      " -1.3626275e+00 -6.6201240e-03 -6.4046168e-01 -1.4147683e+00\n",
      " -3.9515793e-03 -7.6750702e-01 -1.5303699e+00 -1.4107139e-01\n",
      " -5.6566453e-01 -1.4696307e+00 -4.9788103e-02 -6.2203598e-01\n",
      " -1.4477837e+00 -5.4930743e-02 -5.9790117e-01 -1.5429060e+00\n",
      "  7.3002607e-02 -6.2355167e-01 -1.5954995e+00 -4.6468247e-02\n",
      " -4.8340148e-01 -1.2965751e+00 -1.5571813e-01 -2.5720042e-01\n",
      " -1.9259683e+00 -1.1917949e-03 -4.1298494e-01 -1.9195026e+00\n",
      "  1.5275852e-01 -3.7931705e-01 -1.4486051e+00 -1.5100384e-01\n",
      " -2.4503931e-01 -1.2336488e+00 -6.2211707e-02 -2.2571073e-01\n",
      " -1.3143731e+00 -1.2451873e-02 -2.4583481e-01 -1.4308788e+00\n",
      "  5.4836191e-02 -2.5762028e-01 -1.2927065e+00  2.0000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.91  2.908 2.913 ... 2.964 2.969 2.976]\n",
      " [2.891 2.896 2.901 ... 2.965 2.966 2.965]\n",
      " [2.9   2.892 2.889 ... 2.958 2.96  2.955]\n",
      " ...\n",
      " [2.764 2.762 2.763 ... 2.77  2.768 2.764]\n",
      " [2.751 2.748 2.751 ... 2.77  2.762 2.753]\n",
      " [2.738 2.731 2.736 ... 2.758 2.752 2.745]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B9B0>\n",
      "tensor([[ 0.0141, -0.0910, -0.2445,  ...,  0.0470, -0.2786, -1.2964],\n",
      "        [ 0.0141, -0.0910, -0.2445,  ...,  0.0470, -0.2786, -1.2964],\n",
      "        [ 0.0141, -0.0910, -0.2445,  ...,  0.0470, -0.2786, -1.2964],\n",
      "        ...,\n",
      "        [-0.1516,  0.4268, -0.1444,  ..., -0.6985,  0.9139, -0.4008],\n",
      "        [-0.1699, -0.1378,  0.5848,  ..., -0.2604,  0.6359,  0.2366],\n",
      "        [-0.1699, -0.1378,  0.5848,  ..., -0.2604,  0.6359,  0.2366]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01414412 -0.09095238 -0.24446525  0.03410833 -0.23069283 -0.6537484\n",
      " -0.05203328 -0.41806698 -1.4101839  -0.19317636 -0.48119527 -1.7091125\n",
      " -0.35997617 -0.5977383  -2.182426   -0.18761429 -0.6992029  -1.5722935\n",
      "  0.03527329 -0.73189706 -1.3746928  -0.01771186 -0.670208   -1.4281751\n",
      " -0.02300245 -0.80359876 -1.5464501  -0.14261985 -0.5941044  -1.4845359\n",
      " -0.05884726 -0.65009224 -1.4611396  -0.06947879 -0.62501323 -1.5543411\n",
      "  0.05678671 -0.65084404 -1.6008776  -0.05061331 -0.50726676 -1.3124893\n",
      " -0.16672543 -0.28018552 -1.9583124  -0.01230714 -0.43760198 -1.9566069\n",
      "  0.14140397 -0.40377283 -1.4543616  -0.15592727 -0.2705272  -1.2466781\n",
      " -0.07184707 -0.24961914 -1.3283111  -0.02560469 -0.2663999  -1.4435781\n",
      "  0.04697931 -0.2786168  -1.2964313 ]\n",
      "data: [-4.31  0.45 -3.01 -4.2  -0.8  -1.49 -4.15 -1.02 -0.83  0.    0.    0.\n",
      " -4.31 -0.81  0.8  -4.24 -0.29 -0.5  -4.26 -0.23 -0.63 -4.18 -0.28 -0.36\n",
      "  0.    0.    0.   -4.26 -0.23 -0.63 -4.25 -0.09 -0.67 -4.19  0.01 -0.95\n",
      " -3.49  0.43 -3.72 -4.21  0.04 -0.95 -4.21  0.01 -0.95 -4.21  0.04 -0.95\n",
      " -4.21  0.01 -0.95  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.  ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[-0.0824, -0.2970, -0.1044,  ..., -0.0085, -0.5555, -0.3624],\n",
      "        [-0.0824, -0.2970, -0.1044,  ..., -0.0085, -0.5555, -0.3624],\n",
      "        [-0.0824, -0.2970, -0.1044,  ..., -0.0085, -0.5555, -0.3624],\n",
      "        ...,\n",
      "        [ 0.5776, -0.6314,  0.8774,  ..., -0.2719,  0.0573, -0.4911],\n",
      "        [ 0.2051,  0.1425,  0.5105,  ..., -1.4844,  0.6257,  0.3251],\n",
      "        [ 0.2051,  0.1425,  0.5105,  ..., -1.4844,  0.6257,  0.3251]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.08237121 -0.29699743 -0.10435835 -0.11440335 -0.42347357 -0.41711944\n",
      " -0.1088664  -0.51018816 -0.5419266  -0.07272343 -0.60548276 -0.5273174\n",
      " -0.0580902  -0.71269    -0.6310861  -0.15591393 -0.5839396  -0.67682296\n",
      "  0.02365306 -0.6048101  -0.23506126  0.00440232 -0.694944   -0.22132674\n",
      " -0.00637174 -0.7220081  -0.27433777 -0.15036274 -0.51101935 -0.7066076\n",
      " -0.11853023 -0.6017456  -0.6648519  -0.12004836 -0.6601113  -0.62445855\n",
      " -0.0708528  -0.76427734 -0.6074215  -0.14505261 -0.5001761  -0.6499835\n",
      " -0.13694173 -0.48995697 -0.61410785 -0.10715327 -0.5834606  -0.5920764\n",
      " -0.04734404 -0.6748611  -0.50016886 -0.14453387 -0.37566528 -0.5491251\n",
      " -0.0839733  -0.43928185 -0.4812569  -0.0694702  -0.47564512 -0.4980647\n",
      " -0.00849488 -0.55551827 -0.36244005]\n",
      "init: [-0.08237121 -0.29699743 -0.10435835 -0.11440335 -0.42347357 -0.41711944\n",
      " -0.1088664  -0.51018816 -0.5419266  -0.07272343 -0.60548276 -0.5273174\n",
      " -0.0580902  -0.71269    -0.6310861  -0.15591393 -0.5839396  -0.67682296\n",
      "  0.02365306 -0.6048101  -0.23506126  0.00440232 -0.694944   -0.22132674\n",
      " -0.00637174 -0.7220081  -0.27433777 -0.15036274 -0.51101935 -0.7066076\n",
      " -0.11853023 -0.6017456  -0.6648519  -0.12004836 -0.6601113  -0.62445855\n",
      " -0.0708528  -0.76427734 -0.6074215  -0.14505261 -0.5001761  -0.6499835\n",
      " -0.13694173 -0.48995697 -0.61410785 -0.10715327 -0.5834606  -0.5920764\n",
      " -0.04734404 -0.6748611  -0.50016886 -0.14453387 -0.37566528 -0.5491251\n",
      " -0.0839733  -0.43928185 -0.4812569  -0.0694702  -0.47564512 -0.4980647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.00849488 -0.55551827 -0.36244005]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [-0.08237121 -0.29699743 -0.10435835 -0.11440335 -0.42347354 -0.41711944\n",
      " -0.10886641 -0.51018816 -0.5419266  -0.07272343 -0.60548276 -0.5273174\n",
      " -0.0580902  -0.71269    -0.6310861  -0.15591393 -0.5839396  -0.67682296\n",
      "  0.02365306 -0.6048101  -0.23506126  0.00440232 -0.694944   -0.22132674\n",
      " -0.00637174 -0.7220081  -0.27433777 -0.15036274 -0.51101935 -0.7066076\n",
      " -0.11853023 -0.6017456  -0.6648519  -0.12004836 -0.6601113  -0.62445855\n",
      " -0.0708528  -0.76427734 -0.6074215  -0.14505261 -0.5001761  -0.6499835\n",
      " -0.13694173 -0.48995697 -0.61410785 -0.10715327 -0.5834606  -0.5920764\n",
      " -0.04734404 -0.6748611  -0.50016886 -0.14453387 -0.37566528 -0.5491251\n",
      " -0.0839733  -0.43928185 -0.4812569  -0.0694702  -0.47564515 -0.4980647\n",
      " -0.00849488 -0.55551827 -0.36244002  0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B9B0>\n",
      "tensor([[ 0.0898, -0.1905,  0.0605,  ...,  0.1530, -0.3372, -1.0051],\n",
      "        [ 0.0898, -0.1905,  0.0605,  ...,  0.1530, -0.3372, -1.0051],\n",
      "        [ 0.0898, -0.1905,  0.0605,  ...,  0.1530, -0.3372, -1.0051],\n",
      "        ...,\n",
      "        [ 0.2155,  0.0387, -0.3475,  ...,  0.3806,  0.7636, -0.8347],\n",
      "        [-0.2069,  0.2102,  0.2662,  ..., -0.4850,  0.8166, -0.0660],\n",
      "        [-0.2069,  0.2102,  0.2662,  ..., -0.4850,  0.8166, -0.0660]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.08975942 -0.1904518   0.06051809  0.09272462 -0.34948695 -0.32752\n",
      "  0.006835   -0.5210867  -0.9992012  -0.16646835 -0.5669707  -1.2986106\n",
      " -0.37283796 -0.70134056 -1.7678319  -0.17017686 -0.7605741  -1.2416204\n",
      "  0.0731533  -0.78222156 -1.0771552   0.0402689  -0.6886784  -1.104684\n",
      "  0.071819   -0.8111019  -1.1905549  -0.10850534 -0.6378715  -1.1653081\n",
      "  0.00823242 -0.70085    -1.1198783   0.02917005 -0.66838026 -1.2096457\n",
      "  0.18430918 -0.68043804 -1.2692374   0.0272565  -0.571288   -1.006074\n",
      " -0.06774734 -0.32742304 -1.5171233   0.09148137 -0.50402796 -1.4863981\n",
      "  0.26704034 -0.4341736  -1.150228   -0.0872279  -0.32614547 -0.95402527\n",
      "  0.01552914 -0.29306525 -1.0137415   0.0861415  -0.3359058  -1.1344341\n",
      "  0.15304619 -0.33723998 -1.0050874 ]\n",
      "data: [ 0.08975942 -0.1904518   0.06051808  0.09272462 -0.34948695 -0.32752\n",
      "  0.006835   -0.5210867  -0.9992012  -0.16646835 -0.5669707  -1.2986106\n",
      " -0.37283793 -0.70134056 -1.7678319  -0.17017686 -0.7605741  -1.2416204\n",
      "  0.0731533  -0.78222156 -1.0771552   0.0402689  -0.6886784  -1.104684\n",
      "  0.071819   -0.8111019  -1.1905549  -0.10850534 -0.6378715  -1.1653081\n",
      "  0.00823242 -0.70085    -1.1198783   0.02917005 -0.66838026 -1.2096457\n",
      "  0.18430918 -0.6804381  -1.2692374   0.0272565  -0.571288   -1.006074\n",
      " -0.06774734 -0.327423   -1.5171235   0.09148137 -0.50402796 -1.4863982\n",
      "  0.26704034 -0.4341736  -1.150228   -0.0872279  -0.32614547 -0.95402527\n",
      "  0.01552914 -0.29306525 -1.0137415   0.0861415  -0.3359058  -1.1344341\n",
      "  0.15304619 -0.33723998 -1.0050874   0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F978>\n",
      "tensor([[ 1.6096e-02, -8.3678e-02, -2.1286e-01,  ..., -1.7652e-02,\n",
      "         -2.8729e-01, -1.2199e+00],\n",
      "        [ 1.6096e-02, -8.3678e-02, -2.1286e-01,  ..., -1.7652e-02,\n",
      "         -2.8729e-01, -1.2199e+00],\n",
      "        [ 1.6096e-02, -8.3678e-02, -2.1286e-01,  ..., -1.7652e-02,\n",
      "         -2.8729e-01, -1.2199e+00],\n",
      "        ...,\n",
      "        [-2.3710e-01,  3.1786e-01, -2.0161e-02,  ..., -3.4848e-01,\n",
      "          1.0062e+00, -5.6351e-01],\n",
      "        [-2.4335e-01,  1.0544e-01,  4.7116e-01,  ..., -3.3326e-01,\n",
      "          8.4172e-01,  1.1861e-05],\n",
      "        [-2.4335e-01,  1.0544e-01,  4.7116e-01,  ..., -3.3326e-01,\n",
      "          8.4172e-01,  1.1861e-05]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01609566 -0.08367828 -0.21285805  0.01086555 -0.22035709 -0.5713349\n",
      " -0.15149462 -0.44472337 -1.3819046  -0.32226086 -0.5258864  -1.6548996\n",
      " -0.50887936 -0.6063216  -2.158615   -0.19463512 -0.7257307  -1.5750622\n",
      " -0.08460354 -0.79695696 -1.3902259  -0.12400409 -0.6987848  -1.44657\n",
      " -0.1215019  -0.877606   -1.5477921  -0.16463622 -0.61711854 -1.4934759\n",
      " -0.13176936 -0.6711462  -1.412159   -0.17221332 -0.6608914  -1.4892333\n",
      " -0.01253979 -0.647681   -1.4961687  -0.09640018 -0.5342941  -1.344714\n",
      " -0.23184454 -0.30536819 -1.9860142  -0.10258348 -0.4653074  -2.0016003\n",
      "  0.07516586 -0.43550217 -1.3581618  -0.19106844 -0.2945233  -1.2657759\n",
      " -0.16972858 -0.27073342 -1.3328286  -0.14113432 -0.2594539  -1.4384191\n",
      " -0.0176519  -0.28729123 -1.2198604 ]\n",
      "data: [ 0.01609566 -0.08367828 -0.21285805  0.01086555 -0.22035709 -0.5713349\n",
      " -0.15149462 -0.44472337 -1.3819046  -0.32226086 -0.5258864  -1.6548996\n",
      " -0.50887936 -0.6063216  -2.158615   -0.19463512 -0.7257307  -1.5750622\n",
      " -0.08460354 -0.79695696 -1.3902259  -0.12400409 -0.69878477 -1.4465699\n",
      " -0.1215019  -0.877606   -1.5477921  -0.16463622 -0.61711854 -1.4934759\n",
      " -0.13176936 -0.6711462  -1.412159   -0.17221333 -0.6608914  -1.4892333\n",
      " -0.01253979 -0.647681   -1.4961686  -0.09640017 -0.5342941  -1.344714\n",
      " -0.23184454 -0.30536819 -1.9860142  -0.10258348 -0.4653074  -2.0016003\n",
      "  0.07516586 -0.43550217 -1.3581618  -0.19106844 -0.2945233  -1.2657759\n",
      " -0.16972858 -0.27073342 -1.3328286  -0.14113432 -0.2594539  -1.438419\n",
      " -0.0176519  -0.28729123 -1.2198604   0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[ 0.0071, -0.0096, -0.1690,  ...,  0.0410, -0.1923, -1.1759],\n",
      "        [ 0.0071, -0.0096, -0.1690,  ...,  0.0410, -0.1923, -1.1759],\n",
      "        [ 0.0071, -0.0096, -0.1690,  ...,  0.0410, -0.1923, -1.1759],\n",
      "        ...,\n",
      "        [-0.1572,  0.3806,  0.0180,  ..., -0.9372,  0.9660, -0.3112],\n",
      "        [-0.1122, -0.1055,  0.5879,  ..., -0.2618,  0.5605,  0.2835],\n",
      "        [-0.1122, -0.1055,  0.5879,  ..., -0.2618,  0.5605,  0.2835]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0070612  -0.00956214 -0.1690342   0.0287354  -0.1301223  -0.50828874\n",
      " -0.07570503 -0.32814047 -1.3165054  -0.22013377 -0.38606796 -1.6197591\n",
      " -0.39126134 -0.49087954 -2.105123   -0.19429183 -0.62354547 -1.4941965\n",
      "  0.02514653 -0.6592959  -1.307265   -0.02078466 -0.6005319  -1.3567239\n",
      " -0.00865631 -0.7456844  -1.486061   -0.15092732 -0.5207265  -1.3951892\n",
      " -0.0643739  -0.57636416 -1.3675096  -0.05740287 -0.5475953  -1.4678167\n",
      "  0.09826046 -0.5851557  -1.5130727  -0.06094325 -0.42185032 -1.2189964\n",
      " -0.20320486 -0.19145143 -1.9576037  -0.01074833 -0.35956404 -1.9698801\n",
      "  0.1775616  -0.32512766 -1.3519754  -0.18231817 -0.18365154 -1.140848\n",
      " -0.09716664 -0.1624268  -1.216015   -0.05456793 -0.17543465 -1.3392179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.04099769 -0.19231091 -1.1758525 ]\n",
      "data: [ 0.0070612  -0.00956214 -0.1690342   0.02873539 -0.1301223  -0.50828874\n",
      " -0.07570503 -0.32814044 -1.3165054  -0.22013377 -0.38606796 -1.6197591\n",
      " -0.39126134 -0.4908795  -2.105123   -0.19429184 -0.62354547 -1.4941964\n",
      "  0.02514653 -0.65929586 -1.307265   -0.02078466 -0.6005319  -1.3567239\n",
      " -0.00865631 -0.7456844  -1.486061   -0.15092732 -0.5207265  -1.3951892\n",
      " -0.0643739  -0.57636416 -1.3675096  -0.05740287 -0.5475953  -1.4678168\n",
      "  0.09826046 -0.5851557  -1.5130726  -0.06094326 -0.42185032 -1.2189964\n",
      " -0.20320486 -0.19145143 -1.9576038  -0.01074833 -0.359564   -1.9698801\n",
      "  0.17756158 -0.3251277  -1.3519754  -0.18231817 -0.18365154 -1.140848\n",
      " -0.09716664 -0.1624268  -1.216015   -0.05456793 -0.17543465 -1.3392178\n",
      "  0.04099769 -0.1923109  -1.1758525   0.04      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63320>\n",
      "tensor([[ 0.0068, -0.0978, -0.2305,  ...,  0.0260, -0.2605, -1.3255],\n",
      "        [ 0.0068, -0.0978, -0.2305,  ...,  0.0260, -0.2605, -1.3255],\n",
      "        [ 0.0068, -0.0978, -0.2305,  ...,  0.0260, -0.2605, -1.3255],\n",
      "        ...,\n",
      "        [-0.3267,  0.2852, -0.2436,  ..., -0.8019,  0.7460, -0.3921],\n",
      "        [-0.1839,  0.0041,  0.5745,  ..., -0.2882,  0.7726,  0.2922],\n",
      "        [-0.1839,  0.0041,  0.5745,  ..., -0.2882,  0.7726,  0.2922]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00679338 -0.09782396 -0.23051181  0.02775209 -0.256637   -0.69127935\n",
      " -0.0272936  -0.41734925 -1.3986435  -0.1653002  -0.47322857 -1.7016163\n",
      " -0.3381601  -0.6054168  -2.1669176  -0.21188144 -0.68163025 -1.5576272\n",
      "  0.04640853 -0.69116306 -1.3412938  -0.00979798 -0.63474613 -1.3920443\n",
      " -0.01586368 -0.74035335 -1.5055001  -0.16647097 -0.56714904 -1.4791822\n",
      " -0.06419982 -0.6215716  -1.4614162  -0.07265335 -0.5935215  -1.5596578\n",
      "  0.03980562 -0.6178428  -1.6218817  -0.06604845 -0.49227378 -1.3027873\n",
      " -0.16002169 -0.2622275  -1.870539   -0.0219647  -0.41047424 -1.8524294\n",
      "  0.1132068  -0.37562943 -1.4768994  -0.1666619  -0.25009283 -1.2484658\n",
      " -0.07014756 -0.2295617  -1.3231287  -0.01767449 -0.2553013  -1.4409909\n",
      "  0.02603606 -0.2604615  -1.3255241 ]\n",
      "data: [ 0.00679338 -0.09782396 -0.23051181  0.02775209 -0.256637   -0.69127935\n",
      " -0.0272936  -0.41734925 -1.3986435  -0.16530019 -0.47322857 -1.7016162\n",
      " -0.3381601  -0.6054168  -2.1669176  -0.21188144 -0.68163025 -1.5576272\n",
      "  0.04640853 -0.691163   -1.3412938  -0.00979798 -0.63474613 -1.3920444\n",
      " -0.01586368 -0.74035335 -1.5055001  -0.16647096 -0.56714904 -1.4791822\n",
      " -0.06419982 -0.6215716  -1.4614164  -0.07265335 -0.5935215  -1.5596577\n",
      "  0.03980562 -0.6178428  -1.6218817  -0.06604845 -0.49227378 -1.3027873\n",
      " -0.16002169 -0.2622275  -1.870539   -0.0219647  -0.41047424 -1.8524294\n",
      "  0.1132068  -0.37562943 -1.4768994  -0.16666192 -0.25009283 -1.2484658\n",
      " -0.07014756 -0.22956172 -1.3231287  -0.01767449 -0.2553013  -1.4409909\n",
      "  0.02603606 -0.2604615  -1.3255241   0.05      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B320>\n",
      "tensor([[ 0.0490, -0.1444, -0.2975,  ...,  0.0581, -0.3210, -1.3622],\n",
      "        [ 0.0490, -0.1444, -0.2975,  ...,  0.0581, -0.3210, -1.3622],\n",
      "        [ 0.0490, -0.1444, -0.2975,  ...,  0.0581, -0.3210, -1.3622],\n",
      "        ...,\n",
      "        [-0.1579,  0.4551, -0.1086,  ..., -0.7319,  0.9623, -0.4062],\n",
      "        [-0.1905, -0.0919,  0.6372,  ..., -0.2588,  0.6664,  0.3070],\n",
      "        [-0.1905, -0.0919,  0.6372,  ..., -0.2588,  0.6664,  0.3070]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04901105 -0.14436866 -0.2974565   0.07847281 -0.269755   -0.6889219\n",
      " -0.01751412 -0.47094125 -1.4841844  -0.16235405 -0.5322577  -1.7855381\n",
      " -0.31481415 -0.63844275 -2.2831569  -0.15302175 -0.756219   -1.660805\n",
      "  0.06240993 -0.7997719  -1.4751387   0.00389858 -0.73728156 -1.5267875\n",
      " -0.01376478 -0.88043916 -1.6504494  -0.10913789 -0.6583656  -1.5644424\n",
      " -0.03653064 -0.713254   -1.5440123  -0.05156519 -0.6832229  -1.6353072\n",
      "  0.06428257 -0.7180401  -1.672878   -0.0199912  -0.55713236 -1.3956195\n",
      " -0.15717942 -0.32456392 -2.0841439   0.00557747 -0.49032655 -2.0923755\n",
      "  0.15348518 -0.45184526 -1.5296317  -0.13596892 -0.32429928 -1.3224219\n",
      " -0.05373294 -0.29691625 -1.4023025  -0.01545603 -0.31246728 -1.5158187\n",
      "  0.05813035 -0.32103753 -1.3622139 ]\n",
      "data: [ 0.04901105 -0.14436866 -0.2974565   0.07847281 -0.269755   -0.688922\n",
      " -0.01751412 -0.47094125 -1.4841844  -0.16235405 -0.5322577  -1.7855381\n",
      " -0.31481415 -0.63844275 -2.2831569  -0.15302175 -0.756219   -1.6608051\n",
      "  0.06240993 -0.7997719  -1.4751387   0.00389858 -0.73728156 -1.5267875\n",
      " -0.01376478 -0.88043916 -1.6504494  -0.10913789 -0.6583656  -1.5644424\n",
      " -0.03653064 -0.7132539  -1.5440123  -0.05156519 -0.6832229  -1.6353072\n",
      "  0.06428257 -0.7180401  -1.6728779  -0.0199912  -0.55713236 -1.3956195\n",
      " -0.15717942 -0.3245639  -2.0841439   0.00557747 -0.49032652 -2.0923755\n",
      "  0.15348518 -0.45184526 -1.5296319  -0.13596892 -0.32429928 -1.3224219\n",
      " -0.05373294 -0.29691625 -1.4023025  -0.01545603 -0.31246728 -1.5158188\n",
      "  0.05813035 -0.32103753 -1.3622139   0.06      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[-0.0102, -0.1129, -0.2447,  ...,  0.0237, -0.2924, -1.3263],\n",
      "        [-0.0102, -0.1129, -0.2447,  ...,  0.0237, -0.2924, -1.3263],\n",
      "        [-0.0102, -0.1129, -0.2447,  ...,  0.0237, -0.2924, -1.3263],\n",
      "        ...,\n",
      "        [-0.0586,  0.5023, -0.0740,  ..., -0.6704,  1.0038, -0.3310],\n",
      "        [-0.0788, -0.0354,  0.5829,  ..., -0.1539,  0.6644,  0.2853],\n",
      "        [-0.0788, -0.0354,  0.5829,  ..., -0.1539,  0.6644,  0.2853]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-1.0195184e-02 -1.1290607e-01 -2.4472378e-01  1.2085028e-03\n",
      " -2.7172238e-01 -6.8915188e-01 -2.5258832e-02 -4.4046989e-01\n",
      " -1.3921995e+00 -1.6639888e-01 -4.9140063e-01 -1.7269707e+00\n",
      " -3.6099601e-01 -6.4298528e-01 -2.1741908e+00 -2.3846789e-01\n",
      " -6.9436550e-01 -1.5868394e+00  6.5321580e-02 -7.1010810e-01\n",
      " -1.3671191e+00 -1.9726604e-03 -6.6668701e-01 -1.4118826e+00\n",
      " -2.3453459e-03 -7.8149849e-01 -1.5293047e+00 -1.7855382e-01\n",
      " -5.7046670e-01 -1.4856796e+00 -6.5604538e-02 -6.4079010e-01\n",
      " -1.4758008e+00 -6.2120661e-02 -6.2877035e-01 -1.5897098e+00\n",
      "  3.9272189e-02 -6.6816080e-01 -1.6602263e+00 -5.7961695e-02\n",
      " -4.8884740e-01 -1.2942610e+00 -1.7467068e-01 -2.7090302e-01\n",
      " -1.9120128e+00 -2.1075986e-02 -4.4252533e-01 -1.8844888e+00\n",
      "  1.1890848e-01 -4.0226680e-01 -1.4849963e+00 -1.7878935e-01\n",
      " -2.4427377e-01 -1.2382863e+00 -5.7324007e-02 -2.3648718e-01\n",
      " -1.3088837e+00 -4.7258586e-03 -2.8852350e-01 -1.4243824e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.3677029e-02 -2.9235220e-01 -1.3263414e+00]\n",
      "data: [-1.0195184e-02 -1.1290607e-01 -2.4472378e-01  1.2085028e-03\n",
      " -2.7172238e-01 -6.8915194e-01 -2.5258832e-02 -4.4046989e-01\n",
      " -1.3921995e+00 -1.6639888e-01 -4.9140063e-01 -1.7269707e+00\n",
      " -3.6099601e-01 -6.4298528e-01 -2.1741908e+00 -2.3846789e-01\n",
      " -6.9436556e-01 -1.5868394e+00  6.5321580e-02 -7.1010810e-01\n",
      " -1.3671192e+00 -1.9726604e-03 -6.6668701e-01 -1.4118826e+00\n",
      " -2.3453459e-03 -7.8149849e-01 -1.5293049e+00 -1.7855380e-01\n",
      " -5.7046670e-01 -1.4856796e+00 -6.5604538e-02 -6.4079010e-01\n",
      " -1.4758008e+00 -6.2120661e-02 -6.2877035e-01 -1.5897098e+00\n",
      "  3.9272189e-02 -6.6816080e-01 -1.6602263e+00 -5.7961691e-02\n",
      " -4.8884737e-01 -1.2942610e+00 -1.7467068e-01 -2.7090302e-01\n",
      " -1.9120128e+00 -2.1075986e-02 -4.4252533e-01 -1.8844888e+00\n",
      "  1.1890848e-01 -4.0226680e-01 -1.4849963e+00 -1.7878935e-01\n",
      " -2.4427375e-01 -1.2382863e+00 -5.7324007e-02 -2.3648718e-01\n",
      " -1.3088837e+00 -4.7258586e-03 -2.8852350e-01 -1.4243824e+00\n",
      "  2.3677029e-02 -2.9235220e-01 -1.3263414e+00  7.0000000e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0523, -0.1376, -0.2577,  ...,  0.0403, -0.3134, -1.3075],\n",
      "        [ 0.0523, -0.1376, -0.2577,  ...,  0.0403, -0.3134, -1.3075],\n",
      "        [ 0.0523, -0.1376, -0.2577,  ...,  0.0403, -0.3134, -1.3075],\n",
      "        ...,\n",
      "        [-0.1003,  0.4500, -0.1453,  ..., -0.6384,  0.9246, -0.4373],\n",
      "        [-0.1599, -0.0911,  0.6303,  ..., -0.2123,  0.6456,  0.3282],\n",
      "        [-0.1599, -0.0911,  0.6303,  ..., -0.2123,  0.6456,  0.3282]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.05227468 -0.13757041 -0.25769007  0.08277778 -0.24887583 -0.62255293\n",
      " -0.03740469 -0.4669207  -1.4441328  -0.18579145 -0.5298965  -1.7386718\n",
      " -0.33113688 -0.6193746  -2.2489133  -0.14323752 -0.76504093 -1.6178327\n",
      "  0.03303571 -0.824106   -1.4586799  -0.02562512 -0.75476176 -1.5127516\n",
      " -0.0476957  -0.9179377  -1.6372023  -0.10419726 -0.6761972  -1.5195689\n",
      " -0.05176958 -0.726771   -1.4951305  -0.0752093  -0.6944747  -1.5825067\n",
      "  0.04217016 -0.72781867 -1.6026502  -0.02620622 -0.5614302  -1.3624179\n",
      " -0.18208246 -0.32921326 -2.104256   -0.0124675  -0.49694723 -2.1282837\n",
      "  0.1369895  -0.4581747  -1.4722352  -0.14331563 -0.33521822 -1.2828493\n",
      " -0.07919806 -0.30353683 -1.3705664  -0.05211587 -0.30565754 -1.4837084\n",
      "  0.04034097 -0.31338835 -1.3074653 ]\n",
      "data: [ 0.05227468 -0.13757041 -0.25769007  0.08277778 -0.24887583 -0.62255293\n",
      " -0.03740469 -0.4669207  -1.4441328  -0.18579145 -0.5298965  -1.7386718\n",
      " -0.33113688 -0.6193746  -2.2489133  -0.14323752 -0.765041   -1.6178327\n",
      "  0.03303571 -0.824106   -1.4586799  -0.02562512 -0.75476176 -1.5127516\n",
      " -0.0476957  -0.9179377  -1.6372023  -0.10419726 -0.67619723 -1.5195689\n",
      " -0.05176958 -0.726771   -1.4951307  -0.0752093  -0.6944747  -1.5825067\n",
      "  0.04217016 -0.72781867 -1.6026502  -0.02620622 -0.5614302  -1.3624179\n",
      " -0.18208246 -0.32921326 -2.104256   -0.0124675  -0.4969472  -2.1282837\n",
      "  0.1369895  -0.4581747  -1.4722352  -0.14331563 -0.33521825 -1.2828493\n",
      " -0.07919806 -0.30353683 -1.3705664  -0.05211587 -0.30565754 -1.4837084\n",
      "  0.04034097 -0.31338835 -1.3074653   0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0120, -0.0695, -0.1824,  ...,  0.0673, -0.2704, -1.1748],\n",
      "        [ 0.0120, -0.0695, -0.1824,  ...,  0.0673, -0.2704, -1.1748],\n",
      "        [ 0.0120, -0.0695, -0.1824,  ...,  0.0673, -0.2704, -1.1748],\n",
      "        ...,\n",
      "        [-0.1276,  0.3669, -0.0470,  ..., -0.8188,  0.8687, -0.3267],\n",
      "        [-0.1010, -0.0887,  0.5476,  ..., -0.1804,  0.6049,  0.1863],\n",
      "        [-0.1010, -0.0887,  0.5476,  ..., -0.1804,  0.6049,  0.1863]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01196193 -0.06946506 -0.1823968   0.03724331 -0.18598138 -0.50577456\n",
      " -0.06375476 -0.39208707 -1.3105845  -0.21190123 -0.45128256 -1.6194286\n",
      " -0.3747337  -0.56682223 -2.108869   -0.18716174 -0.68784755 -1.4935473\n",
      "  0.03258489 -0.7370684  -1.3345361  -0.02961127 -0.6750138  -1.3851194\n",
      " -0.02924164 -0.83039516 -1.5097519  -0.13299723 -0.59313387 -1.3885874\n",
      " -0.05496302 -0.6529089  -1.3729815  -0.06057993 -0.62777877 -1.4692798\n",
      "  0.06494133 -0.6689718  -1.500152   -0.03322989 -0.48969448 -1.2124082\n",
      " -0.1805309  -0.26017663 -1.9590275   0.0031127  -0.43934524 -1.9686645\n",
      "  0.16964194 -0.4032339  -1.3468858  -0.15474968 -0.25994092 -1.1410322\n",
      " -0.06033179 -0.24195564 -1.2256444  -0.02252643 -0.2608995  -1.3411716\n",
      "  0.06726096 -0.27043426 -1.1748115 ]\n",
      "data: [ 0.01196193 -0.06946506 -0.1823968   0.03724331 -0.18598136 -0.50577456\n",
      " -0.06375476 -0.39208707 -1.3105845  -0.21190123 -0.4512826  -1.6194288\n",
      " -0.3747337  -0.56682223 -2.108869   -0.18716174 -0.6878475  -1.4935473\n",
      "  0.03258489 -0.7370684  -1.3345361  -0.02961127 -0.6750138  -1.3851194\n",
      " -0.02924164 -0.8303951  -1.5097519  -0.13299723 -0.59313387 -1.3885874\n",
      " -0.05496302 -0.6529089  -1.3729815  -0.06057993 -0.62777877 -1.4692798\n",
      "  0.06494133 -0.6689718  -1.500152   -0.03322989 -0.48969448 -1.2124082\n",
      " -0.1805309  -0.26017663 -1.9590275   0.0031127  -0.43934524 -1.9686645\n",
      "  0.16964193 -0.4032339  -1.3468858  -0.15474968 -0.25994092 -1.1410322\n",
      " -0.06033179 -0.24195564 -1.2256444  -0.02252643 -0.2608995  -1.3411716\n",
      "  0.06726096 -0.27043426 -1.1748115   0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[-0.0111, -0.0481, -0.2307,  ...,  0.0174, -0.2464, -1.2138],\n",
      "        [-0.0111, -0.0481, -0.2307,  ...,  0.0174, -0.2464, -1.2138],\n",
      "        [-0.0111, -0.0481, -0.2307,  ...,  0.0174, -0.2464, -1.2138],\n",
      "        ...,\n",
      "        [-0.1528,  0.3385, -0.0458,  ..., -0.7414,  0.8445, -0.3099],\n",
      "        [-0.0999, -0.0677,  0.5620,  ..., -0.2015,  0.7000,  0.2104],\n",
      "        [-0.0999, -0.0677,  0.5620,  ..., -0.2015,  0.7000,  0.2104]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01106288 -0.04814006 -0.23074704  0.02109117 -0.13927417 -0.53565294\n",
      " -0.14791541 -0.37001473 -1.3969936  -0.3021707  -0.43950582 -1.6724608\n",
      " -0.44238815 -0.51093125 -2.1917012  -0.19012907 -0.6933391  -1.5519218\n",
      " -0.0671266  -0.7673876  -1.4228098  -0.11245176 -0.68006676 -1.481736\n",
      " -0.11971563 -0.8647664  -1.6054249  -0.15277249 -0.619576   -1.4561591\n",
      " -0.11484372 -0.6640094  -1.4206145  -0.13612694 -0.62638736 -1.4976702\n",
      "  0.01719002 -0.6492382  -1.5012398  -0.08677063 -0.5080017  -1.3035505\n",
      " -0.24275728 -0.2656985  -2.0881665  -0.0570116  -0.43264157 -2.1280596\n",
      "  0.12507376 -0.39888406 -1.3797944  -0.1965508  -0.28633273 -1.217766\n",
      " -0.15120533 -0.24974783 -1.3167655  -0.12120485 -0.2310207  -1.4315307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.017386   -0.24640486 -1.2138195 ]\n",
      "data: [-0.01106288 -0.04814006 -0.23074704  0.02109117 -0.13927417 -0.53565294\n",
      " -0.14791541 -0.37001473 -1.3969938  -0.3021707  -0.43950582 -1.6724608\n",
      " -0.44238815 -0.51093125 -2.1917012  -0.19012907 -0.6933391  -1.5519218\n",
      " -0.0671266  -0.7673876  -1.42281    -0.11245176 -0.68006676 -1.481736\n",
      " -0.11971563 -0.86476636 -1.6054248  -0.15277249 -0.619576   -1.4561591\n",
      " -0.11484372 -0.6640094  -1.4206145  -0.13612694 -0.62638736 -1.4976702\n",
      "  0.01719002 -0.6492382  -1.5012398  -0.08677063 -0.5080017  -1.3035504\n",
      " -0.24275728 -0.2656985  -2.0881665  -0.0570116  -0.43264157 -2.1280596\n",
      "  0.12507376 -0.39888406 -1.3797944  -0.1965508  -0.28633273 -1.217766\n",
      " -0.15120533 -0.24974783 -1.3167655  -0.12120485 -0.2310207  -1.4315307\n",
      "  0.017386   -0.24640486 -1.2138195   0.1       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0405, -0.0333, -0.1659,  ...,  0.0497, -0.2025, -1.2270],\n",
      "        [ 0.0405, -0.0333, -0.1659,  ...,  0.0497, -0.2025, -1.2270],\n",
      "        [ 0.0405, -0.0333, -0.1659,  ...,  0.0497, -0.2025, -1.2270],\n",
      "        ...,\n",
      "        [-0.2884,  0.1779, -0.1911,  ..., -0.8343,  0.6624, -0.4320],\n",
      "        [-0.2020, -0.1137,  0.5042,  ..., -0.3401,  0.6008,  0.2278],\n",
      "        [-0.2020, -0.1137,  0.5042,  ..., -0.3401,  0.6008,  0.2278]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04051511 -0.03331693 -0.16585918  0.0563082  -0.185063   -0.6009881\n",
      " -0.00945718 -0.35896045 -1.3281316  -0.1501046  -0.4144498  -1.6354041\n",
      " -0.3411782  -0.5383667  -2.086541   -0.17509025 -0.6302021  -1.482865\n",
      "  0.07982121 -0.64688396 -1.2582588   0.03329584 -0.5950565  -1.3054379\n",
      "  0.03452403 -0.71259004 -1.4234896  -0.13159764 -0.51140124 -1.3949006\n",
      " -0.03049249 -0.5716732  -1.3690025  -0.02585199 -0.5478838  -1.4722245\n",
      "  0.11021738 -0.5764422  -1.540108   -0.03525838 -0.43008345 -1.2166646\n",
      " -0.15188654 -0.2043712  -1.8558314   0.01159874 -0.3618912  -1.8434794\n",
      "  0.16964552 -0.32443857 -1.379777   -0.14719029 -0.18333419 -1.1541538\n",
      " -0.05854526 -0.16430357 -1.2270813  -0.00492485 -0.19071041 -1.3487628\n",
      "  0.04966798 -0.20252138 -1.227001  ]\n",
      "data: [ 0.04051511 -0.03331693 -0.16585918  0.0563082  -0.185063   -0.6009881\n",
      " -0.00945718 -0.35896045 -1.3281316  -0.1501046  -0.4144498  -1.6354041\n",
      " -0.3411782  -0.5383667  -2.086541   -0.17509025 -0.6302021  -1.482865\n",
      "  0.07982121 -0.646884   -1.2582588   0.03329584 -0.5950565  -1.3054379\n",
      "  0.03452403 -0.71259004 -1.4234896  -0.13159764 -0.51140124 -1.3949006\n",
      " -0.03049249 -0.5716732  -1.3690026  -0.02585199 -0.5478838  -1.4722245\n",
      "  0.11021738 -0.5764422  -1.5401081  -0.03525838 -0.43008345 -1.2166646\n",
      " -0.15188654 -0.2043712  -1.8558315   0.01159874 -0.3618912  -1.8434795\n",
      "  0.16964552 -0.32443854 -1.379777   -0.14719029 -0.18333417 -1.1541538\n",
      " -0.05854526 -0.16430357 -1.2270813  -0.00492485 -0.19071041 -1.3487629\n",
      "  0.04966798 -0.20252138 -1.227001    0.11      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0321, -0.0784, -0.2616,  ...,  0.0655, -0.2560, -1.3231],\n",
      "        [ 0.0321, -0.0784, -0.2616,  ...,  0.0655, -0.2560, -1.3231],\n",
      "        [ 0.0321, -0.0784, -0.2616,  ...,  0.0655, -0.2560, -1.3231],\n",
      "        ...,\n",
      "        [-0.1653,  0.4291, -0.1562,  ..., -0.7107,  0.9082, -0.3957],\n",
      "        [-0.1782, -0.1029,  0.5775,  ..., -0.2504,  0.6891,  0.2397],\n",
      "        [-0.1782, -0.1029,  0.5775,  ..., -0.2504,  0.6891,  0.2397]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 3.2126892e-02 -7.8365751e-02 -2.6157391e-01  5.0605293e-02\n",
      " -2.3104967e-01 -6.9401491e-01 -4.2091094e-02 -4.1548041e-01\n",
      " -1.4395804e+00 -1.8397093e-01 -4.8127779e-01 -1.7274630e+00\n",
      " -3.5331357e-01 -5.9952140e-01 -2.1935902e+00 -1.7774202e-01\n",
      " -6.8221319e-01 -1.5965146e+00  4.2446151e-02 -7.0950985e-01\n",
      " -1.3826318e+00 -1.9155592e-03 -6.4527124e-01 -1.4343685e+00\n",
      " -2.6525259e-03 -7.6813829e-01 -1.5477480e+00 -1.3540186e-01\n",
      " -5.7020038e-01 -1.5184039e+00 -4.7486842e-02 -6.2673306e-01\n",
      " -1.4844522e+00 -5.3459980e-02 -6.0018420e-01 -1.5716742e+00\n",
      "  8.4018782e-02 -6.1851227e-01 -1.6233308e+00 -4.4696800e-02\n",
      " -4.9244615e-01 -1.3471968e+00 -1.4681137e-01 -2.6341835e-01\n",
      " -1.9439993e+00  2.7487278e-03 -4.1533726e-01 -1.9365720e+00\n",
      "  1.6119909e-01 -3.7953687e-01 -1.4797662e+00 -1.4254825e-01\n",
      " -2.5113428e-01 -1.2835582e+00 -6.3111007e-02 -2.2685800e-01\n",
      " -1.3574060e+00 -7.7206641e-03 -2.4202543e-01 -1.4733531e+00\n",
      "  6.5487571e-02 -2.5601739e-01 -1.3231045e+00]\n",
      "data: [ 3.2126892e-02 -7.8365751e-02 -2.6157391e-01  5.0605293e-02\n",
      " -2.3104967e-01 -6.9401491e-01 -4.2091094e-02 -4.1548043e-01\n",
      " -1.4395804e+00 -1.8397093e-01 -4.8127782e-01 -1.7274631e+00\n",
      " -3.5331357e-01 -5.9952140e-01 -2.1935902e+00 -1.7774202e-01\n",
      " -6.8221319e-01 -1.5965146e+00  4.2446151e-02 -7.0950991e-01\n",
      " -1.3826318e+00 -1.9155592e-03 -6.4527124e-01 -1.4343685e+00\n",
      " -2.6525259e-03 -7.6813829e-01 -1.5477480e+00 -1.3540186e-01\n",
      " -5.7020038e-01 -1.5184039e+00 -4.7486838e-02 -6.2673306e-01\n",
      " -1.4844522e+00 -5.3459980e-02 -6.0018420e-01 -1.5716742e+00\n",
      "  8.4018782e-02 -6.1851227e-01 -1.6233308e+00 -4.4696797e-02\n",
      " -4.9244612e-01 -1.3471968e+00 -1.4681137e-01 -2.6341835e-01\n",
      " -1.9439993e+00  2.7487278e-03 -4.1533726e-01 -1.9365720e+00\n",
      "  1.6119909e-01 -3.7953687e-01 -1.4797662e+00 -1.4254825e-01\n",
      " -2.5113428e-01 -1.2835582e+00 -6.3111007e-02 -2.2685800e-01\n",
      " -1.3574060e+00 -7.7206641e-03 -2.4202543e-01 -1.4733531e+00\n",
      "  6.5487571e-02 -2.5601739e-01 -1.3231045e+00  1.2000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[ 0.0183, -0.1217, -0.2625,  ...,  0.0616, -0.3032, -1.3330],\n",
      "        [ 0.0183, -0.1217, -0.2625,  ...,  0.0616, -0.3032, -1.3330],\n",
      "        [ 0.0183, -0.1217, -0.2625,  ...,  0.0616, -0.3032, -1.3330],\n",
      "        ...,\n",
      "        [-0.1362,  0.4464, -0.1807,  ..., -0.7349,  0.9462, -0.4391],\n",
      "        [-0.1592, -0.1137,  0.6000,  ..., -0.2451,  0.6499,  0.2730],\n",
      "        [-0.1592, -0.1137,  0.6000,  ..., -0.2451,  0.6499,  0.2730]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01833197 -0.12169342 -0.26254633  0.03670681 -0.27322268 -0.6849513\n",
      " -0.02159786 -0.44560555 -1.4133418  -0.16257131 -0.50306225 -1.7234606\n",
      " -0.33734646 -0.63663816 -2.1883721  -0.19369712 -0.71586007 -1.5919485\n",
      "  0.06820505 -0.73484445 -1.392395    0.01172181 -0.680145   -1.441654\n",
      "  0.01578388 -0.7960535  -1.558208   -0.14276072 -0.60168546 -1.5037456\n",
      " -0.03844635 -0.66147697 -1.4876562  -0.03825776 -0.6375552  -1.5882906\n",
      "  0.08140712 -0.6688032  -1.6479235  -0.03633447 -0.52075636 -1.3222588\n",
      " -0.14161265 -0.29435617 -1.9269966   0.01051336 -0.45339167 -1.9113119\n",
      "  0.161576   -0.41685176 -1.493564   -0.14766476 -0.27850115 -1.2633781\n",
      " -0.04243248 -0.26183552 -1.3383275   0.00961874 -0.29432705 -1.4543355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.06156902 -0.3031764  -1.3330042 ]\n",
      "data: [ 0.01833197 -0.12169342 -0.26254633  0.03670681 -0.27322268 -0.6849513\n",
      " -0.02159786 -0.44560555 -1.4133419  -0.16257131 -0.50306225 -1.7234606\n",
      " -0.33734646 -0.63663816 -2.1883721  -0.19369712 -0.71586007 -1.5919485\n",
      "  0.06820505 -0.73484445 -1.392395    0.01172181 -0.680145   -1.4416538\n",
      "  0.01578388 -0.7960535  -1.558208   -0.14276072 -0.60168546 -1.5037456\n",
      " -0.03844635 -0.66147697 -1.4876562  -0.03825776 -0.6375552  -1.5882906\n",
      "  0.08140711 -0.6688033  -1.6479235  -0.03633447 -0.52075636 -1.3222587\n",
      " -0.14161265 -0.29435617 -1.9269966   0.01051336 -0.45339167 -1.9113117\n",
      "  0.161576   -0.41685176 -1.493564   -0.14766476 -0.27850115 -1.2633781\n",
      " -0.04243248 -0.26183552 -1.3383275   0.00961874 -0.29432705 -1.4543355\n",
      "  0.06156902 -0.3031764  -1.3330044   0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F908>\n",
      "tensor([[ 0.0431, -0.1784, -0.2640,  ...,  0.0680, -0.3526, -1.3439],\n",
      "        [ 0.0431, -0.1784, -0.2640,  ...,  0.0680, -0.3526, -1.3439],\n",
      "        [ 0.0431, -0.1784, -0.2640,  ...,  0.0680, -0.3526, -1.3439],\n",
      "        ...,\n",
      "        [-0.0950,  0.4859, -0.1712,  ..., -0.6246,  0.9719, -0.4834],\n",
      "        [-0.1657, -0.0456,  0.6339,  ..., -0.2319,  0.6788,  0.3177],\n",
      "        [-0.1657, -0.0456,  0.6339,  ..., -0.2319,  0.6788,  0.3177]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 4.3133002e-02 -1.7844738e-01 -2.6399603e-01  7.1498990e-02\n",
      " -3.1658936e-01 -6.5668720e-01  6.4850599e-04 -5.1223689e-01\n",
      " -1.4318393e+00 -1.4581265e-01 -5.7121140e-01 -1.7476627e+00\n",
      " -3.1332865e-01 -6.9696188e-01 -2.2328131e+00 -1.6907847e-01\n",
      " -7.8243136e-01 -1.6308755e+00  9.3427777e-02 -8.1872272e-01\n",
      " -1.4228979e+00  3.0685261e-02 -7.6689446e-01 -1.4671458e+00\n",
      "  1.4635935e-02 -8.9909530e-01 -1.5908984e+00 -1.1649102e-01\n",
      " -6.7329001e-01 -1.5302067e+00 -2.3317128e-02 -7.3890865e-01\n",
      " -1.5151459e+00 -2.6917778e-02 -7.1291983e-01 -1.6156092e+00\n",
      "  8.3741203e-02 -7.5799310e-01 -1.6675618e+00 -1.0812797e-02\n",
      " -5.7421994e-01 -1.3508896e+00 -1.4696577e-01 -3.4505779e-01\n",
      " -2.0286548e+00  2.1733873e-02 -5.2064168e-01 -2.0232255e+00\n",
      "  1.6951013e-01 -4.7745439e-01 -1.5122226e+00 -1.3692483e-01\n",
      " -3.3400184e-01 -1.2834655e+00 -3.2656461e-02 -3.1248200e-01\n",
      " -1.3578473e+00  1.3227642e-02 -3.4714368e-01 -1.4734805e+00\n",
      "  6.7983039e-02 -3.5260022e-01 -1.3438920e+00]\n",
      "data: [ 4.31330018e-02 -1.78447381e-01 -2.63996035e-01  7.14989901e-02\n",
      " -3.16589355e-01 -6.56687140e-01  6.48505986e-04 -5.12236893e-01\n",
      " -1.43183935e+00 -1.45812646e-01 -5.71211398e-01 -1.74766266e+00\n",
      " -3.13328654e-01 -6.96961880e-01 -2.23281312e+00 -1.69078469e-01\n",
      " -7.82431364e-01 -1.63087535e+00  9.34277698e-02 -8.18722665e-01\n",
      " -1.42289793e+00  3.06852609e-02 -7.66894460e-01 -1.46714580e+00\n",
      "  1.46359345e-02 -8.99095297e-01 -1.59089839e+00 -1.16491020e-01\n",
      " -6.73290014e-01 -1.53020656e+00 -2.33171266e-02 -7.38908589e-01\n",
      " -1.51514590e+00 -2.69177780e-02 -7.12919831e-01 -1.61560917e+00\n",
      "  8.37412104e-02 -7.57993102e-01 -1.66756177e+00 -1.08127967e-02\n",
      " -5.74219942e-01 -1.35088956e+00 -1.46965772e-01 -3.45057786e-01\n",
      " -2.02865481e+00  2.17338726e-02 -5.20641685e-01 -2.02322555e+00\n",
      "  1.69510111e-01 -4.77454364e-01 -1.51222265e+00 -1.36924833e-01\n",
      " -3.34001839e-01 -1.28346562e+00 -3.26564610e-02 -3.12481999e-01\n",
      " -1.35784733e+00  1.32276416e-02 -3.47143680e-01 -1.47348058e+00\n",
      "  6.79830387e-02 -3.52600217e-01 -1.34389186e+00  1.40000001e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0141, -0.1614, -0.1976,  ...,  0.0807, -0.3529, -1.2358],\n",
      "        [ 0.0141, -0.1614, -0.1976,  ...,  0.0807, -0.3529, -1.2358],\n",
      "        [ 0.0141, -0.1614, -0.1976,  ...,  0.0807, -0.3529, -1.2358],\n",
      "        ...,\n",
      "        [-0.0487,  0.5011, -0.1459,  ..., -0.5827,  1.0526, -0.5165],\n",
      "        [-0.0918, -0.0128,  0.6130,  ..., -0.1644,  0.6521,  0.2734],\n",
      "        [-0.0918, -0.0128,  0.6130,  ..., -0.1644,  0.6521,  0.2734]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01407174 -0.16144022 -0.19762897  0.04109814 -0.30192578 -0.5487237\n",
      " -0.02560877 -0.5006217  -1.3426574  -0.17409918 -0.5613394  -1.6669002\n",
      " -0.35365027 -0.7024965  -2.1448877  -0.20104942 -0.76755524 -1.5493103\n",
      "  0.08645503 -0.80496967 -1.3375238   0.01810515 -0.7569853  -1.3768582\n",
      "  0.01249434 -0.88866293 -1.5020943  -0.13826998 -0.65471566 -1.4398733\n",
      " -0.03274129 -0.72733235 -1.4266667  -0.02675994 -0.70415163 -1.5304207\n",
      "  0.08766393 -0.7567775  -1.584638   -0.01916706 -0.559183   -1.2474753\n",
      " -0.1578108  -0.3298821  -1.944666    0.02320004 -0.51654446 -1.9326125\n",
      "  0.18369043 -0.4726139  -1.4135206  -0.15269308 -0.3146929  -1.1806177\n",
      " -0.0285642  -0.30199653 -1.2544312   0.02292581 -0.3468952  -1.3701074\n",
      "  0.08065914 -0.35293704 -1.2357852 ]\n",
      "data: [ 0.01407174 -0.16144022 -0.19762897  0.04109814 -0.30192578 -0.5487237\n",
      " -0.02560877 -0.5006217  -1.3426574  -0.17409918 -0.5613394  -1.6669002\n",
      " -0.35365027 -0.70249647 -2.1448877  -0.20104942 -0.76755524 -1.5493103\n",
      "  0.08645503 -0.8049696  -1.3375238   0.01810515 -0.7569853  -1.3768582\n",
      "  0.01249434 -0.88866293 -1.5020943  -0.13826998 -0.65471566 -1.4398733\n",
      " -0.03274129 -0.72733235 -1.4266667  -0.02675994 -0.70415163 -1.5304207\n",
      "  0.08766393 -0.7567775  -1.5846381  -0.01916706 -0.559183   -1.2474753\n",
      " -0.1578108  -0.3298821  -1.944666    0.02320004 -0.51654446 -1.9326127\n",
      "  0.18369043 -0.4726139  -1.4135205  -0.15269308 -0.3146929  -1.1806177\n",
      " -0.0285642  -0.30199653 -1.2544312   0.02292581 -0.3468952  -1.3701074\n",
      "  0.08065914 -0.35293704 -1.2357852   0.15      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0116, -0.1015, -0.1694,  ...,  0.0299, -0.2975, -1.1612],\n",
      "        [ 0.0116, -0.1015, -0.1694,  ...,  0.0299, -0.2975, -1.1612],\n",
      "        [ 0.0116, -0.1015, -0.1694,  ...,  0.0299, -0.2975, -1.1612],\n",
      "        ...,\n",
      "        [-0.0798,  0.4560, -0.1052,  ..., -0.2859,  1.0222, -0.5019],\n",
      "        [-0.1082, -0.0545,  0.6358,  ..., -0.1976,  0.6422,  0.3010],\n",
      "        [-0.1082, -0.0545,  0.6358,  ..., -0.1976,  0.6422,  0.3010]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01161902 -0.10150626 -0.16938762  0.04399347 -0.20451166 -0.45262778\n",
      " -0.10740155 -0.44534987 -1.3278879  -0.26587224 -0.51640606 -1.612954\n",
      " -0.41139832 -0.60463154 -2.133138   -0.18137434 -0.7485421  -1.5121411\n",
      " -0.01605096 -0.82421887 -1.359814   -0.07061887 -0.7473978  -1.4076535\n",
      " -0.08365624 -0.92027104 -1.5324342  -0.13771072 -0.6615418  -1.4083054\n",
      " -0.08852495 -0.7159529  -1.3758937  -0.10135207 -0.6798086  -1.4525379\n",
      "  0.03519589 -0.7153151  -1.4638599  -0.05453257 -0.545318   -1.249712\n",
      " -0.22183023 -0.3051797  -2.0187492  -0.03472895 -0.4853955  -2.045906\n",
      "  0.13970548 -0.44147608 -1.3336768  -0.18230279 -0.31544518 -1.1669536\n",
      " -0.11497317 -0.28298584 -1.2540272  -0.08433278 -0.28469083 -1.363255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.02994648 -0.29750496 -1.1611731 ]\n",
      "data: [ 0.01161902 -0.10150626 -0.16938762  0.04399347 -0.20451166 -0.45262778\n",
      " -0.10740155 -0.44534987 -1.3278879  -0.26587224 -0.51640606 -1.6129539\n",
      " -0.41139832 -0.60463154 -2.133138   -0.18137434 -0.7485421  -1.5121411\n",
      " -0.01605096 -0.8242189  -1.359814   -0.07061887 -0.7473978  -1.4076535\n",
      " -0.08365624 -0.9202711  -1.5324342  -0.13771072 -0.6615418  -1.4083054\n",
      " -0.08852495 -0.71595293 -1.3758937  -0.10135207 -0.6798087  -1.4525379\n",
      "  0.03519589 -0.7153151  -1.4638599  -0.05453257 -0.545318   -1.249712\n",
      " -0.22183023 -0.3051797  -2.0187492  -0.03472895 -0.48539552 -2.045906\n",
      "  0.13970548 -0.44147605 -1.3336768  -0.18230277 -0.31544518 -1.1669536\n",
      " -0.11497317 -0.28298584 -1.2540272  -0.08433278 -0.28469083 -1.363255\n",
      "  0.02994648 -0.29750496 -1.1611731   0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[-4.5275e-02,  4.9877e-03, -2.0802e-01,  ...,  8.5229e-04,\n",
      "         -1.8313e-01, -1.1819e+00],\n",
      "        [-4.5275e-02,  4.9877e-03, -2.0802e-01,  ...,  8.5229e-04,\n",
      "         -1.8313e-01, -1.1819e+00],\n",
      "        [-4.5275e-02,  4.9877e-03, -2.0802e-01,  ...,  8.5229e-04,\n",
      "         -1.8313e-01, -1.1819e+00],\n",
      "        ...,\n",
      "        [-1.8381e-01,  3.2847e-01,  1.6680e-02,  ..., -6.6333e-01,\n",
      "          9.1168e-01, -3.6608e-01],\n",
      "        [-1.0052e-01, -1.0788e-01,  5.8840e-01,  ..., -2.3807e-01,\n",
      "          5.8078e-01,  2.5969e-01],\n",
      "        [-1.0052e-01, -1.0788e-01,  5.8840e-01,  ..., -2.3807e-01,\n",
      "          5.8078e-01,  2.5969e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-4.52751331e-02  4.98770364e-03 -2.08019689e-01 -2.12291293e-02\n",
      " -1.05974615e-01 -5.05237401e-01 -1.56887576e-01 -3.28140259e-01\n",
      " -1.34534800e+00 -3.11975121e-01 -3.90600741e-01 -1.63933420e+00\n",
      " -4.73405182e-01 -4.91414309e-01 -2.13744593e+00 -2.48081461e-01\n",
      " -6.30874217e-01 -1.51511014e+00 -5.05636334e-02 -6.86444581e-01\n",
      " -1.33768821e+00 -9.87808257e-02 -6.13001466e-01 -1.38692105e+00\n",
      " -9.39136297e-02 -7.71586359e-01 -1.51655793e+00 -2.01142281e-01\n",
      " -5.36046326e-01 -1.41270065e+00 -1.29853368e-01 -5.88849723e-01\n",
      " -1.38603210e+00 -1.22440509e-01 -5.51289082e-01 -1.47291040e+00\n",
      "  3.48831117e-02 -5.85999310e-01 -1.50007498e+00 -1.07742377e-01\n",
      " -4.28134561e-01 -1.24404871e+00 -2.61707485e-01 -1.86525837e-01\n",
      " -2.00199223e+00 -6.15230352e-02 -3.61850798e-01 -2.02083921e+00\n",
      "  1.34223729e-01 -3.18446577e-01 -1.35785973e+00 -2.34505758e-01\n",
      " -1.92858189e-01 -1.16422260e+00 -1.53533489e-01 -1.63309351e-01\n",
      " -1.25160420e+00 -1.13351122e-01 -1.69673219e-01 -1.36884916e+00\n",
      "  8.52294266e-04 -1.83131427e-01 -1.18189025e+00]\n",
      "data: [-4.52751368e-02  4.98770364e-03 -2.08019689e-01 -2.12291293e-02\n",
      " -1.05974615e-01 -5.05237401e-01 -1.56887576e-01 -3.28140259e-01\n",
      " -1.34534800e+00 -3.11975121e-01 -3.90600741e-01 -1.63933420e+00\n",
      " -4.73405182e-01 -4.91414309e-01 -2.13744593e+00 -2.48081461e-01\n",
      " -6.30874217e-01 -1.51511014e+00 -5.05636297e-02 -6.86444521e-01\n",
      " -1.33768809e+00 -9.87808257e-02 -6.13001466e-01 -1.38692105e+00\n",
      " -9.39136297e-02 -7.71586359e-01 -1.51655793e+00 -2.01142266e-01\n",
      " -5.36046326e-01 -1.41270065e+00 -1.29853368e-01 -5.88849723e-01\n",
      " -1.38603210e+00 -1.22440509e-01 -5.51289082e-01 -1.47291040e+00\n",
      "  3.48831117e-02 -5.85999310e-01 -1.50007486e+00 -1.07742377e-01\n",
      " -4.28134561e-01 -1.24404871e+00 -2.61707485e-01 -1.86525837e-01\n",
      " -2.00199223e+00 -6.15230352e-02 -3.61850828e-01 -2.02083921e+00\n",
      "  1.34223729e-01 -3.18446577e-01 -1.35785985e+00 -2.34505743e-01\n",
      " -1.92858174e-01 -1.16422260e+00 -1.53533489e-01 -1.63309351e-01\n",
      " -1.25160420e+00 -1.13351129e-01 -1.69673219e-01 -1.36884916e+00\n",
      "  8.52294266e-04 -1.83131427e-01 -1.18189025e+00  1.70000002e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[-0.0129, -0.0862, -0.1910,  ...,  0.0065, -0.2418, -1.3167],\n",
      "        [-0.0129, -0.0862, -0.1910,  ...,  0.0065, -0.2418, -1.3167],\n",
      "        [-0.0129, -0.0862, -0.1910,  ...,  0.0065, -0.2418, -1.3167],\n",
      "        ...,\n",
      "        [-0.2810,  0.3271, -0.2271,  ..., -0.7754,  0.7892, -0.4094],\n",
      "        [-0.1947, -0.1115,  0.5114,  ..., -0.2907,  0.6281,  0.2555],\n",
      "        [-0.1947, -0.1115,  0.5114,  ..., -0.2907,  0.6281,  0.2555]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01293548 -0.08616158 -0.19099958  0.00233452 -0.24991387 -0.6654668\n",
      " -0.03392708 -0.38915497 -1.3341639  -0.17272905 -0.43889868 -1.6457642\n",
      " -0.35559756 -0.5769253  -2.1060114  -0.23951985 -0.65964997 -1.496665\n",
      "  0.04729854 -0.6517259  -1.2642229  -0.00348477 -0.6001809  -1.3150786\n",
      " -0.0056577  -0.68921924 -1.4316676  -0.19420226 -0.5415384  -1.4230345\n",
      " -0.07326676 -0.5952524  -1.4188854  -0.07035038 -0.5621864  -1.5291986\n",
      "  0.05275446 -0.5877898  -1.608901   -0.08556502 -0.47265917 -1.2440338\n",
      " -0.16211501 -0.2438476  -1.7631187  -0.02733286 -0.3821156  -1.7380269\n",
      "  0.11514717 -0.34941965 -1.462751   -0.1879636  -0.22556108 -1.1965119\n",
      " -0.0824239  -0.20609805 -1.2740413  -0.0261928  -0.23774974 -1.398045\n",
      "  0.00646745 -0.24176735 -1.3166628 ]\n",
      "data: [-0.01293548 -0.08616158 -0.19099958  0.00233452 -0.24991387 -0.6654668\n",
      " -0.03392708 -0.38915497 -1.334164   -0.17272906 -0.43889868 -1.6457641\n",
      " -0.3555976  -0.5769253  -2.1060114  -0.23951985 -0.65964997 -1.496665\n",
      "  0.04729854 -0.65172595 -1.2642229  -0.00348477 -0.6001809  -1.3150786\n",
      " -0.0056577  -0.68921924 -1.4316677  -0.19420224 -0.5415384  -1.4230345\n",
      " -0.07326676 -0.5952524  -1.4188854  -0.07035038 -0.5621864  -1.5291986\n",
      "  0.05275446 -0.5877898  -1.608901   -0.08556502 -0.4726592  -1.2440338\n",
      " -0.16211501 -0.2438476  -1.7631187  -0.02733286 -0.3821156  -1.7380269\n",
      "  0.11514717 -0.34941968 -1.462751   -0.1879636  -0.22556108 -1.1965119\n",
      " -0.0824239  -0.20609803 -1.2740413  -0.0261928  -0.23774976 -1.398045\n",
      "  0.00646745 -0.24176735 -1.3166628   0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[ 0.0289, -0.1397, -0.2842,  ...,  0.0359, -0.3068, -1.3549],\n",
      "        [ 0.0289, -0.1397, -0.2842,  ...,  0.0359, -0.3068, -1.3549],\n",
      "        [ 0.0289, -0.1397, -0.2842,  ...,  0.0359, -0.3068, -1.3549],\n",
      "        ...,\n",
      "        [-0.1457,  0.4959, -0.1226,  ..., -0.7337,  1.0270, -0.4277],\n",
      "        [-0.1346,  0.0036,  0.6783,  ..., -0.2558,  0.7868,  0.3231],\n",
      "        [-0.1346,  0.0036,  0.6783,  ..., -0.2558,  0.7868,  0.3231]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02887894 -0.13969381 -0.2841589   0.06031522 -0.27013916 -0.6964988\n",
      " -0.03581865 -0.46394864 -1.4745903  -0.17804566 -0.525068   -1.7712995\n",
      " -0.32741365 -0.6281934  -2.266608   -0.17105725 -0.74591446 -1.6445297\n",
      "  0.0370397  -0.78090453 -1.4659113  -0.0148375  -0.7187002  -1.5204043\n",
      " -0.03075027 -0.8562783  -1.642901   -0.13181096 -0.6461954  -1.55491\n",
      " -0.05667228 -0.6986165  -1.5342062  -0.07190858 -0.66599905 -1.6238704\n",
      "  0.05082641 -0.6982244  -1.6664776  -0.04622811 -0.54739463 -1.3864366\n",
      " -0.17391291 -0.31427774 -2.0509005  -0.01478708 -0.47368678 -2.0587204\n",
      "  0.13304126 -0.43616286 -1.5231029  -0.1555275  -0.31485063 -1.3141557\n",
      " -0.07829446 -0.2835114  -1.3888729  -0.03738826 -0.29529834 -1.5060043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.03588054 -0.3068446  -1.3549037 ]\n",
      "data: [ 0.02887894 -0.13969381 -0.2841589   0.06031522 -0.27013916 -0.6964988\n",
      " -0.03581865 -0.46394864 -1.4745903  -0.17804566 -0.525068   -1.7712995\n",
      " -0.32741365 -0.6281934  -2.266608   -0.17105727 -0.74591446 -1.6445297\n",
      "  0.0370397  -0.78090453 -1.4659113  -0.0148375  -0.7187002  -1.5204043\n",
      " -0.03075027 -0.8562783  -1.642901   -0.13181096 -0.64619535 -1.55491\n",
      " -0.05667228 -0.6986165  -1.534206   -0.07190858 -0.66599905 -1.6238704\n",
      "  0.05082641 -0.6982244  -1.6664776  -0.04622811 -0.54739463 -1.3864366\n",
      " -0.17391291 -0.31427774 -2.0509005  -0.01478708 -0.47368678 -2.0587204\n",
      "  0.13304126 -0.43616286 -1.5231029  -0.1555275  -0.31485063 -1.3141557\n",
      " -0.07829446 -0.2835114  -1.3888729  -0.03738826 -0.29529834 -1.5060043\n",
      "  0.03588054 -0.3068446  -1.3549037   0.19      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FC50>\n",
      "tensor([[ 0.0112, -0.0977, -0.2234,  ...,  0.0524, -0.2787, -1.3026],\n",
      "        [ 0.0112, -0.0977, -0.2234,  ...,  0.0524, -0.2787, -1.3026],\n",
      "        [ 0.0112, -0.0977, -0.2234,  ...,  0.0524, -0.2787, -1.3026],\n",
      "        ...,\n",
      "        [-0.1421,  0.4689, -0.1453,  ..., -0.8235,  0.9658, -0.3905],\n",
      "        [-0.1153, -0.0810,  0.5647,  ..., -0.1959,  0.6285,  0.2374],\n",
      "        [-0.1153, -0.0810,  0.5647,  ..., -0.1959,  0.6285,  0.2374]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01116294 -0.09773988 -0.2233786   0.02391948 -0.25376058 -0.659579\n",
      " -0.00671173 -0.41911578 -1.3733609  -0.14740062 -0.47184873 -1.7046274\n",
      " -0.33712274 -0.6200443  -2.1598668  -0.21230908 -0.6809305  -1.5637126\n",
      "  0.08935295 -0.694084   -1.3465967   0.02400428 -0.65068024 -1.3920867\n",
      "  0.02649561 -0.76226836 -1.5121745  -0.15399921 -0.55995744 -1.464362\n",
      " -0.03733712 -0.6280211  -1.4547523  -0.03349166 -0.61118376 -1.5690241\n",
      "  0.07510632 -0.6524685  -1.6394346  -0.03535705 -0.47891074 -1.2721862\n",
      " -0.14616634 -0.25819677 -1.8840928   0.00776023 -0.42502737 -1.8597107\n",
      "  0.1544527  -0.38992035 -1.4653195  -0.15570788 -0.23235674 -1.2138156\n",
      " -0.03257193 -0.22423926 -1.2842914   0.01962624 -0.2729988  -1.4009775\n",
      "  0.05236875 -0.27866948 -1.302626  ]\n",
      "data: [ 0.01116294 -0.09773988 -0.2233786   0.02391948 -0.25376058 -0.65957904\n",
      " -0.00671173 -0.41911578 -1.3733609  -0.14740062 -0.47184873 -1.7046274\n",
      " -0.33712274 -0.6200443  -2.1598668  -0.21230908 -0.6809305  -1.5637126\n",
      "  0.08935295 -0.694084   -1.3465967   0.02400428 -0.65068024 -1.3920867\n",
      "  0.0264956  -0.76226836 -1.5121745  -0.15399921 -0.55995744 -1.464362\n",
      " -0.03733712 -0.6280211  -1.4547523  -0.03349166 -0.61118376 -1.5690241\n",
      "  0.07510632 -0.6524685  -1.6394345  -0.03535705 -0.47891074 -1.2721862\n",
      " -0.14616634 -0.25819677 -1.8840928   0.00776023 -0.4250274  -1.8597107\n",
      "  0.1544527  -0.38992035 -1.4653195  -0.15570788 -0.23235674 -1.2138156\n",
      " -0.03257193 -0.22423926 -1.2842914   0.01962624 -0.2729988  -1.4009775\n",
      "  0.05236875 -0.27866948 -1.302626    0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.143 3.143 3.149 ... 3.145 3.137 3.137]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " [3.124 3.124 3.122 ... 3.13  3.125 3.125]\n",
      " ...\n",
      " [2.963 2.963 2.969 ... 2.965 2.962 2.962]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]\n",
      " [2.953 2.953 2.957 ... 2.959 2.954 2.954]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[ 0.0259, -0.1042, -0.2516,  ...,  0.0540, -0.2881, -1.3168],\n",
      "        [ 0.0259, -0.1042, -0.2516,  ...,  0.0540, -0.2881, -1.3168],\n",
      "        [ 0.0259, -0.1042, -0.2516,  ...,  0.0540, -0.2881, -1.3168],\n",
      "        ...,\n",
      "        [-0.1856,  0.4437, -0.1490,  ..., -0.7171,  0.9419, -0.4367],\n",
      "        [-0.1887, -0.1157,  0.6227,  ..., -0.2596,  0.6527,  0.2752],\n",
      "        [-0.1887, -0.1157,  0.6227,  ..., -0.2596,  0.6527,  0.2752]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02588347 -0.10417892 -0.25157315  0.04169027 -0.2519546  -0.6773747\n",
      " -0.03918517 -0.44254965 -1.4262443  -0.1807177  -0.50630873 -1.7258308\n",
      " -0.35155576 -0.6280795  -2.1895545  -0.18370488 -0.7131373  -1.5903127\n",
      "  0.0489249  -0.74660087 -1.381367   -0.00441311 -0.6863876  -1.4312525\n",
      " -0.00962619 -0.8157153  -1.5475552  -0.13690403 -0.6016119  -1.5024488\n",
      " -0.05054782 -0.6606753  -1.476176   -0.05678135 -0.63718057 -1.5677941\n",
      "  0.06647419 -0.6634749  -1.6183529  -0.04046439 -0.5155306  -1.331042\n",
      " -0.15661544 -0.29012728 -1.9589643  -0.00374021 -0.44941157 -1.951833\n",
      "  0.1482957  -0.41050255 -1.4732754  -0.14864641 -0.2749883  -1.2652261\n",
      " -0.06069051 -0.254005   -1.3459289  -0.01116986 -0.27684313 -1.4593089\n",
      "  0.05399385 -0.2881008  -1.316798  ]\n",
      "data: [ 0.07 -5.18  4.36 -0.07 -4.86  4.42 -0.09 -4.34  4.07 -0.25 -4.17  5.19\n",
      " -0.37 -4.11  6.12  0.1  -4.29  4.91  0.03 -4.03  5.43 -0.13 -3.99  6.02\n",
      " -0.25 -4.    6.13  0.23 -4.36  4.88  0.14 -4.06  5.19  0.   -4.05  5.53\n",
      " -0.14 -4.14  5.85  0.24 -4.48  5.17  0.    0.    0.    0.14 -4.12  4.96\n",
      " -0.02 -4.24  5.38  0.24 -4.58  5.15  0.22 -4.37  5.34  0.19 -4.27  4.96\n",
      "  0.13 -4.26  4.91  0.  ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[-0.1313,  0.2668, -0.3321,  ..., -0.4889,  0.2409, -1.0635],\n",
      "        [-0.1313,  0.2668, -0.3321,  ..., -0.4889,  0.2409, -1.0635],\n",
      "        [-0.1313,  0.2668, -0.3321,  ..., -0.4889,  0.2409, -1.0635],\n",
      "        ...,\n",
      "        [ 0.5644, -0.4018,  0.0255,  ...,  0.6400, -1.0223,  0.5235],\n",
      "        [ 0.1801,  0.1892,  0.5448,  ...,  0.4550, -0.4193,  2.6268],\n",
      "        [ 0.1801,  0.1892,  0.5448,  ...,  0.4550, -0.4193,  2.6268]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.13131122  0.26684088 -0.3321457  -0.20357439  0.17586857 -0.8251105\n",
      " -0.13206083  0.19812423 -0.96739686 -0.12470044  0.16002871 -0.98988044\n",
      " -0.14350963  0.08384265 -1.055459   -0.3185823   0.13467434 -1.2187941\n",
      " -0.08369426  0.17409024 -0.6864928  -0.22920217  0.02708977 -0.69133997\n",
      " -0.3637696   0.08694395 -0.80460584 -0.35110754  0.20040882 -1.2635796\n",
      " -0.39429605  0.15287791 -1.3545265  -0.47969204  0.11543077 -1.3646631\n",
      " -0.5790258  -0.02553907 -1.3210701  -0.37057632  0.24490364 -1.2015908\n",
      " -0.52419937  0.28540665 -1.5145547  -0.5272008   0.21424055 -1.5244136\n",
      " -0.55760914  0.10447921 -1.1829424  -0.40608367  0.3679836  -1.0490392\n",
      " -0.36844307  0.31105953 -1.0949754  -0.45909768  0.29299983 -1.1147907\n",
      " -0.48891163  0.24086948 -1.0635377 ]\n",
      "init: [-0.13131122  0.26684088 -0.3321457  -0.20357439  0.17586857 -0.8251105\n",
      " -0.13206083  0.19812423 -0.96739686 -0.12470044  0.16002871 -0.98988044\n",
      " -0.14350963  0.08384265 -1.055459   -0.3185823   0.13467434 -1.2187941\n",
      " -0.08369426  0.17409024 -0.6864928  -0.22920217  0.02708977 -0.69133997\n",
      " -0.3637696   0.08694395 -0.80460584 -0.35110754  0.20040882 -1.2635796\n",
      " -0.39429605  0.15287791 -1.3545265  -0.47969204  0.11543077 -1.3646631\n",
      " -0.5790258  -0.02553907 -1.3210701  -0.37057632  0.24490364 -1.2015908\n",
      " -0.52419937  0.28540665 -1.5145547  -0.5272008   0.21424055 -1.5244136\n",
      " -0.55760914  0.10447921 -1.1829424  -0.40608367  0.3679836  -1.0490392\n",
      " -0.36844307  0.31105953 -1.0949754  -0.45909768  0.29299983 -1.1147907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.48891163  0.24086948 -1.0635377 ]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [-0.13131122  0.26684088 -0.3321457  -0.20357439  0.17586857 -0.8251105\n",
      " -0.13206083  0.19812423 -0.96739686 -0.12470044  0.16002871 -0.98988044\n",
      " -0.14350963  0.08384265 -1.055459   -0.3185823   0.13467434 -1.2187941\n",
      " -0.08369426  0.17409024 -0.68649274 -0.22920218  0.02708977 -0.69133997\n",
      " -0.36376962  0.08694395 -0.80460584 -0.3511075   0.20040882 -1.2635796\n",
      " -0.39429605  0.15287791 -1.3545265  -0.47969204  0.11543077 -1.3646631\n",
      " -0.5790258  -0.02553907 -1.3210701  -0.37057632  0.24490364 -1.2015908\n",
      " -0.52419937  0.28540665 -1.5145547  -0.5272008   0.21424055 -1.5244136\n",
      " -0.55760914  0.10447921 -1.1829424  -0.40608367  0.36798364 -1.0490392\n",
      " -0.36844307  0.31105953 -1.0949754  -0.45909768  0.29299983 -1.1147907\n",
      " -0.48891163  0.24086948 -1.0635377   0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0780, -0.4615, -0.1435,  ...,  0.1161, -0.5943, -1.3255],\n",
      "        [ 0.0780, -0.4615, -0.1435,  ...,  0.1161, -0.5943, -1.3255],\n",
      "        [ 0.0780, -0.4615, -0.1435,  ...,  0.1161, -0.5943, -1.3255],\n",
      "        ...,\n",
      "        [ 0.1827,  0.9463, -0.6333,  ..., -0.4682,  1.3564, -0.2478],\n",
      "        [-0.3769,  0.1389,  0.3689,  ..., -0.6832,  0.9041,  0.0694],\n",
      "        [-0.3769,  0.1389,  0.3689,  ..., -0.6832,  0.9041,  0.0694]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.07797337 -0.46151918 -0.14351742  0.12669742 -0.5956478  -0.64614195\n",
      "  0.08706301 -0.694955   -1.29885    -0.0344871  -0.70765066 -1.5677675\n",
      " -0.14371414 -0.8217268  -2.0552423  -0.10910903 -1.0037204  -1.399955\n",
      "  0.15067019 -0.9633715  -1.2277076   0.10391927 -0.85796875 -1.2895536\n",
      "  0.08775273 -0.9180926  -1.3999715  -0.08570549 -0.9230405  -1.3617578\n",
      "  0.04230224 -0.9196608  -1.3961233   0.04116368 -0.8308356  -1.4535825\n",
      "  0.13257083 -0.83789337 -1.507941    0.03103743 -0.8661082  -1.2229435\n",
      " -0.01292143 -0.5865034  -1.6621457   0.10185961 -0.70573616 -1.6323248\n",
      "  0.20086071 -0.63387704 -1.4651016  -0.06906918 -0.65462786 -1.1843313\n",
      "  0.03713952 -0.59885406 -1.3085859   0.08377418 -0.60624504 -1.4309857\n",
      "  0.11612727 -0.5942701  -1.3255041 ]\n",
      "data: [ 0.07797337 -0.46151915 -0.14351742  0.12669742 -0.5956478  -0.64614195\n",
      "  0.08706301 -0.694955   -1.29885    -0.0344871  -0.70765066 -1.5677675\n",
      " -0.14371414 -0.82172686 -2.0552423  -0.10910903 -1.0037204  -1.399955\n",
      "  0.15067019 -0.9633715  -1.2277076   0.10391927 -0.85796875 -1.2895536\n",
      "  0.08775273 -0.91809255 -1.3999715  -0.08570549 -0.92304057 -1.3617578\n",
      "  0.04230224 -0.9196608  -1.3961234   0.04116368 -0.8308356  -1.4535824\n",
      "  0.13257083 -0.83789337 -1.507941    0.03103743 -0.8661082  -1.2229435\n",
      " -0.01292143 -0.5865034  -1.6621457   0.10185961 -0.70573616 -1.6323248\n",
      "  0.20086071 -0.63387704 -1.4651016  -0.06906918 -0.65462786 -1.1843313\n",
      "  0.03713952 -0.59885406 -1.3085858   0.08377418 -0.60624504 -1.4309857\n",
      "  0.11612727 -0.5942701  -1.325504    0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F828>\n",
      "tensor([[ 0.0889, -0.1151, -0.2429,  ..., -0.0232, -0.3031, -1.3155],\n",
      "        [ 0.0889, -0.1151, -0.2429,  ..., -0.0232, -0.3031, -1.3155],\n",
      "        [ 0.0889, -0.1151, -0.2429,  ..., -0.0232, -0.3031, -1.3155],\n",
      "        ...,\n",
      "        [-0.2314,  0.2979,  0.0766,  ..., -0.2975,  0.8261, -0.3997],\n",
      "        [-0.0384, -0.1331,  0.6428,  ...,  0.1266,  0.4924,  0.2279],\n",
      "        [-0.0384, -0.1331,  0.6428,  ...,  0.1266,  0.4924,  0.2279]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.08890659 -0.11509757 -0.24287666  0.0524612  -0.2553821  -0.6037266\n",
      " -0.09238604 -0.48585334 -1.4098663  -0.2666728  -0.55822265 -1.6996529\n",
      " -0.48684442 -0.631822   -2.1948977  -0.15089394 -0.76102674 -1.6267493\n",
      " -0.0658737  -0.83891654 -1.503622   -0.10760312 -0.7472695  -1.556053\n",
      " -0.0828775  -0.93119276 -1.646802   -0.12086122 -0.6435946  -1.5370518\n",
      " -0.09998924 -0.69380164 -1.4559522  -0.1352484  -0.69712496 -1.5598042\n",
      "  0.00990142 -0.66984856 -1.5684116  -0.05879907 -0.5489265  -1.4072291\n",
      " -0.20421018 -0.35785523 -2.0388932  -0.08429523 -0.4995473  -2.0606668\n",
      "  0.08079307 -0.46696362 -1.4384658  -0.15413491 -0.31387234 -1.3338099\n",
      " -0.14950965 -0.30446115 -1.4110918  -0.13333073 -0.29392335 -1.5124625\n",
      " -0.02322017 -0.3031497  -1.3155193 ]\n",
      "data: [ 0.08890659 -0.11509757 -0.24287666  0.0524612  -0.2553821  -0.6037266\n",
      " -0.09238604 -0.48585334 -1.4098663  -0.2666728  -0.55822265 -1.6996529\n",
      " -0.48684442 -0.631822   -2.1948977  -0.15089394 -0.76102674 -1.6267493\n",
      " -0.0658737  -0.83891654 -1.5036222  -0.10760312 -0.7472695  -1.556053\n",
      " -0.0828775  -0.93119276 -1.646802   -0.12086122 -0.64359456 -1.5370518\n",
      " -0.09998924 -0.69380164 -1.4559522  -0.1352484  -0.69712496 -1.5598042\n",
      "  0.00990142 -0.66984856 -1.5684116  -0.05879907 -0.5489265  -1.407229\n",
      " -0.20421019 -0.35785523 -2.0388932  -0.08429523 -0.4995473  -2.0606668\n",
      "  0.08079307 -0.46696362 -1.4384658  -0.15413491 -0.31387234 -1.3338099\n",
      " -0.14950965 -0.30446115 -1.4110918  -0.13333073 -0.29392335 -1.5124625\n",
      " -0.02322017 -0.3031497  -1.3155195   0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0186, -0.0374, -0.1240,  ...,  0.1098, -0.2513, -1.0896],\n",
      "        [ 0.0186, -0.0374, -0.1240,  ...,  0.1098, -0.2513, -1.0896],\n",
      "        [ 0.0186, -0.0374, -0.1240,  ...,  0.1098, -0.2513, -1.0896],\n",
      "        ...,\n",
      "        [-0.1478,  0.3676, -0.0648,  ..., -1.0061,  0.9566, -0.4229],\n",
      "        [-0.1304, -0.1395,  0.4743,  ..., -0.2698,  0.4997,  0.1553],\n",
      "        [-0.1304, -0.1395,  0.4743,  ..., -0.2698,  0.4997,  0.1553]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01859073 -0.03741525 -0.12398805  0.03769226 -0.16221449 -0.4436254\n",
      " -0.04447546 -0.35830164 -1.2470963  -0.18617155 -0.4155643  -1.5626894\n",
      " -0.36633107 -0.54859287 -2.0296354  -0.18646654 -0.6459663  -1.4305701\n",
      "  0.07635118 -0.6817394  -1.2476158   0.01933715 -0.6299746  -1.2903587\n",
      "  0.0428519  -0.770414   -1.4174303  -0.12684838 -0.5398508  -1.3205329\n",
      " -0.02188656 -0.6069093  -1.3016521  -0.00301179 -0.5849774  -1.4020959\n",
      "  0.14103542 -0.6345351  -1.4530712  -0.01495729 -0.44996452 -1.1294067\n",
      " -0.15734895 -0.21978481 -1.8792238   0.04646978 -0.40573555 -1.87558\n",
      "  0.23506042 -0.36881787 -1.2759765  -0.1449479  -0.21022728 -1.0542012\n",
      " -0.02613071 -0.2014002  -1.1277299   0.02593949 -0.23562635 -1.2461511\n",
      "  0.10978905 -0.2512817  -1.0895762 ]\n",
      "data: [ 0.01859073 -0.03741525 -0.12398805  0.03769226 -0.16221449 -0.44362536\n",
      " -0.04447546 -0.3583016  -1.2470963  -0.18617155 -0.4155643  -1.5626893\n",
      " -0.36633107 -0.54859287 -2.0296354  -0.18646654 -0.6459663  -1.4305701\n",
      "  0.07635118 -0.68173945 -1.2476158   0.01933715 -0.6299746  -1.2903588\n",
      "  0.0428519  -0.770414   -1.4174303  -0.12684838 -0.5398508  -1.320533\n",
      " -0.02188656 -0.6069093  -1.3016521  -0.00301179 -0.5849774  -1.4020959\n",
      "  0.14103542 -0.6345351  -1.4530712  -0.01495729 -0.44996452 -1.1294067\n",
      " -0.15734895 -0.21978481 -1.8792238   0.04646978 -0.40573555 -1.87558\n",
      "  0.23506042 -0.36881787 -1.2759765  -0.1449479  -0.21022728 -1.0542012\n",
      " -0.0261307  -0.2014002  -1.1277299   0.02593949 -0.23562635 -1.2461511\n",
      "  0.10978904 -0.2512817  -1.0895762   0.04      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0024, -0.0525, -0.2105,  ...,  0.0323, -0.2359, -1.2378],\n",
      "        [ 0.0024, -0.0525, -0.2105,  ...,  0.0323, -0.2359, -1.2378],\n",
      "        [ 0.0024, -0.0525, -0.2105,  ...,  0.0323, -0.2359, -1.2378],\n",
      "        ...,\n",
      "        [-0.2827,  0.3230, -0.2540,  ..., -0.5575,  0.8512, -0.5883],\n",
      "        [-0.1310,  0.0399,  0.5800,  ..., -0.2716,  0.8063,  0.1938],\n",
      "        [-0.1310,  0.0399,  0.5800,  ..., -0.2716,  0.8063,  0.1938]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.4004402e-03 -5.2469276e-02 -2.1054636e-01  2.6526649e-02\n",
      " -1.7794006e-01 -5.7041180e-01 -9.1079108e-02 -3.7996998e-01\n",
      " -1.3713770e+00 -2.4366844e-01 -4.4257858e-01 -1.6695242e+00\n",
      " -4.1144875e-01 -5.4738533e-01 -2.1591682e+00 -2.0135695e-01\n",
      " -6.6872448e-01 -1.5461018e+00 -8.2470477e-04 -7.1315563e-01\n",
      " -1.3542540e+00 -5.1776797e-02 -6.4109546e-01 -1.4085841e+00\n",
      " -5.7836205e-02 -7.9193044e-01 -1.5305657e+00 -1.5649363e-01\n",
      " -5.6780940e-01 -1.4525318e+00 -8.7443843e-02 -6.2127447e-01\n",
      " -1.4252136e+00 -9.7230442e-02 -5.9454203e-01 -1.5150588e+00\n",
      "  4.3931529e-02 -6.1822355e-01 -1.5518646e+00 -6.7890383e-02\n",
      " -4.7624803e-01 -1.2789280e+00 -2.0502383e-01 -2.3562121e-01\n",
      " -1.9840479e+00 -3.4859635e-02 -4.0451497e-01 -1.9921229e+00\n",
      "  1.3563344e-01 -3.6548841e-01 -1.4002976e+00 -1.7998061e-01\n",
      " -2.4017937e-01 -1.2080982e+00 -1.0736729e-01 -2.1215096e-01\n",
      " -1.2917194e+00 -6.3581526e-02 -2.2025593e-01 -1.4094305e+00\n",
      "  3.2285742e-02 -2.3589696e-01 -1.2377837e+00]\n",
      "data: [ 2.4004402e-03 -5.2469276e-02 -2.1054636e-01  2.6526649e-02\n",
      " -1.7794007e-01 -5.7041180e-01 -9.1079108e-02 -3.7996998e-01\n",
      " -1.3713770e+00 -2.4366844e-01 -4.4257858e-01 -1.6695242e+00\n",
      " -4.1144875e-01 -5.4738533e-01 -2.1591682e+00 -2.0135695e-01\n",
      " -6.6872442e-01 -1.5461018e+00 -8.2470477e-04 -7.1315557e-01\n",
      " -1.3542540e+00 -5.1776797e-02 -6.4109540e-01 -1.4085841e+00\n",
      " -5.7836205e-02 -7.9193044e-01 -1.5305657e+00 -1.5649363e-01\n",
      " -5.6780940e-01 -1.4525317e+00 -8.7443851e-02 -6.2127447e-01\n",
      " -1.4252136e+00 -9.7230442e-02 -5.9454203e-01 -1.5150588e+00\n",
      "  4.3931529e-02 -6.1822355e-01 -1.5518646e+00 -6.7890383e-02\n",
      " -4.7624803e-01 -1.2789280e+00 -2.0502383e-01 -2.3562123e-01\n",
      " -1.9840479e+00 -3.4859635e-02 -4.0451497e-01 -1.9921230e+00\n",
      "  1.3563344e-01 -3.6548841e-01 -1.4002976e+00 -1.7998061e-01\n",
      " -2.4017936e-01 -1.2080982e+00 -1.0736730e-01 -2.1215096e-01\n",
      " -1.2917193e+00 -6.3581526e-02 -2.2025593e-01 -1.4094305e+00\n",
      "  3.2285742e-02 -2.3589697e-01 -1.2377837e+00  5.0000001e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[ 0.0285, -0.0545, -0.2480,  ...,  0.0386, -0.2360, -1.2863],\n",
      "        [ 0.0285, -0.0545, -0.2480,  ...,  0.0386, -0.2360, -1.2863],\n",
      "        [ 0.0285, -0.0545, -0.2480,  ...,  0.0386, -0.2360, -1.2863],\n",
      "        ...,\n",
      "        [-0.1843,  0.3777, -0.0750,  ..., -0.8113,  0.8884, -0.3167],\n",
      "        [-0.1149, -0.1144,  0.6104,  ..., -0.2031,  0.6555,  0.2815],\n",
      "        [-0.1149, -0.1144,  0.6104,  ..., -0.2031,  0.6555,  0.2815]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.8459396e-02 -5.4488972e-02 -2.4800380e-01  5.0045643e-02\n",
      " -1.7730090e-01 -6.4191920e-01 -6.9005966e-02 -3.6683589e-01\n",
      " -1.4063766e+00 -2.1868089e-01 -4.2992967e-01 -1.6961807e+00\n",
      " -3.8071093e-01 -5.2237642e-01 -2.1898856e+00 -1.6701788e-01\n",
      " -6.7559183e-01 -1.5564665e+00  9.6565485e-04 -7.1718371e-01\n",
      " -1.3919774e+00 -4.7668070e-02 -6.4397162e-01 -1.4542314e+00\n",
      " -5.2519493e-02 -7.9607666e-01 -1.5734242e+00 -1.3015422e-01\n",
      " -5.8546150e-01 -1.4740049e+00 -6.8237454e-02 -6.3079369e-01\n",
      " -1.4448234e+00 -8.9785382e-02 -5.9989899e-01 -1.5393622e+00\n",
      "  5.1284522e-02 -6.1695057e-01 -1.5653751e+00 -5.7229303e-02\n",
      " -4.8896134e-01 -1.3116413e+00 -1.7718336e-01 -2.5883859e-01\n",
      " -1.9841636e+00 -2.1743134e-02 -4.0619928e-01 -2.0032353e+00\n",
      "  1.4226292e-01 -3.8070816e-01 -1.4348590e+00 -1.5431064e-01\n",
      " -2.5932565e-01 -1.2430301e+00 -9.8855093e-02 -2.3162575e-01\n",
      " -1.3352277e+00 -6.4983457e-02 -2.2382660e-01 -1.4555666e+00\n",
      "  3.8626187e-02 -2.3602596e-01 -1.2862610e+00]\n",
      "data: [ 2.8459396e-02 -5.4488972e-02 -2.4800378e-01  5.0045643e-02\n",
      " -1.7730089e-01 -6.4191920e-01 -6.9005966e-02 -3.6683589e-01\n",
      " -1.4063766e+00 -2.1868090e-01 -4.2992964e-01 -1.6961807e+00\n",
      " -3.8071096e-01 -5.2237642e-01 -2.1898856e+00 -1.6701788e-01\n",
      " -6.7559183e-01 -1.5564666e+00  9.6565485e-04 -7.1718371e-01\n",
      " -1.3919774e+00 -4.7668070e-02 -6.4397162e-01 -1.4542314e+00\n",
      " -5.2519493e-02 -7.9607666e-01 -1.5734242e+00 -1.3015422e-01\n",
      " -5.8546150e-01 -1.4740049e+00 -6.8237454e-02 -6.3079369e-01\n",
      " -1.4448235e+00 -8.9785382e-02 -5.9989899e-01 -1.5393622e+00\n",
      "  5.1284522e-02 -6.1695057e-01 -1.5653751e+00 -5.7229303e-02\n",
      " -4.8896134e-01 -1.3116413e+00 -1.7718336e-01 -2.5883859e-01\n",
      " -1.9841636e+00 -2.1743134e-02 -4.0619928e-01 -2.0032353e+00\n",
      "  1.4226292e-01 -3.8070816e-01 -1.4348590e+00 -1.5431064e-01\n",
      " -2.5932565e-01 -1.2430301e+00 -9.8855093e-02 -2.3162575e-01\n",
      " -1.3352276e+00 -6.4983457e-02 -2.2382660e-01 -1.4555668e+00\n",
      "  3.8626187e-02 -2.3602596e-01 -1.2862610e+00  5.9999999e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[ 0.0296, -0.0495, -0.2385,  ...,  0.0474, -0.2453, -1.2741],\n",
      "        [ 0.0296, -0.0495, -0.2385,  ...,  0.0474, -0.2453, -1.2741],\n",
      "        [ 0.0296, -0.0495, -0.2385,  ...,  0.0474, -0.2453, -1.2741],\n",
      "        ...,\n",
      "        [-0.1305,  0.3449, -0.0749,  ..., -0.7322,  0.8116, -0.2744],\n",
      "        [-0.1445, -0.1691,  0.5284,  ..., -0.2175,  0.5916,  0.2271],\n",
      "        [-0.1445, -0.1691,  0.5284,  ..., -0.2175,  0.5916,  0.2271]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.029555   -0.0494762  -0.23850775  0.04286772 -0.17893426 -0.6213522\n",
      " -0.06982951 -0.36702776 -1.3808866  -0.21867895 -0.43199095 -1.6698903\n",
      " -0.39102352 -0.5316111  -2.1565187  -0.1682101  -0.6683316  -1.5412889\n",
      "  0.00282039 -0.7100748  -1.3797472  -0.04392172 -0.6368667  -1.439258\n",
      " -0.03893005 -0.7865442  -1.5515081  -0.12860963 -0.57220376 -1.4598526\n",
      " -0.06302428 -0.6210793  -1.427733   -0.08189876 -0.59813845 -1.5226734\n",
      "  0.05917923 -0.6087167  -1.553519   -0.05222074 -0.4861949  -1.2983568\n",
      " -0.16619119 -0.2617968  -1.951499   -0.01628309 -0.40959597 -1.9630132\n",
      "  0.14600073 -0.38441697 -1.4189692  -0.14675501 -0.2551632  -1.2341659\n",
      " -0.08930446 -0.23479572 -1.3226897  -0.05112523 -0.23213163 -1.4392787\n",
      "  0.04740117 -0.24534042 -1.2740542 ]\n",
      "data: [ 0.029555   -0.0494762  -0.23850775  0.04286772 -0.17893428 -0.6213522\n",
      " -0.06982951 -0.36702773 -1.3808866  -0.21867895 -0.43199098 -1.6698903\n",
      " -0.39102352 -0.5316111  -2.1565187  -0.1682101  -0.6683316  -1.5412889\n",
      "  0.00282039 -0.7100748  -1.3797472  -0.04392172 -0.6368667  -1.439258\n",
      " -0.03893005 -0.7865442  -1.5515081  -0.12860963 -0.57220376 -1.4598526\n",
      " -0.06302428 -0.6210793  -1.427733   -0.08189876 -0.59813845 -1.5226734\n",
      "  0.05917923 -0.6087167  -1.553519   -0.05222074 -0.4861949  -1.2983568\n",
      " -0.16619119 -0.2617968  -1.951499   -0.01628309 -0.40959594 -1.9630132\n",
      "  0.14600073 -0.38441697 -1.4189692  -0.14675501 -0.2551632  -1.2341659\n",
      " -0.08930447 -0.23479572 -1.3226897  -0.05112523 -0.23213163 -1.4392787\n",
      "  0.04740117 -0.24534042 -1.2740542   0.07      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0250, -0.0656, -0.2523,  ...,  0.0402, -0.2551, -1.2855],\n",
      "        [ 0.0250, -0.0656, -0.2523,  ...,  0.0402, -0.2551, -1.2855],\n",
      "        [ 0.0250, -0.0656, -0.2523,  ...,  0.0402, -0.2551, -1.2855],\n",
      "        ...,\n",
      "        [-0.1196,  0.3698, -0.0673,  ..., -0.6800,  0.8633, -0.3295],\n",
      "        [-0.1328, -0.1385,  0.5663,  ..., -0.2342,  0.6484,  0.2230],\n",
      "        [-0.1328, -0.1385,  0.5663,  ..., -0.2342,  0.6484,  0.2230]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02498245 -0.06561577 -0.2523011   0.04632837 -0.18923333 -0.6485467\n",
      " -0.07177518 -0.3836341  -1.4238882  -0.21817046 -0.44930667 -1.7110274\n",
      " -0.37769383 -0.5434416  -2.2012362  -0.1681664  -0.68368745 -1.5755328\n",
      "  0.00298312 -0.7276396  -1.4017028  -0.04363105 -0.6549643  -1.4623301\n",
      " -0.04915162 -0.80658114 -1.5808403  -0.13119486 -0.59149003 -1.4907123\n",
      " -0.06915385 -0.6400418  -1.4572761  -0.09017872 -0.61262614 -1.5467426\n",
      "  0.05007503 -0.62917274 -1.5754932  -0.05732073 -0.49936077 -1.3274378\n",
      " -0.17798191 -0.27053803 -1.9962262  -0.02388521 -0.42122597 -2.0117934\n",
      "  0.13925189 -0.3945802  -1.438868   -0.15466207 -0.26963025 -1.2559501\n",
      " -0.09721903 -0.24320014 -1.3421671  -0.05951866 -0.23992534 -1.4581625\n",
      "  0.04024833 -0.2550931  -1.2854755 ]\n",
      "data: [ 0.02498245 -0.06561577 -0.2523011   0.04632837 -0.18923335 -0.6485467\n",
      " -0.07177518 -0.38363412 -1.4238882  -0.21817046 -0.44930667 -1.7110274\n",
      " -0.37769383 -0.5434416  -2.2012362  -0.16816638 -0.68368745 -1.5755328\n",
      "  0.00298312 -0.7276396  -1.4017028  -0.04363105 -0.65496427 -1.4623302\n",
      " -0.04915162 -0.80658114 -1.5808403  -0.13119486 -0.59149003 -1.4907123\n",
      " -0.06915385 -0.6400418  -1.4572761  -0.09017872 -0.61262614 -1.5467426\n",
      "  0.05007503 -0.62917274 -1.5754932  -0.05732073 -0.49936077 -1.3274378\n",
      " -0.17798191 -0.27053803 -1.9962262  -0.02388521 -0.42122597 -2.0117934\n",
      "  0.13925189 -0.3945802  -1.438868   -0.15466207 -0.26963025 -1.2559501\n",
      " -0.09721903 -0.24320012 -1.3421673  -0.05951866 -0.23992534 -1.4581625\n",
      "  0.04024834 -0.2550931  -1.2854755   0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F9B0>\n",
      "tensor([[ 0.0218, -0.0327, -0.2394,  ...,  0.0427, -0.2277, -1.2656],\n",
      "        [ 0.0218, -0.0327, -0.2394,  ...,  0.0427, -0.2277, -1.2656],\n",
      "        [ 0.0218, -0.0327, -0.2394,  ...,  0.0427, -0.2277, -1.2656],\n",
      "        ...,\n",
      "        [-0.1407,  0.3517, -0.0911,  ..., -0.7677,  0.8399, -0.3260],\n",
      "        [-0.1449, -0.1712,  0.5434,  ..., -0.2285,  0.5936,  0.2126],\n",
      "        [-0.1449, -0.1712,  0.5434,  ..., -0.2285,  0.5936,  0.2126]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02179097 -0.03273828 -0.23939703  0.03784536 -0.15938029 -0.62897956\n",
      " -0.06860159 -0.34693247 -1.3837492  -0.21421827 -0.4089015  -1.6764987\n",
      " -0.38128036 -0.50983506 -2.1591911  -0.17472701 -0.6479188  -1.539678\n",
      "  0.00614242 -0.68683606 -1.3751613  -0.04142439 -0.6165704  -1.4349756\n",
      " -0.03893708 -0.76508826 -1.5507035  -0.13460228 -0.5527167  -1.4549181\n",
      " -0.06604457 -0.6021432  -1.426331   -0.08255999 -0.5780206  -1.5207032\n",
      "  0.05567208 -0.5942672  -1.5541263  -0.05488571 -0.46339256 -1.2909824\n",
      " -0.17235088 -0.2389433  -1.9523554  -0.0182829  -0.38982737 -1.9630119\n",
      "  0.14306022 -0.3628508  -1.4157146  -0.15241042 -0.23418657 -1.2251278\n",
      " -0.08919218 -0.21253036 -1.3108704  -0.05113369 -0.21379818 -1.4277343\n",
      "  0.04274907 -0.22772795 -1.2656206 ]\n",
      "data: [ 0.02179097 -0.03273828 -0.23939703  0.03784536 -0.15938029 -0.62897956\n",
      " -0.06860159 -0.3469325  -1.3837492  -0.21421827 -0.4089015  -1.6764988\n",
      " -0.38128036 -0.50983506 -2.1591911  -0.17472701 -0.6479189  -1.5396781\n",
      "  0.00614242 -0.68683606 -1.3751613  -0.04142439 -0.6165704  -1.4349756\n",
      " -0.03893708 -0.76508826 -1.5507035  -0.13460228 -0.5527167  -1.4549183\n",
      " -0.06604457 -0.6021432  -1.426331   -0.08255999 -0.5780206  -1.5207031\n",
      "  0.05567208 -0.5942672  -1.5541263  -0.05488571 -0.46339256 -1.2909824\n",
      " -0.17235088 -0.2389433  -1.9523554  -0.0182829  -0.38982737 -1.963012\n",
      "  0.14306022 -0.3628508  -1.4157146  -0.15241042 -0.23418657 -1.2251278\n",
      " -0.08919218 -0.21253036 -1.3108704  -0.05113369 -0.21379818 -1.4277343\n",
      "  0.04274907 -0.22772795 -1.2656206   0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0200, -0.0629, -0.2471,  ...,  0.0342, -0.2463, -1.2989],\n",
      "        [ 0.0200, -0.0629, -0.2471,  ...,  0.0342, -0.2463, -1.2989],\n",
      "        [ 0.0200, -0.0629, -0.2471,  ...,  0.0342, -0.2463, -1.2989],\n",
      "        ...,\n",
      "        [-0.3266,  0.1797, -0.3363,  ..., -0.8186,  0.6072, -0.4861],\n",
      "        [-0.0997, -0.0691,  0.5904,  ..., -0.2076,  0.7206,  0.2567],\n",
      "        [-0.0997, -0.0691,  0.5904,  ..., -0.2076,  0.7206,  0.2567]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02004509 -0.06286658 -0.2471314   0.04286398 -0.19991899 -0.6642761\n",
      " -0.0548116  -0.3806484  -1.4167211  -0.19646841 -0.44458267 -1.7053664\n",
      " -0.36009023 -0.5487107  -2.1868782  -0.17737004 -0.66775227 -1.5704575\n",
      "  0.01685742 -0.6984422  -1.3857539  -0.02994931 -0.6323887  -1.4433935\n",
      " -0.03464258 -0.76689506 -1.5578463  -0.1401363  -0.56761706 -1.4907548\n",
      " -0.06462499 -0.61858726 -1.4594417  -0.08415366 -0.59237707 -1.5512502\n",
      "  0.04850768 -0.6093323  -1.5929747  -0.06133769 -0.48444763 -1.3233259\n",
      " -0.16868186 -0.25810936 -1.9481716  -0.0243478  -0.40503535 -1.9522676\n",
      "  0.12711105 -0.377979   -1.4513297  -0.15572897 -0.25096804 -1.2588203\n",
      " -0.08965395 -0.22756363 -1.3364499  -0.04605635 -0.23231798 -1.4532113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.03424303 -0.24626745 -1.2988584 ]\n",
      "data: [ 0.02004509 -0.06286658 -0.2471314   0.04286398 -0.19991897 -0.6642761\n",
      " -0.05481161 -0.38064843 -1.416721   -0.19646841 -0.44458267 -1.7053664\n",
      " -0.36009023 -0.5487107  -2.1868782  -0.17737003 -0.6677522  -1.5704575\n",
      "  0.01685742 -0.6984422  -1.385754   -0.02994931 -0.6323887  -1.4433933\n",
      " -0.03464258 -0.76689506 -1.5578464  -0.1401363  -0.56761706 -1.4907548\n",
      " -0.06462499 -0.61858726 -1.4594417  -0.08415366 -0.59237707 -1.5512501\n",
      "  0.04850768 -0.6093323  -1.5929747  -0.06133769 -0.48444763 -1.3233258\n",
      " -0.16868187 -0.25810936 -1.9481717  -0.0243478  -0.40503538 -1.9522676\n",
      "  0.12711105 -0.377979   -1.4513297  -0.15572897 -0.25096804 -1.2588203\n",
      " -0.08965395 -0.22756363 -1.3364499  -0.04605635 -0.23231798 -1.4532113\n",
      "  0.03424303 -0.24626745 -1.2988583   0.1       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0209, -0.0736, -0.2606,  ...,  0.0503, -0.2600, -1.3039],\n",
      "        [ 0.0209, -0.0736, -0.2606,  ...,  0.0503, -0.2600, -1.3039],\n",
      "        [ 0.0209, -0.0736, -0.2606,  ...,  0.0503, -0.2600, -1.3039],\n",
      "        ...,\n",
      "        [-0.1285,  0.3940, -0.1201,  ..., -0.7297,  0.9032, -0.3817],\n",
      "        [-0.1327, -0.1513,  0.5710,  ..., -0.2362,  0.6243,  0.2287],\n",
      "        [-0.1327, -0.1513,  0.5710,  ..., -0.2362,  0.6243,  0.2287]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02085179 -0.07360557 -0.26063535  0.04266701 -0.20766534 -0.6636574\n",
      " -0.0477009  -0.3899204  -1.4153547  -0.18932346 -0.450543   -1.711653\n",
      " -0.35296056 -0.5610534  -2.1904602  -0.1773915  -0.67923486 -1.5768955\n",
      "  0.03027225 -0.7105043  -1.4032688  -0.02032479 -0.64590836 -1.4595289\n",
      " -0.01867863 -0.781842   -1.5762892  -0.13477686 -0.5787792  -1.4914215\n",
      " -0.05434673 -0.6305214  -1.4677508  -0.06618202 -0.6046686  -1.5618887\n",
      "  0.0639779  -0.6276102  -1.6041465  -0.04798326 -0.4918401  -1.3207529\n",
      " -0.16107872 -0.2642687  -1.9648032  -0.00743221 -0.41779917 -1.967454\n",
      "  0.14826444 -0.38737622 -1.4605057  -0.1500662  -0.25849515 -1.2560668\n",
      " -0.07203796 -0.23653665 -1.3376443  -0.02872517 -0.24746099 -1.454365\n",
      "  0.05034178 -0.2599845  -1.3039098 ]\n",
      "data: [ 0.0208518  -0.07360557 -0.26063535  0.04266701 -0.20766535 -0.6636574\n",
      " -0.0477009  -0.3899204  -1.4153547  -0.18932347 -0.450543   -1.711653\n",
      " -0.35296056 -0.5610534  -2.1904602  -0.17739148 -0.67923486 -1.5768955\n",
      "  0.03027225 -0.7105043  -1.4032687  -0.02032479 -0.64590836 -1.4595289\n",
      " -0.01867863 -0.781842   -1.5762892  -0.13477686 -0.5787792  -1.4914215\n",
      " -0.05434673 -0.6305214  -1.4677509  -0.06618202 -0.6046686  -1.5618887\n",
      "  0.0639779  -0.6276102  -1.6041465  -0.04798326 -0.4918401  -1.3207529\n",
      " -0.16107872 -0.2642687  -1.9648032  -0.00743222 -0.41779917 -1.967454\n",
      "  0.14826444 -0.38737622 -1.4605057  -0.1500662  -0.25849515 -1.2560668\n",
      " -0.07203796 -0.23653665 -1.3376443  -0.02872517 -0.24746099 -1.4543651\n",
      "  0.05034179 -0.2599845  -1.3039098   0.11      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B320>\n",
      "tensor([[ 0.0198, -0.0893, -0.2668,  ...,  0.0553, -0.2735, -1.3226],\n",
      "        [ 0.0198, -0.0893, -0.2668,  ...,  0.0553, -0.2735, -1.3226],\n",
      "        [ 0.0198, -0.0893, -0.2668,  ...,  0.0553, -0.2735, -1.3226],\n",
      "        ...,\n",
      "        [-0.1246,  0.3995, -0.1224,  ..., -0.7093,  0.9053, -0.3871],\n",
      "        [-0.1362, -0.1349,  0.5849,  ..., -0.2385,  0.6321,  0.2429],\n",
      "        [-0.1362, -0.1349,  0.5849,  ..., -0.2385,  0.6321,  0.2429]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.9806292e-02 -8.9340813e-02 -2.6684347e-01  3.9792668e-02\n",
      " -2.3255445e-01 -6.8242949e-01 -3.4254432e-02 -4.1098458e-01\n",
      " -1.4192148e+00 -1.7476511e-01 -4.7032636e-01 -1.7221634e+00\n",
      " -3.4482101e-01 -5.9187758e-01 -2.1904950e+00 -1.8448377e-01\n",
      " -6.8992227e-01 -1.5864729e+00  5.0428875e-02 -7.1566677e-01\n",
      " -1.3954810e+00 -2.7310178e-03 -6.5661865e-01 -1.4477462e+00\n",
      " -2.3531541e-03 -7.8343982e-01 -1.5642316e+00 -1.3790447e-01\n",
      " -5.8237934e-01 -1.4996927e+00 -4.6065226e-02 -6.3881552e-01\n",
      " -1.4790105e+00 -5.2391239e-02 -6.1418277e-01 -1.5758491e+00\n",
      "  7.1940221e-02 -6.4168739e-01 -1.6273247e+00 -4.1541532e-02\n",
      " -4.9771333e-01 -1.3247122e+00 -1.5179208e-01 -2.7209324e-01\n",
      " -1.9510574e+00  1.1701658e-03 -4.2876172e-01 -1.9444716e+00\n",
      "  1.5324804e-01 -3.9433026e-01 -1.4792132e+00 -1.4810675e-01\n",
      " -2.6019120e-01 -1.2628772e+00 -5.7497390e-02 -2.4073476e-01\n",
      " -1.3419600e+00 -9.7132847e-03 -2.6260060e-01 -1.4585819e+00\n",
      "  5.5323854e-02 -2.7348334e-01 -1.3225535e+00]\n",
      "data: [ 1.9806292e-02 -8.9340813e-02 -2.6684347e-01  3.9792668e-02\n",
      " -2.3255445e-01 -6.8242949e-01 -3.4254432e-02 -4.1098458e-01\n",
      " -1.4192147e+00 -1.7476511e-01 -4.7032633e-01 -1.7221634e+00\n",
      " -3.4482101e-01 -5.9187758e-01 -2.1904950e+00 -1.8448375e-01\n",
      " -6.8992227e-01 -1.5864730e+00  5.0428879e-02 -7.1566683e-01\n",
      " -1.3954810e+00 -2.7310178e-03 -6.5661865e-01 -1.4477462e+00\n",
      " -2.3531541e-03 -7.8343982e-01 -1.5642315e+00 -1.3790447e-01\n",
      " -5.8237934e-01 -1.4996927e+00 -4.6065226e-02 -6.3881552e-01\n",
      " -1.4790105e+00 -5.2391239e-02 -6.1418277e-01 -1.5758491e+00\n",
      "  7.1940221e-02 -6.4168739e-01 -1.6273247e+00 -4.1541532e-02\n",
      " -4.9771333e-01 -1.3247123e+00 -1.5179208e-01 -2.7209324e-01\n",
      " -1.9510574e+00  1.1701658e-03 -4.2876172e-01 -1.9444716e+00\n",
      "  1.5324804e-01 -3.9433026e-01 -1.4792132e+00 -1.4810675e-01\n",
      " -2.6019120e-01 -1.2628772e+00 -5.7497393e-02 -2.4073476e-01\n",
      " -1.3419600e+00 -9.7132847e-03 -2.6260060e-01 -1.4585818e+00\n",
      "  5.5323854e-02 -2.7348334e-01 -1.3225535e+00  1.2000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BB38>\n",
      "tensor([[ 0.0280, -0.1061, -0.2600,  ...,  0.0593, -0.2897, -1.3158],\n",
      "        [ 0.0280, -0.1061, -0.2600,  ...,  0.0593, -0.2897, -1.3158],\n",
      "        [ 0.0280, -0.1061, -0.2600,  ...,  0.0593, -0.2897, -1.3158],\n",
      "        ...,\n",
      "        [-0.1378,  0.4206, -0.1584,  ..., -0.7166,  0.9185, -0.4352],\n",
      "        [-0.1583, -0.1244,  0.6022,  ..., -0.2427,  0.6439,  0.2583],\n",
      "        [-0.1583, -0.1244,  0.6022,  ..., -0.2427,  0.6439,  0.2583]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.7974132e-02 -1.0609810e-01 -2.5996795e-01  4.6471741e-02\n",
      " -2.4999669e-01 -6.7578405e-01 -2.9528715e-02 -4.3309683e-01\n",
      " -1.4153857e+00 -1.7142163e-01 -4.9308419e-01 -1.7181695e+00\n",
      " -3.4214139e-01 -6.1496800e-01 -2.1850827e+00 -1.7839268e-01\n",
      " -7.1027130e-01 -1.5838301e+00  5.3676233e-02 -7.3949492e-01\n",
      " -1.3952961e+00 -3.3211708e-04 -6.7973292e-01 -1.4470923e+00\n",
      "  8.3375722e-04 -8.0873096e-01 -1.5629501e+00 -1.3131766e-01\n",
      " -6.0159713e-01 -1.4960122e+00 -4.2176351e-02 -6.5880346e-01\n",
      " -1.4733639e+00 -4.8128024e-02 -6.3535613e-01 -1.5692990e+00\n",
      "  7.4999541e-02 -6.6237730e-01 -1.6187730e+00 -3.4941532e-02\n",
      " -5.1492083e-01 -1.3220918e+00 -1.4925683e-01 -2.8976297e-01\n",
      " -1.9550838e+00  4.9514547e-03 -4.4818085e-01 -1.9489136e+00\n",
      "  1.5738487e-01 -4.1227061e-01 -1.4720788e+00 -1.4289922e-01\n",
      " -2.7686855e-01 -1.2594488e+00 -5.3326443e-02 -2.5708044e-01\n",
      " -1.3391752e+00 -6.0373396e-03 -2.7942979e-01 -1.4543834e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5.9285350e-02 -2.8972203e-01 -1.3158231e+00]\n",
      "data: [ 2.7974134e-02 -1.0609810e-01 -2.5996795e-01  4.6471737e-02\n",
      " -2.4999671e-01 -6.7578405e-01 -2.9528715e-02 -4.3309680e-01\n",
      " -1.4153857e+00 -1.7142162e-01 -4.9308419e-01 -1.7181695e+00\n",
      " -3.4214139e-01 -6.1496800e-01 -2.1850827e+00 -1.7839268e-01\n",
      " -7.1027130e-01 -1.5838301e+00  5.3676233e-02 -7.3949492e-01\n",
      " -1.3952960e+00 -3.3211708e-04 -6.7973292e-01 -1.4470923e+00\n",
      "  8.3375722e-04 -8.0873090e-01 -1.5629501e+00 -1.3131766e-01\n",
      " -6.0159713e-01 -1.4960122e+00 -4.2176351e-02 -6.5880346e-01\n",
      " -1.4733640e+00 -4.8128024e-02 -6.3535613e-01 -1.5692990e+00\n",
      "  7.4999541e-02 -6.6237730e-01 -1.6187730e+00 -3.4941532e-02\n",
      " -5.1492083e-01 -1.3220918e+00 -1.4925683e-01 -2.8976297e-01\n",
      " -1.9550840e+00  4.9514547e-03 -4.4818085e-01 -1.9489136e+00\n",
      "  1.5738487e-01 -4.1227064e-01 -1.4720788e+00 -1.4289922e-01\n",
      " -2.7686855e-01 -1.2594488e+00 -5.3326443e-02 -2.5708044e-01\n",
      " -1.3391752e+00 -6.0373396e-03 -2.7942979e-01 -1.4543834e+00\n",
      "  5.9285350e-02 -2.8972203e-01 -1.3158231e+00  1.3000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63FD0>\n",
      "tensor([[ 0.0222, -0.1217, -0.2596,  ...,  0.0613, -0.3063, -1.3149],\n",
      "        [ 0.0222, -0.1217, -0.2596,  ...,  0.0613, -0.3063, -1.3149],\n",
      "        [ 0.0222, -0.1217, -0.2596,  ...,  0.0613, -0.3063, -1.3149],\n",
      "        ...,\n",
      "        [-0.0955,  0.4454, -0.1227,  ..., -0.6611,  0.9561, -0.4356],\n",
      "        [-0.1176, -0.0992,  0.6059,  ..., -0.2171,  0.6557,  0.2444],\n",
      "        [-0.1176, -0.0992,  0.6059,  ..., -0.2171,  0.6557,  0.2444]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.2179071e-02 -1.2165586e-01 -2.5963202e-01  4.4881996e-02\n",
      " -2.6407656e-01 -6.6449344e-01 -2.5116928e-02 -4.4830883e-01\n",
      " -1.4132899e+00 -1.6742781e-01 -5.0779933e-01 -1.7230346e+00\n",
      " -3.3874297e-01 -6.3381195e-01 -2.1934900e+00 -1.8440965e-01\n",
      " -7.2332335e-01 -1.5908544e+00  6.5170184e-02 -7.5258482e-01\n",
      " -1.3932904e+00  6.8937540e-03 -6.9749582e-01 -1.4422778e+00\n",
      "  1.8134564e-03 -8.2611299e-01 -1.5613419e+00 -1.3372673e-01\n",
      " -6.1453879e-01 -1.4974471e+00 -3.9462641e-02 -6.7573023e-01\n",
      " -1.4793631e+00 -4.4515550e-02 -6.5176392e-01 -1.5780286e+00\n",
      "  7.3335990e-02 -6.8715358e-01 -1.6303444e+00 -3.1493641e-02\n",
      " -5.2516258e-01 -1.3182297e+00 -1.5092319e-01 -2.9946715e-01\n",
      " -1.9640555e+00  7.8546479e-03 -4.6457568e-01 -1.9561019e+00\n",
      "  1.5826687e-01 -4.2697635e-01 -1.4763362e+00 -1.4557113e-01\n",
      " -2.8639865e-01 -1.2549042e+00 -4.6469092e-02 -2.6803690e-01\n",
      " -1.3323094e+00  1.2634546e-03 -2.9688868e-01 -1.4483851e+00\n",
      "  6.1333410e-02 -3.0629295e-01 -1.3149033e+00]\n",
      "data: [ 2.2179073e-02 -1.2165585e-01 -2.5963202e-01  4.4881996e-02\n",
      " -2.6407656e-01 -6.6449338e-01 -2.5116928e-02 -4.4830883e-01\n",
      " -1.4132899e+00 -1.6742781e-01 -5.0779933e-01 -1.7230346e+00\n",
      " -3.3874297e-01 -6.3381195e-01 -2.1934900e+00 -1.8440966e-01\n",
      " -7.2332335e-01 -1.5908543e+00  6.5170184e-02 -7.5258482e-01\n",
      " -1.3932904e+00  6.8937540e-03 -6.9749582e-01 -1.4422778e+00\n",
      "  1.8134564e-03 -8.2611299e-01 -1.5613419e+00 -1.3372673e-01\n",
      " -6.1453879e-01 -1.4974473e+00 -3.9462641e-02 -6.7573023e-01\n",
      " -1.4793631e+00 -4.4515554e-02 -6.5176392e-01 -1.5780286e+00\n",
      "  7.3335990e-02 -6.8715358e-01 -1.6303444e+00 -3.1493641e-02\n",
      " -5.2516258e-01 -1.3182297e+00 -1.5092319e-01 -2.9946715e-01\n",
      " -1.9640555e+00  7.8546479e-03 -4.6457568e-01 -1.9561019e+00\n",
      "  1.5826687e-01 -4.2697635e-01 -1.4763362e+00 -1.4557113e-01\n",
      " -2.8639865e-01 -1.2549042e+00 -4.6469092e-02 -2.6803690e-01\n",
      " -1.3323094e+00  1.2634546e-03 -2.9688868e-01 -1.4483851e+00\n",
      "  6.1333407e-02 -3.0629295e-01 -1.3149033e+00  1.4000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0191, -0.1206, -0.2348,  ...,  0.0545, -0.3031, -1.2826],\n",
      "        [ 0.0191, -0.1206, -0.2348,  ...,  0.0545, -0.3031, -1.2826],\n",
      "        [ 0.0191, -0.1206, -0.2348,  ...,  0.0545, -0.3031, -1.2826],\n",
      "        ...,\n",
      "        [-0.0847,  0.4585, -0.1335,  ..., -0.6200,  0.9519, -0.4358],\n",
      "        [-0.1213, -0.0876,  0.6119,  ..., -0.2218,  0.6416,  0.2724],\n",
      "        [-0.1213, -0.0876,  0.6119,  ..., -0.2218,  0.6416,  0.2724]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.9068975e-02 -1.2062649e-01 -2.3482934e-01  4.4032205e-02\n",
      " -2.5815281e-01 -6.2456918e-01 -3.4969024e-02 -4.5178017e-01\n",
      " -1.3886253e+00 -1.7915487e-01 -5.1232779e-01 -1.6961621e+00\n",
      " -3.4581488e-01 -6.3455075e-01 -2.1720004e+00 -1.8650030e-01\n",
      " -7.2858715e-01 -1.5686785e+00  5.5350527e-02 -7.6536179e-01\n",
      " -1.3763475e+00 -5.2346289e-03 -7.0964831e-01 -1.4240876e+00\n",
      " -1.4065884e-02 -8.4542423e-01 -1.5448596e+00 -1.3562590e-01\n",
      " -6.2252152e-01 -1.4730344e+00 -4.7305606e-02 -6.8433934e-01\n",
      " -1.4541163e+00 -5.4055676e-02 -6.5886962e-01 -1.5501496e+00\n",
      "  6.2054187e-02 -6.9860309e-01 -1.5952107e+00 -3.4638770e-02\n",
      " -5.2551246e-01 -1.2968732e+00 -1.6478162e-01 -2.9885551e-01\n",
      " -1.9703783e+00  2.8972328e-04 -4.6904710e-01 -1.9679791e+00\n",
      "  1.5150531e-01 -4.3000984e-01 -1.4457126e+00 -1.5237474e-01\n",
      " -2.8809065e-01 -1.2299658e+00 -5.5176362e-02 -2.6784551e-01\n",
      " -1.3096399e+00 -1.1347979e-02 -2.9437989e-01 -1.4255058e+00\n",
      "  5.4528646e-02 -3.0312133e-01 -1.2826473e+00]\n",
      "data: [ 1.9068975e-02 -1.2062649e-01 -2.3482934e-01  4.4032205e-02\n",
      " -2.5815281e-01 -6.2456918e-01 -3.4969024e-02 -4.5178017e-01\n",
      " -1.3886254e+00 -1.7915487e-01 -5.1232779e-01 -1.6961621e+00\n",
      " -3.4581488e-01 -6.3455075e-01 -2.1720004e+00 -1.8650030e-01\n",
      " -7.2858721e-01 -1.5686784e+00  5.5350527e-02 -7.6536179e-01\n",
      " -1.3763475e+00 -5.2346289e-03 -7.0964831e-01 -1.4240876e+00\n",
      " -1.4065884e-02 -8.4542429e-01 -1.5448596e+00 -1.3562590e-01\n",
      " -6.2252152e-01 -1.4730344e+00 -4.7305606e-02 -6.8433934e-01\n",
      " -1.4541163e+00 -5.4055676e-02 -6.5886962e-01 -1.5501496e+00\n",
      "  6.2054187e-02 -6.9860303e-01 -1.5952107e+00 -3.4638770e-02\n",
      " -5.2551246e-01 -1.2968732e+00 -1.6478162e-01 -2.9885551e-01\n",
      " -1.9703783e+00  2.8972328e-04 -4.6904710e-01 -1.9679791e+00\n",
      "  1.5150531e-01 -4.3000984e-01 -1.4457126e+00 -1.5237474e-01\n",
      " -2.8809065e-01 -1.2299658e+00 -5.5176362e-02 -2.6784551e-01\n",
      " -1.3096399e+00 -1.1347979e-02 -2.9437989e-01 -1.4255059e+00\n",
      "  5.4528646e-02 -3.0312133e-01 -1.2826473e+00  1.5000001e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[ 0.0208, -0.1155, -0.1932,  ...,  0.0782, -0.3184, -1.1855],\n",
      "        [ 0.0208, -0.1155, -0.1932,  ...,  0.0782, -0.3184, -1.1855],\n",
      "        [ 0.0208, -0.1155, -0.1932,  ...,  0.0782, -0.3184, -1.1855],\n",
      "        ...,\n",
      "        [-0.1107,  0.4063, -0.1154,  ..., -0.6958,  0.9285, -0.4328],\n",
      "        [-0.1197, -0.0938,  0.5955,  ..., -0.2204,  0.6443,  0.2116],\n",
      "        [-0.1197, -0.0938,  0.5955,  ..., -0.2204,  0.6443,  0.2116]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02076234 -0.11554987 -0.19323188  0.05162613 -0.22868487 -0.5159041\n",
      " -0.06688136 -0.44753    -1.3421701  -0.21448651 -0.5133164  -1.6398156\n",
      " -0.3692633  -0.62004936 -2.1321115  -0.17019033 -0.7431458  -1.5151669\n",
      "  0.03293404 -0.80174816 -1.3470148  -0.02447768 -0.73477256 -1.3964511\n",
      " -0.03346081 -0.8962983  -1.5206339  -0.11904231 -0.65186715 -1.411636\n",
      " -0.04965153 -0.71118045 -1.3889208  -0.0580548  -0.6819402  -1.4749953\n",
      "  0.07200594 -0.7214118  -1.5026494  -0.0261412  -0.54727083 -1.2408282\n",
      " -0.17699204 -0.31266153 -1.9970622   0.00914684 -0.49266854 -2.0111628\n",
      "  0.17675474 -0.45253977 -1.3576858  -0.14691915 -0.31755596 -1.1645371\n",
      " -0.06135127 -0.29303944 -1.2519422  -0.02025194 -0.30641675 -1.365459\n",
      "  0.07821331 -0.318389   -1.1855217 ]\n",
      "data: [ 0.02076234 -0.11554987 -0.19323188  0.05162613 -0.22868486 -0.5159041\n",
      " -0.06688136 -0.44752997 -1.3421701  -0.21448651 -0.5133164  -1.6398156\n",
      " -0.3692633  -0.62004936 -2.1321115  -0.17019033 -0.7431458  -1.5151669\n",
      "  0.03293404 -0.8017481  -1.3470148  -0.02447768 -0.73477256 -1.3964511\n",
      " -0.03346081 -0.8962983  -1.520634   -0.11904231 -0.65186715 -1.411636\n",
      " -0.04965153 -0.71118045 -1.3889208  -0.0580548  -0.68194026 -1.4749953\n",
      "  0.07200594 -0.7214118  -1.5026494  -0.0261412  -0.54727083 -1.2408282\n",
      " -0.17699203 -0.31266153 -1.9970622   0.00914684 -0.49266854 -2.0111628\n",
      "  0.17675474 -0.4525398  -1.3576858  -0.14691915 -0.31755596 -1.1645371\n",
      " -0.06135127 -0.29303944 -1.2519422  -0.02025194 -0.30641675 -1.365459\n",
      "  0.07821331 -0.318389   -1.1855217   0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0161, -0.0848, -0.1965,  ...,  0.0238, -0.2757, -1.1735],\n",
      "        [-0.0161, -0.0848, -0.1965,  ...,  0.0238, -0.2757, -1.1735],\n",
      "        [-0.0161, -0.0848, -0.1965,  ...,  0.0238, -0.2757, -1.1735],\n",
      "        ...,\n",
      "        [-0.1383,  0.3537, -0.0413,  ..., -0.6952,  0.8798, -0.3789],\n",
      "        [-0.0827, -0.0718,  0.6043,  ..., -0.1852,  0.6666,  0.2036],\n",
      "        [-0.0827, -0.0718,  0.6043,  ..., -0.1852,  0.6666,  0.2036]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.0161082  -0.08479025 -0.19649318  0.01924631 -0.18687966 -0.48409247\n",
      " -0.12139267 -0.4175508  -1.3475928  -0.2749479  -0.48349    -1.6418552\n",
      " -0.427649   -0.577641   -2.150852   -0.20719695 -0.7209214  -1.5218829\n",
      " -0.02671632 -0.7872152  -1.3625989  -0.08167918 -0.7142662  -1.4137422\n",
      " -0.09082498 -0.8855884  -1.5419854  -0.16022593 -0.6342895  -1.4149613\n",
      " -0.10262374 -0.68910235 -1.3880627  -0.11244115 -0.65540665 -1.474734\n",
      "  0.02809374 -0.6917231  -1.4932207  -0.07565006 -0.5208614  -1.2467139\n",
      " -0.24044716 -0.2812931  -2.0459733  -0.04435429 -0.4611103  -2.072033\n",
      "  0.13438526 -0.42087948 -1.3492758  -0.19925404 -0.292057   -1.1660696\n",
      " -0.12643553 -0.2623977  -1.2551355  -0.09057418 -0.26504245 -1.3699021\n",
      "  0.02376709 -0.27571115 -1.1735349 ]\n",
      "data: [-0.0161082  -0.08479025 -0.1964932   0.01924631 -0.18687968 -0.48409247\n",
      " -0.12139268 -0.4175508  -1.3475928  -0.2749479  -0.48349    -1.6418551\n",
      " -0.427649   -0.577641   -2.150852   -0.20719697 -0.7209214  -1.5218829\n",
      " -0.02671632 -0.7872152  -1.3625989  -0.08167918 -0.7142662  -1.4137422\n",
      " -0.09082498 -0.8855884  -1.5419853  -0.16022593 -0.6342895  -1.4149613\n",
      " -0.10262374 -0.68910235 -1.3880627  -0.11244115 -0.65540665 -1.4747338\n",
      "  0.02809374 -0.6917231  -1.4932207  -0.07565006 -0.5208614  -1.2467139\n",
      " -0.24044716 -0.2812931  -2.0459733  -0.04435429 -0.4611103  -2.072033\n",
      "  0.13438526 -0.42087948 -1.3492758  -0.19925404 -0.292057   -1.1660696\n",
      " -0.12643553 -0.2623977  -1.2551355  -0.09057418 -0.26504245 -1.3699021\n",
      "  0.02376709 -0.27571115 -1.1735349   0.17      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[-0.0171, -0.0052, -0.1702,  ...,  0.0152, -0.1890, -1.1710],\n",
      "        [-0.0171, -0.0052, -0.1702,  ...,  0.0152, -0.1890, -1.1710],\n",
      "        [-0.0171, -0.0052, -0.1702,  ...,  0.0152, -0.1890, -1.1710],\n",
      "        ...,\n",
      "        [-0.2262,  0.3031, -0.0597,  ..., -0.7933,  0.8930, -0.4146],\n",
      "        [-0.0916, -0.0733,  0.5937,  ..., -0.2262,  0.6323,  0.2772],\n",
      "        [-0.0916, -0.0733,  0.5937,  ..., -0.2262,  0.6323,  0.2772]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01713358 -0.00520281 -0.17016529  0.00651519 -0.11924312 -0.50037277\n",
      " -0.11998077 -0.33265823 -1.3202505  -0.2720919  -0.39361596 -1.616462\n",
      " -0.43576822 -0.49264264 -2.1092439  -0.21966389 -0.63360834 -1.4843912\n",
      " -0.02199416 -0.6840774  -1.3025086  -0.06792545 -0.6128134  -1.3540491\n",
      " -0.0674849  -0.76795495 -1.481817   -0.17530817 -0.53836995 -1.3848363\n",
      " -0.10393951 -0.5912355  -1.3591431  -0.10099854 -0.55629694 -1.4507093\n",
      "  0.05300172 -0.5870941  -1.4845538  -0.0864606  -0.4345281  -1.2168722\n",
      " -0.23221052 -0.19749789 -1.9516388  -0.04236075 -0.3658331  -1.9687028\n",
      "  0.1445775  -0.3253091  -1.340984   -0.20737451 -0.19993386 -1.1398013\n",
      " -0.13235748 -0.17051871 -1.2271832  -0.09057043 -0.1767665  -1.3455138\n",
      "  0.01518101 -0.1890373  -1.170988  ]\n",
      "data: [-0.01713358 -0.00520281 -0.17016529  0.00651519 -0.11924312 -0.50037277\n",
      " -0.11998077 -0.33265823 -1.3202505  -0.2720919  -0.39361596 -1.616462\n",
      " -0.43576822 -0.49264264 -2.1092439  -0.21966389 -0.63360834 -1.4843912\n",
      " -0.02199416 -0.6840774  -1.3025086  -0.06792545 -0.6128134  -1.3540491\n",
      " -0.0674849  -0.76795495 -1.481817   -0.17530817 -0.53836995 -1.3848363\n",
      " -0.10393951 -0.5912355  -1.359143   -0.10099854 -0.55629694 -1.4507093\n",
      "  0.05300172 -0.5870941  -1.4845538  -0.0864606  -0.4345281  -1.2168722\n",
      " -0.23221052 -0.19749789 -1.9516388  -0.04236075 -0.3658331  -1.9687028\n",
      "  0.1445775  -0.3253091  -1.340984   -0.20737451 -0.19993386 -1.1398013\n",
      " -0.13235748 -0.1705187  -1.2271832  -0.09057043 -0.17676648 -1.3455138\n",
      "  0.01518101 -0.18903728 -1.170988    0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0016, -0.1228, -0.2080,  ...,  0.0268, -0.2753, -1.3359],\n",
      "        [-0.0016, -0.1228, -0.2080,  ...,  0.0268, -0.2753, -1.3359],\n",
      "        [-0.0016, -0.1228, -0.2080,  ...,  0.0268, -0.2753, -1.3359],\n",
      "        ...,\n",
      "        [-0.2471,  0.3487, -0.1725,  ..., -0.7297,  0.7795, -0.3365],\n",
      "        [-0.1643, -0.0921,  0.5396,  ..., -0.2601,  0.6759,  0.2383],\n",
      "        [-0.1643, -0.0921,  0.5396,  ..., -0.2601,  0.6759,  0.2383]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-1.57500431e-03 -1.22788697e-01 -2.08031043e-01  1.35069378e-02\n",
      " -2.93230653e-01 -6.88530922e-01 -2.57101282e-02 -4.40162688e-01\n",
      " -1.36224771e+00 -1.67331070e-01 -4.92547184e-01 -1.67478395e+00\n",
      " -3.55569243e-01 -6.34993672e-01 -2.12861204e+00 -2.29479596e-01\n",
      " -7.00441599e-01 -1.52668011e+00  6.23579472e-02 -6.95588708e-01\n",
      " -1.27869451e+00  1.06976405e-02 -6.42475009e-01 -1.32801259e+00\n",
      "  5.36759198e-03 -7.33887672e-01 -1.44408011e+00 -1.82117924e-01\n",
      " -5.78035593e-01 -1.45232844e+00 -5.90120479e-02 -6.35235786e-01\n",
      " -1.43990469e+00 -5.63490391e-02 -6.03021860e-01 -1.54876828e+00\n",
      "  6.74112737e-02 -6.28411889e-01 -1.62634718e+00 -6.97825775e-02\n",
      " -5.07533789e-01 -1.27138925e+00 -1.49066523e-01 -2.78530806e-01\n",
      " -1.79622841e+00 -1.18993148e-02 -4.21880990e-01 -1.76834106e+00\n",
      "  1.33575186e-01 -3.85320514e-01 -1.48042107e+00 -1.74283385e-01\n",
      " -2.57959068e-01 -1.22347701e+00 -6.70192987e-02 -2.38042429e-01\n",
      " -1.30120337e+00 -7.62644410e-03 -2.72749424e-01 -1.42512190e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2.68243477e-02 -2.75309443e-01 -1.33592010e+00]\n",
      "data: [-1.57500431e-03 -1.22788697e-01 -2.08031043e-01  1.35069378e-02\n",
      " -2.93230653e-01 -6.88530862e-01 -2.57101282e-02 -4.40162688e-01\n",
      " -1.36224782e+00 -1.67331070e-01 -4.92547184e-01 -1.67478395e+00\n",
      " -3.55569243e-01 -6.34993672e-01 -2.12861204e+00 -2.29479596e-01\n",
      " -7.00441599e-01 -1.52668011e+00  6.23579472e-02 -6.95588708e-01\n",
      " -1.27869451e+00  1.06976405e-02 -6.42474949e-01 -1.32801259e+00\n",
      "  5.36759198e-03 -7.33887613e-01 -1.44408000e+00 -1.82117924e-01\n",
      " -5.78035593e-01 -1.45232844e+00 -5.90120442e-02 -6.35235786e-01\n",
      " -1.43990469e+00 -5.63490391e-02 -6.03021860e-01 -1.54876828e+00\n",
      "  6.74112737e-02 -6.28411889e-01 -1.62634718e+00 -6.97825775e-02\n",
      " -5.07533789e-01 -1.27138925e+00 -1.49066523e-01 -2.78530806e-01\n",
      " -1.79622829e+00 -1.18993148e-02 -4.21880990e-01 -1.76834106e+00\n",
      "  1.33575186e-01 -3.85320514e-01 -1.48042119e+00 -1.74283385e-01\n",
      " -2.57959068e-01 -1.22347701e+00 -6.70192987e-02 -2.38042429e-01\n",
      " -1.30120325e+00 -7.62644410e-03 -2.72749424e-01 -1.42512190e+00\n",
      "  2.68243477e-02 -2.75309443e-01 -1.33592010e+00  1.89999998e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B320>\n",
      "tensor([[ 0.0448, -0.1389, -0.2748,  ...,  0.0655, -0.3150, -1.3291],\n",
      "        [ 0.0448, -0.1389, -0.2748,  ...,  0.0655, -0.3150, -1.3291],\n",
      "        [ 0.0448, -0.1389, -0.2748,  ...,  0.0655, -0.3150, -1.3291],\n",
      "        ...,\n",
      "        [-0.1507,  0.4982, -0.1630,  ..., -0.6904,  1.0289, -0.5046],\n",
      "        [-0.1968, -0.0779,  0.6310,  ..., -0.2957,  0.6777,  0.2758],\n",
      "        [-0.1968, -0.0779,  0.6310,  ..., -0.2957,  0.6777,  0.2758]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04483519 -0.13894367 -0.27477312  0.07653293 -0.26266122 -0.6519392\n",
      " -0.02165029 -0.4700315  -1.4576868  -0.16729905 -0.53117955 -1.761611\n",
      " -0.31883568 -0.6399447  -2.2594273  -0.15879393 -0.7521367  -1.6395637\n",
      "  0.06680647 -0.79749084 -1.447395    0.00836594 -0.73683405 -1.4964573\n",
      " -0.01113412 -0.88172674 -1.6235396  -0.11211836 -0.6532601  -1.538878\n",
      " -0.03610945 -0.7112553  -1.52113    -0.04521462 -0.6793786  -1.6112503\n",
      "  0.0737164  -0.7209972  -1.6507322  -0.01722089 -0.548241   -1.3673391\n",
      " -0.16143852 -0.3134263  -2.0738673   0.01196866 -0.4867822  -2.0818052\n",
      "  0.1656402  -0.44395086 -1.5033349  -0.13929018 -0.31471363 -1.2915419\n",
      " -0.05011059 -0.2859285  -1.3696964  -0.00961234 -0.30568826 -1.4844204\n",
      "  0.06550712 -0.3150133  -1.3290858 ]\n",
      "data: [ 0.04483519 -0.13894367 -0.27477312  0.07653293 -0.26266122 -0.6519392\n",
      " -0.02165029 -0.4700315  -1.4576868  -0.16729905 -0.53117955 -1.761611\n",
      " -0.31883568 -0.6399447  -2.2594273  -0.15879393 -0.7521367  -1.6395638\n",
      "  0.06680647 -0.79749084 -1.447395    0.00836594 -0.73683405 -1.4964573\n",
      " -0.01113412 -0.88172674 -1.6235396  -0.11211836 -0.6532601  -1.538878\n",
      " -0.03610945 -0.7112553  -1.52113    -0.04521462 -0.6793787  -1.6112503\n",
      "  0.0737164  -0.7209972  -1.6507322  -0.01722089 -0.548241   -1.3673391\n",
      " -0.16143852 -0.3134263  -2.0738673   0.01196866 -0.4867822  -2.0818052\n",
      "  0.1656402  -0.44395083 -1.5033348  -0.13929018 -0.31471363 -1.2915419\n",
      " -0.05011059 -0.2859285  -1.3696964  -0.00961234 -0.30568826 -1.4844204\n",
      "  0.06550712 -0.3150133  -1.3290858   0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.203 3.208 3.204 ... 3.168 3.173 3.179]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " [3.2   3.203 3.197 ... 3.154 3.156 3.158]\n",
      " ...\n",
      " [2.805 2.801 2.798 ... 2.795 2.798 2.799]\n",
      " [2.79  2.786 2.787 ... 2.787 2.792 2.789]\n",
      " [2.773 2.774 2.778 ... 2.781 2.783 2.78 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0059, -0.1053, -0.2080,  ...,  0.0758, -0.3016, -1.2572],\n",
      "        [-0.0059, -0.1053, -0.2080,  ...,  0.0758, -0.3016, -1.2572],\n",
      "        [-0.0059, -0.1053, -0.2080,  ...,  0.0758, -0.3016, -1.2572],\n",
      "        ...,\n",
      "        [-0.1203,  0.4641, -0.1363,  ..., -0.7790,  0.9758, -0.3999],\n",
      "        [-0.1322, -0.0592,  0.5853,  ..., -0.2176,  0.6323,  0.2211],\n",
      "        [-0.1322, -0.0592,  0.5853,  ..., -0.2176,  0.6323,  0.2211]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.00589226 -0.10527686 -0.20799479  0.01410538 -0.25463045 -0.59474325\n",
      " -0.02856343 -0.43193808 -1.342303   -0.17142266 -0.48805636 -1.6713251\n",
      " -0.35918468 -0.6413442  -2.1297154  -0.2254204  -0.69411874 -1.5425447\n",
      "  0.0853124  -0.71672845 -1.3260566   0.02096292 -0.67291117 -1.3655556\n",
      "  0.02760006 -0.78980064 -1.4865718  -0.15916452 -0.57603705 -1.437167\n",
      " -0.03812887 -0.6506368  -1.4286597  -0.02417506 -0.6328579  -1.538307\n",
      "  0.09240843 -0.6818886  -1.6085197  -0.03403895 -0.4960668  -1.2394097\n",
      " -0.1516784  -0.26967707 -1.8857156   0.02100952 -0.45021603 -1.8610604\n",
      "  0.18024777 -0.41098526 -1.4300447  -0.16166022 -0.24836491 -1.1795317\n",
      " -0.02753232 -0.24093994 -1.2506227   0.03326871 -0.29476774 -1.3666298\n",
      "  0.07584568 -0.3015582  -1.2572083 ]\n",
      "data: [-3.78 -1.77  0.15 -3.73 -1.65  0.38 -3.71 -1.59  0.78 -3.71 -1.44  0.52\n",
      " -2.9  -0.44 -2.63 -3.68 -1.45  0.74 -3.68 -1.52  0.74 -2.9  -0.5  -2.63\n",
      " -2.86 -0.31 -2.86  0.    0.    0.   -3.65 -1.13  0.11 -3.61 -0.89  0.11\n",
      " -3.6  -0.71 -0.15 -3.72 -1.17 -0.03 -3.74 -1.07 -0.01 -3.72 -0.86  0.09\n",
      " -3.13 -0.19 -2.83 -3.84 -1.09 -0.11 -3.84 -0.93 -0.09 -3.87 -0.87 -0.05\n",
      " -3.88 -0.62 -0.11  0.  ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63EB8>\n",
      "tensor([[-2.2872e-02,  2.3618e-02, -7.8218e-02,  ...,  1.1192e-01,\n",
      "         -1.2782e-01,  6.1546e-02],\n",
      "        [-2.2872e-02,  2.3618e-02, -7.8218e-02,  ...,  1.1192e-01,\n",
      "         -1.2782e-01,  6.1546e-02],\n",
      "        [-2.2872e-02,  2.3618e-02, -7.8218e-02,  ...,  1.1192e-01,\n",
      "         -1.2782e-01,  6.1546e-02],\n",
      "        ...,\n",
      "        [ 3.1518e-01, -3.1658e-01,  2.8978e-01,  ..., -7.0223e-01,\n",
      "          3.1426e-01, -1.2030e+00],\n",
      "        [ 8.5601e-02, -2.6553e-01,  8.0389e-01,  ..., -1.7331e+00,\n",
      "          8.8608e-04,  2.0593e-01],\n",
      "        [ 8.5601e-02, -2.6553e-01,  8.0389e-01,  ..., -1.7331e+00,\n",
      "          8.8608e-04,  2.0593e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.02287174  0.0236178  -0.07821809 -0.13006057 -0.1030415  -0.31843805\n",
      " -0.25111228 -0.24064997 -0.27722025 -0.3249942  -0.3453246  -0.24057369\n",
      " -0.38636005 -0.45104963 -0.15432982 -0.2641229  -0.19156004 -0.3922787\n",
      " -0.25985166 -0.25964168 -0.21330342 -0.2683786  -0.31767145 -0.17483836\n",
      " -0.21058527 -0.35169053 -0.15724617 -0.17983556 -0.10931963 -0.38570037\n",
      " -0.23097385 -0.21402046 -0.27665016 -0.19235133 -0.294295   -0.23262484\n",
      " -0.1077879  -0.35366404 -0.21773532 -0.13411969 -0.09286426 -0.30883992\n",
      " -0.17119844 -0.0956842  -0.21898708 -0.10855745 -0.19746071 -0.18139914\n",
      "  0.01338646 -0.25115776 -0.07334489 -0.08554555  0.02650047 -0.22428383\n",
      " -0.05416055  0.00420878 -0.09896394  0.03704031 -0.06643352 -0.0704305\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.11192182 -0.12782021  0.06154594]\n",
      "init: [-0.02287174  0.0236178  -0.07821809 -0.13006057 -0.1030415  -0.31843805\n",
      " -0.25111228 -0.24064997 -0.27722025 -0.3249942  -0.3453246  -0.24057369\n",
      " -0.38636005 -0.45104963 -0.15432982 -0.2641229  -0.19156004 -0.3922787\n",
      " -0.25985166 -0.25964168 -0.21330342 -0.2683786  -0.31767145 -0.17483836\n",
      " -0.21058527 -0.35169053 -0.15724617 -0.17983556 -0.10931963 -0.38570037\n",
      " -0.23097385 -0.21402046 -0.27665016 -0.19235133 -0.294295   -0.23262484\n",
      " -0.1077879  -0.35366404 -0.21773532 -0.13411969 -0.09286426 -0.30883992\n",
      " -0.17119844 -0.0956842  -0.21898708 -0.10855745 -0.19746071 -0.18139914\n",
      "  0.01338646 -0.25115776 -0.07334489 -0.08554555  0.02650047 -0.22428383\n",
      " -0.05416055  0.00420878 -0.09896394  0.03704031 -0.06643352 -0.0704305\n",
      "  0.11192182 -0.12782021  0.06154594]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [-0.02287174  0.0236178  -0.07821809 -0.13006057 -0.1030415  -0.31843805\n",
      " -0.25111228 -0.24064997 -0.27722025 -0.3249942  -0.3453246  -0.24057369\n",
      " -0.38636005 -0.45104963 -0.15432982 -0.2641229  -0.19156004 -0.3922787\n",
      " -0.25985166 -0.25964168 -0.21330342 -0.2683786  -0.31767145 -0.17483836\n",
      " -0.21058527 -0.35169053 -0.15724617 -0.17983554 -0.10931963 -0.38570037\n",
      " -0.23097385 -0.21402046 -0.27665016 -0.19235133 -0.294295   -0.23262483\n",
      " -0.10778789 -0.35366404 -0.21773534 -0.13411969 -0.09286425 -0.30883992\n",
      " -0.17119844 -0.0956842  -0.21898708 -0.10855744 -0.19746071 -0.18139914\n",
      "  0.01338646 -0.25115776 -0.07334489 -0.08554555  0.02650047 -0.22428383\n",
      " -0.05416055  0.00420878 -0.09896394  0.03704031 -0.06643352 -0.0704305\n",
      "  0.11192182 -0.12782021  0.06154594  0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[-7.1087e-02,  2.8606e-02,  2.6926e-01,  ..., -9.0672e-02,\n",
      "         -2.1867e-01, -6.3703e-01],\n",
      "        [-7.1087e-02,  2.8606e-02,  2.6926e-01,  ..., -9.0672e-02,\n",
      "         -2.1867e-01, -6.3703e-01],\n",
      "        [-7.1087e-02,  2.8606e-02,  2.6926e-01,  ..., -9.0672e-02,\n",
      "         -2.1867e-01, -6.3703e-01],\n",
      "        ...,\n",
      "        [ 2.7665e-01,  3.6741e-01, -1.2242e+00,  ...,  2.7383e-01,\n",
      "          6.8035e-01, -1.1779e+00],\n",
      "        [ 1.9737e-01,  4.5175e-02,  4.7931e-01,  ..., -2.0244e-01,\n",
      "          8.9640e-01,  8.3864e-05],\n",
      "        [ 1.9737e-01,  4.5175e-02,  4.7931e-01,  ..., -2.0244e-01,\n",
      "          8.9640e-01,  8.3864e-05]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.07108749  0.0286062   0.2692597  -0.13103773 -0.11035398 -0.11255223\n",
      " -0.35340744 -0.23849337 -0.6225368  -0.51095986 -0.3305269  -0.82062525\n",
      " -0.80428356 -0.383696   -1.211344   -0.3177144  -0.5412359  -0.7958235\n",
      " -0.43664432 -0.55614996 -0.8739651  -0.39253855 -0.45363584 -0.9296077\n",
      " -0.28615904 -0.6465516  -0.92694765 -0.27669483 -0.42949057 -0.79053444\n",
      " -0.2948637  -0.48762465 -0.65793407 -0.344324   -0.5106363  -0.74962753\n",
      " -0.07208019 -0.42564523 -0.85689765 -0.27402914 -0.46728635 -0.660711\n",
      " -0.3059523  -0.2692365  -0.98230916 -0.23444389 -0.34801653 -0.9923616\n",
      " -0.06039128 -0.34912065 -0.70724463 -0.25289392 -0.23987299 -0.62967956\n",
      " -0.35711932 -0.22162658 -0.6694462  -0.25864094 -0.15919502 -0.8086857\n",
      " -0.09067167 -0.21866979 -0.63702786]\n",
      "data: [-0.07108749  0.0286062   0.2692597  -0.13103773 -0.11035398 -0.11255223\n",
      " -0.35340744 -0.23849337 -0.6225368  -0.51095986 -0.3305269  -0.82062525\n",
      " -0.8042835  -0.383696   -1.211344   -0.3177144  -0.5412359  -0.7958235\n",
      " -0.43664432 -0.55614996 -0.8739651  -0.39253852 -0.4536358  -0.9296077\n",
      " -0.28615904 -0.6465516  -0.92694765 -0.27669483 -0.4294906  -0.79053444\n",
      " -0.2948637  -0.48762468 -0.657934   -0.344324   -0.5106363  -0.74962753\n",
      " -0.07208019 -0.42564523 -0.85689765 -0.27402914 -0.46728635 -0.660711\n",
      " -0.3059523  -0.2692365  -0.98230916 -0.23444389 -0.34801656 -0.9923616\n",
      " -0.06039128 -0.34912065 -0.70724463 -0.25289392 -0.23987299 -0.62967956\n",
      " -0.35711932 -0.22162658 -0.6694462  -0.25864094 -0.15919502 -0.80868566\n",
      " -0.09067167 -0.2186698  -0.63702786  0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.1095, -0.1939,  0.0374,  ...,  0.2946, -0.4030, -0.9804],\n",
      "        [ 0.1095, -0.1939,  0.0374,  ...,  0.2946, -0.4030, -0.9804],\n",
      "        [ 0.1095, -0.1939,  0.0374,  ...,  0.2946, -0.4030, -0.9804],\n",
      "        ...,\n",
      "        [-0.1641,  0.2720,  0.3255,  ..., -0.7129,  1.0207, -0.1143],\n",
      "        [-0.2287,  0.2781,  0.2978,  ..., -1.0771,  0.8759, -0.0138],\n",
      "        [-0.2287,  0.2781,  0.2978,  ..., -1.0771,  0.8759, -0.0138]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.10947028 -0.19391641  0.03742057  0.1258912  -0.33519176 -0.3754995\n",
      "  0.04337148 -0.48569807 -1.0604043  -0.08991688 -0.53200495 -1.350066\n",
      " -0.25286177 -0.6586332  -1.8091955  -0.09537277 -0.74937516 -1.2791455\n",
      "  0.14443952 -0.7539001  -1.1546586   0.14028119 -0.6838155  -1.2015643\n",
      "  0.21318327 -0.8057067  -1.303807   -0.03521048 -0.6392809  -1.2018952\n",
      "  0.10052909 -0.7033358  -1.1811275   0.15377152 -0.6844084  -1.2706988\n",
      "  0.35353374 -0.710535   -1.3540435   0.08032271 -0.59243774 -1.0155776\n",
      "  0.01857451 -0.35668847 -1.5678027   0.21741031 -0.5287279  -1.5468109\n",
      "  0.42813852 -0.4844231  -1.1840179  -0.01188256 -0.36236924 -0.94719344\n",
      "  0.10203969 -0.33628747 -0.98499066  0.1990021  -0.37325737 -1.1144516\n",
      "  0.2946094  -0.40304762 -0.98038906]\n",
      "data: [ 0.10947028 -0.19391641  0.03742057  0.1258912  -0.33519176 -0.3754995\n",
      "  0.04337148 -0.4856981  -1.0604043  -0.08991688 -0.53200495 -1.350066\n",
      " -0.25286177 -0.6586332  -1.8091955  -0.09537277 -0.74937516 -1.2791455\n",
      "  0.14443952 -0.7539002  -1.1546586   0.14028119 -0.6838155  -1.2015643\n",
      "  0.21318327 -0.80570674 -1.303807   -0.03521048 -0.6392809  -1.2018952\n",
      "  0.10052909 -0.7033358  -1.1811275   0.15377152 -0.6844084  -1.2706988\n",
      "  0.35353374 -0.710535   -1.3540435   0.08032271 -0.59243774 -1.0155776\n",
      "  0.01857451 -0.35668847 -1.5678028   0.21741031 -0.5287279  -1.5468109\n",
      "  0.42813855 -0.4844231  -1.1840179  -0.01188256 -0.36236924 -0.94719344\n",
      "  0.1020397  -0.33628747 -0.9849907   0.19900209 -0.37325737 -1.1144516\n",
      "  0.2946094  -0.40304765 -0.980389    0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0265, -0.1037, -0.2013,  ..., -0.0113, -0.3141, -1.2326],\n",
      "        [ 0.0265, -0.1037, -0.2013,  ..., -0.0113, -0.3141, -1.2326],\n",
      "        [ 0.0265, -0.1037, -0.2013,  ..., -0.0113, -0.3141, -1.2326],\n",
      "        ...,\n",
      "        [-0.3077,  0.3463, -0.2095,  ..., -0.5366,  0.8630, -0.6625],\n",
      "        [-0.2753,  0.0761,  0.4427,  ..., -0.1580,  0.8740, -0.0103],\n",
      "        [-0.2753,  0.0761,  0.4427,  ..., -0.1580,  0.8740, -0.0103]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02653239 -0.10374554 -0.2012932   0.00684976 -0.25699484 -0.6044653\n",
      " -0.14654832 -0.46943438 -1.3865197  -0.3164493  -0.5537051  -1.6626561\n",
      " -0.5232927  -0.6441692  -2.1536183  -0.19949943 -0.73784065 -1.5780597\n",
      " -0.09531161 -0.80496144 -1.4064837  -0.12965362 -0.71121144 -1.4645016\n",
      " -0.11017141 -0.8872191  -1.5567765  -0.16833463 -0.6206825  -1.5000472\n",
      " -0.13242878 -0.68141973 -1.4151981  -0.17088541 -0.6849575  -1.5030854\n",
      " -0.00286003 -0.6611788  -1.5200922  -0.10483903 -0.5544605  -1.3473592\n",
      " -0.22181436 -0.33613512 -1.9461071  -0.10130957 -0.48884118 -1.9550941\n",
      "  0.07680187 -0.47000828 -1.3677566  -0.18521844 -0.31093457 -1.2711582\n",
      " -0.17014395 -0.29722038 -1.3319066  -0.13237369 -0.28664255 -1.4394815\n",
      " -0.01128817 -0.31409174 -1.2325785 ]\n",
      "data: [ 0.02653239 -0.10374555 -0.2012932   0.00684976 -0.25699484 -0.6044653\n",
      " -0.14654832 -0.46943438 -1.3865197  -0.3164493  -0.5537051  -1.6626561\n",
      " -0.5232927  -0.6441692  -2.1536183  -0.19949943 -0.73784065 -1.5780597\n",
      " -0.09531161 -0.80496144 -1.4064837  -0.12965362 -0.71121144 -1.4645016\n",
      " -0.11017141 -0.8872191  -1.5567765  -0.16833463 -0.6206825  -1.5000472\n",
      " -0.13242878 -0.68141973 -1.4151981  -0.17088541 -0.6849575  -1.5030854\n",
      " -0.00286003 -0.6611788  -1.5200924  -0.10483903 -0.5544605  -1.3473592\n",
      " -0.22181436 -0.3361351  -1.9461071  -0.10130957 -0.48884118 -1.9550941\n",
      "  0.07680187 -0.47000828 -1.3677566  -0.18521842 -0.31093457 -1.2711582\n",
      " -0.17014395 -0.29722038 -1.3319066  -0.13237369 -0.28664255 -1.4394815\n",
      " -0.01128817 -0.31409174 -1.2325785   0.04      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B9B0>\n",
      "tensor([[ 0.0107, -0.0458, -0.1336,  ...,  0.0797, -0.2479, -1.0970],\n",
      "        [ 0.0107, -0.0458, -0.1336,  ...,  0.0797, -0.2479, -1.0970],\n",
      "        [ 0.0107, -0.0458, -0.1336,  ...,  0.0797, -0.2479, -1.0970],\n",
      "        ...,\n",
      "        [-0.1359,  0.3933, -0.0387,  ..., -0.9356,  1.0070, -0.4114],\n",
      "        [-0.0997, -0.1192,  0.5777,  ..., -0.2512,  0.5186,  0.2494],\n",
      "        [-0.0997, -0.1192,  0.5777,  ..., -0.2512,  0.5186,  0.2494]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.0699254e-02 -4.5813747e-02 -1.3364871e-01  4.4006769e-02\n",
      " -1.3690728e-01 -3.8682240e-01 -9.1158293e-02 -3.5551038e-01\n",
      " -1.2637039e+00 -2.3958592e-01 -4.1306216e-01 -1.5612280e+00\n",
      " -3.9151174e-01 -5.1002920e-01 -2.0737996e+00 -1.8058039e-01\n",
      " -6.7094648e-01 -1.4561385e+00  2.4333149e-02 -7.2560203e-01\n",
      " -1.3032863e+00 -2.0161346e-02 -6.5856767e-01 -1.3497810e+00\n",
      " -1.2824684e-03 -8.2174742e-01 -1.4854296e+00 -1.3223219e-01\n",
      " -5.8440566e-01 -1.3459554e+00 -5.3729773e-02 -6.3941288e-01\n",
      " -1.3275523e+00 -3.5234660e-02 -6.0326600e-01 -1.4181774e+00\n",
      "  1.3283351e-01 -6.5060580e-01 -1.4504299e+00 -4.0966667e-02\n",
      " -4.7810903e-01 -1.1710396e+00 -2.0576061e-01 -2.3354059e-01\n",
      " -1.9957701e+00  1.9821629e-02 -4.1955051e-01 -2.0213132e+00\n",
      "  2.2827791e-01 -3.7989047e-01 -1.2930381e+00 -1.7579752e-01\n",
      " -2.4735148e-01 -1.0836060e+00 -8.4900960e-02 -2.2129640e-01\n",
      " -1.1647197e+00 -4.2197540e-02 -2.2990732e-01 -1.2861688e+00\n",
      "  7.9677872e-02 -2.4786510e-01 -1.0970443e+00]\n",
      "data: [ 1.0699254e-02 -4.5813747e-02 -1.3364871e-01  4.4006769e-02\n",
      " -1.3690728e-01 -3.8682240e-01 -9.1158293e-02 -3.5551035e-01\n",
      " -1.2637039e+00 -2.3958592e-01 -4.1306219e-01 -1.5612280e+00\n",
      " -3.9151174e-01 -5.1002920e-01 -2.0737996e+00 -1.8058039e-01\n",
      " -6.7094648e-01 -1.4561385e+00  2.4333147e-02 -7.2560203e-01\n",
      " -1.3032863e+00 -2.0161346e-02 -6.5856767e-01 -1.3497810e+00\n",
      " -1.2824684e-03 -8.2174742e-01 -1.4854296e+00 -1.3223219e-01\n",
      " -5.8440566e-01 -1.3459554e+00 -5.3729773e-02 -6.3941288e-01\n",
      " -1.3275523e+00 -3.5234660e-02 -6.0326600e-01 -1.4181774e+00\n",
      "  1.3283351e-01 -6.5060580e-01 -1.4504300e+00 -4.0966667e-02\n",
      " -4.7810900e-01 -1.1710396e+00 -2.0576061e-01 -2.3354059e-01\n",
      " -1.9957701e+00  1.9821629e-02 -4.1955051e-01 -2.0213132e+00\n",
      "  2.2827791e-01 -3.7989047e-01 -1.2930381e+00 -1.7579752e-01\n",
      " -2.4735147e-01 -1.0836060e+00 -8.4900960e-02 -2.2129640e-01\n",
      " -1.1647197e+00 -4.2197540e-02 -2.2990732e-01 -1.2861688e+00\n",
      "  7.9677872e-02 -2.4786511e-01 -1.0970443e+00  5.0000001e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[-0.0475, -0.0320, -0.2333,  ...,  0.0066, -0.2019, -1.2741],\n",
      "        [-0.0475, -0.0320, -0.2333,  ...,  0.0066, -0.2019, -1.2741],\n",
      "        [-0.0475, -0.0320, -0.2333,  ...,  0.0066, -0.2019, -1.2741],\n",
      "        ...,\n",
      "        [-0.2316,  0.2349, -0.0593,  ..., -0.7409,  0.7375, -0.3244],\n",
      "        [-0.1692, -0.0103,  0.5452,  ..., -0.3207,  0.7383,  0.2169],\n",
      "        [-0.1692, -0.0103,  0.5452,  ..., -0.3207,  0.7383,  0.2169]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.04752785 -0.03200503 -0.23328978 -0.01514558 -0.16059017 -0.60648334\n",
      " -0.10071696 -0.34789467 -1.3795729  -0.24850366 -0.40154594 -1.6900026\n",
      " -0.416875   -0.52501225 -2.1680596  -0.25726795 -0.6287259  -1.5595663\n",
      " -0.00815848 -0.6615672  -1.3749864  -0.06553559 -0.5999764  -1.4227345\n",
      " -0.0662524  -0.73406506 -1.5452021  -0.20185554 -0.5254713  -1.4608823\n",
      " -0.11108772 -0.58363986 -1.4509254  -0.10602114 -0.55458856 -1.5482898\n",
      "  0.02183574 -0.59265375 -1.5995536  -0.09900825 -0.4354535  -1.2762628\n",
      " -0.23180766 -0.19039646 -1.9792148  -0.05022798 -0.3662008  -1.9761844\n",
      "  0.11296238 -0.32307783 -1.4423035  -0.22019865 -0.19597182 -1.2108392\n",
      " -0.11895038 -0.16903682 -1.295348   -0.06590825 -0.19439606 -1.4148331\n",
      "  0.00658488 -0.2019359  -1.274089  ]\n",
      "data: [-0.04752785 -0.03200503 -0.23328978 -0.01514558 -0.16059017 -0.60648334\n",
      " -0.10071696 -0.34789467 -1.3795729  -0.24850364 -0.40154594 -1.6900026\n",
      " -0.416875   -0.52501225 -2.1680596  -0.25726795 -0.6287259  -1.5595661\n",
      " -0.00815848 -0.6615672  -1.3749864  -0.06553559 -0.5999764  -1.4227345\n",
      " -0.0662524  -0.7340651  -1.5452021  -0.20185554 -0.5254713  -1.4608823\n",
      " -0.11108771 -0.58363986 -1.4509254  -0.10602114 -0.55458856 -1.5482898\n",
      "  0.02183574 -0.59265375 -1.5995536  -0.09900825 -0.4354535  -1.2762628\n",
      " -0.23180766 -0.19039646 -1.9792148  -0.05022798 -0.3662008  -1.9761844\n",
      "  0.11296238 -0.3230778  -1.4423034  -0.22019865 -0.19597182 -1.2108392\n",
      " -0.11895039 -0.16903682 -1.295348   -0.06590825 -0.19439606 -1.4148331\n",
      "  0.00658488 -0.2019359  -1.274089    0.06      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F438>\n",
      "tensor([[ 0.0365, -0.0798, -0.2212,  ...,  0.0371, -0.2591, -1.3077],\n",
      "        [ 0.0365, -0.0798, -0.2212,  ...,  0.0371, -0.2591, -1.3077],\n",
      "        [ 0.0365, -0.0798, -0.2212,  ...,  0.0371, -0.2591, -1.3077],\n",
      "        ...,\n",
      "        [-0.3575,  0.2666, -0.3234,  ..., -0.8858,  0.7256, -0.4618],\n",
      "        [-0.1854, -0.1214,  0.5699,  ..., -0.2421,  0.6227,  0.3286],\n",
      "        [-0.1854, -0.1214,  0.5699,  ..., -0.2421,  0.6227,  0.3286]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0365052  -0.07984552 -0.22115575  0.04539549 -0.2322418  -0.66459405\n",
      " -0.02870939 -0.39366323 -1.3684523  -0.17061414 -0.45241562 -1.6635758\n",
      " -0.34975907 -0.5686581  -2.1348226  -0.17760056 -0.67879075 -1.5226529\n",
      "  0.03491077 -0.6948919  -1.3374801  -0.01351397 -0.6323047  -1.3942139\n",
      " -0.00956421 -0.7501761  -1.5031315  -0.13865176 -0.56977737 -1.4504694\n",
      " -0.05142246 -0.6183265  -1.4280252  -0.06496051 -0.5932516  -1.5286942\n",
      "  0.06178106 -0.6045284  -1.5822287  -0.05180723 -0.49497396 -1.2859669\n",
      " -0.14109585 -0.2753058  -1.844538   -0.01093895 -0.41032913 -1.8374751\n",
      "  0.1315474  -0.38297647 -1.4476005  -0.14245355 -0.25781876 -1.2327956\n",
      " -0.07015041 -0.24028197 -1.3142384  -0.02593727 -0.25014827 -1.4329195\n",
      "  0.0371315  -0.2590586  -1.3076867 ]\n",
      "data: [ 0.0365052  -0.07984552 -0.22115573  0.04539549 -0.23224181 -0.66459405\n",
      " -0.02870939 -0.39366323 -1.3684523  -0.17061415 -0.45241562 -1.6635758\n",
      " -0.34975907 -0.5686581  -2.1348226  -0.17760056 -0.67879075 -1.5226529\n",
      "  0.03491077 -0.694892   -1.3374801  -0.01351397 -0.6323047  -1.3942139\n",
      " -0.00956421 -0.7501761  -1.5031315  -0.13865176 -0.56977737 -1.4504694\n",
      " -0.05142246 -0.6183265  -1.4280252  -0.06496051 -0.5932516  -1.5286942\n",
      "  0.06178106 -0.6045284  -1.5822287  -0.05180723 -0.49497396 -1.2859668\n",
      " -0.14109585 -0.2753058  -1.844538   -0.01093895 -0.41032913 -1.8374752\n",
      "  0.1315474  -0.38297644 -1.4476006  -0.14245355 -0.25781876 -1.2327956\n",
      " -0.07015041 -0.24028197 -1.3142384  -0.02593727 -0.25014827 -1.4329195\n",
      "  0.0371315  -0.2590586  -1.3076866   0.07      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0300, -0.0855, -0.2662,  ...,  0.0435, -0.2721, -1.3026],\n",
      "        [ 0.0300, -0.0855, -0.2662,  ...,  0.0435, -0.2721, -1.3026],\n",
      "        [ 0.0300, -0.0855, -0.2662,  ...,  0.0435, -0.2721, -1.3026],\n",
      "        ...,\n",
      "        [-0.1621,  0.4260, -0.0616,  ..., -0.7210,  0.9296, -0.3488],\n",
      "        [-0.1717, -0.1178,  0.6036,  ..., -0.2575,  0.6753,  0.2504],\n",
      "        [-0.1717, -0.1178,  0.6036,  ..., -0.2575,  0.6753,  0.2504]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03001116 -0.08546736 -0.2661975   0.05286911 -0.20814876 -0.6520318\n",
      " -0.06945959 -0.4110108  -1.445709   -0.21771476 -0.47756594 -1.7318786\n",
      " -0.3715291  -0.5708638  -2.229093   -0.16492987 -0.7074373  -1.6056985\n",
      "  0.0062091  -0.7565116  -1.4342749  -0.04280115 -0.68256783 -1.4927124\n",
      " -0.0504147  -0.835293   -1.6119447  -0.12670735 -0.614723   -1.5182621\n",
      " -0.06695084 -0.66360694 -1.4844162  -0.08759505 -0.63449764 -1.570353\n",
      "  0.04819461 -0.6536054  -1.5955487  -0.05037387 -0.51800954 -1.3562906\n",
      " -0.17715997 -0.28734082 -2.0302758  -0.02137205 -0.4419517  -2.0469222\n",
      "  0.1407601  -0.41104484 -1.4614493  -0.15223348 -0.2878842  -1.2821951\n",
      " -0.09190849 -0.25941417 -1.3668846  -0.05545958 -0.25802174 -1.4802126\n",
      "  0.04352298 -0.27212676 -1.3025512 ]\n",
      "data: [ 0.03001116 -0.08546736 -0.2661975   0.0528691  -0.20814876 -0.6520318\n",
      " -0.06945959 -0.41101083 -1.4457089  -0.21771474 -0.47756594 -1.7318786\n",
      " -0.37152907 -0.5708638  -2.229093   -0.16492987 -0.7074373  -1.6056983\n",
      "  0.0062091  -0.7565116  -1.4342749  -0.04280115 -0.68256783 -1.4927124\n",
      " -0.0504147  -0.835293   -1.6119447  -0.12670735 -0.614723   -1.5182621\n",
      " -0.06695084 -0.66360694 -1.4844162  -0.08759505 -0.63449764 -1.570353\n",
      "  0.04819461 -0.6536054  -1.5955487  -0.05037387 -0.51800954 -1.3562906\n",
      " -0.17715997 -0.28734082 -2.0302758  -0.02137205 -0.44195166 -2.0469222\n",
      "  0.1407601  -0.41104484 -1.4614493  -0.15223348 -0.2878842  -1.2821951\n",
      " -0.09190849 -0.25941417 -1.3668846  -0.05545958 -0.25802174 -1.4802126\n",
      "  0.04352298 -0.27212676 -1.3025512   0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0160, -0.0404, -0.2333,  ...,  0.0518, -0.2287, -1.2800],\n",
      "        [ 0.0160, -0.0404, -0.2333,  ...,  0.0518, -0.2287, -1.2800],\n",
      "        [ 0.0160, -0.0404, -0.2333,  ...,  0.0518, -0.2287, -1.2800],\n",
      "        ...,\n",
      "        [-0.1548,  0.3516, -0.1062,  ..., -0.8125,  0.8441, -0.3372],\n",
      "        [-0.1364, -0.1505,  0.5539,  ..., -0.2297,  0.5905,  0.2307],\n",
      "        [-0.1364, -0.1505,  0.5539,  ..., -0.2297,  0.5905,  0.2307]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.6022500e-02 -4.0387843e-02 -2.3332985e-01  3.1469058e-02\n",
      " -1.8228397e-01 -6.4529467e-01 -3.5978615e-02 -3.5702634e-01\n",
      " -1.3698310e+00 -1.7715789e-01 -4.1346478e-01 -1.6796170e+00\n",
      " -3.5310623e-01 -5.3878474e-01 -2.1438079e+00 -1.9196373e-01\n",
      " -6.3931721e-01 -1.5390723e+00  4.9977630e-02 -6.6318631e-01\n",
      " -1.3498473e+00 -5.6901276e-03 -6.0701001e-01 -1.4024655e+00\n",
      " -2.7487725e-03 -7.3537612e-01 -1.5197453e+00 -1.4290661e-01\n",
      " -5.3142589e-01 -1.4497210e+00 -4.8702948e-02 -5.8961642e-01\n",
      " -1.4321742e+00 -5.3668946e-02 -5.6805879e-01 -1.5344608e+00\n",
      "  6.9533989e-02 -5.9774613e-01 -1.5872433e+00 -4.2942144e-02\n",
      " -4.4611031e-01 -1.2731590e+00 -1.5631101e-01 -2.2346018e-01\n",
      " -1.9113375e+00 -4.7753751e-04 -3.8243544e-01 -1.9037454e+00\n",
      "  1.5221033e-01 -3.5012603e-01 -1.4346929e+00 -1.5079901e-01\n",
      " -2.0942369e-01 -1.2130054e+00 -5.6753948e-02 -1.9370966e-01\n",
      " -1.2917308e+00 -1.1056855e-02 -2.1828811e-01 -1.4095503e+00\n",
      "  5.1759548e-02 -2.2866932e-01 -1.2799913e+00]\n",
      "data: [ 1.6022500e-02 -4.0387847e-02 -2.3332985e-01  3.1469058e-02\n",
      " -1.8228397e-01 -6.4529467e-01 -3.5978615e-02 -3.5702634e-01\n",
      " -1.3698310e+00 -1.7715789e-01 -4.1346478e-01 -1.6796170e+00\n",
      " -3.5310623e-01 -5.3878474e-01 -2.1438079e+00 -1.9196373e-01\n",
      " -6.3931721e-01 -1.5390723e+00  4.9977630e-02 -6.6318631e-01\n",
      " -1.3498473e+00 -5.6901276e-03 -6.0701001e-01 -1.4024655e+00\n",
      " -2.7487725e-03 -7.3537612e-01 -1.5197453e+00 -1.4290661e-01\n",
      " -5.3142589e-01 -1.4497209e+00 -4.8702944e-02 -5.8961642e-01\n",
      " -1.4321742e+00 -5.3668946e-02 -5.6805879e-01 -1.5344608e+00\n",
      "  6.9533989e-02 -5.9774613e-01 -1.5872433e+00 -4.2942144e-02\n",
      " -4.4611031e-01 -1.2731590e+00 -1.5631101e-01 -2.2346018e-01\n",
      " -1.9113374e+00 -4.7753751e-04 -3.8243544e-01 -1.9037454e+00\n",
      "  1.5221033e-01 -3.5012603e-01 -1.4346929e+00 -1.5079901e-01\n",
      " -2.0942369e-01 -1.2130054e+00 -5.6753948e-02 -1.9370966e-01\n",
      " -1.2917308e+00 -1.1056854e-02 -2.1828812e-01 -1.4095503e+00\n",
      "  5.1759548e-02 -2.2866932e-01 -1.2799913e+00  9.0000004e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[ 0.0073, -0.0835, -0.2645,  ...,  0.0326, -0.2676, -1.3298],\n",
      "        [ 0.0073, -0.0835, -0.2645,  ...,  0.0326, -0.2676, -1.3298],\n",
      "        [ 0.0073, -0.0835, -0.2645,  ...,  0.0326, -0.2676, -1.3298],\n",
      "        ...,\n",
      "        [-0.1589,  0.4164, -0.1045,  ..., -0.7288,  0.9021, -0.3336],\n",
      "        [-0.1565, -0.1272,  0.5840,  ..., -0.2358,  0.6603,  0.2389],\n",
      "        [-0.1565, -0.1272,  0.5840,  ..., -0.2358,  0.6603,  0.2389]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00731288 -0.08350725 -0.26453796  0.02522214 -0.22800419 -0.6923003\n",
      " -0.05959295 -0.40450117 -1.4343832  -0.19971764 -0.46650782 -1.7290659\n",
      " -0.36926585 -0.580518   -2.2015793  -0.19554037 -0.6855203  -1.5928788\n",
      "  0.01873082 -0.7106441  -1.4007244  -0.02858114 -0.64672816 -1.4569228\n",
      " -0.02640221 -0.7735262  -1.5713642  -0.15460242 -0.5788188  -1.5122528\n",
      " -0.06952529 -0.63097703 -1.4857979  -0.08062269 -0.60667765 -1.5802765\n",
      "  0.05174457 -0.6236774  -1.6303947  -0.06798903 -0.5000991  -1.340869\n",
      " -0.17027193 -0.2739504  -1.9504261  -0.02526122 -0.4214587  -1.9469404\n",
      "  0.12857524 -0.39116302 -1.4844217  -0.16510099 -0.26277813 -1.2783201\n",
      " -0.08835128 -0.24184215 -1.3572636  -0.03978822 -0.2542853  -1.4737508\n",
      "  0.03260317 -0.26756114 -1.3298178 ]\n",
      "data: [ 0.00731288 -0.08350725 -0.26453796  0.02522214 -0.22800419 -0.6923003\n",
      " -0.05959295 -0.40450114 -1.434383   -0.19971764 -0.46650782 -1.7290659\n",
      " -0.36926585 -0.580518   -2.2015793  -0.19554037 -0.68552035 -1.5928788\n",
      "  0.01873082 -0.7106441  -1.4007245  -0.02858114 -0.64672816 -1.4569228\n",
      " -0.02640221 -0.77352613 -1.5713642  -0.15460242 -0.5788188  -1.5122528\n",
      " -0.06952529 -0.63097703 -1.4857979  -0.0806227  -0.60667765 -1.5802765\n",
      "  0.05174457 -0.6236774  -1.6303947  -0.06798903 -0.5000991  -1.340869\n",
      " -0.17027193 -0.2739504  -1.950426   -0.02526122 -0.4214587  -1.9469404\n",
      "  0.12857524 -0.39116302 -1.4844217  -0.16510099 -0.26277813 -1.2783201\n",
      " -0.08835128 -0.24184215 -1.3572634  -0.03978822 -0.2542853  -1.4737507\n",
      "  0.03260317 -0.26756114 -1.3298178   0.1       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0442, -0.1407, -0.2769,  ...,  0.0571, -0.3139, -1.3468],\n",
      "        [ 0.0442, -0.1407, -0.2769,  ...,  0.0571, -0.3139, -1.3468],\n",
      "        [ 0.0442, -0.1407, -0.2769,  ...,  0.0571, -0.3139, -1.3468],\n",
      "        ...,\n",
      "        [-0.1298,  0.4192, -0.1651,  ..., -0.7336,  0.9255, -0.4533],\n",
      "        [-0.1769, -0.1050,  0.6035,  ..., -0.2547,  0.6488,  0.2805],\n",
      "        [-0.1769, -0.1050,  0.6035,  ..., -0.2547,  0.6488,  0.2805]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0442343  -0.14072695 -0.276866    0.07345359 -0.26916862 -0.6740781\n",
      " -0.00991322 -0.46117404 -1.4498541  -0.15397242 -0.51878846 -1.7580119\n",
      " -0.31267235 -0.63114405 -2.2495568  -0.16033176 -0.745718   -1.6291776\n",
      "  0.07051743 -0.7814219  -1.4420729   0.01184989 -0.7225317  -1.4936262\n",
      " -0.00240553 -0.8600856  -1.6175839  -0.11490089 -0.6454574  -1.5329305\n",
      " -0.03357298 -0.70125973 -1.5173595  -0.0442099  -0.67181134 -1.6150436\n",
      "  0.07189813 -0.7082546  -1.6595271  -0.02153668 -0.5462886  -1.360018\n",
      " -0.1542494  -0.315119   -2.0407212   0.00964979 -0.4800514  -2.044565\n",
      "  0.15781844 -0.44196835 -1.5120784  -0.13872564 -0.31243515 -1.2911707\n",
      " -0.05035467 -0.2870557  -1.3708166  -0.01005387 -0.30707356 -1.487267\n",
      "  0.05708508 -0.3138907  -1.3467529 ]\n",
      "data: [ 0.0442343  -0.14072695 -0.276866    0.07345359 -0.26916862 -0.67407817\n",
      " -0.00991322 -0.46117404 -1.4498541  -0.15397242 -0.51878846 -1.7580119\n",
      " -0.31267235 -0.63114405 -2.2495568  -0.16033177 -0.745718   -1.6291776\n",
      "  0.07051743 -0.7814219  -1.4420729   0.01184989 -0.7225317  -1.4936262\n",
      " -0.00240553 -0.8600856  -1.6175839  -0.11490089 -0.6454574  -1.5329305\n",
      " -0.03357298 -0.7012598  -1.5173595  -0.0442099  -0.67181134 -1.6150436\n",
      "  0.07189813 -0.7082546  -1.6595272  -0.02153668 -0.5462886  -1.360018\n",
      " -0.1542494  -0.315119   -2.0407212   0.00964979 -0.4800514  -2.044565\n",
      "  0.15781844 -0.44196835 -1.5120784  -0.13872564 -0.31243515 -1.2911706\n",
      " -0.05035467 -0.2870557  -1.3708167  -0.01005387 -0.30707356 -1.487267\n",
      "  0.05708508 -0.3138907  -1.3467529   0.11      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0199, -0.1134, -0.2325,  ...,  0.0737, -0.2932, -1.3197],\n",
      "        [ 0.0199, -0.1134, -0.2325,  ...,  0.0737, -0.2932, -1.3197],\n",
      "        [ 0.0199, -0.1134, -0.2325,  ...,  0.0737, -0.2932, -1.3197],\n",
      "        ...,\n",
      "        [-0.0769,  0.4385, -0.0781,  ..., -0.6320,  0.9308, -0.3614],\n",
      "        [-0.0985, -0.0664,  0.5868,  ..., -0.1681,  0.6229,  0.2804],\n",
      "        [-0.0985, -0.0664,  0.5868,  ..., -0.1681,  0.6229,  0.2804]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0198884  -0.11342624 -0.23247993  0.03353779 -0.27724114 -0.6588017\n",
      "  0.0027499  -0.44499847 -1.3701278  -0.14011428 -0.49986196 -1.6982958\n",
      " -0.33118314 -0.6533985  -2.150717   -0.20608792 -0.6998179  -1.5706323\n",
      "  0.10434181 -0.7135947  -1.3467054   0.03889339 -0.67104447 -1.3880447\n",
      "  0.04192138 -0.77777386 -1.5052147  -0.14416862 -0.57427096 -1.4751954\n",
      " -0.02199395 -0.6456108  -1.4646983  -0.01461438 -0.62828803 -1.5766133\n",
      "  0.0929865  -0.6712128  -1.6490145  -0.02001281 -0.4938425  -1.283363\n",
      " -0.12752095 -0.27336147 -1.8819734   0.0265715  -0.44293195 -1.8533182\n",
      "  0.1729101  -0.40348938 -1.4805117  -0.14120278 -0.24378324 -1.2290552\n",
      " -0.01264223 -0.23547098 -1.2997345   0.04391415 -0.28825825 -1.4166347\n",
      "  0.07371712 -0.29319733 -1.3196865 ]\n",
      "data: [ 0.0198884  -0.11342624 -0.23247993  0.03353779 -0.27724114 -0.6588017\n",
      "  0.0027499  -0.44499847 -1.3701279  -0.14011428 -0.49986196 -1.698296\n",
      " -0.33118314 -0.6533985  -2.150717   -0.20608792 -0.6998179  -1.5706323\n",
      "  0.10434181 -0.7135947  -1.3467054   0.03889339 -0.67104447 -1.3880447\n",
      "  0.04192139 -0.7777739  -1.5052147  -0.14416862 -0.57427096 -1.4751954\n",
      " -0.02199395 -0.6456108  -1.4646983  -0.01461438 -0.62828803 -1.5766133\n",
      "  0.09298649 -0.6712128  -1.6490145  -0.02001281 -0.4938425  -1.283363\n",
      " -0.12752095 -0.27336147 -1.8819734   0.0265715  -0.44293195 -1.8533182\n",
      "  0.1729101  -0.40348938 -1.4805117  -0.14120278 -0.24378322 -1.2290552\n",
      " -0.01264223 -0.23547098 -1.2997345   0.04391415 -0.28825825 -1.4166347\n",
      "  0.07371712 -0.29319733 -1.3196865   0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0334, -0.1408, -0.2452,  ...,  0.0551, -0.3268, -1.2961],\n",
      "        [ 0.0334, -0.1408, -0.2452,  ...,  0.0551, -0.3268, -1.2961],\n",
      "        [ 0.0334, -0.1408, -0.2452,  ...,  0.0551, -0.3268, -1.2961],\n",
      "        ...,\n",
      "        [-0.1498,  0.4670, -0.1360,  ..., -0.6433,  0.9644, -0.4673],\n",
      "        [-0.1747, -0.0930,  0.6333,  ..., -0.2406,  0.6699,  0.2668],\n",
      "        [-0.1747, -0.0930,  0.6333,  ..., -0.2406,  0.6699,  0.2668]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03337443 -0.14081204 -0.24520311  0.05340763 -0.27913582 -0.6448836\n",
      " -0.04398429 -0.48262063 -1.4232676  -0.18985343 -0.5488033  -1.720706\n",
      " -0.355391   -0.661993   -2.1986635  -0.17258534 -0.7595471  -1.5919206\n",
      "  0.04394668 -0.80380404 -1.3880548  -0.01141208 -0.74065775 -1.4385564\n",
      " -0.02354239 -0.88172144 -1.5578752  -0.12696537 -0.65383154 -1.4998229\n",
      " -0.0514404  -0.7124413  -1.470639   -0.06284167 -0.68701226 -1.5594604\n",
      "  0.06049979 -0.7155316  -1.5988476  -0.0347292  -0.5586611  -1.3308668\n",
      " -0.16431123 -0.33183306 -1.9950731  -0.00527975 -0.49596912 -1.9968452\n",
      "  0.14933231 -0.45645636 -1.4559219  -0.14601463 -0.32145533 -1.260459\n",
      " -0.06484921 -0.2980708  -1.3418903  -0.02130768 -0.3153522  -1.4544008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.05514967 -0.32676554 -1.2961006 ]\n",
      "data: [ 0.03337443 -0.14081204 -0.24520311  0.05340762 -0.27913582 -0.6448836\n",
      " -0.04398429 -0.48262063 -1.4232677  -0.18985344 -0.5488033  -1.720706\n",
      " -0.355391   -0.661993   -2.1986635  -0.17258534 -0.7595471  -1.5919206\n",
      "  0.04394668 -0.80380404 -1.3880548  -0.01141208 -0.74065775 -1.4385563\n",
      " -0.02354239 -0.88172144 -1.5578752  -0.12696537 -0.65383154 -1.4998229\n",
      " -0.0514404  -0.7124413  -1.470639   -0.06284167 -0.68701226 -1.5594604\n",
      "  0.0604998  -0.7155316  -1.5988476  -0.0347292  -0.5586611  -1.3308668\n",
      " -0.16431123 -0.33183306 -1.9950731  -0.00527975 -0.49596912 -1.9968452\n",
      "  0.14933231 -0.45645636 -1.4559219  -0.14601463 -0.32145536 -1.260459\n",
      " -0.06484921 -0.2980708  -1.3418902  -0.02130768 -0.3153522  -1.4544008\n",
      "  0.05514967 -0.3267655  -1.2961006   0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[ 0.0220, -0.1075, -0.2002,  ...,  0.0765, -0.3063, -1.1808],\n",
      "        [ 0.0220, -0.1075, -0.2002,  ...,  0.0765, -0.3063, -1.1808],\n",
      "        [ 0.0220, -0.1075, -0.2002,  ...,  0.0765, -0.3063, -1.1808],\n",
      "        ...,\n",
      "        [-0.0722,  0.4364, -0.1034,  ..., -0.6443,  0.9817, -0.4514],\n",
      "        [-0.1130, -0.0750,  0.6048,  ..., -0.2226,  0.6278,  0.2503],\n",
      "        [-0.1130, -0.0750,  0.6048,  ..., -0.2226,  0.6278,  0.2503]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02196462 -0.10750688 -0.2001517   0.05891377 -0.2101639  -0.48762792\n",
      " -0.06946833 -0.43459263 -1.3409092  -0.22157387 -0.49802777 -1.6389079\n",
      " -0.36903954 -0.5993389  -2.150459   -0.16811745 -0.737298   -1.5277975\n",
      "  0.02860849 -0.800633   -1.3777139  -0.03167365 -0.7317887  -1.4268277\n",
      " -0.04015756 -0.8989055  -1.5549066  -0.11723518 -0.6519225  -1.4201655\n",
      " -0.05126228 -0.7091822  -1.4006689  -0.0593684  -0.67527235 -1.4866774\n",
      "  0.07094985 -0.7203642  -1.5044243  -0.02415771 -0.53836    -1.2492917\n",
      " -0.18526445 -0.30042762 -2.03259     0.00961658 -0.48537827 -2.0541375\n",
      "  0.18208544 -0.4446069  -1.3609595  -0.15150814 -0.31212234 -1.1698174\n",
      " -0.06488454 -0.28568152 -1.2562087  -0.03044236 -0.29614982 -1.3704946\n",
      "  0.07648835 -0.30627674 -1.1807768 ]\n",
      "data: [ 0.02196462 -0.10750688 -0.2001517   0.05891377 -0.21016389 -0.4876279\n",
      " -0.06946833 -0.43459263 -1.3409092  -0.22157387 -0.49802777 -1.6389079\n",
      " -0.36903954 -0.5993389  -2.150459   -0.16811745 -0.73729795 -1.5277973\n",
      "  0.02860849 -0.800633   -1.3777139  -0.03167365 -0.7317887  -1.4268277\n",
      " -0.04015756 -0.8989055  -1.5549066  -0.11723518 -0.6519225  -1.4201655\n",
      " -0.05126228 -0.7091822  -1.4006687  -0.0593684  -0.67527235 -1.4866774\n",
      "  0.07094985 -0.7203642  -1.5044243  -0.02415771 -0.53836    -1.2492917\n",
      " -0.18526445 -0.30042762 -2.03259     0.00961658 -0.48537827 -2.0541375\n",
      "  0.18208544 -0.4446069  -1.3609595  -0.15150814 -0.31212234 -1.1698174\n",
      " -0.06488454 -0.28568152 -1.2562087  -0.03044236 -0.29614982 -1.3704945\n",
      "  0.07648835 -0.30627674 -1.1807768   0.14      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[-0.0174, -0.0707, -0.1800,  ...,  0.0470, -0.2599, -1.1807],\n",
      "        [-0.0174, -0.0707, -0.1800,  ...,  0.0470, -0.2599, -1.1807],\n",
      "        [-0.0174, -0.0707, -0.1800,  ...,  0.0470, -0.2599, -1.1807],\n",
      "        ...,\n",
      "        [-0.1285,  0.3190, -0.0127,  ..., -0.6724,  0.8439, -0.3405],\n",
      "        [-0.1039, -0.0675,  0.5708,  ..., -0.2200,  0.6337,  0.2167],\n",
      "        [-0.1039, -0.0675,  0.5708,  ..., -0.2200,  0.6337,  0.2167]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01738298 -0.07068688 -0.18001726  0.00997797 -0.19773917 -0.5068219\n",
      " -0.08457222 -0.40487918 -1.3121611  -0.2345083  -0.46479127 -1.6246824\n",
      " -0.41087726 -0.59168136 -2.1021366  -0.2277962  -0.68646145 -1.4949126\n",
      "  0.02835561 -0.73002446 -1.2872285  -0.03046602 -0.67371285 -1.3303776\n",
      " -0.03405957 -0.81656575 -1.4577973  -0.16946508 -0.5810826  -1.3880618\n",
      " -0.07722964 -0.6475121  -1.3717637  -0.0681501  -0.619959   -1.4698539\n",
      "  0.06595103 -0.66572976 -1.5178413  -0.06099596 -0.48231024 -1.2038423\n",
      " -0.20941085 -0.24658713 -1.9505427  -0.01313177 -0.43124357 -1.9502238\n",
      "  0.16185942 -0.3872945  -1.3550609  -0.18993509 -0.24166879 -1.1340882\n",
      " -0.08402763 -0.22170246 -1.2151088  -0.03291407 -0.25099444 -1.3331661\n",
      "  0.04696316 -0.25987768 -1.1807243 ]\n",
      "data: [-0.01738298 -0.07068688 -0.18001726  0.00997797 -0.19773917 -0.5068219\n",
      " -0.08457222 -0.40487918 -1.3121611  -0.2345083  -0.46479127 -1.6246824\n",
      " -0.41087726 -0.59168136 -2.1021366  -0.2277962  -0.6864615  -1.4949126\n",
      "  0.02835561 -0.7300245  -1.2872283  -0.03046602 -0.67371285 -1.3303775\n",
      " -0.03405957 -0.81656575 -1.4577973  -0.16946508 -0.5810826  -1.3880619\n",
      " -0.07722964 -0.6475121  -1.3717637  -0.0681501  -0.619959   -1.4698539\n",
      "  0.06595103 -0.66572976 -1.5178413  -0.06099596 -0.4823102  -1.2038423\n",
      " -0.20941085 -0.24658713 -1.9505428  -0.01313177 -0.43124354 -1.9502238\n",
      "  0.16185942 -0.3872945  -1.3550609  -0.18993509 -0.24166879 -1.1340882\n",
      " -0.08402763 -0.22170246 -1.2151088  -0.03291407 -0.25099444 -1.3331662\n",
      "  0.04696316 -0.25987768 -1.1807243   0.15      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FF28>\n",
      "tensor([[-0.0294, -0.0585, -0.2561,  ..., -0.0165, -0.2226, -1.2956],\n",
      "        [-0.0294, -0.0585, -0.2561,  ..., -0.0165, -0.2226, -1.2956],\n",
      "        [-0.0294, -0.0585, -0.2561,  ..., -0.0165, -0.2226, -1.2956],\n",
      "        ...,\n",
      "        [-0.1867,  0.3754, -0.0860,  ..., -0.6953,  0.8866, -0.3945],\n",
      "        [-0.0909, -0.0796,  0.6451,  ..., -0.1942,  0.6883,  0.2504],\n",
      "        [-0.0909, -0.0796,  0.6451,  ..., -0.1942,  0.6883,  0.2504]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.02942339 -0.05851199 -0.25613755 -0.00293386 -0.18086953 -0.6257148\n",
      " -0.11008658 -0.384264   -1.4254098  -0.25885904 -0.44430116 -1.7319013\n",
      " -0.42489704 -0.5486962  -2.2229888  -0.23894912 -0.6740234  -1.5900537\n",
      " -0.02613577 -0.71416885 -1.3980272  -0.07816748 -0.6518375  -1.4517076\n",
      " -0.08928872 -0.79907376 -1.5815668  -0.19502814 -0.5746202  -1.4903814\n",
      " -0.12134207 -0.6279523  -1.4703873  -0.12634471 -0.5946407  -1.5709118\n",
      "  0.01283352 -0.62825185 -1.6141744  -0.10662896 -0.46969625 -1.3169208\n",
      " -0.24754962 -0.23623428 -2.0306742  -0.06958606 -0.39851263 -2.0442085\n",
      "  0.10093769 -0.36114055 -1.4626015  -0.22380322 -0.2336064  -1.2439167\n",
      " -0.14617819 -0.20444179 -1.3294038  -0.10488859 -0.21434967 -1.4505628\n",
      " -0.01650789 -0.22260843 -1.2956134 ]\n",
      "data: [-0.02942339 -0.05851199 -0.25613755 -0.00293386 -0.18086953 -0.6257148\n",
      " -0.11008658 -0.384264   -1.4254098  -0.25885904 -0.44430116 -1.7319013\n",
      " -0.42489704 -0.5486962  -2.2229888  -0.23894912 -0.6740234  -1.5900537\n",
      " -0.02613577 -0.71416885 -1.3980272  -0.07816748 -0.6518375  -1.4517076\n",
      " -0.08928872 -0.7990738  -1.5815668  -0.19502813 -0.5746202  -1.4903814\n",
      " -0.12134207 -0.6279523  -1.4703872  -0.12634471 -0.5946407  -1.5709118\n",
      "  0.01283352 -0.62825185 -1.6141744  -0.10662896 -0.46969622 -1.3169208\n",
      " -0.24754962 -0.23623428 -2.0306742  -0.06958606 -0.39851266 -2.0442085\n",
      "  0.10093769 -0.36114055 -1.4626014  -0.22380322 -0.2336064  -1.2439167\n",
      " -0.14617819 -0.2044418  -1.3294036  -0.10488859 -0.21434967 -1.450563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.01650789 -0.22260843 -1.2956134   0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[ 0.0449, -0.0638, -0.1822,  ...,  0.0326, -0.2522, -1.2240],\n",
      "        [ 0.0449, -0.0638, -0.1822,  ...,  0.0326, -0.2522, -1.2240],\n",
      "        [ 0.0449, -0.0638, -0.1822,  ...,  0.0326, -0.2522, -1.2240],\n",
      "        ...,\n",
      "        [-0.4283,  0.1272, -0.4285,  ..., -0.9319,  0.5326, -0.5907],\n",
      "        [-0.1339, -0.1094,  0.5698,  ..., -0.2039,  0.6495,  0.2870],\n",
      "        [-0.1339, -0.1094,  0.5698,  ..., -0.2039,  0.6495,  0.2870]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04488851 -0.06375446 -0.18215117  0.05527742 -0.19230963 -0.5832061\n",
      " -0.06098487 -0.3768145  -1.3326105  -0.20929474 -0.44102618 -1.6184021\n",
      " -0.37899673 -0.5296615  -2.1077352  -0.15166295 -0.6859376  -1.4762589\n",
      " -0.00368777 -0.72560537 -1.328981   -0.04978207 -0.649938   -1.3928956\n",
      " -0.0493612  -0.8012313  -1.5037017  -0.11901276 -0.59240276 -1.3991326\n",
      " -0.06243594 -0.63479006 -1.3652725  -0.0915537  -0.60902363 -1.4609815\n",
      "  0.04655309 -0.61411506 -1.4882457  -0.05123544 -0.5029135  -1.2451984\n",
      " -0.1631194  -0.28123188 -1.884267   -0.02508973 -0.4181239  -1.9014267\n",
      "  0.12840326 -0.39613277 -1.361805   -0.13953008 -0.27441087 -1.1809915\n",
      " -0.09615248 -0.251477   -1.2711673  -0.06586297 -0.23931676 -1.388767\n",
      "  0.03262962 -0.25216877 -1.2239504 ]\n",
      "data: [ 0.04488851 -0.06375446 -0.18215117  0.05527742 -0.19230963 -0.5832061\n",
      " -0.06098487 -0.37681448 -1.3326105  -0.20929474 -0.44102618 -1.6184021\n",
      " -0.37899673 -0.5296615  -2.1077352  -0.15166295 -0.6859376  -1.4762589\n",
      " -0.00368777 -0.72560537 -1.328981   -0.04978207 -0.649938   -1.3928955\n",
      " -0.0493612  -0.8012313  -1.5037017  -0.11901276 -0.59240276 -1.3991325\n",
      " -0.06243594 -0.63479006 -1.3652725  -0.09155371 -0.60902363 -1.4609815\n",
      "  0.04655309 -0.61411506 -1.4882457  -0.05123545 -0.5029135  -1.2451984\n",
      " -0.1631194  -0.28123188 -1.884267   -0.02508973 -0.4181239  -1.9014267\n",
      "  0.12840326 -0.39613277 -1.361805   -0.13953008 -0.27441087 -1.1809915\n",
      " -0.09615248 -0.251477   -1.2711673  -0.06586297 -0.23931676 -1.3887669\n",
      "  0.03262962 -0.25216877 -1.2239504   0.17      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FA58>\n",
      "tensor([[-0.0147, -0.0399, -0.2009,  ...,  0.0104, -0.2475, -1.1818],\n",
      "        [-0.0147, -0.0399, -0.2009,  ...,  0.0104, -0.2475, -1.1818],\n",
      "        [-0.0147, -0.0399, -0.2009,  ...,  0.0104, -0.2475, -1.1818],\n",
      "        ...,\n",
      "        [-0.2731,  0.2822, -0.1979,  ..., -0.8437,  0.7694, -0.4451],\n",
      "        [-0.1241, -0.0781,  0.5691,  ..., -0.2441,  0.7079,  0.2290],\n",
      "        [-0.1241, -0.0781,  0.5691,  ..., -0.2441,  0.7079,  0.2290]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01468043 -0.03994243 -0.20087151  0.01651802 -0.13222301 -0.5151653\n",
      " -0.15067913 -0.35898247 -1.3706665  -0.3023232  -0.43038324 -1.6430578\n",
      " -0.4424686  -0.4989596  -2.1600275  -0.18821758 -0.6827426  -1.5202235\n",
      " -0.07109059 -0.7560701  -1.3883553  -0.11398026 -0.66857994 -1.4480468\n",
      " -0.12385739 -0.85266066 -1.5685134  -0.15374081 -0.60997486 -1.4269744\n",
      " -0.11624099 -0.65585417 -1.3875543  -0.14400041 -0.6205798  -1.463772\n",
      "  0.00869764 -0.63991356 -1.468853   -0.09131496 -0.50387347 -1.2762176\n",
      " -0.24056652 -0.26615787 -2.041606   -0.06479672 -0.42921126 -2.0802178\n",
      "  0.11183268 -0.39898938 -1.3458047  -0.19571911 -0.28355476 -1.1904899\n",
      " -0.15545443 -0.24935898 -1.2851318  -0.12526536 -0.22980618 -1.3985293\n",
      "  0.01035555 -0.24754305 -1.1818293 ]\n",
      "data: [-0.01468043 -0.03994243 -0.20087151  0.01651802 -0.13222301 -0.5151653\n",
      " -0.15067913 -0.35898247 -1.3706665  -0.3023232  -0.43038324 -1.6430578\n",
      " -0.4424686  -0.49895963 -2.1600275  -0.18821758 -0.6827426  -1.5202235\n",
      " -0.07109059 -0.7560701  -1.3883553  -0.11398026 -0.66857994 -1.4480469\n",
      " -0.12385739 -0.85266066 -1.5685134  -0.15374081 -0.60997486 -1.4269745\n",
      " -0.11624099 -0.65585417 -1.3875543  -0.14400041 -0.6205798  -1.4637722\n",
      "  0.00869764 -0.63991356 -1.468853   -0.09131496 -0.50387347 -1.2762176\n",
      " -0.24056652 -0.26615787 -2.041606   -0.06479672 -0.42921126 -2.0802178\n",
      "  0.11183268 -0.39898938 -1.3458047  -0.19571911 -0.28355476 -1.1904899\n",
      " -0.15545443 -0.24935898 -1.2851318  -0.12526536 -0.22980617 -1.3985294\n",
      "  0.01035555 -0.24754305 -1.1818293   0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[-0.0128,  0.0170, -0.2028,  ...,  0.0043, -0.1524, -1.2759],\n",
      "        [-0.0128,  0.0170, -0.2028,  ...,  0.0043, -0.1524, -1.2759],\n",
      "        [-0.0128,  0.0170, -0.2028,  ...,  0.0043, -0.1524, -1.2759],\n",
      "        ...,\n",
      "        [-0.2461,  0.2061, -0.1054,  ..., -0.8080,  0.7046, -0.3650],\n",
      "        [-0.2041, -0.2139,  0.5309,  ..., -0.3344,  0.5134,  0.2616],\n",
      "        [-0.2041, -0.2139,  0.5309,  ..., -0.3344,  0.5134,  0.2616]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-1.28494091e-02  1.70329046e-02 -2.02845231e-01 -1.58371404e-03\n",
      " -1.34092718e-01 -6.49278164e-01 -7.11460486e-02 -3.04924011e-01\n",
      " -1.35934174e+00 -2.15329304e-01 -3.61425042e-01 -1.66638196e+00\n",
      " -4.06155556e-01 -4.85077024e-01 -2.11680055e+00 -2.30345637e-01\n",
      " -5.82253218e-01 -1.51137459e+00  1.48954988e-02 -6.00909472e-01\n",
      " -1.29944599e+00 -3.09942961e-02 -5.44003069e-01 -1.34941638e+00\n",
      " -2.65007019e-02 -6.65155828e-01 -1.46563649e+00 -1.84587881e-01\n",
      " -4.66501415e-01 -1.42644107e+00 -8.59926194e-02 -5.25319636e-01\n",
      " -1.40231073e+00 -8.27361792e-02 -5.01032710e-01 -1.50750971e+00\n",
      "  5.71960062e-02 -5.25905073e-01 -1.57305622e+00 -8.82986858e-02\n",
      " -3.86425912e-01 -1.25057006e+00 -1.96733385e-01 -1.58980563e-01\n",
      " -1.87116992e+00 -3.86345908e-02 -3.12088847e-01 -1.86058295e+00\n",
      "  1.23388052e-01 -2.77869344e-01 -1.42155826e+00 -1.96446478e-01\n",
      " -1.39041036e-01 -1.18959022e+00 -1.10148594e-01 -1.18247151e-01\n",
      " -1.27197921e+00 -5.59413433e-02 -1.41752094e-01 -1.39426899e+00\n",
      "  4.32602316e-03 -1.52362436e-01 -1.27589071e+00]\n",
      "data: [-1.28494091e-02  1.70329046e-02 -2.02845231e-01 -1.58371404e-03\n",
      " -1.34092718e-01 -6.49278164e-01 -7.11460486e-02 -3.04924011e-01\n",
      " -1.35934174e+00 -2.15329304e-01 -3.61425042e-01 -1.66638196e+00\n",
      " -4.06155556e-01 -4.85077024e-01 -2.11680055e+00 -2.30345637e-01\n",
      " -5.82253218e-01 -1.51137471e+00  1.48954988e-02 -6.00909472e-01\n",
      " -1.29944599e+00 -3.09942961e-02 -5.44003069e-01 -1.34941638e+00\n",
      " -2.65007019e-02 -6.65155768e-01 -1.46563649e+00 -1.84587881e-01\n",
      " -4.66501415e-01 -1.42644107e+00 -8.59926194e-02 -5.25319636e-01\n",
      " -1.40231085e+00 -8.27361792e-02 -5.01032710e-01 -1.50750971e+00\n",
      "  5.71960062e-02 -5.25905073e-01 -1.57305622e+00 -8.82986858e-02\n",
      " -3.86425883e-01 -1.25057006e+00 -1.96733385e-01 -1.58980563e-01\n",
      " -1.87116992e+00 -3.86345908e-02 -3.12088847e-01 -1.86058283e+00\n",
      "  1.23388052e-01 -2.77869344e-01 -1.42155826e+00 -1.96446478e-01\n",
      " -1.39041036e-01 -1.18959022e+00 -1.10148594e-01 -1.18247144e-01\n",
      " -1.27197921e+00 -5.59413433e-02 -1.41752094e-01 -1.39426899e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4.32602316e-03 -1.52362436e-01 -1.27589071e+00  1.89999998e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0356, -0.1437, -0.2385,  ...,  0.0725, -0.3206, -1.3492],\n",
      "        [ 0.0356, -0.1437, -0.2385,  ...,  0.0725, -0.3206, -1.3492],\n",
      "        [ 0.0356, -0.1437, -0.2385,  ...,  0.0725, -0.3206, -1.3492],\n",
      "        ...,\n",
      "        [-0.3355,  0.3865, -0.4010,  ..., -0.8996,  0.8564, -0.5135],\n",
      "        [-0.2014, -0.1088,  0.5540,  ..., -0.2816,  0.6462,  0.2670],\n",
      "        [-0.2014, -0.1088,  0.5540,  ..., -0.2816,  0.6462,  0.2670]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03563064 -0.14373541 -0.23847345  0.0474264  -0.3108539  -0.7136316\n",
      "  0.00867407 -0.4568517  -1.3876653  -0.12401839 -0.51100004 -1.6906998\n",
      " -0.29909503 -0.6502576  -2.146566   -0.18141392 -0.723657   -1.5455358\n",
      "  0.09295275 -0.7210425  -1.3124661   0.03732642 -0.66531754 -1.3640411\n",
      "  0.03255896 -0.75994134 -1.4758368  -0.1363863  -0.60736775 -1.475981\n",
      " -0.01984906 -0.65952253 -1.4634123  -0.02697849 -0.62918854 -1.5622101\n",
      "  0.08343694 -0.65181553 -1.6300802  -0.02682653 -0.5401614  -1.3041499\n",
      " -0.10075656 -0.3176099  -1.8158813   0.02457352 -0.4570189  -1.7892785\n",
      "  0.15602818 -0.42209718 -1.4953282  -0.12278336 -0.3001662  -1.2552469\n",
      " -0.0174017  -0.2851457  -1.3336082   0.03538885 -0.31502077 -1.4524477\n",
      "  0.07250905 -0.32057077 -1.3491585 ]\n",
      "data: [ 0.03563064 -0.14373541 -0.23847346  0.0474264  -0.3108539  -0.7136316\n",
      "  0.00867407 -0.4568517  -1.3876653  -0.12401839 -0.51100004 -1.6906998\n",
      " -0.29909503 -0.6502576  -2.146566   -0.18141392 -0.723657   -1.5455357\n",
      "  0.09295275 -0.72104245 -1.3124661   0.03732642 -0.66531754 -1.3640411\n",
      "  0.03255896 -0.75994134 -1.4758368  -0.1363863  -0.60736775 -1.475981\n",
      " -0.01984906 -0.65952253 -1.4634123  -0.02697849 -0.62918854 -1.5622101\n",
      "  0.08343694 -0.6518156  -1.6300802  -0.02682653 -0.5401614  -1.30415\n",
      " -0.10075656 -0.3176099  -1.8158813   0.02457352 -0.45701894 -1.7892785\n",
      "  0.15602818 -0.42209718 -1.4953282  -0.12278336 -0.3001662  -1.2552469\n",
      " -0.0174017  -0.2851457  -1.3336082   0.03538885 -0.31502077 -1.4524477\n",
      "  0.07250905 -0.32057077 -1.3491585   0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.198 3.198 3.197 ... 3.209 3.209 3.205]\n",
      " [3.187 3.187 3.187 ... 3.184 3.184 3.19 ]\n",
      " [3.169 3.169 3.169 ... 3.167 3.167 3.162]\n",
      " ...\n",
      " [2.802 2.802 2.806 ... 2.791 2.791 2.8  ]\n",
      " [2.789 2.789 2.788 ... 2.783 2.783 2.788]\n",
      " [2.779 2.779 2.777 ... 2.778 2.778 2.782]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0534, -0.1822, -0.2548,  ...,  0.0675, -0.3562, -1.3312],\n",
      "        [ 0.0534, -0.1822, -0.2548,  ...,  0.0675, -0.3562, -1.3312],\n",
      "        [ 0.0534, -0.1822, -0.2548,  ...,  0.0675, -0.3562, -1.3312],\n",
      "        ...,\n",
      "        [-0.1045,  0.5252, -0.1602,  ..., -0.6263,  1.0236, -0.5049],\n",
      "        [-0.1943, -0.0615,  0.6411,  ..., -0.2628,  0.6835,  0.2669],\n",
      "        [-0.1943, -0.0615,  0.6411,  ..., -0.2628,  0.6835,  0.2669]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 5.3352732e-02 -1.8224874e-01 -2.5484672e-01  8.2711115e-02\n",
      " -3.1759256e-01 -6.4467120e-01 -8.0762804e-04 -5.2436829e-01\n",
      " -1.4402292e+00 -1.4838850e-01 -5.8751893e-01 -1.7495164e+00\n",
      " -3.1422698e-01 -7.0417875e-01 -2.2412505e+00 -1.5659600e-01\n",
      " -7.9388201e-01 -1.6365192e+00  8.9842118e-02 -8.3791053e-01\n",
      " -1.4238133e+00  2.9923223e-02 -7.8320301e-01 -1.4661958e+00\n",
      "  8.4325597e-03 -9.2184758e-01 -1.5890737e+00 -1.0694704e-01\n",
      " -6.8643510e-01 -1.5349815e+00 -2.1460906e-02 -7.5198215e-01\n",
      " -1.5088803e+00 -2.9780939e-02 -7.2460079e-01 -1.6044853e+00\n",
      "  8.3012022e-02 -7.6805604e-01 -1.6513741e+00 -7.2336644e-03\n",
      " -5.8315599e-01 -1.3613770e+00 -1.4975086e-01 -3.5507947e-01\n",
      " -2.0509453e+00  1.9727863e-02 -5.3071421e-01 -2.0507774e+00\n",
      "  1.6755873e-01 -4.8591220e-01 -1.5004377e+00 -1.3254350e-01\n",
      " -3.4328431e-01 -1.2885712e+00 -3.7286378e-02 -3.1924212e-01\n",
      " -1.3598524e+00  7.2373822e-03 -3.4972861e-01 -1.4735067e+00\n",
      "  6.7519262e-02 -3.5620058e-01 -1.3311603e+00]\n",
      "data: [-4.06 -1.74  1.69 -3.84 -1.67  1.69 -3.74 -1.47  2.15 -3.81 -1.25  2.66\n",
      " -3.88 -1.    2.83 -3.9  -0.97  2.13 -4.05 -0.75  3.07 -4.   -0.79  3.07\n",
      " -3.93 -0.86  2.79 -4.08 -0.95  2.27  0.    0.    0.   -4.07 -0.8   2.85\n",
      " -3.95 -0.93  2.46  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      " -3.99 -0.94  2.16  0.    0.    0.   -5.13 -1.15  5.56 -5.03 -1.17  5.43\n",
      "  0.    0.    0.    0.  ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.1246, -0.1674, -0.4082,  ..., -0.2131, -0.5120, -0.7893],\n",
      "        [ 0.1246, -0.1674, -0.4082,  ..., -0.2131, -0.5120, -0.7893],\n",
      "        [ 0.1246, -0.1674, -0.4082,  ..., -0.2131, -0.5120, -0.7893],\n",
      "        ...,\n",
      "        [ 0.0729, -0.0423,  0.5140,  ..., -0.3009,  0.4032,  0.9369],\n",
      "        [ 0.0637, -0.0097,  0.8974,  ..., -0.7454,  0.2927,  2.5236],\n",
      "        [ 0.0637, -0.0097,  0.8974,  ..., -0.7454,  0.2927,  2.5236]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.12457618 -0.16744567 -0.40818998 -0.03858797 -0.26423645 -0.8977829\n",
      " -0.25700724 -0.46851498 -1.0062759  -0.37010467 -0.60207415 -0.96980506\n",
      " -0.4486248  -0.6772622  -0.9189416  -0.22000834 -0.52316356 -1.1180179\n",
      " -0.3639927  -0.6830907  -0.9627583  -0.42474508 -0.78803134 -0.92770994\n",
      " -0.5241852  -0.88506305 -0.9248816  -0.18845847 -0.49121976 -1.1224666\n",
      " -0.37158838 -0.6695696  -1.0258155  -0.43081594 -0.7407836  -0.9657111\n",
      " -0.42061836 -0.8518667  -0.9117202  -0.1893698  -0.43843046 -1.1166737\n",
      " -0.35496038 -0.54681    -1.0281308  -0.35795826 -0.6553829  -1.0399141\n",
      " -0.33592942 -0.71092105 -0.85933745 -0.18180025 -0.36325467 -0.9928709\n",
      " -0.27468237 -0.42119578 -0.9605049  -0.2721507  -0.46199983 -0.947366\n",
      " -0.21307313 -0.5119543  -0.7892921 ]\n",
      "init: [ 0.12457618 -0.16744567 -0.40818998 -0.03858797 -0.26423645 -0.8977829\n",
      " -0.25700724 -0.46851498 -1.0062759  -0.37010467 -0.60207415 -0.96980506\n",
      " -0.4486248  -0.6772622  -0.9189416  -0.22000834 -0.52316356 -1.1180179\n",
      " -0.3639927  -0.6830907  -0.9627583  -0.42474508 -0.78803134 -0.92770994\n",
      " -0.5241852  -0.88506305 -0.9248816  -0.18845847 -0.49121976 -1.1224666\n",
      " -0.37158838 -0.6695696  -1.0258155  -0.43081594 -0.7407836  -0.9657111\n",
      " -0.42061836 -0.8518667  -0.9117202  -0.1893698  -0.43843046 -1.1166737\n",
      " -0.35496038 -0.54681    -1.0281308  -0.35795826 -0.6553829  -1.0399141\n",
      " -0.33592942 -0.71092105 -0.85933745 -0.18180025 -0.36325467 -0.9928709\n",
      " -0.27468237 -0.42119578 -0.9605049  -0.2721507  -0.46199983 -0.947366\n",
      " -0.21307313 -0.5119543  -0.7892921 ]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [ 0.12457618 -0.16744567 -0.40818995 -0.03858797 -0.26423645 -0.8977829\n",
      " -0.25700724 -0.46851498 -1.0062759  -0.37010467 -0.60207415 -0.96980506\n",
      " -0.4486248  -0.6772622  -0.9189417  -0.22000833 -0.52316356 -1.1180179\n",
      " -0.3639927  -0.6830907  -0.9627583  -0.4247451  -0.78803134 -0.92770994\n",
      " -0.5241852  -0.885063   -0.9248816  -0.18845849 -0.49121976 -1.1224666\n",
      " -0.37158835 -0.6695696  -1.0258155  -0.43081594 -0.7407835  -0.9657111\n",
      " -0.42061836 -0.8518668  -0.9117202  -0.1893698  -0.43843043 -1.1166737\n",
      " -0.35496035 -0.54681    -1.0281308  -0.35795826 -0.6553829  -1.0399141\n",
      " -0.33592942 -0.71092105 -0.85933745 -0.18180025 -0.36325467 -0.9928709\n",
      " -0.27468237 -0.4211958  -0.9605049  -0.2721507  -0.4619998  -0.947366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.21307313 -0.5119543  -0.7892921   0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.1532,  0.0680,  0.0706,  ...,  0.4898, -0.1340, -0.9593],\n",
      "        [ 0.1532,  0.0680,  0.0706,  ...,  0.4898, -0.1340, -0.9593],\n",
      "        [ 0.1532,  0.0680,  0.0706,  ...,  0.4898, -0.1340, -0.9593],\n",
      "        ...,\n",
      "        [-0.0217,  0.2819, -0.2402,  ..., -0.4023,  1.0496, -0.3862],\n",
      "        [-0.2173,  0.1031,  0.1539,  ..., -0.8286,  0.3192,  0.0961],\n",
      "        [-0.2173,  0.1031,  0.1539,  ..., -0.8286,  0.3192,  0.0961]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.15316097  0.06802428  0.07064845  0.22508655 -0.01648793 -0.3755719\n",
      "  0.16633722 -0.13540909 -1.0532936   0.0871969  -0.14391983 -1.3311495\n",
      " -0.03011671 -0.25229356 -1.7438483  -0.04658887 -0.35818148 -1.2945629\n",
      "  0.19940059 -0.3665173  -1.2263399   0.18293346 -0.31787762 -1.2805471\n",
      "  0.21069123 -0.4232187  -1.3704323   0.03266825 -0.33629665 -1.2098519\n",
      "  0.19252655 -0.43357208 -1.2212728   0.22905365 -0.39202568 -1.3531381\n",
      "  0.36902994 -0.42032906 -1.3949333   0.14762771 -0.2778049  -1.0186365\n",
      "  0.13437928 -0.15432015 -1.594706    0.36747277 -0.28855234 -1.6023711\n",
      "  0.5274465  -0.23682109 -1.2343383   0.12784396 -0.15780035 -0.9476877\n",
      "  0.25640562 -0.15456003 -0.9819543   0.3827138  -0.18830419 -1.1082095\n",
      "  0.48980796 -0.13400735 -0.959276  ]\n",
      "data: [ 0.15316097  0.06802428  0.07064845  0.22508655 -0.01648793 -0.3755719\n",
      "  0.16633722 -0.13540909 -1.0532936   0.0871969  -0.14391983 -1.3311495\n",
      " -0.03011671 -0.25229356 -1.7438483  -0.04658887 -0.35818145 -1.2945629\n",
      "  0.1994006  -0.3665173  -1.2263399   0.18293346 -0.31787762 -1.2805471\n",
      "  0.21069123 -0.4232187  -1.3704323   0.03266825 -0.33629665 -1.2098519\n",
      "  0.19252655 -0.43357208 -1.2212728   0.22905365 -0.39202568 -1.3531381\n",
      "  0.3690299  -0.42032906 -1.3949333   0.14762771 -0.2778049  -1.0186365\n",
      "  0.13437928 -0.15432015 -1.594706    0.36747277 -0.28855234 -1.6023711\n",
      "  0.5274465  -0.23682109 -1.2343383   0.12784396 -0.15780035 -0.9476877\n",
      "  0.25640562 -0.15456003 -0.9819543   0.38271376 -0.18830417 -1.1082095\n",
      "  0.48980796 -0.13400735 -0.959276    0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B320>\n",
      "tensor([[ 0.2056, -0.1267, -0.3259,  ...,  0.1925, -0.2884, -1.3641],\n",
      "        [ 0.2056, -0.1267, -0.3259,  ...,  0.1925, -0.2884, -1.3641],\n",
      "        [ 0.2056, -0.1267, -0.3259,  ...,  0.1925, -0.2884, -1.3641],\n",
      "        ...,\n",
      "        [-0.3916,  0.1969,  0.2953,  ..., -0.9736,  0.7130, -0.2067],\n",
      "        [-0.3175,  0.1933,  0.2928,  ..., -0.2262,  1.1085, -0.2226],\n",
      "        [-0.3175,  0.1933,  0.2928,  ..., -0.2262,  1.1085, -0.2226]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.20561634 -0.1267463  -0.32585594  0.2174306  -0.29196414 -0.8640643\n",
      "  0.16297212 -0.44861245 -1.5089755   0.04601528 -0.5035804  -1.7919288\n",
      " -0.10937119 -0.62345135 -2.2263222  -0.0108389  -0.672598   -1.6416419\n",
      "  0.20968299 -0.66971076 -1.4177299   0.16928053 -0.6140163  -1.4762328\n",
      "  0.14235824 -0.7239872  -1.5809705   0.0167242  -0.55179787 -1.5737438\n",
      "  0.10109666 -0.6068677  -1.5486948   0.07341595 -0.5906353  -1.6188443\n",
      "  0.17975903 -0.60495985 -1.6890752   0.11001495 -0.4905601  -1.4134407\n",
      "  0.00998858 -0.266061   -1.9667847   0.13410315 -0.42029783 -1.9407182\n",
      "  0.23736748 -0.38140914 -1.5241768   0.03700453 -0.26859224 -1.349016\n",
      "  0.10807209 -0.24036752 -1.380413    0.16103485 -0.26211652 -1.4931586\n",
      "  0.19248202 -0.28842133 -1.3640926 ]\n",
      "data: [ 0.20561634 -0.1267463  -0.32585594  0.2174306  -0.29196414 -0.8640643\n",
      "  0.16297212 -0.44861245 -1.5089755   0.04601528 -0.5035804  -1.7919288\n",
      " -0.10937119 -0.62345135 -2.2263222  -0.0108389  -0.67259806 -1.6416419\n",
      "  0.20968299 -0.66971076 -1.4177299   0.16928053 -0.6140163  -1.4762328\n",
      "  0.14235824 -0.7239872  -1.5809704   0.0167242  -0.55179787 -1.5737439\n",
      "  0.10109666 -0.6068677  -1.548695    0.07341595 -0.5906353  -1.6188443\n",
      "  0.17975903 -0.60495985 -1.6890751   0.11001495 -0.4905601  -1.4134407\n",
      "  0.00998858 -0.266061   -1.9667847   0.13410315 -0.4202978  -1.9407182\n",
      "  0.23736748 -0.38140914 -1.5241768   0.03700453 -0.26859224 -1.349016\n",
      "  0.10807209 -0.2403675  -1.380413    0.16103485 -0.26211652 -1.4931586\n",
      "  0.19248204 -0.28842133 -1.3640926   0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0017, -0.1971, -0.2630,  ..., -0.0209, -0.3546, -1.4456],\n",
      "        [-0.0017, -0.1971, -0.2630,  ..., -0.0209, -0.3546, -1.4456],\n",
      "        [-0.0017, -0.1971, -0.2630,  ..., -0.0209, -0.3546, -1.4456],\n",
      "        ...,\n",
      "        [-0.0029,  0.4784,  0.0122,  ..., -0.7864,  1.0794, -0.3011],\n",
      "        [-0.0361,  0.1139,  0.6523,  ...,  0.0948,  0.8362,  0.2858],\n",
      "        [-0.0361,  0.1139,  0.6523,  ...,  0.0948,  0.8362,  0.2858]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-1.7246110e-03 -1.9712248e-01 -2.6298231e-01  1.9614477e-02\n",
      " -3.5371822e-01 -8.3105367e-01  2.5909752e-02 -4.6811524e-01\n",
      " -1.4809704e+00 -1.0398390e-01 -5.0527024e-01 -1.8011189e+00\n",
      " -2.4295920e-01 -6.3246417e-01 -2.3042903e+00 -2.0322642e-01\n",
      " -7.5025862e-01 -1.6589222e+00  9.5673449e-02 -7.2661740e-01\n",
      " -1.4341509e+00  2.1869756e-02 -6.6313446e-01 -1.4969081e+00\n",
      " -9.4125494e-03 -7.4039263e-01 -1.6185430e+00 -1.7636704e-01\n",
      " -6.5061867e-01 -1.5881770e+00 -4.4311792e-02 -6.8783802e-01\n",
      " -1.5862927e+00 -8.3471671e-02 -6.3670933e-01 -1.6890047e+00\n",
      " -1.5191250e-02 -6.6696435e-01 -1.7336075e+00 -5.9651271e-02\n",
      " -5.6754589e-01 -1.4209409e+00 -1.2270992e-01 -3.4040478e-01\n",
      " -1.8638315e+00 -3.5214640e-02 -4.6840444e-01 -1.8377913e+00\n",
      "  6.4072721e-02 -4.3893600e-01 -1.6106384e+00 -1.6648406e-01\n",
      " -3.4157771e-01 -1.3573372e+00 -4.5446254e-02 -3.2154405e-01\n",
      " -1.4173621e+00 -2.6029833e-02 -3.5852969e-01 -1.5289501e+00\n",
      " -2.0923488e-02 -3.5458577e-01 -1.4456378e+00]\n",
      "data: [-1.7246110e-03 -1.9712248e-01 -2.6298231e-01  1.9614477e-02\n",
      " -3.5371822e-01 -8.3105367e-01  2.5909754e-02 -4.6811524e-01\n",
      " -1.4809705e+00 -1.0398390e-01 -5.0527024e-01 -1.8011187e+00\n",
      " -2.4295920e-01 -6.3246417e-01 -2.3042903e+00 -2.0322642e-01\n",
      " -7.5025862e-01 -1.6589221e+00  9.5673449e-02 -7.2661746e-01\n",
      " -1.4341511e+00  2.1869756e-02 -6.6313446e-01 -1.4969081e+00\n",
      " -9.4125494e-03 -7.4039263e-01 -1.6185431e+00 -1.7636703e-01\n",
      " -6.5061867e-01 -1.5881771e+00 -4.4311792e-02 -6.8783796e-01\n",
      " -1.5862927e+00 -8.3471671e-02 -6.3670933e-01 -1.6890047e+00\n",
      " -1.5191250e-02 -6.6696435e-01 -1.7336075e+00 -5.9651271e-02\n",
      " -5.6754589e-01 -1.4209409e+00 -1.2270992e-01 -3.4040478e-01\n",
      " -1.8638315e+00 -3.5214640e-02 -4.6840441e-01 -1.8377913e+00\n",
      "  6.4072721e-02 -4.3893600e-01 -1.6106384e+00 -1.6648406e-01\n",
      " -3.4157771e-01 -1.3573372e+00 -4.5446254e-02 -3.2154405e-01\n",
      " -1.4173621e+00 -2.6029833e-02 -3.5852969e-01 -1.5289501e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -2.0923488e-02 -3.5458577e-01 -1.4456378e+00  3.9999999e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0710, -0.2007, -0.1987,  ...,  0.0262, -0.3684, -1.2477],\n",
      "        [ 0.0710, -0.2007, -0.1987,  ...,  0.0262, -0.3684, -1.2477],\n",
      "        [ 0.0710, -0.2007, -0.1987,  ...,  0.0262, -0.3684, -1.2477],\n",
      "        ...,\n",
      "        [ 0.0502,  0.4812, -0.1278,  ..., -0.5159,  1.0352, -0.4933],\n",
      "        [-0.1600, -0.0911,  0.5778,  ..., -0.1713,  0.6182,  0.2783],\n",
      "        [-0.1600, -0.0911,  0.5778,  ..., -0.1713,  0.6182,  0.2783]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.07098235 -0.20065702 -0.19874617  0.09717244 -0.31589222 -0.56715417\n",
      " -0.01812366 -0.53394693 -1.3816117  -0.16754174 -0.5916972  -1.6755621\n",
      " -0.31774265 -0.67863667 -2.1851315  -0.12927838 -0.82510114 -1.565721\n",
      "  0.03296457 -0.88305426 -1.4370985  -0.02397667 -0.8127452  -1.4920232\n",
      " -0.0329383  -0.9755902  -1.6110126  -0.09496044 -0.7306825  -1.4681133\n",
      " -0.04722203 -0.77855384 -1.4384309  -0.06975378 -0.7522621  -1.5267024\n",
      "  0.0435946  -0.7786615  -1.5420667  -0.02071778 -0.6135831  -1.3145807\n",
      " -0.18059455 -0.3890217  -2.0467937  -0.01577534 -0.5551464  -2.0702076\n",
      "  0.12891479 -0.5147743  -1.4106504  -0.13790555 -0.38999838 -1.2370071\n",
      " -0.08241728 -0.3604529  -1.3166584  -0.06152359 -0.36217588 -1.427211\n",
      "  0.02624584 -0.3684134  -1.2477365 ]\n",
      "data: [ 0.07098235 -0.20065702 -0.19874616  0.09717244 -0.31589222 -0.56715417\n",
      " -0.01812366 -0.53394693 -1.3816116  -0.16754173 -0.5916972  -1.6755621\n",
      " -0.31774265 -0.6786367  -2.1851315  -0.12927838 -0.82510114 -1.565721\n",
      "  0.03296457 -0.88305426 -1.4370985  -0.02397667 -0.8127452  -1.4920231\n",
      " -0.0329383  -0.9755902  -1.6110126  -0.09496043 -0.73068255 -1.4681133\n",
      " -0.04722203 -0.77855384 -1.4384309  -0.06975378 -0.7522621  -1.5267024\n",
      "  0.0435946  -0.7786615  -1.5420667  -0.02071778 -0.6135831  -1.3145807\n",
      " -0.18059453 -0.3890217  -2.0467937  -0.01577534 -0.5551464  -2.0702076\n",
      "  0.12891479 -0.5147743  -1.4106504  -0.13790555 -0.38999835 -1.2370071\n",
      " -0.08241728 -0.3604529  -1.3166584  -0.06152359 -0.36217585 -1.427211\n",
      "  0.02624584 -0.3684134  -1.2477365   0.05      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[-2.8816e-04, -7.8245e-02, -2.0835e-01,  ...,  6.0636e-02,\n",
      "         -2.7091e-01, -1.1902e+00],\n",
      "        [-2.8816e-04, -7.8245e-02, -2.0835e-01,  ...,  6.0636e-02,\n",
      "         -2.7091e-01, -1.1902e+00],\n",
      "        [-2.8816e-04, -7.8245e-02, -2.0835e-01,  ...,  6.0636e-02,\n",
      "         -2.7091e-01, -1.1902e+00],\n",
      "        ...,\n",
      "        [-7.8939e-02,  4.9025e-01,  6.1110e-03,  ..., -6.7190e-01,\n",
      "          1.0987e+00, -4.1289e-01],\n",
      "        [-6.0985e-02,  1.7164e-02,  6.4313e-01,  ..., -1.3693e-01,\n",
      "          6.8168e-01,  2.8827e-01],\n",
      "        [-6.0985e-02,  1.7164e-02,  6.4313e-01,  ..., -1.3693e-01,\n",
      "          6.8168e-01,  2.8827e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-2.8816145e-04 -7.8244701e-02 -2.0834839e-01  3.0296627e-02\n",
      " -1.9350792e-01 -5.0990105e-01 -8.1127964e-02 -4.1298035e-01\n",
      " -1.3400736e+00 -2.3486842e-01 -4.7469005e-01 -1.6471393e+00\n",
      " -3.9693016e-01 -5.8988875e-01 -2.1377954e+00 -2.0558679e-01\n",
      " -6.9965720e-01 -1.5316067e+00  2.2740990e-02 -7.5558406e-01\n",
      " -1.3570969e+00 -3.6030054e-02 -6.9239295e-01 -1.4008436e+00\n",
      " -3.7185788e-02 -8.4726453e-01 -1.5271595e+00 -1.4832230e-01\n",
      " -6.0273618e-01 -1.4215450e+00 -6.7461282e-02 -6.6823024e-01\n",
      " -1.3971338e+00 -6.5330841e-02 -6.3919079e-01 -1.4907584e+00\n",
      "  6.8612710e-02 -6.8503481e-01 -1.5238259e+00 -4.3523349e-02\n",
      " -4.9506301e-01 -1.2424030e+00 -1.9775018e-01 -2.6225379e-01\n",
      " -1.9922521e+00 -4.7521591e-03 -4.4825235e-01 -2.0014691e+00\n",
      "  1.7396051e-01 -4.0547144e-01 -1.3687036e+00 -1.7376582e-01\n",
      " -2.5972247e-01 -1.1679802e+00 -7.4447781e-02 -2.3710234e-01\n",
      " -1.2470529e+00 -3.0209109e-02 -2.6218182e-01 -1.3609467e+00\n",
      "  6.0636140e-02 -2.7091247e-01 -1.1901610e+00]\n",
      "data: [-2.8816145e-04 -7.8244701e-02 -2.0834839e-01  3.0296629e-02\n",
      " -1.9350792e-01 -5.0990105e-01 -8.1127971e-02 -4.1298035e-01\n",
      " -1.3400736e+00 -2.3486844e-01 -4.7469005e-01 -1.6471393e+00\n",
      " -3.9693016e-01 -5.8988875e-01 -2.1377954e+00 -2.0558679e-01\n",
      " -6.9965720e-01 -1.5316068e+00  2.2740988e-02 -7.5558400e-01\n",
      " -1.3570969e+00 -3.6030054e-02 -6.9239295e-01 -1.4008436e+00\n",
      " -3.7185788e-02 -8.4726453e-01 -1.5271595e+00 -1.4832230e-01\n",
      " -6.0273618e-01 -1.4215451e+00 -6.7461282e-02 -6.6823024e-01\n",
      " -1.3971338e+00 -6.5330841e-02 -6.3919079e-01 -1.4907584e+00\n",
      "  6.8612710e-02 -6.8503481e-01 -1.5238259e+00 -4.3523349e-02\n",
      " -4.9506301e-01 -1.2424030e+00 -1.9775018e-01 -2.6225379e-01\n",
      " -1.9922520e+00 -4.7521591e-03 -4.4825232e-01 -2.0014691e+00\n",
      "  1.7396051e-01 -4.0547144e-01 -1.3687036e+00 -1.7376584e-01\n",
      " -2.5972247e-01 -1.1679802e+00 -7.4447781e-02 -2.3710233e-01\n",
      " -1.2470529e+00 -3.0209109e-02 -2.6218182e-01 -1.3609467e+00\n",
      "  6.0636140e-02 -2.7091247e-01 -1.1901610e+00  5.9999999e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE3F7CB2E8>\n",
      "tensor([[ 0.0069, -0.0731, -0.2552,  ...,  0.0254, -0.2466, -1.2884],\n",
      "        [ 0.0069, -0.0731, -0.2552,  ...,  0.0254, -0.2466, -1.2884],\n",
      "        [ 0.0069, -0.0731, -0.2552,  ...,  0.0254, -0.2466, -1.2884],\n",
      "        ...,\n",
      "        [-0.1737,  0.3378, -0.0388,  ..., -0.7255,  0.8349, -0.3068],\n",
      "        [-0.1025, -0.0603,  0.6335,  ..., -0.1993,  0.6942,  0.2810],\n",
      "        [-0.1025, -0.0603,  0.6335,  ..., -0.1993,  0.6942,  0.2810]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00693184 -0.07312375 -0.25519192  0.0338409  -0.19775279 -0.6240763\n",
      " -0.07516725 -0.40196913 -1.4216702  -0.22493798 -0.46414962 -1.7243755\n",
      " -0.39245376 -0.57036173 -2.2140884  -0.19919994 -0.69261205 -1.5850296\n",
      "  0.01198927 -0.73576653 -1.390243   -0.04302116 -0.67291    -1.4428637\n",
      " -0.05747928 -0.82091653 -1.5698214  -0.15455776 -0.59413487 -1.4877648\n",
      " -0.08173444 -0.6488105  -1.464942   -0.0902743  -0.6161322  -1.5607762\n",
      "  0.04353598 -0.64984107 -1.5984306  -0.06584588 -0.49046147 -1.3156085\n",
      " -0.20755064 -0.25699514 -2.0335405  -0.03050487 -0.42245418 -2.0454123\n",
      "  0.13481227 -0.38442314 -1.451431   -0.18179697 -0.25561345 -1.2436991\n",
      " -0.10413255 -0.22832805 -1.3298655  -0.06392586 -0.23782161 -1.449646\n",
      "  0.02536982 -0.2466418  -1.288353  ]\n",
      "data: [ 0.00693184 -0.07312375 -0.25519192  0.0338409  -0.19775277 -0.6240763\n",
      " -0.07516725 -0.40196913 -1.4216702  -0.22493798 -0.46414962 -1.7243755\n",
      " -0.39245376 -0.57036173 -2.2140884  -0.19919994 -0.69261205 -1.5850296\n",
      "  0.01198927 -0.73576653 -1.390243   -0.04302116 -0.67291    -1.4428638\n",
      " -0.05747928 -0.82091653 -1.5698214  -0.15455776 -0.59413487 -1.4877648\n",
      " -0.08173444 -0.6488105  -1.464942   -0.0902743  -0.6161322  -1.5607762\n",
      "  0.04353598 -0.64984107 -1.5984306  -0.06584588 -0.49046147 -1.3156085\n",
      " -0.20755064 -0.25699514 -2.0335405  -0.03050487 -0.42245418 -2.0454123\n",
      "  0.13481227 -0.38442314 -1.4514309  -0.18179697 -0.25561345 -1.2436991\n",
      " -0.10413255 -0.22832805 -1.3298655  -0.06392586 -0.23782162 -1.449646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.02536982 -0.24664181 -1.288353    0.07      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0206, -0.0512, -0.2339,  ...,  0.0447, -0.2390, -1.2835],\n",
      "        [ 0.0206, -0.0512, -0.2339,  ...,  0.0447, -0.2390, -1.2835],\n",
      "        [ 0.0206, -0.0512, -0.2339,  ...,  0.0447, -0.2390, -1.2835],\n",
      "        ...,\n",
      "        [-0.2038,  0.3420, -0.1343,  ..., -0.8412,  0.8290, -0.3407],\n",
      "        [-0.1423, -0.1444,  0.5655,  ..., -0.2168,  0.5954,  0.2655],\n",
      "        [-0.1423, -0.1444,  0.5655,  ..., -0.2168,  0.5954,  0.2655]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02061682 -0.05123156 -0.2338967   0.03339513 -0.187438   -0.62721217\n",
      " -0.056782   -0.36866647 -1.3688675  -0.2046199  -0.42889202 -1.670072\n",
      " -0.38000596 -0.5414489  -2.149585   -0.18556695 -0.6631499  -1.5349848\n",
      "  0.02186118 -0.69586146 -1.3647192  -0.03099135 -0.6303347  -1.4198515\n",
      " -0.02769423 -0.76896405 -1.5347166  -0.14012454 -0.5610841  -1.4495957\n",
      " -0.05892262 -0.6135132  -1.4271408  -0.07052164 -0.58820176 -1.5279993\n",
      "  0.06057656 -0.6097616  -1.569523   -0.04942181 -0.47281015 -1.2822802\n",
      " -0.16263036 -0.24802113 -1.92189    -0.0104873  -0.4002017  -1.924466\n",
      "  0.14657031 -0.37060046 -1.4311826  -0.15300661 -0.23748977 -1.2210665\n",
      " -0.07543932 -0.21867007 -1.307975   -0.035134   -0.22965056 -1.4262615\n",
      "  0.04472884 -0.23896663 -1.2834977 ]\n",
      "data: [ 0.02061682 -0.05123157 -0.23389669  0.03339513 -0.187438   -0.62721217\n",
      " -0.056782   -0.36866647 -1.3688675  -0.2046199  -0.42889202 -1.6700721\n",
      " -0.38000596 -0.5414489  -2.149585   -0.18556695 -0.6631499  -1.534985\n",
      "  0.02186118 -0.69586146 -1.364719   -0.03099134 -0.6303347  -1.4198515\n",
      " -0.02769423 -0.76896405 -1.5347166  -0.14012454 -0.5610841  -1.4495957\n",
      " -0.05892262 -0.6135132  -1.4271408  -0.07052164 -0.58820176 -1.5279993\n",
      "  0.06057656 -0.6097616  -1.569523   -0.04942181 -0.47281015 -1.2822803\n",
      " -0.16263036 -0.24802113 -1.9218899  -0.0104873  -0.4002017  -1.9244659\n",
      "  0.14657031 -0.37060046 -1.4311825  -0.15300661 -0.23748977 -1.2210665\n",
      " -0.07543932 -0.21867007 -1.307975   -0.035134   -0.22965056 -1.4262615\n",
      "  0.04472884 -0.23896664 -1.2834976   0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0176, -0.0769, -0.2618,  ...,  0.0341, -0.2650, -1.3035],\n",
      "        [ 0.0176, -0.0769, -0.2618,  ...,  0.0341, -0.2650, -1.3035],\n",
      "        [ 0.0176, -0.0769, -0.2618,  ...,  0.0341, -0.2650, -1.3035],\n",
      "        ...,\n",
      "        [-0.1501,  0.3906, -0.0677,  ..., -0.6999,  0.8816, -0.3236],\n",
      "        [-0.1567, -0.1302,  0.5797,  ..., -0.2528,  0.6573,  0.2347],\n",
      "        [-0.1567, -0.1302,  0.5797,  ..., -0.2528,  0.6573,  0.2347]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01764074 -0.07691947 -0.26175305  0.03876178 -0.20488122 -0.6636975\n",
      " -0.07300584 -0.3972026  -1.4355066  -0.21798725 -0.46263903 -1.7243217\n",
      " -0.37824482 -0.5602844  -2.2124414  -0.17699905 -0.69306684 -1.5894244\n",
      "  0.0029342  -0.73378795 -1.4094226  -0.04433124 -0.66284573 -1.4692048\n",
      " -0.04998554 -0.8098095  -1.5873946  -0.13935092 -0.59773874 -1.5051744\n",
      " -0.07331599 -0.6468817  -1.4728477  -0.09336017 -0.6199497  -1.562979\n",
      "  0.04406197 -0.63671285 -1.5957992  -0.06293736 -0.50733477 -1.3405836\n",
      " -0.18091556 -0.27896047 -1.9994549  -0.02913272 -0.4291771  -2.0115287\n",
      "  0.13114294 -0.40127456 -1.457605   -0.16043958 -0.275987   -1.2706504\n",
      " -0.09918444 -0.25028774 -1.3551548  -0.0597197  -0.25014114 -1.4710006\n",
      "  0.03407051 -0.2649547  -1.3034732 ]\n",
      "data: [ 0.01764074 -0.07691947 -0.26175305  0.03876178 -0.20488124 -0.6636975\n",
      " -0.07300584 -0.3972026  -1.4355066  -0.21798725 -0.46263903 -1.7243217\n",
      " -0.37824482 -0.5602844  -2.2124414  -0.17699905 -0.69306684 -1.5894245\n",
      "  0.0029342  -0.7337879  -1.4094226  -0.04433124 -0.6628458  -1.4692047\n",
      " -0.04998554 -0.8098095  -1.5873946  -0.13935092 -0.59773874 -1.5051744\n",
      " -0.07331599 -0.6468817  -1.4728477  -0.09336016 -0.6199497  -1.562979\n",
      "  0.04406197 -0.63671285 -1.5957992  -0.06293736 -0.50733477 -1.3405834\n",
      " -0.18091556 -0.27896047 -1.9994549  -0.02913272 -0.4291771  -2.0115287\n",
      "  0.13114294 -0.40127456 -1.457605   -0.16043958 -0.275987   -1.2706504\n",
      " -0.09918444 -0.25028774 -1.3551548  -0.0597197  -0.25014114 -1.4710006\n",
      "  0.03407051 -0.2649547  -1.3034732   0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0396, -0.0307, -0.2197,  ...,  0.0438, -0.2261, -1.2483],\n",
      "        [ 0.0396, -0.0307, -0.2197,  ...,  0.0438, -0.2261, -1.2483],\n",
      "        [ 0.0396, -0.0307, -0.2197,  ...,  0.0438, -0.2261, -1.2483],\n",
      "        ...,\n",
      "        [-0.1333,  0.4074, -0.1154,  ..., -0.7357,  0.9094, -0.3662],\n",
      "        [-0.1395, -0.1856,  0.5567,  ..., -0.2131,  0.5807,  0.2373],\n",
      "        [-0.1395, -0.1856,  0.5567,  ..., -0.2131,  0.5807,  0.2373]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 3.9554793e-02 -3.0700687e-02 -2.1971285e-01  5.5047784e-02\n",
      " -1.5267843e-01 -6.0419416e-01 -6.6313073e-02 -3.4291872e-01\n",
      " -1.3684505e+00 -2.1562465e-01 -4.0728951e-01 -1.6555097e+00\n",
      " -3.7987083e-01 -4.9485171e-01 -2.1505108e+00 -1.5052521e-01\n",
      " -6.5516782e-01 -1.5224102e+00  3.3263862e-04 -6.9911450e-01\n",
      " -1.3703965e+00 -4.5102298e-02 -6.2231553e-01 -1.4353728e+00\n",
      " -4.4252962e-02 -7.7892083e-01 -1.5502266e+00 -1.1620939e-01\n",
      " -5.6465787e-01 -1.4413657e+00 -5.9980638e-02 -6.0843539e-01\n",
      " -1.4074320e+00 -8.6334616e-02 -5.8355516e-01 -1.5012065e+00\n",
      "  5.5836231e-02 -5.9162343e-01 -1.5247008e+00 -4.7283642e-02\n",
      " -4.7201356e-01 -1.2833179e+00 -1.6484386e-01 -2.4814522e-01\n",
      " -1.9480189e+00 -1.8292896e-02 -3.9176285e-01 -1.9676088e+00\n",
      "  1.4380154e-01 -3.6878663e-01 -1.3934249e+00 -1.3908082e-01\n",
      " -2.4530245e-01 -1.2162215e+00 -9.2661977e-02 -2.2120884e-01\n",
      " -1.3050120e+00 -6.1696097e-02 -2.1058507e-01 -1.4218773e+00\n",
      "  4.3757498e-02 -2.2612001e-01 -1.2483425e+00]\n",
      "data: [ 3.95547934e-02 -3.07006892e-02 -2.19712853e-01  5.50477840e-02\n",
      " -1.52678430e-01 -6.04194164e-01 -6.63130730e-02 -3.42918754e-01\n",
      " -1.36845052e+00 -2.15624630e-01 -4.07289505e-01 -1.65550959e+00\n",
      " -3.79870832e-01 -4.94851708e-01 -2.15051079e+00 -1.50525212e-01\n",
      " -6.55167818e-01 -1.52241015e+00  3.32638621e-04 -6.99114561e-01\n",
      " -1.37039638e+00 -4.51023020e-02 -6.22315526e-01 -1.43537283e+00\n",
      " -4.42529619e-02 -7.78920829e-01 -1.55022657e+00 -1.16209395e-01\n",
      " -5.64657867e-01 -1.44136572e+00 -5.99806421e-02 -6.08435392e-01\n",
      " -1.40743196e+00 -8.63346159e-02 -5.83555162e-01 -1.50120652e+00\n",
      "  5.58362305e-02 -5.91623425e-01 -1.52470076e+00 -4.72836383e-02\n",
      " -4.72013563e-01 -1.28331792e+00 -1.64843857e-01 -2.48145223e-01\n",
      " -1.94801891e+00 -1.82928964e-02 -3.91762853e-01 -1.96760881e+00\n",
      "  1.43801540e-01 -3.68786633e-01 -1.39342487e+00 -1.39080822e-01\n",
      " -2.45302454e-01 -1.21622145e+00 -9.26619694e-02 -2.21208841e-01\n",
      " -1.30501211e+00 -6.16960973e-02 -2.10585073e-01 -1.42187726e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4.37574945e-02 -2.26120010e-01 -1.24834251e+00  1.00000001e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0259, -0.0757, -0.2354,  ...,  0.0412, -0.2612, -1.2841],\n",
      "        [ 0.0259, -0.0757, -0.2354,  ...,  0.0412, -0.2612, -1.2841],\n",
      "        [ 0.0259, -0.0757, -0.2354,  ...,  0.0412, -0.2612, -1.2841],\n",
      "        ...,\n",
      "        [-0.2950,  0.1945, -0.2660,  ..., -0.8057,  0.6007, -0.4010],\n",
      "        [-0.0940, -0.0552,  0.5778,  ..., -0.1920,  0.7291,  0.2698],\n",
      "        [-0.0940, -0.0552,  0.5778,  ..., -0.1920,  0.7291,  0.2698]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02586486 -0.07570703 -0.23542497  0.04845307 -0.21181838 -0.6395237\n",
      " -0.05732866 -0.399418   -1.4057759  -0.20256127 -0.46625668 -1.6921952\n",
      " -0.36817378 -0.56997395 -2.1777635  -0.17191945 -0.686086   -1.5622929\n",
      "  0.01599388 -0.7236451  -1.3800709  -0.03293823 -0.655286   -1.4359087\n",
      " -0.03993655 -0.794979   -1.5489324  -0.13330491 -0.58692604 -1.4814683\n",
      " -0.06160935 -0.639482   -1.4469689  -0.08370976 -0.6131764  -1.5369128\n",
      "  0.04802267 -0.6302095  -1.5731308  -0.05478662 -0.50235695 -1.3158859\n",
      " -0.16756791 -0.2741602  -1.9558747  -0.02078802 -0.4249742  -1.9617965\n",
      "  0.1308217  -0.3973992  -1.4347656  -0.1508456  -0.26833647 -1.2501667\n",
      " -0.08644167 -0.24522679 -1.33011    -0.04372957 -0.24855451 -1.4457091\n",
      "  0.04117716 -0.26120114 -1.284127  ]\n",
      "data: [ 0.02586486 -0.07570703 -0.23542495  0.04845307 -0.2118184  -0.6395237\n",
      " -0.05732866 -0.399418   -1.4057759  -0.20256129 -0.46625668 -1.6921952\n",
      " -0.36817378 -0.56997395 -2.1777635  -0.17191944 -0.68608594 -1.5622929\n",
      "  0.01599388 -0.7236451  -1.3800709  -0.03293823 -0.655286   -1.4359087\n",
      " -0.03993655 -0.7949789  -1.5489326  -0.13330491 -0.58692604 -1.4814683\n",
      " -0.06160935 -0.639482   -1.4469688  -0.08370976 -0.6131764  -1.5369128\n",
      "  0.04802267 -0.6302095  -1.5731308  -0.05478662 -0.50235695 -1.3158859\n",
      " -0.16756791 -0.2741602  -1.9558747  -0.02078802 -0.4249742  -1.9617965\n",
      "  0.1308217  -0.3973992  -1.4347656  -0.1508456  -0.26833647 -1.2501667\n",
      " -0.08644167 -0.24522679 -1.3301101  -0.04372957 -0.24855451 -1.4457091\n",
      "  0.04117716 -0.26120114 -1.284127    0.11      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0319, -0.0778, -0.2540,  ...,  0.0584, -0.2681, -1.2743],\n",
      "        [ 0.0319, -0.0778, -0.2540,  ...,  0.0584, -0.2681, -1.2743],\n",
      "        [ 0.0319, -0.0778, -0.2540,  ...,  0.0584, -0.2681, -1.2743],\n",
      "        ...,\n",
      "        [-0.1098,  0.3836, -0.0908,  ..., -0.6954,  0.8916, -0.3789],\n",
      "        [-0.1307, -0.1360,  0.5851,  ..., -0.2291,  0.6374,  0.2297],\n",
      "        [-0.1307, -0.1360,  0.5851,  ..., -0.2291,  0.6374,  0.2297]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03191924 -0.07780524 -0.25396112  0.05700387 -0.19805448 -0.6315129\n",
      " -0.05666979 -0.39691186 -1.4126797  -0.20228262 -0.46038187 -1.7045873\n",
      " -0.35861275 -0.5591865  -2.1938665  -0.16021326 -0.69655836 -1.5696398\n",
      "  0.02202997 -0.7423494  -1.4043906  -0.02936265 -0.67215    -1.4624634\n",
      " -0.03552668 -0.82575035 -1.5827873  -0.11905046 -0.60524076 -1.4797041\n",
      " -0.05385678 -0.65574974 -1.4521623  -0.07158168 -0.6271442  -1.5414187\n",
      "  0.06197867 -0.65180165 -1.5693429  -0.03849702 -0.5073671  -1.3144873\n",
      " -0.16834621 -0.2774065  -2.0104496  -0.00496545 -0.43648487 -2.025482\n",
      "  0.15642548 -0.40552056 -1.4321457  -0.14286269 -0.27919483 -1.2430071\n",
      " -0.07543036 -0.25306463 -1.3304828  -0.03856866 -0.25503945 -1.4465874\n",
      "  0.05841889 -0.26813373 -1.2742743 ]\n",
      "data: [ 0.03191924 -0.07780524 -0.25396112  0.05700387 -0.19805449 -0.6315129\n",
      " -0.05666979 -0.39691186 -1.4126798  -0.20228262 -0.46038187 -1.7045875\n",
      " -0.35861275 -0.5591865  -2.1938665  -0.16021326 -0.69655836 -1.5696397\n",
      "  0.02202997 -0.7423494  -1.4043906  -0.02936265 -0.67215    -1.4624634\n",
      " -0.03552668 -0.82575035 -1.5827873  -0.11905046 -0.60524076 -1.4797041\n",
      " -0.05385678 -0.65574974 -1.4521623  -0.07158168 -0.6271442  -1.5414186\n",
      "  0.06197867 -0.6518017  -1.5693429  -0.03849702 -0.5073671  -1.3144873\n",
      " -0.16834621 -0.2774065  -2.0104496  -0.00496545 -0.43648487 -2.025482\n",
      "  0.15642548 -0.40552056 -1.4321457  -0.14286269 -0.27919483 -1.2430071\n",
      " -0.07543036 -0.25306463 -1.3304828  -0.03856866 -0.25503945 -1.4465873\n",
      "  0.05841889 -0.26813373 -1.2742743   0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[ 0.0225, -0.0474, -0.2435,  ...,  0.0554, -0.2396, -1.2800],\n",
      "        [ 0.0225, -0.0474, -0.2435,  ...,  0.0554, -0.2396, -1.2800],\n",
      "        [ 0.0225, -0.0474, -0.2435,  ...,  0.0554, -0.2396, -1.2800],\n",
      "        ...,\n",
      "        [-0.1427,  0.3342, -0.0655,  ..., -0.7756,  0.8112, -0.2965],\n",
      "        [-0.1368, -0.1370,  0.5552,  ..., -0.2108,  0.6212,  0.2118],\n",
      "        [-0.1368, -0.1370,  0.5552,  ..., -0.2108,  0.6212,  0.2118]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0224926  -0.04740129 -0.24346773  0.03669121 -0.18455344 -0.64603984\n",
      " -0.05133313 -0.3684476  -1.3863907  -0.19623104 -0.42899567 -1.6890154\n",
      " -0.3710543  -0.5452343  -2.1587944  -0.1827237  -0.656632   -1.5474932\n",
      "  0.03370523 -0.68899536 -1.3591919  -0.01855845 -0.6261292  -1.4148376\n",
      " -0.01870918 -0.76455235 -1.5320652  -0.13641801 -0.55318755 -1.4597063\n",
      " -0.05392998 -0.609098   -1.4358296  -0.0638551  -0.5865107  -1.5341558\n",
      "  0.06759008 -0.60986096 -1.5783529  -0.04374026 -0.46587116 -1.2882142\n",
      " -0.15991578 -0.2425055  -1.9386022  -0.00391047 -0.3991366  -1.9383852\n",
      "  0.15473971 -0.36817008 -1.4317489  -0.14694616 -0.23148897 -1.2255538\n",
      " -0.06660164 -0.21305239 -1.3087866  -0.02277472 -0.2277653  -1.4261727\n",
      "  0.05539964 -0.23958132 -1.2800481 ]\n",
      "data: [ 0.0224926  -0.04740129 -0.24346773  0.03669121 -0.18455344 -0.6460398\n",
      " -0.05133313 -0.3684476  -1.3863907  -0.19623104 -0.42899567 -1.6890154\n",
      " -0.3710543  -0.5452343  -2.1587944  -0.1827237  -0.656632   -1.5474933\n",
      "  0.03370523 -0.68899536 -1.3591919  -0.01855845 -0.6261292  -1.4148376\n",
      " -0.01870918 -0.76455235 -1.5320652  -0.13641801 -0.55318755 -1.4597063\n",
      " -0.05392998 -0.609098   -1.4358296  -0.0638551  -0.5865107  -1.5341558\n",
      "  0.06759008 -0.60986096 -1.5783529  -0.04374026 -0.46587116 -1.2882142\n",
      " -0.15991578 -0.2425055  -1.9386021  -0.00391047 -0.39913663 -1.9383854\n",
      "  0.15473971 -0.36817008 -1.4317489  -0.14694616 -0.23148897 -1.2255538\n",
      " -0.06660164 -0.21305239 -1.3087866  -0.02277472 -0.2277653  -1.4261727\n",
      "  0.05539964 -0.23958132 -1.280048    0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BB38>\n",
      "tensor([[ 0.0127, -0.0782, -0.2520,  ...,  0.0358, -0.2665, -1.3050],\n",
      "        [ 0.0127, -0.0782, -0.2520,  ...,  0.0358, -0.2665, -1.3050],\n",
      "        [ 0.0127, -0.0782, -0.2520,  ...,  0.0358, -0.2665, -1.3050],\n",
      "        ...,\n",
      "        [-0.1579,  0.4060, -0.1178,  ..., -0.7136,  0.8861, -0.3556],\n",
      "        [-0.1614, -0.1326,  0.5758,  ..., -0.2471,  0.6514,  0.2271],\n",
      "        [-0.1614, -0.1326,  0.5758,  ..., -0.2471,  0.6514,  0.2271]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01266809 -0.07819182 -0.25200248  0.03189504 -0.21438259 -0.66579556\n",
      " -0.06349955 -0.3994083  -1.422724   -0.20568416 -0.46333832 -1.7166173\n",
      " -0.37147674 -0.57132816 -2.195214   -0.18593821 -0.68732107 -1.5797563\n",
      "  0.0160656  -0.7210394  -1.391171   -0.03291378 -0.655056   -1.4485366\n",
      " -0.03586134 -0.79240525 -1.5653634  -0.14528501 -0.58603203 -1.4956055\n",
      " -0.06879639 -0.6382052  -1.4675448  -0.08433041 -0.61363566 -1.5607708\n",
      "  0.04822189 -0.6323495  -1.602942   -0.06215775 -0.50121284 -1.3265829\n",
      " -0.17383558 -0.2745788  -1.9654155  -0.02484202 -0.42529842 -1.9687884\n",
      "  0.13118431 -0.39637217 -1.4591978  -0.16101333 -0.26650417 -1.2603319\n",
      " -0.08932298 -0.24445412 -1.3428454  -0.04528075 -0.25279438 -1.4585466\n",
      "  0.03577855 -0.26651782 -1.3049543 ]\n",
      "data: [ 0.01266809 -0.07819182 -0.25200248  0.03189504 -0.21438259 -0.66579556\n",
      " -0.06349955 -0.3994083  -1.422724   -0.20568414 -0.46333832 -1.7166172\n",
      " -0.37147674 -0.57132816 -2.195214   -0.18593821 -0.68732107 -1.5797563\n",
      "  0.0160656  -0.7210394  -1.391171   -0.03291378 -0.655056   -1.4485366\n",
      " -0.03586134 -0.79240525 -1.5653634  -0.14528501 -0.58603203 -1.4956055\n",
      " -0.06879639 -0.6382052  -1.4675449  -0.08433041 -0.61363566 -1.5607708\n",
      "  0.04822189 -0.6323495  -1.602942   -0.06215775 -0.50121284 -1.3265829\n",
      " -0.17383558 -0.2745788  -1.9654155  -0.02484202 -0.42529842 -1.9687885\n",
      "  0.13118431 -0.3963722  -1.4591976  -0.16101333 -0.26650417 -1.2603319\n",
      " -0.08932298 -0.24445412 -1.3428454  -0.04528075 -0.25279438 -1.4585466\n",
      "  0.03577855 -0.26651782 -1.3049542   0.14      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0245, -0.0682, -0.2512,  ...,  0.0475, -0.2573, -1.2771],\n",
      "        [ 0.0245, -0.0682, -0.2512,  ...,  0.0475, -0.2573, -1.2771],\n",
      "        [ 0.0245, -0.0682, -0.2512,  ...,  0.0475, -0.2573, -1.2771],\n",
      "        ...,\n",
      "        [-0.1208,  0.3970, -0.1408,  ..., -0.7033,  0.9076, -0.4181],\n",
      "        [-0.1378, -0.1560,  0.5788,  ..., -0.2411,  0.6107,  0.2308],\n",
      "        [-0.1378, -0.1560,  0.5788,  ..., -0.2411,  0.6107,  0.2308]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02445738 -0.06816401 -0.2511709   0.0483727  -0.19147842 -0.6343865\n",
      " -0.0567168  -0.38473248 -1.4039546  -0.20020677 -0.44620702 -1.6974615\n",
      " -0.35838974 -0.5471072  -2.1831555  -0.1682894  -0.68302464 -1.5623564\n",
      "  0.01891011 -0.72423625 -1.4011705  -0.03230137 -0.6558573  -1.458909\n",
      " -0.03509964 -0.80500543 -1.5773765  -0.12730747 -0.5892155  -1.4738201\n",
      " -0.05868091 -0.6392524  -1.448383   -0.07538804 -0.612149   -1.5396607\n",
      "  0.05546083 -0.6359205  -1.5718321  -0.0458683  -0.4938031  -1.3084327\n",
      " -0.17210081 -0.26562062 -1.9929082  -0.01212032 -0.42265573 -2.0049262\n",
      "  0.14521272 -0.39171562 -1.4335097  -0.14941554 -0.2650239  -1.2395433\n",
      " -0.08025628 -0.24036482 -1.3254249  -0.04297754 -0.24445578 -1.4417623\n",
      "  0.0475233  -0.25730687 -1.2770543 ]\n",
      "data: [ 0.02445738 -0.06816401 -0.2511709   0.0483727  -0.19147843 -0.6343865\n",
      " -0.0567168  -0.38473248 -1.4039546  -0.20020677 -0.44620702 -1.6974616\n",
      " -0.35838974 -0.5471072  -2.1831555  -0.1682894  -0.68302464 -1.5623565\n",
      "  0.01891011 -0.72423625 -1.4011705  -0.03230137 -0.6558573  -1.458909\n",
      " -0.03509964 -0.80500543 -1.5773766  -0.12730747 -0.5892155  -1.4738201\n",
      " -0.05868091 -0.6392524  -1.448383   -0.07538804 -0.612149   -1.5396607\n",
      "  0.05546083 -0.6359205  -1.5718322  -0.0458683  -0.4938031  -1.3084328\n",
      " -0.17210081 -0.26562062 -1.9929081  -0.01212032 -0.4226557  -2.0049262\n",
      "  0.14521272 -0.39171562 -1.4335097  -0.14941554 -0.2650239  -1.2395433\n",
      " -0.08025628 -0.24036482 -1.3254249  -0.04297754 -0.24445577 -1.4417624\n",
      "  0.0475233  -0.25730687 -1.2770543   0.15      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BB38>\n",
      "tensor([[ 0.0175, -0.0389, -0.2461,  ...,  0.0503, -0.2326, -1.2818],\n",
      "        [ 0.0175, -0.0389, -0.2461,  ...,  0.0503, -0.2326, -1.2818],\n",
      "        [ 0.0175, -0.0389, -0.2461,  ...,  0.0503, -0.2326, -1.2818],\n",
      "        ...,\n",
      "        [-0.1620,  0.3278, -0.0819,  ..., -0.8080,  0.8038, -0.3004],\n",
      "        [-0.1383, -0.1528,  0.5461,  ..., -0.2130,  0.6123,  0.2026],\n",
      "        [-0.1383, -0.1528,  0.5461,  ..., -0.2130,  0.6123,  0.2026]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01749822 -0.03885467 -0.24606802  0.03110893 -0.17516889 -0.64991504\n",
      " -0.06018484 -0.35796055 -1.390233   -0.20437393 -0.41902834 -1.6895933\n",
      " -0.37775636 -0.53280634 -2.1609123  -0.18625014 -0.6482671  -1.5484056\n",
      "  0.02266484 -0.6807347  -1.3644145  -0.02748345 -0.6160805  -1.4210465\n",
      " -0.02513615 -0.75522995 -1.5371966  -0.1413074  -0.54606605 -1.4626031\n",
      " -0.0606357  -0.6004028  -1.4372935  -0.07128536 -0.5778674  -1.5345352\n",
      "  0.06305721 -0.5985688  -1.5777097  -0.05161173 -0.46070948 -1.2928257\n",
      " -0.1645357  -0.2371426  -1.9373512  -0.01030147 -0.39113265 -1.9384992\n",
      "  0.14938183 -0.36190677 -1.4330587  -0.15191112 -0.22695498 -1.2298341\n",
      " -0.07515422 -0.20826907 -1.3133163  -0.03118204 -0.21994229 -1.43066\n",
      "  0.05031001 -0.23260312 -1.2818303 ]\n",
      "data: [ 0.01749822 -0.03885467 -0.24606802  0.03110893 -0.1751689  -0.649915\n",
      " -0.06018485 -0.35796055 -1.390233   -0.20437393 -0.41902837 -1.6895933\n",
      " -0.37775636 -0.53280634 -2.1609123  -0.18625014 -0.64826703 -1.5484056\n",
      "  0.02266484 -0.6807347  -1.3644146  -0.02748345 -0.6160805  -1.4210465\n",
      " -0.02513615 -0.75522995 -1.5371966  -0.1413074  -0.54606605 -1.4626031\n",
      " -0.0606357  -0.6004028  -1.4372935  -0.07128536 -0.5778674  -1.5345352\n",
      "  0.06305721 -0.5985688  -1.5777097  -0.05161173 -0.46070948 -1.2928256\n",
      " -0.1645357  -0.23714261 -1.9373512  -0.01030147 -0.39113265 -1.9384991\n",
      "  0.14938183 -0.36190677 -1.4330587  -0.15191112 -0.22695498 -1.2298341\n",
      " -0.07515422 -0.20826907 -1.3133163  -0.03118204 -0.21994229 -1.4306599\n",
      "  0.05031    -0.23260312 -1.2818303   0.16      ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0090, -0.0754, -0.2484,  ...,  0.0341, -0.2629, -1.3047],\n",
      "        [ 0.0090, -0.0754, -0.2484,  ...,  0.0341, -0.2629, -1.3047],\n",
      "        [ 0.0090, -0.0754, -0.2484,  ...,  0.0341, -0.2629, -1.3047],\n",
      "        ...,\n",
      "        [-0.1670,  0.4051, -0.1333,  ..., -0.7359,  0.8851, -0.3576],\n",
      "        [-0.1662, -0.1393,  0.5654,  ..., -0.2582,  0.6445,  0.2183],\n",
      "        [-0.1662, -0.1393,  0.5654,  ..., -0.2582,  0.6445,  0.2183]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00901554 -0.0753895  -0.24839976  0.02754251 -0.2143466  -0.6683464\n",
      " -0.06110238 -0.39471376 -1.4164444  -0.20151022 -0.4571202  -1.7118838\n",
      " -0.3690345  -0.5683577  -2.186548   -0.19094369 -0.6804039  -1.573265\n",
      "  0.01864725 -0.7097265  -1.383503   -0.02991622 -0.6455381  -1.4402881\n",
      " -0.03063198 -0.7784951  -1.5564888  -0.14983594 -0.5770702  -1.4899224\n",
      " -0.06872751 -0.62955135 -1.4638631  -0.08191585 -0.6053721  -1.5583285\n",
      "  0.05002014 -0.6245393  -1.6048709  -0.06456473 -0.4948599  -1.3195938\n",
      " -0.17277229 -0.26872897 -1.9489118  -0.02455866 -0.4187064  -1.9490732\n",
      "  0.1300878  -0.38949096 -1.4592155  -0.1632458  -0.2593761  -1.2548786\n",
      " -0.08809706 -0.23834133 -1.3359764  -0.04224917 -0.24926822 -1.4523165\n",
      "  0.0340766  -0.262859   -1.3047135 ]\n",
      "data: [ 0.00901554 -0.0753895  -0.24839978  0.02754251 -0.2143466  -0.6683464\n",
      " -0.06110238 -0.39471376 -1.4164444  -0.20151022 -0.4571202  -1.7118839\n",
      " -0.3690345  -0.5683577  -2.186548   -0.19094367 -0.6804039  -1.573265\n",
      "  0.01864725 -0.7097265  -1.383503   -0.02991622 -0.6455381  -1.4402881\n",
      " -0.03063198 -0.7784951  -1.5564888  -0.14983594 -0.5770702  -1.4899223\n",
      " -0.06872751 -0.62955135 -1.463863   -0.08191585 -0.6053721  -1.5583285\n",
      "  0.05002014 -0.6245393  -1.6048709  -0.06456473 -0.49485987 -1.3195938\n",
      " -0.17277229 -0.26872897 -1.9489118  -0.02455866 -0.4187064  -1.9490732\n",
      "  0.1300878  -0.38949096 -1.4592155  -0.1632458  -0.2593761  -1.2548786\n",
      " -0.08809706 -0.23834133 -1.3359764  -0.04224917 -0.24926823 -1.4523166\n",
      "  0.0340766  -0.262859   -1.3047135   0.17      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0146, -0.0828, -0.2502,  ...,  0.0441, -0.2700, -1.2819],\n",
      "        [ 0.0146, -0.0828, -0.2502,  ...,  0.0441, -0.2700, -1.2819],\n",
      "        [ 0.0146, -0.0828, -0.2502,  ...,  0.0441, -0.2700, -1.2819],\n",
      "        ...,\n",
      "        [-0.1289,  0.3950, -0.1601,  ..., -0.7184,  0.9027, -0.4279],\n",
      "        [-0.1426, -0.1648,  0.5690,  ..., -0.2557,  0.6055,  0.2192],\n",
      "        [-0.1426, -0.1648,  0.5690,  ..., -0.2557,  0.6055,  0.2192]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0146401  -0.08282666 -0.25022078  0.03781169 -0.2130603  -0.64322984\n",
      " -0.05811159 -0.40316033 -1.403413   -0.19915274 -0.46421802 -1.6987783\n",
      " -0.36015636 -0.5720587  -2.176453   -0.18081522 -0.69378257 -1.5621743\n",
      "  0.02158169 -0.7299849  -1.3899186  -0.02964649 -0.6650505  -1.4457308\n",
      " -0.03136892 -0.807372   -1.5639343  -0.13826248 -0.5948942  -1.4744539\n",
      " -0.06218364 -0.6470791  -1.4504218  -0.07471199 -0.6207653  -1.5419949\n",
      "  0.05478214 -0.6463783  -1.580857   -0.05214384 -0.5025066  -1.3063173\n",
      " -0.17472994 -0.27495918 -1.9788146  -0.01464602 -0.43291596 -1.9849733\n",
      "  0.14140129 -0.39992318 -1.4393436  -0.15650144 -0.2710446  -1.2390916\n",
      " -0.08036641 -0.24763659 -1.3228897  -0.03899098 -0.257116   -1.4397578\n",
      "  0.04414354 -0.27003527 -1.2818772 ]\n",
      "data: [ 0.0146401  -0.08282666 -0.25022078  0.03781169 -0.2130603  -0.64322984\n",
      " -0.05811159 -0.40316033 -1.403413   -0.19915274 -0.46421802 -1.6987783\n",
      " -0.36015636 -0.5720587  -2.176453   -0.18081522 -0.69378257 -1.5621743\n",
      "  0.02158169 -0.7299849  -1.3899186  -0.02964649 -0.6650505  -1.4457307\n",
      " -0.03136892 -0.807372   -1.5639343  -0.13826248 -0.5948942  -1.4744539\n",
      " -0.06218364 -0.6470791  -1.4504218  -0.07471199 -0.6207653  -1.5419949\n",
      "  0.05478214 -0.6463783  -1.580857   -0.05214384 -0.5025066  -1.3063173\n",
      " -0.17472994 -0.27495918 -1.9788146  -0.01464602 -0.43291596 -1.9849733\n",
      "  0.14140129 -0.39992318 -1.4393436  -0.15650144 -0.2710446  -1.2390916\n",
      " -0.08036641 -0.24763659 -1.3228897  -0.03899098 -0.257116   -1.4397578\n",
      "  0.04414354 -0.27003527 -1.2818772   0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EC24D30>\n",
      "tensor([[ 0.0163, -0.0354, -0.2438,  ...,  0.0422, -0.2306, -1.2669],\n",
      "        [ 0.0163, -0.0354, -0.2438,  ...,  0.0422, -0.2306, -1.2669],\n",
      "        [ 0.0163, -0.0354, -0.2438,  ...,  0.0422, -0.2306, -1.2669],\n",
      "        ...,\n",
      "        [-0.1648,  0.3497, -0.1159,  ..., -0.7980,  0.8360, -0.3628],\n",
      "        [-0.1343, -0.1592,  0.5594,  ..., -0.2083,  0.6042,  0.2111],\n",
      "        [-0.1343, -0.1592,  0.5594,  ..., -0.2083,  0.6042,  0.2111]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01634895 -0.03536431 -0.2437821   0.03237461 -0.16249605 -0.6285298\n",
      " -0.07464354 -0.35488054 -1.3911381  -0.22106193 -0.41725707 -1.6866217\n",
      " -0.388712   -0.5212332  -2.168163   -0.18281862 -0.6531066  -1.5481012\n",
      "  0.00531502 -0.6940441  -1.3745048  -0.0448359  -0.6250204  -1.4330745\n",
      " -0.04564257 -0.7751199  -1.5510643  -0.14034028 -0.5567144  -1.4603903\n",
      " -0.07086929 -0.6083541  -1.4326065  -0.08626992 -0.5841311  -1.5268664\n",
      "  0.05029771 -0.60412765 -1.5602789  -0.05672132 -0.4647218  -1.2947631\n",
      " -0.17954212 -0.2396546  -1.9696836  -0.02114645 -0.3951763  -1.9797914\n",
      "  0.14133663 -0.36604938 -1.4198308  -0.15743075 -0.23463982 -1.2275689\n",
      " -0.08996364 -0.21317643 -1.3139796  -0.05140688 -0.21718675 -1.4309716\n",
      "  0.04215037 -0.23055185 -1.2669382 ]\n",
      "data: [ 0.01634895 -0.03536431 -0.2437821   0.03237461 -0.16249605 -0.6285298\n",
      " -0.07464354 -0.3548805  -1.391138   -0.22106193 -0.41725707 -1.6866217\n",
      " -0.38871202 -0.5212332  -2.168163   -0.18281862 -0.6531065  -1.5481012\n",
      "  0.00531502 -0.6940441  -1.3745048  -0.0448359  -0.6250204  -1.4330745\n",
      " -0.04564257 -0.77511996 -1.5510643  -0.14034028 -0.5567144  -1.4603903\n",
      " -0.07086929 -0.6083541  -1.4326065  -0.08626992 -0.5841311  -1.5268664\n",
      "  0.05029771 -0.60412765 -1.5602789  -0.05672132 -0.4647218  -1.2947631\n",
      " -0.17954212 -0.2396546  -1.9696836  -0.02114644 -0.3951763  -1.9797914\n",
      "  0.14133663 -0.36604938 -1.4198308  -0.15743075 -0.23463982 -1.2275689\n",
      " -0.08996364 -0.21317643 -1.3139796  -0.05140688 -0.21718675 -1.4309716\n",
      "  0.04215037 -0.23055185 -1.2669382   0.19      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0096, -0.0346, -0.2194,  ...,  0.0302, -0.2247, -1.2712],\n",
      "        [ 0.0096, -0.0346, -0.2194,  ...,  0.0302, -0.2247, -1.2712],\n",
      "        [ 0.0096, -0.0346, -0.2194,  ...,  0.0302, -0.2247, -1.2712],\n",
      "        ...,\n",
      "        [-0.3681,  0.1263, -0.3718,  ..., -0.8805,  0.5080, -0.4874],\n",
      "        [-0.1253, -0.1146,  0.5544,  ..., -0.2174,  0.6677,  0.2290],\n",
      "        [-0.1253, -0.1146,  0.5544,  ..., -0.2174,  0.6677,  0.2290]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00961383 -0.03462193 -0.2193536   0.02134905 -0.18017454 -0.6474037\n",
      " -0.06555381 -0.35506684 -1.3762587  -0.20706505 -0.41763753 -1.6707585\n",
      " -0.38427204 -0.531331   -2.137722   -0.19566298 -0.6380266  -1.5277835\n",
      "  0.01272658 -0.6631999  -1.33064    -0.0329464  -0.59960306 -1.3881931\n",
      " -0.03172531 -0.72924227 -1.5011411  -0.15535349 -0.5309379  -1.4485703\n",
      " -0.07247034 -0.5845391  -1.4200126  -0.08571316 -0.5630896  -1.5165019\n",
      "  0.05025741 -0.5769147  -1.5666412  -0.06966811 -0.45419565 -1.2793493\n",
      " -0.17066228 -0.23285913 -1.8847431  -0.02834982 -0.37832367 -1.8811524\n",
      "  0.12594372 -0.35120445 -1.4195054  -0.1625875  -0.21807997 -1.2187663\n",
      " -0.09169679 -0.19994244 -1.2969224  -0.04435911 -0.21027932 -1.4140259\n",
      "  0.0301535  -0.22468571 -1.2711734 ]\n",
      "data: [ 0.00961383 -0.03462193 -0.2193536   0.02134905 -0.18017454 -0.6474037\n",
      " -0.06555381 -0.35506684 -1.3762587  -0.20706505 -0.41763753 -1.6707585\n",
      " -0.38427204 -0.531331   -2.137722   -0.19566298 -0.6380266  -1.5277835\n",
      "  0.01272658 -0.6631999  -1.33064    -0.0329464  -0.59960306 -1.388193\n",
      " -0.03172531 -0.72924227 -1.5011411  -0.15535349 -0.5309379  -1.4485703\n",
      " -0.07247034 -0.5845391  -1.4200127  -0.08571316 -0.5630896  -1.5165019\n",
      "  0.05025741 -0.5769147  -1.5666412  -0.06966811 -0.45419562 -1.2793493\n",
      " -0.17066228 -0.23285913 -1.8847431  -0.02834982 -0.37832367 -1.8811524\n",
      "  0.12594372 -0.35120445 -1.4195054  -0.1625875  -0.21807997 -1.2187663\n",
      " -0.09169678 -0.19994244 -1.2969224  -0.04435911 -0.21027932 -1.4140259\n",
      "  0.0301535  -0.22468571 -1.2711734   0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.053 3.072 3.096 ... 3.316 3.315 3.311]\n",
      " [3.055 3.075 3.098 ... 3.295 3.298 3.293]\n",
      " [3.051 3.073 3.099 ... 3.267 3.273 3.275]\n",
      " ...\n",
      " [2.746 2.737 2.731 ... 2.762 2.762 2.756]\n",
      " [2.733 2.722 2.732 ... 2.753 2.75  2.748]\n",
      " [2.722 2.716 2.728 ... 2.744 2.739 2.738]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0097, -0.0695, -0.2384,  ...,  0.0284, -0.2532, -1.2849],\n",
      "        [ 0.0097, -0.0695, -0.2384,  ...,  0.0284, -0.2532, -1.2849],\n",
      "        [ 0.0097, -0.0695, -0.2384,  ...,  0.0284, -0.2532, -1.2849],\n",
      "        ...,\n",
      "        [-0.3018,  0.2578, -0.3489,  ..., -0.8187,  0.7273, -0.5316],\n",
      "        [-0.1221, -0.0817,  0.6030,  ..., -0.2406,  0.7048,  0.2657],\n",
      "        [-0.1221, -0.0817,  0.6030,  ..., -0.2406,  0.7048,  0.2657]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00974167 -0.06951777 -0.23844057  0.03536976 -0.20366427 -0.645017\n",
      " -0.06443296 -0.3879806  -1.4062817  -0.20442767 -0.45143464 -1.6949706\n",
      " -0.36408463 -0.55377185 -2.1786885  -0.18406737 -0.6766789  -1.5615869\n",
      "  0.00983548 -0.7080239  -1.3799312  -0.03620642 -0.6419158  -1.4374008\n",
      " -0.04153369 -0.7786435  -1.5535281  -0.14717926 -0.5773326  -1.4805315\n",
      " -0.07162677 -0.6278124  -1.4514313  -0.08998322 -0.6000533  -1.5418079\n",
      "  0.04375985 -0.619385   -1.5838559  -0.06796005 -0.49131277 -1.3136439\n",
      " -0.180284   -0.26330182 -1.9576614  -0.03011636 -0.4131665  -1.9636335\n",
      "  0.12249269 -0.38364843 -1.4417596  -0.16441862 -0.25899506 -1.2474856\n",
      " -0.09737396 -0.2339989  -1.32476    -0.05391999 -0.23837045 -1.4424849\n",
      "  0.02835346 -0.2532267  -1.2848909 ]\n",
      "data: [ -3.12  -6.    -3.05  -3.31  -5.91  -3.09  -5.54 -11.71  12.72  -5.69\n",
      " -11.88  12.68  -5.71 -12.14  12.55  -3.38  -6.51  -2.85  -5.21 -12.15\n",
      "  11.5   -3.3   -6.71  -3.21  -3.1   -6.7   -3.23  -3.23  -6.4   -3.15\n",
      "  -3.45  -6.82  -2.27  -3.18  -6.42  -3.08  -5.53 -11.92  12.58  -3.15\n",
      "  -6.59  -3.13  -3.45  -6.84  -2.27  -3.1   -6.45  -3.01  -3.04  -6.41\n",
      "  -3.04  -3.16  -6.6   -3.18  -5.07 -11.84  10.86  -2.87  -6.49  -3.09\n",
      "  -3.04  -6.41  -3.04   0.  ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[-0.0959,  0.3393,  0.1782,  ..., -0.4975,  0.4853,  0.0264],\n",
      "        [-0.0959,  0.3393,  0.1782,  ..., -0.4975,  0.4853,  0.0264],\n",
      "        [-0.0959,  0.3393,  0.1782,  ..., -0.4975,  0.4853,  0.0264],\n",
      "        ...,\n",
      "        [ 0.6064, -0.5028, -0.0627,  ...,  1.4272, -1.0623,  0.9649],\n",
      "        [-0.0206,  0.0412,  0.1958,  ..., -0.3113, -0.4862,  1.0442],\n",
      "        [-0.0206,  0.0412,  0.1958,  ..., -0.3113, -0.4862,  1.0442]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.09588498  0.33933505  0.17822628 -0.13561109  0.20744446 -0.08641519\n",
      " -0.14085823  0.0897413  -0.21759875 -0.12622632  0.02765691 -0.15547378\n",
      " -0.14042312  0.05705383 -0.12595959 -0.23920351  0.17295767 -0.28438783\n",
      " -0.26574963  0.16623993 -0.03393926 -0.27575022  0.09162943  0.00237499\n",
      " -0.2922717   0.13285947 -0.01172023 -0.29630262  0.2972217  -0.29162812\n",
      " -0.39321992  0.3077833  -0.22486366 -0.40902936  0.26669273 -0.19448079\n",
      " -0.4338729   0.25281742 -0.19075878 -0.3773014   0.37603694 -0.29370433\n",
      " -0.49377903  0.37943023 -0.35852462 -0.50265443  0.37718394 -0.36518657\n",
      " -0.5267516   0.358216   -0.07618202 -0.37325045  0.5083277  -0.18435933\n",
      " -0.44931015  0.521183   -0.08992253 -0.46498612  0.52180177 -0.0595212\n",
      " -0.49754247  0.4852832   0.02640893]\n",
      "init: [-0.09588498  0.33933505  0.17822628 -0.13561109  0.20744446 -0.08641519\n",
      " -0.14085823  0.0897413  -0.21759875 -0.12622632  0.02765691 -0.15547378\n",
      " -0.14042312  0.05705383 -0.12595959 -0.23920351  0.17295767 -0.28438783\n",
      " -0.26574963  0.16623993 -0.03393926 -0.27575022  0.09162943  0.00237499\n",
      " -0.2922717   0.13285947 -0.01172023 -0.29630262  0.2972217  -0.29162812\n",
      " -0.39321992  0.3077833  -0.22486366 -0.40902936  0.26669273 -0.19448079\n",
      " -0.4338729   0.25281742 -0.19075878 -0.3773014   0.37603694 -0.29370433\n",
      " -0.49377903  0.37943023 -0.35852462 -0.50265443  0.37718394 -0.36518657\n",
      " -0.5267516   0.358216   -0.07618202 -0.37325045  0.5083277  -0.18435933\n",
      " -0.44931015  0.521183   -0.08992253 -0.46498612  0.52180177 -0.0595212\n",
      " -0.49754247  0.4852832   0.02640893]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [-0.09588498  0.33933505  0.17822628 -0.13561109  0.20744446 -0.08641519\n",
      " -0.14085823  0.0897413  -0.21759874 -0.12622632  0.02765691 -0.15547378\n",
      " -0.14042312  0.05705383 -0.12595959 -0.23920351  0.17295767 -0.28438783\n",
      " -0.26574963  0.16623993 -0.03393926 -0.27575022  0.09162943  0.00237499\n",
      " -0.2922717   0.13285947 -0.01172023 -0.29630262  0.2972217  -0.29162812\n",
      " -0.39321992  0.3077833  -0.22486366 -0.40902936  0.26669273 -0.1944808\n",
      " -0.4338729   0.25281742 -0.19075878 -0.3773014   0.37603694 -0.29370433\n",
      " -0.49377903  0.37943023 -0.35852462 -0.50265443  0.37718394 -0.36518657\n",
      " -0.5267516   0.358216   -0.07618202 -0.37325045  0.5083277  -0.18435933\n",
      " -0.44931015  0.521183   -0.08992253 -0.46498612  0.52180177 -0.0595212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.49754247  0.4852832   0.02640893  0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.1284, -0.1580,  0.3342,  ..., -0.3797, -0.2014, -0.5997],\n",
      "        [-0.1284, -0.1580,  0.3342,  ..., -0.3797, -0.2014, -0.5997],\n",
      "        [-0.1284, -0.1580,  0.3342,  ..., -0.3797, -0.2014, -0.5997],\n",
      "        ...,\n",
      "        [ 0.7673,  0.4883, -0.1009,  ...,  1.0541,  1.4822, -0.3900],\n",
      "        [ 0.2719, -0.1170, -0.2855,  ..., -0.5790,  0.5586, -0.4219],\n",
      "        [ 0.2719, -0.1170, -0.2855,  ..., -0.5790,  0.5586, -0.4219]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.12844321 -0.15796086  0.3342011  -0.2078867  -0.28025484  0.00124824\n",
      " -0.46653694 -0.4099047  -0.44003618 -0.68458277 -0.47860345 -0.58624834\n",
      " -0.90198433 -0.40902066 -0.8842688  -0.48351592 -0.6006197  -0.6016426\n",
      " -0.7501477  -0.61524045 -0.7470787  -0.7009128  -0.5122543  -0.7885756\n",
      " -0.6926131  -0.5890269  -0.7669249  -0.4554786  -0.5216597  -0.5952644\n",
      " -0.5650479  -0.50085914 -0.51414204 -0.61948323 -0.48810944 -0.60812116\n",
      " -0.46771008 -0.3434801  -0.72462004 -0.4607011  -0.48957476 -0.5454801\n",
      " -0.49706763 -0.39831397 -0.6371445  -0.5138722  -0.35845506 -0.65919906\n",
      " -0.44782197 -0.28895342 -0.6605437  -0.3665381  -0.334109   -0.55264163\n",
      " -0.54627365 -0.25440383 -0.5719088  -0.43741632 -0.20231777 -0.6495332\n",
      " -0.37968808 -0.20143455 -0.5997115 ]\n",
      "data: [-0.12844321 -0.15796086  0.3342011  -0.2078867  -0.28025484  0.00124824\n",
      " -0.46653694 -0.40990466 -0.44003618 -0.68458277 -0.47860345 -0.58624834\n",
      " -0.90198433 -0.40902066 -0.8842688  -0.48351592 -0.6006197  -0.6016426\n",
      " -0.7501477  -0.61524045 -0.7470787  -0.7009128  -0.5122543  -0.7885756\n",
      " -0.6926131  -0.5890269  -0.7669249  -0.45547858 -0.5216597  -0.5952644\n",
      " -0.5650479  -0.50085914 -0.51414204 -0.61948323 -0.48810944 -0.60812116\n",
      " -0.46771008 -0.3434801  -0.72462004 -0.4607011  -0.4895748  -0.5454801\n",
      " -0.49706763 -0.39831397 -0.6371445  -0.5138722  -0.35845506 -0.65919906\n",
      " -0.44782197 -0.28895342 -0.6605437  -0.36653814 -0.334109   -0.55264163\n",
      " -0.54627365 -0.25440383 -0.5719088  -0.43741632 -0.20231777 -0.6495332\n",
      " -0.37968808 -0.20143455 -0.5997115   0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[-0.0199, -0.0436, -0.2045,  ...,  0.1247, -0.3252, -0.8159],\n",
      "        [-0.0199, -0.0436, -0.2045,  ...,  0.1247, -0.3252, -0.8159],\n",
      "        [-0.0199, -0.0436, -0.2045,  ...,  0.1247, -0.3252, -0.8159],\n",
      "        ...,\n",
      "        [ 0.6790, -0.5045,  0.4298,  ...,  0.3237,  0.5177, -0.4708],\n",
      "        [ 0.1501,  0.1070,  0.4322,  ..., -0.7412,  0.6616, -0.0132],\n",
      "        [ 0.1501,  0.1070,  0.4322,  ..., -0.7412,  0.6616, -0.0132]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01986989 -0.04362129 -0.20454869 -0.06629926 -0.14116774 -0.34588432\n",
      " -0.4199581  -0.3756634  -1.0206356  -0.57241595 -0.47755727 -1.1566021\n",
      " -0.8247602  -0.525777   -1.5251483  -0.2568499  -0.6590239  -1.1851447\n",
      " -0.4202403  -0.7131994  -1.2636923  -0.3565696  -0.6006738  -1.2951167\n",
      " -0.24129194 -0.82738173 -1.2947142  -0.18194866 -0.5562327  -1.1604391\n",
      " -0.22490579 -0.6290668  -0.9980945  -0.22901714 -0.6223415  -1.0304666\n",
      "  0.09750497 -0.5699149  -1.122717   -0.1567775  -0.5716976  -1.0309868\n",
      " -0.25393447 -0.35971418 -1.473564   -0.08354088 -0.48553064 -1.5042855\n",
      "  0.15331978 -0.43927458 -0.9731609  -0.15916482 -0.36493284 -0.9707051\n",
      " -0.2537428  -0.32636866 -0.9806111  -0.12162629 -0.2607879  -1.1116315\n",
      "  0.12465676 -0.32523048 -0.8159044 ]\n",
      "data: [-0.01986989 -0.04362129 -0.20454869 -0.06629926 -0.14116774 -0.34588432\n",
      " -0.4199581  -0.3756634  -1.0206356  -0.57241595 -0.47755727 -1.1566021\n",
      " -0.8247602  -0.525777   -1.5251483  -0.2568499  -0.6590239  -1.1851447\n",
      " -0.4202403  -0.7131994  -1.2636923  -0.3565696  -0.6006738  -1.2951168\n",
      " -0.24129194 -0.82738173 -1.2947142  -0.18194866 -0.5562327  -1.1604391\n",
      " -0.22490579 -0.6290668  -0.9980945  -0.22901714 -0.6223415  -1.0304666\n",
      "  0.09750498 -0.5699149  -1.122717   -0.1567775  -0.5716976  -1.0309868\n",
      " -0.25393447 -0.35971415 -1.473564   -0.08354088 -0.48553067 -1.5042855\n",
      "  0.15331978 -0.4392746  -0.9731609  -0.15916482 -0.36493284 -0.9707051\n",
      " -0.2537428  -0.3263687  -0.9806111  -0.12162629 -0.2607879  -1.1116315\n",
      "  0.12465677 -0.32523048 -0.8159044   0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.1136, -0.1264, -0.1228,  ...,  0.2267, -0.3060, -1.1822],\n",
      "        [ 0.1136, -0.1264, -0.1228,  ...,  0.2267, -0.3060, -1.1822],\n",
      "        [ 0.1136, -0.1264, -0.1228,  ...,  0.2267, -0.3060, -1.1822],\n",
      "        ...,\n",
      "        [-0.0644,  0.4213,  0.1635,  ...,  0.0976,  1.2057, -0.2102],\n",
      "        [-0.2454,  0.3473,  0.1858,  ..., -0.7488,  0.9250, -0.1145],\n",
      "        [-0.2454,  0.3473,  0.1858,  ..., -0.7488,  0.9250, -0.1145]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.11355506 -0.12642398 -0.12278675  0.1548535  -0.2636586  -0.4847131\n",
      "  0.09484801 -0.41450688 -1.2540419  -0.055084   -0.46168646 -1.5720645\n",
      " -0.21322203 -0.6058042  -2.0798886  -0.10441671 -0.69093436 -1.4755361\n",
      "  0.22263673 -0.6906815  -1.2491157   0.16884261 -0.6362446  -1.2916309\n",
      "  0.17136443 -0.73485994 -1.423803   -0.04276361 -0.581641   -1.380758\n",
      "  0.09783005 -0.64833456 -1.3887737   0.11870988 -0.6079541  -1.4878051\n",
      "  0.26062512 -0.6666898  -1.5647445   0.09259276 -0.51293445 -1.1726913\n",
      " -0.01060972 -0.24755219 -1.7983954   0.173091   -0.4341615  -1.7732816\n",
      "  0.34940815 -0.39509827 -1.3817695  -0.03691729 -0.26314402 -1.1074308\n",
      "  0.1100335  -0.23777308 -1.1596063   0.1773892  -0.28781605 -1.2865962\n",
      "  0.22674507 -0.306      -1.1821921 ]\n",
      "data: [ 0.11355506 -0.12642398 -0.12278674  0.1548535  -0.2636586  -0.4847131\n",
      "  0.09484801 -0.41450688 -1.2540419  -0.055084   -0.4616865  -1.5720645\n",
      " -0.21322203 -0.6058042  -2.0798886  -0.10441671 -0.69093436 -1.475536\n",
      "  0.22263674 -0.6906815  -1.2491157   0.16884261 -0.6362446  -1.2916309\n",
      "  0.17136443 -0.73485994 -1.423803   -0.04276361 -0.581641   -1.380758\n",
      "  0.09783005 -0.64833456 -1.3887737   0.11870989 -0.6079541  -1.4878051\n",
      "  0.26062512 -0.6666898  -1.5647445   0.09259276 -0.51293445 -1.1726913\n",
      " -0.01060972 -0.24755219 -1.7983954   0.173091   -0.43416154 -1.7732816\n",
      "  0.34940815 -0.39509827 -1.3817695  -0.03691729 -0.26314402 -1.1074308\n",
      "  0.11003349 -0.23777308 -1.1596063   0.1773892  -0.28781605 -1.2865962\n",
      "  0.22674507 -0.306      -1.1821921   0.04      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0447, -0.1212, -0.1628,  ..., -0.0054, -0.2952, -1.2394],\n",
      "        [ 0.0447, -0.1212, -0.1628,  ..., -0.0054, -0.2952, -1.2394],\n",
      "        [ 0.0447, -0.1212, -0.1628,  ..., -0.0054, -0.2952, -1.2394],\n",
      "        ...,\n",
      "        [-0.1592,  0.3219, -0.0666,  ..., -0.3789,  0.7838, -0.4852],\n",
      "        [-0.1530,  0.1452,  0.4291,  ..., -0.0630,  0.9699, -0.0450],\n",
      "        [-0.1530,  0.1452,  0.4291,  ..., -0.0630,  0.9699, -0.0450]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 4.4678550e-02 -1.2118217e-01 -1.6280021e-01  5.7038736e-02\n",
      " -2.7043074e-01 -5.8852422e-01 -6.6713706e-02 -4.8921734e-01\n",
      " -1.4073153e+00 -2.2686452e-01 -5.7034731e-01 -1.7025681e+00\n",
      " -4.0841883e-01 -6.7178893e-01 -2.2128854e+00 -1.7894155e-01\n",
      " -7.4310398e-01 -1.5952668e+00 -1.2221336e-03 -8.0061126e-01\n",
      " -1.3588521e+00 -5.6725934e-02 -7.3464680e-01 -1.4135823e+00\n",
      " -9.1236919e-02 -8.8994670e-01 -1.5310123e+00 -1.4532183e-01\n",
      " -6.2961709e-01 -1.5012429e+00 -9.6895725e-02 -6.9431329e-01\n",
      " -1.4469304e+00 -1.3697894e-01 -6.8055403e-01 -1.5371566e+00\n",
      " -1.1641741e-02 -6.9310892e-01 -1.5650823e+00 -7.1714610e-02\n",
      " -5.3666115e-01 -1.3335850e+00 -2.1356770e-01 -3.1244791e-01\n",
      " -1.9965267e+00 -7.4137762e-02 -4.7594839e-01 -2.0049684e+00\n",
      "  7.2584957e-02 -4.4778070e-01 -1.3987567e+00 -1.7111711e-01\n",
      " -2.9612482e-01 -1.2537415e+00 -1.2391144e-01 -2.7424854e-01\n",
      " -1.3090658e+00 -8.9042664e-02 -2.7924812e-01 -1.4181418e+00\n",
      " -5.3810179e-03 -2.9519194e-01 -1.2394080e+00]\n",
      "data: [ 4.4678550e-02 -1.2118217e-01 -1.6280022e-01  5.7038736e-02\n",
      " -2.7043074e-01 -5.8852422e-01 -6.6713706e-02 -4.8921734e-01\n",
      " -1.4073153e+00 -2.2686452e-01 -5.7034731e-01 -1.7025681e+00\n",
      " -4.0841883e-01 -6.7178893e-01 -2.2128854e+00 -1.7894155e-01\n",
      " -7.4310392e-01 -1.5952668e+00 -1.2221336e-03 -8.0061126e-01\n",
      " -1.3588520e+00 -5.6725934e-02 -7.3464674e-01 -1.4135823e+00\n",
      " -9.1236919e-02 -8.8994670e-01 -1.5310123e+00 -1.4532183e-01\n",
      " -6.2961709e-01 -1.5012429e+00 -9.6895725e-02 -6.9431329e-01\n",
      " -1.4469304e+00 -1.3697894e-01 -6.8055403e-01 -1.5371566e+00\n",
      " -1.1641741e-02 -6.9310892e-01 -1.5650822e+00 -7.1714610e-02\n",
      " -5.3666115e-01 -1.3335850e+00 -2.1356769e-01 -3.1244791e-01\n",
      " -1.9965268e+00 -7.4137762e-02 -4.7594842e-01 -2.0049684e+00\n",
      "  7.2584957e-02 -4.4778070e-01 -1.3987567e+00 -1.7111711e-01\n",
      " -2.9612482e-01 -1.2537415e+00 -1.2391144e-01 -2.7424854e-01\n",
      " -1.3090658e+00 -8.9042664e-02 -2.7924812e-01 -1.4181418e+00\n",
      " -5.3810179e-03 -2.9519194e-01 -1.2394080e+00  5.0000001e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0206, -0.0353, -0.1457,  ...,  0.0613, -0.2384, -1.1256],\n",
      "        [ 0.0206, -0.0353, -0.1457,  ...,  0.0613, -0.2384, -1.1256],\n",
      "        [ 0.0206, -0.0353, -0.1457,  ...,  0.0613, -0.2384, -1.1256],\n",
      "        ...,\n",
      "        [-0.1993,  0.3797, -0.1035,  ..., -0.8998,  0.9326, -0.3674],\n",
      "        [-0.0932, -0.1040,  0.6362,  ..., -0.1651,  0.5868,  0.3336],\n",
      "        [-0.0932, -0.1040,  0.6362,  ..., -0.1651,  0.5868,  0.3336]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02055803 -0.03529049 -0.14569111  0.04598026 -0.13252631 -0.43591362\n",
      " -0.09971413 -0.35927004 -1.2826493  -0.2511838  -0.4245358  -1.566051\n",
      " -0.3962022  -0.5119556  -2.0749195  -0.16876072 -0.67557716 -1.4565424\n",
      " -0.00889413 -0.74407774 -1.3288758  -0.05881231 -0.6676096  -1.3790438\n",
      " -0.05236159 -0.8398059  -1.5028577  -0.1243234  -0.5947411  -1.3571082\n",
      " -0.06760375 -0.64521223 -1.3277608  -0.07238234 -0.6086842  -1.4094632\n",
      "  0.07517847 -0.6438014  -1.4202691  -0.04252692 -0.48161203 -1.2018836\n",
      " -0.19792105 -0.24775754 -1.9687017  -0.00410437 -0.42021185 -1.9994614\n",
      "  0.18098937 -0.38291878 -1.2971518  -0.1639407  -0.2567724  -1.1184815\n",
      " -0.09376325 -0.22865658 -1.2124394  -0.06282127 -0.22604738 -1.3259554\n",
      "  0.06125202 -0.23841283 -1.1255889 ]\n",
      "data: [ 0.02055803 -0.03529049 -0.14569111  0.04598026 -0.13252631 -0.43591362\n",
      " -0.09971413 -0.35927    -1.2826493  -0.2511838  -0.42453584 -1.566051\n",
      " -0.3962022  -0.5119556  -2.0749195  -0.16876072 -0.67557716 -1.4565424\n",
      " -0.00889413 -0.74407774 -1.3288758  -0.05881231 -0.6676096  -1.3790439\n",
      " -0.05236159 -0.8398059  -1.5028577  -0.1243234  -0.5947411  -1.3571084\n",
      " -0.06760375 -0.64521223 -1.3277608  -0.07238234 -0.6086842  -1.4094632\n",
      "  0.07517847 -0.64380145 -1.4202691  -0.04252692 -0.48161203 -1.2018836\n",
      " -0.19792105 -0.24775752 -1.9687018  -0.00410437 -0.42021188 -1.9994614\n",
      "  0.18098935 -0.38291878 -1.2971518  -0.1639407  -0.2567724  -1.1184815\n",
      " -0.09376325 -0.22865658 -1.2124394  -0.06282127 -0.22604738 -1.3259554\n",
      "  0.06125202 -0.23841281 -1.1255889   0.06      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[-0.0490, -0.0260, -0.2513,  ...,  0.0115, -0.2117, -1.2626],\n",
      "        [-0.0490, -0.0260, -0.2513,  ...,  0.0115, -0.2117, -1.2626],\n",
      "        [-0.0490, -0.0260, -0.2513,  ...,  0.0115, -0.2117, -1.2626],\n",
      "        ...,\n",
      "        [-0.2497,  0.2575, -0.0670,  ..., -0.7732,  0.7604, -0.3402],\n",
      "        [-0.1592, -0.0648,  0.5561,  ..., -0.3294,  0.6951,  0.2299],\n",
      "        [-0.1592, -0.0648,  0.5561,  ..., -0.3294,  0.6951,  0.2299]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.04902385 -0.02596682 -0.2513163  -0.01678148 -0.13903493 -0.60098505\n",
      " -0.13137388 -0.33697528 -1.392656   -0.27966    -0.39538318 -1.6879363\n",
      " -0.43080282 -0.50176954 -2.17834    -0.24529628 -0.6357199  -1.5624102\n",
      " -0.03995641 -0.6813828  -1.4020817  -0.09270807 -0.6093863  -1.4544728\n",
      " -0.09377302 -0.7606534  -1.5772513  -0.19542238 -0.5466492  -1.4676583\n",
      " -0.1199623  -0.60005987 -1.4508423  -0.12390662 -0.5661546  -1.5383044\n",
      "  0.01438683 -0.60119045 -1.5704824  -0.10241141 -0.4508223  -1.2954129\n",
      " -0.23721749 -0.206155   -2.013503   -0.0553723  -0.37908784 -2.0251179\n",
      "  0.11658041 -0.34122375 -1.4306601  -0.21786511 -0.22023804 -1.2227467\n",
      " -0.13194153 -0.18985972 -1.3130376  -0.08705316 -0.20001811 -1.4312073\n",
      "  0.0115219  -0.21165417 -1.2626157 ]\n",
      "data: [-0.04902385 -0.02596682 -0.2513163  -0.01678148 -0.13903493 -0.60098505\n",
      " -0.13137388 -0.33697528 -1.392656   -0.27966    -0.39538318 -1.6879363\n",
      " -0.43080285 -0.50176954 -2.17834    -0.24529628 -0.6357199  -1.5624102\n",
      " -0.03995641 -0.6813828  -1.4020817  -0.09270807 -0.6093863  -1.4544728\n",
      " -0.09377302 -0.7606534  -1.5772513  -0.19542238 -0.5466492  -1.4676583\n",
      " -0.1199623  -0.60005987 -1.4508423  -0.12390662 -0.5661546  -1.5383044\n",
      "  0.01438683 -0.60119045 -1.5704824  -0.10241141 -0.4508223  -1.2954129\n",
      " -0.23721749 -0.206155   -2.013503   -0.05537229 -0.37908784 -2.0251179\n",
      "  0.11658041 -0.34122375 -1.4306601  -0.21786511 -0.22023803 -1.2227467\n",
      " -0.13194153 -0.18985972 -1.3130375  -0.08705316 -0.20001811 -1.4312073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.0115219  -0.21165417 -1.2626157   0.07      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0429, -0.0560, -0.1944,  ...,  0.0350, -0.2317, -1.2778],\n",
      "        [ 0.0429, -0.0560, -0.1944,  ...,  0.0350, -0.2317, -1.2778],\n",
      "        [ 0.0429, -0.0560, -0.1944,  ...,  0.0350, -0.2317, -1.2778],\n",
      "        ...,\n",
      "        [-0.3331,  0.2584, -0.3037,  ..., -0.8907,  0.7197, -0.4499],\n",
      "        [-0.2016, -0.1351,  0.5164,  ..., -0.2714,  0.6004,  0.2849],\n",
      "        [-0.2016, -0.1351,  0.5164,  ..., -0.2714,  0.6004,  0.2849]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04293198 -0.05600019 -0.19435638  0.05821944 -0.20269641 -0.62756324\n",
      " -0.0194987  -0.36409873 -1.3417984  -0.16064003 -0.4213637  -1.6353647\n",
      " -0.33796042 -0.5317843  -2.1100082  -0.16634123 -0.65444136 -1.493975\n",
      "  0.0415376  -0.6715268  -1.3137097  -0.00563535 -0.6088203  -1.3699312\n",
      " -0.00316897 -0.7282498  -1.4793717  -0.12994848 -0.54843634 -1.4210796\n",
      " -0.04545712 -0.59581375 -1.3994217  -0.05999064 -0.5691339  -1.5003923\n",
      "  0.06815776 -0.58096105 -1.5534382  -0.04846784 -0.47253025 -1.2566166\n",
      " -0.1432031  -0.24964868 -1.8375527  -0.00863773 -0.38573128 -1.8340721\n",
      "  0.13322692 -0.35851234 -1.417643   -0.1408231  -0.23578647 -1.202772\n",
      " -0.07323597 -0.21639349 -1.2849665  -0.0301434  -0.22282064 -1.4051503\n",
      "  0.03495732 -0.23171234 -1.2777932 ]\n",
      "data: [ 0.04293198 -0.05600019 -0.19435638  0.05821944 -0.20269641 -0.62756324\n",
      " -0.0194987  -0.36409873 -1.3417984  -0.16064003 -0.4213637  -1.6353647\n",
      " -0.33796042 -0.5317843  -2.1100082  -0.16634123 -0.65444136 -1.493975\n",
      "  0.0415376  -0.6715268  -1.3137097  -0.00563535 -0.6088203  -1.3699312\n",
      " -0.00316897 -0.7282498  -1.4793717  -0.12994848 -0.54843634 -1.4210798\n",
      " -0.04545711 -0.59581375 -1.3994217  -0.05999064 -0.5691339  -1.5003923\n",
      "  0.06815776 -0.58096105 -1.5534381  -0.04846784 -0.47253025 -1.2566166\n",
      " -0.1432031  -0.24964866 -1.8375527  -0.00863773 -0.38573128 -1.8340721\n",
      "  0.13322692 -0.35851234 -1.417643   -0.1408231  -0.23578648 -1.202772\n",
      " -0.07323597 -0.21639349 -1.2849665  -0.0301434  -0.22282064 -1.4051503\n",
      "  0.03495732 -0.23171234 -1.2777932   0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0229, -0.0665, -0.2676,  ...,  0.0405, -0.2487, -1.3078],\n",
      "        [ 0.0229, -0.0665, -0.2676,  ...,  0.0405, -0.2487, -1.3078],\n",
      "        [ 0.0229, -0.0665, -0.2676,  ...,  0.0405, -0.2487, -1.3078],\n",
      "        ...,\n",
      "        [-0.1648,  0.4161, -0.0696,  ..., -0.7338,  0.9229, -0.3418],\n",
      "        [-0.1606, -0.1059,  0.5904,  ..., -0.2506,  0.6946,  0.2418],\n",
      "        [-0.1606, -0.1059,  0.5904,  ..., -0.2506,  0.6946,  0.2418]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.2893857e-02 -6.6513412e-02 -2.6758397e-01  4.6483558e-02\n",
      " -1.9676276e-01 -6.6643351e-01 -7.3028825e-02 -3.9251146e-01\n",
      " -1.4464246e+00 -2.1902639e-01 -4.5937172e-01 -1.7272682e+00\n",
      " -3.7392282e-01 -5.5472457e-01 -2.2193525e+00 -1.7277181e-01\n",
      " -6.8349856e-01 -1.6023072e+00  1.8778443e-03 -7.2513306e-01\n",
      " -1.4245373e+00 -4.2203560e-02 -6.5151376e-01 -1.4820956e+00\n",
      " -4.5764983e-02 -7.9523170e-01 -1.5985007e+00 -1.3665424e-01\n",
      " -5.8724171e-01 -1.5215001e+00 -6.9913536e-02 -6.3579875e-01\n",
      " -1.4843062e+00 -8.7885350e-02 -6.0497588e-01 -1.5684315e+00\n",
      "  5.3431347e-02 -6.2127757e-01 -1.5989370e+00 -6.0572542e-02\n",
      " -4.9662644e-01 -1.3593060e+00 -1.7636855e-01 -2.6531732e-01\n",
      " -2.0045197e+00 -2.3628160e-02 -4.1541749e-01 -2.0168722e+00\n",
      "  1.3941088e-01 -3.8471317e-01 -1.4660906e+00 -1.5788662e-01\n",
      " -2.6411867e-01 -1.2876292e+00 -9.7339988e-02 -2.3491815e-01\n",
      " -1.3675028e+00 -5.5955902e-02 -2.3337947e-01 -1.4825311e+00\n",
      "  4.0453948e-02 -2.4869989e-01 -1.3078494e+00]\n",
      "data: [ 2.2893857e-02 -6.6513412e-02 -2.6758397e-01  4.6483561e-02\n",
      " -1.9676276e-01 -6.6643351e-01 -7.3028825e-02 -3.9251146e-01\n",
      " -1.4464246e+00 -2.1902639e-01 -4.5937172e-01 -1.7272682e+00\n",
      " -3.7392280e-01 -5.5472457e-01 -2.2193525e+00 -1.7277181e-01\n",
      " -6.8349856e-01 -1.6023071e+00  1.8778443e-03 -7.2513306e-01\n",
      " -1.4245373e+00 -4.2203560e-02 -6.5151376e-01 -1.4820956e+00\n",
      " -4.5764979e-02 -7.9523170e-01 -1.5985007e+00 -1.3665424e-01\n",
      " -5.8724171e-01 -1.5215001e+00 -6.9913536e-02 -6.3579875e-01\n",
      " -1.4843062e+00 -8.7885350e-02 -6.0497588e-01 -1.5684315e+00\n",
      "  5.3431347e-02 -6.2127757e-01 -1.5989370e+00 -6.0572542e-02\n",
      " -4.9662644e-01 -1.3593060e+00 -1.7636853e-01 -2.6531732e-01\n",
      " -2.0045197e+00 -2.3628160e-02 -4.1541749e-01 -2.0168722e+00\n",
      "  1.3941088e-01 -3.8471317e-01 -1.4660906e+00 -1.5788662e-01\n",
      " -2.6411867e-01 -1.2876292e+00 -9.7339995e-02 -2.3491816e-01\n",
      " -1.3675027e+00 -5.5955902e-02 -2.3337945e-01 -1.4825311e+00\n",
      "  4.0453948e-02 -2.4869989e-01 -1.3078494e+00  9.0000004e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0087, -0.0438, -0.2390,  ...,  0.0437, -0.2339, -1.2846],\n",
      "        [ 0.0087, -0.0438, -0.2390,  ...,  0.0437, -0.2339, -1.2846],\n",
      "        [ 0.0087, -0.0438, -0.2390,  ...,  0.0437, -0.2339, -1.2846],\n",
      "        ...,\n",
      "        [-0.1266,  0.3836, -0.1363,  ..., -0.7338,  0.8887, -0.3828],\n",
      "        [-0.1497, -0.1705,  0.5386,  ..., -0.2467,  0.5822,  0.2194],\n",
      "        [-0.1497, -0.1705,  0.5386,  ..., -0.2467,  0.5822,  0.2194]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00869123 -0.04381669 -0.23899508  0.02384539 -0.18549626 -0.65011346\n",
      " -0.04620216 -0.35708424 -1.3730557  -0.18654516 -0.41382766 -1.6787719\n",
      " -0.36101735 -0.53641474 -2.1450973  -0.19729622 -0.6414099  -1.5404295\n",
      "  0.03679949 -0.66350454 -1.3571563  -0.01559883 -0.60493374 -1.4113203\n",
      " -0.00934181 -0.7316382  -1.5268265  -0.15053229 -0.5343197  -1.4541999\n",
      " -0.05746375 -0.59002835 -1.4364895  -0.06281489 -0.5679687  -1.5373566\n",
      "  0.06408462 -0.5930636  -1.5904806  -0.05355228 -0.4529126  -1.2790699\n",
      " -0.16092959 -0.22971627 -1.9019177  -0.00909837 -0.38419843 -1.8945485\n",
      "  0.14429371 -0.35329318 -1.4390959  -0.15766191 -0.2170419  -1.219912\n",
      " -0.06774877 -0.20084003 -1.2976722  -0.02143386 -0.22216982 -1.4150461\n",
      "  0.04367381 -0.23387913 -1.2846212 ]\n",
      "data: [ 0.00869123 -0.04381669 -0.23899508  0.02384539 -0.18549626 -0.65011346\n",
      " -0.04620216 -0.35708424 -1.3730557  -0.18654516 -0.41382766 -1.6787719\n",
      " -0.36101735 -0.53641474 -2.1450973  -0.19729622 -0.64140993 -1.5404296\n",
      "  0.03679949 -0.66350454 -1.3571563  -0.01559883 -0.60493374 -1.4113203\n",
      " -0.00934181 -0.7316382  -1.5268265  -0.15053229 -0.5343197  -1.4542\n",
      " -0.05746375 -0.59002835 -1.4364895  -0.06281489 -0.5679687  -1.5373566\n",
      "  0.06408462 -0.5930636  -1.5904804  -0.05355228 -0.4529126  -1.2790699\n",
      " -0.16092959 -0.22971626 -1.9019177  -0.00909837 -0.38419843 -1.8945485\n",
      "  0.14429371 -0.35329318 -1.439096   -0.15766191 -0.2170419  -1.219912\n",
      " -0.06774877 -0.20084004 -1.2976722  -0.02143386 -0.22216982 -1.4150461\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.04367381 -0.23387913 -1.2846212   0.1       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0113, -0.0754, -0.2593,  ...,  0.0232, -0.2594, -1.3177],\n",
      "        [ 0.0113, -0.0754, -0.2593,  ...,  0.0232, -0.2594, -1.3177],\n",
      "        [ 0.0113, -0.0754, -0.2593,  ...,  0.0232, -0.2594, -1.3177],\n",
      "        ...,\n",
      "        [-0.1827,  0.4003, -0.1189,  ..., -0.7540,  0.8876, -0.3530],\n",
      "        [-0.1782, -0.1433,  0.5851,  ..., -0.2519,  0.6497,  0.2487],\n",
      "        [-0.1782, -0.1433,  0.5851,  ..., -0.2519,  0.6497,  0.2487]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01134766 -0.07537445 -0.2593313   0.02651504 -0.21381357 -0.6843128\n",
      " -0.07481544 -0.39899153 -1.4344118  -0.21707289 -0.46254534 -1.7215364\n",
      " -0.3829146  -0.5655398  -2.1974661  -0.18897322 -0.68657744 -1.58628\n",
      " -0.00347005 -0.72017735 -1.40773    -0.04712865 -0.6494527  -1.46635\n",
      " -0.04338137 -0.78654593 -1.5794895  -0.15208428 -0.5839854  -1.5072718\n",
      " -0.07986848 -0.6323798  -1.4739394  -0.09448218 -0.6076336  -1.5640628\n",
      "  0.04370219 -0.6186808  -1.6045793  -0.07384814 -0.5008426  -1.344286\n",
      " -0.1816917  -0.27496666 -1.967402   -0.03620583 -0.41994482 -1.9721767\n",
      "  0.12184066 -0.38991696 -1.4684224  -0.16832897 -0.2664076  -1.2779268\n",
      " -0.10586603 -0.24196215 -1.3610656  -0.06179565 -0.24507122 -1.4762039\n",
      "  0.02321655 -0.25937486 -1.317698  ]\n",
      "data: [ 0.01134766 -0.07537445 -0.2593313   0.02651504 -0.21381357 -0.6843128\n",
      " -0.07481544 -0.3989915  -1.4344118  -0.21707289 -0.4625453  -1.7215364\n",
      " -0.38291463 -0.5655398  -2.1974661  -0.18897322 -0.68657744 -1.5862801\n",
      " -0.00347005 -0.7201774  -1.40773    -0.04712865 -0.6494527  -1.46635\n",
      " -0.04338137 -0.78654593 -1.5794895  -0.15208428 -0.5839854  -1.5072718\n",
      " -0.07986848 -0.6323798  -1.4739394  -0.09448218 -0.6076336  -1.5640628\n",
      "  0.04370218 -0.6186808  -1.6045793  -0.07384814 -0.5008426  -1.3442858\n",
      " -0.1816917  -0.27496666 -1.967402   -0.03620583 -0.41994485 -1.9721767\n",
      "  0.12184066 -0.38991696 -1.4684224  -0.16832897 -0.2664076  -1.2779268\n",
      " -0.10586603 -0.24196215 -1.3610656  -0.06179566 -0.24507122 -1.4762039\n",
      "  0.02321655 -0.25937486 -1.317698    0.11      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0344, -0.0348, -0.2263,  ...,  0.0372, -0.2311, -1.2530],\n",
      "        [ 0.0344, -0.0348, -0.2263,  ...,  0.0372, -0.2311, -1.2530],\n",
      "        [ 0.0344, -0.0348, -0.2263,  ...,  0.0372, -0.2311, -1.2530],\n",
      "        ...,\n",
      "        [-0.1223,  0.4303, -0.1253,  ..., -0.7191,  0.9394, -0.3850],\n",
      "        [-0.1356, -0.1958,  0.5561,  ..., -0.2149,  0.5731,  0.2425],\n",
      "        [-0.1356, -0.1958,  0.5561,  ..., -0.2149,  0.5731,  0.2425]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03437415 -0.03479657 -0.22628166  0.04960844 -0.15520956 -0.6065546\n",
      " -0.07587175 -0.3460755  -1.3758826  -0.22549526 -0.4109621  -1.6608918\n",
      " -0.38836545 -0.49562564 -2.1596098  -0.1547906  -0.6604092  -1.5301185\n",
      " -0.0105163  -0.7053205  -1.3820946  -0.05478525 -0.6269307  -1.4476941\n",
      " -0.05259833 -0.78504634 -1.5622967  -0.12156855 -0.57092917 -1.4496765\n",
      " -0.06752485 -0.6133783  -1.414712   -0.09465675 -0.5881108  -1.5077288\n",
      "  0.04983231 -0.59469235 -1.5296338  -0.05471838 -0.47862676 -1.2927644\n",
      " -0.1716802  -0.2541765  -1.956193   -0.02579252 -0.39647463 -1.9776475\n",
      "  0.13775826 -0.37429532 -1.3990868  -0.14542554 -0.25240523 -1.2246797\n",
      " -0.10182466 -0.22785148 -1.3130037  -0.07163507 -0.21472695 -1.4297678\n",
      "  0.03724033 -0.23107828 -1.2529676 ]\n",
      "data: [ 0.03437415 -0.03479657 -0.22628166  0.04960845 -0.15520956 -0.6065546\n",
      " -0.07587175 -0.3460755  -1.3758826  -0.22549526 -0.4109621  -1.6608918\n",
      " -0.38836545 -0.49562564 -2.1596098  -0.1547906  -0.6604092  -1.5301185\n",
      " -0.0105163  -0.70532054 -1.3820946  -0.05478525 -0.6269307  -1.4476941\n",
      " -0.05259833 -0.78504634 -1.5622967  -0.12156855 -0.57092917 -1.4496765\n",
      " -0.06752485 -0.6133783  -1.414712   -0.09465675 -0.5881108  -1.5077289\n",
      "  0.04983231 -0.59469235 -1.5296338  -0.05471839 -0.47862676 -1.2927644\n",
      " -0.1716802  -0.2541765  -1.956193   -0.02579252 -0.39647466 -1.9776475\n",
      "  0.13775826 -0.37429532 -1.3990867  -0.14542554 -0.25240523 -1.2246797\n",
      " -0.10182466 -0.22785148 -1.3130037  -0.07163507 -0.21472697 -1.429768\n",
      "  0.03724033 -0.23107828 -1.2529676   0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EC24898>\n",
      "tensor([[ 0.0127, -0.0180, -0.2336,  ...,  0.0262, -0.2084, -1.2714],\n",
      "        [ 0.0127, -0.0180, -0.2336,  ...,  0.0262, -0.2084, -1.2714],\n",
      "        [ 0.0127, -0.0180, -0.2336,  ...,  0.0262, -0.2084, -1.2714],\n",
      "        ...,\n",
      "        [-0.3143,  0.1772, -0.2588,  ..., -0.8449,  0.5940, -0.4149],\n",
      "        [-0.0983, -0.0848,  0.5543,  ..., -0.1930,  0.7003,  0.2367],\n",
      "        [-0.0983, -0.0848,  0.5543,  ..., -0.1930,  0.7003,  0.2367]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01267451 -0.01800735 -0.23358738  0.02904833 -0.15497193 -0.64437044\n",
      " -0.07718209 -0.3378286  -1.3956981  -0.22150081 -0.40328166 -1.6816084\n",
      " -0.390618   -0.50496733 -2.1618564  -0.18678346 -0.62779963 -1.5455997\n",
      " -0.00403567 -0.66115475 -1.3598571  -0.04778043 -0.59189045 -1.4187446\n",
      " -0.04959375 -0.7305236  -1.5316002  -0.15035486 -0.52763736 -1.4672077\n",
      " -0.07852821 -0.57845235 -1.4315956  -0.09832551 -0.5538317  -1.5228808\n",
      "  0.04193773 -0.56551874 -1.5618799  -0.07304594 -0.44646594 -1.302664\n",
      " -0.17938039 -0.22239518 -1.9242404  -0.03580207 -0.36743858 -1.9297311\n",
      "  0.12127987 -0.34194562 -1.4209313  -0.16399825 -0.21369019 -1.2379916\n",
      " -0.10452008 -0.19172028 -1.3152812  -0.06159423 -0.19264822 -1.4316597\n",
      "  0.02624342 -0.20838903 -1.2713952 ]\n",
      "data: [ 0.01267451 -0.01800735 -0.23358738  0.02904833 -0.15497193 -0.64437044\n",
      " -0.07718209 -0.3378286  -1.3956981  -0.22150081 -0.40328166 -1.6816084\n",
      " -0.39061797 -0.50496733 -2.1618564  -0.18678346 -0.62779963 -1.5455997\n",
      " -0.00403567 -0.6611548  -1.3598571  -0.04778043 -0.59189045 -1.4187446\n",
      " -0.04959374 -0.7305236  -1.5316002  -0.15035486 -0.52763736 -1.4672077\n",
      " -0.07852821 -0.57845235 -1.4315956  -0.09832551 -0.5538317  -1.5228809\n",
      "  0.04193773 -0.56551874 -1.5618799  -0.07304594 -0.44646594 -1.302664\n",
      " -0.17938037 -0.22239517 -1.9242405  -0.03580207 -0.36743858 -1.9297311\n",
      "  0.12127987 -0.34194562 -1.4209313  -0.16399825 -0.21369019 -1.2379916\n",
      " -0.10452008 -0.19172028 -1.3152813  -0.06159423 -0.19264822 -1.4316597\n",
      "  0.02624342 -0.20838903 -1.2713952   0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0474, -0.0921, -0.2239,  ...,  0.0570, -0.2804, -1.2840],\n",
      "        [ 0.0474, -0.0921, -0.2239,  ...,  0.0570, -0.2804, -1.2840],\n",
      "        [ 0.0474, -0.0921, -0.2239,  ...,  0.0570, -0.2804, -1.2840],\n",
      "        ...,\n",
      "        [-0.3341,  0.2522, -0.3685,  ..., -0.8526,  0.6720, -0.4759],\n",
      "        [-0.1266, -0.0778,  0.5951,  ..., -0.2138,  0.6986,  0.3055],\n",
      "        [-0.1266, -0.0778,  0.5951,  ..., -0.2138,  0.6986,  0.3055]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 4.74411510e-02 -9.21186134e-02 -2.23933548e-01  7.05920607e-02\n",
      " -2.30003670e-01 -6.28013134e-01 -2.95977294e-02 -4.10167724e-01\n",
      " -1.38327086e+00 -1.72041148e-01 -4.75905538e-01 -1.66852212e+00\n",
      " -3.36021990e-01 -5.77151597e-01 -2.15711713e+00 -1.45121306e-01\n",
      " -7.03375399e-01 -1.54198313e+00  3.57258394e-02 -7.36251056e-01\n",
      " -1.37499285e+00 -1.20001212e-02 -6.68136954e-01 -1.43334901e+00\n",
      " -1.38604417e-02 -8.04462016e-01 -1.54331470e+00 -1.09044544e-01\n",
      " -6.04214132e-01 -1.46626544e+00 -3.76305357e-02 -6.52565897e-01\n",
      " -1.43476605e+00 -6.21587560e-02 -6.27707243e-01 -1.52684844e+00\n",
      "  6.66260943e-02 -6.39778554e-01 -1.56497204e+00 -3.50837111e-02\n",
      " -5.21944880e-01 -1.30308974e+00 -1.40463054e-01 -2.96940446e-01\n",
      " -1.92940307e+00 -1.22114271e-03 -4.40402985e-01 -1.93557155e+00\n",
      "  1.43818974e-01 -4.14744854e-01 -1.43063498e+00 -1.25899166e-01\n",
      " -2.89406240e-01 -1.24271524e+00 -6.59100041e-02 -2.67630219e-01\n",
      " -1.32351661e+00 -2.50524804e-02 -2.67414421e-01 -1.44008172e+00\n",
      "  5.69590479e-02 -2.80420303e-01 -1.28401673e+00]\n",
      "data: [ 4.74411473e-02 -9.21186134e-02 -2.23933548e-01  7.05920607e-02\n",
      " -2.30003655e-01 -6.28013134e-01 -2.95977313e-02 -4.10167724e-01\n",
      " -1.38327086e+00 -1.72041148e-01 -4.75905538e-01 -1.66852224e+00\n",
      " -3.36021990e-01 -5.77151597e-01 -2.15711713e+00 -1.45121306e-01\n",
      " -7.03375399e-01 -1.54198313e+00  3.57258394e-02 -7.36251056e-01\n",
      " -1.37499285e+00 -1.20001212e-02 -6.68136954e-01 -1.43334901e+00\n",
      " -1.38604417e-02 -8.04462075e-01 -1.54331470e+00 -1.09044544e-01\n",
      " -6.04214132e-01 -1.46626544e+00 -3.76305357e-02 -6.52565897e-01\n",
      " -1.43476605e+00 -6.21587560e-02 -6.27707243e-01 -1.52684844e+00\n",
      "  6.66260943e-02 -6.39778554e-01 -1.56497204e+00 -3.50837111e-02\n",
      " -5.21944880e-01 -1.30308974e+00 -1.40463054e-01 -2.96940446e-01\n",
      " -1.92940307e+00 -1.22114271e-03 -4.40402985e-01 -1.93557155e+00\n",
      "  1.43818974e-01 -4.14744884e-01 -1.43063498e+00 -1.25899166e-01\n",
      " -2.89406240e-01 -1.24271524e+00 -6.59100041e-02 -2.67630219e-01\n",
      " -1.32351649e+00 -2.50524804e-02 -2.67414421e-01 -1.44008183e+00\n",
      "  5.69590479e-02 -2.80420303e-01 -1.28401673e+00  1.40000001e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0297, -0.0976, -0.2359,  ...,  0.0698, -0.2921, -1.2571],\n",
      "        [ 0.0297, -0.0976, -0.2359,  ...,  0.0698, -0.2921, -1.2571],\n",
      "        [ 0.0297, -0.0976, -0.2359,  ...,  0.0698, -0.2921, -1.2571],\n",
      "        ...,\n",
      "        [-0.1252,  0.4097, -0.0496,  ..., -0.6598,  0.9111, -0.3652],\n",
      "        [-0.1617, -0.0987,  0.5827,  ..., -0.2505,  0.6673,  0.2102],\n",
      "        [-0.1617, -0.0987,  0.5827,  ..., -0.2505,  0.6673,  0.2102]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0297207  -0.09762029 -0.23586306  0.0570922  -0.22198139 -0.6037137\n",
      " -0.04699404 -0.42785874 -1.4001379  -0.19326015 -0.49313694 -1.7002915\n",
      " -0.35325924 -0.6035516  -2.1865666  -0.16674861 -0.71661794 -1.5669737\n",
      "  0.04651171 -0.7646712  -1.3781251  -0.0108467  -0.7008033  -1.4302204\n",
      " -0.02477763 -0.85044706 -1.5534451  -0.11882289 -0.6202365  -1.4688288\n",
      " -0.04495604 -0.6788056  -1.445071   -0.05776574 -0.65094185 -1.5349308\n",
      "  0.06743369 -0.68523216 -1.569533   -0.02675117 -0.52134216 -1.296232\n",
      " -0.16395557 -0.29046062 -2.0033243   0.00585893 -0.4604377  -2.010923\n",
      "  0.16489708 -0.42381504 -1.4222687  -0.14107412 -0.2889001  -1.2240788\n",
      " -0.05711499 -0.26539287 -1.3079695  -0.01534708 -0.28062364 -1.4216216\n",
      "  0.06979873 -0.29207367 -1.2570596 ]\n",
      "data: [ 0.0297207  -0.09762029 -0.23586306  0.0570922  -0.22198139 -0.6037137\n",
      " -0.04699404 -0.42785874 -1.4001379  -0.19326015 -0.49313694 -1.7002914\n",
      " -0.35325924 -0.6035516  -2.1865666  -0.16674861 -0.71661794 -1.5669737\n",
      "  0.04651171 -0.76467115 -1.378125   -0.0108467  -0.7008033  -1.4302204\n",
      " -0.02477763 -0.85044706 -1.5534451  -0.11882289 -0.6202365  -1.4688287\n",
      " -0.04495604 -0.6788056  -1.445071   -0.05776574 -0.65094185 -1.5349308\n",
      "  0.06743369 -0.68523216 -1.5695329  -0.02675117 -0.52134216 -1.296232\n",
      " -0.16395557 -0.29046062 -2.0033243   0.00585893 -0.4604377  -2.010923\n",
      "  0.16489708 -0.42381504 -1.4222686  -0.14107412 -0.2889001  -1.2240788\n",
      " -0.05711499 -0.26539287 -1.3079696  -0.01534708 -0.28062364 -1.4216216\n",
      "  0.06979873 -0.29207367 -1.2570596   0.15      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0216, -0.1001, -0.1883,  ...,  0.0842, -0.3007, -1.1957],\n",
      "        [ 0.0216, -0.1001, -0.1883,  ...,  0.0842, -0.3007, -1.1957],\n",
      "        [ 0.0216, -0.1001, -0.1883,  ...,  0.0842, -0.3007, -1.1957],\n",
      "        ...,\n",
      "        [-0.1288,  0.3788, -0.1007,  ..., -0.7443,  0.8786, -0.3674],\n",
      "        [-0.1277, -0.0870,  0.5861,  ..., -0.2243,  0.6525,  0.2078],\n",
      "        [-0.1277, -0.0870,  0.5861,  ..., -0.2243,  0.6525,  0.2078]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0215845  -0.10008666 -0.18833153  0.04896341 -0.22168635 -0.53043175\n",
      " -0.0539468  -0.4308194  -1.3348722  -0.19996364 -0.49506107 -1.6385573\n",
      " -0.36238477 -0.61106026 -2.1214013  -0.17528462 -0.72015566 -1.5089295\n",
      "  0.04861136 -0.7696949  -1.3296267  -0.00847521 -0.70751166 -1.3776858\n",
      " -0.01438555 -0.8590732  -1.5011394  -0.12167604 -0.62317854 -1.4064732\n",
      " -0.04092657 -0.6851499  -1.3863484  -0.04451375 -0.65747577 -1.4778123\n",
      "  0.08517818 -0.6977914  -1.5163202  -0.02276111 -0.52422726 -1.2312124\n",
      " -0.1643703  -0.29187414 -1.9605954   0.01849714 -0.4695109  -1.9667072\n",
      "  0.18507773 -0.43005502 -1.3660538  -0.14325108 -0.29058975 -1.1589482\n",
      " -0.04903577 -0.26903903 -1.2440099  -0.0028225  -0.28975776 -1.3589333\n",
      "  0.08424785 -0.3007236  -1.1957289 ]\n",
      "data: [ 0.0215845  -0.10008666 -0.18833153  0.04896341 -0.22168635 -0.53043175\n",
      " -0.0539468  -0.4308194  -1.3348722  -0.19996364 -0.49506107 -1.6385573\n",
      " -0.36238477 -0.61106026 -2.1214013  -0.17528461 -0.72015566 -1.5089295\n",
      "  0.04861136 -0.7696949  -1.3296266  -0.00847521 -0.70751166 -1.3776859\n",
      " -0.01438555 -0.8590733  -1.5011394  -0.12167604 -0.62317854 -1.406473\n",
      " -0.04092656 -0.6851499  -1.3863484  -0.04451375 -0.6574757  -1.4778123\n",
      "  0.08517818 -0.69779134 -1.5163202  -0.02276111 -0.52422726 -1.2312124\n",
      " -0.16437031 -0.29187414 -1.9605954   0.01849714 -0.4695109  -1.9667071\n",
      "  0.18507773 -0.43005502 -1.3660538  -0.14325108 -0.29058975 -1.1589482\n",
      " -0.04903577 -0.26903903 -1.2440099  -0.0028225  -0.28975776 -1.3589332\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.08424785 -0.3007236  -1.1957289   0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 8.1335e-05, -6.7738e-02, -1.9696e-01,  ...,  3.5129e-02,\n",
      "         -2.6927e-01, -1.1773e+00],\n",
      "        [ 8.1335e-05, -6.7738e-02, -1.9696e-01,  ...,  3.5129e-02,\n",
      "         -2.6927e-01, -1.1773e+00],\n",
      "        [ 8.1335e-05, -6.7738e-02, -1.9696e-01,  ...,  3.5129e-02,\n",
      "         -2.6927e-01, -1.1773e+00],\n",
      "        ...,\n",
      "        [-1.5383e-01,  3.7015e-01, -1.0372e-01,  ..., -7.0066e-01,\n",
      "          8.8449e-01, -4.0268e-01],\n",
      "        [-9.2620e-02, -6.4269e-02,  5.9221e-01,  ..., -1.8017e-01,\n",
      "          6.9246e-01,  2.1699e-01],\n",
      "        [-9.2620e-02, -6.4269e-02,  5.9221e-01,  ..., -1.8017e-01,\n",
      "          6.9246e-01,  2.1699e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 8.1335194e-05 -6.7737833e-02 -1.9696428e-01  3.4546230e-02\n",
      " -1.6252276e-01 -4.9152231e-01 -1.2451114e-01 -3.9689609e-01\n",
      " -1.3596554e+00 -2.7959439e-01 -4.6693498e-01 -1.6428275e+00\n",
      " -4.2337924e-01 -5.4831302e-01 -2.1617756e+00 -1.8274829e-01\n",
      " -7.1127319e-01 -1.5268972e+00 -3.6571428e-02 -7.8567874e-01\n",
      " -1.3842943e+00 -8.7313592e-02 -7.0473957e-01 -1.4398811e+00\n",
      " -9.9361956e-02 -8.8627887e-01 -1.5654447e+00 -1.4051728e-01\n",
      " -6.3329649e-01 -1.4250617e+00 -9.6518978e-02 -6.8394816e-01\n",
      " -1.3927937e+00 -1.1512319e-01 -6.4903831e-01 -1.4719176e+00\n",
      "  2.9433981e-02 -6.7866278e-01 -1.4795506e+00 -6.6196360e-02\n",
      " -5.2026486e-01 -1.2657490e+00 -2.2788039e-01 -2.7985018e-01\n",
      " -2.0585792e+00 -3.8418941e-02 -4.5492402e-01 -2.0925510e+00\n",
      "  1.3960251e-01 -4.1832182e-01 -1.3481619e+00 -1.8222710e-01\n",
      " -2.9703933e-01 -1.1819217e+00 -1.2509015e-01 -2.6392591e-01\n",
      " -1.2751069e+00 -9.3034878e-02 -2.5539368e-01 -1.3880341e+00\n",
      "  3.5128601e-02 -2.6926857e-01 -1.1773305e+00]\n",
      "data: [ 8.1335194e-05 -6.7737833e-02 -1.9696428e-01  3.4546230e-02\n",
      " -1.6252275e-01 -4.9152228e-01 -1.2451114e-01 -3.9689609e-01\n",
      " -1.3596555e+00 -2.7959439e-01 -4.6693498e-01 -1.6428275e+00\n",
      " -4.2337924e-01 -5.4831302e-01 -2.1617756e+00 -1.8274827e-01\n",
      " -7.1127319e-01 -1.5268971e+00 -3.6571428e-02 -7.8567868e-01\n",
      " -1.3842943e+00 -8.7313592e-02 -7.0473951e-01 -1.4398811e+00\n",
      " -9.9361956e-02 -8.8627887e-01 -1.5654446e+00 -1.4051728e-01\n",
      " -6.3329649e-01 -1.4250617e+00 -9.6518971e-02 -6.8394816e-01\n",
      " -1.3927935e+00 -1.1512318e-01 -6.4903831e-01 -1.4719176e+00\n",
      "  2.9433981e-02 -6.7866278e-01 -1.4795506e+00 -6.6196360e-02\n",
      " -5.2026486e-01 -1.2657490e+00 -2.2788039e-01 -2.7985018e-01\n",
      " -2.0585792e+00 -3.8418941e-02 -4.5492402e-01 -2.0925510e+00\n",
      "  1.3960251e-01 -4.1832179e-01 -1.3481619e+00 -1.8222709e-01\n",
      " -2.9703933e-01 -1.1819217e+00 -1.2509015e-01 -2.6392591e-01\n",
      " -1.2751069e+00 -9.3034878e-02 -2.5539368e-01 -1.3880341e+00\n",
      "  3.5128601e-02 -2.6926857e-01 -1.1773305e+00  1.7000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE3F7CB278>\n",
      "tensor([[-0.0168,  0.0112, -0.1703,  ...,  0.0217, -0.1734, -1.1715],\n",
      "        [-0.0168,  0.0112, -0.1703,  ...,  0.0217, -0.1734, -1.1715],\n",
      "        [-0.0168,  0.0112, -0.1703,  ...,  0.0217, -0.1734, -1.1715],\n",
      "        ...,\n",
      "        [-0.2923,  0.1575, -0.1459,  ..., -0.8181,  0.6873, -0.4892],\n",
      "        [-0.0972, -0.0851,  0.5742,  ..., -0.2408,  0.6306,  0.2503],\n",
      "        [-0.0972, -0.0851,  0.5742,  ..., -0.2408,  0.6306,  0.2503]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01681967  0.01115839 -0.17025842  0.00445499 -0.11176124 -0.5173107\n",
      " -0.10952898 -0.31889474 -1.3193583  -0.25904256 -0.37960804 -1.6192629\n",
      " -0.42931032 -0.48732597 -2.0998785  -0.22210567 -0.61142653 -1.4800096\n",
      " -0.00872025 -0.65486574 -1.287113   -0.05573989 -0.58831483 -1.3376153\n",
      " -0.05506863 -0.73667645 -1.464087   -0.17596547 -0.5104003  -1.3813734\n",
      " -0.09624939 -0.5666808  -1.3554523  -0.09231485 -0.53456104 -1.4488399\n",
      "  0.05864497 -0.5667969  -1.4901862  -0.0820101  -0.4112566  -1.2091341\n",
      " -0.22312267 -0.17661725 -1.9315939  -0.03583352 -0.34580207 -1.9411175\n",
      "  0.1470552  -0.30553186 -1.3400736  -0.2014831  -0.17416926 -1.1348243\n",
      " -0.11977589 -0.14799975 -1.2181592  -0.0741652  -0.16042005 -1.3373764\n",
      "  0.02167965 -0.17337772 -1.1715417 ]\n",
      "data: [-0.01681967  0.01115839 -0.17025843  0.00445499 -0.11176124 -0.5173107\n",
      " -0.10952898 -0.31889474 -1.3193583  -0.25904256 -0.37960804 -1.619263\n",
      " -0.4293103  -0.48732597 -2.0998785  -0.22210568 -0.61142653 -1.4800096\n",
      " -0.00872025 -0.65486574 -1.2871128  -0.05573989 -0.58831483 -1.3376153\n",
      " -0.05506863 -0.73667645 -1.464087   -0.17596549 -0.5104003  -1.3813734\n",
      " -0.09624939 -0.5666808  -1.3554523  -0.09231485 -0.53456104 -1.4488399\n",
      "  0.05864497 -0.5667969  -1.4901862  -0.0820101  -0.4112566  -1.2091341\n",
      " -0.22312267 -0.17661723 -1.9315939  -0.03583352 -0.34580207 -1.9411175\n",
      "  0.1470552  -0.30553186 -1.3400736  -0.2014831  -0.17416926 -1.1348243\n",
      " -0.11977588 -0.14799975 -1.2181592  -0.0741652  -0.16042003 -1.3373764\n",
      "  0.02167965 -0.17337772 -1.1715417   0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0136, -0.1174, -0.2057,  ...,  0.0388, -0.2795, -1.3322],\n",
      "        [ 0.0136, -0.1174, -0.2057,  ...,  0.0388, -0.2795, -1.3322],\n",
      "        [ 0.0136, -0.1174, -0.2057,  ...,  0.0388, -0.2795, -1.3322],\n",
      "        ...,\n",
      "        [-0.2979,  0.3828, -0.2395,  ..., -0.7983,  0.7915, -0.3285],\n",
      "        [-0.1983, -0.0678,  0.5481,  ..., -0.2842,  0.6936,  0.2883],\n",
      "        [-0.1983, -0.0678,  0.5481,  ..., -0.2842,  0.6936,  0.2883]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.3561707e-02 -1.1742346e-01 -2.0567784e-01  2.6642416e-02\n",
      " -2.8898138e-01 -6.9678855e-01 -1.8098138e-02 -4.3846202e-01\n",
      " -1.3681977e+00 -1.5690538e-01 -4.9325585e-01 -1.6721621e+00\n",
      " -3.4094256e-01 -6.3314950e-01 -2.1234703e+00 -2.1246122e-01\n",
      " -6.9930208e-01 -1.5244801e+00  6.0292110e-02 -7.0029509e-01\n",
      " -1.2865846e+00  7.6336116e-03 -6.4374554e-01 -1.3363800e+00\n",
      "  4.3933466e-03 -7.3922992e-01 -1.4463637e+00 -1.6589706e-01\n",
      " -5.7903051e-01 -1.4544258e+00 -5.2489981e-02 -6.3423944e-01\n",
      " -1.4359424e+00 -5.5505984e-02 -6.0604107e-01 -1.5377336e+00\n",
      "  6.1449423e-02 -6.2548912e-01 -1.6085143e+00 -6.0075261e-02\n",
      " -5.1199508e-01 -1.2798090e+00 -1.3694584e-01 -2.8560489e-01\n",
      " -1.7969985e+00 -6.9430247e-03 -4.2676064e-01 -1.7703495e+00\n",
      "  1.2961926e-01 -3.9052293e-01 -1.4720786e+00 -1.5689576e-01\n",
      " -2.6574171e-01 -1.2323418e+00 -5.7675958e-02 -2.4701008e-01\n",
      " -1.3126297e+00  7.8208745e-04 -2.7637148e-01 -1.4333720e+00\n",
      "  3.8783483e-02 -2.7953863e-01 -1.3322442e+00]\n",
      "data: [ 1.3561707e-02 -1.1742346e-01 -2.0567784e-01  2.6642416e-02\n",
      " -2.8898138e-01 -6.9678855e-01 -1.8098138e-02 -4.3846202e-01\n",
      " -1.3681977e+00 -1.5690538e-01 -4.9325585e-01 -1.6721621e+00\n",
      " -3.4094256e-01 -6.3314950e-01 -2.1234703e+00 -2.1246122e-01\n",
      " -6.9930208e-01 -1.5244801e+00  6.0292110e-02 -7.0029509e-01\n",
      " -1.2865846e+00  7.6336116e-03 -6.4374560e-01 -1.3363800e+00\n",
      "  4.3933466e-03 -7.3922992e-01 -1.4463637e+00 -1.6589707e-01\n",
      " -5.7903051e-01 -1.4544258e+00 -5.2489981e-02 -6.3423944e-01\n",
      " -1.4359424e+00 -5.5505980e-02 -6.0604107e-01 -1.5377336e+00\n",
      "  6.1449423e-02 -6.2548912e-01 -1.6085143e+00 -6.0075261e-02\n",
      " -5.1199508e-01 -1.2798090e+00 -1.3694584e-01 -2.8560489e-01\n",
      " -1.7969985e+00 -6.9430242e-03 -4.2676064e-01 -1.7703494e+00\n",
      "  1.2961926e-01 -3.9052293e-01 -1.4720786e+00 -1.5689576e-01\n",
      " -2.6574171e-01 -1.2323418e+00 -5.7675958e-02 -2.4701008e-01\n",
      " -1.3126297e+00  7.8208745e-04 -2.7637148e-01 -1.4333720e+00\n",
      "  3.8783483e-02 -2.7953863e-01 -1.3322442e+00  1.9000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BB38>\n",
      "tensor([[ 0.0437, -0.1450, -0.2726,  ...,  0.0666, -0.3192, -1.3373],\n",
      "        [ 0.0437, -0.1450, -0.2726,  ...,  0.0666, -0.3192, -1.3373],\n",
      "        [ 0.0437, -0.1450, -0.2726,  ...,  0.0666, -0.3192, -1.3373],\n",
      "        ...,\n",
      "        [-0.1344,  0.4945, -0.1323,  ..., -0.7032,  1.0155, -0.4696],\n",
      "        [-0.1980, -0.0673,  0.6327,  ..., -0.2956,  0.6857,  0.2677],\n",
      "        [-0.1980, -0.0673,  0.6327,  ..., -0.2956,  0.6857,  0.2677]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 4.36643027e-02 -1.44957423e-01 -2.72578239e-01  7.53858238e-02\n",
      " -2.74201632e-01 -6.57149553e-01 -1.21112913e-02 -4.76994395e-01\n",
      " -1.45236778e+00 -1.57624453e-01 -5.37874281e-01 -1.75910068e+00\n",
      " -3.15044194e-01 -6.51503682e-01 -2.25321198e+00 -1.61823273e-01\n",
      " -7.54060209e-01 -1.64091706e+00  7.74040744e-02 -7.96004057e-01\n",
      " -1.44226766e+00  1.81699619e-02 -7.38791049e-01 -1.48773956e+00\n",
      " -5.36367297e-05 -8.78470659e-01 -1.61233616e+00 -1.12821855e-01\n",
      " -6.51431322e-01 -1.54069018e+00 -2.90412754e-02 -7.12673426e-01\n",
      " -1.52011299e+00 -3.70070115e-02 -6.82592928e-01 -1.61358929e+00\n",
      "  7.85506293e-02 -7.26448476e-01 -1.65829873e+00 -1.46626234e-02\n",
      " -5.48633933e-01 -1.36706257e+00 -1.55078143e-01 -3.15955371e-01\n",
      " -2.06185699e+00  1.62071437e-02 -4.90076959e-01 -2.06489444e+00\n",
      "  1.66497439e-01 -4.47226405e-01 -1.50936532e+00 -1.37910396e-01\n",
      " -3.11569750e-01 -1.29349303e+00 -4.28937003e-02 -2.85179794e-01\n",
      " -1.36820841e+00  5.20981848e-04 -3.11153889e-01 -1.48320985e+00\n",
      "  6.65895492e-02 -3.19170535e-01 -1.33732152e+00]\n",
      "data: [ 4.36643027e-02 -1.44957423e-01 -2.72578239e-01  7.53858238e-02\n",
      " -2.74201632e-01 -6.57149553e-01 -1.21112922e-02 -4.76994395e-01\n",
      " -1.45236790e+00 -1.57624453e-01 -5.37874281e-01 -1.75910068e+00\n",
      " -3.15044194e-01 -6.51503682e-01 -2.25321198e+00 -1.61823273e-01\n",
      " -7.54060209e-01 -1.64091706e+00  7.74040744e-02 -7.96004057e-01\n",
      " -1.44226766e+00  1.81699619e-02 -7.38791049e-01 -1.48773956e+00\n",
      " -5.36367297e-05 -8.78470659e-01 -1.61233616e+00 -1.12821855e-01\n",
      " -6.51431322e-01 -1.54069018e+00 -2.90412754e-02 -7.12673426e-01\n",
      " -1.52011287e+00 -3.70070115e-02 -6.82592928e-01 -1.61358929e+00\n",
      "  7.85506293e-02 -7.26448417e-01 -1.65829885e+00 -1.46626234e-02\n",
      " -5.48633933e-01 -1.36706257e+00 -1.55078143e-01 -3.15955371e-01\n",
      " -2.06185699e+00  1.62071437e-02 -4.90076929e-01 -2.06489444e+00\n",
      "  1.66497439e-01 -4.47226405e-01 -1.50936544e+00 -1.37910396e-01\n",
      " -3.11569750e-01 -1.29349303e+00 -4.28937003e-02 -2.85179794e-01\n",
      " -1.36820841e+00  5.20981848e-04 -3.11153889e-01 -1.48320985e+00\n",
      "  6.65895492e-02 -3.19170535e-01 -1.33732152e+00  2.00000003e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.38  3.384 3.398 ... 3.372 3.39  3.391]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " [3.372 3.379 3.392 ... 3.359 3.378 3.383]\n",
      " ...\n",
      " [3.025 3.031 3.023 ... 3.025 3.032 3.036]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]\n",
      " [3.01  3.013 3.016 ... 3.01  3.013 3.022]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[-0.0053, -0.1118, -0.2065,  ...,  0.0755, -0.3081, -1.2545],\n",
      "        [-0.0053, -0.1118, -0.2065,  ...,  0.0755, -0.3081, -1.2545],\n",
      "        [-0.0053, -0.1118, -0.2065,  ...,  0.0755, -0.3081, -1.2545],\n",
      "        ...,\n",
      "        [-0.1089,  0.4738, -0.1385,  ..., -0.7536,  0.9913, -0.4219],\n",
      "        [-0.1278, -0.0530,  0.5905,  ..., -0.2064,  0.6372,  0.2258],\n",
      "        [-0.1278, -0.0530,  0.5905,  ..., -0.2064,  0.6372,  0.2258]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.00532214 -0.11175766 -0.20645382  0.01566501 -0.2593744  -0.5875651\n",
      " -0.03050163 -0.43882245 -1.3411478  -0.17470899 -0.495224   -1.6698234\n",
      " -0.3618263  -0.646929   -2.1316018  -0.22440624 -0.7022873  -1.5428935\n",
      "  0.0828606  -0.72701573 -1.3286064   0.01816772 -0.6818768  -1.3683171\n",
      "  0.02372622 -0.8009882  -1.4895223  -0.15822308 -0.5853714  -1.4368482\n",
      " -0.03933805 -0.6596645  -1.4282575  -0.02643575 -0.6414192  -1.5375354\n",
      "  0.09024157 -0.69016683 -1.6055883  -0.03380185 -0.5042144  -1.2394601\n",
      " -0.15341626 -0.27692136 -1.8912263   0.01994222 -0.45828345 -1.868083\n",
      "  0.1795927  -0.41871783 -1.4277571  -0.16190769 -0.25705314 -1.1791123\n",
      " -0.02933681 -0.24896744 -1.25093     0.03061229 -0.30159605 -1.3667786\n",
      "  0.0755013  -0.30805564 -1.2545106 ]\n",
      "data: [-4.42 -4.54  4.07 -4.32 -4.29  4.15 -4.27 -3.87  4.13 -4.34 -3.59  4.56\n",
      " -4.45 -3.43  5.1  -4.6  -3.7   4.58 -4.65 -3.45  5.03 -4.64 -3.29  5.34\n",
      "  0.    0.    0.   -4.6  -3.82  4.5  -4.61 -3.48  4.7  -4.58 -3.36  5.11\n",
      "  0.    0.    0.   -4.59 -3.94  4.41 -4.6  -3.66  4.58 -4.54 -3.47  4.92\n",
      "  0.    0.    0.   -4.73 -4.14  4.86 -4.52 -3.78  4.44 -4.51 -3.67  4.64\n",
      " -4.47 -3.55  4.76  0.  ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[-0.2694,  0.2166,  0.3244,  ..., -0.5547,  0.1386, -0.4497],\n",
      "        [-0.2694,  0.2166,  0.3244,  ..., -0.5547,  0.1386, -0.4497],\n",
      "        [-0.2694,  0.2166,  0.3244,  ..., -0.5547,  0.1386, -0.4497],\n",
      "        ...,\n",
      "        [ 1.2722, -1.3827,  0.3074,  ...,  0.9557, -1.8180,  1.5290],\n",
      "        [ 0.5244, -0.2045,  0.0365,  ...,  0.5266, -0.6894,  2.2485],\n",
      "        [ 0.5244, -0.2045,  0.0365,  ...,  0.5266, -0.6894,  2.2485]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.26942667  0.21662493  0.32443678 -0.39767104  0.13034719 -0.03699443\n",
      " -0.4205271   0.07727423 -0.4300734  -0.46135038  0.01156199 -0.47127554\n",
      " -0.48828515 -0.02628796 -0.62915516 -0.500653    0.02128519 -0.724648\n",
      " -0.2856469   0.03902201 -0.09990224 -0.39478886 -0.07275261 -0.09671256\n",
      " -0.53685176 -0.00522082 -0.23397473 -0.5204128   0.09827949 -0.7301388\n",
      " -0.5559708   0.07399456 -0.78255486 -0.59376574  0.06912723 -0.7804668\n",
      " -0.6252326  -0.0372733  -0.75874555 -0.49387112  0.14833197 -0.677331\n",
      " -0.62044257  0.17528091 -0.7878821  -0.62938386  0.13659307 -0.7950733\n",
      " -0.58041507  0.07751553 -0.6173223  -0.5459279   0.2750555  -0.51408875\n",
      " -0.49184278  0.22938535 -0.52580476 -0.55749935  0.20015985 -0.5236653\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.5546796   0.13858978 -0.4497014 ]\n",
      "init: [-0.26942667  0.21662493  0.32443678 -0.39767104  0.13034719 -0.03699443\n",
      " -0.4205271   0.07727423 -0.4300734  -0.46135038  0.01156199 -0.47127554\n",
      " -0.48828515 -0.02628796 -0.62915516 -0.500653    0.02128519 -0.724648\n",
      " -0.2856469   0.03902201 -0.09990224 -0.39478886 -0.07275261 -0.09671256\n",
      " -0.53685176 -0.00522082 -0.23397473 -0.5204128   0.09827949 -0.7301388\n",
      " -0.5559708   0.07399456 -0.78255486 -0.59376574  0.06912723 -0.7804668\n",
      " -0.6252326  -0.0372733  -0.75874555 -0.49387112  0.14833197 -0.677331\n",
      " -0.62044257  0.17528091 -0.7878821  -0.62938386  0.13659307 -0.7950733\n",
      " -0.58041507  0.07751553 -0.6173223  -0.5459279   0.2750555  -0.51408875\n",
      " -0.49184278  0.22938535 -0.52580476 -0.55749935  0.20015985 -0.5236653\n",
      " -0.5546796   0.13858978 -0.4497014 ]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [-0.26942667  0.21662493  0.32443678 -0.39767104  0.13034719 -0.03699443\n",
      " -0.4205271   0.07727423 -0.43007338 -0.46135035  0.01156199 -0.4712755\n",
      " -0.48828515 -0.02628796 -0.62915516 -0.500653    0.02128519 -0.724648\n",
      " -0.2856469   0.03902201 -0.09990224 -0.39478886 -0.07275261 -0.09671256\n",
      " -0.53685176 -0.00522082 -0.23397473 -0.5204128   0.0982795  -0.7301388\n",
      " -0.5559708   0.07399456 -0.78255486 -0.59376574  0.06912723 -0.7804668\n",
      " -0.6252326  -0.0372733  -0.75874555 -0.49387112  0.14833197 -0.6773309\n",
      " -0.62044257  0.17528091 -0.7878821  -0.62938386  0.13659307 -0.7950733\n",
      " -0.58041507  0.07751553 -0.6173223  -0.5459279   0.2750555  -0.51408875\n",
      " -0.49184278  0.22938533 -0.52580476 -0.55749935  0.20015985 -0.5236653\n",
      " -0.5546796   0.13858978 -0.4497014   0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[ 0.0388, -0.0258, -0.1067,  ..., -0.0427, -0.1669, -1.1981],\n",
      "        [ 0.0388, -0.0258, -0.1067,  ..., -0.0427, -0.1669, -1.1981],\n",
      "        [ 0.0388, -0.0258, -0.1067,  ..., -0.0427, -0.1669, -1.1981],\n",
      "        ...,\n",
      "        [ 0.8512, -0.3419,  0.3190,  ...,  0.3274,  0.6532, -0.2666],\n",
      "        [ 0.1883,  0.0146, -0.1447,  ..., -0.8520,  0.6531, -0.3563],\n",
      "        [ 0.1883,  0.0146, -0.1447,  ..., -0.8520,  0.6531, -0.3563]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 3.8824461e-02 -2.5808427e-02 -1.0671432e-01  1.8171966e-04\n",
      " -1.9991353e-01 -5.9560251e-01 -1.9765943e-01 -3.2255009e-01\n",
      " -1.1156625e+00 -3.4184253e-01 -4.1168073e-01 -1.2795627e+00\n",
      " -5.8443367e-01 -4.1784063e-01 -1.6384592e+00 -1.9513750e-01\n",
      " -5.7920796e-01 -1.2057110e+00 -3.0993944e-01 -5.8637160e-01\n",
      " -1.2434381e+00 -2.2450718e-01 -4.8798707e-01 -1.2967086e+00\n",
      " -1.3494374e-01 -5.9537381e-01 -1.3019736e+00 -1.9198170e-01\n",
      " -4.6623412e-01 -1.2232418e+00 -1.8070316e-01 -4.9183282e-01\n",
      " -1.1256690e+00 -1.9014725e-01 -4.8588064e-01 -1.2176884e+00\n",
      "  7.6784395e-02 -3.6639556e-01 -1.3445718e+00 -2.1587288e-01\n",
      " -4.7988367e-01 -1.1367997e+00 -1.8835160e-01 -3.1887022e-01\n",
      " -1.3682708e+00 -1.2673306e-01 -3.2770145e-01 -1.3805751e+00\n",
      "  3.2093212e-02 -3.0819982e-01 -1.2598028e+00 -1.6550156e-01\n",
      " -2.5186574e-01 -1.1169246e+00 -2.8582901e-01 -2.0516777e-01\n",
      " -1.1804845e+00 -1.6176769e-01 -1.3502936e-01 -1.3060205e+00\n",
      " -4.2720228e-02 -1.6689759e-01 -1.1980647e+00]\n",
      "data: [ 3.8824461e-02 -2.5808427e-02 -1.0671432e-01  1.8171966e-04\n",
      " -1.9991355e-01 -5.9560251e-01 -1.9765943e-01 -3.2255009e-01\n",
      " -1.1156625e+00 -3.4184253e-01 -4.1168073e-01 -1.2795627e+00\n",
      " -5.8443367e-01 -4.1784060e-01 -1.6384592e+00 -1.9513750e-01\n",
      " -5.7920796e-01 -1.2057110e+00 -3.0993944e-01 -5.8637160e-01\n",
      " -1.2434381e+00 -2.2450718e-01 -4.8798707e-01 -1.2967086e+00\n",
      " -1.3494374e-01 -5.9537381e-01 -1.3019736e+00 -1.9198170e-01\n",
      " -4.6623412e-01 -1.2232418e+00 -1.8070316e-01 -4.9183282e-01\n",
      " -1.1256690e+00 -1.9014725e-01 -4.8588067e-01 -1.2176884e+00\n",
      "  7.6784395e-02 -3.6639556e-01 -1.3445718e+00 -2.1587288e-01\n",
      " -4.7988364e-01 -1.1367997e+00 -1.8835159e-01 -3.1887022e-01\n",
      " -1.3682708e+00 -1.2673306e-01 -3.2770145e-01 -1.3805751e+00\n",
      "  3.2093212e-02 -3.0819982e-01 -1.2598028e+00 -1.6550155e-01\n",
      " -2.5186574e-01 -1.1169246e+00 -2.8582901e-01 -2.0516777e-01\n",
      " -1.1804845e+00 -1.6176769e-01 -1.3502936e-01 -1.3060205e+00\n",
      " -4.2720228e-02 -1.6689759e-01 -1.1980647e+00  2.0000000e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B9B0>\n",
      "tensor([[ 0.1782,  0.0294, -0.2892,  ...,  0.2739, -0.1419, -1.3617],\n",
      "        [ 0.1782,  0.0294, -0.2892,  ...,  0.2739, -0.1419, -1.3617],\n",
      "        [ 0.1782,  0.0294, -0.2892,  ...,  0.2739, -0.1419, -1.3617],\n",
      "        ...,\n",
      "        [-0.1859,  0.4669,  0.1215,  ..., -0.6852,  0.9991, -0.1963],\n",
      "        [-0.2428,  0.1077,  0.5531,  ..., -0.5720,  0.7918,  0.3498],\n",
      "        [-0.2428,  0.1077,  0.5531,  ..., -0.5720,  0.7918,  0.3498]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.17820437  0.02937775 -0.2892322   0.22050864 -0.11240822 -0.68987846\n",
      "  0.15938696 -0.27118254 -1.394234    0.01469222 -0.31525648 -1.6913378\n",
      " -0.12870027 -0.45081115 -2.1740136  -0.03329523 -0.54732007 -1.5982776\n",
      "  0.26789576 -0.5561495  -1.3752625   0.21752125 -0.49287802 -1.4127405\n",
      "  0.21613646 -0.5949397  -1.5309424   0.02420819 -0.4425922  -1.5217319\n",
      "  0.15391016 -0.5021913  -1.5130494   0.1731528  -0.4580328  -1.5944312\n",
      "  0.29780403 -0.51041627 -1.6556499   0.15296122 -0.36190933 -1.3433905\n",
      "  0.05475079 -0.10864358 -1.9253807   0.22764277 -0.28829455 -1.902039\n",
      "  0.38425553 -0.23332031 -1.5312467   0.02931738 -0.12166227 -1.2870791\n",
      "  0.16146569 -0.08732855 -1.3546278   0.22393782 -0.13123728 -1.4784079\n",
      "  0.2738503  -0.14192814 -1.3616767 ]\n",
      "data: [ 0.17820436  0.02937775 -0.2892322   0.22050864 -0.11240822 -0.68987846\n",
      "  0.15938696 -0.27118254 -1.3942341   0.01469222 -0.31525648 -1.691338\n",
      " -0.12870027 -0.45081115 -2.1740136  -0.03329523 -0.54732007 -1.5982776\n",
      "  0.26789576 -0.5561495  -1.3752625   0.21752125 -0.49287805 -1.4127405\n",
      "  0.21613646 -0.5949397  -1.5309424   0.02420819 -0.4425922  -1.5217319\n",
      "  0.15391016 -0.5021913  -1.5130494   0.1731528  -0.4580328  -1.5944312\n",
      "  0.29780403 -0.51041627 -1.6556499   0.15296122 -0.36190933 -1.3433905\n",
      "  0.05475079 -0.10864358 -1.9253807   0.22764279 -0.28829455 -1.902039\n",
      "  0.38425553 -0.23332031 -1.5312467   0.02931738 -0.12166227 -1.2870792\n",
      "  0.16146569 -0.08732855 -1.3546278   0.22393781 -0.13123728 -1.4784079\n",
      "  0.2738503  -0.14192814 -1.3616767   0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 9.5032e-03, -1.8255e-01, -2.8268e-01,  ...,  6.2809e-02,\n",
      "         -3.6057e-01, -1.3810e+00],\n",
      "        [ 9.5032e-03, -1.8255e-01, -2.8268e-01,  ...,  6.2809e-02,\n",
      "         -3.6057e-01, -1.3810e+00],\n",
      "        [ 9.5032e-03, -1.8255e-01, -2.8268e-01,  ...,  6.2809e-02,\n",
      "         -3.6057e-01, -1.3810e+00],\n",
      "        ...,\n",
      "        [-1.2893e-03,  3.3753e-01,  1.9201e-01,  ..., -7.9782e-01,\n",
      "          8.1780e-01, -1.0525e-01],\n",
      "        [-1.4467e-01,  1.9947e-01,  4.7333e-01,  ..., -2.0056e-01,\n",
      "          1.0264e+00,  1.6449e-02],\n",
      "        [-1.4467e-01,  1.9947e-01,  4.7333e-01,  ..., -2.0056e-01,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          1.0264e+00,  1.6449e-02]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00950315 -0.18255346 -0.2826765   0.03997717 -0.3385645  -0.7321834\n",
      "  0.01423992 -0.49760598 -1.4823761  -0.11360616 -0.5530639  -1.801172\n",
      " -0.26737422 -0.70005035 -2.2990496  -0.2003541  -0.74040186 -1.6851459\n",
      "  0.1216912  -0.73649824 -1.416425    0.05251863 -0.69150877 -1.4631672\n",
      "  0.0162043  -0.78570366 -1.5911584  -0.1550172  -0.62718487 -1.5934253\n",
      " -0.02475128 -0.6893815  -1.5880003  -0.04069036 -0.65203774 -1.6806753\n",
      "  0.04792883 -0.7019688  -1.7465107  -0.02824886 -0.5497062  -1.406879\n",
      " -0.1296199  -0.31862554 -1.9815521   0.01343117 -0.48581263 -1.9520066\n",
      "  0.13359362 -0.44462332 -1.5755141  -0.14397278 -0.31845653 -1.3379431\n",
      " -0.00646252 -0.3042044  -1.378166    0.04149991 -0.35341018 -1.4919088\n",
      "  0.06280948 -0.360573   -1.3810132 ]\n",
      "data: [ 0.00950315 -0.18255347 -0.2826765   0.03997717 -0.3385645  -0.7321834\n",
      "  0.01423992 -0.49760598 -1.4823761  -0.11360617 -0.5530639  -1.801172\n",
      " -0.26737422 -0.70005035 -2.2990496  -0.2003541  -0.74040186 -1.6851459\n",
      "  0.1216912  -0.73649824 -1.416425    0.05251863 -0.69150877 -1.4631671\n",
      "  0.0162043  -0.78570366 -1.5911584  -0.1550172  -0.62718487 -1.5934253\n",
      " -0.02475128 -0.6893815  -1.5880003  -0.04069036 -0.65203774 -1.6806751\n",
      "  0.04792883 -0.7019688  -1.7465107  -0.02824886 -0.5497062  -1.406879\n",
      " -0.1296199  -0.31862554 -1.9815521   0.01343117 -0.48581263 -1.9520066\n",
      "  0.13359362 -0.44462335 -1.5755141  -0.14397278 -0.31845653 -1.3379431\n",
      " -0.00646252 -0.3042044  -1.3781658   0.04149991 -0.35341018 -1.4919087\n",
      "  0.06280948 -0.360573   -1.3810132   0.04      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[ 0.0164, -0.1957, -0.2253,  ...,  0.0323, -0.3681, -1.3448],\n",
      "        [ 0.0164, -0.1957, -0.2253,  ...,  0.0323, -0.3681, -1.3448],\n",
      "        [ 0.0164, -0.1957, -0.2253,  ...,  0.0323, -0.3681, -1.3448],\n",
      "        ...,\n",
      "        [-0.0143,  0.5213, -0.1871,  ..., -0.5732,  1.0558, -0.5264],\n",
      "        [-0.1428,  0.0204,  0.6001,  ..., -0.1609,  0.7148,  0.3227],\n",
      "        [-0.1428,  0.0204,  0.6001,  ..., -0.1609,  0.7148,  0.3227]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.6417395e-02 -1.9568130e-01 -2.2525011e-01  3.8195316e-02\n",
      " -3.5525620e-01 -6.5964556e-01  1.1870413e-02 -5.3146446e-01\n",
      " -1.4000125e+00 -1.3098672e-01 -5.8666599e-01 -1.7317024e+00\n",
      " -3.1814727e-01 -7.3545051e-01 -2.2019854e+00 -2.1073157e-01\n",
      " -7.7948612e-01 -1.6177211e+00  1.1032105e-01 -7.9785883e-01\n",
      " -1.3696787e+00  4.4195257e-02 -7.5957745e-01 -1.4081899e+00\n",
      "  3.2335617e-02 -8.6575425e-01 -1.5301088e+00 -1.5462074e-01\n",
      " -6.5336579e-01 -1.5148821e+00 -3.6641181e-02 -7.2712898e-01\n",
      " -1.5031995e+00 -3.0148782e-02 -7.0933181e-01 -1.6149704e+00\n",
      "  6.8892084e-02 -7.5608647e-01 -1.6895424e+00 -3.5275936e-02\n",
      " -5.6827903e-01 -1.3227359e+00 -1.5574834e-01 -3.4701276e-01\n",
      " -1.9314148e+00  2.6370585e-04 -5.2082956e-01 -1.9035735e+00\n",
      "  1.3861847e-01 -4.7712618e-01 -1.5134963e+00 -1.6681203e-01\n",
      " -3.1844014e-01 -1.2626812e+00 -4.0814959e-02 -3.0760711e-01\n",
      " -1.3227743e+00  1.3146602e-02 -3.6514062e-01 -1.4356316e+00\n",
      "  3.2301307e-02 -3.6813414e-01 -1.3448132e+00]\n",
      "data: [ 1.6417395e-02 -1.9568130e-01 -2.2525011e-01  3.8195316e-02\n",
      " -3.5525620e-01 -6.5964556e-01  1.1870413e-02 -5.3146446e-01\n",
      " -1.4000125e+00 -1.3098672e-01 -5.8666599e-01 -1.7317024e+00\n",
      " -3.1814727e-01 -7.3545051e-01 -2.2019854e+00 -2.1073157e-01\n",
      " -7.7948606e-01 -1.6177211e+00  1.1032105e-01 -7.9785883e-01\n",
      " -1.3696789e+00  4.4195257e-02 -7.5957751e-01 -1.4081899e+00\n",
      "  3.2335617e-02 -8.6575425e-01 -1.5301088e+00 -1.5462074e-01\n",
      " -6.5336579e-01 -1.5148821e+00 -3.6641181e-02 -7.2712898e-01\n",
      " -1.5031995e+00 -3.0148782e-02 -7.0933181e-01 -1.6149704e+00\n",
      "  6.8892084e-02 -7.5608653e-01 -1.6895424e+00 -3.5275936e-02\n",
      " -5.6827903e-01 -1.3227359e+00 -1.5574834e-01 -3.4701276e-01\n",
      " -1.9314148e+00  2.6370585e-04 -5.2082956e-01 -1.9035735e+00\n",
      "  1.3861847e-01 -4.7712621e-01 -1.5134963e+00 -1.6681203e-01\n",
      " -3.1844014e-01 -1.2626812e+00 -4.0814959e-02 -3.0760711e-01\n",
      " -1.3227744e+00  1.3146602e-02 -3.6514062e-01 -1.4356315e+00\n",
      "  3.2301307e-02 -3.6813414e-01 -1.3448132e+00  5.0000001e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[ 0.0357, -0.1919, -0.2129,  ...,  0.0613, -0.3752, -1.2345],\n",
      "        [ 0.0357, -0.1919, -0.2129,  ...,  0.0613, -0.3752, -1.2345],\n",
      "        [ 0.0357, -0.1919, -0.2129,  ...,  0.0613, -0.3752, -1.2345],\n",
      "        ...,\n",
      "        [ 0.0243,  0.6106, -0.1445,  ..., -0.3745,  1.1604, -0.5759],\n",
      "        [-0.1289,  0.0078,  0.6562,  ..., -0.1783,  0.6883,  0.3277],\n",
      "        [-0.1289,  0.0078,  0.6562,  ..., -0.1783,  0.6883,  0.3277]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03570373 -0.19186175 -0.2128982   0.07115582 -0.30436462 -0.51228684\n",
      " -0.04828145 -0.5352888  -1.3672603  -0.20491973 -0.59854054 -1.670747\n",
      " -0.35839385 -0.7051563  -2.18463    -0.1692427  -0.8215331  -1.5749971\n",
      "  0.04780889 -0.8855562  -1.4031383  -0.01341006 -0.8195572  -1.4454685\n",
      " -0.02913085 -0.97937167 -1.5726557  -0.11823907 -0.72572076 -1.4650723\n",
      " -0.04880424 -0.7875824  -1.444825   -0.05198222 -0.7534592  -1.5318478\n",
      "  0.07128516 -0.8004886  -1.5579596  -0.01855261 -0.60979974 -1.2956556\n",
      " -0.18592997 -0.37127987 -2.0555453   0.00642008 -0.56070995 -2.0698366\n",
      "  0.17274658 -0.5101154  -1.414156   -0.1562577  -0.37687486 -1.2173446\n",
      " -0.06525405 -0.34792033 -1.2972944  -0.02896813 -0.3687609  -1.409356\n",
      "  0.06132969 -0.37521005 -1.2345325 ]\n",
      "data: [ 0.03570373 -0.19186175 -0.2128982   0.07115582 -0.30436462 -0.51228684\n",
      " -0.04828145 -0.5352888  -1.3672603  -0.20491973 -0.59854054 -1.670747\n",
      " -0.35839385 -0.7051563  -2.18463    -0.16924268 -0.821533   -1.5749971\n",
      "  0.04780889 -0.88555616 -1.4031383  -0.01341006 -0.8195572  -1.4454685\n",
      " -0.02913084 -0.97937167 -1.5726557  -0.11823907 -0.72572076 -1.4650723\n",
      " -0.04880424 -0.7875824  -1.4448249  -0.05198222 -0.7534592  -1.5318478\n",
      "  0.07128516 -0.8004886  -1.5579596  -0.01855261 -0.60979974 -1.2956557\n",
      " -0.18592997 -0.37127987 -2.0555453   0.00642008 -0.56070995 -2.0698366\n",
      "  0.17274658 -0.5101154  -1.4141558  -0.1562577  -0.37687483 -1.2173446\n",
      " -0.06525405 -0.34792033 -1.2972943  -0.02896812 -0.3687609  -1.4093559\n",
      "  0.06132969 -0.37521005 -1.2345325   0.06      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[-0.0117, -0.1009, -0.1717,  ...,  0.0351, -0.2854, -1.1601],\n",
      "        [-0.0117, -0.1009, -0.1717,  ...,  0.0351, -0.2854, -1.1601],\n",
      "        [-0.0117, -0.1009, -0.1717,  ...,  0.0351, -0.2854, -1.1601],\n",
      "        ...,\n",
      "        [-0.1496,  0.4833, -0.0303,  ..., -0.6352,  1.0875, -0.4779],\n",
      "        [-0.0828,  0.0409,  0.6568,  ..., -0.1585,  0.7076,  0.2797],\n",
      "        [-0.0828,  0.0409,  0.6568,  ..., -0.1585,  0.7076,  0.2797]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.0117179  -0.10094411 -0.1716576   0.01665957 -0.2140667  -0.46033937\n",
      " -0.0991802  -0.43551454 -1.3043066  -0.25625998 -0.49584028 -1.6159401\n",
      " -0.4181875  -0.6079758  -2.1197567  -0.22276798 -0.7250132  -1.5029424\n",
      "  0.00518331 -0.7780074  -1.3242295  -0.05289553 -0.714202   -1.3705851\n",
      " -0.05575633 -0.8682375  -1.502746   -0.16862568 -0.62703735 -1.3908057\n",
      " -0.08915357 -0.68823296 -1.3714329  -0.08444531 -0.65477467 -1.4682657\n",
      "  0.05484013 -0.6996898  -1.5018767  -0.06287206 -0.5146377  -1.2117219\n",
      " -0.2204985  -0.2803182  -1.9599028  -0.02545553 -0.4628354  -1.972321\n",
      "  0.15942997 -0.41846538 -1.3437676  -0.19673021 -0.27980056 -1.1364746\n",
      " -0.09896173 -0.25509378 -1.2136464  -0.05919972 -0.27710336 -1.3293287\n",
      "  0.03513806 -0.2854386  -1.1601342 ]\n",
      "data: [-0.0117179  -0.10094411 -0.1716576   0.01665957 -0.2140667  -0.46033937\n",
      " -0.0991802  -0.43551454 -1.3043066  -0.25625998 -0.49584025 -1.6159401\n",
      " -0.4181875  -0.6079758  -2.1197567  -0.22276798 -0.7250132  -1.5029426\n",
      "  0.00518331 -0.7780073  -1.3242295  -0.05289553 -0.714202   -1.370585\n",
      " -0.05575633 -0.86823744 -1.502746   -0.16862568 -0.62703735 -1.3908057\n",
      " -0.08915357 -0.68823296 -1.3714329  -0.08444531 -0.6547746  -1.4682657\n",
      "  0.05484013 -0.6996898  -1.5018767  -0.06287206 -0.5146377  -1.2117219\n",
      " -0.2204985  -0.2803182  -1.9599028  -0.02545553 -0.4628354  -1.972321\n",
      "  0.15942997 -0.41846538 -1.3437676  -0.19673021 -0.27980056 -1.1364746\n",
      " -0.09896173 -0.25509378 -1.2136464  -0.05919972 -0.27710336 -1.3293287\n",
      "  0.03513806 -0.2854386  -1.1601342   0.07      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[-0.0196, -0.0650, -0.2203,  ..., -0.0053, -0.2509, -1.2084],\n",
      "        [-0.0196, -0.0650, -0.2203,  ..., -0.0053, -0.2509, -1.2084],\n",
      "        [-0.0196, -0.0650, -0.2203,  ..., -0.0053, -0.2509, -1.2084],\n",
      "        ...,\n",
      "        [-0.1684,  0.3798,  0.0192,  ..., -0.6535,  0.9453, -0.3307],\n",
      "        [-0.0788, -0.0689,  0.6254,  ..., -0.1878,  0.6740,  0.2701],\n",
      "        [-0.0788, -0.0689,  0.6254,  ..., -0.1878,  0.6740,  0.2701]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01958204 -0.06504403 -0.22033338  0.00880626 -0.15836978 -0.51172704\n",
      " -0.15809946 -0.39032596 -1.3750397  -0.31628847 -0.45732343 -1.6556894\n",
      " -0.46115255 -0.52812827 -2.1788287  -0.20672578 -0.7136265  -1.5396831\n",
      " -0.07604654 -0.7836733  -1.4036242  -0.11825232 -0.69636035 -1.4619863\n",
      " -0.11911669 -0.8757305  -1.5894532  -0.17130993 -0.6348624  -1.4423993\n",
      " -0.12851128 -0.67681557 -1.4067161  -0.14119872 -0.6356298  -1.4903257\n",
      "  0.0210139  -0.6568032  -1.4973902  -0.10193425 -0.5178781  -1.2895968\n",
      " -0.2569973  -0.27856475 -2.0542722  -0.07031597 -0.43973476 -2.0945418\n",
      "  0.12360656 -0.40316552 -1.3757272  -0.2180652  -0.29237643 -1.2053112\n",
      " -0.17114852 -0.2548548  -1.3025693  -0.1434137  -0.23763059 -1.4186443\n",
      " -0.00532139 -0.25087452 -1.2084426 ]\n",
      "data: [-0.01958204 -0.06504403 -0.22033338  0.00880626 -0.15836978 -0.51172704\n",
      " -0.15809946 -0.39032596 -1.3750397  -0.31628847 -0.45732343 -1.6556894\n",
      " -0.46115258 -0.52812827 -2.1788287  -0.20672578 -0.7136265  -1.5396831\n",
      " -0.07604654 -0.7836732  -1.403624   -0.11825232 -0.69636035 -1.4619862\n",
      " -0.11911669 -0.8757305  -1.5894532  -0.17130993 -0.6348624  -1.4423993\n",
      " -0.12851128 -0.67681557 -1.4067161  -0.14119872 -0.6356298  -1.4903256\n",
      "  0.0210139  -0.6568032  -1.4973902  -0.10193424 -0.5178781  -1.2895969\n",
      " -0.2569973  -0.27856475 -2.0542722  -0.07031597 -0.43973476 -2.0945418\n",
      "  0.12360657 -0.40316552 -1.3757272  -0.2180652  -0.29237643 -1.2053112\n",
      " -0.17114852 -0.2548548  -1.3025693  -0.1434137  -0.23763059 -1.4186443\n",
      " -0.00532139 -0.25087452 -1.2084426   0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0344, -0.0292, -0.1622,  ...,  0.0355, -0.2003, -1.2060],\n",
      "        [ 0.0344, -0.0292, -0.1622,  ...,  0.0355, -0.2003, -1.2060],\n",
      "        [ 0.0344, -0.0292, -0.1622,  ...,  0.0355, -0.2003, -1.2060],\n",
      "        ...,\n",
      "        [-0.2612,  0.2528, -0.1245,  ..., -0.8410,  0.8145, -0.4302],\n",
      "        [-0.2290, -0.1556,  0.4936,  ..., -0.3717,  0.5532,  0.2066],\n",
      "        [-0.2290, -0.1556,  0.4936,  ..., -0.3717,  0.5532,  0.2066]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03443883 -0.02917637 -0.16217165  0.05279319 -0.16751541 -0.56908935\n",
      " -0.03580736 -0.35216105 -1.3264158  -0.17923367 -0.40930232 -1.6269314\n",
      " -0.3619634  -0.51825166 -2.0930777  -0.1741635  -0.6365222  -1.4802103\n",
      "  0.0511858  -0.66270113 -1.2685837   0.00723392 -0.6042272  -1.3190826\n",
      "  0.00753248 -0.7346097  -1.4403838  -0.13532907 -0.52595544 -1.3911178\n",
      " -0.04821464 -0.5809884  -1.3613837  -0.04781176 -0.5538533  -1.4606683\n",
      "  0.09665811 -0.5796646  -1.5161432  -0.04839598 -0.4370892  -1.2186476\n",
      " -0.17564084 -0.2088235  -1.8945239  -0.00582657 -0.36565384 -1.8950416\n",
      "  0.1608689  -0.32931152 -1.3615673  -0.16004454 -0.19500999 -1.1501976\n",
      " -0.08475773 -0.17185992 -1.2266424  -0.03805226 -0.18620984 -1.348327\n",
      "  0.03553287 -0.20027702 -1.205969  ]\n",
      "data: [ 0.03443883 -0.02917638 -0.16217165  0.05279319 -0.16751541 -0.56908935\n",
      " -0.03580736 -0.35216105 -1.3264157  -0.17923367 -0.40930232 -1.6269314\n",
      " -0.3619634  -0.51825166 -2.0930777  -0.17416352 -0.6365222  -1.4802103\n",
      "  0.0511858  -0.66270113 -1.2685837   0.00723392 -0.6042272  -1.3190826\n",
      "  0.00753248 -0.7346098  -1.4403838  -0.13532907 -0.52595544 -1.3911178\n",
      " -0.04821464 -0.5809884  -1.3613837  -0.04781176 -0.5538533  -1.4606683\n",
      "  0.09665812 -0.5796646  -1.5161432  -0.04839598 -0.4370892  -1.2186476\n",
      " -0.17564084 -0.2088235  -1.894524   -0.00582657 -0.36565384 -1.8950417\n",
      "  0.1608689  -0.32931152 -1.3615673  -0.16004454 -0.19500999 -1.1501976\n",
      " -0.08475773 -0.17185992 -1.2266424  -0.03805226 -0.18620986 -1.348327\n",
      "  0.03553287 -0.20027703 -1.205969    0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[-0.0020, -0.0821, -0.2420,  ...,  0.0191, -0.2546, -1.3110],\n",
      "        [-0.0020, -0.0821, -0.2420,  ...,  0.0191, -0.2546, -1.3110],\n",
      "        [-0.0020, -0.0821, -0.2420,  ...,  0.0191, -0.2546, -1.3110],\n",
      "        ...,\n",
      "        [-0.3267,  0.3005, -0.3064,  ..., -0.7773,  0.7597, -0.4916],\n",
      "        [-0.1128,  0.0110,  0.6347,  ..., -0.2203,  0.7935,  0.3113],\n",
      "        [-0.1128,  0.0110,  0.6347,  ..., -0.2203,  0.7935,  0.3113]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-1.9895993e-03 -8.2074568e-02 -2.4196243e-01  2.1624226e-02\n",
      " -2.2987129e-01 -6.6401106e-01 -6.1770067e-02 -4.1003260e-01\n",
      " -1.4167665e+00 -2.0396030e-01 -4.7342941e-01 -1.7129022e+00\n",
      " -3.7126967e-01 -5.9273708e-01 -2.1925187e+00 -2.1237367e-01\n",
      " -6.8088472e-01 -1.5788983e+00  1.4778219e-02 -7.0638907e-01\n",
      " -1.3758930e+00 -3.9044209e-02 -6.4560580e-01 -1.4277750e+00\n",
      " -4.8936807e-02 -7.6898736e-01 -1.5434024e+00 -1.6917387e-01\n",
      " -5.7284087e-01 -1.4959593e+00 -8.1840888e-02 -6.2826037e-01\n",
      " -1.4711186e+00 -9.6062630e-02 -5.9953028e-01 -1.5644521e+00\n",
      "  2.5954790e-02 -6.2411237e-01 -1.6146513e+00 -7.6965749e-02\n",
      " -4.9053875e-01 -1.3226727e+00 -1.8417129e-01 -2.6052448e-01\n",
      " -1.9313414e+00 -3.8366564e-02 -4.1323978e-01 -1.9255748e+00\n",
      "  1.0657295e-01 -3.7982887e-01 -1.4687171e+00 -1.7839453e-01\n",
      " -2.5161880e-01 -1.2604486e+00 -9.4175063e-02 -2.2912520e-01\n",
      " -1.3351378e+00 -4.5653977e-02 -2.4558093e-01 -1.4518863e+00\n",
      "  1.9096255e-02 -2.5456810e-01 -1.3110158e+00]\n",
      "data: [-1.98959932e-03 -8.20745677e-02 -2.41962433e-01  2.16242261e-02\n",
      " -2.29871288e-01 -6.64011061e-01 -6.17700666e-02 -4.10032630e-01\n",
      " -1.41676652e+00 -2.03960299e-01 -4.73429412e-01 -1.71290219e+00\n",
      " -3.71269673e-01 -5.92737079e-01 -2.19251871e+00 -2.12373674e-01\n",
      " -6.80884719e-01 -1.57889831e+00  1.47782192e-02 -7.06389070e-01\n",
      " -1.37589300e+00 -3.90442088e-02 -6.45605803e-01 -1.42777491e+00\n",
      " -4.89368066e-02 -7.68987358e-01 -1.54340243e+00 -1.69173867e-01\n",
      " -5.72840869e-01 -1.49595928e+00 -8.18408877e-02 -6.28260374e-01\n",
      " -1.47111857e+00 -9.60626304e-02 -5.99530280e-01 -1.56445205e+00\n",
      "  2.59547904e-02 -6.24112368e-01 -1.61465132e+00 -7.69657493e-02\n",
      " -4.90538746e-01 -1.32267272e+00 -1.84171289e-01 -2.60524482e-01\n",
      " -1.93134141e+00 -3.83665636e-02 -4.13239777e-01 -1.92557478e+00\n",
      "  1.06572956e-01 -3.79828870e-01 -1.46871710e+00 -1.78394526e-01\n",
      " -2.51618803e-01 -1.26044858e+00 -9.41750631e-02 -2.29125202e-01\n",
      " -1.33513784e+00 -4.56539765e-02 -2.45580927e-01 -1.45188630e+00\n",
      "  1.90962553e-02 -2.54568100e-01 -1.31101573e+00  1.00000001e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0448, -0.0870, -0.2538,  ...,  0.0514, -0.2756, -1.2861],\n",
      "        [ 0.0448, -0.0870, -0.2538,  ...,  0.0514, -0.2756, -1.2861],\n",
      "        [ 0.0448, -0.0870, -0.2538,  ...,  0.0514, -0.2756, -1.2861],\n",
      "        ...,\n",
      "        [-0.1156,  0.4445, -0.1254,  ..., -0.7044,  0.9729, -0.4096],\n",
      "        [-0.1175, -0.1579,  0.6068,  ..., -0.2105,  0.6160,  0.2783],\n",
      "        [-0.1175, -0.1579,  0.6068,  ..., -0.2105,  0.6160,  0.2783]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04481024 -0.08696093 -0.2538104   0.06867351 -0.2051842  -0.6330174\n",
      " -0.05448855 -0.40049756 -1.4150109  -0.20165968 -0.46506625 -1.6997969\n",
      " -0.35492536 -0.5509033  -2.2014072  -0.14127682 -0.71119654 -1.5703924\n",
      "  0.01162057 -0.75752604 -1.4243175  -0.03609988 -0.6812594  -1.4872692\n",
      " -0.03921943 -0.8377198  -1.6042913  -0.10689262 -0.6231197  -1.4872468\n",
      " -0.05134324 -0.66609573 -1.4557667  -0.0776943  -0.6368607  -1.5451093\n",
      "  0.05907543 -0.6512219  -1.566678   -0.03821034 -0.52567756 -1.3289472\n",
      " -0.16164176 -0.29643425 -2.0097947  -0.00991419 -0.44415084 -2.031783\n",
      "  0.148998   -0.417959   -1.4380962  -0.13460086 -0.29920626 -1.2582959\n",
      " -0.08377291 -0.2711116  -1.3474361  -0.05295208 -0.2611208  -1.4637417\n",
      "  0.05135506 -0.27564335 -1.2860682 ]\n",
      "data: [ 0.04481024 -0.08696093 -0.2538104   0.06867351 -0.2051842  -0.6330174\n",
      " -0.05448855 -0.40049756 -1.4150109  -0.20165968 -0.46506625 -1.6997969\n",
      " -0.35492533 -0.5509033  -2.2014072  -0.14127682 -0.71119654 -1.5703923\n",
      "  0.01162057 -0.75752604 -1.4243175  -0.03609988 -0.6812594  -1.4872692\n",
      " -0.03921943 -0.8377198  -1.6042914  -0.10689262 -0.6231197  -1.4872468\n",
      " -0.05134324 -0.66609573 -1.4557666  -0.0776943  -0.6368607  -1.5451093\n",
      "  0.05907543 -0.6512219  -1.566678   -0.03821034 -0.52567756 -1.3289472\n",
      " -0.16164178 -0.29643425 -2.0097947  -0.00991419 -0.44415084 -2.031783\n",
      "  0.148998   -0.41795903 -1.4380962  -0.13460086 -0.29920626 -1.2582959\n",
      " -0.08377292 -0.2711116  -1.3474361  -0.05295208 -0.2611208  -1.4637417\n",
      "  0.05135506 -0.27564335 -1.2860683   0.11      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0291, -0.0506, -0.2422,  ...,  0.0641, -0.2411, -1.2785],\n",
      "        [ 0.0291, -0.0506, -0.2422,  ...,  0.0641, -0.2411, -1.2785],\n",
      "        [ 0.0291, -0.0506, -0.2422,  ...,  0.0641, -0.2411, -1.2785],\n",
      "        ...,\n",
      "        [-0.1385,  0.3405, -0.0325,  ..., -0.7789,  0.8248, -0.2791],\n",
      "        [-0.1379, -0.1293,  0.5497,  ..., -0.2182,  0.6256,  0.2040],\n",
      "        [-0.1379, -0.1293,  0.5497,  ..., -0.2182,  0.6256,  0.2040]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02910891 -0.05064695 -0.24215181  0.04456759 -0.18841302 -0.6438534\n",
      " -0.03736605 -0.37154394 -1.3834112  -0.18235357 -0.43088853 -1.6904974\n",
      " -0.35758978 -0.5506157  -2.1595306  -0.17762634 -0.6574499  -1.5487034\n",
      "  0.05038269 -0.68804455 -1.3563335  -0.0046403  -0.62804645 -1.4107664\n",
      " -0.00680544 -0.764142   -1.5297585  -0.12962268 -0.5528879  -1.4583027\n",
      " -0.04309924 -0.61049855 -1.4368935  -0.0516347  -0.5873558  -1.5368857\n",
      "  0.07611208 -0.6151171  -1.5829237  -0.03266173 -0.4636445  -1.2836976\n",
      " -0.1510979  -0.2404414  -1.9366078   0.00673638 -0.39986473 -1.9343481\n",
      "  0.16430023 -0.3675068  -1.4327686  -0.13958268 -0.22867891 -1.2210555\n",
      " -0.05275509 -0.21088625 -1.3024414  -0.0091324  -0.2300746  -1.4199986\n",
      "  0.06408361 -0.24108624 -1.2784724 ]\n",
      "data: [ 0.02910891 -0.05064695 -0.24215181  0.04456759 -0.18841302 -0.6438534\n",
      " -0.03736605 -0.37154397 -1.383411   -0.18235357 -0.43088853 -1.6904974\n",
      " -0.3575898  -0.5506157  -2.1595306  -0.17762634 -0.6574499  -1.5487034\n",
      "  0.05038269 -0.6880446  -1.3563335  -0.0046403  -0.62804645 -1.4107662\n",
      " -0.00680544 -0.764142   -1.5297585  -0.12962268 -0.5528879  -1.4583027\n",
      " -0.04309924 -0.61049855 -1.4368935  -0.0516347  -0.5873558  -1.5368857\n",
      "  0.07611208 -0.6151171  -1.5829235  -0.03266173 -0.46364447 -1.2836976\n",
      " -0.1510979  -0.2404414  -1.9366078   0.00673637 -0.39986473 -1.9343481\n",
      "  0.16430023 -0.3675068  -1.4327686  -0.13958268 -0.22867891 -1.2210555\n",
      " -0.05275509 -0.21088625 -1.3024414  -0.0091324  -0.2300746  -1.4199986\n",
      "  0.06408361 -0.24108623 -1.2784724   0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[ 0.0144, -0.0870, -0.2550,  ...,  0.0434, -0.2745, -1.3154],\n",
      "        [ 0.0144, -0.0870, -0.2550,  ...,  0.0434, -0.2745, -1.3154],\n",
      "        [ 0.0144, -0.0870, -0.2550,  ...,  0.0434, -0.2745, -1.3154],\n",
      "        ...,\n",
      "        [-0.1533,  0.4140, -0.1118,  ..., -0.7046,  0.8918, -0.3496],\n",
      "        [-0.1611, -0.1223,  0.5835,  ..., -0.2396,  0.6611,  0.2331],\n",
      "        [-0.1611, -0.1223,  0.5835,  ..., -0.2396,  0.6611,  0.2331]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01441265 -0.08701726 -0.2550401   0.03279186 -0.22950405 -0.6769546\n",
      " -0.05278543 -0.41070414 -1.4250143  -0.19420286 -0.47428972 -1.7222033\n",
      " -0.36343867 -0.58970296 -2.1953773  -0.18776157 -0.69210833 -1.5850217\n",
      "  0.03068817 -0.7215523  -1.3862014  -0.01983027 -0.6587514  -1.4416995\n",
      " -0.02268343 -0.78917646 -1.5581672  -0.14474595 -0.58659124 -1.5008829\n",
      " -0.06084394 -0.64126986 -1.4749124  -0.07334987 -0.6174224  -1.5696077\n",
      "  0.05604684 -0.63802135 -1.6173759  -0.05609355 -0.50474393 -1.3283348\n",
      " -0.16350037 -0.2787463  -1.9511685  -0.01630513 -0.43027085 -1.9484501\n",
      "  0.1376931  -0.40007198 -1.4701903  -0.15632537 -0.267322   -1.2643378\n",
      " -0.07672304 -0.24711487 -1.3448796  -0.02940166 -0.26161247 -1.4603376\n",
      "  0.04337765 -0.27452788 -1.3153665 ]\n",
      "data: [ 0.01441265 -0.08701726 -0.2550401   0.03279186 -0.22950405 -0.6769546\n",
      " -0.05278543 -0.4107041  -1.4250141  -0.19420286 -0.47428972 -1.7222033\n",
      " -0.3634387  -0.58970296 -2.1953773  -0.18776157 -0.69210833 -1.5850216\n",
      "  0.03068817 -0.72155225 -1.3862014  -0.01983027 -0.6587514  -1.4416995\n",
      " -0.02268343 -0.78917646 -1.5581672  -0.14474595 -0.58659124 -1.5008829\n",
      " -0.06084393 -0.64126986 -1.4749124  -0.07334987 -0.6174224  -1.5696077\n",
      "  0.05604684 -0.63802135 -1.6173759  -0.05609355 -0.50474393 -1.3283348\n",
      " -0.16350037 -0.2787463  -1.9511685  -0.01630513 -0.43027085 -1.94845\n",
      "  0.1376931  -0.40007198 -1.4701903  -0.15632537 -0.267322   -1.2643378\n",
      " -0.07672304 -0.24711487 -1.3448796  -0.02940166 -0.26161247 -1.4603376\n",
      "  0.04337765 -0.27452788 -1.3153665   0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[ 0.0236, -0.0885, -0.2617,  ...,  0.0516, -0.2759, -1.2933],\n",
      "        [ 0.0236, -0.0885, -0.2617,  ...,  0.0516, -0.2759, -1.2933],\n",
      "        [ 0.0236, -0.0885, -0.2617,  ...,  0.0516, -0.2759, -1.2933],\n",
      "        ...,\n",
      "        [-0.1131,  0.4218, -0.1488,  ..., -0.6943,  0.9351, -0.4390],\n",
      "        [-0.1341, -0.1409,  0.5942,  ..., -0.2399,  0.6251,  0.2376],\n",
      "        [-0.1341, -0.1409,  0.5942,  ..., -0.2399,  0.6251,  0.2376]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02363414 -0.0885215  -0.2617367   0.04882866 -0.2151089  -0.6463182\n",
      " -0.0479551  -0.40727958 -1.4156952  -0.19093065 -0.4681718  -1.7133927\n",
      " -0.35039422 -0.5750171  -2.1972544  -0.17180482 -0.7000013  -1.5798434\n",
      "  0.03121121 -0.7390425  -1.4126601  -0.02264579 -0.6741696  -1.4678973\n",
      " -0.02645693 -0.8186624  -1.5870818  -0.12809779 -0.60324246 -1.4889644\n",
      " -0.05350145 -0.65591156 -1.4665664  -0.06727019 -0.6288741  -1.5592262\n",
      "  0.05906717 -0.65703213 -1.5957457  -0.04133687 -0.5082036  -1.3196604\n",
      " -0.16757977 -0.2796607  -1.9992125  -0.00658064 -0.43978235 -2.006978\n",
      "  0.1486086  -0.4067346  -1.4530957  -0.14875594 -0.27723694 -1.2513579\n",
      " -0.07092753 -0.25369292 -1.3351433  -0.03142911 -0.2641583  -1.4511396\n",
      "  0.05157245 -0.27588332 -1.2933142 ]\n",
      "data: [ 0.02363414 -0.0885215  -0.2617367   0.04882866 -0.21510892 -0.6463182\n",
      " -0.0479551  -0.40727958 -1.4156952  -0.19093065 -0.4681718  -1.7133927\n",
      " -0.35039422 -0.5750171  -2.1972544  -0.17180482 -0.7000013  -1.5798434\n",
      "  0.03121121 -0.7390425  -1.4126601  -0.02264579 -0.6741696  -1.4678973\n",
      " -0.02645693 -0.8186624  -1.5870818  -0.12809779 -0.60324246 -1.4889644\n",
      " -0.05350145 -0.65591156 -1.4665664  -0.06727019 -0.6288741  -1.5592263\n",
      "  0.05906717 -0.6570322  -1.5957457  -0.04133687 -0.5082036  -1.3196605\n",
      " -0.16757977 -0.2796607  -1.9992125  -0.00658064 -0.43978232 -2.006978\n",
      "  0.1486086  -0.4067346  -1.4530957  -0.14875594 -0.27723694 -1.2513579\n",
      " -0.07092753 -0.25369292 -1.3351433  -0.03142911 -0.2641583  -1.4511396\n",
      "  0.05157245 -0.27588332 -1.2933142   0.14      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0191, -0.0541, -0.2467,  ...,  0.0563, -0.2441, -1.2937],\n",
      "        [ 0.0191, -0.0541, -0.2467,  ...,  0.0563, -0.2441, -1.2937],\n",
      "        [ 0.0191, -0.0541, -0.2467,  ...,  0.0563, -0.2441, -1.2937],\n",
      "        ...,\n",
      "        [-0.1466,  0.3524, -0.0943,  ..., -0.7771,  0.8382, -0.3357],\n",
      "        [-0.1349, -0.1440,  0.5641,  ..., -0.2130,  0.6068,  0.2250],\n",
      "        [-0.1349, -0.1440,  0.5641,  ..., -0.2130,  0.6068,  0.2250]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.9147266e-02 -5.4116830e-02 -2.4669215e-01  3.2639254e-02\n",
      " -1.9792415e-01 -6.5725142e-01 -4.2179629e-02 -3.7693363e-01\n",
      " -1.3859426e+00 -1.8518695e-01 -4.3586561e-01 -1.6924486e+00\n",
      " -3.6328340e-01 -5.5973411e-01 -2.1556082e+00 -1.8965784e-01\n",
      " -6.5803838e-01 -1.5524602e+00  4.5896597e-02 -6.8495440e-01\n",
      " -1.3562717e+00 -7.6256916e-03 -6.2608236e-01 -1.4089707e+00\n",
      " -6.1112791e-03 -7.5642967e-01 -1.5252047e+00 -1.4087346e-01\n",
      " -5.4934335e-01 -1.4647601e+00 -4.9392879e-02 -6.0777271e-01\n",
      " -1.4437096e+00 -5.4945245e-02 -5.8624727e-01 -1.5439897e+00\n",
      "  7.2181247e-02 -6.1235338e-01 -1.5956835e+00 -4.1973993e-02\n",
      " -4.6494207e-01 -1.2903390e+00 -1.5428245e-01 -2.4260321e-01\n",
      " -1.9244272e+00  3.1522661e-04 -4.0053099e-01 -1.9173150e+00\n",
      "  1.5552148e-01 -3.6715269e-01 -1.4460455e+00 -1.4769205e-01\n",
      " -2.2747327e-01 -1.2303137e+00 -5.8133252e-02 -2.1094809e-01\n",
      " -1.3109601e+00 -1.0870449e-02 -2.3327269e-01 -1.4283714e+00\n",
      "  5.6269735e-02 -2.4413975e-01 -1.2937095e+00]\n",
      "data: [ 1.9147266e-02 -5.4116830e-02 -2.4669214e-01  3.2639254e-02\n",
      " -1.9792415e-01 -6.5725142e-01 -4.2179629e-02 -3.7693363e-01\n",
      " -1.3859426e+00 -1.8518695e-01 -4.3586558e-01 -1.6924486e+00\n",
      " -3.6328340e-01 -5.5973411e-01 -2.1556082e+00 -1.8965784e-01\n",
      " -6.5803838e-01 -1.5524602e+00  4.5896597e-02 -6.8495440e-01\n",
      " -1.3562716e+00 -7.6256921e-03 -6.2608236e-01 -1.4089706e+00\n",
      " -6.1112791e-03 -7.5642967e-01 -1.5252047e+00 -1.4087346e-01\n",
      " -5.4934335e-01 -1.4647602e+00 -4.9392883e-02 -6.0777271e-01\n",
      " -1.4437096e+00 -5.4945245e-02 -5.8624727e-01 -1.5439897e+00\n",
      "  7.2181247e-02 -6.1235338e-01 -1.5956835e+00 -4.1973993e-02\n",
      " -4.6494207e-01 -1.2903390e+00 -1.5428245e-01 -2.4260321e-01\n",
      " -1.9244272e+00  3.1522661e-04 -4.0053099e-01 -1.9173150e+00\n",
      "  1.5552148e-01 -3.6715272e-01 -1.4460455e+00 -1.4769205e-01\n",
      " -2.2747327e-01 -1.2303137e+00 -5.8133256e-02 -2.1094808e-01\n",
      " -1.3109601e+00 -1.0870449e-02 -2.3327269e-01 -1.4283714e+00\n",
      "  5.6269735e-02 -2.4413975e-01 -1.2937095e+00  1.5000001e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0098, -0.0853, -0.2560,  ...,  0.0376, -0.2727, -1.3140],\n",
      "        [ 0.0098, -0.0853, -0.2560,  ...,  0.0376, -0.2727, -1.3140],\n",
      "        [ 0.0098, -0.0853, -0.2560,  ...,  0.0376, -0.2727, -1.3140],\n",
      "        ...,\n",
      "        [-0.1574,  0.4252, -0.1345,  ..., -0.7131,  0.9080, -0.3805],\n",
      "        [-0.1618, -0.1328,  0.5836,  ..., -0.2457,  0.6479,  0.2323],\n",
      "        [-0.1618, -0.1328,  0.5836,  ..., -0.2457,  0.6479,  0.2323]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00979756 -0.08534234 -0.25604704  0.02874798 -0.22511514 -0.67324466\n",
      " -0.05876075 -0.40816054 -1.4258978  -0.20005603 -0.47097313 -1.7231925\n",
      " -0.36741108 -0.5844661  -2.1983135  -0.1915929  -0.69170463 -1.585856\n",
      "  0.02409086 -0.72250533 -1.3912654  -0.0267984  -0.65905064 -1.4467816\n",
      " -0.02993965 -0.79182    -1.5639114  -0.14868918 -0.5874989  -1.5006468\n",
      " -0.0665268  -0.6413318  -1.4755564  -0.07915774 -0.61679846 -1.569772\n",
      "  0.04977964 -0.6384229  -1.6161313  -0.06039969 -0.50360143 -1.3292058\n",
      " -0.17100748 -0.27700076 -1.961304   -0.02174044 -0.42962658 -1.9604459\n",
      "  0.13224563 -0.3985262  -1.4700732  -0.1617785  -0.26724127 -1.2640367\n",
      " -0.08277406 -0.2462757  -1.3455639  -0.03679326 -0.2598687  -1.4612234\n",
      "  0.03759938 -0.2726673  -1.3140106 ]\n",
      "data: [ 0.00979756 -0.08534234 -0.25604704  0.02874798 -0.22511512 -0.67324466\n",
      " -0.05876075 -0.40816057 -1.4258978  -0.20005603 -0.47097313 -1.7231925\n",
      " -0.36741108 -0.5844661  -2.1983135  -0.1915929  -0.69170463 -1.585856\n",
      "  0.02409086 -0.72250533 -1.3912654  -0.0267984  -0.6590507  -1.4467816\n",
      " -0.02993965 -0.79182    -1.5639114  -0.14868918 -0.5874989  -1.5006468\n",
      " -0.0665268  -0.6413318  -1.4755564  -0.07915774 -0.61679846 -1.569772\n",
      "  0.04977964 -0.6384229  -1.6161313  -0.06039969 -0.50360143 -1.3292058\n",
      " -0.17100748 -0.27700076 -1.9613041  -0.02174044 -0.42962658 -1.9604459\n",
      "  0.13224563 -0.3985262  -1.4700732  -0.1617785  -0.26724127 -1.2640367\n",
      " -0.08277406 -0.2462757  -1.345564   -0.03679326 -0.2598687  -1.4612232\n",
      "  0.03759938 -0.2726673  -1.3140106   0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0216, -0.0880, -0.2518,  ...,  0.0513, -0.2748, -1.2857],\n",
      "        [ 0.0216, -0.0880, -0.2518,  ...,  0.0513, -0.2748, -1.2857],\n",
      "        [ 0.0216, -0.0880, -0.2518,  ...,  0.0513, -0.2748, -1.2857],\n",
      "        ...,\n",
      "        [-0.1195,  0.4045, -0.1611,  ..., -0.7076,  0.9184, -0.4413],\n",
      "        [-0.1421, -0.1548,  0.5825,  ..., -0.2539,  0.6094,  0.2276],\n",
      "        [-0.1421, -0.1548,  0.5825,  ..., -0.2539,  0.6094,  0.2276]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02155556 -0.08799843 -0.2517904   0.04513012 -0.2180867  -0.64466417\n",
      " -0.04583708 -0.40768188 -1.4035848  -0.18711841 -0.46781278 -1.7025702\n",
      " -0.34910795 -0.5780374  -2.1797757  -0.17532319 -0.69717467 -1.5660269\n",
      "  0.03448601 -0.7331929  -1.3942357  -0.01892933 -0.67028666 -1.4487761\n",
      " -0.02165741 -0.8118148  -1.5674026  -0.13098541 -0.5978011  -1.4759021\n",
      " -0.05283545 -0.65151906 -1.4540899  -0.06449672 -0.6256132  -1.5474209\n",
      "  0.06131159 -0.6542486  -1.5878042  -0.04216198 -0.50440454 -1.3060325\n",
      " -0.16650909 -0.2772661  -1.9799389  -0.00568667 -0.4374049  -1.9846755\n",
      "  0.14840314 -0.40364113 -1.4440768  -0.14934447 -0.27248055 -1.2389894\n",
      " -0.06892657 -0.24989572 -1.3222842  -0.02763642 -0.262941   -1.4388489\n",
      "  0.05125112 -0.27482265 -1.2856978 ]\n",
      "data: [ 0.02155556 -0.08799843 -0.2517904   0.04513012 -0.2180867  -0.64466417\n",
      " -0.04583708 -0.40768188 -1.403585   -0.18711841 -0.46781278 -1.7025702\n",
      " -0.34910792 -0.5780374  -2.1797757  -0.17532319 -0.69717467 -1.5660269\n",
      "  0.03448601 -0.7331929  -1.3942357  -0.01892933 -0.67028666 -1.4487761\n",
      " -0.02165741 -0.8118148  -1.5674026  -0.13098541 -0.5978011  -1.4759021\n",
      " -0.05283545 -0.65151906 -1.4540898  -0.06449672 -0.6256132  -1.5474209\n",
      "  0.06131159 -0.6542486  -1.5878043  -0.04216198 -0.50440454 -1.3060325\n",
      " -0.16650909 -0.2772661  -1.9799389  -0.00568667 -0.4374049  -1.9846756\n",
      "  0.14840314 -0.40364113 -1.4440769  -0.14934447 -0.27248055 -1.2389894\n",
      " -0.06892657 -0.24989572 -1.3222842  -0.02763642 -0.262941   -1.4388489\n",
      "  0.05125112 -0.27482265 -1.2856978   0.17      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0267, -0.0745, -0.2518,  ...,  0.0616, -0.2637, -1.2875],\n",
      "        [ 0.0267, -0.0745, -0.2518,  ...,  0.0616, -0.2637, -1.2875],\n",
      "        [ 0.0267, -0.0745, -0.2518,  ...,  0.0616, -0.2637, -1.2875],\n",
      "        ...,\n",
      "        [-0.1430,  0.3697, -0.1058,  ..., -0.7723,  0.8638, -0.3621],\n",
      "        [-0.1319, -0.1247,  0.5793,  ..., -0.2169,  0.6399,  0.2192],\n",
      "        [-0.1319, -0.1247,  0.5793,  ..., -0.2169,  0.6399,  0.2192]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.66596861e-02 -7.45211542e-02 -2.51809657e-01  4.72224094e-02\n",
      " -2.08643422e-01 -6.46659255e-01 -4.37846184e-02 -3.98203969e-01\n",
      " -1.40419137e+00 -1.87445104e-01 -4.59539860e-01 -1.70517600e+00\n",
      " -3.55117470e-01 -5.74024081e-01 -2.17981100e+00 -1.74618125e-01\n",
      " -6.85161531e-01 -1.56706154e+00  4.13789377e-02 -7.20779181e-01\n",
      " -1.38343227e+00 -1.24976411e-02 -6.58199966e-01 -1.43770921e+00\n",
      " -1.54820755e-02 -7.98376083e-01 -1.55653560e+00 -1.28344148e-01\n",
      " -5.83409846e-01 -1.47696590e+00 -4.74668518e-02 -6.39338195e-01\n",
      " -1.45373344e+00 -5.79559281e-02 -6.14526093e-01 -1.54878187e+00\n",
      "  7.01190755e-02 -6.42247856e-01 -1.59062076e+00 -3.64625007e-02\n",
      " -4.92152184e-01 -1.30483210e+00 -1.58483982e-01 -2.65671939e-01\n",
      " -1.97217965e+00  1.87456608e-03 -4.26257014e-01 -1.97427094e+00\n",
      "  1.58999085e-01 -3.93020093e-01 -1.44457865e+00 -1.43186539e-01\n",
      " -2.58093983e-01 -1.23919046e+00 -6.07734695e-02 -2.37279266e-01\n",
      " -1.32253408e+00 -1.72721371e-02 -2.52205312e-01 -1.43937087e+00\n",
      "  6.15795702e-02 -2.63724387e-01 -1.28746521e+00]\n",
      "data: [ 2.66596861e-02 -7.45211542e-02 -2.51809657e-01  4.72224094e-02\n",
      " -2.08643422e-01 -6.46659255e-01 -4.37846184e-02 -3.98203969e-01\n",
      " -1.40419149e+00 -1.87445104e-01 -4.59539860e-01 -1.70517588e+00\n",
      " -3.55117440e-01 -5.74024081e-01 -2.17981100e+00 -1.74618125e-01\n",
      " -6.85161531e-01 -1.56706166e+00  4.13789377e-02 -7.20779181e-01\n",
      " -1.38343227e+00 -1.24976411e-02 -6.58200026e-01 -1.43770921e+00\n",
      " -1.54820755e-02 -7.98376083e-01 -1.55653560e+00 -1.28344148e-01\n",
      " -5.83409846e-01 -1.47696590e+00 -4.74668518e-02 -6.39338195e-01\n",
      " -1.45373356e+00 -5.79559281e-02 -6.14526093e-01 -1.54878187e+00\n",
      "  7.01190755e-02 -6.42247856e-01 -1.59062076e+00 -3.64625007e-02\n",
      " -4.92152184e-01 -1.30483210e+00 -1.58483982e-01 -2.65671939e-01\n",
      " -1.97217977e+00  1.87456608e-03 -4.26257014e-01 -1.97427094e+00\n",
      "  1.58999085e-01 -3.93020093e-01 -1.44457865e+00 -1.43186539e-01\n",
      " -2.58093983e-01 -1.23919046e+00 -6.07734695e-02 -2.37279266e-01\n",
      " -1.32253408e+00 -1.72721371e-02 -2.52205312e-01 -1.43937087e+00\n",
      "  6.15795702e-02 -2.63724387e-01 -1.28746521e+00  1.80000007e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0228, -0.0937, -0.2587,  ...,  0.0648, -0.2806, -1.3090],\n",
      "        [ 0.0228, -0.0937, -0.2587,  ...,  0.0648, -0.2806, -1.3090],\n",
      "        [ 0.0228, -0.0937, -0.2587,  ...,  0.0648, -0.2806, -1.3090],\n",
      "        ...,\n",
      "        [-0.1297,  0.3927, -0.1327,  ..., -0.7385,  0.8841, -0.3854],\n",
      "        [-0.1351, -0.1126,  0.5834,  ..., -0.2276,  0.6569,  0.2227],\n",
      "        [-0.1351, -0.1126,  0.5834,  ..., -0.2276,  0.6569,  0.2227]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.2790048e-02 -9.3665145e-02 -2.5866684e-01  4.3068234e-02\n",
      " -2.3542109e-01 -6.6946101e-01 -3.4695223e-02 -4.1799769e-01\n",
      " -1.4127164e+00 -1.7603922e-01 -4.7865656e-01 -1.7165400e+00\n",
      " -3.4636995e-01 -6.0100192e-01 -2.1843691e+00 -1.8135086e-01\n",
      " -6.9709468e-01 -1.5789149e+00  5.4150708e-02 -7.2588485e-01\n",
      " -1.3840250e+00  3.2157451e-04 -6.6703862e-01 -1.4360014e+00\n",
      " -1.4551580e-03 -7.9746968e-01 -1.5539261e+00 -1.3321531e-01\n",
      " -5.9047043e-01 -1.4901447e+00 -4.2138375e-02 -6.4883173e-01\n",
      " -1.4690961e+00 -4.8363209e-02 -6.2435633e-01 -1.5657111e+00\n",
      "  7.7404074e-02 -6.5400577e-01 -1.6161094e+00 -3.5828650e-02\n",
      " -5.0423545e-01 -1.3142766e+00 -1.4959037e-01 -2.7820212e-01\n",
      " -1.9543848e+00  7.4728429e-03 -4.3810919e-01 -1.9489222e+00\n",
      "  1.6223219e-01 -4.0363866e-01 -1.4668273e+00 -1.4351529e-01\n",
      " -2.6674515e-01 -1.2510531e+00 -5.1954962e-02 -2.4737945e-01\n",
      " -1.3315669e+00 -3.4103468e-03 -2.6958123e-01 -1.4485669e+00\n",
      "  6.4845011e-02 -2.8060073e-01 -1.3090119e+00]\n",
      "data: [ 2.2790048e-02 -9.3665145e-02 -2.5866684e-01  4.3068234e-02\n",
      " -2.3542109e-01 -6.6946101e-01 -3.4695223e-02 -4.1799772e-01\n",
      " -1.4127164e+00 -1.7603922e-01 -4.7865659e-01 -1.7165399e+00\n",
      " -3.4636992e-01 -6.0100192e-01 -2.1843691e+00 -1.8135086e-01\n",
      " -6.9709468e-01 -1.5789150e+00  5.4150712e-02 -7.2588485e-01\n",
      " -1.3840250e+00  3.2157451e-04 -6.6703868e-01 -1.4360014e+00\n",
      " -1.4551580e-03 -7.9746974e-01 -1.5539261e+00 -1.3321531e-01\n",
      " -5.9047043e-01 -1.4901446e+00 -4.2138375e-02 -6.4883173e-01\n",
      " -1.4690961e+00 -4.8363209e-02 -6.2435633e-01 -1.5657113e+00\n",
      "  7.7404074e-02 -6.5400577e-01 -1.6161094e+00 -3.5828650e-02\n",
      " -5.0423545e-01 -1.3142766e+00 -1.4959037e-01 -2.7820212e-01\n",
      " -1.9543848e+00  7.4728429e-03 -4.3810922e-01 -1.9489222e+00\n",
      "  1.6223219e-01 -4.0363866e-01 -1.4668273e+00 -1.4351529e-01\n",
      " -2.6674515e-01 -1.2510531e+00 -5.1954962e-02 -2.4737945e-01\n",
      " -1.3315669e+00 -3.4103468e-03 -2.6958123e-01 -1.4485669e+00\n",
      "  6.4845011e-02 -2.8060073e-01 -1.3090119e+00  1.9000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B320>\n",
      "tensor([[ 0.0187, -0.1118, -0.2623,  ...,  0.0642, -0.2976, -1.3198],\n",
      "        [ 0.0187, -0.1118, -0.2623,  ...,  0.0642, -0.2976, -1.3198],\n",
      "        [ 0.0187, -0.1118, -0.2623,  ...,  0.0642, -0.2976, -1.3198],\n",
      "        ...,\n",
      "        [-0.1043,  0.4404, -0.1511,  ..., -0.6623,  0.9450, -0.4459],\n",
      "        [-0.1338, -0.1062,  0.5976,  ..., -0.2350,  0.6534,  0.2357],\n",
      "        [-0.1338, -0.1062,  0.5976,  ..., -0.2350,  0.6534,  0.2357]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0187417  -0.11178748 -0.26233035  0.03975062 -0.25822473 -0.6740254\n",
      " -0.02708629 -0.43964612 -1.4140104  -0.16778842 -0.49947345 -1.7227721\n",
      " -0.34083283 -0.62855387 -2.187072   -0.18853998 -0.7117657  -1.5886711\n",
      "  0.06620666 -0.7379508  -1.3842821   0.00985072 -0.68353266 -1.4328368\n",
      "  0.00662347 -0.80835205 -1.550938   -0.13737962 -0.60060203 -1.4975445\n",
      " -0.03916363 -0.66250694 -1.4793253  -0.04178505 -0.6390441  -1.5775918\n",
      "  0.07832319 -0.67332995 -1.6340481  -0.03346999 -0.5149359  -1.3179355\n",
      " -0.14764035 -0.2897334  -1.9508648   0.00982589 -0.4534397  -1.939649\n",
      "  0.161116   -0.41567272 -1.4799676  -0.14579985 -0.27470666 -1.2561733\n",
      " -0.04475991 -0.2569614  -1.333394    0.00630728 -0.28739962 -1.4498261\n",
      "  0.06424299 -0.29758084 -1.3197663 ]\n",
      "data: [ 0.0187417  -0.11178747 -0.26233035  0.03975062 -0.25822473 -0.6740254\n",
      " -0.02708629 -0.43964612 -1.4140105  -0.16778842 -0.49947345 -1.7227721\n",
      " -0.34083283 -0.62855387 -2.187072   -0.18853998 -0.71176565 -1.5886711\n",
      "  0.06620666 -0.7379508  -1.3842821   0.00985072 -0.68353266 -1.4328368\n",
      "  0.00662347 -0.80835205 -1.550938   -0.13737962 -0.60060203 -1.4975445\n",
      " -0.03916363 -0.66250694 -1.4793253  -0.04178505 -0.6390441  -1.5775917\n",
      "  0.07832319 -0.67332995 -1.6340481  -0.03346999 -0.5149359  -1.3179355\n",
      " -0.14764035 -0.2897334  -1.9508649   0.00982589 -0.4534397  -1.9396491\n",
      "  0.161116   -0.41567272 -1.4799676  -0.14579985 -0.27470666 -1.2561733\n",
      " -0.04475991 -0.2569614  -1.333394    0.00630728 -0.28739962 -1.449826\n",
      "  0.06424299 -0.29758084 -1.3197663   0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.041 3.037 3.041 ... 3.007 0.    0.   ]\n",
      " [3.03  3.03  3.029 ... 2.993 2.996 2.996]\n",
      " [3.013 3.014 3.013 ... 2.987 2.986 2.986]\n",
      " ...\n",
      " [2.783 2.772 2.774 ... 2.774 2.772 2.772]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]\n",
      " [2.772 2.762 2.762 ... 2.763 2.76  2.76 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 1. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EC24128>\n",
      "tensor([[ 0.0107, -0.1209, -0.2329,  ...,  0.0553, -0.3046, -1.2934],\n",
      "        [ 0.0107, -0.1209, -0.2329,  ...,  0.0553, -0.3046, -1.2934],\n",
      "        [ 0.0107, -0.1209, -0.2329,  ...,  0.0553, -0.3046, -1.2934],\n",
      "        ...,\n",
      "        [-0.0867,  0.4630, -0.1521,  ..., -0.6260,  0.9501, -0.4395],\n",
      "        [-0.1320, -0.0913,  0.6008,  ..., -0.2338,  0.6414,  0.2619],\n",
      "        [-0.1320, -0.0913,  0.6008,  ..., -0.2338,  0.6414,  0.2619]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.0747355e-02 -1.2086733e-01 -2.3288471e-01  3.2391179e-02\n",
      " -2.6641792e-01 -6.3673991e-01 -3.3183910e-02 -4.5182100e-01\n",
      " -1.3842502e+00 -1.7543073e-01 -5.1145267e-01 -1.6959044e+00\n",
      " -3.4823155e-01 -6.4238441e-01 -2.1628923e+00 -1.9892603e-01\n",
      " -7.2207576e-01 -1.5678689e+00  6.1579391e-02 -7.5168908e-01\n",
      " -1.3656708e+00  1.7198026e-03 -6.9966501e-01 -1.4117060e+00\n",
      " -2.3851916e-03 -8.2666659e-01 -1.5310097e+00 -1.4534575e-01\n",
      " -6.1029077e-01 -1.4734609e+00 -4.6659730e-02 -6.7489481e-01\n",
      " -1.4566370e+00 -4.8249148e-02 -6.5206885e-01 -1.5562258e+00\n",
      "  6.8043992e-02 -6.9206911e-01 -1.6110382e+00 -3.8721584e-02\n",
      " -5.2034068e-01 -1.2929678e+00 -1.5948184e-01 -2.9531658e-01\n",
      " -1.9395802e+00  2.1195337e-03 -4.6439105e-01 -1.9291844e+00\n",
      "  1.5314448e-01 -4.2565900e-01 -1.4560546e+00 -1.5621090e-01\n",
      " -2.7900887e-01 -1.2293390e+00 -5.0608814e-02 -2.6199806e-01\n",
      " -1.3066518e+00 -1.1245906e-03 -2.9575279e-01 -1.4229956e+00\n",
      "  5.5306979e-02 -3.0463696e-01 -1.2933563e+00]\n",
      "data: [-5.03 -1.58  0.23 -4.97 -1.29  0.29 -4.84 -0.89  0.34 -4.82 -0.63  0.59\n",
      " -4.75 -0.49  0.73 -4.73 -0.96  0.49 -4.72 -0.89  0.82 -4.7  -0.68  0.82\n",
      " -4.71 -0.55  0.89 -4.79 -1.05  0.43 -4.75 -0.88  0.59 -4.8  -0.6   0.6\n",
      " -4.8  -0.5   0.62 -4.84 -1.08  0.43 -4.81 -0.87  0.41 -4.85 -0.69  0.52\n",
      " -4.96 -0.55  0.68 -4.91 -1.06  0.31 -4.89 -0.89  0.34 -4.91 -0.81  0.43\n",
      " -4.99 -0.63  0.6   0.  ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[-0.0220, -0.1485, -0.0824,  ...,  0.1750, -0.3778,  0.3966],\n",
      "        [-0.0220, -0.1485, -0.0824,  ...,  0.1750, -0.3778,  0.3966],\n",
      "        [-0.0220, -0.1485, -0.0824,  ...,  0.1750, -0.3778,  0.3966],\n",
      "        ...,\n",
      "        [ 0.5679, -0.2300,  0.3031,  ..., -0.3848, -0.0208, -1.0176],\n",
      "        [ 0.5208, -0.0399,  0.4498,  ..., -1.3733,  0.3408,  0.2080],\n",
      "        [ 0.5208, -0.0399,  0.4498,  ..., -1.3733,  0.3408,  0.2080]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.02203892 -0.14847013 -0.08239771 -0.09786526 -0.19388586  0.14393665\n",
      " -0.13162321 -0.29562902  0.41966397 -0.16307239 -0.394193    0.51031625\n",
      " -0.17947794 -0.48861048  0.64644164 -0.13204214 -0.34152865  0.3038357\n",
      " -0.01853922 -0.40470243  0.74248284 -0.04276893 -0.46830335  0.81810933\n",
      " -0.08977643 -0.4617856   0.850975   -0.04722678 -0.32737818  0.2729063\n",
      " -0.0646996  -0.4193705   0.36396503 -0.06307495 -0.45561704  0.4024707\n",
      " -0.0589146  -0.51507384  0.43600404  0.02221567 -0.29364443  0.25402272\n",
      "  0.03393324 -0.3802956   0.5278718   0.01270431 -0.41187653  0.5707005\n",
      "  0.06138134 -0.46626386  0.41165525  0.05680291 -0.22590259  0.24474226\n",
      "  0.11416757 -0.280189    0.32085013  0.1513608  -0.35925826  0.38467985\n",
      "  0.17500323 -0.37775344  0.39664453]\n",
      "init: [-0.02203892 -0.14847013 -0.08239771 -0.09786526 -0.19388586  0.14393665\n",
      " -0.13162321 -0.29562902  0.41966397 -0.16307239 -0.394193    0.51031625\n",
      " -0.17947794 -0.48861048  0.64644164 -0.13204214 -0.34152865  0.3038357\n",
      " -0.01853922 -0.40470243  0.74248284 -0.04276893 -0.46830335  0.81810933\n",
      " -0.08977643 -0.4617856   0.850975   -0.04722678 -0.32737818  0.2729063\n",
      " -0.0646996  -0.4193705   0.36396503 -0.06307495 -0.45561704  0.4024707\n",
      " -0.0589146  -0.51507384  0.43600404  0.02221567 -0.29364443  0.25402272\n",
      "  0.03393324 -0.3802956   0.5278718   0.01270431 -0.41187653  0.5707005\n",
      "  0.06138134 -0.46626386  0.41165525  0.05680291 -0.22590259  0.24474226\n",
      "  0.11416757 -0.280189    0.32085013  0.1513608  -0.35925826  0.38467985\n",
      "  0.17500323 -0.37775344  0.39664453]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [-0.02203892 -0.14847013 -0.08239772 -0.09786525 -0.19388586  0.14393665\n",
      " -0.13162321 -0.29562902  0.41966397 -0.16307239 -0.394193    0.51031625\n",
      " -0.17947794 -0.48861045  0.64644164 -0.13204214 -0.34152865  0.3038357\n",
      " -0.01853922 -0.40470243  0.74248284 -0.04276893 -0.46830332  0.81810933\n",
      " -0.08977643 -0.4617856   0.850975   -0.04722678 -0.32737818  0.2729063\n",
      " -0.0646996  -0.4193705   0.36396503 -0.06307495 -0.45561704  0.4024707\n",
      " -0.05891461 -0.51507384  0.43600404  0.02221567 -0.29364443  0.25402272\n",
      "  0.03393324 -0.3802956   0.5278718   0.01270431 -0.41187653  0.5707005\n",
      "  0.06138134 -0.46626386  0.41165525  0.05680291 -0.2259026   0.24474226\n",
      "  0.11416758 -0.280189    0.32085013  0.1513608  -0.35925826  0.38467988\n",
      "  0.17500323 -0.37775344  0.3966445   0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[-0.1396,  0.1728,  0.0422,  ..., -0.3158, -0.1302,  0.3634],\n",
      "        [-0.1396,  0.1728,  0.0422,  ..., -0.3158, -0.1302,  0.3634],\n",
      "        [-0.1396,  0.1728,  0.0422,  ..., -0.3158, -0.1302,  0.3634],\n",
      "        ...,\n",
      "        [-0.1515,  0.2714, -0.3596,  ...,  0.6372,  1.0794, -1.0275],\n",
      "        [ 0.2300,  0.0337, -0.0611,  ...,  0.2862,  0.4354, -0.1735],\n",
      "        [ 0.2300,  0.0337, -0.0611,  ...,  0.2862,  0.4354, -0.1735]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.13957773  0.17277494  0.04215441 -0.37018335  0.09502184 -0.17346565\n",
      " -0.63497055 -0.05770025  0.0745471  -0.8074146  -0.18253088  0.21732225\n",
      " -0.9059439  -0.28141698  0.42403263 -0.6218772  -0.05763263  0.05462362\n",
      " -0.8783119  -0.21616328 -0.00096289 -0.9100226  -0.2877568   0.09214177\n",
      " -0.84405065 -0.34222844  0.1876138  -0.52265716 -0.0420748   0.0238563\n",
      " -0.70055234 -0.20736867  0.24020393 -0.6681517  -0.28982118  0.33891696\n",
      " -0.6098287  -0.37617412  0.40533882 -0.47043782 -0.03316161 -0.00552755\n",
      " -0.56690955 -0.15362129  0.35488153 -0.54154927 -0.23667231  0.38227606\n",
      " -0.45334262 -0.2986047   0.36193162 -0.39465392  0.03376476  0.05843648\n",
      " -0.4472692  -0.01479521  0.18920453 -0.38031605 -0.08481315  0.25030082\n",
      " -0.31580806 -0.13021559  0.36344165]\n",
      "data: [-0.13957773  0.17277494  0.04215441 -0.37018335  0.09502184 -0.17346565\n",
      " -0.63497055 -0.05770025  0.0745471  -0.80741465 -0.18253088  0.21732226\n",
      " -0.90594393 -0.28141698  0.42403263 -0.6218772  -0.05763263  0.05462362\n",
      " -0.8783119  -0.21616328 -0.00096289 -0.91002256 -0.2877568   0.09214177\n",
      " -0.84405065 -0.34222844  0.18761379 -0.52265716 -0.0420748   0.02385629\n",
      " -0.70055234 -0.20736867  0.24020393 -0.6681517  -0.28982118  0.33891696\n",
      " -0.6098287  -0.37617412  0.40533882 -0.47043782 -0.03316161 -0.00552755\n",
      " -0.56690955 -0.15362129  0.35488153 -0.54154927 -0.23667231  0.3822761\n",
      " -0.45334262 -0.2986047   0.36193162 -0.39465392  0.03376476  0.05843648\n",
      " -0.4472692  -0.01479521  0.18920451 -0.38031605 -0.08481315  0.25030082\n",
      " -0.31580806 -0.13021559  0.36344165  0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[-0.0271, -0.0941,  0.2410,  ..., -0.6211, -0.3614,  0.1077],\n",
      "        [-0.0271, -0.0941,  0.2410,  ..., -0.6211, -0.3614,  0.1077],\n",
      "        [-0.0271, -0.0941,  0.2410,  ..., -0.6211, -0.3614,  0.1077],\n",
      "        ...,\n",
      "        [ 0.5215, -0.0390, -0.1046,  ...,  0.4457,  0.5467, -0.1850],\n",
      "        [ 0.2409,  0.2926, -0.0665,  ..., -0.3611,  1.0144, -0.5421],\n",
      "        [ 0.2409,  0.2926, -0.0665,  ..., -0.3611,  1.0144, -0.5421]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.02709696 -0.09411085  0.24103296 -0.24309117 -0.27189466 -0.18392888\n",
      " -0.44828948 -0.46137208 -0.02688396 -0.640167   -0.5873549   0.0495574\n",
      " -0.8116597  -0.6935066   0.19885533 -0.49508217 -0.5097755   0.06252687\n",
      " -0.73562074 -0.6746664   0.0670765  -0.8162395  -0.75365245  0.13117644\n",
      " -0.89389586 -0.786422    0.22028789 -0.4589924  -0.44110778  0.0250982\n",
      " -0.6695757  -0.6083696   0.16891441 -0.73834324 -0.67547274  0.22485964\n",
      " -0.8033116  -0.7169725   0.27942303 -0.44602874 -0.37857354 -0.03862771\n",
      " -0.62446344 -0.5133434   0.14889494 -0.68049085 -0.5716876   0.17974237\n",
      " -0.7649473  -0.60169005  0.19630182 -0.40320346 -0.27849144 -0.01164126\n",
      " -0.551533   -0.33216292  0.03468663 -0.5556865  -0.3687646   0.07310601\n",
      " -0.6211406  -0.36139113  0.10771816]\n",
      "data: [-0.02709696 -0.09411085  0.24103296 -0.24309117 -0.27189466 -0.18392888\n",
      " -0.44828948 -0.46137208 -0.02688396 -0.640167   -0.5873549   0.0495574\n",
      " -0.8116597  -0.6935066   0.19885533 -0.49508217 -0.5097755   0.06252687\n",
      " -0.73562074 -0.67466646  0.0670765  -0.8162395  -0.7536524   0.13117644\n",
      " -0.89389586 -0.786422    0.22028789 -0.4589924  -0.44110778  0.0250982\n",
      " -0.66957563 -0.6083696   0.16891441 -0.7383432  -0.67547274  0.22485964\n",
      " -0.8033116  -0.71697253  0.27942303 -0.44602874 -0.37857354 -0.03862771\n",
      " -0.62446344 -0.5133434   0.14889494 -0.68049085 -0.5716876   0.17974238\n",
      " -0.7649473  -0.60169005  0.19630182 -0.40320346 -0.27849144 -0.01164126\n",
      " -0.551533   -0.33216295  0.03468663 -0.5556865  -0.3687646   0.07310601\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.6211406  -0.36139116  0.10771816  0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[ 0.0346, -0.0431,  0.2035,  ..., -0.8331, -0.2051,  0.1267],\n",
      "        [ 0.0346, -0.0431,  0.2035,  ..., -0.8331, -0.2051,  0.1267],\n",
      "        [ 0.0346, -0.0431,  0.2035,  ..., -0.8331, -0.2051,  0.1267],\n",
      "        ...,\n",
      "        [ 0.2970, -0.1191, -0.3571,  ...,  0.2327,  0.5403, -0.8221],\n",
      "        [ 0.1940, -0.0607,  0.3236,  ...,  0.2799,  0.2956,  0.0417],\n",
      "        [ 0.1940, -0.0607,  0.3236,  ...,  0.2799,  0.2956,  0.0417]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03457014 -0.04305787  0.20346849 -0.17992963 -0.19559932 -0.29984015\n",
      " -0.33618072 -0.31490034 -0.03584428 -0.5534885  -0.3869983   0.03581378\n",
      " -0.7674264  -0.43693352  0.18383887 -0.47855178 -0.3776157   0.08695358\n",
      " -0.79636085 -0.51042867 -0.06448172 -0.8796419  -0.55464244  0.00234155\n",
      " -0.93657255 -0.56241393  0.12086131 -0.48752394 -0.32242656  0.05993657\n",
      " -0.7270529  -0.43941343  0.2156211  -0.8118248  -0.48719162  0.25791103\n",
      " -0.91551864 -0.49007887  0.33272117 -0.50137246 -0.25437474 -0.02476826\n",
      " -0.70288897 -0.38335782  0.23461498 -0.7993051  -0.40497202  0.26635477\n",
      " -0.9332808  -0.41187668  0.23643339 -0.46781138 -0.17284882  0.01233403\n",
      " -0.67046857 -0.20793796  0.08326996 -0.7182478  -0.23556037  0.13146415\n",
      " -0.8330885  -0.20514593  0.12672427]\n",
      "data: [ 0.03457014 -0.04305787  0.2034685  -0.17992964 -0.19559933 -0.29984015\n",
      " -0.33618072 -0.31490034 -0.03584428 -0.5534885  -0.3869983   0.03581378\n",
      " -0.7674264  -0.43693352  0.18383889 -0.47855178 -0.3776157   0.08695358\n",
      " -0.79636085 -0.51042867 -0.06448172 -0.8796419  -0.55464244  0.00234155\n",
      " -0.93657255 -0.56241393  0.12086131 -0.48752394 -0.32242656  0.05993657\n",
      " -0.7270529  -0.43941343  0.21562108 -0.8118248  -0.48719162  0.25791103\n",
      " -0.91551864 -0.49007884  0.33272117 -0.50137246 -0.25437474 -0.02476826\n",
      " -0.70288897 -0.38335782  0.23461498 -0.79930514 -0.404972    0.26635477\n",
      " -0.93328077 -0.41187668  0.23643339 -0.4678114  -0.17284882  0.01233403\n",
      " -0.67046857 -0.20793797  0.08326996 -0.7182478  -0.23556037  0.13146415\n",
      " -0.8330885  -0.20514593  0.12672427  0.04      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[-0.0947, -0.1085,  0.1477,  ..., -0.7650, -0.3682,  0.0684],\n",
      "        [-0.0947, -0.1085,  0.1477,  ..., -0.7650, -0.3682,  0.0684],\n",
      "        [-0.0947, -0.1085,  0.1477,  ..., -0.7650, -0.3682,  0.0684],\n",
      "        ...,\n",
      "        [-0.0173, -0.2614, -0.8109,  ..., -0.3477,  0.3615, -1.1332],\n",
      "        [ 0.3117, -0.0513,  0.5699,  ...,  0.0313,  0.4675, -0.1229],\n",
      "        [ 0.3117, -0.0513,  0.5699,  ...,  0.0313,  0.4675, -0.1229]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.09465297 -0.10845713  0.1477142  -0.32122758 -0.27936286 -0.29131445\n",
      " -0.5112361  -0.448784   -0.08841005 -0.7121521  -0.5644694  -0.00207834\n",
      " -0.90807056 -0.6548534   0.15094697 -0.58131677 -0.51231176  0.01526028\n",
      " -0.8247256  -0.6691633   0.0357816  -0.9067219  -0.74154055  0.11398569\n",
      " -0.98316336 -0.7562787   0.21414855 -0.5566673  -0.448254   -0.02394277\n",
      " -0.76501083 -0.60518694  0.14704004 -0.8338218  -0.65828085  0.20906919\n",
      " -0.90669966 -0.6954952   0.27248085 -0.5446466  -0.38393348 -0.10361654\n",
      " -0.7282286  -0.52442425  0.13578683 -0.7945708  -0.56868297  0.1707415\n",
      " -0.8864358  -0.58796513  0.1679045  -0.5088846  -0.28435725 -0.06800842\n",
      " -0.6625738  -0.33823848 -0.00510186 -0.6823885  -0.3776849   0.04162137\n",
      " -0.76501966 -0.36816293  0.06839465]\n",
      "data: [-0.09465297 -0.10845713  0.1477142  -0.32122758 -0.27936286 -0.29131445\n",
      " -0.5112361  -0.448784   -0.08841005 -0.7121521  -0.5644694  -0.00207834\n",
      " -0.9080705  -0.65485346  0.15094697 -0.58131677 -0.51231176  0.01526028\n",
      " -0.8247256  -0.6691633   0.0357816  -0.9067219  -0.74154055  0.11398569\n",
      " -0.98316336 -0.7562787   0.21414857 -0.5566673  -0.448254   -0.02394277\n",
      " -0.76501083 -0.60518694  0.14704004 -0.8338218  -0.65828085  0.20906919\n",
      " -0.90669966 -0.69549525  0.27248085 -0.5446466  -0.38393348 -0.10361654\n",
      " -0.7282286  -0.52442425  0.13578683 -0.79457074 -0.56868297  0.1707415\n",
      " -0.88643575 -0.58796513  0.1679045  -0.5088846  -0.28435725 -0.06800842\n",
      " -0.6625739  -0.33823848 -0.00510186 -0.6823885  -0.3776849   0.04162137\n",
      " -0.76501966 -0.36816293  0.06839465  0.05      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[ 0.0350,  0.0470,  0.2164,  ..., -0.7376, -0.1497,  0.1692],\n",
      "        [ 0.0350,  0.0470,  0.2164,  ..., -0.7376, -0.1497,  0.1692],\n",
      "        [ 0.0350,  0.0470,  0.2164,  ..., -0.7376, -0.1497,  0.1692],\n",
      "        ...,\n",
      "        [ 0.4729, -0.3304, -0.2246,  ...,  0.5584,  0.1101, -0.4571],\n",
      "        [ 0.1504, -0.1990,  0.5255,  ...,  0.0713,  0.1914,  0.1317],\n",
      "        [ 0.1504, -0.1990,  0.5255,  ...,  0.0713,  0.1914,  0.1317]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03497367  0.04699898  0.21635824 -0.18275689 -0.1120549  -0.2554405\n",
      " -0.3580838  -0.25515762  0.01268366 -0.5717442  -0.34107384  0.0929877\n",
      " -0.779796   -0.41830778  0.2524464  -0.47973052 -0.30475456  0.11029817\n",
      " -0.7965882  -0.45444715 -0.06612334 -0.8750204  -0.5033114   0.00615403\n",
      " -0.9042425  -0.5326244   0.13427612 -0.46566102 -0.24585176  0.07688002\n",
      " -0.6966709  -0.39030513  0.25424424 -0.77347755 -0.45264333  0.30087805\n",
      " -0.85720813 -0.4686038   0.3768941  -0.4675751  -0.18377991 -0.00189336\n",
      " -0.65495    -0.3206315   0.28021744 -0.74046063 -0.36135632  0.3138692\n",
      " -0.8506707  -0.3803087   0.27636757 -0.42907456 -0.09663855  0.02794309\n",
      " -0.6154069  -0.14068767  0.10293355 -0.64447856 -0.17744404  0.15004982\n",
      " -0.73764825 -0.14969678  0.16924644]\n",
      "data: [ 0.03497367  0.04699898  0.21635824 -0.18275689 -0.1120549  -0.2554405\n",
      " -0.3580838  -0.25515762  0.01268366 -0.5717442  -0.34107384  0.0929877\n",
      " -0.779796   -0.4183078   0.2524464  -0.47973052 -0.30475456  0.11029818\n",
      " -0.7965882  -0.45444715 -0.06612334 -0.8750204  -0.5033114   0.00615403\n",
      " -0.9042426  -0.5326244   0.13427612 -0.46566102 -0.24585174  0.07688002\n",
      " -0.6966709  -0.39030513  0.25424424 -0.77347755 -0.4526433   0.30087805\n",
      " -0.8572081  -0.4686038   0.3768941  -0.4675751  -0.18377991 -0.00189336\n",
      " -0.65495    -0.32063147  0.28021744 -0.74046063 -0.36135632  0.3138692\n",
      " -0.8506707  -0.3803087   0.27636757 -0.42907456 -0.09663855  0.02794309\n",
      " -0.6154069  -0.14068767  0.10293355 -0.64447856 -0.17744404  0.15004982\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.73764825 -0.14969678  0.16924645  0.06      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[-0.0799, -0.0358,  0.1254,  ..., -0.7668, -0.3073,  0.2050],\n",
      "        [-0.0799, -0.0358,  0.1254,  ..., -0.7668, -0.3073,  0.2050],\n",
      "        [-0.0799, -0.0358,  0.1254,  ..., -0.7668, -0.3073,  0.2050],\n",
      "        ...,\n",
      "        [ 0.1213, -0.4496, -0.3459,  ..., -0.0327, -0.0010, -0.4643],\n",
      "        [ 0.3602,  0.0105,  0.4614,  ...,  0.0032,  0.6266, -0.3359],\n",
      "        [ 0.3602,  0.0105,  0.4614,  ...,  0.0032,  0.6266, -0.3359]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-7.9944760e-02 -3.5828367e-02  1.2544835e-01 -3.0459517e-01\n",
      " -2.0464556e-01 -2.8195450e-01 -5.0462401e-01 -3.8817126e-01\n",
      " -6.8494029e-02 -6.9797975e-01 -5.1031250e-01  3.5005800e-02\n",
      " -8.8759106e-01 -6.0523736e-01  2.1212500e-01 -5.7659066e-01\n",
      " -4.2455664e-01  8.0168642e-02 -8.3206409e-01 -5.8770907e-01\n",
      "  1.5136634e-01 -9.1906130e-01 -6.6774535e-01  2.3170362e-01\n",
      " -1.0160842e+00 -6.9112146e-01  3.3545873e-01 -5.5222565e-01\n",
      " -3.5915095e-01  4.5697905e-02 -7.8016591e-01 -5.2643180e-01\n",
      "  2.4661782e-01 -8.6372876e-01 -5.9217119e-01  3.2544148e-01\n",
      " -9.5184511e-01 -6.3216794e-01  3.9364374e-01 -5.4191327e-01\n",
      " -3.0023110e-01 -3.1517453e-02 -7.3826957e-01 -4.5108244e-01\n",
      "  2.1635813e-01 -8.1392962e-01 -5.0286388e-01  2.5757635e-01\n",
      " -9.2492795e-01 -5.2788544e-01  3.0662110e-01 -4.9315774e-01\n",
      " -2.0956095e-01  6.3411146e-04 -6.5606213e-01 -2.6795533e-01\n",
      "  1.0090433e-01 -6.7597252e-01 -3.0927134e-01  1.5927589e-01\n",
      " -7.6678377e-01 -3.0730531e-01  2.0500182e-01]\n",
      "data: [-7.9944760e-02 -3.5828367e-02  1.2544835e-01 -3.0459517e-01\n",
      " -2.0464556e-01 -2.8195450e-01 -5.0462401e-01 -3.8817129e-01\n",
      " -6.8494029e-02 -6.9797975e-01 -5.1031250e-01  3.5005800e-02\n",
      " -8.8759112e-01 -6.0523736e-01  2.1212500e-01 -5.7659066e-01\n",
      " -4.2455664e-01  8.0168635e-02 -8.3206403e-01 -5.8770907e-01\n",
      "  1.5136634e-01 -9.1906130e-01 -6.6774535e-01  2.3170362e-01\n",
      " -1.0160842e+00 -6.9112146e-01  3.3545873e-01 -5.5222565e-01\n",
      " -3.5915098e-01  4.5697905e-02 -7.8016591e-01 -5.2643180e-01\n",
      "  2.4661784e-01 -8.6372876e-01 -5.9217119e-01  3.2544148e-01\n",
      " -9.5184511e-01 -6.3216794e-01  3.9364374e-01 -5.4191327e-01\n",
      " -3.0023110e-01 -3.1517453e-02 -7.3826957e-01 -4.5108241e-01\n",
      "  2.1635813e-01 -8.1392962e-01 -5.0286388e-01  2.5757635e-01\n",
      " -9.2492795e-01 -5.2788544e-01  3.0662110e-01 -4.9315774e-01\n",
      " -2.0956095e-01  6.3411146e-04 -6.5606219e-01 -2.6795533e-01\n",
      "  1.0090433e-01 -6.7597252e-01 -3.0927134e-01  1.5927589e-01\n",
      " -7.6678377e-01 -3.0730531e-01  2.0500182e-01  7.0000000e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 2.6154e-02, -3.1201e-03,  1.6267e-01,  ..., -7.3769e-01,\n",
      "         -2.2505e-01,  1.2682e-01],\n",
      "        [ 2.6154e-02, -3.1201e-03,  1.6267e-01,  ..., -7.3769e-01,\n",
      "         -2.2505e-01,  1.2682e-01],\n",
      "        [ 2.6154e-02, -3.1201e-03,  1.6267e-01,  ..., -7.3769e-01,\n",
      "         -2.2505e-01,  1.2682e-01],\n",
      "        ...,\n",
      "        [ 3.5167e-01, -2.0768e-01, -4.0067e-01,  ...,  3.9898e-02,\n",
      "          5.1103e-01, -7.5590e-01],\n",
      "        [ 2.5068e-01, -6.7729e-04,  4.4217e-01,  ...,  2.2247e-01,\n",
      "          4.1357e-01, -3.7252e-02],\n",
      "        [ 2.5068e-01, -6.7729e-04,  4.4217e-01,  ...,  2.2247e-01,\n",
      "          4.1357e-01, -3.7252e-02]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02615381 -0.00312006  0.16266577 -0.19731009 -0.16536407 -0.2673897\n",
      " -0.38364083 -0.32017162 -0.03808065 -0.6004725  -0.41991806  0.04150049\n",
      " -0.81494313 -0.5036824   0.2045968  -0.49689662 -0.3722459   0.07041261\n",
      " -0.7983236  -0.5292521  -0.03531711 -0.88909346 -0.58609164  0.03600898\n",
      " -0.94908136 -0.6099708   0.157316   -0.47676224 -0.31185955  0.0382772\n",
      " -0.71481484 -0.4652861   0.20927063 -0.8056006  -0.5296357   0.25591812\n",
      " -0.8999735  -0.5443108   0.3246563  -0.47314852 -0.25403637 -0.03624867\n",
      " -0.6716844  -0.3934288   0.19745643 -0.7618332  -0.43319196  0.2334764\n",
      " -0.8799759  -0.4552343   0.23528874 -0.42599666 -0.16197474 -0.01132236\n",
      " -0.6099642  -0.21220976  0.05909198 -0.6357859  -0.24912587  0.11221422\n",
      " -0.737689   -0.22504635  0.12681696]\n",
      "data: [ 0.02615381 -0.00312006  0.16266577 -0.19731009 -0.16536407 -0.2673897\n",
      " -0.38364083 -0.32017162 -0.03808065 -0.6004725  -0.41991806  0.04150049\n",
      " -0.81494313 -0.5036824   0.2045968  -0.49689662 -0.3722459   0.07041261\n",
      " -0.7983236  -0.5292521  -0.03531711 -0.88909346 -0.58609164  0.03600898\n",
      " -0.94908136 -0.6099708   0.157316   -0.47676224 -0.31185955  0.0382772\n",
      " -0.71481484 -0.4652861   0.20927063 -0.8056006  -0.5296357   0.25591812\n",
      " -0.8999735  -0.5443108   0.3246563  -0.47314852 -0.25403637 -0.03624867\n",
      " -0.67168444 -0.3934288   0.19745643 -0.7618332  -0.43319196  0.23347642\n",
      " -0.8799759  -0.4552343   0.23528874 -0.42599666 -0.16197473 -0.01132237\n",
      " -0.6099642  -0.21220976  0.05909198 -0.6357859  -0.24912587  0.11221422\n",
      " -0.7376891  -0.22504635  0.12681696  0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FB38>\n",
      "tensor([[ 0.0705, -0.0066,  0.2066,  ..., -0.6548, -0.2418,  0.1783],\n",
      "        [ 0.0705, -0.0066,  0.2066,  ..., -0.6548, -0.2418,  0.1783],\n",
      "        [ 0.0705, -0.0066,  0.2066,  ..., -0.6548, -0.2418,  0.1783],\n",
      "        ...,\n",
      "        [-0.0063, -0.2840, -0.7920,  ..., -0.1065,  0.2318, -0.9733],\n",
      "        [ 0.1885, -0.0710,  0.5555,  ..., -0.0501,  0.4423, -0.0511],\n",
      "        [ 0.1885, -0.0710,  0.5555,  ..., -0.0501,  0.4423, -0.0511]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.07054701 -0.00655813  0.20661011 -0.14672215 -0.17074218 -0.21439792\n",
      " -0.34146994 -0.3407577  -0.02519865 -0.54620624 -0.45021406  0.06346531\n",
      " -0.75331134 -0.53696513  0.2182855  -0.43687642 -0.39339912  0.11142734\n",
      " -0.6994253  -0.5511162   0.10863429 -0.7857913  -0.6190743   0.18794644\n",
      " -0.8718772  -0.6351354   0.29515606 -0.41519046 -0.3320216   0.07955293\n",
      " -0.6400639  -0.48856968  0.2545091  -0.72112083 -0.5413292   0.31493375\n",
      " -0.80798656 -0.5705515   0.37738872 -0.4087512  -0.27105227  0.00210933\n",
      " -0.60529673 -0.4077468   0.22866912 -0.67940205 -0.45024022  0.26459032\n",
      " -0.79251987 -0.46857703  0.28302285 -0.36753243 -0.17415039  0.03190015\n",
      " -0.5374277  -0.22503957  0.10177962 -0.5578383  -0.26081282  0.15260348\n",
      " -0.6547701  -0.24178338  0.17830107]\n",
      "data: [ 0.07054701 -0.00655813  0.20661011 -0.14672215 -0.17074218 -0.21439792\n",
      " -0.34146994 -0.34075773 -0.02519865 -0.54620624 -0.45021403  0.06346531\n",
      " -0.75331134 -0.53696513  0.2182855  -0.43687642 -0.39339912  0.11142734\n",
      " -0.6994253  -0.5511162   0.10863428 -0.7857912  -0.6190743   0.18794644\n",
      " -0.8718772  -0.6351354   0.29515606 -0.41519046 -0.3320216   0.07955293\n",
      " -0.6400639  -0.48856968  0.2545091  -0.72112083 -0.5413292   0.31493375\n",
      " -0.8079865  -0.5705515   0.37738872 -0.4087512  -0.27105227  0.00210933\n",
      " -0.60529673 -0.40774682  0.22866912 -0.6794021  -0.45024022  0.26459032\n",
      " -0.7925198  -0.46857703  0.28302285 -0.36753243 -0.17415039  0.03190015\n",
      " -0.5374277  -0.22503957  0.10177961 -0.5578383  -0.26081282  0.15260348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.6547701  -0.24178337  0.17830107  0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[-0.0093, -0.0294,  0.2252,  ..., -0.7685, -0.2670,  0.0625],\n",
      "        [-0.0093, -0.0294,  0.2252,  ..., -0.7685, -0.2670,  0.0625],\n",
      "        [-0.0093, -0.0294,  0.2252,  ..., -0.7685, -0.2670,  0.0625],\n",
      "        ...,\n",
      "        [ 0.1983, -0.1947, -0.1129,  ...,  0.0578,  0.5028, -0.5132],\n",
      "        [ 0.2798, -0.0696,  0.4151,  ...,  0.2565,  0.4541, -0.0501],\n",
      "        [ 0.2798, -0.0696,  0.4151,  ...,  0.2565,  0.4541, -0.0501]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.00927791 -0.02944105  0.22515765 -0.23320018 -0.18459499 -0.25558704\n",
      " -0.40820715 -0.33643946 -0.0468597  -0.61886704 -0.43210524  0.01780024\n",
      " -0.8243866  -0.5100954   0.16310737 -0.5251801  -0.41056693  0.04783395\n",
      " -0.80242467 -0.56605726 -0.04865219 -0.88857305 -0.6262763   0.02318518\n",
      " -0.9557811  -0.64537466  0.13337123 -0.5087495  -0.3593198   0.01763023\n",
      " -0.73168063 -0.5102077   0.16796425 -0.8108829  -0.5627424   0.20934884\n",
      " -0.90219295 -0.5852077   0.27091548 -0.50257194 -0.29473808 -0.06572305\n",
      " -0.6967273  -0.4374881   0.16003694 -0.77487063 -0.4746652   0.19127312\n",
      " -0.8890952  -0.48931164  0.16585135 -0.4666281  -0.20644377 -0.03374453\n",
      " -0.6396496  -0.2562452   0.01570313 -0.66658103 -0.2953325   0.06167939\n",
      " -0.7685119  -0.2669722   0.06253792]\n",
      "data: [-0.00927791 -0.02944105  0.22515765 -0.23320016 -0.18459499 -0.25558704\n",
      " -0.40820712 -0.3364395  -0.0468597  -0.61886704 -0.43210524  0.01780024\n",
      " -0.8243866  -0.5100954   0.16310735 -0.5251801  -0.41056693  0.04783395\n",
      " -0.80242467 -0.56605726 -0.04865219 -0.88857305 -0.6262763   0.02318518\n",
      " -0.9557811  -0.64537466  0.13337123 -0.5087495  -0.3593198   0.01763023\n",
      " -0.73168063 -0.5102077   0.16796425 -0.8108829  -0.5627424   0.20934886\n",
      " -0.9021929  -0.5852077   0.27091548 -0.50257194 -0.29473808 -0.06572305\n",
      " -0.6967273  -0.4374881   0.16003695 -0.77487063 -0.4746652   0.19127312\n",
      " -0.8890951  -0.48931164  0.16585137 -0.4666281  -0.20644377 -0.03374453\n",
      " -0.6396496  -0.2562452   0.01570313 -0.66658103 -0.2953325   0.06167939\n",
      " -0.7685119  -0.2669722   0.06253792  0.1       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FE10>\n",
      "tensor([[ 0.0768, -0.0300,  0.1469,  ..., -0.6112, -0.2878,  0.1023],\n",
      "        [ 0.0768, -0.0300,  0.1469,  ..., -0.6112, -0.2878,  0.1023],\n",
      "        [ 0.0768, -0.0300,  0.1469,  ..., -0.6112, -0.2878,  0.1023],\n",
      "        ...,\n",
      "        [-0.0183, -0.2664, -0.5731,  ..., -0.0401,  0.2220, -0.7442],\n",
      "        [ 0.1177, -0.0049,  0.7033,  ..., -0.2730,  0.5874,  0.0124],\n",
      "        [ 0.1177, -0.0049,  0.7033,  ..., -0.2730,  0.5874,  0.0124]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.07683011 -0.03001946  0.1469263  -0.14040521 -0.18711895 -0.27151486\n",
      " -0.34471512 -0.35630566 -0.08313486 -0.54549575 -0.4691401   0.00726722\n",
      " -0.73760325 -0.5559417   0.15172696 -0.42158896 -0.4255604   0.0304963\n",
      " -0.6845091  -0.5811225   0.02498711 -0.76042885 -0.64841944  0.09896169\n",
      " -0.8312828  -0.67169976  0.19997218 -0.39883578 -0.3666777  -0.00602111\n",
      " -0.61862403 -0.52610743  0.16584466 -0.68940943 -0.5791705   0.22670363\n",
      " -0.7491179  -0.61385244  0.2817596  -0.39272273 -0.31133354 -0.07786427\n",
      " -0.5795877  -0.44033462  0.1595447  -0.6442504  -0.48530447  0.19140726\n",
      " -0.73055565 -0.5100794   0.19191048 -0.35348356 -0.21206081 -0.04245472\n",
      " -0.5195103  -0.26025897  0.02919602 -0.5331787  -0.29538935  0.07476912\n",
      " -0.6112435  -0.2878152   0.10227621]\n",
      "data: [ 0.07683011 -0.03001946  0.1469263  -0.14040521 -0.18711895 -0.27151486\n",
      " -0.34471512 -0.35630566 -0.08313486 -0.54549575 -0.46914014  0.00726722\n",
      " -0.73760325 -0.5559417   0.15172696 -0.421589   -0.4255604   0.0304963\n",
      " -0.6845091  -0.5811225   0.02498711 -0.76042885 -0.64841944  0.09896169\n",
      " -0.8312828  -0.67169976  0.1999722  -0.39883578 -0.3666777  -0.00602111\n",
      " -0.61862403 -0.52610743  0.16584466 -0.68940943 -0.5791705   0.22670363\n",
      " -0.7491179  -0.61385244  0.2817596  -0.39272273 -0.31133354 -0.07786427\n",
      " -0.5795877  -0.44033462  0.1595447  -0.6442504  -0.48530447  0.19140726\n",
      " -0.73055565 -0.5100794   0.19191048 -0.35348356 -0.21206081 -0.04245472\n",
      " -0.5195103  -0.26025897  0.02919602 -0.5331787  -0.29538935  0.07476912\n",
      " -0.6112435  -0.2878152   0.10227621  0.11      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[-0.0519, -0.2231,  0.1667,  ..., -0.7593, -0.4672, -0.1658],\n",
      "        [-0.0519, -0.2231,  0.1667,  ..., -0.7593, -0.4672, -0.1658],\n",
      "        [-0.0519, -0.2231,  0.1667,  ..., -0.7593, -0.4672, -0.1658],\n",
      "        ...,\n",
      "        [ 0.0828,  0.1511, -0.3511,  ..., -0.0671,  0.8477, -0.7028],\n",
      "        [ 0.3873,  0.1016,  0.4393,  ...,  0.3725,  0.6124,  0.0017],\n",
      "        [ 0.3873,  0.1016,  0.4393,  ...,  0.3725,  0.6124,  0.0017]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.05191284 -0.2230553   0.1666935  -0.2663554  -0.38318944 -0.33394217\n",
      " -0.44739014 -0.51883817 -0.14237751 -0.6758375  -0.62107253 -0.09206657\n",
      " -0.881364   -0.7038336  -0.01269543 -0.5606526  -0.62090075 -0.1331092\n",
      " -0.82084    -0.7756629  -0.24737988 -0.90154326 -0.8309078  -0.18371691\n",
      " -0.9530598  -0.85285497 -0.08208232 -0.5386392  -0.5743182  -0.17350735\n",
      " -0.741259   -0.7276361  -0.04327597 -0.8099029  -0.7739662  -0.02254447\n",
      " -0.87074447 -0.8011905   0.04052026 -0.53212166 -0.5129911  -0.2406105\n",
      " -0.68763185 -0.6408274   0.05298696 -0.7664887  -0.67392576  0.07709578\n",
      " -0.8453609  -0.7015257  -0.07085691 -0.5034025  -0.4121471  -0.20915781\n",
      " -0.6654401  -0.4597196  -0.18203782 -0.686226   -0.49666044 -0.1516882\n",
      " -0.7593391  -0.4672345  -0.16575693]\n",
      "data: [-0.05191284 -0.2230553   0.1666935  -0.2663554  -0.38318944 -0.33394217\n",
      " -0.44739014 -0.51883817 -0.14237751 -0.6758376  -0.62107253 -0.09206657\n",
      " -0.881364   -0.70383364 -0.01269543 -0.5606526  -0.62090075 -0.1331092\n",
      " -0.82084    -0.7756629  -0.24737987 -0.90154326 -0.8309078  -0.18371691\n",
      " -0.9530598  -0.85285497 -0.08208232 -0.5386392  -0.5743182  -0.17350735\n",
      " -0.741259   -0.7276361  -0.04327597 -0.8099029  -0.7739662  -0.02254448\n",
      " -0.87074447 -0.8011905   0.04052026 -0.53212166 -0.5129911  -0.24061051\n",
      " -0.68763185 -0.6408274   0.05298696 -0.7664887  -0.67392576  0.07709578\n",
      " -0.8453609  -0.70152575 -0.07085691 -0.5034025  -0.4121471  -0.20915781\n",
      " -0.6654401  -0.45971957 -0.18203782 -0.68622607 -0.4966604  -0.1516882\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.7593391  -0.4672345  -0.16575693  0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0321, -0.0243, -0.1603,  ..., -0.8209, -0.2318, -0.5273],\n",
      "        [ 0.0321, -0.0243, -0.1603,  ..., -0.8209, -0.2318, -0.5273],\n",
      "        [ 0.0321, -0.0243, -0.1603,  ..., -0.8209, -0.2318, -0.5273],\n",
      "        ...,\n",
      "        [ 0.5465, -0.0594,  0.4925,  ...,  0.6660,  0.5068,  0.1962],\n",
      "        [ 0.4663, -0.1230,  0.9468,  ...,  0.3517,  0.2743,  0.4970],\n",
      "        [ 0.4663, -0.1230,  0.9468,  ...,  0.3517,  0.2743,  0.4970]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03210521 -0.02427653 -0.16030125 -0.17615207 -0.19013318 -0.74042684\n",
      " -0.3190034  -0.29671457 -0.5290947  -0.5376319  -0.3710739  -0.4927695\n",
      " -0.748541   -0.43051228 -0.40668875 -0.45579565 -0.41515264 -0.4830674\n",
      " -0.7585221  -0.5388634  -0.71686065 -0.8303558  -0.5768249  -0.6708101\n",
      " -0.85802215 -0.58929706 -0.5604739  -0.46992743 -0.35502973 -0.521081\n",
      " -0.6822112  -0.48157656 -0.40920314 -0.7679058  -0.52591753 -0.3988787\n",
      " -0.83806336 -0.526006   -0.3497014  -0.48663223 -0.2968371  -0.5889363\n",
      " -0.6535855  -0.41406152 -0.28766    -0.76602495 -0.42893127 -0.26089847\n",
      " -0.8753751  -0.44825426 -0.43988168 -0.46851838 -0.19530264 -0.5508259\n",
      " -0.6698862  -0.23347148 -0.5199418  -0.71280414 -0.26106822 -0.4943884\n",
      " -0.8208581  -0.2317708  -0.5273069 ]\n",
      "data: [ 0.03210521 -0.02427653 -0.16030125 -0.17615205 -0.19013318 -0.74042684\n",
      " -0.3190034  -0.29671457 -0.5290947  -0.5376319  -0.3710739  -0.4927695\n",
      " -0.74854106 -0.43051228 -0.40668878 -0.45579565 -0.41515264 -0.4830674\n",
      " -0.7585221  -0.5388634  -0.71686065 -0.8303558  -0.5768249  -0.6708101\n",
      " -0.85802215 -0.58929706 -0.5604739  -0.46992743 -0.3550297  -0.521081\n",
      " -0.6822112  -0.48157656 -0.40920314 -0.76790583 -0.52591753 -0.3988787\n",
      " -0.83806336 -0.526006   -0.34970137 -0.48663223 -0.2968371  -0.5889363\n",
      " -0.6535855  -0.41406152 -0.28766    -0.76602495 -0.42893127 -0.26089847\n",
      " -0.87537503 -0.44825423 -0.43988168 -0.46851838 -0.19530264 -0.5508259\n",
      " -0.6698862  -0.23347148 -0.5199418  -0.7128041  -0.26106822 -0.4943884\n",
      " -0.8208582  -0.2317708  -0.5273069   0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[-0.0935, -0.1311, -0.0709,  ..., -0.0190, -0.3163, -1.0957],\n",
      "        [-0.0935, -0.1311, -0.0709,  ..., -0.0190, -0.3163, -1.0957],\n",
      "        [-0.0935, -0.1311, -0.0709,  ..., -0.0190, -0.3163, -1.0957],\n",
      "        ...,\n",
      "        [ 0.7236,  0.0845,  0.6075,  ..., -0.1367,  0.9621,  0.1475],\n",
      "        [ 0.0395,  0.1611,  0.5097,  ..., -0.6178,  0.5988,  0.2102],\n",
      "        [ 0.0395,  0.1611,  0.5097,  ..., -0.6178,  0.5988,  0.2102]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.09348794 -0.13108867 -0.0708622  -0.08135821 -0.27132097 -0.42638826\n",
      " -0.1941276  -0.38452813 -1.0068845  -0.31727943 -0.4526649  -1.2197282\n",
      " -0.48983145 -0.526871   -1.6142294  -0.28900915 -0.66977763 -1.1621574\n",
      " -0.1845582  -0.6648903  -1.1176234  -0.16790707 -0.59526134 -1.1494292\n",
      " -0.10629983 -0.67657304 -1.1983802  -0.25525987 -0.5773103  -1.1502317\n",
      " -0.1626113  -0.62042856 -1.1080308  -0.15254013 -0.58480334 -1.1838641\n",
      "  0.03886005 -0.56259644 -1.2890955  -0.19904003 -0.5598968  -1.0282704\n",
      " -0.2216013  -0.35635158 -1.4541783  -0.09399664 -0.44493768 -1.445677\n",
      "  0.05713621 -0.40802026 -1.2056414  -0.22958079 -0.33492923 -1.0026875\n",
      " -0.19622332 -0.30204162 -1.0707804  -0.09771301 -0.28899565 -1.1956248\n",
      " -0.01896397 -0.31631395 -1.0956695 ]\n",
      "data: [-0.09348794 -0.13108867 -0.0708622  -0.08135822 -0.27132097 -0.42638823\n",
      " -0.1941276  -0.38452813 -1.0068845  -0.31727943 -0.4526649  -1.2197282\n",
      " -0.48983148 -0.526871   -1.6142294  -0.28900915 -0.66977763 -1.1621574\n",
      " -0.1845582  -0.6648903  -1.1176234  -0.16790706 -0.59526134 -1.1494292\n",
      " -0.10629983 -0.67657304 -1.1983802  -0.25525987 -0.5773103  -1.1502317\n",
      " -0.1626113  -0.62042856 -1.1080308  -0.15254013 -0.58480334 -1.1838641\n",
      "  0.03886005 -0.56259644 -1.2890954  -0.19904003 -0.5598968  -1.0282704\n",
      " -0.2216013  -0.35635158 -1.4541783  -0.09399664 -0.44493768 -1.445677\n",
      "  0.05713621 -0.40802026 -1.2056414  -0.22958079 -0.33492923 -1.0026875\n",
      " -0.19622332 -0.30204162 -1.0707804  -0.09771302 -0.28899565 -1.1956248\n",
      " -0.01896397 -0.31631395 -1.0956695   0.14      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[ 0.0785,  0.0267, -0.2483,  ...,  0.1859, -0.1518, -1.2855],\n",
      "        [ 0.0785,  0.0267, -0.2483,  ...,  0.1859, -0.1518, -1.2855],\n",
      "        [ 0.0785,  0.0267, -0.2483,  ...,  0.1859, -0.1518, -1.2855],\n",
      "        ...,\n",
      "        [-0.3601,  0.3524, -0.0911,  ..., -0.4316,  1.0776, -0.6258],\n",
      "        [-0.2142,  0.1143,  0.4469,  ..., -0.7600,  0.6851,  0.1285],\n",
      "        [-0.2142,  0.1143,  0.4469,  ..., -0.7600,  0.6851,  0.1285]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.07849728  0.02670345 -0.24827997  0.11761539 -0.11561489 -0.60596\n",
      "  0.06280877 -0.2944824  -1.3716637  -0.07797522 -0.3474572  -1.686413\n",
      " -0.23625141 -0.49647686 -2.1643162  -0.14077055 -0.550462   -1.6026249\n",
      "  0.20320103 -0.5601784  -1.3364884   0.1535762  -0.51447284 -1.3645352\n",
      "  0.15711913 -0.61831737 -1.4982394  -0.08147713 -0.4314789  -1.5039885\n",
      "  0.06273162 -0.50633526 -1.4902905   0.09957389 -0.46620718 -1.577908\n",
      "  0.24511543 -0.5383048  -1.6572603   0.05831745 -0.34727243 -1.3067349\n",
      " -0.06738407 -0.09543532 -1.9564108   0.137101   -0.2944854  -1.9297086\n",
      "  0.3252419  -0.23766968 -1.4859185  -0.08894257 -0.09508374 -1.2326952\n",
      "  0.06678353 -0.06927001 -1.2803456   0.13505217 -0.13087809 -1.4055837\n",
      "  0.18589865 -0.15180506 -1.2855375 ]\n",
      "data: [ 0.07849728  0.02670345 -0.24827997  0.11761539 -0.11561489 -0.60596\n",
      "  0.06280877 -0.2944824  -1.3716637  -0.07797522 -0.3474572  -1.6864132\n",
      " -0.23625141 -0.49647686 -2.1643162  -0.14077055 -0.550462   -1.6026248\n",
      "  0.20320103 -0.5601784  -1.3364884   0.1535762  -0.51447284 -1.3645352\n",
      "  0.15711913 -0.61831737 -1.4982394  -0.08147713 -0.4314789  -1.5039885\n",
      "  0.06273162 -0.50633526 -1.4902905   0.09957389 -0.46620715 -1.577908\n",
      "  0.24511543 -0.5383048  -1.6572603   0.05831745 -0.34727243 -1.3067349\n",
      " -0.06738407 -0.09543532 -1.9564109   0.137101   -0.2944854  -1.9297086\n",
      "  0.3252419  -0.23766968 -1.4859185  -0.08894257 -0.09508374 -1.2326952\n",
      "  0.06678353 -0.06927001 -1.2803456   0.13505217 -0.13087809 -1.4055839\n",
      "  0.18589865 -0.15180506 -1.2855374   0.15      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[ 0.0430, -0.1372, -0.3575,  ..., -0.0108, -0.2716, -1.5163],\n",
      "        [ 0.0430, -0.1372, -0.3575,  ..., -0.0108, -0.2716, -1.5163],\n",
      "        [ 0.0430, -0.1372, -0.3575,  ..., -0.0108, -0.2716, -1.5163],\n",
      "        ...,\n",
      "        [-0.2424,  0.3466, -0.0671,  ..., -0.8532,  0.8417, -0.4099],\n",
      "        [-0.1353,  0.0827,  0.5603,  ..., -0.1381,  0.8821,  0.1526],\n",
      "        [-0.1353,  0.0827,  0.5603,  ..., -0.1381,  0.8821,  0.1526]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04298944 -0.13722867 -0.35745743  0.05286254 -0.3131534  -0.88010067\n",
      "  0.02309337 -0.47309864 -1.6214386  -0.11841311 -0.5301274  -1.9536934\n",
      " -0.3134843  -0.6640891  -2.435056   -0.19428793 -0.7135745  -1.7890732\n",
      "  0.11187011 -0.7078692  -1.4729289   0.0464544  -0.6672108  -1.5273607\n",
      "  0.00256995 -0.7583833  -1.6610947  -0.15983535 -0.57941777 -1.6947044\n",
      " -0.05048344 -0.63604987 -1.6798656  -0.06899585 -0.6075971  -1.7947046\n",
      "  0.03274703 -0.6367936  -1.8740029  -0.05430447 -0.4976743  -1.5042418\n",
      " -0.1628975  -0.2717548  -2.0640202  -0.03767256 -0.4154917  -2.0390158\n",
      "  0.08855881 -0.379994   -1.6849275  -0.1674538  -0.24525522 -1.4357626\n",
      " -0.06699641 -0.22792503 -1.4876686  -0.02466114 -0.264781   -1.6057773\n",
      " -0.01084527 -0.27159223 -1.5163448 ]\n",
      "data: [ 0.04298944 -0.13722867 -0.35745743  0.05286254 -0.3131534  -0.8801006\n",
      "  0.02309337 -0.47309864 -1.6214386  -0.11841311 -0.5301274  -1.9536934\n",
      " -0.3134843  -0.664089   -2.435056   -0.19428793 -0.7135745  -1.7890732\n",
      "  0.11187011 -0.7078692  -1.4729289   0.0464544  -0.6672108  -1.5273607\n",
      "  0.00256995 -0.7583833  -1.6610947  -0.15983535 -0.57941777 -1.6947044\n",
      " -0.05048344 -0.63604987 -1.6798656  -0.06899585 -0.6075971  -1.7947046\n",
      "  0.03274703 -0.6367936  -1.8740029  -0.05430447 -0.4976743  -1.5042418\n",
      " -0.1628975  -0.2717548  -2.0640202  -0.03767256 -0.4154917  -2.0390158\n",
      "  0.08855881 -0.379994   -1.6849275  -0.16745381 -0.24525522 -1.4357626\n",
      " -0.06699641 -0.22792503 -1.4876686  -0.02466114 -0.264781   -1.6057773\n",
      " -0.01084527 -0.27159223 -1.5163448   0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B9B0>\n",
      "tensor([[ 0.0642, -0.1633, -0.1907,  ...,  0.0627, -0.3424, -1.3128],\n",
      "        [ 0.0642, -0.1633, -0.1907,  ...,  0.0627, -0.3424, -1.3128],\n",
      "        [ 0.0642, -0.1633, -0.1907,  ...,  0.0627, -0.3424, -1.3128],\n",
      "        ...,\n",
      "        [-0.0115,  0.5098, -0.1725,  ..., -0.7151,  1.0595, -0.4124],\n",
      "        [-0.2192, -0.1020,  0.5272,  ..., -0.1913,  0.5912,  0.2502],\n",
      "        [-0.2192, -0.1020,  0.5272,  ..., -0.1913,  0.5912,  0.2502]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.06416866 -0.16334614 -0.19070938  0.08303742 -0.3171605  -0.64756936\n",
      "  0.07569323 -0.4660641  -1.3501142  -0.05907074 -0.51184344 -1.6770058\n",
      " -0.22203001 -0.64993536 -2.1674573  -0.14545792 -0.73064077 -1.5640255\n",
      "  0.15072161 -0.7330731  -1.3598037   0.07353961 -0.68349105 -1.410603\n",
      "  0.05584247 -0.78469753 -1.5262932  -0.10011687 -0.61829686 -1.4747347\n",
      "  0.01634976 -0.6744822  -1.4683497  -0.01086207 -0.6508487  -1.5765331\n",
      "  0.05616976 -0.6877716  -1.6293913   0.01841296 -0.53365934 -1.2980632\n",
      " -0.08234159 -0.31749249 -1.8520151   0.03288177 -0.47379553 -1.8259219\n",
      "  0.13616896 -0.44058698 -1.4762601  -0.09663302 -0.30218288 -1.2421516\n",
      "  0.02469967 -0.29468244 -1.2977719   0.05420966 -0.3424951  -1.4056071\n",
      "  0.06268699 -0.3423561  -1.31281   ]\n",
      "data: [ 0.06416866 -0.16334614 -0.19070938  0.08303742 -0.3171605  -0.64756936\n",
      "  0.07569323 -0.4660641  -1.3501143  -0.05907074 -0.51184344 -1.6770058\n",
      " -0.22203001 -0.64993536 -2.1674573  -0.14545792 -0.73064077 -1.5640255\n",
      "  0.15072161 -0.7330731  -1.3598037   0.07353961 -0.68349105 -1.410603\n",
      "  0.05584247 -0.7846976  -1.5262932  -0.10011687 -0.61829686 -1.4747347\n",
      "  0.01634976 -0.67448217 -1.4683498  -0.01086207 -0.6508487  -1.5765331\n",
      "  0.05616976 -0.6877716  -1.6293913   0.01841296 -0.53365934 -1.2980632\n",
      " -0.08234158 -0.31749249 -1.852015    0.03288177 -0.47379553 -1.8259219\n",
      "  0.13616896 -0.44058695 -1.4762601  -0.09663302 -0.30218288 -1.2421516\n",
      "  0.02469967 -0.29468244 -1.2977719   0.05420966 -0.3424951  -1.4056071\n",
      "  0.06268699 -0.3423561  -1.31281     0.17      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FF98>\n",
      "tensor([[ 0.0465, -0.1518, -0.1644,  ...,  0.0527, -0.3399, -1.1940],\n",
      "        [ 0.0465, -0.1518, -0.1644,  ...,  0.0527, -0.3399, -1.1940],\n",
      "        [ 0.0465, -0.1518, -0.1644,  ...,  0.0527, -0.3399, -1.1940],\n",
      "        ...,\n",
      "        [-0.0760,  0.5377, -0.1320,  ..., -0.5208,  1.0409, -0.5161],\n",
      "        [-0.1889, -0.0285,  0.5617,  ..., -0.2538,  0.7014,  0.1635],\n",
      "        [-0.1889, -0.0285,  0.5617,  ..., -0.2538,  0.7014,  0.1635]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04653354 -0.15180117 -0.1643907   0.07239784 -0.27413055 -0.50495243\n",
      " -0.04730438 -0.5079526  -1.3400021  -0.20121706 -0.57781786 -1.6382239\n",
      " -0.36840633 -0.67984396 -2.1344762  -0.15619072 -0.78753734 -1.5300868\n",
      "  0.04057533 -0.85521597 -1.342948   -0.01630812 -0.79040635 -1.3869656\n",
      " -0.03515819 -0.95533055 -1.5077488  -0.10902876 -0.68644094 -1.4244775\n",
      " -0.04930216 -0.750158   -1.386828   -0.0621177  -0.7262625  -1.4735829\n",
      "  0.06077491 -0.7620763  -1.5009068  -0.02117525 -0.57415545 -1.2612923\n",
      " -0.18586853 -0.3479279  -2.0161517  -0.00535379 -0.5293398  -2.030455\n",
      "  0.15333897 -0.4827913  -1.3582311  -0.14633855 -0.3397393  -1.1826867\n",
      " -0.07340071 -0.3142486  -1.2629257  -0.03590474 -0.330402   -1.3729511\n",
      "  0.05274146 -0.33994365 -1.1940296 ]\n",
      "data: [ 0.04653354 -0.15180117 -0.1643907   0.07239784 -0.27413055 -0.50495243\n",
      " -0.04730438 -0.5079526  -1.3400022  -0.20121706 -0.57781786 -1.6382239\n",
      " -0.36840633 -0.67984396 -2.1344762  -0.15619072 -0.78753734 -1.5300869\n",
      "  0.04057533 -0.85521597 -1.342948   -0.01630812 -0.79040635 -1.3869656\n",
      " -0.03515819 -0.9553306  -1.5077488  -0.10902877 -0.68644094 -1.4244773\n",
      " -0.04930216 -0.750158   -1.386828   -0.06211771 -0.7262625  -1.4735829\n",
      "  0.06077491 -0.7620763  -1.5009068  -0.02117525 -0.57415545 -1.2612923\n",
      " -0.18586853 -0.3479279  -2.0161517  -0.00535379 -0.5293398  -2.030455\n",
      "  0.15333897 -0.4827913  -1.3582311  -0.14633855 -0.3397393  -1.1826867\n",
      " -0.07340071 -0.3142486  -1.2629257  -0.03590474 -0.330402   -1.3729511\n",
      "  0.05274146 -0.33994365 -1.1940296   0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0170, -0.1092, -0.2035,  ...,  0.0454, -0.2893, -1.1994],\n",
      "        [-0.0170, -0.1092, -0.2035,  ...,  0.0454, -0.2893, -1.1994],\n",
      "        [-0.0170, -0.1092, -0.2035,  ...,  0.0454, -0.2893, -1.1994],\n",
      "        ...,\n",
      "        [-0.1423,  0.4054, -0.0213,  ..., -0.6657,  1.0243, -0.4668],\n",
      "        [-0.0707, -0.0075,  0.6413,  ..., -0.1913,  0.6681,  0.2793],\n",
      "        [-0.0707, -0.0075,  0.6413,  ..., -0.1913,  0.6681,  0.2793]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.0169681  -0.10921041 -0.2035482   0.01545404 -0.23726472 -0.49577418\n",
      " -0.08383103 -0.45475084 -1.3400081  -0.2375625  -0.516417   -1.6503489\n",
      " -0.40759963 -0.6431359  -2.144284   -0.2306916  -0.72865224 -1.5425026\n",
      "  0.03091525 -0.7752961  -1.3465613  -0.02945989 -0.718638   -1.3830212\n",
      " -0.02771664 -0.85695124 -1.5113229  -0.1719032  -0.6195968  -1.4313139\n",
      " -0.07473605 -0.68637305 -1.4105603  -0.06015553 -0.65259945 -1.5051389\n",
      "  0.07369116 -0.7048358  -1.5500939  -0.0579521  -0.51463884 -1.2453623\n",
      " -0.21186706 -0.27504116 -1.9840974  -0.01087238 -0.4643395  -1.9838774\n",
      "  0.16935895 -0.41458493 -1.3872052  -0.19837199 -0.26953813 -1.1715727\n",
      " -0.08274443 -0.24778247 -1.2427837  -0.03285593 -0.28191674 -1.3582247\n",
      "  0.04544447 -0.28930998 -1.1993834 ]\n",
      "data: [-0.0169681  -0.1092104  -0.20354821  0.01545404 -0.23726472 -0.49577418\n",
      " -0.08383103 -0.45475084 -1.3400081  -0.2375625  -0.516417   -1.650349\n",
      " -0.40759963 -0.6431359  -2.144284   -0.23069161 -0.72865224 -1.5425026\n",
      "  0.03091525 -0.7752961  -1.3465613  -0.02945989 -0.718638   -1.3830212\n",
      " -0.02771664 -0.85695124 -1.5113227  -0.1719032  -0.6195968  -1.431314\n",
      " -0.07473605 -0.68637305 -1.4105603  -0.06015553 -0.6525995  -1.5051389\n",
      "  0.07369116 -0.7048357  -1.5500939  -0.0579521  -0.51463884 -1.2453623\n",
      " -0.21186706 -0.27504116 -1.9840972  -0.01087238 -0.4643395  -1.9838774\n",
      "  0.16935895 -0.41458493 -1.3872052  -0.19837198 -0.26953813 -1.1715727\n",
      " -0.08274443 -0.24778248 -1.2427837  -0.03285593 -0.28191674 -1.3582247\n",
      "  0.04544447 -0.28930998 -1.1993834   0.19      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[-0.0174, -0.1010, -0.2219,  ...,  0.0119, -0.2626, -1.2801],\n",
      "        [-0.0174, -0.1010, -0.2219,  ...,  0.0119, -0.2626, -1.2801],\n",
      "        [-0.0174, -0.1010, -0.2219,  ...,  0.0119, -0.2626, -1.2801],\n",
      "        ...,\n",
      "        [-0.1666,  0.3718, -0.1021,  ..., -0.6876,  0.9159, -0.4292],\n",
      "        [-0.0920, -0.0701,  0.6567,  ..., -0.2055,  0.6598,  0.2822],\n",
      "        [-0.0920, -0.0701,  0.6567,  ..., -0.2055,  0.6598,  0.2822]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01740042 -0.10099137 -0.22186972  0.00435245 -0.2493877  -0.5991764\n",
      " -0.06193729 -0.44445765 -1.378444   -0.2065452  -0.50246406 -1.6985723\n",
      " -0.39229    -0.63664806 -2.1662955  -0.24336903 -0.7036358  -1.566015\n",
      "  0.04283658 -0.72791886 -1.3283578  -0.01266754 -0.68263584 -1.3681954\n",
      " -0.01769295 -0.80181396 -1.4962821  -0.18996987 -0.5812617  -1.4627659\n",
      " -0.08269212 -0.64773774 -1.4461579  -0.06727628 -0.61928827 -1.5528532\n",
      "  0.06292272 -0.6643096  -1.623432   -0.07745039 -0.48610452 -1.2762836\n",
      " -0.21194918 -0.258153   -1.9480014  -0.03016894 -0.42972606 -1.9359256\n",
      "  0.13602726 -0.38210285 -1.4532993  -0.20778824 -0.23635946 -1.2106134\n",
      " -0.09568304 -0.21694192 -1.2802725  -0.0403277  -0.25612688 -1.400624\n",
      "  0.01192794 -0.26258415 -1.280058  ]\n",
      "data: [-0.01740042 -0.10099136 -0.22186972  0.00435245 -0.2493877  -0.5991764\n",
      " -0.06193729 -0.44445765 -1.378444   -0.2065452  -0.50246406 -1.6985723\n",
      " -0.39229    -0.63664806 -2.1662955  -0.24336903 -0.7036358  -1.566015\n",
      "  0.04283658 -0.72791886 -1.3283578  -0.01266754 -0.6826359  -1.3681953\n",
      " -0.01769295 -0.80181396 -1.4962821  -0.18996987 -0.5812617  -1.4627659\n",
      " -0.08269212 -0.64773774 -1.4461579  -0.06727628 -0.61928827 -1.5528532\n",
      "  0.06292272 -0.6643096  -1.623432   -0.07745039 -0.48610452 -1.2762836\n",
      " -0.21194917 -0.258153   -1.9480014  -0.03016894 -0.42972606 -1.9359256\n",
      "  0.13602726 -0.38210285 -1.4532993  -0.20778824 -0.23635946 -1.2106134\n",
      " -0.09568304 -0.21694192 -1.2802725  -0.0403277  -0.25612688 -1.400624\n",
      "  0.01192794 -0.26258415 -1.280058    0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.769 3.78  3.795 ... 3.7   3.684 3.684]\n",
      " [3.776 3.79  3.801 ... 3.674 3.665 3.663]\n",
      " [3.781 3.795 3.805 ... 3.639 3.638 3.644]\n",
      " ...\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.331 3.336 3.34  ... 3.318 3.314 3.322]\n",
      " [3.313 3.319 3.32  ... 3.305 3.305 3.316]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0031, -0.0814, -0.2405,  ...,  0.0329, -0.2608, -1.2804],\n",
      "        [-0.0031, -0.0814, -0.2405,  ...,  0.0329, -0.2608, -1.2804],\n",
      "        [-0.0031, -0.0814, -0.2405,  ...,  0.0329, -0.2608, -1.2804],\n",
      "        ...,\n",
      "        [-0.2130,  0.3851, -0.1762,  ..., -0.7650,  0.9111, -0.4918],\n",
      "        [-0.1218, -0.1256,  0.6510,  ..., -0.2091,  0.6166,  0.2999],\n",
      "        [-0.1218, -0.1256,  0.6510,  ..., -0.2091,  0.6166,  0.2999]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.00313354 -0.08137254 -0.24045369  0.01704896 -0.21632741 -0.62174886\n",
      " -0.07478658 -0.41201147 -1.3927718  -0.22100548 -0.47357583 -1.6972061\n",
      " -0.39077    -0.5914575  -2.1739244  -0.21356183 -0.6940211  -1.561339\n",
      "  0.01722971 -0.729962   -1.3674178  -0.03731374 -0.6700609  -1.4170699\n",
      " -0.04228925 -0.80643463 -1.5399486  -0.16493632 -0.5893165  -1.4669513\n",
      " -0.07870938 -0.64675856 -1.447795   -0.07966281 -0.61563754 -1.5442991\n",
      "  0.05191793 -0.65016234 -1.5906775  -0.06602035 -0.49322385 -1.293289\n",
      " -0.19229327 -0.2644831  -1.9567556  -0.02303444 -0.4272367  -1.9580162\n",
      "  0.14135423 -0.38787052 -1.4441407  -0.1820274  -0.25554314 -1.225396\n",
      " -0.09056342 -0.23261209 -1.3091432  -0.04492001 -0.2522105  -1.4268593\n",
      "  0.0329274  -0.26083785 -1.2804285 ]\n",
      "data: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "mask: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[-0.0333,  0.0448,  0.4349,  ..., -0.2319, -0.0727, -0.3665],\n",
      "        [-0.0333,  0.0448,  0.4349,  ..., -0.2319, -0.0727, -0.3665],\n",
      "        [-0.0333,  0.0448,  0.4349,  ..., -0.2319, -0.0727, -0.3665],\n",
      "        ...,\n",
      "        [ 0.3777,  0.0338, -0.4249,  ...,  0.2617,  0.7308, -0.4466],\n",
      "        [ 0.3953,  0.0267, -0.4035,  ...,  0.2826,  0.7878, -0.4917],\n",
      "        [ 0.3953,  0.0267, -0.4035,  ...,  0.2826,  0.7878, -0.4917]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.03331171  0.04475227  0.43488228 -0.08014037 -0.1283966   0.04251438\n",
      " -0.43275732 -0.30288675 -0.52919793 -0.6339379  -0.4416606  -0.64817005\n",
      " -0.92006445 -0.45257625 -1.0338042  -0.32898337 -0.5638237  -0.5347692\n",
      " -0.48484027 -0.5967127  -0.22969621 -0.4647954  -0.4992316  -0.28106982\n",
      " -0.5385193  -0.63992906 -0.29921997 -0.30783296 -0.44557652 -0.56127876\n",
      " -0.40865445 -0.4935944  -0.37488335 -0.53361404 -0.46619457 -0.43082047\n",
      " -0.28280222 -0.36111313 -0.51204956 -0.349191   -0.46142566 -0.4435553\n",
      " -0.3940547  -0.24101767 -0.6121369  -0.40089983 -0.258882   -0.64137584\n",
      " -0.26609105 -0.26819363 -0.39044648 -0.29307145 -0.20285279 -0.41877973\n",
      " -0.48265147 -0.14345443 -0.4460817  -0.39757866 -0.02279501 -0.5691981\n",
      " -0.23187025 -0.07268029 -0.3664986 ]\n",
      "init: [-0.03331171  0.04475227  0.43488228 -0.08014037 -0.1283966   0.04251438\n",
      " -0.43275732 -0.30288675 -0.52919793 -0.6339379  -0.4416606  -0.64817005\n",
      " -0.92006445 -0.45257625 -1.0338042  -0.32898337 -0.5638237  -0.5347692\n",
      " -0.48484027 -0.5967127  -0.22969621 -0.4647954  -0.4992316  -0.28106982\n",
      " -0.5385193  -0.63992906 -0.29921997 -0.30783296 -0.44557652 -0.56127876\n",
      " -0.40865445 -0.4935944  -0.37488335 -0.53361404 -0.46619457 -0.43082047\n",
      " -0.28280222 -0.36111313 -0.51204956 -0.349191   -0.46142566 -0.4435553\n",
      " -0.3940547  -0.24101767 -0.6121369  -0.40089983 -0.258882   -0.64137584\n",
      " -0.26609105 -0.26819363 -0.39044648 -0.29307145 -0.20285279 -0.41877973\n",
      " -0.48265147 -0.14345443 -0.4460817  -0.39757866 -0.02279501 -0.5691981\n",
      " -0.23187025 -0.07268029 -0.3664986 ]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [-0.03331171  0.04475227  0.43488228 -0.08014037 -0.1283966   0.04251438\n",
      " -0.4327573  -0.30288675 -0.52919793 -0.6339379  -0.4416606  -0.6481701\n",
      " -0.92006445 -0.45257625 -1.0338042  -0.3289834  -0.5638237  -0.5347692\n",
      " -0.48484027 -0.5967127  -0.22969621 -0.4647954  -0.4992316  -0.28106982\n",
      " -0.5385193  -0.63992906 -0.29921997 -0.30783296 -0.44557652 -0.56127876\n",
      " -0.40865445 -0.4935944  -0.37488335 -0.53361404 -0.46619457 -0.43082047\n",
      " -0.28280222 -0.36111313 -0.51204956 -0.349191   -0.46142566 -0.4435553\n",
      " -0.3940547  -0.24101767 -0.6121369  -0.4008998  -0.258882   -0.6413758\n",
      " -0.26609105 -0.26819363 -0.39044648 -0.29307145 -0.20285279 -0.41877973\n",
      " -0.48265147 -0.14345443 -0.4460817  -0.39757866 -0.02279501 -0.5691981\n",
      " -0.23187025 -0.07268029 -0.3664986   0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[ 0.0976, -0.1282, -0.0014,  ..., -0.1768, -0.3206, -0.4777],\n",
      "        [ 0.0976, -0.1282, -0.0014,  ..., -0.1768, -0.3206, -0.4777],\n",
      "        [ 0.0976, -0.1282, -0.0014,  ..., -0.1768, -0.3206, -0.4777],\n",
      "        ...,\n",
      "        [ 0.3807, -0.3220,  0.1800,  ...,  0.0255,  0.4814, -0.7080],\n",
      "        [ 0.2470, -0.0607,  0.3909,  ..., -0.2374,  0.5988, -0.3907],\n",
      "        [ 0.2470, -0.0607,  0.3909,  ..., -0.2374,  0.5988, -0.3907]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.09764333 -0.12818111 -0.00139142  0.01448007 -0.21023431 -0.21530163\n",
      " -0.19374429 -0.3714562  -0.6253542  -0.37554568 -0.43195403 -0.8070229\n",
      " -0.6704508  -0.44929424 -1.1941503  -0.23161386 -0.6267141  -0.80595434\n",
      " -0.49900675 -0.64790744 -1.1695795  -0.50235474 -0.5776095  -1.1860143\n",
      " -0.41920716 -0.7813401  -1.1322979  -0.17645065 -0.54897135 -0.7414032\n",
      " -0.28347117 -0.59008485 -0.56041884 -0.39183152 -0.6059165  -0.66071415\n",
      " -0.27003443 -0.5561799  -0.7184459  -0.17070954 -0.496056   -0.6637727\n",
      " -0.30694145 -0.41535404 -0.9040673  -0.271919   -0.47494265 -0.9372133\n",
      " -0.24233057 -0.4594384  -0.5834764  -0.14623041 -0.35705602 -0.6308223\n",
      " -0.28953373 -0.35680002 -0.5369657  -0.25904596 -0.32209873 -0.6326524\n",
      " -0.17676057 -0.32056063 -0.47769672]\n",
      "data: [ 0.09764333 -0.12818111 -0.00139142  0.01448007 -0.21023431 -0.21530163\n",
      " -0.19374427 -0.37145624 -0.6253542  -0.37554568 -0.43195403 -0.8070229\n",
      " -0.6704508  -0.44929424 -1.1941503  -0.23161386 -0.6267141  -0.80595434\n",
      " -0.49900672 -0.64790744 -1.1695795  -0.50235474 -0.5776095  -1.1860143\n",
      " -0.41920716 -0.7813401  -1.1322979  -0.17645065 -0.54897135 -0.7414032\n",
      " -0.28347117 -0.59008485 -0.56041884 -0.39183152 -0.6059165  -0.6607141\n",
      " -0.27003443 -0.5561799  -0.7184459  -0.17070954 -0.496056   -0.66377276\n",
      " -0.30694145 -0.41535404 -0.9040673  -0.271919   -0.47494265 -0.9372133\n",
      " -0.24233057 -0.4594384  -0.5834764  -0.14623041 -0.35705602 -0.6308223\n",
      " -0.28953373 -0.3568     -0.5369657  -0.25904596 -0.32209873 -0.6326524\n",
      " -0.17676058 -0.32056063 -0.47769672  0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[ 0.0900,  0.1017, -0.2073,  ...,  0.3068, -0.1375, -1.1475],\n",
      "        [ 0.0900,  0.1017, -0.2073,  ...,  0.3068, -0.1375, -1.1475],\n",
      "        [ 0.0900,  0.1017, -0.2073,  ...,  0.3068, -0.1375, -1.1475],\n",
      "        ...,\n",
      "        [ 0.1401, -0.4187,  0.1613,  ...,  0.3673,  0.7864, -0.4577],\n",
      "        [-0.1169,  0.0864,  0.2130,  ..., -0.8328,  0.7281, -0.1858],\n",
      "        [-0.1169,  0.0864,  0.2130,  ..., -0.8328,  0.7281, -0.1858]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.09004354  0.10170863 -0.2072531   0.10468787  0.00330134 -0.5347936\n",
      "  0.00726356 -0.16720459 -1.1657598  -0.10037886 -0.2120057  -1.4103525\n",
      " -0.22976235 -0.3165544  -1.8076682  -0.07890822 -0.4489165  -1.3445523\n",
      "  0.10811283 -0.4684853  -1.2729223   0.13283332 -0.36777702 -1.302366\n",
      "  0.21368803 -0.50388235 -1.3826895  -0.02680372 -0.36518514 -1.2833881\n",
      "  0.09790829 -0.41684842 -1.2526379   0.16122824 -0.3782552  -1.2983732\n",
      "  0.37268096 -0.39036024 -1.3855743   0.09173962 -0.3243102  -1.1600358\n",
      "  0.02003389 -0.08915249 -1.7330775   0.2276017  -0.2581452  -1.7140632\n",
      "  0.43774143 -0.18318337 -1.3041556  -0.00486229 -0.11566274 -1.0981929\n",
      "  0.09842834 -0.07345021 -1.1778378   0.20156622 -0.10605052 -1.2936413\n",
      "  0.30680764 -0.13745171 -1.1474593 ]\n",
      "data: [ 0.09004354  0.10170863 -0.2072531   0.10468787  0.00330134 -0.5347936\n",
      "  0.00726356 -0.16720459 -1.1657598  -0.10037886 -0.2120057  -1.4103525\n",
      " -0.22976235 -0.3165544  -1.8076682  -0.07890822 -0.44891652 -1.3445523\n",
      "  0.10811283 -0.4684853  -1.2729223   0.13283332 -0.36777702 -1.302366\n",
      "  0.21368803 -0.50388235 -1.3826895  -0.02680372 -0.36518514 -1.283388\n",
      "  0.09790829 -0.41684842 -1.2526379   0.16122824 -0.3782552  -1.2983732\n",
      "  0.37268096 -0.39036024 -1.3855743   0.09173962 -0.3243102  -1.1600358\n",
      "  0.02003389 -0.08915249 -1.7330775   0.2276017  -0.2581452  -1.7140632\n",
      "  0.43774143 -0.18318337 -1.3041556  -0.00486229 -0.11566274 -1.0981929\n",
      "  0.09842834 -0.07345021 -1.1778378   0.20156622 -0.10605052 -1.2936413\n",
      "  0.30680764 -0.13745171 -1.1474593   0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BB38>\n",
      "tensor([[ 0.1626, -0.2447, -0.2165,  ...,  0.1342, -0.3837, -1.3979],\n",
      "        [ 0.1626, -0.2447, -0.2165,  ...,  0.1342, -0.3837, -1.3979],\n",
      "        [ 0.1626, -0.2447, -0.2165,  ...,  0.1342, -0.3837, -1.3979],\n",
      "        ...,\n",
      "        [-0.3962,  0.3155, -0.2418,  ..., -0.9098,  0.8485, -0.5920],\n",
      "        [-0.1954,  0.1442,  0.4025,  ..., -0.1335,  0.9645,  0.0509],\n",
      "        [-0.1954,  0.1442,  0.4025,  ..., -0.1335,  0.9645,  0.0509]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.16259731 -0.24474892 -0.21654204  0.17051058 -0.42394608 -0.75639176\n",
      "  0.1134444  -0.5734697  -1.4409375  -0.03744851 -0.6310879  -1.7440678\n",
      " -0.24560687 -0.75492847 -2.2096317  -0.07778284 -0.8134382  -1.6215749\n",
      "  0.17727114 -0.8176117  -1.3409047   0.13588884 -0.75505805 -1.3899015\n",
      "  0.12326978 -0.8522508  -1.492666   -0.03816712 -0.68302584 -1.5522274\n",
      "  0.0609953  -0.7390543  -1.5093521   0.04989593 -0.7221918  -1.6149815\n",
      "  0.17674719 -0.7207309  -1.6925542   0.05065572 -0.6286533  -1.3766742\n",
      " -0.02669583 -0.39854333 -1.8704634   0.09021126 -0.5355292  -1.8423752\n",
      "  0.22470109 -0.49820426 -1.535238   -0.03708974 -0.37536836 -1.3240654\n",
      "  0.03305179 -0.35118255 -1.382289    0.09875719 -0.37684909 -1.4995192\n",
      "  0.13417494 -0.3836607  -1.3978517 ]\n",
      "data: [ 0.16259731 -0.24474892 -0.21654204  0.17051058 -0.42394608 -0.75639176\n",
      "  0.1134444  -0.5734697  -1.4409375  -0.03744851 -0.6310879  -1.7440678\n",
      " -0.24560685 -0.7549284  -2.2096317  -0.07778284 -0.8134382  -1.6215749\n",
      "  0.17727114 -0.8176117  -1.3409047   0.13588884 -0.75505805 -1.3899016\n",
      "  0.12326977 -0.8522508  -1.492666   -0.03816712 -0.68302584 -1.5522274\n",
      "  0.0609953  -0.7390543  -1.5093521   0.04989593 -0.72219175 -1.6149815\n",
      "  0.17674719 -0.7207309  -1.6925541   0.05065572 -0.6286533  -1.3766742\n",
      " -0.02669583 -0.39854333 -1.8704634   0.09021126 -0.5355292  -1.8423752\n",
      "  0.2247011  -0.49820426 -1.535238   -0.03708974 -0.37536836 -1.3240654\n",
      "  0.03305179 -0.35118255 -1.3822892   0.09875719 -0.37684909 -1.4995192\n",
      "  0.13417494 -0.3836607  -1.3978517   0.04      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[-0.0014, -0.2214, -0.1263,  ...,  0.0219, -0.4075, -1.1864],\n",
      "        [-0.0014, -0.2214, -0.1263,  ...,  0.0219, -0.4075, -1.1864],\n",
      "        [-0.0014, -0.2214, -0.1263,  ...,  0.0219, -0.4075, -1.1864],\n",
      "        ...,\n",
      "        [ 0.0067,  0.6645, -0.2338,  ..., -0.3585,  1.1325, -0.6183],\n",
      "        [-0.0874,  0.0135,  0.6353,  ..., -0.0416,  0.7029,  0.2584],\n",
      "        [-0.0874,  0.0135,  0.6353,  ..., -0.0416,  0.7029,  0.2584]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-1.3944982e-03 -2.2139496e-01 -1.2627394e-01  2.3896504e-02\n",
      " -3.5566261e-01 -4.8942316e-01 -6.1672233e-02 -5.7245290e-01\n",
      " -1.3055301e+00 -2.1586958e-01 -6.4056301e-01 -1.6239984e+00\n",
      " -3.9545536e-01 -7.6506054e-01 -2.1170881e+00 -2.1994479e-01\n",
      " -8.3480060e-01 -1.5171304e+00  3.2335058e-02 -8.9029098e-01\n",
      " -1.2990570e+00 -3.5176113e-02 -8.3683205e-01 -1.3376410e+00\n",
      " -5.8789648e-02 -9.8474634e-01 -1.4589331e+00 -1.6269988e-01\n",
      " -7.2757673e-01 -1.4053984e+00 -8.0031395e-02 -8.0164874e-01\n",
      " -1.3744018e+00 -9.1910936e-02 -7.8105390e-01 -1.4764490e+00\n",
      "  1.6207248e-02 -8.2567239e-01 -1.5186138e+00 -5.7775117e-02\n",
      " -6.2455750e-01 -1.2261112e+00 -2.0671402e-01 -4.0292698e-01\n",
      " -1.9258494e+00 -3.7350178e-02 -5.8595496e-01 -1.9243019e+00\n",
      "  1.1297764e-01 -5.4334009e-01 -1.3564241e+00 -1.8654317e-01\n",
      " -3.8413808e-01 -1.1533756e+00 -8.6353734e-02 -3.6845621e-01\n",
      " -1.2241373e+00 -4.1480303e-02 -4.0528905e-01 -1.3338790e+00\n",
      "  2.1869339e-02 -4.0752119e-01 -1.1863778e+00]\n",
      "data: [-1.3944982e-03 -2.2139496e-01 -1.2627394e-01  2.3896504e-02\n",
      " -3.5566261e-01 -4.8942316e-01 -6.1672233e-02 -5.7245290e-01\n",
      " -1.3055301e+00 -2.1586958e-01 -6.4056307e-01 -1.6239984e+00\n",
      " -3.9545536e-01 -7.6506060e-01 -2.1170881e+00 -2.1994478e-01\n",
      " -8.3480054e-01 -1.5171304e+00  3.2335058e-02 -8.9029098e-01\n",
      " -1.2990570e+00 -3.5176113e-02 -8.3683205e-01 -1.3376410e+00\n",
      " -5.8789648e-02 -9.8474634e-01 -1.4589331e+00 -1.6269988e-01\n",
      " -7.2757673e-01 -1.4053984e+00 -8.0031395e-02 -8.0164874e-01\n",
      " -1.3744018e+00 -9.1910936e-02 -7.8105390e-01 -1.4764490e+00\n",
      "  1.6207248e-02 -8.2567239e-01 -1.5186139e+00 -5.7775117e-02\n",
      " -6.2455750e-01 -1.2261112e+00 -2.0671402e-01 -4.0292698e-01\n",
      " -1.9258494e+00 -3.7350178e-02 -5.8595496e-01 -1.9243019e+00\n",
      "  1.1297764e-01 -5.4334009e-01 -1.3564241e+00 -1.8654317e-01\n",
      " -3.8413808e-01 -1.1533756e+00 -8.6353734e-02 -3.6845624e-01\n",
      " -1.2241373e+00 -4.1480303e-02 -4.0528905e-01 -1.3338790e+00\n",
      "  2.1869339e-02 -4.0752116e-01 -1.1863778e+00  5.0000001e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0126, -0.0440, -0.2498,  ..., -0.0144, -0.2194, -1.2621],\n",
      "        [-0.0126, -0.0440, -0.2498,  ..., -0.0144, -0.2194, -1.2621],\n",
      "        [-0.0126, -0.0440, -0.2498,  ..., -0.0144, -0.2194, -1.2621],\n",
      "        ...,\n",
      "        [-0.1622,  0.4425,  0.0162,  ..., -0.4609,  1.0799, -0.4565],\n",
      "        [ 0.0126,  0.0322,  0.7024,  ..., -0.0314,  0.6517,  0.3784],\n",
      "        [ 0.0126,  0.0322,  0.7024,  ..., -0.0314,  0.6517,  0.3784]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01260016 -0.04402129 -0.24975152  0.01478846 -0.15472816 -0.5266131\n",
      " -0.12502363 -0.39141747 -1.3883462  -0.28649244 -0.4564404  -1.6764512\n",
      " -0.44515777 -0.5470189  -2.1928806  -0.21939155 -0.6873365  -1.5933857\n",
      " -0.04077457 -0.75610626 -1.4431407  -0.09004906 -0.6806608  -1.4832897\n",
      " -0.08545484 -0.8435774  -1.6042371  -0.17609191 -0.5906966  -1.4917936\n",
      " -0.11457139 -0.64559436 -1.4508238  -0.11473942 -0.609194   -1.5363119\n",
      "  0.02967812 -0.6430152  -1.5548451  -0.08876392 -0.47219065 -1.336669\n",
      " -0.25466174 -0.23785785 -2.0866678  -0.06368307 -0.41475224 -2.1103518\n",
      "  0.1194841  -0.36610073 -1.4301422  -0.22323063 -0.2350219  -1.257385\n",
      " -0.15236887 -0.2039865  -1.3396013  -0.12047899 -0.21180402 -1.4516761\n",
      " -0.01440995 -0.21942571 -1.2620718 ]\n",
      "data: [-0.01260016 -0.04402129 -0.24975152  0.01478846 -0.15472816 -0.5266131\n",
      " -0.12502363 -0.39141747 -1.3883462  -0.28649244 -0.4564404  -1.6764512\n",
      " -0.44515777 -0.5470189  -2.1928806  -0.21939155 -0.6873365  -1.5933856\n",
      " -0.04077457 -0.75610626 -1.4431407  -0.09004906 -0.6806608  -1.4832898\n",
      " -0.08545484 -0.84357744 -1.6042371  -0.17609192 -0.5906966  -1.4917936\n",
      " -0.11457139 -0.64559436 -1.4508238  -0.11473942 -0.609194   -1.5363117\n",
      "  0.02967812 -0.6430152  -1.5548451  -0.08876392 -0.47219068 -1.336669\n",
      " -0.25466174 -0.23785786 -2.0866678  -0.06368307 -0.41475224 -2.1103518\n",
      "  0.1194841  -0.36610073 -1.4301422  -0.22323063 -0.23502189 -1.257385\n",
      " -0.15236887 -0.2039865  -1.3396013  -0.120479   -0.211804   -1.4516761\n",
      " -0.01440995 -0.21942572 -1.2620718   0.06      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0241, -0.0234, -0.1925,  ...,  0.0487, -0.2037, -1.2475],\n",
      "        [ 0.0241, -0.0234, -0.1925,  ...,  0.0487, -0.2037, -1.2475],\n",
      "        [ 0.0241, -0.0234, -0.1925,  ...,  0.0487, -0.2037, -1.2475],\n",
      "        ...,\n",
      "        [-0.2241,  0.2757, -0.0837,  ..., -0.8886,  0.7851, -0.3009],\n",
      "        [-0.1668, -0.1511,  0.5197,  ..., -0.2715,  0.5750,  0.2545],\n",
      "        [-0.1668, -0.1511,  0.5197,  ..., -0.2715,  0.5750,  0.2545]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.4095450e-02 -2.3397317e-02 -1.9246504e-01  3.6783312e-02\n",
      " -1.6441725e-01 -6.0392940e-01 -4.2973556e-02 -3.3719155e-01\n",
      " -1.3340273e+00 -1.8918999e-01 -3.9412382e-01 -1.6379774e+00\n",
      " -3.6821616e-01 -5.1253116e-01 -2.1097999e+00 -1.8746799e-01\n",
      " -6.2799186e-01 -1.4924631e+00  4.1402489e-02 -6.5166652e-01\n",
      " -1.3033230e+00 -1.1073619e-02 -5.8972663e-01 -1.3564935e+00\n",
      " -7.5356439e-03 -7.1693379e-01 -1.4738281e+00 -1.4160079e-01\n",
      " -5.2175683e-01 -1.4072740e+00 -5.0551347e-02 -5.7420695e-01\n",
      " -1.3881953e+00 -5.4612584e-02 -5.4588443e-01 -1.4897521e+00\n",
      "  7.8031853e-02 -5.7079208e-01 -1.5400798e+00 -4.5987733e-02\n",
      " -4.3723911e-01 -1.2351930e+00 -1.5537095e-01 -2.0841861e-01\n",
      " -1.8606520e+00 -5.9393793e-04 -3.6003166e-01 -1.8570783e+00\n",
      "  1.5815663e-01 -3.2823038e-01 -1.3971918e+00 -1.5282506e-01\n",
      " -1.9761012e-01 -1.1739750e+00 -6.6620931e-02 -1.7802325e-01\n",
      " -1.2591355e+00 -2.2320703e-02 -1.9408941e-01 -1.3791182e+00\n",
      "  4.8713304e-02 -2.0370828e-01 -1.2475183e+00]\n",
      "data: [ 2.4095450e-02 -2.3397317e-02 -1.9246504e-01  3.6783312e-02\n",
      " -1.6441725e-01 -6.0392940e-01 -4.2973556e-02 -3.3719155e-01\n",
      " -1.3340273e+00 -1.8918999e-01 -3.9412385e-01 -1.6379772e+00\n",
      " -3.6821616e-01 -5.1253116e-01 -2.1097999e+00 -1.8746799e-01\n",
      " -6.2799186e-01 -1.4924631e+00  4.1402489e-02 -6.5166646e-01\n",
      " -1.3033230e+00 -1.1073619e-02 -5.8972663e-01 -1.3564935e+00\n",
      " -7.5356434e-03 -7.1693385e-01 -1.4738281e+00 -1.4160079e-01\n",
      " -5.2175683e-01 -1.4072740e+00 -5.0551347e-02 -5.7420695e-01\n",
      " -1.3881954e+00 -5.4612584e-02 -5.4588443e-01 -1.4897521e+00\n",
      "  7.8031853e-02 -5.7079208e-01 -1.5400798e+00 -4.5987736e-02\n",
      " -4.3723911e-01 -1.2351930e+00 -1.5537095e-01 -2.0841862e-01\n",
      " -1.8606520e+00 -5.9393793e-04 -3.6003166e-01 -1.8570782e+00\n",
      "  1.5815663e-01 -3.2823035e-01 -1.3971918e+00 -1.5282506e-01\n",
      " -1.9761012e-01 -1.1739750e+00 -6.6620931e-02 -1.7802325e-01\n",
      " -1.2591355e+00 -2.2320703e-02 -1.9408941e-01 -1.3791182e+00\n",
      "  4.8713304e-02 -2.0370826e-01 -1.2475183e+00  7.0000000e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B320>\n",
      "tensor([[ 0.0102, -0.0693, -0.2598,  ...,  0.0176, -0.2459, -1.3157],\n",
      "        [ 0.0102, -0.0693, -0.2598,  ...,  0.0176, -0.2459, -1.3157],\n",
      "        [ 0.0102, -0.0693, -0.2598,  ...,  0.0176, -0.2459, -1.3157],\n",
      "        ...,\n",
      "        [-0.3330,  0.2517, -0.2988,  ..., -0.7963,  0.7065, -0.4631],\n",
      "        [-0.1239, -0.0322,  0.6275,  ..., -0.2299,  0.7668,  0.3044],\n",
      "        [-0.1239, -0.0322,  0.6275,  ..., -0.2299,  0.7668,  0.3044]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01024572 -0.06931494 -0.2598051   0.03312368 -0.2075434  -0.68211603\n",
      " -0.07930832 -0.39508712 -1.4422097  -0.22210291 -0.460741   -1.7198243\n",
      " -0.37954766 -0.5575431  -2.203863   -0.18865076 -0.6795629  -1.5934205\n",
      " -0.01316372 -0.71378154 -1.4135439  -0.0533497  -0.6419605  -1.4709892\n",
      " -0.05412048 -0.7772885  -1.5830765  -0.15499717 -0.5786366  -1.5188525\n",
      " -0.08566172 -0.6265348  -1.4798243  -0.102837   -0.59772456 -1.5636504\n",
      "  0.03792007 -0.6093027  -1.6019843  -0.08149062 -0.4948063  -1.3575823\n",
      " -0.18831497 -0.26535553 -1.9734454  -0.04275692 -0.40987033 -1.9808154\n",
      "  0.11367745 -0.37895876 -1.4695594  -0.17289576 -0.26083225 -1.2903743\n",
      " -0.11604499 -0.23133117 -1.3662765  -0.07049152 -0.23005366 -1.482204\n",
      "  0.01759061 -0.24590851 -1.3157165 ]\n",
      "data: [ 0.01024572 -0.06931494 -0.2598051   0.03312368 -0.20754342 -0.68211603\n",
      " -0.07930832 -0.39508712 -1.4422097  -0.22210291 -0.460741   -1.7198243\n",
      " -0.37954766 -0.5575431  -2.203863   -0.18865076 -0.6795629  -1.5934205\n",
      " -0.01316372 -0.71378154 -1.413544   -0.0533497  -0.6419605  -1.4709892\n",
      " -0.05412048 -0.7772885  -1.5830765  -0.15499717 -0.5786366  -1.5188526\n",
      " -0.08566172 -0.6265348  -1.4798244  -0.102837   -0.59772456 -1.5636504\n",
      "  0.03792007 -0.6093027  -1.6019843  -0.08149062 -0.4948063  -1.3575824\n",
      " -0.18831497 -0.26535553 -1.9734454  -0.04275693 -0.40987033 -1.9808154\n",
      "  0.11367746 -0.3789588  -1.4695594  -0.17289576 -0.26083225 -1.2903743\n",
      " -0.11604499 -0.23133117 -1.3662765  -0.07049152 -0.23005368 -1.482204\n",
      "  0.01759061 -0.24590851 -1.3157165   0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[ 0.0310, -0.0370, -0.2254,  ...,  0.0422, -0.2325, -1.2599],\n",
      "        [ 0.0310, -0.0370, -0.2254,  ...,  0.0422, -0.2325, -1.2599],\n",
      "        [ 0.0310, -0.0370, -0.2254,  ...,  0.0422, -0.2325, -1.2599],\n",
      "        ...,\n",
      "        [-0.1242,  0.4261, -0.1213,  ..., -0.7403,  0.9402, -0.3746],\n",
      "        [-0.1425, -0.1996,  0.5466,  ..., -0.2242,  0.5669,  0.2386],\n",
      "        [-0.1425, -0.1996,  0.5466,  ..., -0.2242,  0.5669,  0.2386]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03098525 -0.0369584  -0.22536117  0.0457354  -0.1634521  -0.6162344\n",
      " -0.06468469 -0.34620738 -1.3712485  -0.21197489 -0.40877116 -1.6614351\n",
      " -0.37882566 -0.5032124  -2.1528764  -0.16229638 -0.65427005 -1.5283666\n",
      "  0.00432426 -0.69171864 -1.3727202  -0.04136017 -0.61794734 -1.4362378\n",
      " -0.03623128 -0.7666334  -1.550544   -0.1260556  -0.5603209  -1.4475327\n",
      " -0.06136589 -0.60525876 -1.4175541  -0.08286375 -0.58111477 -1.5134637\n",
      "  0.05832118 -0.59067565 -1.5440633  -0.0524356  -0.47312889 -1.2852862\n",
      " -0.16334678 -0.24868193 -1.9304912  -0.01802361 -0.39201474 -1.9440534\n",
      "  0.14322752 -0.36902076 -1.4075608  -0.1451025  -0.24416183 -1.2203326\n",
      " -0.09040126 -0.22229508 -1.3060975  -0.05568475 -0.21716872 -1.4232748\n",
      "  0.04217426 -0.23254047 -1.2598553 ]\n",
      "data: [ 0.03098525 -0.0369584  -0.22536117  0.0457354  -0.1634521  -0.6162344\n",
      " -0.06468469 -0.34620738 -1.3712485  -0.21197489 -0.40877116 -1.6614351\n",
      " -0.3788257  -0.5032124  -2.1528764  -0.16229638 -0.65427    -1.5283666\n",
      "  0.00432426 -0.6917187  -1.3727202  -0.04136017 -0.61794734 -1.4362378\n",
      " -0.03623128 -0.7666334  -1.550544   -0.1260556  -0.5603209  -1.4475327\n",
      " -0.06136589 -0.60525876 -1.4175541  -0.08286375 -0.58111477 -1.5134637\n",
      "  0.05832118 -0.59067565 -1.5440632  -0.0524356  -0.47312889 -1.2852863\n",
      " -0.16334678 -0.24868193 -1.9304912  -0.01802361 -0.39201474 -1.9440533\n",
      "  0.14322752 -0.36902076 -1.4075608  -0.1451025  -0.24416183 -1.2203326\n",
      " -0.09040126 -0.22229508 -1.3060975  -0.05568475 -0.21716872 -1.4232746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.04217426 -0.23254047 -1.2598553   0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0199, -0.0697, -0.2487,  ...,  0.0320, -0.2531, -1.2927],\n",
      "        [ 0.0199, -0.0697, -0.2487,  ...,  0.0320, -0.2531, -1.2927],\n",
      "        [ 0.0199, -0.0697, -0.2487,  ...,  0.0320, -0.2531, -1.2927],\n",
      "        ...,\n",
      "        [-0.3097,  0.2221, -0.2705,  ..., -0.8127,  0.6871, -0.4634],\n",
      "        [-0.1198, -0.0546,  0.5971,  ..., -0.2316,  0.7330,  0.2658],\n",
      "        [-0.1198, -0.0546,  0.5971,  ..., -0.2316,  0.7330,  0.2658]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01993579 -0.06966496 -0.24868593  0.04546595 -0.20132595 -0.65480894\n",
      " -0.06169572 -0.38936648 -1.4213474  -0.20471168 -0.45474204 -1.707409\n",
      " -0.36309698 -0.5531723  -2.1952357  -0.1739611  -0.67992055 -1.5750332\n",
      "  0.01060649 -0.7160629  -1.3920755  -0.03621762 -0.6476884  -1.4501544\n",
      " -0.04519835 -0.7880746  -1.5663325  -0.13796845 -0.5832308  -1.4938437\n",
      " -0.06822199 -0.6332417  -1.4603218  -0.0903716  -0.604864   -1.5490668\n",
      "  0.04306478 -0.62273866 -1.5850796  -0.06169336 -0.4949101  -1.3288889\n",
      " -0.17586058 -0.26691678 -1.972605   -0.02801518 -0.41588277 -1.9816806\n",
      "  0.12506765 -0.38769275 -1.4466456  -0.15750927 -0.26335585 -1.261453\n",
      " -0.09531512 -0.2372543  -1.3397003  -0.05449202 -0.23855072 -1.4558673\n",
      "  0.03199758 -0.25306916 -1.2926606 ]\n",
      "data: [ 0.01993579 -0.06966496 -0.24868593  0.04546595 -0.20132595 -0.65480894\n",
      " -0.06169572 -0.3893665  -1.4213474  -0.20471169 -0.45474204 -1.707409\n",
      " -0.363097   -0.5531723  -2.1952357  -0.1739611  -0.67992055 -1.5750333\n",
      "  0.01060649 -0.7160629  -1.3920755  -0.03621762 -0.6476884  -1.4501544\n",
      " -0.04519835 -0.7880747  -1.5663323  -0.13796845 -0.5832308  -1.4938437\n",
      " -0.06822199 -0.6332417  -1.4603218  -0.0903716  -0.604864   -1.5490668\n",
      "  0.04306478 -0.62273866 -1.5850796  -0.06169336 -0.4949101  -1.3288889\n",
      " -0.17586058 -0.26691678 -1.972605   -0.02801518 -0.41588277 -1.9816806\n",
      "  0.12506765 -0.38769275 -1.4466456  -0.15750927 -0.26335585 -1.261453\n",
      " -0.09531512 -0.23725432 -1.3397003  -0.05449202 -0.23855072 -1.4558673\n",
      "  0.03199758 -0.25306916 -1.2926605   0.1       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F5F8>\n",
      "tensor([[ 0.0187, -0.0340, -0.2442,  ...,  0.0442, -0.2280, -1.2735],\n",
      "        [ 0.0187, -0.0340, -0.2442,  ...,  0.0442, -0.2280, -1.2735],\n",
      "        [ 0.0187, -0.0340, -0.2442,  ...,  0.0442, -0.2280, -1.2735],\n",
      "        ...,\n",
      "        [-0.1402,  0.3682, -0.1050,  ..., -0.7597,  0.8633, -0.3519],\n",
      "        [-0.1398, -0.1774,  0.5514,  ..., -0.2241,  0.5857,  0.2216],\n",
      "        [-0.1398, -0.1774,  0.5514,  ..., -0.2241,  0.5857,  0.2216]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0187253  -0.0340382  -0.24415536  0.03442964 -0.163959   -0.6357593\n",
      " -0.06546284 -0.34910768 -1.38576    -0.21017951 -0.41019332 -1.6806914\n",
      " -0.3784844  -0.516016   -2.160459   -0.18052876 -0.6461446  -1.5448583\n",
      "  0.01111954 -0.6821052  -1.3773452  -0.03746217 -0.61397254 -1.4355869\n",
      " -0.03325067 -0.7581028  -1.5510861  -0.13857403 -0.5482849  -1.4597867\n",
      " -0.06493092 -0.5990529  -1.4332521  -0.07838099 -0.5752411  -1.5285146\n",
      "  0.05787501 -0.59343493 -1.5657237  -0.05484162 -0.46058643 -1.2936817\n",
      " -0.17032844 -0.23605642 -1.9470209  -0.01595812 -0.3881109  -1.9539549\n",
      "  0.14444256 -0.3599206  -1.4251697  -0.1539166  -0.22981551 -1.229129\n",
      " -0.08462662 -0.20924242 -1.313206   -0.0444864  -0.21470958 -1.4300601\n",
      "  0.04417196 -0.2280462  -1.273493  ]\n",
      "data: [ 0.0187253  -0.0340382  -0.24415536  0.03442964 -0.16395898 -0.6357593\n",
      " -0.06546284 -0.34910765 -1.3857598  -0.21017951 -0.41019332 -1.6806914\n",
      " -0.37848437 -0.516016   -2.160459   -0.18052876 -0.6461446  -1.5448585\n",
      "  0.01111954 -0.6821052  -1.3773453  -0.03746217 -0.61397254 -1.4355868\n",
      " -0.03325067 -0.7581028  -1.5510861  -0.13857403 -0.5482849  -1.4597867\n",
      " -0.06493092 -0.5990529  -1.4332521  -0.07838099 -0.5752411  -1.5285145\n",
      "  0.05787501 -0.59343493 -1.5657238  -0.05484162 -0.46058643 -1.2936817\n",
      " -0.17032844 -0.23605642 -1.9470209  -0.01595812 -0.38811094 -1.9539549\n",
      "  0.14444256 -0.3599206  -1.4251697  -0.1539166  -0.22981553 -1.229129\n",
      " -0.08462663 -0.20924242 -1.3132061  -0.04448639 -0.21470958 -1.4300601\n",
      "  0.04417196 -0.2280462  -1.273493    0.11      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[ 0.0132, -0.0842, -0.2445,  ...,  0.0303, -0.2682, -1.3034],\n",
      "        [ 0.0132, -0.0842, -0.2445,  ...,  0.0303, -0.2682, -1.3034],\n",
      "        [ 0.0132, -0.0842, -0.2445,  ...,  0.0303, -0.2682, -1.3034],\n",
      "        ...,\n",
      "        [-0.3820,  0.1613, -0.3620,  ..., -0.8460,  0.5785, -0.5050],\n",
      "        [-0.1389, -0.0780,  0.5941,  ..., -0.2411,  0.7120,  0.2555],\n",
      "        [-0.1389, -0.0780,  0.5941,  ..., -0.2411,  0.7120,  0.2555]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01317122 -0.08420759 -0.24447842  0.03387051 -0.22291018 -0.6670164\n",
      " -0.05781015 -0.40272167 -1.4146664  -0.19922587 -0.46573347 -1.707496\n",
      " -0.3650534  -0.57390565 -2.185775   -0.18652824 -0.6884461  -1.5699589\n",
      "  0.01727763 -0.71784186 -1.3798735  -0.03082883 -0.6531759  -1.4372903\n",
      " -0.03544701 -0.7856607  -1.5528088  -0.14727165 -0.5864631  -1.4885563\n",
      " -0.06896251 -0.63815844 -1.4606987  -0.08568815 -0.6128505  -1.5542698\n",
      "  0.04498531 -0.6306838  -1.5992135  -0.06493799 -0.5036864  -1.3195809\n",
      " -0.17197004 -0.27776727 -1.9419552  -0.02732164 -0.42539236 -1.9434358\n",
      "  0.12402959 -0.39702588 -1.4558326  -0.16129605 -0.2691484  -1.2558676\n",
      " -0.0905993  -0.24664025 -1.3354272  -0.04584904 -0.255022   -1.4517472\n",
      "  0.03030748 -0.26821536 -1.3034326 ]\n",
      "data: [ 0.01317122 -0.08420759 -0.24447842  0.03387051 -0.22291018 -0.6670164\n",
      " -0.05781015 -0.40272167 -1.4146664  -0.19922586 -0.46573344 -1.707496\n",
      " -0.36505336 -0.57390565 -2.185775   -0.18652825 -0.6884461  -1.5699589\n",
      "  0.01727763 -0.71784186 -1.3798735  -0.03082883 -0.6531759  -1.4372903\n",
      " -0.03544701 -0.7856607  -1.5528089  -0.14727165 -0.5864631  -1.4885563\n",
      " -0.06896251 -0.63815844 -1.4606987  -0.08568815 -0.6128505  -1.5542697\n",
      "  0.04498531 -0.6306838  -1.5992134  -0.06493799 -0.5036864  -1.3195808\n",
      " -0.17197004 -0.27776727 -1.9419552  -0.02732164 -0.42539233 -1.9434358\n",
      "  0.12402959 -0.39702588 -1.4558327  -0.16129607 -0.2691484  -1.2558676\n",
      " -0.0905993  -0.24664025 -1.335427   -0.04584904 -0.255022   -1.4517472\n",
      "  0.03030748 -0.26821536 -1.3034326   0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FAC8>\n",
      "tensor([[ 0.0292, -0.0712, -0.2568,  ...,  0.0470, -0.2604, -1.2756],\n",
      "        [ 0.0292, -0.0712, -0.2568,  ...,  0.0470, -0.2604, -1.2756],\n",
      "        [ 0.0292, -0.0712, -0.2568,  ...,  0.0470, -0.2604, -1.2756],\n",
      "        ...,\n",
      "        [-0.1131,  0.4028, -0.1182,  ..., -0.6925,  0.9186, -0.4084],\n",
      "        [-0.1317, -0.1494,  0.5852,  ..., -0.2366,  0.6244,  0.2316],\n",
      "        [-0.1317, -0.1494,  0.5852,  ..., -0.2366,  0.6244,  0.2316]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02916662 -0.07121755 -0.25683823  0.05573737 -0.1874336  -0.6280253\n",
      " -0.061896   -0.38714936 -1.4160516  -0.20724678 -0.45026577 -1.7057368\n",
      " -0.36000913 -0.5431663  -2.2015133  -0.15958752 -0.69123936 -1.5733212\n",
      "  0.01099057 -0.7386838  -1.4203315  -0.04005335 -0.6666436  -1.4796513\n",
      " -0.04582473 -0.8232968  -1.5993981  -0.12081635 -0.6024811  -1.483692\n",
      " -0.06065308 -0.65020525 -1.455825   -0.08193974 -0.6211251  -1.5445349\n",
      "  0.05071092 -0.64407504 -1.5690382  -0.04484559 -0.50279593 -1.321171\n",
      " -0.17687836 -0.27244315 -2.0243282  -0.01500839 -0.42969415 -2.0433455\n",
      "  0.14415224 -0.39983675 -1.4338677  -0.14805438 -0.27652055 -1.2486303\n",
      " -0.08610347 -0.24931505 -1.335945   -0.052626   -0.24709266 -1.4516914\n",
      "  0.04699627 -0.2604264  -1.275606  ]\n",
      "data: [ 0.02916662 -0.07121755 -0.25683823  0.05573737 -0.1874336  -0.6280253\n",
      " -0.061896   -0.38714936 -1.4160516  -0.20724678 -0.45026577 -1.7057366\n",
      " -0.3600091  -0.5431663  -2.2015133  -0.15958752 -0.6912393  -1.5733212\n",
      "  0.01099057 -0.7386839  -1.4203315  -0.04005335 -0.6666436  -1.4796513\n",
      " -0.04582473 -0.8232968  -1.5993981  -0.12081634 -0.6024811  -1.483692\n",
      " -0.06065308 -0.65020525 -1.4558251  -0.08193974 -0.6211251  -1.5445349\n",
      "  0.05071092 -0.64407504 -1.569038   -0.04484559 -0.50279593 -1.3211712\n",
      " -0.17687836 -0.27244315 -2.0243282  -0.01500839 -0.42969415 -2.0433455\n",
      "  0.14415224 -0.39983672 -1.4338677  -0.14805438 -0.27652055 -1.2486303\n",
      " -0.08610347 -0.24931505 -1.335945   -0.052626   -0.24709266 -1.4516914\n",
      "  0.04699627 -0.2604264  -1.275606    0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[ 0.0230, -0.0372, -0.2422,  ...,  0.0576, -0.2269, -1.2875],\n",
      "        [ 0.0230, -0.0372, -0.2422,  ...,  0.0576, -0.2269, -1.2875],\n",
      "        [ 0.0230, -0.0372, -0.2422,  ...,  0.0576, -0.2269, -1.2875],\n",
      "        ...,\n",
      "        [-0.1597,  0.3064, -0.0638,  ..., -0.8163,  0.7750, -0.2602],\n",
      "        [-0.1439, -0.1477,  0.5407,  ..., -0.2249,  0.6090,  0.2045],\n",
      "        [-0.1439, -0.1477,  0.5407,  ..., -0.2249,  0.6090,  0.2045]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.3042787e-02 -3.7230767e-02 -2.4223529e-01  3.5724577e-02\n",
      " -1.8028998e-01 -6.5864050e-01 -4.0733352e-02 -3.5711950e-01\n",
      " -1.3823895e+00 -1.8318781e-01 -4.1604334e-01 -1.6870021e+00\n",
      " -3.6080936e-01 -5.3784776e-01 -2.1495292e+00 -1.8492353e-01\n",
      " -6.4026117e-01 -1.5435262e+00  4.4981636e-02 -6.6600215e-01\n",
      " -1.3499525e+00 -6.9272146e-03 -6.0652733e-01 -1.4039832e+00\n",
      " -4.6802983e-03 -7.3688364e-01 -1.5198811e+00 -1.3772333e-01\n",
      " -5.3281367e-01 -1.4575163e+00 -4.7519006e-02 -5.8990312e-01\n",
      " -1.4353443e+00 -5.4078214e-02 -5.6793535e-01 -1.5353205e+00\n",
      "  7.5322591e-02 -5.9230816e-01 -1.5865121e+00 -4.1371629e-02\n",
      " -4.4928089e-01 -1.2843589e+00 -1.5145689e-01 -2.2720829e-01\n",
      " -1.9146917e+00  1.9137785e-03 -3.8235337e-01 -1.9087580e+00\n",
      "  1.5758198e-01 -3.5089782e-01 -1.4381639e+00 -1.4449716e-01\n",
      " -2.1268624e-01 -1.2242508e+00 -5.8170266e-02 -1.9572136e-01\n",
      " -1.3048688e+00 -1.1379279e-02 -2.1538013e-01 -1.4227263e+00\n",
      "  5.7570726e-02 -2.2686397e-01 -1.2875177e+00]\n",
      "data: [ 2.3042787e-02 -3.7230767e-02 -2.4223527e-01  3.5724577e-02\n",
      " -1.8029000e-01 -6.5864050e-01 -4.0733352e-02 -3.5711947e-01\n",
      " -1.3823895e+00 -1.8318781e-01 -4.1604337e-01 -1.6870021e+00\n",
      " -3.6080936e-01 -5.3784776e-01 -2.1495292e+00 -1.8492353e-01\n",
      " -6.4026117e-01 -1.5435262e+00  4.4981636e-02 -6.6600209e-01\n",
      " -1.3499523e+00 -6.9272150e-03 -6.0652733e-01 -1.4039834e+00\n",
      " -4.6802983e-03 -7.3688364e-01 -1.5198811e+00 -1.3772333e-01\n",
      " -5.3281367e-01 -1.4575163e+00 -4.7519006e-02 -5.8990312e-01\n",
      " -1.4353443e+00 -5.4078210e-02 -5.6793535e-01 -1.5353206e+00\n",
      "  7.5322591e-02 -5.9230816e-01 -1.5865121e+00 -4.1371629e-02\n",
      " -4.4928089e-01 -1.2843589e+00 -1.5145689e-01 -2.2720829e-01\n",
      " -1.9146916e+00  1.9137785e-03 -3.8235337e-01 -1.9087580e+00\n",
      "  1.5758198e-01 -3.5089782e-01 -1.4381639e+00 -1.4449716e-01\n",
      " -2.1268624e-01 -1.2242508e+00 -5.8170266e-02 -1.9572136e-01\n",
      " -1.3048688e+00 -1.1379279e-02 -2.1538013e-01 -1.4227263e+00\n",
      "  5.7570726e-02 -2.2686395e-01 -1.2875177e+00  1.4000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0041, -0.0836, -0.2582,  ...,  0.0346, -0.2694, -1.3243],\n",
      "        [ 0.0041, -0.0836, -0.2582,  ...,  0.0346, -0.2694, -1.3243],\n",
      "        [ 0.0041, -0.0836, -0.2582,  ...,  0.0346, -0.2694, -1.3243],\n",
      "        ...,\n",
      "        [-0.1612,  0.4267, -0.1277,  ..., -0.7379,  0.9055, -0.3494],\n",
      "        [-0.1618, -0.1301,  0.5748,  ..., -0.2441,  0.6576,  0.2250],\n",
      "        [-0.1618, -0.1301,  0.5748,  ..., -0.2441,  0.6576,  0.2250]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00407988 -0.08359344 -0.2582027   0.02187051 -0.22928755 -0.6863927\n",
      " -0.05784484 -0.40370727 -1.426588   -0.1973928  -0.46529534 -1.723791\n",
      " -0.36754414 -0.5827589  -2.1953363  -0.19925562 -0.6832558  -1.5873829\n",
      "  0.02424657 -0.706555   -1.3903131  -0.02450652 -0.6442908  -1.4457728\n",
      " -0.02278657 -0.7686751  -1.5609192  -0.15684618 -0.5756391  -1.5057184\n",
      " -0.0677494  -0.6291536  -1.481269   -0.07786174 -0.60508585 -1.5768788\n",
      "  0.05266879 -0.62423277 -1.6291211  -0.06693908 -0.49808642 -1.3321203\n",
      " -0.16779985 -0.27194118 -1.9375144  -0.02313013 -0.4207144  -1.9315535\n",
      "  0.13012919 -0.39059308 -1.4804531  -0.16552384 -0.25997525 -1.2699429\n",
      " -0.08363894 -0.24044001 -1.3478446  -0.03423342 -0.2562467  -1.464148\n",
      "  0.03460834 -0.26935798 -1.3243209 ]\n",
      "data: [ 0.00407988 -0.08359344 -0.2582027   0.02187051 -0.22928755 -0.6863927\n",
      " -0.05784484 -0.40370727 -1.4265882  -0.1973928  -0.46529534 -1.723791\n",
      " -0.36754414 -0.5827589  -2.1953363  -0.19925562 -0.6832558  -1.5873829\n",
      "  0.02424657 -0.706555   -1.3903131  -0.02450652 -0.64429075 -1.4457726\n",
      " -0.02278657 -0.7686751  -1.5609192  -0.15684618 -0.5756391  -1.5057184\n",
      " -0.0677494  -0.6291536  -1.4812691  -0.07786174 -0.60508585 -1.5768788\n",
      "  0.05266879 -0.62423277 -1.6291211  -0.06693908 -0.49808642 -1.3321204\n",
      " -0.16779986 -0.27194118 -1.9375145  -0.02313013 -0.4207144  -1.9315535\n",
      "  0.13012919 -0.39059308 -1.4804531  -0.16552383 -0.25997525 -1.2699429\n",
      " -0.08363894 -0.24044001 -1.3478446  -0.03423342 -0.2562467  -1.464148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.03460834 -0.26935798 -1.324321    0.15      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0241, -0.0933, -0.2459,  ...,  0.0459, -0.2781, -1.2807],\n",
      "        [ 0.0241, -0.0933, -0.2459,  ...,  0.0459, -0.2781, -1.2807],\n",
      "        [ 0.0241, -0.0933, -0.2459,  ...,  0.0459, -0.2781, -1.2807],\n",
      "        ...,\n",
      "        [-0.1527,  0.3986, -0.1902,  ..., -0.7500,  0.9068, -0.4612],\n",
      "        [-0.1692, -0.1684,  0.5791,  ..., -0.2687,  0.6039,  0.2355],\n",
      "        [-0.1692, -0.1684,  0.5791,  ..., -0.2687,  0.6039,  0.2355]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02405426 -0.09329669 -0.24587399  0.04516376 -0.22385135 -0.6413789\n",
      " -0.05228023 -0.4159141  -1.4008029  -0.19413619 -0.47682616 -1.6946249\n",
      " -0.35476357 -0.5829661  -2.1721427  -0.17270982 -0.7067873  -1.5596671\n",
      "  0.0235682  -0.74467915 -1.3943219  -0.02722746 -0.678051   -1.4503255\n",
      " -0.02631444 -0.8210188  -1.5672812  -0.13112943 -0.607279   -1.4726441\n",
      " -0.0577386  -0.6581544  -1.4470634  -0.07004002 -0.63195837 -1.5378811\n",
      "  0.05928189 -0.65534395 -1.5748246  -0.04646807 -0.5135435  -1.3071845\n",
      " -0.17021157 -0.28638527 -1.9779005  -0.01119384 -0.4428941  -1.9850924\n",
      "  0.14500926 -0.40908748 -1.4369848  -0.15102048 -0.28183347 -1.2394478\n",
      " -0.07761821 -0.2575308  -1.3241556  -0.03760019 -0.26579723 -1.4397407\n",
      "  0.04589526 -0.27813    -1.2807441 ]\n",
      "data: [ 0.02405426 -0.09329669 -0.24587399  0.04516376 -0.22385135 -0.6413789\n",
      " -0.05228023 -0.4159141  -1.400803   -0.19413619 -0.47682616 -1.6946249\n",
      " -0.35476357 -0.5829661  -2.1721427  -0.17270982 -0.7067873  -1.5596671\n",
      "  0.0235682  -0.7446792  -1.3943219  -0.02722746 -0.678051   -1.4503255\n",
      " -0.02631444 -0.8210188  -1.5672812  -0.13112943 -0.607279   -1.4726441\n",
      " -0.0577386  -0.6581544  -1.4470634  -0.07004002 -0.63195837 -1.5378811\n",
      "  0.05928188 -0.65534395 -1.5748246  -0.04646807 -0.5135435  -1.3071845\n",
      " -0.17021157 -0.28638527 -1.9779005  -0.01119384 -0.4428941  -1.9850925\n",
      "  0.14500926 -0.40908748 -1.4369847  -0.15102048 -0.28183347 -1.2394478\n",
      " -0.07761821 -0.2575308  -1.3241556  -0.03760019 -0.26579723 -1.4397407\n",
      "  0.04589526 -0.27813    -1.2807441   0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0203, -0.0423, -0.2425,  ...,  0.0457, -0.2376, -1.2608],\n",
      "        [ 0.0203, -0.0423, -0.2425,  ...,  0.0457, -0.2376, -1.2608],\n",
      "        [ 0.0203, -0.0423, -0.2425,  ...,  0.0457, -0.2376, -1.2608],\n",
      "        ...,\n",
      "        [-0.1507,  0.3545, -0.0864,  ..., -0.7675,  0.8441, -0.3535],\n",
      "        [-0.1277, -0.1458,  0.5647,  ..., -0.1990,  0.6161,  0.2121],\n",
      "        [-0.1277, -0.1458,  0.5647,  ..., -0.1990,  0.6161,  0.2121]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02032201 -0.04232518 -0.24251935  0.03750729 -0.1674389  -0.619884\n",
      " -0.07305197 -0.36381134 -1.3907509  -0.22104084 -0.42669317 -1.6868615\n",
      " -0.38773397 -0.52973783 -2.1714387  -0.17872459 -0.6626768  -1.5492554\n",
      "  0.00834455 -0.70633155 -1.3744185  -0.04324014 -0.6368795  -1.4329362\n",
      " -0.04687808 -0.78968304 -1.5523462  -0.13597015 -0.567352   -1.4596367\n",
      " -0.06841292 -0.6194267  -1.4315226  -0.08480944 -0.5943592  -1.5252087\n",
      "  0.05102829 -0.6158621  -1.5557768  -0.0518491  -0.47231787 -1.2937882\n",
      " -0.17923045 -0.24662167 -1.9799185  -0.01842423 -0.4044822  -1.9916806\n",
      "  0.1449407  -0.37449282 -1.4151249  -0.15448698 -0.24288552 -1.22539\n",
      " -0.08705758 -0.2208285  -1.3118737  -0.05002124 -0.22453347 -1.4285755\n",
      "  0.04565737 -0.23757015 -1.2608013 ]\n",
      "data: [ 0.02032201 -0.04232518 -0.24251933  0.03750729 -0.1674389  -0.619884\n",
      " -0.07305197 -0.36381134 -1.3907509  -0.22104084 -0.42669314 -1.6868615\n",
      " -0.38773397 -0.52973783 -2.1714387  -0.17872459 -0.6626769  -1.5492554\n",
      "  0.00834455 -0.70633155 -1.3744185  -0.04324014 -0.6368795  -1.4329362\n",
      " -0.04687808 -0.7896831  -1.5523462  -0.13597015 -0.567352   -1.4596367\n",
      " -0.06841292 -0.6194267  -1.4315227  -0.08480944 -0.5943592  -1.5252087\n",
      "  0.05102829 -0.6158621  -1.5557768  -0.0518491  -0.47231787 -1.2937882\n",
      " -0.17923047 -0.24662167 -1.9799185  -0.01842423 -0.4044822  -1.9916806\n",
      "  0.1449407  -0.37449282 -1.4151248  -0.15448698 -0.24288552 -1.22539\n",
      " -0.08705758 -0.22082849 -1.3118737  -0.05002124 -0.22453347 -1.4285754\n",
      "  0.04565737 -0.23757015 -1.2608013   0.17      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0097, -0.0175, -0.2367,  ...,  0.0328, -0.2104, -1.2826],\n",
      "        [ 0.0097, -0.0175, -0.2367,  ...,  0.0328, -0.2104, -1.2826],\n",
      "        [ 0.0097, -0.0175, -0.2367,  ...,  0.0328, -0.2104, -1.2826],\n",
      "        ...,\n",
      "        [-0.1950,  0.3170, -0.1135,  ..., -0.8350,  0.7675, -0.2843],\n",
      "        [-0.1441, -0.1694,  0.5389,  ..., -0.2148,  0.6050,  0.2085],\n",
      "        [-0.1441, -0.1694,  0.5389,  ..., -0.2148,  0.6050,  0.2085]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 9.6957423e-03 -1.7540956e-02 -2.3670152e-01  2.0198744e-02\n",
      " -1.5665853e-01 -6.5317059e-01 -7.7152520e-02 -3.3759966e-01\n",
      " -1.3940303e+00 -2.2170720e-01 -4.0134719e-01 -1.6876669e+00\n",
      " -3.9735940e-01 -5.1058763e-01 -2.1608167e+00 -1.9503158e-01\n",
      " -6.2774152e-01 -1.5464107e+00  1.8257424e-03 -6.5968937e-01\n",
      " -1.3583251e+00 -4.3820105e-02 -5.9263766e-01 -1.4164497e+00\n",
      " -4.0410087e-02 -7.3038417e-01 -1.5306120e+00 -1.5384853e-01\n",
      " -5.2475870e-01 -1.4649322e+00 -7.6631814e-02 -5.7720381e-01\n",
      " -1.4345090e+00 -8.9721777e-02 -5.5491596e-01 -1.5307798e+00\n",
      "  5.0859548e-02 -5.6873751e-01 -1.5745070e+00 -7.0448592e-02\n",
      " -4.4422770e-01 -1.2978053e+00 -1.7627239e-01 -2.2107893e-01\n",
      " -1.9210631e+00 -2.8854631e-02 -3.6793989e-01 -1.9232837e+00\n",
      "  1.3230395e-01 -3.4189343e-01 -1.4312024e+00 -1.6485283e-01\n",
      " -2.0893762e-01 -1.2340430e+00 -9.7116463e-02 -1.8972977e-01\n",
      " -1.3166769e+00 -5.2041925e-02 -1.9612694e-01 -1.4336727e+00\n",
      "  3.2794476e-02 -2.1040545e-01 -1.2826364e+00]\n",
      "data: [ 9.6957423e-03 -1.7540956e-02 -2.3670153e-01  2.0198744e-02\n",
      " -1.5665853e-01 -6.5317065e-01 -7.7152520e-02 -3.3759966e-01\n",
      " -1.3940303e+00 -2.2170720e-01 -4.0134719e-01 -1.6876669e+00\n",
      " -3.9735940e-01 -5.1058763e-01 -2.1608167e+00 -1.9503158e-01\n",
      " -6.2774152e-01 -1.5464107e+00  1.8257424e-03 -6.5968931e-01\n",
      " -1.3583252e+00 -4.3820105e-02 -5.9263766e-01 -1.4164498e+00\n",
      " -4.0410087e-02 -7.3038411e-01 -1.5306120e+00 -1.5384853e-01\n",
      " -5.2475870e-01 -1.4649322e+00 -7.6631814e-02 -5.7720381e-01\n",
      " -1.4345089e+00 -8.9721777e-02 -5.5491596e-01 -1.5307798e+00\n",
      "  5.0859548e-02 -5.6873751e-01 -1.5745070e+00 -7.0448592e-02\n",
      " -4.4422767e-01 -1.2978053e+00 -1.7627239e-01 -2.2107893e-01\n",
      " -1.9210631e+00 -2.8854631e-02 -3.6793986e-01 -1.9232837e+00\n",
      "  1.3230395e-01 -3.4189343e-01 -1.4312024e+00 -1.6485283e-01\n",
      " -2.0893760e-01 -1.2340430e+00 -9.7116463e-02 -1.8972977e-01\n",
      " -1.3166767e+00 -5.2041925e-02 -1.9612694e-01 -1.4336727e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3.2794476e-02 -2.1040544e-01 -1.2826364e+00  1.8000001e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0298, -0.0944, -0.2253,  ...,  0.0415, -0.2793, -1.2887],\n",
      "        [ 0.0298, -0.0944, -0.2253,  ...,  0.0415, -0.2793, -1.2887],\n",
      "        [ 0.0298, -0.0944, -0.2253,  ...,  0.0415, -0.2793, -1.2887],\n",
      "        ...,\n",
      "        [-0.3447,  0.2673, -0.3659,  ..., -0.8881,  0.7105, -0.5020],\n",
      "        [-0.1401, -0.0853,  0.6052,  ..., -0.2408,  0.7101,  0.2831],\n",
      "        [-0.1401, -0.0853,  0.6052,  ..., -0.2408,  0.7101,  0.2831]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02980468 -0.0944279  -0.22531241  0.04968468 -0.23617496 -0.65564966\n",
      " -0.04248378 -0.40791294 -1.3882446  -0.182984   -0.47026825 -1.6770884\n",
      " -0.34849173 -0.5740971  -2.1573117  -0.16581956 -0.69838583 -1.5418682\n",
      "  0.02273691 -0.72247857 -1.3683832  -0.02121063 -0.6554276  -1.4299309\n",
      " -0.01921084 -0.78598994 -1.5415591  -0.13077798 -0.59643227 -1.4676651\n",
      " -0.05378554 -0.6437021  -1.4380842  -0.07388707 -0.61944336 -1.5323057\n",
      "  0.06012168 -0.6296937  -1.5767486  -0.05434228 -0.5171677  -1.3011203\n",
      " -0.15129846 -0.2938594  -1.9017724  -0.01491269 -0.43319562 -1.9041388\n",
      "  0.134208   -0.408033   -1.4369583  -0.14240438 -0.28464544 -1.2415241\n",
      " -0.0804932  -0.26217127 -1.319212   -0.03705171 -0.26433507 -1.4374014\n",
      "  0.04149192 -0.2792822  -1.2887274 ]\n",
      "data: [ 0.02980468 -0.0944279  -0.22531241  0.04968468 -0.23617497 -0.65564966\n",
      " -0.04248378 -0.40791294 -1.3882446  -0.182984   -0.47026825 -1.6770883\n",
      " -0.34849176 -0.5740971  -2.1573117  -0.16581956 -0.69838583 -1.5418683\n",
      "  0.02273691 -0.72247857 -1.3683832  -0.02121063 -0.6554276  -1.4299309\n",
      " -0.01921084 -0.78598994 -1.5415591  -0.13077798 -0.59643227 -1.4676651\n",
      " -0.05378554 -0.6437021  -1.4380842  -0.07388707 -0.61944336 -1.5323057\n",
      "  0.06012168 -0.6296937  -1.5767486  -0.05434228 -0.5171677  -1.3011203\n",
      " -0.15129846 -0.2938594  -1.9017723  -0.01491269 -0.43319562 -1.9041388\n",
      "  0.134208   -0.408033   -1.4369583  -0.14240438 -0.28464544 -1.2415241\n",
      " -0.0804932  -0.26217127 -1.3192121  -0.03705171 -0.26433507 -1.4374014\n",
      "  0.04149192 -0.2792822  -1.2887274   0.19      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0282, -0.0811, -0.2347,  ...,  0.0535, -0.2728, -1.2553],\n",
      "        [ 0.0282, -0.0811, -0.2347,  ...,  0.0535, -0.2728, -1.2553],\n",
      "        [ 0.0282, -0.0811, -0.2347,  ...,  0.0535, -0.2728, -1.2553],\n",
      "        ...,\n",
      "        [-0.1342,  0.4133, -0.0857,  ..., -0.6803,  0.9076, -0.3705],\n",
      "        [-0.1709, -0.1329,  0.5785,  ..., -0.2704,  0.6418,  0.2198],\n",
      "        [-0.1709, -0.1329,  0.5785,  ..., -0.2704,  0.6418,  0.2198]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02816815 -0.08113734 -0.23470102  0.05448964 -0.20259416 -0.6067131\n",
      " -0.05689751 -0.40877473 -1.4034604  -0.201745   -0.4741286  -1.6977472\n",
      " -0.3580877  -0.5759067  -2.1875956  -0.1647164  -0.7030825  -1.5625972\n",
      "  0.0276154  -0.75211453 -1.385365   -0.02708234 -0.68484086 -1.440582\n",
      " -0.03968798 -0.83827746 -1.5627589  -0.12207609 -0.6093996  -1.4680835\n",
      " -0.05621065 -0.6630323  -1.4413962  -0.0739717  -0.63447803 -1.5292794\n",
      "  0.05361292 -0.66346437 -1.5588163  -0.038385   -0.508909   -1.301694\n",
      " -0.17596874 -0.27884126 -2.012947   -0.00942268 -0.44306737 -2.0264025\n",
      "  0.14836587 -0.4087786  -1.4176841  -0.14769542 -0.279141   -1.2278215\n",
      " -0.07524806 -0.25375974 -1.3134234  -0.03800599 -0.2602498  -1.4274628\n",
      "  0.05346889 -0.27275142 -1.2552907 ]\n",
      "data: [ 0.02816815 -0.08113734 -0.23470102  0.05448963 -0.20259416 -0.6067131\n",
      " -0.05689751 -0.40877473 -1.4034604  -0.20174499 -0.4741286  -1.6977472\n",
      " -0.3580877  -0.5759067  -2.1875956  -0.1647164  -0.7030825  -1.5625972\n",
      "  0.0276154  -0.75211453 -1.385365   -0.02708234 -0.68484086 -1.4405819\n",
      " -0.03968798 -0.83827746 -1.5627589  -0.12207609 -0.6093996  -1.4680835\n",
      " -0.05621065 -0.6630323  -1.4413962  -0.0739717  -0.63447803 -1.5292794\n",
      "  0.05361292 -0.66346437 -1.5588164  -0.038385   -0.508909   -1.301694\n",
      " -0.17596874 -0.27884126 -2.012947   -0.00942268 -0.44306737 -2.0264025\n",
      "  0.14836587 -0.4087786  -1.4176841  -0.14769542 -0.279141   -1.2278215\n",
      " -0.07524806 -0.25375974 -1.3134235  -0.03800599 -0.2602498  -1.4274628\n",
      "  0.05346889 -0.27275142 -1.2552907   0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.267 3.267 3.271 ... 3.249 3.257 3.257]\n",
      " [3.261 3.261 3.263 ... 3.238 3.25  3.25 ]\n",
      " ...\n",
      " [2.947 2.947 2.942 ... 2.954 2.953 2.953]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]\n",
      " [2.936 2.936 2.932 ... 2.941 2.945 2.945]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0226, -0.0326, -0.2272,  ...,  0.0524, -0.2233, -1.2639],\n",
      "        [ 0.0226, -0.0326, -0.2272,  ...,  0.0524, -0.2233, -1.2639],\n",
      "        [ 0.0226, -0.0326, -0.2272,  ...,  0.0524, -0.2233, -1.2639],\n",
      "        ...,\n",
      "        [-0.1732,  0.3196, -0.0942,  ..., -0.8005,  0.7683, -0.2880],\n",
      "        [-0.1389, -0.1402,  0.5657,  ..., -0.2003,  0.6145,  0.2224],\n",
      "        [-0.1389, -0.1402,  0.5657,  ..., -0.2003,  0.6145,  0.2224]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02261335 -0.03259488 -0.22722827  0.0358988  -0.17118192 -0.6328558\n",
      " -0.05360056 -0.3601619  -1.3790615  -0.1990054  -0.42242756 -1.6825256\n",
      " -0.37526977 -0.53995955 -2.150021   -0.18561791 -0.64506763 -1.5363955\n",
      "  0.03333679 -0.67985415 -1.3402103  -0.02033344 -0.61870426 -1.3946754\n",
      " -0.02466972 -0.7581346  -1.5131634  -0.13847889 -0.5400909  -1.4465063\n",
      " -0.05719346 -0.5980793  -1.4215841  -0.06730608 -0.5754268  -1.5194017\n",
      "  0.06275862 -0.60101813 -1.5643357  -0.0448676  -0.4505403  -1.2748191\n",
      " -0.16581438 -0.22724172 -1.9344547  -0.0074747  -0.38606045 -1.9342352\n",
      "  0.15063585 -0.35405213 -1.4163742  -0.14974532 -0.21457717 -1.2104315\n",
      " -0.06867282 -0.19587041 -1.2937682  -0.02432555 -0.21187077 -1.4106572\n",
      "  0.05238169 -0.22331305 -1.263922  ]\n",
      "data: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "mask: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0333,  0.0448,  0.4349,  ..., -0.2319, -0.0727, -0.3665],\n",
      "        [-0.0333,  0.0448,  0.4349,  ..., -0.2319, -0.0727, -0.3665],\n",
      "        [-0.0333,  0.0448,  0.4349,  ..., -0.2319, -0.0727, -0.3665],\n",
      "        ...,\n",
      "        [ 0.3777,  0.0338, -0.4249,  ...,  0.2617,  0.7308, -0.4466],\n",
      "        [ 0.3953,  0.0267, -0.4035,  ...,  0.2826,  0.7878, -0.4917],\n",
      "        [ 0.3953,  0.0267, -0.4035,  ...,  0.2826,  0.7878, -0.4917]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.03331171  0.04475227  0.43488228 -0.08014037 -0.1283966   0.04251438\n",
      " -0.43275732 -0.30288675 -0.52919793 -0.6339379  -0.4416606  -0.64817005\n",
      " -0.92006445 -0.45257625 -1.0338042  -0.32898337 -0.5638237  -0.5347692\n",
      " -0.48484027 -0.5967127  -0.22969621 -0.4647954  -0.4992316  -0.28106982\n",
      " -0.5385193  -0.63992906 -0.29921997 -0.30783296 -0.44557652 -0.56127876\n",
      " -0.40865445 -0.4935944  -0.37488335 -0.53361404 -0.46619457 -0.43082047\n",
      " -0.28280222 -0.36111313 -0.51204956 -0.349191   -0.46142566 -0.4435553\n",
      " -0.3940547  -0.24101767 -0.6121369  -0.40089983 -0.258882   -0.64137584\n",
      " -0.26609105 -0.26819363 -0.39044648 -0.29307145 -0.20285279 -0.41877973\n",
      " -0.48265147 -0.14345443 -0.4460817  -0.39757866 -0.02279501 -0.5691981\n",
      " -0.23187025 -0.07268029 -0.3664986 ]\n",
      "init: [-0.03331171  0.04475227  0.43488228 -0.08014037 -0.1283966   0.04251438\n",
      " -0.43275732 -0.30288675 -0.52919793 -0.6339379  -0.4416606  -0.64817005\n",
      " -0.92006445 -0.45257625 -1.0338042  -0.32898337 -0.5638237  -0.5347692\n",
      " -0.48484027 -0.5967127  -0.22969621 -0.4647954  -0.4992316  -0.28106982\n",
      " -0.5385193  -0.63992906 -0.29921997 -0.30783296 -0.44557652 -0.56127876\n",
      " -0.40865445 -0.4935944  -0.37488335 -0.53361404 -0.46619457 -0.43082047\n",
      " -0.28280222 -0.36111313 -0.51204956 -0.349191   -0.46142566 -0.4435553\n",
      " -0.3940547  -0.24101767 -0.6121369  -0.40089983 -0.258882   -0.64137584\n",
      " -0.26609105 -0.26819363 -0.39044648 -0.29307145 -0.20285279 -0.41877973\n",
      " -0.48265147 -0.14345443 -0.4460817  -0.39757866 -0.02279501 -0.5691981\n",
      " -0.23187025 -0.07268029 -0.3664986 ]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [-0.03331171  0.04475227  0.43488228 -0.08014037 -0.1283966   0.04251438\n",
      " -0.4327573  -0.30288675 -0.52919793 -0.6339379  -0.4416606  -0.6481701\n",
      " -0.92006445 -0.45257625 -1.0338042  -0.3289834  -0.5638237  -0.5347692\n",
      " -0.48484027 -0.5967127  -0.22969621 -0.4647954  -0.4992316  -0.28106982\n",
      " -0.5385193  -0.63992906 -0.29921997 -0.30783296 -0.44557652 -0.56127876\n",
      " -0.40865445 -0.4935944  -0.37488335 -0.53361404 -0.46619457 -0.43082047\n",
      " -0.28280222 -0.36111313 -0.51204956 -0.349191   -0.46142566 -0.4435553\n",
      " -0.3940547  -0.24101767 -0.6121369  -0.4008998  -0.258882   -0.6413758\n",
      " -0.26609105 -0.26819363 -0.39044648 -0.29307145 -0.20285279 -0.41877973\n",
      " -0.48265147 -0.14345443 -0.4460817  -0.39757866 -0.02279501 -0.5691981\n",
      " -0.23187025 -0.07268029 -0.3664986   0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0976, -0.1282, -0.0014,  ..., -0.1768, -0.3206, -0.4777],\n",
      "        [ 0.0976, -0.1282, -0.0014,  ..., -0.1768, -0.3206, -0.4777],\n",
      "        [ 0.0976, -0.1282, -0.0014,  ..., -0.1768, -0.3206, -0.4777],\n",
      "        ...,\n",
      "        [ 0.3807, -0.3220,  0.1800,  ...,  0.0255,  0.4814, -0.7080],\n",
      "        [ 0.2470, -0.0607,  0.3909,  ..., -0.2374,  0.5988, -0.3907],\n",
      "        [ 0.2470, -0.0607,  0.3909,  ..., -0.2374,  0.5988, -0.3907]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.09764333 -0.12818111 -0.00139142  0.01448007 -0.21023431 -0.21530163\n",
      " -0.19374429 -0.3714562  -0.6253542  -0.37554568 -0.43195403 -0.8070229\n",
      " -0.6704508  -0.44929424 -1.1941503  -0.23161386 -0.6267141  -0.80595434\n",
      " -0.49900675 -0.64790744 -1.1695795  -0.50235474 -0.5776095  -1.1860143\n",
      " -0.41920716 -0.7813401  -1.1322979  -0.17645065 -0.54897135 -0.7414032\n",
      " -0.28347117 -0.59008485 -0.56041884 -0.39183152 -0.6059165  -0.66071415\n",
      " -0.27003443 -0.5561799  -0.7184459  -0.17070954 -0.496056   -0.6637727\n",
      " -0.30694145 -0.41535404 -0.9040673  -0.271919   -0.47494265 -0.9372133\n",
      " -0.24233057 -0.4594384  -0.5834764  -0.14623041 -0.35705602 -0.6308223\n",
      " -0.28953373 -0.35680002 -0.5369657  -0.25904596 -0.32209873 -0.6326524\n",
      " -0.17676057 -0.32056063 -0.47769672]\n",
      "data: [ 0.09764333 -0.12818111 -0.00139142  0.01448007 -0.21023431 -0.21530163\n",
      " -0.19374427 -0.37145624 -0.6253542  -0.37554568 -0.43195403 -0.8070229\n",
      " -0.6704508  -0.44929424 -1.1941503  -0.23161386 -0.6267141  -0.80595434\n",
      " -0.49900672 -0.64790744 -1.1695795  -0.50235474 -0.5776095  -1.1860143\n",
      " -0.41920716 -0.7813401  -1.1322979  -0.17645065 -0.54897135 -0.7414032\n",
      " -0.28347117 -0.59008485 -0.56041884 -0.39183152 -0.6059165  -0.6607141\n",
      " -0.27003443 -0.5561799  -0.7184459  -0.17070954 -0.496056   -0.66377276\n",
      " -0.30694145 -0.41535404 -0.9040673  -0.271919   -0.47494265 -0.9372133\n",
      " -0.24233057 -0.4594384  -0.5834764  -0.14623041 -0.35705602 -0.6308223\n",
      " -0.28953373 -0.3568     -0.5369657  -0.25904596 -0.32209873 -0.6326524\n",
      " -0.17676058 -0.32056063 -0.47769672  0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0900,  0.1017, -0.2073,  ...,  0.3068, -0.1375, -1.1475],\n",
      "        [ 0.0900,  0.1017, -0.2073,  ...,  0.3068, -0.1375, -1.1475],\n",
      "        [ 0.0900,  0.1017, -0.2073,  ...,  0.3068, -0.1375, -1.1475],\n",
      "        ...,\n",
      "        [ 0.1401, -0.4187,  0.1613,  ...,  0.3673,  0.7864, -0.4577],\n",
      "        [-0.1169,  0.0864,  0.2130,  ..., -0.8328,  0.7281, -0.1858],\n",
      "        [-0.1169,  0.0864,  0.2130,  ..., -0.8328,  0.7281, -0.1858]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.09004354  0.10170863 -0.2072531   0.10468787  0.00330134 -0.5347936\n",
      "  0.00726356 -0.16720459 -1.1657598  -0.10037886 -0.2120057  -1.4103525\n",
      " -0.22976235 -0.3165544  -1.8076682  -0.07890822 -0.4489165  -1.3445523\n",
      "  0.10811283 -0.4684853  -1.2729223   0.13283332 -0.36777702 -1.302366\n",
      "  0.21368803 -0.50388235 -1.3826895  -0.02680372 -0.36518514 -1.2833881\n",
      "  0.09790829 -0.41684842 -1.2526379   0.16122824 -0.3782552  -1.2983732\n",
      "  0.37268096 -0.39036024 -1.3855743   0.09173962 -0.3243102  -1.1600358\n",
      "  0.02003389 -0.08915249 -1.7330775   0.2276017  -0.2581452  -1.7140632\n",
      "  0.43774143 -0.18318337 -1.3041556  -0.00486229 -0.11566274 -1.0981929\n",
      "  0.09842834 -0.07345021 -1.1778378   0.20156622 -0.10605052 -1.2936413\n",
      "  0.30680764 -0.13745171 -1.1474593 ]\n",
      "data: [ 0.09004354  0.10170863 -0.2072531   0.10468787  0.00330134 -0.5347936\n",
      "  0.00726356 -0.16720459 -1.1657598  -0.10037886 -0.2120057  -1.4103525\n",
      " -0.22976235 -0.3165544  -1.8076682  -0.07890822 -0.44891652 -1.3445523\n",
      "  0.10811283 -0.4684853  -1.2729223   0.13283332 -0.36777702 -1.302366\n",
      "  0.21368803 -0.50388235 -1.3826895  -0.02680372 -0.36518514 -1.283388\n",
      "  0.09790829 -0.41684842 -1.2526379   0.16122824 -0.3782552  -1.2983732\n",
      "  0.37268096 -0.39036024 -1.3855743   0.09173962 -0.3243102  -1.1600358\n",
      "  0.02003389 -0.08915249 -1.7330775   0.2276017  -0.2581452  -1.7140632\n",
      "  0.43774143 -0.18318337 -1.3041556  -0.00486229 -0.11566274 -1.0981929\n",
      "  0.09842834 -0.07345021 -1.1778378   0.20156622 -0.10605052 -1.2936413\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.30680764 -0.13745171 -1.1474593   0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.1626, -0.2447, -0.2165,  ...,  0.1342, -0.3837, -1.3979],\n",
      "        [ 0.1626, -0.2447, -0.2165,  ...,  0.1342, -0.3837, -1.3979],\n",
      "        [ 0.1626, -0.2447, -0.2165,  ...,  0.1342, -0.3837, -1.3979],\n",
      "        ...,\n",
      "        [-0.3962,  0.3155, -0.2418,  ..., -0.9098,  0.8485, -0.5920],\n",
      "        [-0.1954,  0.1442,  0.4025,  ..., -0.1335,  0.9645,  0.0509],\n",
      "        [-0.1954,  0.1442,  0.4025,  ..., -0.1335,  0.9645,  0.0509]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.16259731 -0.24474892 -0.21654204  0.17051058 -0.42394608 -0.75639176\n",
      "  0.1134444  -0.5734697  -1.4409375  -0.03744851 -0.6310879  -1.7440678\n",
      " -0.24560687 -0.75492847 -2.2096317  -0.07778284 -0.8134382  -1.6215749\n",
      "  0.17727114 -0.8176117  -1.3409047   0.13588884 -0.75505805 -1.3899015\n",
      "  0.12326978 -0.8522508  -1.492666   -0.03816712 -0.68302584 -1.5522274\n",
      "  0.0609953  -0.7390543  -1.5093521   0.04989593 -0.7221918  -1.6149815\n",
      "  0.17674719 -0.7207309  -1.6925542   0.05065572 -0.6286533  -1.3766742\n",
      " -0.02669583 -0.39854333 -1.8704634   0.09021126 -0.5355292  -1.8423752\n",
      "  0.22470109 -0.49820426 -1.535238   -0.03708974 -0.37536836 -1.3240654\n",
      "  0.03305179 -0.35118255 -1.382289    0.09875719 -0.37684909 -1.4995192\n",
      "  0.13417494 -0.3836607  -1.3978517 ]\n",
      "data: [ 0.16259731 -0.24474892 -0.21654204  0.17051058 -0.42394608 -0.75639176\n",
      "  0.1134444  -0.5734697  -1.4409375  -0.03744851 -0.6310879  -1.7440678\n",
      " -0.24560685 -0.7549284  -2.2096317  -0.07778284 -0.8134382  -1.6215749\n",
      "  0.17727114 -0.8176117  -1.3409047   0.13588884 -0.75505805 -1.3899016\n",
      "  0.12326977 -0.8522508  -1.492666   -0.03816712 -0.68302584 -1.5522274\n",
      "  0.0609953  -0.7390543  -1.5093521   0.04989593 -0.72219175 -1.6149815\n",
      "  0.17674719 -0.7207309  -1.6925541   0.05065572 -0.6286533  -1.3766742\n",
      " -0.02669583 -0.39854333 -1.8704634   0.09021126 -0.5355292  -1.8423752\n",
      "  0.2247011  -0.49820426 -1.535238   -0.03708974 -0.37536836 -1.3240654\n",
      "  0.03305179 -0.35118255 -1.3822892   0.09875719 -0.37684909 -1.4995192\n",
      "  0.13417494 -0.3836607  -1.3978517   0.04      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[-0.0014, -0.2214, -0.1263,  ...,  0.0219, -0.4075, -1.1864],\n",
      "        [-0.0014, -0.2214, -0.1263,  ...,  0.0219, -0.4075, -1.1864],\n",
      "        [-0.0014, -0.2214, -0.1263,  ...,  0.0219, -0.4075, -1.1864],\n",
      "        ...,\n",
      "        [ 0.0067,  0.6645, -0.2338,  ..., -0.3585,  1.1325, -0.6183],\n",
      "        [-0.0874,  0.0135,  0.6353,  ..., -0.0416,  0.7029,  0.2584],\n",
      "        [-0.0874,  0.0135,  0.6353,  ..., -0.0416,  0.7029,  0.2584]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-1.3944982e-03 -2.2139496e-01 -1.2627394e-01  2.3896504e-02\n",
      " -3.5566261e-01 -4.8942316e-01 -6.1672233e-02 -5.7245290e-01\n",
      " -1.3055301e+00 -2.1586958e-01 -6.4056301e-01 -1.6239984e+00\n",
      " -3.9545536e-01 -7.6506054e-01 -2.1170881e+00 -2.1994479e-01\n",
      " -8.3480060e-01 -1.5171304e+00  3.2335058e-02 -8.9029098e-01\n",
      " -1.2990570e+00 -3.5176113e-02 -8.3683205e-01 -1.3376410e+00\n",
      " -5.8789648e-02 -9.8474634e-01 -1.4589331e+00 -1.6269988e-01\n",
      " -7.2757673e-01 -1.4053984e+00 -8.0031395e-02 -8.0164874e-01\n",
      " -1.3744018e+00 -9.1910936e-02 -7.8105390e-01 -1.4764490e+00\n",
      "  1.6207248e-02 -8.2567239e-01 -1.5186138e+00 -5.7775117e-02\n",
      " -6.2455750e-01 -1.2261112e+00 -2.0671402e-01 -4.0292698e-01\n",
      " -1.9258494e+00 -3.7350178e-02 -5.8595496e-01 -1.9243019e+00\n",
      "  1.1297764e-01 -5.4334009e-01 -1.3564241e+00 -1.8654317e-01\n",
      " -3.8413808e-01 -1.1533756e+00 -8.6353734e-02 -3.6845621e-01\n",
      " -1.2241373e+00 -4.1480303e-02 -4.0528905e-01 -1.3338790e+00\n",
      "  2.1869339e-02 -4.0752119e-01 -1.1863778e+00]\n",
      "data: [-1.3944982e-03 -2.2139496e-01 -1.2627394e-01  2.3896504e-02\n",
      " -3.5566261e-01 -4.8942316e-01 -6.1672233e-02 -5.7245290e-01\n",
      " -1.3055301e+00 -2.1586958e-01 -6.4056307e-01 -1.6239984e+00\n",
      " -3.9545536e-01 -7.6506060e-01 -2.1170881e+00 -2.1994478e-01\n",
      " -8.3480054e-01 -1.5171304e+00  3.2335058e-02 -8.9029098e-01\n",
      " -1.2990570e+00 -3.5176113e-02 -8.3683205e-01 -1.3376410e+00\n",
      " -5.8789648e-02 -9.8474634e-01 -1.4589331e+00 -1.6269988e-01\n",
      " -7.2757673e-01 -1.4053984e+00 -8.0031395e-02 -8.0164874e-01\n",
      " -1.3744018e+00 -9.1910936e-02 -7.8105390e-01 -1.4764490e+00\n",
      "  1.6207248e-02 -8.2567239e-01 -1.5186139e+00 -5.7775117e-02\n",
      " -6.2455750e-01 -1.2261112e+00 -2.0671402e-01 -4.0292698e-01\n",
      " -1.9258494e+00 -3.7350178e-02 -5.8595496e-01 -1.9243019e+00\n",
      "  1.1297764e-01 -5.4334009e-01 -1.3564241e+00 -1.8654317e-01\n",
      " -3.8413808e-01 -1.1533756e+00 -8.6353734e-02 -3.6845624e-01\n",
      " -1.2241373e+00 -4.1480303e-02 -4.0528905e-01 -1.3338790e+00\n",
      "  2.1869339e-02 -4.0752116e-01 -1.1863778e+00  5.0000001e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F630B8>\n",
      "tensor([[-0.0126, -0.0440, -0.2498,  ..., -0.0144, -0.2194, -1.2621],\n",
      "        [-0.0126, -0.0440, -0.2498,  ..., -0.0144, -0.2194, -1.2621],\n",
      "        [-0.0126, -0.0440, -0.2498,  ..., -0.0144, -0.2194, -1.2621],\n",
      "        ...,\n",
      "        [-0.1622,  0.4425,  0.0162,  ..., -0.4609,  1.0799, -0.4565],\n",
      "        [ 0.0126,  0.0322,  0.7024,  ..., -0.0314,  0.6517,  0.3784],\n",
      "        [ 0.0126,  0.0322,  0.7024,  ..., -0.0314,  0.6517,  0.3784]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01260016 -0.04402129 -0.24975152  0.01478846 -0.15472816 -0.5266131\n",
      " -0.12502363 -0.39141747 -1.3883462  -0.28649244 -0.4564404  -1.6764512\n",
      " -0.44515777 -0.5470189  -2.1928806  -0.21939155 -0.6873365  -1.5933857\n",
      " -0.04077457 -0.75610626 -1.4431407  -0.09004906 -0.6806608  -1.4832897\n",
      " -0.08545484 -0.8435774  -1.6042371  -0.17609191 -0.5906966  -1.4917936\n",
      " -0.11457139 -0.64559436 -1.4508238  -0.11473942 -0.609194   -1.5363119\n",
      "  0.02967812 -0.6430152  -1.5548451  -0.08876392 -0.47219065 -1.336669\n",
      " -0.25466174 -0.23785785 -2.0866678  -0.06368307 -0.41475224 -2.1103518\n",
      "  0.1194841  -0.36610073 -1.4301422  -0.22323063 -0.2350219  -1.257385\n",
      " -0.15236887 -0.2039865  -1.3396013  -0.12047899 -0.21180402 -1.4516761\n",
      " -0.01440995 -0.21942571 -1.2620718 ]\n",
      "data: [-0.01260016 -0.04402129 -0.24975152  0.01478846 -0.15472816 -0.5266131\n",
      " -0.12502363 -0.39141747 -1.3883462  -0.28649244 -0.4564404  -1.6764512\n",
      " -0.44515777 -0.5470189  -2.1928806  -0.21939155 -0.6873365  -1.5933856\n",
      " -0.04077457 -0.75610626 -1.4431407  -0.09004906 -0.6806608  -1.4832898\n",
      " -0.08545484 -0.84357744 -1.6042371  -0.17609192 -0.5906966  -1.4917936\n",
      " -0.11457139 -0.64559436 -1.4508238  -0.11473942 -0.609194   -1.5363117\n",
      "  0.02967812 -0.6430152  -1.5548451  -0.08876392 -0.47219068 -1.336669\n",
      " -0.25466174 -0.23785786 -2.0866678  -0.06368307 -0.41475224 -2.1103518\n",
      "  0.1194841  -0.36610073 -1.4301422  -0.22323063 -0.23502189 -1.257385\n",
      " -0.15236887 -0.2039865  -1.3396013  -0.120479   -0.211804   -1.4516761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.01440995 -0.21942572 -1.2620718   0.06      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0241, -0.0234, -0.1925,  ...,  0.0487, -0.2037, -1.2475],\n",
      "        [ 0.0241, -0.0234, -0.1925,  ...,  0.0487, -0.2037, -1.2475],\n",
      "        [ 0.0241, -0.0234, -0.1925,  ...,  0.0487, -0.2037, -1.2475],\n",
      "        ...,\n",
      "        [-0.2241,  0.2757, -0.0837,  ..., -0.8886,  0.7851, -0.3009],\n",
      "        [-0.1668, -0.1511,  0.5197,  ..., -0.2715,  0.5750,  0.2545],\n",
      "        [-0.1668, -0.1511,  0.5197,  ..., -0.2715,  0.5750,  0.2545]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.4095450e-02 -2.3397317e-02 -1.9246504e-01  3.6783312e-02\n",
      " -1.6441725e-01 -6.0392940e-01 -4.2973556e-02 -3.3719155e-01\n",
      " -1.3340273e+00 -1.8918999e-01 -3.9412382e-01 -1.6379774e+00\n",
      " -3.6821616e-01 -5.1253116e-01 -2.1097999e+00 -1.8746799e-01\n",
      " -6.2799186e-01 -1.4924631e+00  4.1402489e-02 -6.5166652e-01\n",
      " -1.3033230e+00 -1.1073619e-02 -5.8972663e-01 -1.3564935e+00\n",
      " -7.5356439e-03 -7.1693379e-01 -1.4738281e+00 -1.4160079e-01\n",
      " -5.2175683e-01 -1.4072740e+00 -5.0551347e-02 -5.7420695e-01\n",
      " -1.3881953e+00 -5.4612584e-02 -5.4588443e-01 -1.4897521e+00\n",
      "  7.8031853e-02 -5.7079208e-01 -1.5400798e+00 -4.5987733e-02\n",
      " -4.3723911e-01 -1.2351930e+00 -1.5537095e-01 -2.0841861e-01\n",
      " -1.8606520e+00 -5.9393793e-04 -3.6003166e-01 -1.8570783e+00\n",
      "  1.5815663e-01 -3.2823038e-01 -1.3971918e+00 -1.5282506e-01\n",
      " -1.9761012e-01 -1.1739750e+00 -6.6620931e-02 -1.7802325e-01\n",
      " -1.2591355e+00 -2.2320703e-02 -1.9408941e-01 -1.3791182e+00\n",
      "  4.8713304e-02 -2.0370828e-01 -1.2475183e+00]\n",
      "data: [ 2.4095450e-02 -2.3397317e-02 -1.9246504e-01  3.6783312e-02\n",
      " -1.6441725e-01 -6.0392940e-01 -4.2973556e-02 -3.3719155e-01\n",
      " -1.3340273e+00 -1.8918999e-01 -3.9412385e-01 -1.6379772e+00\n",
      " -3.6821616e-01 -5.1253116e-01 -2.1097999e+00 -1.8746799e-01\n",
      " -6.2799186e-01 -1.4924631e+00  4.1402489e-02 -6.5166646e-01\n",
      " -1.3033230e+00 -1.1073619e-02 -5.8972663e-01 -1.3564935e+00\n",
      " -7.5356434e-03 -7.1693385e-01 -1.4738281e+00 -1.4160079e-01\n",
      " -5.2175683e-01 -1.4072740e+00 -5.0551347e-02 -5.7420695e-01\n",
      " -1.3881954e+00 -5.4612584e-02 -5.4588443e-01 -1.4897521e+00\n",
      "  7.8031853e-02 -5.7079208e-01 -1.5400798e+00 -4.5987736e-02\n",
      " -4.3723911e-01 -1.2351930e+00 -1.5537095e-01 -2.0841862e-01\n",
      " -1.8606520e+00 -5.9393793e-04 -3.6003166e-01 -1.8570782e+00\n",
      "  1.5815663e-01 -3.2823035e-01 -1.3971918e+00 -1.5282506e-01\n",
      " -1.9761012e-01 -1.1739750e+00 -6.6620931e-02 -1.7802325e-01\n",
      " -1.2591355e+00 -2.2320703e-02 -1.9408941e-01 -1.3791182e+00\n",
      "  4.8713304e-02 -2.0370826e-01 -1.2475183e+00  7.0000000e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0102, -0.0693, -0.2598,  ...,  0.0176, -0.2459, -1.3157],\n",
      "        [ 0.0102, -0.0693, -0.2598,  ...,  0.0176, -0.2459, -1.3157],\n",
      "        [ 0.0102, -0.0693, -0.2598,  ...,  0.0176, -0.2459, -1.3157],\n",
      "        ...,\n",
      "        [-0.3330,  0.2517, -0.2988,  ..., -0.7963,  0.7065, -0.4631],\n",
      "        [-0.1239, -0.0322,  0.6275,  ..., -0.2299,  0.7668,  0.3044],\n",
      "        [-0.1239, -0.0322,  0.6275,  ..., -0.2299,  0.7668,  0.3044]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01024572 -0.06931494 -0.2598051   0.03312368 -0.2075434  -0.68211603\n",
      " -0.07930832 -0.39508712 -1.4422097  -0.22210291 -0.460741   -1.7198243\n",
      " -0.37954766 -0.5575431  -2.203863   -0.18865076 -0.6795629  -1.5934205\n",
      " -0.01316372 -0.71378154 -1.4135439  -0.0533497  -0.6419605  -1.4709892\n",
      " -0.05412048 -0.7772885  -1.5830765  -0.15499717 -0.5786366  -1.5188525\n",
      " -0.08566172 -0.6265348  -1.4798243  -0.102837   -0.59772456 -1.5636504\n",
      "  0.03792007 -0.6093027  -1.6019843  -0.08149062 -0.4948063  -1.3575823\n",
      " -0.18831497 -0.26535553 -1.9734454  -0.04275692 -0.40987033 -1.9808154\n",
      "  0.11367745 -0.37895876 -1.4695594  -0.17289576 -0.26083225 -1.2903743\n",
      " -0.11604499 -0.23133117 -1.3662765  -0.07049152 -0.23005366 -1.482204\n",
      "  0.01759061 -0.24590851 -1.3157165 ]\n",
      "data: [ 0.01024572 -0.06931494 -0.2598051   0.03312368 -0.20754342 -0.68211603\n",
      " -0.07930832 -0.39508712 -1.4422097  -0.22210291 -0.460741   -1.7198243\n",
      " -0.37954766 -0.5575431  -2.203863   -0.18865076 -0.6795629  -1.5934205\n",
      " -0.01316372 -0.71378154 -1.413544   -0.0533497  -0.6419605  -1.4709892\n",
      " -0.05412048 -0.7772885  -1.5830765  -0.15499717 -0.5786366  -1.5188526\n",
      " -0.08566172 -0.6265348  -1.4798244  -0.102837   -0.59772456 -1.5636504\n",
      "  0.03792007 -0.6093027  -1.6019843  -0.08149062 -0.4948063  -1.3575824\n",
      " -0.18831497 -0.26535553 -1.9734454  -0.04275693 -0.40987033 -1.9808154\n",
      "  0.11367746 -0.3789588  -1.4695594  -0.17289576 -0.26083225 -1.2903743\n",
      " -0.11604499 -0.23133117 -1.3662765  -0.07049152 -0.23005368 -1.482204\n",
      "  0.01759061 -0.24590851 -1.3157165   0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0310, -0.0370, -0.2254,  ...,  0.0422, -0.2325, -1.2599],\n",
      "        [ 0.0310, -0.0370, -0.2254,  ...,  0.0422, -0.2325, -1.2599],\n",
      "        [ 0.0310, -0.0370, -0.2254,  ...,  0.0422, -0.2325, -1.2599],\n",
      "        ...,\n",
      "        [-0.1242,  0.4261, -0.1213,  ..., -0.7403,  0.9402, -0.3746],\n",
      "        [-0.1425, -0.1996,  0.5466,  ..., -0.2242,  0.5669,  0.2386],\n",
      "        [-0.1425, -0.1996,  0.5466,  ..., -0.2242,  0.5669,  0.2386]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03098525 -0.0369584  -0.22536117  0.0457354  -0.1634521  -0.6162344\n",
      " -0.06468469 -0.34620738 -1.3712485  -0.21197489 -0.40877116 -1.6614351\n",
      " -0.37882566 -0.5032124  -2.1528764  -0.16229638 -0.65427005 -1.5283666\n",
      "  0.00432426 -0.69171864 -1.3727202  -0.04136017 -0.61794734 -1.4362378\n",
      " -0.03623128 -0.7666334  -1.550544   -0.1260556  -0.5603209  -1.4475327\n",
      " -0.06136589 -0.60525876 -1.4175541  -0.08286375 -0.58111477 -1.5134637\n",
      "  0.05832118 -0.59067565 -1.5440633  -0.0524356  -0.47312889 -1.2852862\n",
      " -0.16334678 -0.24868193 -1.9304912  -0.01802361 -0.39201474 -1.9440534\n",
      "  0.14322752 -0.36902076 -1.4075608  -0.1451025  -0.24416183 -1.2203326\n",
      " -0.09040126 -0.22229508 -1.3060975  -0.05568475 -0.21716872 -1.4232748\n",
      "  0.04217426 -0.23254047 -1.2598553 ]\n",
      "data: [ 0.03098525 -0.0369584  -0.22536117  0.0457354  -0.1634521  -0.6162344\n",
      " -0.06468469 -0.34620738 -1.3712485  -0.21197489 -0.40877116 -1.6614351\n",
      " -0.3788257  -0.5032124  -2.1528764  -0.16229638 -0.65427    -1.5283666\n",
      "  0.00432426 -0.6917187  -1.3727202  -0.04136017 -0.61794734 -1.4362378\n",
      " -0.03623128 -0.7666334  -1.550544   -0.1260556  -0.5603209  -1.4475327\n",
      " -0.06136589 -0.60525876 -1.4175541  -0.08286375 -0.58111477 -1.5134637\n",
      "  0.05832118 -0.59067565 -1.5440632  -0.0524356  -0.47312889 -1.2852863\n",
      " -0.16334678 -0.24868193 -1.9304912  -0.01802361 -0.39201474 -1.9440533\n",
      "  0.14322752 -0.36902076 -1.4075608  -0.1451025  -0.24416183 -1.2203326\n",
      " -0.09040126 -0.22229508 -1.3060975  -0.05568475 -0.21716872 -1.4232746\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.04217426 -0.23254047 -1.2598553   0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0199, -0.0697, -0.2487,  ...,  0.0320, -0.2531, -1.2927],\n",
      "        [ 0.0199, -0.0697, -0.2487,  ...,  0.0320, -0.2531, -1.2927],\n",
      "        [ 0.0199, -0.0697, -0.2487,  ...,  0.0320, -0.2531, -1.2927],\n",
      "        ...,\n",
      "        [-0.3097,  0.2221, -0.2705,  ..., -0.8127,  0.6871, -0.4634],\n",
      "        [-0.1198, -0.0546,  0.5971,  ..., -0.2316,  0.7330,  0.2658],\n",
      "        [-0.1198, -0.0546,  0.5971,  ..., -0.2316,  0.7330,  0.2658]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01993579 -0.06966496 -0.24868593  0.04546595 -0.20132595 -0.65480894\n",
      " -0.06169572 -0.38936648 -1.4213474  -0.20471168 -0.45474204 -1.707409\n",
      " -0.36309698 -0.5531723  -2.1952357  -0.1739611  -0.67992055 -1.5750332\n",
      "  0.01060649 -0.7160629  -1.3920755  -0.03621762 -0.6476884  -1.4501544\n",
      " -0.04519835 -0.7880746  -1.5663325  -0.13796845 -0.5832308  -1.4938437\n",
      " -0.06822199 -0.6332417  -1.4603218  -0.0903716  -0.604864   -1.5490668\n",
      "  0.04306478 -0.62273866 -1.5850796  -0.06169336 -0.4949101  -1.3288889\n",
      " -0.17586058 -0.26691678 -1.972605   -0.02801518 -0.41588277 -1.9816806\n",
      "  0.12506765 -0.38769275 -1.4466456  -0.15750927 -0.26335585 -1.261453\n",
      " -0.09531512 -0.2372543  -1.3397003  -0.05449202 -0.23855072 -1.4558673\n",
      "  0.03199758 -0.25306916 -1.2926606 ]\n",
      "data: [ 0.01993579 -0.06966496 -0.24868593  0.04546595 -0.20132595 -0.65480894\n",
      " -0.06169572 -0.3893665  -1.4213474  -0.20471169 -0.45474204 -1.707409\n",
      " -0.363097   -0.5531723  -2.1952357  -0.1739611  -0.67992055 -1.5750333\n",
      "  0.01060649 -0.7160629  -1.3920755  -0.03621762 -0.6476884  -1.4501544\n",
      " -0.04519835 -0.7880747  -1.5663323  -0.13796845 -0.5832308  -1.4938437\n",
      " -0.06822199 -0.6332417  -1.4603218  -0.0903716  -0.604864   -1.5490668\n",
      "  0.04306478 -0.62273866 -1.5850796  -0.06169336 -0.4949101  -1.3288889\n",
      " -0.17586058 -0.26691678 -1.972605   -0.02801518 -0.41588277 -1.9816806\n",
      "  0.12506765 -0.38769275 -1.4466456  -0.15750927 -0.26335585 -1.261453\n",
      " -0.09531512 -0.23725432 -1.3397003  -0.05449202 -0.23855072 -1.4558673\n",
      "  0.03199758 -0.25306916 -1.2926605   0.1       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0187, -0.0340, -0.2442,  ...,  0.0442, -0.2280, -1.2735],\n",
      "        [ 0.0187, -0.0340, -0.2442,  ...,  0.0442, -0.2280, -1.2735],\n",
      "        [ 0.0187, -0.0340, -0.2442,  ...,  0.0442, -0.2280, -1.2735],\n",
      "        ...,\n",
      "        [-0.1402,  0.3682, -0.1050,  ..., -0.7597,  0.8633, -0.3519],\n",
      "        [-0.1398, -0.1774,  0.5514,  ..., -0.2241,  0.5857,  0.2216],\n",
      "        [-0.1398, -0.1774,  0.5514,  ..., -0.2241,  0.5857,  0.2216]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0187253  -0.0340382  -0.24415536  0.03442964 -0.163959   -0.6357593\n",
      " -0.06546284 -0.34910768 -1.38576    -0.21017951 -0.41019332 -1.6806914\n",
      " -0.3784844  -0.516016   -2.160459   -0.18052876 -0.6461446  -1.5448583\n",
      "  0.01111954 -0.6821052  -1.3773452  -0.03746217 -0.61397254 -1.4355869\n",
      " -0.03325067 -0.7581028  -1.5510861  -0.13857403 -0.5482849  -1.4597867\n",
      " -0.06493092 -0.5990529  -1.4332521  -0.07838099 -0.5752411  -1.5285146\n",
      "  0.05787501 -0.59343493 -1.5657237  -0.05484162 -0.46058643 -1.2936817\n",
      " -0.17032844 -0.23605642 -1.9470209  -0.01595812 -0.3881109  -1.9539549\n",
      "  0.14444256 -0.3599206  -1.4251697  -0.1539166  -0.22981551 -1.229129\n",
      " -0.08462662 -0.20924242 -1.313206   -0.0444864  -0.21470958 -1.4300601\n",
      "  0.04417196 -0.2280462  -1.273493  ]\n",
      "data: [ 0.0187253  -0.0340382  -0.24415536  0.03442964 -0.16395898 -0.6357593\n",
      " -0.06546284 -0.34910765 -1.3857598  -0.21017951 -0.41019332 -1.6806914\n",
      " -0.37848437 -0.516016   -2.160459   -0.18052876 -0.6461446  -1.5448585\n",
      "  0.01111954 -0.6821052  -1.3773453  -0.03746217 -0.61397254 -1.4355868\n",
      " -0.03325067 -0.7581028  -1.5510861  -0.13857403 -0.5482849  -1.4597867\n",
      " -0.06493092 -0.5990529  -1.4332521  -0.07838099 -0.5752411  -1.5285145\n",
      "  0.05787501 -0.59343493 -1.5657238  -0.05484162 -0.46058643 -1.2936817\n",
      " -0.17032844 -0.23605642 -1.9470209  -0.01595812 -0.38811094 -1.9539549\n",
      "  0.14444256 -0.3599206  -1.4251697  -0.1539166  -0.22981553 -1.229129\n",
      " -0.08462663 -0.20924242 -1.3132061  -0.04448639 -0.21470958 -1.4300601\n",
      "  0.04417196 -0.2280462  -1.273493    0.11      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F898>\n",
      "tensor([[ 0.0132, -0.0842, -0.2445,  ...,  0.0303, -0.2682, -1.3034],\n",
      "        [ 0.0132, -0.0842, -0.2445,  ...,  0.0303, -0.2682, -1.3034],\n",
      "        [ 0.0132, -0.0842, -0.2445,  ...,  0.0303, -0.2682, -1.3034],\n",
      "        ...,\n",
      "        [-0.3820,  0.1613, -0.3620,  ..., -0.8460,  0.5785, -0.5050],\n",
      "        [-0.1389, -0.0780,  0.5941,  ..., -0.2411,  0.7120,  0.2555],\n",
      "        [-0.1389, -0.0780,  0.5941,  ..., -0.2411,  0.7120,  0.2555]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01317122 -0.08420759 -0.24447842  0.03387051 -0.22291018 -0.6670164\n",
      " -0.05781015 -0.40272167 -1.4146664  -0.19922587 -0.46573347 -1.707496\n",
      " -0.3650534  -0.57390565 -2.185775   -0.18652824 -0.6884461  -1.5699589\n",
      "  0.01727763 -0.71784186 -1.3798735  -0.03082883 -0.6531759  -1.4372903\n",
      " -0.03544701 -0.7856607  -1.5528088  -0.14727165 -0.5864631  -1.4885563\n",
      " -0.06896251 -0.63815844 -1.4606987  -0.08568815 -0.6128505  -1.5542698\n",
      "  0.04498531 -0.6306838  -1.5992135  -0.06493799 -0.5036864  -1.3195809\n",
      " -0.17197004 -0.27776727 -1.9419552  -0.02732164 -0.42539236 -1.9434358\n",
      "  0.12402959 -0.39702588 -1.4558326  -0.16129605 -0.2691484  -1.2558676\n",
      " -0.0905993  -0.24664025 -1.3354272  -0.04584904 -0.255022   -1.4517472\n",
      "  0.03030748 -0.26821536 -1.3034326 ]\n",
      "data: [ 0.01317122 -0.08420759 -0.24447842  0.03387051 -0.22291018 -0.6670164\n",
      " -0.05781015 -0.40272167 -1.4146664  -0.19922586 -0.46573344 -1.707496\n",
      " -0.36505336 -0.57390565 -2.185775   -0.18652825 -0.6884461  -1.5699589\n",
      "  0.01727763 -0.71784186 -1.3798735  -0.03082883 -0.6531759  -1.4372903\n",
      " -0.03544701 -0.7856607  -1.5528089  -0.14727165 -0.5864631  -1.4885563\n",
      " -0.06896251 -0.63815844 -1.4606987  -0.08568815 -0.6128505  -1.5542697\n",
      "  0.04498531 -0.6306838  -1.5992134  -0.06493799 -0.5036864  -1.3195808\n",
      " -0.17197004 -0.27776727 -1.9419552  -0.02732164 -0.42539233 -1.9434358\n",
      "  0.12402959 -0.39702588 -1.4558327  -0.16129607 -0.2691484  -1.2558676\n",
      " -0.0905993  -0.24664025 -1.335427   -0.04584904 -0.255022   -1.4517472\n",
      "  0.03030748 -0.26821536 -1.3034326   0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[ 0.0292, -0.0712, -0.2568,  ...,  0.0470, -0.2604, -1.2756],\n",
      "        [ 0.0292, -0.0712, -0.2568,  ...,  0.0470, -0.2604, -1.2756],\n",
      "        [ 0.0292, -0.0712, -0.2568,  ...,  0.0470, -0.2604, -1.2756],\n",
      "        ...,\n",
      "        [-0.1131,  0.4028, -0.1182,  ..., -0.6925,  0.9186, -0.4084],\n",
      "        [-0.1317, -0.1494,  0.5852,  ..., -0.2366,  0.6244,  0.2316],\n",
      "        [-0.1317, -0.1494,  0.5852,  ..., -0.2366,  0.6244,  0.2316]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02916662 -0.07121755 -0.25683823  0.05573737 -0.1874336  -0.6280253\n",
      " -0.061896   -0.38714936 -1.4160516  -0.20724678 -0.45026577 -1.7057368\n",
      " -0.36000913 -0.5431663  -2.2015133  -0.15958752 -0.69123936 -1.5733212\n",
      "  0.01099057 -0.7386838  -1.4203315  -0.04005335 -0.6666436  -1.4796513\n",
      " -0.04582473 -0.8232968  -1.5993981  -0.12081635 -0.6024811  -1.483692\n",
      " -0.06065308 -0.65020525 -1.455825   -0.08193974 -0.6211251  -1.5445349\n",
      "  0.05071092 -0.64407504 -1.5690382  -0.04484559 -0.50279593 -1.321171\n",
      " -0.17687836 -0.27244315 -2.0243282  -0.01500839 -0.42969415 -2.0433455\n",
      "  0.14415224 -0.39983675 -1.4338677  -0.14805438 -0.27652055 -1.2486303\n",
      " -0.08610347 -0.24931505 -1.335945   -0.052626   -0.24709266 -1.4516914\n",
      "  0.04699627 -0.2604264  -1.275606  ]\n",
      "data: [ 0.02916662 -0.07121755 -0.25683823  0.05573737 -0.1874336  -0.6280253\n",
      " -0.061896   -0.38714936 -1.4160516  -0.20724678 -0.45026577 -1.7057366\n",
      " -0.3600091  -0.5431663  -2.2015133  -0.15958752 -0.6912393  -1.5733212\n",
      "  0.01099057 -0.7386839  -1.4203315  -0.04005335 -0.6666436  -1.4796513\n",
      " -0.04582473 -0.8232968  -1.5993981  -0.12081634 -0.6024811  -1.483692\n",
      " -0.06065308 -0.65020525 -1.4558251  -0.08193974 -0.6211251  -1.5445349\n",
      "  0.05071092 -0.64407504 -1.569038   -0.04484559 -0.50279593 -1.3211712\n",
      " -0.17687836 -0.27244315 -2.0243282  -0.01500839 -0.42969415 -2.0433455\n",
      "  0.14415224 -0.39983672 -1.4338677  -0.14805438 -0.27652055 -1.2486303\n",
      " -0.08610347 -0.24931505 -1.335945   -0.052626   -0.24709266 -1.4516914\n",
      "  0.04699627 -0.2604264  -1.275606    0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F0B8>\n",
      "tensor([[ 0.0230, -0.0372, -0.2422,  ...,  0.0576, -0.2269, -1.2875],\n",
      "        [ 0.0230, -0.0372, -0.2422,  ...,  0.0576, -0.2269, -1.2875],\n",
      "        [ 0.0230, -0.0372, -0.2422,  ...,  0.0576, -0.2269, -1.2875],\n",
      "        ...,\n",
      "        [-0.1597,  0.3064, -0.0638,  ..., -0.8163,  0.7750, -0.2602],\n",
      "        [-0.1439, -0.1477,  0.5407,  ..., -0.2249,  0.6090,  0.2045],\n",
      "        [-0.1439, -0.1477,  0.5407,  ..., -0.2249,  0.6090,  0.2045]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.3042787e-02 -3.7230767e-02 -2.4223529e-01  3.5724577e-02\n",
      " -1.8028998e-01 -6.5864050e-01 -4.0733352e-02 -3.5711950e-01\n",
      " -1.3823895e+00 -1.8318781e-01 -4.1604334e-01 -1.6870021e+00\n",
      " -3.6080936e-01 -5.3784776e-01 -2.1495292e+00 -1.8492353e-01\n",
      " -6.4026117e-01 -1.5435262e+00  4.4981636e-02 -6.6600215e-01\n",
      " -1.3499525e+00 -6.9272146e-03 -6.0652733e-01 -1.4039832e+00\n",
      " -4.6802983e-03 -7.3688364e-01 -1.5198811e+00 -1.3772333e-01\n",
      " -5.3281367e-01 -1.4575163e+00 -4.7519006e-02 -5.8990312e-01\n",
      " -1.4353443e+00 -5.4078214e-02 -5.6793535e-01 -1.5353205e+00\n",
      "  7.5322591e-02 -5.9230816e-01 -1.5865121e+00 -4.1371629e-02\n",
      " -4.4928089e-01 -1.2843589e+00 -1.5145689e-01 -2.2720829e-01\n",
      " -1.9146917e+00  1.9137785e-03 -3.8235337e-01 -1.9087580e+00\n",
      "  1.5758198e-01 -3.5089782e-01 -1.4381639e+00 -1.4449716e-01\n",
      " -2.1268624e-01 -1.2242508e+00 -5.8170266e-02 -1.9572136e-01\n",
      " -1.3048688e+00 -1.1379279e-02 -2.1538013e-01 -1.4227263e+00\n",
      "  5.7570726e-02 -2.2686397e-01 -1.2875177e+00]\n",
      "data: [ 2.3042787e-02 -3.7230767e-02 -2.4223527e-01  3.5724577e-02\n",
      " -1.8029000e-01 -6.5864050e-01 -4.0733352e-02 -3.5711947e-01\n",
      " -1.3823895e+00 -1.8318781e-01 -4.1604337e-01 -1.6870021e+00\n",
      " -3.6080936e-01 -5.3784776e-01 -2.1495292e+00 -1.8492353e-01\n",
      " -6.4026117e-01 -1.5435262e+00  4.4981636e-02 -6.6600209e-01\n",
      " -1.3499523e+00 -6.9272150e-03 -6.0652733e-01 -1.4039834e+00\n",
      " -4.6802983e-03 -7.3688364e-01 -1.5198811e+00 -1.3772333e-01\n",
      " -5.3281367e-01 -1.4575163e+00 -4.7519006e-02 -5.8990312e-01\n",
      " -1.4353443e+00 -5.4078210e-02 -5.6793535e-01 -1.5353206e+00\n",
      "  7.5322591e-02 -5.9230816e-01 -1.5865121e+00 -4.1371629e-02\n",
      " -4.4928089e-01 -1.2843589e+00 -1.5145689e-01 -2.2720829e-01\n",
      " -1.9146916e+00  1.9137785e-03 -3.8235337e-01 -1.9087580e+00\n",
      "  1.5758198e-01 -3.5089782e-01 -1.4381639e+00 -1.4449716e-01\n",
      " -2.1268624e-01 -1.2242508e+00 -5.8170266e-02 -1.9572136e-01\n",
      " -1.3048688e+00 -1.1379279e-02 -2.1538013e-01 -1.4227263e+00\n",
      "  5.7570726e-02 -2.2686395e-01 -1.2875177e+00  1.4000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0041, -0.0836, -0.2582,  ...,  0.0346, -0.2694, -1.3243],\n",
      "        [ 0.0041, -0.0836, -0.2582,  ...,  0.0346, -0.2694, -1.3243],\n",
      "        [ 0.0041, -0.0836, -0.2582,  ...,  0.0346, -0.2694, -1.3243],\n",
      "        ...,\n",
      "        [-0.1612,  0.4267, -0.1277,  ..., -0.7379,  0.9055, -0.3494],\n",
      "        [-0.1618, -0.1301,  0.5748,  ..., -0.2441,  0.6576,  0.2250],\n",
      "        [-0.1618, -0.1301,  0.5748,  ..., -0.2441,  0.6576,  0.2250]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00407988 -0.08359344 -0.2582027   0.02187051 -0.22928755 -0.6863927\n",
      " -0.05784484 -0.40370727 -1.426588   -0.1973928  -0.46529534 -1.723791\n",
      " -0.36754414 -0.5827589  -2.1953363  -0.19925562 -0.6832558  -1.5873829\n",
      "  0.02424657 -0.706555   -1.3903131  -0.02450652 -0.6442908  -1.4457728\n",
      " -0.02278657 -0.7686751  -1.5609192  -0.15684618 -0.5756391  -1.5057184\n",
      " -0.0677494  -0.6291536  -1.481269   -0.07786174 -0.60508585 -1.5768788\n",
      "  0.05266879 -0.62423277 -1.6291211  -0.06693908 -0.49808642 -1.3321203\n",
      " -0.16779985 -0.27194118 -1.9375144  -0.02313013 -0.4207144  -1.9315535\n",
      "  0.13012919 -0.39059308 -1.4804531  -0.16552384 -0.25997525 -1.2699429\n",
      " -0.08363894 -0.24044001 -1.3478446  -0.03423342 -0.2562467  -1.464148\n",
      "  0.03460834 -0.26935798 -1.3243209 ]\n",
      "data: [ 0.00407988 -0.08359344 -0.2582027   0.02187051 -0.22928755 -0.6863927\n",
      " -0.05784484 -0.40370727 -1.4265882  -0.1973928  -0.46529534 -1.723791\n",
      " -0.36754414 -0.5827589  -2.1953363  -0.19925562 -0.6832558  -1.5873829\n",
      "  0.02424657 -0.706555   -1.3903131  -0.02450652 -0.64429075 -1.4457726\n",
      " -0.02278657 -0.7686751  -1.5609192  -0.15684618 -0.5756391  -1.5057184\n",
      " -0.0677494  -0.6291536  -1.4812691  -0.07786174 -0.60508585 -1.5768788\n",
      "  0.05266879 -0.62423277 -1.6291211  -0.06693908 -0.49808642 -1.3321204\n",
      " -0.16779986 -0.27194118 -1.9375145  -0.02313013 -0.4207144  -1.9315535\n",
      "  0.13012919 -0.39059308 -1.4804531  -0.16552383 -0.25997525 -1.2699429\n",
      " -0.08363894 -0.24044001 -1.3478446  -0.03423342 -0.2562467  -1.464148\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.03460834 -0.26935798 -1.324321    0.15      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B320>\n",
      "tensor([[ 0.0241, -0.0933, -0.2459,  ...,  0.0459, -0.2781, -1.2807],\n",
      "        [ 0.0241, -0.0933, -0.2459,  ...,  0.0459, -0.2781, -1.2807],\n",
      "        [ 0.0241, -0.0933, -0.2459,  ...,  0.0459, -0.2781, -1.2807],\n",
      "        ...,\n",
      "        [-0.1527,  0.3986, -0.1902,  ..., -0.7500,  0.9068, -0.4612],\n",
      "        [-0.1692, -0.1684,  0.5791,  ..., -0.2687,  0.6039,  0.2355],\n",
      "        [-0.1692, -0.1684,  0.5791,  ..., -0.2687,  0.6039,  0.2355]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02405426 -0.09329669 -0.24587399  0.04516376 -0.22385135 -0.6413789\n",
      " -0.05228023 -0.4159141  -1.4008029  -0.19413619 -0.47682616 -1.6946249\n",
      " -0.35476357 -0.5829661  -2.1721427  -0.17270982 -0.7067873  -1.5596671\n",
      "  0.0235682  -0.74467915 -1.3943219  -0.02722746 -0.678051   -1.4503255\n",
      " -0.02631444 -0.8210188  -1.5672812  -0.13112943 -0.607279   -1.4726441\n",
      " -0.0577386  -0.6581544  -1.4470634  -0.07004002 -0.63195837 -1.5378811\n",
      "  0.05928189 -0.65534395 -1.5748246  -0.04646807 -0.5135435  -1.3071845\n",
      " -0.17021157 -0.28638527 -1.9779005  -0.01119384 -0.4428941  -1.9850924\n",
      "  0.14500926 -0.40908748 -1.4369848  -0.15102048 -0.28183347 -1.2394478\n",
      " -0.07761821 -0.2575308  -1.3241556  -0.03760019 -0.26579723 -1.4397407\n",
      "  0.04589526 -0.27813    -1.2807441 ]\n",
      "data: [ 0.02405426 -0.09329669 -0.24587399  0.04516376 -0.22385135 -0.6413789\n",
      " -0.05228023 -0.4159141  -1.400803   -0.19413619 -0.47682616 -1.6946249\n",
      " -0.35476357 -0.5829661  -2.1721427  -0.17270982 -0.7067873  -1.5596671\n",
      "  0.0235682  -0.7446792  -1.3943219  -0.02722746 -0.678051   -1.4503255\n",
      " -0.02631444 -0.8210188  -1.5672812  -0.13112943 -0.607279   -1.4726441\n",
      " -0.0577386  -0.6581544  -1.4470634  -0.07004002 -0.63195837 -1.5378811\n",
      "  0.05928188 -0.65534395 -1.5748246  -0.04646807 -0.5135435  -1.3071845\n",
      " -0.17021157 -0.28638527 -1.9779005  -0.01119384 -0.4428941  -1.9850925\n",
      "  0.14500926 -0.40908748 -1.4369847  -0.15102048 -0.28183347 -1.2394478\n",
      " -0.07761821 -0.2575308  -1.3241556  -0.03760019 -0.26579723 -1.4397407\n",
      "  0.04589526 -0.27813    -1.2807441   0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BB38>\n",
      "tensor([[ 0.0203, -0.0423, -0.2425,  ...,  0.0457, -0.2376, -1.2608],\n",
      "        [ 0.0203, -0.0423, -0.2425,  ...,  0.0457, -0.2376, -1.2608],\n",
      "        [ 0.0203, -0.0423, -0.2425,  ...,  0.0457, -0.2376, -1.2608],\n",
      "        ...,\n",
      "        [-0.1507,  0.3545, -0.0864,  ..., -0.7675,  0.8441, -0.3535],\n",
      "        [-0.1277, -0.1458,  0.5647,  ..., -0.1990,  0.6161,  0.2121],\n",
      "        [-0.1277, -0.1458,  0.5647,  ..., -0.1990,  0.6161,  0.2121]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02032201 -0.04232518 -0.24251935  0.03750729 -0.1674389  -0.619884\n",
      " -0.07305197 -0.36381134 -1.3907509  -0.22104084 -0.42669317 -1.6868615\n",
      " -0.38773397 -0.52973783 -2.1714387  -0.17872459 -0.6626768  -1.5492554\n",
      "  0.00834455 -0.70633155 -1.3744185  -0.04324014 -0.6368795  -1.4329362\n",
      " -0.04687808 -0.78968304 -1.5523462  -0.13597015 -0.567352   -1.4596367\n",
      " -0.06841292 -0.6194267  -1.4315226  -0.08480944 -0.5943592  -1.5252087\n",
      "  0.05102829 -0.6158621  -1.5557768  -0.0518491  -0.47231787 -1.2937882\n",
      " -0.17923045 -0.24662167 -1.9799185  -0.01842423 -0.4044822  -1.9916806\n",
      "  0.1449407  -0.37449282 -1.4151249  -0.15448698 -0.24288552 -1.22539\n",
      " -0.08705758 -0.2208285  -1.3118737  -0.05002124 -0.22453347 -1.4285755\n",
      "  0.04565737 -0.23757015 -1.2608013 ]\n",
      "data: [ 0.02032201 -0.04232518 -0.24251933  0.03750729 -0.1674389  -0.619884\n",
      " -0.07305197 -0.36381134 -1.3907509  -0.22104084 -0.42669314 -1.6868615\n",
      " -0.38773397 -0.52973783 -2.1714387  -0.17872459 -0.6626769  -1.5492554\n",
      "  0.00834455 -0.70633155 -1.3744185  -0.04324014 -0.6368795  -1.4329362\n",
      " -0.04687808 -0.7896831  -1.5523462  -0.13597015 -0.567352   -1.4596367\n",
      " -0.06841292 -0.6194267  -1.4315227  -0.08480944 -0.5943592  -1.5252087\n",
      "  0.05102829 -0.6158621  -1.5557768  -0.0518491  -0.47231787 -1.2937882\n",
      " -0.17923047 -0.24662167 -1.9799185  -0.01842423 -0.4044822  -1.9916806\n",
      "  0.1449407  -0.37449282 -1.4151248  -0.15448698 -0.24288552 -1.22539\n",
      " -0.08705758 -0.22082849 -1.3118737  -0.05002124 -0.22453347 -1.4285754\n",
      "  0.04565737 -0.23757015 -1.2608013   0.17      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F438>\n",
      "tensor([[ 0.0097, -0.0175, -0.2367,  ...,  0.0328, -0.2104, -1.2826],\n",
      "        [ 0.0097, -0.0175, -0.2367,  ...,  0.0328, -0.2104, -1.2826],\n",
      "        [ 0.0097, -0.0175, -0.2367,  ...,  0.0328, -0.2104, -1.2826],\n",
      "        ...,\n",
      "        [-0.1950,  0.3170, -0.1135,  ..., -0.8350,  0.7675, -0.2843],\n",
      "        [-0.1441, -0.1694,  0.5389,  ..., -0.2148,  0.6050,  0.2085],\n",
      "        [-0.1441, -0.1694,  0.5389,  ..., -0.2148,  0.6050,  0.2085]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 9.6957423e-03 -1.7540956e-02 -2.3670152e-01  2.0198744e-02\n",
      " -1.5665853e-01 -6.5317059e-01 -7.7152520e-02 -3.3759966e-01\n",
      " -1.3940303e+00 -2.2170720e-01 -4.0134719e-01 -1.6876669e+00\n",
      " -3.9735940e-01 -5.1058763e-01 -2.1608167e+00 -1.9503158e-01\n",
      " -6.2774152e-01 -1.5464107e+00  1.8257424e-03 -6.5968937e-01\n",
      " -1.3583251e+00 -4.3820105e-02 -5.9263766e-01 -1.4164497e+00\n",
      " -4.0410087e-02 -7.3038417e-01 -1.5306120e+00 -1.5384853e-01\n",
      " -5.2475870e-01 -1.4649322e+00 -7.6631814e-02 -5.7720381e-01\n",
      " -1.4345090e+00 -8.9721777e-02 -5.5491596e-01 -1.5307798e+00\n",
      "  5.0859548e-02 -5.6873751e-01 -1.5745070e+00 -7.0448592e-02\n",
      " -4.4422770e-01 -1.2978053e+00 -1.7627239e-01 -2.2107893e-01\n",
      " -1.9210631e+00 -2.8854631e-02 -3.6793989e-01 -1.9232837e+00\n",
      "  1.3230395e-01 -3.4189343e-01 -1.4312024e+00 -1.6485283e-01\n",
      " -2.0893762e-01 -1.2340430e+00 -9.7116463e-02 -1.8972977e-01\n",
      " -1.3166769e+00 -5.2041925e-02 -1.9612694e-01 -1.4336727e+00\n",
      "  3.2794476e-02 -2.1040545e-01 -1.2826364e+00]\n",
      "data: [ 9.6957423e-03 -1.7540956e-02 -2.3670153e-01  2.0198744e-02\n",
      " -1.5665853e-01 -6.5317065e-01 -7.7152520e-02 -3.3759966e-01\n",
      " -1.3940303e+00 -2.2170720e-01 -4.0134719e-01 -1.6876669e+00\n",
      " -3.9735940e-01 -5.1058763e-01 -2.1608167e+00 -1.9503158e-01\n",
      " -6.2774152e-01 -1.5464107e+00  1.8257424e-03 -6.5968931e-01\n",
      " -1.3583252e+00 -4.3820105e-02 -5.9263766e-01 -1.4164498e+00\n",
      " -4.0410087e-02 -7.3038411e-01 -1.5306120e+00 -1.5384853e-01\n",
      " -5.2475870e-01 -1.4649322e+00 -7.6631814e-02 -5.7720381e-01\n",
      " -1.4345089e+00 -8.9721777e-02 -5.5491596e-01 -1.5307798e+00\n",
      "  5.0859548e-02 -5.6873751e-01 -1.5745070e+00 -7.0448592e-02\n",
      " -4.4422767e-01 -1.2978053e+00 -1.7627239e-01 -2.2107893e-01\n",
      " -1.9210631e+00 -2.8854631e-02 -3.6793986e-01 -1.9232837e+00\n",
      "  1.3230395e-01 -3.4189343e-01 -1.4312024e+00 -1.6485283e-01\n",
      " -2.0893760e-01 -1.2340430e+00 -9.7116463e-02 -1.8972977e-01\n",
      " -1.3166767e+00 -5.2041925e-02 -1.9612694e-01 -1.4336727e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3.2794476e-02 -2.1040544e-01 -1.2826364e+00  1.8000001e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0298, -0.0944, -0.2253,  ...,  0.0415, -0.2793, -1.2887],\n",
      "        [ 0.0298, -0.0944, -0.2253,  ...,  0.0415, -0.2793, -1.2887],\n",
      "        [ 0.0298, -0.0944, -0.2253,  ...,  0.0415, -0.2793, -1.2887],\n",
      "        ...,\n",
      "        [-0.3447,  0.2673, -0.3659,  ..., -0.8881,  0.7105, -0.5020],\n",
      "        [-0.1401, -0.0853,  0.6052,  ..., -0.2408,  0.7101,  0.2831],\n",
      "        [-0.1401, -0.0853,  0.6052,  ..., -0.2408,  0.7101,  0.2831]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02980468 -0.0944279  -0.22531241  0.04968468 -0.23617496 -0.65564966\n",
      " -0.04248378 -0.40791294 -1.3882446  -0.182984   -0.47026825 -1.6770884\n",
      " -0.34849173 -0.5740971  -2.1573117  -0.16581956 -0.69838583 -1.5418682\n",
      "  0.02273691 -0.72247857 -1.3683832  -0.02121063 -0.6554276  -1.4299309\n",
      " -0.01921084 -0.78598994 -1.5415591  -0.13077798 -0.59643227 -1.4676651\n",
      " -0.05378554 -0.6437021  -1.4380842  -0.07388707 -0.61944336 -1.5323057\n",
      "  0.06012168 -0.6296937  -1.5767486  -0.05434228 -0.5171677  -1.3011203\n",
      " -0.15129846 -0.2938594  -1.9017724  -0.01491269 -0.43319562 -1.9041388\n",
      "  0.134208   -0.408033   -1.4369583  -0.14240438 -0.28464544 -1.2415241\n",
      " -0.0804932  -0.26217127 -1.319212   -0.03705171 -0.26433507 -1.4374014\n",
      "  0.04149192 -0.2792822  -1.2887274 ]\n",
      "data: [ 0.02980468 -0.0944279  -0.22531241  0.04968468 -0.23617497 -0.65564966\n",
      " -0.04248378 -0.40791294 -1.3882446  -0.182984   -0.47026825 -1.6770883\n",
      " -0.34849176 -0.5740971  -2.1573117  -0.16581956 -0.69838583 -1.5418683\n",
      "  0.02273691 -0.72247857 -1.3683832  -0.02121063 -0.6554276  -1.4299309\n",
      " -0.01921084 -0.78598994 -1.5415591  -0.13077798 -0.59643227 -1.4676651\n",
      " -0.05378554 -0.6437021  -1.4380842  -0.07388707 -0.61944336 -1.5323057\n",
      "  0.06012168 -0.6296937  -1.5767486  -0.05434228 -0.5171677  -1.3011203\n",
      " -0.15129846 -0.2938594  -1.9017723  -0.01491269 -0.43319562 -1.9041388\n",
      "  0.134208   -0.408033   -1.4369583  -0.14240438 -0.28464544 -1.2415241\n",
      " -0.0804932  -0.26217127 -1.3192121  -0.03705171 -0.26433507 -1.4374014\n",
      "  0.04149192 -0.2792822  -1.2887274   0.19      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[ 0.0282, -0.0811, -0.2347,  ...,  0.0535, -0.2728, -1.2553],\n",
      "        [ 0.0282, -0.0811, -0.2347,  ...,  0.0535, -0.2728, -1.2553],\n",
      "        [ 0.0282, -0.0811, -0.2347,  ...,  0.0535, -0.2728, -1.2553],\n",
      "        ...,\n",
      "        [-0.1342,  0.4133, -0.0857,  ..., -0.6803,  0.9076, -0.3705],\n",
      "        [-0.1709, -0.1329,  0.5785,  ..., -0.2704,  0.6418,  0.2198],\n",
      "        [-0.1709, -0.1329,  0.5785,  ..., -0.2704,  0.6418,  0.2198]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02816815 -0.08113734 -0.23470102  0.05448964 -0.20259416 -0.6067131\n",
      " -0.05689751 -0.40877473 -1.4034604  -0.201745   -0.4741286  -1.6977472\n",
      " -0.3580877  -0.5759067  -2.1875956  -0.1647164  -0.7030825  -1.5625972\n",
      "  0.0276154  -0.75211453 -1.385365   -0.02708234 -0.68484086 -1.440582\n",
      " -0.03968798 -0.83827746 -1.5627589  -0.12207609 -0.6093996  -1.4680835\n",
      " -0.05621065 -0.6630323  -1.4413962  -0.0739717  -0.63447803 -1.5292794\n",
      "  0.05361292 -0.66346437 -1.5588163  -0.038385   -0.508909   -1.301694\n",
      " -0.17596874 -0.27884126 -2.012947   -0.00942268 -0.44306737 -2.0264025\n",
      "  0.14836587 -0.4087786  -1.4176841  -0.14769542 -0.279141   -1.2278215\n",
      " -0.07524806 -0.25375974 -1.3134234  -0.03800599 -0.2602498  -1.4274628\n",
      "  0.05346889 -0.27275142 -1.2552907 ]\n",
      "data: [ 0.02816815 -0.08113734 -0.23470102  0.05448963 -0.20259416 -0.6067131\n",
      " -0.05689751 -0.40877473 -1.4034604  -0.20174499 -0.4741286  -1.6977472\n",
      " -0.3580877  -0.5759067  -2.1875956  -0.1647164  -0.7030825  -1.5625972\n",
      "  0.0276154  -0.75211453 -1.385365   -0.02708234 -0.68484086 -1.4405819\n",
      " -0.03968798 -0.83827746 -1.5627589  -0.12207609 -0.6093996  -1.4680835\n",
      " -0.05621065 -0.6630323  -1.4413962  -0.0739717  -0.63447803 -1.5292794\n",
      "  0.05361292 -0.66346437 -1.5588164  -0.038385   -0.508909   -1.301694\n",
      " -0.17596874 -0.27884126 -2.012947   -0.00942268 -0.44306737 -2.0264025\n",
      "  0.14836587 -0.4087786  -1.4176841  -0.14769542 -0.279141   -1.2278215\n",
      " -0.07524806 -0.25375974 -1.3134235  -0.03800599 -0.2602498  -1.4274628\n",
      "  0.05346889 -0.27275142 -1.2552907   0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.183 3.193 3.203]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " [3.147 3.147 3.146 ... 3.18  3.181 3.179]\n",
      " ...\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.987 2.987 2.986 ... 2.954 2.981 2.992]\n",
      " [2.978 2.978 2.979 ... 2.954 2.972 2.979]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[ 0.0226, -0.0326, -0.2272,  ...,  0.0524, -0.2233, -1.2639],\n",
      "        [ 0.0226, -0.0326, -0.2272,  ...,  0.0524, -0.2233, -1.2639],\n",
      "        [ 0.0226, -0.0326, -0.2272,  ...,  0.0524, -0.2233, -1.2639],\n",
      "        ...,\n",
      "        [-0.1732,  0.3196, -0.0942,  ..., -0.8005,  0.7683, -0.2880],\n",
      "        [-0.1389, -0.1402,  0.5657,  ..., -0.2003,  0.6145,  0.2224],\n",
      "        [-0.1389, -0.1402,  0.5657,  ..., -0.2003,  0.6145,  0.2224]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02261335 -0.03259488 -0.22722827  0.0358988  -0.17118192 -0.6328558\n",
      " -0.05360056 -0.3601619  -1.3790615  -0.1990054  -0.42242756 -1.6825256\n",
      " -0.37526977 -0.53995955 -2.150021   -0.18561791 -0.64506763 -1.5363955\n",
      "  0.03333679 -0.67985415 -1.3402103  -0.02033344 -0.61870426 -1.3946754\n",
      " -0.02466972 -0.7581346  -1.5131634  -0.13847889 -0.5400909  -1.4465063\n",
      " -0.05719346 -0.5980793  -1.4215841  -0.06730608 -0.5754268  -1.5194017\n",
      "  0.06275862 -0.60101813 -1.5643357  -0.0448676  -0.4505403  -1.2748191\n",
      " -0.16581438 -0.22724172 -1.9344547  -0.0074747  -0.38606045 -1.9342352\n",
      "  0.15063585 -0.35405213 -1.4163742  -0.14974532 -0.21457717 -1.2104315\n",
      " -0.06867282 -0.19587041 -1.2937682  -0.02432555 -0.21187077 -1.4106572\n",
      "  0.05238169 -0.22331305 -1.263922  ]\n",
      "data: [-2.82 -3.54  2.29 -2.83 -3.45  2.35 -2.78 -3.34  2.61 -2.76 -3.19  2.53\n",
      " -2.76 -3.19  2.53 -2.76 -3.16  2.53 -2.75 -3.28  2.49 -2.18 -1.89 -0.21\n",
      " -2.21 -1.79 -0.24 -2.15 -2.13  0.03  0.    0.    0.   -2.17 -1.68  0.02\n",
      " -2.13 -1.68  0.02 -2.1  -2.07 -0.01 -2.19 -2.13  0.03  0.    0.    0.\n",
      " -2.03 -1.64  0.15 -2.73 -3.25  2.49 -2.71 -3.28  2.49 -1.99 -1.62  0.24\n",
      " -2.01 -1.64  0.22  0.  ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F470>\n",
      "tensor([[ 0.0400,  0.0021, -0.0558,  ...,  0.0627, -0.2429,  0.0282],\n",
      "        [ 0.0400,  0.0021, -0.0558,  ...,  0.0627, -0.2429,  0.0282],\n",
      "        [ 0.0400,  0.0021, -0.0558,  ...,  0.0627, -0.2429,  0.0282],\n",
      "        ...,\n",
      "        [ 0.8066, -0.8571,  0.3204,  ..., -0.0544, -0.8569, -0.3960],\n",
      "        [-0.2616,  0.0179,  0.4265,  ..., -1.2756, -0.0550,  1.7485],\n",
      "        [-0.2616,  0.0179,  0.4265,  ..., -1.2756, -0.0550,  1.7485]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04004776  0.00208582 -0.05577053 -0.0475677   0.00323168 -0.05274851\n",
      " -0.13392326 -0.09401576 -0.19357686 -0.15984192 -0.18766683 -0.13679738\n",
      " -0.09685885 -0.22255976 -0.14254306 -0.15498358 -0.13278341 -0.39352334\n",
      " -0.08615998 -0.16279338  0.09037852 -0.14676878 -0.2530632   0.11698869\n",
      " -0.22766155 -0.22475386  0.05269196 -0.11958232 -0.14219859 -0.38879833\n",
      " -0.1949876  -0.1880113  -0.3162108  -0.22224298 -0.22063912 -0.25707236\n",
      " -0.24098486 -0.30194354 -0.20591101 -0.07844949 -0.10352759 -0.35479996\n",
      " -0.1411387  -0.17456867 -0.26755187 -0.15239036 -0.20096457 -0.26287365\n",
      " -0.08306831 -0.27297318 -0.11334734 -0.03553226 -0.06724973 -0.2672311\n",
      "  0.01530195 -0.11976935 -0.16405976  0.01690162 -0.17901997 -0.09862569\n",
      "  0.06270769 -0.24291216  0.02818788]\n",
      "init: [ 0.04004776  0.00208582 -0.05577053 -0.0475677   0.00323168 -0.05274851\n",
      " -0.13392326 -0.09401576 -0.19357686 -0.15984192 -0.18766683 -0.13679738\n",
      " -0.09685885 -0.22255976 -0.14254306 -0.15498358 -0.13278341 -0.39352334\n",
      " -0.08615998 -0.16279338  0.09037852 -0.14676878 -0.2530632   0.11698869\n",
      " -0.22766155 -0.22475386  0.05269196 -0.11958232 -0.14219859 -0.38879833\n",
      " -0.1949876  -0.1880113  -0.3162108  -0.22224298 -0.22063912 -0.25707236\n",
      " -0.24098486 -0.30194354 -0.20591101 -0.07844949 -0.10352759 -0.35479996\n",
      " -0.1411387  -0.17456867 -0.26755187 -0.15239036 -0.20096457 -0.26287365\n",
      " -0.08306831 -0.27297318 -0.11334734 -0.03553226 -0.06724973 -0.2672311\n",
      "  0.01530195 -0.11976935 -0.16405976  0.01690162 -0.17901997 -0.09862569\n",
      "  0.06270769 -0.24291216  0.02818788]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [ 0.04004775  0.00208582 -0.05577053 -0.0475677   0.00323168 -0.05274851\n",
      " -0.13392326 -0.09401576 -0.19357686 -0.15984192 -0.18766683 -0.13679738\n",
      " -0.09685885 -0.22255975 -0.14254306 -0.15498358 -0.13278341 -0.39352334\n",
      " -0.08615998 -0.16279338  0.09037852 -0.14676878 -0.2530632   0.11698869\n",
      " -0.22766155 -0.22475386  0.05269196 -0.11958232 -0.14219859 -0.38879833\n",
      " -0.1949876  -0.1880113  -0.3162108  -0.22224298 -0.22063914 -0.25707236\n",
      " -0.24098486 -0.30194354 -0.20591101 -0.07844949 -0.10352759 -0.35479996\n",
      " -0.1411387  -0.17456867 -0.26755187 -0.15239036 -0.20096457 -0.26287365\n",
      " -0.08306831 -0.27297318 -0.11334734 -0.03553226 -0.06724973 -0.2672311\n",
      "  0.01530195 -0.11976936 -0.16405976  0.01690162 -0.17901997 -0.09862569\n",
      "  0.06270769 -0.24291216  0.02818788  0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FF28>\n",
      "tensor([[-0.1413, -0.1303,  0.5330,  ..., -0.6219, -0.4314, -0.0778],\n",
      "        [-0.1413, -0.1303,  0.5330,  ..., -0.6219, -0.4314, -0.0778],\n",
      "        [-0.1413, -0.1303,  0.5330,  ..., -0.6219, -0.4314, -0.0778],\n",
      "        ...,\n",
      "        [ 0.5459, -0.0533, -0.3558,  ...,  0.7800,  0.6452, -0.8529],\n",
      "        [ 0.5309, -0.0549, -0.3646,  ...,  0.7057,  0.7370, -0.9246],\n",
      "        [ 0.5309, -0.0549, -0.3646,  ...,  0.7057,  0.7370, -0.9246]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.14132203 -0.13034119  0.53299993 -0.25339034 -0.20449325 -0.05493146\n",
      " -0.4529305  -0.2659465  -0.05343324 -0.65116936 -0.33885396 -0.09817243\n",
      " -0.77042216 -0.4310981  -0.23234373 -0.5755889  -0.46142218 -0.30828804\n",
      " -0.7623726  -0.51484346 -0.44572127 -0.8609047  -0.57528234 -0.46658385\n",
      " -0.89964205 -0.6632389  -0.46426165 -0.5424788  -0.44982108 -0.3272457\n",
      " -0.7400027  -0.56937873 -0.2674209  -0.8238736  -0.60651547 -0.26192868\n",
      " -0.8184217  -0.7051859  -0.21786302 -0.53407204 -0.41844004 -0.22673178\n",
      " -0.6750842  -0.41916224  0.03103673 -0.7205178  -0.5097996   0.02866256\n",
      " -0.7075326  -0.5673449  -0.14624107 -0.5425234  -0.34367722 -0.15416843\n",
      " -0.65399283 -0.36610413 -0.12381232 -0.6790487  -0.3903907  -0.1707555\n",
      " -0.6218629  -0.43136954 -0.07783943]\n",
      "data: [-0.14132203 -0.13034119  0.53299993 -0.25339034 -0.20449325 -0.05493146\n",
      " -0.45293054 -0.2659465  -0.05343324 -0.65116936 -0.33885396 -0.09817243\n",
      " -0.77042216 -0.4310981  -0.23234373 -0.5755889  -0.46142215 -0.30828804\n",
      " -0.7623726  -0.51484346 -0.44572127 -0.8609047  -0.57528234 -0.46658385\n",
      " -0.89964205 -0.6632389  -0.46426165 -0.5424788  -0.44982108 -0.3272457\n",
      " -0.7400027  -0.56937873 -0.2674209  -0.8238736  -0.60651547 -0.26192868\n",
      " -0.8184217  -0.70518583 -0.21786302 -0.53407204 -0.41844004 -0.22673178\n",
      " -0.6750842  -0.41916224  0.03103673 -0.7205178  -0.5097996   0.02866256\n",
      " -0.7075326  -0.5673449  -0.14624107 -0.5425234  -0.34367722 -0.15416843\n",
      " -0.65399283 -0.36610413 -0.12381231 -0.6790487  -0.3903907  -0.1707555\n",
      " -0.6218629  -0.43136954 -0.07783943  0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B320>\n",
      "tensor([[-0.1208, -0.2412,  0.2246,  ..., -0.6873, -0.5489, -0.0639],\n",
      "        [-0.1208, -0.2412,  0.2246,  ..., -0.6873, -0.5489, -0.0639],\n",
      "        [-0.1208, -0.2412,  0.2246,  ..., -0.6873, -0.5489, -0.0639],\n",
      "        ...,\n",
      "        [ 0.1768, -0.1183,  0.1475,  ...,  0.3976,  0.5811, -0.5567],\n",
      "        [ 0.3350,  0.1681,  0.1965,  ..., -0.1320,  0.8574, -0.2884],\n",
      "        [ 0.3350,  0.1681,  0.1965,  ..., -0.1320,  0.8574, -0.2884]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.12076766 -0.24116221  0.22463691 -0.30799335 -0.3671611  -0.18422788\n",
      " -0.4999165  -0.50985473 -0.08375517 -0.6874712  -0.6167904  -0.03142484\n",
      " -0.81406784 -0.67281187  0.01467423 -0.53501827 -0.6310371  -0.11933488\n",
      " -0.80854744 -0.7818022  -0.27093363 -0.84068936 -0.822155   -0.22519147\n",
      " -0.84915453 -0.8786645  -0.14533445 -0.5223713  -0.58808625 -0.14324725\n",
      " -0.7139488  -0.7330575  -0.04556236 -0.75674206 -0.7933328  -0.01773484\n",
      " -0.7446026  -0.825277    0.00686663 -0.5261207  -0.55446374 -0.1872673\n",
      " -0.6447978  -0.66054136  0.1488347  -0.7206194  -0.7037506   0.16332391\n",
      " -0.7394772  -0.74001265 -0.04331517 -0.5089645  -0.4555872  -0.12819624\n",
      " -0.6643103  -0.49325725 -0.08618388 -0.66053694 -0.53322494 -0.06418741\n",
      " -0.6873252  -0.5488868  -0.06385323]\n",
      "data: [-0.12076766 -0.24116221  0.22463691 -0.30799335 -0.3671611  -0.18422788\n",
      " -0.4999165  -0.50985473 -0.08375517 -0.6874712  -0.6167904  -0.03142484\n",
      " -0.81406784 -0.67281187  0.01467423 -0.53501827 -0.6310371  -0.11933488\n",
      " -0.80854744 -0.78180224 -0.27093363 -0.8406894  -0.822155   -0.22519147\n",
      " -0.84915453 -0.8786645  -0.14533445 -0.5223713  -0.58808625 -0.14324725\n",
      " -0.71394885 -0.7330575  -0.04556236 -0.7567421  -0.7933328  -0.01773484\n",
      " -0.74460256 -0.825277    0.00686663 -0.5261207  -0.55446374 -0.1872673\n",
      " -0.6447978  -0.66054136  0.1488347  -0.7206194  -0.7037506   0.16332392\n",
      " -0.7394772  -0.74001265 -0.04331517 -0.5089645  -0.4555872  -0.12819624\n",
      " -0.6643103  -0.49325725 -0.08618388 -0.66053694 -0.53322494 -0.06418741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.68732524 -0.5488868  -0.06385323  0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0054, -0.0822, -0.0639,  ..., -0.8141, -0.2905, -0.3494],\n",
      "        [ 0.0054, -0.0822, -0.0639,  ..., -0.8141, -0.2905, -0.3494],\n",
      "        [ 0.0054, -0.0822, -0.0639,  ..., -0.8141, -0.2905, -0.3494],\n",
      "        ...,\n",
      "        [ 0.7863, -0.1939,  0.6879,  ...,  0.8519,  0.5072,  0.1610],\n",
      "        [ 0.4787, -0.0755,  0.8172,  ...,  0.4770,  0.1963,  0.6598],\n",
      "        [ 0.4787, -0.0755,  0.8172,  ...,  0.4770,  0.1963,  0.6598]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00536957 -0.08219263 -0.06385716 -0.23318999 -0.25400478 -0.6449901\n",
      " -0.39115775 -0.3814045  -0.39840758 -0.62011623 -0.46674785 -0.35590327\n",
      " -0.82889485 -0.53032005 -0.24276198 -0.5048821  -0.45866334 -0.35213828\n",
      " -0.83162653 -0.5993548  -0.58022696 -0.90415156 -0.6372716  -0.5311308\n",
      " -0.930526   -0.6604192  -0.4160211  -0.5071608  -0.39675328 -0.38425615\n",
      " -0.73128057 -0.5274482  -0.24757537 -0.81484604 -0.58453757 -0.22718945\n",
      " -0.88891065 -0.58246887 -0.16009682 -0.5099298  -0.32981914 -0.46295917\n",
      " -0.669701   -0.474158   -0.09135899 -0.7933053  -0.4886454  -0.06196196\n",
      " -0.89333725 -0.510185   -0.25619268 -0.47805223 -0.23920356 -0.42318493\n",
      " -0.673663   -0.28153428 -0.37442663 -0.7156279  -0.31825522 -0.3328209\n",
      " -0.8141091  -0.29050964 -0.34936288]\n",
      "data: [ 0.00536957 -0.08219263 -0.06385716 -0.23318999 -0.25400478 -0.6449901\n",
      " -0.39115775 -0.3814045  -0.39840758 -0.62011623 -0.46674785 -0.35590327\n",
      " -0.82889485 -0.53032005 -0.242762   -0.5048821  -0.45866334 -0.35213828\n",
      " -0.83162653 -0.5993548  -0.58022696 -0.90415156 -0.6372716  -0.5311308\n",
      " -0.930526   -0.6604192  -0.4160211  -0.5071608  -0.39675328 -0.38425618\n",
      " -0.73128057 -0.5274482  -0.24757537 -0.81484604 -0.58453757 -0.22718945\n",
      " -0.88891065 -0.58246887 -0.16009682 -0.5099298  -0.32981914 -0.46295917\n",
      " -0.669701   -0.474158   -0.09135899 -0.7933053  -0.4886454  -0.06196196\n",
      " -0.89333725 -0.510185   -0.25619268 -0.47805223 -0.23920354 -0.42318493\n",
      " -0.673663   -0.28153428 -0.37442666 -0.7156279  -0.31825522 -0.3328209\n",
      " -0.8141091  -0.29050964 -0.34936288  0.04      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F635F8>\n",
      "tensor([[-0.0535, -0.1993, -0.2012,  ..., -0.1459, -0.3744, -1.1368],\n",
      "        [-0.0535, -0.1993, -0.2012,  ..., -0.1459, -0.3744, -1.1368],\n",
      "        [-0.0535, -0.1993, -0.2012,  ..., -0.1459, -0.3744, -1.1368],\n",
      "        ...,\n",
      "        [ 0.8650, -0.0795,  0.6674,  ...,  0.2480,  0.7313,  0.3526],\n",
      "        [-0.0284,  0.1363,  0.4952,  ..., -0.6182,  0.5730,  0.1319],\n",
      "        [-0.0284,  0.1363,  0.4952,  ..., -0.6182,  0.5730,  0.1319]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.05353475 -0.19928287 -0.20119332 -0.14199124 -0.3569299  -0.5429996\n",
      " -0.40135023 -0.5174073  -1.0198753  -0.5959387  -0.61405146 -1.1613882\n",
      " -0.8454524  -0.6424083  -1.5057788  -0.3830149  -0.7411878  -1.2464119\n",
      " -0.56026745 -0.77358377 -1.3612698  -0.5339621  -0.67326045 -1.3919698\n",
      " -0.467129   -0.7966428  -1.3607199  -0.3227958  -0.6343738  -1.2582479\n",
      " -0.38093042 -0.67999685 -1.1263173  -0.44005927 -0.6776258  -1.1972415\n",
      " -0.24876711 -0.57872605 -1.2824701  -0.2944452  -0.63404    -1.175384\n",
      " -0.3183     -0.50113046 -1.2435364  -0.31275046 -0.5309701  -1.2486812\n",
      " -0.19633017 -0.49477652 -1.2133099  -0.24419732 -0.43290356 -1.1631154\n",
      " -0.35889772 -0.39654082 -1.1867882  -0.25676584 -0.35656098 -1.2790021\n",
      " -0.14585967 -0.3743676  -1.1367517 ]\n",
      "data: [-0.05353475 -0.19928287 -0.20119332 -0.14199124 -0.3569299  -0.5429996\n",
      " -0.4013502  -0.5174073  -1.0198753  -0.5959387  -0.61405146 -1.1613882\n",
      " -0.8454524  -0.6424083  -1.5057788  -0.38301486 -0.7411878  -1.2464119\n",
      " -0.56026745 -0.77358377 -1.3612698  -0.5339621  -0.67326045 -1.3919698\n",
      " -0.467129   -0.7966428  -1.3607199  -0.32279578 -0.6343738  -1.2582479\n",
      " -0.3809304  -0.67999685 -1.1263173  -0.44005927 -0.67762583 -1.1972415\n",
      " -0.24876711 -0.57872605 -1.2824701  -0.2944452  -0.63404    -1.175384\n",
      " -0.3183     -0.50113046 -1.2435364  -0.31275046 -0.5309701  -1.2486812\n",
      " -0.19633016 -0.49477655 -1.2133099  -0.24419732 -0.43290356 -1.1631154\n",
      " -0.35889772 -0.39654082 -1.1867882  -0.25676584 -0.35656098 -1.2790021\n",
      " -0.14585967 -0.3743676  -1.1367517   0.05      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F3C8>\n",
      "tensor([[ 0.0917,  0.0153, -0.0599,  ...,  0.2927, -0.1695, -1.0618],\n",
      "        [ 0.0917,  0.0153, -0.0599,  ...,  0.2927, -0.1695, -1.0618],\n",
      "        [ 0.0917,  0.0153, -0.0599,  ...,  0.2927, -0.1695, -1.0618],\n",
      "        ...,\n",
      "        [ 0.0611,  0.1152,  0.1126,  ..., -0.0164,  0.8036, -0.1487],\n",
      "        [-0.1138,  0.0200,  0.3139,  ..., -1.1259,  0.3159,  0.0561],\n",
      "        [-0.1138,  0.0200,  0.3139,  ..., -1.1259,  0.3159,  0.0561]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.09173343  0.01532535 -0.0599238   0.16701911 -0.09657909 -0.3527511\n",
      "  0.10383905 -0.21498996 -1.1077853  -0.02451687 -0.25434506 -1.4023635\n",
      " -0.15547957 -0.38785854 -1.9217111  -0.09405538 -0.51068735 -1.3314955\n",
      "  0.20052597 -0.4902719  -1.2077187   0.15732478 -0.4342099  -1.2531006\n",
      "  0.17807391 -0.5239706  -1.3732067  -0.03346547 -0.43255714 -1.2534453\n",
      "  0.12301973 -0.49149218 -1.277267    0.14224412 -0.4331607  -1.3742819\n",
      "  0.29160085 -0.49269566 -1.4511986   0.09209777 -0.37371737 -1.0479254\n",
      "  0.01358759 -0.11227933 -1.7209746   0.2225767  -0.28478995 -1.7081686\n",
      "  0.39081478 -0.24736902 -1.2835425  -0.00721951 -0.15411218 -0.9899444\n",
      "  0.1437825  -0.12647267 -1.0363231   0.22471707 -0.15832832 -1.1757449\n",
      "  0.29272407 -0.16953494 -1.0617797 ]\n",
      "data: [ 0.09173343  0.01532535 -0.0599238   0.16701911 -0.0965791  -0.35275114\n",
      "  0.10383905 -0.21498996 -1.1077853  -0.02451687 -0.25434506 -1.4023635\n",
      " -0.15547957 -0.38785854 -1.9217111  -0.09405538 -0.51068735 -1.3314955\n",
      "  0.20052597 -0.49027193 -1.2077187   0.15732478 -0.4342099  -1.2531006\n",
      "  0.17807393 -0.5239706  -1.3732067  -0.03346547 -0.43255714 -1.2534453\n",
      "  0.12301973 -0.49149218 -1.277267    0.14224412 -0.4331607  -1.3742819\n",
      "  0.29160085 -0.49269566 -1.4511986   0.09209777 -0.3737174  -1.0479254\n",
      "  0.01358759 -0.11227933 -1.7209746   0.2225767  -0.28478995 -1.7081686\n",
      "  0.39081478 -0.24736902 -1.2835425  -0.00721951 -0.15411218 -0.9899444\n",
      "  0.1437825  -0.12647267 -1.0363231   0.22471707 -0.15832832 -1.1757449\n",
      "  0.29272407 -0.16953494 -1.0617797   0.06      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[ 0.1359, -0.1062, -0.1538,  ...,  0.1137, -0.2724, -1.2646],\n",
      "        [ 0.1359, -0.1062, -0.1538,  ...,  0.1137, -0.2724, -1.2646],\n",
      "        [ 0.1359, -0.1062, -0.1538,  ...,  0.1137, -0.2724, -1.2646],\n",
      "        ...,\n",
      "        [-0.3498,  0.1110, -0.1918,  ..., -0.6028,  0.6292, -0.5662],\n",
      "        [-0.2108,  0.1635,  0.3892,  ..., -0.2282,  1.0832, -0.0473],\n",
      "        [-0.2108,  0.1635,  0.3892,  ..., -0.2282,  1.0832, -0.0473]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.35869831e-01 -1.06244437e-01 -1.53774783e-01  1.41675428e-01\n",
      " -2.83911526e-01 -6.51843250e-01  3.25495154e-02 -4.60511863e-01\n",
      " -1.37609839e+00 -1.16098359e-01 -5.41682303e-01 -1.65380883e+00\n",
      " -3.21022332e-01 -6.45140529e-01 -2.11458254e+00 -8.43816847e-02\n",
      " -7.08198071e-01 -1.54270983e+00  9.16724056e-02 -7.32801795e-01\n",
      " -1.30051374e+00  6.95873648e-02 -6.68497682e-01 -1.35523367e+00\n",
      "  7.66689777e-02 -7.93353319e-01 -1.45499182e+00 -5.53667545e-02\n",
      " -5.75752139e-01 -1.47876930e+00  1.48130506e-02 -6.35401368e-01\n",
      " -1.41191840e+00 -1.87054276e-04 -6.29691005e-01 -1.50413346e+00\n",
      "  1.69270426e-01 -6.18644118e-01 -1.57522607e+00  3.98443639e-03\n",
      " -5.22925615e-01 -1.30530715e+00 -8.26560855e-02 -2.96566904e-01\n",
      " -1.85021663e+00  4.51654196e-02 -4.32406396e-01 -1.84100246e+00\n",
      "  2.10388020e-01 -4.07018930e-01 -1.40518856e+00 -6.95095658e-02\n",
      " -2.65420556e-01 -1.24102902e+00 -3.51693034e-02 -2.40058273e-01\n",
      " -1.29377079e+00  3.31026167e-02 -2.41124555e-01 -1.41447783e+00\n",
      "  1.13662004e-01 -2.72449553e-01 -1.26461172e+00]\n",
      "data: [ 1.35869831e-01 -1.06244437e-01 -1.53774783e-01  1.41675428e-01\n",
      " -2.83911526e-01 -6.51843250e-01  3.25495154e-02 -4.60511863e-01\n",
      " -1.37609828e+00 -1.16098359e-01 -5.41682303e-01 -1.65380895e+00\n",
      " -3.21022332e-01 -6.45140529e-01 -2.11458254e+00 -8.43816847e-02\n",
      " -7.08198071e-01 -1.54270983e+00  9.16723981e-02 -7.32801795e-01\n",
      " -1.30051374e+00  6.95873648e-02 -6.68497682e-01 -1.35523367e+00\n",
      "  7.66689777e-02 -7.93353319e-01 -1.45499182e+00 -5.53667545e-02\n",
      " -5.75752139e-01 -1.47876918e+00  1.48130516e-02 -6.35401368e-01\n",
      " -1.41191828e+00 -1.87054276e-04 -6.29691005e-01 -1.50413346e+00\n",
      "  1.69270426e-01 -6.18644118e-01 -1.57522619e+00  3.98443639e-03\n",
      " -5.22925615e-01 -1.30530715e+00 -8.26560855e-02 -2.96566904e-01\n",
      " -1.85021663e+00  4.51654196e-02 -4.32406396e-01 -1.84100246e+00\n",
      "  2.10388005e-01 -4.07018930e-01 -1.40518856e+00 -6.95095658e-02\n",
      " -2.65420556e-01 -1.24102902e+00 -3.51693034e-02 -2.40058273e-01\n",
      " -1.29377079e+00  3.31026167e-02 -2.41124555e-01 -1.41447783e+00\n",
      "  1.13662004e-01 -2.72449553e-01 -1.26461172e+00  7.00000003e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[-0.0079, -0.1229, -0.2068,  ...,  0.0915, -0.3226, -1.2368],\n",
      "        [-0.0079, -0.1229, -0.2068,  ...,  0.0915, -0.3226, -1.2368],\n",
      "        [-0.0079, -0.1229, -0.2068,  ...,  0.0915, -0.3226, -1.2368],\n",
      "        ...,\n",
      "        [-0.0894,  0.5043, -0.1213,  ..., -0.6562,  1.0104, -0.4860],\n",
      "        [-0.1347, -0.0074,  0.5935,  ..., -0.1963,  0.7344,  0.2119],\n",
      "        [-0.1347, -0.0074,  0.5935,  ..., -0.1963,  0.7344,  0.2119]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.00787172 -0.12287945 -0.20684683  0.02142398 -0.25611734 -0.56708384\n",
      " -0.06524751 -0.45463142 -1.3477175  -0.21409157 -0.5188125  -1.6547399\n",
      " -0.3807883  -0.65356266 -2.1311405  -0.21504816 -0.7272215  -1.5424409\n",
      "  0.046559   -0.7708417  -1.3485873  -0.01161527 -0.7114999  -1.3889244\n",
      " -0.01236669 -0.8484415  -1.5074546  -0.15065661 -0.62465405 -1.4419165\n",
      " -0.04967893 -0.69614327 -1.4226158  -0.04339428 -0.66958237 -1.5145206\n",
      "  0.08412112 -0.7158992  -1.5636315  -0.03634287 -0.5370381  -1.2573662\n",
      " -0.16187277 -0.30010986 -1.9380856   0.02019068 -0.48500684 -1.9293401\n",
      "  0.18792066 -0.4429815  -1.4102087  -0.15905145 -0.29634994 -1.1896522\n",
      " -0.04202687 -0.27636576 -1.2684026   0.01859549 -0.31398463 -1.3824601\n",
      "  0.09145646 -0.32260823 -1.2368021 ]\n",
      "data: [-0.00787172 -0.12287945 -0.20684683  0.02142398 -0.25611734 -0.56708384\n",
      " -0.06524751 -0.45463142 -1.3477176  -0.21409157 -0.5188125  -1.6547399\n",
      " -0.3807883  -0.6535627  -2.1311405  -0.21504816 -0.72722155 -1.5424409\n",
      "  0.046559   -0.7708418  -1.3485874  -0.01161527 -0.7114999  -1.3889244\n",
      " -0.01236669 -0.8484415  -1.5074546  -0.15065661 -0.62465405 -1.4419165\n",
      " -0.04967893 -0.69614327 -1.4226158  -0.04339428 -0.66958237 -1.5145205\n",
      "  0.08412112 -0.7158992  -1.5636315  -0.03634287 -0.5370381  -1.2573662\n",
      " -0.16187277 -0.30010986 -1.9380857   0.02019068 -0.48500684 -1.92934\n",
      "  0.18792066 -0.44298154 -1.4102087  -0.15905145 -0.29634994 -1.1896522\n",
      " -0.04202687 -0.27636576 -1.2684026   0.01859549 -0.31398463 -1.3824601\n",
      "  0.09145646 -0.32260823 -1.2368021   0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0226, -0.1125, -0.1850,  ...,  0.0516, -0.3130, -1.1640],\n",
      "        [ 0.0226, -0.1125, -0.1850,  ...,  0.0516, -0.3130, -1.1640],\n",
      "        [ 0.0226, -0.1125, -0.1850,  ...,  0.0516, -0.3130, -1.1640],\n",
      "        ...,\n",
      "        [-0.0937,  0.4488, -0.1155,  ..., -0.4218,  1.0075, -0.4983],\n",
      "        [-0.1005, -0.0531,  0.6127,  ..., -0.2236,  0.6814,  0.2399],\n",
      "        [-0.1005, -0.0531,  0.6127,  ..., -0.2236,  0.6814,  0.2399]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02255258 -0.11254258 -0.1849699   0.05702939 -0.20974955 -0.4653347\n",
      " -0.09896144 -0.4471636  -1.337759   -0.25404334 -0.51672614 -1.6211011\n",
      " -0.39872253 -0.5998442  -2.1398456  -0.16267233 -0.7588434  -1.5122609\n",
      " -0.00596832 -0.8319843  -1.3607755  -0.05633812 -0.75348884 -1.4118729\n",
      " -0.06831206 -0.9311716  -1.5380807  -0.12074734 -0.67618096 -1.4099596\n",
      " -0.07285099 -0.7275374  -1.3778372  -0.08603492 -0.69109493 -1.4545615\n",
      "  0.05803034 -0.72476447 -1.4663589  -0.04209451 -0.5613867  -1.2519491\n",
      " -0.20877515 -0.32018206 -2.0433562  -0.01601599 -0.49892896 -2.0743291\n",
      "  0.16218261 -0.45677245 -1.3358064  -0.16501753 -0.33523488 -1.1687033\n",
      " -0.10310996 -0.3018197  -1.2585807  -0.07146977 -0.2976179  -1.371614\n",
      "  0.05156308 -0.31302857 -1.1640077 ]\n",
      "data: [ 0.02255258 -0.11254258 -0.1849699   0.05702939 -0.20974955 -0.4653347\n",
      " -0.09896144 -0.4471636  -1.3377591  -0.25404334 -0.51672614 -1.621101\n",
      " -0.39872253 -0.5998442  -2.1398456  -0.16267233 -0.75884336 -1.5122609\n",
      " -0.00596832 -0.8319843  -1.3607755  -0.05633812 -0.75348884 -1.4118729\n",
      " -0.06831206 -0.9311716  -1.5380807  -0.12074735 -0.67618096 -1.4099596\n",
      " -0.07285099 -0.7275374  -1.3778372  -0.08603492 -0.691095   -1.4545615\n",
      "  0.05803034 -0.72476447 -1.4663589  -0.04209451 -0.5613867  -1.2519491\n",
      " -0.20877513 -0.32018203 -2.0433562  -0.01601599 -0.49892893 -2.0743291\n",
      "  0.16218261 -0.45677245 -1.3358064  -0.16501753 -0.33523488 -1.1687033\n",
      " -0.10310995 -0.3018197  -1.2585807  -0.07146977 -0.2976179  -1.371614\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.05156308 -0.31302857 -1.1640077   0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[-4.3596e-02, -9.6100e-03, -2.0823e-01,  ..., -1.1080e-03,\n",
      "         -1.9590e-01, -1.1827e+00],\n",
      "        [-4.3596e-02, -9.6100e-03, -2.0823e-01,  ..., -1.1080e-03,\n",
      "         -1.9590e-01, -1.1827e+00],\n",
      "        [-4.3596e-02, -9.6100e-03, -2.0823e-01,  ..., -1.1080e-03,\n",
      "         -1.9590e-01, -1.1827e+00],\n",
      "        ...,\n",
      "        [-1.7403e-01,  3.3761e-01,  2.7628e-02,  ..., -7.1690e-01,\n",
      "          9.0714e-01, -3.5551e-01],\n",
      "        [-1.0502e-01, -8.5770e-02,  5.8581e-01,  ..., -2.3389e-01,\n",
      "          6.1376e-01,  2.4209e-01],\n",
      "        [-1.0502e-01, -8.5770e-02,  5.8581e-01,  ..., -2.3389e-01,\n",
      "          6.1376e-01,  2.4209e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-4.35958765e-02 -9.61001031e-03 -2.08228499e-01 -1.84678324e-02\n",
      " -1.18316710e-01 -5.01570821e-01 -1.54137403e-01 -3.43110442e-01\n",
      " -1.34951103e+00 -3.10270190e-01 -4.05578762e-01 -1.64638579e+00\n",
      " -4.71071959e-01 -5.06224275e-01 -2.14916468e+00 -2.48346150e-01\n",
      " -6.44537687e-01 -1.52215135e+00 -5.10937423e-02 -7.02512085e-01\n",
      " -1.34888685e+00 -1.02622345e-01 -6.29989862e-01 -1.39786720e+00\n",
      " -1.01931065e-01 -7.90904343e-01 -1.52802145e+00 -2.00168237e-01\n",
      " -5.51444113e-01 -1.41643953e+00 -1.30987570e-01 -6.05360508e-01\n",
      " -1.39076710e+00 -1.26921132e-01 -5.67717850e-01 -1.47962320e+00\n",
      "  2.49530226e-02 -6.04310036e-01 -1.50471365e+00 -1.06171779e-01\n",
      " -4.40568238e-01 -1.24731553e+00 -2.63961077e-01 -2.00265735e-01\n",
      " -2.01301956e+00 -6.39127567e-02 -3.76940489e-01 -2.03337431e+00\n",
      "  1.27802059e-01 -3.33866179e-01 -1.36073935e+00 -2.33773693e-01\n",
      " -2.06958249e-01 -1.16684830e+00 -1.52021587e-01 -1.77984595e-01\n",
      " -1.25305426e+00 -1.13615528e-01 -1.85085610e-01 -1.36943471e+00\n",
      " -1.10799819e-03 -1.95902720e-01 -1.18271089e+00]\n",
      "data: [-4.35958765e-02 -9.61001031e-03 -2.08228499e-01 -1.84678324e-02\n",
      " -1.18316710e-01 -5.01570821e-01 -1.54137403e-01 -3.43110442e-01\n",
      " -1.34951091e+00 -3.10270190e-01 -4.05578762e-01 -1.64638579e+00\n",
      " -4.71071959e-01 -5.06224275e-01 -2.14916468e+00 -2.48346150e-01\n",
      " -6.44537687e-01 -1.52215135e+00 -5.10937423e-02 -7.02512026e-01\n",
      " -1.34888685e+00 -1.02622345e-01 -6.29989862e-01 -1.39786708e+00\n",
      " -1.01931065e-01 -7.90904284e-01 -1.52802134e+00 -2.00168222e-01\n",
      " -5.51444113e-01 -1.41643953e+00 -1.30987570e-01 -6.05360508e-01\n",
      " -1.39076710e+00 -1.26921132e-01 -5.67717850e-01 -1.47962332e+00\n",
      "  2.49530226e-02 -6.04310036e-01 -1.50471354e+00 -1.06171779e-01\n",
      " -4.40568238e-01 -1.24731553e+00 -2.63961077e-01 -2.00265735e-01\n",
      " -2.01301956e+00 -6.39127567e-02 -3.76940489e-01 -2.03337431e+00\n",
      "  1.27802059e-01 -3.33866209e-01 -1.36073923e+00 -2.33773693e-01\n",
      " -2.06958249e-01 -1.16684830e+00 -1.52021587e-01 -1.77984595e-01\n",
      " -1.25305426e+00 -1.13615535e-01 -1.85085595e-01 -1.36943471e+00\n",
      " -1.10799819e-03 -1.95902735e-01 -1.18271089e+00  1.00000001e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[-0.0070, -0.0874, -0.1938,  ...,  0.0108, -0.2425, -1.3173],\n",
      "        [-0.0070, -0.0874, -0.1938,  ...,  0.0108, -0.2425, -1.3173],\n",
      "        [-0.0070, -0.0874, -0.1938,  ...,  0.0108, -0.2425, -1.3173],\n",
      "        ...,\n",
      "        [-0.2620,  0.3055, -0.1741,  ..., -0.7671,  0.7881, -0.3745],\n",
      "        [-0.1888, -0.1098,  0.5251,  ..., -0.2949,  0.6300,  0.2656],\n",
      "        [-0.1888, -0.1098,  0.5251,  ..., -0.2949,  0.6300,  0.2656]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.00696963 -0.08737057 -0.19375019  0.00709195 -0.2506135  -0.66485584\n",
      " -0.03040767 -0.39346886 -1.3339927  -0.16963077 -0.44285345 -1.6463587\n",
      " -0.35671216 -0.5799684  -2.1007552  -0.23363565 -0.66263914 -1.4981916\n",
      "  0.0516469  -0.6572277  -1.2692542   0.00406143 -0.60600823 -1.3185843\n",
      "  0.0061998  -0.6976032  -1.434126   -0.18771972 -0.54249156 -1.4227059\n",
      " -0.06754182 -0.59783566 -1.4164551  -0.059958   -0.5672052  -1.5277756\n",
      "  0.06783554 -0.5920548  -1.6100948  -0.08009913 -0.4732408  -1.2439307\n",
      " -0.16055462 -0.24573113 -1.7734566  -0.02074604 -0.38614613 -1.7485511\n",
      "  0.12602134 -0.3513686  -1.461939   -0.1848961  -0.22480093 -1.1961427\n",
      " -0.081386   -0.20512111 -1.2741858  -0.02291425 -0.23796956 -1.3983427\n",
      "  0.01081919 -0.24251887 -1.3173429 ]\n",
      "data: [-0.00696963 -0.08737057 -0.19375019  0.00709195 -0.2506135  -0.6648558\n",
      " -0.03040767 -0.39346886 -1.3339927  -0.16963078 -0.44285348 -1.6463588\n",
      " -0.35671216 -0.5799684  -2.1007552  -0.23363565 -0.66263914 -1.4981915\n",
      "  0.0516469  -0.6572277  -1.2692542   0.00406143 -0.60600823 -1.3185843\n",
      "  0.0061998  -0.6976032  -1.434126   -0.18771973 -0.54249156 -1.4227059\n",
      " -0.06754182 -0.59783566 -1.416455   -0.059958   -0.5672052  -1.5277755\n",
      "  0.06783554 -0.5920548  -1.6100948  -0.08009913 -0.47324076 -1.2439307\n",
      " -0.16055462 -0.24573113 -1.7734566  -0.02074604 -0.38614613 -1.7485511\n",
      "  0.12602134 -0.3513686  -1.461939   -0.18489608 -0.22480093 -1.1961427\n",
      " -0.081386   -0.20512111 -1.2741858  -0.02291425 -0.23796958 -1.3983427\n",
      "  0.01081919 -0.24251886 -1.3173429   0.11      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B9B0>\n",
      "tensor([[ 0.0355, -0.1280, -0.2997,  ...,  0.0471, -0.2984, -1.3541],\n",
      "        [ 0.0355, -0.1280, -0.2997,  ...,  0.0471, -0.2984, -1.3541],\n",
      "        [ 0.0355, -0.1280, -0.2997,  ...,  0.0471, -0.2984, -1.3541],\n",
      "        ...,\n",
      "        [-0.1556,  0.4786, -0.0962,  ..., -0.7227,  1.0080, -0.4111],\n",
      "        [-0.1837, -0.0734,  0.6296,  ..., -0.2784,  0.7031,  0.2818],\n",
      "        [-0.1837, -0.0734,  0.6296,  ..., -0.2784,  0.7031,  0.2818]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03553629 -0.12798207 -0.29973698  0.0690534  -0.24822588 -0.68749046\n",
      " -0.04083744 -0.4486824  -1.4863861  -0.18605578 -0.5098818  -1.7808557\n",
      " -0.3307591  -0.60709965 -2.2850354  -0.16305068 -0.73897123 -1.6571026\n",
      "  0.03444091 -0.78111887 -1.4820628  -0.01772787 -0.7145686  -1.5370576\n",
      " -0.03351323 -0.86011255 -1.6621277  -0.12305931 -0.64561296 -1.5645769\n",
      " -0.05452805 -0.6963016  -1.5426424  -0.06989551 -0.661674   -1.6307228\n",
      "  0.05752274 -0.69424677 -1.665375   -0.0396513  -0.5431653  -1.3973076\n",
      " -0.17374739 -0.3067713  -2.0849292  -0.00835445 -0.468658   -2.0993862\n",
      "  0.14713329 -0.43182722 -1.5246935  -0.15072057 -0.31291324 -1.3221514\n",
      " -0.07664376 -0.2799444  -1.4005415  -0.038298   -0.28697947 -1.5171647\n",
      "  0.04707335 -0.2984174  -1.354054  ]\n",
      "data: [ 0.03553629 -0.12798207 -0.29973698  0.0690534  -0.24822588 -0.68749046\n",
      " -0.04083744 -0.4486824  -1.4863861  -0.18605578 -0.5098818  -1.7808557\n",
      " -0.33075914 -0.60709965 -2.2850354  -0.1630507  -0.73897123 -1.6571027\n",
      "  0.03444091 -0.78111887 -1.4820628  -0.01772787 -0.7145686  -1.5370576\n",
      " -0.03351323 -0.86011255 -1.6621277  -0.12305931 -0.64561296 -1.5645769\n",
      " -0.05452805 -0.6963016  -1.5426424  -0.06989551 -0.661674   -1.6307228\n",
      "  0.05752274 -0.69424677 -1.6653751  -0.0396513  -0.5431653  -1.3973076\n",
      " -0.17374739 -0.3067713  -2.0849292  -0.00835445 -0.468658   -2.0993862\n",
      "  0.14713329 -0.4318272  -1.5246935  -0.15072057 -0.31291324 -1.3221515\n",
      " -0.07664376 -0.2799444  -1.4005415  -0.038298   -0.28697947 -1.5171647\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.04707335 -0.2984174  -1.354054    0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0068, -0.0999, -0.2209,  ...,  0.0438, -0.2792, -1.3086],\n",
      "        [ 0.0068, -0.0999, -0.2209,  ...,  0.0438, -0.2792, -1.3086],\n",
      "        [ 0.0068, -0.0999, -0.2209,  ...,  0.0438, -0.2792, -1.3086],\n",
      "        ...,\n",
      "        [-0.1292,  0.4541, -0.1261,  ..., -0.7992,  0.9425, -0.3518],\n",
      "        [-0.1147, -0.0764,  0.5545,  ..., -0.1949,  0.6370,  0.2395],\n",
      "        [-0.1147, -0.0764,  0.5545,  ..., -0.1949,  0.6370,  0.2395]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 6.7523913e-03 -9.9917516e-02 -2.2090057e-01  1.6533252e-02\n",
      " -2.5974375e-01 -6.7238116e-01 -8.3761886e-03 -4.2036653e-01\n",
      " -1.3716141e+00 -1.4739290e-01 -4.7240973e-01 -1.7029958e+00\n",
      " -3.3879280e-01 -6.2199539e-01 -2.1529264e+00 -2.1797161e-01\n",
      " -6.7954290e-01 -1.5606989e+00  8.5031092e-02 -6.8919176e-01\n",
      " -1.3415071e+00  2.0348504e-02 -6.4617580e-01 -1.3878976e+00\n",
      "  2.4328642e-02 -7.5447947e-01 -1.5064493e+00 -1.6082606e-01\n",
      " -5.5656832e-01 -1.4639491e+00 -4.2776622e-02 -6.2389404e-01\n",
      " -1.4540981e+00 -3.9356619e-02 -6.0844010e-01 -1.5691841e+00\n",
      "  6.8140060e-02 -6.4692605e-01 -1.6416354e+00 -4.2457484e-02\n",
      " -4.7828937e-01 -1.2726717e+00 -1.4816137e-01 -2.5960314e-01\n",
      " -1.8671880e+00  4.7177821e-04 -4.2294830e-01 -1.8403853e+00\n",
      "  1.4479373e-01 -3.8859439e-01 -1.4681959e+00 -1.6028881e-01\n",
      " -2.3157097e-01 -1.2157290e+00 -3.7878230e-02 -2.2426839e-01\n",
      " -1.2859385e+00  1.4498323e-02 -2.7348739e-01 -1.4023861e+00\n",
      "  4.3819748e-02 -2.7918223e-01 -1.3085884e+00]\n",
      "data: [ 6.7523913e-03 -9.9917516e-02 -2.2090058e-01  1.6533252e-02\n",
      " -2.5974375e-01 -6.7238116e-01 -8.3761886e-03 -4.2036653e-01\n",
      " -1.3716141e+00 -1.4739290e-01 -4.7240975e-01 -1.7029958e+00\n",
      " -3.3879280e-01 -6.2199539e-01 -2.1529264e+00 -2.1797161e-01\n",
      " -6.7954290e-01 -1.5606989e+00  8.5031092e-02 -6.8919176e-01\n",
      " -1.3415071e+00  2.0348504e-02 -6.4617574e-01 -1.3878976e+00\n",
      "  2.4328642e-02 -7.5447947e-01 -1.5064492e+00 -1.6082606e-01\n",
      " -5.5656832e-01 -1.4639491e+00 -4.2776622e-02 -6.2389404e-01\n",
      " -1.4540981e+00 -3.9356619e-02 -6.0844010e-01 -1.5691841e+00\n",
      "  6.8140060e-02 -6.4692605e-01 -1.6416354e+00 -4.2457484e-02\n",
      " -4.7828937e-01 -1.2726717e+00 -1.4816137e-01 -2.5960314e-01\n",
      " -1.8671880e+00  4.7177821e-04 -4.2294830e-01 -1.8403853e+00\n",
      "  1.4479373e-01 -3.8859439e-01 -1.4681959e+00 -1.6028881e-01\n",
      " -2.3157097e-01 -1.2157290e+00 -3.7878230e-02 -2.2426839e-01\n",
      " -1.2859386e+00  1.4498323e-02 -2.7348739e-01 -1.4023861e+00\n",
      "  4.3819748e-02 -2.7918223e-01 -1.3085884e+00  1.3000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0302, -0.0996, -0.2609,  ...,  0.0471, -0.2845, -1.3139],\n",
      "        [ 0.0302, -0.0996, -0.2609,  ...,  0.0471, -0.2845, -1.3139],\n",
      "        [ 0.0302, -0.0996, -0.2609,  ...,  0.0471, -0.2845, -1.3139],\n",
      "        ...,\n",
      "        [-0.1736,  0.4545, -0.1433,  ..., -0.7048,  0.9541, -0.4342],\n",
      "        [-0.1787, -0.1274,  0.6300,  ..., -0.2482,  0.6452,  0.2875],\n",
      "        [-0.1787, -0.1274,  0.6300,  ..., -0.2482,  0.6452,  0.2875]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03024617 -0.09955872 -0.260929    0.04788064 -0.23676154 -0.67041826\n",
      " -0.05409755 -0.43538737 -1.4394426  -0.19821636 -0.50098044 -1.7306108\n",
      " -0.36133516 -0.60815835 -2.2073689  -0.17247672 -0.7176158  -1.5989696\n",
      "  0.02651912 -0.7599413  -1.4082863  -0.0245892  -0.6922166  -1.4620324\n",
      " -0.03101647 -0.8335766  -1.5785965  -0.13078244 -0.6142311  -1.5125331\n",
      " -0.05933567 -0.6677001  -1.4813384  -0.07299812 -0.6416192  -1.5685248\n",
      "  0.05540183 -0.6629007  -1.6056857  -0.0450493  -0.5223866  -1.3484267\n",
      " -0.16748357 -0.29541856 -1.9988121  -0.01405384 -0.45178717 -2.0034003\n",
      "  0.1414891  -0.41511917 -1.4694709  -0.14970152 -0.28693512 -1.2783239\n",
      " -0.07747975 -0.26206523 -1.3629842  -0.03502887 -0.2720011  -1.4758883\n",
      "  0.04706001 -0.2845312  -1.3138756 ]\n",
      "data: [ 0.03024617 -0.09955872 -0.260929    0.04788064 -0.23676153 -0.67041826\n",
      " -0.05409755 -0.43538737 -1.4394426  -0.19821636 -0.50098044 -1.7306108\n",
      " -0.36133516 -0.60815835 -2.2073689  -0.17247672 -0.71761584 -1.5989696\n",
      "  0.02651912 -0.7599413  -1.4082863  -0.0245892  -0.6922166  -1.4620324\n",
      " -0.03101647 -0.83357656 -1.5785965  -0.13078244 -0.6142311  -1.5125331\n",
      " -0.05933567 -0.6677001  -1.4813384  -0.07299812 -0.6416192  -1.5685248\n",
      "  0.05540183 -0.6629007  -1.6056857  -0.0450493  -0.5223866  -1.3484267\n",
      " -0.16748355 -0.29541856 -1.9988121  -0.01405384 -0.45178717 -2.0034003\n",
      "  0.1414891  -0.41511917 -1.4694709  -0.14970152 -0.28693512 -1.2783239\n",
      " -0.07747975 -0.26206523 -1.3629842  -0.03502887 -0.2720011  -1.4758883\n",
      "  0.04706    -0.2845312  -1.3138756   0.14      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 4.8645e-04, -5.0108e-02, -2.1543e-01,  ...,  3.7795e-02,\n",
      "         -2.3977e-01, -1.2538e+00],\n",
      "        [ 4.8645e-04, -5.0108e-02, -2.1543e-01,  ...,  3.7795e-02,\n",
      "         -2.3977e-01, -1.2538e+00],\n",
      "        [ 4.8645e-04, -5.0108e-02, -2.1543e-01,  ...,  3.7795e-02,\n",
      "         -2.3977e-01, -1.2538e+00],\n",
      "        ...,\n",
      "        [-1.2514e-01,  4.0004e-01, -1.3160e-01,  ..., -7.4129e-01,\n",
      "          8.7767e-01, -3.7360e-01],\n",
      "        [-1.2958e-01, -1.4733e-01,  5.7200e-01,  ..., -2.1980e-01,\n",
      "          5.8036e-01,  2.5997e-01],\n",
      "        [-1.2958e-01, -1.4733e-01,  5.7200e-01,  ..., -2.1980e-01,\n",
      "          5.8036e-01,  2.5997e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 4.8644561e-04 -5.0108440e-02 -2.1543184e-01  1.7577935e-02\n",
      " -1.8541455e-01 -6.0400528e-01 -6.4554833e-02 -3.7163231e-01\n",
      " -1.3487821e+00 -2.0948839e-01 -4.3000656e-01 -1.6549509e+00\n",
      " -3.7971526e-01 -5.4978645e-01 -2.1280169e+00 -2.0545654e-01\n",
      " -6.5753710e-01 -1.5240016e+00  2.2922039e-02 -6.9168460e-01\n",
      " -1.3433502e+00 -3.4103617e-02 -6.3203120e-01 -1.3954158e+00\n",
      " -3.4503385e-02 -7.7059257e-01 -1.5138273e+00 -1.5557145e-01\n",
      " -5.5375886e-01 -1.4328244e+00 -6.9544509e-02 -6.1225116e-01\n",
      " -1.4145491e+00 -7.6821491e-02 -5.8930647e-01 -1.5131977e+00\n",
      "  4.6986327e-02 -6.2152350e-01 -1.5564873e+00 -5.6861408e-02\n",
      " -4.6136281e-01 -1.2603559e+00 -1.7993416e-01 -2.3712230e-01\n",
      " -1.9240563e+00 -1.8695287e-02 -4.0146056e-01 -1.9232612e+00\n",
      "  1.3705601e-01 -3.6756179e-01 -1.4101760e+00 -1.6748907e-01\n",
      " -2.2689967e-01 -1.1967173e+00 -7.7312991e-02 -2.0877717e-01\n",
      " -1.2792344e+00 -3.5361975e-02 -2.2953868e-01 -1.3963954e+00\n",
      "  3.7795357e-02 -2.3976745e-01 -1.2537971e+00]\n",
      "data: [ 4.8644561e-04 -5.0108444e-02 -2.1543184e-01  1.7577935e-02\n",
      " -1.8541454e-01 -6.0400528e-01 -6.4554833e-02 -3.7163231e-01\n",
      " -1.3487821e+00 -2.0948839e-01 -4.3000656e-01 -1.6549509e+00\n",
      " -3.7971526e-01 -5.4978645e-01 -2.1280169e+00 -2.0545654e-01\n",
      " -6.5753710e-01 -1.5240016e+00  2.2922039e-02 -6.9168454e-01\n",
      " -1.3433502e+00 -3.4103617e-02 -6.3203120e-01 -1.3954158e+00\n",
      " -3.4503385e-02 -7.7059257e-01 -1.5138273e+00 -1.5557145e-01\n",
      " -5.5375886e-01 -1.4328244e+00 -6.9544509e-02 -6.1225116e-01\n",
      " -1.4145491e+00 -7.6821491e-02 -5.8930647e-01 -1.5131977e+00\n",
      "  4.6986327e-02 -6.2152350e-01 -1.5564873e+00 -5.6861412e-02\n",
      " -4.6136281e-01 -1.2603559e+00 -1.7993416e-01 -2.3712231e-01\n",
      " -1.9240563e+00 -1.8695287e-02 -4.0146056e-01 -1.9232612e+00\n",
      "  1.3705601e-01 -3.6756179e-01 -1.4101760e+00 -1.6748907e-01\n",
      " -2.2689967e-01 -1.1967173e+00 -7.7312991e-02 -2.0877717e-01\n",
      " -1.2792344e+00 -3.5361975e-02 -2.2953869e-01 -1.3963954e+00\n",
      "  3.7795357e-02 -2.3976746e-01 -1.2537971e+00  1.5000001e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[ 0.0184, -0.0653, -0.2477,  ...,  0.0187, -0.2481, -1.2839],\n",
      "        [ 0.0184, -0.0653, -0.2477,  ...,  0.0187, -0.2481, -1.2839],\n",
      "        [ 0.0184, -0.0653, -0.2477,  ...,  0.0187, -0.2481, -1.2839],\n",
      "        ...,\n",
      "        [-0.3567,  0.1895, -0.3294,  ..., -0.8150,  0.6174, -0.5095],\n",
      "        [-0.1096, -0.0625,  0.6160,  ..., -0.2092,  0.7257,  0.2791],\n",
      "        [-0.1096, -0.0625,  0.6160,  ..., -0.2092,  0.7257,  0.2791]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01843209 -0.06528413 -0.24774861  0.04456883 -0.18800043 -0.6420953\n",
      " -0.07921866 -0.38690367 -1.430797   -0.22431016 -0.45389503 -1.7140808\n",
      " -0.37853083 -0.5421469  -2.2092206  -0.17284799 -0.6858283  -1.5779155\n",
      " -0.01129421 -0.7312734  -1.404813   -0.05870173 -0.6591159  -1.4653542\n",
      " -0.0719429  -0.81212807 -1.5839758  -0.13930422 -0.594504   -1.4942344\n",
      " -0.08307954 -0.64182746 -1.458472   -0.11070729 -0.6123719  -1.5453175\n",
      "  0.02491223 -0.6294817  -1.5724685  -0.07049564 -0.4986866  -1.3339919\n",
      " -0.19716597 -0.26902118 -2.0170817  -0.04418924 -0.41919616 -2.036267\n",
      "  0.11130092 -0.39158812 -1.4381152  -0.16631791 -0.26995495 -1.2614403\n",
      " -0.11539965 -0.24073131 -1.3453703  -0.08008344 -0.23321515 -1.4618456\n",
      "  0.01865184 -0.24814224 -1.2839229 ]\n",
      "data: [ 0.01843209 -0.06528413 -0.2477486   0.04456883 -0.18800043 -0.6420953\n",
      " -0.07921866 -0.38690367 -1.430797   -0.22431014 -0.45389503 -1.7140808\n",
      " -0.37853086 -0.5421469  -2.2092206  -0.17284797 -0.6858283  -1.5779155\n",
      " -0.01129421 -0.7312734  -1.404813   -0.05870173 -0.6591159  -1.4653542\n",
      " -0.0719429  -0.81212807 -1.5839758  -0.13930422 -0.594504   -1.4942344\n",
      " -0.08307954 -0.64182746 -1.458472   -0.11070729 -0.6123719  -1.5453175\n",
      "  0.02491223 -0.6294817  -1.5724685  -0.07049564 -0.4986866  -1.3339919\n",
      " -0.19716597 -0.26902118 -2.0170817  -0.04418924 -0.41919616 -2.036267\n",
      "  0.11130092 -0.39158812 -1.4381152  -0.1663179  -0.26995495 -1.2614403\n",
      " -0.11539964 -0.24073131 -1.3453703  -0.08008344 -0.23321515 -1.4618458\n",
      "  0.01865184 -0.24814224 -1.2839229   0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[ 0.0478, -0.0253, -0.2009,  ...,  0.0602, -0.2211, -1.2351],\n",
      "        [ 0.0478, -0.0253, -0.2009,  ...,  0.0602, -0.2211, -1.2351],\n",
      "        [ 0.0478, -0.0253, -0.2009,  ...,  0.0602, -0.2211, -1.2351],\n",
      "        ...,\n",
      "        [-0.1993,  0.3226, -0.1449,  ..., -0.8661,  0.7651, -0.2890],\n",
      "        [-0.1445, -0.2093,  0.5267,  ..., -0.2057,  0.5423,  0.2315],\n",
      "        [-0.1445, -0.2093,  0.5267,  ..., -0.2057,  0.5423,  0.2315]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04782018 -0.02530163 -0.20091347  0.05977404 -0.15376446 -0.5862697\n",
      " -0.05774323 -0.34204406 -1.3400537  -0.20715603 -0.40738875 -1.6269753\n",
      " -0.37749457 -0.5012665  -2.113665   -0.14535007 -0.6501957  -1.4944426\n",
      "  0.01097627 -0.6931788  -1.3422176  -0.03570136 -0.6178665  -1.4048015\n",
      " -0.0311304  -0.77173865 -1.516326   -0.10782112 -0.555974   -1.4160583\n",
      " -0.04760138 -0.6018474  -1.3819015  -0.07196441 -0.57906854 -1.4768006\n",
      "  0.06897579 -0.58678746 -1.5028849  -0.03597734 -0.46649987 -1.2584687\n",
      " -0.15051126 -0.24382302 -1.9192094  -0.00400864 -0.38808924 -1.935124\n",
      "  0.15662979 -0.36485085 -1.3745879  -0.1266082  -0.23704249 -1.1949296\n",
      " -0.07666016 -0.2155719  -1.2870772  -0.04272515 -0.20697829 -1.4048253\n",
      "  0.06016214 -0.22112723 -1.2350802 ]\n",
      "data: [ 0.04782018 -0.02530163 -0.20091347  0.05977404 -0.15376446 -0.5862697\n",
      " -0.05774323 -0.34204406 -1.3400537  -0.20715603 -0.40738878 -1.6269753\n",
      " -0.37749457 -0.5012665  -2.113665   -0.14535007 -0.6501957  -1.4944426\n",
      "  0.01097627 -0.6931788  -1.3422176  -0.03570136 -0.6178665  -1.4048015\n",
      " -0.0311304  -0.77173865 -1.516326   -0.10782112 -0.555974   -1.4160583\n",
      " -0.04760138 -0.6018474  -1.3819015  -0.07196441 -0.57906854 -1.4768006\n",
      "  0.06897579 -0.58678746 -1.5028849  -0.03597734 -0.46649987 -1.2584687\n",
      " -0.15051126 -0.243823   -1.9192092  -0.00400864 -0.38808927 -1.935124\n",
      "  0.15662979 -0.36485085 -1.3745879  -0.1266082  -0.23704249 -1.1949296\n",
      " -0.07666016 -0.2155719  -1.2870772  -0.04272514 -0.20697828 -1.4048253\n",
      "  0.06016214 -0.22112723 -1.2350802   0.17      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0042, -0.0581, -0.2507,  ...,  0.0211, -0.2413, -1.2931],\n",
      "        [ 0.0042, -0.0581, -0.2507,  ...,  0.0211, -0.2413, -1.2931],\n",
      "        [ 0.0042, -0.0581, -0.2507,  ...,  0.0211, -0.2413, -1.2931],\n",
      "        ...,\n",
      "        [-0.3317,  0.2183, -0.2585,  ..., -0.8399,  0.6356, -0.4250],\n",
      "        [-0.1054, -0.0360,  0.5903,  ..., -0.2158,  0.7660,  0.2491],\n",
      "        [-0.1054, -0.0360,  0.5903,  ..., -0.2158,  0.7660,  0.2491]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00423134 -0.05812118 -0.2506972   0.03009741 -0.19116499 -0.6586092\n",
      " -0.07975296 -0.38024685 -1.433698   -0.22389875 -0.44647092 -1.7204416\n",
      " -0.38237146 -0.546424   -2.2100153  -0.1918841  -0.6677692  -1.5865968\n",
      " -0.00332409 -0.70337087 -1.3935927  -0.05038379 -0.63461816 -1.4517335\n",
      " -0.06136551 -0.77441686 -1.5695398  -0.15528561 -0.5700844  -1.5044148\n",
      " -0.08382281 -0.6213934  -1.4692065  -0.10619463 -0.5924411  -1.5574368\n",
      "  0.02952556 -0.6111701  -1.5941429  -0.07710101 -0.48314157 -1.3364624\n",
      " -0.19119911 -0.25259474 -1.9804833  -0.04231311 -0.4034977  -1.9885031\n",
      "  0.11345193 -0.37552738 -1.4512858  -0.17310433 -0.25020683 -1.26733\n",
      " -0.10898231 -0.22375639 -1.3425548  -0.06624371 -0.22599249 -1.4590724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.02110634 -0.24126323 -1.2931216 ]\n",
      "data: [ 0.00423134 -0.05812118 -0.2506972   0.03009741 -0.19116499 -0.6586092\n",
      " -0.07975296 -0.38024685 -1.4336982  -0.22389875 -0.44647092 -1.7204416\n",
      " -0.38237146 -0.546424   -2.2100153  -0.1918841  -0.6677692  -1.5865968\n",
      " -0.00332409 -0.70337087 -1.3935927  -0.05038379 -0.63461816 -1.4517334\n",
      " -0.06136551 -0.77441686 -1.5695398  -0.15528561 -0.5700844  -1.5044148\n",
      " -0.08382282 -0.6213934  -1.4692063  -0.10619463 -0.5924411  -1.5574368\n",
      "  0.02952556 -0.6111701  -1.5941429  -0.07710101 -0.48314154 -1.3364624\n",
      " -0.19119911 -0.25259474 -1.9804833  -0.04231311 -0.4034977  -1.9885031\n",
      "  0.11345193 -0.37552738 -1.4512858  -0.17310433 -0.25020683 -1.26733\n",
      " -0.1089823  -0.22375639 -1.3425548  -0.06624371 -0.22599249 -1.4590725\n",
      "  0.02110634 -0.24126321 -1.2931217   0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0271, -0.0299, -0.2160,  ...,  0.0482, -0.2249, -1.2547],\n",
      "        [ 0.0271, -0.0299, -0.2160,  ...,  0.0482, -0.2249, -1.2547],\n",
      "        [ 0.0271, -0.0299, -0.2160,  ...,  0.0482, -0.2249, -1.2547],\n",
      "        ...,\n",
      "        [-0.2114,  0.3609, -0.1867,  ..., -0.8864,  0.8454, -0.3769],\n",
      "        [-0.1499, -0.2162,  0.5446,  ..., -0.2265,  0.5471,  0.2329],\n",
      "        [-0.1499, -0.2162,  0.5446,  ..., -0.2265,  0.5471,  0.2329]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0271304  -0.02985448 -0.21601321  0.03896192 -0.16755281 -0.6250242\n",
      " -0.05871571 -0.34468    -1.3554167  -0.20200667 -0.4066332  -1.6462545\n",
      " -0.3737046  -0.51156783 -2.1210146  -0.1707515  -0.64268804 -1.5080384\n",
      "  0.01311819 -0.6728592  -1.3418932  -0.03175873 -0.6042173  -1.4027268\n",
      " -0.02265531 -0.74342823 -1.5144854  -0.13200594 -0.54177594 -1.4308285\n",
      " -0.05721361 -0.589993   -1.4010975  -0.07267264 -0.5679635  -1.4968733\n",
      "  0.06683527 -0.57906187 -1.5363694  -0.05243542 -0.4593514  -1.2669014\n",
      " -0.15615079 -0.23834568 -1.8911617  -0.01126215 -0.3817635  -1.8962033\n",
      "  0.14709793 -0.3567095  -1.3994843  -0.14340691 -0.22749804 -1.2064732\n",
      " -0.08062929 -0.20818387 -1.2902601  -0.03983466 -0.20958063 -1.4086764\n",
      "  0.04818689 -0.22485428 -1.2547059 ]\n",
      "data: [ 0.0271304  -0.02985448 -0.21601321  0.03896192 -0.16755281 -0.6250242\n",
      " -0.05871571 -0.34468    -1.3554168  -0.20200667 -0.4066332  -1.6462545\n",
      " -0.3737046  -0.51156783 -2.1210146  -0.1707515  -0.64268804 -1.5080383\n",
      "  0.01311819 -0.6728592  -1.3418932  -0.03175873 -0.6042173  -1.4027268\n",
      " -0.02265531 -0.7434282  -1.5144854  -0.13200594 -0.54177594 -1.4308285\n",
      " -0.05721361 -0.589993   -1.4010975  -0.07267264 -0.5679635  -1.4968734\n",
      "  0.06683527 -0.57906187 -1.5363694  -0.05243542 -0.4593514  -1.2669014\n",
      " -0.15615079 -0.23834568 -1.8911617  -0.01126215 -0.3817635  -1.8962033\n",
      "  0.14709793 -0.3567095  -1.3994843  -0.14340691 -0.22749804 -1.2064732\n",
      " -0.08062929 -0.20818385 -1.29026    -0.03983466 -0.20958063 -1.4086765\n",
      "  0.04818689 -0.22485428 -1.2547059   0.19      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0109, -0.0703, -0.2373,  ...,  0.0311, -0.2524, -1.2846],\n",
      "        [ 0.0109, -0.0703, -0.2373,  ...,  0.0311, -0.2524, -1.2846],\n",
      "        [ 0.0109, -0.0703, -0.2373,  ...,  0.0311, -0.2524, -1.2846],\n",
      "        ...,\n",
      "        [-0.3168,  0.2486, -0.3202,  ..., -0.8374,  0.7010, -0.4944],\n",
      "        [-0.1190, -0.0605,  0.5916,  ..., -0.2396,  0.7348,  0.2500],\n",
      "        [-0.1190, -0.0605,  0.5916,  ..., -0.2396,  0.7348,  0.2500]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01092957 -0.07032151 -0.23727548  0.03683756 -0.20593509 -0.647477\n",
      " -0.06341421 -0.39057887 -1.411237   -0.20463558 -0.45480317 -1.7002854\n",
      " -0.3645385  -0.5583599  -2.184968   -0.18440579 -0.6765555  -1.5665805\n",
      "  0.01383831 -0.7075123  -1.3752749  -0.0327335  -0.64118445 -1.4324462\n",
      " -0.04085573 -0.77636826 -1.5495753  -0.14729397 -0.57656723 -1.4851258\n",
      " -0.07011183 -0.62796754 -1.4543514  -0.08896822 -0.5991746  -1.5443025\n",
      "  0.04512769 -0.6190338  -1.5862529  -0.06641459 -0.490915   -1.3166685\n",
      " -0.17782722 -0.2617036  -1.9550068  -0.02851855 -0.41207665 -1.9597874\n",
      "  0.12520422 -0.38248855 -1.4427254  -0.16349977 -0.2574923  -1.2497022\n",
      " -0.09466971 -0.23208424 -1.3251498  -0.05046518 -0.23769377 -1.4425025\n",
      "  0.03105255 -0.2524477  -1.2846277 ]\n",
      "data: [ 0.01092957 -0.07032151 -0.23727548  0.03683756 -0.20593509 -0.647477\n",
      " -0.06341421 -0.39057887 -1.411237   -0.20463558 -0.45480317 -1.7002854\n",
      " -0.3645385  -0.5583599  -2.184968   -0.18440579 -0.67655545 -1.5665805\n",
      "  0.01383831 -0.70751226 -1.375275   -0.0327335  -0.64118445 -1.4324462\n",
      " -0.04085573 -0.77636826 -1.5495753  -0.14729397 -0.57656723 -1.4851258\n",
      " -0.07011183 -0.62796754 -1.4543515  -0.08896822 -0.5991746  -1.5443025\n",
      "  0.04512769 -0.6190338  -1.5862529  -0.06641459 -0.490915   -1.3166685\n",
      " -0.17782722 -0.2617036  -1.9550068  -0.02851855 -0.41207665 -1.9597872\n",
      "  0.12520422 -0.38248855 -1.4427254  -0.16349977 -0.2574923  -1.2497022\n",
      " -0.09466971 -0.23208423 -1.3251499  -0.05046518 -0.23769377 -1.4425025\n",
      "  0.03105255 -0.2524477  -1.2846277   0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " [2.918 2.921 2.921 ... 2.929 2.929 2.926]\n",
      " ...\n",
      " [2.822 2.828 2.828 ... 2.816 2.816 2.822]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]\n",
      " [2.815 2.813 2.813 ... 2.806 2.806 2.81 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[ 0.0194, -0.0720, -0.2337,  ...,  0.0562, -0.2593, -1.2789],\n",
      "        [ 0.0194, -0.0720, -0.2337,  ...,  0.0562, -0.2593, -1.2789],\n",
      "        [ 0.0194, -0.0720, -0.2337,  ...,  0.0562, -0.2593, -1.2789],\n",
      "        ...,\n",
      "        [-0.1781,  0.3670, -0.1631,  ..., -0.8324,  0.8558, -0.3732],\n",
      "        [-0.1453, -0.1622,  0.5684,  ..., -0.2452,  0.6064,  0.2299],\n",
      "        [-0.1453, -0.1622,  0.5684,  ..., -0.2452,  0.6064,  0.2299]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.9400094e-02 -7.2020322e-02 -2.3374008e-01  3.8259584e-02\n",
      " -2.1063039e-01 -6.4504743e-01 -4.6066865e-02 -3.9512926e-01\n",
      " -1.3897607e+00 -1.8581533e-01 -4.5635736e-01 -1.6882262e+00\n",
      " -3.5378119e-01 -5.7353854e-01 -2.1556215e+00 -1.8174559e-01\n",
      " -6.7833775e-01 -1.5476358e+00  3.8956739e-02 -7.0971251e-01\n",
      " -1.3621459e+00 -1.2392350e-02 -6.4808172e-01 -1.4153337e+00\n",
      " -1.1506304e-02 -7.8224307e-01 -1.5319512e+00 -1.3610610e-01\n",
      " -5.7397485e-01 -1.4607565e+00 -5.0853997e-02 -6.2957692e-01\n",
      " -1.4377623e+00 -5.8486111e-02 -6.0500568e-01 -1.5317481e+00\n",
      "  7.0441552e-02 -6.3116968e-01 -1.5789609e+00 -4.4475615e-02\n",
      " -4.8775619e-01 -1.2897882e+00 -1.5972152e-01 -2.6089990e-01\n",
      " -1.9399819e+00 -1.7073080e-03 -4.1842425e-01 -1.9385114e+00\n",
      "  1.5386090e-01 -3.8539600e-01 -1.4345291e+00 -1.4926273e-01\n",
      " -2.5162143e-01 -1.2246728e+00 -6.4873450e-02 -2.3100515e-01\n",
      " -1.3080795e+00 -1.7795004e-02 -2.4735586e-01 -1.4246566e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5.6212917e-02 -2.5926670e-01 -1.2789133e+00]\n",
      "data: [-4.55 -0.89 -0.97 -4.5  -0.6  -0.75 -4.39 -0.46 -0.63  0.    0.    0.\n",
      "  0.    0.    0.   -4.32 -0.26 -0.75 -4.26 -0.08 -0.66 -4.28  0.09 -0.31\n",
      "  0.    0.    0.   -4.39 -0.21 -0.85 -4.46  0.01 -0.61 -4.39  0.38 -0.75\n",
      " -3.69  1.21 -4.34 -4.41 -0.17 -0.85 -4.47  0.08 -0.82 -4.43  0.34 -0.75\n",
      "  0.    0.    0.   -4.47 -0.14 -1.04 -4.47  0.12 -1.04 -4.48  0.24 -1.11\n",
      " -4.47  0.27 -0.92  0.  ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0220, -0.0908, -0.3346,  ...,  0.0045, -0.3220, -0.9701],\n",
      "        [ 0.0220, -0.0908, -0.3346,  ...,  0.0045, -0.3220, -0.9701],\n",
      "        [ 0.0220, -0.0908, -0.3346,  ...,  0.0045, -0.3220, -0.9701],\n",
      "        ...,\n",
      "        [ 0.5007, -0.6346,  0.8601,  ..., -0.1661, -0.1773,  0.2200],\n",
      "        [ 0.6914, -0.3548,  0.6271,  ..., -0.7384,  0.1080,  0.5732],\n",
      "        [ 0.6914, -0.3548,  0.6271,  ..., -0.7384,  0.1080,  0.5732]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02199036 -0.09081455 -0.33456331 -0.04520277 -0.1755104  -0.85874\n",
      " -0.0254509  -0.20061806 -1.0783982  -0.02876845 -0.25930756 -1.1347406\n",
      "  0.04960894 -0.2959764  -1.4404416  -0.08455385 -0.36037898 -1.302093\n",
      "  0.14969015 -0.3316145  -0.6497735   0.10930113 -0.37584436 -0.7033729\n",
      "  0.01044254 -0.35425526 -0.8407132  -0.11717848 -0.33149707 -1.3253376\n",
      " -0.07963635 -0.33518624 -1.3508708  -0.09817354 -0.32199588 -1.3378489\n",
      " -0.06597296 -0.39528793 -1.2816143  -0.08662526 -0.28724205 -1.2637856\n",
      "  0.01515214 -0.27275038 -0.81569177 -0.06987444 -0.2603976  -0.8160255\n",
      "  0.02260585 -0.3362012  -1.1950254  -0.09368794 -0.20029667 -1.1249014\n",
      " -0.01890337 -0.23131406 -1.0724332  -0.06914477 -0.25201863 -1.0720263\n",
      "  0.00447268 -0.32199845 -0.9700713 ]\n",
      "init: [ 0.02199036 -0.09081455 -0.33456331 -0.04520277 -0.1755104  -0.85874\n",
      " -0.0254509  -0.20061806 -1.0783982  -0.02876845 -0.25930756 -1.1347406\n",
      "  0.04960894 -0.2959764  -1.4404416  -0.08455385 -0.36037898 -1.302093\n",
      "  0.14969015 -0.3316145  -0.6497735   0.10930113 -0.37584436 -0.7033729\n",
      "  0.01044254 -0.35425526 -0.8407132  -0.11717848 -0.33149707 -1.3253376\n",
      " -0.07963635 -0.33518624 -1.3508708  -0.09817354 -0.32199588 -1.3378489\n",
      " -0.06597296 -0.39528793 -1.2816143  -0.08662526 -0.28724205 -1.2637856\n",
      "  0.01515214 -0.27275038 -0.81569177 -0.06987444 -0.2603976  -0.8160255\n",
      "  0.02260585 -0.3362012  -1.1950254  -0.09368794 -0.20029667 -1.1249014\n",
      " -0.01890337 -0.23131406 -1.0724332  -0.06914477 -0.25201863 -1.0720263\n",
      "  0.00447268 -0.32199845 -0.9700713 ]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [ 0.02199036 -0.09081455 -0.33456334 -0.04520278 -0.1755104  -0.85874003\n",
      " -0.0254509  -0.20061806 -1.0783982  -0.02876845 -0.25930756 -1.1347406\n",
      "  0.04960893 -0.2959764  -1.4404416  -0.08455385 -0.36037898 -1.302093\n",
      "  0.14969015 -0.3316145  -0.6497735   0.10930113 -0.37584436 -0.7033729\n",
      "  0.01044254 -0.35425526 -0.8407132  -0.11717848 -0.33149707 -1.3253376\n",
      " -0.07963635 -0.33518624 -1.3508708  -0.09817353 -0.32199588 -1.337849\n",
      " -0.06597296 -0.39528793 -1.2816144  -0.08662525 -0.28724205 -1.2637856\n",
      "  0.01515214 -0.27275038 -0.81569177 -0.06987444 -0.2603976  -0.8160255\n",
      "  0.02260585 -0.33620116 -1.1950254  -0.09368794 -0.20029667 -1.1249014\n",
      " -0.01890337 -0.23131406 -1.0724332  -0.06914477 -0.25201863 -1.0720263\n",
      "  0.00447268 -0.32199845 -0.9700713   0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.1655, -0.3909, -0.0546,  ...,  0.2329, -0.5696, -1.1221],\n",
      "        [ 0.1655, -0.3909, -0.0546,  ...,  0.2329, -0.5696, -1.1221],\n",
      "        [ 0.1655, -0.3909, -0.0546,  ...,  0.2329, -0.5696, -1.1221],\n",
      "        ...,\n",
      "        [-0.3485,  0.5644, -0.3067,  ..., -0.7226,  1.0750, -0.5113],\n",
      "        [-0.2352,  0.2255,  0.2772,  ..., -0.5796,  0.9724, -0.0576],\n",
      "        [-0.2352,  0.2255,  0.2772,  ..., -0.5796,  0.9724, -0.0576]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.16554908 -0.39093778 -0.05457255  0.20373905 -0.53673935 -0.51803815\n",
      "  0.16979541 -0.6765113  -1.195638    0.04146597 -0.7165237  -1.4917698\n",
      " -0.08505724 -0.85118675 -1.9845113  -0.03542875 -0.9444951  -1.3787639\n",
      "  0.26396167 -0.93072367 -1.1404078   0.20634411 -0.86728895 -1.1895827\n",
      "  0.18390357 -0.95853317 -1.3103607   0.00566503 -0.84393454 -1.3080022\n",
      "  0.13795201 -0.89108944 -1.2976588   0.1308389  -0.84183633 -1.3692127\n",
      "  0.2263776  -0.88922846 -1.422618    0.1353859  -0.76659876 -1.1376306\n",
      "  0.05129506 -0.5234021  -1.6566144   0.19153357 -0.6881021  -1.6265823\n",
      "  0.31332064 -0.63756895 -1.2991002   0.02493522 -0.54548496 -1.0775723\n",
      "  0.15690379 -0.51579154 -1.1236751   0.20206234 -0.5574591  -1.2415605\n",
      "  0.23289546 -0.56963253 -1.122111  ]\n",
      "data: [ 0.16554908 -0.39093778 -0.05457255  0.20373905 -0.53673935 -0.51803815\n",
      "  0.16979542 -0.6765113  -1.195638    0.04146597 -0.71652377 -1.4917697\n",
      " -0.08505724 -0.85118675 -1.9845113  -0.03542875 -0.9444951  -1.3787639\n",
      "  0.26396167 -0.93072367 -1.1404078   0.20634411 -0.86728895 -1.1895827\n",
      "  0.18390357 -0.95853317 -1.3103607   0.00566503 -0.84393454 -1.3080021\n",
      "  0.13795201 -0.8910895  -1.2976588   0.1308389  -0.84183633 -1.3692127\n",
      "  0.2263776  -0.88922846 -1.4226182   0.1353859  -0.76659876 -1.1376306\n",
      "  0.05129506 -0.5234021  -1.6566144   0.19153357 -0.6881021  -1.6265824\n",
      "  0.31332064 -0.63756895 -1.2991002   0.02493522 -0.54548496 -1.0775723\n",
      "  0.15690379 -0.51579154 -1.1236751   0.20206234 -0.5574591  -1.2415605\n",
      "  0.23289546 -0.56963253 -1.122111    0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0219, -0.1229, -0.2315,  ..., -0.0905, -0.3338, -1.2318],\n",
      "        [ 0.0219, -0.1229, -0.2315,  ..., -0.0905, -0.3338, -1.2318],\n",
      "        [ 0.0219, -0.1229, -0.2315,  ..., -0.0905, -0.3338, -1.2318],\n",
      "        ...,\n",
      "        [-0.1422,  0.3841, -0.1149,  ..., -0.1732,  0.9228, -0.6321],\n",
      "        [-0.0456, -0.0484,  0.6727,  ...,  0.2571,  0.6202,  0.2116],\n",
      "        [-0.0456, -0.0484,  0.6727,  ...,  0.2571,  0.6202,  0.2116]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02191715 -0.12289414 -0.23147227 -0.02479503 -0.2497326  -0.6290325\n",
      " -0.15188658 -0.48129642 -1.393787   -0.32166296 -0.5455261  -1.7138278\n",
      " -0.54612225 -0.6394212  -2.1946487  -0.23326987 -0.7498758  -1.5921425\n",
      " -0.15567419 -0.8379618  -1.492523   -0.21943271 -0.7446959  -1.5602562\n",
      " -0.20123428 -0.9634222  -1.6532578  -0.19553381 -0.64496124 -1.480383\n",
      " -0.19732118 -0.70141983 -1.409347   -0.2535178  -0.7282536  -1.5245783\n",
      " -0.13763267 -0.69779146 -1.5130675  -0.1291092  -0.5483985  -1.3420811\n",
      " -0.29478508 -0.3686353  -2.0434217  -0.17549437 -0.5275248  -2.0661297\n",
      " -0.02869616 -0.5076891  -1.3558493  -0.21377027 -0.33715528 -1.2675712\n",
      " -0.20950425 -0.3417694  -1.3443553  -0.2061958  -0.3332626  -1.4417315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.09051645 -0.3338306  -1.2318392 ]\n",
      "data: [ 0.02191715 -0.12289414 -0.23147227 -0.02479503 -0.24973258 -0.6290325\n",
      " -0.15188658 -0.48129642 -1.393787   -0.321663   -0.5455261  -1.7138278\n",
      " -0.54612225 -0.6394212  -2.1946487  -0.23326987 -0.7498758  -1.5921425\n",
      " -0.15567419 -0.8379618  -1.4925228  -0.21943271 -0.7446959  -1.5602562\n",
      " -0.20123428 -0.9634222  -1.6532578  -0.19553381 -0.64496124 -1.480383\n",
      " -0.19732116 -0.70141983 -1.409347   -0.2535178  -0.7282536  -1.5245785\n",
      " -0.13763267 -0.69779146 -1.5130675  -0.1291092  -0.5483985  -1.342081\n",
      " -0.29478508 -0.3686353  -2.0434217  -0.17549437 -0.5275248  -2.0661297\n",
      " -0.02869616 -0.5076891  -1.3558493  -0.21377027 -0.33715525 -1.2675712\n",
      " -0.20950425 -0.3417694  -1.3443553  -0.20619579 -0.3332626  -1.4417315\n",
      " -0.09051646 -0.3338306  -1.2318392   0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0163,  0.0386, -0.1791,  ...,  0.0582, -0.1614, -1.1970],\n",
      "        [ 0.0163,  0.0386, -0.1791,  ...,  0.0582, -0.1614, -1.1970],\n",
      "        [ 0.0163,  0.0386, -0.1791,  ...,  0.0582, -0.1614, -1.1970],\n",
      "        ...,\n",
      "        [-0.1948,  0.3208, -0.1225,  ..., -0.9434,  0.9108, -0.4402],\n",
      "        [-0.1840, -0.3086,  0.5117,  ..., -0.2917,  0.3182,  0.2752],\n",
      "        [-0.1840, -0.3086,  0.5117,  ..., -0.2917,  0.3182,  0.2752]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01631811  0.03856105 -0.1791219   0.01897672 -0.10233913 -0.57689005\n",
      " -0.05368835 -0.27015865 -1.3193942  -0.19214913 -0.3257495  -1.6274816\n",
      " -0.38866287 -0.44627973 -2.0773702  -0.18899295 -0.5617919  -1.4836707\n",
      "  0.04435348 -0.57875896 -1.3028227   0.00346569 -0.5220822  -1.3550055\n",
      "  0.04239161 -0.6514257  -1.4730448  -0.14515376 -0.44644085 -1.393377\n",
      " -0.04115902 -0.5044582  -1.361355   -0.03035748 -0.48912713 -1.4710515\n",
      "  0.1323196  -0.5128325  -1.5338831  -0.05242072 -0.37364182 -1.2103436\n",
      " -0.16542915 -0.15091854 -1.8818793   0.00729492 -0.3071238  -1.8762873\n",
      "  0.19644144 -0.28320608 -1.3604387  -0.16198722 -0.12705076 -1.1393656\n",
      " -0.07292304 -0.11856222 -1.2130213  -0.02124269 -0.13972946 -1.3360771\n",
      "  0.0582453  -0.16144292 -1.1969686 ]\n",
      "data: [ 0.01631811  0.03856105 -0.1791219   0.01897672 -0.10233913 -0.57689005\n",
      " -0.05368834 -0.27015865 -1.3193942  -0.19214912 -0.3257495  -1.6274816\n",
      " -0.38866287 -0.4462797  -2.0773702  -0.18899293 -0.5617919  -1.4836707\n",
      "  0.04435347 -0.57875896 -1.3028227   0.00346569 -0.5220822  -1.3550055\n",
      "  0.04239161 -0.6514257  -1.4730448  -0.14515376 -0.44644085 -1.393377\n",
      " -0.04115902 -0.5044582  -1.361355   -0.03035748 -0.48912713 -1.4710515\n",
      "  0.1323196  -0.5128325  -1.5338831  -0.05242072 -0.37364182 -1.2103436\n",
      " -0.16542916 -0.15091854 -1.8818793   0.00729492 -0.3071238  -1.8762873\n",
      "  0.19644144 -0.28320608 -1.3604387  -0.16198722 -0.12705076 -1.1393656\n",
      " -0.07292304 -0.11856222 -1.2130213  -0.02124269 -0.13972946 -1.3360771\n",
      "  0.0582453  -0.16144294 -1.1969686   0.04      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0842, -0.1132, -0.1821,  ...,  0.1043, -0.2817, -1.2916],\n",
      "        [ 0.0842, -0.1132, -0.1821,  ...,  0.1043, -0.2817, -1.2916],\n",
      "        [ 0.0842, -0.1132, -0.1821,  ...,  0.1043, -0.2817, -1.2916],\n",
      "        ...,\n",
      "        [-0.2697,  0.3167, -0.2996,  ..., -0.7921,  0.7906, -0.4351],\n",
      "        [-0.2408, -0.0702,  0.4581,  ..., -0.3162,  0.6979,  0.1753],\n",
      "        [-0.2408, -0.0702,  0.4581,  ..., -0.3162,  0.6979,  0.1753]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.08423954 -0.11321427 -0.18212235  0.09338029 -0.28868562 -0.6698061\n",
      "  0.05036802 -0.44518298 -1.3497313  -0.08199449 -0.4996456  -1.6450777\n",
      " -0.26391706 -0.64084446 -2.0851347  -0.14147446 -0.6950208  -1.5004414\n",
      "  0.13019133 -0.69691694 -1.2621738   0.08072944 -0.64032304 -1.3083955\n",
      "  0.08289457 -0.731285   -1.4146082  -0.09693733 -0.56857765 -1.4307535\n",
      "  0.01542749 -0.62342155 -1.4093046   0.01813672 -0.5978749  -1.4999937\n",
      "  0.13170402 -0.614686   -1.5735422   0.0103342  -0.5055688  -1.2611979\n",
      " -0.07132319 -0.28136927 -1.776467    0.05987523 -0.42542532 -1.744472\n",
      "  0.19166458 -0.38164458 -1.4368567  -0.08750518 -0.2601276  -1.2112904\n",
      "  0.01223105 -0.24230874 -1.2853334   0.07307914 -0.2751843  -1.3999467\n",
      "  0.10433841 -0.28173077 -1.2916354 ]\n",
      "data: [ 0.08423954 -0.11321428 -0.18212235  0.09338029 -0.28868562 -0.6698061\n",
      "  0.05036802 -0.44518298 -1.3497313  -0.08199449 -0.4996456  -1.6450777\n",
      " -0.26391706 -0.6408445  -2.0851347  -0.14147446 -0.69502085 -1.5004414\n",
      "  0.13019133 -0.69691694 -1.2621738   0.08072944 -0.64032304 -1.3083955\n",
      "  0.08289457 -0.7312849  -1.4146084  -0.09693733 -0.56857765 -1.4307535\n",
      "  0.01542749 -0.62342155 -1.4093046   0.01813672 -0.5978749  -1.4999938\n",
      "  0.13170402 -0.614686   -1.5735421   0.0103342  -0.5055688  -1.2611979\n",
      " -0.07132319 -0.28136927 -1.776467    0.05987523 -0.42542535 -1.744472\n",
      "  0.19166458 -0.3816446  -1.4368567  -0.08750518 -0.2601276  -1.2112904\n",
      "  0.01223105 -0.24230874 -1.2853334   0.07307914 -0.2751843  -1.3999467\n",
      "  0.10433841 -0.28173077 -1.2916354   0.05      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[-0.0029, -0.1163, -0.2142,  ...,  0.0664, -0.3139, -1.2409],\n",
      "        [-0.0029, -0.1163, -0.2142,  ...,  0.0664, -0.3139, -1.2409],\n",
      "        [-0.0029, -0.1163, -0.2142,  ...,  0.0664, -0.3139, -1.2409],\n",
      "        ...,\n",
      "        [-0.0718,  0.5416, -0.1183,  ..., -0.5777,  1.0507, -0.5030],\n",
      "        [-0.1741, -0.0441,  0.5970,  ..., -0.2567,  0.7276,  0.1669],\n",
      "        [-0.1741, -0.0441,  0.5970,  ..., -0.2567,  0.7276,  0.1669]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.00291843 -0.11630192 -0.21416827  0.02407498 -0.2385868  -0.5827342\n",
      " -0.08726687 -0.4488351  -1.3797779  -0.23743027 -0.5140929  -1.6759217\n",
      " -0.39409888 -0.62819487 -2.1608076  -0.20568354 -0.7293769  -1.5635468\n",
      "  0.00977173 -0.7850406  -1.386716   -0.04339632 -0.7159495  -1.4323773\n",
      " -0.04734256 -0.8694303  -1.5506649  -0.14958675 -0.6338898  -1.4643106\n",
      " -0.07252287 -0.6981927  -1.4364262  -0.07530246 -0.6720504  -1.5200642\n",
      "  0.05692723 -0.7099197  -1.5547462  -0.05050012 -0.53995407 -1.2915562\n",
      " -0.18491976 -0.30330446 -1.9850243  -0.00751837 -0.4841276  -1.989633\n",
      "  0.16119428 -0.4424712  -1.4115412  -0.16800703 -0.30567783 -1.2155967\n",
      " -0.07576975 -0.27907807 -1.2987052  -0.02389432 -0.30169943 -1.4105985\n",
      "  0.06639389 -0.3139118  -1.24092   ]\n",
      "data: [-0.00291843 -0.11630192 -0.21416827  0.02407498 -0.23858681 -0.5827342\n",
      " -0.08726688 -0.4488351  -1.3797778  -0.23743027 -0.5140929  -1.6759217\n",
      " -0.39409888 -0.62819487 -2.1608076  -0.20568353 -0.7293769  -1.5635468\n",
      "  0.00977173 -0.7850406  -1.386716   -0.04339632 -0.7159495  -1.4323773\n",
      " -0.04734256 -0.8694303  -1.550665   -0.14958675 -0.6338898  -1.4643106\n",
      " -0.07252287 -0.6981928  -1.436426   -0.07530246 -0.6720504  -1.5200642\n",
      "  0.05692723 -0.7099197  -1.5547462  -0.05050012 -0.53995407 -1.2915562\n",
      " -0.18491976 -0.30330446 -1.9850242  -0.00751837 -0.4841276  -1.9896331\n",
      "  0.16119428 -0.4424712  -1.4115413  -0.16800703 -0.30567783 -1.2155967\n",
      " -0.07576975 -0.27907807 -1.2987053  -0.02389432 -0.30169943 -1.4105984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.06639389 -0.3139118  -1.24092     0.06      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0327, -0.1023, -0.1849,  ...,  0.0625, -0.3005, -1.1631],\n",
      "        [ 0.0327, -0.1023, -0.1849,  ...,  0.0625, -0.3005, -1.1631],\n",
      "        [ 0.0327, -0.1023, -0.1849,  ...,  0.0625, -0.3005, -1.1631],\n",
      "        ...,\n",
      "        [-0.1226,  0.4297, -0.0813,  ..., -0.6724,  0.9887, -0.4284],\n",
      "        [-0.0836, -0.0715,  0.6142,  ..., -0.1956,  0.6667,  0.2418],\n",
      "        [-0.0836, -0.0715,  0.6142,  ..., -0.1956,  0.6667,  0.2418]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03270439 -0.10226878 -0.18487999  0.06471089 -0.19845061 -0.4631045\n",
      " -0.09354717 -0.4283826  -1.3248663  -0.25012535 -0.4952926  -1.6089139\n",
      " -0.3984542  -0.5749084  -2.130037   -0.15248112 -0.74666226 -1.500169\n",
      " -0.00611103 -0.8158829  -1.3590539  -0.05396762 -0.7354065  -1.4146173\n",
      " -0.05870995 -0.9135417  -1.540359   -0.11216001 -0.6665801  -1.4014158\n",
      " -0.06423239 -0.71433365 -1.368882   -0.0779424  -0.6782484  -1.4521716\n",
      "  0.07307944 -0.7056838  -1.4604726  -0.03726863 -0.55207586 -1.2436335\n",
      " -0.19570453 -0.31600085 -2.0249152  -0.00544894 -0.48649004 -2.0595968\n",
      "  0.17832933 -0.44910875 -1.3315003  -0.15361959 -0.3291821  -1.1638145\n",
      " -0.09801795 -0.2975806  -1.2555149  -0.06862557 -0.28695387 -1.3717549\n",
      "  0.06246717 -0.30049455 -1.1630597 ]\n",
      "data: [ 0.03270439 -0.10226879 -0.18487999  0.06471089 -0.19845061 -0.4631045\n",
      " -0.09354717 -0.4283826  -1.3248663  -0.25012535 -0.49529257 -1.6089139\n",
      " -0.39845422 -0.5749084  -2.130037   -0.15248112 -0.7466623  -1.500169\n",
      " -0.00611103 -0.8158829  -1.3590539  -0.05396762 -0.7354065  -1.4146173\n",
      " -0.05870995 -0.9135416  -1.540359   -0.11216001 -0.66658    -1.4014158\n",
      " -0.06423239 -0.71433365 -1.368882   -0.0779424  -0.67824847 -1.4521717\n",
      "  0.07307944 -0.7056838  -1.4604726  -0.03726863 -0.55207586 -1.2436335\n",
      " -0.19570453 -0.31600085 -2.0249152  -0.00544894 -0.48649007 -2.0595968\n",
      "  0.17832933 -0.44910872 -1.3315003  -0.15361959 -0.3291821  -1.1638145\n",
      " -0.09801795 -0.2975806  -1.2555149  -0.06862557 -0.28695387 -1.3717549\n",
      "  0.06246717 -0.30049455 -1.1630597   0.07      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EC24748>\n",
      "tensor([[-0.0448, -0.0110, -0.2234,  ...,  0.0034, -0.1972, -1.1954],\n",
      "        [-0.0448, -0.0110, -0.2234,  ...,  0.0034, -0.1972, -1.1954],\n",
      "        [-0.0448, -0.0110, -0.2234,  ...,  0.0034, -0.1972, -1.1954],\n",
      "        ...,\n",
      "        [-0.1458,  0.3304,  0.0472,  ..., -0.7240,  0.8867, -0.3374],\n",
      "        [-0.0967, -0.0694,  0.5696,  ..., -0.2252,  0.6537,  0.1917],\n",
      "        [-0.0967, -0.0694,  0.5696,  ..., -0.2252,  0.6537,  0.1917]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.04480878 -0.01104876 -0.22340403 -0.0187601  -0.11873542 -0.5205159\n",
      " -0.15346032 -0.3403821  -1.3622991  -0.3099299  -0.40221107 -1.6633357\n",
      " -0.47220975 -0.5036416  -2.1654983  -0.24773537 -0.64368653 -1.5328379\n",
      " -0.05131288 -0.6997236  -1.3614167  -0.10438935 -0.6274407  -1.4135804\n",
      " -0.10625124 -0.7916666  -1.5450027  -0.1986472  -0.5520941  -1.426503\n",
      " -0.13005078 -0.60608184 -1.4030249  -0.1299909  -0.5699136  -1.4951311\n",
      "  0.02138378 -0.60658944 -1.5201379  -0.10473578 -0.44102493 -1.2543563\n",
      " -0.26256537 -0.20038685 -2.0318615  -0.06276997 -0.37764505 -2.0530908\n",
      "  0.12799697 -0.33725205 -1.3720376  -0.22954084 -0.20903009 -1.1751013\n",
      " -0.14865328 -0.18037356 -1.2628438  -0.11068977 -0.18625626 -1.3816078\n",
      "  0.00341862 -0.19723423 -1.1953719 ]\n",
      "data: [-0.04480878 -0.01104876 -0.22340402 -0.0187601  -0.11873542 -0.5205159\n",
      " -0.15346032 -0.34038207 -1.3622991  -0.3099299  -0.40221107 -1.6633357\n",
      " -0.47220975 -0.5036416  -2.1654983  -0.24773537 -0.64368653 -1.5328379\n",
      " -0.05131288 -0.6997236  -1.3614166  -0.10438935 -0.6274407  -1.4135804\n",
      " -0.10625124 -0.7916666  -1.5450027  -0.1986472  -0.5520941  -1.426503\n",
      " -0.13005078 -0.60608184 -1.4030249  -0.1299909  -0.5699136  -1.495131\n",
      "  0.02138378 -0.60658944 -1.5201379  -0.10473578 -0.44102493 -1.2543563\n",
      " -0.26256537 -0.20038685 -2.0318615  -0.06276997 -0.37764505 -2.0530908\n",
      "  0.12799697 -0.33725205 -1.3720376  -0.22954084 -0.20903009 -1.1751013\n",
      " -0.14865328 -0.18037358 -1.2628438  -0.11068977 -0.18625626 -1.3816078\n",
      "  0.00341862 -0.19723423 -1.1953719   0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0173, -0.0816, -0.1829,  ...,  0.0198, -0.2399, -1.3042],\n",
      "        [ 0.0173, -0.0816, -0.1829,  ...,  0.0198, -0.2399, -1.3042],\n",
      "        [ 0.0173, -0.0816, -0.1829,  ...,  0.0198, -0.2399, -1.3042],\n",
      "        ...,\n",
      "        [-0.2784,  0.3093, -0.1953,  ..., -0.7953,  0.7900, -0.3823],\n",
      "        [-0.2082, -0.1065,  0.4955,  ..., -0.2939,  0.6297,  0.2422],\n",
      "        [-0.2082, -0.1065,  0.4955,  ..., -0.2939,  0.6297,  0.2422]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01725983 -0.08156444 -0.18292859  0.02991903 -0.24283814 -0.6531254\n",
      " -0.01734281 -0.39042327 -1.3330467  -0.15601231 -0.4427774  -1.6392368\n",
      " -0.34192303 -0.5715377  -2.0964293  -0.20605138 -0.6629031  -1.4907438\n",
      "  0.05801407 -0.6620659  -1.2696735   0.01306441 -0.6086117  -1.3206226\n",
      "  0.01483597 -0.7047671  -1.4342462  -0.16469714 -0.54443985 -1.4170023\n",
      " -0.05387006 -0.59765476 -1.4050884  -0.05173731 -0.56797326 -1.5138148\n",
      "  0.0781462  -0.58731747 -1.5919601  -0.06577431 -0.47478226 -1.2432972\n",
      " -0.1480183  -0.25008318 -1.7758837  -0.01234561 -0.38596576 -1.7559205\n",
      "  0.13290766 -0.3532251  -1.4465424  -0.16631341 -0.22788543 -1.193559\n",
      " -0.07493733 -0.20793596 -1.2715492  -0.01945058 -0.23362228 -1.3942488\n",
      "  0.01981949 -0.23986188 -1.3041724 ]\n",
      "data: [ 0.01725983 -0.08156445 -0.1829286   0.02991903 -0.24283813 -0.6531254\n",
      " -0.01734281 -0.39042327 -1.3330467  -0.15601231 -0.4427774  -1.6392368\n",
      " -0.34192303 -0.5715377  -2.0964293  -0.2060514  -0.6629031  -1.4907438\n",
      "  0.05801407 -0.66206586 -1.2696735   0.01306441 -0.6086117  -1.3206226\n",
      "  0.01483597 -0.70476705 -1.4342462  -0.16469713 -0.54443985 -1.4170022\n",
      " -0.05387006 -0.59765476 -1.4050885  -0.05173731 -0.56797326 -1.5138148\n",
      "  0.0781462  -0.58731747 -1.5919602  -0.06577431 -0.47478226 -1.2432972\n",
      " -0.1480183  -0.25008318 -1.7758837  -0.01234561 -0.38596576 -1.7559205\n",
      "  0.13290766 -0.3532251  -1.4465424  -0.1663134  -0.22788543 -1.193559\n",
      " -0.07493733 -0.20793596 -1.2715492  -0.01945058 -0.23362228 -1.3942488\n",
      "  0.01981949 -0.23986188 -1.3041724   0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0403, -0.1335, -0.2991,  ...,  0.0554, -0.3039, -1.3564],\n",
      "        [ 0.0403, -0.1335, -0.2991,  ...,  0.0554, -0.3039, -1.3564],\n",
      "        [ 0.0403, -0.1335, -0.2991,  ...,  0.0554, -0.3039, -1.3564],\n",
      "        ...,\n",
      "        [-0.1460,  0.4791, -0.0613,  ..., -0.7185,  1.0029, -0.3774],\n",
      "        [-0.1868, -0.0588,  0.6240,  ..., -0.2752,  0.7215,  0.2674],\n",
      "        [-0.1868, -0.0588,  0.6240,  ..., -0.2752,  0.7215,  0.2674]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 4.0258739e-02 -1.3351771e-01 -2.9912826e-01  7.3353916e-02\n",
      " -2.5735313e-01 -6.9190836e-01 -3.2836691e-02 -4.5715883e-01\n",
      " -1.4886727e+00 -1.7849307e-01 -5.1883680e-01 -1.7851187e+00\n",
      " -3.2577294e-01 -6.2014908e-01 -2.2866912e+00 -1.6059592e-01\n",
      " -7.4292690e-01 -1.6609011e+00  4.6405077e-02 -7.8370011e-01\n",
      " -1.4747941e+00 -6.5532178e-03 -7.1866673e-01 -1.5287950e+00\n",
      " -2.3997068e-02 -8.6123413e-01 -1.6542677e+00 -1.1929992e-01\n",
      " -6.4723331e-01 -1.5678122e+00 -4.6955355e-02 -7.0016551e-01\n",
      " -1.5454028e+00 -6.1222069e-02 -6.6604966e-01 -1.6341504e+00\n",
      "  6.5375492e-02 -6.9964558e-01 -1.6711448e+00 -3.2728724e-02\n",
      " -5.4617977e-01 -1.3980420e+00 -1.6516109e-01 -3.1021672e-01\n",
      " -2.0781217e+00 -4.8464537e-04 -4.7331178e-01 -2.0893204e+00\n",
      "  1.5508988e-01 -4.3593425e-01 -1.5275421e+00 -1.4474019e-01\n",
      " -3.1425506e-01 -1.3235058e+00 -6.6750333e-02 -2.8230768e-01\n",
      " -1.4001201e+00 -2.6405737e-02 -2.9284561e-01 -1.5164815e+00\n",
      "  5.5395938e-02 -3.0394661e-01 -1.3563614e+00]\n",
      "data: [ 4.0258743e-02 -1.3351771e-01 -2.9912826e-01  7.3353916e-02\n",
      " -2.5735313e-01 -6.9190836e-01 -3.2836691e-02 -4.5715886e-01\n",
      " -1.4886727e+00 -1.7849307e-01 -5.1883680e-01 -1.7851187e+00\n",
      " -3.2577294e-01 -6.2014908e-01 -2.2866912e+00 -1.6059594e-01\n",
      " -7.4292684e-01 -1.6609011e+00  4.6405077e-02 -7.8370011e-01\n",
      " -1.4747941e+00 -6.5532178e-03 -7.1866679e-01 -1.5287950e+00\n",
      " -2.3997068e-02 -8.6123413e-01 -1.6542678e+00 -1.1929992e-01\n",
      " -6.4723325e-01 -1.5678122e+00 -4.6955358e-02 -7.0016551e-01\n",
      " -1.5454029e+00 -6.1222065e-02 -6.6604966e-01 -1.6341504e+00\n",
      "  6.5375492e-02 -6.9964564e-01 -1.6711448e+00 -3.2728724e-02\n",
      " -5.4617977e-01 -1.3980420e+00 -1.6516109e-01 -3.1021672e-01\n",
      " -2.0781217e+00 -4.8464537e-04 -4.7331178e-01 -2.0893204e+00\n",
      "  1.5508988e-01 -4.3593425e-01 -1.5275421e+00 -1.4474019e-01\n",
      " -3.1425506e-01 -1.3235058e+00 -6.6750333e-02 -2.8230768e-01\n",
      " -1.4001201e+00 -2.6405737e-02 -2.9284561e-01 -1.5164815e+00\n",
      "  5.5395938e-02 -3.0394661e-01 -1.3563614e+00  1.0000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 4.0795e-04, -1.0770e-01, -2.3664e-01,  ...,  4.1650e-02,\n",
      "         -2.8744e-01, -1.3250e+00],\n",
      "        [ 4.0795e-04, -1.0770e-01, -2.3664e-01,  ...,  4.1650e-02,\n",
      "         -2.8744e-01, -1.3250e+00],\n",
      "        [ 4.0795e-04, -1.0770e-01, -2.3664e-01,  ...,  4.1650e-02,\n",
      "         -2.8744e-01, -1.3250e+00],\n",
      "        ...,\n",
      "        [-8.1961e-02,  4.9663e-01, -1.2052e-01,  ..., -6.8266e-01,\n",
      "          9.9086e-01, -3.6720e-01],\n",
      "        [-1.0273e-01, -6.2403e-02,  5.7032e-01,  ..., -1.8762e-01,\n",
      "          6.4312e-01,  2.6675e-01],\n",
      "        [-1.0273e-01, -6.2403e-02,  5.7032e-01,  ..., -1.8762e-01,\n",
      "          6.4312e-01,  2.6675e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 4.0794630e-04 -1.0769808e-01 -2.3664057e-01  1.1947263e-02\n",
      " -2.6935616e-01 -6.8729854e-01 -8.5789487e-03 -4.3031859e-01\n",
      " -1.3855879e+00 -1.4752012e-01 -4.8174649e-01 -1.7193925e+00\n",
      " -3.3966374e-01 -6.3568771e-01 -2.1675100e+00 -2.2636150e-01\n",
      " -6.8502283e-01 -1.5796461e+00  8.6510316e-02 -6.9416213e-01\n",
      " -1.3548119e+00  2.0095050e-02 -6.5286708e-01 -1.3996308e+00\n",
      "  2.2565261e-02 -7.5940824e-01 -1.5182354e+00 -1.6712470e-01\n",
      " -5.6035292e-01 -1.4813819e+00 -4.6355963e-02 -6.2994850e-01\n",
      " -1.4729428e+00 -4.1117579e-02 -6.1546564e-01 -1.5877647e+00\n",
      "  6.2762782e-02 -6.5632963e-01 -1.6623046e+00 -4.4987313e-02\n",
      " -4.8257273e-01 -1.2874775e+00 -1.5203804e-01 -2.6363966e-01\n",
      " -1.8820119e+00 -1.9683614e-03 -4.3078297e-01 -1.8519609e+00\n",
      "  1.4025299e-01 -3.9392295e-01 -1.4860997e+00 -1.6496639e-01\n",
      " -2.3550084e-01 -1.2317607e+00 -3.7658647e-02 -2.2874792e-01\n",
      " -1.3002152e+00  1.6583443e-02 -2.8231150e-01 -1.4163234e+00\n",
      "  4.1650318e-02 -2.8744489e-01 -1.3249702e+00]\n",
      "data: [ 4.07946296e-04 -1.07698075e-01 -2.36640573e-01  1.19472630e-02\n",
      " -2.69356161e-01 -6.87298536e-01 -8.57894868e-03 -4.30318594e-01\n",
      " -1.38558793e+00 -1.47520125e-01 -4.81746495e-01 -1.71939254e+00\n",
      " -3.39663744e-01 -6.35687709e-01 -2.16751003e+00 -2.26361498e-01\n",
      " -6.85022831e-01 -1.57964611e+00  8.65103155e-02 -6.94162130e-01\n",
      " -1.35481191e+00  2.00950503e-02 -6.52867079e-01 -1.39963078e+00\n",
      "  2.25652605e-02 -7.59408236e-01 -1.51823545e+00 -1.67124704e-01\n",
      " -5.60352921e-01 -1.48138189e+00 -4.63559628e-02 -6.29948497e-01\n",
      " -1.47294283e+00 -4.11175787e-02 -6.15465641e-01 -1.58776474e+00\n",
      "  6.27627820e-02 -6.56329632e-01 -1.66230464e+00 -4.49873097e-02\n",
      " -4.82572734e-01 -1.28747737e+00 -1.52038038e-01 -2.63639659e-01\n",
      " -1.88201189e+00 -1.96836144e-03 -4.30782974e-01 -1.85196090e+00\n",
      "  1.40252993e-01 -3.93922955e-01 -1.48609972e+00 -1.64966390e-01\n",
      " -2.35500857e-01 -1.23176074e+00 -3.76586467e-02 -2.28747919e-01\n",
      " -1.30021524e+00  1.65834427e-02 -2.82311499e-01 -1.41632342e+00\n",
      "  4.16503176e-02 -2.87444890e-01 -1.32497025e+00  1.09999999e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0377, -0.1147, -0.2553,  ...,  0.0524, -0.3002, -1.3099],\n",
      "        [ 0.0377, -0.1147, -0.2553,  ...,  0.0524, -0.3002, -1.3099],\n",
      "        [ 0.0377, -0.1147, -0.2553,  ...,  0.0524, -0.3002, -1.3099],\n",
      "        ...,\n",
      "        [-0.1622,  0.4557, -0.1511,  ..., -0.6918,  0.9524, -0.4529],\n",
      "        [-0.1806, -0.1273,  0.6283,  ..., -0.2476,  0.6384,  0.2804],\n",
      "        [-0.1806, -0.1273,  0.6283,  ..., -0.2476,  0.6384,  0.2804]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03770148 -0.11467026 -0.25527382  0.05599264 -0.2505998  -0.66240305\n",
      " -0.03896945 -0.4484088  -1.4328828  -0.18231621 -0.51225173 -1.7294238\n",
      " -0.3468125  -0.6219697  -2.206182   -0.16557634 -0.73076296 -1.5959649\n",
      "  0.04159287 -0.77243865 -1.4076555  -0.01231906 -0.7074596  -1.4606996\n",
      " -0.01886564 -0.8486288  -1.5783389  -0.12234612 -0.6268573  -1.5057852\n",
      " -0.04922839 -0.6813609  -1.4781988  -0.06200781 -0.656786   -1.5684388\n",
      "  0.06159757 -0.68106174 -1.6079006  -0.03461107 -0.5339897  -1.3392003\n",
      " -0.16068093 -0.30764696 -1.9992418  -0.00560461 -0.4664661  -2.0026662\n",
      "  0.14711955 -0.42948276 -1.4671466  -0.14267352 -0.29844242 -1.2693367\n",
      " -0.06619854 -0.2752566  -1.3536775  -0.02447271 -0.2888257  -1.4663079\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.05242661 -0.30022913 -1.3098819 ]\n",
      "data: [ 0.03770148 -0.11467025 -0.25527382  0.05599264 -0.2505998  -0.66240305\n",
      " -0.03896945 -0.4484088  -1.4328828  -0.18231621 -0.51225173 -1.7294239\n",
      " -0.3468125  -0.6219697  -2.206182   -0.16557634 -0.73076296 -1.5959649\n",
      "  0.04159287 -0.77243865 -1.4076555  -0.01231906 -0.7074596  -1.4606996\n",
      " -0.01886564 -0.8486288  -1.578339   -0.12234612 -0.6268573  -1.5057852\n",
      " -0.04922839 -0.68136096 -1.4781986  -0.06200781 -0.656786   -1.5684388\n",
      "  0.06159757 -0.6810617  -1.6079007  -0.03461107 -0.5339897  -1.3392003\n",
      " -0.16068095 -0.30764696 -1.9992418  -0.00560461 -0.4664661  -2.0026662\n",
      "  0.14711955 -0.42948276 -1.4671466  -0.14267352 -0.29844242 -1.2693367\n",
      " -0.06619854 -0.2752566  -1.3536775  -0.02447271 -0.2888257  -1.4663079\n",
      "  0.05242661 -0.30022913 -1.3098819   0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0109, -0.0671, -0.2147,  ...,  0.0480, -0.2565, -1.2485],\n",
      "        [ 0.0109, -0.0671, -0.2147,  ...,  0.0480, -0.2565, -1.2485],\n",
      "        [ 0.0109, -0.0671, -0.2147,  ...,  0.0480, -0.2565, -1.2485],\n",
      "        ...,\n",
      "        [-0.0993,  0.4195, -0.0936,  ..., -0.6699,  0.9016, -0.3716],\n",
      "        [-0.1191, -0.1236,  0.5802,  ..., -0.2010,  0.5996,  0.2574],\n",
      "        [-0.1191, -0.1236,  0.5802,  ..., -0.2010,  0.5996,  0.2574]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01094527 -0.06711075 -0.21471687  0.03002127 -0.20095831 -0.59529805\n",
      " -0.05553612 -0.39241132 -1.3510572  -0.20209166 -0.45170966 -1.6582191\n",
      " -0.37224928 -0.57127583 -2.1332283  -0.19503224 -0.6777948  -1.5273043\n",
      "  0.03394089 -0.71532243 -1.3434771  -0.02504956 -0.65579724 -1.3949826\n",
      " -0.02932483 -0.79687464 -1.5149553  -0.14438558 -0.57450235 -1.4334779\n",
      " -0.06043341 -0.6340957  -1.4151486  -0.06853945 -0.6104978  -1.5130397\n",
      "  0.05368031 -0.64469916 -1.5541457  -0.04498836 -0.47884008 -1.2599386\n",
      " -0.17399153 -0.25379658 -1.9387673  -0.00960478 -0.42135677 -1.9392456\n",
      "  0.14651847 -0.38578033 -1.406557   -0.15813223 -0.24437132 -1.1950444\n",
      " -0.06751495 -0.22561944 -1.2783386  -0.02637761 -0.24673986 -1.3950686\n",
      "  0.04802829 -0.25649518 -1.2484764 ]\n",
      "data: [ 0.01094527 -0.06711075 -0.21471687  0.03002127 -0.20095831 -0.59529805\n",
      " -0.05553612 -0.39241132 -1.3510572  -0.20209165 -0.45170966 -1.6582191\n",
      " -0.37224925 -0.57127583 -2.1332283  -0.19503224 -0.6777948  -1.5273042\n",
      "  0.03394089 -0.71532243 -1.3434771  -0.02504956 -0.65579724 -1.3949826\n",
      " -0.02932483 -0.79687464 -1.5149553  -0.14438558 -0.57450235 -1.4334779\n",
      " -0.06043341 -0.6340957  -1.4151486  -0.06853945 -0.6104978  -1.5130397\n",
      "  0.05368031 -0.64469916 -1.5541457  -0.04498836 -0.47884005 -1.2599386\n",
      " -0.17399153 -0.25379658 -1.9387672  -0.00960478 -0.42135677 -1.9392456\n",
      "  0.14651847 -0.38578033 -1.406557   -0.15813223 -0.24437132 -1.1950444\n",
      " -0.06751495 -0.22561944 -1.2783386  -0.02637761 -0.24673986 -1.3950686\n",
      "  0.04802829 -0.25649518 -1.2484764   0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0219, -0.0613, -0.2551,  ...,  0.0301, -0.2501, -1.2754],\n",
      "        [ 0.0219, -0.0613, -0.2551,  ...,  0.0301, -0.2501, -1.2754],\n",
      "        [ 0.0219, -0.0613, -0.2551,  ...,  0.0301, -0.2501, -1.2754],\n",
      "        ...,\n",
      "        [-0.1741,  0.3566, -0.0968,  ..., -0.7633,  0.8426, -0.3386],\n",
      "        [-0.1269, -0.1197,  0.5934,  ..., -0.2008,  0.6599,  0.2435],\n",
      "        [-0.1269, -0.1197,  0.5934,  ..., -0.2008,  0.6599,  0.2435]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02189947 -0.06127658 -0.25513867  0.04810989 -0.17668131 -0.625779\n",
      " -0.08692297 -0.3863862  -1.4361107  -0.23517549 -0.45500842 -1.7196933\n",
      " -0.38838962 -0.54128456 -2.2206054  -0.16775462 -0.69146144 -1.5850542\n",
      " -0.0129801  -0.74607223 -1.4173913  -0.06226984 -0.67117053 -1.477549\n",
      " -0.0750802  -0.83403337 -1.5989207  -0.13213345 -0.6040245  -1.4963256\n",
      " -0.08098149 -0.6517009  -1.4602386  -0.10706785 -0.6211371  -1.5456948\n",
      "  0.03186644 -0.6409285  -1.5650704  -0.06304622 -0.5023364  -1.3368846\n",
      " -0.20019197 -0.27037507 -2.0552025  -0.03684884 -0.42646807 -2.0799062\n",
      "  0.12660179 -0.3978328  -1.4325973  -0.16377434 -0.27482504 -1.2602043\n",
      " -0.11273003 -0.24533165 -1.3493203  -0.0798477  -0.23564343 -1.4651169\n",
      "  0.03010219 -0.25010777 -1.2753757 ]\n",
      "data: [ 0.02189947 -0.06127658 -0.25513867  0.04810989 -0.17668131 -0.625779\n",
      " -0.08692297 -0.3863862  -1.4361107  -0.23517549 -0.45500842 -1.7196933\n",
      " -0.38838962 -0.54128456 -2.2206054  -0.1677546  -0.6914614  -1.5850542\n",
      " -0.0129801  -0.74607223 -1.4173913  -0.06226984 -0.6711705  -1.477549\n",
      " -0.0750802  -0.83403337 -1.5989207  -0.13213345 -0.6040245  -1.4963257\n",
      " -0.08098149 -0.6517009  -1.4602387  -0.10706785 -0.6211371  -1.5456948\n",
      "  0.03186644 -0.6409285  -1.5650704  -0.06304622 -0.5023364  -1.3368846\n",
      " -0.20019197 -0.27037507 -2.0552025  -0.03684884 -0.42646807 -2.0799062\n",
      "  0.12660179 -0.39783278 -1.4325974  -0.16377434 -0.27482504 -1.2602043\n",
      " -0.11273003 -0.24533165 -1.3493202  -0.0798477  -0.23564343 -1.4651169\n",
      "  0.03010219 -0.25010777 -1.2753757   0.14      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0541, -0.0156, -0.1979,  ...,  0.0587, -0.2091, -1.2346],\n",
      "        [ 0.0541, -0.0156, -0.1979,  ...,  0.0587, -0.2091, -1.2346],\n",
      "        [ 0.0541, -0.0156, -0.1979,  ...,  0.0587, -0.2091, -1.2346],\n",
      "        ...,\n",
      "        [-0.1979,  0.3173, -0.1350,  ..., -0.8528,  0.7587, -0.2764],\n",
      "        [-0.1473, -0.1841,  0.5238,  ..., -0.2009,  0.5647,  0.2281],\n",
      "        [-0.1473, -0.1841,  0.5238,  ..., -0.2009,  0.5647,  0.2281]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.05414837 -0.0156472  -0.19794461  0.06597181 -0.14223257 -0.5836156\n",
      " -0.05403746 -0.33166057 -1.3425493  -0.20547554 -0.3970251  -1.6308155\n",
      " -0.37600154 -0.48799473 -2.1215994  -0.13949934 -0.64204335 -1.4963517\n",
      "  0.01264706 -0.68625396 -1.3449829  -0.03533098 -0.6098498  -1.4087155\n",
      " -0.03397281 -0.76576257 -1.5213888  -0.10296327 -0.5490954  -1.4167125\n",
      " -0.04573782 -0.5938644  -1.3820686  -0.07329406 -0.5700821  -1.4781051\n",
      "  0.06657155 -0.5773135  -1.5017815  -0.03234861 -0.45721096 -1.2594092\n",
      " -0.14921495 -0.23419584 -1.9233305  -0.00457536 -0.37743014 -1.9413972\n",
      "  0.15547292 -0.35479873 -1.3735497  -0.12354496 -0.22809722 -1.1948178\n",
      " -0.07627292 -0.20582254 -1.2878091  -0.0450754  -0.19557253 -1.4054213\n",
      "  0.05873181 -0.20908839 -1.2345946 ]\n",
      "data: [ 0.05414837 -0.0156472  -0.1979446   0.06597181 -0.14223257 -0.5836156\n",
      " -0.05403746 -0.33166057 -1.3425493  -0.20547554 -0.3970251  -1.6308154\n",
      " -0.37600154 -0.48799473 -2.1215994  -0.13949934 -0.64204335 -1.4963517\n",
      "  0.01264706 -0.68625396 -1.3449829  -0.03533098 -0.6098498  -1.4087155\n",
      " -0.03397281 -0.76576257 -1.5213886  -0.10296327 -0.5490954  -1.4167125\n",
      " -0.04573782 -0.5938644  -1.3820686  -0.07329406 -0.5700821  -1.4781051\n",
      "  0.06657155 -0.5773135  -1.5017815  -0.03234861 -0.45721096 -1.2594092\n",
      " -0.14921495 -0.23419584 -1.9233305  -0.00457536 -0.37743014 -1.9413972\n",
      "  0.15547292 -0.35479873 -1.3735497  -0.12354496 -0.22809722 -1.1948178\n",
      " -0.07627292 -0.20582254 -1.2878091  -0.0450754  -0.19557253 -1.4054213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.05873181 -0.20908839 -1.2345946   0.15      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0051, -0.0628, -0.2564,  ...,  0.0293, -0.2445, -1.3060],\n",
      "        [ 0.0051, -0.0628, -0.2564,  ...,  0.0293, -0.2445, -1.3060],\n",
      "        [ 0.0051, -0.0628, -0.2564,  ...,  0.0293, -0.2445, -1.3060],\n",
      "        ...,\n",
      "        [-0.3331,  0.2143, -0.2507,  ..., -0.8559,  0.6247, -0.3997],\n",
      "        [-0.1089, -0.0304,  0.5879,  ..., -0.2219,  0.7714,  0.2500],\n",
      "        [-0.1089, -0.0304,  0.5879,  ..., -0.2219,  0.7714,  0.2500]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00506023 -0.06279383 -0.25643146  0.03036199 -0.20296209 -0.6765792\n",
      " -0.06677677 -0.3843965  -1.434891   -0.2085872  -0.44881654 -1.7238985\n",
      " -0.36979467 -0.5570652  -2.20582    -0.19443206 -0.6653071  -1.5888298\n",
      "  0.01146008 -0.693631   -1.3899674  -0.03586487 -0.62824416 -1.4462488\n",
      " -0.04364198 -0.7585251  -1.5625026  -0.1557847  -0.5632431  -1.5084697\n",
      " -0.07469182 -0.6162395  -1.4760566  -0.09246356 -0.5878334  -1.5654655\n",
      "  0.04050659 -0.6079629  -1.6094296  -0.07197946 -0.48120117 -1.3372557\n",
      " -0.17834324 -0.25132817 -1.9572805  -0.03179287 -0.40173358 -1.957892\n",
      "  0.12107401 -0.3726499  -1.4642377  -0.16803953 -0.24602222 -1.2717524\n",
      " -0.09525959 -0.22143963 -1.3442198  -0.04818922 -0.2300116  -1.4610542\n",
      "  0.02934863 -0.24445143 -1.3059582 ]\n",
      "data: [ 0.00506023 -0.06279383 -0.25643146  0.03036199 -0.2029621  -0.67657924\n",
      " -0.06677677 -0.38439646 -1.4348911  -0.20858721 -0.44881654 -1.7238984\n",
      " -0.36979467 -0.5570652  -2.20582    -0.19443206 -0.6653071  -1.5888298\n",
      "  0.01146008 -0.693631   -1.3899674  -0.03586487 -0.62824416 -1.4462488\n",
      " -0.04364199 -0.7585251  -1.5625026  -0.1557847  -0.5632431  -1.5084697\n",
      " -0.07469182 -0.6162395  -1.4760566  -0.09246356 -0.5878334  -1.5654655\n",
      "  0.04050659 -0.6079629  -1.6094296  -0.07197946 -0.48120117 -1.3372557\n",
      " -0.17834324 -0.25132817 -1.9572806  -0.03179287 -0.40173358 -1.957892\n",
      "  0.12107401 -0.3726499  -1.4642377  -0.16803953 -0.24602222 -1.2717524\n",
      " -0.09525959 -0.22143963 -1.3442198  -0.04818922 -0.2300116  -1.4610542\n",
      "  0.02934863 -0.24445143 -1.3059582   0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0315, -0.0891, -0.2349,  ...,  0.0580, -0.2756, -1.2904],\n",
      "        [ 0.0315, -0.0891, -0.2349,  ...,  0.0580, -0.2756, -1.2904],\n",
      "        [ 0.0315, -0.0891, -0.2349,  ...,  0.0580, -0.2756, -1.2904],\n",
      "        ...,\n",
      "        [-0.1353,  0.4222, -0.1802,  ..., -0.7418,  0.9308, -0.4209],\n",
      "        [-0.1475, -0.1769,  0.5658,  ..., -0.2457,  0.5927,  0.2386],\n",
      "        [-0.1475, -0.1769,  0.5658,  ..., -0.2457,  0.5927,  0.2386]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 3.15036885e-02 -8.91007632e-02 -2.34919161e-01  5.04687689e-02\n",
      " -2.30374500e-01 -6.52444243e-01 -3.08897123e-02 -4.05574590e-01\n",
      " -1.38290715e+00 -1.70401275e-01 -4.65368897e-01 -1.67898798e+00\n",
      " -3.37734282e-01 -5.78025937e-01 -2.15062761e+00 -1.65820375e-01\n",
      " -6.93669021e-01 -1.54372311e+00  4.50214893e-02 -7.19042480e-01\n",
      " -1.36946177e+00 -3.59338522e-03 -6.55713975e-01 -1.42620635e+00\n",
      "  1.59744918e-03 -7.85730302e-01 -1.53989458e+00 -1.24665976e-01\n",
      " -5.89241803e-01 -1.46331477e+00 -3.96056324e-02 -6.40202999e-01\n",
      " -1.43947363e+00 -5.09361103e-02 -6.15989625e-01 -1.53521204e+00\n",
      "  7.83861578e-02 -6.35441542e-01 -1.58207059e+00 -3.78105566e-02\n",
      " -5.05653679e-01 -1.29416800e+00 -1.42822251e-01 -2.81946033e-01\n",
      " -1.91553164e+00  4.22521681e-03 -4.30501103e-01 -1.91416907e+00\n",
      "  1.56109050e-01 -4.00125086e-01 -1.44128919e+00 -1.36615977e-01\n",
      " -2.71065772e-01 -1.23370981e+00 -5.92547804e-02 -2.50657260e-01\n",
      " -1.31510997e+00 -1.49987340e-02 -2.62629539e-01 -1.43277049e+00\n",
      "  5.79532608e-02 -2.75553048e-01 -1.29038405e+00]\n",
      "data: [ 3.15036885e-02 -8.91007632e-02 -2.34919161e-01  5.04687689e-02\n",
      " -2.30374515e-01 -6.52444243e-01 -3.08897123e-02 -4.05574620e-01\n",
      " -1.38290715e+00 -1.70401275e-01 -4.65368867e-01 -1.67898798e+00\n",
      " -3.37734312e-01 -5.78025937e-01 -2.15062761e+00 -1.65820375e-01\n",
      " -6.93669081e-01 -1.54372311e+00  4.50214893e-02 -7.19042540e-01\n",
      " -1.36946177e+00 -3.59338522e-03 -6.55713975e-01 -1.42620635e+00\n",
      "  1.59744918e-03 -7.85730302e-01 -1.53989458e+00 -1.24665976e-01\n",
      " -5.89241803e-01 -1.46331477e+00 -3.96056324e-02 -6.40202999e-01\n",
      " -1.43947363e+00 -5.09361140e-02 -6.15989625e-01 -1.53521204e+00\n",
      "  7.83861578e-02 -6.35441542e-01 -1.58207059e+00 -3.78105566e-02\n",
      " -5.05653679e-01 -1.29416800e+00 -1.42822251e-01 -2.81946033e-01\n",
      " -1.91553164e+00  4.22521681e-03 -4.30501103e-01 -1.91416895e+00\n",
      "  1.56109050e-01 -4.00125086e-01 -1.44128919e+00 -1.36615977e-01\n",
      " -2.71065772e-01 -1.23370981e+00 -5.92547804e-02 -2.50657260e-01\n",
      " -1.31510997e+00 -1.49987340e-02 -2.62629539e-01 -1.43277049e+00\n",
      "  5.79532608e-02 -2.75553048e-01 -1.29038405e+00  1.70000002e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0250, -0.0921, -0.2500,  ...,  0.0558, -0.2825, -1.2873],\n",
      "        [ 0.0250, -0.0921, -0.2500,  ...,  0.0558, -0.2825, -1.2873],\n",
      "        [ 0.0250, -0.0921, -0.2500,  ...,  0.0558, -0.2825, -1.2873],\n",
      "        ...,\n",
      "        [-0.1391,  0.4210, -0.0845,  ..., -0.6712,  0.9152, -0.3791],\n",
      "        [-0.1665, -0.1134,  0.5936,  ..., -0.2489,  0.6619,  0.2269],\n",
      "        [-0.1665, -0.1134,  0.5936,  ..., -0.2489,  0.6619,  0.2269]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02501298 -0.09209833 -0.25003892  0.04870381 -0.22328718 -0.6417163\n",
      " -0.04922245 -0.42081553 -1.4203281  -0.19411662 -0.48564935 -1.7195902\n",
      " -0.3569495  -0.5969962  -2.2022378  -0.17429467 -0.7068172  -1.5835297\n",
      "  0.03784777 -0.74885774 -1.391578   -0.01841803 -0.6852052  -1.44573\n",
      " -0.03025007 -0.82902277 -1.5666964  -0.12870672 -0.607333   -1.4904487\n",
      " -0.05370744 -0.6639211  -1.4655144  -0.0689263  -0.6378251  -1.5570493\n",
      "  0.05537648 -0.6668131  -1.5945079  -0.03889536 -0.51321423 -1.3184898\n",
      " -0.16640362 -0.28462926 -1.995441   -0.0068582  -0.4473461  -2.0002716\n",
      "  0.14814566 -0.41349334 -1.4479816  -0.14731826 -0.2794538  -1.2488525\n",
      " -0.06672136 -0.25693864 -1.3319952  -0.0248016  -0.27077255 -1.4461203\n",
      "  0.05581414 -0.28249013 -1.2873073 ]\n",
      "data: [ 0.02501298 -0.09209833 -0.25003892  0.04870381 -0.22328718 -0.6417163\n",
      " -0.04922245 -0.42081556 -1.420328   -0.19411664 -0.48564935 -1.7195902\n",
      " -0.3569495  -0.5969962  -2.2022378  -0.17429467 -0.70681727 -1.5835297\n",
      "  0.03784777 -0.74885774 -1.391578   -0.01841803 -0.6852052  -1.44573\n",
      " -0.03025007 -0.82902277 -1.5666965  -0.12870672 -0.607333   -1.4904487\n",
      " -0.05370744 -0.6639211  -1.4655144  -0.0689263  -0.6378251  -1.5570493\n",
      "  0.05537648 -0.6668131  -1.5945079  -0.03889536 -0.51321423 -1.3184898\n",
      " -0.16640362 -0.28462926 -1.995441   -0.0068582  -0.4473461  -2.0002716\n",
      "  0.14814566 -0.41349334 -1.4479816  -0.14731826 -0.2794538  -1.2488525\n",
      " -0.06672136 -0.25693864 -1.3319952  -0.0248016  -0.27077255 -1.4461203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.05581414 -0.28249013 -1.2873073   0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0195, -0.0585, -0.2393,  ...,  0.0580, -0.2501, -1.2801],\n",
      "        [ 0.0195, -0.0585, -0.2393,  ...,  0.0580, -0.2501, -1.2801],\n",
      "        [ 0.0195, -0.0585, -0.2393,  ...,  0.0580, -0.2501, -1.2801],\n",
      "        ...,\n",
      "        [-0.1485,  0.3698, -0.1241,  ..., -0.7755,  0.8537, -0.3701],\n",
      "        [-0.1325, -0.1380,  0.5730,  ..., -0.2058,  0.6095,  0.2272],\n",
      "        [-0.1325, -0.1380,  0.5730,  ..., -0.2058,  0.6095,  0.2272]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.9516844e-02 -5.8486514e-02 -2.3927672e-01  3.3905033e-02\n",
      " -2.0017624e-01 -6.4282250e-01 -4.5195453e-02 -3.8349405e-01\n",
      " -1.3795881e+00 -1.8880574e-01 -4.4336367e-01 -1.6860222e+00\n",
      " -3.6627966e-01 -5.6641513e-01 -2.1499109e+00 -1.8866643e-01\n",
      " -6.6556859e-01 -1.5453104e+00  4.4708684e-02 -6.9562680e-01\n",
      " -1.3481992e+00 -9.5226169e-03 -6.3701862e-01 -1.4008446e+00\n",
      " -9.7849891e-03 -7.7081573e-01 -1.5184028e+00 -1.3935362e-01\n",
      " -5.5785650e-01 -1.4559004e+00 -5.0360695e-02 -6.1716634e-01\n",
      " -1.4346591e+00 -5.6169838e-02 -5.9579569e-01 -1.5342216e+00\n",
      "  7.1539074e-02 -6.2350917e-01 -1.5840739e+00 -4.0981986e-02\n",
      " -4.7119424e-01 -1.2812092e+00 -1.5805732e-01 -2.4849015e-01\n",
      " -1.9308603e+00  2.9630214e-04 -4.0898687e-01 -1.9257247e+00\n",
      "  1.5709168e-01 -3.7538016e-01 -1.4335668e+00 -1.4779301e-01\n",
      " -2.3412874e-01 -1.2198458e+00 -5.8999851e-02 -2.1734345e-01\n",
      " -1.3015382e+00 -1.2225181e-02 -2.3885897e-01 -1.4190445e+00\n",
      "  5.8038451e-02 -2.5010854e-01 -1.2800605e+00]\n",
      "data: [ 1.9516844e-02 -5.8486514e-02 -2.3927671e-01  3.3905033e-02\n",
      " -2.0017624e-01 -6.4282250e-01 -4.5195449e-02 -3.8349402e-01\n",
      " -1.3795881e+00 -1.8880576e-01 -4.4336364e-01 -1.6860222e+00\n",
      " -3.6627969e-01 -5.6641513e-01 -2.1499109e+00 -1.8866643e-01\n",
      " -6.6556859e-01 -1.5453104e+00  4.4708684e-02 -6.9562685e-01\n",
      " -1.3481994e+00 -9.5226169e-03 -6.3701862e-01 -1.4008446e+00\n",
      " -9.7849891e-03 -7.7081573e-01 -1.5184028e+00 -1.3935362e-01\n",
      " -5.5785650e-01 -1.4559004e+00 -5.0360695e-02 -6.1716634e-01\n",
      " -1.4346591e+00 -5.6169838e-02 -5.9579569e-01 -1.5342216e+00\n",
      "  7.1539074e-02 -6.2350917e-01 -1.5840739e+00 -4.0981986e-02\n",
      " -4.7119424e-01 -1.2812092e+00 -1.5805732e-01 -2.4849015e-01\n",
      " -1.9308603e+00  2.9630214e-04 -4.0898687e-01 -1.9257247e+00\n",
      "  1.5709168e-01 -3.7538016e-01 -1.4335667e+00 -1.4779301e-01\n",
      " -2.3412874e-01 -1.2198458e+00 -5.8999851e-02 -2.1734345e-01\n",
      " -1.3015382e+00 -1.2225181e-02 -2.3885897e-01 -1.4190445e+00\n",
      "  5.8038451e-02 -2.5010854e-01 -1.2800605e+00  1.9000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0131, -0.0799, -0.2481,  ...,  0.0375, -0.2685, -1.2967],\n",
      "        [ 0.0131, -0.0799, -0.2481,  ...,  0.0375, -0.2685, -1.2967],\n",
      "        [ 0.0131, -0.0799, -0.2481,  ...,  0.0375, -0.2685, -1.2967],\n",
      "        ...,\n",
      "        [-0.1520,  0.4206, -0.1380,  ..., -0.6893,  0.9022, -0.3945],\n",
      "        [-0.1639, -0.1292,  0.5822,  ..., -0.2476,  0.6531,  0.2266],\n",
      "        [-0.1639, -0.1292,  0.5822,  ..., -0.2476,  0.6531,  0.2266]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01314016 -0.07985759 -0.24814682  0.03345513 -0.2140282  -0.65522623\n",
      " -0.0653763  -0.40406632 -1.4204868  -0.20840988 -0.46879762 -1.714893\n",
      " -0.3723631  -0.5762938  -2.1953611  -0.18530674 -0.6921148  -1.5780379\n",
      "  0.01644127 -0.7291476  -1.3874134  -0.03415717 -0.66314167 -1.4443085\n",
      " -0.04056495 -0.8036899  -1.5627538  -0.1438126  -0.59176844 -1.4917016\n",
      " -0.06938388 -0.644762   -1.4639827  -0.08552683 -0.61941946 -1.5560473\n",
      "  0.04574573 -0.6406318  -1.5960176  -0.05976192 -0.50360817 -1.322846\n",
      " -0.1767734  -0.27609634 -1.9753815  -0.02451174 -0.42996532 -1.9804072\n",
      "  0.13193737 -0.39967406 -1.4525784  -0.16083424 -0.26936254 -1.2549489\n",
      " -0.08837306 -0.2464716  -1.3383911  -0.04534717 -0.25492892 -1.4538357\n",
      "  0.03754508 -0.2684813  -1.2966789 ]\n",
      "data: [ 0.01314016 -0.07985759 -0.24814682  0.03345513 -0.21402818 -0.65522623\n",
      " -0.0653763  -0.40406632 -1.4204868  -0.20840988 -0.4687976  -1.714893\n",
      " -0.3723631  -0.5762938  -2.1953611  -0.18530674 -0.6921148  -1.5780379\n",
      "  0.01644127 -0.7291477  -1.3874134  -0.03415717 -0.6631416  -1.4443085\n",
      " -0.04056496 -0.8036899  -1.5627538  -0.1438126  -0.59176844 -1.4917016\n",
      " -0.06938388 -0.644762   -1.4639827  -0.08552683 -0.61941946 -1.5560473\n",
      "  0.04574573 -0.6406318  -1.5960176  -0.05976192 -0.50360817 -1.322846\n",
      " -0.1767734  -0.27609634 -1.9753815  -0.02451174 -0.42996532 -1.9804072\n",
      "  0.13193737 -0.39967406 -1.4525784  -0.16083424 -0.26936254 -1.2549489\n",
      " -0.08837307 -0.2464716  -1.3383911  -0.04534717 -0.25492892 -1.4538357\n",
      "  0.03754508 -0.2684813  -1.2966789   0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[4.075 4.073 4.073 ... 3.638 3.638 3.628]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " [4.051 0.    0.    ... 3.619 3.619 3.615]\n",
      " ...\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.382 3.38  3.38  ... 3.335 3.335 3.36 ]\n",
      " [3.377 3.369 3.369 ... 3.336 3.336 3.34 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " [0. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[ 0.0089, -0.0459, -0.2337,  ...,  0.0430, -0.2400, -1.2618],\n",
      "        [ 0.0089, -0.0459, -0.2337,  ...,  0.0430, -0.2400, -1.2618],\n",
      "        [ 0.0089, -0.0459, -0.2337,  ...,  0.0430, -0.2400, -1.2618],\n",
      "        ...,\n",
      "        [-0.1759,  0.3557, -0.1630,  ..., -0.8251,  0.8373, -0.3927],\n",
      "        [-0.1455, -0.1836,  0.5519,  ..., -0.2346,  0.5735,  0.2112],\n",
      "        [-0.1455, -0.1836,  0.5519,  ..., -0.2346,  0.5735,  0.2112]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00894869 -0.04587682 -0.23366809  0.02389829 -0.1795135  -0.628245\n",
      " -0.06951524 -0.36608714 -1.3741342  -0.21259858 -0.42663604 -1.6730828\n",
      " -0.38361698 -0.53891945 -2.1442144  -0.19271153 -0.657529   -1.5326704\n",
      "  0.0147745  -0.6918895  -1.3511978  -0.03547101 -0.62752867 -1.4072188\n",
      " -0.0334864  -0.7696123  -1.5244404  -0.14781374 -0.556036   -1.4455374\n",
      " -0.06847709 -0.610306   -1.4211198  -0.07812587 -0.5872984  -1.5169729\n",
      "  0.05621339 -0.6103599  -1.5589436  -0.05806904 -0.46756223 -1.2769513\n",
      " -0.17659523 -0.24375057 -1.9389793  -0.0173815  -0.40067926 -1.9420608\n",
      "  0.14303592 -0.36953565 -1.4149678  -0.16043955 -0.23496449 -1.212461\n",
      " -0.08351837 -0.21552175 -1.296584   -0.04062982 -0.22677237 -1.414382\n",
      "  0.04299822 -0.23996426 -1.2617805 ]\n",
      "data: [-1.98 -5.33  4.01 -1.92 -5.09  3.99 -1.91 -4.75  4.19 -1.91 -4.5   4.52\n",
      "  0.    0.    0.   -1.82 -4.76  4.71  0.    0.    0.   -1.14 -3.32  0.18\n",
      " -1.17 -3.31  0.13 -1.87 -4.76  4.71  0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.   -1.88 -4.78  4.48  0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.   -1.92 -4.59  3.95 -1.94 -4.39  3.8  -1.94 -4.26  3.51\n",
      " -1.9  -4.11  2.98  0.  ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[-0.2921,  0.4660, -0.2072,  ..., -0.4810,  0.2325, -0.9156],\n",
      "        [-0.2921,  0.4660, -0.2072,  ..., -0.4810,  0.2325, -0.9156],\n",
      "        [-0.2921,  0.4660, -0.2072,  ..., -0.4810,  0.2325, -0.9156],\n",
      "        ...,\n",
      "        [ 1.2016, -1.2246,  0.4724,  ...,  1.1677, -0.7821,  0.5216],\n",
      "        [ 0.4105, -0.2338,  0.4834,  ...,  0.7591, -0.4759,  2.4948],\n",
      "        [ 0.4105, -0.2338,  0.4834,  ...,  0.7591, -0.4759,  2.4948]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.29212904  0.4660052  -0.20720646 -0.34433857  0.31746322 -0.8800446\n",
      " -0.450908    0.24428444 -1.0834868  -0.5217372   0.12205142 -1.1040297\n",
      " -0.55413187  0.06747058 -1.2451975  -0.4610701   0.13767898 -1.2891954\n",
      " -0.40434408  0.07122374 -0.9008828  -0.44462508 -0.0453676  -0.9377189\n",
      " -0.5133273  -0.08602378 -1.024397   -0.47992706  0.20923743 -1.3237064\n",
      " -0.5478147   0.08339605 -1.3065295  -0.58825517  0.00282258 -1.2993191\n",
      " -0.5024523  -0.10591957 -1.2587899  -0.5399085   0.23493621 -1.1937548\n",
      " -0.5697341   0.24918166 -1.1408807  -0.5796976   0.1630086  -1.1601272\n",
      " -0.4728566   0.0334883  -1.0637553  -0.5326833   0.3907708  -1.0456784\n",
      " -0.574821    0.35346192 -1.0150907  -0.57710534  0.34814742 -1.0521877\n",
      " -0.48097777  0.23253523 -0.91555166]\n",
      "init: [-0.29212904  0.4660052  -0.20720646 -0.34433857  0.31746322 -0.8800446\n",
      " -0.450908    0.24428444 -1.0834868  -0.5217372   0.12205142 -1.1040297\n",
      " -0.55413187  0.06747058 -1.2451975  -0.4610701   0.13767898 -1.2891954\n",
      " -0.40434408  0.07122374 -0.9008828  -0.44462508 -0.0453676  -0.9377189\n",
      " -0.5133273  -0.08602378 -1.024397   -0.47992706  0.20923743 -1.3237064\n",
      " -0.5478147   0.08339605 -1.3065295  -0.58825517  0.00282258 -1.2993191\n",
      " -0.5024523  -0.10591957 -1.2587899  -0.5399085   0.23493621 -1.1937548\n",
      " -0.5697341   0.24918166 -1.1408807  -0.5796976   0.1630086  -1.1601272\n",
      " -0.4728566   0.0334883  -1.0637553  -0.5326833   0.3907708  -1.0456784\n",
      " -0.574821    0.35346192 -1.0150907  -0.57710534  0.34814742 -1.0521877\n",
      " -0.48097777  0.23253523 -0.91555166]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [-0.29212904  0.4660052  -0.20720646 -0.34433857  0.31746322 -0.8800446\n",
      " -0.450908    0.24428444 -1.0834868  -0.5217372   0.12205142 -1.1040297\n",
      " -0.55413187  0.06747058 -1.2451975  -0.4610701   0.13767898 -1.2891954\n",
      " -0.4043441   0.07122374 -0.9008828  -0.44462508 -0.0453676  -0.937719\n",
      " -0.5133273  -0.08602378 -1.024397   -0.47992706  0.20923743 -1.3237064\n",
      " -0.5478147   0.08339605 -1.3065295  -0.58825517  0.00282258 -1.2993191\n",
      " -0.5024523  -0.10591957 -1.2587899  -0.5399085   0.2349362  -1.1937548\n",
      " -0.5697341   0.24918166 -1.1408807  -0.5796976   0.1630086  -1.1601272\n",
      " -0.4728566   0.0334883  -1.0637553  -0.5326833   0.3907708  -1.0456784\n",
      " -0.574821    0.35346192 -1.0150907  -0.57710534  0.34814742 -1.0521877\n",
      " -0.48097777  0.23253523 -0.91555166  0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 9.7386e-04, -4.3663e-01, -9.8857e-02,  ...,  3.7400e-02,\n",
      "         -5.7827e-01, -1.1869e+00],\n",
      "        [ 9.7386e-04, -4.3663e-01, -9.8857e-02,  ...,  3.7400e-02,\n",
      "         -5.7827e-01, -1.1869e+00],\n",
      "        [ 9.7386e-04, -4.3663e-01, -9.8857e-02,  ...,  3.7400e-02,\n",
      "         -5.7827e-01, -1.1869e+00],\n",
      "        ...,\n",
      "        [ 2.3057e-01,  5.2673e-01,  4.0879e-01,  ..., -7.0917e-01,\n",
      "          1.0132e+00,  5.8632e-01],\n",
      "        [-3.4645e-01,  3.2095e-01,  3.4304e-01,  ..., -7.8287e-01,\n",
      "          1.1496e+00, -5.9010e-02],\n",
      "        [-3.4645e-01,  3.2095e-01,  3.4304e-01,  ..., -7.8287e-01,\n",
      "          1.1496e+00, -5.9010e-02]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 9.7386166e-04 -4.3663490e-01 -9.8857164e-02  3.8108062e-02\n",
      " -5.8396596e-01 -5.9078133e-01 -7.4708089e-03 -7.0337605e-01\n",
      " -1.2332680e+00 -1.2828223e-01 -7.3020577e-01 -1.5009624e+00\n",
      " -2.4353826e-01 -8.4159100e-01 -1.9958079e+00 -1.9583112e-01\n",
      " -9.7863472e-01 -1.3751414e+00  1.5181422e-02 -9.4975233e-01\n",
      " -1.3032800e+00 -2.2420719e-02 -8.6301321e-01 -1.3572654e+00\n",
      " -3.2822564e-03 -9.4953549e-01 -1.4521624e+00 -1.6866411e-01\n",
      " -8.8332772e-01 -1.3266691e+00 -4.6269998e-02 -9.0146303e-01\n",
      " -1.3210789e+00 -5.2043989e-02 -8.3805108e-01 -1.3825552e+00\n",
      "  5.0434574e-02 -8.6060560e-01 -1.4334346e+00 -5.7996549e-02\n",
      " -8.1391054e-01 -1.1838710e+00 -1.1118737e-01 -5.6507266e-01\n",
      " -1.6174147e+00  1.1509806e-02 -6.9962835e-01 -1.5947932e+00\n",
      "  1.1454117e-01 -6.4263499e-01 -1.3540426e+00 -1.4750098e-01\n",
      " -6.0347235e-01 -1.1309699e+00 -4.6279967e-02 -5.5976748e-01\n",
      " -1.1895829e+00 -1.0944009e-03 -5.7517356e-01 -1.3129352e+00\n",
      "  3.7399925e-02 -5.7826841e-01 -1.1868750e+00]\n",
      "data: [ 9.73861665e-04 -4.36634898e-01 -9.88571644e-02  3.81080620e-02\n",
      " -5.83965957e-01 -5.90781331e-01 -7.47080939e-03 -7.03376055e-01\n",
      " -1.23326802e+00 -1.28282234e-01 -7.30205774e-01 -1.50096238e+00\n",
      " -2.43538260e-01 -8.41591060e-01 -1.99580801e+00 -1.95831120e-01\n",
      " -9.78634715e-01 -1.37514150e+00  1.51814222e-02 -9.49752331e-01\n",
      " -1.30328000e+00 -2.24207193e-02 -8.63013208e-01 -1.35726535e+00\n",
      " -3.28225642e-03 -9.49535549e-01 -1.45216227e+00 -1.68664113e-01\n",
      " -8.83327723e-01 -1.32666922e+00 -4.62699980e-02 -9.01463032e-01\n",
      " -1.32107890e+00 -5.20439893e-02 -8.38051081e-01 -1.38255525e+00\n",
      "  5.04345745e-02 -8.60605597e-01 -1.43343461e+00 -5.79965487e-02\n",
      " -8.13910544e-01 -1.18387103e+00 -1.11187369e-01 -5.65072656e-01\n",
      " -1.61741471e+00  1.15098059e-02 -6.99628353e-01 -1.59479320e+00\n",
      "  1.14541166e-01 -6.42634988e-01 -1.35404265e+00 -1.47500977e-01\n",
      " -6.03472352e-01 -1.13096988e+00 -4.62799631e-02 -5.59767485e-01\n",
      " -1.18958294e+00 -1.09440088e-03 -5.75173557e-01 -1.31293523e+00\n",
      "  3.73999253e-02 -5.78268409e-01 -1.18687499e+00  1.99999996e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0798, -0.1347, -0.2220,  ...,  0.0738, -0.3043, -1.2731],\n",
      "        [ 0.0798, -0.1347, -0.2220,  ...,  0.0738, -0.3043, -1.2731],\n",
      "        [ 0.0798, -0.1347, -0.2220,  ...,  0.0738, -0.3043, -1.2731],\n",
      "        ...,\n",
      "        [-0.2038,  0.3982, -0.0156,  ..., -0.2842,  1.0761, -0.5210],\n",
      "        [-0.0692,  0.0229,  0.6713,  ..., -0.1437,  0.5289,  0.4072],\n",
      "        [-0.0692,  0.0229,  0.6713,  ..., -0.1437,  0.5289,  0.4072]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 7.97883123e-02 -1.34696573e-01 -2.21953928e-01  9.79941934e-02\n",
      " -2.59995937e-01 -5.47201514e-01  5.29204309e-03 -4.73662138e-01\n",
      " -1.36778367e+00 -1.56299055e-01 -5.30244350e-01 -1.68605435e+00\n",
      " -3.39307815e-01 -6.49516821e-01 -2.18148732e+00 -1.48885190e-01\n",
      " -7.49159515e-01 -1.59504795e+00  1.03754468e-01 -8.00334275e-01\n",
      " -1.37623405e+00  4.11270633e-02 -7.34943092e-01 -1.41300297e+00\n",
      "  3.94840613e-02 -8.82829785e-01 -1.53915703e+00 -9.76937339e-02\n",
      " -6.37500167e-01 -1.48528993e+00 -1.46499574e-02 -7.02233195e-01\n",
      " -1.45311165e+00 -1.16579235e-02 -6.77594066e-01 -1.55410504e+00\n",
      "  1.18197806e-01 -7.18094170e-01 -1.59321415e+00  1.06383860e-02\n",
      " -5.33272147e-01 -1.31111073e+00 -1.53796285e-01 -2.96257466e-01\n",
      " -2.03796530e+00  2.73439288e-02 -4.84002858e-01 -2.03913426e+00\n",
      "  2.05184370e-01 -4.35352683e-01 -1.43861151e+00 -1.34802163e-01\n",
      " -2.85364449e-01 -1.23480093e+00 -3.68031189e-02 -2.64340281e-01\n",
      " -1.31376386e+00 -8.88235867e-04 -2.97670245e-01 -1.42728066e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7.37888366e-02 -3.04346561e-01 -1.27309752e+00]\n",
      "data: [ 7.97883123e-02 -1.34696573e-01 -2.21953928e-01  9.79941934e-02\n",
      " -2.59995937e-01 -5.47201514e-01  5.29204309e-03 -4.73662138e-01\n",
      " -1.36778367e+00 -1.56299055e-01 -5.30244350e-01 -1.68605435e+00\n",
      " -3.39307815e-01 -6.49516821e-01 -2.18148732e+00 -1.48885190e-01\n",
      " -7.49159575e-01 -1.59504795e+00  1.03754476e-01 -8.00334215e-01\n",
      " -1.37623417e+00  4.11270633e-02 -7.34943092e-01 -1.41300297e+00\n",
      "  3.94840613e-02 -8.82829845e-01 -1.53915715e+00 -9.76937264e-02\n",
      " -6.37500167e-01 -1.48528993e+00 -1.46499574e-02 -7.02233195e-01\n",
      " -1.45311153e+00 -1.16579235e-02 -6.77594066e-01 -1.55410504e+00\n",
      "  1.18197806e-01 -7.18094170e-01 -1.59321415e+00  1.06383860e-02\n",
      " -5.33272147e-01 -1.31111073e+00 -1.53796285e-01 -2.96257466e-01\n",
      " -2.03796530e+00  2.73439288e-02 -4.84002888e-01 -2.03913426e+00\n",
      "  2.05184370e-01 -4.35352683e-01 -1.43861151e+00 -1.34802163e-01\n",
      " -2.85364449e-01 -1.23480093e+00 -3.68031189e-02 -2.64340281e-01\n",
      " -1.31376386e+00 -8.88235867e-04 -2.97670245e-01 -1.42728078e+00\n",
      "  7.37888366e-02 -3.04346561e-01 -1.27309752e+00  2.99999993e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0307, -0.1647, -0.1928,  ...,  0.1127, -0.3575, -1.2395],\n",
      "        [ 0.0307, -0.1647, -0.1928,  ...,  0.1127, -0.3575, -1.2395],\n",
      "        [ 0.0307, -0.1647, -0.1928,  ...,  0.1127, -0.3575, -1.2395],\n",
      "        ...,\n",
      "        [-0.0619,  0.4299, -0.0393,  ..., -0.5613,  0.9605, -0.3868],\n",
      "        [-0.1000,  0.0146,  0.6205,  ..., -0.1953,  0.7021,  0.2778],\n",
      "        [-0.1000,  0.0146,  0.6205,  ..., -0.1953,  0.7021,  0.2778]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 3.0723665e-02 -1.6468406e-01 -1.9280654e-01  5.7588857e-02\n",
      " -3.1220186e-01 -5.6166077e-01 -2.0124763e-03 -5.0656730e-01\n",
      " -1.3426219e+00 -1.4893210e-01 -5.6986940e-01 -1.6667830e+00\n",
      " -3.3126044e-01 -7.1846068e-01 -2.1361988e+00 -1.8619326e-01\n",
      " -7.6650167e-01 -1.5456986e+00  1.2133791e-01 -7.9844999e-01\n",
      " -1.3094538e+00  5.6024306e-02 -7.5438237e-01 -1.3459777e+00\n",
      "  4.7329374e-02 -8.7643123e-01 -1.4715301e+00 -1.2119777e-01\n",
      " -6.4964342e-01 -1.4381053e+00 -4.9310625e-03 -7.2671890e-01\n",
      " -1.4249337e+00  6.7821741e-03 -7.0186043e-01 -1.5274713e+00\n",
      "  1.2522209e-01 -7.5730503e-01 -1.5926130e+00  3.2831877e-03\n",
      " -5.6034923e-01 -1.2419186e+00 -1.2708521e-01 -3.2899472e-01\n",
      " -1.9166315e+00  5.4978959e-02 -5.1576996e-01 -1.8971369e+00\n",
      "  2.1765026e-01 -4.7071740e-01 -1.4180437e+00 -1.3040659e-01\n",
      " -3.1113350e-01 -1.1759632e+00  2.5194660e-03 -2.9799429e-01\n",
      " -1.2459701e+00  6.2813260e-02 -3.4965479e-01 -1.3619046e+00\n",
      "  1.1266279e-01 -3.5749561e-01 -1.2394618e+00]\n",
      "data: [ 3.0723665e-02 -1.6468407e-01 -1.9280654e-01  5.7588860e-02\n",
      " -3.1220186e-01 -5.6166077e-01 -2.0124763e-03 -5.0656730e-01\n",
      " -1.3426219e+00 -1.4893210e-01 -5.6986940e-01 -1.6667830e+00\n",
      " -3.3126044e-01 -7.1846068e-01 -2.1361988e+00 -1.8619326e-01\n",
      " -7.6650167e-01 -1.5456986e+00  1.2133791e-01 -7.9844999e-01\n",
      " -1.3094538e+00  5.6024302e-02 -7.5438237e-01 -1.3459777e+00\n",
      "  4.7329374e-02 -8.7643123e-01 -1.4715302e+00 -1.2119777e-01\n",
      " -6.4964342e-01 -1.4381053e+00 -4.9310625e-03 -7.2671890e-01\n",
      " -1.4249337e+00  6.7821741e-03 -7.0186043e-01 -1.5274713e+00\n",
      "  1.2522209e-01 -7.5730497e-01 -1.5926129e+00  3.2831877e-03\n",
      " -5.6034923e-01 -1.2419186e+00 -1.2708521e-01 -3.2899472e-01\n",
      " -1.9166315e+00  5.4978956e-02 -5.1576996e-01 -1.8971370e+00\n",
      "  2.1765026e-01 -4.7071740e-01 -1.4180436e+00 -1.3040659e-01\n",
      " -3.1113350e-01 -1.1759632e+00  2.5194660e-03 -2.9799429e-01\n",
      " -1.2459701e+00  6.2813260e-02 -3.4965479e-01 -1.3619046e+00\n",
      "  1.1266279e-01 -3.5749561e-01 -1.2394618e+00  3.9999999e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0135, -0.1574, -0.1864,  ...,  0.0341, -0.3519, -1.1912],\n",
      "        [ 0.0135, -0.1574, -0.1864,  ...,  0.0341, -0.3519, -1.1912],\n",
      "        [ 0.0135, -0.1574, -0.1864,  ...,  0.0341, -0.3519, -1.1912],\n",
      "        ...,\n",
      "        [-0.0314,  0.5215, -0.1314,  ..., -0.3117,  1.0689, -0.5721],\n",
      "        [-0.1132, -0.0164,  0.6361,  ..., -0.1683,  0.7008,  0.2429],\n",
      "        [-0.1132, -0.0164,  0.6361,  ..., -0.1683,  0.7008,  0.2429]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01352995 -0.15738867 -0.18639877  0.03865317 -0.2725318  -0.50813234\n",
      " -0.09929391 -0.5056561  -1.3485816  -0.25831026 -0.57580864 -1.6392429\n",
      " -0.4185055  -0.67274475 -2.1424387  -0.18732159 -0.7976824  -1.5311772\n",
      " -0.01134236 -0.8680387  -1.367669   -0.06509234 -0.79260856 -1.415413\n",
      " -0.07505287 -0.9615706  -1.5354791  -0.14070475 -0.70333356 -1.4288985\n",
      " -0.08590961 -0.76142067 -1.3918691  -0.09763931 -0.7321465  -1.4727237\n",
      "  0.03751209 -0.76293015 -1.4909797  -0.05359025 -0.59374666 -1.2669722\n",
      " -0.21207671 -0.35868424 -2.0077899  -0.03215993 -0.5376499  -2.0261862\n",
      "  0.13924693 -0.49339223 -1.355885   -0.17648436 -0.36088413 -1.1879138\n",
      " -0.10759376 -0.33154792 -1.2736202  -0.07139054 -0.33963713 -1.3833134\n",
      "  0.03407436 -0.3518725  -1.1911703 ]\n",
      "data: [ 0.01352995 -0.15738867 -0.18639877  0.03865317 -0.2725318  -0.50813234\n",
      " -0.09929391 -0.5056561  -1.3485816  -0.25831026 -0.57580864 -1.6392429\n",
      " -0.4185055  -0.67274475 -2.1424387  -0.18732159 -0.7976824  -1.5311772\n",
      " -0.01134236 -0.8680387  -1.3676689  -0.06509234 -0.79260856 -1.415413\n",
      " -0.07505287 -0.96157056 -1.5354791  -0.14070475 -0.7033336  -1.4288985\n",
      " -0.08590961 -0.76142067 -1.3918691  -0.09763931 -0.7321465  -1.4727237\n",
      "  0.03751209 -0.76293015 -1.4909797  -0.05359025 -0.59374666 -1.2669722\n",
      " -0.21207671 -0.35868424 -2.0077899  -0.03215993 -0.5376499  -2.0261862\n",
      "  0.13924693 -0.49339223 -1.355885   -0.17648436 -0.36088413 -1.1879138\n",
      " -0.10759375 -0.33154792 -1.2736202  -0.07139054 -0.33963716 -1.3833134\n",
      "  0.03407436 -0.35187253 -1.1911703   0.05      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BB38>\n",
      "tensor([[-0.0026, -0.0145, -0.1866,  ...,  0.0206, -0.2151, -1.1494],\n",
      "        [-0.0026, -0.0145, -0.1866,  ...,  0.0206, -0.2151, -1.1494],\n",
      "        [-0.0026, -0.0145, -0.1866,  ...,  0.0206, -0.2151, -1.1494],\n",
      "        ...,\n",
      "        [-0.1761,  0.4020,  0.0104,  ..., -0.6759,  1.0206, -0.4213],\n",
      "        [-0.0817, -0.0882,  0.6192,  ..., -0.1951,  0.5925,  0.2597],\n",
      "        [-0.0817, -0.0882,  0.6192,  ..., -0.1951,  0.5925,  0.2597]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.0026376  -0.01447725 -0.18664922  0.01482544 -0.11646483 -0.46459156\n",
      " -0.14705624 -0.3529492  -1.3303297  -0.30784732 -0.42113572 -1.6125736\n",
      " -0.4699468  -0.5037875  -2.1224587  -0.19860546 -0.6666063  -1.5030541\n",
      " -0.05100609 -0.7392861  -1.3486032  -0.09410708 -0.65442437 -1.400634\n",
      " -0.08308066 -0.8312744  -1.5247617  -0.15809634 -0.5779412  -1.4022675\n",
      " -0.10779045 -0.6271452  -1.3570302  -0.11102898 -0.5941308  -1.439723\n",
      "  0.05475858 -0.6149916  -1.4484587  -0.08015864 -0.46702027 -1.2460272\n",
      " -0.24016874 -0.2317854  -2.0170937  -0.04686017 -0.4019618  -2.0483804\n",
      "  0.15539439 -0.36328053 -1.3175011  -0.20137946 -0.23570475 -1.161133\n",
      " -0.14564931 -0.20695804 -1.251137   -0.11417158 -0.19946153 -1.3632119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.02061749 -0.2151213  -1.14938   ]\n",
      "data: [-0.0026376  -0.01447725 -0.18664923  0.01482544 -0.11646483 -0.46459156\n",
      " -0.14705624 -0.35294923 -1.3303295  -0.30784732 -0.42113572 -1.6125735\n",
      " -0.46994677 -0.5037875  -2.1224587  -0.19860546 -0.6666063  -1.5030541\n",
      " -0.05100609 -0.7392861  -1.3486032  -0.09410708 -0.65442437 -1.400634\n",
      " -0.08308066 -0.8312744  -1.5247617  -0.15809634 -0.5779412  -1.4022675\n",
      " -0.10779045 -0.6271452  -1.3570302  -0.11102898 -0.5941308  -1.439723\n",
      "  0.05475858 -0.6149916  -1.4484587  -0.08015864 -0.46702027 -1.2460272\n",
      " -0.24016875 -0.23178539 -2.0170937  -0.04686017 -0.40196183 -2.0483804\n",
      "  0.15539439 -0.36328053 -1.3175011  -0.20137948 -0.23570475 -1.161133\n",
      " -0.14564931 -0.20695804 -1.251137   -0.11417158 -0.19946153 -1.3632119\n",
      "  0.02061749 -0.21512131 -1.14938     0.06      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B9B0>\n",
      "tensor([[-2.4072e-02, -3.5518e-02, -2.3054e-01,  ..., -7.0892e-05,\n",
      "         -1.9751e-01, -1.3291e+00],\n",
      "        [-2.4072e-02, -3.5518e-02, -2.3054e-01,  ..., -7.0892e-05,\n",
      "         -1.9751e-01, -1.3291e+00],\n",
      "        [-2.4072e-02, -3.5518e-02, -2.3054e-01,  ..., -7.0892e-05,\n",
      "         -1.9751e-01, -1.3291e+00],\n",
      "        ...,\n",
      "        [-2.3000e-01,  2.6806e-01, -8.1805e-02,  ..., -7.3480e-01,\n",
      "          7.4570e-01, -3.0403e-01],\n",
      "        [-1.7670e-01, -1.1312e-01,  5.1974e-01,  ..., -2.9209e-01,\n",
      "          6.3373e-01,  2.5591e-01],\n",
      "        [-1.7670e-01, -1.1312e-01,  5.1974e-01,  ..., -2.9209e-01,\n",
      "          6.3373e-01,  2.5591e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-2.40720473e-02 -3.55181545e-02 -2.30538160e-01 -1.24960728e-02\n",
      " -1.92104310e-01 -6.79993987e-01 -7.33837113e-02 -3.51992130e-01\n",
      " -1.37814796e+00 -2.18834132e-01 -4.06868339e-01 -1.68749583e+00\n",
      " -4.08228040e-01 -5.36454201e-01 -2.14440560e+00 -2.47221455e-01\n",
      " -6.25401914e-01 -1.54079068e+00  1.38951540e-02 -6.34803772e-01\n",
      " -1.32034659e+00 -3.27072591e-02 -5.77693343e-01 -1.37045062e+00\n",
      " -2.96228826e-02 -6.87008739e-01 -1.48669648e+00 -2.00004518e-01\n",
      " -5.07885695e-01 -1.46035051e+00 -9.19886678e-02 -5.65242290e-01\n",
      " -1.44369578e+00 -8.75352472e-02 -5.37016809e-01 -1.55211067e+00\n",
      "  5.03503382e-02 -5.60608149e-01 -1.62363219e+00 -9.69110206e-02\n",
      " -4.33155477e-01 -1.28251922e+00 -1.90904975e-01 -2.03331336e-01\n",
      " -1.85669672e+00 -4.21795845e-02 -3.50735068e-01 -1.84029830e+00\n",
      "  1.17171839e-01 -3.16739798e-01 -1.47433567e+00 -2.03503221e-01\n",
      " -1.84137493e-01 -1.22766948e+00 -1.09290555e-01 -1.62971407e-01\n",
      " -1.30934596e+00 -5.24882525e-02 -1.89849243e-01 -1.43261254e+00\n",
      " -7.08922744e-05 -1.97507933e-01 -1.32913899e+00]\n",
      "data: [-2.40720455e-02 -3.55181545e-02 -2.30538160e-01 -1.24960728e-02\n",
      " -1.92104295e-01 -6.79993987e-01 -7.33837113e-02 -3.51992100e-01\n",
      " -1.37814784e+00 -2.18834132e-01 -4.06868339e-01 -1.68749583e+00\n",
      " -4.08228040e-01 -5.36454201e-01 -2.14440560e+00 -2.47221455e-01\n",
      " -6.25401914e-01 -1.54079068e+00  1.38951540e-02 -6.34803772e-01\n",
      " -1.32034647e+00 -3.27072591e-02 -5.77693343e-01 -1.37045062e+00\n",
      " -2.96228845e-02 -6.87008739e-01 -1.48669648e+00 -2.00004518e-01\n",
      " -5.07885695e-01 -1.46035051e+00 -9.19886678e-02 -5.65242290e-01\n",
      " -1.44369578e+00 -8.75352472e-02 -5.37016809e-01 -1.55211055e+00\n",
      "  5.03503382e-02 -5.60608149e-01 -1.62363219e+00 -9.69110206e-02\n",
      " -4.33155477e-01 -1.28251922e+00 -1.90904975e-01 -2.03331336e-01\n",
      " -1.85669672e+00 -4.21795845e-02 -3.50735068e-01 -1.84029830e+00\n",
      "  1.17171839e-01 -3.16739798e-01 -1.47433567e+00 -2.03503221e-01\n",
      " -1.84137493e-01 -1.22766948e+00 -1.09290555e-01 -1.62971407e-01\n",
      " -1.30934596e+00 -5.24882525e-02 -1.89849243e-01 -1.43261266e+00\n",
      " -7.08922744e-05 -1.97507933e-01 -1.32913899e+00  7.00000003e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0258, -0.1538, -0.2758,  ...,  0.0311, -0.3281, -1.3668],\n",
      "        [ 0.0258, -0.1538, -0.2758,  ...,  0.0311, -0.3281, -1.3668],\n",
      "        [ 0.0258, -0.1538, -0.2758,  ...,  0.0311, -0.3281, -1.3668],\n",
      "        ...,\n",
      "        [-0.3733,  0.3257, -0.3785,  ..., -0.8851,  0.7898, -0.5561],\n",
      "        [-0.1452, -0.0113,  0.6723,  ..., -0.2270,  0.7622,  0.3671],\n",
      "        [-0.1452, -0.0113,  0.6723,  ..., -0.2270,  0.7622,  0.3671]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02577697 -0.15378182 -0.27577597  0.05059822 -0.29034364 -0.6979248\n",
      " -0.03204484 -0.46022692 -1.4433258  -0.17535533 -0.51869476 -1.7398922\n",
      " -0.33724308 -0.62583905 -2.2344868  -0.17803922 -0.75030357 -1.618326\n",
      "  0.03599483 -0.774225   -1.4417615  -0.01448804 -0.7123247  -1.4970899\n",
      " -0.01804179 -0.83667195 -1.612525   -0.1388172  -0.6497154  -1.5379467\n",
      " -0.05517366 -0.69906086 -1.519305   -0.06898607 -0.6693512  -1.617511\n",
      "  0.05562544 -0.6919225  -1.6657767  -0.05520279 -0.56630665 -1.3681853\n",
      " -0.15859497 -0.33659783 -1.9706888  -0.01525985 -0.48213387 -1.9718232\n",
      "  0.13033462 -0.45289052 -1.5242791  -0.1562056  -0.33131602 -1.3059571\n",
      " -0.07947725 -0.3071252  -1.3816276  -0.03668487 -0.318145   -1.499182\n",
      "  0.03109001 -0.32807982 -1.3668256 ]\n",
      "data: [ 0.02577697 -0.15378182 -0.27577597  0.05059822 -0.29034364 -0.6979248\n",
      " -0.03204484 -0.46022692 -1.4433258  -0.17535535 -0.51869476 -1.7398922\n",
      " -0.33724308 -0.62583905 -2.2344868  -0.17803922 -0.75030357 -1.618326\n",
      "  0.03599483 -0.774225   -1.4417615  -0.01448804 -0.7123247  -1.4970899\n",
      " -0.01804179 -0.836672   -1.612525   -0.1388172  -0.6497154  -1.5379468\n",
      " -0.05517366 -0.6990608  -1.519305   -0.06898607 -0.6693512  -1.617511\n",
      "  0.05562544 -0.6919224  -1.6657767  -0.05520279 -0.56630665 -1.3681853\n",
      " -0.15859497 -0.33659783 -1.9706888  -0.01525985 -0.48213387 -1.9718232\n",
      "  0.13033462 -0.45289052 -1.5242791  -0.1562056  -0.33131602 -1.3059571\n",
      " -0.07947725 -0.3071252  -1.3816276  -0.03668487 -0.318145   -1.499182\n",
      "  0.03109001 -0.32807982 -1.3668256   0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B320>\n",
      "tensor([[ 0.0547, -0.1774, -0.2551,  ...,  0.0755, -0.3485, -1.3465],\n",
      "        [ 0.0547, -0.1774, -0.2551,  ...,  0.0755, -0.3485, -1.3465],\n",
      "        [ 0.0547, -0.1774, -0.2551,  ...,  0.0755, -0.3485, -1.3465],\n",
      "        ...,\n",
      "        [-0.1004,  0.4604, -0.1229,  ..., -0.6771,  0.9667, -0.4277],\n",
      "        [-0.1602, -0.0484,  0.6275,  ..., -0.2292,  0.6516,  0.3472],\n",
      "        [-0.1602, -0.0484,  0.6275,  ..., -0.2292,  0.6516,  0.3472]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.05468012 -0.17743836 -0.25514713  0.08002298 -0.3230756  -0.6554125\n",
      "  0.02574844 -0.5135211  -1.42289    -0.12023947 -0.5703337  -1.7467151\n",
      " -0.29733962 -0.7043297  -2.2249205  -0.16353086 -0.7760938  -1.629878\n",
      "  0.12355554 -0.80602825 -1.4064565   0.05868271 -0.7601629  -1.4472318\n",
      "  0.04485452 -0.88331956 -1.5713754  -0.10876094 -0.6592874  -1.5265388\n",
      " -0.00517893 -0.72821295 -1.5121953  -0.00347633 -0.7048326  -1.618351\n",
      "  0.10345598 -0.7526781  -1.6793766   0.00346654 -0.562714   -1.3419588\n",
      " -0.13166432 -0.3363611  -2.0079744   0.03615937 -0.5131455  -1.9948766\n",
      "  0.18246779 -0.4682238  -1.5154028  -0.12788938 -0.3174228  -1.276505\n",
      " -0.01383539 -0.29994455 -1.3462415   0.03433095 -0.34412223 -1.4617093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.07547308 -0.34847414 -1.3465416 ]\n",
      "data: [ 0.05468012 -0.17743835 -0.25514713  0.08002298 -0.3230756  -0.6554125\n",
      "  0.02574844 -0.5135211  -1.4228901  -0.12023947 -0.5703337  -1.7467151\n",
      " -0.29733962 -0.7043297  -2.2249205  -0.16353087 -0.7760937  -1.629878\n",
      "  0.12355555 -0.8060282  -1.4064565   0.05868271 -0.7601629  -1.4472318\n",
      "  0.04485452 -0.88331956 -1.5713754  -0.10876094 -0.6592874  -1.5265388\n",
      " -0.00517893 -0.72821295 -1.5121952  -0.00347633 -0.7048326  -1.618351\n",
      "  0.10345598 -0.7526781  -1.6793765   0.00346654 -0.562714   -1.3419588\n",
      " -0.13166432 -0.3363611  -2.0079744   0.03615937 -0.5131455  -1.9948765\n",
      "  0.18246779 -0.4682238  -1.5154028  -0.12788938 -0.3174228  -1.276505\n",
      " -0.01383538 -0.29994455 -1.3462415   0.03433095 -0.34412223 -1.4617093\n",
      "  0.07547308 -0.34847414 -1.3465416   0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EC24940>\n",
      "tensor([[ 0.0015, -0.1673, -0.2024,  ...,  0.0568, -0.3601, -1.2318],\n",
      "        [ 0.0015, -0.1673, -0.2024,  ...,  0.0568, -0.3601, -1.2318],\n",
      "        [ 0.0015, -0.1673, -0.2024,  ...,  0.0568, -0.3601, -1.2318],\n",
      "        ...,\n",
      "        [-0.0325,  0.5492, -0.1583,  ..., -0.5304,  1.0992, -0.5430],\n",
      "        [-0.1303,  0.0149,  0.6086,  ..., -0.1807,  0.6985,  0.2620],\n",
      "        [-0.1303,  0.0149,  0.6086,  ..., -0.1807,  0.6985,  0.2620]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.4665322e-03 -1.6729844e-01 -2.0244174e-01  2.9383618e-02\n",
      " -3.0203640e-01 -5.6086636e-01 -4.8112147e-02 -5.0663257e-01\n",
      " -1.3576707e+00 -1.9819707e-01 -5.6849849e-01 -1.6771080e+00\n",
      " -3.7197328e-01 -7.0288306e-01 -2.1587431e+00 -2.1071927e-01\n",
      " -7.7710110e-01 -1.5561749e+00  5.7935283e-02 -8.2070500e-01\n",
      " -1.3480703e+00 -9.1966689e-03 -7.6699102e-01 -1.3909699e+00\n",
      " -1.9743189e-02 -9.0631372e-01 -1.5162866e+00 -1.5187423e-01\n",
      " -6.6950136e-01 -1.4469200e+00 -5.6850366e-02 -7.4003559e-01\n",
      " -1.4288454e+00 -5.6778111e-02 -7.1606052e-01 -1.5275437e+00\n",
      "  5.8217466e-02 -7.6418275e-01 -1.5728317e+00 -3.8597517e-02\n",
      " -5.7110035e-01 -1.2591339e+00 -1.8202753e-01 -3.4030598e-01\n",
      " -1.9666418e+00 -2.1768510e-03 -5.2662551e-01 -1.9594413e+00\n",
      "  1.5807630e-01 -4.8336202e-01 -1.4071641e+00 -1.6973351e-01\n",
      " -3.3102369e-01 -1.1893541e+00 -5.5873379e-02 -3.1478226e-01\n",
      " -1.2637646e+00 -8.1055611e-03 -3.5365787e-01 -1.3769319e+00\n",
      "  5.6783132e-02 -3.6010689e-01 -1.2317662e+00]\n",
      "data: [ 1.4665322e-03 -1.6729844e-01 -2.0244174e-01  2.9383618e-02\n",
      " -3.0203640e-01 -5.6086636e-01 -4.8112143e-02 -5.0663257e-01\n",
      " -1.3576705e+00 -1.9819707e-01 -5.6849849e-01 -1.6771080e+00\n",
      " -3.7197328e-01 -7.0288306e-01 -2.1587431e+00 -2.1071929e-01\n",
      " -7.7710116e-01 -1.5561749e+00  5.7935283e-02 -8.2070506e-01\n",
      " -1.3480703e+00 -9.1966689e-03 -7.6699102e-01 -1.3909699e+00\n",
      " -1.9743189e-02 -9.0631372e-01 -1.5162866e+00 -1.5187423e-01\n",
      " -6.6950136e-01 -1.4469200e+00 -5.6850366e-02 -7.4003565e-01\n",
      " -1.4288454e+00 -5.6778111e-02 -7.1606046e-01 -1.5275437e+00\n",
      "  5.8217470e-02 -7.6418275e-01 -1.5728317e+00 -3.8597517e-02\n",
      " -5.7110035e-01 -1.2591339e+00 -1.8202753e-01 -3.4030598e-01\n",
      " -1.9666419e+00 -2.1768510e-03 -5.2662551e-01 -1.9594414e+00\n",
      "  1.5807630e-01 -4.8336202e-01 -1.4071641e+00 -1.6973351e-01\n",
      " -3.3102372e-01 -1.1893541e+00 -5.5873379e-02 -3.1478226e-01\n",
      " -1.2637646e+00 -8.1055611e-03 -3.5365787e-01 -1.3769319e+00\n",
      "  5.6783132e-02 -3.6010689e-01 -1.2317662e+00  1.0000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0107, -0.0839, -0.1741,  ...,  0.0118, -0.2723, -1.1744],\n",
      "        [ 0.0107, -0.0839, -0.1741,  ...,  0.0118, -0.2723, -1.1744],\n",
      "        [ 0.0107, -0.0839, -0.1741,  ...,  0.0118, -0.2723, -1.1744],\n",
      "        ...,\n",
      "        [-0.1511,  0.4649, -0.0987,  ..., -0.4949,  1.0334, -0.4685],\n",
      "        [-0.1025, -0.0441,  0.6450,  ..., -0.1783,  0.6476,  0.3258],\n",
      "        [-0.1025, -0.0441,  0.6450,  ..., -0.1783,  0.6476,  0.3258]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01068425 -0.08385826 -0.17412217  0.03671333 -0.1816797  -0.45083442\n",
      " -0.12467207 -0.42494872 -1.3320795  -0.28563517 -0.49429277 -1.6132286\n",
      " -0.42910954 -0.5721192  -2.1431317  -0.186748   -0.73459345 -1.5189402\n",
      " -0.0443702  -0.8128174  -1.3908185  -0.09424964 -0.73019046 -1.4397835\n",
      " -0.09840254 -0.906436   -1.563307   -0.14686924 -0.6507275  -1.416661\n",
      " -0.10379419 -0.6988252  -1.3812131  -0.11481582 -0.65885043 -1.4596909\n",
      "  0.02946389 -0.6882048  -1.4650506  -0.0686793  -0.530067   -1.2672251\n",
      " -0.23344083 -0.29372382 -2.0180366  -0.04860426 -0.46451873 -2.052836\n",
      "  0.13253614 -0.4208818  -1.3461412  -0.19530928 -0.30283788 -1.1821864\n",
      " -0.13728808 -0.2684314  -1.2718092  -0.11188297 -0.2624453  -1.3807954\n",
      "  0.01176339 -0.2723493  -1.1744374 ]\n",
      "data: [ 0.01068425 -0.08385826 -0.17412215  0.03671333 -0.18167968 -0.45083442\n",
      " -0.12467207 -0.42494872 -1.3320794  -0.28563517 -0.49429277 -1.6132286\n",
      " -0.42910954 -0.5721192  -2.1431317  -0.18674798 -0.73459345 -1.5189403\n",
      " -0.0443702  -0.8128174  -1.3908185  -0.09424964 -0.73019046 -1.4397835\n",
      " -0.09840254 -0.906436   -1.563307   -0.14686924 -0.6507275  -1.416661\n",
      " -0.10379419 -0.6988251  -1.3812131  -0.11481582 -0.65885043 -1.4596908\n",
      "  0.02946389 -0.6882048  -1.4650505  -0.0686793  -0.530067   -1.2672251\n",
      " -0.23344083 -0.29372382 -2.0180366  -0.04860426 -0.46451873 -2.052836\n",
      "  0.13253614 -0.4208818  -1.3461412  -0.19530928 -0.30283788 -1.1821864\n",
      " -0.13728808 -0.2684314  -1.2718092  -0.11188297 -0.2624453  -1.3807952\n",
      "  0.01176339 -0.2723493  -1.1744374   0.11      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[-0.0250, -0.0049, -0.1889,  ...,  0.0204, -0.1890, -1.1772],\n",
      "        [-0.0250, -0.0049, -0.1889,  ...,  0.0204, -0.1890, -1.1772],\n",
      "        [-0.0250, -0.0049, -0.1889,  ...,  0.0204, -0.1890, -1.1772],\n",
      "        ...,\n",
      "        [-0.2343,  0.2588, -0.0090,  ..., -0.7576,  0.8531, -0.3949],\n",
      "        [-0.0949, -0.0926,  0.5930,  ..., -0.2534,  0.6143,  0.2667],\n",
      "        [-0.0949, -0.0926,  0.5930,  ..., -0.2534,  0.6143,  0.2667]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.02504722 -0.00485422 -0.18889587 -0.00388054 -0.12362894 -0.5224296\n",
      " -0.12915805 -0.33586937 -1.3293362  -0.28183252 -0.39675474 -1.6238022\n",
      " -0.44831172 -0.5007955  -2.1065676  -0.22924405 -0.6326569  -1.4917133\n",
      " -0.02593423 -0.68090785 -1.3070459  -0.07011542 -0.6088317  -1.3571584\n",
      " -0.06332098 -0.7609292  -1.483413   -0.18312453 -0.5342007  -1.3943264\n",
      " -0.10601859 -0.5885373  -1.3649585  -0.09793799 -0.5535815  -1.4540498\n",
      "  0.06115632 -0.5845629  -1.4885948  -0.08967075 -0.43228936 -1.2251227\n",
      " -0.23248383 -0.19428153 -1.9523525  -0.03960886 -0.3647635  -1.9655216\n",
      "  0.15373757 -0.32265192 -1.3462234  -0.21104288 -0.19543675 -1.1486793\n",
      " -0.13120219 -0.1660825  -1.2349458  -0.08621407 -0.17521542 -1.3535366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.02040605 -0.1889604  -1.177239  ]\n",
      "data: [-0.02504722 -0.00485422 -0.18889588 -0.00388054 -0.12362894 -0.5224296\n",
      " -0.12915805 -0.33586937 -1.3293363  -0.28183252 -0.39675477 -1.6238022\n",
      " -0.44831172 -0.5007955  -2.1065676  -0.22924405 -0.6326569  -1.4917133\n",
      " -0.02593423 -0.68090785 -1.3070459  -0.07011542 -0.6088317  -1.3571583\n",
      " -0.06332098 -0.7609293  -1.483413   -0.18312453 -0.5342007  -1.3943264\n",
      " -0.10601859 -0.5885373  -1.3649585  -0.09793799 -0.5535815  -1.4540498\n",
      "  0.06115632 -0.5845629  -1.4885948  -0.08967075 -0.43228936 -1.2251227\n",
      " -0.23248382 -0.19428153 -1.9523526  -0.03960886 -0.3647635  -1.9655216\n",
      "  0.15373757 -0.32265195 -1.3462234  -0.21104288 -0.19543675 -1.1486793\n",
      " -0.13120219 -0.1660825  -1.2349458  -0.08621407 -0.17521542 -1.3535367\n",
      "  0.02040605 -0.1889604  -1.177239    0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BB38>\n",
      "tensor([[-1.4117e-02, -1.0629e-01, -2.1754e-01,  ...,  1.1134e-03,\n",
      "         -2.6043e-01, -1.3411e+00],\n",
      "        [-1.4117e-02, -1.0629e-01, -2.1754e-01,  ...,  1.1134e-03,\n",
      "         -2.6043e-01, -1.3411e+00],\n",
      "        [-1.4117e-02, -1.0629e-01, -2.1754e-01,  ...,  1.1134e-03,\n",
      "         -2.6043e-01, -1.3411e+00],\n",
      "        ...,\n",
      "        [-2.4437e-01,  3.6164e-01, -1.7627e-01,  ..., -7.4369e-01,\n",
      "          8.2429e-01, -3.5355e-01],\n",
      "        [-1.5972e-01, -7.6668e-02,  5.6868e-01,  ..., -2.6058e-01,\n",
      "          6.9671e-01,  2.7271e-01],\n",
      "        [-1.5972e-01, -7.6668e-02,  5.6868e-01,  ..., -2.6058e-01,\n",
      "          6.9671e-01,  2.7271e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-1.4116932e-02 -1.0628925e-01 -2.1754164e-01  4.9256422e-03\n",
      " -2.6683432e-01 -6.8851852e-01 -4.3681771e-02 -4.1351128e-01\n",
      " -1.3777468e+00 -1.8459302e-01 -4.6680015e-01 -1.6865122e+00\n",
      " -3.6295658e-01 -5.9747958e-01 -2.1546836e+00 -2.3497109e-01\n",
      " -6.8429077e-01 -1.5439150e+00  3.2735497e-02 -6.8325520e-01\n",
      " -1.3218961e+00 -1.7511874e-02 -6.2895739e-01 -1.3752799e+00\n",
      " -1.9702606e-02 -7.2685409e-01 -1.4920585e+00 -1.9179593e-01\n",
      " -5.6842577e-01 -1.4691386e+00 -7.9849564e-02 -6.2186641e-01\n",
      " -1.4567137e+00 -8.3568588e-02 -5.9112453e-01 -1.5659597e+00\n",
      "  4.2150110e-02 -6.1451274e-01 -1.6379855e+00 -9.1077693e-02\n",
      " -4.9632579e-01 -1.2890387e+00 -1.7196536e-01 -2.6690751e-01\n",
      " -1.8243818e+00 -3.7987657e-02 -4.0604085e-01 -1.8057485e+00\n",
      "  1.0743885e-01 -3.7656260e-01 -1.4893718e+00 -1.9164215e-01\n",
      " -2.4987139e-01 -1.2378733e+00 -9.5083848e-02 -2.2864823e-01\n",
      " -1.3134031e+00 -4.0959716e-02 -2.5472298e-01 -1.4369071e+00\n",
      "  1.1134222e-03 -2.6043469e-01 -1.3410611e+00]\n",
      "data: [-1.4116932e-02 -1.0628925e-01 -2.1754164e-01  4.9256422e-03\n",
      " -2.6683432e-01 -6.8851852e-01 -4.3681771e-02 -4.1351128e-01\n",
      " -1.3777469e+00 -1.8459302e-01 -4.6680015e-01 -1.6865124e+00\n",
      " -3.6295658e-01 -5.9747958e-01 -2.1546836e+00 -2.3497109e-01\n",
      " -6.8429077e-01 -1.5439152e+00  3.2735497e-02 -6.8325514e-01\n",
      " -1.3218961e+00 -1.7511874e-02 -6.2895739e-01 -1.3752799e+00\n",
      " -1.9702606e-02 -7.2685409e-01 -1.4920585e+00 -1.9179592e-01\n",
      " -5.6842577e-01 -1.4691386e+00 -7.9849564e-02 -6.2186641e-01\n",
      " -1.4567137e+00 -8.3568595e-02 -5.9112453e-01 -1.5659596e+00\n",
      "  4.2150110e-02 -6.1451274e-01 -1.6379856e+00 -9.1077693e-02\n",
      " -4.9632579e-01 -1.2890387e+00 -1.7196538e-01 -2.6690751e-01\n",
      " -1.8243818e+00 -3.7987657e-02 -4.0604085e-01 -1.8057485e+00\n",
      "  1.0743885e-01 -3.7656257e-01 -1.4893718e+00 -1.9164215e-01\n",
      " -2.4987139e-01 -1.2378733e+00 -9.5083848e-02 -2.2864823e-01\n",
      " -1.3134031e+00 -4.0959716e-02 -2.5472298e-01 -1.4369071e+00\n",
      "  1.1134222e-03 -2.6043469e-01 -1.3410611e+00  1.3000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0599, -0.1391, -0.2896,  ...,  0.0540, -0.3150, -1.3435],\n",
      "        [ 0.0599, -0.1391, -0.2896,  ...,  0.0540, -0.3150, -1.3435],\n",
      "        [ 0.0599, -0.1391, -0.2896,  ...,  0.0540, -0.3150, -1.3435],\n",
      "        ...,\n",
      "        [-0.1677,  0.4858, -0.1312,  ..., -0.7331,  1.0188, -0.4445],\n",
      "        [-0.1839, -0.1000,  0.6370,  ..., -0.2633,  0.6632,  0.3194],\n",
      "        [-0.1839, -0.1000,  0.6370,  ..., -0.2633,  0.6632,  0.3194]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 5.9888292e-02 -1.3905683e-01 -2.8956181e-01  9.2326537e-02\n",
      " -2.5278413e-01 -6.6489142e-01 -2.8154880e-02 -4.6060902e-01\n",
      " -1.4744730e+00 -1.7547959e-01 -5.2369165e-01 -1.7642119e+00\n",
      " -3.1699812e-01 -6.1050403e-01 -2.2774720e+00 -1.3185854e-01\n",
      " -7.6304799e-01 -1.6421961e+00  4.0472373e-02 -8.1438953e-01\n",
      " -1.4828291e+00 -1.3261333e-02 -7.4287134e-01 -1.5400237e+00\n",
      " -3.2353975e-02 -8.9819556e-01 -1.6633936e+00 -9.5439881e-02\n",
      " -6.7516637e-01 -1.5506183e+00 -3.9878726e-02 -7.2138768e-01\n",
      " -1.5260372e+00 -6.3552544e-02 -6.8630701e-01 -1.6118748e+00\n",
      "  5.9464037e-02 -7.1423072e-01 -1.6353002e+00 -2.0231776e-02\n",
      " -5.6642276e-01 -1.3925121e+00 -1.6107599e-01 -3.3237723e-01\n",
      " -2.0982211e+00  3.9714575e-04 -4.9096382e-01 -2.1208396e+00\n",
      "  1.5092184e-01 -4.5477498e-01 -1.5070915e+00 -1.3004468e-01\n",
      " -3.3998781e-01 -1.3164505e+00 -6.8546370e-02 -3.0625379e-01\n",
      " -1.4020097e+00 -3.8819075e-02 -3.0455324e-01 -1.5164182e+00\n",
      "  5.3973578e-02 -3.1504059e-01 -1.3434833e+00]\n",
      "data: [ 5.9888292e-02 -1.3905683e-01 -2.8956181e-01  9.2326537e-02\n",
      " -2.5278413e-01 -6.6489142e-01 -2.8154878e-02 -4.6060902e-01\n",
      " -1.4744730e+00 -1.7547959e-01 -5.2369165e-01 -1.7642119e+00\n",
      " -3.1699812e-01 -6.1050403e-01 -2.2774720e+00 -1.3185854e-01\n",
      " -7.6304799e-01 -1.6421961e+00  4.0472373e-02 -8.1438947e-01\n",
      " -1.4828291e+00 -1.3261332e-02 -7.4287134e-01 -1.5400237e+00\n",
      " -3.2353975e-02 -8.9819556e-01 -1.6633935e+00 -9.5439881e-02\n",
      " -6.7516637e-01 -1.5506183e+00 -3.9878726e-02 -7.2138768e-01\n",
      " -1.5260373e+00 -6.3552544e-02 -6.8630701e-01 -1.6118748e+00\n",
      "  5.9464034e-02 -7.1423072e-01 -1.6353002e+00 -2.0231776e-02\n",
      " -5.6642276e-01 -1.3925121e+00 -1.6107599e-01 -3.3237725e-01\n",
      " -2.0982211e+00  3.9714575e-04 -4.9096382e-01 -2.1208396e+00\n",
      "  1.5092184e-01 -4.5477498e-01 -1.5070915e+00 -1.3004468e-01\n",
      " -3.3998784e-01 -1.3164505e+00 -6.8546370e-02 -3.0625379e-01\n",
      " -1.4020097e+00 -3.8819075e-02 -3.0455324e-01 -1.5164181e+00\n",
      "  5.3973578e-02 -3.1504059e-01 -1.3434833e+00  1.4000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0019, -0.0965, -0.1884,  ...,  0.0747, -0.2911, -1.2397],\n",
      "        [ 0.0019, -0.0965, -0.1884,  ...,  0.0747, -0.2911, -1.2397],\n",
      "        [ 0.0019, -0.0965, -0.1884,  ...,  0.0747, -0.2911, -1.2397],\n",
      "        ...,\n",
      "        [-0.1265,  0.4071, -0.0754,  ..., -0.8255,  0.9085, -0.3379],\n",
      "        [-0.1080, -0.0789,  0.5376,  ..., -0.1846,  0.6079,  0.1794],\n",
      "        [-0.1080, -0.0789,  0.5376,  ..., -0.1846,  0.6079,  0.1794]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.9021975e-03 -9.6525013e-02 -1.8835917e-01  1.6723949e-02\n",
      " -2.4685967e-01 -5.7905394e-01 -2.6626475e-02 -4.2379278e-01\n",
      " -1.3159966e+00 -1.6892001e-01 -4.7911161e-01 -1.6436403e+00\n",
      " -3.5634720e-01 -6.2900782e-01 -2.0992937e+00 -2.1772625e-01\n",
      " -6.8775249e-01 -1.5167965e+00  7.9360470e-02 -7.1078569e-01\n",
      " -1.3161132e+00  1.5090093e-02 -6.6589653e-01 -1.3575857e+00\n",
      "  2.6858285e-02 -7.8579456e-01 -1.4762073e+00 -1.5309335e-01\n",
      " -5.6927943e-01 -1.4144953e+00 -3.6454186e-02 -6.4132398e-01\n",
      " -1.4038728e+00 -2.5459737e-02 -6.2585664e-01 -1.5146294e+00\n",
      "  8.9977264e-02 -6.7143160e-01 -1.5807904e+00 -3.1017460e-02\n",
      " -4.8666853e-01 -1.2218776e+00 -1.4812438e-01 -2.6552391e-01\n",
      " -1.8648740e+00  2.0045057e-02 -4.4201273e-01 -1.8431746e+00\n",
      "  1.7757036e-01 -4.0432549e-01 -1.4081585e+00 -1.5495124e-01\n",
      " -2.4100041e-01 -1.1628274e+00 -2.6707038e-02 -2.3447157e-01\n",
      " -1.2358127e+00  2.9629275e-02 -2.8441745e-01 -1.3520322e+00\n",
      "  7.4747182e-02 -2.9105690e-01 -1.2397416e+00]\n",
      "data: [ 1.9021975e-03 -9.6525013e-02 -1.8835917e-01  1.6723949e-02\n",
      " -2.4685967e-01 -5.7905394e-01 -2.6626475e-02 -4.2379275e-01\n",
      " -1.3159966e+00 -1.6892000e-01 -4.7911158e-01 -1.6436403e+00\n",
      " -3.5634720e-01 -6.2900782e-01 -2.0992937e+00 -2.1772625e-01\n",
      " -6.8775249e-01 -1.5167965e+00  7.9360470e-02 -7.1078569e-01\n",
      " -1.3161132e+00  1.5090094e-02 -6.6589653e-01 -1.3575855e+00\n",
      "  2.6858285e-02 -7.8579450e-01 -1.4762073e+00 -1.5309335e-01\n",
      " -5.6927943e-01 -1.4144953e+00 -3.6454186e-02 -6.4132398e-01\n",
      " -1.4038728e+00 -2.5459738e-02 -6.2585664e-01 -1.5146294e+00\n",
      "  8.9977264e-02 -6.7143160e-01 -1.5807904e+00 -3.1017460e-02\n",
      " -4.8666850e-01 -1.2218776e+00 -1.4812438e-01 -2.6552391e-01\n",
      " -1.8648740e+00  2.0045057e-02 -4.4201270e-01 -1.8431746e+00\n",
      "  1.7757036e-01 -4.0432549e-01 -1.4081585e+00 -1.5495124e-01\n",
      " -2.4100040e-01 -1.1628274e+00 -2.6707038e-02 -2.3447157e-01\n",
      " -1.2358127e+00  2.9629275e-02 -2.8441745e-01 -1.3520322e+00\n",
      "  7.4747182e-02 -2.9105690e-01 -1.2397416e+00  1.5000001e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[ 0.0363, -0.0806, -0.2449,  ...,  0.0260, -0.2651, -1.2633],\n",
      "        [ 0.0363, -0.0806, -0.2449,  ...,  0.0260, -0.2651, -1.2633],\n",
      "        [ 0.0363, -0.0806, -0.2449,  ...,  0.0260, -0.2651, -1.2633],\n",
      "        ...,\n",
      "        [-0.1528,  0.4373, -0.1208,  ..., -0.5190,  0.9447, -0.4513],\n",
      "        [-0.1610, -0.0830,  0.6309,  ..., -0.2315,  0.6821,  0.2811],\n",
      "        [-0.1610, -0.0830,  0.6309,  ..., -0.2315,  0.6821,  0.2811]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03634242 -0.08055389 -0.24486837  0.06477211 -0.19333732 -0.5954089\n",
      " -0.08313329 -0.4181145  -1.433754   -0.23471758 -0.4899483  -1.7134815\n",
      " -0.3832736  -0.5688965  -2.224575   -0.15342093 -0.7224599  -1.5884947\n",
      " -0.00682851 -0.7846605  -1.4104317  -0.05585264 -0.7076571  -1.4690768\n",
      " -0.07763849 -0.87463564 -1.5939505  -0.12168831 -0.63400316 -1.4974883\n",
      " -0.07898854 -0.68031067 -1.4587874  -0.1059595  -0.6455362  -1.5378532\n",
      "  0.03336933 -0.6663355  -1.5523883  -0.05425443 -0.52360225 -1.3426491\n",
      " -0.20480126 -0.28942335 -2.0773897  -0.03811326 -0.44843167 -2.1066802\n",
      "  0.12715906 -0.4129871  -1.423699   -0.16151822 -0.2955209  -1.261665\n",
      " -0.1160142  -0.26123795 -1.349798   -0.08795456 -0.24884538 -1.4635589\n",
      "  0.02601358 -0.26505357 -1.2633438 ]\n",
      "data: [ 0.03634242 -0.0805539  -0.24486837  0.06477211 -0.19333732 -0.5954089\n",
      " -0.08313329 -0.4181145  -1.433754   -0.23471758 -0.4899483  -1.7134815\n",
      " -0.38327363 -0.5688965  -2.224575   -0.15342093 -0.72246    -1.5884948\n",
      " -0.00682851 -0.7846605  -1.4104316  -0.05585264 -0.7076571  -1.4690766\n",
      " -0.07763849 -0.87463564 -1.5939505  -0.12168832 -0.63400316 -1.4974883\n",
      " -0.07898854 -0.68031067 -1.4587874  -0.1059595  -0.6455362  -1.5378532\n",
      "  0.03336933 -0.6663355  -1.5523883  -0.05425443 -0.52360225 -1.3426491\n",
      " -0.20480126 -0.28942335 -2.0773897  -0.03811326 -0.44843167 -2.1066802\n",
      "  0.12715906 -0.4129871  -1.423699   -0.16151822 -0.2955209  -1.261665\n",
      " -0.1160142  -0.26123795 -1.349798   -0.08795456 -0.24884538 -1.4635589\n",
      "  0.02601358 -0.26505357 -1.2633438   0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0061, -0.0523, -0.1718,  ...,  0.0771, -0.2439, -1.1861],\n",
      "        [ 0.0061, -0.0523, -0.1718,  ...,  0.0771, -0.2439, -1.1861],\n",
      "        [ 0.0061, -0.0523, -0.1718,  ...,  0.0771, -0.2439, -1.1861],\n",
      "        ...,\n",
      "        [-0.1521,  0.3242, -0.1092,  ..., -0.8516,  0.8026, -0.3283],\n",
      "        [-0.1415, -0.1435,  0.5084,  ..., -0.2479,  0.5555,  0.1602],\n",
      "        [-0.1415, -0.1435,  0.5084,  ..., -0.2479,  0.5555,  0.1602]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 6.1160820e-03 -5.2255385e-02 -1.7175117e-01  2.6632827e-02\n",
      " -1.8244284e-01 -5.2711415e-01 -5.0904088e-02 -3.7207305e-01\n",
      " -1.2933398e+00 -1.9550350e-01 -4.2762071e-01 -1.6114833e+00\n",
      " -3.7600940e-01 -5.5830580e-01 -2.0768116e+00 -2.0260046e-01\n",
      " -6.5801537e-01 -1.4692428e+00  5.2302048e-02 -6.9222158e-01\n",
      " -1.2875494e+00 -7.1789324e-03 -6.3597077e-01 -1.3338552e+00\n",
      "  3.3339858e-04 -7.7684861e-01 -1.4561498e+00 -1.4313473e-01\n",
      " -5.5333585e-01 -1.3664839e+00 -4.5152158e-02 -6.1721611e-01\n",
      " -1.3542222e+00 -3.9635345e-02 -5.9382039e-01 -1.4602106e+00\n",
      "  9.1184139e-02 -6.3568968e-01 -1.5123637e+00 -3.4494303e-02\n",
      " -4.6140271e-01 -1.1832254e+00 -1.6827209e-01 -2.3080100e-01\n",
      " -1.9039347e+00  1.6795471e-02 -4.0775234e-01 -1.9007040e+00\n",
      "  1.8563135e-01 -3.7050664e-01 -1.3519014e+00 -1.5593924e-01\n",
      " -2.2237021e-01 -1.1179463e+00 -4.8367009e-02 -2.0737824e-01\n",
      " -1.2051052e+00  2.1690875e-03 -2.3675089e-01 -1.3261769e+00\n",
      "  7.7122055e-02 -2.4385640e-01 -1.1861356e+00]\n",
      "data: [ 6.1160820e-03 -5.2255381e-02 -1.7175117e-01  2.6632827e-02\n",
      " -1.8244284e-01 -5.2711415e-01 -5.0904088e-02 -3.7207305e-01\n",
      " -1.2933398e+00 -1.9550350e-01 -4.2762071e-01 -1.6114833e+00\n",
      " -3.7600940e-01 -5.5830580e-01 -2.0768116e+00 -2.0260046e-01\n",
      " -6.5801537e-01 -1.4692428e+00  5.2302048e-02 -6.9222158e-01\n",
      " -1.2875495e+00 -7.1789324e-03 -6.3597077e-01 -1.3338552e+00\n",
      "  3.3339858e-04 -7.7684861e-01 -1.4561497e+00 -1.4313473e-01\n",
      " -5.5333585e-01 -1.3664839e+00 -4.5152158e-02 -6.1721611e-01\n",
      " -1.3542221e+00 -3.9635345e-02 -5.9382039e-01 -1.4602106e+00\n",
      "  9.1184139e-02 -6.3568968e-01 -1.5123638e+00 -3.4494303e-02\n",
      " -4.6140271e-01 -1.1832254e+00 -1.6827209e-01 -2.3080102e-01\n",
      " -1.9039348e+00  1.6795471e-02 -4.0775234e-01 -1.9007040e+00\n",
      "  1.8563135e-01 -3.7050664e-01 -1.3519014e+00 -1.5593924e-01\n",
      " -2.2237021e-01 -1.1179463e+00 -4.8367009e-02 -2.0737824e-01\n",
      " -1.2051052e+00  2.1690875e-03 -2.3675089e-01 -1.3261769e+00\n",
      "  7.7122055e-02 -2.4385639e-01 -1.1861356e+00  1.7000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63E80>\n",
      "tensor([[ 0.0292, -0.0885, -0.2523,  ...,  0.0335, -0.2658, -1.3046],\n",
      "        [ 0.0292, -0.0885, -0.2523,  ...,  0.0335, -0.2658, -1.3046],\n",
      "        [ 0.0292, -0.0885, -0.2523,  ...,  0.0335, -0.2658, -1.3046],\n",
      "        ...,\n",
      "        [-0.2784,  0.2952, -0.2569,  ..., -0.7180,  0.7472, -0.4884],\n",
      "        [-0.1232, -0.0142,  0.6191,  ..., -0.2114,  0.7725,  0.2678],\n",
      "        [-0.1232, -0.0142,  0.6191,  ..., -0.2114,  0.7725,  0.2678]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02920463 -0.08846061 -0.25226432  0.05141481 -0.2252823  -0.66327953\n",
      " -0.06277768 -0.42604    -1.4504088  -0.21009396 -0.49424464 -1.7405143\n",
      " -0.37678224 -0.5958942  -2.223628   -0.17651112 -0.70477015 -1.6046387\n",
      "  0.01724681 -0.7463127  -1.3895174  -0.03102998 -0.6795564  -1.4448541\n",
      " -0.04875886 -0.8225461  -1.5646961  -0.13818437 -0.6011196  -1.5180134\n",
      " -0.07142089 -0.65621215 -1.4800673  -0.09075962 -0.6296723  -1.5683457\n",
      "  0.0447408  -0.6492218  -1.6079472  -0.05835927 -0.51060575 -1.349816\n",
      " -0.18486367 -0.2803796  -2.0144234  -0.03007823 -0.43671858 -2.021676\n",
      "  0.12731554 -0.4027593  -1.4612591  -0.15923232 -0.27373296 -1.2786535\n",
      " -0.09697072 -0.24614668 -1.3559965  -0.05235951 -0.2511168  -1.471987\n",
      "  0.03351507 -0.26580524 -1.3046184 ]\n",
      "data: [ 0.02920463 -0.08846061 -0.25226432  0.05141481 -0.22528228 -0.6632796\n",
      " -0.06277768 -0.42604    -1.4504088  -0.21009396 -0.49424466 -1.7405143\n",
      " -0.37678224 -0.5958942  -2.223628   -0.17651111 -0.70477015 -1.6046387\n",
      "  0.01724681 -0.74631274 -1.3895173  -0.03102998 -0.6795564  -1.4448541\n",
      " -0.04875886 -0.8225462  -1.5646961  -0.13818437 -0.6011196  -1.5180134\n",
      " -0.07142089 -0.65621215 -1.4800673  -0.09075962 -0.6296723  -1.5683457\n",
      "  0.0447408  -0.6492218  -1.6079472  -0.05835928 -0.51060575 -1.349816\n",
      " -0.18486366 -0.2803796  -2.0144234  -0.03007823 -0.43671858 -2.021676\n",
      "  0.12731554 -0.4027593  -1.4612591  -0.15923232 -0.27373296 -1.2786535\n",
      " -0.09697072 -0.24614668 -1.3559966  -0.05235951 -0.2511168  -1.471987\n",
      "  0.03351507 -0.26580524 -1.3046184   0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EC24D30>\n",
      "tensor([[-0.0057, -0.0406, -0.2050,  ...,  0.0381, -0.2301, -1.2473],\n",
      "        [-0.0057, -0.0406, -0.2050,  ...,  0.0381, -0.2301, -1.2473],\n",
      "        [-0.0057, -0.0406, -0.2050,  ...,  0.0381, -0.2301, -1.2473],\n",
      "        ...,\n",
      "        [-0.1839,  0.3584, -0.1936,  ..., -0.8615,  0.8209, -0.3876],\n",
      "        [-0.1485, -0.1782,  0.5604,  ..., -0.2410,  0.5494,  0.2572],\n",
      "        [-0.1485, -0.1782,  0.5604,  ..., -0.2410,  0.5494,  0.2572]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.00574155 -0.04064157 -0.20495477  0.0074045  -0.18337367 -0.6075455\n",
      " -0.06442695 -0.36307892 -1.3329538  -0.20573494 -0.42080474 -1.6403842\n",
      " -0.3802992  -0.5471077  -2.102023   -0.21422137 -0.64354336 -1.5047826\n",
      "  0.0258828  -0.67049015 -1.3180472  -0.02914667 -0.6145667  -1.3690188\n",
      " -0.02479465 -0.7458689  -1.4860171  -0.16351357 -0.5346724  -1.4163653\n",
      " -0.06906635 -0.5947459  -1.3990446  -0.07174318 -0.57322156 -1.4993758\n",
      "  0.053929   -0.6056256  -1.5508785  -0.06121986 -0.4470584  -1.2427602\n",
      " -0.17724852 -0.22528777 -1.8889731  -0.01685116 -0.38762674 -1.8824506\n",
      "  0.13882397 -0.3539789  -1.4023173  -0.17010121 -0.21021438 -1.181607\n",
      " -0.07458717 -0.19440383 -1.2618905  -0.02846988 -0.21915364 -1.380451\n",
      "  0.03809079 -0.23014332 -1.2472887 ]\n",
      "data: [-0.00574155 -0.04064157 -0.20495477  0.0074045  -0.18337367 -0.6075455\n",
      " -0.06442695 -0.36307892 -1.3329538  -0.20573494 -0.42080474 -1.6403842\n",
      " -0.3802992  -0.5471077  -2.102023   -0.21422139 -0.6435434  -1.5047826\n",
      "  0.0258828  -0.6704901  -1.3180472  -0.02914667 -0.6145667  -1.3690189\n",
      " -0.02479465 -0.7458689  -1.4860171  -0.16351357 -0.5346724  -1.4163651\n",
      " -0.06906635 -0.5947459  -1.3990446  -0.07174318 -0.57322156 -1.4993758\n",
      "  0.053929   -0.6056256  -1.5508786  -0.06121986 -0.4470584  -1.2427602\n",
      " -0.17724852 -0.22528777 -1.8889731  -0.01685116 -0.38762674 -1.8824506\n",
      "  0.13882397 -0.35397893 -1.4023174  -0.17010121 -0.21021439 -1.181607\n",
      " -0.07458717 -0.19440383 -1.2618905  -0.02846988 -0.21915363 -1.3804508\n",
      "  0.03809079 -0.23014332 -1.2472887   0.19      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0097, -0.0601, -0.2518,  ...,  0.0116, -0.2403, -1.2922],\n",
      "        [ 0.0097, -0.0601, -0.2518,  ...,  0.0116, -0.2403, -1.2922],\n",
      "        [ 0.0097, -0.0601, -0.2518,  ...,  0.0116, -0.2403, -1.2922],\n",
      "        ...,\n",
      "        [-0.3420,  0.2331, -0.3372,  ..., -0.8213,  0.6778, -0.5187],\n",
      "        [-0.1071, -0.0546,  0.6251,  ..., -0.2148,  0.7396,  0.2840],\n",
      "        [-0.1071, -0.0546,  0.6251,  ..., -0.2148,  0.7396,  0.2840]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00965337 -0.06014431 -0.25178576  0.0365099  -0.18602896 -0.6511396\n",
      " -0.08320934 -0.38038123 -1.4356712  -0.22693649 -0.44614133 -1.7191203\n",
      " -0.38137752 -0.5362582  -2.2135122  -0.18318549 -0.6753818  -1.585106\n",
      " -0.01616012 -0.71574557 -1.4107072  -0.06162827 -0.6446952  -1.4709274\n",
      " -0.07226404 -0.79257643 -1.5888387  -0.14995259 -0.5815363  -1.5029416\n",
      " -0.08936834 -0.62885743 -1.467853   -0.11475205 -0.59954256 -1.5550371\n",
      "  0.02227094 -0.6161338  -1.5870327  -0.07983735 -0.4892879  -1.3406116\n",
      " -0.20193967 -0.25893825 -2.0101824  -0.05018073 -0.40813684 -2.0262856\n",
      "  0.10482802 -0.38006425 -1.4490161  -0.17444605 -0.25961947 -1.269385\n",
      " -0.12139574 -0.23030823 -1.3487222  -0.08324679 -0.224626   -1.4660519\n",
      "  0.01164335 -0.24034831 -1.2922077 ]\n",
      "data: [ 0.00965337 -0.06014431 -0.25178576  0.0365099  -0.18602896 -0.6511396\n",
      " -0.08320934 -0.38038123 -1.4356712  -0.22693649 -0.44614133 -1.7191204\n",
      " -0.38137752 -0.5362582  -2.2135122  -0.18318549 -0.6753818  -1.585106\n",
      " -0.01616012 -0.71574557 -1.4107072  -0.06162827 -0.6446952  -1.4709275\n",
      " -0.07226404 -0.79257643 -1.5888387  -0.14995259 -0.5815363  -1.5029416\n",
      " -0.08936834 -0.62885743 -1.467853   -0.11475205 -0.59954256 -1.555037\n",
      "  0.02227094 -0.6161338  -1.5870327  -0.07983735 -0.4892879  -1.3406116\n",
      " -0.20193967 -0.25893825 -2.0101824  -0.05018073 -0.4081368  -2.0262856\n",
      "  0.10482802 -0.38006425 -1.4490161  -0.17444605 -0.25961947 -1.269385\n",
      " -0.12139574 -0.23030823 -1.3487222  -0.0832468  -0.224626   -1.4660519\n",
      "  0.01164335 -0.2403483  -1.2922076   0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[0.    0.    0.    ... 3.781 3.781 3.792]\n",
      " [0.    0.    0.    ... 3.788 3.775 3.788]\n",
      " [0.    0.    0.    ... 3.77  3.777 3.79 ]\n",
      " ...\n",
      " [3.535 3.535 3.524 ... 3.539 3.547 3.545]\n",
      " [3.499 3.499 3.497 ... 3.521 3.524 3.536]\n",
      " [3.482 3.482 3.487 ... 3.506 3.504 3.507]]\n",
      "imask:  [[1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " [1. 1. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[ 0.0407, -0.0223, -0.2017,  ...,  0.0538, -0.2177, -1.2388],\n",
      "        [ 0.0407, -0.0223, -0.2017,  ...,  0.0538, -0.2177, -1.2388],\n",
      "        [ 0.0407, -0.0223, -0.2017,  ...,  0.0538, -0.2177, -1.2388],\n",
      "        ...,\n",
      "        [-0.2207,  0.3271, -0.1879,  ..., -0.9021,  0.7740, -0.3254],\n",
      "        [-0.1492, -0.2213,  0.5179,  ..., -0.2099,  0.5288,  0.2294],\n",
      "        [-0.1492, -0.2213,  0.5179,  ..., -0.2099,  0.5288,  0.2294]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04068564 -0.02226892 -0.20166078  0.05100074 -0.15462005 -0.5924794\n",
      " -0.06170677 -0.33917588 -1.338419   -0.20954025 -0.40430766 -1.6251607\n",
      " -0.38158402 -0.500801   -2.1078842  -0.15386003 -0.64465886 -1.4924672\n",
      "  0.00617813 -0.68435127 -1.3400877  -0.03999756 -0.61022466 -1.4021952\n",
      " -0.03237147 -0.7599564  -1.512125   -0.11622887 -0.54788756 -1.4158998\n",
      " -0.0530078  -0.59386605 -1.3821476  -0.07610276 -0.5720557  -1.4776015\n",
      "  0.06450751 -0.5786118  -1.507026   -0.04352954 -0.46157032 -1.2578244\n",
      " -0.15380877 -0.23976858 -1.9061115  -0.00985651 -0.38215607 -1.9192252\n",
      "  0.14938527 -0.35919237 -1.3777728  -0.13265562 -0.23081216 -1.195853\n",
      " -0.08098725 -0.21055308 -1.2866325  -0.04545341 -0.20326845 -1.4044282\n",
      "  0.05384505 -0.21769258 -1.2388291 ]\n",
      "data: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "mask: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[-0.0333,  0.0448,  0.4349,  ..., -0.2319, -0.0727, -0.3665],\n",
      "        [-0.0333,  0.0448,  0.4349,  ..., -0.2319, -0.0727, -0.3665],\n",
      "        [-0.0333,  0.0448,  0.4349,  ..., -0.2319, -0.0727, -0.3665],\n",
      "        ...,\n",
      "        [ 0.3777,  0.0338, -0.4249,  ...,  0.2617,  0.7308, -0.4466],\n",
      "        [ 0.3953,  0.0267, -0.4035,  ...,  0.2826,  0.7878, -0.4917],\n",
      "        [ 0.3953,  0.0267, -0.4035,  ...,  0.2826,  0.7878, -0.4917]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.03331171  0.04475227  0.43488228 -0.08014037 -0.1283966   0.04251438\n",
      " -0.43275732 -0.30288675 -0.52919793 -0.6339379  -0.4416606  -0.64817005\n",
      " -0.92006445 -0.45257625 -1.0338042  -0.32898337 -0.5638237  -0.5347692\n",
      " -0.48484027 -0.5967127  -0.22969621 -0.4647954  -0.4992316  -0.28106982\n",
      " -0.5385193  -0.63992906 -0.29921997 -0.30783296 -0.44557652 -0.56127876\n",
      " -0.40865445 -0.4935944  -0.37488335 -0.53361404 -0.46619457 -0.43082047\n",
      " -0.28280222 -0.36111313 -0.51204956 -0.349191   -0.46142566 -0.4435553\n",
      " -0.3940547  -0.24101767 -0.6121369  -0.40089983 -0.258882   -0.64137584\n",
      " -0.26609105 -0.26819363 -0.39044648 -0.29307145 -0.20285279 -0.41877973\n",
      " -0.48265147 -0.14345443 -0.4460817  -0.39757866 -0.02279501 -0.5691981\n",
      " -0.23187025 -0.07268029 -0.3664986 ]\n",
      "init: [-0.03331171  0.04475227  0.43488228 -0.08014037 -0.1283966   0.04251438\n",
      " -0.43275732 -0.30288675 -0.52919793 -0.6339379  -0.4416606  -0.64817005\n",
      " -0.92006445 -0.45257625 -1.0338042  -0.32898337 -0.5638237  -0.5347692\n",
      " -0.48484027 -0.5967127  -0.22969621 -0.4647954  -0.4992316  -0.28106982\n",
      " -0.5385193  -0.63992906 -0.29921997 -0.30783296 -0.44557652 -0.56127876\n",
      " -0.40865445 -0.4935944  -0.37488335 -0.53361404 -0.46619457 -0.43082047\n",
      " -0.28280222 -0.36111313 -0.51204956 -0.349191   -0.46142566 -0.4435553\n",
      " -0.3940547  -0.24101767 -0.6121369  -0.40089983 -0.258882   -0.64137584\n",
      " -0.26609105 -0.26819363 -0.39044648 -0.29307145 -0.20285279 -0.41877973\n",
      " -0.48265147 -0.14345443 -0.4460817  -0.39757866 -0.02279501 -0.5691981\n",
      " -0.23187025 -0.07268029 -0.3664986 ]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [-0.03331171  0.04475227  0.43488228 -0.08014037 -0.1283966   0.04251438\n",
      " -0.4327573  -0.30288675 -0.52919793 -0.6339379  -0.4416606  -0.6481701\n",
      " -0.92006445 -0.45257625 -1.0338042  -0.3289834  -0.5638237  -0.5347692\n",
      " -0.48484027 -0.5967127  -0.22969621 -0.4647954  -0.4992316  -0.28106982\n",
      " -0.5385193  -0.63992906 -0.29921997 -0.30783296 -0.44557652 -0.56127876\n",
      " -0.40865445 -0.4935944  -0.37488335 -0.53361404 -0.46619457 -0.43082047\n",
      " -0.28280222 -0.36111313 -0.51204956 -0.349191   -0.46142566 -0.4435553\n",
      " -0.3940547  -0.24101767 -0.6121369  -0.4008998  -0.258882   -0.6413758\n",
      " -0.26609105 -0.26819363 -0.39044648 -0.29307145 -0.20285279 -0.41877973\n",
      " -0.48265147 -0.14345443 -0.4460817  -0.39757866 -0.02279501 -0.5691981\n",
      " -0.23187025 -0.07268029 -0.3664986   0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0976, -0.1282, -0.0014,  ..., -0.1768, -0.3206, -0.4777],\n",
      "        [ 0.0976, -0.1282, -0.0014,  ..., -0.1768, -0.3206, -0.4777],\n",
      "        [ 0.0976, -0.1282, -0.0014,  ..., -0.1768, -0.3206, -0.4777],\n",
      "        ...,\n",
      "        [ 0.3807, -0.3220,  0.1800,  ...,  0.0255,  0.4814, -0.7080],\n",
      "        [ 0.2470, -0.0607,  0.3909,  ..., -0.2374,  0.5988, -0.3907],\n",
      "        [ 0.2470, -0.0607,  0.3909,  ..., -0.2374,  0.5988, -0.3907]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.09764333 -0.12818111 -0.00139142  0.01448007 -0.21023431 -0.21530163\n",
      " -0.19374429 -0.3714562  -0.6253542  -0.37554568 -0.43195403 -0.8070229\n",
      " -0.6704508  -0.44929424 -1.1941503  -0.23161386 -0.6267141  -0.80595434\n",
      " -0.49900675 -0.64790744 -1.1695795  -0.50235474 -0.5776095  -1.1860143\n",
      " -0.41920716 -0.7813401  -1.1322979  -0.17645065 -0.54897135 -0.7414032\n",
      " -0.28347117 -0.59008485 -0.56041884 -0.39183152 -0.6059165  -0.66071415\n",
      " -0.27003443 -0.5561799  -0.7184459  -0.17070954 -0.496056   -0.6637727\n",
      " -0.30694145 -0.41535404 -0.9040673  -0.271919   -0.47494265 -0.9372133\n",
      " -0.24233057 -0.4594384  -0.5834764  -0.14623041 -0.35705602 -0.6308223\n",
      " -0.28953373 -0.35680002 -0.5369657  -0.25904596 -0.32209873 -0.6326524\n",
      " -0.17676057 -0.32056063 -0.47769672]\n",
      "data: [ 0.09764333 -0.12818111 -0.00139142  0.01448007 -0.21023431 -0.21530163\n",
      " -0.19374427 -0.37145624 -0.6253542  -0.37554568 -0.43195403 -0.8070229\n",
      " -0.6704508  -0.44929424 -1.1941503  -0.23161386 -0.6267141  -0.80595434\n",
      " -0.49900672 -0.64790744 -1.1695795  -0.50235474 -0.5776095  -1.1860143\n",
      " -0.41920716 -0.7813401  -1.1322979  -0.17645065 -0.54897135 -0.7414032\n",
      " -0.28347117 -0.59008485 -0.56041884 -0.39183152 -0.6059165  -0.6607141\n",
      " -0.27003443 -0.5561799  -0.7184459  -0.17070954 -0.496056   -0.66377276\n",
      " -0.30694145 -0.41535404 -0.9040673  -0.271919   -0.47494265 -0.9372133\n",
      " -0.24233057 -0.4594384  -0.5834764  -0.14623041 -0.35705602 -0.6308223\n",
      " -0.28953373 -0.3568     -0.5369657  -0.25904596 -0.32209873 -0.6326524\n",
      " -0.17676058 -0.32056063 -0.47769672  0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0900,  0.1017, -0.2073,  ...,  0.3068, -0.1375, -1.1475],\n",
      "        [ 0.0900,  0.1017, -0.2073,  ...,  0.3068, -0.1375, -1.1475],\n",
      "        [ 0.0900,  0.1017, -0.2073,  ...,  0.3068, -0.1375, -1.1475],\n",
      "        ...,\n",
      "        [ 0.1401, -0.4187,  0.1613,  ...,  0.3673,  0.7864, -0.4577],\n",
      "        [-0.1169,  0.0864,  0.2130,  ..., -0.8328,  0.7281, -0.1858],\n",
      "        [-0.1169,  0.0864,  0.2130,  ..., -0.8328,  0.7281, -0.1858]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.09004354  0.10170863 -0.2072531   0.10468787  0.00330134 -0.5347936\n",
      "  0.00726356 -0.16720459 -1.1657598  -0.10037886 -0.2120057  -1.4103525\n",
      " -0.22976235 -0.3165544  -1.8076682  -0.07890822 -0.4489165  -1.3445523\n",
      "  0.10811283 -0.4684853  -1.2729223   0.13283332 -0.36777702 -1.302366\n",
      "  0.21368803 -0.50388235 -1.3826895  -0.02680372 -0.36518514 -1.2833881\n",
      "  0.09790829 -0.41684842 -1.2526379   0.16122824 -0.3782552  -1.2983732\n",
      "  0.37268096 -0.39036024 -1.3855743   0.09173962 -0.3243102  -1.1600358\n",
      "  0.02003389 -0.08915249 -1.7330775   0.2276017  -0.2581452  -1.7140632\n",
      "  0.43774143 -0.18318337 -1.3041556  -0.00486229 -0.11566274 -1.0981929\n",
      "  0.09842834 -0.07345021 -1.1778378   0.20156622 -0.10605052 -1.2936413\n",
      "  0.30680764 -0.13745171 -1.1474593 ]\n",
      "data: [ 0.09004354  0.10170863 -0.2072531   0.10468787  0.00330134 -0.5347936\n",
      "  0.00726356 -0.16720459 -1.1657598  -0.10037886 -0.2120057  -1.4103525\n",
      " -0.22976235 -0.3165544  -1.8076682  -0.07890822 -0.44891652 -1.3445523\n",
      "  0.10811283 -0.4684853  -1.2729223   0.13283332 -0.36777702 -1.302366\n",
      "  0.21368803 -0.50388235 -1.3826895  -0.02680372 -0.36518514 -1.283388\n",
      "  0.09790829 -0.41684842 -1.2526379   0.16122824 -0.3782552  -1.2983732\n",
      "  0.37268096 -0.39036024 -1.3855743   0.09173962 -0.3243102  -1.1600358\n",
      "  0.02003389 -0.08915249 -1.7330775   0.2276017  -0.2581452  -1.7140632\n",
      "  0.43774143 -0.18318337 -1.3041556  -0.00486229 -0.11566274 -1.0981929\n",
      "  0.09842834 -0.07345021 -1.1778378   0.20156622 -0.10605052 -1.2936413\n",
      "  0.30680764 -0.13745171 -1.1474593   0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.1626, -0.2447, -0.2165,  ...,  0.1342, -0.3837, -1.3979],\n",
      "        [ 0.1626, -0.2447, -0.2165,  ...,  0.1342, -0.3837, -1.3979],\n",
      "        [ 0.1626, -0.2447, -0.2165,  ...,  0.1342, -0.3837, -1.3979],\n",
      "        ...,\n",
      "        [-0.3962,  0.3155, -0.2418,  ..., -0.9098,  0.8485, -0.5920],\n",
      "        [-0.1954,  0.1442,  0.4025,  ..., -0.1335,  0.9645,  0.0509],\n",
      "        [-0.1954,  0.1442,  0.4025,  ..., -0.1335,  0.9645,  0.0509]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.16259731 -0.24474892 -0.21654204  0.17051058 -0.42394608 -0.75639176\n",
      "  0.1134444  -0.5734697  -1.4409375  -0.03744851 -0.6310879  -1.7440678\n",
      " -0.24560687 -0.75492847 -2.2096317  -0.07778284 -0.8134382  -1.6215749\n",
      "  0.17727114 -0.8176117  -1.3409047   0.13588884 -0.75505805 -1.3899015\n",
      "  0.12326978 -0.8522508  -1.492666   -0.03816712 -0.68302584 -1.5522274\n",
      "  0.0609953  -0.7390543  -1.5093521   0.04989593 -0.7221918  -1.6149815\n",
      "  0.17674719 -0.7207309  -1.6925542   0.05065572 -0.6286533  -1.3766742\n",
      " -0.02669583 -0.39854333 -1.8704634   0.09021126 -0.5355292  -1.8423752\n",
      "  0.22470109 -0.49820426 -1.535238   -0.03708974 -0.37536836 -1.3240654\n",
      "  0.03305179 -0.35118255 -1.382289    0.09875719 -0.37684909 -1.4995192\n",
      "  0.13417494 -0.3836607  -1.3978517 ]\n",
      "data: [ 0.16259731 -0.24474892 -0.21654204  0.17051058 -0.42394608 -0.75639176\n",
      "  0.1134444  -0.5734697  -1.4409375  -0.03744851 -0.6310879  -1.7440678\n",
      " -0.24560685 -0.7549284  -2.2096317  -0.07778284 -0.8134382  -1.6215749\n",
      "  0.17727114 -0.8176117  -1.3409047   0.13588884 -0.75505805 -1.3899016\n",
      "  0.12326977 -0.8522508  -1.492666   -0.03816712 -0.68302584 -1.5522274\n",
      "  0.0609953  -0.7390543  -1.5093521   0.04989593 -0.72219175 -1.6149815\n",
      "  0.17674719 -0.7207309  -1.6925541   0.05065572 -0.6286533  -1.3766742\n",
      " -0.02669583 -0.39854333 -1.8704634   0.09021126 -0.5355292  -1.8423752\n",
      "  0.2247011  -0.49820426 -1.535238   -0.03708974 -0.37536836 -1.3240654\n",
      "  0.03305179 -0.35118255 -1.3822892   0.09875719 -0.37684909 -1.4995192\n",
      "  0.13417494 -0.3836607  -1.3978517   0.04      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0014, -0.2214, -0.1263,  ...,  0.0219, -0.4075, -1.1864],\n",
      "        [-0.0014, -0.2214, -0.1263,  ...,  0.0219, -0.4075, -1.1864],\n",
      "        [-0.0014, -0.2214, -0.1263,  ...,  0.0219, -0.4075, -1.1864],\n",
      "        ...,\n",
      "        [ 0.0067,  0.6645, -0.2338,  ..., -0.3585,  1.1325, -0.6183],\n",
      "        [-0.0874,  0.0135,  0.6353,  ..., -0.0416,  0.7029,  0.2584],\n",
      "        [-0.0874,  0.0135,  0.6353,  ..., -0.0416,  0.7029,  0.2584]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-1.3944982e-03 -2.2139496e-01 -1.2627394e-01  2.3896504e-02\n",
      " -3.5566261e-01 -4.8942316e-01 -6.1672233e-02 -5.7245290e-01\n",
      " -1.3055301e+00 -2.1586958e-01 -6.4056301e-01 -1.6239984e+00\n",
      " -3.9545536e-01 -7.6506054e-01 -2.1170881e+00 -2.1994479e-01\n",
      " -8.3480060e-01 -1.5171304e+00  3.2335058e-02 -8.9029098e-01\n",
      " -1.2990570e+00 -3.5176113e-02 -8.3683205e-01 -1.3376410e+00\n",
      " -5.8789648e-02 -9.8474634e-01 -1.4589331e+00 -1.6269988e-01\n",
      " -7.2757673e-01 -1.4053984e+00 -8.0031395e-02 -8.0164874e-01\n",
      " -1.3744018e+00 -9.1910936e-02 -7.8105390e-01 -1.4764490e+00\n",
      "  1.6207248e-02 -8.2567239e-01 -1.5186138e+00 -5.7775117e-02\n",
      " -6.2455750e-01 -1.2261112e+00 -2.0671402e-01 -4.0292698e-01\n",
      " -1.9258494e+00 -3.7350178e-02 -5.8595496e-01 -1.9243019e+00\n",
      "  1.1297764e-01 -5.4334009e-01 -1.3564241e+00 -1.8654317e-01\n",
      " -3.8413808e-01 -1.1533756e+00 -8.6353734e-02 -3.6845621e-01\n",
      " -1.2241373e+00 -4.1480303e-02 -4.0528905e-01 -1.3338790e+00\n",
      "  2.1869339e-02 -4.0752119e-01 -1.1863778e+00]\n",
      "data: [-1.3944982e-03 -2.2139496e-01 -1.2627394e-01  2.3896504e-02\n",
      " -3.5566261e-01 -4.8942316e-01 -6.1672233e-02 -5.7245290e-01\n",
      " -1.3055301e+00 -2.1586958e-01 -6.4056307e-01 -1.6239984e+00\n",
      " -3.9545536e-01 -7.6506060e-01 -2.1170881e+00 -2.1994478e-01\n",
      " -8.3480054e-01 -1.5171304e+00  3.2335058e-02 -8.9029098e-01\n",
      " -1.2990570e+00 -3.5176113e-02 -8.3683205e-01 -1.3376410e+00\n",
      " -5.8789648e-02 -9.8474634e-01 -1.4589331e+00 -1.6269988e-01\n",
      " -7.2757673e-01 -1.4053984e+00 -8.0031395e-02 -8.0164874e-01\n",
      " -1.3744018e+00 -9.1910936e-02 -7.8105390e-01 -1.4764490e+00\n",
      "  1.6207248e-02 -8.2567239e-01 -1.5186139e+00 -5.7775117e-02\n",
      " -6.2455750e-01 -1.2261112e+00 -2.0671402e-01 -4.0292698e-01\n",
      " -1.9258494e+00 -3.7350178e-02 -5.8595496e-01 -1.9243019e+00\n",
      "  1.1297764e-01 -5.4334009e-01 -1.3564241e+00 -1.8654317e-01\n",
      " -3.8413808e-01 -1.1533756e+00 -8.6353734e-02 -3.6845624e-01\n",
      " -1.2241373e+00 -4.1480303e-02 -4.0528905e-01 -1.3338790e+00\n",
      "  2.1869339e-02 -4.0752116e-01 -1.1863778e+00  5.0000001e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[-0.0126, -0.0440, -0.2498,  ..., -0.0144, -0.2194, -1.2621],\n",
      "        [-0.0126, -0.0440, -0.2498,  ..., -0.0144, -0.2194, -1.2621],\n",
      "        [-0.0126, -0.0440, -0.2498,  ..., -0.0144, -0.2194, -1.2621],\n",
      "        ...,\n",
      "        [-0.1622,  0.4425,  0.0162,  ..., -0.4609,  1.0799, -0.4565],\n",
      "        [ 0.0126,  0.0322,  0.7024,  ..., -0.0314,  0.6517,  0.3784],\n",
      "        [ 0.0126,  0.0322,  0.7024,  ..., -0.0314,  0.6517,  0.3784]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01260016 -0.04402129 -0.24975152  0.01478846 -0.15472816 -0.5266131\n",
      " -0.12502363 -0.39141747 -1.3883462  -0.28649244 -0.4564404  -1.6764512\n",
      " -0.44515777 -0.5470189  -2.1928806  -0.21939155 -0.6873365  -1.5933857\n",
      " -0.04077457 -0.75610626 -1.4431407  -0.09004906 -0.6806608  -1.4832897\n",
      " -0.08545484 -0.8435774  -1.6042371  -0.17609191 -0.5906966  -1.4917936\n",
      " -0.11457139 -0.64559436 -1.4508238  -0.11473942 -0.609194   -1.5363119\n",
      "  0.02967812 -0.6430152  -1.5548451  -0.08876392 -0.47219065 -1.336669\n",
      " -0.25466174 -0.23785785 -2.0866678  -0.06368307 -0.41475224 -2.1103518\n",
      "  0.1194841  -0.36610073 -1.4301422  -0.22323063 -0.2350219  -1.257385\n",
      " -0.15236887 -0.2039865  -1.3396013  -0.12047899 -0.21180402 -1.4516761\n",
      " -0.01440995 -0.21942571 -1.2620718 ]\n",
      "data: [-0.01260016 -0.04402129 -0.24975152  0.01478846 -0.15472816 -0.5266131\n",
      " -0.12502363 -0.39141747 -1.3883462  -0.28649244 -0.4564404  -1.6764512\n",
      " -0.44515777 -0.5470189  -2.1928806  -0.21939155 -0.6873365  -1.5933856\n",
      " -0.04077457 -0.75610626 -1.4431407  -0.09004906 -0.6806608  -1.4832898\n",
      " -0.08545484 -0.84357744 -1.6042371  -0.17609192 -0.5906966  -1.4917936\n",
      " -0.11457139 -0.64559436 -1.4508238  -0.11473942 -0.609194   -1.5363117\n",
      "  0.02967812 -0.6430152  -1.5548451  -0.08876392 -0.47219068 -1.336669\n",
      " -0.25466174 -0.23785786 -2.0866678  -0.06368307 -0.41475224 -2.1103518\n",
      "  0.1194841  -0.36610073 -1.4301422  -0.22323063 -0.23502189 -1.257385\n",
      " -0.15236887 -0.2039865  -1.3396013  -0.120479   -0.211804   -1.4516761\n",
      " -0.01440995 -0.21942572 -1.2620718   0.06      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BB38>\n",
      "tensor([[ 0.0241, -0.0234, -0.1925,  ...,  0.0487, -0.2037, -1.2475],\n",
      "        [ 0.0241, -0.0234, -0.1925,  ...,  0.0487, -0.2037, -1.2475],\n",
      "        [ 0.0241, -0.0234, -0.1925,  ...,  0.0487, -0.2037, -1.2475],\n",
      "        ...,\n",
      "        [-0.2241,  0.2757, -0.0837,  ..., -0.8886,  0.7851, -0.3009],\n",
      "        [-0.1668, -0.1511,  0.5197,  ..., -0.2715,  0.5750,  0.2545],\n",
      "        [-0.1668, -0.1511,  0.5197,  ..., -0.2715,  0.5750,  0.2545]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.4095450e-02 -2.3397317e-02 -1.9246504e-01  3.6783312e-02\n",
      " -1.6441725e-01 -6.0392940e-01 -4.2973556e-02 -3.3719155e-01\n",
      " -1.3340273e+00 -1.8918999e-01 -3.9412382e-01 -1.6379774e+00\n",
      " -3.6821616e-01 -5.1253116e-01 -2.1097999e+00 -1.8746799e-01\n",
      " -6.2799186e-01 -1.4924631e+00  4.1402489e-02 -6.5166652e-01\n",
      " -1.3033230e+00 -1.1073619e-02 -5.8972663e-01 -1.3564935e+00\n",
      " -7.5356439e-03 -7.1693379e-01 -1.4738281e+00 -1.4160079e-01\n",
      " -5.2175683e-01 -1.4072740e+00 -5.0551347e-02 -5.7420695e-01\n",
      " -1.3881953e+00 -5.4612584e-02 -5.4588443e-01 -1.4897521e+00\n",
      "  7.8031853e-02 -5.7079208e-01 -1.5400798e+00 -4.5987733e-02\n",
      " -4.3723911e-01 -1.2351930e+00 -1.5537095e-01 -2.0841861e-01\n",
      " -1.8606520e+00 -5.9393793e-04 -3.6003166e-01 -1.8570783e+00\n",
      "  1.5815663e-01 -3.2823038e-01 -1.3971918e+00 -1.5282506e-01\n",
      " -1.9761012e-01 -1.1739750e+00 -6.6620931e-02 -1.7802325e-01\n",
      " -1.2591355e+00 -2.2320703e-02 -1.9408941e-01 -1.3791182e+00\n",
      "  4.8713304e-02 -2.0370828e-01 -1.2475183e+00]\n",
      "data: [ 2.4095450e-02 -2.3397317e-02 -1.9246504e-01  3.6783312e-02\n",
      " -1.6441725e-01 -6.0392940e-01 -4.2973556e-02 -3.3719155e-01\n",
      " -1.3340273e+00 -1.8918999e-01 -3.9412385e-01 -1.6379772e+00\n",
      " -3.6821616e-01 -5.1253116e-01 -2.1097999e+00 -1.8746799e-01\n",
      " -6.2799186e-01 -1.4924631e+00  4.1402489e-02 -6.5166646e-01\n",
      " -1.3033230e+00 -1.1073619e-02 -5.8972663e-01 -1.3564935e+00\n",
      " -7.5356434e-03 -7.1693385e-01 -1.4738281e+00 -1.4160079e-01\n",
      " -5.2175683e-01 -1.4072740e+00 -5.0551347e-02 -5.7420695e-01\n",
      " -1.3881954e+00 -5.4612584e-02 -5.4588443e-01 -1.4897521e+00\n",
      "  7.8031853e-02 -5.7079208e-01 -1.5400798e+00 -4.5987736e-02\n",
      " -4.3723911e-01 -1.2351930e+00 -1.5537095e-01 -2.0841862e-01\n",
      " -1.8606520e+00 -5.9393793e-04 -3.6003166e-01 -1.8570782e+00\n",
      "  1.5815663e-01 -3.2823035e-01 -1.3971918e+00 -1.5282506e-01\n",
      " -1.9761012e-01 -1.1739750e+00 -6.6620931e-02 -1.7802325e-01\n",
      " -1.2591355e+00 -2.2320703e-02 -1.9408941e-01 -1.3791182e+00\n",
      "  4.8713304e-02 -2.0370826e-01 -1.2475183e+00  7.0000000e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0102, -0.0693, -0.2598,  ...,  0.0176, -0.2459, -1.3157],\n",
      "        [ 0.0102, -0.0693, -0.2598,  ...,  0.0176, -0.2459, -1.3157],\n",
      "        [ 0.0102, -0.0693, -0.2598,  ...,  0.0176, -0.2459, -1.3157],\n",
      "        ...,\n",
      "        [-0.3330,  0.2517, -0.2988,  ..., -0.7963,  0.7065, -0.4631],\n",
      "        [-0.1239, -0.0322,  0.6275,  ..., -0.2299,  0.7668,  0.3044],\n",
      "        [-0.1239, -0.0322,  0.6275,  ..., -0.2299,  0.7668,  0.3044]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01024572 -0.06931494 -0.2598051   0.03312368 -0.2075434  -0.68211603\n",
      " -0.07930832 -0.39508712 -1.4422097  -0.22210291 -0.460741   -1.7198243\n",
      " -0.37954766 -0.5575431  -2.203863   -0.18865076 -0.6795629  -1.5934205\n",
      " -0.01316372 -0.71378154 -1.4135439  -0.0533497  -0.6419605  -1.4709892\n",
      " -0.05412048 -0.7772885  -1.5830765  -0.15499717 -0.5786366  -1.5188525\n",
      " -0.08566172 -0.6265348  -1.4798243  -0.102837   -0.59772456 -1.5636504\n",
      "  0.03792007 -0.6093027  -1.6019843  -0.08149062 -0.4948063  -1.3575823\n",
      " -0.18831497 -0.26535553 -1.9734454  -0.04275692 -0.40987033 -1.9808154\n",
      "  0.11367745 -0.37895876 -1.4695594  -0.17289576 -0.26083225 -1.2903743\n",
      " -0.11604499 -0.23133117 -1.3662765  -0.07049152 -0.23005366 -1.482204\n",
      "  0.01759061 -0.24590851 -1.3157165 ]\n",
      "data: [ 0.01024572 -0.06931494 -0.2598051   0.03312368 -0.20754342 -0.68211603\n",
      " -0.07930832 -0.39508712 -1.4422097  -0.22210291 -0.460741   -1.7198243\n",
      " -0.37954766 -0.5575431  -2.203863   -0.18865076 -0.6795629  -1.5934205\n",
      " -0.01316372 -0.71378154 -1.413544   -0.0533497  -0.6419605  -1.4709892\n",
      " -0.05412048 -0.7772885  -1.5830765  -0.15499717 -0.5786366  -1.5188526\n",
      " -0.08566172 -0.6265348  -1.4798244  -0.102837   -0.59772456 -1.5636504\n",
      "  0.03792007 -0.6093027  -1.6019843  -0.08149062 -0.4948063  -1.3575824\n",
      " -0.18831497 -0.26535553 -1.9734454  -0.04275693 -0.40987033 -1.9808154\n",
      "  0.11367746 -0.3789588  -1.4695594  -0.17289576 -0.26083225 -1.2903743\n",
      " -0.11604499 -0.23133117 -1.3662765  -0.07049152 -0.23005368 -1.482204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.01759061 -0.24590851 -1.3157165   0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0310, -0.0370, -0.2254,  ...,  0.0422, -0.2325, -1.2599],\n",
      "        [ 0.0310, -0.0370, -0.2254,  ...,  0.0422, -0.2325, -1.2599],\n",
      "        [ 0.0310, -0.0370, -0.2254,  ...,  0.0422, -0.2325, -1.2599],\n",
      "        ...,\n",
      "        [-0.1242,  0.4261, -0.1213,  ..., -0.7403,  0.9402, -0.3746],\n",
      "        [-0.1425, -0.1996,  0.5466,  ..., -0.2242,  0.5669,  0.2386],\n",
      "        [-0.1425, -0.1996,  0.5466,  ..., -0.2242,  0.5669,  0.2386]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03098525 -0.0369584  -0.22536117  0.0457354  -0.1634521  -0.6162344\n",
      " -0.06468469 -0.34620738 -1.3712485  -0.21197489 -0.40877116 -1.6614351\n",
      " -0.37882566 -0.5032124  -2.1528764  -0.16229638 -0.65427005 -1.5283666\n",
      "  0.00432426 -0.69171864 -1.3727202  -0.04136017 -0.61794734 -1.4362378\n",
      " -0.03623128 -0.7666334  -1.550544   -0.1260556  -0.5603209  -1.4475327\n",
      " -0.06136589 -0.60525876 -1.4175541  -0.08286375 -0.58111477 -1.5134637\n",
      "  0.05832118 -0.59067565 -1.5440633  -0.0524356  -0.47312889 -1.2852862\n",
      " -0.16334678 -0.24868193 -1.9304912  -0.01802361 -0.39201474 -1.9440534\n",
      "  0.14322752 -0.36902076 -1.4075608  -0.1451025  -0.24416183 -1.2203326\n",
      " -0.09040126 -0.22229508 -1.3060975  -0.05568475 -0.21716872 -1.4232748\n",
      "  0.04217426 -0.23254047 -1.2598553 ]\n",
      "data: [ 0.03098525 -0.0369584  -0.22536117  0.0457354  -0.1634521  -0.6162344\n",
      " -0.06468469 -0.34620738 -1.3712485  -0.21197489 -0.40877116 -1.6614351\n",
      " -0.3788257  -0.5032124  -2.1528764  -0.16229638 -0.65427    -1.5283666\n",
      "  0.00432426 -0.6917187  -1.3727202  -0.04136017 -0.61794734 -1.4362378\n",
      " -0.03623128 -0.7666334  -1.550544   -0.1260556  -0.5603209  -1.4475327\n",
      " -0.06136589 -0.60525876 -1.4175541  -0.08286375 -0.58111477 -1.5134637\n",
      "  0.05832118 -0.59067565 -1.5440632  -0.0524356  -0.47312889 -1.2852863\n",
      " -0.16334678 -0.24868193 -1.9304912  -0.01802361 -0.39201474 -1.9440533\n",
      "  0.14322752 -0.36902076 -1.4075608  -0.1451025  -0.24416183 -1.2203326\n",
      " -0.09040126 -0.22229508 -1.3060975  -0.05568475 -0.21716872 -1.4232746\n",
      "  0.04217426 -0.23254047 -1.2598553   0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0199, -0.0697, -0.2487,  ...,  0.0320, -0.2531, -1.2927],\n",
      "        [ 0.0199, -0.0697, -0.2487,  ...,  0.0320, -0.2531, -1.2927],\n",
      "        [ 0.0199, -0.0697, -0.2487,  ...,  0.0320, -0.2531, -1.2927],\n",
      "        ...,\n",
      "        [-0.3097,  0.2221, -0.2705,  ..., -0.8127,  0.6871, -0.4634],\n",
      "        [-0.1198, -0.0546,  0.5971,  ..., -0.2316,  0.7330,  0.2658],\n",
      "        [-0.1198, -0.0546,  0.5971,  ..., -0.2316,  0.7330,  0.2658]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01993579 -0.06966496 -0.24868593  0.04546595 -0.20132595 -0.65480894\n",
      " -0.06169572 -0.38936648 -1.4213474  -0.20471168 -0.45474204 -1.707409\n",
      " -0.36309698 -0.5531723  -2.1952357  -0.1739611  -0.67992055 -1.5750332\n",
      "  0.01060649 -0.7160629  -1.3920755  -0.03621762 -0.6476884  -1.4501544\n",
      " -0.04519835 -0.7880746  -1.5663325  -0.13796845 -0.5832308  -1.4938437\n",
      " -0.06822199 -0.6332417  -1.4603218  -0.0903716  -0.604864   -1.5490668\n",
      "  0.04306478 -0.62273866 -1.5850796  -0.06169336 -0.4949101  -1.3288889\n",
      " -0.17586058 -0.26691678 -1.972605   -0.02801518 -0.41588277 -1.9816806\n",
      "  0.12506765 -0.38769275 -1.4466456  -0.15750927 -0.26335585 -1.261453\n",
      " -0.09531512 -0.2372543  -1.3397003  -0.05449202 -0.23855072 -1.4558673\n",
      "  0.03199758 -0.25306916 -1.2926606 ]\n",
      "data: [ 0.01993579 -0.06966496 -0.24868593  0.04546595 -0.20132595 -0.65480894\n",
      " -0.06169572 -0.3893665  -1.4213474  -0.20471169 -0.45474204 -1.707409\n",
      " -0.363097   -0.5531723  -2.1952357  -0.1739611  -0.67992055 -1.5750333\n",
      "  0.01060649 -0.7160629  -1.3920755  -0.03621762 -0.6476884  -1.4501544\n",
      " -0.04519835 -0.7880747  -1.5663323  -0.13796845 -0.5832308  -1.4938437\n",
      " -0.06822199 -0.6332417  -1.4603218  -0.0903716  -0.604864   -1.5490668\n",
      "  0.04306478 -0.62273866 -1.5850796  -0.06169336 -0.4949101  -1.3288889\n",
      " -0.17586058 -0.26691678 -1.972605   -0.02801518 -0.41588277 -1.9816806\n",
      "  0.12506765 -0.38769275 -1.4466456  -0.15750927 -0.26335585 -1.261453\n",
      " -0.09531512 -0.23725432 -1.3397003  -0.05449202 -0.23855072 -1.4558673\n",
      "  0.03199758 -0.25306916 -1.2926605   0.1       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0187, -0.0340, -0.2442,  ...,  0.0442, -0.2280, -1.2735],\n",
      "        [ 0.0187, -0.0340, -0.2442,  ...,  0.0442, -0.2280, -1.2735],\n",
      "        [ 0.0187, -0.0340, -0.2442,  ...,  0.0442, -0.2280, -1.2735],\n",
      "        ...,\n",
      "        [-0.1402,  0.3682, -0.1050,  ..., -0.7597,  0.8633, -0.3519],\n",
      "        [-0.1398, -0.1774,  0.5514,  ..., -0.2241,  0.5857,  0.2216],\n",
      "        [-0.1398, -0.1774,  0.5514,  ..., -0.2241,  0.5857,  0.2216]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0187253  -0.0340382  -0.24415536  0.03442964 -0.163959   -0.6357593\n",
      " -0.06546284 -0.34910768 -1.38576    -0.21017951 -0.41019332 -1.6806914\n",
      " -0.3784844  -0.516016   -2.160459   -0.18052876 -0.6461446  -1.5448583\n",
      "  0.01111954 -0.6821052  -1.3773452  -0.03746217 -0.61397254 -1.4355869\n",
      " -0.03325067 -0.7581028  -1.5510861  -0.13857403 -0.5482849  -1.4597867\n",
      " -0.06493092 -0.5990529  -1.4332521  -0.07838099 -0.5752411  -1.5285146\n",
      "  0.05787501 -0.59343493 -1.5657237  -0.05484162 -0.46058643 -1.2936817\n",
      " -0.17032844 -0.23605642 -1.9470209  -0.01595812 -0.3881109  -1.9539549\n",
      "  0.14444256 -0.3599206  -1.4251697  -0.1539166  -0.22981551 -1.229129\n",
      " -0.08462662 -0.20924242 -1.313206   -0.0444864  -0.21470958 -1.4300601\n",
      "  0.04417196 -0.2280462  -1.273493  ]\n",
      "data: [ 0.0187253  -0.0340382  -0.24415536  0.03442964 -0.16395898 -0.6357593\n",
      " -0.06546284 -0.34910765 -1.3857598  -0.21017951 -0.41019332 -1.6806914\n",
      " -0.37848437 -0.516016   -2.160459   -0.18052876 -0.6461446  -1.5448585\n",
      "  0.01111954 -0.6821052  -1.3773453  -0.03746217 -0.61397254 -1.4355868\n",
      " -0.03325067 -0.7581028  -1.5510861  -0.13857403 -0.5482849  -1.4597867\n",
      " -0.06493092 -0.5990529  -1.4332521  -0.07838099 -0.5752411  -1.5285145\n",
      "  0.05787501 -0.59343493 -1.5657238  -0.05484162 -0.46058643 -1.2936817\n",
      " -0.17032844 -0.23605642 -1.9470209  -0.01595812 -0.38811094 -1.9539549\n",
      "  0.14444256 -0.3599206  -1.4251697  -0.1539166  -0.22981553 -1.229129\n",
      " -0.08462663 -0.20924242 -1.3132061  -0.04448639 -0.21470958 -1.4300601\n",
      "  0.04417196 -0.2280462  -1.273493    0.11      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0132, -0.0842, -0.2445,  ...,  0.0303, -0.2682, -1.3034],\n",
      "        [ 0.0132, -0.0842, -0.2445,  ...,  0.0303, -0.2682, -1.3034],\n",
      "        [ 0.0132, -0.0842, -0.2445,  ...,  0.0303, -0.2682, -1.3034],\n",
      "        ...,\n",
      "        [-0.3820,  0.1613, -0.3620,  ..., -0.8460,  0.5785, -0.5050],\n",
      "        [-0.1389, -0.0780,  0.5941,  ..., -0.2411,  0.7120,  0.2555],\n",
      "        [-0.1389, -0.0780,  0.5941,  ..., -0.2411,  0.7120,  0.2555]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01317122 -0.08420759 -0.24447842  0.03387051 -0.22291018 -0.6670164\n",
      " -0.05781015 -0.40272167 -1.4146664  -0.19922587 -0.46573347 -1.707496\n",
      " -0.3650534  -0.57390565 -2.185775   -0.18652824 -0.6884461  -1.5699589\n",
      "  0.01727763 -0.71784186 -1.3798735  -0.03082883 -0.6531759  -1.4372903\n",
      " -0.03544701 -0.7856607  -1.5528088  -0.14727165 -0.5864631  -1.4885563\n",
      " -0.06896251 -0.63815844 -1.4606987  -0.08568815 -0.6128505  -1.5542698\n",
      "  0.04498531 -0.6306838  -1.5992135  -0.06493799 -0.5036864  -1.3195809\n",
      " -0.17197004 -0.27776727 -1.9419552  -0.02732164 -0.42539236 -1.9434358\n",
      "  0.12402959 -0.39702588 -1.4558326  -0.16129605 -0.2691484  -1.2558676\n",
      " -0.0905993  -0.24664025 -1.3354272  -0.04584904 -0.255022   -1.4517472\n",
      "  0.03030748 -0.26821536 -1.3034326 ]\n",
      "data: [ 0.01317122 -0.08420759 -0.24447842  0.03387051 -0.22291018 -0.6670164\n",
      " -0.05781015 -0.40272167 -1.4146664  -0.19922586 -0.46573344 -1.707496\n",
      " -0.36505336 -0.57390565 -2.185775   -0.18652825 -0.6884461  -1.5699589\n",
      "  0.01727763 -0.71784186 -1.3798735  -0.03082883 -0.6531759  -1.4372903\n",
      " -0.03544701 -0.7856607  -1.5528089  -0.14727165 -0.5864631  -1.4885563\n",
      " -0.06896251 -0.63815844 -1.4606987  -0.08568815 -0.6128505  -1.5542697\n",
      "  0.04498531 -0.6306838  -1.5992134  -0.06493799 -0.5036864  -1.3195808\n",
      " -0.17197004 -0.27776727 -1.9419552  -0.02732164 -0.42539233 -1.9434358\n",
      "  0.12402959 -0.39702588 -1.4558327  -0.16129607 -0.2691484  -1.2558676\n",
      " -0.0905993  -0.24664025 -1.335427   -0.04584904 -0.255022   -1.4517472\n",
      "  0.03030748 -0.26821536 -1.3034326   0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0292, -0.0712, -0.2568,  ...,  0.0470, -0.2604, -1.2756],\n",
      "        [ 0.0292, -0.0712, -0.2568,  ...,  0.0470, -0.2604, -1.2756],\n",
      "        [ 0.0292, -0.0712, -0.2568,  ...,  0.0470, -0.2604, -1.2756],\n",
      "        ...,\n",
      "        [-0.1131,  0.4028, -0.1182,  ..., -0.6925,  0.9186, -0.4084],\n",
      "        [-0.1317, -0.1494,  0.5852,  ..., -0.2366,  0.6244,  0.2316],\n",
      "        [-0.1317, -0.1494,  0.5852,  ..., -0.2366,  0.6244,  0.2316]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02916662 -0.07121755 -0.25683823  0.05573737 -0.1874336  -0.6280253\n",
      " -0.061896   -0.38714936 -1.4160516  -0.20724678 -0.45026577 -1.7057368\n",
      " -0.36000913 -0.5431663  -2.2015133  -0.15958752 -0.69123936 -1.5733212\n",
      "  0.01099057 -0.7386838  -1.4203315  -0.04005335 -0.6666436  -1.4796513\n",
      " -0.04582473 -0.8232968  -1.5993981  -0.12081635 -0.6024811  -1.483692\n",
      " -0.06065308 -0.65020525 -1.455825   -0.08193974 -0.6211251  -1.5445349\n",
      "  0.05071092 -0.64407504 -1.5690382  -0.04484559 -0.50279593 -1.321171\n",
      " -0.17687836 -0.27244315 -2.0243282  -0.01500839 -0.42969415 -2.0433455\n",
      "  0.14415224 -0.39983675 -1.4338677  -0.14805438 -0.27652055 -1.2486303\n",
      " -0.08610347 -0.24931505 -1.335945   -0.052626   -0.24709266 -1.4516914\n",
      "  0.04699627 -0.2604264  -1.275606  ]\n",
      "data: [ 0.02916662 -0.07121755 -0.25683823  0.05573737 -0.1874336  -0.6280253\n",
      " -0.061896   -0.38714936 -1.4160516  -0.20724678 -0.45026577 -1.7057366\n",
      " -0.3600091  -0.5431663  -2.2015133  -0.15958752 -0.6912393  -1.5733212\n",
      "  0.01099057 -0.7386839  -1.4203315  -0.04005335 -0.6666436  -1.4796513\n",
      " -0.04582473 -0.8232968  -1.5993981  -0.12081634 -0.6024811  -1.483692\n",
      " -0.06065308 -0.65020525 -1.4558251  -0.08193974 -0.6211251  -1.5445349\n",
      "  0.05071092 -0.64407504 -1.569038   -0.04484559 -0.50279593 -1.3211712\n",
      " -0.17687836 -0.27244315 -2.0243282  -0.01500839 -0.42969415 -2.0433455\n",
      "  0.14415224 -0.39983672 -1.4338677  -0.14805438 -0.27652055 -1.2486303\n",
      " -0.08610347 -0.24931505 -1.335945   -0.052626   -0.24709266 -1.4516914\n",
      "  0.04699627 -0.2604264  -1.275606    0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0230, -0.0372, -0.2422,  ...,  0.0576, -0.2269, -1.2875],\n",
      "        [ 0.0230, -0.0372, -0.2422,  ...,  0.0576, -0.2269, -1.2875],\n",
      "        [ 0.0230, -0.0372, -0.2422,  ...,  0.0576, -0.2269, -1.2875],\n",
      "        ...,\n",
      "        [-0.1597,  0.3064, -0.0638,  ..., -0.8163,  0.7750, -0.2602],\n",
      "        [-0.1439, -0.1477,  0.5407,  ..., -0.2249,  0.6090,  0.2045],\n",
      "        [-0.1439, -0.1477,  0.5407,  ..., -0.2249,  0.6090,  0.2045]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.3042787e-02 -3.7230767e-02 -2.4223529e-01  3.5724577e-02\n",
      " -1.8028998e-01 -6.5864050e-01 -4.0733352e-02 -3.5711950e-01\n",
      " -1.3823895e+00 -1.8318781e-01 -4.1604334e-01 -1.6870021e+00\n",
      " -3.6080936e-01 -5.3784776e-01 -2.1495292e+00 -1.8492353e-01\n",
      " -6.4026117e-01 -1.5435262e+00  4.4981636e-02 -6.6600215e-01\n",
      " -1.3499525e+00 -6.9272146e-03 -6.0652733e-01 -1.4039832e+00\n",
      " -4.6802983e-03 -7.3688364e-01 -1.5198811e+00 -1.3772333e-01\n",
      " -5.3281367e-01 -1.4575163e+00 -4.7519006e-02 -5.8990312e-01\n",
      " -1.4353443e+00 -5.4078214e-02 -5.6793535e-01 -1.5353205e+00\n",
      "  7.5322591e-02 -5.9230816e-01 -1.5865121e+00 -4.1371629e-02\n",
      " -4.4928089e-01 -1.2843589e+00 -1.5145689e-01 -2.2720829e-01\n",
      " -1.9146917e+00  1.9137785e-03 -3.8235337e-01 -1.9087580e+00\n",
      "  1.5758198e-01 -3.5089782e-01 -1.4381639e+00 -1.4449716e-01\n",
      " -2.1268624e-01 -1.2242508e+00 -5.8170266e-02 -1.9572136e-01\n",
      " -1.3048688e+00 -1.1379279e-02 -2.1538013e-01 -1.4227263e+00\n",
      "  5.7570726e-02 -2.2686397e-01 -1.2875177e+00]\n",
      "data: [ 2.3042787e-02 -3.7230767e-02 -2.4223527e-01  3.5724577e-02\n",
      " -1.8029000e-01 -6.5864050e-01 -4.0733352e-02 -3.5711947e-01\n",
      " -1.3823895e+00 -1.8318781e-01 -4.1604337e-01 -1.6870021e+00\n",
      " -3.6080936e-01 -5.3784776e-01 -2.1495292e+00 -1.8492353e-01\n",
      " -6.4026117e-01 -1.5435262e+00  4.4981636e-02 -6.6600209e-01\n",
      " -1.3499523e+00 -6.9272150e-03 -6.0652733e-01 -1.4039834e+00\n",
      " -4.6802983e-03 -7.3688364e-01 -1.5198811e+00 -1.3772333e-01\n",
      " -5.3281367e-01 -1.4575163e+00 -4.7519006e-02 -5.8990312e-01\n",
      " -1.4353443e+00 -5.4078210e-02 -5.6793535e-01 -1.5353206e+00\n",
      "  7.5322591e-02 -5.9230816e-01 -1.5865121e+00 -4.1371629e-02\n",
      " -4.4928089e-01 -1.2843589e+00 -1.5145689e-01 -2.2720829e-01\n",
      " -1.9146916e+00  1.9137785e-03 -3.8235337e-01 -1.9087580e+00\n",
      "  1.5758198e-01 -3.5089782e-01 -1.4381639e+00 -1.4449716e-01\n",
      " -2.1268624e-01 -1.2242508e+00 -5.8170266e-02 -1.9572136e-01\n",
      " -1.3048688e+00 -1.1379279e-02 -2.1538013e-01 -1.4227263e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5.7570726e-02 -2.2686395e-01 -1.2875177e+00  1.4000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0041, -0.0836, -0.2582,  ...,  0.0346, -0.2694, -1.3243],\n",
      "        [ 0.0041, -0.0836, -0.2582,  ...,  0.0346, -0.2694, -1.3243],\n",
      "        [ 0.0041, -0.0836, -0.2582,  ...,  0.0346, -0.2694, -1.3243],\n",
      "        ...,\n",
      "        [-0.1612,  0.4267, -0.1277,  ..., -0.7379,  0.9055, -0.3494],\n",
      "        [-0.1618, -0.1301,  0.5748,  ..., -0.2441,  0.6576,  0.2250],\n",
      "        [-0.1618, -0.1301,  0.5748,  ..., -0.2441,  0.6576,  0.2250]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00407988 -0.08359344 -0.2582027   0.02187051 -0.22928755 -0.6863927\n",
      " -0.05784484 -0.40370727 -1.426588   -0.1973928  -0.46529534 -1.723791\n",
      " -0.36754414 -0.5827589  -2.1953363  -0.19925562 -0.6832558  -1.5873829\n",
      "  0.02424657 -0.706555   -1.3903131  -0.02450652 -0.6442908  -1.4457728\n",
      " -0.02278657 -0.7686751  -1.5609192  -0.15684618 -0.5756391  -1.5057184\n",
      " -0.0677494  -0.6291536  -1.481269   -0.07786174 -0.60508585 -1.5768788\n",
      "  0.05266879 -0.62423277 -1.6291211  -0.06693908 -0.49808642 -1.3321203\n",
      " -0.16779985 -0.27194118 -1.9375144  -0.02313013 -0.4207144  -1.9315535\n",
      "  0.13012919 -0.39059308 -1.4804531  -0.16552384 -0.25997525 -1.2699429\n",
      " -0.08363894 -0.24044001 -1.3478446  -0.03423342 -0.2562467  -1.464148\n",
      "  0.03460834 -0.26935798 -1.3243209 ]\n",
      "data: [ 0.00407988 -0.08359344 -0.2582027   0.02187051 -0.22928755 -0.6863927\n",
      " -0.05784484 -0.40370727 -1.4265882  -0.1973928  -0.46529534 -1.723791\n",
      " -0.36754414 -0.5827589  -2.1953363  -0.19925562 -0.6832558  -1.5873829\n",
      "  0.02424657 -0.706555   -1.3903131  -0.02450652 -0.64429075 -1.4457726\n",
      " -0.02278657 -0.7686751  -1.5609192  -0.15684618 -0.5756391  -1.5057184\n",
      " -0.0677494  -0.6291536  -1.4812691  -0.07786174 -0.60508585 -1.5768788\n",
      "  0.05266879 -0.62423277 -1.6291211  -0.06693908 -0.49808642 -1.3321204\n",
      " -0.16779986 -0.27194118 -1.9375145  -0.02313013 -0.4207144  -1.9315535\n",
      "  0.13012919 -0.39059308 -1.4804531  -0.16552383 -0.25997525 -1.2699429\n",
      " -0.08363894 -0.24044001 -1.3478446  -0.03423342 -0.2562467  -1.464148\n",
      "  0.03460834 -0.26935798 -1.324321    0.15      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0241, -0.0933, -0.2459,  ...,  0.0459, -0.2781, -1.2807],\n",
      "        [ 0.0241, -0.0933, -0.2459,  ...,  0.0459, -0.2781, -1.2807],\n",
      "        [ 0.0241, -0.0933, -0.2459,  ...,  0.0459, -0.2781, -1.2807],\n",
      "        ...,\n",
      "        [-0.1527,  0.3986, -0.1902,  ..., -0.7500,  0.9068, -0.4612],\n",
      "        [-0.1692, -0.1684,  0.5791,  ..., -0.2687,  0.6039,  0.2355],\n",
      "        [-0.1692, -0.1684,  0.5791,  ..., -0.2687,  0.6039,  0.2355]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02405426 -0.09329669 -0.24587399  0.04516376 -0.22385135 -0.6413789\n",
      " -0.05228023 -0.4159141  -1.4008029  -0.19413619 -0.47682616 -1.6946249\n",
      " -0.35476357 -0.5829661  -2.1721427  -0.17270982 -0.7067873  -1.5596671\n",
      "  0.0235682  -0.74467915 -1.3943219  -0.02722746 -0.678051   -1.4503255\n",
      " -0.02631444 -0.8210188  -1.5672812  -0.13112943 -0.607279   -1.4726441\n",
      " -0.0577386  -0.6581544  -1.4470634  -0.07004002 -0.63195837 -1.5378811\n",
      "  0.05928189 -0.65534395 -1.5748246  -0.04646807 -0.5135435  -1.3071845\n",
      " -0.17021157 -0.28638527 -1.9779005  -0.01119384 -0.4428941  -1.9850924\n",
      "  0.14500926 -0.40908748 -1.4369848  -0.15102048 -0.28183347 -1.2394478\n",
      " -0.07761821 -0.2575308  -1.3241556  -0.03760019 -0.26579723 -1.4397407\n",
      "  0.04589526 -0.27813    -1.2807441 ]\n",
      "data: [ 0.02405426 -0.09329669 -0.24587399  0.04516376 -0.22385135 -0.6413789\n",
      " -0.05228023 -0.4159141  -1.400803   -0.19413619 -0.47682616 -1.6946249\n",
      " -0.35476357 -0.5829661  -2.1721427  -0.17270982 -0.7067873  -1.5596671\n",
      "  0.0235682  -0.7446792  -1.3943219  -0.02722746 -0.678051   -1.4503255\n",
      " -0.02631444 -0.8210188  -1.5672812  -0.13112943 -0.607279   -1.4726441\n",
      " -0.0577386  -0.6581544  -1.4470634  -0.07004002 -0.63195837 -1.5378811\n",
      "  0.05928188 -0.65534395 -1.5748246  -0.04646807 -0.5135435  -1.3071845\n",
      " -0.17021157 -0.28638527 -1.9779005  -0.01119384 -0.4428941  -1.9850925\n",
      "  0.14500926 -0.40908748 -1.4369847  -0.15102048 -0.28183347 -1.2394478\n",
      " -0.07761821 -0.2575308  -1.3241556  -0.03760019 -0.26579723 -1.4397407\n",
      "  0.04589526 -0.27813    -1.2807441   0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0203, -0.0423, -0.2425,  ...,  0.0457, -0.2376, -1.2608],\n",
      "        [ 0.0203, -0.0423, -0.2425,  ...,  0.0457, -0.2376, -1.2608],\n",
      "        [ 0.0203, -0.0423, -0.2425,  ...,  0.0457, -0.2376, -1.2608],\n",
      "        ...,\n",
      "        [-0.1507,  0.3545, -0.0864,  ..., -0.7675,  0.8441, -0.3535],\n",
      "        [-0.1277, -0.1458,  0.5647,  ..., -0.1990,  0.6161,  0.2121],\n",
      "        [-0.1277, -0.1458,  0.5647,  ..., -0.1990,  0.6161,  0.2121]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02032201 -0.04232518 -0.24251935  0.03750729 -0.1674389  -0.619884\n",
      " -0.07305197 -0.36381134 -1.3907509  -0.22104084 -0.42669317 -1.6868615\n",
      " -0.38773397 -0.52973783 -2.1714387  -0.17872459 -0.6626768  -1.5492554\n",
      "  0.00834455 -0.70633155 -1.3744185  -0.04324014 -0.6368795  -1.4329362\n",
      " -0.04687808 -0.78968304 -1.5523462  -0.13597015 -0.567352   -1.4596367\n",
      " -0.06841292 -0.6194267  -1.4315226  -0.08480944 -0.5943592  -1.5252087\n",
      "  0.05102829 -0.6158621  -1.5557768  -0.0518491  -0.47231787 -1.2937882\n",
      " -0.17923045 -0.24662167 -1.9799185  -0.01842423 -0.4044822  -1.9916806\n",
      "  0.1449407  -0.37449282 -1.4151249  -0.15448698 -0.24288552 -1.22539\n",
      " -0.08705758 -0.2208285  -1.3118737  -0.05002124 -0.22453347 -1.4285755\n",
      "  0.04565737 -0.23757015 -1.2608013 ]\n",
      "data: [ 0.02032201 -0.04232518 -0.24251933  0.03750729 -0.1674389  -0.619884\n",
      " -0.07305197 -0.36381134 -1.3907509  -0.22104084 -0.42669314 -1.6868615\n",
      " -0.38773397 -0.52973783 -2.1714387  -0.17872459 -0.6626769  -1.5492554\n",
      "  0.00834455 -0.70633155 -1.3744185  -0.04324014 -0.6368795  -1.4329362\n",
      " -0.04687808 -0.7896831  -1.5523462  -0.13597015 -0.567352   -1.4596367\n",
      " -0.06841292 -0.6194267  -1.4315227  -0.08480944 -0.5943592  -1.5252087\n",
      "  0.05102829 -0.6158621  -1.5557768  -0.0518491  -0.47231787 -1.2937882\n",
      " -0.17923047 -0.24662167 -1.9799185  -0.01842423 -0.4044822  -1.9916806\n",
      "  0.1449407  -0.37449282 -1.4151248  -0.15448698 -0.24288552 -1.22539\n",
      " -0.08705758 -0.22082849 -1.3118737  -0.05002124 -0.22453347 -1.4285754\n",
      "  0.04565737 -0.23757015 -1.2608013   0.17      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0097, -0.0175, -0.2367,  ...,  0.0328, -0.2104, -1.2826],\n",
      "        [ 0.0097, -0.0175, -0.2367,  ...,  0.0328, -0.2104, -1.2826],\n",
      "        [ 0.0097, -0.0175, -0.2367,  ...,  0.0328, -0.2104, -1.2826],\n",
      "        ...,\n",
      "        [-0.1950,  0.3170, -0.1135,  ..., -0.8350,  0.7675, -0.2843],\n",
      "        [-0.1441, -0.1694,  0.5389,  ..., -0.2148,  0.6050,  0.2085],\n",
      "        [-0.1441, -0.1694,  0.5389,  ..., -0.2148,  0.6050,  0.2085]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 9.6957423e-03 -1.7540956e-02 -2.3670152e-01  2.0198744e-02\n",
      " -1.5665853e-01 -6.5317059e-01 -7.7152520e-02 -3.3759966e-01\n",
      " -1.3940303e+00 -2.2170720e-01 -4.0134719e-01 -1.6876669e+00\n",
      " -3.9735940e-01 -5.1058763e-01 -2.1608167e+00 -1.9503158e-01\n",
      " -6.2774152e-01 -1.5464107e+00  1.8257424e-03 -6.5968937e-01\n",
      " -1.3583251e+00 -4.3820105e-02 -5.9263766e-01 -1.4164497e+00\n",
      " -4.0410087e-02 -7.3038417e-01 -1.5306120e+00 -1.5384853e-01\n",
      " -5.2475870e-01 -1.4649322e+00 -7.6631814e-02 -5.7720381e-01\n",
      " -1.4345090e+00 -8.9721777e-02 -5.5491596e-01 -1.5307798e+00\n",
      "  5.0859548e-02 -5.6873751e-01 -1.5745070e+00 -7.0448592e-02\n",
      " -4.4422770e-01 -1.2978053e+00 -1.7627239e-01 -2.2107893e-01\n",
      " -1.9210631e+00 -2.8854631e-02 -3.6793989e-01 -1.9232837e+00\n",
      "  1.3230395e-01 -3.4189343e-01 -1.4312024e+00 -1.6485283e-01\n",
      " -2.0893762e-01 -1.2340430e+00 -9.7116463e-02 -1.8972977e-01\n",
      " -1.3166769e+00 -5.2041925e-02 -1.9612694e-01 -1.4336727e+00\n",
      "  3.2794476e-02 -2.1040545e-01 -1.2826364e+00]\n",
      "data: [ 9.6957423e-03 -1.7540956e-02 -2.3670153e-01  2.0198744e-02\n",
      " -1.5665853e-01 -6.5317065e-01 -7.7152520e-02 -3.3759966e-01\n",
      " -1.3940303e+00 -2.2170720e-01 -4.0134719e-01 -1.6876669e+00\n",
      " -3.9735940e-01 -5.1058763e-01 -2.1608167e+00 -1.9503158e-01\n",
      " -6.2774152e-01 -1.5464107e+00  1.8257424e-03 -6.5968931e-01\n",
      " -1.3583252e+00 -4.3820105e-02 -5.9263766e-01 -1.4164498e+00\n",
      " -4.0410087e-02 -7.3038411e-01 -1.5306120e+00 -1.5384853e-01\n",
      " -5.2475870e-01 -1.4649322e+00 -7.6631814e-02 -5.7720381e-01\n",
      " -1.4345089e+00 -8.9721777e-02 -5.5491596e-01 -1.5307798e+00\n",
      "  5.0859548e-02 -5.6873751e-01 -1.5745070e+00 -7.0448592e-02\n",
      " -4.4422767e-01 -1.2978053e+00 -1.7627239e-01 -2.2107893e-01\n",
      " -1.9210631e+00 -2.8854631e-02 -3.6793986e-01 -1.9232837e+00\n",
      "  1.3230395e-01 -3.4189343e-01 -1.4312024e+00 -1.6485283e-01\n",
      " -2.0893760e-01 -1.2340430e+00 -9.7116463e-02 -1.8972977e-01\n",
      " -1.3166767e+00 -5.2041925e-02 -1.9612694e-01 -1.4336727e+00\n",
      "  3.2794476e-02 -2.1040544e-01 -1.2826364e+00  1.8000001e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0298, -0.0944, -0.2253,  ...,  0.0415, -0.2793, -1.2887],\n",
      "        [ 0.0298, -0.0944, -0.2253,  ...,  0.0415, -0.2793, -1.2887],\n",
      "        [ 0.0298, -0.0944, -0.2253,  ...,  0.0415, -0.2793, -1.2887],\n",
      "        ...,\n",
      "        [-0.3447,  0.2673, -0.3659,  ..., -0.8881,  0.7105, -0.5020],\n",
      "        [-0.1401, -0.0853,  0.6052,  ..., -0.2408,  0.7101,  0.2831],\n",
      "        [-0.1401, -0.0853,  0.6052,  ..., -0.2408,  0.7101,  0.2831]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02980468 -0.0944279  -0.22531241  0.04968468 -0.23617496 -0.65564966\n",
      " -0.04248378 -0.40791294 -1.3882446  -0.182984   -0.47026825 -1.6770884\n",
      " -0.34849173 -0.5740971  -2.1573117  -0.16581956 -0.69838583 -1.5418682\n",
      "  0.02273691 -0.72247857 -1.3683832  -0.02121063 -0.6554276  -1.4299309\n",
      " -0.01921084 -0.78598994 -1.5415591  -0.13077798 -0.59643227 -1.4676651\n",
      " -0.05378554 -0.6437021  -1.4380842  -0.07388707 -0.61944336 -1.5323057\n",
      "  0.06012168 -0.6296937  -1.5767486  -0.05434228 -0.5171677  -1.3011203\n",
      " -0.15129846 -0.2938594  -1.9017724  -0.01491269 -0.43319562 -1.9041388\n",
      "  0.134208   -0.408033   -1.4369583  -0.14240438 -0.28464544 -1.2415241\n",
      " -0.0804932  -0.26217127 -1.319212   -0.03705171 -0.26433507 -1.4374014\n",
      "  0.04149192 -0.2792822  -1.2887274 ]\n",
      "data: [ 0.02980468 -0.0944279  -0.22531241  0.04968468 -0.23617497 -0.65564966\n",
      " -0.04248378 -0.40791294 -1.3882446  -0.182984   -0.47026825 -1.6770883\n",
      " -0.34849176 -0.5740971  -2.1573117  -0.16581956 -0.69838583 -1.5418683\n",
      "  0.02273691 -0.72247857 -1.3683832  -0.02121063 -0.6554276  -1.4299309\n",
      " -0.01921084 -0.78598994 -1.5415591  -0.13077798 -0.59643227 -1.4676651\n",
      " -0.05378554 -0.6437021  -1.4380842  -0.07388707 -0.61944336 -1.5323057\n",
      "  0.06012168 -0.6296937  -1.5767486  -0.05434228 -0.5171677  -1.3011203\n",
      " -0.15129846 -0.2938594  -1.9017723  -0.01491269 -0.43319562 -1.9041388\n",
      "  0.134208   -0.408033   -1.4369583  -0.14240438 -0.28464544 -1.2415241\n",
      " -0.0804932  -0.26217127 -1.3192121  -0.03705171 -0.26433507 -1.4374014\n",
      "  0.04149192 -0.2792822  -1.2887274   0.19      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[ 0.0282, -0.0811, -0.2347,  ...,  0.0535, -0.2728, -1.2553],\n",
      "        [ 0.0282, -0.0811, -0.2347,  ...,  0.0535, -0.2728, -1.2553],\n",
      "        [ 0.0282, -0.0811, -0.2347,  ...,  0.0535, -0.2728, -1.2553],\n",
      "        ...,\n",
      "        [-0.1342,  0.4133, -0.0857,  ..., -0.6803,  0.9076, -0.3705],\n",
      "        [-0.1709, -0.1329,  0.5785,  ..., -0.2704,  0.6418,  0.2198],\n",
      "        [-0.1709, -0.1329,  0.5785,  ..., -0.2704,  0.6418,  0.2198]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02816815 -0.08113734 -0.23470102  0.05448964 -0.20259416 -0.6067131\n",
      " -0.05689751 -0.40877473 -1.4034604  -0.201745   -0.4741286  -1.6977472\n",
      " -0.3580877  -0.5759067  -2.1875956  -0.1647164  -0.7030825  -1.5625972\n",
      "  0.0276154  -0.75211453 -1.385365   -0.02708234 -0.68484086 -1.440582\n",
      " -0.03968798 -0.83827746 -1.5627589  -0.12207609 -0.6093996  -1.4680835\n",
      " -0.05621065 -0.6630323  -1.4413962  -0.0739717  -0.63447803 -1.5292794\n",
      "  0.05361292 -0.66346437 -1.5588163  -0.038385   -0.508909   -1.301694\n",
      " -0.17596874 -0.27884126 -2.012947   -0.00942268 -0.44306737 -2.0264025\n",
      "  0.14836587 -0.4087786  -1.4176841  -0.14769542 -0.279141   -1.2278215\n",
      " -0.07524806 -0.25375974 -1.3134234  -0.03800599 -0.2602498  -1.4274628\n",
      "  0.05346889 -0.27275142 -1.2552907 ]\n",
      "data: [ 0.02816815 -0.08113734 -0.23470102  0.05448963 -0.20259416 -0.6067131\n",
      " -0.05689751 -0.40877473 -1.4034604  -0.20174499 -0.4741286  -1.6977472\n",
      " -0.3580877  -0.5759067  -2.1875956  -0.1647164  -0.7030825  -1.5625972\n",
      "  0.0276154  -0.75211453 -1.385365   -0.02708234 -0.68484086 -1.4405819\n",
      " -0.03968798 -0.83827746 -1.5627589  -0.12207609 -0.6093996  -1.4680835\n",
      " -0.05621065 -0.6630323  -1.4413962  -0.0739717  -0.63447803 -1.5292794\n",
      "  0.05361292 -0.66346437 -1.5588164  -0.038385   -0.508909   -1.301694\n",
      " -0.17596874 -0.27884126 -2.012947   -0.00942268 -0.44306737 -2.0264025\n",
      "  0.14836587 -0.4087786  -1.4176841  -0.14769542 -0.279141   -1.2278215\n",
      " -0.07524806 -0.25375974 -1.3134235  -0.03800599 -0.2602498  -1.4274628\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.05346889 -0.27275142 -1.2552907   0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.297 3.297 3.288 ... 3.229 3.252 3.286]\n",
      " [3.291 3.291 3.292 ... 3.239 3.244 3.26 ]\n",
      " [3.42  3.42  0.    ... 3.237 3.239 3.25 ]\n",
      " ...\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.986 2.986 2.984 ... 3.003 2.997 2.993]\n",
      " [2.973 2.973 2.972 ... 2.995 2.981 2.981]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 1. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63EF0>\n",
      "tensor([[ 0.0226, -0.0326, -0.2272,  ...,  0.0524, -0.2233, -1.2639],\n",
      "        [ 0.0226, -0.0326, -0.2272,  ...,  0.0524, -0.2233, -1.2639],\n",
      "        [ 0.0226, -0.0326, -0.2272,  ...,  0.0524, -0.2233, -1.2639],\n",
      "        ...,\n",
      "        [-0.1732,  0.3196, -0.0942,  ..., -0.8005,  0.7683, -0.2880],\n",
      "        [-0.1389, -0.1402,  0.5657,  ..., -0.2003,  0.6145,  0.2224],\n",
      "        [-0.1389, -0.1402,  0.5657,  ..., -0.2003,  0.6145,  0.2224]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02261335 -0.03259488 -0.22722827  0.0358988  -0.17118192 -0.6328558\n",
      " -0.05360056 -0.3601619  -1.3790615  -0.1990054  -0.42242756 -1.6825256\n",
      " -0.37526977 -0.53995955 -2.150021   -0.18561791 -0.64506763 -1.5363955\n",
      "  0.03333679 -0.67985415 -1.3402103  -0.02033344 -0.61870426 -1.3946754\n",
      " -0.02466972 -0.7581346  -1.5131634  -0.13847889 -0.5400909  -1.4465063\n",
      " -0.05719346 -0.5980793  -1.4215841  -0.06730608 -0.5754268  -1.5194017\n",
      "  0.06275862 -0.60101813 -1.5643357  -0.0448676  -0.4505403  -1.2748191\n",
      " -0.16581438 -0.22724172 -1.9344547  -0.0074747  -0.38606045 -1.9342352\n",
      "  0.15063585 -0.35405213 -1.4163742  -0.14974532 -0.21457717 -1.2104315\n",
      " -0.06867282 -0.19587041 -1.2937682  -0.02432555 -0.21187077 -1.4106572\n",
      "  0.05238169 -0.22331305 -1.263922  ]\n",
      "data: [-0.9  -4.48  3.51 -1.06 -4.21  3.65 -1.1  -3.72  3.6  -1.12 -3.43  3.91\n",
      " -1.22 -3.34  4.8  -0.85 -3.7   4.26 -0.91 -3.35  4.67 -1.05 -3.23  5.19\n",
      " -1.1  -3.15  5.19 -0.73 -3.74  4.1  -0.77 -3.37  4.36 -0.93 -3.32  4.67\n",
      " -1.04 -3.29  4.93 -0.71 -3.78  4.1  -0.72 -3.41  4.22 -0.95 -3.48  4.8\n",
      " -1.05 -3.62  4.98 -0.71 -3.82  3.94 -0.74 -3.58  4.16 -0.78 -3.53  4.07\n",
      " -0.94 -3.65  4.55  0.  ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B9B0>\n",
      "tensor([[-0.1028,  0.4596, -0.0144,  ..., -0.5470,  0.4185, -0.7402],\n",
      "        [-0.1028,  0.4596, -0.0144,  ..., -0.5470,  0.4185, -0.7402],\n",
      "        [-0.1028,  0.4596, -0.0144,  ..., -0.5470,  0.4185, -0.7402],\n",
      "        ...,\n",
      "        [ 0.3731, -0.9315,  0.8486,  ..., -0.6489, -1.1141,  1.0814],\n",
      "        [ 0.1835,  0.1112,  0.1959,  ...,  0.4856, -0.4742,  2.4856],\n",
      "        [ 0.1835,  0.1112,  0.1959,  ...,  0.4856, -0.4742,  2.4856]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.10283577  0.45958224 -0.01443899 -0.21573317  0.2742619  -0.4756187\n",
      " -0.23422286  0.17632902 -0.59893167 -0.2696802   0.06338316 -0.5539043\n",
      " -0.31399226 -0.00495112 -0.58080745 -0.35978866  0.23208681 -0.88288903\n",
      " -0.24287328  0.17792118 -0.34116113 -0.3370071   0.00952953 -0.30649313\n",
      " -0.46671456  0.05373028 -0.37163535 -0.3896296   0.3544802  -0.943539\n",
      " -0.4862355   0.2575344  -0.9506854  -0.53448725  0.17401013 -0.9305334\n",
      " -0.60482484  0.06061959 -0.88971686 -0.430322    0.41782525 -0.93220186\n",
      " -0.5597058   0.36826834 -0.955364   -0.59333956  0.30417228 -0.9547243\n",
      " -0.621868    0.21285953 -0.7992164  -0.4382584   0.5660572  -0.8101188\n",
      " -0.4697265   0.5068788  -0.8006058  -0.5224272   0.47836912 -0.7942493\n",
      " -0.5469624   0.41851246 -0.7401917 ]\n",
      "init: [-0.10283577  0.45958224 -0.01443899 -0.21573317  0.2742619  -0.4756187\n",
      " -0.23422286  0.17632902 -0.59893167 -0.2696802   0.06338316 -0.5539043\n",
      " -0.31399226 -0.00495112 -0.58080745 -0.35978866  0.23208681 -0.88288903\n",
      " -0.24287328  0.17792118 -0.34116113 -0.3370071   0.00952953 -0.30649313\n",
      " -0.46671456  0.05373028 -0.37163535 -0.3896296   0.3544802  -0.943539\n",
      " -0.4862355   0.2575344  -0.9506854  -0.53448725  0.17401013 -0.9305334\n",
      " -0.60482484  0.06061959 -0.88971686 -0.430322    0.41782525 -0.93220186\n",
      " -0.5597058   0.36826834 -0.955364   -0.59333956  0.30417228 -0.9547243\n",
      " -0.621868    0.21285953 -0.7992164  -0.4382584   0.5660572  -0.8101188\n",
      " -0.4697265   0.5068788  -0.8006058  -0.5224272   0.47836912 -0.7942493\n",
      " -0.5469624   0.41851246 -0.7401917 ]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [-0.10283577  0.45958224 -0.01443899 -0.21573317  0.2742619  -0.47561872\n",
      " -0.23422284  0.17632902 -0.59893167 -0.2696802   0.06338316 -0.5539043\n",
      " -0.31399226 -0.00495112 -0.58080745 -0.35978866  0.23208681 -0.88288903\n",
      " -0.24287328  0.17792118 -0.34116113 -0.3370071   0.00952953 -0.30649313\n",
      " -0.46671456  0.05373028 -0.37163535 -0.3896296   0.3544802  -0.943539\n",
      " -0.4862355   0.2575344  -0.9506853  -0.53448725  0.17401013 -0.93053347\n",
      " -0.60482484  0.06061959 -0.88971686 -0.430322    0.41782525 -0.93220186\n",
      " -0.5597058   0.36826837 -0.955364   -0.59333956  0.30417228 -0.95472425\n",
      " -0.621868    0.21285954 -0.7992164  -0.4382584   0.5660572  -0.8101188\n",
      " -0.46972647  0.5068788  -0.8006058  -0.5224272   0.47836912 -0.7942493\n",
      " -0.5469624   0.41851246 -0.7401917   0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F828>\n",
      "tensor([[ 0.0076, -0.2875, -0.0587,  ..., -0.0319, -0.3981, -1.1456],\n",
      "        [ 0.0076, -0.2875, -0.0587,  ..., -0.0319, -0.3981, -1.1456],\n",
      "        [ 0.0076, -0.2875, -0.0587,  ..., -0.0319, -0.3981, -1.1456],\n",
      "        ...,\n",
      "        [ 0.1888,  0.7782, -0.5005,  ..., -0.0537,  0.8506, -0.1289],\n",
      "        [-0.1076,  0.0353,  0.3432,  ..., -0.7491,  1.1276, -0.3081],\n",
      "        [-0.1076,  0.0353,  0.3432,  ..., -0.7491,  1.1276, -0.3081]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00759152 -0.28753513 -0.05868057 -0.00731969 -0.4617963  -0.5837444\n",
      " -0.15179098 -0.59316087 -1.1836802  -0.27990562 -0.6467612  -1.4062707\n",
      " -0.4714197  -0.6966633  -1.827345   -0.21546428 -0.84913474 -1.2666093\n",
      " -0.19693758 -0.8248403  -1.2432413  -0.1479719  -0.7183746  -1.3118436\n",
      " -0.06429277 -0.8284764  -1.3687652  -0.21178593 -0.72214025 -1.2538457\n",
      " -0.15053202 -0.7314993  -1.1812792  -0.14403164 -0.7023872  -1.2598151\n",
      "  0.09026493 -0.6295286  -1.3625863  -0.17771916 -0.6996645  -1.1342074\n",
      " -0.18123318 -0.48459664 -1.4361552  -0.08915524 -0.5449573  -1.434184\n",
      "  0.07846464 -0.503194   -1.2603033  -0.19209506 -0.46909094 -1.097672\n",
      " -0.22678305 -0.41388485 -1.1540205  -0.137369   -0.36811244 -1.2906041\n",
      " -0.03186654 -0.39813024 -1.1456053 ]\n",
      "data: [ 0.00759152 -0.28753513 -0.05868057 -0.00731969 -0.4617963  -0.5837444\n",
      " -0.15179098 -0.59316087 -1.1836802  -0.27990562 -0.6467612  -1.4062707\n",
      " -0.4714197  -0.69666326 -1.827345   -0.2154643  -0.84913474 -1.2666093\n",
      " -0.19693758 -0.8248403  -1.2432413  -0.1479719  -0.7183746  -1.3118435\n",
      " -0.06429277 -0.8284764  -1.3687652  -0.21178593 -0.72214025 -1.2538457\n",
      " -0.15053202 -0.7314993  -1.1812792  -0.14403164 -0.7023872  -1.2598151\n",
      "  0.09026493 -0.6295286  -1.3625863  -0.17771916 -0.6996645  -1.1342074\n",
      " -0.18123318 -0.48459664 -1.4361552  -0.08915524 -0.5449573  -1.434184\n",
      "  0.07846464 -0.503194   -1.2603033  -0.19209506 -0.46909097 -1.097672\n",
      " -0.22678305 -0.41388485 -1.1540205  -0.137369   -0.36811244 -1.2906041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.03186654 -0.39813024 -1.1456053   0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[ 0.0605, -0.0512, -0.2556,  ...,  0.1406, -0.2265, -1.2991],\n",
      "        [ 0.0605, -0.0512, -0.2556,  ...,  0.1406, -0.2265, -1.2991],\n",
      "        [ 0.0605, -0.0512, -0.2556,  ...,  0.1406, -0.2265, -1.2991],\n",
      "        ...,\n",
      "        [-0.1139,  0.3884,  0.1448,  ..., -0.1410,  1.1599, -0.4064],\n",
      "        [-0.0665,  0.1506,  0.4753,  ..., -0.4198,  0.7213,  0.1302],\n",
      "        [-0.0665,  0.1506,  0.4753,  ..., -0.4198,  0.7213,  0.1302]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.060461   -0.05122827 -0.25561637  0.09935042 -0.17679757 -0.5841077\n",
      "  0.02732419 -0.37624896 -1.388252   -0.12623714 -0.43073583 -1.7093762\n",
      " -0.29142278 -0.56977874 -2.1998744  -0.15964301 -0.63910973 -1.6284128\n",
      "  0.15515961 -0.6744091  -1.390478    0.09700626 -0.61602867 -1.4177716\n",
      "  0.09263735 -0.7444578  -1.5471232  -0.09610255 -0.52899045 -1.5169883\n",
      "  0.02341912 -0.60470307 -1.4972758   0.04437756 -0.569993   -1.5897511\n",
      "  0.17807019 -0.633605   -1.6520132   0.03653497 -0.43616545 -1.3260665\n",
      " -0.11348678 -0.18112053 -2.0377827   0.08763056 -0.3876006  -2.0217874\n",
      "  0.2701512  -0.33088946 -1.486338   -0.11719733 -0.18503201 -1.2499746\n",
      "  0.02311817 -0.15796259 -1.3139733   0.08296835 -0.21517591 -1.4314471\n",
      "  0.1405592  -0.22651625 -1.2991288 ]\n",
      "data: [ 0.060461   -0.05122827 -0.25561637  0.09935042 -0.17679757 -0.5841077\n",
      "  0.02732419 -0.37624896 -1.3882519  -0.12623714 -0.43073583 -1.7093762\n",
      " -0.29142278 -0.56977874 -2.1998744  -0.15964301 -0.63910973 -1.6284127\n",
      "  0.15515961 -0.6744091  -1.390478    0.09700626 -0.61602867 -1.4177716\n",
      "  0.09263735 -0.7444578  -1.5471233  -0.09610255 -0.52899045 -1.5169883\n",
      "  0.02341912 -0.60470307 -1.4972758   0.04437755 -0.569993   -1.5897511\n",
      "  0.17807019 -0.633605   -1.6520133   0.03653497 -0.43616545 -1.3260665\n",
      " -0.11348679 -0.18112053 -2.0377827   0.08763056 -0.3876006  -2.0217874\n",
      "  0.2701512  -0.33088946 -1.486338   -0.11719733 -0.18503201 -1.2499746\n",
      "  0.02311817 -0.15796259 -1.3139732   0.08296835 -0.21517591 -1.4314471\n",
      "  0.1405592  -0.22651625 -1.2991288   0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[-1.0902e-03, -1.8546e-01, -3.1403e-01,  ...,  5.0582e-02,\n",
      "         -3.5789e-01, -1.4180e+00],\n",
      "        [-1.0902e-03, -1.8546e-01, -3.1403e-01,  ...,  5.0582e-02,\n",
      "         -3.5789e-01, -1.4180e+00],\n",
      "        [-1.0902e-03, -1.8546e-01, -3.1403e-01,  ...,  5.0582e-02,\n",
      "         -3.5789e-01, -1.4180e+00],\n",
      "        ...,\n",
      "        [-1.7283e-01,  4.5432e-01, -2.5741e-02,  ..., -7.2464e-01,\n",
      "          9.8215e-01, -2.7449e-01],\n",
      "        [-1.9015e-01,  8.1027e-02,  6.3428e-01,  ..., -2.7277e-01,\n",
      "          8.0947e-01,  3.0132e-01],\n",
      "        [-1.9015e-01,  8.1027e-02,  6.3428e-01,  ..., -2.7277e-01,\n",
      "          8.0947e-01,  3.0132e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-1.09024625e-03 -1.85459018e-01 -3.14032614e-01  2.86988355e-02\n",
      " -3.44547004e-01 -7.86641717e-01  1.33864647e-02 -4.85766172e-01\n",
      " -1.47947431e+00 -1.21675178e-01 -5.33281922e-01 -1.80098486e+00\n",
      " -2.78660536e-01 -6.84767127e-01 -2.28495193e+00 -2.10882902e-01\n",
      " -7.54548311e-01 -1.65194237e+00  1.16162345e-01 -7.42946267e-01\n",
      " -1.39261711e+00  4.11025733e-02 -6.91359520e-01 -1.44695377e+00\n",
      "  9.63670015e-03 -7.76384473e-01 -1.57497203e+00 -1.62459165e-01\n",
      " -6.44770026e-01 -1.56905437e+00 -3.01665962e-02 -6.97417617e-01\n",
      " -1.57497406e+00 -4.52060699e-02 -6.55023575e-01 -1.67239201e+00\n",
      "  3.73201817e-02 -6.98808670e-01 -1.73338091e+00 -3.25417891e-02\n",
      " -5.63970923e-01 -1.38157332e+00 -1.20388329e-01 -3.27121198e-01\n",
      " -1.93077862e+00  1.03727281e-02 -4.82418090e-01 -1.89866555e+00\n",
      "  1.29391074e-01 -4.44075197e-01 -1.58596516e+00 -1.45769894e-01\n",
      " -3.28063905e-01 -1.32739556e+00 -8.06409121e-03 -3.10046196e-01\n",
      " -1.39577603e+00  3.48459929e-02 -3.55736971e-01 -1.51152384e+00\n",
      "  5.05819097e-02 -3.57890546e-01 -1.41800761e+00]\n",
      "data: [-1.09024625e-03 -1.85459018e-01 -3.14032614e-01  2.86988355e-02\n",
      " -3.44547004e-01 -7.86641717e-01  1.33864637e-02 -4.85766172e-01\n",
      " -1.47947431e+00 -1.21675178e-01 -5.33281922e-01 -1.80098486e+00\n",
      " -2.78660536e-01 -6.84767127e-01 -2.28495193e+00 -2.10882917e-01\n",
      " -7.54548311e-01 -1.65194249e+00  1.16162345e-01 -7.42946267e-01\n",
      " -1.39261699e+00  4.11025733e-02 -6.91359580e-01 -1.44695377e+00\n",
      "  9.63670015e-03 -7.76384532e-01 -1.57497203e+00 -1.62459165e-01\n",
      " -6.44770026e-01 -1.56905437e+00 -3.01665980e-02 -6.97417617e-01\n",
      " -1.57497406e+00 -4.52060699e-02 -6.55023575e-01 -1.67239201e+00\n",
      "  3.73201817e-02 -6.98808670e-01 -1.73338091e+00 -3.25417891e-02\n",
      " -5.63970923e-01 -1.38157332e+00 -1.20388329e-01 -3.27121198e-01\n",
      " -1.93077862e+00  1.03727281e-02 -4.82418090e-01 -1.89866567e+00\n",
      "  1.29391074e-01 -4.44075197e-01 -1.58596516e+00 -1.45769894e-01\n",
      " -3.28063875e-01 -1.32739568e+00 -8.06409121e-03 -3.10046196e-01\n",
      " -1.39577603e+00  3.48459929e-02 -3.55736971e-01 -1.51152384e+00\n",
      "  5.05819097e-02 -3.57890546e-01 -1.41800761e+00  3.99999991e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0206, -0.1986, -0.2194,  ...,  0.0135, -0.3717, -1.3060],\n",
      "        [ 0.0206, -0.1986, -0.2194,  ...,  0.0135, -0.3717, -1.3060],\n",
      "        [ 0.0206, -0.1986, -0.2194,  ...,  0.0135, -0.3717, -1.3060],\n",
      "        ...,\n",
      "        [ 0.0220,  0.5493, -0.2156,  ..., -0.4780,  1.0602, -0.5751],\n",
      "        [-0.1705, -0.0379,  0.6230,  ..., -0.1740,  0.6634,  0.3175],\n",
      "        [-0.1705, -0.0379,  0.6230,  ..., -0.1740,  0.6634,  0.3175]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02058862 -0.19864194 -0.21936749  0.04538504 -0.3362074  -0.604854\n",
      " -0.03221733 -0.53980345 -1.3948973  -0.18044655 -0.6005795  -1.7074203\n",
      " -0.34920523 -0.7176471  -2.2003784  -0.19234595 -0.8096068  -1.6010739\n",
      "  0.04994918 -0.852268   -1.3999876  -0.01260929 -0.7993009  -1.4453721\n",
      " -0.0293085  -0.9365064  -1.5673518  -0.14506377 -0.6993394  -1.5005053\n",
      " -0.06371187 -0.76266253 -1.4788504  -0.07348984 -0.74027944 -1.5791649\n",
      "  0.03364967 -0.77881503 -1.6239982  -0.04766282 -0.5958096  -1.3277286\n",
      " -0.19036728 -0.3738259  -2.007434   -0.02858002 -0.5452622  -2.007122\n",
      "  0.11470205 -0.50280356 -1.4710398  -0.17235316 -0.35756683 -1.2594469\n",
      " -0.08160876 -0.33741766 -1.3312557  -0.04329379 -0.36656693 -1.4435108\n",
      "  0.01350863 -0.37172592 -1.3059781 ]\n",
      "data: [ 0.02058862 -0.19864196 -0.21936749  0.04538505 -0.3362074  -0.604854\n",
      " -0.03221733 -0.53980345 -1.3948973  -0.18044655 -0.6005795  -1.7074203\n",
      " -0.3492052  -0.7176471  -2.2003784  -0.19234595 -0.8096068  -1.6010739\n",
      "  0.04994918 -0.852268   -1.3999877  -0.01260929 -0.7993009  -1.4453721\n",
      " -0.0293085  -0.93650645 -1.5673518  -0.14506377 -0.6993394  -1.5005053\n",
      " -0.06371187 -0.76266253 -1.4788504  -0.07348984 -0.74027944 -1.5791649\n",
      "  0.03364967 -0.77881503 -1.6239982  -0.04766282 -0.5958096  -1.3277286\n",
      " -0.19036728 -0.3738259  -2.007434   -0.02858002 -0.5452622  -2.007122\n",
      "  0.11470205 -0.50280356 -1.4710398  -0.17235318 -0.35756683 -1.2594469\n",
      " -0.08160875 -0.3374177  -1.3312557  -0.04329379 -0.36656693 -1.4435108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.01350863 -0.37172592 -1.3059781   0.05      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B320>\n",
      "tensor([[ 0.0341, -0.1728, -0.1948,  ...,  0.0557, -0.3526, -1.2167],\n",
      "        [ 0.0341, -0.1728, -0.1948,  ...,  0.0557, -0.3526, -1.2167],\n",
      "        [ 0.0341, -0.1728, -0.1948,  ...,  0.0557, -0.3526, -1.2167],\n",
      "        ...,\n",
      "        [-0.1157,  0.4913, -0.0930,  ..., -0.6423,  1.0823, -0.5354],\n",
      "        [-0.1144,  0.0112,  0.6341,  ..., -0.1586,  0.6691,  0.2947],\n",
      "        [-0.1144,  0.0112,  0.6341,  ..., -0.1586,  0.6691,  0.2947]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03405691 -0.17284644 -0.19476232  0.06734183 -0.28002203 -0.48148346\n",
      " -0.0468074  -0.50670373 -1.34156    -0.20673569 -0.56644803 -1.6548027\n",
      " -0.3646401  -0.6735751  -2.1793995  -0.17672873 -0.79962903 -1.5586883\n",
      "  0.04756106 -0.86004514 -1.3971183  -0.01594089 -0.7971158  -1.440241\n",
      " -0.02672914 -0.95538145 -1.5717608  -0.12425932 -0.70611185 -1.4430073\n",
      " -0.05040067 -0.76633894 -1.4274311  -0.04921228 -0.7296828  -1.5243826\n",
      "  0.07604276 -0.7800696  -1.5509075  -0.02169021 -0.58538806 -1.2696164\n",
      " -0.18906556 -0.3504172  -2.0277467   0.00707774 -0.5361476  -2.0447173\n",
      "  0.17982915 -0.48834568 -1.4015976  -0.16385311 -0.35364032 -1.1911966\n",
      " -0.0670374  -0.32745257 -1.2692808  -0.03457372 -0.34995508 -1.3827633\n",
      "  0.0557228  -0.35262442 -1.216689  ]\n",
      "data: [ 0.03405691 -0.17284644 -0.19476232  0.06734183 -0.28002203 -0.48148346\n",
      " -0.0468074  -0.50670373 -1.34156    -0.20673569 -0.56644803 -1.6548027\n",
      " -0.3646401  -0.67357516 -2.1793995  -0.17672873 -0.79962903 -1.5586884\n",
      "  0.04756106 -0.8600452  -1.3971183  -0.01594089 -0.7971158  -1.440241\n",
      " -0.02672913 -0.95538145 -1.5717607  -0.12425932 -0.70611185 -1.4430073\n",
      " -0.05040068 -0.76633894 -1.427431   -0.04921228 -0.72968274 -1.5243826\n",
      "  0.07604276 -0.7800696  -1.5509075  -0.02169021 -0.58538806 -1.2696164\n",
      " -0.18906555 -0.35041723 -2.0277467   0.00707774 -0.5361476  -2.0447173\n",
      "  0.17982917 -0.48834568 -1.4015976  -0.16385311 -0.35364032 -1.1911966\n",
      " -0.0670374  -0.32745257 -1.2692808  -0.03457372 -0.34995505 -1.3827633\n",
      "  0.0557228  -0.35262445 -1.216689    0.06      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FC18>\n",
      "tensor([[ 0.0168, -0.1201, -0.1750,  ...,  0.0480, -0.3050, -1.1828],\n",
      "        [ 0.0168, -0.1201, -0.1750,  ...,  0.0480, -0.3050, -1.1828],\n",
      "        [ 0.0168, -0.1201, -0.1750,  ...,  0.0480, -0.3050, -1.1828],\n",
      "        ...,\n",
      "        [-0.1496,  0.4370, -0.0019,  ..., -0.5576,  1.0134, -0.3852],\n",
      "        [-0.1118,  0.0336,  0.6269,  ..., -0.1930,  0.6962,  0.2998],\n",
      "        [-0.1118,  0.0336,  0.6269,  ..., -0.1930,  0.6962,  0.2998]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0167976  -0.12014036 -0.17502494  0.04907351 -0.23260932 -0.47145942\n",
      " -0.07473639 -0.46463713 -1.3356723  -0.23276198 -0.531165   -1.6380506\n",
      " -0.3859732  -0.63782513 -2.1533883  -0.19043899 -0.7554561  -1.5308617\n",
      "  0.02711678 -0.8186577  -1.3515099  -0.03553331 -0.7530173  -1.3941956\n",
      " -0.05082856 -0.90939206 -1.5249937  -0.1392021  -0.66103846 -1.419872\n",
      " -0.06747188 -0.7213133  -1.3959149  -0.06998106 -0.68182296 -1.483114\n",
      "  0.05790813 -0.7303335  -1.5072018  -0.03808344 -0.5429709  -1.2488526\n",
      " -0.20180449 -0.3046857  -1.9981236  -0.0097268  -0.4883001  -2.0141962\n",
      "  0.16442728 -0.44087213 -1.3648895  -0.17593455 -0.30755195 -1.1678964\n",
      " -0.08102894 -0.27936953 -1.2487404  -0.04589044 -0.29848307 -1.360079\n",
      "  0.04803614 -0.30502975 -1.1828055 ]\n",
      "data: [ 0.0167976  -0.12014036 -0.17502494  0.04907351 -0.23260932 -0.47145942\n",
      " -0.07473639 -0.46463716 -1.3356723  -0.23276198 -0.531165   -1.6380506\n",
      " -0.38597316 -0.63782513 -2.1533883  -0.190439   -0.7554561  -1.5308616\n",
      "  0.02711678 -0.8186577  -1.3515098  -0.03553331 -0.75301725 -1.3941956\n",
      " -0.05082856 -0.9093921  -1.5249935  -0.1392021  -0.66103846 -1.4198719\n",
      " -0.06747188 -0.7213133  -1.3959149  -0.06998106 -0.68182296 -1.483114\n",
      "  0.05790813 -0.7303335  -1.5072018  -0.03808344 -0.5429709  -1.2488526\n",
      " -0.20180449 -0.3046857  -1.9981236  -0.0097268  -0.48830014 -2.0141962\n",
      "  0.16442728 -0.4408721  -1.3648895  -0.17593457 -0.30755195 -1.1678964\n",
      " -0.08102894 -0.27936953 -1.2487404  -0.04589044 -0.29848307 -1.360079\n",
      "  0.04803614 -0.30502975 -1.1828055   0.07      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0263, -0.0946, -0.2013,  ...,  0.0148, -0.2777, -1.1869],\n",
      "        [-0.0263, -0.0946, -0.2013,  ...,  0.0148, -0.2777, -1.1869],\n",
      "        [-0.0263, -0.0946, -0.2013,  ...,  0.0148, -0.2777, -1.1869],\n",
      "        ...,\n",
      "        [-0.1506,  0.3723,  0.0075,  ..., -0.6544,  0.9600, -0.3805],\n",
      "        [-0.0792, -0.0479,  0.6253,  ..., -0.2030,  0.6750,  0.2497],\n",
      "        [-0.0792, -0.0479,  0.6253,  ..., -0.2030,  0.6750,  0.2497]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.02630716 -0.09463747 -0.20132938  0.00569242 -0.20320226 -0.49726292\n",
      " -0.12466945 -0.43088162 -1.3498225  -0.2775346  -0.4945375  -1.6466143\n",
      " -0.43068373 -0.5962981  -2.1509743  -0.22730388 -0.72679424 -1.5275302\n",
      " -0.02348302 -0.78592646 -1.3533609  -0.07734275 -0.7165222  -1.4002049\n",
      " -0.08312604 -0.8759116  -1.530855   -0.17919365 -0.6342273  -1.4206007\n",
      " -0.10961732 -0.68973804 -1.3966708  -0.10746052 -0.65116    -1.483053\n",
      "  0.03539521 -0.69271505 -1.5093544  -0.08491399 -0.5207099  -1.2513216\n",
      " -0.24494131 -0.28053877 -2.0164003  -0.04612263 -0.45984516 -2.035851\n",
      "  0.13762121 -0.41436413 -1.3667228  -0.21556236 -0.28778422 -1.1707702\n",
      " -0.12976451 -0.2574017  -1.2559929  -0.09106639 -0.26806882 -1.3711171\n",
      "  0.01476059 -0.2777077  -1.1868947 ]\n",
      "data: [-0.02630716 -0.09463747 -0.20132938  0.00569242 -0.20320226 -0.49726292\n",
      " -0.12466945 -0.43088162 -1.3498225  -0.2775346  -0.4945375  -1.6466144\n",
      " -0.43068373 -0.5962981  -2.1509743  -0.22730389 -0.7267943  -1.5275302\n",
      " -0.02348302 -0.78592646 -1.3533609  -0.07734275 -0.7165222  -1.4002049\n",
      " -0.08312604 -0.87591153 -1.530855   -0.17919365 -0.6342273  -1.4206005\n",
      " -0.10961732 -0.68973804 -1.3966708  -0.10746052 -0.65116    -1.483053\n",
      "  0.03539521 -0.69271505 -1.5093544  -0.08491399 -0.5207099  -1.2513216\n",
      " -0.24494131 -0.28053877 -2.0164003  -0.04612263 -0.45984516 -2.035851\n",
      "  0.13762121 -0.41436413 -1.3667228  -0.21556236 -0.28778422 -1.1707702\n",
      " -0.12976451 -0.2574017  -1.2559929  -0.09106639 -0.26806882 -1.3711171\n",
      "  0.01476059 -0.2777077  -1.1868947   0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F588>\n",
      "tensor([[-0.0122, -0.0195, -0.1724,  ...,  0.0101, -0.2068, -1.1632],\n",
      "        [-0.0122, -0.0195, -0.1724,  ...,  0.0101, -0.2068, -1.1632],\n",
      "        [-0.0122, -0.0195, -0.1724,  ...,  0.0101, -0.2068, -1.1632],\n",
      "        ...,\n",
      "        [-0.1941,  0.3325, -0.0229,  ..., -0.7489,  0.9045, -0.3570],\n",
      "        [-0.1131, -0.1226,  0.5862,  ..., -0.2228,  0.6012,  0.2420],\n",
      "        [-0.1131, -0.1226,  0.5862,  ..., -0.2228,  0.6012,  0.2420]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01221296 -0.01951683 -0.17237547  0.01078413 -0.12084042 -0.47560734\n",
      " -0.14078696 -0.3448194  -1.3173352  -0.29581323 -0.40883246 -1.6034589\n",
      " -0.44991168 -0.49025783 -2.1127825  -0.20737389 -0.6602268  -1.4819871\n",
      " -0.0516589  -0.72161865 -1.326645   -0.09242678 -0.6409651  -1.3823396\n",
      " -0.08916516 -0.81017137 -1.5093873  -0.1683001  -0.5742959  -1.3847604\n",
      " -0.11386181 -0.6201432  -1.353158   -0.11700919 -0.5824908  -1.4409254\n",
      "  0.04607001 -0.6052184  -1.46092    -0.09146855 -0.463995   -1.2279161\n",
      " -0.24076003 -0.22823507 -1.9759616  -0.05165398 -0.38994256 -2.007112\n",
      "  0.14219874 -0.35192385 -1.3309193  -0.20756918 -0.23559909 -1.1477194\n",
      " -0.15100862 -0.20222166 -1.2401588  -0.11655803 -0.19351341 -1.3572863\n",
      "  0.01007728 -0.20681125 -1.1632085 ]\n",
      "data: [-0.01221296 -0.01951683 -0.17237547  0.01078413 -0.12084042 -0.47560734\n",
      " -0.14078696 -0.34481943 -1.3173352  -0.29581323 -0.40883246 -1.6034589\n",
      " -0.44991168 -0.49025783 -2.1127825  -0.20737389 -0.6602268  -1.4819871\n",
      " -0.0516589  -0.72161865 -1.326645   -0.09242678 -0.6409651  -1.3823396\n",
      " -0.08916517 -0.81017137 -1.5093873  -0.1683001  -0.5742959  -1.3847604\n",
      " -0.11386181 -0.6201432  -1.353158   -0.11700919 -0.5824908  -1.4409252\n",
      "  0.04607001 -0.6052184  -1.46092    -0.09146855 -0.463995   -1.2279161\n",
      " -0.24076003 -0.22823507 -1.9759616  -0.05165398 -0.38994256 -2.007112\n",
      "  0.14219874 -0.35192385 -1.3309191  -0.20756918 -0.23559909 -1.1477194\n",
      " -0.15100862 -0.20222166 -1.2401588  -0.11655803 -0.19351341 -1.3572863\n",
      "  0.01007728 -0.20681125 -1.1632085   0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[-0.0265, -0.0443, -0.2391,  ..., -0.0049, -0.2073, -1.3413],\n",
      "        [-0.0265, -0.0443, -0.2391,  ..., -0.0049, -0.2073, -1.3413],\n",
      "        [-0.0265, -0.0443, -0.2391,  ..., -0.0049, -0.2073, -1.3413],\n",
      "        ...,\n",
      "        [-0.2354,  0.3038, -0.0719,  ..., -0.7485,  0.7761, -0.2819],\n",
      "        [-0.1701, -0.1121,  0.5261,  ..., -0.2801,  0.6466,  0.2580],\n",
      "        [-0.1701, -0.1121,  0.5261,  ..., -0.2801,  0.6466,  0.2580]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.02647715 -0.04427917 -0.23907028 -0.01347316 -0.20134161 -0.68356276\n",
      " -0.07764752 -0.35760206 -1.3852165  -0.2236856  -0.41321963 -1.6908458\n",
      " -0.4112196  -0.5399482  -2.1558254  -0.247407   -0.6335511  -1.551633\n",
      "  0.00630017 -0.64094245 -1.3345646  -0.03879696 -0.5815222  -1.38667\n",
      " -0.03396164 -0.68881536 -1.5016315  -0.20291056 -0.51709425 -1.4751363\n",
      " -0.09584155 -0.57182753 -1.4573326  -0.09452031 -0.54290986 -1.5653425\n",
      "  0.04530135 -0.5619247  -1.6347537  -0.10324716 -0.4453716  -1.297861\n",
      " -0.19123043 -0.2149047  -1.858316   -0.04792367 -0.3577793  -1.8428115\n",
      "  0.11104997 -0.32640138 -1.4866424  -0.20571083 -0.19717404 -1.2447718\n",
      " -0.11589526 -0.1761277  -1.3241389  -0.06011948 -0.198919   -1.447408\n",
      " -0.00491882 -0.20726772 -1.3412871 ]\n",
      "data: [-0.02647715 -0.04427917 -0.23907028 -0.01347316 -0.20134161 -0.68356276\n",
      " -0.07764752 -0.35760203 -1.3852165  -0.2236856  -0.41321963 -1.6908458\n",
      " -0.4112196  -0.5399482  -2.1558254  -0.247407   -0.6335511  -1.551633\n",
      "  0.00630017 -0.64094245 -1.3345646  -0.03879696 -0.5815222  -1.3866699\n",
      " -0.03396164 -0.68881536 -1.5016315  -0.20291056 -0.51709425 -1.4751363\n",
      " -0.09584155 -0.57182753 -1.4573326  -0.09452031 -0.54290986 -1.5653425\n",
      "  0.04530135 -0.5619247  -1.6347537  -0.10324716 -0.4453716  -1.297861\n",
      " -0.19123043 -0.2149047  -1.858316   -0.04792367 -0.35777932 -1.8428115\n",
      "  0.11104997 -0.32640135 -1.4866424  -0.20571083 -0.19717403 -1.2447718\n",
      " -0.11589525 -0.1761277  -1.324139   -0.06011948 -0.198919   -1.447408\n",
      " -0.00491882 -0.20726772 -1.3412871   0.1       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FB00>\n",
      "tensor([[ 0.0323, -0.1593, -0.2560,  ...,  0.0422, -0.3322, -1.3509],\n",
      "        [ 0.0323, -0.1593, -0.2560,  ...,  0.0422, -0.3322, -1.3509],\n",
      "        [ 0.0323, -0.1593, -0.2560,  ...,  0.0422, -0.3322, -1.3509],\n",
      "        ...,\n",
      "        [-0.3638,  0.3161, -0.3838,  ..., -0.8946,  0.7929, -0.5761],\n",
      "        [-0.1562, -0.0241,  0.6588,  ..., -0.2531,  0.7445,  0.3549],\n",
      "        [-0.1562, -0.0241,  0.6588,  ..., -0.2531,  0.7445,  0.3549]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 3.2281902e-02 -1.5932040e-01 -2.5604641e-01  5.7168100e-02\n",
      " -2.9721183e-01 -6.7482585e-01 -1.7562367e-02 -4.6619317e-01\n",
      " -1.4180162e+00 -1.6014907e-01 -5.2309239e-01 -1.7194613e+00\n",
      " -3.2315266e-01 -6.3492036e-01 -2.2127180e+00 -1.7250912e-01\n",
      " -7.5450814e-01 -1.5981178e+00  5.7390422e-02 -7.7576828e-01\n",
      " -1.4121785e+00  5.0859004e-03 -7.1658945e-01 -1.4659947e+00\n",
      "  6.2972307e-05 -8.3744848e-01 -1.5838314e+00 -1.3154756e-01\n",
      " -6.5180051e-01 -1.5156091e+00 -4.1641548e-02 -7.0242846e-01\n",
      " -1.5017561e+00 -5.1654272e-02 -6.7161667e-01 -1.6021274e+00\n",
      "  7.0772290e-02 -6.9818652e-01 -1.6540765e+00 -4.2363845e-02\n",
      " -5.6691790e-01 -1.3439214e+00 -1.4718030e-01 -3.3713371e-01\n",
      " -1.9489239e+00 -7.3163211e-04 -4.8504817e-01 -1.9472644e+00\n",
      "  1.4519979e-01 -4.5341691e-01 -1.5104817e+00 -1.4813118e-01\n",
      " -3.3072335e-01 -1.2821810e+00 -6.3470170e-02 -3.0736637e-01\n",
      " -1.3579447e+00 -2.0277768e-02 -3.2338572e-01 -1.4759816e+00\n",
      "  4.2225674e-02 -3.3219969e-01 -1.3508815e+00]\n",
      "data: [ 3.2281902e-02 -1.5932040e-01 -2.5604641e-01  5.7168104e-02\n",
      " -2.9721183e-01 -6.7482585e-01 -1.7562367e-02 -4.6619317e-01\n",
      " -1.4180162e+00 -1.6014905e-01 -5.2309239e-01 -1.7194613e+00\n",
      " -3.2315266e-01 -6.3492036e-01 -2.2127180e+00 -1.7250912e-01\n",
      " -7.5450814e-01 -1.5981178e+00  5.7390422e-02 -7.7576828e-01\n",
      " -1.4121785e+00  5.0859004e-03 -7.1658945e-01 -1.4659947e+00\n",
      "  6.2972307e-05 -8.3744848e-01 -1.5838314e+00 -1.3154756e-01\n",
      " -6.5180051e-01 -1.5156091e+00 -4.1641548e-02 -7.0242846e-01\n",
      " -1.5017562e+00 -5.1654272e-02 -6.7161667e-01 -1.6021274e+00\n",
      "  7.0772290e-02 -6.9818652e-01 -1.6540763e+00 -4.2363845e-02\n",
      " -5.6691790e-01 -1.3439213e+00 -1.4718030e-01 -3.3713371e-01\n",
      " -1.9489239e+00 -7.3163211e-04 -4.8504817e-01 -1.9472644e+00\n",
      "  1.4519979e-01 -4.5341691e-01 -1.5104817e+00 -1.4813118e-01\n",
      " -3.3072335e-01 -1.2821811e+00 -6.3470170e-02 -3.0736637e-01\n",
      " -1.3579448e+00 -2.0277767e-02 -3.2338569e-01 -1.4759816e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4.2225674e-02 -3.3219969e-01 -1.3508815e+00  1.1000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0353, -0.1734, -0.2360,  ...,  0.0893, -0.3600, -1.2703],\n",
      "        [ 0.0353, -0.1734, -0.2360,  ...,  0.0893, -0.3600, -1.2703],\n",
      "        [ 0.0353, -0.1734, -0.2360,  ...,  0.0893, -0.3600, -1.2703],\n",
      "        ...,\n",
      "        [-0.0679,  0.4841, -0.1292,  ..., -0.6250,  1.0129, -0.4802],\n",
      "        [-0.1654, -0.0341,  0.6249,  ..., -0.2452,  0.6606,  0.3022],\n",
      "        [-0.1654, -0.0341,  0.6249,  ..., -0.2452,  0.6606,  0.3022]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03528165 -0.17344403 -0.2359625   0.07233478 -0.29329365 -0.55820733\n",
      " -0.02182698 -0.50843817 -1.385828   -0.1731872  -0.56922877 -1.7002871\n",
      " -0.3322549  -0.6907932  -2.2006679  -0.16944154 -0.7887374  -1.5959706\n",
      "  0.08437431 -0.8408869  -1.4060671   0.01968625 -0.7844103  -1.4474926\n",
      "  0.00471692 -0.93304956 -1.5758383  -0.1114136  -0.68903834 -1.4849896\n",
      " -0.02435976 -0.7567875  -1.4724143  -0.0230199  -0.726938   -1.5678449\n",
      "  0.0946724  -0.7806461  -1.608279   -0.00292956 -0.58122563 -1.3036544\n",
      " -0.15918888 -0.3440941  -2.053091    0.03340822 -0.53541666 -2.0569718\n",
      "  0.19578724 -0.48808205 -1.4515297  -0.13963993 -0.34503382 -1.2301335\n",
      " -0.0306882  -0.32138258 -1.3079009   0.01446123 -0.35423267 -1.4226646\n",
      "  0.08927412 -0.3600458  -1.2702577 ]\n",
      "data: [ 0.03528165 -0.17344402 -0.23596248  0.07233478 -0.29329365 -0.55820733\n",
      " -0.02182698 -0.50843817 -1.3858279  -0.1731872  -0.56922877 -1.7002872\n",
      " -0.33225486 -0.6907932  -2.2006679  -0.16944152 -0.7887374  -1.5959706\n",
      "  0.08437432 -0.8408869  -1.4060673   0.01968625 -0.7844103  -1.4474927\n",
      "  0.00471692 -0.93304956 -1.5758383  -0.11141359 -0.68903834 -1.4849896\n",
      " -0.02435976 -0.7567875  -1.4724143  -0.0230199  -0.726938   -1.5678449\n",
      "  0.0946724  -0.7806461  -1.608279   -0.00292956 -0.58122563 -1.3036544\n",
      " -0.15918888 -0.3440941  -2.053091    0.03340822 -0.53541666 -2.0569718\n",
      "  0.19578724 -0.48808205 -1.4515297  -0.13963993 -0.34503382 -1.2301335\n",
      " -0.03068819 -0.3213826  -1.3079009   0.01446123 -0.35423267 -1.4226646\n",
      "  0.08927412 -0.3600458  -1.2702577   0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[ 0.0212, -0.1570, -0.1983,  ...,  0.0791, -0.3484, -1.2077],\n",
      "        [ 0.0212, -0.1570, -0.1983,  ...,  0.0791, -0.3484, -1.2077],\n",
      "        [ 0.0212, -0.1570, -0.1983,  ...,  0.0791, -0.3484, -1.2077],\n",
      "        ...,\n",
      "        [-0.0617,  0.4504, -0.0755,  ..., -0.5759,  1.0076, -0.4486],\n",
      "        [-0.0949,  0.0157,  0.6340,  ..., -0.1683,  0.6897,  0.2760],\n",
      "        [-0.0949,  0.0157,  0.6340,  ..., -0.1683,  0.6897,  0.2760]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02121846 -0.1570064  -0.19827941  0.05410865 -0.28437907 -0.51209664\n",
      " -0.0406084  -0.49883997 -1.345313   -0.19343191 -0.5621865  -1.6618816\n",
      " -0.36463016 -0.6891098  -2.1554716  -0.18780719 -0.77518964 -1.5476375\n",
      "  0.07059209 -0.82337844 -1.3447245   0.00493374 -0.7694763  -1.3867979\n",
      " -0.00669542 -0.9143131  -1.5159769  -0.12959513 -0.6700028  -1.43577\n",
      " -0.03904088 -0.739156   -1.4181229  -0.03737925 -0.71121    -1.5158329\n",
      "  0.0854644  -0.7623627  -1.557787   -0.01896315 -0.5653377  -1.2477964\n",
      " -0.17316218 -0.33178622 -1.9930304   0.01838289 -0.5211983  -1.993432\n",
      "  0.18653299 -0.4763216  -1.3897524  -0.15327768 -0.32594913 -1.1760708\n",
      " -0.04323806 -0.30762208 -1.2498283   0.00270906 -0.3405652  -1.3654996\n",
      "  0.07914429 -0.34843814 -1.2077348 ]\n",
      "data: [ 0.02121846 -0.1570064  -0.19827943  0.05410864 -0.28437907 -0.51209664\n",
      " -0.04060839 -0.49883997 -1.345313   -0.19343191 -0.5621865  -1.6618816\n",
      " -0.36463016 -0.6891098  -2.1554716  -0.18780717 -0.77518964 -1.5476375\n",
      "  0.07059209 -0.82337844 -1.3447245   0.00493374 -0.7694763  -1.3867979\n",
      " -0.00669542 -0.9143131  -1.5159769  -0.12959513 -0.6700028  -1.4357699\n",
      " -0.03904088 -0.739156   -1.4181229  -0.03737925 -0.71121    -1.5158328\n",
      "  0.0854644  -0.7623627  -1.5577868  -0.01896315 -0.5653377  -1.2477964\n",
      " -0.17316218 -0.33178625 -1.9930304   0.01838289 -0.5211983  -1.993432\n",
      "  0.18653299 -0.4763216  -1.3897524  -0.15327768 -0.32594913 -1.1760708\n",
      " -0.04323806 -0.30762208 -1.2498283   0.00270906 -0.34056517 -1.3654996\n",
      "  0.07914429 -0.34843814 -1.2077348   0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[ 0.0092, -0.1104, -0.1812,  ...,  0.0430, -0.3011, -1.1755],\n",
      "        [ 0.0092, -0.1104, -0.1812,  ...,  0.0430, -0.3011, -1.1755],\n",
      "        [ 0.0092, -0.1104, -0.1812,  ...,  0.0430, -0.3011, -1.1755],\n",
      "        ...,\n",
      "        [-0.1724,  0.4156, -0.1258,  ..., -0.5874,  0.9873, -0.5281],\n",
      "        [-0.0893, -0.0183,  0.6398,  ..., -0.1616,  0.6751,  0.2665],\n",
      "        [-0.0893, -0.0183,  0.6398,  ..., -0.1616,  0.6751,  0.2665]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00920619 -0.11040959 -0.18120907  0.04277122 -0.22130924 -0.46345684\n",
      " -0.08504365 -0.45249438 -1.3334761  -0.24113393 -0.5194492  -1.6346922\n",
      " -0.39686683 -0.6239455  -2.1505454  -0.1927304  -0.74617255 -1.5255258\n",
      "  0.01588856 -0.8078392  -1.3503425  -0.04421407 -0.74164844 -1.3960652\n",
      " -0.05786277 -0.9008874  -1.526479   -0.14358056 -0.65219426 -1.4154484\n",
      " -0.07498737 -0.71066946 -1.3926358  -0.07935505 -0.67364955 -1.4802003\n",
      "  0.05254887 -0.7175128  -1.5053918  -0.04679558 -0.5374482  -1.2434316\n",
      " -0.21095833 -0.2997893  -2.0084288  -0.01760805 -0.48211265 -2.025835\n",
      "  0.15672275 -0.43630862 -1.3574083  -0.18001188 -0.3046372  -1.1647704\n",
      " -0.09156282 -0.2778916  -1.2449939  -0.05596478 -0.2922063  -1.3578541\n",
      "  0.04302462 -0.3010909  -1.1754882 ]\n",
      "data: [ 0.00920619 -0.11040959 -0.18120907  0.04277122 -0.22130924 -0.46345684\n",
      " -0.08504365 -0.45249438 -1.3334761  -0.24113391 -0.5194492  -1.6346922\n",
      " -0.39686683 -0.6239455  -2.1505454  -0.19273038 -0.74617255 -1.5255258\n",
      "  0.01588856 -0.8078392  -1.3503425  -0.04421407 -0.74164844 -1.3960652\n",
      " -0.05786277 -0.9008874  -1.526479   -0.14358056 -0.65219426 -1.4154484\n",
      " -0.07498737 -0.71066946 -1.3926358  -0.07935505 -0.67364955 -1.4802003\n",
      "  0.05254887 -0.71751285 -1.5053918  -0.04679558 -0.5374482  -1.2434316\n",
      " -0.21095833 -0.2997893  -2.0084288  -0.01760805 -0.48211265 -2.025835\n",
      "  0.15672275 -0.43630862 -1.3574083  -0.18001188 -0.3046372  -1.1647704\n",
      " -0.09156282 -0.2778916  -1.2449939  -0.05596478 -0.2922063  -1.3578541\n",
      "  0.04302462 -0.3010909  -1.1754882   0.14      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0329, -0.0766, -0.1995,  ...,  0.0200, -0.2576, -1.1957],\n",
      "        [-0.0329, -0.0766, -0.1995,  ...,  0.0200, -0.2576, -1.1957],\n",
      "        [-0.0329, -0.0766, -0.1995,  ...,  0.0200, -0.2576, -1.1957],\n",
      "        ...,\n",
      "        [-0.1643,  0.3589, -0.0141,  ..., -0.6540,  0.9554, -0.3974],\n",
      "        [-0.0946, -0.0561,  0.6126,  ..., -0.2384,  0.6479,  0.2591],\n",
      "        [-0.0946, -0.0561,  0.6126,  ..., -0.2384,  0.6479,  0.2591]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.03291847 -0.07664266 -0.19953525 -0.00251754 -0.19424416 -0.5091144\n",
      " -0.11393487 -0.41235706 -1.3444035  -0.26436952 -0.47320548 -1.6481514\n",
      " -0.42552197 -0.58772004 -2.141229   -0.24075912 -0.6997516  -1.5260775\n",
      " -0.00451471 -0.7491297  -1.3347075  -0.05916198 -0.6865891  -1.3772871\n",
      " -0.06023099 -0.833573   -1.5081592  -0.18805556 -0.59946775 -1.4183464\n",
      " -0.10291313 -0.6591323  -1.3988049  -0.09082948 -0.6221423  -1.489409\n",
      "  0.05096409 -0.6690146  -1.5291426  -0.08433003 -0.49231693 -1.2416303\n",
      " -0.2380556  -0.25142297 -1.9882412  -0.03669168 -0.4333969  -1.9971795\n",
      "  0.14737137 -0.38597536 -1.3778822  -0.21902314 -0.25333196 -1.1639681\n",
      " -0.11793052 -0.22618376 -1.2455053  -0.07188539 -0.2482675  -1.3621953\n",
      "  0.01998162 -0.2576353  -1.1956732 ]\n",
      "data: [-0.03291847 -0.07664266 -0.19953525 -0.00251754 -0.19424416 -0.5091144\n",
      " -0.11393487 -0.41235706 -1.3444035  -0.26436952 -0.47320548 -1.6481514\n",
      " -0.42552197 -0.58772004 -2.141229   -0.24075912 -0.6997516  -1.5260776\n",
      " -0.00451471 -0.7491297  -1.3347075  -0.05916198 -0.6865891  -1.3772871\n",
      " -0.06023099 -0.833573   -1.5081592  -0.18805556 -0.59946775 -1.4183464\n",
      " -0.10291313 -0.6591323  -1.3988049  -0.09082948 -0.6221423  -1.489409\n",
      "  0.05096409 -0.6690146  -1.5291426  -0.08433004 -0.49231693 -1.2416303\n",
      " -0.23805562 -0.25142297 -1.9882413  -0.03669168 -0.4333969  -1.9971795\n",
      "  0.14737137 -0.38597533 -1.3778822  -0.21902314 -0.25333196 -1.1639681\n",
      " -0.11793052 -0.22618376 -1.2455053  -0.07188539 -0.2482675  -1.3621953\n",
      "  0.01998162 -0.2576353  -1.1956732   0.15      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F635F8>\n",
      "tensor([[-0.0100, -0.0466, -0.2143,  ..., -0.0199, -0.2168, -1.2462],\n",
      "        [-0.0100, -0.0466, -0.2143,  ..., -0.0199, -0.2168, -1.2462],\n",
      "        [-0.0100, -0.0466, -0.2143,  ..., -0.0199, -0.2168, -1.2462],\n",
      "        ...,\n",
      "        [-0.2809,  0.2417, -0.1651,  ..., -0.7172,  0.7234, -0.4467],\n",
      "        [-0.0646, -0.0535,  0.6542,  ..., -0.1620,  0.7063,  0.3082],\n",
      "        [-0.0646, -0.0535,  0.6542,  ..., -0.1620,  0.7063,  0.3082]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01002109 -0.04658733 -0.21429077  0.00945795 -0.17111917 -0.59071296\n",
      " -0.10679469 -0.37178478 -1.373664   -0.2568999  -0.4326542  -1.6718144\n",
      " -0.42743862 -0.52613306 -2.1605487  -0.21557136 -0.6689651  -1.527144\n",
      " -0.03218327 -0.7088196  -1.3406271  -0.07770534 -0.6414557  -1.3994038\n",
      " -0.08764682 -0.791536   -1.5238743  -0.1792225  -0.56969684 -1.4360394\n",
      " -0.11512566 -0.6183773  -1.4078465  -0.12803651 -0.5878093  -1.5066216\n",
      "  0.01653478 -0.6079291  -1.5452574  -0.1007706  -0.467213   -1.2717396\n",
      " -0.23582543 -0.24115092 -1.9654263  -0.07061258 -0.39260775 -1.9821033\n",
      "  0.09677228 -0.35843438 -1.4011675  -0.20688541 -0.23466627 -1.2025263\n",
      " -0.14990725 -0.20591119 -1.2864199  -0.11380653 -0.20513229 -1.4071771\n",
      " -0.01992923 -0.21676044 -1.2462152 ]\n",
      "data: [-0.01002109 -0.04658733 -0.21429077  0.00945795 -0.17111917 -0.59071296\n",
      " -0.10679469 -0.37178478 -1.3736641  -0.2568999  -0.4326542  -1.6718144\n",
      " -0.42743862 -0.52613306 -2.1605487  -0.21557136 -0.6689651  -1.527144\n",
      " -0.03218327 -0.7088196  -1.3406272  -0.07770534 -0.6414557  -1.3994038\n",
      " -0.08764682 -0.791536   -1.5238742  -0.1792225  -0.56969684 -1.4360394\n",
      " -0.11512566 -0.6183773  -1.4078463  -0.12803651 -0.5878093  -1.5066216\n",
      "  0.01653478 -0.6079291  -1.5452574  -0.1007706  -0.46721303 -1.2717396\n",
      " -0.23582545 -0.24115092 -1.9654263  -0.07061258 -0.39260778 -1.9821032\n",
      "  0.09677228 -0.35843438 -1.4011674  -0.20688541 -0.23466627 -1.2025263\n",
      " -0.14990725 -0.2059112  -1.2864199  -0.11380653 -0.20513229 -1.4071771\n",
      " -0.01992923 -0.21676044 -1.2462152   0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F080>\n",
      "tensor([[ 0.0212, -0.0505, -0.1966,  ...,  0.0223, -0.2271, -1.2627],\n",
      "        [ 0.0212, -0.0505, -0.1966,  ...,  0.0223, -0.2271, -1.2627],\n",
      "        [ 0.0212, -0.0505, -0.1966,  ...,  0.0223, -0.2271, -1.2627],\n",
      "        ...,\n",
      "        [-0.2965,  0.2887, -0.2409,  ..., -0.8180,  0.7438, -0.4318],\n",
      "        [-0.1716, -0.1602,  0.5465,  ..., -0.2462,  0.5995,  0.2456],\n",
      "        [-0.1716, -0.1602,  0.5465,  ..., -0.2462,  0.5995,  0.2456]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0211654  -0.05047559 -0.19663718  0.03375708 -0.18948393 -0.6221064\n",
      " -0.05906234 -0.3641242  -1.3494546  -0.2051312  -0.42508054 -1.6471419\n",
      " -0.38119656 -0.52996993 -2.1240613  -0.18461256 -0.6602026  -1.4982786\n",
      "  0.0088423  -0.68728304 -1.3219869  -0.0382815  -0.6216347  -1.3821883\n",
      " -0.03994044 -0.75778866 -1.4974217  -0.14644247 -0.5579792  -1.4188471\n",
      " -0.07026481 -0.60723066 -1.3945801  -0.0882373  -0.5809759  -1.4975753\n",
      "  0.04892914 -0.5958185  -1.5435283  -0.06600761 -0.47175792 -1.2538061\n",
      " -0.17231993 -0.24804536 -1.8771422  -0.02922847 -0.38903585 -1.8828504\n",
      "  0.12551506 -0.36451897 -1.4048293  -0.16053669 -0.23558243 -1.192677\n",
      " -0.0974599  -0.2131626  -1.279881   -0.05736805 -0.21597034 -1.4012647\n",
      "  0.022284   -0.22708045 -1.2626698 ]\n",
      "data: [ 0.0211654  -0.05047559 -0.1966372   0.03375708 -0.18948393 -0.6221064\n",
      " -0.05906234 -0.3641242  -1.3494546  -0.2051312  -0.42508054 -1.6471419\n",
      " -0.38119656 -0.52996993 -2.1240613  -0.18461256 -0.6602026  -1.4982786\n",
      "  0.0088423  -0.68728304 -1.3219868  -0.0382815  -0.6216347  -1.3821883\n",
      " -0.03994044 -0.7577887  -1.4974217  -0.14644247 -0.5579792  -1.4188471\n",
      " -0.07026481 -0.60723066 -1.3945801  -0.08823731 -0.5809759  -1.4975753\n",
      "  0.04892914 -0.5958185  -1.5435283  -0.06600761 -0.47175792 -1.2538061\n",
      " -0.17231993 -0.24804536 -1.8771422  -0.02922847 -0.38903582 -1.8828503\n",
      "  0.12551506 -0.36451897 -1.4048293  -0.16053669 -0.23558243 -1.192677\n",
      " -0.0974599  -0.2131626  -1.279881   -0.05736805 -0.21597034 -1.4012647\n",
      "  0.022284   -0.22708043 -1.2626698   0.17      ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0177, -0.0627, -0.2417,  ...,  0.0260, -0.2482, -1.2737],\n",
      "        [ 0.0177, -0.0627, -0.2417,  ...,  0.0260, -0.2482, -1.2737],\n",
      "        [ 0.0177, -0.0627, -0.2417,  ...,  0.0260, -0.2482, -1.2737],\n",
      "        ...,\n",
      "        [-0.3004,  0.2559, -0.2681,  ..., -0.8152,  0.7170, -0.4528],\n",
      "        [-0.1148, -0.0842,  0.6048,  ..., -0.2336,  0.7112,  0.2694],\n",
      "        [-0.1148, -0.0842,  0.6048,  ..., -0.2336,  0.7112,  0.2694]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01767841 -0.06270254 -0.24172597  0.04404687 -0.18799989 -0.6367176\n",
      " -0.07738718 -0.38413763 -1.4199529  -0.22087315 -0.4511103  -1.7013267\n",
      " -0.3752348  -0.5410601  -2.1944463  -0.17190146 -0.6800946  -1.5689623\n",
      " -0.00744689 -0.72265536 -1.3960717  -0.0517709  -0.650134   -1.4557456\n",
      " -0.06143471 -0.8000837  -1.5723823  -0.13865767 -0.5873041  -1.4872031\n",
      " -0.07763106 -0.6355318  -1.4501501  -0.10319206 -0.60618025 -1.5356202\n",
      "  0.03562517 -0.62229806 -1.5654371  -0.06828759 -0.49526614 -1.3266162\n",
      " -0.1897711  -0.26589316 -1.9969885  -0.03727631 -0.41604847 -2.0132692\n",
      "  0.1194064  -0.3879677  -1.4298156  -0.16274984 -0.26639903 -1.2547051\n",
      " -0.1098426  -0.23776166 -1.3342785  -0.07161406 -0.23196076 -1.4508628\n",
      "  0.02602027 -0.24818867 -1.2737225 ]\n",
      "data: [ 0.01767841 -0.06270254 -0.24172597  0.04404687 -0.1879999  -0.6367176\n",
      " -0.07738718 -0.38413766 -1.4199529  -0.22087315 -0.4511103  -1.7013267\n",
      " -0.37523478 -0.5410601  -2.1944463  -0.17190148 -0.6800946  -1.5689625\n",
      " -0.00744689 -0.72265536 -1.3960717  -0.0517709  -0.650134   -1.4557456\n",
      " -0.06143471 -0.8000837  -1.5723823  -0.13865767 -0.5873041  -1.4872031\n",
      " -0.07763106 -0.6355318  -1.4501501  -0.10319206 -0.60618025 -1.5356202\n",
      "  0.03562517 -0.62229806 -1.565437   -0.06828759 -0.49526614 -1.3266162\n",
      " -0.1897711  -0.26589316 -1.9969885  -0.03727631 -0.41604847 -2.0132692\n",
      "  0.1194064  -0.3879677  -1.4298156  -0.16274984 -0.26639903 -1.2547051\n",
      " -0.1098426  -0.23776168 -1.3342785  -0.07161406 -0.23196076 -1.4508628\n",
      "  0.02602027 -0.24818867 -1.2737225   0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63F28>\n",
      "tensor([[ 0.0370, -0.0206, -0.2148,  ...,  0.0534, -0.2165, -1.2428],\n",
      "        [ 0.0370, -0.0206, -0.2148,  ...,  0.0534, -0.2165, -1.2428],\n",
      "        [ 0.0370, -0.0206, -0.2148,  ...,  0.0534, -0.2165, -1.2428],\n",
      "        ...,\n",
      "        [-0.1964,  0.3326, -0.1276,  ..., -0.8665,  0.7986, -0.3113],\n",
      "        [-0.1444, -0.2043,  0.5417,  ..., -0.2163,  0.5659,  0.2174],\n",
      "        [-0.1444, -0.2043,  0.5417,  ..., -0.2163,  0.5659,  0.2174]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03700146 -0.02062795 -0.21475615  0.05044262 -0.14969347 -0.6100035\n",
      " -0.06524838 -0.33640516 -1.3596042  -0.21229129 -0.40091464 -1.6461729\n",
      " -0.37938738 -0.49581397 -2.1304321  -0.15640317 -0.6422946  -1.5085875\n",
      "  0.00543308 -0.68149215 -1.3485421  -0.03848855 -0.6074935  -1.4118013\n",
      " -0.03418195 -0.7580929  -1.5253851  -0.11987756 -0.5476826  -1.4301478\n",
      " -0.05628897 -0.59382415 -1.3959904  -0.0774654  -0.5696681  -1.4890355\n",
      "  0.06672166 -0.57893157 -1.5184754  -0.04663341 -0.45910037 -1.2704586\n",
      " -0.15824193 -0.23620325 -1.9211133  -0.01019572 -0.38019085 -1.9352747\n",
      "  0.1528647  -0.35640842 -1.3867841  -0.13678317 -0.23022555 -1.2059196\n",
      " -0.08447917 -0.20748107 -1.2934237  -0.04812729 -0.20057057 -1.4116306\n",
      "  0.05337166 -0.21650855 -1.2427509 ]\n",
      "data: [ 0.03700146 -0.02062795 -0.21475615  0.05044262 -0.14969347 -0.6100035\n",
      " -0.06524838 -0.33640516 -1.3596042  -0.21229129 -0.40091464 -1.646173\n",
      " -0.37938735 -0.49581397 -2.1304321  -0.15640317 -0.64229465 -1.5085875\n",
      "  0.00543308 -0.68149215 -1.348542   -0.03848855 -0.6074935  -1.4118013\n",
      " -0.03418195 -0.7580929  -1.5253851  -0.11987755 -0.5476826  -1.4301476\n",
      " -0.05628897 -0.59382415 -1.3959903  -0.0774654  -0.5696681  -1.4890355\n",
      "  0.06672166 -0.57893157 -1.5184753  -0.04663341 -0.45910037 -1.2704586\n",
      " -0.15824193 -0.23620325 -1.9211133  -0.01019572 -0.38019085 -1.9352746\n",
      "  0.1528647  -0.35640842 -1.3867841  -0.13678317 -0.23022555 -1.2059196\n",
      " -0.08447917 -0.20748109 -1.2934237  -0.04812729 -0.20057057 -1.4116305\n",
      "  0.05337166 -0.21650857 -1.2427509   0.19      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F358>\n",
      "tensor([[ 0.0105, -0.0675, -0.2339,  ...,  0.0333, -0.2498, -1.2820],\n",
      "        [ 0.0105, -0.0675, -0.2339,  ...,  0.0333, -0.2498, -1.2820],\n",
      "        [ 0.0105, -0.0675, -0.2339,  ...,  0.0333, -0.2498, -1.2820],\n",
      "        ...,\n",
      "        [-0.3359,  0.2206, -0.3029,  ..., -0.8750,  0.6431, -0.4498],\n",
      "        [-0.1204, -0.0530,  0.5813,  ..., -0.2389,  0.7447,  0.2423],\n",
      "        [-0.1204, -0.0530,  0.5813,  ..., -0.2389,  0.7447,  0.2423]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01054924 -0.06752459 -0.23389022  0.03627575 -0.2062505  -0.6504991\n",
      " -0.05819923 -0.38757378 -1.4080895  -0.19838628 -0.4511752  -1.6985343\n",
      " -0.35981792 -0.55913484 -2.1797564  -0.18682666 -0.6701329  -1.5623313\n",
      "  0.02002616 -0.6980088  -1.3661855  -0.02740888 -0.6337371  -1.4225543\n",
      " -0.03504371 -0.7648202  -1.5392692  -0.14868213 -0.5683532  -1.4810691\n",
      " -0.06737423 -0.62112916 -1.4508587  -0.08496358 -0.59306    -1.5414394\n",
      "  0.04710281 -0.6139333  -1.5863352  -0.06534588 -0.48520166 -1.3104539\n",
      " -0.17409346 -0.25630376 -1.9406735  -0.02565906 -0.40711054 -1.9419322\n",
      "  0.12611322 -0.3778586  -1.4403499  -0.16233356 -0.25085974 -1.244953\n",
      " -0.08943146 -0.22689655 -1.3181612  -0.04338391 -0.23554382 -1.4354422\n",
      "  0.03325351 -0.24983306 -1.2820153 ]\n",
      "data: [ 0.01054924 -0.06752459 -0.23389024  0.03627575 -0.20625049 -0.6504991\n",
      " -0.05819922 -0.38757378 -1.4080894  -0.19838628 -0.45117524 -1.6985343\n",
      " -0.35981792 -0.55913484 -2.1797564  -0.18682666 -0.6701329  -1.5623314\n",
      "  0.02002616 -0.6980088  -1.3661857  -0.02740888 -0.6337371  -1.4225544\n",
      " -0.03504371 -0.7648203  -1.5392692  -0.14868213 -0.5683532  -1.4810691\n",
      " -0.06737423 -0.62112916 -1.4508587  -0.08496358 -0.59306    -1.5414394\n",
      "  0.04710281 -0.6139333  -1.5863352  -0.06534588 -0.48520166 -1.3104539\n",
      " -0.17409346 -0.25630376 -1.9406735  -0.02565906 -0.40711057 -1.9419322\n",
      "  0.12611322 -0.3778586  -1.4403499  -0.16233356 -0.25085974 -1.244953\n",
      " -0.08943146 -0.22689655 -1.3181614  -0.04338391 -0.23554382 -1.4354422\n",
      "  0.03325351 -0.24983306 -1.2820153   0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.146 3.146 3.146 ... 3.135 3.128 3.128]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " [3.13  3.123 3.123 ... 3.119 3.112 3.112]\n",
      " ...\n",
      " [3.005 3.017 3.017 ... 3.002 3.007 3.007]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]\n",
      " [2.966 2.971 2.971 ... 2.995 3.001 3.001]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0164, -0.0758, -0.2335,  ...,  0.0510, -0.2645, -1.2799],\n",
      "        [ 0.0164, -0.0758, -0.2335,  ...,  0.0510, -0.2645, -1.2799],\n",
      "        [ 0.0164, -0.0758, -0.2335,  ...,  0.0510, -0.2645, -1.2799],\n",
      "        ...,\n",
      "        [-0.1981,  0.3837, -0.1680,  ..., -0.8319,  0.8736, -0.3803],\n",
      "        [-0.1714, -0.1565,  0.5706,  ..., -0.2668,  0.6120,  0.2341],\n",
      "        [-0.1714, -0.1565,  0.5706,  ..., -0.2668,  0.6120,  0.2341]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01636136 -0.07580665 -0.23353331  0.0364192  -0.21386117 -0.6405394\n",
      " -0.0496557  -0.39989078 -1.3925748  -0.1888719  -0.4621846  -1.6895545\n",
      " -0.35488334 -0.5778726  -2.1601996  -0.1830242  -0.68368685 -1.5514016\n",
      "  0.03565158 -0.7159199  -1.3639722  -0.01571167 -0.6540824  -1.4173455\n",
      " -0.01633373 -0.7881709  -1.5342717  -0.13844734 -0.57967913 -1.4647703\n",
      " -0.05466431 -0.63475174 -1.4414389  -0.06379776 -0.6099297  -1.5342953\n",
      "  0.06436537 -0.63533396 -1.5808923  -0.0483206  -0.49348998 -1.294394\n",
      " -0.16427462 -0.26640832 -1.946847   -0.00719915 -0.42336422 -1.9461501\n",
      "  0.14722303 -0.39041138 -1.4365418  -0.15273471 -0.2575438  -1.2289767\n",
      " -0.069738   -0.23683672 -1.3117425  -0.02323446 -0.2520612  -1.4276004\n",
      "  0.05103339 -0.2644815  -1.2799339 ]\n",
      "data: [-5.11 -0.22  2.41 -4.95 -0.2   2.62 -4.83 -0.05  3.   -4.82  0.23  3.31\n",
      " -5.02  0.4   4.21 -4.88  0.47  2.94 -5.04  0.65  3.75 -5.06  0.65  3.75\n",
      " -4.98  0.57  3.41 -5.    0.54  2.84 -5.38  0.72  4.37 -5.18  0.65  3.68\n",
      " -4.96  0.53  2.9  -5.11  0.54  2.79 -5.64  0.71  4.59 -5.37  0.65  3.71\n",
      " -5.1   0.54  2.79 -5.3   0.44  2.87 -5.49  0.59  3.6  -5.47  0.59  3.6\n",
      " -5.45  0.56  3.6   0.  ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[ 0.0540, -0.1811,  0.1761,  ...,  0.0284, -0.4972,  0.1759],\n",
      "        [ 0.0540, -0.1811,  0.1761,  ...,  0.0284, -0.4972,  0.1759],\n",
      "        [ 0.0540, -0.1811,  0.1761,  ...,  0.0284, -0.4972,  0.1759],\n",
      "        ...,\n",
      "        [ 0.0176,  0.0090,  0.3921,  ..., -0.1019,  0.5688,  1.3812],\n",
      "        [ 0.0644,  0.2701,  0.3054,  ..., -1.1159,  0.6143,  1.9201],\n",
      "        [ 0.0644,  0.2701,  0.3054,  ..., -1.1159,  0.6143,  1.9201]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.05401364 -0.18111488  0.17605594 -0.0918     -0.24123251  0.00581007\n",
      " -0.18152748 -0.42487872 -0.07344082 -0.22125424 -0.570704   -0.03703938\n",
      " -0.24094972 -0.6847366   0.02074911 -0.24064705 -0.35547736 -0.42060414\n",
      " -0.1262252  -0.45536888  0.13687474 -0.20613864 -0.63886106  0.21006185\n",
      " -0.28478953 -0.68245435  0.15932861 -0.16692919 -0.31535345 -0.39692786\n",
      " -0.24962315 -0.49092445 -0.21490201 -0.26736602 -0.597756   -0.17059088\n",
      " -0.27776104 -0.7752935  -0.11508462 -0.11182569 -0.25034535 -0.34220788\n",
      " -0.23813367 -0.41718772 -0.2136358  -0.20852672 -0.5314485  -0.20192686\n",
      " -0.11215236 -0.633689    0.03211927 -0.10502802 -0.18951198 -0.2145505\n",
      " -0.03478566 -0.29805943 -0.03951478 -0.02582698 -0.4209762   0.01615216\n",
      "  0.02841414 -0.4971665   0.1759308 ]\n",
      "init: [ 0.05401364 -0.18111488  0.17605594 -0.0918     -0.24123251  0.00581007\n",
      " -0.18152748 -0.42487872 -0.07344082 -0.22125424 -0.570704   -0.03703938\n",
      " -0.24094972 -0.6847366   0.02074911 -0.24064705 -0.35547736 -0.42060414\n",
      " -0.1262252  -0.45536888  0.13687474 -0.20613864 -0.63886106  0.21006185\n",
      " -0.28478953 -0.68245435  0.15932861 -0.16692919 -0.31535345 -0.39692786\n",
      " -0.24962315 -0.49092445 -0.21490201 -0.26736602 -0.597756   -0.17059088\n",
      " -0.27776104 -0.7752935  -0.11508462 -0.11182569 -0.25034535 -0.34220788\n",
      " -0.23813367 -0.41718772 -0.2136358  -0.20852672 -0.5314485  -0.20192686\n",
      " -0.11215236 -0.633689    0.03211927 -0.10502802 -0.18951198 -0.2145505\n",
      " -0.03478566 -0.29805943 -0.03951478 -0.02582698 -0.4209762   0.01615216\n",
      "  0.02841414 -0.4971665   0.1759308 ]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [ 0.05401363 -0.18111488  0.17605595 -0.0918     -0.24123251  0.00581007\n",
      " -0.18152748 -0.42487872 -0.07344082 -0.22125426 -0.570704   -0.03703938\n",
      " -0.24094972 -0.6847366   0.02074911 -0.24064705 -0.35547736 -0.42060414\n",
      " -0.1262252  -0.45536888  0.13687474 -0.20613866 -0.63886106  0.21006185\n",
      " -0.28478953 -0.68245435  0.15932861 -0.16692919 -0.31535345 -0.39692786\n",
      " -0.24962315 -0.49092445 -0.21490201 -0.26736602 -0.597756   -0.17059088\n",
      " -0.27776104 -0.7752935  -0.11508462 -0.11182568 -0.25034535 -0.34220788\n",
      " -0.23813365 -0.41718772 -0.2136358  -0.2085267  -0.5314485  -0.20192686\n",
      " -0.11215236 -0.633689    0.03211927 -0.10502802 -0.18951198 -0.2145505\n",
      " -0.03478566 -0.29805943 -0.03951478 -0.02582698 -0.4209762   0.01615216\n",
      "  0.02841414 -0.4971665   0.1759308   0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F978>\n",
      "tensor([[-0.0290,  0.0030,  0.2442,  ..., -0.6143, -0.3058, -0.2517],\n",
      "        [-0.0290,  0.0030,  0.2442,  ..., -0.6143, -0.3058, -0.2517],\n",
      "        [-0.0290,  0.0030,  0.2442,  ..., -0.6143, -0.3058, -0.2517],\n",
      "        ...,\n",
      "        [ 0.7390, -0.2586,  0.2368,  ...,  0.6648,  0.6040, -0.6077],\n",
      "        [ 0.4507, -0.0786,  0.2361,  ...,  0.2891,  0.3237,  0.2466],\n",
      "        [ 0.4507, -0.0786,  0.2361,  ...,  0.2891,  0.3237,  0.2466]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.02903923  0.00304674  0.24420255 -0.09095132 -0.03781947 -0.12232557\n",
      " -0.1933571  -0.14426221 -0.27334145 -0.36428547 -0.19854699 -0.38557336\n",
      " -0.5753953  -0.26934114 -0.57693946 -0.3839842  -0.32476962 -0.5082544\n",
      " -0.6388412  -0.42461258 -0.97672534 -0.72342837 -0.44388062 -0.95214725\n",
      " -0.7275288  -0.627874   -0.8570466  -0.34574884 -0.31256536 -0.44613853\n",
      " -0.5266769  -0.47073248 -0.31422916 -0.7118219  -0.56513345 -0.38622156\n",
      " -0.78668046 -0.61065745 -0.37953016 -0.3620447  -0.29045746 -0.3904247\n",
      " -0.582532   -0.31917155 -0.5591563  -0.63807946 -0.46018022 -0.55917525\n",
      " -0.7759164  -0.5232961  -0.2666401  -0.37461972 -0.21165301 -0.34678575\n",
      " -0.52998835 -0.2776662  -0.26160267 -0.5503993  -0.33023936 -0.29737464\n",
      " -0.61426926 -0.30580312 -0.25171363]\n",
      "data: [-0.02903924  0.00304674  0.24420255 -0.09095133 -0.03781947 -0.12232557\n",
      " -0.19335708 -0.14426221 -0.27334145 -0.36428547 -0.19854698 -0.38557336\n",
      " -0.5753953  -0.26934114 -0.57693946 -0.3839842  -0.32476962 -0.5082544\n",
      " -0.6388412  -0.42461258 -0.97672534 -0.72342837 -0.44388062 -0.95214725\n",
      " -0.7275288  -0.627874   -0.8570466  -0.3457488  -0.31256536 -0.44613853\n",
      " -0.5266769  -0.4707325  -0.31422916 -0.7118219  -0.56513345 -0.38622153\n",
      " -0.78668046 -0.61065745 -0.37953013 -0.3620447  -0.29045746 -0.3904247\n",
      " -0.582532   -0.31917155 -0.5591563  -0.63807946 -0.4601802  -0.55917525\n",
      " -0.77591634 -0.5232961  -0.2666401  -0.37461972 -0.21165301 -0.34678572\n",
      " -0.52998835 -0.2776662  -0.26160267 -0.5503993  -0.3302394  -0.29737464\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.61426926 -0.30580312 -0.25171363  0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[-0.0748, -0.1189, -0.0574,  ..., -0.3223, -0.2771, -0.6557],\n",
      "        [-0.0748, -0.1189, -0.0574,  ..., -0.3223, -0.2771, -0.6557],\n",
      "        [-0.0748, -0.1189, -0.0574,  ..., -0.3223, -0.2771, -0.6557],\n",
      "        ...,\n",
      "        [ 0.7293, -0.1316,  0.5657,  ...,  0.1059,  0.5611, -0.0732],\n",
      "        [ 0.3659, -0.1117,  0.5559,  ..., -0.2783,  0.5312, -0.0849],\n",
      "        [ 0.3659, -0.1117,  0.5559,  ..., -0.2783,  0.5312, -0.0849]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.07484499 -0.11889921 -0.05742908 -0.15431052 -0.20544028 -0.2734815\n",
      " -0.48125273 -0.42905998 -0.6885029  -0.6717006  -0.49511477 -0.81734455\n",
      " -0.96814835 -0.48790613 -1.12616    -0.4383262  -0.69758844 -0.8169558\n",
      " -0.7611598  -0.7206492  -1.0870963  -0.71723855 -0.6050428  -1.0974917\n",
      " -0.6687509  -0.79720813 -1.029336   -0.37688306 -0.6098869  -0.8022345\n",
      " -0.5194601  -0.63609827 -0.60746235 -0.59211123 -0.59561765 -0.65354115\n",
      " -0.40293196 -0.5020467  -0.76312315 -0.36531797 -0.5636118  -0.76320475\n",
      " -0.5130726  -0.4398809  -0.9568662  -0.45151263 -0.4767     -0.98875016\n",
      " -0.38700518 -0.36744642 -0.72664905 -0.33358642 -0.41462007 -0.7596042\n",
      " -0.532493   -0.34620315 -0.7397817  -0.44415495 -0.28077644 -0.8489352\n",
      " -0.32232663 -0.27706873 -0.6557028 ]\n",
      "data: [-0.07484499 -0.11889921 -0.05742908 -0.15431052 -0.2054403  -0.2734815\n",
      " -0.48125276 -0.42905998 -0.6885029  -0.6717006  -0.49511477 -0.8173445\n",
      " -0.96814835 -0.4879061  -1.12616    -0.43832624 -0.69758844 -0.8169558\n",
      " -0.7611597  -0.7206492  -1.0870963  -0.71723855 -0.6050428  -1.0974917\n",
      " -0.66875094 -0.7972081  -1.029336   -0.37688306 -0.6098869  -0.8022345\n",
      " -0.5194601  -0.63609827 -0.60746235 -0.59211123 -0.59561765 -0.6535412\n",
      " -0.402932   -0.5020467  -0.76312315 -0.36531794 -0.5636118  -0.76320475\n",
      " -0.5130726  -0.4398809  -0.9568662  -0.45151263 -0.4767     -0.98875016\n",
      " -0.3870052  -0.36744645 -0.72664905 -0.33358642 -0.41462004 -0.7596042\n",
      " -0.532493   -0.34620315 -0.7397816  -0.44415492 -0.28077644 -0.8489352\n",
      " -0.32232663 -0.27706873 -0.6557028   0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 1.3799e-01,  5.7962e-02, -1.6615e-01,  ...,  3.7581e-01,\n",
      "         -1.4836e-01, -1.1025e+00],\n",
      "        [ 1.3799e-01,  5.7962e-02, -1.6615e-01,  ...,  3.7581e-01,\n",
      "         -1.4836e-01, -1.1025e+00],\n",
      "        [ 1.3799e-01,  5.7962e-02, -1.6615e-01,  ...,  3.7581e-01,\n",
      "         -1.4836e-01, -1.1025e+00],\n",
      "        ...,\n",
      "        [ 1.1352e-01,  8.7945e-02,  7.6083e-01,  ..., -8.1419e-04,\n",
      "          1.0288e+00,  2.7295e-01],\n",
      "        [-1.6583e-01,  2.5111e-02,  5.0695e-01,  ..., -9.8617e-01,\n",
      "          4.3785e-01,  1.3965e-01],\n",
      "        [-1.6583e-01,  2.5111e-02,  5.0695e-01,  ..., -9.8617e-01,\n",
      "          4.3785e-01,  1.3965e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.13798922  0.05796214 -0.16614603  0.16982463 -0.06846429 -0.49118245\n",
      "  0.08713017 -0.2556251  -1.1788884  -0.03142381 -0.3015075  -1.447183\n",
      " -0.17329502 -0.44521248 -1.8567694  -0.06230548 -0.51110166 -1.3599346\n",
      "  0.21867386 -0.5262499  -1.1887994   0.1954228  -0.4553336  -1.2078568\n",
      "  0.23220955 -0.5731747  -1.3104142   0.00967227 -0.41344154 -1.2849672\n",
      "  0.15727526 -0.47966123 -1.2588419   0.21763104 -0.4270507  -1.3097281\n",
      "  0.38017195 -0.4856516  -1.3819767   0.15962583 -0.33819523 -1.1301552\n",
      "  0.05143583 -0.09774694 -1.7990295   0.29089937 -0.29556873 -1.7727735\n",
      "  0.48188624 -0.20815462 -1.2863582   0.04145192 -0.11917467 -1.0651352\n",
      "  0.19532093 -0.08327946 -1.138477    0.2910847  -0.13411462 -1.2630491\n",
      "  0.3758128  -0.14835954 -1.1024594 ]\n",
      "data: [ 0.13798922  0.05796214 -0.16614603  0.16982464 -0.06846429 -0.49118245\n",
      "  0.08713017 -0.2556251  -1.1788884  -0.03142381 -0.3015075  -1.4471831\n",
      " -0.17329502 -0.44521248 -1.8567694  -0.06230548 -0.51110166 -1.3599346\n",
      "  0.21867386 -0.5262499  -1.1887994   0.1954228  -0.4553336  -1.2078568\n",
      "  0.23220955 -0.5731747  -1.3104141   0.00967227 -0.41344154 -1.2849672\n",
      "  0.15727526 -0.47966123 -1.2588419   0.21763104 -0.4270507  -1.3097281\n",
      "  0.38017195 -0.4856516  -1.3819767   0.15962583 -0.33819523 -1.1301552\n",
      "  0.05143583 -0.09774694 -1.7990296   0.29089937 -0.29556873 -1.7727734\n",
      "  0.48188627 -0.20815462 -1.2863582   0.04145192 -0.11917467 -1.0651352\n",
      "  0.19532093 -0.08327946 -1.138477    0.2910847  -0.13411462 -1.2630491\n",
      "  0.3758128  -0.14835954 -1.1024594   0.04      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.1095, -0.1423, -0.1962,  ...,  0.1518, -0.2990, -1.2942],\n",
      "        [ 0.1095, -0.1423, -0.1962,  ...,  0.1518, -0.2990, -1.2942],\n",
      "        [ 0.1095, -0.1423, -0.1962,  ...,  0.1518, -0.2990, -1.2942],\n",
      "        ...,\n",
      "        [-0.2897,  0.3377, -0.0121,  ..., -0.8275,  0.7290, -0.3886],\n",
      "        [-0.3159,  0.1802,  0.3462,  ..., -0.3546,  1.0331, -0.0905],\n",
      "        [-0.3159,  0.1802,  0.3462,  ..., -0.3546,  1.0331, -0.0905]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.109479   -0.14229463 -0.1962444   0.13742292 -0.31140184 -0.6305066\n",
      "  0.08155867 -0.47762123 -1.3591118  -0.05530624 -0.5373087  -1.6613379\n",
      " -0.22983651 -0.67292976 -2.132369   -0.11037369 -0.7117264  -1.5503433\n",
      "  0.18182756 -0.71237266 -1.2648548   0.1328452  -0.66314375 -1.3092672\n",
      "  0.10263518 -0.75711477 -1.4253983  -0.06332073 -0.5844811  -1.4730614\n",
      "  0.0516049  -0.64715743 -1.457611    0.04676116 -0.6183878  -1.5487022\n",
      "  0.16215278 -0.64759624 -1.6321161   0.0495332  -0.5169625  -1.2908572\n",
      " -0.04732168 -0.28264976 -1.8549899   0.09674959 -0.44259977 -1.8248763\n",
      "  0.22662623 -0.39357176 -1.4640279  -0.05095427 -0.2733528  -1.2378756\n",
      "  0.05438361 -0.24806735 -1.2842965   0.12129675 -0.28569543 -1.4028554\n",
      "  0.15177554 -0.29903632 -1.2941502 ]\n",
      "data: [ 0.109479   -0.14229463 -0.19624442  0.13742292 -0.31140184 -0.6305066\n",
      "  0.08155867 -0.47762123 -1.3591118  -0.05530624 -0.5373087  -1.6613379\n",
      " -0.22983651 -0.67292976 -2.132369   -0.11037369 -0.7117264  -1.5503433\n",
      "  0.18182756 -0.71237266 -1.2648548   0.1328452  -0.66314375 -1.3092672\n",
      "  0.10263518 -0.75711477 -1.4253983  -0.06332073 -0.5844811  -1.4730613\n",
      "  0.0516049  -0.64715743 -1.457611    0.04676117 -0.6183878  -1.5487022\n",
      "  0.16215278 -0.6475962  -1.6321161   0.0495332  -0.5169625  -1.2908572\n",
      " -0.04732168 -0.28264976 -1.8549899   0.09674959 -0.4425998  -1.8248763\n",
      "  0.22662622 -0.39357176 -1.4640279  -0.05095427 -0.2733528  -1.2378756\n",
      "  0.05438361 -0.24806733 -1.2842965   0.12129675 -0.28569543 -1.4028554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.15177554 -0.29903632 -1.2941502   0.05      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0280, -0.1972, -0.2123,  ...,  0.0658, -0.3773, -1.2732],\n",
      "        [ 0.0280, -0.1972, -0.2123,  ...,  0.0658, -0.3773, -1.2732],\n",
      "        [ 0.0280, -0.1972, -0.2123,  ...,  0.0658, -0.3773, -1.2732],\n",
      "        ...,\n",
      "        [-0.0620,  0.5887, -0.1242,  ..., -0.5279,  1.0764, -0.5170],\n",
      "        [-0.1557,  0.0263,  0.5967,  ..., -0.2326,  0.7935,  0.1591],\n",
      "        [-0.1557,  0.0263,  0.5967,  ..., -0.2326,  0.7935,  0.1591]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.7995314e-02 -1.9716157e-01 -2.1227139e-01  5.5467021e-02\n",
      " -3.3715704e-01 -5.9962630e-01 -2.9929295e-02 -5.4879093e-01\n",
      " -1.4027182e+00 -1.8165946e-01 -6.1535358e-01 -1.7213720e+00\n",
      " -3.6095440e-01 -7.4219149e-01 -2.2039180e+00 -1.8935451e-01\n",
      " -8.0488449e-01 -1.6058757e+00  7.8282602e-02 -8.4982687e-01\n",
      " -1.3501639e+00  1.7939307e-02 -7.9855347e-01 -1.3918344e+00\n",
      " -1.0009967e-02 -9.3974584e-01 -1.5193969e+00 -1.3385761e-01\n",
      " -6.9227147e-01 -1.4975376e+00 -4.3638416e-02 -7.6648921e-01\n",
      " -1.4672277e+00 -4.7687493e-02 -7.4456549e-01 -1.5659051e+00\n",
      "  7.3245011e-02 -7.9018569e-01 -1.6186136e+00 -2.6106223e-02\n",
      " -5.9322190e-01 -1.3114340e+00 -1.7109412e-01 -3.6635682e-01\n",
      " -2.0084205e+00  5.0448626e-03 -5.5080295e-01 -2.0022340e+00\n",
      "  1.6481915e-01 -5.0452346e-01 -1.4471096e+00 -1.5308321e-01\n",
      " -3.5072470e-01 -1.2380781e+00 -5.0874628e-02 -3.2991201e-01\n",
      " -1.3043259e+00  1.8317327e-03 -3.6809599e-01 -1.4192866e+00\n",
      "  6.5821886e-02 -3.7729996e-01 -1.2732047e+00]\n",
      "data: [ 2.7995314e-02 -1.9716159e-01 -2.1227139e-01  5.5467021e-02\n",
      " -3.3715707e-01 -5.9962630e-01 -2.9929295e-02 -5.4879093e-01\n",
      " -1.4027182e+00 -1.8165947e-01 -6.1535358e-01 -1.7213721e+00\n",
      " -3.6095440e-01 -7.4219149e-01 -2.2039180e+00 -1.8935451e-01\n",
      " -8.0488449e-01 -1.6058757e+00  7.8282602e-02 -8.4982687e-01\n",
      " -1.3501639e+00  1.7939307e-02 -7.9855347e-01 -1.3918344e+00\n",
      " -1.0009967e-02 -9.3974584e-01 -1.5193970e+00 -1.3385761e-01\n",
      " -6.9227147e-01 -1.4975375e+00 -4.3638416e-02 -7.6648921e-01\n",
      " -1.4672276e+00 -4.7687493e-02 -7.4456549e-01 -1.5659051e+00\n",
      "  7.3245011e-02 -7.9018569e-01 -1.6186136e+00 -2.6106223e-02\n",
      " -5.9322190e-01 -1.3114340e+00 -1.7109412e-01 -3.6635682e-01\n",
      " -2.0084205e+00  5.0448626e-03 -5.5080295e-01 -2.0022340e+00\n",
      "  1.6481915e-01 -5.0452346e-01 -1.4471096e+00 -1.5308321e-01\n",
      " -3.5072473e-01 -1.2380781e+00 -5.0874628e-02 -3.2991201e-01\n",
      " -1.3043258e+00  1.8317327e-03 -3.6809599e-01 -1.4192866e+00\n",
      "  6.5821886e-02 -3.7729996e-01 -1.2732047e+00  5.9999999e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0196, -0.1509, -0.1735,  ...,  0.0557, -0.3321, -1.1945],\n",
      "        [ 0.0196, -0.1509, -0.1735,  ...,  0.0557, -0.3321, -1.1945],\n",
      "        [ 0.0196, -0.1509, -0.1735,  ...,  0.0557, -0.3321, -1.1945],\n",
      "        ...,\n",
      "        [-0.0878,  0.5275, -0.1462,  ..., -0.4237,  1.1018, -0.5882],\n",
      "        [-0.1110,  0.0217,  0.6627,  ..., -0.1752,  0.6636,  0.3281],\n",
      "        [-0.1110,  0.0217,  0.6627,  ..., -0.1752,  0.6636,  0.3281]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.9637238e-02 -1.5093312e-01 -1.7349097e-01  4.5833070e-02\n",
      " -2.7051434e-01 -4.8069066e-01 -5.6256287e-02 -4.8975518e-01\n",
      " -1.3147730e+00 -2.1402824e-01 -5.5105412e-01 -1.6289096e+00\n",
      " -3.8103187e-01 -6.6841495e-01 -2.1327775e+00 -1.9580652e-01\n",
      " -7.7512044e-01 -1.5234041e+00  4.2363837e-02 -8.2984090e-01\n",
      " -1.3541057e+00 -2.2495121e-02 -7.6938301e-01 -1.3938977e+00\n",
      " -2.5589734e-02 -9.1990131e-01 -1.5210456e+00 -1.3906604e-01\n",
      " -6.7402047e-01 -1.4111586e+00 -5.5747166e-02 -7.3713577e-01\n",
      " -1.3915805e+00 -5.1905207e-02 -7.0362407e-01 -1.4894396e+00\n",
      "  7.3039681e-02 -7.5433612e-01 -1.5233063e+00 -3.0408733e-02\n",
      " -5.6058961e-01 -1.2347754e+00 -1.8729393e-01 -3.2711166e-01\n",
      " -1.9627049e+00  2.0817518e-03 -5.1124310e-01 -1.9710088e+00\n",
      "  1.7520358e-01 -4.6442246e-01 -1.3735231e+00 -1.7049505e-01\n",
      " -3.2138717e-01 -1.1587449e+00 -6.4857826e-02 -2.9908866e-01\n",
      " -1.2393484e+00 -2.6983425e-02 -3.2794487e-01 -1.3532567e+00\n",
      "  5.5712037e-02 -3.3210528e-01 -1.1944885e+00]\n",
      "data: [ 1.9637238e-02 -1.5093312e-01 -1.7349096e-01  4.5833066e-02\n",
      " -2.7051434e-01 -4.8069066e-01 -5.6256283e-02 -4.8975518e-01\n",
      " -1.3147730e+00 -2.1402824e-01 -5.5105412e-01 -1.6289096e+00\n",
      " -3.8103187e-01 -6.6841489e-01 -2.1327775e+00 -1.9580652e-01\n",
      " -7.7512050e-01 -1.5234041e+00  4.2363837e-02 -8.2984090e-01\n",
      " -1.3541057e+00 -2.2495123e-02 -7.6938301e-01 -1.3938977e+00\n",
      " -2.5589732e-02 -9.1990125e-01 -1.5210456e+00 -1.3906604e-01\n",
      " -6.7402047e-01 -1.4111586e+00 -5.5747166e-02 -7.3713577e-01\n",
      " -1.3915805e+00 -5.1905207e-02 -7.0362401e-01 -1.4894395e+00\n",
      "  7.3039681e-02 -7.5433612e-01 -1.5233063e+00 -3.0408733e-02\n",
      " -5.6058961e-01 -1.2347754e+00 -1.8729393e-01 -3.2711166e-01\n",
      " -1.9627049e+00  2.0817518e-03 -5.1124310e-01 -1.9710088e+00\n",
      "  1.7520358e-01 -4.6442246e-01 -1.3735231e+00 -1.7049505e-01\n",
      " -3.2138717e-01 -1.1587449e+00 -6.4857826e-02 -2.9908866e-01\n",
      " -1.2393484e+00 -2.6983425e-02 -3.2794487e-01 -1.3532567e+00\n",
      "  5.5712037e-02 -3.3210528e-01 -1.1944885e+00  7.0000000e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[-0.0014, -0.0907, -0.1920,  ...,  0.0144, -0.2844, -1.1737],\n",
      "        [-0.0014, -0.0907, -0.1920,  ...,  0.0144, -0.2844, -1.1737],\n",
      "        [-0.0014, -0.0907, -0.1920,  ...,  0.0144, -0.2844, -1.1737],\n",
      "        ...,\n",
      "        [-0.1909,  0.4098, -0.0353,  ..., -0.6056,  0.9868, -0.4121],\n",
      "        [-0.0819, -0.0181,  0.6321,  ..., -0.1631,  0.7007,  0.2755],\n",
      "        [-0.0819, -0.0181,  0.6321,  ..., -0.1631,  0.7007,  0.2755]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-1.37409102e-03 -9.07245651e-02 -1.91998318e-01  3.04821469e-02\n",
      " -1.87995225e-01 -4.66912240e-01 -1.30658805e-01 -4.30673748e-01\n",
      " -1.34864891e+00 -2.89533198e-01 -5.01375616e-01 -1.63011551e+00\n",
      " -4.33793068e-01 -5.82623124e-01 -2.15497255e+00 -1.93133339e-01\n",
      " -7.40241349e-01 -1.52608168e+00 -4.19111997e-02 -8.16921830e-01\n",
      " -1.37820959e+00 -9.27349478e-02 -7.35986233e-01 -1.42852795e+00\n",
      " -1.04254201e-01 -9.11822379e-01 -1.55488920e+00 -1.52844384e-01\n",
      " -6.57918632e-01 -1.42284346e+00 -1.07691206e-01 -7.07870722e-01\n",
      " -1.38876522e+00 -1.19721077e-01 -6.67284906e-01 -1.46530116e+00\n",
      "  2.50675231e-02 -6.98380709e-01 -1.47184741e+00 -7.40964785e-02\n",
      " -5.39061129e-01 -1.26799786e+00 -2.40608841e-01 -2.99979925e-01\n",
      " -2.03992367e+00 -5.03977835e-02 -4.74142849e-01 -2.07302332e+00\n",
      "  1.31204352e-01 -4.30504560e-01 -1.34662604e+00 -1.99433640e-01\n",
      " -3.12891006e-01 -1.18338370e+00 -1.39029816e-01 -2.78525084e-01\n",
      " -1.27317441e+00 -1.10586584e-01 -2.72765964e-01 -1.38325667e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.44325122e-02 -2.84361660e-01 -1.17365777e+00]\n",
      "data: [-1.3740910e-03 -9.0724565e-02 -1.9199830e-01  3.0482147e-02\n",
      " -1.8799523e-01 -4.6691224e-01 -1.3065881e-01 -4.3067375e-01\n",
      " -1.3486488e+00 -2.8953320e-01 -5.0137562e-01 -1.6301155e+00\n",
      " -4.3379307e-01 -5.8262312e-01 -2.1549726e+00 -1.9313334e-01\n",
      " -7.4024129e-01 -1.5260817e+00 -4.1911200e-02 -8.1692183e-01\n",
      " -1.3782096e+00 -9.2734948e-02 -7.3598623e-01 -1.4285280e+00\n",
      " -1.0425420e-01 -9.1182238e-01 -1.5548892e+00 -1.5284438e-01\n",
      " -6.5791863e-01 -1.4228435e+00 -1.0769120e-01 -7.0787072e-01\n",
      " -1.3887652e+00 -1.1972108e-01 -6.6728491e-01 -1.4653012e+00\n",
      "  2.5067523e-02 -6.9838071e-01 -1.4718474e+00 -7.4096479e-02\n",
      " -5.3906113e-01 -1.2679979e+00 -2.4060884e-01 -2.9997993e-01\n",
      " -2.0399237e+00 -5.0397784e-02 -4.7414285e-01 -2.0730233e+00\n",
      "  1.3120435e-01 -4.3050456e-01 -1.3466259e+00 -1.9943362e-01\n",
      " -3.1289101e-01 -1.1833837e+00 -1.3902982e-01 -2.7852508e-01\n",
      " -1.2731744e+00 -1.1058658e-01 -2.7276596e-01 -1.3832567e+00\n",
      "  1.4432512e-02 -2.8436166e-01 -1.1736578e+00  7.9999998e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[-0.0177,  0.0158, -0.1806,  ...,  0.0128, -0.1743, -1.1572],\n",
      "        [-0.0177,  0.0158, -0.1806,  ...,  0.0128, -0.1743, -1.1572],\n",
      "        [-0.0177,  0.0158, -0.1806,  ...,  0.0128, -0.1743, -1.1572],\n",
      "        ...,\n",
      "        [-0.1488,  0.3681,  0.0713,  ..., -0.7228,  0.9692, -0.2938],\n",
      "        [-0.1019, -0.0920,  0.5721,  ..., -0.2554,  0.6080,  0.2480],\n",
      "        [-0.1019, -0.0920,  0.5721,  ..., -0.2554,  0.6080,  0.2480]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01774264  0.01576562 -0.1805524   0.00402657 -0.09398973 -0.49081472\n",
      " -0.14019424 -0.3161742  -1.33003    -0.2938937  -0.38045746 -1.6161231\n",
      " -0.45475167 -0.47057104 -2.1126082  -0.21431394 -0.62245    -1.4906863\n",
      " -0.04041545 -0.68008506 -1.3155172  -0.08304952 -0.60257703 -1.3678082\n",
      " -0.0778472  -0.7652096  -1.4944457  -0.17391394 -0.5296236  -1.3932633\n",
      " -0.1106886  -0.5795905  -1.3570124  -0.11024445 -0.54389906 -1.4417505\n",
      "  0.05240071 -0.5699005  -1.464913   -0.09131127 -0.42396992 -1.2308152\n",
      " -0.24218568 -0.18607624 -1.9829392  -0.04967804 -0.35419333 -2.0062773\n",
      "  0.14568453 -0.31443715 -1.327216   -0.21075608 -0.19063488 -1.1491556\n",
      " -0.14555739 -0.16029532 -1.2363247  -0.10761984 -0.15832247 -1.3528343\n",
      "  0.01282426 -0.17434102 -1.1571782 ]\n",
      "data: [-0.01774264  0.01576562 -0.1805524   0.00402657 -0.09398974 -0.49081472\n",
      " -0.14019424 -0.3161742  -1.33003    -0.2938937  -0.38045746 -1.6161231\n",
      " -0.45475167 -0.47057107 -2.1126082  -0.21431394 -0.62245    -1.4906863\n",
      " -0.04041545 -0.68008506 -1.3155171  -0.08304951 -0.60257703 -1.3678082\n",
      " -0.0778472  -0.76520956 -1.4944457  -0.17391394 -0.5296236  -1.3932633\n",
      " -0.1106886  -0.5795905  -1.3570123  -0.11024445 -0.54389906 -1.4417505\n",
      "  0.05240071 -0.5699005  -1.464913   -0.09131126 -0.42396992 -1.2308152\n",
      " -0.24218568 -0.18607624 -1.9829392  -0.04967804 -0.35419333 -2.0062773\n",
      "  0.14568453 -0.31443715 -1.327216   -0.21075608 -0.19063488 -1.1491556\n",
      " -0.14555739 -0.16029531 -1.2363247  -0.10761984 -0.15832247 -1.3528343\n",
      "  0.01282426 -0.17434102 -1.1571782   0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[-0.0079, -0.0723, -0.2146,  ...,  0.0141, -0.2339, -1.3404],\n",
      "        [-0.0079, -0.0723, -0.2146,  ...,  0.0141, -0.2339, -1.3404],\n",
      "        [-0.0079, -0.0723, -0.2146,  ...,  0.0141, -0.2339, -1.3404],\n",
      "        ...,\n",
      "        [-0.2747,  0.3256, -0.1686,  ..., -0.8031,  0.7734, -0.3128],\n",
      "        [-0.1782, -0.0794,  0.5119,  ..., -0.2663,  0.6804,  0.2609],\n",
      "        [-0.1782, -0.0794,  0.5119,  ..., -0.2663,  0.6804,  0.2609]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.00790667 -0.07232122 -0.21462567  0.00526823 -0.23588963 -0.6908697\n",
      " -0.04144386 -0.3764275  -1.3644722  -0.18260464 -0.42955223 -1.6690526\n",
      " -0.3643937  -0.5636552  -2.1331313  -0.23178574 -0.6500098  -1.5244741\n",
      "  0.03723025 -0.64683855 -1.2972696  -0.01310886 -0.58897454 -1.3502469\n",
      " -0.01328262 -0.68214047 -1.463388   -0.18757066 -0.5347877  -1.4549129\n",
      " -0.07302368 -0.58631086 -1.4436314  -0.07615601 -0.55411315 -1.5504153\n",
      "  0.04888649 -0.5728058  -1.6217864  -0.08383821 -0.4692755  -1.2789052\n",
      " -0.15472242 -0.23966512 -1.7850754  -0.02748658 -0.37419036 -1.7623897\n",
      "  0.11621419 -0.34489    -1.4824355  -0.1804958  -0.22294435 -1.230952\n",
      " -0.08259908 -0.20365688 -1.3117232  -0.02745657 -0.22927433 -1.4334822\n",
      "  0.01408958 -0.23389713 -1.3404074 ]\n",
      "data: [-0.00790667 -0.07232122 -0.21462566  0.00526823 -0.23588963 -0.6908697\n",
      " -0.04144386 -0.3764275  -1.3644722  -0.18260464 -0.42955223 -1.6690526\n",
      " -0.36439368 -0.5636552  -2.1331313  -0.23178573 -0.6500099  -1.5244741\n",
      "  0.03723025 -0.64683855 -1.2972696  -0.01310886 -0.58897454 -1.3502469\n",
      " -0.01328262 -0.6821405  -1.463388   -0.18757066 -0.5347877  -1.4549129\n",
      " -0.07302368 -0.58631086 -1.4436314  -0.07615601 -0.55411315 -1.5504154\n",
      "  0.04888649 -0.5728058  -1.6217864  -0.0838382  -0.4692755  -1.2789052\n",
      " -0.15472242 -0.23966512 -1.7850754  -0.02748658 -0.37419036 -1.7623897\n",
      "  0.11621419 -0.34489    -1.4824355  -0.1804958  -0.22294435 -1.230952\n",
      " -0.08259907 -0.20365688 -1.3117232  -0.02745657 -0.22927433 -1.4334822\n",
      "  0.01408958 -0.23389713 -1.3404074   0.1       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0566, -0.1597, -0.2868,  ...,  0.0649, -0.3308, -1.3649],\n",
      "        [ 0.0566, -0.1597, -0.2868,  ...,  0.0649, -0.3308, -1.3649],\n",
      "        [ 0.0566, -0.1597, -0.2868,  ...,  0.0649, -0.3308, -1.3649],\n",
      "        ...,\n",
      "        [-0.1233,  0.5396, -0.0670,  ..., -0.7327,  1.0648, -0.3446],\n",
      "        [-0.1804, -0.0689,  0.6373,  ..., -0.2768,  0.7107,  0.3130],\n",
      "        [-0.1804, -0.0689,  0.6373,  ..., -0.2768,  0.7107,  0.3130]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.05658485 -0.15970956 -0.28681386  0.08512719 -0.2899108  -0.6990487\n",
      " -0.00705724 -0.47678307 -1.46755    -0.14971809 -0.5355147  -1.7652471\n",
      " -0.3023954  -0.63838553 -2.2596767  -0.14276223 -0.7653301  -1.6389153\n",
      "  0.06528732 -0.7976259  -1.4652731   0.0145416  -0.7335119  -1.5207295\n",
      "  0.00548701 -0.868492   -1.6410308  -0.10296884 -0.66607547 -1.5516772\n",
      " -0.02579349 -0.71596384 -1.5322201  -0.03934477 -0.684721   -1.6252568\n",
      "  0.08486278 -0.7122705  -1.6692917  -0.01804241 -0.57136786 -1.3838434\n",
      " -0.13874224 -0.3393056  -2.0343688   0.01600769 -0.4939445  -2.0410004\n",
      "  0.16487743 -0.4580761  -1.5287042  -0.1253631  -0.3383615  -1.3152597\n",
      " -0.04899399 -0.30889118 -1.3934975  -0.00781906 -0.32003587 -1.5105581\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.06485017 -0.33082977 -1.364923  ]\n",
      "data: [ 0.05658485 -0.15970956 -0.28681386  0.08512719 -0.2899108  -0.6990487\n",
      " -0.00705724 -0.47678307 -1.46755    -0.14971809 -0.5355147  -1.765247\n",
      " -0.3023954  -0.63838553 -2.2596767  -0.14276223 -0.7653301  -1.6389153\n",
      "  0.06528732 -0.7976259  -1.4652731   0.0145416  -0.733512   -1.5207295\n",
      "  0.00548701 -0.86849195 -1.6410308  -0.10296884 -0.66607547 -1.5516772\n",
      " -0.02579349 -0.71596384 -1.5322201  -0.03934477 -0.684721   -1.6252568\n",
      "  0.08486278 -0.7122705  -1.6692917  -0.01804241 -0.57136786 -1.3838434\n",
      " -0.13874224 -0.3393056  -2.0343688   0.01600769 -0.49394453 -2.0410004\n",
      "  0.16487743 -0.4580761  -1.5287042  -0.1253631  -0.3383615  -1.3152597\n",
      " -0.04899399 -0.30889118 -1.3934975  -0.00781906 -0.32003585 -1.5105581\n",
      "  0.06485017 -0.33082977 -1.364923    0.11      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0167, -0.1702, -0.2122,  ...,  0.0863, -0.3542, -1.3034],\n",
      "        [ 0.0167, -0.1702, -0.2122,  ...,  0.0863, -0.3542, -1.3034],\n",
      "        [ 0.0167, -0.1702, -0.2122,  ...,  0.0863, -0.3542, -1.3034],\n",
      "        ...,\n",
      "        [-0.0158,  0.4940, -0.0969,  ..., -0.6043,  1.0182, -0.4323],\n",
      "        [-0.1219, -0.0122,  0.5931,  ..., -0.1763,  0.6721,  0.2620],\n",
      "        [-0.1219, -0.0122,  0.5931,  ..., -0.1763,  0.6721,  0.2620]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.016695   -0.17015769 -0.21224982  0.03952216 -0.3218608  -0.5998831\n",
      "  0.00480693 -0.5007086  -1.3541462  -0.14276873 -0.55541575 -1.6927629\n",
      " -0.33342525 -0.7107893  -2.161995   -0.21061748 -0.75435877 -1.5820702\n",
      "  0.11854646 -0.7774924  -1.3523289   0.05088913 -0.7370156  -1.3880241\n",
      "  0.04807872 -0.85145164 -1.5101978  -0.14154461 -0.6325755  -1.4728237\n",
      " -0.01700423 -0.7111069  -1.4684222  -0.00271601 -0.6935084  -1.5847163\n",
      "  0.10568413 -0.7469373  -1.6606318  -0.0112099  -0.54929316 -1.2727088\n",
      " -0.13243794 -0.32281217 -1.9094434   0.03821179 -0.5074017  -1.882058\n",
      "  0.191248   -0.4631556  -1.4783065  -0.1462394  -0.29890192 -1.2144446\n",
      " -0.00671229 -0.29006094 -1.2817116   0.05495466 -0.35200155 -1.3979725\n",
      "  0.08632625 -0.35420823 -1.3033586 ]\n",
      "data: [ 0.016695   -0.17015769 -0.21224982  0.03952216 -0.32186082 -0.5998831\n",
      "  0.00480693 -0.5007086  -1.3541462  -0.14276873 -0.55541575 -1.6927629\n",
      " -0.33342525 -0.7107893  -2.161995   -0.21061748 -0.75435877 -1.5820701\n",
      "  0.11854646 -0.77749234 -1.3523289   0.05088913 -0.7370156  -1.3880241\n",
      "  0.04807872 -0.85145164 -1.5101978  -0.14154461 -0.6325755  -1.4728237\n",
      " -0.01700423 -0.7111069  -1.4684223  -0.00271601 -0.6935084  -1.5847163\n",
      "  0.10568413 -0.7469373  -1.6606317  -0.0112099  -0.54929316 -1.2727088\n",
      " -0.13243794 -0.32281217 -1.9094434   0.03821179 -0.5074017  -1.8820579\n",
      "  0.191248   -0.4631556  -1.4783065  -0.1462394  -0.29890192 -1.2144446\n",
      " -0.00671229 -0.29006094 -1.2817116   0.05495466 -0.35200155 -1.3979725\n",
      "  0.08632625 -0.35420823 -1.3033586   0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0142, -0.1452, -0.1641,  ...,  0.0359, -0.3398, -1.1609],\n",
      "        [ 0.0142, -0.1452, -0.1641,  ...,  0.0359, -0.3398, -1.1609],\n",
      "        [ 0.0142, -0.1452, -0.1641,  ...,  0.0359, -0.3398, -1.1609],\n",
      "        ...,\n",
      "        [-0.0689,  0.5164, -0.1481,  ..., -0.3310,  1.0575, -0.5594],\n",
      "        [-0.1649, -0.0297,  0.6243,  ..., -0.2459,  0.6657,  0.2717],\n",
      "        [-0.1649, -0.0297,  0.6243,  ..., -0.2459,  0.6657,  0.2717]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.014239   -0.14522049 -0.1641298   0.04517077 -0.2523353  -0.46284536\n",
      " -0.09877077 -0.49130836 -1.3233502  -0.2556421  -0.56103235 -1.6110204\n",
      " -0.40224785 -0.6535382  -2.1249576  -0.1799075  -0.7909422  -1.5072836\n",
      " -0.00730699 -0.86441946 -1.3523729  -0.06357447 -0.78893423 -1.4003667\n",
      " -0.077029   -0.96077776 -1.5250678  -0.13516945 -0.7017807  -1.4038535\n",
      " -0.08283025 -0.7571964  -1.3732048  -0.09507883 -0.72207105 -1.4500357\n",
      "  0.03761553 -0.7593976  -1.4620785  -0.04860619 -0.5844257  -1.2449526\n",
      " -0.21551445 -0.34564108 -2.0128875  -0.02834221 -0.52766764 -2.0374641\n",
      "  0.14335403 -0.48214433 -1.3327054  -0.17650205 -0.3546966  -1.1621509\n",
      " -0.10527413 -0.3226971  -1.2502657  -0.07459981 -0.327435   -1.3602448\n",
      "  0.03590642 -0.3397568  -1.1608859 ]\n",
      "data: [ 0.014239   -0.14522049 -0.1641298   0.04517077 -0.2523353  -0.46284536\n",
      " -0.09877077 -0.49130836 -1.3233502  -0.2556421  -0.56103235 -1.6110206\n",
      " -0.40224785 -0.6535382  -2.1249576  -0.1799075  -0.79094225 -1.5072837\n",
      " -0.00730699 -0.86441946 -1.3523729  -0.06357447 -0.78893423 -1.4003667\n",
      " -0.077029   -0.96077776 -1.5250678  -0.13516945 -0.7017807  -1.4038537\n",
      " -0.08283025 -0.7571964  -1.3732048  -0.09507883 -0.72207105 -1.4500357\n",
      "  0.03761553 -0.7593977  -1.4620785  -0.04860619 -0.5844257  -1.2449526\n",
      " -0.21551445 -0.34564105 -2.0128875  -0.02834221 -0.52766764 -2.0374641\n",
      "  0.14335403 -0.48214433 -1.3327054  -0.17650205 -0.35469663 -1.1621509\n",
      " -0.10527413 -0.3226971  -1.2502657  -0.07459981 -0.327435   -1.3602448\n",
      "  0.03590642 -0.3397568  -1.1608859   0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0501,  0.0163, -0.2188,  ..., -0.0175, -0.1762, -1.1719],\n",
      "        [-0.0501,  0.0163, -0.2188,  ..., -0.0175, -0.1762, -1.1719],\n",
      "        [-0.0501,  0.0163, -0.2188,  ..., -0.0175, -0.1762, -1.1719],\n",
      "        ...,\n",
      "        [-0.1627,  0.3520,  0.0392,  ..., -0.5491,  0.9619, -0.3782],\n",
      "        [-0.0653, -0.0829,  0.6403,  ..., -0.2032,  0.5826,  0.3161],\n",
      "        [-0.0653, -0.0829,  0.6403,  ..., -0.2032,  0.5826,  0.3161]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.05007889  0.0163286  -0.21880431 -0.02552724 -0.09047522 -0.48482436\n",
      " -0.17111301 -0.32481977 -1.3499894  -0.32819772 -0.38918883 -1.6396778\n",
      " -0.48809165 -0.48554465 -2.1448932  -0.25215685 -0.6267853  -1.5276167\n",
      " -0.06660965 -0.6907779  -1.354737   -0.11639027 -0.61492467 -1.4013963\n",
      " -0.11244817 -0.78010917 -1.5297987  -0.20741901 -0.53235376 -1.4226158\n",
      " -0.14403467 -0.58542824 -1.3889759  -0.13980524 -0.5486773  -1.4707258\n",
      "  0.01490228 -0.5826049  -1.4895391  -0.11597999 -0.4199395  -1.258735\n",
      " -0.2834115  -0.17937735 -2.0420537  -0.08002547 -0.36003017 -2.0642738\n",
      "  0.11477832 -0.31356534 -1.3493395  -0.24671714 -0.18668358 -1.1766169\n",
      " -0.17073324 -0.157922   -1.2594857  -0.13605718 -0.16217522 -1.3732884\n",
      " -0.01752193 -0.17620684 -1.1719341 ]\n",
      "data: [-0.05007889  0.0163286  -0.21880431 -0.02552723 -0.09047522 -0.48482436\n",
      " -0.17111301 -0.32481974 -1.3499894  -0.32819772 -0.38918886 -1.6396778\n",
      " -0.48809165 -0.48554465 -2.1448932  -0.25215685 -0.6267853  -1.5276167\n",
      " -0.06660965 -0.6907779  -1.354737   -0.11639027 -0.61492467 -1.4013963\n",
      " -0.11244817 -0.78010917 -1.5297987  -0.20741901 -0.53235376 -1.4226158\n",
      " -0.14403467 -0.58542824 -1.3889759  -0.13980524 -0.5486773  -1.4707257\n",
      "  0.01490228 -0.5826049  -1.4895391  -0.11598    -0.4199395  -1.258735\n",
      " -0.2834115  -0.17937735 -2.0420537  -0.08002547 -0.36003017 -2.0642738\n",
      "  0.11477832 -0.31356534 -1.3493395  -0.24671715 -0.18668358 -1.1766169\n",
      " -0.17073324 -0.157922   -1.2594857  -0.13605718 -0.16217522 -1.3732884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.01752193 -0.17620684 -1.1719341   0.14      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[ 0.0039, -0.0774, -0.1726,  ...,  0.0309, -0.2323, -1.2891],\n",
      "        [ 0.0039, -0.0774, -0.1726,  ...,  0.0309, -0.2323, -1.2891],\n",
      "        [ 0.0039, -0.0774, -0.1726,  ...,  0.0309, -0.2323, -1.2891],\n",
      "        ...,\n",
      "        [-0.2979,  0.3129, -0.2454,  ..., -0.8156,  0.8092, -0.4566],\n",
      "        [-0.2233, -0.1166,  0.4792,  ..., -0.3393,  0.5984,  0.2462],\n",
      "        [-0.2233, -0.1166,  0.4792,  ..., -0.3393,  0.5984,  0.2462]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 3.93541623e-03 -7.73751736e-02 -1.72561526e-01  2.33278163e-02\n",
      " -2.34513581e-01 -6.39930844e-01 -8.24620575e-03 -3.68144721e-01\n",
      " -1.30337524e+00 -1.45144820e-01 -4.12357569e-01 -1.61269236e+00\n",
      " -3.15742016e-01 -5.50714016e-01 -2.07895565e+00 -2.19495073e-01\n",
      " -6.45602584e-01 -1.46209216e+00  7.61819482e-02 -6.33429527e-01\n",
      " -1.23245800e+00  2.11156011e-02 -5.79047441e-01 -1.28315830e+00\n",
      "  1.46643445e-02 -6.63388610e-01 -1.40246165e+00 -1.74490109e-01\n",
      " -5.34073710e-01 -1.38984394e+00 -4.86436188e-02 -5.82727790e-01\n",
      " -1.39432371e+00 -4.54289988e-02 -5.40910125e-01 -1.49908555e+00\n",
      "  6.94249272e-02 -5.72407365e-01 -1.57290661e+00 -5.90341017e-02\n",
      " -4.61865634e-01 -1.21430981e+00 -1.34930208e-01 -2.27548420e-01\n",
      " -1.72953773e+00  7.78429210e-04 -3.67133349e-01 -1.70397449e+00\n",
      "  1.38537511e-01 -3.31427425e-01 -1.43833447e+00 -1.65323749e-01\n",
      " -2.19777063e-01 -1.16619921e+00 -5.03342003e-02 -1.97698176e-01\n",
      " -1.24689054e+00  8.62717628e-04 -2.30477780e-01 -1.36998534e+00\n",
      "  3.09444591e-02 -2.32287928e-01 -1.28913951e+00]\n",
      "data: [ 3.93541623e-03 -7.73751736e-02 -1.72561526e-01  2.33278163e-02\n",
      " -2.34513581e-01 -6.39930844e-01 -8.24620575e-03 -3.68144721e-01\n",
      " -1.30337524e+00 -1.45144820e-01 -4.12357569e-01 -1.61269236e+00\n",
      " -3.15742016e-01 -5.50714016e-01 -2.07895565e+00 -2.19495073e-01\n",
      " -6.45602584e-01 -1.46209216e+00  7.61819482e-02 -6.33429527e-01\n",
      " -1.23245800e+00  2.11156011e-02 -5.79047441e-01 -1.28315830e+00\n",
      "  1.46643445e-02 -6.63388610e-01 -1.40246165e+00 -1.74490109e-01\n",
      " -5.34073710e-01 -1.38984394e+00 -4.86436188e-02 -5.82727790e-01\n",
      " -1.39432371e+00 -4.54290025e-02 -5.40910125e-01 -1.49908555e+00\n",
      "  6.94249272e-02 -5.72407365e-01 -1.57290661e+00 -5.90340979e-02\n",
      " -4.61865604e-01 -1.21430981e+00 -1.34930208e-01 -2.27548420e-01\n",
      " -1.72953761e+00  7.78429210e-04 -3.67133319e-01 -1.70397449e+00\n",
      "  1.38537511e-01 -3.31427425e-01 -1.43833447e+00 -1.65323749e-01\n",
      " -2.19777063e-01 -1.16619921e+00 -5.03342003e-02 -1.97698176e-01\n",
      " -1.24689054e+00  8.62717628e-04 -2.30477765e-01 -1.36998534e+00\n",
      "  3.09444591e-02 -2.32287928e-01 -1.28913951e+00  1.50000006e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0698, -0.1418, -0.2997,  ...,  0.0826, -0.3037, -1.3919],\n",
      "        [ 0.0698, -0.1418, -0.2997,  ...,  0.0826, -0.3037, -1.3919],\n",
      "        [ 0.0698, -0.1418, -0.2997,  ...,  0.0826, -0.3037, -1.3919],\n",
      "        ...,\n",
      "        [-0.2170,  0.4032, -0.2094,  ..., -0.7431,  0.9157, -0.5060],\n",
      "        [-0.1522,  0.0162,  0.6560,  ..., -0.2642,  0.7949,  0.2833],\n",
      "        [-0.1522,  0.0162,  0.6560,  ..., -0.2642,  0.7949,  0.2833]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 6.98153526e-02 -1.41814619e-01 -2.99745649e-01  9.93376672e-02\n",
      " -2.92257845e-01 -7.40878582e-01  3.01429927e-02 -4.77151185e-01\n",
      " -1.50187945e+00 -1.10621631e-01 -5.35953641e-01 -1.80681300e+00\n",
      " -2.78321683e-01 -6.59499526e-01 -2.28143883e+00 -1.44718543e-01\n",
      " -7.31759548e-01 -1.68381691e+00  1.17377549e-01 -7.54236221e-01\n",
      " -1.45388174e+00  6.68722093e-02 -7.02336788e-01 -1.49920130e+00\n",
      "  5.29274791e-02 -8.18265915e-01 -1.62022495e+00 -1.00588113e-01\n",
      " -6.14998937e-01 -1.59252763e+00 -1.92909688e-03 -6.78277254e-01\n",
      " -1.56816435e+00 -2.31728703e-03 -6.50977731e-01 -1.66129589e+00\n",
      "  1.19236261e-01 -6.87298059e-01 -1.72506714e+00 -7.03014433e-04\n",
      " -5.28992295e-01 -1.41151714e+00 -1.20569244e-01 -2.97607720e-01\n",
      " -2.03468156e+00  3.92946303e-02 -4.63778734e-01 -2.02173948e+00\n",
      "  1.86937466e-01 -4.19750661e-01 -1.56303215e+00 -1.17171153e-01\n",
      " -2.85484999e-01 -1.34343934e+00 -2.04838663e-02 -2.59553403e-01\n",
      " -1.40413761e+00  3.48124802e-02 -2.92504430e-01 -1.52052426e+00\n",
      "  8.26009065e-02 -3.03662002e-01 -1.39187241e+00]\n",
      "data: [ 6.9815353e-02 -1.4181462e-01 -2.9974565e-01  9.9337667e-02\n",
      " -2.9225785e-01 -7.4087858e-01  3.0142995e-02 -4.7715119e-01\n",
      " -1.5018795e+00 -1.1062163e-01 -5.3595364e-01 -1.8068130e+00\n",
      " -2.7832168e-01 -6.5949953e-01 -2.2814388e+00 -1.4471854e-01\n",
      " -7.3175955e-01 -1.6838168e+00  1.1737755e-01 -7.5423622e-01\n",
      " -1.4538817e+00  6.6872209e-02 -7.0233679e-01 -1.4992013e+00\n",
      "  5.2927479e-02 -8.1826591e-01 -1.6202250e+00 -1.0058811e-01\n",
      " -6.1499894e-01 -1.5925276e+00 -1.9290969e-03 -6.7827725e-01\n",
      " -1.5681643e+00 -2.3172870e-03 -6.5097773e-01 -1.6612959e+00\n",
      "  1.1923626e-01 -6.8729806e-01 -1.7250671e+00 -7.0301443e-04\n",
      " -5.2899230e-01 -1.4115171e+00 -1.2056925e-01 -2.9760772e-01\n",
      " -2.0346816e+00  3.9294630e-02 -4.6377873e-01 -2.0217395e+00\n",
      "  1.8693747e-01 -4.1975066e-01 -1.5630323e+00 -1.1717115e-01\n",
      " -2.8548500e-01 -1.3434393e+00 -2.0483866e-02 -2.5955340e-01\n",
      " -1.4041376e+00  3.4812480e-02 -2.9250443e-01 -1.5205243e+00\n",
      "  8.2600906e-02 -3.0366200e-01 -1.3918724e+00  1.6000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0087, -0.1716, -0.2283,  ...,  0.0461, -0.3513, -1.3365],\n",
      "        [ 0.0087, -0.1716, -0.2283,  ...,  0.0461, -0.3513, -1.3365],\n",
      "        [ 0.0087, -0.1716, -0.2283,  ...,  0.0461, -0.3513, -1.3365],\n",
      "        ...,\n",
      "        [-0.0671,  0.4811, -0.1406,  ..., -0.6702,  0.9699, -0.4068],\n",
      "        [-0.1266, -0.0032,  0.5582,  ..., -0.1447,  0.7255,  0.2395],\n",
      "        [-0.1266, -0.0032,  0.5582,  ..., -0.1447,  0.7255,  0.2395]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 8.6711245e-03 -1.7158379e-01 -2.2831441e-01  1.9202691e-02\n",
      " -3.4288198e-01 -6.9481671e-01 -4.2090565e-04 -5.0409842e-01\n",
      " -1.3937075e+00 -1.3858138e-01 -5.6053001e-01 -1.7207727e+00\n",
      " -3.2698548e-01 -7.1580642e-01 -2.1721156e+00 -2.1641378e-01\n",
      " -7.5195187e-01 -1.5859277e+00  9.6933156e-02 -7.5900513e-01\n",
      " -1.3452635e+00  3.0524403e-02 -7.1641451e-01 -1.3905771e+00\n",
      "  2.5784418e-02 -8.1499857e-01 -1.5078859e+00 -1.6127424e-01\n",
      " -6.2451488e-01 -1.4942033e+00 -3.7743263e-02 -6.9324601e-01\n",
      " -1.4827123e+00 -3.8025826e-02 -6.7500895e-01 -1.5923288e+00\n",
      "  6.1753094e-02 -7.1234691e-01 -1.6655726e+00 -3.8738720e-02\n",
      " -5.4875761e-01 -1.3042572e+00 -1.3612756e-01 -3.3151755e-01\n",
      " -1.8618302e+00  1.9214973e-03 -4.9223948e-01 -1.8283710e+00\n",
      "  1.3807927e-01 -4.5491457e-01 -1.4972317e+00 -1.5505847e-01\n",
      " -3.0053699e-01 -1.2487292e+00 -2.8253302e-02 -2.9336363e-01\n",
      " -1.3150482e+00  2.5817603e-02 -3.4645191e-01 -1.4283650e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4.6087764e-02 -3.5129166e-01 -1.3365154e+00]\n",
      "data: [ 8.6711245e-03 -1.7158379e-01 -2.2831441e-01  1.9202691e-02\n",
      " -3.4288198e-01 -6.9481677e-01 -4.2090565e-04 -5.0409842e-01\n",
      " -1.3937076e+00 -1.3858138e-01 -5.6053001e-01 -1.7207727e+00\n",
      " -3.2698548e-01 -7.1580642e-01 -2.1721156e+00 -2.1641378e-01\n",
      " -7.5195193e-01 -1.5859277e+00  9.6933156e-02 -7.5900513e-01\n",
      " -1.3452635e+00  3.0524401e-02 -7.1641451e-01 -1.3905771e+00\n",
      "  2.5784418e-02 -8.1499857e-01 -1.5078859e+00 -1.6127424e-01\n",
      " -6.2451488e-01 -1.4942033e+00 -3.7743263e-02 -6.9324601e-01\n",
      " -1.4827123e+00 -3.8025826e-02 -6.7500895e-01 -1.5923288e+00\n",
      "  6.1753090e-02 -7.1234685e-01 -1.6655726e+00 -3.8738720e-02\n",
      " -5.4875761e-01 -1.3042572e+00 -1.3612756e-01 -3.3151758e-01\n",
      " -1.8618302e+00  1.9214973e-03 -4.9223945e-01 -1.8283709e+00\n",
      "  1.3807927e-01 -4.5491454e-01 -1.4972317e+00 -1.5505847e-01\n",
      " -3.0053699e-01 -1.2487292e+00 -2.8253302e-02 -2.9336363e-01\n",
      " -1.3150482e+00  2.5817605e-02 -3.4645191e-01 -1.4283650e+00\n",
      "  4.6087764e-02 -3.5129166e-01 -1.3365155e+00  1.7000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F898>\n",
      "tensor([[ 0.0100, -0.1648, -0.2103,  ...,  0.0425, -0.3535, -1.2378],\n",
      "        [ 0.0100, -0.1648, -0.2103,  ...,  0.0425, -0.3535, -1.2378],\n",
      "        [ 0.0100, -0.1648, -0.2103,  ...,  0.0425, -0.3535, -1.2378],\n",
      "        ...,\n",
      "        [-0.0480,  0.5492, -0.2125,  ..., -0.5055,  1.0772, -0.5822],\n",
      "        [-0.1767, -0.0366,  0.6515,  ..., -0.2522,  0.6470,  0.3328],\n",
      "        [-0.1767, -0.0366,  0.6515,  ..., -0.2522,  0.6470,  0.3328]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00996872 -0.16477033 -0.21034203  0.04677256 -0.27504092 -0.5151293\n",
      " -0.07163724 -0.5052553  -1.3660069  -0.22583148 -0.56948245 -1.6653548\n",
      " -0.3761958  -0.6738645  -2.1777527  -0.1893738  -0.79440916 -1.5731701\n",
      "  0.02239938 -0.8616735  -1.4133289  -0.03800632 -0.7955291  -1.4533488\n",
      " -0.05152738 -0.9579656  -1.5766451  -0.13673684 -0.7013165  -1.4646864\n",
      " -0.06764277 -0.76446605 -1.44181    -0.07236785 -0.7319716  -1.52695\n",
      "  0.04812139 -0.7807348  -1.5527935  -0.03969239 -0.5869267  -1.2985437\n",
      " -0.20567751 -0.3485399  -2.0640795  -0.01320536 -0.53927946 -2.0793529\n",
      "  0.14873435 -0.4899728  -1.4150686  -0.17573032 -0.35406142 -1.218934\n",
      " -0.08492075 -0.32525477 -1.3008286  -0.04664622 -0.34661198 -1.4120501\n",
      "  0.04252543 -0.35345685 -1.2378479 ]\n",
      "data: [ 0.00996872 -0.16477033 -0.21034202  0.04677255 -0.27504092 -0.5151293\n",
      " -0.07163724 -0.5052553  -1.3660067  -0.22583146 -0.56948245 -1.665355\n",
      " -0.3761958  -0.67386454 -2.1777527  -0.18937379 -0.79440916 -1.5731701\n",
      "  0.02239938 -0.86167353 -1.4133289  -0.03800632 -0.7955291  -1.4533486\n",
      " -0.05152738 -0.9579656  -1.5766453  -0.13673684 -0.7013165  -1.4646864\n",
      " -0.06764277 -0.76446605 -1.44181    -0.07236785 -0.73197156 -1.5269501\n",
      "  0.0481214  -0.7807348  -1.5527936  -0.03969239 -0.5869267  -1.2985437\n",
      " -0.20567751 -0.3485399  -2.0640795  -0.01320536 -0.53927946 -2.0793529\n",
      "  0.14873435 -0.4899728  -1.4150686  -0.17573032 -0.35406142 -1.218934\n",
      " -0.08492075 -0.3252548  -1.3008286  -0.04664622 -0.34661198 -1.4120501\n",
      "  0.04252543 -0.35345685 -1.2378479   0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[-0.0380, -0.0788, -0.1693,  ...,  0.0253, -0.2575, -1.1779],\n",
      "        [-0.0380, -0.0788, -0.1693,  ...,  0.0253, -0.2575, -1.1779],\n",
      "        [-0.0380, -0.0788, -0.1693,  ...,  0.0253, -0.2575, -1.1779],\n",
      "        ...,\n",
      "        [-0.1504,  0.4193, -0.0310,  ..., -0.6926,  1.0295, -0.4553],\n",
      "        [-0.0971, -0.0215,  0.6233,  ..., -0.2270,  0.6055,  0.2941],\n",
      "        [-0.0971, -0.0215,  0.6233,  ..., -0.2270,  0.6055,  0.2941]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.03803326 -0.07876956 -0.1693174  -0.01491102 -0.2201962  -0.4865995\n",
      " -0.08698524 -0.4212984  -1.2945142  -0.23725908 -0.47754532 -1.6165315\n",
      " -0.421553   -0.6174991  -2.093854   -0.26381505 -0.6859262  -1.504694\n",
      "  0.03475206 -0.7152035  -1.2833021  -0.0233514  -0.66967094 -1.3178632\n",
      " -0.01225767 -0.7908679  -1.4473242  -0.20250693 -0.56463146 -1.3943664\n",
      " -0.08579921 -0.6359341  -1.3768265  -0.05931064 -0.60760486 -1.481816\n",
      "  0.07770261 -0.6622579  -1.5458264  -0.07828093 -0.46701664 -1.2004427\n",
      " -0.22141008 -0.23562306 -1.9029796  -0.02206242 -0.42194322 -1.8902352\n",
      "  0.1610133  -0.3730944  -1.367469   -0.21919736 -0.21618451 -1.1318277\n",
      " -0.09005025 -0.20125641 -1.1918355  -0.03434826 -0.24833249 -1.310204\n",
      "  0.02525053 -0.25753796 -1.1778914 ]\n",
      "data: [-0.03803326 -0.07876956 -0.1693174  -0.01491102 -0.2201962  -0.4865995\n",
      " -0.08698524 -0.4212984  -1.2945142  -0.23725909 -0.47754532 -1.6165315\n",
      " -0.42155302 -0.6174991  -2.093854   -0.26381505 -0.6859262  -1.5046939\n",
      "  0.03475206 -0.7152035  -1.283302   -0.0233514  -0.66967094 -1.3178631\n",
      " -0.01225767 -0.7908679  -1.4473243  -0.20250693 -0.56463146 -1.3943665\n",
      " -0.08579921 -0.6359341  -1.3768265  -0.05931064 -0.60760486 -1.481816\n",
      "  0.07770261 -0.6622579  -1.5458264  -0.07828093 -0.46701664 -1.2004427\n",
      " -0.22141008 -0.23562306 -1.9029796  -0.02206242 -0.42194322 -1.8902352\n",
      "  0.1610133  -0.3730944  -1.3674691  -0.21919736 -0.21618453 -1.1318277\n",
      " -0.09005025 -0.20125641 -1.1918355  -0.03434826 -0.24833249 -1.310204\n",
      "  0.02525053 -0.25753796 -1.1778914   0.19      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[-0.0157, -0.0631, -0.2361,  ...,  0.0068, -0.2349, -1.2715],\n",
      "        [-0.0157, -0.0631, -0.2361,  ...,  0.0068, -0.2349, -1.2715],\n",
      "        [-0.0157, -0.0631, -0.2361,  ...,  0.0068, -0.2349, -1.2715],\n",
      "        ...,\n",
      "        [-0.2058,  0.4181, -0.1192,  ..., -0.7039,  0.9517, -0.4149],\n",
      "        [-0.1447, -0.1157,  0.6344,  ..., -0.2456,  0.6314,  0.2952],\n",
      "        [-0.1447, -0.1157,  0.6344,  ..., -0.2456,  0.6314,  0.2952]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01571459 -0.06308077 -0.23610875  0.01435518 -0.18610647 -0.610188\n",
      " -0.09396998 -0.38768935 -1.403243   -0.24258724 -0.44888553 -1.7040099\n",
      " -0.4062845  -0.55559915 -2.1932628  -0.22153781 -0.6793295  -1.5644355\n",
      " -0.0092708  -0.72217417 -1.3722363  -0.06425314 -0.65779215 -1.424912\n",
      " -0.07791229 -0.80417085 -1.5511748  -0.17614946 -0.5826057  -1.4681414\n",
      " -0.10411809 -0.63601303 -1.4485761  -0.11115993 -0.60243565 -1.542129\n",
      "  0.02153143 -0.6357733  -1.5804687  -0.08815243 -0.48142275 -1.2951999\n",
      " -0.22762462 -0.243278   -2.009598   -0.05032498 -0.40892547 -2.0207713\n",
      "  0.11389889 -0.37006694 -1.4351591  -0.20339127 -0.24645418 -1.2235566\n",
      " -0.1245864  -0.21687394 -1.3123404  -0.08218311 -0.22612551 -1.4315901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.00682759 -0.23491424 -1.2715305 ]\n",
      "data: [-0.01571459 -0.06308077 -0.23610874  0.01435518 -0.18610647 -0.610188\n",
      " -0.09396997 -0.38768935 -1.403243   -0.24258724 -0.44888553 -1.7040099\n",
      " -0.4062845  -0.55559915 -2.1932628  -0.22153781 -0.6793295  -1.5644355\n",
      " -0.0092708  -0.72217417 -1.3722364  -0.06425314 -0.65779215 -1.424912\n",
      " -0.07791229 -0.80417085 -1.5511748  -0.17614946 -0.5826057  -1.4681414\n",
      " -0.10411809 -0.63601303 -1.4485761  -0.11115993 -0.60243565 -1.542129\n",
      "  0.02153143 -0.6357733  -1.5804687  -0.08815243 -0.48142278 -1.2951999\n",
      " -0.22762462 -0.24327798 -2.009598   -0.05032497 -0.40892547 -2.0207713\n",
      "  0.11389889 -0.37006694 -1.4351592  -0.20339127 -0.24645418 -1.2235566\n",
      " -0.1245864  -0.21687394 -1.3123404  -0.0821831  -0.22612551 -1.4315901\n",
      "  0.00682759 -0.23491424 -1.2715305   0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.969 2.987 3.003 ... 0.    0.    0.   ]\n",
      " [2.971 2.989 3.009 ... 0.    0.    0.   ]\n",
      " [2.969 2.984 3.004 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.694 2.694 2.694 ... 2.524 0.    2.7  ]\n",
      " [2.685 2.684 2.684 ... 2.522 0.    2.689]\n",
      " [2.658 2.659 2.664 ... 2.521 0.    2.589]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]\n",
      " [0. 0. 0. ... 0. 1. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BB38>\n",
      "tensor([[-6.6722e-04, -4.4202e-02, -2.1757e-01,  ...,  1.2792e-02,\n",
      "         -2.1901e-01, -1.2840e+00],\n",
      "        [-6.6722e-04, -4.4202e-02, -2.1757e-01,  ...,  1.2792e-02,\n",
      "         -2.1901e-01, -1.2840e+00],\n",
      "        [-6.6722e-04, -4.4202e-02, -2.1757e-01,  ...,  1.2792e-02,\n",
      "         -2.1901e-01, -1.2840e+00],\n",
      "        ...,\n",
      "        [-3.7765e-01,  1.2254e-01, -3.6129e-01,  ..., -8.8285e-01,\n",
      "          5.4950e-01, -5.8282e-01],\n",
      "        [-1.1752e-01, -1.3762e-01,  5.9446e-01,  ..., -2.0888e-01,\n",
      "          6.2127e-01,  2.6441e-01],\n",
      "        [-1.1752e-01, -1.3762e-01,  5.9446e-01,  ..., -2.0888e-01,\n",
      "          6.2127e-01,  2.6441e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-6.67224638e-04 -4.42016870e-02 -2.17568979e-01  6.59275427e-03\n",
      " -1.94470420e-01 -6.60000682e-01 -6.41993135e-02 -3.65374684e-01\n",
      " -1.36033976e+00 -2.06145048e-01 -4.22678441e-01 -1.66724062e+00\n",
      " -3.90391290e-01 -5.41896462e-01 -2.12381887e+00 -2.14834079e-01\n",
      " -6.46726012e-01 -1.51255238e+00  1.29356533e-02 -6.64639115e-01\n",
      " -1.31520307e+00 -3.41467559e-02 -6.06428146e-01 -1.37104058e+00\n",
      " -3.20826843e-02 -7.31666446e-01 -1.48659348e+00 -1.71893671e-01\n",
      " -5.34406066e-01 -1.43065596e+00 -7.97806382e-02 -5.88620543e-01\n",
      " -1.40887737e+00 -8.54912624e-02 -5.64617515e-01 -1.51490855e+00\n",
      "  4.87799793e-02 -5.84628224e-01 -1.57411301e+00 -7.78418407e-02\n",
      " -4.49782968e-01 -1.26106083e+00 -1.80272758e-01 -2.32432663e-01\n",
      " -1.85993588e+00 -3.40942815e-02 -3.76669407e-01 -1.85363615e+00\n",
      "  1.20794326e-01 -3.45029861e-01 -1.42860293e+00 -1.77501217e-01\n",
      " -2.10754901e-01 -1.20330036e+00 -9.78436172e-02 -1.91730067e-01\n",
      " -1.28470206e+00 -5.12822568e-02 -2.09043711e-01 -1.40631759e+00\n",
      "  1.27917603e-02 -2.19006911e-01 -1.28396022e+00]\n",
      "data: [-4.26 -2.88  5.1  -4.28 -2.62  5.08 -4.29 -2.21  5.36 -4.28 -1.94  5.57\n",
      " -4.3  -1.78  5.92 -4.1  -2.23  5.54 -4.09 -1.86  5.75 -4.25 -1.79  5.99\n",
      " -4.34 -1.75  5.98 -4.12 -2.26  5.54 -4.11 -1.86  5.75 -4.3  -1.78  5.92\n",
      "  0.    0.    0.   -4.11 -2.27  5.31 -4.2  -1.93  5.77 -4.28 -1.81  5.59\n",
      "  0.    0.    0.   -4.25 -2.21  5.36 -4.28 -1.97  5.57 -4.55 -2.    6.33\n",
      " -4.51 -1.93  6.01  0.  ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[-2.2371e-02, -2.7968e-03, -6.6571e-02,  ..., -1.6999e-01,\n",
      "         -2.1121e-01, -6.3131e-01],\n",
      "        [-2.2371e-02, -2.7968e-03, -6.6571e-02,  ..., -1.6999e-01,\n",
      "         -2.1121e-01, -6.3131e-01],\n",
      "        [-2.2371e-02, -2.7968e-03, -6.6571e-02,  ..., -1.6999e-01,\n",
      "         -2.1121e-01, -6.3131e-01],\n",
      "        ...,\n",
      "        [ 9.8467e-01, -1.0751e+00,  4.0975e-01,  ..., -8.2348e-02,\n",
      "         -9.2293e-01,  7.8803e-01],\n",
      "        [ 3.3716e-01,  3.6978e-01,  1.1654e+00,  ...,  3.0336e-01,\n",
      "          2.1495e-01,  3.4814e+00],\n",
      "        [ 3.3716e-01,  3.6978e-01,  1.1654e+00,  ...,  3.0336e-01,\n",
      "          2.1495e-01,  3.4814e+00]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.02237065 -0.00279676 -0.06657142 -0.11321448 -0.07381529 -0.47453448\n",
      " -0.11189262 -0.17991982 -0.62229097 -0.08655821 -0.29859704 -0.5872375\n",
      " -0.03874383 -0.38656265 -0.65106785 -0.17514881 -0.1974276  -0.95165265\n",
      "  0.00675306 -0.24887682 -0.32016522 -0.079492   -0.3879227  -0.2986232\n",
      " -0.19886255 -0.39279932 -0.39110455 -0.18086085 -0.15545858 -0.9860443\n",
      " -0.23368996 -0.26540095 -0.9322033  -0.29992715 -0.33014244 -0.888059\n",
      " -0.3359848  -0.46372986 -0.82499087 -0.18958196 -0.11068141 -0.9658649\n",
      " -0.29126003 -0.1564606  -1.0357013  -0.29832348 -0.23484625 -1.0463264\n",
      " -0.2545338  -0.3523649  -0.74425685 -0.2069675  -0.0129867  -0.8102555\n",
      " -0.15764853 -0.0877188  -0.7818799  -0.20147638 -0.14029315 -0.75178814\n",
      " -0.16999355 -0.21120888 -0.63130665]\n",
      "init: [-0.02237065 -0.00279676 -0.06657142 -0.11321448 -0.07381529 -0.47453448\n",
      " -0.11189262 -0.17991982 -0.62229097 -0.08655821 -0.29859704 -0.5872375\n",
      " -0.03874383 -0.38656265 -0.65106785 -0.17514881 -0.1974276  -0.95165265\n",
      "  0.00675306 -0.24887682 -0.32016522 -0.079492   -0.3879227  -0.2986232\n",
      " -0.19886255 -0.39279932 -0.39110455 -0.18086085 -0.15545858 -0.9860443\n",
      " -0.23368996 -0.26540095 -0.9322033  -0.29992715 -0.33014244 -0.888059\n",
      " -0.3359848  -0.46372986 -0.82499087 -0.18958196 -0.11068141 -0.9658649\n",
      " -0.29126003 -0.1564606  -1.0357013  -0.29832348 -0.23484625 -1.0463264\n",
      " -0.2545338  -0.3523649  -0.74425685 -0.2069675  -0.0129867  -0.8102555\n",
      " -0.15764853 -0.0877188  -0.7818799  -0.20147638 -0.14029315 -0.75178814\n",
      " -0.16999355 -0.21120888 -0.63130665]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [-0.02237065 -0.00279676 -0.06657142 -0.11321447 -0.07381529 -0.47453448\n",
      " -0.11189261 -0.17991981 -0.62229097 -0.08655821 -0.29859704 -0.5872375\n",
      " -0.03874383 -0.38656265 -0.6510679  -0.17514881 -0.1974276  -0.9516527\n",
      "  0.00675306 -0.24887682 -0.32016522 -0.079492   -0.3879227  -0.2986232\n",
      " -0.19886255 -0.3927993  -0.39110455 -0.18086085 -0.15545858 -0.9860443\n",
      " -0.23368996 -0.26540095 -0.9322033  -0.29992715 -0.33014244 -0.888059\n",
      " -0.3359848  -0.46372986 -0.82499087 -0.18958196 -0.11068142 -0.9658649\n",
      " -0.29126003 -0.1564606  -1.0357013  -0.29832348 -0.23484625 -1.0463264\n",
      " -0.2545338  -0.3523649  -0.7442568  -0.2069675  -0.0129867  -0.8102555\n",
      " -0.15764853 -0.0877188  -0.7818799  -0.20147638 -0.14029315 -0.7517882\n",
      " -0.16999355 -0.21120888 -0.63130665  0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EC24BA8>\n",
      "tensor([[ 0.1319, -0.2336,  0.2936,  ...,  0.2676, -0.3780, -0.7740],\n",
      "        [ 0.1319, -0.2336,  0.2936,  ...,  0.2676, -0.3780, -0.7740],\n",
      "        [ 0.1319, -0.2336,  0.2936,  ...,  0.2676, -0.3780, -0.7740],\n",
      "        ...,\n",
      "        [-0.0010,  0.0281, -0.5317,  ..., -0.7699,  0.5029, -0.8235],\n",
      "        [-0.2136,  0.1739,  0.0607,  ..., -0.5496,  0.8697, -0.1786],\n",
      "        [-0.2136,  0.1739,  0.0607,  ..., -0.5496,  0.8697, -0.1786]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.3185479e-01 -2.3358521e-01  2.9363060e-01  1.6609821e-01\n",
      " -3.7333101e-01  1.4158189e-03  8.0055155e-02 -5.4264224e-01\n",
      " -7.5543904e-01 -7.7169552e-02 -5.8496696e-01 -1.0629519e+00\n",
      " -2.5305679e-01 -7.1664500e-01 -1.5491462e+00 -9.1884077e-02\n",
      " -8.1906319e-01 -9.5627165e-01  2.1901673e-01 -8.1956208e-01\n",
      " -7.1562862e-01  1.7305483e-01 -7.4843562e-01 -7.4552417e-01\n",
      "  1.5678778e-01 -8.5330272e-01 -8.6724007e-01 -2.2470593e-02\n",
      " -7.0655763e-01 -8.7483811e-01  1.1787626e-01 -7.5790751e-01\n",
      " -8.8304222e-01  1.4803882e-01 -6.9453537e-01 -9.7604394e-01\n",
      "  2.9307604e-01 -7.4636400e-01 -1.0612043e+00  1.2721205e-01\n",
      " -6.2412655e-01 -6.9977403e-01  1.9813165e-02 -3.5627860e-01\n",
      " -1.3255931e+00  2.1291158e-01 -5.3484201e-01 -1.3022044e+00\n",
      "  3.8139176e-01 -4.5821956e-01 -9.3909419e-01 -4.4067502e-03\n",
      " -3.7703714e-01 -6.5344024e-01  1.3281307e-01 -3.3494616e-01\n",
      " -7.4244893e-01  2.0749098e-01 -3.7541470e-01 -8.7950706e-01\n",
      "  2.6762170e-01 -3.7798560e-01 -7.7396691e-01]\n",
      "data: [ 1.3185479e-01 -2.3358521e-01  2.9363060e-01  1.6609821e-01\n",
      " -3.7333098e-01  1.4158189e-03  8.0055147e-02 -5.4264224e-01\n",
      " -7.5543904e-01 -7.7169552e-02 -5.8496696e-01 -1.0629519e+00\n",
      " -2.5305679e-01 -7.1664500e-01 -1.5491462e+00 -9.1884077e-02\n",
      " -8.1906319e-01 -9.5627165e-01  2.1901673e-01 -8.1956208e-01\n",
      " -7.1562868e-01  1.7305483e-01 -7.4843562e-01 -7.4552417e-01\n",
      "  1.5678778e-01 -8.5330272e-01 -8.6724007e-01 -2.2470593e-02\n",
      " -7.0655763e-01 -8.7483811e-01  1.1787626e-01 -7.5790751e-01\n",
      " -8.8304222e-01  1.4803882e-01 -6.9453537e-01 -9.7604394e-01\n",
      "  2.9307604e-01 -7.4636400e-01 -1.0612043e+00  1.2721205e-01\n",
      " -6.2412655e-01 -6.9977403e-01  1.9813165e-02 -3.5627860e-01\n",
      " -1.3255931e+00  2.1291156e-01 -5.3484201e-01 -1.3022045e+00\n",
      "  3.8139176e-01 -4.5821956e-01 -9.3909419e-01 -4.4067502e-03\n",
      " -3.7703714e-01 -6.5344024e-01  1.3281307e-01 -3.3494613e-01\n",
      " -7.4244899e-01  2.0749098e-01 -3.7541470e-01 -8.7950706e-01\n",
      "  2.6762170e-01 -3.7798560e-01 -7.7396691e-01  2.0000000e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B320>\n",
      "tensor([[ 0.0110, -0.0530, -0.0177,  ..., -0.1044, -0.2958, -0.9575],\n",
      "        [ 0.0110, -0.0530, -0.0177,  ..., -0.1044, -0.2958, -0.9575],\n",
      "        [ 0.0110, -0.0530, -0.0177,  ..., -0.1044, -0.2958, -0.9575],\n",
      "        ...,\n",
      "        [-0.3236,  0.0813,  0.4479,  ..., -0.3793,  0.8105, -0.2149],\n",
      "        [-0.1584,  0.2471,  0.4383,  ...,  0.1497,  0.6645,  0.1837],\n",
      "        [-0.1584,  0.2471,  0.4383,  ...,  0.1497,  0.6645,  0.1837]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01098992 -0.05296104 -0.01769522 -0.05973843 -0.18045539 -0.37435034\n",
      " -0.21337128 -0.3867334  -1.090114   -0.40133876 -0.45412776 -1.4118278\n",
      " -0.6603498  -0.5413095  -1.8940352  -0.24032158 -0.66782784 -1.3031027\n",
      " -0.27136952 -0.7636961  -1.3358155  -0.32649016 -0.642887   -1.4310651\n",
      " -0.2654671  -0.89854157 -1.4942465  -0.20080246 -0.5612978  -1.1986996\n",
      " -0.24737021 -0.61174107 -1.1345518  -0.3337186  -0.6816404  -1.2689635\n",
      " -0.19709775 -0.5944996  -1.2513813  -0.1610536  -0.5075186  -1.0511767\n",
      " -0.30150828 -0.32690793 -1.7235867  -0.22791347 -0.47251335 -1.748757\n",
      " -0.08281595 -0.48312345 -1.0555454  -0.20182253 -0.30300897 -0.99751705\n",
      " -0.2551713  -0.3194704  -1.0767167  -0.2508629  -0.28348973 -1.1729625\n",
      " -0.10439801 -0.29579967 -0.9574566 ]\n",
      "data: [ 0.01098992 -0.05296104 -0.01769522 -0.05973843 -0.18045539 -0.37435037\n",
      " -0.21337128 -0.3867334  -1.090114   -0.40133876 -0.45412776 -1.4118278\n",
      " -0.6603498  -0.5413095  -1.8940352  -0.24032158 -0.66782784 -1.3031027\n",
      " -0.27136952 -0.7636961  -1.3358155  -0.32649016 -0.64288694 -1.4310651\n",
      " -0.2654671  -0.89854157 -1.4942465  -0.20080246 -0.5612978  -1.1986996\n",
      " -0.2473702  -0.61174107 -1.1345518  -0.3337186  -0.6816404  -1.2689635\n",
      " -0.19709773 -0.5944996  -1.2513813  -0.1610536  -0.5075186  -1.0511767\n",
      " -0.30150828 -0.32690793 -1.7235867  -0.22791347 -0.47251335 -1.748757\n",
      " -0.08281595 -0.48312342 -1.0555454  -0.20182253 -0.30300897 -0.997517\n",
      " -0.2551713  -0.3194704  -1.0767167  -0.2508629  -0.28348973 -1.1729625\n",
      " -0.10439801 -0.29579967 -0.9574566   0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EC246D8>\n",
      "tensor([[ 0.0541,  0.1145, -0.2289,  ...,  0.1788, -0.0986, -1.2330],\n",
      "        [ 0.0541,  0.1145, -0.2289,  ...,  0.1788, -0.0986, -1.2330],\n",
      "        [ 0.0541,  0.1145, -0.2289,  ...,  0.1788, -0.0986, -1.2330],\n",
      "        ...,\n",
      "        [-0.0997,  0.3820,  0.1988,  ..., -0.2774,  1.0857, -0.1712],\n",
      "        [-0.1093, -0.1148,  0.4718,  ..., -0.4364,  0.4522,  0.2235],\n",
      "        [-0.1093, -0.1148,  0.4718,  ..., -0.4364,  0.4522,  0.2235]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.05405778  0.11445393 -0.22888441  0.08972684 -0.02385548 -0.5626631\n",
      "  0.01650044 -0.2006527  -1.3285736  -0.12308813 -0.2605967  -1.6232247\n",
      " -0.28873137 -0.40509742 -2.0817006  -0.14857584 -0.48101622 -1.515594\n",
      "  0.16275382 -0.49729365 -1.2603706   0.12305803 -0.43914807 -1.2916727\n",
      "  0.14241567 -0.54223806 -1.4156764  -0.09139786 -0.36861193 -1.4273843\n",
      "  0.04274321 -0.43603402 -1.4071162   0.08159079 -0.39760196 -1.4850569\n",
      "  0.24286029 -0.44716305 -1.5633862   0.03436451 -0.30350274 -1.2364572\n",
      " -0.07431216 -0.04923926 -1.8708162   0.12061977 -0.23289399 -1.843494\n",
      "  0.31768638 -0.18160145 -1.4092717  -0.10055637 -0.04870808 -1.173099\n",
      "  0.03706317 -0.02579798 -1.2453977   0.11309446 -0.07350029 -1.3648521\n",
      "  0.1788114  -0.09863551 -1.2329843 ]\n",
      "data: [ 0.05405778  0.11445393 -0.22888441  0.08972684 -0.02385548 -0.5626631\n",
      "  0.01650044 -0.20065269 -1.3285736  -0.12308813 -0.2605967  -1.6232247\n",
      " -0.28873137 -0.40509742 -2.0817006  -0.14857584 -0.48101625 -1.515594\n",
      "  0.16275384 -0.49729365 -1.2603706   0.12305804 -0.43914807 -1.2916727\n",
      "  0.14241567 -0.54223806 -1.4156765  -0.09139786 -0.36861193 -1.4273841\n",
      "  0.04274322 -0.43603402 -1.4071163   0.08159079 -0.39760196 -1.4850569\n",
      "  0.24286027 -0.44716305 -1.5633862   0.03436451 -0.30350274 -1.2364572\n",
      " -0.07431216 -0.04923926 -1.8708162   0.12061977 -0.23289399 -1.843494\n",
      "  0.31768638 -0.18160145 -1.4092717  -0.10055637 -0.04870808 -1.173099\n",
      "  0.03706317 -0.02579798 -1.2453977   0.11309446 -0.07350029 -1.3648522\n",
      "  0.1788114  -0.09863551 -1.2329843   0.04      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.1012, -0.2105, -0.2029,  ...,  0.1316, -0.3686, -1.3101],\n",
      "        [ 0.1012, -0.2105, -0.2029,  ...,  0.1316, -0.3686, -1.3101],\n",
      "        [ 0.1012, -0.2105, -0.2029,  ...,  0.1316, -0.3686, -1.3101],\n",
      "        ...,\n",
      "        [-0.4452,  0.1724, -0.4220,  ..., -1.0456,  0.5770, -0.6319],\n",
      "        [-0.1330,  0.1889,  0.5158,  ..., -0.1868,  1.0229,  0.1188],\n",
      "        [-0.1330,  0.1889,  0.5158,  ..., -0.1868,  1.0229,  0.1188]],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.1011823  -0.2105326  -0.20288162  0.12169483 -0.38047227 -0.7169988\n",
      "  0.08074813 -0.5244553  -1.401      -0.05148032 -0.5758801  -1.6974348\n",
      " -0.20904218 -0.7116128  -2.1704116  -0.11650102 -0.7750554  -1.5560291\n",
      "  0.16232835 -0.7636336  -1.3023349   0.10550471 -0.70380884 -1.3565291\n",
      "  0.08462726 -0.78928536 -1.4729296  -0.07829079 -0.65948987 -1.4884099\n",
      "  0.04128806 -0.7072596  -1.4702708   0.02591906 -0.6670602  -1.5545263\n",
      "  0.12827136 -0.6934539  -1.6144667   0.03517664 -0.58893436 -1.3148317\n",
      " -0.03881319 -0.35624644 -1.8074647   0.08259846 -0.49909472 -1.7784314\n",
      "  0.20545597 -0.4590053  -1.4763361  -0.05870491 -0.35413274 -1.2555368\n",
      "  0.05069251 -0.3297166  -1.3120447   0.10068293 -0.3604175  -1.4282333\n",
      "  0.1316072  -0.36863118 -1.3100946 ]\n",
      "data: [ 0.1011823  -0.2105326  -0.20288162  0.12169483 -0.38047227 -0.7169988\n",
      "  0.08074813 -0.5244553  -1.401      -0.05148032 -0.5758801  -1.6974349\n",
      " -0.20904216 -0.7116129  -2.1704116  -0.11650102 -0.7750554  -1.5560291\n",
      "  0.16232833 -0.76363355 -1.3023349   0.10550471 -0.70380884 -1.3565291\n",
      "  0.08462726 -0.78928536 -1.4729295  -0.07829079 -0.65948987 -1.4884099\n",
      "  0.04128806 -0.7072596  -1.4702706   0.02591906 -0.66706014 -1.5545263\n",
      "  0.12827136 -0.6934539  -1.6144667   0.03517664 -0.58893436 -1.3148317\n",
      " -0.03881319 -0.35624644 -1.8074647   0.08259847 -0.49909472 -1.7784314\n",
      "  0.20545597 -0.45900527 -1.476336   -0.05870491 -0.35413274 -1.2555368\n",
      "  0.05069251 -0.3297166  -1.3120446   0.10068293 -0.3604175  -1.4282334\n",
      "  0.1316072  -0.36863118 -1.3100946   0.05      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[ 0.0085, -0.2035, -0.1850,  ...,  0.0347, -0.3911, -1.2270],\n",
      "        [ 0.0085, -0.2035, -0.1850,  ...,  0.0347, -0.3911, -1.2270],\n",
      "        [ 0.0085, -0.2035, -0.1850,  ...,  0.0347, -0.3911, -1.2270],\n",
      "        ...,\n",
      "        [-0.0114,  0.5752, -0.2271,  ..., -0.4963,  1.0836, -0.6394],\n",
      "        [-0.1415, -0.0014,  0.5976,  ..., -0.1454,  0.7210,  0.1764],\n",
      "        [-0.1415, -0.0014,  0.5976,  ..., -0.1454,  0.7210,  0.1764]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00851746 -0.20347203 -0.18500005  0.04188546 -0.33181322 -0.5522039\n",
      " -0.04946913 -0.5493716  -1.3695388  -0.19977635 -0.6132933  -1.6804565\n",
      " -0.36994624 -0.7333626  -2.1698952  -0.20257181 -0.8110385  -1.5728503\n",
      "  0.04220369 -0.86571485 -1.3637425  -0.01818616 -0.80976355 -1.4030923\n",
      " -0.03927331 -0.9592599  -1.5235413  -0.14813802 -0.7062655  -1.4622352\n",
      " -0.06756836 -0.77986175 -1.4292486  -0.07536671 -0.75985986 -1.5218513\n",
      "  0.03725929 -0.8044265  -1.5648712  -0.04668047 -0.60580766 -1.2833415\n",
      " -0.20150867 -0.37834382 -2.0085163  -0.02213944 -0.56850755 -2.006928\n",
      "  0.12801072 -0.52208394 -1.4011278  -0.17456397 -0.36976844 -1.2089807\n",
      " -0.07903055 -0.3488085  -1.2732487  -0.02988017 -0.3844478  -1.3831941\n",
      "  0.03469512 -0.39105695 -1.2269661 ]\n",
      "data: [ 0.00851746 -0.20347205 -0.18500003  0.04188546 -0.33181322 -0.5522039\n",
      " -0.04946913 -0.5493716  -1.3695388  -0.19977635 -0.6132933  -1.6804565\n",
      " -0.36994624 -0.73336256 -2.1698952  -0.20257181 -0.8110385  -1.5728503\n",
      "  0.04220369 -0.86571485 -1.3637425  -0.01818616 -0.80976355 -1.4030921\n",
      " -0.03927331 -0.9592599  -1.5235412  -0.14813802 -0.7062655  -1.4622352\n",
      " -0.06756836 -0.77986175 -1.4292485  -0.07536671 -0.75985986 -1.5218513\n",
      "  0.03725929 -0.8044265  -1.5648712  -0.04668047 -0.60580766 -1.2833415\n",
      " -0.20150867 -0.37834382 -2.0085163  -0.02213944 -0.56850755 -2.006928\n",
      "  0.12801072 -0.52208394 -1.4011278  -0.17456397 -0.36976844 -1.2089807\n",
      " -0.07903055 -0.34880847 -1.2732487  -0.02988017 -0.3844478  -1.3831941\n",
      "  0.03469512 -0.39105693 -1.2269661   0.06      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[-0.0133, -0.0789, -0.1686,  ...,  0.0095, -0.2562, -1.1675],\n",
      "        [-0.0133, -0.0789, -0.1686,  ...,  0.0095, -0.2562, -1.1675],\n",
      "        [-0.0133, -0.0789, -0.1686,  ...,  0.0095, -0.2562, -1.1675],\n",
      "        ...,\n",
      "        [-0.1474,  0.4768, -0.1128,  ..., -0.6669,  1.1013, -0.5563],\n",
      "        [-0.0530,  0.0139,  0.6697,  ..., -0.1243,  0.6744,  0.2946],\n",
      "        [-0.0530,  0.0139,  0.6697,  ..., -0.1243,  0.6744,  0.2946]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01331154 -0.07893009 -0.16862066  0.01556388 -0.19230951 -0.45309907\n",
      " -0.10741436 -0.42183828 -1.3099117  -0.26315004 -0.48489383 -1.6073279\n",
      " -0.42407024 -0.58769107 -2.1144376  -0.22016199 -0.7101675  -1.510602\n",
      " -0.01585384 -0.7712625  -1.3574088  -0.06928726 -0.7043823  -1.397776\n",
      " -0.0624145  -0.86074865 -1.5216216  -0.17063859 -0.6106961  -1.4027861\n",
      " -0.09814753 -0.6698836  -1.370655   -0.09385107 -0.637043   -1.461365\n",
      "  0.0454721  -0.67797935 -1.4898152  -0.07625439 -0.4965462  -1.2355895\n",
      " -0.23989521 -0.26212475 -1.9974127  -0.04305458 -0.44318482 -2.0146847\n",
      "  0.13794355 -0.39744398 -1.3462735  -0.21084704 -0.25843227 -1.1563547\n",
      " -0.12413426 -0.23187876 -1.2332073  -0.08579859 -0.24876155 -1.3454959\n",
      "  0.0095351  -0.25624532 -1.1675465 ]\n",
      "data: [-0.01331154 -0.07893009 -0.16862066  0.01556388 -0.19230951 -0.45309907\n",
      " -0.10741436 -0.4218383  -1.3099118  -0.26315004 -0.48489383 -1.6073279\n",
      " -0.42407024 -0.58769107 -2.1144376  -0.22016199 -0.7101675  -1.510602\n",
      " -0.01585384 -0.7712625  -1.3574088  -0.06928726 -0.7043823  -1.397776\n",
      " -0.0624145  -0.86074865 -1.5216216  -0.1706386  -0.6106961  -1.4027861\n",
      " -0.09814753 -0.66988355 -1.370655   -0.09385107 -0.637043   -1.4613651\n",
      "  0.0454721  -0.67797935 -1.4898152  -0.07625439 -0.4965462  -1.2355895\n",
      " -0.23989521 -0.26212475 -1.9974127  -0.04305458 -0.44318482 -2.0146847\n",
      "  0.13794355 -0.39744395 -1.3462735  -0.21084704 -0.25843227 -1.1563547\n",
      " -0.12413426 -0.23187876 -1.2332073  -0.08579859 -0.24876156 -1.3454959\n",
      "  0.0095351  -0.25624532 -1.1675465   0.07      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B320>\n",
      "tensor([[-0.0022, -0.0614, -0.2362,  ...,  0.0134, -0.2352, -1.2574],\n",
      "        [-0.0022, -0.0614, -0.2362,  ...,  0.0134, -0.2352, -1.2574],\n",
      "        [-0.0022, -0.0614, -0.2362,  ...,  0.0134, -0.2352, -1.2574],\n",
      "        ...,\n",
      "        [-0.2078,  0.3295,  0.0181,  ..., -0.7059,  0.8883, -0.2855],\n",
      "        [-0.0954, -0.0557,  0.6550,  ..., -0.2390,  0.6758,  0.3848],\n",
      "        [-0.0954, -0.0557,  0.6550,  ..., -0.2390,  0.6758,  0.3848]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.00220863 -0.06138002 -0.23619492  0.02652932 -0.17419416 -0.6041552\n",
      " -0.10023997 -0.3798648  -1.3938079  -0.2520657  -0.43978775 -1.6841334\n",
      " -0.40373862 -0.5317093  -2.1772926  -0.19963902 -0.68620783 -1.54731\n",
      " -0.01788443 -0.73563814 -1.3732606  -0.06823452 -0.6615192  -1.4296956\n",
      " -0.08058216 -0.81667334 -1.5556331  -0.15967195 -0.5982487  -1.4563777\n",
      " -0.09777259 -0.64558136 -1.4314958  -0.10854638 -0.6068877  -1.5178138\n",
      "  0.03180347 -0.63607377 -1.5415467  -0.07773175 -0.49014676 -1.2945825\n",
      " -0.21893086 -0.25153238 -2.01059    -0.04315652 -0.4135638  -2.0314143\n",
      "  0.12812632 -0.37487847 -1.4150162  -0.19128281 -0.26096052 -1.2198073\n",
      " -0.12533672 -0.22552277 -1.3144674  -0.09104612 -0.22417396 -1.433119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.01338743 -0.23522668 -1.2573509 ]\n",
      "data: [-0.00220863 -0.06138002 -0.23619491  0.02652932 -0.17419416 -0.6041552\n",
      " -0.10023997 -0.3798648  -1.3938079  -0.2520657  -0.43978775 -1.6841334\n",
      " -0.40373862 -0.5317093  -2.1772926  -0.19963902 -0.68620783 -1.54731\n",
      " -0.01788443 -0.73563814 -1.3732606  -0.06823452 -0.6615192  -1.4296956\n",
      " -0.08058216 -0.81667334 -1.5556331  -0.15967195 -0.5982487  -1.4563777\n",
      " -0.09777259 -0.64558136 -1.4314958  -0.10854638 -0.6068877  -1.5178139\n",
      "  0.03180347 -0.63607377 -1.5415466  -0.07773175 -0.49014676 -1.2945825\n",
      " -0.21893086 -0.25153238 -2.01059    -0.04315652 -0.41356382 -2.0314143\n",
      "  0.12812632 -0.37487847 -1.4150162  -0.19128281 -0.26096052 -1.2198073\n",
      " -0.12533672 -0.22552277 -1.3144674  -0.09104612 -0.22417396 -1.433119\n",
      "  0.01338743 -0.23522668 -1.2573509   0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0423, -0.0428, -0.1858,  ...,  0.0244, -0.2338, -1.2208],\n",
      "        [ 0.0423, -0.0428, -0.1858,  ...,  0.0244, -0.2338, -1.2208],\n",
      "        [ 0.0423, -0.0428, -0.1858,  ...,  0.0244, -0.2338, -1.2208],\n",
      "        ...,\n",
      "        [-0.3419,  0.1922, -0.2850,  ..., -0.8425,  0.6132, -0.4485],\n",
      "        [-0.1115, -0.0750,  0.5877,  ..., -0.1805,  0.6883,  0.3060],\n",
      "        [-0.1115, -0.0750,  0.5877,  ..., -0.1805,  0.6883,  0.3060]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04231596 -0.04280547 -0.18578696  0.05496174 -0.16632329 -0.5782182\n",
      " -0.07443914 -0.3595969  -1.3443468  -0.22582506 -0.42620862 -1.6262486\n",
      " -0.39394033 -0.5082164  -2.1217089  -0.15148844 -0.6714921  -1.4874333\n",
      " -0.01954226 -0.7198675  -1.3448858  -0.06453453 -0.6403795  -1.4090434\n",
      " -0.06737088 -0.80072904 -1.5191875  -0.12008066 -0.58145523 -1.4087934\n",
      " -0.07227232 -0.624537   -1.3692645  -0.10578609 -0.5993543  -1.462052\n",
      "  0.0345249  -0.60276586 -1.4823412  -0.05749898 -0.48897886 -1.2575234\n",
      " -0.17655836 -0.2661152  -1.9174615  -0.0361928  -0.40610152 -1.9399087\n",
      "  0.11875175 -0.38435763 -1.3580124  -0.14553717 -0.2618699  -1.1902902\n",
      " -0.11078155 -0.23703307 -1.2811239  -0.08217679 -0.22042868 -1.3976603\n",
      "  0.02435184 -0.23381096 -1.2208208 ]\n",
      "data: [ 0.04231596 -0.04280547 -0.18578698  0.05496174 -0.16632327 -0.5782182\n",
      " -0.07443914 -0.3595969  -1.3443468  -0.22582506 -0.42620862 -1.6262486\n",
      " -0.39394033 -0.5082164  -2.1217089  -0.15148844 -0.6714921  -1.4874333\n",
      " -0.01954226 -0.7198675  -1.3448858  -0.06453453 -0.6403795  -1.4090434\n",
      " -0.06737088 -0.80072904 -1.5191875  -0.12008066 -0.58145523 -1.4087934\n",
      " -0.07227232 -0.624537   -1.3692645  -0.10578609 -0.5993543  -1.462052\n",
      "  0.0345249  -0.60276586 -1.4823412  -0.05749898 -0.4889789  -1.2575234\n",
      " -0.17655836 -0.2661152  -1.9174615  -0.0361928  -0.40610152 -1.9399087\n",
      "  0.11875174 -0.38435763 -1.3580124  -0.14553717 -0.2618699  -1.1902902\n",
      " -0.11078156 -0.23703307 -1.2811238  -0.08217679 -0.22042868 -1.3976603\n",
      "  0.02435184 -0.23381096 -1.2208208   0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0361, -0.0298, -0.2591,  ...,  0.0138, -0.2246, -1.2885],\n",
      "        [ 0.0361, -0.0298, -0.2591,  ...,  0.0138, -0.2246, -1.2885],\n",
      "        [ 0.0361, -0.0298, -0.2591,  ...,  0.0138, -0.2246, -1.2885],\n",
      "        ...,\n",
      "        [-0.2581,  0.2831, -0.1705,  ..., -0.7906,  0.7181, -0.3466],\n",
      "        [-0.1163, -0.1135,  0.5831,  ..., -0.2096,  0.6938,  0.2868],\n",
      "        [-0.1163, -0.1135,  0.5831,  ..., -0.2096,  0.6938,  0.2868]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03610354 -0.02981331 -0.25910473  0.05324658 -0.14631188 -0.6460519\n",
      " -0.1060201  -0.34998718 -1.4488375  -0.2586912  -0.42345646 -1.7143412\n",
      " -0.417043   -0.48658234 -2.2227468  -0.14633691 -0.66861993 -1.5824022\n",
      " -0.05017427 -0.7253212  -1.4347858  -0.08436783 -0.63583523 -1.5020344\n",
      " -0.0899838  -0.8038229  -1.6129074  -0.12405302 -0.58489853 -1.5083334\n",
      " -0.08834905 -0.62355644 -1.4546502  -0.12754983 -0.593178   -1.5373929\n",
      "  0.03083288 -0.5879097  -1.549366   -0.07587338 -0.49305624 -1.362953\n",
      " -0.19282112 -0.26699644 -2.0217223  -0.05436187 -0.40021825 -2.0546668\n",
      "  0.11275923 -0.3794458  -1.4310277  -0.15775019 -0.26743293 -1.286757\n",
      " -0.1426104  -0.23577318 -1.376396   -0.1135039  -0.20514773 -1.4920442\n",
      "  0.01381693 -0.22464229 -1.2884908 ]\n",
      "data: [ 0.03610354 -0.02981331 -0.25910473  0.05324658 -0.14631188 -0.6460519\n",
      " -0.1060201  -0.34998718 -1.4488376  -0.2586912  -0.42345646 -1.7143412\n",
      " -0.417043   -0.48658234 -2.2227468  -0.14633691 -0.66861993 -1.5824022\n",
      " -0.05017427 -0.7253212  -1.4347857  -0.08436784 -0.63583523 -1.5020344\n",
      " -0.0899838  -0.8038229  -1.6129074  -0.12405302 -0.58489853 -1.5083334\n",
      " -0.08834906 -0.62355644 -1.4546502  -0.12754983 -0.593178   -1.5373929\n",
      "  0.03083288 -0.5879097  -1.549366   -0.07587338 -0.4930562  -1.3629528\n",
      " -0.19282112 -0.26699644 -2.0217223  -0.05436187 -0.40021825 -2.0546668\n",
      "  0.11275923 -0.3794458  -1.4310277  -0.15775019 -0.26743293 -1.286757\n",
      " -0.1426104  -0.23577318 -1.3763958  -0.1135039  -0.20514773 -1.4920442\n",
      "  0.01381693 -0.22464229 -1.2884908   0.1       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0506, -0.0236, -0.1728,  ...,  0.0629, -0.2172, -1.2097],\n",
      "        [ 0.0506, -0.0236, -0.1728,  ...,  0.0629, -0.2172, -1.2097],\n",
      "        [ 0.0506, -0.0236, -0.1728,  ...,  0.0629, -0.2172, -1.2097],\n",
      "        ...,\n",
      "        [-0.3265,  0.1537, -0.3320,  ..., -0.8972,  0.5378, -0.4514],\n",
      "        [-0.1514, -0.1327,  0.5078,  ..., -0.2484,  0.6360,  0.2285],\n",
      "        [-0.1514, -0.1327,  0.5078,  ..., -0.2484,  0.6360,  0.2285]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 5.06456383e-02 -2.36223843e-02 -1.72811151e-01  6.64028525e-02\n",
      " -1.60242006e-01 -5.73241472e-01 -3.81935984e-02 -3.39601576e-01\n",
      " -1.31569839e+00 -1.83621764e-01 -4.04998839e-01 -1.60128021e+00\n",
      " -3.54977071e-01 -5.05942822e-01 -2.08054519e+00 -1.42511040e-01\n",
      " -6.34725928e-01 -1.47096682e+00  2.79720128e-02 -6.69995308e-01\n",
      " -1.31563759e+00 -1.80998147e-02 -6.00308776e-01 -1.37625527e+00\n",
      " -1.28194243e-02 -7.42137909e-01 -1.48424315e+00 -1.05246335e-01\n",
      " -5.35175443e-01 -1.39466858e+00 -3.76949310e-02 -5.84513783e-01\n",
      " -1.36131477e+00 -6.11647069e-02 -5.64672589e-01 -1.45479989e+00\n",
      "  7.43155479e-02 -5.72924972e-01 -1.48979282e+00 -3.20451930e-02\n",
      " -4.54913765e-01 -1.23092461e+00 -1.38457030e-01 -2.32166529e-01\n",
      " -1.86253500e+00  1.59652531e-03 -3.76472741e-01 -1.86937737e+00\n",
      "  1.53475091e-01 -3.54353458e-01 -1.35111475e+00 -1.20705217e-01\n",
      " -2.23140016e-01 -1.17095590e+00 -6.52783513e-02 -2.03654751e-01\n",
      " -1.25280499e+00 -2.55673230e-02 -2.01597720e-01 -1.36876893e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6.29375726e-02 -2.17190519e-01 -1.20973444e+00]\n",
      "data: [ 5.06456383e-02 -2.36223843e-02 -1.72811151e-01  6.64028525e-02\n",
      " -1.60242006e-01 -5.73241472e-01 -3.81935984e-02 -3.39601606e-01\n",
      " -1.31569839e+00 -1.83621764e-01 -4.04998869e-01 -1.60128021e+00\n",
      " -3.54977071e-01 -5.05942822e-01 -2.08054519e+00 -1.42511040e-01\n",
      " -6.34725928e-01 -1.47096682e+00  2.79720109e-02 -6.69995248e-01\n",
      " -1.31563747e+00 -1.80998147e-02 -6.00308776e-01 -1.37625539e+00\n",
      " -1.28194233e-02 -7.42137909e-01 -1.48424315e+00 -1.05246335e-01\n",
      " -5.35175443e-01 -1.39466858e+00 -3.76949310e-02 -5.84513783e-01\n",
      " -1.36131465e+00 -6.11647069e-02 -5.64672589e-01 -1.45480001e+00\n",
      "  7.43155479e-02 -5.72924972e-01 -1.48979282e+00 -3.20451930e-02\n",
      " -4.54913735e-01 -1.23092461e+00 -1.38457030e-01 -2.32166514e-01\n",
      " -1.86253500e+00  1.59652531e-03 -3.76472741e-01 -1.86937749e+00\n",
      "  1.53475091e-01 -3.54353458e-01 -1.35111475e+00 -1.20705217e-01\n",
      " -2.23140016e-01 -1.17095590e+00 -6.52783513e-02 -2.03654751e-01\n",
      " -1.25280499e+00 -2.55673211e-02 -2.01597735e-01 -1.36876893e+00\n",
      "  6.29375726e-02 -2.17190519e-01 -1.20973444e+00  1.09999999e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0323, -0.0884, -0.2704,  ...,  0.0688, -0.2696, -1.3284],\n",
      "        [ 0.0323, -0.0884, -0.2704,  ...,  0.0688, -0.2696, -1.3284],\n",
      "        [ 0.0323, -0.0884, -0.2704,  ...,  0.0688, -0.2696, -1.3284],\n",
      "        ...,\n",
      "        [-0.3051,  0.2608, -0.2580,  ..., -0.7774,  0.6829, -0.4341],\n",
      "        [-0.1240, -0.0252,  0.5892,  ..., -0.2369,  0.7703,  0.2543],\n",
      "        [-0.1240, -0.0252,  0.5892,  ..., -0.2369,  0.7703,  0.2543]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03227999 -0.08836854 -0.27038482  0.05347748 -0.23911272 -0.69833744\n",
      " -0.03953443 -0.4228815  -1.4508016  -0.18228626 -0.48951402 -1.7411005\n",
      " -0.35277137 -0.60747737 -2.2098086  -0.1754809  -0.69139504 -1.606281\n",
      "  0.05079594 -0.71859556 -1.377826    0.00466911 -0.65578055 -1.4294205\n",
      " -0.00405072 -0.7795935  -1.5450122  -0.13249487 -0.5810745  -1.5262516\n",
      " -0.04333871 -0.6396022  -1.4920394  -0.05304999 -0.61256063 -1.5807068\n",
      "  0.08314475 -0.6336742  -1.633349   -0.0408048  -0.5037372  -1.3520699\n",
      " -0.14422849 -0.27392855 -1.9560938   0.00476843 -0.42779258 -1.9484386\n",
      "  0.16172925 -0.3934998  -1.4853368  -0.1393373  -0.26226193 -1.2882559\n",
      " -0.05871633 -0.23877974 -1.3608975  -0.00323927 -0.2550875  -1.4776666\n",
      "  0.06884761 -0.26964808 -1.3284073 ]\n",
      "data: [ 0.03227999 -0.08836853 -0.27038482  0.05347748 -0.23911272 -0.6983374\n",
      " -0.03953443 -0.4228815  -1.4508015  -0.18228626 -0.489514   -1.7411007\n",
      " -0.35277137 -0.60747737 -2.2098086  -0.1754809  -0.69139504 -1.6062809\n",
      "  0.05079594 -0.71859556 -1.377826    0.00466911 -0.65578055 -1.4294205\n",
      " -0.00405072 -0.7795935  -1.5450122  -0.13249487 -0.5810745  -1.5262516\n",
      " -0.04333871 -0.6396022  -1.4920394  -0.05304999 -0.61256063 -1.5807068\n",
      "  0.08314475 -0.6336742  -1.633349   -0.04080481 -0.5037372  -1.3520699\n",
      " -0.14422849 -0.27392855 -1.9560938   0.00476843 -0.42779258 -1.9484388\n",
      "  0.16172925 -0.3934998  -1.4853368  -0.1393373  -0.26226193 -1.2882559\n",
      " -0.05871633 -0.23877974 -1.3608975  -0.00323927 -0.2550875  -1.4776666\n",
      "  0.06884761 -0.26964808 -1.3284073   0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0234, -0.1290, -0.2563,  ...,  0.0693, -0.3125, -1.3228],\n",
      "        [ 0.0234, -0.1290, -0.2563,  ...,  0.0693, -0.3125, -1.3228],\n",
      "        [ 0.0234, -0.1290, -0.2563,  ...,  0.0693, -0.3125, -1.3228],\n",
      "        ...,\n",
      "        [-0.1278,  0.4439, -0.1893,  ..., -0.7179,  0.9441, -0.4529],\n",
      "        [-0.1581, -0.1075,  0.6038,  ..., -0.2440,  0.6501,  0.2737],\n",
      "        [-0.1581, -0.1075,  0.6038,  ..., -0.2440,  0.6501,  0.2737]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02343937 -0.12902538 -0.25629616  0.04172685 -0.2805808  -0.67622805\n",
      " -0.01638745 -0.45607162 -1.4031987  -0.15708144 -0.51438063 -1.7134364\n",
      " -0.33273953 -0.6489805  -2.1743724  -0.1878229  -0.7250496  -1.5825262\n",
      "  0.07502924 -0.7465558  -1.382998    0.01828031 -0.69300485 -1.4309411\n",
      "  0.02193799 -0.8109418  -1.5469426  -0.13568482 -0.61044836 -1.4933281\n",
      " -0.03171934 -0.6722965  -1.4764175  -0.03067173 -0.64960766 -1.5765007\n",
      "  0.08821493 -0.68252265 -1.6361077  -0.02860274 -0.5281538  -1.3123393\n",
      " -0.13698961 -0.30310923 -1.9257824   0.01782201 -0.46483523 -1.9099638\n",
      "  0.16883363 -0.42723468 -1.4821801  -0.14125186 -0.28578985 -1.2532926\n",
      " -0.03517273 -0.2695591  -1.3289632   0.01747558 -0.30357116 -1.4446088\n",
      "  0.06926899 -0.3125248  -1.3227924 ]\n",
      "data: [ 0.02343937 -0.12902538 -0.25629616  0.04172685 -0.2805808  -0.67622805\n",
      " -0.01638745 -0.45607162 -1.4031987  -0.15708144 -0.51438063 -1.7134365\n",
      " -0.33273953 -0.6489805  -2.1743724  -0.1878229  -0.7250496  -1.5825262\n",
      "  0.07502924 -0.7465558  -1.382998    0.01828031 -0.69300485 -1.4309411\n",
      "  0.02193799 -0.8109419  -1.5469426  -0.13568482 -0.61044836 -1.4933281\n",
      " -0.03171934 -0.6722965  -1.4764175  -0.03067173 -0.6496077  -1.5765007\n",
      "  0.08821493 -0.68252265 -1.6361077  -0.02860274 -0.5281538  -1.3123393\n",
      " -0.13698961 -0.30310923 -1.9257824   0.01782201 -0.46483526 -1.9099638\n",
      "  0.16883364 -0.42723468 -1.4821801  -0.14125186 -0.28578985 -1.2532926\n",
      " -0.03517273 -0.2695591  -1.3289632   0.01747558 -0.30357116 -1.4446088\n",
      "  0.06926899 -0.3125248  -1.3227924   0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0243, -0.1289, -0.2333,  ...,  0.0504, -0.3139, -1.2635],\n",
      "        [ 0.0243, -0.1289, -0.2333,  ...,  0.0504, -0.3139, -1.2635],\n",
      "        [ 0.0243, -0.1289, -0.2333,  ...,  0.0504, -0.3139, -1.2635],\n",
      "        ...,\n",
      "        [-0.1106,  0.4747, -0.1662,  ..., -0.6168,  0.9607, -0.4914],\n",
      "        [-0.1482, -0.0795,  0.6213,  ..., -0.2288,  0.6586,  0.2792],\n",
      "        [-0.1482, -0.0795,  0.6213,  ..., -0.2288,  0.6586,  0.2792]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02427689 -0.12890105 -0.23330016  0.05041591 -0.25575197 -0.5997515\n",
      " -0.05499956 -0.46425495 -1.3920327  -0.2034794  -0.5278292  -1.689834\n",
      " -0.36082354 -0.63644856 -2.1787312  -0.17630404 -0.7503684  -1.568154\n",
      "  0.0312674  -0.800055   -1.3894624  -0.02745548 -0.7352603  -1.4405901\n",
      " -0.0392812  -0.8852812  -1.5623384  -0.12951793 -0.6517201  -1.4727159\n",
      " -0.05840421 -0.709054   -1.4481707  -0.07123144 -0.68086743 -1.5366472\n",
      "  0.05030645 -0.71570456 -1.5663023  -0.03719088 -0.54729474 -1.3047266\n",
      " -0.17826569 -0.31751803 -2.0090346  -0.0095171  -0.48833188 -2.018293\n",
      "  0.14717185 -0.44888955 -1.4269783  -0.15332676 -0.31485617 -1.2327458\n",
      " -0.07152645 -0.28947747 -1.3165748  -0.03418654 -0.30379087 -1.4302938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.05043546 -0.3138901  -1.2634795 ]\n",
      "data: [ 0.02427689 -0.12890105 -0.23330016  0.05041592 -0.25575197 -0.5997515\n",
      " -0.05499956 -0.46425495 -1.3920327  -0.20347938 -0.5278292  -1.689834\n",
      " -0.36082354 -0.63644856 -2.1787312  -0.17630404 -0.7503684  -1.568154\n",
      "  0.0312674  -0.800055   -1.3894622  -0.02745548 -0.7352603  -1.4405903\n",
      " -0.0392812  -0.8852812  -1.5623384  -0.12951793 -0.6517201  -1.4727159\n",
      " -0.05840421 -0.70905393 -1.4481707  -0.07123144 -0.68086743 -1.5366472\n",
      "  0.05030645 -0.71570456 -1.5663023  -0.03719088 -0.54729474 -1.3047266\n",
      " -0.17826569 -0.31751803 -2.0090346  -0.0095171  -0.48833188 -2.018293\n",
      "  0.14717185 -0.44888955 -1.4269783  -0.15332676 -0.31485617 -1.2327458\n",
      " -0.07152645 -0.28947747 -1.3165748  -0.03418654 -0.30379087 -1.4302937\n",
      "  0.05043546 -0.3138901  -1.2634795   0.14      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B320>\n",
      "tensor([[ 0.0047, -0.0582, -0.1682,  ...,  0.0550, -0.2652, -1.1383],\n",
      "        [ 0.0047, -0.0582, -0.1682,  ...,  0.0550, -0.2652, -1.1383],\n",
      "        [ 0.0047, -0.0582, -0.1682,  ...,  0.0550, -0.2652, -1.1383],\n",
      "        ...,\n",
      "        [-0.1300,  0.3811, -0.0782,  ..., -0.7473,  0.8879, -0.3621],\n",
      "        [-0.1147, -0.0984,  0.5744,  ..., -0.2114,  0.6161,  0.2342],\n",
      "        [-0.1147, -0.0984,  0.5744,  ..., -0.2114,  0.6161,  0.2342]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00467074 -0.05824932 -0.16823548  0.03244312 -0.15940401 -0.4577542\n",
      " -0.10889004 -0.38489923 -1.2973005  -0.26304132 -0.44937786 -1.5887655\n",
      " -0.41555896 -0.544113   -2.0940435  -0.18546492 -0.6953165  -1.4727848\n",
      " -0.01183288 -0.7622187  -1.3227125  -0.06573984 -0.6875198  -1.3753427\n",
      " -0.07038848 -0.8619718  -1.5002952  -0.13693927 -0.611469   -1.3705748\n",
      " -0.07957628 -0.6663232  -1.3453807  -0.088897   -0.63551855 -1.4297014\n",
      "  0.05241352 -0.67059875 -1.4438608  -0.04987139 -0.5010489  -1.2075385\n",
      " -0.2084237  -0.2660105  -1.9895569  -0.01577709 -0.4458991  -2.014711\n",
      "  0.16259822 -0.4077248  -1.3079463  -0.16917169 -0.27696854 -1.1294652\n",
      " -0.09728935 -0.25038603 -1.2205652  -0.06363641 -0.25217724 -1.3351808\n",
      "  0.05504156 -0.26521784 -1.1382703 ]\n",
      "data: [ 0.00467074 -0.05824932 -0.16823548  0.03244312 -0.15940401 -0.45775422\n",
      " -0.10889003 -0.38489923 -1.2973005  -0.26304132 -0.44937786 -1.5887656\n",
      " -0.41555896 -0.544113   -2.0940435  -0.18546492 -0.6953165  -1.4727848\n",
      " -0.01183288 -0.7622187  -1.3227125  -0.06573984 -0.6875198  -1.3753427\n",
      " -0.07038848 -0.8619718  -1.5002952  -0.13693927 -0.611469   -1.3705748\n",
      " -0.07957628 -0.6663232  -1.3453807  -0.088897   -0.63551855 -1.4297013\n",
      "  0.05241352 -0.67059875 -1.4438608  -0.04987139 -0.5010489  -1.2075385\n",
      " -0.2084237  -0.2660105  -1.9895569  -0.01577709 -0.4458991  -2.014711\n",
      "  0.16259822 -0.4077248  -1.3079463  -0.16917169 -0.27696854 -1.1294652\n",
      " -0.09728935 -0.25038603 -1.2205652  -0.06363641 -0.25217724 -1.3351808\n",
      "  0.05504156 -0.26521784 -1.1382703   0.15      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0496,  0.0045, -0.2231,  ..., -0.0126, -0.1837, -1.2162],\n",
      "        [-0.0496,  0.0045, -0.2231,  ..., -0.0126, -0.1837, -1.2162],\n",
      "        [-0.0496,  0.0045, -0.2231,  ..., -0.0126, -0.1837, -1.2162],\n",
      "        ...,\n",
      "        [-0.2457,  0.2513, -0.0744,  ..., -0.7079,  0.7748, -0.4215],\n",
      "        [-0.1491, -0.1435,  0.5753,  ..., -0.2854,  0.6031,  0.2287],\n",
      "        [-0.1491, -0.1435,  0.5753,  ..., -0.2854,  0.6031,  0.2287]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.0495871   0.00448659 -0.22309656 -0.02267651 -0.09959212 -0.54806334\n",
      " -0.16150579 -0.31235093 -1.3680685  -0.31676978 -0.37405652 -1.6627808\n",
      " -0.4723761  -0.4645929  -2.1670713  -0.24290851 -0.6272291  -1.5287712\n",
      " -0.07081962 -0.6822207  -1.3692124  -0.11812639 -0.6034342  -1.4284458\n",
      " -0.12118003 -0.7711762  -1.5569642  -0.20011598 -0.54212487 -1.4307525\n",
      " -0.13968012 -0.59062207 -1.4061675  -0.148787   -0.5550474  -1.4977047\n",
      "  0.00589196 -0.58195555 -1.5198276  -0.11757011 -0.4351055  -1.2646568\n",
      " -0.26311842 -0.19478905 -2.0165138  -0.07793228 -0.3611014  -2.0422518\n",
      "  0.10904071 -0.32695755 -1.3820479  -0.23209807 -0.20657802 -1.1873648\n",
      " -0.16737187 -0.17426519 -1.2818189  -0.13163155 -0.17064185 -1.4013839\n",
      " -0.01258951 -0.18368833 -1.2162416 ]\n",
      "data: [-0.0495871   0.00448659 -0.22309656 -0.02267651 -0.09959212 -0.54806334\n",
      " -0.16150579 -0.31235093 -1.3680683  -0.31676978 -0.37405652 -1.6627808\n",
      " -0.4723761  -0.4645929  -2.1670713  -0.24290852 -0.6272291  -1.5287712\n",
      " -0.07081962 -0.6822207  -1.3692124  -0.11812639 -0.6034342  -1.4284457\n",
      " -0.12118003 -0.7711762  -1.5569642  -0.20011598 -0.54212487 -1.4307525\n",
      " -0.13968012 -0.59062207 -1.4061675  -0.148787   -0.5550474  -1.4977047\n",
      "  0.00589196 -0.58195555 -1.5198276  -0.11757012 -0.4351055  -1.2646568\n",
      " -0.26311842 -0.19478905 -2.0165138  -0.07793228 -0.3611014  -2.0422518\n",
      "  0.10904071 -0.32695755 -1.3820479  -0.23209806 -0.20657803 -1.1873648\n",
      " -0.16737187 -0.17426519 -1.2818189  -0.13163155 -0.17064185 -1.4013839\n",
      " -0.01258951 -0.18368834 -1.2162416   0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE3F7CB748>\n",
      "tensor([[-0.0043, -0.0683, -0.1819,  ...,  0.0162, -0.2300, -1.2941],\n",
      "        [-0.0043, -0.0683, -0.1819,  ...,  0.0162, -0.2300, -1.2941],\n",
      "        [-0.0043, -0.0683, -0.1819,  ...,  0.0162, -0.2300, -1.2941],\n",
      "        ...,\n",
      "        [-0.3047,  0.3145, -0.2465,  ..., -0.8749,  0.7802, -0.4090],\n",
      "        [-0.2059, -0.1405,  0.4908,  ..., -0.3015,  0.6035,  0.2136],\n",
      "        [-0.2059, -0.1405,  0.4908,  ..., -0.3015,  0.6035,  0.2136]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.00425075 -0.06827411 -0.18191223  0.01145569 -0.22958902 -0.66002285\n",
      " -0.02131804 -0.36148655 -1.3116678  -0.15681928 -0.40838563 -1.6188737\n",
      " -0.33411425 -0.5442049  -2.0772622  -0.22373898 -0.6377865  -1.4655137\n",
      "  0.05476469 -0.6263805  -1.2459987   0.00360407 -0.5712447  -1.2999877\n",
      "  0.00219002 -0.6597017  -1.413767   -0.18125483 -0.5241825  -1.396422\n",
      " -0.06105165 -0.5737306  -1.3939627  -0.06379698 -0.53962886 -1.5008007\n",
      "  0.05417895 -0.56198907 -1.5752044  -0.07360434 -0.45737398 -1.2215886\n",
      " -0.14400879 -0.2298096  -1.7272241  -0.01725886 -0.36438298 -1.7017258\n",
      "  0.11812644 -0.33374548 -1.4363018  -0.17099471 -0.21588233 -1.1763806\n",
      " -0.0680842  -0.19705112 -1.2551256  -0.01609603 -0.22569506 -1.377861\n",
      "  0.01620423 -0.23000765 -1.2940712 ]\n",
      "data: [-0.00425075 -0.06827411 -0.18191223  0.01145569 -0.22958903 -0.6600229\n",
      " -0.02131804 -0.36148655 -1.3116678  -0.15681928 -0.40838563 -1.6188737\n",
      " -0.33411425 -0.5442049  -2.0772622  -0.22373897 -0.6377865  -1.4655137\n",
      "  0.05476469 -0.6263805  -1.2459987   0.00360407 -0.5712447  -1.2999877\n",
      "  0.00219002 -0.6597017  -1.413767   -0.18125482 -0.5241825  -1.3964219\n",
      " -0.06105165 -0.5737306  -1.3939627  -0.06379698 -0.53962886 -1.5008007\n",
      "  0.05417895 -0.56198907 -1.5752044  -0.07360434 -0.45737398 -1.2215886\n",
      " -0.14400879 -0.22980958 -1.7272241  -0.01725886 -0.36438298 -1.7017257\n",
      "  0.11812644 -0.3337455  -1.4363018  -0.17099471 -0.21588235 -1.1763806\n",
      " -0.0680842  -0.19705112 -1.2551256  -0.01609603 -0.22569506 -1.377861\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.01620423 -0.23000765 -1.2940712   0.17      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0642, -0.1468, -0.2848,  ...,  0.0758, -0.3092, -1.3775],\n",
      "        [ 0.0642, -0.1468, -0.2848,  ...,  0.0758, -0.3092, -1.3775],\n",
      "        [ 0.0642, -0.1468, -0.2848,  ...,  0.0758, -0.3092, -1.3775],\n",
      "        ...,\n",
      "        [-0.1901,  0.4387, -0.2080,  ..., -0.7441,  0.9434, -0.4829],\n",
      "        [-0.2027, -0.0488,  0.6123,  ..., -0.3025,  0.7328,  0.2529],\n",
      "        [-0.2027, -0.0488,  0.6123,  ..., -0.3025,  0.7328,  0.2529]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.06416836 -0.14681393 -0.2848436   0.09127432 -0.29505175 -0.73736286\n",
      "  0.01738735 -0.4784925  -1.4887955  -0.12270817 -0.5379342  -1.7915292\n",
      " -0.28731698 -0.6572372  -2.2672317  -0.14705543 -0.7418604  -1.6585703\n",
      "  0.09903643 -0.76503634 -1.4423561   0.04919234 -0.70946527 -1.4918876\n",
      "  0.0363692  -0.8302052  -1.6126494  -0.10511819 -0.629302   -1.5702682\n",
      " -0.01137659 -0.6885148  -1.5466177  -0.016298   -0.6593617  -1.639828\n",
      "  0.10754271 -0.692413   -1.6987777  -0.00995976 -0.5412791  -1.3938017\n",
      " -0.12659587 -0.3097164  -2.0181835   0.03058949 -0.4703537  -2.0102777\n",
      "  0.17867847 -0.42991552 -1.5448072  -0.12137131 -0.30003905 -1.3246636\n",
      " -0.03117459 -0.27262348 -1.3920441   0.02078082 -0.2983066  -1.5099084\n",
      "  0.0758188  -0.30920547 -1.3774786 ]\n",
      "data: [ 0.06416836 -0.14681393 -0.2848436   0.09127432 -0.29505175 -0.7373628\n",
      "  0.01738735 -0.4784925  -1.4887955  -0.12270817 -0.5379342  -1.7915292\n",
      " -0.28731698 -0.6572372  -2.2672317  -0.14705543 -0.74186033 -1.6585703\n",
      "  0.09903643 -0.76503634 -1.4423561   0.04919234 -0.70946527 -1.4918876\n",
      "  0.0363692  -0.8302052  -1.6126494  -0.10511819 -0.629302   -1.5702682\n",
      " -0.01137659 -0.6885149  -1.5466177  -0.016298   -0.6593617  -1.6398281\n",
      "  0.10754271 -0.692413   -1.6987777  -0.00995976 -0.5412791  -1.3938017\n",
      " -0.12659587 -0.3097164  -2.0181835   0.03058949 -0.4703537  -2.0102777\n",
      "  0.17867847 -0.42991552 -1.5448071  -0.12137131 -0.30003905 -1.3246636\n",
      " -0.03117459 -0.27262348 -1.3920441   0.02078082 -0.2983066  -1.5099084\n",
      "  0.0758188  -0.30920547 -1.3774786   0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B320>\n",
      "tensor([[ 0.0074, -0.1640, -0.2135,  ...,  0.0549, -0.3425, -1.3143],\n",
      "        [ 0.0074, -0.1640, -0.2135,  ...,  0.0549, -0.3425, -1.3143],\n",
      "        [ 0.0074, -0.1640, -0.2135,  ...,  0.0549, -0.3425, -1.3143],\n",
      "        ...,\n",
      "        [-0.0643,  0.5208, -0.1636,  ..., -0.6733,  1.0123, -0.4360],\n",
      "        [-0.1427, -0.0194,  0.5736,  ..., -0.1851,  0.7073,  0.2552],\n",
      "        [-0.1427, -0.0194,  0.5736,  ..., -0.1851,  0.7073,  0.2552]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00735428 -0.16402072 -0.2135495   0.02024836 -0.33183777 -0.6705135\n",
      " -0.00380145 -0.4965831  -1.3726444  -0.14436716 -0.5525738  -1.7020805\n",
      " -0.3341369  -0.7082846  -2.1510863  -0.2185978  -0.74541354 -1.5682912\n",
      "  0.09527654 -0.7560682  -1.3349245   0.02991764 -0.7134906  -1.3787405\n",
      "  0.02863005 -0.8166816  -1.4965312  -0.159919   -0.61898875 -1.4733269\n",
      " -0.03655154 -0.69028354 -1.4616647  -0.03200354 -0.6726837  -1.5727983\n",
      "  0.07299506 -0.71318054 -1.6467178  -0.03631201 -0.5412426  -1.2802684\n",
      " -0.13809314 -0.32197282 -1.8548965   0.00865433 -0.48780444 -1.8230631\n",
      "  0.15189725 -0.44902244 -1.475992   -0.15593603 -0.2919721  -1.2242451\n",
      " -0.02730737 -0.2833207  -1.2926154   0.02984691 -0.3377968  -1.4077077\n",
      "  0.05489318 -0.34251636 -1.3142579 ]\n",
      "data: [ 0.00735428 -0.16402072 -0.2135495   0.02024836 -0.33183777 -0.6705135\n",
      " -0.00380145 -0.4965831  -1.3726443  -0.14436716 -0.5525738  -1.7020805\n",
      " -0.33413687 -0.7082846  -2.1510863  -0.2185978  -0.74541354 -1.5682912\n",
      "  0.09527655 -0.7560683  -1.3349245   0.02991764 -0.7134906  -1.3787405\n",
      "  0.02863005 -0.8166816  -1.4965312  -0.159919   -0.61898875 -1.4733269\n",
      " -0.03655154 -0.69028354 -1.4616647  -0.03200354 -0.6726837  -1.5727983\n",
      "  0.07299506 -0.71318054 -1.6467178  -0.03631201 -0.5412426  -1.2802684\n",
      " -0.13809314 -0.32197282 -1.8548965   0.00865433 -0.48780444 -1.8230633\n",
      "  0.15189725 -0.44902244 -1.475992   -0.15593603 -0.2919721  -1.2242451\n",
      " -0.02730737 -0.2833207  -1.2926154   0.02984691 -0.3377968  -1.4077077\n",
      "  0.05489318 -0.34251636 -1.3142579   0.19      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63F28>\n",
      "tensor([[ 0.0091, -0.1527, -0.1946,  ...,  0.0351, -0.3425, -1.2168],\n",
      "        [ 0.0091, -0.1527, -0.1946,  ...,  0.0351, -0.3425, -1.2168],\n",
      "        [ 0.0091, -0.1527, -0.1946,  ...,  0.0351, -0.3425, -1.2168],\n",
      "        ...,\n",
      "        [-0.0696,  0.5315, -0.2011,  ..., -0.5020,  1.0436, -0.5612],\n",
      "        [-0.1828, -0.0412,  0.6403,  ..., -0.2532,  0.6519,  0.3182],\n",
      "        [-0.1828, -0.0412,  0.6403,  ..., -0.2532,  0.6519,  0.3182]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00911995 -0.15265527 -0.19460428  0.04620134 -0.2589829  -0.4942161\n",
      " -0.08183834 -0.4938789  -1.3516958  -0.2366756  -0.55946666 -1.6452239\n",
      " -0.38301307 -0.65735066 -2.1606715  -0.18772797 -0.7862226  -1.554711\n",
      "  0.00710195 -0.8584204  -1.4066525  -0.05062753 -0.78851783 -1.4474618\n",
      " -0.06375277 -0.95524824 -1.5689924  -0.13744152 -0.696272   -1.4473598\n",
      " -0.07556804 -0.75743365 -1.4219145  -0.08227291 -0.7238511  -1.5034374\n",
      "  0.04056521 -0.76916516 -1.5247978  -0.04537239 -0.58067584 -1.2860215\n",
      " -0.21247019 -0.34233636 -2.0511494  -0.02126995 -0.530928   -2.070496\n",
      "  0.14108916 -0.48149422 -1.392725   -0.17953865 -0.34996146 -1.205181\n",
      " -0.09655085 -0.31890988 -1.2884816  -0.05979422 -0.335254   -1.3980908\n",
      "  0.03514617 -0.3424698  -1.2168479 ]\n",
      "data: [ 0.00911995 -0.15265527 -0.19460428  0.04620134 -0.2589829  -0.4942161\n",
      " -0.08183834 -0.4938789  -1.3516957  -0.2366756  -0.55946666 -1.6452239\n",
      " -0.38301307 -0.6573507  -2.1606715  -0.18772797 -0.78622264 -1.554711\n",
      "  0.00710195 -0.85842043 -1.4066526  -0.05062753 -0.78851783 -1.4474618\n",
      " -0.06375277 -0.95524824 -1.5689923  -0.13744152 -0.6962721  -1.4473598\n",
      " -0.07556804 -0.75743365 -1.4219146  -0.08227291 -0.7238511  -1.5034374\n",
      "  0.04056521 -0.7691652  -1.5247978  -0.04537239 -0.58067584 -1.2860215\n",
      " -0.21247019 -0.34233636 -2.0511494  -0.02126995 -0.530928   -2.070496\n",
      "  0.14108916 -0.48149422 -1.3927249  -0.17953865 -0.34996146 -1.205181\n",
      " -0.09655085 -0.31890988 -1.2884816  -0.05979422 -0.335254   -1.3980908\n",
      "  0.03514617 -0.3424698  -1.2168479   0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[2.988 3.004 3.023 ... 0.    0.    0.   ]\n",
      " [2.989 3.005 3.025 ... 0.    0.    0.   ]\n",
      " [2.99  3.005 3.024 ... 0.    0.    0.   ]\n",
      " ...\n",
      " [2.697 2.694 2.693 ... 2.514 2.53  0.   ]\n",
      " [2.688 2.684 2.685 ... 2.501 2.526 0.   ]\n",
      " [2.672 2.675 2.679 ... 2.496 2.537 2.648]]\n",
      "imask:  [[0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " [0. 0. 0. ... 1. 1. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[-0.0320, -0.0462, -0.1655,  ...,  0.0282, -0.2286, -1.1556],\n",
      "        [-0.0320, -0.0462, -0.1655,  ...,  0.0282, -0.2286, -1.1556],\n",
      "        [-0.0320, -0.0462, -0.1655,  ...,  0.0282, -0.2286, -1.1556],\n",
      "        ...,\n",
      "        [-0.1615,  0.3749, -0.0236,  ..., -0.6656,  0.9769, -0.4341],\n",
      "        [-0.0846, -0.0464,  0.6165,  ..., -0.2230,  0.5829,  0.3009],\n",
      "        [-0.0846, -0.0464,  0.6165,  ..., -0.2230,  0.5829,  0.3009]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.03195643 -0.04616985 -0.16553353 -0.00548091 -0.17830686 -0.4614609\n",
      " -0.09514644 -0.3881455  -1.2892185  -0.2458411  -0.44586146 -1.6016953\n",
      " -0.4198748  -0.57749254 -2.0865743  -0.25223494 -0.6599276  -1.4932947\n",
      "  0.02622269 -0.69749695 -1.2794704  -0.0310818  -0.646985   -1.3151624\n",
      " -0.02310181 -0.77594507 -1.4458158  -0.19407053 -0.5453484  -1.3839324\n",
      " -0.08833589 -0.6134152  -1.365938   -0.06423844 -0.58178353 -1.4625653\n",
      "  0.07515085 -0.6357409  -1.5161486  -0.07562169 -0.44411254 -1.1961092\n",
      " -0.22688557 -0.2086216  -1.9229709  -0.02241375 -0.39702415 -1.9176915\n",
      "  0.16285397 -0.34739614 -1.3461851  -0.21655343 -0.19781044 -1.1239699\n",
      " -0.09551556 -0.17932959 -1.1878587  -0.0440678  -0.21788917 -1.3047996\n",
      "  0.02817776 -0.2286346  -1.1556356 ]\n",
      "data: [-3.16 -2.93  2.66 -3.11 -2.72  2.77 -2.95 -2.38  2.85  0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.   -2.34 -1.12 -0.85 -2.4  -1.02 -1.03\n",
      " -2.37 -0.99 -1.03 -2.47 -1.34 -1.13 -2.43 -1.12 -0.98 -2.41 -0.96 -1.18\n",
      " -2.41 -0.96 -1.18  0.    0.    0.   -2.47 -1.2  -1.37 -2.54 -1.02 -1.35\n",
      " -2.54 -0.99 -1.33  0.    0.    0.    0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.  ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 8.8766e-03,  7.7521e-04, -2.3262e-01,  ..., -3.0538e-01,\n",
      "         -3.4998e-01, -5.1276e-01],\n",
      "        [ 8.8766e-03,  7.7521e-04, -2.3262e-01,  ..., -3.0538e-01,\n",
      "         -3.4998e-01, -5.1276e-01],\n",
      "        [ 8.8766e-03,  7.7521e-04, -2.3262e-01,  ..., -3.0538e-01,\n",
      "         -3.4998e-01, -5.1276e-01],\n",
      "        ...,\n",
      "        [ 5.1506e-01, -4.6867e-01,  1.1016e+00,  ...,  3.6564e-01,\n",
      "          4.9817e-01, -9.1111e-01],\n",
      "        [ 5.9471e-02, -6.3189e-02,  3.3095e-01,  ..., -1.3849e+00,\n",
      "          6.3809e-01,  5.9951e-01],\n",
      "        [ 5.9471e-02, -6.3189e-02,  3.3095e-01,  ..., -1.3849e+00,\n",
      "          6.3809e-01,  5.9951e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 8.8765966e-03  7.7521172e-04 -2.3261684e-01 -9.0008870e-02\n",
      " -3.5260800e-02 -6.7060184e-01 -1.9911118e-01 -9.0095580e-02\n",
      " -7.6295483e-01 -2.9467058e-01 -1.4779471e-01 -7.5236523e-01\n",
      " -3.7677985e-01 -1.6892728e-01 -8.1193662e-01 -2.1125537e-01\n",
      " -2.5987664e-01 -8.5720074e-01 -2.9001796e-01 -3.1656870e-01\n",
      " -7.8852761e-01 -3.2256591e-01 -4.0920687e-01 -7.6753235e-01\n",
      " -3.7342548e-01 -4.4756553e-01 -7.7898383e-01 -2.1634714e-01\n",
      " -2.6326215e-01 -8.4559286e-01 -3.1559068e-01 -3.5860035e-01\n",
      " -8.0662584e-01 -3.3433944e-01 -3.9453217e-01 -7.6993024e-01\n",
      " -3.1774259e-01 -5.0905466e-01 -7.3932731e-01 -2.3580471e-01\n",
      " -2.3593092e-01 -8.0604839e-01 -3.4425545e-01 -3.0589899e-01\n",
      " -7.0810783e-01 -3.2735094e-01 -3.8163996e-01 -7.1091843e-01\n",
      " -3.2069468e-01 -4.3256408e-01 -6.4201987e-01 -2.5176859e-01\n",
      " -1.9215618e-01 -6.7616713e-01 -3.1743598e-01 -2.4791208e-01\n",
      " -5.9753096e-01 -3.3176816e-01 -2.8917691e-01 -6.0351539e-01\n",
      " -3.0537799e-01 -3.4998184e-01 -5.1275754e-01]\n",
      "init: [ 8.8765966e-03  7.7521172e-04 -2.3261684e-01 -9.0008870e-02\n",
      " -3.5260800e-02 -6.7060184e-01 -1.9911118e-01 -9.0095580e-02\n",
      " -7.6295483e-01 -2.9467058e-01 -1.4779471e-01 -7.5236523e-01\n",
      " -3.7677985e-01 -1.6892728e-01 -8.1193662e-01 -2.1125537e-01\n",
      " -2.5987664e-01 -8.5720074e-01 -2.9001796e-01 -3.1656870e-01\n",
      " -7.8852761e-01 -3.2256591e-01 -4.0920687e-01 -7.6753235e-01\n",
      " -3.7342548e-01 -4.4756553e-01 -7.7898383e-01 -2.1634714e-01\n",
      " -2.6326215e-01 -8.4559286e-01 -3.1559068e-01 -3.5860035e-01\n",
      " -8.0662584e-01 -3.3433944e-01 -3.9453217e-01 -7.6993024e-01\n",
      " -3.1774259e-01 -5.0905466e-01 -7.3932731e-01 -2.3580471e-01\n",
      " -2.3593092e-01 -8.0604839e-01 -3.4425545e-01 -3.0589899e-01\n",
      " -7.0810783e-01 -3.2735094e-01 -3.8163996e-01 -7.1091843e-01\n",
      " -3.2069468e-01 -4.3256408e-01 -6.4201987e-01 -2.5176859e-01\n",
      " -1.9215618e-01 -6.7616713e-01 -3.1743598e-01 -2.4791208e-01\n",
      " -5.9753096e-01 -3.3176816e-01 -2.8917691e-01 -6.0351539e-01\n",
      " -3.0537799e-01 -3.4998184e-01 -5.1275754e-01]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [ 8.8765966e-03  7.7521172e-04 -2.3261684e-01 -9.0008870e-02\n",
      " -3.5260800e-02 -6.7060179e-01 -1.9911118e-01 -9.0095580e-02\n",
      " -7.6295489e-01 -2.9467058e-01 -1.4779471e-01 -7.5236529e-01\n",
      " -3.7677985e-01 -1.6892728e-01 -8.1193662e-01 -2.1125537e-01\n",
      " -2.5987664e-01 -8.5720080e-01 -2.9001796e-01 -3.1656870e-01\n",
      " -7.8852761e-01 -3.2256591e-01 -4.0920684e-01 -7.6753235e-01\n",
      " -3.7342548e-01 -4.4756553e-01 -7.7898383e-01 -2.1634714e-01\n",
      " -2.6326215e-01 -8.4559286e-01 -3.1559068e-01 -3.5860035e-01\n",
      " -8.0662584e-01 -3.3433944e-01 -3.9453217e-01 -7.6993024e-01\n",
      " -3.1774259e-01 -5.0905466e-01 -7.3932731e-01 -2.3580471e-01\n",
      " -2.3593092e-01 -8.0604845e-01 -3.4425545e-01 -3.0589899e-01\n",
      " -7.0810783e-01 -3.2735097e-01 -3.8163993e-01 -7.1091843e-01\n",
      " -3.2069468e-01 -4.3256408e-01 -6.4201987e-01 -2.5176859e-01\n",
      " -1.9215618e-01 -6.7616713e-01 -3.1743598e-01 -2.4791208e-01\n",
      " -5.9753096e-01 -3.3176816e-01 -2.8917691e-01 -6.0351539e-01\n",
      " -3.0537799e-01 -3.4998184e-01 -5.1275754e-01  9.9999998e-03]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BB38>\n",
      "tensor([[ 0.2565, -0.1653,  0.0619,  ...,  0.3460, -0.3228, -0.9771],\n",
      "        [ 0.2565, -0.1653,  0.0619,  ...,  0.3460, -0.3228, -0.9771],\n",
      "        [ 0.2565, -0.1653,  0.0619,  ...,  0.3460, -0.3228, -0.9771],\n",
      "        ...,\n",
      "        [-0.2043, -0.0798, -0.1112,  ..., -1.2513,  0.7190, -0.4925],\n",
      "        [-0.4337,  0.3037, -0.0345,  ..., -0.9720,  1.0205, -0.2868],\n",
      "        [-0.4337,  0.3037, -0.0345,  ..., -0.9720,  1.0205, -0.2868]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.25653934 -0.16527198  0.06187012  0.28650266 -0.31047314 -0.33754987\n",
      "  0.23528197 -0.46471494 -1.053416    0.09572317 -0.5028829  -1.3683327\n",
      " -0.06291848 -0.64231503 -1.8531039   0.03117532 -0.726853   -1.2478509\n",
      "  0.33241624 -0.71730125 -1.0593773   0.2803405  -0.6629752  -1.0964617\n",
      "  0.2854924  -0.7714131  -1.2177808   0.09075134 -0.6089933  -1.1583282\n",
      "  0.22459769 -0.66388535 -1.1534357   0.24657148 -0.6233009  -1.2400773\n",
      "  0.3710913  -0.6864811  -1.3209887   0.2284773  -0.5289115  -0.97290796\n",
      "  0.11266309 -0.27025694 -1.5996144   0.3003994  -0.459152   -1.5728395\n",
      "  0.44843358 -0.39967397 -1.1645628   0.10238601 -0.28966057 -0.9093513\n",
      "  0.24283816 -0.25737637 -0.9548083   0.30494884 -0.3049412  -1.0884054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.34596658 -0.32275409 -0.9770704 ]\n",
      "data: [ 0.25653934 -0.16527198  0.06187012  0.28650266 -0.31047314 -0.33754987\n",
      "  0.23528199 -0.4647149  -1.053416    0.09572317 -0.5028829  -1.3683326\n",
      " -0.06291848 -0.6423151  -1.853104    0.03117532 -0.726853   -1.2478509\n",
      "  0.33241624 -0.71730125 -1.0593773   0.2803405  -0.66297513 -1.0964617\n",
      "  0.2854924  -0.7714131  -1.2177808   0.09075134 -0.6089933  -1.1583282\n",
      "  0.2245977  -0.66388535 -1.1534357   0.24657148 -0.6233009  -1.2400773\n",
      "  0.3710913  -0.6864811  -1.3209887   0.2284773  -0.5289115  -0.97290796\n",
      "  0.11266309 -0.27025694 -1.5996144   0.3003994  -0.45915204 -1.5728395\n",
      "  0.44843358 -0.39967397 -1.1645628   0.10238602 -0.28966057 -0.9093513\n",
      "  0.24283816 -0.25737637 -0.9548083   0.30494884 -0.3049412  -1.0884054\n",
      "  0.34596658 -0.32275409 -0.9770704   0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0858, -0.0379, -0.1032,  ..., -0.0047, -0.2544, -1.2068],\n",
      "        [ 0.0858, -0.0379, -0.1032,  ..., -0.0047, -0.2544, -1.2068],\n",
      "        [ 0.0858, -0.0379, -0.1032,  ..., -0.0047, -0.2544, -1.2068],\n",
      "        ...,\n",
      "        [-0.3288,  0.2455, -0.0844,  ..., -0.8282,  0.8416, -0.6565],\n",
      "        [-0.1093,  0.0893,  0.3410,  ...,  0.3546,  0.8067,  0.0037],\n",
      "        [-0.1093,  0.0893,  0.3410,  ...,  0.3546,  0.8067,  0.0037]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.08579506 -0.0379421  -0.1032365   0.02253027 -0.22140418 -0.61245143\n",
      " -0.07017726 -0.41160282 -1.3064108  -0.23742421 -0.4898873  -1.6096717\n",
      " -0.4944898  -0.601745   -2.0641756  -0.18030061 -0.6453427  -1.5076917\n",
      " -0.08497573 -0.71022236 -1.403039   -0.12487441 -0.624002   -1.4606444\n",
      " -0.06842096 -0.79532075 -1.526402   -0.14321701 -0.5114523  -1.4217496\n",
      " -0.10977936 -0.5732943  -1.3357794  -0.14579345 -0.61462283 -1.453882\n",
      " -0.011227   -0.5606911  -1.4829737  -0.08263461 -0.4637096  -1.2776452\n",
      " -0.17403881 -0.29198587 -1.785383   -0.08775978 -0.42329374 -1.775744\n",
      "  0.05542279 -0.4111142  -1.3202158  -0.14013897 -0.22652973 -1.2139158\n",
      " -0.13122518 -0.24074309 -1.2728609  -0.08975354 -0.24573481 -1.3690485\n",
      " -0.00474979 -0.25439793 -1.2068065 ]\n",
      "data: [ 0.08579506 -0.0379421  -0.1032365   0.02253027 -0.22140417 -0.61245143\n",
      " -0.07017726 -0.41160282 -1.3064108  -0.2374242  -0.48988733 -1.6096718\n",
      " -0.4944898  -0.601745   -2.0641756  -0.18030062 -0.6453427  -1.5076919\n",
      " -0.08497574 -0.7102224  -1.403039   -0.12487441 -0.624002   -1.4606444\n",
      " -0.06842096 -0.79532075 -1.526402   -0.14321701 -0.5114523  -1.4217496\n",
      " -0.10977936 -0.5732943  -1.3357794  -0.14579345 -0.61462283 -1.453882\n",
      " -0.011227   -0.5606911  -1.4829736  -0.08263461 -0.4637096  -1.2776452\n",
      " -0.17403881 -0.29198587 -1.785383   -0.08775978 -0.4232937  -1.775744\n",
      "  0.05542279 -0.4111142  -1.3202157  -0.14013897 -0.22652973 -1.2139158\n",
      " -0.13122518 -0.24074309 -1.2728609  -0.08975354 -0.24573481 -1.3690485\n",
      " -0.00474979 -0.25439793 -1.2068065   0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0518, -0.0347, -0.2597,  ...,  0.0969, -0.2282, -1.3006],\n",
      "        [ 0.0518, -0.0347, -0.2597,  ...,  0.0969, -0.2282, -1.3006],\n",
      "        [ 0.0518, -0.0347, -0.2597,  ...,  0.0969, -0.2282, -1.3006],\n",
      "        ...,\n",
      "        [-0.2225,  0.3641, -0.0336,  ..., -0.9048,  0.8922, -0.2522],\n",
      "        [-0.1117, -0.1334,  0.5945,  ..., -0.2216,  0.6309,  0.3238],\n",
      "        [-0.1117, -0.1334,  0.5945,  ..., -0.2216,  0.6309,  0.3238]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0517824  -0.03472922 -0.25971124  0.0681355  -0.16965756 -0.6638105\n",
      " -0.03307278 -0.34102085 -1.4007678  -0.17917459 -0.40053084 -1.6898875\n",
      " -0.3462881  -0.5074003  -2.1687233  -0.14591628 -0.6400659  -1.5621727\n",
      "  0.04537889 -0.66618    -1.4019201   0.00408043 -0.59203553 -1.4619579\n",
      "  0.02245484 -0.7269622  -1.5743434  -0.10501273 -0.5409882  -1.4862742\n",
      " -0.02098165 -0.588884   -1.4559152  -0.029376   -0.56238806 -1.5495522\n",
      "  0.12112708 -0.5748155  -1.5904188  -0.01998592 -0.46438614 -1.3164742\n",
      " -0.11711022 -0.23264915 -1.9317942   0.033484   -0.3797005  -1.9341836\n",
      "  0.20495218 -0.35373524 -1.4526155  -0.11419681 -0.22992721 -1.2543633\n",
      " -0.04306123 -0.20703566 -1.3368251   0.00421278 -0.211473   -1.4565957\n",
      "  0.09688578 -0.22815453 -1.30057   ]\n",
      "data: [ 0.0517824  -0.03472922 -0.25971124  0.0681355  -0.16965756 -0.6638105\n",
      " -0.03307278 -0.34102085 -1.4007678  -0.1791746  -0.40053084 -1.6898875\n",
      " -0.3462881  -0.5074003  -2.1687233  -0.14591628 -0.6400659  -1.5621727\n",
      "  0.04537889 -0.66618    -1.40192     0.00408043 -0.59203553 -1.461958\n",
      "  0.02245484 -0.7269622  -1.5743434  -0.10501273 -0.5409882  -1.4862742\n",
      " -0.02098165 -0.588884   -1.4559152  -0.029376   -0.56238806 -1.5495522\n",
      "  0.12112708 -0.5748155  -1.5904188  -0.01998592 -0.46438614 -1.3164742\n",
      " -0.11711022 -0.23264915 -1.9317942   0.033484   -0.3797005  -1.9341836\n",
      "  0.20495218 -0.35373524 -1.4526155  -0.11419681 -0.22992721 -1.2543633\n",
      " -0.04306123 -0.20703566 -1.3368251   0.00421278 -0.211473   -1.4565957\n",
      "  0.09688578 -0.22815453 -1.30057     0.04      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0052, -0.1234, -0.2770,  ...,  0.0478, -0.2990, -1.3706],\n",
      "        [ 0.0052, -0.1234, -0.2770,  ...,  0.0478, -0.2990, -1.3706],\n",
      "        [ 0.0052, -0.1234, -0.2770,  ...,  0.0478, -0.2990, -1.3706],\n",
      "        ...,\n",
      "        [-0.1338,  0.4304, -0.0416,  ..., -0.7269,  0.9185, -0.2566],\n",
      "        [-0.1942, -0.0689,  0.5782,  ..., -0.2751,  0.7127,  0.2486],\n",
      "        [-0.1942, -0.0689,  0.5782,  ..., -0.2751,  0.7127,  0.2486]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 5.2226596e-03 -1.2336556e-01 -2.7701223e-01  2.3266774e-02\n",
      " -2.8366584e-01 -7.2994715e-01 -2.2571579e-02 -4.4067159e-01\n",
      " -1.4347417e+00 -1.6054907e-01 -4.9550840e-01 -1.7436517e+00\n",
      " -3.3475685e-01 -6.3250101e-01 -2.2059233e+00 -2.0769742e-01\n",
      " -7.0679826e-01 -1.6084456e+00  6.7041606e-02 -7.1222383e-01\n",
      " -1.3911881e+00  1.3133481e-02 -6.5720153e-01 -1.4423772e+00\n",
      "  1.6149834e-02 -7.5815743e-01 -1.5578367e+00 -1.5990102e-01\n",
      " -5.8975106e-01 -1.5281191e+00 -4.5289598e-02 -6.4640552e-01\n",
      " -1.5131313e+00 -4.6079606e-02 -6.1962521e-01 -1.6143306e+00\n",
      "  7.2571233e-02 -6.4591026e-01 -1.6808692e+00 -5.1306196e-02\n",
      " -5.1691782e-01 -1.3459438e+00 -1.3848725e-01 -2.9052988e-01\n",
      " -1.8985372e+00  3.9944798e-04 -4.3995509e-01 -1.8755912e+00\n",
      "  1.4631200e-01 -4.0470213e-01 -1.5287153e+00 -1.5658112e-01\n",
      " -2.7348310e-01 -1.2916934e+00 -4.8708677e-02 -2.5655031e-01\n",
      " -1.3632152e+00  6.2177777e-03 -2.9062167e-01 -1.4800853e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4.7794603e-02 -2.9896283e-01 -1.3705552e+00]\n",
      "data: [ 5.2226596e-03 -1.2336555e-01 -2.7701223e-01  2.3266774e-02\n",
      " -2.8366584e-01 -7.2994715e-01 -2.2571579e-02 -4.4067156e-01\n",
      " -1.4347416e+00 -1.6054907e-01 -4.9550837e-01 -1.7436517e+00\n",
      " -3.3475685e-01 -6.3250101e-01 -2.2059233e+00 -2.0769744e-01\n",
      " -7.0679826e-01 -1.6084456e+00  6.7041606e-02 -7.1222383e-01\n",
      " -1.3911881e+00  1.3133480e-02 -6.5720153e-01 -1.4423772e+00\n",
      "  1.6149834e-02 -7.5815743e-01 -1.5578367e+00 -1.5990102e-01\n",
      " -5.8975106e-01 -1.5281191e+00 -4.5289598e-02 -6.4640546e-01\n",
      " -1.5131313e+00 -4.6079606e-02 -6.1962521e-01 -1.6143306e+00\n",
      "  7.2571233e-02 -6.4591026e-01 -1.6808693e+00 -5.1306196e-02\n",
      " -5.1691782e-01 -1.3459438e+00 -1.3848725e-01 -2.9052988e-01\n",
      " -1.8985372e+00  3.9944798e-04 -4.3995512e-01 -1.8755912e+00\n",
      "  1.4631200e-01 -4.0470210e-01 -1.5287153e+00 -1.5658112e-01\n",
      " -2.7348310e-01 -1.2916934e+00 -4.8708677e-02 -2.5655031e-01\n",
      " -1.3632152e+00  6.2177777e-03 -2.9062167e-01 -1.4800853e+00\n",
      "  4.7794603e-02 -2.9896283e-01 -1.3705552e+00  5.0000001e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0433, -0.2041, -0.2625,  ...,  0.0676, -0.3788, -1.3515],\n",
      "        [ 0.0433, -0.2041, -0.2625,  ...,  0.0676, -0.3788, -1.3515],\n",
      "        [ 0.0433, -0.2041, -0.2625,  ...,  0.0676, -0.3788, -1.3515],\n",
      "        ...,\n",
      "        [-0.1157,  0.5064, -0.1786,  ..., -0.6651,  0.9915, -0.4793],\n",
      "        [-0.1999, -0.0512,  0.6390,  ..., -0.2682,  0.6716,  0.3377],\n",
      "        [-0.1999, -0.0512,  0.6390,  ..., -0.2682,  0.6716,  0.3377]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04329524 -0.20413402 -0.26245952  0.07103048 -0.3417235  -0.65823394\n",
      "  0.00380342 -0.53469515 -1.43301    -0.14162475 -0.5929396  -1.7503157\n",
      " -0.3085353  -0.71895933 -2.2363605  -0.16851342 -0.8063271  -1.6350511\n",
      "  0.09764639 -0.8413929  -1.4260145   0.03432182 -0.7906076  -1.4703777\n",
      "  0.01951165 -0.9212488  -1.5948771  -0.11573466 -0.69711447 -1.534194\n",
      " -0.02146324 -0.7621429  -1.5213295  -0.02417239 -0.73686445 -1.623239\n",
      "  0.08553038 -0.78239036 -1.6768271  -0.01026887 -0.5992169  -1.3541965\n",
      " -0.14507529 -0.36993143 -2.0294406   0.02258748 -0.54452527 -2.0237203\n",
      "  0.17015085 -0.50222266 -1.5204716  -0.137065   -0.35838526 -1.2864399\n",
      " -0.03107586 -0.3376043  -1.3619076   0.01466004 -0.37310705 -1.4774283\n",
      "  0.06764819 -0.3788001  -1.3515046 ]\n",
      "data: [ 0.04329524 -0.20413403 -0.26245952  0.07103048 -0.34172353 -0.65823394\n",
      "  0.00380342 -0.53469515 -1.43301    -0.14162475 -0.5929396  -1.7503157\n",
      " -0.3085353  -0.71895933 -2.2363605  -0.16851342 -0.8063271  -1.6350511\n",
      "  0.09764639 -0.8413929  -1.4260145   0.03432182 -0.79060763 -1.4703777\n",
      "  0.01951165 -0.9212488  -1.5948771  -0.11573467 -0.69711447 -1.534194\n",
      " -0.02146324 -0.7621429  -1.5213295  -0.02417239 -0.73686445 -1.623239\n",
      "  0.08553038 -0.78239036 -1.6768271  -0.01026887 -0.5992169  -1.3541964\n",
      " -0.14507529 -0.3699314  -2.0294406   0.02258748 -0.54452527 -2.0237203\n",
      "  0.17015085 -0.50222266 -1.5204715  -0.137065   -0.35838526 -1.2864398\n",
      " -0.03107586 -0.33760434 -1.3619076   0.01466004 -0.37310705 -1.4774283\n",
      "  0.06764819 -0.3788001  -1.3515046   0.06      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0054, -0.1985, -0.1939,  ...,  0.0404, -0.3788, -1.2585],\n",
      "        [ 0.0054, -0.1985, -0.1939,  ...,  0.0404, -0.3788, -1.2585],\n",
      "        [ 0.0054, -0.1985, -0.1939,  ...,  0.0404, -0.3788, -1.2585],\n",
      "        ...,\n",
      "        [ 0.0202,  0.5715, -0.1782,  ..., -0.4463,  1.1368, -0.5949],\n",
      "        [-0.1106,  0.0464,  0.6118,  ..., -0.1301,  0.7031,  0.2968],\n",
      "        [-0.1106,  0.0464,  0.6118,  ..., -0.1301,  0.7031,  0.2968]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00543465 -0.19846447 -0.1938572   0.03333358 -0.33578634 -0.5502198\n",
      " -0.03337895 -0.53841454 -1.3533912  -0.18620448 -0.59737694 -1.6824579\n",
      " -0.36540234 -0.7326577  -2.173997   -0.21519852 -0.8046272  -1.5740511\n",
      "  0.072368   -0.84345555 -1.3558116   0.00452331 -0.7952374  -1.3950486\n",
      " -0.00891861 -0.92805004 -1.5228865  -0.15623489 -0.6913254  -1.4614627\n",
      " -0.05452806 -0.76359165 -1.4472442  -0.05066656 -0.73878133 -1.5544212\n",
      "  0.06152321 -0.79111266 -1.609205   -0.03892808 -0.58986324 -1.271714\n",
      " -0.18587214 -0.36016718 -1.9717777  -0.00586314 -0.54685044 -1.9622333\n",
      "  0.15205386 -0.50046504 -1.437259   -0.17801651 -0.34538233 -1.2030077\n",
      " -0.05903332 -0.329181   -1.2710631  -0.01186089 -0.37502062 -1.3858705\n",
      "  0.04042812 -0.37876135 -1.2585213 ]\n",
      "data: [ 0.00543465 -0.19846447 -0.1938572   0.03333358 -0.33578637 -0.5502198\n",
      " -0.03337895 -0.53841454 -1.3533912  -0.18620448 -0.59737694 -1.6824579\n",
      " -0.36540234 -0.7326577  -2.173997   -0.21519852 -0.8046272  -1.5740513\n",
      "  0.072368   -0.84345555 -1.3558116   0.00452331 -0.7952374  -1.3950486\n",
      " -0.00891861 -0.9280501  -1.5228865  -0.15623489 -0.6913254  -1.4614627\n",
      " -0.05452805 -0.7635916  -1.4472442  -0.05066656 -0.73878133 -1.5544212\n",
      "  0.06152321 -0.79111266 -1.609205   -0.03892808 -0.58986324 -1.271714\n",
      " -0.18587214 -0.36016715 -1.9717777  -0.00586314 -0.54685044 -1.9622333\n",
      "  0.15205386 -0.50046504 -1.437259   -0.17801651 -0.34538233 -1.2030077\n",
      " -0.05903332 -0.329181   -1.2710631  -0.01186089 -0.37502062 -1.3858705\n",
      "  0.04042812 -0.37876138 -1.2585213   0.07      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0478, -0.1555, -0.1780,  ...,  0.0383, -0.3342, -1.2024],\n",
      "        [ 0.0478, -0.1555, -0.1780,  ...,  0.0383, -0.3342, -1.2024],\n",
      "        [ 0.0478, -0.1555, -0.1780,  ...,  0.0383, -0.3342, -1.2024],\n",
      "        ...,\n",
      "        [-0.0826,  0.5301, -0.0904,  ..., -0.2568,  1.1351, -0.5496],\n",
      "        [-0.1291,  0.0340,  0.6380,  ..., -0.1836,  0.6904,  0.3219],\n",
      "        [-0.1291,  0.0340,  0.6380,  ..., -0.1836,  0.6904,  0.3219]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04781825 -0.15545261 -0.17802133  0.08191451 -0.2548343  -0.45621318\n",
      " -0.05794116 -0.496289   -1.3388393  -0.22046    -0.5617608  -1.6356962\n",
      " -0.36602318 -0.65115    -2.1740131  -0.15690072 -0.79809177 -1.5441828\n",
      "  0.02460244 -0.8720472  -1.3965042  -0.03508194 -0.79824317 -1.4408033\n",
      " -0.05332944 -0.9676118  -1.5690668  -0.11260685 -0.7107934  -1.4333568\n",
      " -0.06029251 -0.76436245 -1.4085374  -0.07038117 -0.72355425 -1.4931633\n",
      "  0.05544688 -0.765241   -1.5070021  -0.02381397 -0.585212   -1.2762544\n",
      " -0.19953614 -0.34526387 -2.0436082  -0.01033825 -0.52663255 -2.071302\n",
      "  0.1573712  -0.47782192 -1.3783937  -0.16288245 -0.35556772 -1.1939559\n",
      " -0.08819717 -0.3216725  -1.2777927  -0.06320298 -0.3297057  -1.3870676\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.03829669 -0.3341728  -1.2023733 ]\n",
      "data: [ 0.04781825 -0.15545261 -0.17802134  0.08191451 -0.2548343  -0.45621318\n",
      " -0.05794116 -0.496289   -1.3388393  -0.22046    -0.5617608  -1.635696\n",
      " -0.36602318 -0.65115    -2.1740131  -0.15690072 -0.7980917  -1.5441828\n",
      "  0.02460244 -0.8720472  -1.3965042  -0.03508194 -0.79824317 -1.4408032\n",
      " -0.05332944 -0.9676118  -1.5690668  -0.11260685 -0.7107934  -1.4333568\n",
      " -0.06029251 -0.7643625  -1.4085374  -0.07038117 -0.72355425 -1.4931633\n",
      "  0.05544688 -0.765241   -1.5070021  -0.02381397 -0.585212   -1.2762544\n",
      " -0.19953614 -0.34526387 -2.0436082  -0.01033825 -0.52663255 -2.071302\n",
      "  0.1573712  -0.47782192 -1.3783937  -0.16288245 -0.35556775 -1.1939559\n",
      " -0.08819717 -0.32167253 -1.2777927  -0.06320298 -0.3297057  -1.3870676\n",
      "  0.03829669 -0.3341728  -1.2023733   0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B9B0>\n",
      "tensor([[-0.0224, -0.0785, -0.2056,  ...,  0.0359, -0.2609, -1.1964],\n",
      "        [-0.0224, -0.0785, -0.2056,  ...,  0.0359, -0.2609, -1.1964],\n",
      "        [-0.0224, -0.0785, -0.2056,  ...,  0.0359, -0.2609, -1.1964],\n",
      "        ...,\n",
      "        [-0.1489,  0.3956,  0.0445,  ..., -0.5832,  1.0048, -0.4153],\n",
      "        [-0.0818, -0.0158,  0.6127,  ..., -0.2063,  0.6407,  0.2541],\n",
      "        [-0.0818, -0.0158,  0.6127,  ..., -0.2063,  0.6407,  0.2541]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.02240093 -0.07845861 -0.20556557  0.0040775  -0.20517334 -0.51009905\n",
      " -0.09383052 -0.41861352 -1.337134   -0.24742793 -0.47813356 -1.6503026\n",
      " -0.4168078  -0.6049646  -2.1409616  -0.24022976 -0.69776046 -1.531985\n",
      "  0.02420233 -0.74021804 -1.3208232  -0.0354341  -0.6835954  -1.3612257\n",
      " -0.03611077 -0.82082653 -1.4940212  -0.18322252 -0.58990467 -1.4218538\n",
      " -0.08608832 -0.6546953  -1.4042122  -0.07057127 -0.6196805  -1.4997841\n",
      "  0.06721278 -0.6709335  -1.5448834  -0.0671292  -0.48371908 -1.2371918\n",
      " -0.21889366 -0.24640906 -1.9653771  -0.01976117 -0.43181047 -1.9655777\n",
      "  0.16510531 -0.38377658 -1.3825457  -0.20570382 -0.24086425 -1.1633123\n",
      " -0.09068494 -0.21903622 -1.2356626  -0.04416263 -0.2517159  -1.3521781\n",
      "  0.03590789 -0.26093072 -1.1964047 ]\n",
      "data: [-0.02240093 -0.07845861 -0.20556557  0.0040775  -0.20517334 -0.51009905\n",
      " -0.09383052 -0.41861352 -1.3371339  -0.24742793 -0.47813356 -1.6503025\n",
      " -0.41680777 -0.6049646  -2.1409616  -0.24022976 -0.69776046 -1.531985\n",
      "  0.02420233 -0.74021804 -1.3208232  -0.0354341  -0.6835954  -1.3612257\n",
      " -0.03611077 -0.8208266  -1.4940212  -0.18322252 -0.58990467 -1.4218538\n",
      " -0.08608832 -0.6546953  -1.4042122  -0.07057127 -0.6196805  -1.4997841\n",
      "  0.06721278 -0.6709335  -1.5448834  -0.0671292  -0.48371905 -1.2371918\n",
      " -0.21889366 -0.24640906 -1.9653771  -0.01976117 -0.43181047 -1.9655777\n",
      "  0.1651053  -0.38377658 -1.3825458  -0.20570382 -0.24086423 -1.1633123\n",
      " -0.09068494 -0.21903622 -1.2356626  -0.04416263 -0.2517159  -1.3521781\n",
      "  0.03590789 -0.26093072 -1.1964047   0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[-3.0083e-04, -7.9370e-02, -2.5237e-01,  ...,  2.0854e-02,\n",
      "         -2.5452e-01, -1.2785e+00],\n",
      "        [-3.0083e-04, -7.9370e-02, -2.5237e-01,  ...,  2.0854e-02,\n",
      "         -2.5452e-01, -1.2785e+00],\n",
      "        [-3.0083e-04, -7.9370e-02, -2.5237e-01,  ...,  2.0854e-02,\n",
      "         -2.5452e-01, -1.2785e+00],\n",
      "        ...,\n",
      "        [-1.7687e-01,  3.7146e-01, -1.0098e-01,  ..., -7.0901e-01,\n",
      "          8.9767e-01, -3.8903e-01],\n",
      "        [-1.0585e-01, -6.9382e-02,  6.4233e-01,  ..., -2.1256e-01,\n",
      "          6.7798e-01,  3.0364e-01],\n",
      "        [-1.0585e-01, -6.9382e-02,  6.4233e-01,  ..., -2.1256e-01,\n",
      "          6.7798e-01,  3.0364e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-3.0083489e-04 -7.9370350e-02 -2.5237262e-01  2.7866337e-02\n",
      " -1.9955632e-01 -6.1706209e-01 -8.6227380e-02 -4.0411940e-01\n",
      " -1.4128153e+00 -2.3549436e-01 -4.6537632e-01 -1.7127342e+00\n",
      " -4.0016556e-01 -5.6780368e-01 -2.2021780e+00 -2.0278423e-01\n",
      " -7.0048714e-01 -1.5723052e+00 -1.5202165e-03 -7.4599493e-01\n",
      " -1.3877978e+00 -5.5353358e-02 -6.8010443e-01 -1.4416175e+00\n",
      " -6.7739323e-02 -8.3247769e-01 -1.5674727e+00 -1.5847319e-01\n",
      " -6.0539645e-01 -1.4761767e+00 -8.9913301e-02 -6.5797353e-01\n",
      " -1.4541090e+00 -9.9103458e-02 -6.2522811e-01 -1.5482121e+00\n",
      "  3.6486790e-02 -6.5720034e-01 -1.5827010e+00 -7.2960295e-02\n",
      " -5.0147212e-01 -1.3063793e+00 -2.1605866e-01 -2.6578373e-01\n",
      " -2.0365362e+00 -3.6815993e-02 -4.3154901e-01 -2.0514965e+00\n",
      "  1.2933522e-01 -3.9366704e-01 -1.4396887e+00 -1.8715683e-01\n",
      " -2.6859456e-01 -1.2342858e+00 -1.1371626e-01 -2.3962495e-01\n",
      " -1.3244030e+00 -7.4204102e-02 -2.4512678e-01 -1.4446588e+00\n",
      "  2.0854451e-02 -2.5452352e-01 -1.2784548e+00]\n",
      "data: [-3.0083489e-04 -7.9370350e-02 -2.5237262e-01  2.7866337e-02\n",
      " -1.9955631e-01 -6.1706209e-01 -8.6227380e-02 -4.0411940e-01\n",
      " -1.4128155e+00 -2.3549436e-01 -4.6537632e-01 -1.7127342e+00\n",
      " -4.0016556e-01 -5.6780368e-01 -2.2021780e+00 -2.0278424e-01\n",
      " -7.0048714e-01 -1.5723052e+00 -1.5202165e-03 -7.4599493e-01\n",
      " -1.3877978e+00 -5.5353358e-02 -6.8010443e-01 -1.4416175e+00\n",
      " -6.7739323e-02 -8.3247775e-01 -1.5674727e+00 -1.5847319e-01\n",
      " -6.0539645e-01 -1.4761767e+00 -8.9913301e-02 -6.5797353e-01\n",
      " -1.4541088e+00 -9.9103458e-02 -6.2522811e-01 -1.5482119e+00\n",
      "  3.6486790e-02 -6.5720034e-01 -1.5827010e+00 -7.2960295e-02\n",
      " -5.0147212e-01 -1.3063794e+00 -2.1605866e-01 -2.6578373e-01\n",
      " -2.0365362e+00 -3.6815993e-02 -4.3154898e-01 -2.0514965e+00\n",
      "  1.2933522e-01 -3.9366704e-01 -1.4396887e+00 -1.8715683e-01\n",
      " -2.6859456e-01 -1.2342858e+00 -1.1371626e-01 -2.3962493e-01\n",
      " -1.3244030e+00 -7.4204102e-02 -2.4512678e-01 -1.4446588e+00\n",
      "  2.0854451e-02 -2.5452352e-01 -1.2784548e+00  1.0000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[ 0.0227, -0.0221, -0.2236,  ...,  0.0344, -0.2105, -1.2537],\n",
      "        [ 0.0227, -0.0221, -0.2236,  ...,  0.0344, -0.2105, -1.2537],\n",
      "        [ 0.0227, -0.0221, -0.2236,  ...,  0.0344, -0.2105, -1.2537],\n",
      "        ...,\n",
      "        [-0.2117,  0.3361, -0.0996,  ..., -0.8561,  0.8434, -0.3474],\n",
      "        [-0.1336, -0.1671,  0.5832,  ..., -0.2096,  0.5897,  0.2487],\n",
      "        [-0.1336, -0.1671,  0.5832,  ..., -0.2096,  0.5897,  0.2487]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0227052  -0.02213115 -0.22364108  0.03557546 -0.14768156 -0.610139\n",
      " -0.07837511 -0.334044   -1.3636583  -0.22915122 -0.39576513 -1.6587358\n",
      " -0.39974695 -0.49093136 -2.148356   -0.17582405 -0.64328635 -1.5182365\n",
      " -0.00622922 -0.6812049  -1.3567997  -0.05386344 -0.6084055  -1.4206665\n",
      " -0.05310149 -0.76022446 -1.5390117  -0.13805377 -0.54959214 -1.4350603\n",
      " -0.07324591 -0.5948036  -1.4072423  -0.09290378 -0.5673003  -1.5063304\n",
      "  0.05095135 -0.5807631  -1.5355055  -0.06075952 -0.45509276 -1.2725084\n",
      " -0.17763884 -0.2312074  -1.932658   -0.02564389 -0.3759931  -1.9488738\n",
      "  0.14092165 -0.35092548 -1.4003686  -0.15661623 -0.22636475 -1.2069842\n",
      " -0.10034156 -0.20300928 -1.2971009  -0.06772235 -0.19728884 -1.417517\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.03441143 -0.21054359 -1.2536815 ]\n",
      "data: [ 0.0227052  -0.02213115 -0.2236411   0.03557546 -0.14768156 -0.610139\n",
      " -0.07837511 -0.334044   -1.3636583  -0.2291512  -0.39576513 -1.6587358\n",
      " -0.39974698 -0.49093136 -2.148356   -0.17582405 -0.64328635 -1.5182365\n",
      " -0.00622922 -0.6812049  -1.3567997  -0.05386344 -0.6084055  -1.4206665\n",
      " -0.05310149 -0.76022446 -1.5390117  -0.13805377 -0.54959214 -1.4350603\n",
      " -0.07324591 -0.5948036  -1.4072423  -0.09290378 -0.5673003  -1.5063304\n",
      "  0.05095135 -0.5807631  -1.5355055  -0.06075952 -0.4550928  -1.2725084\n",
      " -0.17763883 -0.23120742 -1.932658   -0.02564389 -0.37599313 -1.9488738\n",
      "  0.14092165 -0.35092548 -1.4003685  -0.15661623 -0.22636475 -1.2069842\n",
      " -0.10034156 -0.20300928 -1.2971008  -0.06772235 -0.19728884 -1.417517\n",
      "  0.03441143 -0.21054359 -1.2536815   0.11      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[ 0.0457, -0.0816, -0.2287,  ...,  0.0377, -0.2685, -1.2861],\n",
      "        [ 0.0457, -0.0816, -0.2287,  ...,  0.0377, -0.2685, -1.2861],\n",
      "        [ 0.0457, -0.0816, -0.2287,  ...,  0.0377, -0.2685, -1.2861],\n",
      "        ...,\n",
      "        [-0.3148,  0.2689, -0.2740,  ..., -0.8180,  0.6870, -0.3890],\n",
      "        [-0.1528, -0.0798,  0.5705,  ..., -0.2318,  0.7034,  0.2887],\n",
      "        [-0.1528, -0.0798,  0.5705,  ..., -0.2318,  0.7034,  0.2887]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04570087 -0.08157682 -0.22867218  0.06753543 -0.21519436 -0.634231\n",
      " -0.05154284 -0.40204805 -1.4034021  -0.19844316 -0.4711608  -1.6813285\n",
      " -0.36077273 -0.5605397  -2.1786253  -0.14619784 -0.7005291  -1.5555444\n",
      "  0.00570412 -0.74090314 -1.3948574  -0.03900748 -0.66676664 -1.4560431\n",
      " -0.04348808 -0.8118392  -1.5650953  -0.1148228  -0.6053295  -1.4816667\n",
      " -0.0565511  -0.65083385 -1.4406798  -0.0883964  -0.62525296 -1.5296398\n",
      "  0.04650927 -0.6309968  -1.5584545  -0.05071526 -0.5205169  -1.3237808\n",
      " -0.15892196 -0.29498    -1.9535364  -0.02335307 -0.43443498 -1.9677202\n",
      "  0.12474595 -0.41171816 -1.4294299  -0.13696863 -0.2894086  -1.259626\n",
      " -0.09307252 -0.26442158 -1.3409057  -0.0563602  -0.25400662 -1.4567031\n",
      "  0.037739   -0.2685492  -1.2861392 ]\n",
      "data: [ 0.04570086 -0.08157682 -0.22867218  0.06753543 -0.21519436 -0.634231\n",
      " -0.05154284 -0.40204802 -1.4034021  -0.19844316 -0.4711608  -1.6813285\n",
      " -0.36077273 -0.5605397  -2.1786253  -0.14619784 -0.7005291  -1.5555444\n",
      "  0.00570412 -0.74090314 -1.3948575  -0.03900748 -0.66676664 -1.4560431\n",
      " -0.04348808 -0.8118392  -1.5650954  -0.1148228  -0.6053295  -1.4816667\n",
      " -0.0565511  -0.65083385 -1.4406798  -0.0883964  -0.62525296 -1.5296398\n",
      "  0.04650927 -0.6309968  -1.5584546  -0.05071526 -0.5205169  -1.3237808\n",
      " -0.15892196 -0.29498    -1.9535364  -0.02335307 -0.43443498 -1.9677202\n",
      "  0.12474595 -0.4117182  -1.4294299  -0.13696863 -0.2894086  -1.259626\n",
      " -0.09307252 -0.26442158 -1.3409057  -0.0563602  -0.25400662 -1.4567031\n",
      "  0.037739   -0.2685492  -1.2861392   0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[ 0.0366, -0.0839, -0.2525,  ...,  0.0681, -0.2729, -1.2691],\n",
      "        [ 0.0366, -0.0839, -0.2525,  ...,  0.0681, -0.2729, -1.2691],\n",
      "        [ 0.0366, -0.0839, -0.2525,  ...,  0.0681, -0.2729, -1.2691],\n",
      "        ...,\n",
      "        [-0.1166,  0.3779, -0.0460,  ..., -0.7588,  0.8863, -0.3271],\n",
      "        [-0.1276, -0.1184,  0.5732,  ..., -0.2263,  0.6559,  0.2101],\n",
      "        [-0.1276, -0.1184,  0.5732,  ..., -0.2263,  0.6559,  0.2101]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0366109  -0.0838832  -0.2524715   0.06312925 -0.20383996 -0.6256118\n",
      " -0.04785972 -0.4038563  -1.4106498  -0.19439988 -0.46665716 -1.7064965\n",
      " -0.35078317 -0.56885105 -2.1966422  -0.15760227 -0.70176923 -1.5701617\n",
      "  0.03485738 -0.7470886  -1.4005774  -0.01925415 -0.67889714 -1.4572918\n",
      " -0.02790208 -0.83142966 -1.5798508  -0.11426979 -0.61022055 -1.4770639\n",
      " -0.04552507 -0.6624412  -1.4516026  -0.06147103 -0.6322037  -1.5418756\n",
      "  0.06984863 -0.6616083  -1.5704089  -0.02911771 -0.5098438  -1.3088913\n",
      " -0.1620043  -0.2789909  -2.0107834   0.00523597 -0.4415963  -2.0246208\n",
      "  0.16725679 -0.40903968 -1.430419   -0.13746497 -0.2813068  -1.2368455\n",
      " -0.06346937 -0.2553979  -1.3229616  -0.02649717 -0.26101726 -1.4394169\n",
      "  0.0681319  -0.27289683 -1.2690762 ]\n",
      "data: [ 0.0366109  -0.0838832  -0.2524715   0.06312925 -0.20383996 -0.6256118\n",
      " -0.04785972 -0.4038563  -1.4106498  -0.19439988 -0.4666572  -1.7064965\n",
      " -0.35078317 -0.56885105 -2.1966422  -0.15760227 -0.70176923 -1.5701617\n",
      "  0.03485738 -0.7470886  -1.4005774  -0.01925415 -0.67889714 -1.4572918\n",
      " -0.02790208 -0.83142966 -1.5798508  -0.11426979 -0.61022055 -1.4770639\n",
      " -0.04552507 -0.6624412  -1.4516026  -0.06147103 -0.6322037  -1.5418756\n",
      "  0.06984863 -0.6616083  -1.5704089  -0.02911771 -0.5098438  -1.3088913\n",
      " -0.16200429 -0.2789909  -2.0107834   0.00523597 -0.4415963  -2.0246208\n",
      "  0.16725679 -0.40903968 -1.430419   -0.13746497 -0.2813068  -1.2368455\n",
      " -0.06346937 -0.2553979  -1.3229616  -0.02649717 -0.26101726 -1.4394168\n",
      "  0.0681319  -0.27289683 -1.2690762   0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0231, -0.0583, -0.2458,  ...,  0.0623, -0.2488, -1.2929],\n",
      "        [ 0.0231, -0.0583, -0.2458,  ...,  0.0623, -0.2488, -1.2929],\n",
      "        [ 0.0231, -0.0583, -0.2458,  ...,  0.0623, -0.2488, -1.2929],\n",
      "        ...,\n",
      "        [-0.1330,  0.3452, -0.0617,  ..., -0.7471,  0.8205, -0.2949],\n",
      "        [-0.1345, -0.1173,  0.5644,  ..., -0.2053,  0.6359,  0.2210],\n",
      "        [-0.1345, -0.1173,  0.5644,  ..., -0.2053,  0.6359,  0.2210]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02306871 -0.058311   -0.24579594  0.03634458 -0.20305799 -0.658018\n",
      " -0.03859257 -0.38265723 -1.3868449  -0.18258265 -0.44240996 -1.6946497\n",
      " -0.3623004  -0.5678203  -2.1569345  -0.18683976 -0.6626055  -1.5532176\n",
      "  0.05158553 -0.68971133 -1.3520536  -0.00251307 -0.6315628  -1.4047885\n",
      " -0.00283766 -0.76186144 -1.5217586  -0.13731363 -0.5534928  -1.4648311\n",
      " -0.04506353 -0.6132684  -1.443536   -0.05073419 -0.59182405 -1.5444257\n",
      "  0.07677441 -0.6186546  -1.5965769  -0.03726858 -0.46900517 -1.2889085\n",
      " -0.14985144 -0.24672931 -1.9238074   0.00528098 -0.40549025 -1.9160299\n",
      "  0.16143024 -0.37238494 -1.4451702  -0.14328974 -0.23093522 -1.2289252\n",
      " -0.05264495 -0.21470292 -1.3093991  -0.00466273 -0.23800683 -1.4269648\n",
      "  0.06228004 -0.24882777 -1.2928827 ]\n",
      "data: [ 0.02306871 -0.058311   -0.24579594  0.03634458 -0.20305799 -0.65801793\n",
      " -0.03859257 -0.38265723 -1.386845   -0.18258265 -0.44240996 -1.6946497\n",
      " -0.36230043 -0.5678203  -2.1569345  -0.18683976 -0.6626055  -1.5532176\n",
      "  0.05158553 -0.68971133 -1.3520536  -0.00251307 -0.6315628  -1.4047885\n",
      " -0.00283766 -0.76186144 -1.5217586  -0.13731363 -0.5534928  -1.4648311\n",
      " -0.04506353 -0.6132684  -1.443536   -0.05073419 -0.59182405 -1.5444256\n",
      "  0.07677441 -0.6186546  -1.596577   -0.03726858 -0.46900517 -1.2889085\n",
      " -0.14985144 -0.24672931 -1.9238074   0.00528098 -0.40549028 -1.9160299\n",
      "  0.16143024 -0.37238494 -1.4451702  -0.14328974 -0.23093522 -1.2289252\n",
      " -0.05264495 -0.2147029  -1.3093991  -0.00466273 -0.23800682 -1.4269648\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.06228004 -0.24882776 -1.2928827   0.14      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0131, -0.0892, -0.2556,  ...,  0.0404, -0.2774, -1.3114],\n",
      "        [ 0.0131, -0.0892, -0.2556,  ...,  0.0404, -0.2774, -1.3114],\n",
      "        [ 0.0131, -0.0892, -0.2556,  ...,  0.0404, -0.2774, -1.3114],\n",
      "        ...,\n",
      "        [-0.1523,  0.4304, -0.1317,  ..., -0.7003,  0.9102, -0.3815],\n",
      "        [-0.1621, -0.1277,  0.5896,  ..., -0.2419,  0.6527,  0.2384],\n",
      "        [-0.1621, -0.1277,  0.5896,  ..., -0.2419,  0.6527,  0.2384]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01306144 -0.08921674 -0.25556132  0.03226295 -0.2280296  -0.66875523\n",
      " -0.05849055 -0.41376126 -1.4263914  -0.20072196 -0.4775865  -1.722878\n",
      " -0.36738047 -0.5899949  -2.1999133  -0.18791088 -0.6978381  -1.5870357\n",
      "  0.02479163 -0.7309816  -1.3921599  -0.02651271 -0.6669155  -1.4477034\n",
      " -0.03085955 -0.8016648  -1.5650921  -0.14501375 -0.59432685 -1.5013599\n",
      " -0.06488781 -0.6483854  -1.4751258  -0.0785848  -0.62382746 -1.5685809\n",
      "  0.05038288 -0.6454575  -1.6128304  -0.05741421 -0.5092038  -1.3304441\n",
      " -0.16994113 -0.28248847 -1.9674077  -0.02014339 -0.43587053 -1.9678342\n",
      "  0.13440625 -0.40484416 -1.4674847  -0.1590248  -0.27306306 -1.2645965\n",
      " -0.08125143 -0.25185645 -1.3464067  -0.03602999 -0.26454595 -1.4615862\n",
      "  0.04038706 -0.27744246 -1.3113766 ]\n",
      "data: [ 0.01306144 -0.08921674 -0.25556132  0.03226295 -0.2280296  -0.6687553\n",
      " -0.05849055 -0.41376126 -1.4263912  -0.20072196 -0.4775865  -1.722878\n",
      " -0.3673805  -0.5899949  -2.1999133  -0.18791088 -0.6978381  -1.5870357\n",
      "  0.02479163 -0.7309816  -1.3921599  -0.02651271 -0.66691554 -1.4477034\n",
      " -0.03085955 -0.8016648  -1.5650922  -0.14501375 -0.59432685 -1.5013598\n",
      " -0.06488781 -0.6483854  -1.4751258  -0.0785848  -0.62382746 -1.568581\n",
      "  0.05038288 -0.6454575  -1.6128304  -0.05741421 -0.5092038  -1.330444\n",
      " -0.16994113 -0.28248847 -1.9674077  -0.02014339 -0.43587053 -1.9678341\n",
      "  0.13440625 -0.40484416 -1.4674847  -0.1590248  -0.27306306 -1.2645965\n",
      " -0.08125143 -0.25185645 -1.3464067  -0.03602999 -0.26454595 -1.4615864\n",
      "  0.04038706 -0.27744246 -1.3113767   0.15      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0239, -0.0819, -0.2537,  ...,  0.0507, -0.2689, -1.2834],\n",
      "        [ 0.0239, -0.0819, -0.2537,  ...,  0.0507, -0.2689, -1.2834],\n",
      "        [ 0.0239, -0.0819, -0.2537,  ...,  0.0507, -0.2689, -1.2834],\n",
      "        ...,\n",
      "        [-0.1178,  0.4086, -0.1522,  ..., -0.6969,  0.9265, -0.4435],\n",
      "        [-0.1357, -0.1446,  0.5902,  ..., -0.2441,  0.6178,  0.2354],\n",
      "        [-0.1357, -0.1446,  0.5902,  ..., -0.2441,  0.6178,  0.2354]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02389957 -0.0819366  -0.25372833  0.04925447 -0.20801815 -0.638772\n",
      " -0.04771054 -0.40066522 -1.4068053  -0.19044545 -0.4612441  -1.7045913\n",
      " -0.34967965 -0.5676692  -2.1872113  -0.17121282 -0.693752   -1.5694277\n",
      "  0.03138796 -0.73288894 -1.4017303  -0.02249282 -0.668179   -1.4571269\n",
      " -0.02720394 -0.81330466 -1.5766854  -0.12780187 -0.59724116 -1.4784329\n",
      " -0.05373489 -0.64985275 -1.456147   -0.06762026 -0.622625   -1.5485554\n",
      "  0.05855689 -0.65118766 -1.5847964  -0.04114443 -0.5012427  -1.3095565\n",
      " -0.16880086 -0.27290738 -1.9930387  -0.00694171 -0.43342787 -2.0012023\n",
      "  0.14805657 -0.3999688  -1.4425967  -0.14880642 -0.2707532  -1.2411442\n",
      " -0.07148021 -0.24686624 -1.3253899  -0.03249488 -0.25706196 -1.4416714\n",
      "  0.05070193 -0.268863   -1.2834227 ]\n",
      "data: [ 0.02389957 -0.0819366  -0.25372833  0.04925447 -0.20801815 -0.638772\n",
      " -0.04771054 -0.4006652  -1.4068053  -0.19044547 -0.46124414 -1.7045913\n",
      " -0.34967965 -0.5676692  -2.1872113  -0.17121282 -0.693752   -1.5694278\n",
      "  0.03138796 -0.73288894 -1.4017303  -0.02249282 -0.6681789  -1.457127\n",
      " -0.02720394 -0.81330466 -1.5766854  -0.12780187 -0.59724116 -1.4784329\n",
      " -0.05373489 -0.64985275 -1.456147   -0.06762026 -0.622625   -1.5485553\n",
      "  0.05855689 -0.65118766 -1.5847964  -0.04114443 -0.5012427  -1.3095565\n",
      " -0.16880088 -0.27290738 -1.9930387  -0.00694171 -0.4334279  -2.0012023\n",
      "  0.14805657 -0.3999688  -1.4425968  -0.14880642 -0.2707532  -1.2411442\n",
      " -0.07148021 -0.24686624 -1.3253899  -0.03249488 -0.25706196 -1.4416715\n",
      "  0.05070193 -0.268863   -1.2834227   0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0186, -0.0474, -0.2469,  ...,  0.0551, -0.2396, -1.2876],\n",
      "        [ 0.0186, -0.0474, -0.2469,  ...,  0.0551, -0.2396, -1.2876],\n",
      "        [ 0.0186, -0.0474, -0.2469,  ...,  0.0551, -0.2396, -1.2876],\n",
      "        ...,\n",
      "        [-0.1552,  0.3435, -0.0910,  ..., -0.7960,  0.8242, -0.3240],\n",
      "        [-0.1350, -0.1444,  0.5594,  ..., -0.2080,  0.6132,  0.2147],\n",
      "        [-0.1350, -0.1444,  0.5594,  ..., -0.2080,  0.6132,  0.2147]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01862139 -0.04736958 -0.2469066   0.03215976 -0.18782996 -0.6529748\n",
      " -0.05091162 -0.36965317 -1.3888106  -0.194742   -0.42987698 -1.6922698\n",
      " -0.3707925  -0.5496845  -2.159053   -0.18823531 -0.65467787 -1.551435\n",
      "  0.03560835 -0.68481314 -1.359879   -0.01682337 -0.6234058  -1.4142914\n",
      " -0.01526428 -0.7583151  -1.5307782  -0.1407102  -0.54884434 -1.4641688\n",
      " -0.05436791 -0.60581315 -1.4412043  -0.06214964 -0.58396745 -1.5399787\n",
      "  0.0681762  -0.6080431  -1.5874944  -0.04558896 -0.4636429  -1.2915108\n",
      " -0.15905505 -0.24058062 -1.933289   -0.00381411 -0.3975021  -1.9300051\n",
      "  0.15382901 -0.3658878  -1.4398067  -0.14910623 -0.22771183 -1.2299905\n",
      " -0.06495021 -0.21028744 -1.312221   -0.01901677 -0.22793937 -1.4295578\n",
      "  0.05511964 -0.23958339 -1.2875767 ]\n",
      "data: [ 0.01862139 -0.04736958 -0.24690658  0.03215976 -0.18782996 -0.6529748\n",
      " -0.05091162 -0.36965317 -1.3888106  -0.194742   -0.42987698 -1.6922698\n",
      " -0.3707925  -0.5496845  -2.159053   -0.18823533 -0.65467787 -1.551435\n",
      "  0.03560835 -0.68481314 -1.359879   -0.01682337 -0.6234058  -1.4142914\n",
      " -0.01526428 -0.75831515 -1.5307782  -0.1407102  -0.54884434 -1.4641689\n",
      " -0.05436791 -0.60581315 -1.4412044  -0.06214963 -0.58396745 -1.5399787\n",
      "  0.0681762  -0.6080431  -1.5874944  -0.04558896 -0.4636429  -1.2915108\n",
      " -0.15905505 -0.24058062 -1.933289   -0.00381411 -0.3975021  -1.9300051\n",
      "  0.15382901 -0.3658878  -1.4398067  -0.14910623 -0.22771183 -1.2299905\n",
      " -0.06495021 -0.21028744 -1.312221   -0.01901677 -0.22793938 -1.4295578\n",
      "  0.05511964 -0.2395834  -1.2875766   0.17      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0087, -0.0796, -0.2508,  ...,  0.0356, -0.2672, -1.3079],\n",
      "        [ 0.0087, -0.0796, -0.2508,  ...,  0.0356, -0.2672, -1.3079],\n",
      "        [ 0.0087, -0.0796, -0.2508,  ...,  0.0356, -0.2672, -1.3079],\n",
      "        ...,\n",
      "        [-0.1623,  0.4165, -0.1407,  ..., -0.7212,  0.8974, -0.3776],\n",
      "        [-0.1648, -0.1360,  0.5743,  ..., -0.2519,  0.6455,  0.2241],\n",
      "        [-0.1648, -0.1360,  0.5743,  ..., -0.2519,  0.6455,  0.2241]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00866021 -0.07963304 -0.25084373  0.0274888  -0.21872798 -0.668907\n",
      " -0.06064876 -0.40095097 -1.4201121  -0.20152389 -0.46363968 -1.7167447\n",
      " -0.3687237  -0.5760913  -2.1915941  -0.1918847  -0.6857121  -1.5784144\n",
      "  0.0212951  -0.7161568  -1.3855641  -0.02874167 -0.6524096  -1.4416401\n",
      " -0.0311783  -0.7855972  -1.5586152  -0.14966907 -0.582071   -1.4937797\n",
      " -0.06810069 -0.6353719  -1.4684463  -0.08102825 -0.61092496 -1.5627711\n",
      "  0.04912634 -0.63177073 -1.6091027  -0.06263243 -0.49861932 -1.322835\n",
      " -0.17261572 -0.2721411  -1.9551902  -0.02354099 -0.42382854 -1.9549644\n",
      "  0.130844   -0.3935426  -1.463304   -0.16309005 -0.26264554 -1.2576821\n",
      " -0.08562587 -0.24159837 -1.339442   -0.03980222 -0.254058   -1.4553969\n",
      "  0.03558231 -0.26719782 -1.3079202 ]\n",
      "data: [ 0.00866021 -0.07963304 -0.25084373  0.0274888  -0.21872798 -0.668907\n",
      " -0.06064876 -0.40095097 -1.4201121  -0.20152387 -0.46363968 -1.7167447\n",
      " -0.3687237  -0.5760913  -2.1915941  -0.1918847  -0.6857121  -1.5784144\n",
      "  0.0212951  -0.7161568  -1.3855641  -0.02874167 -0.6524096  -1.4416401\n",
      " -0.0311783  -0.7855972  -1.5586152  -0.14966907 -0.582071   -1.4937797\n",
      " -0.06810069 -0.6353719  -1.4684463  -0.08102825 -0.61092496 -1.5627712\n",
      "  0.04912634 -0.63177073 -1.6091027  -0.06263243 -0.49861932 -1.322835\n",
      " -0.17261572 -0.2721411  -1.9551902  -0.02354099 -0.42382854 -1.9549644\n",
      "  0.130844   -0.3935426  -1.463304   -0.16309005 -0.26264554 -1.2576821\n",
      " -0.08562586 -0.24159835 -1.339442   -0.03980222 -0.254058   -1.4553969\n",
      "  0.03558231 -0.26719782 -1.3079202   0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[ 0.0157, -0.0884, -0.2488,  ...,  0.0481, -0.2758, -1.2809],\n",
      "        [ 0.0157, -0.0884, -0.2488,  ...,  0.0481, -0.2758, -1.2809],\n",
      "        [ 0.0157, -0.0884, -0.2488,  ...,  0.0481, -0.2758, -1.2809],\n",
      "        ...,\n",
      "        [-0.1233,  0.3970, -0.1657,  ..., -0.7113,  0.9054, -0.4368],\n",
      "        [-0.1447, -0.1626,  0.5724,  ..., -0.2583,  0.6041,  0.2194],\n",
      "        [-0.1447, -0.1626,  0.5724,  ..., -0.2583,  0.6041,  0.2194]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01565049 -0.08840943 -0.24882078  0.03881737 -0.2197536  -0.6423788\n",
      " -0.05313284 -0.4095633  -1.3998382  -0.19370238 -0.47009066 -1.6973335\n",
      " -0.35597128 -0.5807245  -2.172038   -0.18072878 -0.698176   -1.5601467\n",
      "  0.02861246 -0.73364294 -1.3856161  -0.02345239 -0.67033494 -1.4402721\n",
      " -0.02526256 -0.81137764 -1.5586308  -0.13676174 -0.59805393 -1.4712715\n",
      " -0.0579998  -0.65173817 -1.4486294  -0.06874707 -0.6258596  -1.5409696\n",
      "  0.05923612 -0.6534864  -1.5820004  -0.04806466 -0.5056778  -1.301833\n",
      " -0.1713272  -0.27852252 -1.9751074  -0.00985499 -0.43833175 -1.9793541\n",
      "  0.14563595 -0.40422437 -1.4388739  -0.154238   -0.27352446 -1.2350404\n",
      " -0.07441902 -0.2507955  -1.3185734  -0.0319517  -0.26329017 -1.4354665\n",
      "  0.04810753 -0.2757852  -1.2808844 ]\n",
      "data: [ 0.01565049 -0.08840943 -0.24882078  0.03881737 -0.2197536  -0.64237887\n",
      " -0.05313284 -0.4095633  -1.3998382  -0.1937024  -0.4700907  -1.6973336\n",
      " -0.35597125 -0.5807245  -2.172038   -0.18072878 -0.698176   -1.5601467\n",
      "  0.02861247 -0.73364294 -1.385616   -0.02345239 -0.67033494 -1.4402721\n",
      " -0.02526256 -0.81137764 -1.5586308  -0.13676174 -0.59805393 -1.4712715\n",
      " -0.0579998  -0.6517381  -1.4486295  -0.06874707 -0.6258596  -1.5409695\n",
      "  0.05923612 -0.65348643 -1.5820004  -0.04806466 -0.5056778  -1.301833\n",
      " -0.1713272  -0.27852252 -1.9751074  -0.00985499 -0.43833175 -1.9793541\n",
      "  0.14563595 -0.40422437 -1.4388739  -0.154238   -0.27352446 -1.2350404\n",
      " -0.07441902 -0.2507955  -1.3185734  -0.0319517  -0.26329017 -1.4354664\n",
      "  0.04810753 -0.2757852  -1.2808844   0.19      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[ 0.0262, -0.0719, -0.2504,  ...,  0.0543, -0.2619, -1.2735],\n",
      "        [ 0.0262, -0.0719, -0.2504,  ...,  0.0543, -0.2619, -1.2735],\n",
      "        [ 0.0262, -0.0719, -0.2504,  ...,  0.0543, -0.2619, -1.2735],\n",
      "        ...,\n",
      "        [-0.1488,  0.3685, -0.1191,  ..., -0.7789,  0.8664, -0.3820],\n",
      "        [-0.1308, -0.1280,  0.5814,  ..., -0.2185,  0.6411,  0.2156],\n",
      "        [-0.1308, -0.1280,  0.5814,  ..., -0.2185,  0.6411,  0.2156]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02618609 -0.0718894  -0.25038207  0.0498399  -0.19689885 -0.62996787\n",
      " -0.05672058 -0.39453232 -1.4079318  -0.2017671  -0.45729634 -1.7038543\n",
      " -0.36245883 -0.561671   -2.1887474  -0.1695978  -0.68947995 -1.5666568\n",
      "  0.02460727 -0.7323432  -1.39428    -0.02850939 -0.66535354 -1.4509304\n",
      " -0.03450555 -0.81533194 -1.5714383  -0.1265092  -0.59406364 -1.4755664\n",
      " -0.05645888 -0.6466981  -1.4496002  -0.0720493  -0.61958873 -1.5411127\n",
      "  0.05876072 -0.6461464  -1.5735934  -0.04168689 -0.4971312  -1.3076706\n",
      " -0.17161305 -0.26860848 -2.001585   -0.00784267 -0.42942274 -2.0125797\n",
      "  0.15160257 -0.39720467 -1.4321389  -0.14761664 -0.2669545  -1.2379389\n",
      " -0.0749477  -0.24297506 -1.3236129  -0.03639652 -0.24946713 -1.4401889\n",
      "  0.05432136 -0.2618507  -1.2734876 ]\n",
      "data: [ 0.02618609 -0.0718894  -0.25038207  0.0498399  -0.19689885 -0.62996787\n",
      " -0.05672058 -0.39453232 -1.4079318  -0.2017671  -0.45729634 -1.7038543\n",
      " -0.36245883 -0.561671   -2.1887474  -0.1695978  -0.68948    -1.5666568\n",
      "  0.02460727 -0.7323432  -1.39428    -0.02850939 -0.66535354 -1.4509304\n",
      " -0.03450555 -0.81533194 -1.5714383  -0.1265092  -0.59406364 -1.4755664\n",
      " -0.05645888 -0.6466982  -1.4496002  -0.0720493  -0.61958873 -1.5411127\n",
      "  0.05876072 -0.6461464  -1.5735935  -0.04168688 -0.4971312  -1.3076706\n",
      " -0.17161304 -0.26860848 -2.001585   -0.00784267 -0.42942274 -2.0125797\n",
      "  0.15160257 -0.39720467 -1.4321389  -0.14761664 -0.2669545  -1.2379389\n",
      " -0.0749477  -0.24297506 -1.3236129  -0.03639652 -0.24946712 -1.4401889\n",
      "  0.05432136 -0.2618507  -1.2734876   0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.234 3.234 3.238 ... 3.226 3.216 3.219]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " [3.21  3.21  3.212 ... 3.208 3.207 3.207]\n",
      " ...\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.88  2.88  2.893 ... 2.9   2.912 2.921]\n",
      " [2.883 2.883 2.894 ... 2.894 2.901 2.906]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F9E8>\n",
      "tensor([[ 0.0150, -0.0390, -0.2423,  ...,  0.0529, -0.2311, -1.2824],\n",
      "        [ 0.0150, -0.0390, -0.2423,  ...,  0.0529, -0.2311, -1.2824],\n",
      "        [ 0.0150, -0.0390, -0.2423,  ...,  0.0529, -0.2311, -1.2824],\n",
      "        ...,\n",
      "        [-0.1702,  0.3345, -0.1124,  ..., -0.8146,  0.8012, -0.3203],\n",
      "        [-0.1403, -0.1450,  0.5520,  ..., -0.2140,  0.6143,  0.2066],\n",
      "        [-0.1403, -0.1450,  0.5520,  ..., -0.2140,  0.6143,  0.2066]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01498981 -0.0389964  -0.24228404  0.02859202 -0.17943622 -0.6505176\n",
      " -0.05444761 -0.360452   -1.3854585  -0.19795354 -0.42076594 -1.6891277\n",
      " -0.373949   -0.54098654 -2.1552439  -0.19208516 -0.6456346  -1.5458566\n",
      "  0.03279623 -0.67498153 -1.3526632  -0.01946224 -0.6141258  -1.4073437\n",
      " -0.01838566 -0.74861866 -1.524459   -0.14450373 -0.54001766 -1.4586015\n",
      " -0.05757417 -0.5971565  -1.4362093  -0.06511912 -0.5749578  -1.5352043\n",
      "  0.06610192 -0.5996313  -1.583543   -0.04930442 -0.45520812 -1.2852707\n",
      " -0.16212055 -0.23177688 -1.9268696  -0.00636835 -0.38847947 -1.9235458\n",
      "  0.15188895 -0.35752726 -1.4349601  -0.15245521 -0.21914467 -1.22355\n",
      " -0.0678363  -0.20165877 -1.3058531  -0.02138251 -0.2192069  -1.4237076\n",
      "  0.05293977 -0.23109904 -1.2823699 ]\n",
      "data: [ -5.18   9.54 -12.66  -5.13   9.71 -12.29  -5.01   9.92 -12.09  -5.01\n",
      "  10.13 -11.97   0.     0.     0.    -5.16  10.3  -12.1    0.     0.\n",
      "   0.    -5.14  10.39 -12.02  -5.12  10.19 -12.17  -5.25  10.19 -12.21\n",
      "  -7.58  13.23  -4.67  -5.24  10.28 -12.18  -5.23  10.16 -12.19  -5.39\n",
      "  10.18 -12.19  -7.79  13.15  -4.53  -5.4   10.22 -12.16  -5.36  10.06\n",
      " -12.25  -5.49  10.08 -12.24  -5.49  10.14 -12.3   -5.49  10.1  -12.27\n",
      "  -5.46  10.02 -12.28   0.  ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[ 0.1501, -0.4984, -0.3885,  ...,  0.1845, -0.7372, -0.0455],\n",
      "        [ 0.1501, -0.4984, -0.3885,  ...,  0.1845, -0.7372, -0.0455],\n",
      "        [ 0.1501, -0.4984, -0.3885,  ...,  0.1845, -0.7372, -0.0455],\n",
      "        ...,\n",
      "        [ 0.9415,  0.7092,  1.0447,  ..., -0.1724,  1.4020,  0.4430],\n",
      "        [ 0.9228,  0.1725, -0.1145,  ...,  1.0942,  0.7803, -1.7086],\n",
      "        [ 0.9228,  0.1725, -0.1145,  ...,  1.0942,  0.7803, -1.7086]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.15011042 -0.49842834 -0.38848162  0.10079224 -0.5601156  -0.31477654\n",
      "  0.02743319 -0.6283959  -0.11229432 -0.03843342 -0.7377856  -0.00553533\n",
      " -0.06438521 -0.8098905   0.05492687 -0.01147498 -0.698673   -0.2616793\n",
      "  0.0770711  -0.7375614   0.22401541  0.05733632 -0.8439441   0.30808944\n",
      "  0.01244649 -0.8128095   0.31711316  0.04677667 -0.6672174  -0.30070028\n",
      "  0.00997868 -0.7627634  -0.14254132  0.03206141 -0.8112807  -0.07310754\n",
      "  0.06255344 -0.91209865 -0.05988824  0.07249876 -0.6423298  -0.27595925\n",
      "  0.01950306 -0.6904502  -0.15142378  0.06177486 -0.75696075 -0.11240092\n",
      "  0.11949377 -0.8138436  -0.04128498  0.0972127  -0.54899174 -0.2553609\n",
      "  0.12855159 -0.58955324 -0.10478064  0.17006187 -0.6593671  -0.07681209\n",
      "  0.1845204  -0.7371862  -0.04551378]\n",
      "init: [ 0.15011042 -0.49842834 -0.38848162  0.10079224 -0.5601156  -0.31477654\n",
      "  0.02743319 -0.6283959  -0.11229432 -0.03843342 -0.7377856  -0.00553533\n",
      " -0.06438521 -0.8098905   0.05492687 -0.01147498 -0.698673   -0.2616793\n",
      "  0.0770711  -0.7375614   0.22401541  0.05733632 -0.8439441   0.30808944\n",
      "  0.01244649 -0.8128095   0.31711316  0.04677667 -0.6672174  -0.30070028\n",
      "  0.00997868 -0.7627634  -0.14254132  0.03206141 -0.8112807  -0.07310754\n",
      "  0.06255344 -0.91209865 -0.05988824  0.07249876 -0.6423298  -0.27595925\n",
      "  0.01950306 -0.6904502  -0.15142378  0.06177486 -0.75696075 -0.11240092\n",
      "  0.11949377 -0.8138436  -0.04128498  0.0972127  -0.54899174 -0.2553609\n",
      "  0.12855159 -0.58955324 -0.10478064  0.17006187 -0.6593671  -0.07681209\n",
      "  0.1845204  -0.7371862  -0.04551378]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [ 0.15011042 -0.49842834 -0.3884816   0.10079224 -0.5601156  -0.31477654\n",
      "  0.02743319 -0.6283959  -0.11229431 -0.03843342 -0.7377856  -0.00553533\n",
      " -0.06438521 -0.8098905   0.05492687 -0.01147498 -0.698673   -0.2616793\n",
      "  0.0770711  -0.7375614   0.22401541  0.05733632 -0.8439441   0.30808944\n",
      "  0.01244649 -0.8128095   0.31711316  0.04677667 -0.66721743 -0.30070028\n",
      "  0.00997868 -0.7627634  -0.14254132  0.03206141 -0.8112807  -0.07310754\n",
      "  0.06255344 -0.91209865 -0.05988824  0.07249876 -0.6423298  -0.27595925\n",
      "  0.01950306 -0.6904502  -0.15142378  0.06177486 -0.75696075 -0.11240092\n",
      "  0.11949377 -0.8138436  -0.04128498  0.0972127  -0.54899174 -0.2553609\n",
      "  0.12855159 -0.58955324 -0.10478064  0.17006187 -0.6593671  -0.07681209\n",
      "  0.1845204  -0.7371862  -0.04551378  0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3F98>\n",
      "tensor([[-0.1186,  0.1468,  0.0673,  ..., -0.0203, -0.1890, -0.4958],\n",
      "        [-0.1186,  0.1468,  0.0673,  ..., -0.0203, -0.1890, -0.4958],\n",
      "        [-0.1186,  0.1468,  0.0673,  ..., -0.0203, -0.1890, -0.4958],\n",
      "        ...,\n",
      "        [ 0.1750,  0.0475,  0.0117,  ..., -0.1443,  0.7345, -0.4342],\n",
      "        [ 0.3455, -0.2853,  0.0617,  ...,  0.7724,  0.0147,  0.2080],\n",
      "        [ 0.3455, -0.2853,  0.0617,  ...,  0.7724,  0.0147,  0.2080]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.11856715  0.14679766  0.06725986 -0.22518727  0.02428654 -0.23407279\n",
      " -0.40322646 -0.09891073 -0.76158327 -0.56388664 -0.1748755  -0.9997993\n",
      " -0.8115647  -0.2536615  -1.3564947  -0.3314559  -0.42601946 -0.8593856\n",
      " -0.39366353 -0.4843394  -0.9968594  -0.36238256 -0.38218695 -1.0807067\n",
      " -0.14616123 -0.5799919  -1.1269181  -0.29522467 -0.32627904 -0.79154927\n",
      " -0.2786789  -0.37424928 -0.73675764 -0.24029312 -0.4320092  -0.84295\n",
      "  0.07026695 -0.3608279  -0.8719764  -0.26611087 -0.34359238 -0.62404287\n",
      " -0.26819962 -0.176949   -0.9442099  -0.15970588 -0.27160233 -0.9583295\n",
      "  0.13870594 -0.32055965 -0.6471585  -0.28163034 -0.12493107 -0.5477392\n",
      " -0.30523202 -0.1502567  -0.5893648  -0.24520828 -0.10925762 -0.6912393\n",
      " -0.02031758 -0.18903777 -0.49583042]\n",
      "data: [-0.11856715  0.14679766  0.06725986 -0.22518726  0.02428654 -0.23407277\n",
      " -0.40322646 -0.09891072 -0.76158327 -0.56388664 -0.17487548 -0.9997994\n",
      " -0.8115647  -0.2536615  -1.3564945  -0.3314559  -0.4260195  -0.8593856\n",
      " -0.39366353 -0.48433936 -0.9968594  -0.36238253 -0.38218698 -1.0807067\n",
      " -0.14616123 -0.5799919  -1.1269181  -0.29522467 -0.32627904 -0.7915493\n",
      " -0.2786789  -0.37424928 -0.73675764 -0.24029312 -0.4320092  -0.84295\n",
      "  0.07026695 -0.3608279  -0.8719764  -0.26611087 -0.34359238 -0.62404287\n",
      " -0.26819962 -0.17694898 -0.9442099  -0.15970588 -0.27160233 -0.95832944\n",
      "  0.13870594 -0.32055965 -0.6471585  -0.28163034 -0.12493107 -0.5477392\n",
      " -0.30523202 -0.1502567  -0.5893648  -0.24520828 -0.10925761 -0.6912393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.02031758 -0.18903776 -0.49583042  0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.2124, -0.1992, -0.0553,  ...,  0.2485, -0.3526, -1.2062],\n",
      "        [ 0.2124, -0.1992, -0.0553,  ...,  0.2485, -0.3526, -1.2062],\n",
      "        [ 0.2124, -0.1992, -0.0553,  ...,  0.2485, -0.3526, -1.2062],\n",
      "        ...,\n",
      "        [-0.0987,  0.1928,  0.4868,  ..., -0.2323,  0.8479,  0.2273],\n",
      "        [-0.6467,  0.3779,  0.2728,  ..., -1.2975,  1.0934,  0.0208],\n",
      "        [-0.6467,  0.3779,  0.2728,  ..., -1.2975,  1.0934,  0.0208]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.21235022 -0.19923162 -0.055316    0.2388141  -0.3227366  -0.48527202\n",
      "  0.17966762 -0.44764346 -1.1500429   0.04126929 -0.47612095 -1.4335662\n",
      " -0.08646607 -0.579447   -1.9501979   0.00491565 -0.76461554 -1.3206859\n",
      "  0.25311267 -0.74586105 -1.136657    0.21480964 -0.64817977 -1.1914643\n",
      "  0.20582157 -0.7340281  -1.3060157   0.03592217 -0.68201673 -1.2677416\n",
      "  0.15745541 -0.6955464  -1.2836413   0.16096917 -0.6162243  -1.3615501\n",
      "  0.2843461  -0.62975645 -1.4168878   0.15629518 -0.60826933 -1.1322379\n",
      "  0.09986378 -0.35048205 -1.5746211   0.2254906  -0.47266117 -1.5594893\n",
      "  0.36270338 -0.4111109  -1.3552362   0.05049156 -0.39041388 -1.0837948\n",
      "  0.15382774 -0.34260425 -1.1824926   0.19471791 -0.3558956  -1.3038455\n",
      "  0.2484645  -0.3525933  -1.2062072 ]\n",
      "data: [ 0.21235022 -0.19923162 -0.055316    0.2388141  -0.3227366  -0.48527202\n",
      "  0.17966762 -0.44764346 -1.1500429   0.04126929 -0.47612095 -1.4335663\n",
      " -0.08646607 -0.579447   -1.9501979   0.00491565 -0.76461554 -1.3206859\n",
      "  0.25311267 -0.74586105 -1.136657    0.21480964 -0.64817977 -1.1914643\n",
      "  0.20582157 -0.7340281  -1.3060157   0.03592217 -0.68201673 -1.2677416\n",
      "  0.15745541 -0.6955464  -1.2836413   0.16096917 -0.6162243  -1.3615501\n",
      "  0.2843461  -0.62975645 -1.4168878   0.15629518 -0.60826933 -1.1322379\n",
      "  0.09986379 -0.35048208 -1.5746211   0.22549061 -0.47266117 -1.5594893\n",
      "  0.3627034  -0.4111109  -1.3552362   0.05049156 -0.39041388 -1.0837948\n",
      "  0.15382774 -0.34260425 -1.1824926   0.19471793 -0.3558956  -1.3038455\n",
      "  0.2484645  -0.3525933  -1.2062072   0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0316, -0.1459, -0.1685,  ...,  0.0344, -0.3277, -1.2186],\n",
      "        [ 0.0316, -0.1459, -0.1685,  ...,  0.0344, -0.3277, -1.2186],\n",
      "        [ 0.0316, -0.1459, -0.1685,  ...,  0.0344, -0.3277, -1.2186],\n",
      "        ...,\n",
      "        [-0.1678,  0.3985, -0.2209,  ..., -0.4675,  0.8946, -0.7394],\n",
      "        [-0.2204,  0.0284,  0.4881,  ..., -0.1618,  0.8059, -0.0451],\n",
      "        [-0.2204,  0.0284,  0.4881,  ..., -0.1618,  0.8059, -0.0451]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 3.1556580e-02 -1.4594047e-01 -1.6848859e-01  3.6773037e-02\n",
      " -2.9903001e-01 -5.5063748e-01 -7.7040367e-02 -5.1685601e-01\n",
      " -1.3572819e+00 -2.3873317e-01 -5.9041780e-01 -1.6565279e+00\n",
      " -4.3287858e-01 -7.1094716e-01 -2.1459727e+00 -2.0883912e-01\n",
      " -7.5633347e-01 -1.5700412e+00  2.1149516e-03 -8.1092858e-01\n",
      " -1.3377504e+00 -5.2159518e-02 -7.4286115e-01 -1.3787837e+00\n",
      " -6.2102541e-02 -8.9174879e-01 -1.4882501e+00 -1.5929168e-01\n",
      " -6.3619936e-01 -1.4734594e+00 -8.9387089e-02 -7.0729101e-01\n",
      " -1.4160774e+00 -1.0480210e-01 -6.9515729e-01 -1.5061255e+00\n",
      "  2.6134565e-02 -7.1282053e-01 -1.5424386e+00 -6.0760297e-02\n",
      " -5.5178750e-01 -1.3031934e+00 -1.9670367e-01 -3.3003438e-01\n",
      " -1.9382017e+00 -4.3464363e-02 -5.0600106e-01 -1.9321847e+00\n",
      "  1.1711034e-01 -4.6367732e-01 -1.3806018e+00 -1.6961971e-01\n",
      " -3.0932385e-01 -1.2308422e+00 -9.5564261e-02 -2.9338223e-01\n",
      " -1.2859069e+00 -4.7028244e-02 -3.1688029e-01 -1.3948172e+00\n",
      "  3.4411684e-02 -3.2767951e-01 -1.2186011e+00]\n",
      "data: [ 3.1556580e-02 -1.4594047e-01 -1.6848859e-01  3.6773037e-02\n",
      " -2.9903001e-01 -5.5063748e-01 -7.7040367e-02 -5.1685601e-01\n",
      " -1.3572819e+00 -2.3873317e-01 -5.9041780e-01 -1.6565279e+00\n",
      " -4.3287858e-01 -7.1094722e-01 -2.1459727e+00 -2.0883912e-01\n",
      " -7.5633347e-01 -1.5700412e+00  2.1149516e-03 -8.1092858e-01\n",
      " -1.3377504e+00 -5.2159518e-02 -7.4286115e-01 -1.3787837e+00\n",
      " -6.2102541e-02 -8.9174879e-01 -1.4882501e+00 -1.5929168e-01\n",
      " -6.3619936e-01 -1.4734594e+00 -8.9387089e-02 -7.0729101e-01\n",
      " -1.4160774e+00 -1.0480210e-01 -6.9515729e-01 -1.5061255e+00\n",
      "  2.6134565e-02 -7.1282053e-01 -1.5424386e+00 -6.0760297e-02\n",
      " -5.5178750e-01 -1.3031936e+00 -1.9670369e-01 -3.3003438e-01\n",
      " -1.9382015e+00 -4.3464366e-02 -5.0600106e-01 -1.9321847e+00\n",
      "  1.1711034e-01 -4.6367732e-01 -1.3806018e+00 -1.6961971e-01\n",
      " -3.0932385e-01 -1.2308422e+00 -9.5564261e-02 -2.9338223e-01\n",
      " -1.2859070e+00 -4.7028247e-02 -3.1688029e-01 -1.3948172e+00\n",
      "  3.4411684e-02 -3.2767951e-01 -1.2186011e+00  3.9999999e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0117, -0.0686, -0.1553,  ...,  0.0568, -0.2716, -1.1177],\n",
      "        [ 0.0117, -0.0686, -0.1553,  ...,  0.0568, -0.2716, -1.1177],\n",
      "        [ 0.0117, -0.0686, -0.1553,  ...,  0.0568, -0.2716, -1.1177],\n",
      "        ...,\n",
      "        [-0.1961,  0.4115, -0.0885,  ..., -0.7143,  1.0140, -0.4341],\n",
      "        [-0.0892, -0.0445,  0.6485,  ..., -0.1937,  0.6326,  0.3372],\n",
      "        [-0.0892, -0.0445,  0.6485,  ..., -0.1937,  0.6326,  0.3372]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01174215 -0.06855387 -0.15530655  0.04191713 -0.15917195 -0.4190836\n",
      " -0.11379759 -0.39284    -1.2896487  -0.2686301  -0.4578343  -1.5718112\n",
      " -0.40952465 -0.5438051  -2.0884314  -0.17806008 -0.71059203 -1.4684259\n",
      " -0.0159944  -0.7838404  -1.3353952  -0.06687503 -0.70463777 -1.3838823\n",
      " -0.06303655 -0.8796389  -1.5113347  -0.13285989 -0.6320518  -1.3649328\n",
      " -0.0786178  -0.6824701  -1.3377929  -0.07998382 -0.64241385 -1.4148662\n",
      "  0.07088843 -0.6811341  -1.4217157  -0.04858602 -0.516539   -1.2074051\n",
      " -0.21292868 -0.27519503 -1.9936101  -0.01079237 -0.45484832 -2.0262876\n",
      "  0.18123296 -0.4137462  -1.2959895  -0.17679559 -0.29156905 -1.1206616\n",
      " -0.10390636 -0.2604703  -1.2146211  -0.07362747 -0.2578906  -1.3272933\n",
      "  0.05683643 -0.27156478 -1.1176858 ]\n",
      "data: [ 0.01174215 -0.06855387 -0.15530655  0.04191713 -0.15917195 -0.4190836\n",
      " -0.11379759 -0.39284    -1.2896485  -0.2686301  -0.45783433 -1.5718112\n",
      " -0.40952465 -0.5438051  -2.0884314  -0.1780601  -0.71059203 -1.4684259\n",
      " -0.0159944  -0.7838404  -1.3353952  -0.06687503 -0.70463777 -1.3838823\n",
      " -0.06303655 -0.8796389  -1.5113347  -0.13285989 -0.6320518  -1.3649327\n",
      " -0.0786178  -0.6824701  -1.3377929  -0.07998382 -0.64241385 -1.4148662\n",
      "  0.07088843 -0.6811341  -1.4217157  -0.04858602 -0.516539   -1.2074051\n",
      " -0.21292868 -0.27519503 -1.99361    -0.01079237 -0.45484832 -2.0262876\n",
      "  0.18123297 -0.41374624 -1.2959895  -0.17679557 -0.29156905 -1.1206616\n",
      " -0.10390636 -0.2604703  -1.2146211  -0.07362747 -0.2578906  -1.3272933\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.05683643 -0.27156478 -1.1176858   0.05      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-4.2666e-02, -1.7392e-03, -2.4590e-01,  ..., -8.6974e-03,\n",
      "         -1.8679e-01, -1.2423e+00],\n",
      "        [-4.2666e-02, -1.7392e-03, -2.4590e-01,  ..., -8.6974e-03,\n",
      "         -1.8679e-01, -1.2423e+00],\n",
      "        [-4.2666e-02, -1.7392e-03, -2.4590e-01,  ..., -8.6974e-03,\n",
      "         -1.8679e-01, -1.2423e+00],\n",
      "        ...,\n",
      "        [-2.0950e-01,  2.8209e-01,  1.2043e-03,  ..., -6.6862e-01,\n",
      "          8.1310e-01, -3.4805e-01],\n",
      "        [-1.4217e-01, -9.6481e-02,  5.6704e-01,  ..., -2.7312e-01,\n",
      "          6.4004e-01,  2.3552e-01],\n",
      "        [-1.4217e-01, -9.6481e-02,  5.6704e-01,  ..., -2.7312e-01,\n",
      "          6.4004e-01,  2.3552e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-4.26657461e-02 -1.73917226e-03 -2.45898679e-01 -1.66098587e-02\n",
      " -1.07902810e-01 -5.73545575e-01 -1.55073911e-01 -3.20625395e-01\n",
      " -1.38919508e+00 -3.11991453e-01 -3.82259667e-01 -1.68388140e+00\n",
      " -4.69752133e-01 -4.73675162e-01 -2.18778062e+00 -2.37520739e-01\n",
      " -6.34800911e-01 -1.55100155e+00 -6.39822632e-02 -6.89862251e-01\n",
      " -1.38659298e+00 -1.13173038e-01 -6.10588908e-01 -1.44550645e+00\n",
      " -1.18404776e-01 -7.77751923e-01 -1.57382321e+00 -1.94783643e-01\n",
      " -5.48907638e-01 -1.45423520e+00 -1.34272754e-01 -5.97126365e-01\n",
      " -1.42885101e+00 -1.44622326e-01 -5.60705304e-01 -1.52011895e+00\n",
      "  7.93951750e-03 -5.87492108e-01 -1.53968310e+00 -1.11273147e-01\n",
      " -4.40233648e-01 -1.28922439e+00 -2.58100450e-01 -1.99578702e-01\n",
      " -2.04244161e+00 -7.33884797e-02 -3.66238326e-01 -2.06787658e+00\n",
      "  1.12427816e-01 -3.31116229e-01 -1.40517938e+00 -2.26304710e-01\n",
      " -2.11225614e-01 -1.21235561e+00 -1.61509618e-01 -1.78722993e-01\n",
      " -1.30842173e+00 -1.27539068e-01 -1.74776733e-01 -1.42820883e+00\n",
      " -8.69742781e-03 -1.86792955e-01 -1.24227250e+00]\n",
      "data: [-4.26657423e-02 -1.73917238e-03 -2.45898679e-01 -1.66098587e-02\n",
      " -1.07902810e-01 -5.73545575e-01 -1.55073911e-01 -3.20625395e-01\n",
      " -1.38919508e+00 -3.11991453e-01 -3.82259667e-01 -1.68388140e+00\n",
      " -4.69752133e-01 -4.73675162e-01 -2.18778062e+00 -2.37520739e-01\n",
      " -6.34800911e-01 -1.55100155e+00 -6.39822632e-02 -6.89862192e-01\n",
      " -1.38659298e+00 -1.13173038e-01 -6.10588908e-01 -1.44550645e+00\n",
      " -1.18404776e-01 -7.77751923e-01 -1.57382321e+00 -1.94783643e-01\n",
      " -5.48907638e-01 -1.45423520e+00 -1.34272754e-01 -5.97126365e-01\n",
      " -1.42885101e+00 -1.44622326e-01 -5.60705304e-01 -1.52011907e+00\n",
      "  7.93951750e-03 -5.87492108e-01 -1.53968310e+00 -1.11273147e-01\n",
      " -4.40233648e-01 -1.28922439e+00 -2.58100450e-01 -1.99578702e-01\n",
      " -2.04244161e+00 -7.33884797e-02 -3.66238326e-01 -2.06787658e+00\n",
      "  1.12427816e-01 -3.31116229e-01 -1.40517950e+00 -2.26304710e-01\n",
      " -2.11225599e-01 -1.21235561e+00 -1.61509603e-01 -1.78722993e-01\n",
      " -1.30842173e+00 -1.27539068e-01 -1.74776733e-01 -1.42820883e+00\n",
      " -8.69742781e-03 -1.86792940e-01 -1.24227250e+00  5.99999987e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0312, -0.0765, -0.1678,  ...,  0.0289, -0.2385, -1.2911],\n",
      "        [ 0.0312, -0.0765, -0.1678,  ...,  0.0289, -0.2385, -1.2911],\n",
      "        [ 0.0312, -0.0765, -0.1678,  ...,  0.0289, -0.2385, -1.2911],\n",
      "        ...,\n",
      "        [-0.3091,  0.2881, -0.2450,  ..., -0.8751,  0.7628, -0.3990],\n",
      "        [-0.2236, -0.1328,  0.4800,  ..., -0.3071,  0.6078,  0.2362],\n",
      "        [-0.2236, -0.1328,  0.4800,  ..., -0.3071,  0.6078,  0.2362]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 3.11994068e-02 -7.65322596e-02 -1.67797998e-01  4.16086800e-02\n",
      " -2.43273407e-01 -6.56704903e-01  2.13281065e-03 -3.80884945e-01\n",
      " -1.31450284e+00 -1.33517325e-01 -4.32792664e-01 -1.61552405e+00\n",
      " -3.19118887e-01 -5.62369704e-01 -2.06703758e+00 -1.90366060e-01\n",
      " -6.51465297e-01 -1.46605468e+00  7.03264773e-02 -6.45359755e-01\n",
      " -1.25125444e+00  2.60749906e-02 -5.91371059e-01 -1.30282009e+00\n",
      "  3.05773616e-02 -6.80458069e-01 -1.41066742e+00 -1.51592374e-01\n",
      " -5.32379746e-01 -1.39870167e+00 -3.86364534e-02 -5.83899617e-01\n",
      " -1.38458490e+00 -4.04859036e-02 -5.55373311e-01 -1.49093068e+00\n",
      "  8.41780752e-02 -5.69831967e-01 -1.56919539e+00 -5.42447194e-02\n",
      " -4.69678402e-01 -1.22766626e+00 -1.24220476e-01 -2.48293728e-01\n",
      " -1.72005117e+00 -1.69068575e-03 -3.77609104e-01 -1.69544256e+00\n",
      "  1.34566635e-01 -3.47558111e-01 -1.42814994e+00 -1.48338050e-01\n",
      " -2.24036351e-01 -1.18144596e+00 -5.88592887e-02 -2.06365287e-01\n",
      " -1.25631058e+00 -3.80094349e-03 -2.31829017e-01 -1.37684035e+00\n",
      "  2.88520381e-02 -2.38513187e-01 -1.29111528e+00]\n",
      "data: [ 3.11994068e-02 -7.65322596e-02 -1.67797998e-01  4.16086800e-02\n",
      " -2.43273407e-01 -6.56704843e-01  2.13281065e-03 -3.80884945e-01\n",
      " -1.31450284e+00 -1.33517325e-01 -4.32792664e-01 -1.61552393e+00\n",
      " -3.19118887e-01 -5.62369704e-01 -2.06703758e+00 -1.90366060e-01\n",
      " -6.51465297e-01 -1.46605468e+00  7.03264773e-02 -6.45359755e-01\n",
      " -1.25125444e+00  2.60749906e-02 -5.91371059e-01 -1.30282009e+00\n",
      "  3.05773616e-02 -6.80458069e-01 -1.41066742e+00 -1.51592374e-01\n",
      " -5.32379746e-01 -1.39870167e+00 -3.86364534e-02 -5.83899617e-01\n",
      " -1.38458490e+00 -4.04859036e-02 -5.55373311e-01 -1.49093068e+00\n",
      "  8.41780752e-02 -5.69831967e-01 -1.56919539e+00 -5.42447194e-02\n",
      " -4.69678432e-01 -1.22766626e+00 -1.24220476e-01 -2.48293728e-01\n",
      " -1.72005117e+00 -1.69068575e-03 -3.77609104e-01 -1.69544256e+00\n",
      "  1.34566635e-01 -3.47558111e-01 -1.42814982e+00 -1.48338050e-01\n",
      " -2.24036351e-01 -1.18144596e+00 -5.88592924e-02 -2.06365287e-01\n",
      " -1.25631058e+00 -3.80094349e-03 -2.31829017e-01 -1.37684035e+00\n",
      "  2.88520381e-02 -2.38513187e-01 -1.29111528e+00  7.00000003e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63E80>\n",
      "tensor([[ 0.0655, -0.1150, -0.3038,  ...,  0.0818, -0.2821, -1.3646],\n",
      "        [ 0.0655, -0.1150, -0.3038,  ...,  0.0818, -0.2821, -1.3646],\n",
      "        [ 0.0655, -0.1150, -0.3038,  ...,  0.0818, -0.2821, -1.3646],\n",
      "        ...,\n",
      "        [-0.1599,  0.4704, -0.0788,  ..., -0.7288,  0.9982, -0.4008],\n",
      "        [-0.1892, -0.0458,  0.6120,  ..., -0.2845,  0.7302,  0.2492],\n",
      "        [-0.1892, -0.0458,  0.6120,  ..., -0.2845,  0.7302,  0.2492]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.06546668 -0.11498398 -0.30381307  0.10278231 -0.24316955 -0.6963588\n",
      "  0.00725235 -0.4380828  -1.4960053  -0.13716939 -0.49699146 -1.7948709\n",
      " -0.2878753  -0.60425955 -2.2944996  -0.13730446 -0.7160206  -1.6758473\n",
      "  0.09081741 -0.75063175 -1.4806063   0.03828792 -0.6899804  -1.5305324\n",
      "  0.02319845 -0.8228215  -1.6558044  -0.09510043 -0.61523414 -1.5813286\n",
      " -0.01242242 -0.67121136 -1.5601075  -0.02040786 -0.63741887 -1.649436\n",
      "  0.10472298 -0.67492735 -1.6943688  -0.0038524  -0.5184866  -1.4054193\n",
      " -0.13602734 -0.28012228 -2.081515    0.03235457 -0.44778842 -2.0856903\n",
      "  0.18652576 -0.40755612 -1.541528   -0.12085802 -0.28303108 -1.3318784\n",
      " -0.03400563 -0.25232232 -1.4002273   0.01103594 -0.270841   -1.5166531\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.08183178 -0.2821222  -1.3646116 ]\n",
      "data: [ 0.06546668 -0.11498398 -0.30381307  0.10278231 -0.24316956 -0.6963588\n",
      "  0.00725235 -0.4380828  -1.4960053  -0.13716939 -0.49699146 -1.7948709\n",
      " -0.2878753  -0.60425955 -2.2944996  -0.13730446 -0.7160206  -1.6758473\n",
      "  0.09081741 -0.7506317  -1.4806064   0.03828792 -0.6899804  -1.5305324\n",
      "  0.02319845 -0.8228215  -1.6558044  -0.09510043 -0.61523414 -1.5813286\n",
      " -0.01242242 -0.6712114  -1.5601075  -0.02040786 -0.63741887 -1.649436\n",
      "  0.10472298 -0.67492735 -1.6943688  -0.0038524  -0.5184866  -1.4054193\n",
      " -0.13602734 -0.28012228 -2.081515    0.03235457 -0.44778842 -2.0856903\n",
      "  0.18652576 -0.40755612 -1.541528   -0.12085802 -0.28303108 -1.3318783\n",
      " -0.03400563 -0.25232232 -1.4002273   0.01103594 -0.270841   -1.5166532\n",
      "  0.08183178 -0.2821222  -1.3646116   0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[-0.0076, -0.1253, -0.2703,  ...,  0.0413, -0.3049, -1.3560],\n",
      "        [-0.0076, -0.1253, -0.2703,  ...,  0.0413, -0.3049, -1.3560],\n",
      "        [-0.0076, -0.1253, -0.2703,  ...,  0.0413, -0.3049, -1.3560],\n",
      "        ...,\n",
      "        [-0.0383,  0.4675, -0.0529,  ..., -0.6411,  0.9584, -0.2865],\n",
      "        [-0.0937, -0.0265,  0.5787,  ..., -0.1544,  0.6818,  0.2680],\n",
      "        [-0.0937, -0.0265,  0.5787,  ..., -0.1544,  0.6818,  0.2680]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.00755997 -0.12531357 -0.2703319   0.009091   -0.28835285 -0.70969695\n",
      " -0.00806255 -0.44171542 -1.4062178  -0.14451706 -0.49109393 -1.7353258\n",
      " -0.32442594 -0.64586174 -2.1963584  -0.22759615 -0.6991198  -1.6007388\n",
      "  0.09144472 -0.69898564 -1.3636259   0.01988102 -0.6538825  -1.4121685\n",
      "  0.01062983 -0.75125176 -1.5327023  -0.17223042 -0.5781017  -1.5102243\n",
      " -0.04627637 -0.64076257 -1.5096977  -0.05053729 -0.61721206 -1.618291\n",
      "  0.042014   -0.65692866 -1.68609    -0.04454117 -0.49985588 -1.3201082\n",
      " -0.14444341 -0.27715856 -1.8983668  -0.00391072 -0.4400983  -1.8661464\n",
      "  0.12657075 -0.40155315 -1.5200504  -0.16014224 -0.2591216  -1.2684239\n",
      " -0.02812514 -0.2509845  -1.3351114   0.01966299 -0.30124784 -1.450704\n",
      "  0.04132146 -0.3049353  -1.3559726 ]\n",
      "data: [-0.00755997 -0.12531357 -0.2703319   0.009091   -0.28835285 -0.70969695\n",
      " -0.00806255 -0.44171542 -1.4062178  -0.14451706 -0.49109393 -1.7353258\n",
      " -0.32442594 -0.64586174 -2.1963584  -0.22759615 -0.6991198  -1.6007389\n",
      "  0.09144471 -0.6989857  -1.363626    0.01988102 -0.6538825  -1.4121686\n",
      "  0.01062983 -0.75125176 -1.5327023  -0.17223042 -0.5781017  -1.5102243\n",
      " -0.04627637 -0.64076257 -1.5096977  -0.05053729 -0.61721206 -1.618291\n",
      "  0.042014   -0.65692866 -1.68609    -0.04454117 -0.49985588 -1.3201082\n",
      " -0.14444341 -0.27715856 -1.8983668  -0.00391072 -0.44009826 -1.8661464\n",
      "  0.12657075 -0.40155315 -1.5200504  -0.16014224 -0.2591216  -1.2684239\n",
      " -0.02812514 -0.2509845  -1.3351114   0.01966299 -0.30124784 -1.4507041\n",
      "  0.04132146 -0.3049353  -1.3559726   0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BB38>\n",
      "tensor([[ 0.0435, -0.1908, -0.2566,  ...,  0.0600, -0.3662, -1.3366],\n",
      "        [ 0.0435, -0.1908, -0.2566,  ...,  0.0600, -0.3662, -1.3366],\n",
      "        [ 0.0435, -0.1908, -0.2566,  ...,  0.0600, -0.3662, -1.3366],\n",
      "        ...,\n",
      "        [-0.1254,  0.5027, -0.1805,  ..., -0.6531,  0.9954, -0.4980],\n",
      "        [-0.1944, -0.0565,  0.6419,  ..., -0.2567,  0.6695,  0.3282],\n",
      "        [-0.1944, -0.0565,  0.6419,  ..., -0.2567,  0.6695,  0.3282]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 4.35033329e-02 -1.90793887e-01 -2.56612539e-01  7.16632903e-02\n",
      " -3.24056804e-01 -6.50462747e-01 -4.33474779e-03 -5.21879911e-01\n",
      " -1.43173599e+00 -1.49254411e-01 -5.80406070e-01 -1.74455190e+00\n",
      " -3.12719196e-01 -7.00015783e-01 -2.23211145e+00 -1.65224224e-01\n",
      " -7.97505856e-01 -1.62586522e+00  8.36509392e-02 -8.36772084e-01\n",
      " -1.42833209e+00  2.19672993e-02 -7.82432437e-01 -1.47441483e+00\n",
      "  7.13627785e-03 -9.19332027e-01 -1.59814143e+00 -1.15295090e-01\n",
      " -6.91387057e-01 -1.52536607e+00 -2.89357230e-02 -7.53804088e-01\n",
      " -1.50998878e+00 -3.46753150e-02 -7.28009582e-01 -1.60843277e+00\n",
      "  7.63888136e-02 -7.70775914e-01 -1.65673876e+00 -1.52012557e-02\n",
      " -5.90998709e-01 -1.34982371e+00 -1.54614031e-01 -3.61255646e-01\n",
      " -2.03950548e+00  1.42027885e-02 -5.35268426e-01 -2.03854799e+00\n",
      "  1.61348283e-01 -4.92754549e-01 -1.50475168e+00 -1.40051395e-01\n",
      " -3.53044629e-01 -1.27977467e+00 -4.24384549e-02 -3.30169618e-01\n",
      " -1.35727096e+00  5.98125160e-04 -3.59891236e-01 -1.47226262e+00\n",
      "  6.00387752e-02 -3.66225183e-01 -1.33658338e+00]\n",
      "data: [ 4.3503333e-02 -1.9079390e-01 -2.5661254e-01  7.1663290e-02\n",
      " -3.2405680e-01 -6.5046275e-01 -4.3347478e-03 -5.2187991e-01\n",
      " -1.4317360e+00 -1.4925441e-01 -5.8040607e-01 -1.7445519e+00\n",
      " -3.1271920e-01 -7.0001578e-01 -2.2321115e+00 -1.6522422e-01\n",
      " -7.9750586e-01 -1.6258652e+00  8.3650939e-02 -8.3677208e-01\n",
      " -1.4283321e+00  2.1967299e-02 -7.8243238e-01 -1.4744148e+00\n",
      "  7.1362783e-03 -9.1933203e-01 -1.5981414e+00 -1.1529508e-01\n",
      " -6.9138700e-01 -1.5253661e+00 -2.8935723e-02 -7.5380409e-01\n",
      " -1.5099887e+00 -3.4675315e-02 -7.2800958e-01 -1.6084328e+00\n",
      "  7.6388814e-02 -7.7077591e-01 -1.6567388e+00 -1.5201257e-02\n",
      " -5.9099871e-01 -1.3498237e+00 -1.5461403e-01 -3.6125565e-01\n",
      " -2.0395055e+00  1.4202788e-02 -5.3526843e-01 -2.0385480e+00\n",
      "  1.6134828e-01 -4.9275455e-01 -1.5047517e+00 -1.4005139e-01\n",
      " -3.5304463e-01 -1.2797747e+00 -4.2438455e-02 -3.3016959e-01\n",
      " -1.3572710e+00  5.9812516e-04 -3.5989124e-01 -1.4722626e+00\n",
      "  6.0038775e-02 -3.6622515e-01 -1.3365834e+00  1.0000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[ 0.0152, -0.1664, -0.2065,  ...,  0.0693, -0.3551, -1.2394],\n",
      "        [ 0.0152, -0.1664, -0.2065,  ...,  0.0693, -0.3551, -1.2394],\n",
      "        [ 0.0152, -0.1664, -0.2065,  ...,  0.0693, -0.3551, -1.2394],\n",
      "        ...,\n",
      "        [-0.0352,  0.5114, -0.1329,  ..., -0.5487,  1.0811, -0.5324],\n",
      "        [-0.0876,  0.0118,  0.6148,  ..., -0.1490,  0.6730,  0.2750],\n",
      "        [-0.0876,  0.0118,  0.6148,  ..., -0.1490,  0.6730,  0.2750]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.5235809e-02 -1.6644520e-01 -2.0649603e-01  4.4739898e-02\n",
      " -3.0019993e-01 -5.4402000e-01 -3.0535527e-02 -5.0499344e-01\n",
      " -1.3551202e+00 -1.8141119e-01 -5.6531221e-01 -1.6797731e+00\n",
      " -3.5691997e-01 -6.9980705e-01 -2.1683927e+00 -1.9904479e-01\n",
      " -7.7618027e-01 -1.5644221e+00  7.8493342e-02 -8.1728280e-01\n",
      " -1.3569460e+00  9.6478909e-03 -7.6739204e-01 -1.3978775e+00\n",
      " -8.6903572e-04 -9.0483594e-01 -1.5261219e+00 -1.3899273e-01\n",
      " -6.6674948e-01 -1.4521859e+00 -4.0165730e-02 -7.3733580e-01\n",
      " -1.4389062e+00 -3.7425667e-02 -7.1173346e-01 -1.5421319e+00\n",
      "  7.7321842e-02 -7.6483822e-01 -1.5911121e+00 -2.2687800e-02\n",
      " -5.6506222e-01 -1.2616541e+00 -1.7002803e-01 -3.3466354e-01\n",
      " -1.9779239e+00  1.3744369e-02 -5.2244329e-01 -1.9715357e+00\n",
      "  1.7512241e-01 -4.7767350e-01 -1.4200771e+00 -1.5862145e-01\n",
      " -3.2355869e-01 -1.1922851e+00 -3.9931908e-02 -3.0837312e-01\n",
      " -1.2648423e+00  6.4883679e-03 -3.4929764e-01 -1.3805354e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6.9282271e-02 -3.5508329e-01 -1.2394376e+00]\n",
      "data: [ 1.5235809e-02 -1.6644520e-01 -2.0649603e-01  4.4739898e-02\n",
      " -3.0019993e-01 -5.4402000e-01 -3.0535527e-02 -5.0499344e-01\n",
      " -1.3551202e+00 -1.8141119e-01 -5.6531221e-01 -1.6797731e+00\n",
      " -3.5691997e-01 -6.9980705e-01 -2.1683927e+00 -1.9904479e-01\n",
      " -7.7618027e-01 -1.5644221e+00  7.8493342e-02 -8.1728280e-01\n",
      " -1.3569460e+00  9.6478909e-03 -7.6739204e-01 -1.3978775e+00\n",
      " -8.6903572e-04 -9.0483594e-01 -1.5261219e+00 -1.3899273e-01\n",
      " -6.6674948e-01 -1.4521859e+00 -4.0165730e-02 -7.3733580e-01\n",
      " -1.4389062e+00 -3.7425667e-02 -7.1173346e-01 -1.5421319e+00\n",
      "  7.7321842e-02 -7.6483828e-01 -1.5911120e+00 -2.2687800e-02\n",
      " -5.6506222e-01 -1.2616541e+00 -1.7002803e-01 -3.3466354e-01\n",
      " -1.9779239e+00  1.3744368e-02 -5.2244329e-01 -1.9715357e+00\n",
      "  1.7512241e-01 -4.7767350e-01 -1.4200771e+00 -1.5862145e-01\n",
      " -3.2355869e-01 -1.1922851e+00 -3.9931908e-02 -3.0837312e-01\n",
      " -1.2648423e+00  6.4883679e-03 -3.4929764e-01 -1.3805355e+00\n",
      "  6.9282271e-02 -3.5508329e-01 -1.2394376e+00  1.1000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63EB8>\n",
      "tensor([[ 0.0165, -0.1070, -0.1724,  ...,  0.0395, -0.2961, -1.1676],\n",
      "        [ 0.0165, -0.1070, -0.1724,  ...,  0.0395, -0.2961, -1.1676],\n",
      "        [ 0.0165, -0.1070, -0.1724,  ...,  0.0395, -0.2961, -1.1676],\n",
      "        ...,\n",
      "        [-0.1246,  0.4546, -0.0918,  ..., -0.4409,  1.0126, -0.4865],\n",
      "        [-0.1023, -0.0290,  0.6449,  ..., -0.1836,  0.6545,  0.3019],\n",
      "        [-0.1023, -0.0290,  0.6449,  ..., -0.1836,  0.6545,  0.3019]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.65093727e-02 -1.07035235e-01 -1.72392473e-01  4.73191775e-02\n",
      " -2.13898405e-01 -4.54586565e-01 -9.26960781e-02 -4.50875342e-01\n",
      " -1.32664752e+00 -2.50685662e-01 -5.19104600e-01 -1.62020004e+00\n",
      " -3.99610072e-01 -6.14626646e-01 -2.13980103e+00 -1.83615625e-01\n",
      " -7.49246895e-01 -1.51641583e+00  1.80976093e-03 -8.17752361e-01\n",
      " -1.35741961e+00 -5.60066253e-02 -7.45715201e-01 -1.40399742e+00\n",
      " -6.78091943e-02 -9.11714792e-01 -1.53217983e+00 -1.37273416e-01\n",
      " -6.58588290e-01 -1.40945959e+00 -7.82177448e-02 -7.13784158e-01\n",
      " -1.38174748e+00 -8.60644132e-02 -6.75500333e-01 -1.46442688e+00\n",
      "  4.81721908e-02 -7.16045558e-01 -1.48113263e+00 -4.58912626e-02\n",
      " -5.40043831e-01 -1.24615836e+00 -2.11756229e-01 -3.02114010e-01\n",
      " -2.00723386e+00 -2.19610855e-02 -4.82012212e-01 -2.03080177e+00\n",
      "  1.53778940e-01 -4.36542213e-01 -1.34553671e+00 -1.77590102e-01\n",
      " -3.08834225e-01 -1.16462576e+00 -9.87019837e-02 -2.78570652e-01\n",
      " -1.24859560e+00 -6.76481426e-02 -2.86349535e-01 -1.35976851e+00\n",
      "  3.95378694e-02 -2.96075255e-01 -1.16764319e+00]\n",
      "data: [ 1.65093727e-02 -1.07035235e-01 -1.72392458e-01  4.73191775e-02\n",
      " -2.13898405e-01 -4.54586565e-01 -9.26960781e-02 -4.50875372e-01\n",
      " -1.32664752e+00 -2.50685662e-01 -5.19104600e-01 -1.62020004e+00\n",
      " -3.99610072e-01 -6.14626646e-01 -2.13980103e+00 -1.83615625e-01\n",
      " -7.49246895e-01 -1.51641583e+00  1.80976093e-03 -8.17752361e-01\n",
      " -1.35741961e+00 -5.60066253e-02 -7.45715201e-01 -1.40399754e+00\n",
      " -6.78091943e-02 -9.11714792e-01 -1.53217983e+00 -1.37273416e-01\n",
      " -6.58588231e-01 -1.40945959e+00 -7.82177448e-02 -7.13784158e-01\n",
      " -1.38174748e+00 -8.60644132e-02 -6.75500333e-01 -1.46442688e+00\n",
      "  4.81721908e-02 -7.16045558e-01 -1.48113263e+00 -4.58912626e-02\n",
      " -5.40043831e-01 -1.24615836e+00 -2.11756229e-01 -3.02114010e-01\n",
      " -2.00723386e+00 -2.19610855e-02 -4.82012212e-01 -2.03080177e+00\n",
      "  1.53778940e-01 -4.36542213e-01 -1.34553671e+00 -1.77590102e-01\n",
      " -3.08834225e-01 -1.16462576e+00 -9.87019837e-02 -2.78570652e-01\n",
      " -1.24859560e+00 -6.76481426e-02 -2.86349535e-01 -1.35976851e+00\n",
      "  3.95378694e-02 -2.96075255e-01 -1.16764319e+00  1.19999997e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BB38>\n",
      "tensor([[-0.0482, -0.0218, -0.2074,  ...,  0.0029, -0.2096, -1.1828],\n",
      "        [-0.0482, -0.0218, -0.2074,  ...,  0.0029, -0.2096, -1.1828],\n",
      "        [-0.0482, -0.0218, -0.2074,  ...,  0.0029, -0.2096, -1.1828],\n",
      "        ...,\n",
      "        [-0.1724,  0.3375,  0.0217,  ..., -0.6419,  0.9176, -0.3596],\n",
      "        [-0.0982, -0.0836,  0.5880,  ..., -0.2317,  0.6133,  0.2527],\n",
      "        [-0.0982, -0.0836,  0.5880,  ..., -0.2317,  0.6133,  0.2527]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.04816314 -0.02179962 -0.2073713  -0.0228404  -0.13246174 -0.50693274\n",
      " -0.1518175  -0.35342765 -1.3421276  -0.3053825  -0.41482428 -1.6393433\n",
      " -0.46539903 -0.5203273  -2.1346924  -0.25282717 -0.6532998  -1.5125501\n",
      " -0.04459475 -0.7081727  -1.3333552  -0.09569831 -0.6373086  -1.381233\n",
      " -0.09363155 -0.7941244  -1.511395   -0.20309225 -0.55874974 -1.4079821\n",
      " -0.12924957 -0.6135582  -1.3863466  -0.1208026  -0.57616735 -1.4739349\n",
      "  0.03067198 -0.61485445 -1.5038712  -0.10579505 -0.45099837 -1.237632\n",
      " -0.2603377  -0.20909014 -1.995192   -0.05944382 -0.38710526 -2.011543\n",
      "  0.13211666 -0.34280562 -1.360043   -0.23446372 -0.21607678 -1.1586622\n",
      " -0.14706251 -0.18710834 -1.2467139  -0.10553345 -0.19786294 -1.363353\n",
      "  0.00286939 -0.2096477  -1.1828227 ]\n",
      "data: [-0.04816314 -0.02179962 -0.2073713  -0.0228404  -0.13246174 -0.50693274\n",
      " -0.1518175  -0.35342765 -1.3421276  -0.3053825  -0.4148243  -1.6393433\n",
      " -0.46539903 -0.5203273  -2.1346924  -0.25282717 -0.6532998  -1.51255\n",
      " -0.04459475 -0.7081727  -1.3333553  -0.09569831 -0.6373086  -1.3812329\n",
      " -0.09363155 -0.7941244  -1.511395   -0.20309225 -0.55874974 -1.4079822\n",
      " -0.12924957 -0.6135582  -1.3863466  -0.1208026  -0.57616735 -1.4739349\n",
      "  0.03067198 -0.61485445 -1.5038712  -0.10579505 -0.4509984  -1.237632\n",
      " -0.2603377  -0.20909014 -1.995192   -0.05944382 -0.38710526 -2.011543\n",
      "  0.13211666 -0.34280562 -1.360043   -0.23446374 -0.21607678 -1.1586622\n",
      " -0.14706251 -0.18710834 -1.2467139  -0.10553345 -0.19786292 -1.363353\n",
      "  0.00286939 -0.2096477  -1.1828227   0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[-0.0146, -0.0819, -0.1982,  ..., -0.0029, -0.2397, -1.3138],\n",
      "        [-0.0146, -0.0819, -0.1982,  ..., -0.0029, -0.2397, -1.3138],\n",
      "        [-0.0146, -0.0819, -0.1982,  ..., -0.0029, -0.2397, -1.3138],\n",
      "        ...,\n",
      "        [-0.2632,  0.3078, -0.1764,  ..., -0.7532,  0.7876, -0.3882],\n",
      "        [-0.1799, -0.1230,  0.5423,  ..., -0.2775,  0.6258,  0.2573],\n",
      "        [-0.1799, -0.1230,  0.5423,  ..., -0.2775,  0.6258,  0.2573]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-1.45899765e-02 -8.19381177e-02 -1.98193699e-01 -6.92602247e-04\n",
      " -2.40073562e-01 -6.62375391e-01 -5.05674854e-02 -3.91505837e-01\n",
      " -1.34681034e+00 -1.92511976e-01 -4.43890959e-01 -1.65915298e+00\n",
      " -3.81346166e-01 -5.74406385e-01 -2.11673856e+00 -2.38766342e-01\n",
      " -6.65491462e-01 -1.50893617e+00  2.88071185e-02 -6.68588161e-01\n",
      " -1.28616834e+00 -1.83635950e-02 -6.15795135e-01 -1.33779311e+00\n",
      " -1.73751712e-02 -7.18973756e-01 -1.45446467e+00 -1.93549454e-01\n",
      " -5.47867179e-01 -1.43021798e+00 -8.41310918e-02 -6.03685975e-01\n",
      " -1.41952229e+00 -8.06363821e-02 -5.76231241e-01 -1.53197932e+00\n",
      "  5.14928848e-02 -5.99272132e-01 -1.60886431e+00 -9.31008533e-02\n",
      " -4.74570632e-01 -1.25151491e+00 -1.81904659e-01 -2.47922897e-01\n",
      " -1.81059194e+00 -3.87657061e-02 -3.89766276e-01 -1.79281259e+00\n",
      "  1.12530440e-01 -3.57577533e-01 -1.45764136e+00 -1.96796790e-01\n",
      " -2.26743072e-01 -1.20030856e+00 -1.03229418e-01 -2.06466883e-01\n",
      " -1.28124833e+00 -4.70414460e-02 -2.33597636e-01 -1.40569115e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -2.87459791e-03 -2.39719614e-01 -1.31380105e+00]\n",
      "data: [-1.45899765e-02 -8.19381177e-02 -1.98193699e-01 -6.92602247e-04\n",
      " -2.40073562e-01 -6.62375391e-01 -5.05674854e-02 -3.91505837e-01\n",
      " -1.34681034e+00 -1.92511976e-01 -4.43890959e-01 -1.65915298e+00\n",
      " -3.81346166e-01 -5.74406385e-01 -2.11673856e+00 -2.38766342e-01\n",
      " -6.65491462e-01 -1.50893617e+00  2.88071185e-02 -6.68588161e-01\n",
      " -1.28616834e+00 -1.83635950e-02 -6.15795135e-01 -1.33779311e+00\n",
      " -1.73751712e-02 -7.18973756e-01 -1.45446467e+00 -1.93549454e-01\n",
      " -5.47867179e-01 -1.43021810e+00 -8.41310918e-02 -6.03685975e-01\n",
      " -1.41952229e+00 -8.06363896e-02 -5.76231241e-01 -1.53197932e+00\n",
      "  5.14928848e-02 -5.99272132e-01 -1.60886431e+00 -9.31008533e-02\n",
      " -4.74570632e-01 -1.25151491e+00 -1.81904659e-01 -2.47922897e-01\n",
      " -1.81059194e+00 -3.87657061e-02 -3.89766276e-01 -1.79281271e+00\n",
      "  1.12530440e-01 -3.57577503e-01 -1.45764124e+00 -1.96796805e-01\n",
      " -2.26743072e-01 -1.20030856e+00 -1.03229418e-01 -2.06466883e-01\n",
      " -1.28124833e+00 -4.70414460e-02 -2.33597636e-01 -1.40569127e+00\n",
      " -2.87459791e-03 -2.39719614e-01 -1.31380117e+00  1.40000001e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0396, -0.1417, -0.2676,  ...,  0.0387, -0.3173, -1.3228],\n",
      "        [ 0.0396, -0.1417, -0.2676,  ...,  0.0387, -0.3173, -1.3228],\n",
      "        [ 0.0396, -0.1417, -0.2676,  ...,  0.0387, -0.3173, -1.3228],\n",
      "        ...,\n",
      "        [-0.2229,  0.4597, -0.1597,  ..., -0.7784,  0.9868, -0.4799],\n",
      "        [-0.1329, -0.0163,  0.6903,  ..., -0.2288,  0.7648,  0.3385],\n",
      "        [-0.1329, -0.0163,  0.6903,  ..., -0.2288,  0.7648,  0.3385]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03961344 -0.14167991 -0.26759464  0.07063653 -0.25900698 -0.6478001\n",
      " -0.0455507  -0.4557998  -1.4399999  -0.19467886 -0.518994   -1.7337723\n",
      " -0.3444252  -0.60897267 -2.2457643  -0.15453056 -0.7587272  -1.6106062\n",
      "  0.02328297 -0.8030784  -1.4434884  -0.03020714 -0.73468816 -1.5034572\n",
      " -0.04940262 -0.88622403 -1.6270552  -0.1175901  -0.6698388  -1.5217685\n",
      " -0.05804252 -0.7169578  -1.4997818  -0.08290258 -0.68372667 -1.5923218\n",
      "  0.04428293 -0.70987546 -1.6200515  -0.04242068 -0.5662559  -1.3578038\n",
      " -0.17387167 -0.3341304  -2.044808   -0.01692499 -0.48810232 -2.0652108\n",
      "  0.13558155 -0.457386   -1.4836226  -0.14693758 -0.33922184 -1.2861544\n",
      " -0.08568653 -0.30817187 -1.3695915  -0.05437109 -0.30583033 -1.4873075\n",
      "  0.03871151 -0.31727427 -1.3227668 ]\n",
      "data: [ 0.03961344 -0.14167991 -0.26759464  0.07063653 -0.25900698 -0.6478001\n",
      " -0.04555069 -0.4557998  -1.44       -0.19467886 -0.518994   -1.7337723\n",
      " -0.3444252  -0.60897267 -2.2457643  -0.15453056 -0.7587272  -1.6106062\n",
      "  0.02328298 -0.8030784  -1.4434884  -0.03020714 -0.73468816 -1.5034572\n",
      " -0.04940262 -0.88622403 -1.6270552  -0.1175901  -0.6698388  -1.5217685\n",
      " -0.05804252 -0.7169578  -1.4997818  -0.08290258 -0.68372667 -1.5923218\n",
      "  0.04428293 -0.70987546 -1.6200516  -0.04242068 -0.5662559  -1.3578038\n",
      " -0.17387167 -0.3341304  -2.044808   -0.01692499 -0.48810232 -2.0652108\n",
      "  0.13558155 -0.457386   -1.4836226  -0.14693758 -0.33922184 -1.2861543\n",
      " -0.08568653 -0.30817187 -1.3695915  -0.05437109 -0.30583033 -1.4873075\n",
      "  0.03871151 -0.31727427 -1.3227668   0.15      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0132, -0.0812, -0.1919,  ...,  0.0842, -0.2817, -1.1950],\n",
      "        [ 0.0132, -0.0812, -0.1919,  ...,  0.0842, -0.2817, -1.1950],\n",
      "        [ 0.0132, -0.0812, -0.1919,  ...,  0.0842, -0.2817, -1.1950],\n",
      "        ...,\n",
      "        [-0.1393,  0.3980, -0.0867,  ..., -0.8104,  0.9134, -0.3708],\n",
      "        [-0.1284, -0.1013,  0.5660,  ..., -0.2306,  0.5752,  0.2230],\n",
      "        [-0.1284, -0.1013,  0.5660,  ..., -0.2306,  0.5752,  0.2230]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01315248 -0.08121764 -0.19194737  0.04029853 -0.20589449 -0.5196885\n",
      " -0.04565675 -0.4070153  -1.3165398  -0.1918777  -0.46578255 -1.6296818\n",
      " -0.3588831  -0.5932627  -2.1115384  -0.19010304 -0.69308436 -1.5077069\n",
      "  0.06058419 -0.7365037  -1.3298655  -0.00366163 -0.6811825  -1.3746972\n",
      " -0.00266008 -0.82589674 -1.4992568  -0.13067444 -0.5921018  -1.4020522\n",
      " -0.03855221 -0.65756047 -1.3892026  -0.03666729 -0.6332059  -1.4871545\n",
      "  0.08501951 -0.6816573  -1.5285239  -0.02160274 -0.49310744 -1.21942\n",
      " -0.16469607 -0.2627068  -1.9527915   0.02177212 -0.44691283 -1.9530802\n",
      "  0.18663916 -0.40798482 -1.3697579  -0.14790457 -0.25771058 -1.150662\n",
      " -0.03778933 -0.242365   -1.2317367   0.0072339  -0.27273372 -1.347966\n",
      "  0.08418373 -0.28166288 -1.1950419 ]\n",
      "data: [ 0.01315248 -0.08121764 -0.19194737  0.04029853 -0.20589449 -0.5196885\n",
      " -0.04565675 -0.4070153  -1.3165398  -0.1918777  -0.46578255 -1.6296818\n",
      " -0.35888308 -0.5932627  -2.1115384  -0.19010304 -0.69308436 -1.5077069\n",
      "  0.06058419 -0.7365038  -1.3298655  -0.00366163 -0.6811825  -1.3746972\n",
      " -0.00266008 -0.82589674 -1.4992568  -0.13067444 -0.5921018  -1.4020522\n",
      " -0.03855221 -0.6575605  -1.3892026  -0.03666729 -0.6332059  -1.4871545\n",
      "  0.08501951 -0.6816573  -1.5285239  -0.02160274 -0.49310744 -1.21942\n",
      " -0.16469607 -0.2627068  -1.9527915   0.02177212 -0.44691285 -1.9530802\n",
      "  0.18663916 -0.40798482 -1.3697579  -0.14790457 -0.25771058 -1.150662\n",
      " -0.03778933 -0.242365   -1.2317367   0.0072339  -0.27273372 -1.347966\n",
      "  0.08418373 -0.28166288 -1.1950419   0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 8.5224e-04, -7.8399e-02, -1.9320e-01,  ...,  4.0403e-02,\n",
      "         -2.7621e-01, -1.1826e+00],\n",
      "        [ 8.5224e-04, -7.8399e-02, -1.9320e-01,  ...,  4.0403e-02,\n",
      "         -2.7621e-01, -1.1826e+00],\n",
      "        [ 8.5224e-04, -7.8399e-02, -1.9320e-01,  ...,  4.0403e-02,\n",
      "         -2.7621e-01, -1.1826e+00],\n",
      "        ...,\n",
      "        [-1.8277e-01,  3.6679e-01, -1.2091e-01,  ..., -7.2061e-01,\n",
      "          8.7814e-01, -4.0790e-01],\n",
      "        [-1.3722e-01, -5.4070e-02,  5.8343e-01,  ..., -2.2816e-01,\n",
      "          7.0533e-01,  2.0072e-01],\n",
      "        [-1.3722e-01, -5.4070e-02,  5.8343e-01,  ..., -2.2816e-01,\n",
      "          7.0533e-01,  2.0072e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 8.5223932e-04 -7.8399010e-02 -1.9320168e-01  3.6879908e-02\n",
      " -1.7653500e-01 -5.0008857e-01 -1.1148516e-01 -4.0650409e-01\n",
      " -1.3577313e+00 -2.6347265e-01 -4.7477412e-01 -1.6454487e+00\n",
      " -4.0738407e-01 -5.6166428e-01 -2.1590123e+00 -1.8375359e-01\n",
      " -7.1683651e-01 -1.5239248e+00 -2.1448120e-02 -7.8565133e-01\n",
      " -1.3721242e+00 -7.3621646e-02 -7.0900983e-01 -1.4266205e+00\n",
      " -8.7982193e-02 -8.8519847e-01 -1.5535216e+00 -1.3972874e-01\n",
      " -6.3637620e-01 -1.4215271e+00 -8.9248650e-02 -6.8844700e-01\n",
      " -1.3934653e+00 -1.0541472e-01 -6.5337270e-01 -1.4745390e+00\n",
      "  3.5065338e-02 -6.8701100e-01 -1.4892888e+00 -6.1380066e-02\n",
      " -5.2423489e-01 -1.2591884e+00 -2.2168925e-01 -2.8321370e-01\n",
      " -2.0500894e+00 -3.0836962e-02 -4.5961726e-01 -2.0799489e+00\n",
      "  1.4321223e-01 -4.2153502e-01 -1.3546476e+00 -1.7865212e-01\n",
      " -2.9967213e-01 -1.1769586e+00 -1.1424990e-01 -2.6668382e-01\n",
      " -1.2690487e+00 -7.9283625e-02 -2.6309127e-01 -1.3835750e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4.0402837e-02 -2.7621102e-01 -1.1826165e+00]\n",
      "data: [ 8.5223926e-04 -7.8399010e-02 -1.9320168e-01  3.6879908e-02\n",
      " -1.7653500e-01 -5.0008857e-01 -1.1148515e-01 -4.0650409e-01\n",
      " -1.3577313e+00 -2.6347265e-01 -4.7477412e-01 -1.6454486e+00\n",
      " -4.0738407e-01 -5.6166428e-01 -2.1590123e+00 -1.8375358e-01\n",
      " -7.1683657e-01 -1.5239248e+00 -2.1448120e-02 -7.8565133e-01\n",
      " -1.3721242e+00 -7.3621646e-02 -7.0900989e-01 -1.4266205e+00\n",
      " -8.7982200e-02 -8.8519841e-01 -1.5535216e+00 -1.3972874e-01\n",
      " -6.3637620e-01 -1.4215271e+00 -8.9248650e-02 -6.8844694e-01\n",
      " -1.3934653e+00 -1.0541472e-01 -6.5337270e-01 -1.4745390e+00\n",
      "  3.5065338e-02 -6.8701100e-01 -1.4892888e+00 -6.1380066e-02\n",
      " -5.2423489e-01 -1.2591884e+00 -2.2168927e-01 -2.8321370e-01\n",
      " -2.0500894e+00 -3.0836962e-02 -4.5961726e-01 -2.0799489e+00\n",
      "  1.4321223e-01 -4.2153504e-01 -1.3546476e+00 -1.7865211e-01\n",
      " -2.9967213e-01 -1.1769586e+00 -1.1424990e-01 -2.6668382e-01\n",
      " -1.2690487e+00 -7.9283625e-02 -2.6309127e-01 -1.3835750e+00\n",
      "  4.0402837e-02 -2.7621102e-01 -1.1826165e+00  1.7000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[-0.0197,  0.0135, -0.1869,  ...,  0.0252, -0.1740, -1.1828],\n",
      "        [-0.0197,  0.0135, -0.1869,  ...,  0.0252, -0.1740, -1.1828],\n",
      "        [-0.0197,  0.0135, -0.1869,  ...,  0.0252, -0.1740, -1.1828],\n",
      "        ...,\n",
      "        [-0.1804,  0.2990, -0.0203,  ..., -0.7587,  0.8506, -0.3621],\n",
      "        [-0.1235, -0.1510,  0.5574,  ..., -0.2460,  0.5683,  0.2086],\n",
      "        [-0.1235, -0.1510,  0.5574,  ..., -0.2460,  0.5683,  0.2086]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-1.97181888e-02  1.34532396e-02 -1.86891735e-01  1.24700740e-03\n",
      " -1.04115382e-01 -5.11500239e-01 -1.23163290e-01 -3.16214889e-01\n",
      " -1.32735085e+00 -2.76359230e-01 -3.78287882e-01 -1.62636709e+00\n",
      " -4.44514483e-01 -4.82384026e-01 -2.11736655e+00 -2.23870993e-01\n",
      " -6.15915358e-01 -1.49511373e+00 -2.12603807e-02 -6.64759934e-01\n",
      " -1.31334519e+00 -6.84422255e-02 -5.94784737e-01 -1.36502230e+00\n",
      " -6.45759404e-02 -7.49602973e-01 -1.49255288e+00 -1.76485345e-01\n",
      " -5.18425882e-01 -1.39548671e+00 -1.01313189e-01 -5.72820485e-01\n",
      " -1.37006664e+00 -9.71903130e-02 -5.39695024e-01 -1.46404386e+00\n",
      "  5.81914634e-02 -5.71029782e-01 -1.49910414e+00 -8.39058384e-02\n",
      " -4.15894389e-01 -1.22457957e+00 -2.27079615e-01 -1.79943800e-01\n",
      " -1.95825291e+00 -3.64166647e-02 -3.49255443e-01 -1.97321141e+00\n",
      "  1.53153569e-01 -3.10163617e-01 -1.35252333e+00 -2.03864872e-01\n",
      " -1.79986760e-01 -1.14958167e+00 -1.24493316e-01 -1.53269961e-01\n",
      " -1.23662198e+00 -8.12588930e-02 -1.61399275e-01 -1.35600102e+00\n",
      "  2.51779184e-02 -1.74044117e-01 -1.18277335e+00]\n",
      "data: [-1.97181888e-02  1.34532396e-02 -1.86891735e-01  1.24700740e-03\n",
      " -1.04115382e-01 -5.11500239e-01 -1.23163290e-01 -3.16214889e-01\n",
      " -1.32735097e+00 -2.76359230e-01 -3.78287882e-01 -1.62636709e+00\n",
      " -4.44514453e-01 -4.82384026e-01 -2.11736655e+00 -2.23871008e-01\n",
      " -6.15915358e-01 -1.49511373e+00 -2.12603807e-02 -6.64759874e-01\n",
      " -1.31334519e+00 -6.84422255e-02 -5.94784737e-01 -1.36502230e+00\n",
      " -6.45759404e-02 -7.49602973e-01 -1.49255300e+00 -1.76485345e-01\n",
      " -5.18425882e-01 -1.39548671e+00 -1.01313189e-01 -5.72820485e-01\n",
      " -1.37006664e+00 -9.71903130e-02 -5.39695024e-01 -1.46404386e+00\n",
      "  5.81914634e-02 -5.71029782e-01 -1.49910414e+00 -8.39058384e-02\n",
      " -4.15894389e-01 -1.22457957e+00 -2.27079615e-01 -1.79943815e-01\n",
      " -1.95825291e+00 -3.64166647e-02 -3.49255443e-01 -1.97321141e+00\n",
      "  1.53153569e-01 -3.10163617e-01 -1.35252333e+00 -2.03864872e-01\n",
      " -1.79986760e-01 -1.14958167e+00 -1.24493316e-01 -1.53269961e-01\n",
      " -1.23662198e+00 -8.12588856e-02 -1.61399275e-01 -1.35600102e+00\n",
      "  2.51779184e-02 -1.74044117e-01 -1.18277335e+00  1.80000007e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[ 1.2829e-03, -1.3294e-01, -2.1069e-01,  ...,  2.9892e-02,\n",
      "         -2.8742e-01, -1.3381e+00],\n",
      "        [ 1.2829e-03, -1.3294e-01, -2.1069e-01,  ...,  2.9892e-02,\n",
      "         -2.8742e-01, -1.3381e+00],\n",
      "        [ 1.2829e-03, -1.3294e-01, -2.1069e-01,  ...,  2.9892e-02,\n",
      "         -2.8742e-01, -1.3381e+00],\n",
      "        ...,\n",
      "        [-2.5032e-01,  3.6200e-01, -1.9690e-01,  ..., -7.4014e-01,\n",
      "          7.8549e-01, -3.5198e-01],\n",
      "        [-1.7741e-01, -8.3254e-02,  5.2805e-01,  ..., -2.6470e-01,\n",
      "          6.8291e-01,  2.2540e-01],\n",
      "        [-1.7741e-01, -8.3254e-02,  5.2805e-01,  ..., -2.6470e-01,\n",
      "          6.8291e-01,  2.2540e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.2829043e-03 -1.3294348e-01 -2.1068799e-01  1.6536672e-02\n",
      " -3.0102080e-01 -6.9516468e-01 -2.1230519e-02 -4.4273826e-01\n",
      " -1.3630860e+00 -1.6029474e-01 -4.9360102e-01 -1.6738399e+00\n",
      " -3.4115446e-01 -6.3448483e-01 -2.1316009e+00 -2.2438352e-01\n",
      " -7.0813394e-01 -1.5216587e+00  6.4589605e-02 -6.9967598e-01\n",
      " -1.2748746e+00  1.1334240e-02 -6.4505929e-01 -1.3271581e+00\n",
      "  3.4293383e-03 -7.3442352e-01 -1.4445649e+00 -1.7913209e-01\n",
      " -5.8976829e-01 -1.4502238e+00 -5.6489773e-02 -6.4290625e-01\n",
      " -1.4416200e+00 -5.7853207e-02 -6.0762918e-01 -1.5488291e+00\n",
      "  6.2204063e-02 -6.3231480e-01 -1.6233438e+00 -6.6937976e-02\n",
      " -5.1932418e-01 -1.2718875e+00 -1.4100999e-01 -2.9067746e-01\n",
      " -1.7833563e+00 -9.7936913e-03 -4.2923588e-01 -1.7566668e+00\n",
      "  1.3166581e-01 -3.9459568e-01 -1.4828963e+00 -1.6790545e-01\n",
      " -2.7371228e-01 -1.2245429e+00 -6.0623646e-02 -2.5358951e-01\n",
      " -1.3040155e+00 -4.9864203e-03 -2.8512239e-01 -1.4279411e+00\n",
      "  2.9891960e-02 -2.8742325e-01 -1.3380738e+00]\n",
      "data: [ 1.2829043e-03 -1.3294348e-01 -2.1068799e-01  1.6536672e-02\n",
      " -3.0102080e-01 -6.9516462e-01 -2.1230519e-02 -4.4273826e-01\n",
      " -1.3630860e+00 -1.6029474e-01 -4.9360102e-01 -1.6738399e+00\n",
      " -3.4115446e-01 -6.3448483e-01 -2.1316009e+00 -2.2438353e-01\n",
      " -7.0813394e-01 -1.5216587e+00  6.4589605e-02 -6.9967598e-01\n",
      " -1.2748746e+00  1.1334240e-02 -6.4505929e-01 -1.3271581e+00\n",
      "  3.4293383e-03 -7.3442352e-01 -1.4445649e+00 -1.7913207e-01\n",
      " -5.8976829e-01 -1.4502238e+00 -5.6489773e-02 -6.4290625e-01\n",
      " -1.4416200e+00 -5.7853207e-02 -6.0762918e-01 -1.5488291e+00\n",
      "  6.2204067e-02 -6.3231480e-01 -1.6233438e+00 -6.6937976e-02\n",
      " -5.1932418e-01 -1.2718875e+00 -1.4100999e-01 -2.9067746e-01\n",
      " -1.7833563e+00 -9.7936913e-03 -4.2923588e-01 -1.7566667e+00\n",
      "  1.3166581e-01 -3.9459568e-01 -1.4828963e+00 -1.6790545e-01\n",
      " -2.7371228e-01 -1.2245429e+00 -6.0623646e-02 -2.5358951e-01\n",
      " -1.3040155e+00 -4.9864203e-03 -2.8512239e-01 -1.4279411e+00\n",
      "  2.9891960e-02 -2.8742325e-01 -1.3380738e+00  1.9000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0422, -0.1444, -0.2736,  ...,  0.0638, -0.3182, -1.3356],\n",
      "        [ 0.0422, -0.1444, -0.2736,  ...,  0.0638, -0.3182, -1.3356],\n",
      "        [ 0.0422, -0.1444, -0.2736,  ...,  0.0638, -0.3182, -1.3356],\n",
      "        ...,\n",
      "        [-0.1383,  0.5005, -0.1485,  ..., -0.6849,  1.0352, -0.5008],\n",
      "        [-0.1990, -0.0693,  0.6428,  ..., -0.3057,  0.6771,  0.2816],\n",
      "        [-0.1990, -0.0693,  0.6428,  ..., -0.3057,  0.6771,  0.2816]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04218609 -0.14441042 -0.27355197  0.07454577 -0.27236432 -0.65258443\n",
      " -0.01590193 -0.47786817 -1.4521102  -0.16181186 -0.53901064 -1.7574829\n",
      " -0.31774026 -0.65102625 -2.253364   -0.16292511 -0.7556467  -1.6413183\n",
      "  0.07382531 -0.7992718  -1.4440234   0.0150269  -0.7415458  -1.4889755\n",
      " -0.0037184  -0.88245845 -1.6139505  -0.1143337  -0.65350235 -1.5407908\n",
      " -0.03194349 -0.7143899  -1.5201077  -0.03917176 -0.6832266  -1.6121508\n",
      "  0.07707128 -0.7277843  -1.655567   -0.01647487 -0.5488543  -1.368468\n",
      " -0.15923454 -0.31571895 -2.0674634   0.0140106  -0.4906502  -2.0718057\n",
      "  0.16517965 -0.4464669  -1.508409   -0.14093111 -0.3121518  -1.2940348\n",
      " -0.04668091 -0.2847489  -1.3689501  -0.00398026 -0.309957   -1.4838266\n",
      "  0.06383391 -0.31817335 -1.3356178 ]\n",
      "data: [ 0.04218609 -0.14441042 -0.27355197  0.07454577 -0.27236432 -0.65258443\n",
      " -0.01590193 -0.47786817 -1.4521102  -0.16181187 -0.53901064 -1.7574829\n",
      " -0.31774026 -0.65102625 -2.253364   -0.16292511 -0.75564665 -1.6413183\n",
      "  0.07382531 -0.7992718  -1.4440235   0.0150269  -0.7415458  -1.4889755\n",
      " -0.0037184  -0.88245845 -1.6139505  -0.1143337  -0.65350235 -1.5407909\n",
      " -0.03194349 -0.71439    -1.5201077  -0.03917176 -0.68322664 -1.6121507\n",
      "  0.07707128 -0.7277843  -1.655567   -0.01647487 -0.5488543  -1.368468\n",
      " -0.15923454 -0.31571895 -2.0674634   0.0140106  -0.4906502  -2.0718057\n",
      "  0.16517965 -0.4464669  -1.508409   -0.14093111 -0.3121518  -1.2940348\n",
      " -0.04668091 -0.2847489  -1.3689502  -0.00398026 -0.309957   -1.4838266\n",
      "  0.06383391 -0.31817335 -1.3356178   0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.209 3.212 3.202 ... 3.208 3.197 3.195]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " [3.194 3.202 3.19  ... 3.192 3.18  3.179]\n",
      " ...\n",
      " [2.841 2.897 2.874 ... 2.902 2.904 2.908]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]\n",
      " [2.833 2.872 2.87  ... 2.896 2.898 2.904]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3F208>\n",
      "tensor([[-0.0061, -0.1097, -0.2057,  ...,  0.0734, -0.3060, -1.2508],\n",
      "        [-0.0061, -0.1097, -0.2057,  ...,  0.0734, -0.3060, -1.2508],\n",
      "        [-0.0061, -0.1097, -0.2057,  ...,  0.0734, -0.3060, -1.2508],\n",
      "        ...,\n",
      "        [-0.1132,  0.4721, -0.1400,  ..., -0.7650,  0.9895, -0.4209],\n",
      "        [-0.1273, -0.0541,  0.5891,  ..., -0.2075,  0.6363,  0.2230],\n",
      "        [-0.1273, -0.0541,  0.5891,  ..., -0.2075,  0.6363,  0.2230]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.00605021 -0.10968094 -0.20574751  0.01544496 -0.2557404  -0.5837827\n",
      " -0.03246776 -0.43599045 -1.3406085  -0.17678374 -0.49225786 -1.6689837\n",
      " -0.36280912 -0.64262843 -2.132554   -0.22440386 -0.7009398  -1.5416709\n",
      "  0.08027011 -0.7262405  -1.32963     0.0154499  -0.6806866  -1.3698306\n",
      "  0.02081069 -0.80092347 -1.4915838  -0.15876119 -0.5849569  -1.435209\n",
      " -0.04120638 -0.65854573 -1.426724   -0.02886239 -0.63983107 -1.5357238\n",
      "  0.08802997 -0.6886368  -1.6024752  -0.03516955 -0.5028051  -1.238115\n",
      " -0.15620506 -0.2751658  -1.8944892   0.0179093  -0.45653835 -1.872629\n",
      "  0.17790353 -0.41718033 -1.4247476  -0.16343036 -0.25634795 -1.1772077\n",
      " -0.0318694  -0.24793243 -1.249069    0.0270271  -0.2993979  -1.3649449\n",
      "  0.07337331 -0.30596602 -1.250823  ]\n",
      "data: [ 4.990e+00  7.000e-01 -7.940e+00  5.070e+00  5.100e-01 -7.210e+00\n",
      "  5.130e+00  3.800e-01 -6.700e+00  5.590e+00  0.000e+00 -2.430e+00\n",
      "  5.410e+00  0.000e+00 -2.180e+00  5.100e+00  3.500e-01 -6.700e+00\n",
      "  5.690e+00 -9.000e-02 -2.570e+00  5.530e+00 -1.000e-02 -2.230e+00\n",
      "  5.420e+00  2.000e-02 -2.010e+00  5.750e+00  2.200e-01 -2.410e+00\n",
      "  5.580e+00  8.000e-02 -2.050e+00  5.530e+00  1.600e-01 -1.660e+00\n",
      "  7.870e+00 -1.010e+00  1.311e+01  5.730e+00  2.400e-01 -1.940e+00\n",
      "  7.880e+00 -5.600e-01  1.228e+01  5.550e+00  2.100e-01 -1.660e+00\n",
      "  7.820e+00 -1.050e+00  1.298e+01  5.830e+00  5.400e-01 -1.460e+00\n",
      "  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00  0.000e+00\n",
      "  7.880e+00 -5.600e-01  1.228e+01  0.000e+00]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[-0.1070,  0.0335, -0.2282,  ..., -0.6499, -0.1895, -1.0337],\n",
      "        [-0.1070,  0.0335, -0.2282,  ..., -0.6499, -0.1895, -1.0337],\n",
      "        [-0.1070,  0.0335, -0.2282,  ..., -0.6499, -0.1895, -1.0337],\n",
      "        ...,\n",
      "        [ 0.7558,  0.3770,  0.3194,  ...,  0.7572,  0.4594,  1.4537],\n",
      "        [ 0.7780, -0.0845,  0.0029,  ...,  1.4096,  0.4201, -0.5211],\n",
      "        [ 0.7780, -0.0845,  0.0029,  ...,  1.4096,  0.4201, -0.5211]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.10695712  0.03345665 -0.22819631 -0.32735723 -0.13462637 -0.7280887\n",
      " -0.3693644  -0.21939017 -0.9233306  -0.51104903 -0.33141372 -0.98685217\n",
      " -0.6116402  -0.38894945 -1.1375821  -0.5169359  -0.24898851 -1.2827344\n",
      " -0.49922743 -0.31723747 -1.0560925  -0.6071109  -0.4657171  -1.0546918\n",
      " -0.6859132  -0.43486145 -1.1231503  -0.54057384 -0.1560747  -1.2853764\n",
      " -0.6412467  -0.2558036  -1.3148772  -0.6810209  -0.33235934 -1.3416147\n",
      " -0.7391912  -0.42926198 -1.2880805  -0.50793576 -0.07685468 -1.254671\n",
      " -0.6023536  -0.2035326  -0.97150767 -0.6957198  -0.23280558 -0.9626942\n",
      " -0.6824906  -0.32326478 -1.1567602  -0.5148235   0.03249151 -1.1298449\n",
      " -0.5267403  -0.05914073 -1.061424   -0.6134176  -0.12518632 -1.0343738\n",
      " -0.649928   -0.18948953 -1.0336742 ]\n",
      "init: [-0.10695712  0.03345665 -0.22819631 -0.32735723 -0.13462637 -0.7280887\n",
      " -0.3693644  -0.21939017 -0.9233306  -0.51104903 -0.33141372 -0.98685217\n",
      " -0.6116402  -0.38894945 -1.1375821  -0.5169359  -0.24898851 -1.2827344\n",
      " -0.49922743 -0.31723747 -1.0560925  -0.6071109  -0.4657171  -1.0546918\n",
      " -0.6859132  -0.43486145 -1.1231503  -0.54057384 -0.1560747  -1.2853764\n",
      " -0.6412467  -0.2558036  -1.3148772  -0.6810209  -0.33235934 -1.3416147\n",
      " -0.7391912  -0.42926198 -1.2880805  -0.50793576 -0.07685468 -1.254671\n",
      " -0.6023536  -0.2035326  -0.97150767 -0.6957198  -0.23280558 -0.9626942\n",
      " -0.6824906  -0.32326478 -1.1567602  -0.5148235   0.03249151 -1.1298449\n",
      " -0.5267403  -0.05914073 -1.061424   -0.6134176  -0.12518632 -1.0343738\n",
      " -0.649928   -0.18948953 -1.0336742 ]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [-0.10695712  0.03345665 -0.22819632 -0.3273572  -0.13462637 -0.7280887\n",
      " -0.36936438 -0.21939017 -0.9233306  -0.51104903 -0.33141372 -0.98685217\n",
      " -0.6116402  -0.38894948 -1.1375821  -0.5169359  -0.24898851 -1.2827344\n",
      " -0.49922743 -0.31723747 -1.0560925  -0.6071109  -0.46571714 -1.0546918\n",
      " -0.68591326 -0.43486145 -1.1231503  -0.54057384 -0.1560747  -1.2853764\n",
      " -0.6412466  -0.2558036  -1.3148772  -0.6810209  -0.33235934 -1.3416147\n",
      " -0.73919123 -0.42926198 -1.2880805  -0.50793576 -0.07685468 -1.254671\n",
      " -0.6023536  -0.2035326  -0.97150767 -0.6957198  -0.23280558 -0.9626942\n",
      " -0.6824906  -0.32326478 -1.1567602  -0.5148235   0.03249151 -1.1298449\n",
      " -0.5267403  -0.05914073 -1.061424   -0.6134176  -0.12518632 -1.0343738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -0.649928   -0.18948954 -1.0336742   0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63668>\n",
      "tensor([[ 0.0233, -0.2528, -0.0385,  ...,  0.4231, -0.3868, -1.1501],\n",
      "        [ 0.0233, -0.2528, -0.0385,  ...,  0.4231, -0.3868, -1.1501],\n",
      "        [ 0.0233, -0.2528, -0.0385,  ...,  0.4231, -0.3868, -1.1501],\n",
      "        ...,\n",
      "        [ 0.0656,  0.5390,  0.1152,  ..., -0.6761,  1.3183,  0.0949],\n",
      "        [-0.1411,  0.2685,  0.2919,  ..., -1.0776,  0.4609,  0.3565],\n",
      "        [-0.1411,  0.2685,  0.2919,  ..., -1.0776,  0.4609,  0.3565]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02332719 -0.25276494 -0.03849489  0.12804966 -0.3140055  -0.43381086\n",
      "  0.05913451 -0.35457724 -1.1638945  -0.03756477 -0.32492778 -1.460992\n",
      " -0.14720976 -0.41226056 -1.9325199  -0.16446725 -0.64649826 -1.3489339\n",
      "  0.09896666 -0.6037252  -1.3158002   0.07822752 -0.50316435 -1.3936878\n",
      "  0.10452905 -0.57806087 -1.4963995  -0.08307856 -0.6492764  -1.2742153\n",
      "  0.10507001 -0.6924625  -1.3574914   0.1382848  -0.59939843 -1.5199082\n",
      "  0.29878086 -0.601087   -1.5779762   0.0437619  -0.62256426 -1.0556659\n",
      "  0.09610638 -0.4200282  -1.5532088   0.30048966 -0.5137223  -1.562293\n",
      "  0.47070217 -0.45763233 -1.430359    0.02758172 -0.49269375 -1.0051409\n",
      "  0.16373427 -0.46045756 -1.1080816   0.30015308 -0.4640935  -1.261928\n",
      "  0.42306015 -0.38682508 -1.1501276 ]\n",
      "data: [ 0.02332719 -0.25276494 -0.03849489  0.12804966 -0.3140055  -0.43381083\n",
      "  0.05913451 -0.35457724 -1.1638945  -0.03756477 -0.32492778 -1.460992\n",
      " -0.14720976 -0.41226056 -1.9325198  -0.16446725 -0.64649826 -1.3489338\n",
      "  0.09896666 -0.6037252  -1.3158002   0.07822752 -0.50316435 -1.3936878\n",
      "  0.10452905 -0.57806087 -1.4963995  -0.08307856 -0.6492764  -1.2742153\n",
      "  0.10507001 -0.69246256 -1.3574913   0.1382848  -0.59939843 -1.5199082\n",
      "  0.29878086 -0.601087   -1.5779762   0.0437619  -0.62256426 -1.0556659\n",
      "  0.09610638 -0.42002824 -1.5532088   0.30048966 -0.5137223  -1.562293\n",
      "  0.47070217 -0.45763233 -1.430359    0.02758172 -0.49269375 -1.0051409\n",
      "  0.16373426 -0.46045756 -1.1080816   0.30015308 -0.4640935  -1.261928\n",
      "  0.42306015 -0.3868251  -1.1501276   0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.1333, -0.2534, -0.2495,  ...,  0.1454, -0.4250, -1.2666],\n",
      "        [ 0.1333, -0.2534, -0.2495,  ...,  0.1454, -0.4250, -1.2666],\n",
      "        [ 0.1333, -0.2534, -0.2495,  ...,  0.1454, -0.4250, -1.2666],\n",
      "        ...,\n",
      "        [-0.3474,  0.3257,  0.0286,  ..., -0.5161,  0.9316, -0.4933],\n",
      "        [-0.2991,  0.2229,  0.4657,  ..., -0.3892,  0.9659, -0.0417],\n",
      "        [-0.2991,  0.2229,  0.4657,  ..., -0.3892,  0.9659, -0.0417]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.13327299 -0.25335512 -0.2494569   0.1584035  -0.40231007 -0.6445124\n",
      "  0.06196142 -0.6163373  -1.427304   -0.08514643 -0.6804963  -1.7183535\n",
      " -0.2494329  -0.8070649  -2.1854005  -0.09563969 -0.8486279  -1.6218958\n",
      "  0.15455505 -0.8896291  -1.3727858   0.10227653 -0.8290677  -1.4071364\n",
      "  0.08292727 -0.9596789  -1.5226922  -0.04873712 -0.7266846  -1.5274615\n",
      "  0.03499748 -0.7980399  -1.4830608   0.03423404 -0.7745472  -1.5496976\n",
      "  0.15541208 -0.813938   -1.599613    0.06182302 -0.6393316  -1.3551826\n",
      " -0.08859241 -0.39909196 -2.0134876   0.08298466 -0.5933067  -1.9965136\n",
      "  0.23420605 -0.5342871  -1.4401252  -0.06270829 -0.39700007 -1.2802248\n",
      "  0.03357433 -0.367483   -1.3257122   0.08715016 -0.40485236 -1.4344666\n",
      "  0.14537701 -0.42502904 -1.2666371 ]\n",
      "data: [ 0.13327299 -0.25335512 -0.2494569   0.1584035  -0.40231007 -0.6445124\n",
      "  0.06196142 -0.6163373  -1.427304   -0.08514643 -0.6804963  -1.7183536\n",
      " -0.2494329  -0.8070649  -2.1854005  -0.09563968 -0.8486279  -1.6218958\n",
      "  0.15455505 -0.8896291  -1.3727858   0.10227653 -0.8290677  -1.4071364\n",
      "  0.08292727 -0.9596789  -1.5226922  -0.04873712 -0.7266846  -1.5274615\n",
      "  0.03499748 -0.7980399  -1.483061    0.03423404 -0.7745472  -1.5496975\n",
      "  0.15541208 -0.81393796 -1.5996128   0.06182302 -0.6393316  -1.3551826\n",
      " -0.08859242 -0.39909196 -2.0134876   0.08298466 -0.5933067  -1.9965137\n",
      "  0.23420605 -0.5342871  -1.4401252  -0.06270829 -0.39700007 -1.2802248\n",
      "  0.03357433 -0.367483   -1.3257123   0.08715016 -0.40485236 -1.4344666\n",
      "  0.14537701 -0.42502904 -1.2666371   0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B9B0>\n",
      "tensor([[-0.0041, -0.1893, -0.1588,  ...,  0.0088, -0.3689, -1.2147],\n",
      "        [-0.0041, -0.1893, -0.1588,  ...,  0.0088, -0.3689, -1.2147],\n",
      "        [-0.0041, -0.1893, -0.1588,  ...,  0.0088, -0.3689, -1.2147],\n",
      "        ...,\n",
      "        [ 0.0361,  0.6278, -0.1413,  ..., -0.2359,  1.1479, -0.6035],\n",
      "        [-0.0171,  0.0523,  0.6067,  ...,  0.0488,  0.7372,  0.2188],\n",
      "        [-0.0171,  0.0523,  0.6067,  ...,  0.0488,  0.7372,  0.2188]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.00410488 -0.18931243 -0.15883626  0.00651836 -0.33782184 -0.51177204\n",
      " -0.07053707 -0.5375688  -1.3137074  -0.22527352 -0.6024259  -1.6350274\n",
      " -0.42601803 -0.72866154 -2.1158652  -0.228212   -0.80058825 -1.5237377\n",
      "  0.02296764 -0.8373052  -1.312839   -0.03521769 -0.78160083 -1.3558834\n",
      " -0.03101714 -0.91354084 -1.4743855  -0.17729077 -0.6796074  -1.4194171\n",
      " -0.08287532 -0.7457671  -1.3866727  -0.08588917 -0.7274871  -1.5004919\n",
      "  0.04426569 -0.7541864  -1.5549362  -0.07303667 -0.58888996 -1.2360344\n",
      " -0.20331049 -0.37219688 -1.8898594  -0.04450409 -0.5364687  -1.8821034\n",
      "  0.12330382 -0.49836835 -1.381124   -0.19607627 -0.34001467 -1.1707602\n",
      " -0.10094409 -0.3305583  -1.239007   -0.05473372 -0.3634454  -1.3522425\n",
      "  0.00877923 -0.36889696 -1.2146544 ]\n",
      "data: [-0.00410488 -0.18931241 -0.15883626  0.00651836 -0.33782184 -0.51177204\n",
      " -0.07053707 -0.5375688  -1.3137072  -0.22527352 -0.6024259  -1.6350274\n",
      " -0.42601803 -0.7286615  -2.1158652  -0.228212   -0.80058825 -1.5237377\n",
      "  0.02296764 -0.83730525 -1.312839   -0.03521769 -0.7816008  -1.3558834\n",
      " -0.03101714 -0.9135408  -1.4743855  -0.17729077 -0.6796074  -1.4194171\n",
      " -0.08287532 -0.7457671  -1.3866726  -0.08588917 -0.7274871  -1.5004917\n",
      "  0.04426569 -0.7541864  -1.5549362  -0.07303667 -0.58888996 -1.2360344\n",
      " -0.20331049 -0.37219688 -1.8898594  -0.04450409 -0.5364687  -1.8821034\n",
      "  0.12330382 -0.49836835 -1.381124   -0.19607627 -0.34001464 -1.1707602\n",
      " -0.10094409 -0.33055833 -1.239007   -0.05473372 -0.3634454  -1.3522425\n",
      "  0.00877923 -0.36889693 -1.2146544   0.04      ]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0418, -0.1358, -0.1699,  ...,  0.0425, -0.3156, -1.1843],\n",
      "        [ 0.0418, -0.1358, -0.1699,  ...,  0.0425, -0.3156, -1.1843],\n",
      "        [ 0.0418, -0.1358, -0.1699,  ...,  0.0425, -0.3156, -1.1843],\n",
      "        ...,\n",
      "        [-0.1439,  0.5228, -0.0830,  ..., -0.2349,  1.2091, -0.5436],\n",
      "        [-0.0803,  0.0543,  0.6811,  ..., -0.2083,  0.6852,  0.3763],\n",
      "        [-0.0803,  0.0543,  0.6811,  ..., -0.2083,  0.6852,  0.3763]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04175557 -0.13582475 -0.16993968  0.07791734 -0.22792746 -0.4357096\n",
      " -0.0791604  -0.47217786 -1.3224478  -0.24304686 -0.53890836 -1.6059378\n",
      " -0.38266987 -0.6189294  -2.1454778  -0.15862708 -0.78237057 -1.5249152\n",
      "  0.00619884 -0.86188316 -1.3841597  -0.04502894 -0.78160083 -1.4249381\n",
      " -0.05522878 -0.95464504 -1.5508169  -0.11548482 -0.7005329  -1.4193454\n",
      " -0.0654164  -0.75245905 -1.3859802  -0.07013253 -0.7072656  -1.4631561\n",
      "  0.07122356 -0.7481935  -1.4722418  -0.03182092 -0.57573557 -1.269203\n",
      " -0.20603882 -0.33044103 -2.040835   -0.00900794 -0.51204395 -2.0743628\n",
      "  0.17200173 -0.46282533 -1.3574823  -0.17034142 -0.3447832  -1.1829643\n",
      " -0.10136531 -0.30595273 -1.270995   -0.0736184  -0.307789   -1.3814882\n",
      "  0.0425114  -0.31555843 -1.1842848 ]\n",
      "data: [ 0.04175557 -0.13582475 -0.1699397   0.07791734 -0.22792746 -0.4357096\n",
      " -0.0791604  -0.47217786 -1.3224478  -0.24304685 -0.53890836 -1.6059378\n",
      " -0.38266987 -0.6189294  -2.1454778  -0.15862708 -0.7823706  -1.5249152\n",
      "  0.00619884 -0.86188316 -1.3841597  -0.04502894 -0.7816008  -1.4249381\n",
      " -0.05522878 -0.954645   -1.550817   -0.11548482 -0.7005329  -1.4193454\n",
      " -0.0654164  -0.75245905 -1.3859802  -0.07013253 -0.7072656  -1.4631561\n",
      "  0.07122356 -0.7481935  -1.4722419  -0.03182092 -0.57573557 -1.269203\n",
      " -0.20603882 -0.33044103 -2.040835   -0.00900794 -0.51204395 -2.0743628\n",
      "  0.17200175 -0.46282533 -1.3574823  -0.17034142 -0.3447832  -1.1829643\n",
      " -0.10136531 -0.30595273 -1.270995   -0.0736184  -0.307789   -1.3814882\n",
      "  0.04251141 -0.31555843 -1.1842848   0.05      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[-0.0312, -0.0480, -0.1977,  ...,  0.0167, -0.2335, -1.1759],\n",
      "        [-0.0312, -0.0480, -0.1977,  ...,  0.0167, -0.2335, -1.1759],\n",
      "        [-0.0312, -0.0480, -0.1977,  ...,  0.0167, -0.2335, -1.1759],\n",
      "        ...,\n",
      "        [-0.1502,  0.3583,  0.0717,  ..., -0.6179,  0.9455, -0.3476],\n",
      "        [-0.0897, -0.0458,  0.6001,  ..., -0.2193,  0.6383,  0.2536],\n",
      "        [-0.0897, -0.0458,  0.6001,  ..., -0.2193,  0.6383,  0.2536]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.03120036 -0.04801105 -0.1977014  -0.00441914 -0.16562799 -0.48987132\n",
      " -0.12398373 -0.38874638 -1.3338994  -0.2795514  -0.45091596 -1.6369567\n",
      " -0.4448085  -0.5645944  -2.135097   -0.24231333 -0.6778841  -1.5179836\n",
      " -0.01195115 -0.7308099  -1.3218805  -0.06847316 -0.66602975 -1.365087\n",
      " -0.07146779 -0.81603706 -1.4962491  -0.18998888 -0.57727486 -1.4096055\n",
      " -0.10851602 -0.6371622  -1.3867333  -0.09906916 -0.60011417 -1.4761575\n",
      "  0.0438496  -0.64473623 -1.5091813  -0.0848896  -0.46764383 -1.2340746\n",
      " -0.24380557 -0.22783512 -1.9886484  -0.04216769 -0.4113621  -1.9989208\n",
      "  0.14447561 -0.3637923  -1.3576801  -0.21973294 -0.22956534 -1.1564256\n",
      " -0.12175952 -0.2039012  -1.2352216  -0.08000067 -0.22367236 -1.3506112\n",
      "  0.01670561 -0.23354264 -1.1759074 ]\n",
      "data: [-0.03120036 -0.04801105 -0.1977014  -0.00441914 -0.165628   -0.48987132\n",
      " -0.12398373 -0.38874638 -1.3338994  -0.2795514  -0.45091593 -1.6369567\n",
      " -0.4448085  -0.5645944  -2.135097   -0.24231333 -0.67788404 -1.5179836\n",
      " -0.01195115 -0.7308099  -1.3218805  -0.06847316 -0.66602975 -1.365087\n",
      " -0.07146779 -0.81603706 -1.4962491  -0.18998888 -0.57727486 -1.4096055\n",
      " -0.10851602 -0.6371622  -1.3867333  -0.09906916 -0.60011417 -1.4761575\n",
      "  0.0438496  -0.64473623 -1.5091813  -0.08488961 -0.46764383 -1.2340746\n",
      " -0.24380559 -0.22783512 -1.9886484  -0.04216769 -0.4113621  -1.9989208\n",
      "  0.14447561 -0.3637923  -1.3576801  -0.21973294 -0.22956534 -1.1564256\n",
      " -0.12175952 -0.2039012  -1.2352216  -0.08000067 -0.22367235 -1.3506112\n",
      "  0.01670561 -0.23354264 -1.1759074   0.06      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[ 4.4218e-03, -9.0808e-02, -2.3997e-01,  ...,  3.9541e-04,\n",
      "         -2.5243e-01, -1.3002e+00],\n",
      "        [ 4.4218e-03, -9.0808e-02, -2.3997e-01,  ...,  3.9541e-04,\n",
      "         -2.5243e-01, -1.3002e+00],\n",
      "        [ 4.4218e-03, -9.0808e-02, -2.3997e-01,  ...,  3.9541e-04,\n",
      "         -2.5243e-01, -1.3002e+00],\n",
      "        ...,\n",
      "        [-2.5323e-01,  3.0464e-01, -1.4628e-01,  ..., -6.8726e-01,\n",
      "          7.9997e-01, -4.0614e-01],\n",
      "        [-1.5166e-01, -9.3790e-02,  6.0132e-01,  ..., -2.6315e-01,\n",
      "          6.6764e-01,  2.7418e-01],\n",
      "        [-1.5166e-01, -9.3790e-02,  6.0132e-01,  ..., -2.6315e-01,\n",
      "          6.6764e-01,  2.7418e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 4.42183483e-03 -9.08079967e-02 -2.39967465e-01  2.99372561e-02\n",
      " -2.20873639e-01 -6.51082575e-01 -6.99452832e-02 -4.06399697e-01\n",
      " -1.40593147e+00 -2.16797337e-01 -4.64804739e-01 -1.70610607e+00\n",
      " -3.84304553e-01 -5.65046430e-01 -2.19021249e+00 -2.00310826e-01\n",
      " -7.01640904e-01 -1.55799925e+00  3.83262336e-03 -7.31450677e-01\n",
      " -1.36210847e+00 -4.34389561e-02 -6.68680727e-01 -1.42063141e+00\n",
      " -5.55308685e-02 -8.06859732e-01 -1.54527700e+00 -1.63021073e-01\n",
      " -6.01818919e-01 -1.47174585e+00 -8.85614082e-02 -6.51190639e-01\n",
      " -1.44905734e+00 -1.00526541e-01 -6.18953049e-01 -1.54984307e+00\n",
      "  3.82903069e-02 -6.43311501e-01 -1.59549141e+00 -8.28850046e-02\n",
      " -5.03875613e-01 -1.30247116e+00 -2.07182691e-01 -2.73348123e-01\n",
      " -1.97511196e+00 -4.55418751e-02 -4.23038721e-01 -1.98604298e+00\n",
      "  1.15304396e-01 -3.91295969e-01 -1.45228434e+00 -1.87689126e-01\n",
      " -2.68231094e-01 -1.23660910e+00 -1.22025996e-01 -2.38128632e-01\n",
      " -1.32144332e+00 -8.17752033e-02 -2.41919592e-01 -1.44486642e+00\n",
      "  3.95409763e-04 -2.52432823e-01 -1.30017769e+00]\n",
      "data: [ 4.42183483e-03 -9.08080041e-02 -2.39967465e-01  2.99372561e-02\n",
      " -2.20873639e-01 -6.51082635e-01 -6.99452832e-02 -4.06399697e-01\n",
      " -1.40593135e+00 -2.16797337e-01 -4.64804739e-01 -1.70610607e+00\n",
      " -3.84304553e-01 -5.65046430e-01 -2.19021249e+00 -2.00310826e-01\n",
      " -7.01640904e-01 -1.55799925e+00  3.83262336e-03 -7.31450677e-01\n",
      " -1.36210847e+00 -4.34389561e-02 -6.68680727e-01 -1.42063141e+00\n",
      " -5.55308685e-02 -8.06859732e-01 -1.54527700e+00 -1.63021073e-01\n",
      " -6.01818919e-01 -1.47174597e+00 -8.85614082e-02 -6.51190639e-01\n",
      " -1.44905734e+00 -1.00526541e-01 -6.18953049e-01 -1.54984319e+00\n",
      "  3.82903069e-02 -6.43311441e-01 -1.59549129e+00 -8.28850046e-02\n",
      " -5.03875613e-01 -1.30247116e+00 -2.07182691e-01 -2.73348123e-01\n",
      " -1.97511196e+00 -4.55418713e-02 -4.23038721e-01 -1.98604298e+00\n",
      "  1.15304396e-01 -3.91295969e-01 -1.45228434e+00 -1.87689126e-01\n",
      " -2.68231094e-01 -1.23660910e+00 -1.22025996e-01 -2.38128617e-01\n",
      " -1.32144332e+00 -8.17752108e-02 -2.41919592e-01 -1.44486654e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3.95409763e-04 -2.52432823e-01 -1.30017781e+00  7.00000003e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0275, -0.0289, -0.2226,  ...,  0.0298, -0.2189, -1.2546],\n",
      "        [ 0.0275, -0.0289, -0.2226,  ...,  0.0298, -0.2189, -1.2546],\n",
      "        [ 0.0275, -0.0289, -0.2226,  ...,  0.0298, -0.2189, -1.2546],\n",
      "        ...,\n",
      "        [-0.1812,  0.4000, -0.0979,  ..., -0.7638,  0.9112, -0.3849],\n",
      "        [-0.1271, -0.1756,  0.6082,  ..., -0.1993,  0.5882,  0.2819],\n",
      "        [-0.1271, -0.1756,  0.6082,  ..., -0.1993,  0.5882,  0.2819]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02751968 -0.02886344 -0.22258227  0.03999272 -0.14762302 -0.6048707\n",
      " -0.08564919 -0.33968887 -1.371816   -0.23859799 -0.40397215 -1.6628733\n",
      " -0.40317535 -0.4901197  -2.1641235  -0.16869198 -0.6549715  -1.5274836\n",
      " -0.01823659 -0.7002082  -1.3743373  -0.06551115 -0.62285906 -1.4399197\n",
      " -0.0684497  -0.78253835 -1.5583886  -0.13343766 -0.5668278  -1.4439583\n",
      " -0.07830027 -0.6099731  -1.4130347  -0.10459591 -0.5810286  -1.5101609\n",
      "  0.04015036 -0.5921049  -1.5313721  -0.06199945 -0.46904492 -1.2866634\n",
      " -0.18140997 -0.2445746  -1.949978   -0.032828   -0.3871607  -1.9732454\n",
      "  0.13412845 -0.36459184 -1.4016612  -0.15620014 -0.2428031  -1.2169118\n",
      " -0.10840486 -0.21730223 -1.3082991  -0.08043575 -0.20538428 -1.426797\n",
      "  0.02976409 -0.2188807  -1.2546158 ]\n",
      "data: [ 0.02751968 -0.02886344 -0.22258227  0.03999272 -0.14762302 -0.6048707\n",
      " -0.08564919 -0.33968887 -1.3718162  -0.23859799 -0.40397218 -1.6628733\n",
      " -0.40317535 -0.4901197  -2.1641235  -0.16869198 -0.6549715  -1.5274835\n",
      " -0.01823659 -0.7002082  -1.3743373  -0.06551115 -0.62285906 -1.4399197\n",
      " -0.0684497  -0.78253835 -1.5583885  -0.13343766 -0.5668278  -1.4439583\n",
      " -0.07830027 -0.6099731  -1.4130347  -0.10459592 -0.5810286  -1.5101609\n",
      "  0.04015036 -0.5921049  -1.5313721  -0.06199945 -0.46904492 -1.2866634\n",
      " -0.18140997 -0.2445746  -1.949978   -0.032828   -0.3871607  -1.9732454\n",
      "  0.13412845 -0.36459184 -1.4016613  -0.15620014 -0.2428031  -1.2169118\n",
      " -0.10840485 -0.21730223 -1.3082991  -0.08043575 -0.2053843  -1.426797\n",
      "  0.02976408 -0.2188807  -1.2546158   0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0471, -0.0397, -0.2135,  ...,  0.0326, -0.2338, -1.2653],\n",
      "        [ 0.0471, -0.0397, -0.2135,  ...,  0.0326, -0.2338, -1.2653],\n",
      "        [ 0.0471, -0.0397, -0.2135,  ...,  0.0326, -0.2338, -1.2653],\n",
      "        ...,\n",
      "        [-0.3057,  0.2313, -0.2575,  ..., -0.8069,  0.6250, -0.3527],\n",
      "        [-0.1214, -0.0933,  0.5584,  ..., -0.1864,  0.6841,  0.2931],\n",
      "        [-0.1214, -0.0933,  0.5584,  ..., -0.1864,  0.6841,  0.2931]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.04709836 -0.03969218 -0.21353804  0.0583301  -0.17396772 -0.6136582\n",
      " -0.07154372 -0.3616214  -1.3779243  -0.22307464 -0.43238842 -1.6526083\n",
      " -0.39747295 -0.51622593 -2.1478248  -0.14782861 -0.66584074 -1.5264242\n",
      " -0.01540951 -0.7097156  -1.3700835  -0.0539997  -0.6298268  -1.4328418\n",
      " -0.05209068 -0.7803242  -1.5378864  -0.1184156  -0.57007754 -1.455396\n",
      " -0.06551436 -0.6141231  -1.409281   -0.09708989 -0.59066176 -1.5003126\n",
      "  0.05043549 -0.58613276 -1.5271672  -0.05838982 -0.4890513  -1.3031491\n",
      " -0.16170487 -0.26829934 -1.9170502  -0.03054918 -0.40112743 -1.9336785\n",
      "  0.12587819 -0.38013038 -1.4014325  -0.13957557 -0.25780886 -1.2394196\n",
      " -0.10811425 -0.234774   -1.3244101  -0.07209567 -0.21799977 -1.4403591\n",
      "  0.03256419 -0.23380993 -1.2653475 ]\n",
      "data: [ 0.04709835 -0.03969218 -0.21353804  0.0583301  -0.17396772 -0.6136582\n",
      " -0.07154372 -0.3616214  -1.3779243  -0.22307464 -0.43238842 -1.6526084\n",
      " -0.39747295 -0.51622593 -2.1478248  -0.14782861 -0.66584074 -1.526424\n",
      " -0.01540951 -0.7097156  -1.3700835  -0.0539997  -0.6298268  -1.4328418\n",
      " -0.05209068 -0.7803242  -1.5378864  -0.1184156  -0.57007754 -1.4553962\n",
      " -0.06551436 -0.6141231  -1.409281   -0.09708989 -0.59066176 -1.5003124\n",
      "  0.05043549 -0.58613276 -1.5271672  -0.05838982 -0.4890513  -1.3031491\n",
      " -0.16170487 -0.26829934 -1.9170501  -0.03054918 -0.40112743 -1.9336784\n",
      "  0.12587819 -0.38013038 -1.4014325  -0.13957557 -0.25780886 -1.2394196\n",
      " -0.10811425 -0.234774   -1.3244101  -0.07209567 -0.21799976 -1.4403592\n",
      "  0.03256419 -0.23380993 -1.2653475   0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0214, -0.0627, -0.2447,  ...,  0.0375, -0.2498, -1.2723],\n",
      "        [ 0.0214, -0.0627, -0.2447,  ...,  0.0375, -0.2498, -1.2723],\n",
      "        [ 0.0214, -0.0627, -0.2447,  ...,  0.0375, -0.2498, -1.2723],\n",
      "        ...,\n",
      "        [-0.2621,  0.2323, -0.2334,  ..., -0.7746,  0.7014, -0.4419],\n",
      "        [-0.0839, -0.0682,  0.5971,  ..., -0.2079,  0.7208,  0.2648],\n",
      "        [-0.0839, -0.0682,  0.5971,  ..., -0.2079,  0.7208,  0.2648]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.1392282e-02 -6.2734902e-02 -2.4473564e-01  4.7804985e-02\n",
      " -1.8609291e-01 -6.3589835e-01 -7.2874412e-02 -3.8066477e-01\n",
      " -1.4156622e+00 -2.1875358e-01 -4.4732195e-01 -1.6987303e+00\n",
      " -3.7284115e-01 -5.3970975e-01 -2.1927948e+00 -1.6946521e-01\n",
      " -6.7783320e-01 -1.5682318e+00  8.3440542e-04 -7.2123533e-01\n",
      " -1.3933703e+00 -4.5733899e-02 -6.4922994e-01 -1.4526359e+00\n",
      " -5.5939920e-02 -7.9898202e-01 -1.5704929e+00 -1.3353086e-01\n",
      " -5.8694184e-01 -1.4851408e+00 -7.0789903e-02 -6.3636142e-01\n",
      " -1.4496281e+00 -9.4945282e-02 -6.0652924e-01 -1.5358164e+00\n",
      "  4.3104336e-02 -6.2558913e-01 -1.5634764e+00 -5.9914939e-02\n",
      " -4.9440175e-01 -1.3221741e+00 -1.8014415e-01 -2.6439989e-01\n",
      " -1.9868435e+00 -2.7154095e-02 -4.1623425e-01 -2.0025079e+00\n",
      "  1.3207893e-01 -3.8940114e-01 -1.4278593e+00 -1.5640220e-01\n",
      " -2.6566672e-01 -1.2507211e+00 -9.8681331e-02 -2.3767482e-01\n",
      " -1.3314902e+00 -6.0834825e-02 -2.3415814e-01 -1.4474896e+00\n",
      "  3.7509777e-02 -2.4981523e-01 -1.2723323e+00]\n",
      "data: [ 2.1392280e-02 -6.2734902e-02 -2.4473564e-01  4.7804985e-02\n",
      " -1.8609291e-01 -6.3589835e-01 -7.2874412e-02 -3.8066474e-01\n",
      " -1.4156623e+00 -2.1875359e-01 -4.4732198e-01 -1.6987303e+00\n",
      " -3.7284115e-01 -5.3970975e-01 -2.1927948e+00 -1.6946521e-01\n",
      " -6.7783320e-01 -1.5682318e+00  8.3440542e-04 -7.2123533e-01\n",
      " -1.3933702e+00 -4.5733899e-02 -6.4922994e-01 -1.4526360e+00\n",
      " -5.5939924e-02 -7.9898202e-01 -1.5704929e+00 -1.3353086e-01\n",
      " -5.8694184e-01 -1.4851408e+00 -7.0789903e-02 -6.3636142e-01\n",
      " -1.4496281e+00 -9.4945282e-02 -6.0652924e-01 -1.5358166e+00\n",
      "  4.3104336e-02 -6.2558913e-01 -1.5634764e+00 -5.9914935e-02\n",
      " -4.9440175e-01 -1.3221741e+00 -1.8014413e-01 -2.6439989e-01\n",
      " -1.9868435e+00 -2.7154095e-02 -4.1623425e-01 -2.0025079e+00\n",
      "  1.3207893e-01 -3.8940114e-01 -1.4278593e+00 -1.5640220e-01\n",
      " -2.6566672e-01 -1.2507211e+00 -9.8681338e-02 -2.3767480e-01\n",
      " -1.3314902e+00 -6.0834829e-02 -2.3415813e-01 -1.4474896e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  3.7509777e-02 -2.4981521e-01 -1.2723323e+00  1.0000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0239, -0.0309, -0.2423,  ...,  0.0470, -0.2265, -1.2697],\n",
      "        [ 0.0239, -0.0309, -0.2423,  ...,  0.0470, -0.2265, -1.2697],\n",
      "        [ 0.0239, -0.0309, -0.2423,  ...,  0.0470, -0.2265, -1.2697],\n",
      "        ...,\n",
      "        [-0.1618,  0.3414, -0.0864,  ..., -0.8119,  0.8265, -0.3006],\n",
      "        [-0.1402, -0.1724,  0.5473,  ..., -0.2200,  0.5951,  0.2175],\n",
      "        [-0.1402, -0.1724,  0.5473,  ..., -0.2200,  0.5951,  0.2175]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0238638  -0.03093706 -0.24232203  0.03912248 -0.15894568 -0.63401246\n",
      " -0.06981223 -0.34575635 -1.3869567  -0.2157969  -0.40867752 -1.677617\n",
      " -0.3834005  -0.5091764  -2.1599023  -0.17266615 -0.6470421  -1.5410893\n",
      "  0.00515004 -0.6856585  -1.3757408  -0.04077494 -0.6145577  -1.4359113\n",
      " -0.03683317 -0.76258624 -1.5508367  -0.13283697 -0.5515826  -1.4583331\n",
      " -0.06427866 -0.6007314  -1.4280654  -0.08060451 -0.57664704 -1.5219295\n",
      "  0.06062499 -0.5910936  -1.5554928  -0.05425035 -0.46389276 -1.2949182\n",
      " -0.16864166 -0.2392902  -1.9502212  -0.01551652 -0.38852966 -1.9609313\n",
      "  0.14752202 -0.36250877 -1.4184637  -0.1496282  -0.2340382  -1.229653\n",
      " -0.08820647 -0.21220893 -1.3156503  -0.0489525  -0.21194643 -1.4329611\n",
      "  0.04698052 -0.22650382 -1.2697383 ]\n",
      "data: [ 0.0238638  -0.03093706 -0.24232203  0.03912248 -0.15894568 -0.63401246\n",
      " -0.06981223 -0.34575635 -1.3869567  -0.2157969  -0.40867752 -1.6776168\n",
      " -0.3834005  -0.5091764  -2.1599023  -0.17266615 -0.6470421  -1.5410893\n",
      "  0.00515004 -0.6856585  -1.3757408  -0.04077494 -0.6145577  -1.4359113\n",
      " -0.03683317 -0.76258624 -1.5508367  -0.13283697 -0.5515826  -1.4583331\n",
      " -0.06427866 -0.6007314  -1.4280655  -0.08060451 -0.57664704 -1.5219295\n",
      "  0.06062499 -0.5910936  -1.5554928  -0.05425035 -0.46389276 -1.2949182\n",
      " -0.16864166 -0.2392902  -1.9502213  -0.01551652 -0.38852966 -1.9609313\n",
      "  0.14752202 -0.36250877 -1.4184637  -0.1496282  -0.2340382  -1.229653\n",
      " -0.08820647 -0.21220893 -1.3156503  -0.0489525  -0.21194643 -1.4329611\n",
      "  0.04698052 -0.2265038  -1.2697383   0.11      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0141, -0.0817, -0.2418,  ...,  0.0304, -0.2658, -1.2977],\n",
      "        [ 0.0141, -0.0817, -0.2418,  ...,  0.0304, -0.2658, -1.2977],\n",
      "        [ 0.0141, -0.0817, -0.2418,  ...,  0.0304, -0.2658, -1.2977],\n",
      "        ...,\n",
      "        [-0.3565,  0.1824, -0.3352,  ..., -0.8445,  0.6089, -0.4857],\n",
      "        [-0.1289, -0.0715,  0.5924,  ..., -0.2349,  0.7214,  0.2549],\n",
      "        [-0.1289, -0.0715,  0.5924,  ..., -0.2349,  0.7214,  0.2549]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01405067 -0.081738   -0.24184586  0.03476316 -0.22031124 -0.6646235\n",
      " -0.05888142 -0.40034324 -1.4124372  -0.2007083  -0.46367773 -1.7043519\n",
      " -0.3663044  -0.57090795 -2.1832786  -0.18554705 -0.6856853  -1.5673032\n",
      "  0.01503064 -0.71530795 -1.3779967  -0.03253485 -0.65009356 -1.4359717\n",
      " -0.03722659 -0.7833986  -1.551228   -0.1468564  -0.5840068  -1.4863043\n",
      " -0.06967244 -0.63560224 -1.4568787  -0.08741347 -0.6105591  -1.5499377\n",
      "  0.04414754 -0.6275686  -1.5937796  -0.06537792 -0.5013779  -1.3174019\n",
      " -0.17210558 -0.27570552 -1.9383509  -0.02815463 -0.42305884 -1.9403095\n",
      "  0.12353339 -0.39531222 -1.4500258  -0.160618   -0.26741898 -1.2535944\n",
      " -0.09163781 -0.24474168 -1.331825   -0.04717033 -0.25214353 -1.4481125\n",
      "  0.03037528 -0.26580435 -1.2977257 ]\n",
      "data: [ 0.01405067 -0.081738   -0.24184586  0.03476316 -0.22031124 -0.6646235\n",
      " -0.05888142 -0.40034324 -1.4124371  -0.2007083  -0.46367776 -1.7043519\n",
      " -0.3663044  -0.57090795 -2.1832786  -0.18554705 -0.6856853  -1.5673032\n",
      "  0.01503064 -0.71530795 -1.3779967  -0.03253485 -0.65009356 -1.4359717\n",
      " -0.03722659 -0.78339857 -1.551228   -0.1468564  -0.5840068  -1.4863043\n",
      " -0.06967244 -0.63560224 -1.4568787  -0.08741347 -0.6105591  -1.5499377\n",
      "  0.04414754 -0.6275686  -1.5937796  -0.06537792 -0.5013779  -1.3174019\n",
      " -0.17210558 -0.27570552 -1.938351   -0.02815463 -0.42305887 -1.9403094\n",
      "  0.12353339 -0.39531222 -1.4500258  -0.160618   -0.26741898 -1.2535944\n",
      " -0.09163781 -0.24474166 -1.3318249  -0.04717033 -0.25214353 -1.4481125\n",
      "  0.03037528 -0.26580435 -1.2977257   0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0292, -0.0683, -0.2562,  ...,  0.0458, -0.2577, -1.2747],\n",
      "        [ 0.0292, -0.0683, -0.2562,  ...,  0.0458, -0.2577, -1.2747],\n",
      "        [ 0.0292, -0.0683, -0.2562,  ...,  0.0458, -0.2577, -1.2747],\n",
      "        ...,\n",
      "        [-0.1133,  0.4026, -0.1135,  ..., -0.6931,  0.9172, -0.4015],\n",
      "        [-0.1304, -0.1499,  0.5839,  ..., -0.2346,  0.6259,  0.2319],\n",
      "        [-0.1304, -0.1499,  0.5839,  ..., -0.2346,  0.6259,  0.2319]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0292435  -0.06826396 -0.2562253   0.05564853 -0.18372439 -0.6272136\n",
      " -0.06455807 -0.38376775 -1.4166403  -0.21027313 -0.447337   -1.7051811\n",
      " -0.362526   -0.5385062  -2.2024062  -0.15882184 -0.689279   -1.5728331\n",
      "  0.00749452 -0.737369   -1.4208908  -0.04296686 -0.6643573  -1.4809241\n",
      " -0.04878584 -0.82213277 -1.6006336  -0.12081337 -0.6013237  -1.4838209\n",
      " -0.0622806  -0.64831984 -1.4550028  -0.0846598  -0.6190538  -1.5434043\n",
      "  0.04924294 -0.64085895 -1.5666399  -0.04639695 -0.50156677 -1.3220806\n",
      " -0.17811382 -0.27106547 -2.0254972  -0.01690348 -0.4272905  -2.0457702\n",
      "  0.14294414 -0.39820677 -1.4324071  -0.14854074 -0.27563757 -1.2491822\n",
      " -0.08888455 -0.24805424 -1.3369117  -0.05599619 -0.24402246 -1.4527292\n",
      "  0.04576557 -0.25768757 -1.2746718 ]\n",
      "data: [ 0.0292435  -0.06826396 -0.2562253   0.05564853 -0.18372439 -0.6272136\n",
      " -0.06455807 -0.38376772 -1.4166403  -0.21027313 -0.447337   -1.7051811\n",
      " -0.36252603 -0.5385062  -2.2024062  -0.15882184 -0.689279   -1.5728331\n",
      "  0.00749452 -0.737369   -1.4208908  -0.04296686 -0.6643573  -1.4809241\n",
      " -0.04878584 -0.8221328  -1.6006335  -0.12081337 -0.6013237  -1.4838209\n",
      " -0.0622806  -0.64831984 -1.4550028  -0.08465979 -0.6190538  -1.5434043\n",
      "  0.04924294 -0.6408589  -1.5666399  -0.04639695 -0.50156677 -1.3220807\n",
      " -0.17811382 -0.27106547 -2.0254972  -0.01690348 -0.4272905  -2.0457702\n",
      "  0.14294414 -0.3982068  -1.432407   -0.14854074 -0.27563757 -1.2491822\n",
      " -0.08888455 -0.24805424 -1.3369117  -0.05599619 -0.24402246 -1.4527292\n",
      "  0.04576557 -0.25768757 -1.2746718   0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0227, -0.0344, -0.2415,  ...,  0.0568, -0.2242, -1.2858],\n",
      "        [ 0.0227, -0.0344, -0.2415,  ...,  0.0568, -0.2242, -1.2858],\n",
      "        [ 0.0227, -0.0344, -0.2415,  ...,  0.0568, -0.2242, -1.2858],\n",
      "        ...,\n",
      "        [-0.1621,  0.3030, -0.0649,  ..., -0.8211,  0.7703, -0.2565],\n",
      "        [-0.1458, -0.1505,  0.5371,  ..., -0.2282,  0.6074,  0.2013],\n",
      "        [-0.1458, -0.1505,  0.5371,  ..., -0.2282,  0.6074,  0.2013]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.2728879e-02 -3.4435533e-02 -2.4145265e-01  3.5467576e-02\n",
      " -1.7697723e-01 -6.5794015e-01 -4.1905880e-02 -3.5368720e-01\n",
      " -1.3816953e+00 -1.8422195e-01 -4.1265589e-01 -1.6856058e+00\n",
      " -3.6134762e-01 -5.3366876e-01 -2.1484990e+00 -1.8476126e-01\n",
      " -6.3747966e-01 -1.5418649e+00  4.3145128e-02 -6.6332078e-01\n",
      " -1.3495691e+00 -8.3668903e-03 -6.0349524e-01 -1.4038813e+00\n",
      " -5.9117451e-03 -7.3421180e-01 -1.5196586e+00 -1.3796431e-01\n",
      " -5.3052497e-01 -1.4561734e+00 -4.8425257e-02 -5.8720994e-01\n",
      " -1.4337361e+00 -5.5295855e-02 -5.6511617e-01 -1.5333936e+00\n",
      "  7.4610971e-02 -5.8906090e-01 -1.5841391e+00 -4.2382151e-02\n",
      " -4.4709617e-01 -1.2834466e+00 -1.5220007e-01 -2.2497058e-01\n",
      " -1.9136021e+00  9.9728256e-04 -3.7962621e-01 -1.9081817e+00\n",
      "  1.5676853e-01 -3.4850743e-01 -1.4362416e+00 -1.4495519e-01\n",
      " -2.1085593e-01 -1.2232001e+00 -5.9589081e-02 -1.9370577e-01\n",
      " -1.3038552e+00 -1.3003267e-02 -2.1255024e-01 -1.4217341e+00\n",
      "  5.6774631e-02 -2.2421934e-01 -1.2857516e+00]\n",
      "data: [ 2.2728879e-02 -3.4435533e-02 -2.4145265e-01  3.5467576e-02\n",
      " -1.7697723e-01 -6.5794015e-01 -4.1905880e-02 -3.5368720e-01\n",
      " -1.3816953e+00 -1.8422195e-01 -4.1265592e-01 -1.6856058e+00\n",
      " -3.6134762e-01 -5.3366876e-01 -2.1484990e+00 -1.8476126e-01\n",
      " -6.3747966e-01 -1.5418649e+00  4.3145128e-02 -6.6332078e-01\n",
      " -1.3495691e+00 -8.3668903e-03 -6.0349524e-01 -1.4038814e+00\n",
      " -5.9117447e-03 -7.3421180e-01 -1.5196586e+00 -1.3796431e-01\n",
      " -5.3052497e-01 -1.4561734e+00 -4.8425253e-02 -5.8720994e-01\n",
      " -1.4337361e+00 -5.5295855e-02 -5.6511617e-01 -1.5333935e+00\n",
      "  7.4610971e-02 -5.8906090e-01 -1.5841391e+00 -4.2382151e-02\n",
      " -4.4709617e-01 -1.2834466e+00 -1.5220007e-01 -2.2497059e-01\n",
      " -1.9136021e+00  9.9728256e-04 -3.7962618e-01 -1.9081817e+00\n",
      "  1.5676853e-01 -3.4850743e-01 -1.4362416e+00 -1.4495519e-01\n",
      " -2.1085592e-01 -1.2232001e+00 -5.9589081e-02 -1.9370577e-01\n",
      " -1.3038552e+00 -1.3003267e-02 -2.1255024e-01 -1.4217342e+00\n",
      "  5.6774631e-02 -2.2421934e-01 -1.2857517e+00  1.4000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0030, -0.0827, -0.2580,  ...,  0.0338, -0.2683, -1.3244],\n",
      "        [ 0.0030, -0.0827, -0.2580,  ...,  0.0338, -0.2683, -1.3244],\n",
      "        [ 0.0030, -0.0827, -0.2580,  ...,  0.0338, -0.2683, -1.3244],\n",
      "        ...,\n",
      "        [-0.1623,  0.4254, -0.1262,  ..., -0.7421,  0.9039, -0.3444],\n",
      "        [-0.1622, -0.1302,  0.5730,  ..., -0.2453,  0.6584,  0.2237],\n",
      "        [-0.1622, -0.1302,  0.5730,  ..., -0.2453,  0.6584,  0.2237]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00301177 -0.08268975 -0.2579527   0.02080414 -0.22892177 -0.68694794\n",
      " -0.05812575 -0.40221214 -1.4257829  -0.19736727 -0.46357358 -1.7228076\n",
      " -0.36767077 -0.58133125 -2.1941009  -0.20039445 -0.68139315 -1.5866504\n",
      "  0.02365094 -0.703675   -1.3898404  -0.02470651 -0.6415044  -1.4453473\n",
      " -0.02226326 -0.76489526 -1.5602152  -0.15817854 -0.5734678  -1.5054855\n",
      " -0.06830639 -0.6268329  -1.4811099  -0.07813167 -0.60277456 -1.576788\n",
      "  0.05271517 -0.6215572  -1.6297054  -0.06820825 -0.49673152 -1.3316822\n",
      " -0.16790074 -0.27061242 -1.9340532  -0.02370419 -0.41888577 -1.9275563\n",
      "  0.12944542 -0.38889652 -1.4806814  -0.16635157 -0.25857693 -1.2698903\n",
      " -0.08429237 -0.23917624 -1.3471293  -0.03451516 -0.25509214 -1.463547\n",
      "  0.03379098 -0.26831335 -1.3244078 ]\n",
      "data: [ 0.00301177 -0.08268974 -0.2579527   0.02080414 -0.22892177 -0.68694794\n",
      " -0.05812575 -0.40221214 -1.4257829  -0.19736727 -0.46357358 -1.7228076\n",
      " -0.36767077 -0.58133125 -2.1941009  -0.20039445 -0.68139315 -1.5866504\n",
      "  0.02365094 -0.70367503 -1.3898404  -0.02470651 -0.64150447 -1.4453473\n",
      " -0.02226326 -0.76489526 -1.5602154  -0.15817854 -0.5734678  -1.5054855\n",
      " -0.06830639 -0.6268329  -1.48111    -0.07813167 -0.60277456 -1.5767881\n",
      "  0.05271517 -0.6215572  -1.6297055  -0.06820825 -0.49673152 -1.3316821\n",
      " -0.16790074 -0.27061242 -1.9340532  -0.02370419 -0.41888577 -1.9275563\n",
      "  0.12944542 -0.38889652 -1.4806814  -0.16635157 -0.25857693 -1.2698903\n",
      " -0.08429237 -0.23917623 -1.3471293  -0.03451516 -0.25509214 -1.4635471\n",
      "  0.03379098 -0.26831335 -1.3244078   0.15      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0237, -0.0930, -0.2468,  ...,  0.0452, -0.2775, -1.2831],\n",
      "        [ 0.0237, -0.0930, -0.2468,  ...,  0.0452, -0.2775, -1.2831],\n",
      "        [ 0.0237, -0.0930, -0.2468,  ...,  0.0452, -0.2775, -1.2831],\n",
      "        ...,\n",
      "        [-0.1537,  0.4002, -0.1900,  ..., -0.7512,  0.9091, -0.4615],\n",
      "        [-0.1693, -0.1687,  0.5784,  ..., -0.2689,  0.6041,  0.2350],\n",
      "        [-0.1693, -0.1687,  0.5784,  ..., -0.2689,  0.6041,  0.2350]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02373355 -0.09304289 -0.24677339  0.04496157 -0.22357734 -0.64299494\n",
      " -0.05221949 -0.41502738 -1.4024789  -0.19406903 -0.47578645 -1.6963965\n",
      " -0.3545304  -0.58178174 -2.174543   -0.17309003 -0.70609725 -1.5615706\n",
      "  0.02347508 -0.74357235 -1.3959932  -0.02722362 -0.6768755  -1.4521141\n",
      " -0.02627463 -0.8194258  -1.5691587  -0.13163021 -0.6066332  -1.4746687\n",
      " -0.05802958 -0.6572877  -1.4493302  -0.0703578  -0.63095725 -1.540355\n",
      "  0.05905737 -0.65419567 -1.5775802  -0.04706716 -0.51318836 -1.3090583\n",
      " -0.17021154 -0.28580266 -1.9781327  -0.01164202 -0.4419191  -1.9852788\n",
      "  0.14452685 -0.4082745  -1.4395851  -0.1515084  -0.28138012 -1.2413476\n",
      " -0.07809791 -0.2569893  -1.32596    -0.03802535 -0.26520687 -1.4416137\n",
      "  0.04524281 -0.27753115 -1.283142  ]\n",
      "data: [ 0.02373355 -0.09304289 -0.24677339  0.04496157 -0.22357732 -0.64299494\n",
      " -0.05221949 -0.41502738 -1.4024789  -0.19406903 -0.47578645 -1.6963965\n",
      " -0.35453042 -0.58178174 -2.174543   -0.17309003 -0.70609725 -1.5615706\n",
      "  0.02347508 -0.7435724  -1.3959932  -0.02722361 -0.6768755  -1.4521141\n",
      " -0.02627463 -0.8194258  -1.5691587  -0.13163021 -0.6066332  -1.4746687\n",
      " -0.05802958 -0.6572878  -1.4493301  -0.0703578  -0.63095725 -1.540355\n",
      "  0.05905737 -0.6541956  -1.5775802  -0.04706715 -0.51318836 -1.3090584\n",
      " -0.17021154 -0.28580266 -1.9781327  -0.01164202 -0.4419191  -1.9852787\n",
      "  0.14452685 -0.4082745  -1.4395851  -0.1515084  -0.28138012 -1.2413476\n",
      " -0.07809791 -0.2569893  -1.32596    -0.03802535 -0.26520687 -1.4416137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.04524281 -0.27753115 -1.283142    0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0202, -0.0428, -0.2428,  ...,  0.0467, -0.2376, -1.2630],\n",
      "        [ 0.0202, -0.0428, -0.2428,  ...,  0.0467, -0.2376, -1.2630],\n",
      "        [ 0.0202, -0.0428, -0.2428,  ...,  0.0467, -0.2376, -1.2630],\n",
      "        ...,\n",
      "        [-0.1511,  0.3555, -0.0889,  ..., -0.7689,  0.8455, -0.3547],\n",
      "        [-0.1288, -0.1472,  0.5641,  ..., -0.2013,  0.6140,  0.2126],\n",
      "        [-0.1288, -0.1472,  0.5641,  ..., -0.2013,  0.6140,  0.2126]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02019228 -0.04277489 -0.24275105  0.03716334 -0.16916205 -0.62257725\n",
      " -0.07060383 -0.3640619  -1.3900006  -0.21815836 -0.42654172 -1.6869228\n",
      " -0.38556272 -0.531198   -2.1698554  -0.17956588 -0.66172576 -1.5490582\n",
      "  0.01122697 -0.7040379  -1.3730419  -0.04052994 -0.63539076 -1.4311464\n",
      " -0.04362262 -0.78646815 -1.550343   -0.1363106  -0.56549525 -1.459578\n",
      " -0.06689739 -0.6179882  -1.432195   -0.08236119 -0.5931394  -1.5263836\n",
      "  0.05281722 -0.61507845 -1.5585434  -0.05104025 -0.471264   -1.2930353\n",
      " -0.17723507 -0.24574116 -1.9753094  -0.01677906 -0.40361458 -1.9856722\n",
      "  0.14602163 -0.3733844  -1.4172423  -0.15392727 -0.24128874 -1.2252719\n",
      " -0.08468667 -0.2196204  -1.3114004  -0.04687721 -0.22472754 -1.428191\n",
      "  0.04669012 -0.23758869 -1.2629838 ]\n",
      "data: [ 0.02019228 -0.04277489 -0.24275105  0.03716334 -0.16916205 -0.62257725\n",
      " -0.07060383 -0.3640619  -1.3900006  -0.21815836 -0.42654172 -1.6869228\n",
      " -0.38556272 -0.531198   -2.1698554  -0.17956586 -0.66172576 -1.5490582\n",
      "  0.01122697 -0.7040379  -1.3730419  -0.04052994 -0.63539076 -1.4311464\n",
      " -0.04362262 -0.78646815 -1.550343   -0.1363106  -0.56549525 -1.459578\n",
      " -0.06689739 -0.6179882  -1.432195   -0.08236119 -0.5931394  -1.5263836\n",
      "  0.05281721 -0.61507845 -1.5585434  -0.05104025 -0.471264   -1.2930353\n",
      " -0.17723507 -0.24574116 -1.9753095  -0.01677906 -0.40361458 -1.9856724\n",
      "  0.14602163 -0.3733844  -1.4172423  -0.15392727 -0.24128874 -1.2252719\n",
      " -0.08468667 -0.2196204  -1.3114004  -0.04687721 -0.22472754 -1.428191\n",
      "  0.04669012 -0.23758869 -1.2629838   0.17      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0093, -0.0192, -0.2377,  ...,  0.0328, -0.2122, -1.2846],\n",
      "        [ 0.0093, -0.0192, -0.2377,  ...,  0.0328, -0.2122, -1.2846],\n",
      "        [ 0.0093, -0.0192, -0.2377,  ...,  0.0328, -0.2122, -1.2846],\n",
      "        ...,\n",
      "        [-0.1936,  0.3227, -0.1152,  ..., -0.8308,  0.7761, -0.2918],\n",
      "        [-0.1430, -0.1691,  0.5405,  ..., -0.2129,  0.6058,  0.2098],\n",
      "        [-0.1430, -0.1691,  0.5405,  ..., -0.2129,  0.6058,  0.2098]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00928621 -0.01920857 -0.23772818  0.01956337 -0.15904869 -0.6548717\n",
      " -0.07677667 -0.33936954 -1.3950641  -0.22127128 -0.40305784 -1.6890491\n",
      " -0.39732265 -0.5129807  -2.1619744  -0.19583629 -0.6288817  -1.5481505\n",
      "  0.00258844 -0.6602255  -1.3587403  -0.04320879 -0.59342456 -1.416819\n",
      " -0.03967418 -0.7303786  -1.530963   -0.15452744 -0.5253917  -1.4667717\n",
      " -0.07658036 -0.57796955 -1.4365426  -0.08949334 -0.5558691  -1.5330348\n",
      "  0.05083033 -0.5696417  -1.5772951  -0.07061616 -0.4453826  -1.2992059\n",
      " -0.17573851 -0.22235253 -1.9199605  -0.02888759 -0.36910567 -1.9215189\n",
      "  0.13210061 -0.3430561  -1.43339    -0.16500027 -0.20984398 -1.2357014\n",
      " -0.09659541 -0.19093972 -1.3179374  -0.05129281 -0.197874   -1.434884\n",
      "  0.03277459 -0.21218194 -1.2846292 ]\n",
      "data: [ 0.00928621 -0.01920857 -0.23772818  0.01956337 -0.15904869 -0.6548717\n",
      " -0.07677667 -0.33936954 -1.3950641  -0.22127129 -0.40305787 -1.6890491\n",
      " -0.39732265 -0.5129807  -2.1619744  -0.19583629 -0.6288817  -1.5481505\n",
      "  0.00258844 -0.6602255  -1.3587403  -0.04320879 -0.59342456 -1.416819\n",
      " -0.03967418 -0.7303786  -1.530963   -0.15452744 -0.5253917  -1.4667717\n",
      " -0.07658036 -0.57796955 -1.4365426  -0.08949334 -0.5558691  -1.5330348\n",
      "  0.05083033 -0.5696417  -1.5772951  -0.07061616 -0.44538262 -1.2992059\n",
      " -0.17573851 -0.22235255 -1.9199605  -0.02888759 -0.3691057  -1.9215188\n",
      "  0.13210061 -0.3430561  -1.43339    -0.16500026 -0.20984398 -1.2357014\n",
      " -0.0965954  -0.19093972 -1.3179374  -0.05129281 -0.197874   -1.4348838\n",
      "  0.03277459 -0.21218196 -1.2846292   0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0295, -0.0945, -0.2256,  ...,  0.0405, -0.2796, -1.2881],\n",
      "        [ 0.0295, -0.0945, -0.2256,  ...,  0.0405, -0.2796, -1.2881],\n",
      "        [ 0.0295, -0.0945, -0.2256,  ...,  0.0405, -0.2796, -1.2881],\n",
      "        ...,\n",
      "        [-0.3370,  0.2709, -0.3637,  ..., -0.8788,  0.7226, -0.5099],\n",
      "        [-0.1401, -0.0879,  0.6051,  ..., -0.2403,  0.7060,  0.2835],\n",
      "        [-0.1401, -0.0879,  0.6051,  ..., -0.2403,  0.7060,  0.2835]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02947903 -0.09449033 -0.22562076  0.0494662  -0.23549654 -0.65321016\n",
      " -0.04418155 -0.40826556 -1.3880646  -0.18497194 -0.47085175 -1.6765215\n",
      " -0.3501453  -0.57372755 -2.1577816  -0.16563886 -0.6995197  -1.5421674\n",
      "  0.02106267 -0.72445995 -1.3696043  -0.02279525 -0.657014   -1.4312449\n",
      " -0.02097727 -0.78848106 -1.5430133  -0.1308574  -0.5979456  -1.4678268\n",
      " -0.05482372 -0.64495265 -1.4381151  -0.07517344 -0.6204807  -1.5321007\n",
      "  0.05921961 -0.630571   -1.5757165  -0.0549294  -0.5180179  -1.3017633\n",
      " -0.15279463 -0.29466188 -1.9048996  -0.01601275 -0.43404132 -1.9080775\n",
      "  0.13356791 -0.40873802 -1.4364016  -0.14319922 -0.28572083 -1.2418501\n",
      " -0.08212921 -0.26302388 -1.3198838  -0.03922741 -0.26450065 -1.4380026\n",
      "  0.0404722  -0.2795503  -1.2880957 ]\n",
      "data: [ 0.02947903 -0.09449033 -0.22562076  0.0494662  -0.23549654 -0.65321016\n",
      " -0.04418155 -0.40826556 -1.3880646  -0.18497194 -0.47085175 -1.6765217\n",
      " -0.3501453  -0.57372755 -2.1577816  -0.16563886 -0.69951975 -1.5421673\n",
      "  0.02106267 -0.7244599  -1.3696043  -0.02279525 -0.657014   -1.4312449\n",
      " -0.02097727 -0.78848106 -1.5430133  -0.1308574  -0.5979456  -1.4678268\n",
      " -0.05482372 -0.6449526  -1.4381151  -0.07517344 -0.6204807  -1.5321007\n",
      "  0.05921961 -0.630571   -1.5757165  -0.0549294  -0.5180179  -1.3017633\n",
      " -0.15279463 -0.29466188 -1.9048996  -0.01601275 -0.43404132 -1.9080776\n",
      "  0.13356791 -0.40873802 -1.4364017  -0.14319922 -0.28572083 -1.2418501\n",
      " -0.08212921 -0.26302388 -1.3198838  -0.03922741 -0.26450065 -1.4380026\n",
      "  0.0404722  -0.2795503  -1.2880957   0.19      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0285, -0.0803, -0.2340,  ...,  0.0527, -0.2720, -1.2526],\n",
      "        [ 0.0285, -0.0803, -0.2340,  ...,  0.0527, -0.2720, -1.2526],\n",
      "        [ 0.0285, -0.0803, -0.2340,  ...,  0.0527, -0.2720, -1.2526],\n",
      "        ...,\n",
      "        [-0.1326,  0.4101, -0.0849,  ..., -0.6781,  0.9048, -0.3702],\n",
      "        [-0.1697, -0.1335,  0.5778,  ..., -0.2695,  0.6408,  0.2197],\n",
      "        [-0.1697, -0.1335,  0.5778,  ..., -0.2695,  0.6408,  0.2197]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02847145 -0.08030284 -0.23400176  0.05498813 -0.20074275 -0.6039785\n",
      " -0.05825195 -0.4080009  -1.4027426  -0.20327812 -0.47348276 -1.6963608\n",
      " -0.35907036 -0.57407355 -2.1870222  -0.16387652 -0.70325196 -1.5611544\n",
      "  0.02587382 -0.75316155 -1.3851788  -0.02858418 -0.68538463 -1.4405713\n",
      " -0.0414078  -0.8399539  -1.5628772  -0.12165201 -0.6102208  -1.466548\n",
      " -0.05699994 -0.6634978  -1.4394267  -0.07510778 -0.63463485 -1.5268743\n",
      "  0.05300647 -0.6634426  -1.5553713  -0.03874546 -0.50898767 -1.3008404\n",
      " -0.17738284 -0.2788393  -2.0152836  -0.01021594 -0.4430807  -2.0297492\n",
      "  0.14800236 -0.40876338 -1.4149699  -0.14806302 -0.27966565 -1.2265413\n",
      " -0.07684343 -0.25393113 -1.3124378  -0.04017337 -0.25945124 -1.4264517\n",
      "  0.05271142 -0.27202243 -1.2525954 ]\n",
      "data: [ 0.02847145 -0.08030284 -0.23400176  0.05498813 -0.20074277 -0.6039785\n",
      " -0.05825195 -0.40800086 -1.4027426  -0.20327812 -0.47348273 -1.6963608\n",
      " -0.35907036 -0.57407355 -2.1870222  -0.16387652 -0.70325196 -1.5611544\n",
      "  0.02587382 -0.75316155 -1.3851788  -0.02858418 -0.6853846  -1.4405713\n",
      " -0.0414078  -0.8399539  -1.5628772  -0.12165201 -0.6102208  -1.466548\n",
      " -0.05699994 -0.66349775 -1.4394268  -0.07510778 -0.63463485 -1.5268742\n",
      "  0.05300647 -0.6634426  -1.5553713  -0.03874546 -0.50898767 -1.3008405\n",
      " -0.17738286 -0.2788393  -2.0152836  -0.01021594 -0.44308072 -2.0297492\n",
      "  0.14800236 -0.40876338 -1.4149699  -0.14806302 -0.27966565 -1.2265413\n",
      " -0.07684343 -0.25393113 -1.3124378  -0.04017337 -0.25945124 -1.4264517\n",
      "  0.05271142 -0.27202243 -1.2525954   0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.19  3.19  3.19  ... 3.203 3.205 3.202]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " [3.181 3.181 3.175 ... 3.187 3.178 3.181]\n",
      " ...\n",
      " [2.881 2.881 2.888 ... 2.888 2.892 2.89 ]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]\n",
      " [2.877 2.877 2.881 ... 2.876 2.88  2.883]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0224, -0.0294, -0.2245,  ...,  0.0506, -0.2199, -1.2611],\n",
      "        [ 0.0224, -0.0294, -0.2245,  ...,  0.0506, -0.2199, -1.2611],\n",
      "        [ 0.0224, -0.0294, -0.2245,  ...,  0.0506, -0.2199, -1.2611],\n",
      "        ...,\n",
      "        [-0.1752,  0.3138, -0.0921,  ..., -0.8016,  0.7585, -0.2801],\n",
      "        [-0.1391, -0.1422,  0.5642,  ..., -0.1991,  0.6125,  0.2231],\n",
      "        [-0.1391, -0.1422,  0.5642,  ..., -0.1991,  0.6125,  0.2231]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02235977 -0.02943329 -0.22449256  0.03543291 -0.1676367  -0.63029695\n",
      " -0.05529554 -0.35741526 -1.3777707  -0.20092773 -0.41997123 -1.6808313\n",
      " -0.37707824 -0.53669703 -2.148804   -0.18592001 -0.64263296 -1.5342613\n",
      "  0.03113262 -0.6780659  -1.3385181  -0.02243443 -0.6165737  -1.3931004\n",
      " -0.02722833 -0.75665426 -1.5116166  -0.13910289 -0.5379542  -1.4443015\n",
      " -0.05878784 -0.59574175 -1.4188774  -0.06939655 -0.5728545  -1.5164746\n",
      "  0.06088826 -0.59815407 -1.5608163  -0.04609021 -0.44795874 -1.2731712\n",
      " -0.16757281 -0.22467497 -1.9336927  -0.00931098 -0.383199   -1.9341011\n",
      "  0.14888237 -0.35125306 -1.4133735  -0.15085094 -0.21210827 -1.2083666\n",
      " -0.07077003 -0.193139   -1.2919248  -0.02678904 -0.20849164 -1.4086734\n",
      "  0.05059134 -0.2198879  -1.2610894 ]\n",
      "data: [-4.53 -0.46 -0.99 -4.27 -0.06 -0.69  0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.   -3.82  0.82 -4.09  0.    0.    0.    0.    0.    0.\n",
      "  0.    0.    0.    0.    0.    0.   -3.68  1.25 -4.04 -3.71  1.32 -4.09\n",
      " -3.78  1.43 -4.27  0.    0.    0.   -3.63  1.04 -4.01 -3.69  1.35 -4.08\n",
      " -3.75  1.45 -4.15 -4.84 -0.06 -0.01 -4.76  0.14 -0.28 -4.74  0.28 -0.83\n",
      "  0.    0.    0.    0.  ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[-0.0616, -0.0989, -0.3574,  ...,  0.0308, -0.3425, -0.6167],\n",
      "        [-0.0616, -0.0989, -0.3574,  ...,  0.0308, -0.3425, -0.6167],\n",
      "        [-0.0616, -0.0989, -0.3574,  ...,  0.0308, -0.3425, -0.6167],\n",
      "        ...,\n",
      "        [ 0.5100,  0.4480,  0.0639,  ...,  0.2533,  0.8246, -0.7671],\n",
      "        [ 0.4547, -0.2717,  1.1917,  ..., -1.0919,  0.3483,  0.4608],\n",
      "        [ 0.4547, -0.2717,  1.1917,  ..., -1.0919,  0.3483,  0.4608]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.06159512 -0.09888814 -0.3573879  -0.14766493 -0.18241678 -0.67857355\n",
      " -0.17417017 -0.26297915 -0.89150494 -0.20749469 -0.3308816  -0.9291102\n",
      " -0.20983192 -0.3942481  -1.0895681  -0.22721528 -0.355773   -1.0514485\n",
      " -0.08823545 -0.36254534 -0.65349936 -0.1156304  -0.40354416 -0.6623882\n",
      " -0.10940352 -0.4071207  -0.743747   -0.21565776 -0.3231642  -1.0387394\n",
      " -0.18061316 -0.34741795 -0.9775894  -0.14346008 -0.35464376 -0.95585185\n",
      " -0.08546731 -0.42304897 -0.89687306 -0.1574499  -0.27153972 -0.97456473\n",
      " -0.10960367 -0.30154997 -0.7116641  -0.09800826 -0.32457992 -0.69676304\n",
      "  0.03570297 -0.36801982 -0.81507385 -0.15547906 -0.19662386 -0.8594278\n",
      " -0.06648405 -0.24405976 -0.7866912  -0.06333552 -0.29356343 -0.7742376\n",
      "  0.03076672 -0.34251368 -0.61673343]\n",
      "init: [-0.06159512 -0.09888814 -0.3573879  -0.14766493 -0.18241678 -0.67857355\n",
      " -0.17417017 -0.26297915 -0.89150494 -0.20749469 -0.3308816  -0.9291102\n",
      " -0.20983192 -0.3942481  -1.0895681  -0.22721528 -0.355773   -1.0514485\n",
      " -0.08823545 -0.36254534 -0.65349936 -0.1156304  -0.40354416 -0.6623882\n",
      " -0.10940352 -0.4071207  -0.743747   -0.21565776 -0.3231642  -1.0387394\n",
      " -0.18061316 -0.34741795 -0.9775894  -0.14346008 -0.35464376 -0.95585185\n",
      " -0.08546731 -0.42304897 -0.89687306 -0.1574499  -0.27153972 -0.97456473\n",
      " -0.10960367 -0.30154997 -0.7116641  -0.09800826 -0.32457992 -0.69676304\n",
      "  0.03570297 -0.36801982 -0.81507385 -0.15547906 -0.19662386 -0.8594278\n",
      " -0.06648405 -0.24405976 -0.7866912  -0.06333552 -0.29356343 -0.7742376\n",
      "  0.03076672 -0.34251368 -0.61673343]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [-0.06159512 -0.09888814 -0.3573879  -0.14766493 -0.18241678 -0.67857355\n",
      " -0.17417017 -0.26297915 -0.891505   -0.20749469 -0.33088157 -0.9291103\n",
      " -0.20983192 -0.3942481  -1.0895681  -0.22721528 -0.355773   -1.0514485\n",
      " -0.08823545 -0.36254537 -0.65349936 -0.11563041 -0.40354416 -0.6623882\n",
      " -0.10940352 -0.4071207  -0.743747   -0.21565776 -0.32316417 -1.0387394\n",
      " -0.18061316 -0.34741795 -0.9775894  -0.14346008 -0.35464373 -0.9558518\n",
      " -0.08546731 -0.42304897 -0.8968731  -0.1574499  -0.27153972 -0.97456473\n",
      " -0.10960367 -0.30154997 -0.711664   -0.09800826 -0.32457992 -0.696763\n",
      "  0.03570297 -0.36801982 -0.81507385 -0.15547906 -0.19662386 -0.8594278\n",
      " -0.06648405 -0.24405976 -0.7866912  -0.06333552 -0.29356343 -0.7742376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.03076672 -0.34251368 -0.61673343  0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[ 0.2892, -0.1116, -0.0274,  ...,  0.3475, -0.2799, -1.1951],\n",
      "        [ 0.2892, -0.1116, -0.0274,  ...,  0.3475, -0.2799, -1.1951],\n",
      "        [ 0.2892, -0.1116, -0.0274,  ...,  0.3475, -0.2799, -1.1951],\n",
      "        ...,\n",
      "        [-0.3509,  0.3386,  0.2062,  ..., -0.2344,  1.0064,  0.0143],\n",
      "        [-0.3723,  0.1065,  0.0543,  ..., -0.8547,  0.7977, -0.0714],\n",
      "        [-0.3723,  0.1065,  0.0543,  ..., -0.8547,  0.7977, -0.0714]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.2892052  -0.11159389 -0.02741515  0.33861566 -0.23916528 -0.50993496\n",
      "  0.2948746  -0.3436696  -1.1940434   0.15625882 -0.3730706  -1.4777098\n",
      "  0.05073822 -0.48649526 -2.0213895   0.09556359 -0.66309094 -1.379338\n",
      "  0.39751607 -0.6333294  -1.122509    0.3460033  -0.5440927  -1.1751587\n",
      "  0.32102394 -0.61515456 -1.3030899   0.12420428 -0.5839757  -1.3278599\n",
      "  0.26980007 -0.6057713  -1.328527    0.26500875 -0.52260417 -1.3958173\n",
      "  0.3780082  -0.56310046 -1.4418764   0.25084707 -0.5163857  -1.1678164\n",
      "  0.19998464 -0.2390842  -1.6019726   0.32512933 -0.3806346  -1.5779197\n",
      "  0.46238378 -0.32977885 -1.3653932   0.1331511  -0.29079264 -1.1048086\n",
      "  0.2648838  -0.24446303 -1.1782615   0.3037019  -0.27116925 -1.302675\n",
      "  0.34754008 -0.2798958  -1.1950808 ]\n",
      "data: [ 0.2892052  -0.11159389 -0.02741515  0.33861566 -0.23916526 -0.50993496\n",
      "  0.2948746  -0.3436696  -1.1940434   0.15625882 -0.3730706  -1.4777098\n",
      "  0.05073822 -0.48649526 -2.0213895   0.09556359 -0.66309094 -1.379338\n",
      "  0.39751607 -0.6333294  -1.122509    0.3460033  -0.5440927  -1.1751587\n",
      "  0.32102394 -0.61515456 -1.3030899   0.12420427 -0.5839757  -1.3278598\n",
      "  0.26980007 -0.6057713  -1.328527    0.26500875 -0.52260417 -1.3958173\n",
      "  0.3780082  -0.56310046 -1.4418764   0.25084707 -0.5163857  -1.1678164\n",
      "  0.19998464 -0.2390842  -1.6019727   0.32512933 -0.3806346  -1.5779197\n",
      "  0.46238378 -0.32977885 -1.3653932   0.1331511  -0.29079264 -1.1048086\n",
      "  0.2648838  -0.24446303 -1.1782615   0.3037019  -0.27116925 -1.302675\n",
      "  0.34754008 -0.2798958  -1.1950808   0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0991, -0.0931, -0.1294,  ...,  0.1359, -0.2614, -1.2076],\n",
      "        [ 0.0991, -0.0931, -0.1294,  ...,  0.1359, -0.2614, -1.2076],\n",
      "        [ 0.0991, -0.0931, -0.1294,  ...,  0.1359, -0.2614, -1.2076],\n",
      "        ...,\n",
      "        [-0.2792,  0.3122, -0.0283,  ..., -0.7693,  0.8389, -0.5401],\n",
      "        [-0.3182,  0.0620,  0.3594,  ..., -0.2562,  0.8672, -0.1510],\n",
      "        [-0.3182,  0.0620,  0.3594,  ..., -0.2562,  0.8672, -0.1510]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0990836  -0.09314179 -0.12941873  0.12400255 -0.26048994 -0.55957353\n",
      "  0.06785074 -0.4430298  -1.321447   -0.07196943 -0.50558496 -1.6328049\n",
      " -0.25644803 -0.64935726 -2.1117072  -0.13507846 -0.667788   -1.5244257\n",
      "  0.170044   -0.67908037 -1.2202975   0.11573125 -0.63365394 -1.2582569\n",
      "  0.08787798 -0.7367581  -1.3792622  -0.08584931 -0.5402435  -1.4321455\n",
      "  0.0299793  -0.61069494 -1.4023988   0.03100913 -0.584784   -1.4946207\n",
      "  0.14663748 -0.6225173  -1.5688828   0.03208333 -0.46531    -1.2451272\n",
      " -0.0794217  -0.23936233 -1.8278072   0.07844911 -0.41103595 -1.7982236\n",
      "  0.21951726 -0.36025232 -1.3901112  -0.07997917 -0.22264296 -1.181436\n",
      "  0.03468497 -0.20562966 -1.2185676   0.09845467 -0.25143403 -1.3346069\n",
      "  0.13587597 -0.26144475 -1.2076298 ]\n",
      "data: [ 0.0990836  -0.09314179 -0.12941873  0.12400255 -0.26048994 -0.55957353\n",
      "  0.06785074 -0.4430298  -1.321447   -0.07196943 -0.50558496 -1.6328049\n",
      " -0.25644803 -0.6493572  -2.1117072  -0.13507846 -0.667788   -1.5244259\n",
      "  0.170044   -0.67908037 -1.2202975   0.11573126 -0.63365394 -1.2582569\n",
      "  0.08787798 -0.7367581  -1.3792622  -0.08584931 -0.5402435  -1.4321456\n",
      "  0.0299793  -0.61069494 -1.4023988   0.03100913 -0.584784   -1.4946207\n",
      "  0.14663748 -0.6225173  -1.5688827   0.03208333 -0.46531    -1.2451272\n",
      " -0.0794217  -0.23936233 -1.8278072   0.07844911 -0.41103595 -1.7982236\n",
      "  0.21951728 -0.3602523  -1.3901112  -0.07997917 -0.22264296 -1.181436\n",
      "  0.03468497 -0.20562965 -1.2185676   0.09845467 -0.25143403 -1.3346069\n",
      "  0.13587597 -0.26144475 -1.2076298   0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0246, -0.0876, -0.2159,  ...,  0.0647, -0.2677, -1.2753],\n",
      "        [ 0.0246, -0.0876, -0.2159,  ...,  0.0647, -0.2677, -1.2753],\n",
      "        [ 0.0246, -0.0876, -0.2159,  ...,  0.0647, -0.2677, -1.2753],\n",
      "        ...,\n",
      "        [-0.1028,  0.5222, -0.0966,  ..., -0.6027,  1.0443, -0.4941],\n",
      "        [-0.1544,  0.0124,  0.5803,  ..., -0.2409,  0.7955,  0.1463],\n",
      "        [-0.1544,  0.0124,  0.5803,  ..., -0.2409,  0.7955,  0.1463]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.4595644e-02 -8.7649614e-02 -2.1590614e-01  4.9370226e-02\n",
      " -2.2423454e-01 -5.9941554e-01 -4.7251999e-02 -4.3276685e-01\n",
      " -1.4084921e+00 -1.9889624e-01 -4.9900988e-01 -1.7208235e+00\n",
      " -3.7183896e-01 -6.1948007e-01 -2.2092423e+00 -1.9038644e-01\n",
      " -6.9741499e-01 -1.6050162e+00  6.1796576e-02 -7.3986822e-01\n",
      " -1.3613328e+00  6.8969429e-03 -6.8233395e-01 -1.4078052e+00\n",
      " -1.3778344e-02 -8.2231849e-01 -1.5369936e+00 -1.3912226e-01\n",
      " -5.8733827e-01 -1.5010624e+00 -5.1831655e-02 -6.5472591e-01\n",
      " -1.4750342e+00 -5.3289592e-02 -6.2817681e-01 -1.5705584e+00\n",
      "  8.0164537e-02 -6.6740036e-01 -1.6212204e+00 -3.5210364e-02\n",
      " -4.9174011e-01 -1.3172528e+00 -1.7352998e-01 -2.5882936e-01\n",
      " -2.0017567e+00  1.8806830e-03 -4.3626267e-01 -1.9994822e+00\n",
      "  1.7168242e-01 -3.9205313e-01 -1.4527310e+00 -1.5875620e-01\n",
      " -2.4994309e-01 -1.2417182e+00 -6.2314749e-02 -2.2567256e-01\n",
      " -1.3114629e+00 -1.0491908e-02 -2.5523207e-01 -1.4271759e+00\n",
      "  6.4735301e-02 -2.6772910e-01 -1.2753187e+00]\n",
      "data: [ 2.4595644e-02 -8.7649614e-02 -2.1590614e-01  4.9370226e-02\n",
      " -2.2423454e-01 -5.9941554e-01 -4.7251996e-02 -4.3276682e-01\n",
      " -1.4084921e+00 -1.9889623e-01 -4.9900991e-01 -1.7208235e+00\n",
      " -3.7183896e-01 -6.1948007e-01 -2.2092423e+00 -1.9038644e-01\n",
      " -6.9741499e-01 -1.6050162e+00  6.1796576e-02 -7.3986822e-01\n",
      " -1.3613327e+00  6.8969429e-03 -6.8233401e-01 -1.4078052e+00\n",
      " -1.3778343e-02 -8.2231849e-01 -1.5369935e+00 -1.3912226e-01\n",
      " -5.8733827e-01 -1.5010623e+00 -5.1831655e-02 -6.5472585e-01\n",
      " -1.4750342e+00 -5.3289596e-02 -6.2817681e-01 -1.5705584e+00\n",
      "  8.0164537e-02 -6.6740036e-01 -1.6212204e+00 -3.5210364e-02\n",
      " -4.9174011e-01 -1.3172528e+00 -1.7352998e-01 -2.5882936e-01\n",
      " -2.0017567e+00  1.8806830e-03 -4.3626267e-01 -1.9994822e+00\n",
      "  1.7168242e-01 -3.9205316e-01 -1.4527310e+00 -1.5875620e-01\n",
      " -2.4994308e-01 -1.2417182e+00 -6.2314749e-02 -2.2567254e-01\n",
      " -1.3114629e+00 -1.0491908e-02 -2.5523207e-01 -1.4271759e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  6.4735301e-02 -2.6772910e-01 -1.2753187e+00  3.9999999e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0243, -0.1195, -0.2455,  ...,  0.0630, -0.2966, -1.3201],\n",
      "        [ 0.0243, -0.1195, -0.2455,  ...,  0.0630, -0.2966, -1.3201],\n",
      "        [ 0.0243, -0.1195, -0.2455,  ...,  0.0630, -0.2966, -1.3201],\n",
      "        ...,\n",
      "        [-0.1069,  0.4229, -0.1196,  ..., -0.6190,  0.9267, -0.4073],\n",
      "        [-0.1204, -0.0885,  0.6407,  ..., -0.2091,  0.6557,  0.3153],\n",
      "        [-0.1204, -0.0885,  0.6407,  ..., -0.2091,  0.6557,  0.3153]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02428309 -0.11954894 -0.24548194  0.03990952 -0.2724902  -0.6756314\n",
      " -0.02216232 -0.45206437 -1.400195   -0.16421367 -0.5122546  -1.7101653\n",
      " -0.34176058 -0.644566   -2.168634   -0.19119185 -0.71943474 -1.573407\n",
      "  0.07108244 -0.7424136  -1.3610795   0.01575805 -0.68934155 -1.4079131\n",
      "  0.01256885 -0.8080539  -1.5257204  -0.13991244 -0.6040507  -1.4842148\n",
      " -0.03723163 -0.66655755 -1.4658813  -0.03576914 -0.64043045 -1.5658762\n",
      "  0.0862408  -0.6747672  -1.6269851  -0.03258388 -0.51800406 -1.3064071\n",
      " -0.14247288 -0.29373097 -1.9142742   0.01304565 -0.45359907 -1.900081\n",
      "  0.16608733 -0.41395122 -1.4770432  -0.14636952 -0.27400756 -1.2450683\n",
      " -0.0424509  -0.25512287 -1.3232636   0.01015969 -0.28821456 -1.4401362\n",
      "  0.06304202 -0.29660445 -1.3201377 ]\n",
      "data: [ 0.02428309 -0.11954894 -0.24548192  0.03990952 -0.2724902  -0.6756314\n",
      " -0.02216232 -0.45206437 -1.400195   -0.16421367 -0.5122546  -1.7101653\n",
      " -0.34176055 -0.64456594 -2.168634   -0.19119185 -0.71943474 -1.5734069\n",
      "  0.07108244 -0.7424136  -1.3610795   0.01575805 -0.6893416  -1.4079131\n",
      "  0.01256885 -0.8080539  -1.5257204  -0.13991244 -0.6040507  -1.4842148\n",
      " -0.03723163 -0.66655755 -1.4658813  -0.03576914 -0.64043045 -1.5658764\n",
      "  0.0862408  -0.67476726 -1.6269851  -0.03258388 -0.51800406 -1.3064072\n",
      " -0.14247288 -0.29373097 -1.9142743   0.01304565 -0.45359907 -1.900081\n",
      "  0.16608733 -0.41395122 -1.4770432  -0.14636952 -0.27400756 -1.2450683\n",
      " -0.0424509  -0.25512287 -1.3232636   0.01015969 -0.28821456 -1.4401363\n",
      "  0.06304202 -0.29660445 -1.3201377   0.05      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0610, -0.1881, -0.2800,  ...,  0.0731, -0.3645, -1.3512],\n",
      "        [ 0.0610, -0.1881, -0.2800,  ...,  0.0731, -0.3645, -1.3512],\n",
      "        [ 0.0610, -0.1881, -0.2800,  ...,  0.0731, -0.3645, -1.3512],\n",
      "        ...,\n",
      "        [-0.0803,  0.4768, -0.1248,  ..., -0.6099,  0.9725, -0.4584],\n",
      "        [-0.1445, -0.0454,  0.6598,  ..., -0.1949,  0.6979,  0.3127],\n",
      "        [-0.1445, -0.0454,  0.6598,  ..., -0.1949,  0.6979,  0.3127]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0610242  -0.18809211 -0.27998686  0.0884272  -0.3227576  -0.6722292\n",
      "  0.00327726 -0.5266839  -1.4626255  -0.14412719 -0.58906525 -1.7718278\n",
      " -0.3093778  -0.70590043 -2.2612972  -0.14879082 -0.7997464  -1.6507785\n",
      "  0.09208198 -0.8426266  -1.4410006   0.0313105  -0.7861967  -1.4873751\n",
      "  0.0102001  -0.9250101  -1.610809   -0.10034478 -0.6936878  -1.5505732\n",
      " -0.01854564 -0.75655806 -1.5283685  -0.02851769 -0.7297543  -1.6239767\n",
      "  0.08429462 -0.7690097  -1.6689287  -0.00229212 -0.5925791  -1.3766435\n",
      " -0.14244    -0.36394832 -2.0621588   0.02350897 -0.53630555 -2.062357\n",
      "  0.17098993 -0.49364004 -1.5177222  -0.12440309 -0.35472023 -1.3059919\n",
      " -0.03261502 -0.33110076 -1.3810996   0.01014023 -0.35780498 -1.494496\n",
      "  0.07314367 -0.36447144 -1.3511688 ]\n",
      "data: [ 0.0610242  -0.18809211 -0.27998686  0.0884272  -0.3227576  -0.6722292\n",
      "  0.00327726 -0.5266839  -1.4626254  -0.14412719 -0.58906525 -1.7718278\n",
      " -0.3093778  -0.70590043 -2.2612972  -0.14879082 -0.7997464  -1.6507785\n",
      "  0.09208198 -0.8426266  -1.4410005   0.0313105  -0.78619677 -1.4873751\n",
      "  0.0102001  -0.9250101  -1.610809   -0.10034477 -0.6936878  -1.5505732\n",
      " -0.01854564 -0.75655806 -1.5283685  -0.0285177  -0.7297543  -1.6239767\n",
      "  0.08429462 -0.7690097  -1.6689286  -0.00229212 -0.5925791  -1.3766435\n",
      " -0.14244    -0.36394832 -2.0621588   0.02350897 -0.53630555 -2.062357\n",
      "  0.17098993 -0.49364004 -1.5177224  -0.12440309 -0.35472023 -1.3059918\n",
      " -0.03261502 -0.33110076 -1.3810996   0.01014023 -0.35780498 -1.494496\n",
      "  0.07314367 -0.36447144 -1.3511689   0.06      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[-1.0588e-02, -1.4278e-01, -1.8799e-01,  ...,  4.6696e-02,\n",
      "         -3.3009e-01, -1.2345e+00],\n",
      "        [-1.0588e-02, -1.4278e-01, -1.8799e-01,  ...,  4.6696e-02,\n",
      "         -3.3009e-01, -1.2345e+00],\n",
      "        [-1.0588e-02, -1.4278e-01, -1.8799e-01,  ...,  4.6696e-02,\n",
      "         -3.3009e-01, -1.2345e+00],\n",
      "        ...,\n",
      "        [-2.6975e-02,  5.3857e-01, -1.3604e-01,  ..., -5.3487e-01,\n",
      "          1.0936e+00, -5.3815e-01],\n",
      "        [-7.5178e-02,  1.1375e-03,  6.0047e-01,  ..., -1.0785e-01,\n",
      "          6.6040e-01,  2.6148e-01],\n",
      "        [-7.5178e-02,  1.1375e-03,  6.0047e-01,  ..., -1.0785e-01,\n",
      "          6.6040e-01,  2.6148e-01]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01058777 -0.14277557 -0.18798932  0.00965619 -0.28521892 -0.54969966\n",
      " -0.05334686 -0.47655338 -1.3244838  -0.20493993 -0.53367054 -1.6535815\n",
      " -0.39097893 -0.67456055 -2.1289983  -0.23278095 -0.7434703  -1.5354764\n",
      "  0.0526277  -0.77587056 -1.3285698  -0.01327248 -0.72639644 -1.3711553\n",
      " -0.01366428 -0.8560504  -1.495071   -0.17026901 -0.6285124  -1.4275339\n",
      " -0.06437545 -0.6997583  -1.4153764  -0.05796877 -0.6795293  -1.5254374\n",
      "  0.06028742 -0.7256707  -1.5825651  -0.05019306 -0.5356957  -1.2346733\n",
      " -0.18240781 -0.30996883 -1.9073956  -0.00870608 -0.4911001  -1.8936838\n",
      "  0.15414326 -0.44954833 -1.4079942  -0.17993738 -0.29148215 -1.1718132\n",
      " -0.05977298 -0.27967516 -1.2439901  -0.00894105 -0.32461643 -1.3602705\n",
      "  0.0466963  -0.33008593 -1.2345012 ]\n",
      "data: [-0.01058777 -0.14277557 -0.18798932  0.00965619 -0.28521892 -0.54969966\n",
      " -0.05334686 -0.47655338 -1.3244838  -0.20493993 -0.53367054 -1.6535815\n",
      " -0.39097893 -0.67456055 -2.1289983  -0.23278095 -0.7434703  -1.5354763\n",
      "  0.0526277  -0.77587056 -1.3285698  -0.01327248 -0.7263964  -1.3711553\n",
      " -0.01366428 -0.8560503  -1.495071   -0.17026901 -0.6285124  -1.4275339\n",
      " -0.06437545 -0.6997583  -1.4153764  -0.05796877 -0.67952937 -1.5254374\n",
      "  0.06028742 -0.7256707  -1.582565   -0.05019306 -0.5356957  -1.2346733\n",
      " -0.18240781 -0.30996883 -1.9073956  -0.00870608 -0.49110013 -1.8936838\n",
      "  0.15414326 -0.44954833 -1.407994   -0.17993738 -0.29148215 -1.1718132\n",
      " -0.05977298 -0.27967516 -1.2439901  -0.00894105 -0.32461643 -1.3602705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.04669629 -0.33008593 -1.2345012   0.07      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BB38>\n",
      "tensor([[ 0.0102, -0.0890, -0.1745,  ...,  0.0292, -0.2859, -1.1470],\n",
      "        [ 0.0102, -0.0890, -0.1745,  ...,  0.0292, -0.2859, -1.1470],\n",
      "        [ 0.0102, -0.0890, -0.1745,  ...,  0.0292, -0.2859, -1.1470],\n",
      "        ...,\n",
      "        [-0.1502,  0.4302, -0.0958,  ..., -0.3828,  1.0288, -0.5192],\n",
      "        [-0.0911, -0.0694,  0.6329,  ..., -0.2184,  0.6463,  0.2692],\n",
      "        [-0.0911, -0.0694,  0.6329,  ..., -0.2184,  0.6463,  0.2692]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01020548 -0.08899603 -0.17448173  0.04284561 -0.18452308 -0.4422792\n",
      " -0.11944649 -0.4257366  -1.3232718  -0.27532575 -0.49587703 -1.6038108\n",
      " -0.41768613 -0.57529056 -2.126519   -0.17739171 -0.73899066 -1.4984901\n",
      " -0.02975395 -0.81374776 -1.3538704  -0.07923384 -0.7334266  -1.4047964\n",
      " -0.08820219 -0.9120207  -1.5317428  -0.13830058 -0.65664303 -1.396625\n",
      " -0.09383081 -0.70535827 -1.3632185  -0.10614808 -0.6660391  -1.438674\n",
      "  0.0416771  -0.6984756  -1.4468226  -0.0613156  -0.5386749  -1.2421343\n",
      " -0.23005739 -0.29807603 -2.028931   -0.03719887 -0.4739975  -2.0633757\n",
      "  0.14546034 -0.4311972  -1.3200438  -0.18581872 -0.31281704 -1.157182\n",
      " -0.12701198 -0.27852133 -1.2473352  -0.09925075 -0.27050698 -1.3601727\n",
      "  0.02919466 -0.28586328 -1.1469564 ]\n",
      "data: [ 0.01020548 -0.08899603 -0.17448173  0.04284561 -0.18452306 -0.44227922\n",
      " -0.11944649 -0.4257366  -1.3232718  -0.27532575 -0.49587703 -1.6038108\n",
      " -0.4176861  -0.57529056 -2.126519   -0.17739171 -0.7389906  -1.4984901\n",
      " -0.02975395 -0.81374776 -1.3538704  -0.07923384 -0.7334266  -1.4047962\n",
      " -0.08820219 -0.91202074 -1.5317428  -0.13830058 -0.6566431  -1.396625\n",
      " -0.0938308  -0.70535827 -1.3632185  -0.10614808 -0.6660391  -1.438674\n",
      "  0.0416771  -0.6984756  -1.4468226  -0.0613156  -0.5386749  -1.2421343\n",
      " -0.23005739 -0.29807603 -2.028931   -0.03719887 -0.4739975  -2.0633757\n",
      "  0.14546034 -0.4311972  -1.3200438  -0.18581872 -0.31281704 -1.157182\n",
      " -0.12701198 -0.27852133 -1.2473352  -0.09925075 -0.27050698 -1.3601727\n",
      "  0.02919466 -0.28586328 -1.1469564   0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[-0.0425,  0.0082, -0.2159,  ..., -0.0048, -0.1770, -1.1976],\n",
      "        [-0.0425,  0.0082, -0.2159,  ..., -0.0048, -0.1770, -1.1976],\n",
      "        [-0.0425,  0.0082, -0.2159,  ..., -0.0048, -0.1770, -1.1976],\n",
      "        ...,\n",
      "        [-0.1304,  0.3661,  0.1172,  ..., -0.6541,  0.9515, -0.2600],\n",
      "        [-0.0725, -0.0687,  0.5986,  ..., -0.2261,  0.6476,  0.2675],\n",
      "        [-0.0725, -0.0687,  0.5986,  ..., -0.2261,  0.6476,  0.2675]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.04254099  0.00817353 -0.21592948 -0.02015235 -0.10115206 -0.536059\n",
      " -0.16061422 -0.32004815 -1.3597233  -0.31758484 -0.3820755  -1.6518495\n",
      " -0.47889867 -0.47604698 -2.1475694  -0.24254376 -0.62623006 -1.5224819\n",
      " -0.06341258 -0.68262464 -1.3538148  -0.10850455 -0.6036809  -1.4075768\n",
      " -0.10495126 -0.7676115  -1.5346196  -0.19877376 -0.53507674 -1.4237239\n",
      " -0.13361621 -0.58577764 -1.3915386  -0.1336798  -0.5491936  -1.4794235\n",
      "  0.02656446 -0.576899   -1.5021238  -0.1113487  -0.42754978 -1.2586844\n",
      " -0.26024538 -0.18777855 -2.0046935  -0.06858686 -0.35759008 -2.0268164\n",
      "  0.12657595 -0.3175578  -1.365453   -0.23153806 -0.19502984 -1.1791518\n",
      " -0.16215652 -0.16298264 -1.2695501  -0.12383194 -0.16372453 -1.3874145\n",
      " -0.00484588 -0.1769605  -1.1976197 ]\n",
      "data: [-0.04254098  0.00817353 -0.21592946 -0.02015235 -0.10115205 -0.536059\n",
      " -0.16061422 -0.32004815 -1.3597233  -0.31758484 -0.3820755  -1.6518495\n",
      " -0.47889864 -0.47604698 -2.1475694  -0.24254376 -0.62623006 -1.522482\n",
      " -0.06341258 -0.68262464 -1.3538148  -0.10850456 -0.6036809  -1.4075768\n",
      " -0.10495127 -0.76761156 -1.5346196  -0.19877377 -0.53507674 -1.4237239\n",
      " -0.13361621 -0.58577764 -1.3915387  -0.1336798  -0.5491936  -1.4794235\n",
      "  0.02656446 -0.576899   -1.5021238  -0.1113487  -0.42754978 -1.2586844\n",
      " -0.26024538 -0.18777855 -2.0046935  -0.06858686 -0.35759008 -2.0268164\n",
      "  0.12657595 -0.3175578  -1.365453   -0.23153804 -0.19502982 -1.1791518\n",
      " -0.16215652 -0.16298264 -1.2695501  -0.12383194 -0.16372451 -1.3874145\n",
      " -0.00484588 -0.17696051 -1.1976197   0.09      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182B9B0>\n",
      "tensor([[-0.0039, -0.0861, -0.1984,  ...,  0.0090, -0.2433, -1.3269],\n",
      "        [-0.0039, -0.0861, -0.1984,  ...,  0.0090, -0.2433, -1.3269],\n",
      "        [-0.0039, -0.0861, -0.1984,  ...,  0.0090, -0.2433, -1.3269],\n",
      "        ...,\n",
      "        [-0.2789,  0.3238, -0.1976,  ..., -0.8100,  0.7879, -0.3633],\n",
      "        [-0.1926, -0.1087,  0.5036,  ..., -0.2819,  0.6379,  0.2458],\n",
      "        [-0.1926, -0.1087,  0.5036,  ..., -0.2819,  0.6379,  0.2458]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-3.9314665e-03 -8.6066231e-02 -1.9840765e-01  1.0187391e-02\n",
      " -2.4983004e-01 -6.8162209e-01 -2.7394466e-02 -3.8574666e-01\n",
      " -1.3421468e+00 -1.6523568e-01 -4.3579304e-01 -1.6496226e+00\n",
      " -3.4727138e-01 -5.6987488e-01 -2.1088181e+00 -2.2757548e-01\n",
      " -6.5904897e-01 -1.4997323e+00  4.7193632e-02 -6.5080243e-01\n",
      " -1.2763767e+00 -1.4150143e-03 -5.9682953e-01 -1.3290987e+00\n",
      " -1.2650490e-03 -6.8603295e-01 -1.4425930e+00 -1.8506899e-01\n",
      " -5.4265130e-01 -1.4298711e+00 -6.7418337e-02 -5.9401035e-01\n",
      " -1.4230188e+00 -6.8122126e-02 -5.6167811e-01 -1.5324823e+00\n",
      "  5.5468008e-02 -5.8204293e-01 -1.6100479e+00 -8.1399344e-02\n",
      " -4.7623277e-01 -1.2542114e+00 -1.5232871e-01 -2.4954785e-01\n",
      " -1.7582494e+00 -2.4549097e-02 -3.8231218e-01 -1.7343078e+00\n",
      "  1.1546677e-01 -3.5215390e-01 -1.4683981e+00 -1.7889538e-01\n",
      " -2.3065148e-01 -1.2078363e+00 -8.0190152e-02 -2.1127658e-01\n",
      " -1.2865533e+00 -2.5229558e-02 -2.3893744e-01 -1.4097779e+00\n",
      "  8.9619458e-03 -2.4330273e-01 -1.3269126e+00]\n",
      "data: [-3.9314665e-03 -8.6066224e-02 -1.9840765e-01  1.0187391e-02\n",
      " -2.4983004e-01 -6.8162209e-01 -2.7394466e-02 -3.8574666e-01\n",
      " -1.3421468e+00 -1.6523570e-01 -4.3579304e-01 -1.6496224e+00\n",
      " -3.4727138e-01 -5.6987488e-01 -2.1088181e+00 -2.2757548e-01\n",
      " -6.5904897e-01 -1.4997323e+00  4.7193632e-02 -6.5080243e-01\n",
      " -1.2763767e+00 -1.4150143e-03 -5.9682953e-01 -1.3290987e+00\n",
      " -1.2650490e-03 -6.8603295e-01 -1.4425930e+00 -1.8506899e-01\n",
      " -5.4265130e-01 -1.4298711e+00 -6.7418337e-02 -5.9401035e-01\n",
      " -1.4230188e+00 -6.8122126e-02 -5.6167811e-01 -1.5324823e+00\n",
      "  5.5468008e-02 -5.8204293e-01 -1.6100479e+00 -8.1399344e-02\n",
      " -4.7623277e-01 -1.2542114e+00 -1.5232871e-01 -2.4954787e-01\n",
      " -1.7582494e+00 -2.4549099e-02 -3.8231218e-01 -1.7343078e+00\n",
      "  1.1546677e-01 -3.5215390e-01 -1.4683981e+00 -1.7889538e-01\n",
      " -2.3065147e-01 -1.2078363e+00 -8.0190152e-02 -2.1127658e-01\n",
      " -1.2865531e+00 -2.5229558e-02 -2.3893744e-01 -1.4097779e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  8.9619458e-03 -2.4330273e-01 -1.3269126e+00  1.0000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0414, -0.1406, -0.2970,  ...,  0.0524, -0.3103, -1.3601],\n",
      "        [ 0.0414, -0.1406, -0.2970,  ...,  0.0524, -0.3103, -1.3601],\n",
      "        [ 0.0414, -0.1406, -0.2970,  ...,  0.0524, -0.3103, -1.3601],\n",
      "        ...,\n",
      "        [-0.1042,  0.5352, -0.0094,  ..., -0.6975,  1.0745, -0.3261],\n",
      "        [-0.1662, -0.0392,  0.6563,  ..., -0.2748,  0.7425,  0.3060],\n",
      "        [-0.1662, -0.0392,  0.6563,  ..., -0.2748,  0.7425,  0.3060]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 4.14253585e-02 -1.40624598e-01 -2.96994686e-01  7.38958716e-02\n",
      " -2.66126901e-01 -6.95631802e-01 -2.72081494e-02 -4.62107509e-01\n",
      " -1.48364639e+00 -1.71550885e-01 -5.22535205e-01 -1.78028774e+00\n",
      " -3.19743872e-01 -6.23710871e-01 -2.27878070e+00 -1.58568695e-01\n",
      " -7.47373104e-01 -1.65606236e+00  4.87852395e-02 -7.85620213e-01\n",
      " -1.47490573e+00 -3.77534330e-03 -7.21654534e-01 -1.52878094e+00\n",
      " -1.97874531e-02 -8.61985922e-01 -1.65219522e+00 -1.17605925e-01\n",
      " -6.50354207e-01 -1.56452179e+00 -4.42406535e-02 -7.02839851e-01\n",
      " -1.54264808e+00 -5.90998605e-02 -6.70221925e-01 -1.63235831e+00\n",
      "  6.47605658e-02 -7.02940524e-01 -1.67213106e+00 -3.16054747e-02\n",
      " -5.51005483e-01 -1.39542365e+00 -1.61677167e-01 -3.16533059e-01\n",
      " -2.06766105e+00 -6.45622611e-04 -4.77949679e-01 -2.07719111e+00\n",
      "  1.50485933e-01 -4.40693438e-01 -1.52885342e+00 -1.42413065e-01\n",
      " -3.18911701e-01 -1.32284069e+00 -6.50543272e-02 -2.87480712e-01\n",
      " -1.39868259e+00 -2.44659334e-02 -2.99039215e-01 -1.51496983e+00\n",
      "  5.24304062e-02 -3.10259104e-01 -1.36009002e+00]\n",
      "data: [ 4.14253585e-02 -1.40624598e-01 -2.96994686e-01  7.38958716e-02\n",
      " -2.66126901e-01 -6.95631802e-01 -2.72081494e-02 -4.62107509e-01\n",
      " -1.48364639e+00 -1.71550885e-01 -5.22535205e-01 -1.78028774e+00\n",
      " -3.19743872e-01 -6.23710871e-01 -2.27878070e+00 -1.58568695e-01\n",
      " -7.47373104e-01 -1.65606236e+00  4.87852395e-02 -7.85620213e-01\n",
      " -1.47490573e+00 -3.77534330e-03 -7.21654534e-01 -1.52878094e+00\n",
      " -1.97874531e-02 -8.61985922e-01 -1.65219533e+00 -1.17605925e-01\n",
      " -6.50354207e-01 -1.56452179e+00 -4.42406572e-02 -7.02839792e-01\n",
      " -1.54264796e+00 -5.90998605e-02 -6.70221925e-01 -1.63235819e+00\n",
      "  6.47605658e-02 -7.02940524e-01 -1.67213106e+00 -3.16054747e-02\n",
      " -5.51005483e-01 -1.39542353e+00 -1.61677167e-01 -3.16533059e-01\n",
      " -2.06766105e+00 -6.45622611e-04 -4.77949679e-01 -2.07719111e+00\n",
      "  1.50485933e-01 -4.40693438e-01 -1.52885342e+00 -1.42413065e-01\n",
      " -3.18911701e-01 -1.32284069e+00 -6.50543272e-02 -2.87480712e-01\n",
      " -1.39868259e+00 -2.44659334e-02 -2.99039215e-01 -1.51496983e+00\n",
      "  5.24304062e-02 -3.10259104e-01 -1.36009002e+00  1.09999999e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63828>\n",
      "tensor([[ 0.0102, -0.1145, -0.2258,  ...,  0.0478, -0.2931, -1.3161],\n",
      "        [ 0.0102, -0.1145, -0.2258,  ...,  0.0478, -0.2931, -1.3161],\n",
      "        [ 0.0102, -0.1145, -0.2258,  ...,  0.0478, -0.2931, -1.3161],\n",
      "        ...,\n",
      "        [-0.0794,  0.5017, -0.1160,  ..., -0.6693,  1.0016, -0.3883],\n",
      "        [-0.1045, -0.0615,  0.5688,  ..., -0.1789,  0.6474,  0.2537],\n",
      "        [-0.1045, -0.0615,  0.5688,  ..., -0.1789,  0.6474,  0.2537]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01018016 -0.11450277 -0.22584413  0.02155941 -0.27464256 -0.67332107\n",
      " -0.00358649 -0.43742058 -1.377435   -0.14427666 -0.4896078  -1.7102168\n",
      " -0.33634198 -0.6404085  -2.1619358  -0.21621694 -0.69447386 -1.5714881\n",
      "  0.09091055 -0.70549726 -1.3485742   0.02536862 -0.6626544  -1.3939137\n",
      "  0.02740481 -0.7708397  -1.5128651  -0.15789497 -0.5708535  -1.4732196\n",
      " -0.03951471 -0.6395047  -1.4637716  -0.03514241 -0.6239768  -1.5788312\n",
      "  0.0710746  -0.6635473  -1.6515992  -0.03771158 -0.49180084 -1.280417\n",
      " -0.14521345 -0.2725275  -1.8754551   0.00439011 -0.4381483  -1.8477159\n",
      "  0.14868958 -0.40175816 -1.4768887  -0.15768072 -0.24450487 -1.2238371\n",
      " -0.03354894 -0.23676848 -1.2935264   0.01969415 -0.28806862 -1.4095697\n",
      "  0.0477918  -0.29308414 -1.3161416 ]\n",
      "data: [ 0.01018016 -0.11450277 -0.22584413  0.02155941 -0.27464256 -0.67332107\n",
      " -0.00358649 -0.43742058 -1.377435   -0.14427666 -0.4896078  -1.7102169\n",
      " -0.33634198 -0.64040846 -2.1619358  -0.21621695 -0.69447386 -1.5714881\n",
      "  0.09091055 -0.70549726 -1.3485742   0.02536862 -0.6626544  -1.3939137\n",
      "  0.02740481 -0.7708397  -1.512865   -0.15789497 -0.5708535  -1.4732196\n",
      " -0.03951471 -0.6395047  -1.4637715  -0.03514241 -0.6239768  -1.5788312\n",
      "  0.0710746  -0.6635473  -1.6515992  -0.03771158 -0.49180084 -1.280417\n",
      " -0.14521345 -0.2725275  -1.8754551   0.00439011 -0.43814832 -1.8477159\n",
      "  0.14868958 -0.40175816 -1.4768888  -0.15768072 -0.24450487 -1.2238371\n",
      " -0.03354894 -0.2367685  -1.2935264   0.01969415 -0.28806862 -1.4095697\n",
      "  0.0477918  -0.29308414 -1.3161416   0.12      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0359, -0.1146, -0.2504,  ...,  0.0521, -0.3010, -1.2967],\n",
      "        [ 0.0359, -0.1146, -0.2504,  ...,  0.0521, -0.3010, -1.2967],\n",
      "        [ 0.0359, -0.1146, -0.2504,  ...,  0.0521, -0.3010, -1.2967],\n",
      "        ...,\n",
      "        [-0.1612,  0.4631, -0.1471,  ..., -0.6781,  0.9676, -0.4664],\n",
      "        [-0.1802, -0.1149,  0.6332,  ..., -0.2529,  0.6502,  0.2766],\n",
      "        [-0.1802, -0.1149,  0.6332,  ..., -0.2529,  0.6502,  0.2766]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03585218 -0.11458728 -0.25039652  0.05579716 -0.2486906  -0.64890766\n",
      " -0.04463922 -0.45155644 -1.4276011  -0.18919799 -0.51681215 -1.7225263\n",
      " -0.35141748 -0.6251986  -2.2021892  -0.16654734 -0.734077   -1.5912087\n",
      "  0.03742208 -0.7792678  -1.4024708  -0.01718561 -0.7138295  -1.4550059\n",
      " -0.02651339 -0.85799325 -1.5735109  -0.12309854 -0.6314515  -1.499954\n",
      " -0.05237073 -0.68669903 -1.4710281  -0.06606036 -0.6610311  -1.5589628\n",
      "  0.05748755 -0.68714833 -1.5950084  -0.03534272 -0.53552663 -1.3339837\n",
      " -0.16567965 -0.3084756  -2.0045364  -0.0076405  -0.4699648  -2.0099168\n",
      "  0.14601985 -0.43207756 -1.455404   -0.14461286 -0.3007447  -1.2626941\n",
      " -0.06863384 -0.27657515 -1.3464813  -0.02795851 -0.289276   -1.4587066\n",
      "  0.05213434 -0.30100125 -1.2967    ]\n",
      "data: [ 0.03585218 -0.11458728 -0.25039652  0.05579716 -0.2486906  -0.6489076\n",
      " -0.04463922 -0.45155644 -1.4276012  -0.18919797 -0.51681215 -1.7225262\n",
      " -0.35141745 -0.6251986  -2.2021892  -0.16654734 -0.734077   -1.5912087\n",
      "  0.03742208 -0.7792678  -1.4024708  -0.01718561 -0.7138295  -1.455006\n",
      " -0.02651339 -0.85799325 -1.5735109  -0.12309854 -0.6314515  -1.4999539\n",
      " -0.05237073 -0.6866991  -1.4710281  -0.06606036 -0.6610311  -1.5589628\n",
      "  0.05748754 -0.68714833 -1.5950084  -0.03534272 -0.53552663 -1.3339837\n",
      " -0.16567965 -0.3084756  -2.0045364  -0.0076405  -0.4699648  -2.0099168\n",
      "  0.14601985 -0.43207756 -1.455404   -0.14461286 -0.3007447  -1.2626941\n",
      " -0.06863384 -0.27657515 -1.3464813  -0.02795851 -0.289276   -1.4587066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.05213434 -0.30100125 -1.2967      0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE59F644E0>\n",
      "tensor([[ 0.0012, -0.0651, -0.1802,  ...,  0.0688, -0.2714, -1.1702],\n",
      "        [ 0.0012, -0.0651, -0.1802,  ...,  0.0688, -0.2714, -1.1702],\n",
      "        [ 0.0012, -0.0651, -0.1802,  ...,  0.0688, -0.2714, -1.1702],\n",
      "        ...,\n",
      "        [-0.1216,  0.4051, -0.1098,  ..., -0.7534,  0.9040, -0.3865],\n",
      "        [-0.1292, -0.1142,  0.5663,  ..., -0.2283,  0.5973,  0.2157],\n",
      "        [-0.1292, -0.1142,  0.5663,  ..., -0.2283,  0.5973,  0.2157]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 1.2120875e-03 -6.5107390e-02 -1.8018021e-01  2.7200203e-02\n",
      " -1.7871039e-01 -5.0032353e-01 -8.3583899e-02 -3.8758451e-01\n",
      " -1.3032666e+00 -2.3214810e-01 -4.4878006e-01 -1.6046503e+00\n",
      " -3.9068037e-01 -5.6091702e-01 -2.0932143e+00 -1.9361559e-01\n",
      " -6.8718809e-01 -1.4823297e+00  1.8203929e-02 -7.4071062e-01\n",
      " -1.3205131e+00 -3.9762825e-02 -6.7453879e-01 -1.3703523e+00\n",
      " -4.0572926e-02 -8.3347660e-01 -1.4936062e+00 -1.3925782e-01\n",
      " -5.9589475e-01 -1.3809764e+00 -6.3174963e-02 -6.5562928e-01\n",
      " -1.3638532e+00 -6.7120895e-02 -6.2830800e-01 -1.4545351e+00\n",
      "  6.4730823e-02 -6.6877002e-01 -1.4834069e+00 -4.0796764e-02\n",
      " -4.9411637e-01 -1.2093936e+00 -1.8547241e-01 -2.6148170e-01\n",
      " -1.9536487e+00  6.7478418e-04 -4.4153154e-01 -1.9650139e+00\n",
      "  1.7135738e-01 -4.0405053e-01 -1.3393919e+00 -1.6085251e-01\n",
      " -2.6516163e-01 -1.1370610e+00 -6.9515198e-02 -2.4403551e-01\n",
      " -1.2261345e+00 -2.8815448e-02 -2.6008862e-01 -1.3417487e+00\n",
      "  6.8771549e-02 -2.7141064e-01 -1.1701620e+00]\n",
      "data: [ 1.2120875e-03 -6.5107390e-02 -1.8018021e-01  2.7200203e-02\n",
      " -1.7871039e-01 -5.0032353e-01 -8.3583899e-02 -3.8758451e-01\n",
      " -1.3032666e+00 -2.3214810e-01 -4.4878006e-01 -1.6046503e+00\n",
      " -3.9068040e-01 -5.6091702e-01 -2.0932143e+00 -1.9361559e-01\n",
      " -6.8718809e-01 -1.4823297e+00  1.8203929e-02 -7.4071062e-01\n",
      " -1.3205131e+00 -3.9762825e-02 -6.7453879e-01 -1.3703523e+00\n",
      " -4.0572926e-02 -8.3347666e-01 -1.4936062e+00 -1.3925782e-01\n",
      " -5.9589475e-01 -1.3809764e+00 -6.3174963e-02 -6.5562928e-01\n",
      " -1.3638531e+00 -6.7120895e-02 -6.2830800e-01 -1.4545350e+00\n",
      "  6.4730823e-02 -6.6877002e-01 -1.4834068e+00 -4.0796768e-02\n",
      " -4.9411637e-01 -1.2093936e+00 -1.8547241e-01 -2.6148170e-01\n",
      " -1.9536487e+00  6.7478418e-04 -4.4153154e-01 -1.9650139e+00\n",
      "  1.7135738e-01 -4.0405053e-01 -1.3393919e+00 -1.6085251e-01\n",
      " -2.6516163e-01 -1.1370610e+00 -6.9515198e-02 -2.4403551e-01\n",
      " -1.2261345e+00 -2.8815448e-02 -2.6008862e-01 -1.3417487e+00\n",
      "  6.8771549e-02 -2.7141064e-01 -1.1701620e+00  1.4000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63320>\n",
      "tensor([[-0.0431, -0.0528, -0.2322,  ..., -0.0179, -0.2386, -1.2123],\n",
      "        [-0.0431, -0.0528, -0.2322,  ..., -0.0179, -0.2386, -1.2123],\n",
      "        [-0.0431, -0.0528, -0.2322,  ..., -0.0179, -0.2386, -1.2123],\n",
      "        ...,\n",
      "        [-0.2145,  0.3132, -0.0915,  ..., -0.7543,  0.8365, -0.4280],\n",
      "        [-0.0612,  0.0032,  0.6137,  ..., -0.1926,  0.7757,  0.2133],\n",
      "        [-0.0612,  0.0032,  0.6137,  ..., -0.1926,  0.7757,  0.2133]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.04308465 -0.05283199 -0.2321727  -0.01228864 -0.14744265 -0.53927934\n",
      " -0.16337009 -0.37287802 -1.3905406  -0.31595957 -0.4365527  -1.6820469\n",
      " -0.46102792 -0.5170747  -2.195004   -0.23094875 -0.6882174  -1.5486326\n",
      " -0.08048265 -0.75157404 -1.4058967  -0.13023274 -0.6720617  -1.4660606\n",
      " -0.13990411 -0.8509743  -1.5964487  -0.19099851 -0.6082201  -1.4461234\n",
      " -0.1438956  -0.65443254 -1.4197104  -0.16132379 -0.61814666 -1.5072742\n",
      " -0.01239499 -0.6472844  -1.5214581  -0.11535276 -0.4929601  -1.2846894\n",
      " -0.27493367 -0.2536667  -2.0733728  -0.08698681 -0.42228988 -2.1084664\n",
      "  0.09443572 -0.38759795 -1.3840342  -0.23013206 -0.27004737 -1.2014964\n",
      " -0.1732585  -0.23554525 -1.2952724  -0.14372943 -0.22542879 -1.4132984\n",
      " -0.01793402 -0.23855713 -1.2122817 ]\n",
      "data: [-0.04308464 -0.05283199 -0.2321727  -0.01228864 -0.14744265 -0.53927934\n",
      " -0.16337009 -0.372878   -1.3905406  -0.31595957 -0.4365527  -1.6820468\n",
      " -0.46102792 -0.5170747  -2.195004   -0.23094875 -0.6882174  -1.5486326\n",
      " -0.08048265 -0.75157404 -1.4058967  -0.13023274 -0.6720617  -1.4660606\n",
      " -0.13990411 -0.8509743  -1.5964487  -0.19099851 -0.6082201  -1.4461234\n",
      " -0.1438956  -0.65443254 -1.4197104  -0.16132377 -0.61814666 -1.5072742\n",
      " -0.01239499 -0.6472844  -1.5214581  -0.11535276 -0.4929601  -1.2846894\n",
      " -0.27493367 -0.2536667  -2.0733728  -0.08698681 -0.42228988 -2.1084664\n",
      "  0.09443572 -0.38759795 -1.3840342  -0.23013206 -0.27004737 -1.2014964\n",
      " -0.1732585  -0.23554525 -1.2952724  -0.14372943 -0.22542879 -1.4132984\n",
      " -0.01793402 -0.23855713 -1.2122817   0.15      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0284, -0.0396, -0.1535,  ...,  0.0389, -0.2070, -1.2405],\n",
      "        [ 0.0284, -0.0396, -0.1535,  ...,  0.0389, -0.2070, -1.2405],\n",
      "        [ 0.0284, -0.0396, -0.1535,  ...,  0.0389, -0.2070, -1.2405],\n",
      "        ...,\n",
      "        [-0.2890,  0.2329, -0.1851,  ..., -0.8816,  0.7855, -0.4534],\n",
      "        [-0.2590, -0.1993,  0.4942,  ..., -0.3976,  0.4961,  0.2565],\n",
      "        [-0.2590, -0.1993,  0.4942,  ..., -0.3976,  0.4961,  0.2565]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02838794 -0.03959948 -0.15346265  0.03867505 -0.19471963 -0.6160178\n",
      " -0.01559848 -0.35643265 -1.3117578  -0.15324241 -0.40971974 -1.6187416\n",
      " -0.34227538 -0.5374837  -2.0619984  -0.19263716 -0.62849474 -1.4642965\n",
      "  0.0699255  -0.63826287 -1.2413698   0.02543512 -0.5869585  -1.288564\n",
      "  0.03266927 -0.69524205 -1.4048136  -0.14849076 -0.50924027 -1.3815719\n",
      " -0.04169725 -0.5677651  -1.3611517  -0.03206307 -0.54310393 -1.4658369\n",
      "  0.10438032 -0.56988215 -1.5407611  -0.04969736 -0.43413746 -1.2058471\n",
      " -0.15182889 -0.20958778 -1.7986449   0.00345768 -0.35910738 -1.781967\n",
      "  0.16089858 -0.32308397 -1.3879693  -0.15872745 -0.18592165 -1.1461092\n",
      " -0.06533594 -0.16687076 -1.22416    -0.00886899 -0.19583356 -1.3459101\n",
      "  0.03888827 -0.2069744  -1.240461  ]\n",
      "data: [ 0.02838794 -0.03959948 -0.15346265  0.03867505 -0.19471961 -0.6160178\n",
      " -0.01559848 -0.35643265 -1.3117578  -0.15324241 -0.40971974 -1.6187416\n",
      " -0.34227538 -0.5374837  -2.0619984  -0.19263716 -0.62849474 -1.4642965\n",
      "  0.0699255  -0.63826287 -1.2413698   0.02543512 -0.5869585  -1.288564\n",
      "  0.03266927 -0.6952421  -1.4048136  -0.14849076 -0.50924027 -1.381572\n",
      " -0.04169725 -0.5677651  -1.3611517  -0.03206307 -0.54310393 -1.465837\n",
      "  0.10438032 -0.56988215 -1.5407611  -0.04969736 -0.43413746 -1.2058471\n",
      " -0.15182889 -0.20958778 -1.7986449   0.00345768 -0.35910738 -1.781967\n",
      "  0.1608986  -0.32308397 -1.3879693  -0.15872745 -0.18592165 -1.1461092\n",
      " -0.06533594 -0.16687077 -1.22416    -0.00886899 -0.19583356 -1.3459101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.03888827 -0.20697442 -1.240461    0.16      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0333, -0.0833, -0.2571,  ...,  0.0596, -0.2597, -1.3140],\n",
      "        [ 0.0333, -0.0833, -0.2571,  ...,  0.0596, -0.2597, -1.3140],\n",
      "        [ 0.0333, -0.0833, -0.2571,  ...,  0.0596, -0.2597, -1.3140],\n",
      "        ...,\n",
      "        [-0.2899,  0.3133, -0.3249,  ..., -0.7669,  0.7758, -0.5344],\n",
      "        [-0.1440, -0.0476,  0.6232,  ..., -0.2418,  0.7526,  0.2750],\n",
      "        [-0.1440, -0.0476,  0.6232,  ..., -0.2418,  0.7526,  0.2750]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03327632 -0.08331247 -0.2570792   0.05451242 -0.23200141 -0.68493503\n",
      " -0.04788357 -0.4208268  -1.4405352  -0.19036058 -0.4879638  -1.7239097\n",
      " -0.3555509  -0.59894264 -2.1947656  -0.17345536 -0.68964326 -1.5954658\n",
      "  0.03384507 -0.7204422  -1.3826919  -0.00816055 -0.65432453 -1.4353169\n",
      " -0.01268272 -0.78159475 -1.5491431  -0.13396992 -0.58030784 -1.5180324\n",
      " -0.05234642 -0.6358838  -1.4805713  -0.0616912  -0.6082432  -1.5648882\n",
      "  0.07853463 -0.6255652  -1.6132063  -0.04837259 -0.500211   -1.349386\n",
      " -0.1540985  -0.27056566 -1.9554042  -0.00400154 -0.42218393 -1.9525083\n",
      "  0.15500669 -0.3864595  -1.4712846  -0.1446833  -0.2606434  -1.2834705\n",
      " -0.07286972 -0.2335379  -1.3559332  -0.0189769  -0.24406427 -1.4719516\n",
      "  0.05960736 -0.25971603 -1.313985  ]\n",
      "data: [ 0.03327632 -0.08331247 -0.2570792   0.05451242 -0.2320014  -0.684935\n",
      " -0.04788357 -0.4208268  -1.4405351  -0.19036059 -0.4879638  -1.7239097\n",
      " -0.3555509  -0.59894264 -2.1947656  -0.17345536 -0.68964326 -1.5954659\n",
      "  0.03384507 -0.7204422  -1.3826919  -0.00816055 -0.6543245  -1.4353169\n",
      " -0.01268272 -0.78159475 -1.5491431  -0.13396992 -0.58030784 -1.5180324\n",
      " -0.05234642 -0.6358838  -1.4805713  -0.0616912  -0.6082432  -1.5648884\n",
      "  0.07853463 -0.6255652  -1.6132064  -0.04837259 -0.500211   -1.349386\n",
      " -0.1540985  -0.27056566 -1.9554042  -0.00400154 -0.4221839  -1.9525084\n",
      "  0.15500669 -0.3864595  -1.4712846  -0.1446833  -0.2606434  -1.2834705\n",
      " -0.07286972 -0.2335379  -1.3559332  -0.0189769  -0.24406427 -1.4719516\n",
      "  0.05960736 -0.25971603 -1.313985    0.17      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0096, -0.1300, -0.2542,  ...,  0.0669, -0.3129, -1.3247],\n",
      "        [ 0.0096, -0.1300, -0.2542,  ...,  0.0669, -0.3129, -1.3247],\n",
      "        [ 0.0096, -0.1300, -0.2542,  ...,  0.0669, -0.3129, -1.3247],\n",
      "        ...,\n",
      "        [-0.1015,  0.4466, -0.1733,  ..., -0.7057,  0.9485, -0.4317],\n",
      "        [-0.1471, -0.1223,  0.5795,  ..., -0.2590,  0.6327,  0.2407],\n",
      "        [-0.1471, -0.1223,  0.5795,  ..., -0.2590,  0.6327,  0.2407]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0095737  -0.13001633 -0.25424653  0.02854564 -0.28469336 -0.67840993\n",
      " -0.01754753 -0.45331013 -1.3981342  -0.155659   -0.50964165 -1.7146044\n",
      " -0.33329913 -0.6509417  -2.1727793  -0.20295236 -0.719056   -1.5798253\n",
      "  0.08107537 -0.7330023  -1.3684607   0.02271181 -0.68388414 -1.4150152\n",
      "  0.02500127 -0.7951765  -1.533363   -0.14846346 -0.6020274  -1.4891549\n",
      " -0.0339805  -0.6656047  -1.4776646  -0.02980893 -0.641791   -1.5811479\n",
      "  0.08726306 -0.67984724 -1.6482782  -0.03450143 -0.5220144  -1.3031662\n",
      " -0.13880752 -0.29661435 -1.9079859   0.01692039 -0.45966247 -1.8870803\n",
      "  0.16693082 -0.42159715 -1.4878403  -0.14946023 -0.27810222 -1.2451909\n",
      " -0.03249063 -0.26386622 -1.3183644   0.0227448  -0.30412805 -1.4361551\n",
      "  0.06693346 -0.31287754 -1.3246748 ]\n",
      "data: [ 0.0095737  -0.13001633 -0.25424653  0.02854564 -0.28469336 -0.67840993\n",
      " -0.01754753 -0.45331013 -1.3981341  -0.155659   -0.50964165 -1.7146044\n",
      " -0.33329913 -0.65094167 -2.1727793  -0.20295234 -0.719056   -1.5798253\n",
      "  0.08107537 -0.7330023  -1.3684607   0.02271181 -0.68388414 -1.4150152\n",
      "  0.02500127 -0.79517657 -1.533363   -0.14846346 -0.6020274  -1.4891549\n",
      " -0.0339805  -0.6656047  -1.4776646  -0.02980893 -0.641791   -1.5811479\n",
      "  0.08726306 -0.67984724 -1.6482782  -0.03450143 -0.5220144  -1.3031662\n",
      " -0.13880752 -0.29661435 -1.907986    0.01692039 -0.45966247 -1.8870804\n",
      "  0.16693082 -0.42159712 -1.4878403  -0.14946023 -0.27810222 -1.2451909\n",
      " -0.03249063 -0.26386622 -1.3183644   0.0227448  -0.30412805 -1.4361551\n",
      "  0.06693346 -0.31287754 -1.3246748   0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0174, -0.1269, -0.2224,  ...,  0.0383, -0.3133, -1.2474],\n",
      "        [ 0.0174, -0.1269, -0.2224,  ...,  0.0383, -0.3133, -1.2474],\n",
      "        [ 0.0174, -0.1269, -0.2224,  ...,  0.0383, -0.3133, -1.2474],\n",
      "        ...,\n",
      "        [-0.1402,  0.4726, -0.1689,  ..., -0.6279,  0.9620, -0.4961],\n",
      "        [-0.1921, -0.0840,  0.6188,  ..., -0.2744,  0.6549,  0.2715],\n",
      "        [-0.1921, -0.0840,  0.6188,  ..., -0.2744,  0.6549,  0.2715]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01743386 -0.12691255 -0.22237746  0.04662374 -0.24637155 -0.5756698\n",
      " -0.06771434 -0.4604289  -1.3839593  -0.21615057 -0.5247371  -1.6789417\n",
      " -0.36717746 -0.62616104 -2.177099   -0.17831564 -0.7531507  -1.5596666\n",
      "  0.01598884 -0.8075343  -1.3896208  -0.0424825  -0.7404181  -1.4420636\n",
      " -0.05703259 -0.8968752  -1.5654285  -0.13388008 -0.6593696  -1.4630725\n",
      " -0.06968743 -0.7142292  -1.4382982  -0.08596753 -0.68405414 -1.5245948\n",
      "  0.03596552 -0.7190502  -1.5486686  -0.04625415 -0.5504589  -1.2985325\n",
      " -0.19359608 -0.31939736 -2.0240257  -0.02194847 -0.4905532  -2.0396292\n",
      "  0.13487212 -0.4514162  -1.4128244  -0.16272075 -0.3211735  -1.2237537\n",
      " -0.08656558 -0.2937323  -1.3090715  -0.05308051 -0.3027881  -1.4225714\n",
      "  0.03826993 -0.3132894  -1.2473762 ]\n",
      "data: [ 0.01743386 -0.12691255 -0.22237748  0.04662374 -0.24637155 -0.5756698\n",
      " -0.06771434 -0.4604289  -1.3839593  -0.21615057 -0.5247371  -1.6789416\n",
      " -0.36717746 -0.62616104 -2.177099   -0.17831564 -0.7531507  -1.5596666\n",
      "  0.01598884 -0.8075343  -1.3896208  -0.0424825  -0.7404181  -1.4420636\n",
      " -0.05703259 -0.8968752  -1.5654285  -0.13388008 -0.6593696  -1.4630725\n",
      " -0.06968743 -0.7142292  -1.4382982  -0.08596752 -0.68405414 -1.5245948\n",
      "  0.03596552 -0.7190502  -1.5486686  -0.04625415 -0.5504589  -1.2985324\n",
      " -0.19359608 -0.31939736 -2.0240257  -0.02194847 -0.4905532  -2.0396292\n",
      "  0.13487212 -0.4514162  -1.4128244  -0.16272075 -0.3211735  -1.2237537\n",
      " -0.08656558 -0.2937323  -1.3090715  -0.05308051 -0.3027881  -1.4225714\n",
      "  0.03826993 -0.3132894  -1.2473762   0.19      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[-0.0123, -0.0619, -0.1719,  ...,  0.0447, -0.2596, -1.1417],\n",
      "        [-0.0123, -0.0619, -0.1719,  ...,  0.0447, -0.2596, -1.1417],\n",
      "        [-0.0123, -0.0619, -0.1719,  ...,  0.0447, -0.2596, -1.1417],\n",
      "        ...,\n",
      "        [-0.1304,  0.3445, -0.0361,  ..., -0.7475,  0.8687, -0.3625],\n",
      "        [-0.1041, -0.1214,  0.5814,  ..., -0.2155,  0.5980,  0.1953],\n",
      "        [-0.1041, -0.1214,  0.5814,  ..., -0.2155,  0.5980,  0.1953]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01228445 -0.06194561 -0.17185745  0.01556756 -0.17647576 -0.47698742\n",
      " -0.0999682  -0.39397407 -1.2994998  -0.24898525 -0.45489353 -1.6026719\n",
      " -0.415196   -0.5672028  -2.0866544  -0.21274354 -0.6861132  -1.4736865\n",
      "  0.00345613 -0.739951   -1.2952476  -0.05175993 -0.67615616 -1.3430502\n",
      " -0.05244038 -0.8348446  -1.469022   -0.15948457 -0.5894767  -1.3672025\n",
      " -0.08455235 -0.6506659  -1.3450694  -0.08245505 -0.6240998  -1.4368474\n",
      "  0.05608754 -0.66366464 -1.4706607  -0.06224573 -0.48565596 -1.1918187\n",
      " -0.21840905 -0.2524147  -1.9659851  -0.02082345 -0.4357236  -1.9772894\n",
      "  0.15627791 -0.3939336  -1.3153803  -0.18590814 -0.25394118 -1.1186447\n",
      " -0.09730819 -0.23192829 -1.2016461  -0.05338147 -0.24831998 -1.3179901\n",
      "  0.04470699 -0.25961214 -1.141707  ]\n",
      "data: [-0.01228445 -0.06194561 -0.17185745  0.01556756 -0.17647575 -0.47698742\n",
      " -0.0999682  -0.39397407 -1.2994999  -0.24898525 -0.45489353 -1.6026719\n",
      " -0.415196   -0.5672028  -2.0866544  -0.21274354 -0.6861132  -1.4736866\n",
      "  0.00345613 -0.739951   -1.2952476  -0.05175993 -0.67615616 -1.3430502\n",
      " -0.05244038 -0.8348446  -1.469022   -0.15948457 -0.5894767  -1.3672024\n",
      " -0.08455235 -0.6506659  -1.3450694  -0.08245505 -0.6240998  -1.4368473\n",
      "  0.05608754 -0.66366464 -1.4706607  -0.06224574 -0.48565596 -1.1918187\n",
      " -0.21840905 -0.2524147  -1.9659851  -0.02082345 -0.4357236  -1.9772894\n",
      "  0.15627791 -0.3939336  -1.3153805  -0.18590814 -0.25394118 -1.1186447\n",
      " -0.09730819 -0.23192829 -1.2016461  -0.05338147 -0.24831998 -1.3179901\n",
      "  0.04470699 -0.25961214 -1.141707    0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.25  3.245 3.265 ... 3.235 3.236 3.23 ]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " [3.235 3.228 3.238 ... 3.214 3.208 3.224]\n",
      " ...\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.936 2.942 2.907 ... 2.97  2.973 2.973]\n",
      " [2.93  2.898 2.897 ... 2.954 2.951 2.96 ]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0479, -0.0484, -0.2082,  ..., -0.0063, -0.2285, -1.2108],\n",
      "        [-0.0479, -0.0484, -0.2082,  ..., -0.0063, -0.2285, -1.2108],\n",
      "        [-0.0479, -0.0484, -0.2082,  ..., -0.0063, -0.2285, -1.2108],\n",
      "        ...,\n",
      "        [-0.2318,  0.3041, -0.1163,  ..., -0.7078,  0.8427, -0.4607],\n",
      "        [-0.1497, -0.1280,  0.5977,  ..., -0.2967,  0.6235,  0.2289],\n",
      "        [-0.1497, -0.1280,  0.5977,  ..., -0.2967,  0.6235,  0.2289]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.04794021 -0.04837726 -0.20823601 -0.01612841 -0.15443897 -0.5364765\n",
      " -0.14283249 -0.36441216 -1.3567575  -0.2949692  -0.42372575 -1.6573435\n",
      " -0.44802147 -0.5205911  -2.159737   -0.24377246 -0.6716604  -1.5235026\n",
      " -0.05095841 -0.7214394  -1.3605235  -0.10089654 -0.6487329  -1.4168558\n",
      " -0.10505985 -0.80977005 -1.547728   -0.19829193 -0.5838133  -1.4221607\n",
      " -0.12984025 -0.63455015 -1.4031503  -0.13433114 -0.5980675  -1.4971522\n",
      "  0.0144069  -0.6325806  -1.5268798  -0.11030897 -0.47596014 -1.2505438\n",
      " -0.25666982 -0.2345539  -2.0013323  -0.06786846 -0.40437305 -2.0229888\n",
      "  0.11551414 -0.3676653  -1.3827096  -0.2299171  -0.24570593 -1.1739513\n",
      " -0.15371357 -0.21331228 -1.2649683  -0.11480531 -0.21726197 -1.3856541\n",
      " -0.00625307 -0.22845216 -1.2108232 ]\n",
      "data: [-3.32 -3.2   0.8  -3.27 -3.    1.49 -3.27 -2.68  2.06 -3.21 -2.33  1.86\n",
      "  0.    0.    0.   -3.16 -2.8   2.28 -3.13 -2.6   2.51  0.    0.    0.\n",
      "  0.    0.    0.   -3.26 -2.74  2.01 -3.21 -2.42  1.99  0.    0.    0.\n",
      "  0.    0.    0.   -3.3  -2.72  1.77 -3.27 -2.52  1.79 -3.39 -2.3   1.91\n",
      " -3.39 -2.3   1.91 -3.42 -2.6   1.53 -3.4  -2.6   1.68 -3.47 -2.48  1.94\n",
      " -3.47 -2.41  1.94  0.  ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0.\n",
      " 0. 0. 0. 1. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.4088, -0.1583, -0.2330,  ...,  0.1695, -0.1975, -0.7195],\n",
      "        [ 0.4088, -0.1583, -0.2330,  ...,  0.1695, -0.1975, -0.7195],\n",
      "        [ 0.4088, -0.1583, -0.2330,  ...,  0.1695, -0.1975, -0.7195],\n",
      "        ...,\n",
      "        [-0.0420, -0.9453, -0.0266,  ...,  0.1668, -1.0402, -0.5223],\n",
      "        [-0.4433,  0.1242,  0.4401,  ..., -0.7988, -0.2520,  2.1505],\n",
      "        [-0.4433,  0.1242,  0.4401,  ..., -0.7988, -0.2520,  2.1505]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.4088333  -0.15834327 -0.23295991  0.3063401  -0.29365736 -0.44305533\n",
      "  0.20301007 -0.46337968 -0.74097097  0.18553706 -0.59409994 -0.6578311\n",
      "  0.16394499 -0.62284875 -0.6478258   0.18782832 -0.3962135  -0.9911042\n",
      "  0.32729733 -0.45791912 -0.28041708  0.28639325 -0.5955285  -0.21514356\n",
      "  0.16378057 -0.5373255  -0.29758033  0.17226009 -0.28499758 -1.0302024\n",
      "  0.10317844 -0.3621807  -0.97788453  0.11877751 -0.39080498 -0.9229968\n",
      "  0.15028396 -0.49019864 -0.9141351   0.15432903 -0.2216268  -1.0264452\n",
      "  0.03210863 -0.25710818 -1.0430012   0.06188649 -0.29885918 -1.0511461\n",
      "  0.14883327 -0.33475202 -0.83145183  0.1275599  -0.06910606 -0.8853378\n",
      "  0.12707943 -0.0994907  -0.86484104  0.12821501 -0.12909248 -0.8414034\n",
      "  0.16951236 -0.19750583 -0.71949315]\n",
      "init: [ 0.4088333  -0.15834327 -0.23295991  0.3063401  -0.29365736 -0.44305533\n",
      "  0.20301007 -0.46337968 -0.74097097  0.18553706 -0.59409994 -0.6578311\n",
      "  0.16394499 -0.62284875 -0.6478258   0.18782832 -0.3962135  -0.9911042\n",
      "  0.32729733 -0.45791912 -0.28041708  0.28639325 -0.5955285  -0.21514356\n",
      "  0.16378057 -0.5373255  -0.29758033  0.17226009 -0.28499758 -1.0302024\n",
      "  0.10317844 -0.3621807  -0.97788453  0.11877751 -0.39080498 -0.9229968\n",
      "  0.15028396 -0.49019864 -0.9141351   0.15432903 -0.2216268  -1.0264452\n",
      "  0.03210863 -0.25710818 -1.0430012   0.06188649 -0.29885918 -1.0511461\n",
      "  0.14883327 -0.33475202 -0.83145183  0.1275599  -0.06910606 -0.8853378\n",
      "  0.12707943 -0.0994907  -0.86484104  0.12821501 -0.12909248 -0.8414034\n",
      "  0.16951236 -0.19750583 -0.71949315]\n",
      "type: <class 'numpy.ndarray'>\n",
      "data: [ 0.40883332 -0.15834327 -0.23295993  0.3063401  -0.29365736 -0.44305533\n",
      "  0.20301007 -0.46337968 -0.74097097  0.18553706 -0.59409994 -0.657831\n",
      "  0.16394499 -0.62284875 -0.6478258   0.18782832 -0.3962135  -0.9911042\n",
      "  0.32729733 -0.45791912 -0.28041708  0.28639325 -0.5955285  -0.21514356\n",
      "  0.16378057 -0.5373255  -0.29758033  0.17226009 -0.28499758 -1.0302024\n",
      "  0.10317844 -0.3621807  -0.97788453  0.11877751 -0.39080498 -0.9229968\n",
      "  0.15028396 -0.49019864 -0.91413516  0.15432903 -0.2216268  -1.0264452\n",
      "  0.03210863 -0.25710818 -1.0430012   0.06188649 -0.29885918 -1.0511461\n",
      "  0.14883327 -0.334752   -0.8314518   0.1275599  -0.06910606 -0.8853378\n",
      "  0.12707943 -0.0994907  -0.8648411   0.12821501 -0.12909248 -0.8414034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.16951236 -0.19750583 -0.71949315  0.01      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.1246, -0.0202,  0.1891,  ..., -0.1077, -0.2313, -0.9579],\n",
      "        [ 0.1246, -0.0202,  0.1891,  ..., -0.1077, -0.2313, -0.9579],\n",
      "        [ 0.1246, -0.0202,  0.1891,  ..., -0.1077, -0.2313, -0.9579],\n",
      "        ...,\n",
      "        [ 0.1558,  0.5862, -0.2994,  ..., -0.0019,  1.3589, -0.7980],\n",
      "        [-0.0936, -0.0108,  0.2504,  ...,  0.5251,  0.5991, -0.0303],\n",
      "        [-0.0936, -0.0108,  0.2504,  ...,  0.5251,  0.5991, -0.0303]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.12459634 -0.02022119  0.18911009  0.00219895 -0.20046148 -0.40985185\n",
      " -0.09251741 -0.3574744  -0.99984735 -0.27393943 -0.4180681  -1.3127542\n",
      " -0.56239563 -0.48290765 -1.7738683  -0.16803244 -0.62240905 -1.1823354\n",
      " -0.23317441 -0.6879033  -1.2784121  -0.25777566 -0.5644957  -1.359515\n",
      " -0.15013477 -0.7699283  -1.3857694  -0.15162843 -0.4951952  -1.1070912\n",
      " -0.16796926 -0.5264542  -1.0048087  -0.2429569  -0.5938804  -1.1544011\n",
      " -0.10852307 -0.47172564 -1.1666267  -0.1275315  -0.45777953 -1.0084219\n",
      " -0.19094169 -0.32248855 -1.4063251  -0.17659137 -0.40101618 -1.4153821\n",
      " -0.06365263 -0.40796047 -1.0296135  -0.13772151 -0.24200684 -0.95235926\n",
      " -0.21119192 -0.2635303  -1.0116596  -0.19995189 -0.23202227 -1.1058004\n",
      " -0.10769591 -0.2312537  -0.9579025 ]\n",
      "data: [ 0.12459633 -0.02022119  0.18911009  0.00219895 -0.20046148 -0.40985185\n",
      " -0.09251741 -0.35747442 -0.99984735 -0.27393943 -0.4180681  -1.3127542\n",
      " -0.56239563 -0.48290765 -1.7738682  -0.16803244 -0.62240905 -1.1823354\n",
      " -0.23317441 -0.6879033  -1.2784121  -0.25777566 -0.5644957  -1.359515\n",
      " -0.15013477 -0.7699283  -1.3857694  -0.15162843 -0.4951952  -1.1070912\n",
      " -0.16796927 -0.5264542  -1.0048087  -0.2429569  -0.5938804  -1.1544011\n",
      " -0.10852307 -0.47172564 -1.1666267  -0.1275315  -0.45777953 -1.0084219\n",
      " -0.19094169 -0.32248855 -1.4063251  -0.17659135 -0.40101615 -1.415382\n",
      " -0.06365263 -0.40796047 -1.0296135  -0.13772151 -0.24200684 -0.95235926\n",
      " -0.21119192 -0.2635303  -1.0116596  -0.1999519  -0.23202227 -1.1058004\n",
      " -0.10769591 -0.2312537  -0.95790255  0.02      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0704,  0.0809, -0.2381,  ...,  0.2039, -0.1075, -1.2545],\n",
      "        [ 0.0704,  0.0809, -0.2381,  ...,  0.2039, -0.1075, -1.2545],\n",
      "        [ 0.0704,  0.0809, -0.2381,  ...,  0.2039, -0.1075, -1.2545],\n",
      "        ...,\n",
      "        [-0.0914,  0.4736,  0.2470,  ..., -0.3183,  1.1706, -0.1457],\n",
      "        [-0.0305,  0.0666,  0.5570,  ..., -0.4111,  0.6987,  0.3084],\n",
      "        [-0.0305,  0.0666,  0.5570,  ..., -0.4111,  0.6987,  0.3084]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.07041749  0.08087856 -0.2380596   0.11188129 -0.04651107 -0.593524\n",
      "  0.0369784  -0.2173428  -1.3077521  -0.09982549 -0.26689008 -1.5877218\n",
      " -0.23249993 -0.40049228 -2.0551298  -0.13112476 -0.49900344 -1.4932907\n",
      "  0.15305701 -0.512602   -1.2970088   0.11287431 -0.43640766 -1.3269511\n",
      "  0.12549986 -0.5429841  -1.4402632  -0.07419175 -0.40281966 -1.4181497\n",
      "  0.0570392  -0.45725307 -1.4015865   0.08560558 -0.4004372  -1.4635857\n",
      "  0.22698016 -0.4520199  -1.5254251   0.05999518 -0.3268057  -1.253471\n",
      " -0.0375306  -0.06565163 -1.8323177   0.14496449 -0.24551678 -1.8091065\n",
      "  0.31887746 -0.18162647 -1.4236158  -0.06899811 -0.08874243 -1.1920954\n",
      "  0.07010144 -0.04948705 -1.2716212   0.13883573 -0.09286425 -1.3900852\n",
      "  0.20385292 -0.10746641 -1.2544596 ]\n",
      "data: [ 0.07041749  0.08087856 -0.2380596   0.11188129 -0.04651107 -0.593524\n",
      "  0.0369784  -0.2173428  -1.3077521  -0.09982549 -0.26689008 -1.5877218\n",
      " -0.23249993 -0.40049228 -2.0551298  -0.13112476 -0.49900344 -1.4932907\n",
      "  0.15305701 -0.512602   -1.2970089   0.11287431 -0.43640766 -1.3269511\n",
      "  0.12549986 -0.5429841  -1.4402633  -0.07419175 -0.40281966 -1.4181497\n",
      "  0.0570392  -0.45725307 -1.4015867   0.08560558 -0.4004372  -1.4635856\n",
      "  0.22698016 -0.45201987 -1.5254251   0.05999519 -0.3268057  -1.253471\n",
      " -0.0375306  -0.06565163 -1.8323177   0.14496449 -0.24551678 -1.8091065\n",
      "  0.31887746 -0.18162647 -1.4236159  -0.06899811 -0.08874243 -1.1920954\n",
      "  0.07010144 -0.04948706 -1.2716212   0.13883573 -0.09286425 -1.3900851\n",
      "  0.20385292 -0.10746641 -1.2544596   0.03      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[ 0.0815, -0.1447, -0.2480,  ...,  0.0991, -0.2912, -1.3839],\n",
      "        [ 0.0815, -0.1447, -0.2480,  ...,  0.0991, -0.2912, -1.3839],\n",
      "        [ 0.0815, -0.1447, -0.2480,  ...,  0.0991, -0.2912, -1.3839],\n",
      "        ...,\n",
      "        [-0.3572,  0.1870, -0.4105,  ..., -0.9574,  0.4673, -0.5629],\n",
      "        [-0.1467,  0.1141,  0.5210,  ..., -0.2650,  1.0116,  0.1232],\n",
      "        [-0.1467,  0.1141,  0.5210,  ..., -0.2650,  1.0116,  0.1232]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 8.1490040e-02 -1.4469561e-01 -2.4801569e-01  9.7671077e-02\n",
      " -3.2587498e-01 -7.3710960e-01  3.4836978e-02 -4.8695534e-01\n",
      " -1.4552214e+00 -1.0790475e-01 -5.5327630e-01 -1.7530010e+00\n",
      " -2.9128781e-01 -6.8300343e-01 -2.2284744e+00 -1.4273360e-01\n",
      " -7.2343862e-01 -1.6394835e+00  1.1370386e-01 -7.2670400e-01\n",
      " -1.3960643e+00  7.1625382e-02 -6.7446172e-01 -1.4442430e+00\n",
      "  6.6801518e-02 -7.7152991e-01 -1.5544841e+00 -1.0129985e-01\n",
      " -5.9193695e-01 -1.5680943e+00  9.7890347e-03 -6.5342808e-01\n",
      " -1.5326242e+00  2.1582246e-03 -6.2992060e-01 -1.6324604e+00\n",
      "  1.3540067e-01 -6.4930642e-01 -1.7092044e+00 -4.8131272e-03\n",
      " -5.2590454e-01 -1.3871017e+00 -8.3646759e-02 -2.9849574e-01\n",
      " -1.9020498e+00  4.7233984e-02 -4.4234380e-01 -1.8794484e+00\n",
      "  1.9150309e-01 -4.0957573e-01 -1.5460777e+00 -9.7276866e-02\n",
      " -2.7254611e-01 -1.3277469e+00 -7.5811297e-03 -2.5002128e-01\n",
      " -1.3753564e+00  5.7192832e-02 -2.7747089e-01 -1.4969025e+00\n",
      "  9.9099003e-02 -2.9115921e-01 -1.3839355e+00]\n",
      "data: [ 8.1490040e-02 -1.4469561e-01 -2.4801569e-01  9.7671077e-02\n",
      " -3.2587498e-01 -7.3710960e-01  3.4836978e-02 -4.8695534e-01\n",
      " -1.4552214e+00 -1.0790475e-01 -5.5327630e-01 -1.7530010e+00\n",
      " -2.9128781e-01 -6.8300337e-01 -2.2284744e+00 -1.4273360e-01\n",
      " -7.2343862e-01 -1.6394835e+00  1.1370386e-01 -7.2670400e-01\n",
      " -1.3960643e+00  7.1625382e-02 -6.7446172e-01 -1.4442430e+00\n",
      "  6.6801518e-02 -7.7152991e-01 -1.5544841e+00 -1.0129985e-01\n",
      " -5.9193695e-01 -1.5680941e+00  9.7890347e-03 -6.5342802e-01\n",
      " -1.5326242e+00  2.1582246e-03 -6.2992060e-01 -1.6324604e+00\n",
      "  1.3540067e-01 -6.4930642e-01 -1.7092044e+00 -4.8131272e-03\n",
      " -5.2590454e-01 -1.3871017e+00 -8.3646752e-02 -2.9849574e-01\n",
      " -1.9020497e+00  4.7233984e-02 -4.4234380e-01 -1.8794484e+00\n",
      "  1.9150309e-01 -4.0957573e-01 -1.5460777e+00 -9.7276866e-02\n",
      " -2.7254611e-01 -1.3277469e+00 -7.5811297e-03 -2.5002128e-01\n",
      " -1.3753564e+00  5.7192832e-02 -2.7747089e-01 -1.4969025e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  9.9099010e-02 -2.9115921e-01 -1.3839355e+00  3.9999999e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0222, -0.2359, -0.2448,  ...,  0.0694, -0.4098, -1.3656],\n",
      "        [ 0.0222, -0.2359, -0.2448,  ...,  0.0694, -0.4098, -1.3656],\n",
      "        [ 0.0222, -0.2359, -0.2448,  ...,  0.0694, -0.4098, -1.3656],\n",
      "        ...,\n",
      "        [-0.0243,  0.5930, -0.1938,  ..., -0.5726,  1.0935, -0.5326],\n",
      "        [-0.1775,  0.0390,  0.6295,  ..., -0.2157,  0.7608,  0.3092],\n",
      "        [-0.1775,  0.0390,  0.6295,  ..., -0.2157,  0.7608,  0.3092]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.02224021 -0.23587255 -0.24475221  0.04636989 -0.399424   -0.675328\n",
      "  0.01784981 -0.5748842  -1.4199216  -0.12703967 -0.63311076 -1.7538813\n",
      " -0.31588894 -0.78924835 -2.2239537  -0.2074758  -0.81755304 -1.6417564\n",
      "  0.12900269 -0.8336973  -1.3777368   0.06259245 -0.79707575 -1.4141947\n",
      "  0.0475277  -0.9002117  -1.537868   -0.14554203 -0.6903106  -1.5388694\n",
      " -0.01850837 -0.7688205  -1.5284493  -0.00915147 -0.7486557  -1.6406653\n",
      "  0.09509239 -0.8005065  -1.720394   -0.01859925 -0.60844505 -1.340028\n",
      " -0.13369338 -0.38309604 -1.9448339   0.02731766 -0.5612649  -1.9133857\n",
      "  0.17174195 -0.5170268  -1.5393829  -0.14974284 -0.35544795 -1.2805564\n",
      " -0.01343761 -0.34435582 -1.3394808   0.04846537 -0.4061913  -1.455362\n",
      "  0.06935381 -0.40977478 -1.3655636 ]\n",
      "data: [ 0.02224021 -0.23587255 -0.24475221  0.04636989 -0.399424   -0.675328\n",
      "  0.01784981 -0.5748842  -1.4199215  -0.12703967 -0.63311076 -1.7538813\n",
      " -0.31588894 -0.78924835 -2.2239537  -0.2074758  -0.81755304 -1.6417564\n",
      "  0.12900269 -0.8336974  -1.3777368   0.06259245 -0.79707575 -1.4141946\n",
      "  0.0475277  -0.9002117  -1.537868   -0.14554203 -0.6903106  -1.5388694\n",
      " -0.01850837 -0.7688205  -1.5284493  -0.00915147 -0.7486557  -1.6406653\n",
      "  0.09509239 -0.8005064  -1.720394   -0.01859925 -0.60844505 -1.340028\n",
      " -0.13369338 -0.38309604 -1.9448339   0.02731766 -0.5612649  -1.9133857\n",
      "  0.17174195 -0.5170268  -1.5393829  -0.14974284 -0.35544795 -1.2805564\n",
      " -0.01343761 -0.34435582 -1.3394808   0.04846537 -0.4061913  -1.455362\n",
      "  0.06935381 -0.40977478 -1.3655636   0.05      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[-0.0016, -0.1895, -0.1666,  ...,  0.0084, -0.3731, -1.2160],\n",
      "        [-0.0016, -0.1895, -0.1666,  ...,  0.0084, -0.3731, -1.2160],\n",
      "        [-0.0016, -0.1895, -0.1666,  ...,  0.0084, -0.3731, -1.2160],\n",
      "        ...,\n",
      "        [-0.0053,  0.6191, -0.1638,  ..., -0.4361,  1.1763, -0.5834],\n",
      "        [-0.1070,  0.0663,  0.6271,  ..., -0.1046,  0.7249,  0.2976],\n",
      "        [-0.1070,  0.0663,  0.6271,  ..., -0.1046,  0.7249,  0.2976]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-1.5811427e-03 -1.8947846e-01 -1.6658936e-01  2.6433300e-02\n",
      " -3.1167352e-01 -5.0431633e-01 -6.7277797e-02 -5.3203094e-01\n",
      " -1.3322266e+00 -2.2501417e-01 -5.9326470e-01 -1.6492481e+00\n",
      " -3.9731663e-01 -7.1046841e-01 -2.1540942e+00 -2.1791556e-01\n",
      " -8.0903351e-01 -1.5491844e+00  2.2833571e-02 -8.6786699e-01\n",
      " -1.3612345e+00 -4.2823553e-02 -8.0807745e-01 -1.4008718e+00\n",
      " -5.6958891e-02 -9.6170604e-01 -1.5246001e+00 -1.6378783e-01\n",
      " -7.0656776e-01 -1.4352237e+00 -8.5688978e-02 -7.7453983e-01\n",
      " -1.4095147e+00 -9.0033390e-02 -7.4912786e-01 -1.5086807e+00\n",
      "  2.3441613e-02 -7.9497969e-01 -1.5427483e+00 -5.9939615e-02\n",
      " -5.9621692e-01 -1.2601584e+00 -2.2096112e-01 -3.6709589e-01\n",
      " -1.9896573e+00 -3.9421007e-02 -5.5469388e-01 -1.9944111e+00\n",
      "  1.1914486e-01 -5.0771463e-01 -1.3887913e+00 -1.9851248e-01\n",
      " -3.5881504e-01 -1.1848056e+00 -1.0117480e-01 -3.3832186e-01\n",
      " -1.2595689e+00 -6.3315198e-02 -3.7107915e-01 -1.3698535e+00\n",
      "  8.4193423e-03 -3.7305146e-01 -1.2160137e+00]\n",
      "data: [-1.5811427e-03 -1.8947846e-01 -1.6658935e-01  2.6433300e-02\n",
      " -3.1167352e-01 -5.0431633e-01 -6.7277797e-02 -5.3203094e-01\n",
      " -1.3322265e+00 -2.2501417e-01 -5.9326470e-01 -1.6492480e+00\n",
      " -3.9731663e-01 -7.1046847e-01 -2.1540942e+00 -2.1791558e-01\n",
      " -8.0903351e-01 -1.5491844e+00  2.2833571e-02 -8.6786699e-01\n",
      " -1.3612345e+00 -4.2823553e-02 -8.0807745e-01 -1.4008718e+00\n",
      " -5.6958891e-02 -9.6170598e-01 -1.5246003e+00 -1.6378783e-01\n",
      " -7.0656776e-01 -1.4352237e+00 -8.5688978e-02 -7.7453977e-01\n",
      " -1.4095147e+00 -9.0033390e-02 -7.4912786e-01 -1.5086807e+00\n",
      "  2.3441613e-02 -7.9497969e-01 -1.5427482e+00 -5.9939612e-02\n",
      " -5.9621692e-01 -1.2601584e+00 -2.2096114e-01 -3.6709586e-01\n",
      " -1.9896573e+00 -3.9421007e-02 -5.5469388e-01 -1.9944111e+00\n",
      "  1.1914486e-01 -5.0771463e-01 -1.3887913e+00 -1.9851248e-01\n",
      " -3.5881504e-01 -1.1848056e+00 -1.0117480e-01 -3.3832186e-01\n",
      " -1.2595689e+00 -6.3315198e-02 -3.7107915e-01 -1.3698535e+00\n",
      "  8.4193423e-03 -3.7305146e-01 -1.2160137e+00  5.9999999e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F634E0>\n",
      "tensor([[-0.0082, -0.1021, -0.1936,  ...,  0.0122, -0.2759, -1.2059],\n",
      "        [-0.0082, -0.1021, -0.1936,  ...,  0.0122, -0.2759, -1.2059],\n",
      "        [-0.0082, -0.1021, -0.1936,  ...,  0.0122, -0.2759, -1.2059],\n",
      "        ...,\n",
      "        [-0.1442,  0.4655, -0.0344,  ..., -0.5545,  1.1048, -0.4750],\n",
      "        [-0.0656,  0.0376,  0.6581,  ..., -0.1687,  0.6723,  0.3472],\n",
      "        [-0.0656,  0.0376,  0.6581,  ..., -0.1687,  0.6723,  0.3472]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.00817808 -0.10214648 -0.19356342  0.03047847 -0.20705017 -0.4625692\n",
      " -0.09190357 -0.43893415 -1.3379813  -0.24893592 -0.49923784 -1.6386385\n",
      " -0.3996595  -0.6007548  -2.1622756  -0.2134206  -0.73221123 -1.5511564\n",
      "  0.00767335 -0.7940197  -1.3848163  -0.0485487  -0.72777903 -1.4221785\n",
      " -0.05337411 -0.8832163  -1.5522873  -0.16405626 -0.6369278  -1.4392858\n",
      " -0.08840653 -0.6961128  -1.4160334  -0.08142987 -0.65590256 -1.5042512\n",
      "  0.05338275 -0.70681375 -1.5335057  -0.06498799 -0.5176654  -1.2715157\n",
      " -0.23867369 -0.27338696 -2.0550845  -0.03247432 -0.46303725 -2.073337\n",
      "  0.14659664 -0.41158634 -1.391758   -0.21096364 -0.2802243  -1.1894741\n",
      " -0.11597876 -0.24871466 -1.2653806  -0.0794901  -0.26940912 -1.3787377\n",
      "  0.01224449 -0.27593762 -1.2058969 ]\n",
      "data: [-0.00817808 -0.10214648 -0.19356342  0.03047847 -0.20705017 -0.4625692\n",
      " -0.09190357 -0.43893415 -1.3379815  -0.24893592 -0.49923784 -1.6386385\n",
      " -0.3996595  -0.6007548  -2.1622756  -0.2134206  -0.73221123 -1.5511565\n",
      "  0.00767335 -0.7940197  -1.3848163  -0.0485487  -0.72777903 -1.4221785\n",
      " -0.05337411 -0.8832163  -1.5522873  -0.16405626 -0.6369278  -1.4392858\n",
      " -0.08840653 -0.6961128  -1.4160333  -0.08142987 -0.65590256 -1.5042512\n",
      "  0.05338275 -0.70681375 -1.5335057  -0.06498799 -0.5176654  -1.2715157\n",
      " -0.23867369 -0.27338696 -2.0550845  -0.03247432 -0.46303725 -2.073337\n",
      "  0.14659664 -0.41158634 -1.391758   -0.21096364 -0.2802243  -1.1894741\n",
      " -0.11597876 -0.24871466 -1.2653806  -0.0794901  -0.26940912 -1.3787377\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.01224449 -0.27593762 -1.2058969   0.07      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE6182BC88>\n",
      "tensor([[-0.0140, -0.0252, -0.1743,  ...,  0.0416, -0.2139, -1.1670],\n",
      "        [-0.0140, -0.0252, -0.1743,  ...,  0.0416, -0.2139, -1.1670],\n",
      "        [-0.0140, -0.0252, -0.1743,  ...,  0.0416, -0.2139, -1.1670],\n",
      "        ...,\n",
      "        [-0.1873,  0.3072, -0.0232,  ..., -0.7099,  0.8836, -0.3548],\n",
      "        [-0.1268, -0.0850,  0.5642,  ..., -0.2554,  0.6033,  0.2579],\n",
      "        [-0.1268, -0.0850,  0.5642,  ..., -0.2554,  0.6033,  0.2579]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01396478 -0.02522582 -0.1743472   0.0105522  -0.14016993 -0.48927602\n",
      " -0.10364405 -0.35341766 -1.3043811  -0.25441006 -0.4125968  -1.606802\n",
      " -0.4169071  -0.52563506 -2.0957925  -0.22231254 -0.64920753 -1.4785793\n",
      "  0.00404297 -0.69857824 -1.2928195  -0.05026372 -0.6334051  -1.3387425\n",
      " -0.05110985 -0.78348684 -1.4679341  -0.16925146 -0.5527444  -1.3745255\n",
      " -0.08861816 -0.60976547 -1.3594441  -0.07784118 -0.57366765 -1.4495385\n",
      "  0.06456681 -0.6162484  -1.4864514  -0.06657548 -0.44780385 -1.2025044\n",
      " -0.2168178  -0.20860589 -1.945015   -0.0178864  -0.38721728 -1.9553356\n",
      "  0.16468057 -0.34116924 -1.3419383  -0.1954241  -0.2133939  -1.1275856\n",
      " -0.09939852 -0.18688864 -1.2157271  -0.05542658 -0.2041131  -1.3331223\n",
      "  0.04159295 -0.21391766 -1.1669915 ]\n",
      "data: [-0.01396478 -0.02522582 -0.1743472   0.0105522  -0.14016993 -0.48927602\n",
      " -0.10364404 -0.35341766 -1.3043811  -0.25441006 -0.4125968  -1.6068021\n",
      " -0.41690713 -0.52563506 -2.0957925  -0.22231254 -0.64920753 -1.4785793\n",
      "  0.00404297 -0.69857824 -1.2928195  -0.05026372 -0.6334051  -1.3387425\n",
      " -0.05110985 -0.78348684 -1.4679341  -0.16925146 -0.5527444  -1.3745255\n",
      " -0.08861817 -0.60976547 -1.3594441  -0.07784118 -0.57366765 -1.4495385\n",
      "  0.06456681 -0.6162484  -1.4864514  -0.06657548 -0.44780385 -1.2025044\n",
      " -0.2168178  -0.20860589 -1.945015   -0.0178864  -0.38721728 -1.9553357\n",
      "  0.16468057 -0.34116924 -1.3419384  -0.1954241  -0.2133939  -1.1275856\n",
      " -0.09939852 -0.18688864 -1.2157271  -0.05542658 -0.2041131  -1.3331223\n",
      "  0.04159294 -0.21391766 -1.1669915   0.08      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[-0.0237, -0.0494, -0.2633,  ..., -0.0175, -0.2189, -1.3363],\n",
      "        [-0.0237, -0.0494, -0.2633,  ..., -0.0175, -0.2189, -1.3363],\n",
      "        [-0.0237, -0.0494, -0.2633,  ..., -0.0175, -0.2189, -1.3363],\n",
      "        ...,\n",
      "        [-0.2644,  0.3332, -0.1444,  ..., -0.7390,  0.7933, -0.3316],\n",
      "        [-0.1473, -0.0837,  0.6078,  ..., -0.2626,  0.6978,  0.3188],\n",
      "        [-0.1473, -0.0837,  0.6078,  ..., -0.2626,  0.6978,  0.3188]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-2.3688208e-02 -4.9367152e-02 -2.6334220e-01 -4.8511848e-04\n",
      " -1.9290404e-01 -7.0484644e-01 -9.3534790e-02 -3.6142206e-01\n",
      " -1.4303361e+00 -2.3984851e-01 -4.2042154e-01 -1.7222708e+00\n",
      " -4.1198125e-01 -5.2655768e-01 -2.2010558e+00 -2.2897351e-01\n",
      " -6.5024108e-01 -1.5839393e+00 -3.0038744e-02 -6.7323208e-01\n",
      " -1.3967865e+00 -7.5738817e-02 -6.0514337e-01 -1.4563630e+00\n",
      " -7.5721867e-02 -7.3325241e-01 -1.5683444e+00 -1.9117180e-01\n",
      " -5.4655164e-01 -1.5094808e+00 -1.1300826e-01 -5.9452361e-01\n",
      " -1.4791946e+00 -1.2941277e-01 -5.6887847e-01 -1.5760806e+00\n",
      "  5.8837086e-03 -5.8000410e-01 -1.6218044e+00 -1.1345508e-01\n",
      " -4.6755517e-01 -1.3382422e+00 -2.1366730e-01 -2.3529039e-01\n",
      " -1.9472837e+00 -7.1494363e-02 -3.7863958e-01 -1.9479171e+00\n",
      "  8.0125511e-02 -3.5099334e-01 -1.4809339e+00 -2.0451625e-01\n",
      " -2.3002766e-01 -1.2802100e+00 -1.4164972e-01 -2.0356287e-01\n",
      " -1.3598886e+00 -9.5035702e-02 -2.0679094e-01 -1.4808266e+00\n",
      " -1.7543890e-02 -2.1892588e-01 -1.3362913e+00]\n",
      "data: [-2.3688208e-02 -4.9367152e-02 -2.6334220e-01 -4.8511848e-04\n",
      " -1.9290404e-01 -7.0484644e-01 -9.3534797e-02 -3.6142203e-01\n",
      " -1.4303361e+00 -2.3984852e-01 -4.2042151e-01 -1.7222708e+00\n",
      " -4.1198123e-01 -5.2655768e-01 -2.2010558e+00 -2.2897351e-01\n",
      " -6.5024108e-01 -1.5839393e+00 -3.0038742e-02 -6.7323214e-01\n",
      " -1.3967865e+00 -7.5738817e-02 -6.0514337e-01 -1.4563630e+00\n",
      " -7.5721867e-02 -7.3325241e-01 -1.5683445e+00 -1.9117180e-01\n",
      " -5.4655164e-01 -1.5094810e+00 -1.1300826e-01 -5.9452361e-01\n",
      " -1.4791946e+00 -1.2941277e-01 -5.6887847e-01 -1.5760807e+00\n",
      "  5.8837086e-03 -5.8000410e-01 -1.6218044e+00 -1.1345508e-01\n",
      " -4.6755517e-01 -1.3382422e+00 -2.1366730e-01 -2.3529039e-01\n",
      " -1.9472837e+00 -7.1494363e-02 -3.7863958e-01 -1.9479172e+00\n",
      "  8.0125511e-02 -3.5099334e-01 -1.4809338e+00 -2.0451623e-01\n",
      " -2.3002766e-01 -1.2802100e+00 -1.4164972e-01 -2.0356287e-01\n",
      " -1.3598886e+00 -9.5035702e-02 -2.0679094e-01 -1.4808266e+00\n",
      " -1.7543890e-02 -2.1892588e-01 -1.3362913e+00  9.0000004e-02]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE62F63438>\n",
      "tensor([[ 0.0641, -0.1227, -0.2174,  ...,  0.0646, -0.3021, -1.2988],\n",
      "        [ 0.0641, -0.1227, -0.2174,  ...,  0.0646, -0.3021, -1.2988],\n",
      "        [ 0.0641, -0.1227, -0.2174,  ...,  0.0646, -0.3021, -1.2988],\n",
      "        ...,\n",
      "        [-0.2914,  0.2523, -0.3705,  ..., -0.8481,  0.7207, -0.5158],\n",
      "        [-0.1517, -0.0934,  0.5571,  ..., -0.2366,  0.6565,  0.3008],\n",
      "        [-0.1517, -0.0934,  0.5571,  ..., -0.2366,  0.6565,  0.3008]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.06413683 -0.12269788 -0.21738727  0.09069285 -0.2533096  -0.615709\n",
      "  0.00364892 -0.427685   -1.3750222  -0.14098433 -0.4869313  -1.6734829\n",
      " -0.3019487  -0.5912289  -2.1754525  -0.13501796 -0.7229125  -1.5533395\n",
      "  0.07075848 -0.75248474 -1.3829944   0.01586201 -0.6899018  -1.4399316\n",
      "  0.00674761 -0.82260936 -1.5561337  -0.09542019 -0.62573016 -1.4698699\n",
      " -0.01942503 -0.6750016  -1.4535122  -0.04101955 -0.6480965  -1.5532892\n",
      "  0.07737216 -0.6703931  -1.5957246  -0.01430532 -0.53931403 -1.3011799\n",
      " -0.12635607 -0.31015536 -1.9339943   0.01620221 -0.4588775  -1.9392638\n",
      "  0.156317   -0.4322217  -1.4528913  -0.11551087 -0.30725783 -1.240226\n",
      " -0.04323738 -0.2850654  -1.3188848  -0.00595326 -0.29285777 -1.435772\n",
      "  0.06458569 -0.302118   -1.29883   ]\n",
      "data: [ 0.06413683 -0.12269787 -0.21738727  0.09069285 -0.2533096  -0.615709\n",
      "  0.00364892 -0.42768496 -1.3750222  -0.14098433 -0.4869313  -1.673483\n",
      " -0.3019487  -0.5912289  -2.1754525  -0.13501796 -0.72291255 -1.5533395\n",
      "  0.07075848 -0.75248474 -1.3829944   0.01586201 -0.6899018  -1.4399316\n",
      "  0.00674761 -0.8226093  -1.5561337  -0.09542019 -0.62573016 -1.4698699\n",
      " -0.01942503 -0.6750016  -1.4535123  -0.04101955 -0.64809644 -1.5532892\n",
      "  0.07737216 -0.67039317 -1.5957246  -0.01430532 -0.53931403 -1.3011798\n",
      " -0.12635607 -0.31015536 -1.9339943   0.01620221 -0.45887747 -1.9392638\n",
      "  0.156317   -0.4322217  -1.4528913  -0.11551087 -0.30725783 -1.240226\n",
      " -0.04323738 -0.2850654  -1.3188848  -0.00595326 -0.29285777 -1.435772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.06458569 -0.302118   -1.2988299   0.1       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3C88>\n",
      "tensor([[ 0.0312, -0.1329, -0.2032,  ...,  0.0982, -0.3318, -1.2273],\n",
      "        [ 0.0312, -0.1329, -0.2032,  ...,  0.0982, -0.3318, -1.2273],\n",
      "        [ 0.0312, -0.1329, -0.2032,  ...,  0.0982, -0.3318, -1.2273],\n",
      "        ...,\n",
      "        [-0.1134,  0.4451, -0.0455,  ..., -0.6443,  0.9724, -0.3958],\n",
      "        [-0.1649, -0.0550,  0.5830,  ..., -0.2558,  0.6831,  0.1883],\n",
      "        [-0.1649, -0.0550,  0.5830,  ..., -0.2558,  0.6831,  0.1883]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.03123678 -0.13285375 -0.20315067  0.05984717 -0.26300412 -0.55737925\n",
      " -0.02667706 -0.46915314 -1.3576937  -0.17268789 -0.5336963  -1.6689419\n",
      " -0.34121987 -0.6606175  -2.1474698  -0.17155811 -0.74553263 -1.5442116\n",
      "  0.08213406 -0.7913329  -1.3427614   0.02151792 -0.7351886  -1.3861415\n",
      "  0.01220448 -0.87715834 -1.5095615  -0.1138593  -0.6418627  -1.4381689\n",
      " -0.0223249  -0.710067   -1.4189217  -0.02211232 -0.6846243  -1.513533\n",
      "  0.10005993 -0.72955394 -1.5609298  -0.00664964 -0.5465671  -1.2553037\n",
      " -0.1451869  -0.31543446 -1.9629658   0.0350382  -0.4970773  -1.9594404\n",
      "  0.19730231 -0.45461243 -1.4009455  -0.1324628  -0.30791742 -1.1846832\n",
      " -0.02503444 -0.28936076 -1.2633564   0.02649509 -0.322548   -1.3765013\n",
      "  0.0981631  -0.3318206  -1.2272526 ]\n",
      "data: [ 0.03123678 -0.13285375 -0.20315067  0.05984717 -0.26300412 -0.55737925\n",
      " -0.02667706 -0.46915314 -1.3576937  -0.17268789 -0.5336963  -1.6689419\n",
      " -0.34121987 -0.6606175  -2.1474698  -0.17155811 -0.74553263 -1.5442116\n",
      "  0.08213405 -0.79133296 -1.3427614   0.02151792 -0.7351886  -1.3861415\n",
      "  0.01220448 -0.87715834 -1.5095614  -0.1138593  -0.6418627  -1.438169\n",
      " -0.0223249  -0.710067   -1.4189217  -0.02211232 -0.6846243  -1.513533\n",
      "  0.10005994 -0.72955394 -1.5609298  -0.00664964 -0.5465671  -1.2553037\n",
      " -0.1451869  -0.31543446 -1.9629658   0.0350382  -0.4970773  -1.9594404\n",
      "  0.1973023  -0.45461243 -1.4009455  -0.1324628  -0.30791742 -1.1846832\n",
      " -0.02503444 -0.28936076 -1.2633564   0.02649509 -0.322548   -1.3765013\n",
      "  0.0981631  -0.3318206  -1.2272526   0.11      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE281B3978>\n",
      "tensor([[ 0.0242, -0.1194, -0.1874,  ...,  0.0666, -0.3217, -1.1733],\n",
      "        [ 0.0242, -0.1194, -0.1874,  ...,  0.0666, -0.3217, -1.1733],\n",
      "        [ 0.0242, -0.1194, -0.1874,  ...,  0.0666, -0.3217, -1.1733],\n",
      "        ...,\n",
      "        [-0.0865,  0.4492, -0.1217,  ..., -0.4422,  0.9944, -0.5175],\n",
      "        [-0.1014, -0.0331,  0.6132,  ..., -0.1912,  0.6923,  0.2277],\n",
      "        [-0.1014, -0.0331,  0.6132,  ..., -0.1912,  0.6923,  0.2277]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 2.42487453e-02 -1.19445123e-01 -1.87442809e-01  6.00603409e-02\n",
      " -2.27471039e-01 -4.83773172e-01 -7.29450062e-02 -4.57951218e-01\n",
      " -1.34045005e+00 -2.26540327e-01 -5.27255535e-01 -1.63559127e+00\n",
      " -3.80304962e-01 -6.27967834e-01 -2.14368463e+00 -1.66525126e-01\n",
      " -7.56270230e-01 -1.52141643e+00  2.73801237e-02 -8.22422504e-01\n",
      " -1.34769058e+00 -3.07783037e-02 -7.53522456e-01 -1.39595938e+00\n",
      " -4.82499227e-02 -9.21198249e-01 -1.52276039e+00 -1.18127376e-01\n",
      " -6.66808844e-01 -1.41511893e+00 -5.66622093e-02 -7.26372361e-01\n",
      " -1.38818789e+00 -6.86728060e-02 -6.94194973e-01 -1.47055507e+00\n",
      "  6.27729446e-02 -7.34996676e-01 -1.49202037e+00 -2.83196643e-02\n",
      " -5.56078136e-01 -1.24570251e+00 -1.92470223e-01 -3.17329049e-01\n",
      " -2.02968073e+00 -1.05107576e-03 -5.02308071e-01 -2.04878855e+00\n",
      "  1.68467999e-01 -4.59875703e-01 -1.34722972e+00 -1.54155821e-01\n",
      " -3.26233447e-01 -1.16684532e+00 -7.48168081e-02 -2.98801601e-01\n",
      " -1.25129652e+00 -3.78608406e-02 -3.08662176e-01 -1.36402440e+00\n",
      "  6.66077808e-02 -3.21688116e-01 -1.17330647e+00]\n",
      "data: [ 2.42487453e-02 -1.19445123e-01 -1.87442824e-01  6.00603372e-02\n",
      " -2.27471054e-01 -4.83773142e-01 -7.29450062e-02 -4.57951188e-01\n",
      " -1.34044993e+00 -2.26540342e-01 -5.27255535e-01 -1.63559127e+00\n",
      " -3.80304933e-01 -6.27967834e-01 -2.14368463e+00 -1.66525111e-01\n",
      " -7.56270230e-01 -1.52141643e+00  2.73801237e-02 -8.22422504e-01\n",
      " -1.34769058e+00 -3.07783037e-02 -7.53522515e-01 -1.39595938e+00\n",
      " -4.82499227e-02 -9.21198249e-01 -1.52276027e+00 -1.18127376e-01\n",
      " -6.66808844e-01 -1.41511881e+00 -5.66622131e-02 -7.26372361e-01\n",
      " -1.38818789e+00 -6.86728060e-02 -6.94194973e-01 -1.47055507e+00\n",
      "  6.27729446e-02 -7.34996617e-01 -1.49202037e+00 -2.83196643e-02\n",
      " -5.56078136e-01 -1.24570251e+00 -1.92470223e-01 -3.17329049e-01\n",
      " -2.02968073e+00 -1.05107576e-03 -5.02308071e-01 -2.04878855e+00\n",
      "  1.68467999e-01 -4.59875703e-01 -1.34722972e+00 -1.54155821e-01\n",
      " -3.26233447e-01 -1.16684532e+00 -7.48168081e-02 -2.98801601e-01\n",
      " -1.25129652e+00 -3.78608406e-02 -3.08662176e-01 -1.36402440e+00\n",
      "  6.66077808e-02 -3.21688116e-01 -1.17330647e+00  1.19999997e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[-0.0377, -0.0399, -0.1947,  ...,  0.0139, -0.2268, -1.1799],\n",
      "        [-0.0377, -0.0399, -0.1947,  ...,  0.0139, -0.2268, -1.1799],\n",
      "        [-0.0377, -0.0399, -0.1947,  ...,  0.0139, -0.2268, -1.1799],\n",
      "        ...,\n",
      "        [-0.1658,  0.3407, -0.0054,  ..., -0.7021,  0.9106, -0.4055],\n",
      "        [-0.0928, -0.0743,  0.6025,  ..., -0.2099,  0.6287,  0.2339],\n",
      "        [-0.0928, -0.0743,  0.6025,  ..., -0.2099,  0.6287,  0.2339]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.03774831 -0.03992422 -0.19473897 -0.01243975 -0.15870084 -0.4949648\n",
      " -0.12735745 -0.37710163 -1.3297752  -0.28171152 -0.43866843 -1.6375688\n",
      " -0.45143998 -0.55375177 -2.132227   -0.24856867 -0.66650164 -1.5130336\n",
      " -0.01886049 -0.71668226 -1.321993   -0.07531387 -0.6535468  -1.3678502\n",
      " -0.07726026 -0.80539876 -1.4983389  -0.19494838 -0.5655671  -1.4043918\n",
      " -0.11311267 -0.6261503  -1.3839012  -0.10599165 -0.5929922  -1.4791896\n",
      "  0.03668973 -0.63570625 -1.5161865  -0.09091795 -0.45850444 -1.2262201\n",
      " -0.24591611 -0.22186124 -1.980862   -0.0471673  -0.40311453 -1.9906731\n",
      "  0.13725306 -0.35888594 -1.3593925  -0.22135963 -0.22125784 -1.1511607\n",
      " -0.12512152 -0.19778231 -1.2314931  -0.0816659  -0.21746245 -1.348914\n",
      "  0.01385603 -0.22680221 -1.1798531 ]\n",
      "data: [-0.03774831 -0.03992422 -0.19473895 -0.01243975 -0.15870084 -0.49496478\n",
      " -0.12735745 -0.37710163 -1.3297752  -0.28171152 -0.43866843 -1.6375688\n",
      " -0.45143998 -0.55375177 -2.132227   -0.24856867 -0.66650164 -1.5130336\n",
      " -0.01886049 -0.71668226 -1.321993   -0.07531387 -0.6535468  -1.3678502\n",
      " -0.07726026 -0.80539876 -1.4983389  -0.19494838 -0.5655671  -1.4043918\n",
      " -0.11311267 -0.6261503  -1.3839012  -0.10599165 -0.5929922  -1.4791896\n",
      "  0.03668973 -0.63570625 -1.5161865  -0.09091795 -0.45850444 -1.2262201\n",
      " -0.24591611 -0.22186124 -1.980862   -0.0471673  -0.4031145  -1.9906731\n",
      "  0.13725306 -0.35888594 -1.3593925  -0.22135964 -0.22125784 -1.1511607\n",
      " -0.12512152 -0.19778231 -1.2314931  -0.0816659  -0.21746245 -1.348914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0.01385603 -0.22680221 -1.1798531   0.13      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[-0.0381, -0.0426, -0.2282,  ..., -0.0233, -0.2039, -1.3155],\n",
      "        [-0.0381, -0.0426, -0.2282,  ..., -0.0233, -0.2039, -1.3155],\n",
      "        [-0.0381, -0.0426, -0.2282,  ..., -0.0233, -0.2039, -1.3155],\n",
      "        ...,\n",
      "        [-0.2625,  0.2877, -0.1418,  ..., -0.7217,  0.7794, -0.3984],\n",
      "        [-0.1617, -0.1545,  0.5967,  ..., -0.2707,  0.6069,  0.2728],\n",
      "        [-0.1617, -0.1545,  0.5967,  ..., -0.2707,  0.6069,  0.2728]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.03810981 -0.04264897 -0.22820584 -0.02190181 -0.19071093 -0.67937016\n",
      " -0.0893152  -0.35502964 -1.3788745  -0.23496106 -0.4089102  -1.6915686\n",
      " -0.42217666 -0.5315005  -2.1519618  -0.25779396 -0.6365591  -1.5365748\n",
      " -0.00957195 -0.6505094  -1.321084   -0.05601606 -0.59472054 -1.3759925\n",
      " -0.05743404 -0.7143286  -1.4960885  -0.21222156 -0.5245661  -1.452388\n",
      " -0.11507596 -0.5806158  -1.4374485  -0.11338002 -0.55453604 -1.5484655\n",
      "  0.02540271 -0.57862675 -1.6157024  -0.11733846 -0.44212615 -1.2732351\n",
      " -0.22021596 -0.21473317 -1.8813736  -0.06540657 -0.36253792 -1.8731925\n",
      "  0.0950584  -0.3302967  -1.4619906  -0.221667   -0.19817558 -1.216789\n",
      " -0.13713618 -0.17464781 -1.3002193  -0.08387627 -0.19556005 -1.4254322\n",
      " -0.02325371 -0.20387158 -1.3154631 ]\n",
      "data: [-0.03810981 -0.04264897 -0.22820586 -0.02190181 -0.19071093 -0.67937016\n",
      " -0.0893152  -0.35502964 -1.3788745  -0.23496108 -0.4089102  -1.6915686\n",
      " -0.42217666 -0.5315005  -2.1519618  -0.25779396 -0.6365591  -1.5365748\n",
      " -0.00957195 -0.6505094  -1.321084   -0.05601606 -0.59472054 -1.3759925\n",
      " -0.05743404 -0.7143286  -1.4960885  -0.21222156 -0.5245661  -1.452388\n",
      " -0.11507596 -0.5806158  -1.4374484  -0.11338002 -0.55453604 -1.5484654\n",
      "  0.02540271 -0.57862675 -1.6157024  -0.11733846 -0.44212615 -1.2732351\n",
      " -0.22021598 -0.21473317 -1.8813736  -0.06540657 -0.36253792 -1.8731925\n",
      "  0.0950584  -0.3302967  -1.4619907  -0.221667   -0.19817558 -1.216789\n",
      " -0.13713618 -0.17464781 -1.3002193  -0.08387627 -0.19556005 -1.4254321\n",
      " -0.02325371 -0.20387158 -1.3154631   0.14      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B0F0>\n",
      "tensor([[ 0.0299, -0.1439, -0.2442,  ...,  0.0376, -0.3150, -1.3483],\n",
      "        [ 0.0299, -0.1439, -0.2442,  ...,  0.0376, -0.3150, -1.3483],\n",
      "        [ 0.0299, -0.1439, -0.2442,  ...,  0.0376, -0.3150, -1.3483],\n",
      "        ...,\n",
      "        [-0.2653,  0.3906, -0.3020,  ..., -0.8213,  0.8987, -0.5086],\n",
      "        [-0.1946, -0.0846,  0.6085,  ..., -0.2939,  0.6730,  0.3198],\n",
      "        [-0.1946, -0.0846,  0.6085,  ..., -0.2939,  0.6730,  0.3198]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.0298538  -0.14391011 -0.24423781  0.05697441 -0.28549737 -0.681025\n",
      " -0.0060932  -0.44251475 -1.4089224  -0.1460389  -0.4979305  -1.7133508\n",
      " -0.31055194 -0.6124377  -2.2051325  -0.17444907 -0.7304043  -1.5854133\n",
      "  0.06447209 -0.74331456 -1.398322    0.01097786 -0.68769073 -1.4531193\n",
      "  0.00466792 -0.80137426 -1.5702822  -0.13436328 -0.6270794  -1.5048027\n",
      " -0.03881597 -0.6774734  -1.4940504  -0.05171961 -0.6468235  -1.5980643\n",
      "  0.06644784 -0.674135   -1.6555318  -0.04524665 -0.54692304 -1.3288882\n",
      " -0.14116882 -0.3175038  -1.911627   -0.00223222 -0.46137166 -1.9061028\n",
      "  0.13680981 -0.4335003  -1.5068749  -0.14788775 -0.30984366 -1.2699134\n",
      " -0.0604154  -0.288244   -1.3428102  -0.01638269 -0.30619794 -1.4625696\n",
      "  0.03764743 -0.31502444 -1.3483033 ]\n",
      "data: [ 0.0298538  -0.14391011 -0.24423781  0.05697441 -0.28549737 -0.681025\n",
      " -0.0060932  -0.44251478 -1.4089224  -0.1460389  -0.4979305  -1.7133508\n",
      " -0.31055194 -0.6124377  -2.2051325  -0.17444906 -0.73040426 -1.5854133\n",
      "  0.06447209 -0.74331456 -1.398322    0.01097786 -0.68769073 -1.4531192\n",
      "  0.00466792 -0.80137426 -1.5702823  -0.13436328 -0.6270794  -1.5048027\n",
      " -0.03881597 -0.6774734  -1.4940505  -0.05171961 -0.6468235  -1.5980643\n",
      "  0.06644784 -0.674135   -1.6555318  -0.04524665 -0.54692304 -1.3288883\n",
      " -0.14116882 -0.3175038  -1.911627   -0.00223222 -0.46137166 -1.9061028\n",
      "  0.13680981 -0.4335003  -1.5068748  -0.14788775 -0.30984366 -1.2699134\n",
      " -0.0604154  -0.288244   -1.3428102  -0.01638269 -0.30619794 -1.4625696\n",
      "  0.03764743 -0.31502444 -1.3483033   0.15      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE4E09B9E8>\n",
      "tensor([[ 0.0435, -0.1766, -0.2422,  ...,  0.0788, -0.3595, -1.2904],\n",
      "        [ 0.0435, -0.1766, -0.2422,  ...,  0.0788, -0.3595, -1.2904],\n",
      "        [ 0.0435, -0.1766, -0.2422,  ...,  0.0788, -0.3595, -1.2904],\n",
      "        ...,\n",
      "        [-0.1186,  0.4849, -0.1236,  ..., -0.6752,  0.9911, -0.4452],\n",
      "        [-0.2041, -0.0457,  0.6276,  ..., -0.2737,  0.6681,  0.3047],\n",
      "        [-0.2041, -0.0457,  0.6276,  ..., -0.2737,  0.6681,  0.3047]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 4.3527272e-02 -1.7663789e-01 -2.4223381e-01  7.8749418e-02\n",
      " -2.9833889e-01 -5.8831215e-01 -1.4840521e-02 -5.1140106e-01\n",
      " -1.4035920e+00 -1.6345707e-01 -5.7329476e-01 -1.7139957e+00\n",
      " -3.1928372e-01 -6.8913555e-01 -2.2135279e+00 -1.5821391e-01\n",
      " -7.9360735e-01 -1.6034276e+00  8.3309934e-02 -8.4446192e-01\n",
      " -1.4105822e+00  1.9380555e-02 -7.8732693e-01 -1.4550551e+00\n",
      " -1.0527223e-03 -9.3588340e-01 -1.5824435e+00 -1.0538261e-01\n",
      " -6.9473433e-01 -1.4973481e+00 -2.4149761e-02 -7.5900555e-01\n",
      " -1.4816030e+00 -3.0742593e-02 -7.2911966e-01 -1.5755992e+00\n",
      "  8.2889125e-02 -7.7825689e-01 -1.6139568e+00 -3.8393810e-03\n",
      " -5.8567905e-01 -1.3223630e+00 -1.5737309e-01 -3.5167763e-01\n",
      " -2.0619133e+00  2.5752649e-02 -5.3551483e-01 -2.0683584e+00\n",
      "  1.8008700e-01 -4.9072614e-01 -1.4646356e+00 -1.3446394e-01\n",
      " -3.5108179e-01 -1.2488126e+00 -3.5026699e-02 -3.2604980e-01\n",
      " -1.3281660e+00  5.9310198e-03 -3.5323590e-01 -1.4425862e+00\n",
      "  7.8834482e-02 -3.5949987e-01 -1.2903644e+00]\n",
      "data: [ 4.3527268e-02 -1.7663787e-01 -2.4223381e-01  7.8749418e-02\n",
      " -2.9833889e-01 -5.8831215e-01 -1.4840521e-02 -5.1140106e-01\n",
      " -1.4035919e+00 -1.6345707e-01 -5.7329476e-01 -1.7139957e+00\n",
      " -3.1928372e-01 -6.8913561e-01 -2.2135279e+00 -1.5821391e-01\n",
      " -7.9360735e-01 -1.6034275e+00  8.3309934e-02 -8.4446192e-01\n",
      " -1.4105821e+00  1.9380555e-02 -7.8732699e-01 -1.4550551e+00\n",
      " -1.0527223e-03 -9.3588340e-01 -1.5824436e+00 -1.0538261e-01\n",
      " -6.9473433e-01 -1.4973481e+00 -2.4149761e-02 -7.5900561e-01\n",
      " -1.4816031e+00 -3.0742593e-02 -7.2911966e-01 -1.5755992e+00\n",
      "  8.2889125e-02 -7.7825689e-01 -1.6139568e+00 -3.8393810e-03\n",
      " -5.8567905e-01 -1.3223630e+00 -1.5737309e-01 -3.5167763e-01\n",
      " -2.0619133e+00  2.5752649e-02 -5.3551483e-01 -2.0683584e+00\n",
      "  1.8008700e-01 -4.9072611e-01 -1.4646356e+00 -1.3446394e-01\n",
      " -3.5108176e-01 -1.2488126e+00 -3.5026699e-02 -3.2604980e-01\n",
      " -1.3281660e+00  5.9310198e-03 -3.5323590e-01 -1.4425862e+00\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  7.8834482e-02 -3.5949984e-01 -1.2903644e+00  1.6000000e-01]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[ 0.0045, -0.1169, -0.1969,  ...,  0.0653, -0.3105, -1.1976],\n",
      "        [ 0.0045, -0.1169, -0.1969,  ...,  0.0653, -0.3105, -1.1976],\n",
      "        [ 0.0045, -0.1169, -0.1969,  ...,  0.0653, -0.3105, -1.1976],\n",
      "        ...,\n",
      "        [-0.0905,  0.4559, -0.0857,  ..., -0.6646,  1.0018, -0.4470],\n",
      "        [-0.0910, -0.0094,  0.6229,  ..., -0.1389,  0.6632,  0.2583],\n",
      "        [-0.0910, -0.0094,  0.6229,  ..., -0.1389,  0.6632,  0.2583]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.00453762 -0.11690919 -0.19685921  0.03183507 -0.24406844 -0.5109719\n",
      " -0.06206992 -0.45168757 -1.327222   -0.21487331 -0.51192623 -1.644766\n",
      " -0.3887117  -0.6381991  -2.1340082  -0.20579992 -0.732488   -1.5253258\n",
      "  0.04543698 -0.7761092  -1.3352877  -0.01711321 -0.71998495 -1.3813444\n",
      " -0.02075115 -0.86435884 -1.5090121  -0.14774935 -0.6276047  -1.4161204\n",
      " -0.05688647 -0.6941904  -1.4013921  -0.05450008 -0.6682055  -1.5026393\n",
      "  0.07378301 -0.71346414 -1.5457709  -0.03703917 -0.5259472  -1.2290218\n",
      " -0.18417957 -0.2956252  -1.9613945   0.00332676 -0.4794832  -1.9618422\n",
      "  0.17471029 -0.43787044 -1.3769917  -0.1653788  -0.28870362 -1.1608686\n",
      " -0.05895473 -0.27179134 -1.235601   -0.0134432  -0.30199605 -1.3523761\n",
      "  0.06529357 -0.3104623  -1.1976458 ]\n",
      "data: [ 0.00453762 -0.11690919 -0.19685921  0.03183507 -0.24406844 -0.5109719\n",
      " -0.06206992 -0.45168757 -1.327222   -0.21487331 -0.51192623 -1.644766\n",
      " -0.3887117  -0.6381991  -2.1340082  -0.20579992 -0.7324879  -1.5253258\n",
      "  0.04543698 -0.7761092  -1.3352876  -0.01711321 -0.71998495 -1.3813444\n",
      " -0.02075115 -0.86435884 -1.5090121  -0.14774935 -0.6276047  -1.4161204\n",
      " -0.05688647 -0.6941904  -1.4013921  -0.05450008 -0.6682055  -1.5026393\n",
      "  0.07378301 -0.71346414 -1.5457709  -0.03703917 -0.5259472  -1.2290218\n",
      " -0.18417957 -0.2956252  -1.9613945   0.00332676 -0.4794832  -1.9618422\n",
      "  0.17471029 -0.43787044 -1.3769917  -0.1653788  -0.28870362 -1.1608686\n",
      " -0.05895473 -0.27179134 -1.235601   -0.0134432  -0.30199605 -1.3523761\n",
      "  0.06529357 -0.3104623  -1.1976458   0.17      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[-0.0191, -0.0958, -0.1833,  ...,  0.0272, -0.2807, -1.1756],\n",
      "        [-0.0191, -0.0958, -0.1833,  ...,  0.0272, -0.2807, -1.1756],\n",
      "        [-0.0191, -0.0958, -0.1833,  ...,  0.0272, -0.2807, -1.1756],\n",
      "        ...,\n",
      "        [-0.1580,  0.3940, -0.0843,  ..., -0.6693,  0.9638, -0.4703],\n",
      "        [-0.0893, -0.0634,  0.6407,  ..., -0.2067,  0.6751,  0.2184],\n",
      "        [-0.0893, -0.0634,  0.6407,  ..., -0.2067,  0.6751,  0.2184]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.01908859 -0.09576681 -0.18327466  0.01463665 -0.20642507 -0.47797406\n",
      " -0.10660106 -0.43074018 -1.3304957  -0.2574301  -0.4939143  -1.6346601\n",
      " -0.41504422 -0.60016537 -2.1381733  -0.21972865 -0.7232349  -1.5141382\n",
      " -0.00497851 -0.7784967  -1.3375278  -0.05994688 -0.7137678  -1.3846178\n",
      " -0.06683493 -0.8724524  -1.5158446  -0.16929643 -0.62798125 -1.4043255\n",
      " -0.09562368 -0.686371   -1.3843553  -0.09415799 -0.6520131  -1.4766809\n",
      "  0.04569124 -0.69540936 -1.5110888  -0.07311351 -0.5171721  -1.229406\n",
      " -0.23259816 -0.27903807 -2.001381   -0.03404428 -0.46018744 -2.0177526\n",
      "  0.14547625 -0.41601384 -1.3574774  -0.20321156 -0.28349227 -1.1516134\n",
      " -0.11373684 -0.25605837 -1.2339513  -0.071877   -0.27112883 -1.350922\n",
      "  0.02715219 -0.28074154 -1.1755843 ]\n",
      "data: [-0.01908859 -0.09576681 -0.18327466  0.01463665 -0.20642507 -0.47797406\n",
      " -0.10660106 -0.43074018 -1.3304957  -0.2574301  -0.4939143  -1.6346602\n",
      " -0.41504422 -0.60016537 -2.1381733  -0.21972865 -0.7232349  -1.5141382\n",
      " -0.00497851 -0.7784967  -1.3375278  -0.05994688 -0.7137678  -1.3846178\n",
      " -0.06683493 -0.8724524  -1.5158446  -0.16929644 -0.62798125 -1.4043256\n",
      " -0.09562369 -0.686371   -1.3843553  -0.09415798 -0.65201306 -1.4766809\n",
      "  0.04569124 -0.6954094  -1.5110888  -0.07311351 -0.5171721  -1.229406\n",
      " -0.23259816 -0.27903807 -2.001381   -0.03404428 -0.46018746 -2.0177526\n",
      "  0.14547625 -0.41601384 -1.3574774  -0.20321156 -0.28349227 -1.1516134\n",
      " -0.11373684 -0.25605837 -1.2339513  -0.071877   -0.27112883 -1.350922\n",
      "  0.02715219 -0.28074154 -1.1755843   0.18      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE63025470>\n",
      "tensor([[-0.0223, -0.0243, -0.1814,  ...,  0.0165, -0.2117, -1.1751],\n",
      "        [-0.0223, -0.0243, -0.1814,  ...,  0.0165, -0.2117, -1.1751],\n",
      "        [-0.0223, -0.0243, -0.1814,  ...,  0.0165, -0.2117, -1.1751],\n",
      "        ...,\n",
      "        [-0.1907,  0.3503, -0.0403,  ..., -0.6738,  0.9280, -0.3971],\n",
      "        [-0.1104, -0.1130,  0.5938,  ..., -0.2262,  0.5992,  0.2545],\n",
      "        [-0.1104, -0.1130,  0.5938,  ..., -0.2262,  0.5992,  0.2545]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.02229249 -0.02434896 -0.18138547  0.003474   -0.13070127 -0.48659384\n",
      " -0.13142473 -0.34968823 -1.3197763  -0.2859124  -0.41122276 -1.6157851\n",
      " -0.4438397  -0.50697035 -2.1198404  -0.22216564 -0.6584527  -1.4908347\n",
      " -0.03284077 -0.7143272  -1.320652   -0.07976954 -0.63985103 -1.3732433\n",
      " -0.07888806 -0.8018737  -1.5028756  -0.17656037 -0.5682273  -1.3893116\n",
      " -0.11001571 -0.6189529  -1.3667314  -0.1072772  -0.5820998  -1.4576557\n",
      "  0.04789962 -0.6138466  -1.4856191  -0.08803452 -0.45976543 -1.2232642\n",
      " -0.23775166 -0.22065787 -1.9727726  -0.04404341 -0.39059097 -1.9950998\n",
      "  0.14672104 -0.34991193 -1.3467534  -0.21088898 -0.22787979 -1.1459143\n",
      " -0.13655017 -0.19702269 -1.2374864  -0.09774604 -0.20010072 -1.3556039\n",
      "  0.01649756 -0.21172288 -1.1750991 ]\n",
      "data: [-0.02229249 -0.02434896 -0.18138547  0.003474   -0.13070127 -0.48659384\n",
      " -0.13142473 -0.34968823 -1.3197763  -0.2859124  -0.41122276 -1.6157851\n",
      " -0.44383967 -0.50697035 -2.1198404  -0.22216564 -0.6584527  -1.4908347\n",
      " -0.03284077 -0.7143272  -1.320652   -0.07976954 -0.63985103 -1.3732435\n",
      " -0.07888806 -0.8018737  -1.5028756  -0.17656036 -0.5682273  -1.3893116\n",
      " -0.11001571 -0.6189529  -1.3667314  -0.1072772  -0.5820998  -1.4576557\n",
      "  0.04789962 -0.6138466  -1.4856191  -0.08803452 -0.45976543 -1.2232642\n",
      " -0.23775166 -0.22065787 -1.9727725  -0.04404341 -0.39059097 -1.9950998\n",
      "  0.14672104 -0.34991193 -1.3467534  -0.21088898 -0.22787979 -1.1459143\n",
      " -0.13655017 -0.19702269 -1.2374864  -0.09774604 -0.20010072 -1.3556039\n",
      "  0.01649756 -0.2117229  -1.1750991   0.19      ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE630256A0>\n",
      "tensor([[-0.0324, -0.0511, -0.2121,  ..., -0.0075, -0.2103, -1.3204],\n",
      "        [-0.0324, -0.0511, -0.2121,  ..., -0.0075, -0.2103, -1.3204],\n",
      "        [-0.0324, -0.0511, -0.2121,  ..., -0.0075, -0.2103, -1.3204],\n",
      "        ...,\n",
      "        [-0.2453,  0.2999, -0.1419,  ..., -0.7399,  0.7729, -0.3650],\n",
      "        [-0.1689, -0.1265,  0.5411,  ..., -0.2820,  0.6341,  0.2439],\n",
      "        [-0.1689, -0.1265,  0.5411,  ..., -0.2820,  0.6341,  0.2439]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[-0.03238913 -0.05113777 -0.21213908 -0.01859513 -0.21085131 -0.6748495\n",
      " -0.06938725 -0.36372507 -1.3603823  -0.21319593 -0.41675895 -1.6749524\n",
      " -0.40294188 -0.55104953 -2.1317499  -0.25798243 -0.6346263  -1.526272\n",
      "  0.01640601 -0.6378731  -1.296207   -0.03198266 -0.5852513  -1.3477582\n",
      " -0.03132626 -0.68922913 -1.4659141  -0.20999779 -0.5157631  -1.4460683\n",
      " -0.09763333 -0.5738407  -1.4344736  -0.09261505 -0.5467834  -1.5466366\n",
      "  0.0412699  -0.5723762  -1.6229818  -0.1051329  -0.4421885  -1.2633519\n",
      " -0.19445677 -0.21383719 -1.8253759  -0.04814624 -0.35989034 -1.8059391\n",
      "  0.1075     -0.32709122 -1.4677373  -0.2101362  -0.1934319  -1.21125\n",
      " -0.11156136 -0.17323186 -1.2900516  -0.0535388  -0.20318706 -1.4148936\n",
      " -0.00754917 -0.21030158 -1.3204253 ]\n",
      "data: [-0.03238913 -0.05113777 -0.21213908 -0.01859513 -0.21085131 -0.67484957\n",
      " -0.06938725 -0.36372507 -1.3603824  -0.21319593 -0.41675895 -1.6749524\n",
      " -0.40294188 -0.55104953 -2.1317499  -0.25798243 -0.6346263  -1.5262722\n",
      "  0.01640601 -0.6378731  -1.296207   -0.03198266 -0.5852513  -1.3477582\n",
      " -0.03132626 -0.68922913 -1.4659141  -0.20999779 -0.5157631  -1.4460683\n",
      " -0.09763333 -0.5738407  -1.4344735  -0.09261504 -0.5467834  -1.5466367\n",
      "  0.0412699  -0.5723762  -1.6229817  -0.10513291 -0.4421885  -1.2633519\n",
      " -0.19445677 -0.21383719 -1.825376   -0.04814624 -0.35989034 -1.8059391\n",
      "  0.1075     -0.32709122 -1.4677373  -0.2101362  -0.1934319  -1.21125\n",
      " -0.11156136 -0.17323186 -1.2900516  -0.0535388  -0.20318706 -1.4148936\n",
      " -0.00754917 -0.21030158 -1.3204253   0.2       ]\n",
      "mask: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.\n",
      " 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "img: [[3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.22  3.218 3.223 ... 3.215 3.222 3.223]\n",
      " [3.215 3.219 3.221 ... 3.209 3.201 3.196]\n",
      " ...\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.909 2.911 2.917 ... 2.944 2.937 2.935]\n",
      " [2.902 2.909 2.904 ... 2.93  2.93  2.929]]\n",
      "imask:  [[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "recall_set: <__main__.Mydatasets2 object at 0x000001DE2EA3FA90>\n",
      "tensor([[ 0.0164, -0.1369, -0.2563,  ...,  0.0189, -0.3045, -1.3541],\n",
      "        [ 0.0164, -0.1369, -0.2563,  ...,  0.0189, -0.3045, -1.3541],\n",
      "        [ 0.0164, -0.1369, -0.2563,  ...,  0.0189, -0.3045, -1.3541],\n",
      "        ...,\n",
      "        [-0.2665,  0.4464, -0.3108,  ..., -0.8218,  0.9516, -0.5557],\n",
      "        [-0.1835, -0.0508,  0.6460,  ..., -0.2694,  0.7203,  0.3197],\n",
      "        [-0.1835, -0.0508,  0.6460,  ..., -0.2694,  0.7203,  0.3197]],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n",
      "[ 0.01644298 -0.1368838  -0.2562804   0.04181166 -0.280289   -0.6913363\n",
      " -0.03232475 -0.44970137 -1.4306872  -0.1731234  -0.5085337  -1.7284698\n",
      " -0.33511522 -0.61911404 -2.2193117  -0.18724266 -0.7324282  -1.6048625\n",
      "  0.0351654  -0.75202453 -1.4277562  -0.01564588 -0.6932374  -1.4818894\n",
      " -0.02021458 -0.81189024 -1.5972384  -0.14897977 -0.6268275  -1.5247351\n",
      " -0.06022799 -0.6767452  -1.5071702  -0.07300251 -0.6456907  -1.6045094\n",
      "  0.04784749 -0.67071533 -1.6572596  -0.06271068 -0.541787   -1.3542098\n",
      " -0.1656697  -0.31273064 -1.9495099  -0.02312613 -0.45814797 -1.9472139\n",
      "  0.11813469 -0.42596927 -1.5142043  -0.16541745 -0.30464178 -1.2912889\n",
      " -0.08404382 -0.27972028 -1.3633522  -0.04042459 -0.29448685 -1.4810777\n",
      "  0.01889513 -0.30453455 -1.3540697 ]\n"
     ]
    }
   ],
   "source": [
    "#recallset = Mydatasets2(datas = data_recall, img_array = img_recall, data_masks = mask_recall, transform = trans)\n",
    "\n",
    "def recall_sequence(data, mask, img, imask):\n",
    "    data = data.astype('float32')/100\n",
    "    mask = mask.astype('float32')\n",
    "    img = img.astype('float32')\n",
    "    imask = imask.astype('float32')\n",
    "    \n",
    "    #data = np.array(data.astype(np.float32))\n",
    "    #mask = np.array(mask.astype(np.float32))\n",
    "    #img = trans(np.array(img.astype(np.float32)))\n",
    "    \n",
    "    print(\"data:\",data)\n",
    "    print(\"mask:\",mask)\n",
    "    print(\"img:\",img)\n",
    "    print(\"imask: \",imask)\n",
    "    #init_l_points = np.array(init_l_points.astype(np.float32))\n",
    "    #print(init_l_points)\n",
    "    recallset = Mydatasets2(datas = data, img_array = img, data_masks = mask, img_masks = imask, transform = trans)\n",
    "    print(\"recall_set:\",recallset)\n",
    "    recallloader = torch.utils.data.DataLoader(recallset, batch_size = 25, shuffle = False, num_workers = 0)\n",
    "    \n",
    "    #net.eval()\n",
    "    for (inputs, imgs, masks, imasks) in recallloader:\n",
    "    #tmp = recallloader.__iter__()\n",
    "    #inputs, imgs, masks = tmp.next()\n",
    "        inputs, imgs, masks, imasks = inputs.to(device), imgs.to(device), masks.to(device), imasks.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        handloc, pose_h, posedesc = net(input_img, inputs, input_mask, img_mask)\n",
    "        #手首位置基準座標→物体位置基準座標\n",
    "        xd = torch.zeros_like(pose_h).to(device)\n",
    "        yd = torch.zeros_like(pose_h).to(device)\n",
    "        zd = torch.zeros_like(pose_h).to(device)\n",
    "        for bsize in range(pose_h.size()[0]):\n",
    "            xval = handloc[bsize][0].item()\n",
    "            yval = handloc[bsize][1].item()\n",
    "            zval = handloc[bsize][2].item()\n",
    "            for i in range(int(pose_h.size()[1] / 3)):\n",
    "                xd[bsize][i*3+0] = xval\n",
    "                yd[bsize][i*3+1] = yval\n",
    "                zd[bsize][i*3+2] = zval\n",
    "        recall_out = (pose_h + xd + yd + zd).to(device)\n",
    "        print(recall_out)\n",
    "        break\n",
    "    recall_out_np = recall_out.to('cpu').detach().numpy().copy()\n",
    "    print(recall_out_np[0])\n",
    "    return recall_out_np[0]\n",
    "\n",
    "mask_static = np.ones(data_recall.shape[1])\n",
    "\n",
    "for r in range(len(data_recall)):\n",
    "    with open(PATH + \"\\\\recalls\\\\{:0=4}\".format(r) + \"\\\\recall_0.csv\" , 'w') as f:\n",
    "        writer = csv.writer(f)\n",
    "        record = data_recall[r]\n",
    "        writer.writerow(record.tolist())\n",
    "    initial = recall_sequence(data_recall[r], mask_recall[r], img_recall[r], imgmask_recall[r])\n",
    "    print(\"init:\",initial)\n",
    "    print(\"type:\",type(initial))\n",
    "    \n",
    "    for t in range(20):\n",
    "        initial = (initial*100).tolist()\n",
    "        initial.append(t+1)\n",
    "        with open(PATH + \"\\\\recalls\\\\{:0=4}\".format(r) + \"\\\\recall_\" + \"{:0=2}\".format(t+1) + \".csv\", 'w') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(initial)\n",
    "        initial = recall_sequence( np.array(initial), mask_static, img_recall[r], imgmask_recall[r])\n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mydatasets3(torch.utils.data.Dataset):\n",
    "    def __init__(self, datas, img_array, data_masks, img_masks, transform = None):\n",
    "        self.transform = transform\n",
    "        #self.transform2 = torchvision.transforms.Compose([torchvision.transforms.ToTensor()])\n",
    "\n",
    "        self.data = datas\n",
    "        self.img_array = img_array\n",
    "        self.masks = data_masks\n",
    "        self.img_masks = img_masks\n",
    "\n",
    "        self.datanum = datas.shape[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.datanum\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        #batch_set = []\n",
    "        \n",
    "        i_data = self.data[idx]\n",
    "        i_img = self.img_array[idx]\n",
    "        i_mask = self.masks[idx]\n",
    "        i_imask = self.img_masks[idx]\n",
    "        \n",
    "        #print(out_label)\n",
    "        #print(type(i_label))\n",
    "        out_data = np.array(i_data.astype(np.float32))\n",
    "        out_img = np.array(i_img.astype(np.float32))\n",
    "        out_mask = np.array(i_mask.astype(np.float32))\n",
    "        out_imask = np.array(i_imask.astype(np.float32))\n",
    "        #out_label.append(i_label.astype(np.float32))\n",
    "        #print(type(out_label))\n",
    "\n",
    "        if self.transform:\n",
    "            #out_data = self.transform(i_data)\n",
    "            out_img = self.transform(out_img)\n",
    "            out_imask = self.transform(out_imask)\n",
    "            #out_label = self.transform2(out_label)\n",
    "        \n",
    "        #batch_set.append(out_data)\n",
    "        #batch_set.append(out_label)\n",
    "        #batch_set.append(out_img)\n",
    "        #batch_set.append(out_mask)\n",
    "        #batch_set.append(out_lmask)\n",
    "\n",
    "        return out_data, out_img, out_mask, out_imask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(600, 64)\n",
      "(600, 36, 36)\n",
      "(600, 64)\n",
      "(600, 36, 36)\n",
      "train_test\n"
     ]
    }
   ],
   "source": [
    "data_check = []\n",
    "img_check = []\n",
    "mask_check = []\n",
    "imgmask_check = []\n",
    "for i in range(len(img_skeleton_sets_train)):\n",
    "    data_check.append(img_skeleton_sets_train[i][0])\n",
    "    img_check.append(img_skeleton_sets_train[i][1])\n",
    "    mask_check.append(img_skeleton_sets_train[i][2])\n",
    "    imgmask_check.append(img_skeleton_sets_train[i][3])\n",
    "    \n",
    "data_check = np.array(data_check).astype('float32')/100\n",
    "img_check = np.array(img_check).astype('float32')/1000\n",
    "mask_check = np.array(mask_check).astype('float32')\n",
    "imgmask_check = np.array(imgmask_check).astype('float32')\n",
    "print(data_check.shape)\n",
    "print(img_check.shape)\n",
    "print(mask_check.shape)\n",
    "print(imgmask_check.shape)\n",
    "\n",
    "checkset = Mydatasets3(datas = data_check, img_array = img_check, data_masks = mask_check, img_masks = imgmask_check, transform = trans)\n",
    "\n",
    "checkloader = torch.utils.data.DataLoader(checkset, batch_size = BATCH_SIZE,\n",
    "                        shuffle = False, num_workers = 0)\n",
    "\n",
    "print(\"train_test\")\n",
    "#train dataを使ってテストをする(パラメータ更新がないようになっている)\n",
    "num = 0\n",
    "net.eval()\n",
    "for (inputs, input_img, input_mask, input_imask) in checkloader:\n",
    "    inputs, input_img, input_mask, input_imask = \\\n",
    "    inputs.to(device), input_img.to(device), input_mask.to(device), input_imask.to(device)\n",
    "    optimizer.zero_grad()\n",
    "    outputs = net(input_img, inputs, input_mask, input_imask)\n",
    "    out_np = (outputs.to('cpu').detach().numpy().copy()) * 100\n",
    "    for b in range(BATCH_SIZE):\n",
    "        with open(PATH + \"\\\\checks\\\\check_\" + str((num * BATCH_SIZE) + b) + \".csv\" , 'w') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(out_np[b].tolist())\n",
    "    num += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(net.state_dict(), PATH + \"\\\\model8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.pool = nn.AvgPool2d(2, stride=2)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1,16,3)\n",
    "        self.conv2 = nn.Conv2d(16,32,3)\n",
    "        self.bn2d1 = nn.BatchNorm2d(16)\n",
    "        self.bn2d2 = nn.BatchNorm2d(32)\n",
    "        \n",
    "        self.fcm = Ignore(32 * 7 * 7 + 64, 32 * 7 * 7 + 64)\n",
    "        self.bnm = nn.BatchNorm1d(32 * 7 * 7 + 64)\n",
    "        #fully connect for hand Location(x,y,z)\n",
    "        self.fcL1 = nn.Linear(32 * 7 * 7 + 64, 300)\n",
    "        self.fcL2 = nn.Linear(300, 30)\n",
    "        self.fcL3 = nn.Linear(30, 3)        \n",
    "        self.bnL1 = nn.BatchNorm1d(300)\n",
    "        self.bnL2 = nn.BatchNorm1d(30)\n",
    "        #fully connect for hand Pose Descriptor(8 properties)\n",
    "        self.fcPD1 = nn.Linear(32 * 7 * 7 + 64, 300)\n",
    "        self.fcPD2 = nn.Linear(300, 60)\n",
    "        self.fcPD3 = nn.Linear(60, 8)\n",
    "        self.bnPD1 = nn.BatchNorm1d(300)\n",
    "        self.bnPD2 = nn.BatchNorm1d(60)\n",
    "\n",
    "    def forward(self, x, y, m, im):\n",
    "        #print(\"original: \",x[0][0:2],\"\\n\",x[1][0:2], x.size())\n",
    "        #print(\"original mask: \",im[0][0:2],\"\\n\",im[1][0:2], im.size())\n",
    "        \n",
    "        #Conv2d 1\n",
    "        x = self.conv1(x)\n",
    "        im = self.conv1(im)\n",
    "        #print(\"conv1: \",x[0:2][0:2], x.size())\n",
    "        #print(\"conv1 mask: \",im[0:2][0:2], im.size())\n",
    "        im_conv1 = im.clone().detach().to(torch.device(\"cuda:0\"))\n",
    "        for c in range(im.size()[1]):\n",
    "            mode, ind = torch.mode(torch.reshape(im[0][c].clone().detach(), (-1, im.size()[2] * im.size()[3])))\n",
    "            im_conv1[:,c] = torch.sub(im_conv1[:,c], mode.item())\n",
    "        #print(\"conv1 mask fix: \",im_conv1[0:2][0:2], im_conv1.size())       \n",
    "        \n",
    "        #ReLU→BatchNorm2d 1\n",
    "        x = self.bn2d1(self.relu(x))\n",
    "        #print(\"relu1: \", x[0:2][0:2], x.size())\n",
    "        #x = self.bn2d1(self.tanh(x))\n",
    "        #print(\"tanh1: \", x[0:2][0:2], x.size())\n",
    "        \n",
    "        #AvgPool2d\n",
    "        x = self.pool(x)\n",
    "        im = self.pool(im_conv1)\n",
    "        #print(\"pool1: \", x[0:2][0:2], x.size())\n",
    "        #print(\"pool1 mask: \",im[0:2][0:2], im.size())\n",
    "        \n",
    "        #Conv2d 2\n",
    "        x = self.conv2(x)\n",
    "        im = self.conv2(im)\n",
    "        #print(\"conv2: \",x[0:2][0:2], x.size())\n",
    "        #print(\"conv2 mask: \",im[0:2][0:2], im.size())\n",
    "        im_conv2 = im.clone().detach().to(torch.device(\"cuda:0\"))\n",
    "        for c in range(im.size()[1]):\n",
    "            mode, ind = torch.mode(torch.reshape(im[0][c].clone().detach(), (-1, im.size()[2] * im.size()[3])))\n",
    "            im_conv2[:,c] = torch.sub(im_conv2[:,c], mode.item())\n",
    "        #print(\"conv2 mask fix: \",im_conv2[0:2][0:2], im_conv2.size())\n",
    "        \n",
    "        #ReLU→BatchNorm2d 2\n",
    "        x = self.bn2d2(self.relu(x))\n",
    "        #print(\"relu2: \", x[0:2][0:2], x.size())\n",
    "        #x = self.bn2d2(self.tanh(x))\n",
    "        #print(\"tanh2: \", x[0:2][0:2], x.size())\n",
    "        \n",
    "        #AvgPool2d\n",
    "        x = self.pool(x)\n",
    "        im = self.pool(im_conv2)\n",
    "        #print(\"pool2: \", x[0:2][0:2], x.size())\n",
    "        #print(\"pool2 mask: \",im[0:2][0:2], im.size())\n",
    "        \n",
    "        #1次元ベクトル化\n",
    "        x = x.view(x.size()[0], -1)\n",
    "        im = im.view(im.size()[0], -1)\n",
    "        #print(\"view: \", x[0:2], x.size())\n",
    "        #print(\"view mask: \",im[0:2], im.size())\n",
    "        \n",
    "        #マスク再構築(0→1, 0以外→0)\n",
    "        im = torch.logical_not(torch.logical_and(im, torch.tensor([True]).to(torch.device(\"cuda:0\")))).float()\n",
    "        #print(\"mask_img: \", im[0:2], im.size())\n",
    "        \n",
    "        #骨格データと結合\n",
    "        x = torch.cat([x, y], axis = -1)\n",
    "        m = torch.cat([im, m], axis = -1)\n",
    "        #print(\"cat: \", x[0:2], x.size())\n",
    "        #print(\"cat mask: \", m[0:2], m.size())\n",
    "        \n",
    "        #MaskedLinear\n",
    "        x = self.fcm(x, m)\n",
    "        #print(\"masked: \", x[0], x.size())\n",
    "        x = self.bnm(self.relu(x))\n",
    "        #x = self.bnm(self.tanh(x))\n",
    "        xL = self.fcL1(x)\n",
    "        xPD = self.fcPD1(x)\n",
    "        #print(\"fc1: \",x[0])\n",
    "        xL = self.bnL1(self.relu(xL))\n",
    "        xPD = self.bnPD1(self.relu(xPD))\n",
    "        #x = self.bn1(self.tanh(x))\n",
    "        xL = self.fcL2(xL)\n",
    "        xPD = self.fcPD2(xPD)\n",
    "        #print(\"fc2: \",x[0])\n",
    "        xL = self.bnL2(self.relu(xL))\n",
    "        xPD = self.bnPD2(self.relu(xPD))\n",
    "        #x = self.bn2(self.tanh(x))\n",
    "        xL = self.fcL3(xL)\n",
    "        xPD = self.fcPD3(xPD)\n",
    "        return xL, xPD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
